
@_date: 2010-08-04 10:32:22
@_author: Dirk Walter 
@_subject: Gnupg good for big groups? 
I disagree with you there, as long as the archive is large enough that
a person could not read it all there are sensible reasons to lock out
people, say an archive of internal company documents. You want to lock
out employees that leave, sure they might still have copies of the
documents but the damage is limited if they can't get more to
deliberately do damage. You could probably implement access control
using a quorum type key setup where multiple parties need to agree to
a decryption before it can happen but I can't think of any such key
schema that would allow you to change users dynamically, and it also
doesn't really conform to your usecase.
That said assess control is not usually solved by crypto, and this is
not a case where I would use GNUPG, all it can realistically add is
transport level security. Your solution of using a service to provide
the data after checking for access is probably the right one.

@_date: 2010-06-02 11:15:36
@_author: Dirk Walter 
@_subject: Trying to build gpg on AIX 6.1 
Hello all, I am trying to build gpg on an AIX 6.1 machine and while
some people have reported success I can't even get configure to
successfully run. The problem seems to be with the -V flag which takes
arguments but none are provided in the configure script. I have
included the part of the log I believe are relevant.
I get the same regardless of if I run plain "./configure" or
"CFLAGS="-g -O2 -mcpu=powerpc" ./configure" as I have read elsewhere.
What am I doing wrong?
configure:3305: result: gcc
configure:3543: checking for C compiler version
configure:3550: gcc --version >&5
gcc (GCC) 4.2.4
Copyright (C) 2007 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
configure:3553: $? = 0
configure:3560: gcc -v >&5
Using built-in specs.
Target: powerpc-ibm-aix5.3.0.0
Configured with: ../gcc-4.2.4/configure --with-as=/usr/bin/as
--with-ld=/usr/bin/ld --enable-languages=c,c++,fortran
--prefix=/opt/freeware --enable-threads
--enable-version-specific-runtime-libs --disable-nls
--enable-decimal-float=dpd --host=powerpc-ibm-aix5.3.0.0
Thread model: aix
gcc version 4.2.4
configure:3563: $? = 0
configure:3570: gcc -V >&5
gcc: '-V' option must have argument
configure:3573: $? = 1
configure:3596: checking for C compiler default output file name
configure:3623: gcc    conftest.c  >&5
gcc: error trying to exec 'cc1': execvp: No such file or directory
configure:3626: $? = 1
configure:3664: result:
configure: failed program was:
configure:3670: error: C compiler cannot create executables
See `config.log' for more details

@_date: 2010-06-29 10:36:53
@_author: Dirk Walter 
@_subject: On the fly encryption of files possible? 
It would seem like a fairly trivial thing to code, just have whatever
is writing the file pipe it to GNUPG with the appropriate settings and
write output of gpg to disk. I don't think there if a front end that
does it for you though, some custom code seems unavoidable but
depending on your precise usecase and language it might just be a line
or two.

@_date: 2010-06-29 13:25:04
@_author: Dirk Walter 
@_subject: On the fly encryption of files possible? 
That depends on the source of the files, if you have eg a java app
that is generating the files it would be trivial to pipe it through
gpg, similarly if it is done through an ftp server or something it is
also trivial. I'm not sure how I would deal with multiple sources,
that indeed requires a bit more thought, but usually in these kinds of
use cases you are dealing with a single source for all or most of the
files. That is why usecase details matter.
Also if you are dealing with 10'000 multi gig files a second and it's
highly time critical you'll need loadbalancing and failover between
multiple systems, and kernel drivers etc, although the only case I
could think of where something like this would apply is to collate all
the data from us satellites and transmit it to the people in the
warzone in which case you should have the resources to do it right. If
you are dealing with one or two small files a minute you don't need
that kind of infrastructure.
But even if there are multiple sources I would think about doing
something like the printer demon that picks up files from a given
directory and encrypts them and deletes the source file. Probably want
to put some additional security on that but that again depends on what
the usecase is.

@_date: 2011-02-03 16:29:41
@_author: Dirk Walter 
@_subject: moving user ID Comments to --expert mode 
I like the idea of adding the (Optional) to the prompt because I'm a
big fan of optional fields being marked as such. This is an simple and
elegant fix to an issue.
And I'd hesitate to move it to expert since we have been (ab)using the
comment field for our keys, then again this is being used by sysadmins
who should know what they are doing, so moving it to expert mode
shouldn't be too bad... but what should be is not the same as what is.
