
@_date: 2010-04-28 16:52:51
@_author: Aleksander Adamowski 
@_subject: Encrypting/decrypting large amounts of data in parallel using GnuPG  
Does anyone here on the list have experience with encrypting large
files with GnuPG using a private key stored on HSM, with many
encryptions going on in parallel?
As far as I understand:
1) unless the --symmetric option is employed, data encryption employs
a randomly generated one time symmetric key, which is encrypted by
recipient's public key. Data decryption obtains the symmetric key
embedded in the message and decrypts it using the private key - this
is the step where a SmartCard or HSM can be potentially employed
2) If the --symmetric option is used, symmetric data encryption using
a password-based key is used and no SmartCard nor HSM can be employed.
3) SmartCards / HSMs must employ the OpenPGP standard
4) PKCS interface to HSMs is not supported by the official GnuPG
distribution due to personal options of Werner Koch, but an
independent SmartCard daemon has been developed:
only way to use hardware assisted encryption and key management by the
official GnuPG is through the use of SmartCard devices.
As far as I understand, SmartCards generally don't support
multithreading or parallel processing, and any cryptographic
operations involving them must be carried out sequentially.
In the crypto security world of financial institutions, when massive
amounts of crypto operations are to be performed in parallel, usually
HSMs from companies like Thales or SafeNet are employed, and PKCS
is the usual programming interface of choice in accessing them. This
handles massive amounts of parallel cryptographic operations
Keeping that in mind, did anyone try to use GnuPG in a massively
parallel crypto processing scenario with hardware assisted decryption?
How did you accomplish that?
Did you go the OpenPGP card way (e.g. a massive array of redundant
SmartCards?) or the PKCS way (which vendor's HSMs did you use?)?
What performance did you get out of your setup (number of parallel
encryptions/decryptions, number of decryptions/second, data file sizes
Best Regards,
?Aleksander Adamowski

@_date: 2010-04-29 14:57:33
@_author: Aleksander Adamowski 
@_subject: Encrypting/decrypting large amounts of data in parallel using  
I'd tend to disagree. When symmetric encryption becomes a bottleneck,
we can usually add more CPU cores to process more encryptions in
Also, for small portions of data, this should not become a concern.
However, depending on a single SmartCard to realize asymmetric crypto
ops is a bottleneck which seems much harder to overcome.
I'm not talking about symmetric crypto, and, specifically, not about
PGP encryption at all, since it doesn't involve the private asymmetric
I suppose that host-handled, purely software crypto is not a concern,
exactly for the reasons you have listed - it's quite easy to scale
What I'm talking about, is PGP *decryption* and *signing* (the
operations which have to involve the secret key) using a SmartCard or
I want to have the private key securely stored in the hardware
(SmartCard or HSM), asymmetric crypto ops securely performed in the
hardware and I'm concerned with the hardware becoming a bottleneck.
I suspect that handling e.g. 50 PGP signatures and/or decryptions per
second may be too much for this kind of setup - am I right?
In such a case, I'd like to know what behaviour would gpg agent
exhibit under high load:
* will it queue the crypto requests?
* will these requests wait indefinitely if the queue grows faster than
it is processed or will they timeout?
* is there a way to add more SmartCards with readers with the same
keypair loaded onto them, and load balance them?
As an alternative, I'd like to know whether anyone tried using
gnupg-pkcs11 and a HSM (like Thawte/nCipher/nShield or SafeNet Luna)
for handling large loads with GnuPG.
