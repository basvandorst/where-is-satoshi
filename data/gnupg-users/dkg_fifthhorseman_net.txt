
@_date: 2009-08-11 14:35:16
@_author: Daniel Kahn Gillmor 
@_subject: Entropy-on-a-key 
Bdale Garbee reports a prototype of that key working quite well with debian:
i think it could be very useful.

@_date: 2009-08-13 10:25:25
@_author: Daniel Kahn Gillmor 
@_subject: Two convicted in U.K. for refusal to decrypt data 
Some of them may molest children and some may want to be terrorists (is
wanting to be a terrorist illegal in your jurisdiction?).  Some of them
may simply be accused of doing these things (or of other activities
which you might find more or less offensive than molestation or
terrorism-wanting).  And perhaps they are accused incorrectly.
It sounds like the innocent accused will still be at risk of conviction
(for violating RIPA if not for their alleged crimes) if they choose to
maintain personal and data privacy in the face of these accusations.
It sounds like the UK has made laws that target users of encryption
whether or not those users have actually broken other laws.  So in that
sense, encryption *is* about having a tool to break the law, at least in
the UK :(

@_date: 2009-08-27 15:25:57
@_author: Daniel Kahn Gillmor 
@_subject: changing key expiration 
Hi Berhnard--
yes, the most recent certification made by the same issuer on a given
subject is considered to supercede all other signatures by the same
issuer over that subject (in your case, this is a self-signature, so the
issuer is the same as the subject).
A revocation of the User ID from your Key with timestamp X will
effectively revoke *any* certification over the Key/User ID pair with a
timestamp < X.
So even if you were to issue a revocation of an earlier signature, if
the timstamp of your revocation happens to post-date a signature you
wanted to keep, it would be effectively invalidated by the same
revocation.  At least, this is how gpg appears to interpret the spec,
and it seems to be the only reasonable interpretation.
So the answer is: you don't need to issue a revocation for the earlier
certifications; they're already superceded by the new certification you
made.  And it could be actively harmful to try to issue a revocation
even for the first one (which you *can* distinguish by date) because the
revocation will effectively clobber *any* certification over the same
key/user ID made prior to the revocation.
If i've made any mistakes above, i hope someone will step in and correct me!

@_date: 2009-08-27 16:06:39
@_author: Daniel Kahn Gillmor 
@_subject: changing key expiration 
Yes, i'm pretty sure you can do this, but i always take pains to try to
update the expiration date *before* it passes ;)

@_date: 2009-12-01 13:12:15
@_author: Daniel Kahn Gillmor 
@_subject: Equivalent segments between different Fedora & RPM Fusion ASCII 
These blocks are actually certificates, not just public keys -- that is,
each one contains a public key, one more more User IDs, and a signature
for each User ID from the public key, binding it to the given User ID.
The entire thing is Base64-encoded, but the User ID packets in there are
simple UTF-8 text (and the two certificates have very similar User IDs).
So the similar regions are most likely the regions of each certificate
that contains the User ID.
Try the following transformation on each key to see the internals in
ascii-ish form:
 grep '^[^-]' $KEYFILE | base64 -d | hd
search through the right-hand columns of the output for "fedora".
You might also be interested in breaking the certificate apart into its
component elements.  You can use gpgsplit for this.  Set KEYID to the
key you're interested in, and:
 mkdir $KEYID-parts && \
  (cd $KEYID-parts && gpg --export $KEYID | gpgsplit) && \
  ls -l $KEYID-parts
Compare the *.user_id pieces of each of each key to see how similar they
No idea.  These appear to be fedora package names, if my memory of rpm
is correct.  Perhaps you should ask this question on a fedora list?

@_date: 2009-12-14 11:56:28
@_author: Daniel Kahn Gillmor 
@_subject: --edit-key Information 
maybe this info could go in DETAILS as well?
If you're curious about what these words themselves mean in the context
of OpenPGP, you might be interested in the relevant section of the
OpenPGP RFC:

@_date: 2009-12-15 19:04:45
@_author: Daniel Kahn Gillmor 
@_subject: The number of lines of a key opened in a text-editor 
If you're interested in making those unintelligible lines more
intelligible, you could also try running the key through gpg
--list-packets. if you've saved the file as example.cert, you'd do that
like this:
 gpg --list-packets < example.cert
(this assumes a regular shell on a modern operating system.  i don't
know if the windows shell supports this kind of redirection).
This will print out details of what exactly is in the certificate.

@_date: 2009-07-02 09:07:43
@_author: Daniel Kahn Gillmor 
@_subject: My public key block appears different on keyservers 
What you're referring to as a "public key" is actually a compound
certificate which contains a public key and (potentially many)
associated certifications.  Internally, the certificate structure
usually looks something like this:
Primary public key (pub)
+--User ID A
+--User ID B
+--Public key of subkey (sub)
   +---Binding signature by pub (certifies that sub belongs to pub)
Different keyservers may have gotten different User IDs, different
signatures, and different subkeys associated with this particular
compound certificate at different times.  And certain kinds of
re-orderings within the certificate leave the certificate semantically
unchanged.  For example "User ID A" and all of its dependent signatures
could be placed after "User ID B" without changing the meaning of the
cert.  Also, signatures associated with any single User ID or subkey can
be re-ordered without changing the semantic content of the cert.
If you're interested in exactly what is in the certificates you've
downloaded, to see what the underlying differences are, you can use
GnuPG to get a more human-readable form:
 gpg --list-packets < cert-from-keyserver0.gpg
 gpg --list-packets < cert-from-keyserver1.gpg
The content of this output is still fairly complicated, but it's nothing
that you won't be able to figure out by doing some serious digging
through RFC 4880:
 So the two compound certificates received may have different orderings
of their internal elements, and some may even be missing some elements
that others have (e.g. if a particular signature has not propagated from
one keyserver to another yet).
I think this could explain significant differences between the files
you've downloaded from different keyservers.
I hope this explanation is useful (and happy as always to receive
corrections or clarifications if i've mixed anything up).

@_date: 2009-07-03 01:21:08
@_author: Daniel Kahn Gillmor 
@_subject: verifying rpms - public key not found 
--check-sig is for verifying certifications on keys, not for verifying
signatures on arbitrary data.  The man page isn't terribly clear about
that if you didn't already know it though, unfortunately :(
You're probably interested in something like gpg --verify, but i don't
know exactly how signed .rpms work (i work with .debs mostly, which have
external signatures), so hopefully someone else can pipe up with the

@_date: 2009-07-07 13:59:11
@_author: Daniel Kahn Gillmor 
@_subject: algorythm 11 mistake mac 
I think the difference here is that the OP is using PGP/MIME (hence the
reference to RFC 3156), whereas Charly is using inline PGP.
Charly, can you try one more time with SHA-224 and PGP/MIME to see if
you can replicate the error?

@_date: 2009-07-10 12:58:16
@_author: Daniel Kahn Gillmor 
@_subject: gnupg as ssh-agent 
If you have an authentication-capable subkey on your OpenPGP key, you
might be interested in monkeysphere (
which has some tools for importing authentication-capable RSA subkeys
into a running ssh-agent.
i'm part of upstream on the monkeysphere project, and i recommend using
OpenSSH's implementation of ssh-agent over any other implementation,
including the implementation in gnupg-agent.  The OpenSSH folks have
done a really solid job for every day use.
As far as i know, that doesn't exist yet, but i'd like to see it as well.

@_date: 2009-07-11 09:57:20
@_author: Daniel Kahn Gillmor 
@_subject: gnupg as ssh-agent 
hum, we're no longer relying on GnuTLS -- those docs should be updated!
All it does is to set the authentication-capable flag, use RSA of a
requested length (it should default to gpg's default size).

@_date: 2009-07-20 17:22:52
@_author: Daniel Kahn Gillmor 
@_subject: gnupg as ssh-agent 
I haven't been able to get the one OpenPGP smartcard i've fooled around
with to work (maybe i have a crappy reader), so i can't comment on
whether GnuPG can actually expose that through it's ssh-agent emulation.
The monkeysphere package i described above actually *can't* send a key
from the GPG smartcard through to a separate (non-gpg-agent) ssh-agent,
though -- it extracts the relevant subkey, transforms its RSA key
material to a form that ssh-agent can read, and hands it off directly.
I've never been able to convince gpg-agent to treat a gpg key as key for
ssh-agent myself, but perhaps Werner or David can comment on whether
that's actually possible or intended.  I agree it would be a useful
feature, but i prefer OpenSSH's ssh-agent implementation over the
gpg-agent implementation of the same protocol.

@_date: 2009-07-22 16:12:34
@_author: Daniel Kahn Gillmor 
@_subject: Question about authentication subkeys and SSH 
You can use such a subkey without a smartcard by using software provided
by the monkeysphere project:
 Assuming this is the only authentication-capable subkey on your only gpg
secret key, you'd simply do:
 monkeysphere subkey-to-ssh-agent
which would load the key into the agent for use.  You can pass
additional parameters to ssh-add at the end of the argument list.  For
example, if you want to ensure that the key is only held by the agent
for an hour, do:
 monkeysphere subkey-to-ssh-agent -t 3600
hope this helps,

@_date: 2009-07-24 18:49:07
@_author: Daniel Kahn Gillmor 
@_subject: Question About Accumulated Bad Signatures in Public Key 
There is no good reason for bad signatures to show up in the first
place, but there is no good way for keyservers to drop them either, if
they do show up (by error or by malice).  Here's why.
Signatures are marked by a shorthand identifier of what key has made
them.  This ID is the last 64 bits of the key fingerprint.  Technically,
this identifier is part of an "Issuer subpacket", and it's not even
required to be included in the signature, though well-formed signatures
 do have them.  (see  )
Key fingerprints (160 bits) themselves aren't technically guaranteed to
be unique, but for all practical purposes, they currently are.  But the
last 64 bits are certainly not guaranteed to be unique, and deliberate
collisions could probably even be generated by well-financed groups.
So consider a few possible scenarios keyservers must face upon receipt
of a signature over the first User ID of key 0123456789ABCDEF, which
contains an Issuer subpacket claiming it is issued by key DEADBEEFDEADBEEF:
 * say the keyserver doesn't currently know of any key where the last 64
bits of the fingerprint match DEADBEEFDEADBEEF: should it ignore the
signature and discard it?  or should it store it for use by people who
have a copy of that public key even if it's not on the keyservers?
 * say the keyserver *does* know of a key where the last 64 bits match
DEADBEEFDEADBEEF, *and* the keyserver has the capability to
cryptographically verify the signature (an unusual keyserver these days

@_date: 2009-07-27 08:29:10
@_author: Daniel Kahn Gillmor 
@_subject: IT Department having the secure key. 
Hi Ingo--
This is a well-thought-out response, but there are some nagging,
nit-picky details that i'm not sure are what you meant:
I think you mean to contrast OpenPGP certificates with X.509
certificates here, not GnuPG with SSL.  It is possible to use OpenPGP
certificates with recent versions of TLS under some implementations:
 If the OP works in a traditional office, then transferring the keys to
the users via a pendrive (or other variation of sneakernet) is a pretty
reasonable way to avoid this concern
You actually can encrypt files to more than one OpenPGP key, so that
anyone holding any of the recipient keys can decrypt the data.  Maybe
this approach would be useful for the OP?
If, as IT administrator, you have the opportunity to configure your
users' ~/.gnupg/gpg.conf, you could add a line like
  recipient 0xDEADBEEFDEADBEEF
to specify that all encryptions will automatically be encrypted to a key
that you retain for the kind of emergency recovery scenarios you describe.

@_date: 2009-07-27 10:54:20
@_author: Daniel Kahn Gillmor 
@_subject: IT Department having the secure key. 
I believe the way that it works is that the content of the file is
encrypted with a symmetric cipher (against a randomly-generated session
key).  Then, the session key itself is encrypted to the relevant
asymmetric key, and placed in a "Public-Key Encrypted Session Key Packet":
  So if you encrypt a file to multiple public keys, the encrypted data
only grows by the size of one additional Public-Key Encrypted Session
Key Packet per recipient (about 0.5KB, depending on the algorithms
used).  If you're encrypting a 500K file, an extra ESK packet isn't much

@_date: 2009-07-30 20:46:38
@_author: Daniel Kahn Gillmor 
@_subject: list of OpenPGP implementations [was: Re: Changing GPG's default 
Have you had the opportunity to publish this tally someplace?  Even if
it was out-of-date and lacked deployment estimates, it would be useful
to have this information collected where folks could see it.

@_date: 2009-07-30 20:50:53
@_author: Daniel Kahn Gillmor 
@_subject: gpg - what are the strange characters ? 
Hi Alain--
 [...]
You can find some documentation of the intended significance of this
output in the file named DETAILS.  look for the section called "Key

@_date: 2009-07-31 17:51:07
@_author: Daniel Kahn Gillmor 
@_subject: Needed help 
Probably you mean to say that you are unable to decrypt, right?  If
you've lost the secret part of that subkey somehow, material encrypted
to it is gone for good.  But you can still move forward:
Your best short-term bet is to revoke your subkey and add a new one.
  gpg --edit-key 01A82A13
then within that subshell, you're interested in the subcommands "revkey"
and "addkey".
Note that before you "revkey", you'll want to explictly select the
subkey first.  And when you addkey, you want to choose either "Elgamal
(encrypt only)" or "RSA (encrypt only)" to make sure you make another
encrpytion-capable subkey.  So the commands you might want to run
probably look something like:
key 1
Be sure to read and understand the prompts before committing to anything!
when it's all done and you like the changes, do:
Finally, you'll want to publish the new subkey and the revocation of the
old one:
  gpg --keyserver keys.gnupg.net --send 01A82A13
These are Key Usage Flags.
SCA means that your primary key is to be used only for the following
 Signing (signing text and binary documents)
 Certifying (signing other people's key/userID bindings)
 Authentication (identifying you in some context, e.g. SSH)
E measn that your subkey is to be used for Encrypted communications
and/or storage.

@_date: 2009-06-02 11:58:59
@_author: Daniel Kahn Gillmor 
@_subject: Running GPG from a PHP Script under Windows 
This sounds more like a question for php folks than gpg folks to me.  I
recommend you try asking on one of the many php forums.
And if you want to get a helpful answer, you should probably consider
including more detail.  For example, show the code you are using
exactly, the output it produces under the different circumstances, and
the exact error codes and messages produced during a failure.

@_date: 2009-06-02 12:40:59
@_author: Daniel Kahn Gillmor 
@_subject: Changing the expiration date after the key has expired 
yes, this is possible.  Assming you're talking about 56B55C11, it looks
like you've successfully done so.
It's actually self-signed three times by the same key:
 * the original self-signature
 * the new self-signature with the updated expiration
 * a third self-signature which moves the "primary User ID" flag from
one UID to another.
If pgp.mit.edu rejected the key, that's a bug in that keyserver.
I just tried pulling this key from pgp.mit.edu and from
pool.sks-keyservers.net, and found that pgp.mit.edu only had the first
two self-sigs on each UID, while pool.sks-keyservers.net had all three.
then i tried pushing the full key (with all three self-sigs) back to
pgp.mit.edu.  After that, pgp.mit.edu returned all three self-sigs.
So it seems there was a buggy propagation in there, but i might have
just fixed it manually for this specific key.
(the explicit steps described above were:
umask 077
mkdir yohonet yohonet/mit yohonet/sks
GNUPGHOME=yohonet/mit gpg --keyserver pgp.mit.edu --recv 56B55C11
GNUPGHOME=yohonet/sks gpg --keyserver pool.sks-keyservers.net --recv
GNUPGHOME=yohonet/sks gpg --list-sigs 56B55C11
GNUPGHOME=yohonet/mit gpg --list-sigs 56B55C11
GNUPGHOME=yohonet/sks gpg --keyserver pgp.mit.edu --send 56B55C11
GNUPGHOME=yohonet/mit gpg --keyserver pgp.mit.edu --recv 56B55C11
GNUPGHOME=yohonet/mit gpg --list-sigs 56B55C11
I'd be interested in seeing the error output you got from sending the
key to pgp.mit.edu.  When i sent the full key back to pgp.mit.edu, i got
no error message at all, just the expected line from gpg:
 gpg: sending key 56B55C11 to hkp server pgp.mit.edu
It's probably a good idea to use the other keyserver then, and avoid
this is already done.  the old self-signature with the old expiration
date will persist forever, but the new self-sig has a more recent
creation date, and RFC-compliant OpenPGP implementations will respect it.

@_date: 2009-06-02 13:16:10
@_author: Daniel Kahn Gillmor 
@_subject: Security Concern: Unsigned Windows Executable 
guys, with all due respect, the original poster was not asking for a
philosophical digression.  he was asking how he could practically
identify the provenance of the copy of gpg he was hoping to use.  It's
neat to point out how each layer of trust rests on another one, but we
should be giving practical advice which helps the OP push the leaps of
faith necessary to run gpg back by a few levels.
John Clizbe has offered one practical choice (see if PGP Corp. offers a
demo version with a signed executable).  Another choice would be to use
a local, trusted GNU/Linux or *BSD installation to verify Werner's
signature on the package (e.g. put it on a USB stick) and then transfer
the package back to the windows machine for installation.
A third way (if you don't currently have a local trusted free OS
installation) would be to reboot the machine with a liveCD (if you can
find a satisfactory trust path to a LiveCD) or with something like wubi
[0] which itself might offer a signed windows installer (i haven't
checked).  You can use wubi or the liveCD to verify Werner's signature
on the packages, and then transfer them back to the windows machine to
[0]

@_date: 2009-06-02 19:48:30
@_author: Daniel Kahn Gillmor 
@_subject: Security Concern: Unsigned Windows Executable 
I understand (and i very much appreciate the warning), but sometimes
it's useful to go a little way into the rabbit hole instead of all the
way to the bottom, no?  otherwise, why bother with crypto software at
all, built as it is upon a teetering edifice of trust-in-others?
I beg to differ.  In today's wireless network, active MitM can be done
by a moderately-skilled hacker on a lark, or by an unskilled user who
can follow directions:
  it's a small step from there to a script kiddie's bot on a WAP replacing
everything that looks like a windows executable or installer crossing
the network with a program of his own choosing (even a signed one!).
Even checking sha1sums from a web page would defeat this basic attack
though, which is why i think it's reasonable for the OP to ask his question.
The OP wanted to to know how to make a few more checks than zero,
forcing any possible attacker to be marginally more clever than the
hypothesized bot above.
But that's exactly the OPs point: "the box" on windows is a "signed
executable", whatever that is.  Since gpg is distributed outside of that
framework, he's concerned that an attacker could exploit it.
Fortunately, we can offer the OP some other techniques to put things
back "in the box" of secured communications -- he still has to trust our
 recommendations, but he can research those as well and make his own
The MitM attack doesn't need to be "against him", it just needs to be
going on.  Do you cryptographically check the integrity of software you
downoload?  Do you check the host keys of machines you ssh into?  these
are both reasonable actions, based on a concern that there may be an
active MitM attack.
The OP may not have the resources to do what you're suggesting, or may
want to see what other options are available before resorting to such
lengths.  Practical approaches exist, and while they are imperfect, they
do have an effect against some non-zero subset of real-world threats.
let's not overstate their capabilities (the phrase "100% secure" is
meaningless), but let's offer practical approaches even as we warn of
their limitations.

@_date: 2009-06-05 15:00:23
@_author: Daniel Kahn Gillmor 
@_subject: Security Concern: Unsigned Windows Executable 
An ultra-competent attacker with the resources of the NSA behind them
and full control of your network might well be the incendiary bomb you
describe, particularly if you're starting with nothing but a blank
computer (or a Windows machine) and a liveCD of dubious provenance.
But a neighborhood kid who's playing tricks with your wireless router
(which can also be an active MitM) is another story.  You actually *can*
use a fire extinguisher to squirt the neighborhood kid or at least to
extinguish the fire he lit in your armchair.  There's no need to flee
your house.  And practicing with the fire extinguisher is useful too!
Additionally, there are a lot more people who are being messed with by
neighborhood kids than being targeted by the full might of the NSA.  We
need to support those people.  This is a list to help gnupg users, after

@_date: 2009-06-09 15:23:42
@_author: Daniel Kahn Gillmor 
@_subject: Security Concern - Open Source Binaries 
I don't believe that sourceforge (or any other major free software
service provider) does this.
however, most gnu/linux distributions do.  If you want a centralized
software aggregator who cryptographically signs off on packages at their
own distribution step, you should install debian or ubuntu (i know they
do this, through secure apt) or fedora or gentoo (i'm pretty sure they
do).  I can't speak for other distros.
The usual caveats apply, of course: trusting the distro is often the
same as trusting the weakest link in the chain -- the most sloppy
developer with commit privileges to the distro, or the most sloppy
upstream developer, or the least-secured machinery in the chain between
you and the original developer who wrote the code.

@_date: 2009-06-16 09:11:08
@_author: Daniel Kahn Gillmor 
@_subject: Plaintext attack vulnerabilities? 
The client may or may not be able to learn anything about the private
key directly, but there are other serious attacks that such a scheme
could be vulnerable to.
For example, a relay or man-in-the-middle attack is possible:
Alice wants to bob.example.org, a server run by Bob.  Mallory happens to
have a machine (mallory.example.net) on the network path between Alice
and bob.example.org.
mallory.example.net intercepts the traffic, and answers to Alice as
though it were bob.example.org.
Alice asks mallory.example.net to prove that it is bob.example.org by
supplying it a random token to sign.
mallory.example.net in turn opens a connection to the real
bob.example.org, pretending to be Alice, and hands it the same token,
which bob.example.org signs and returns to mallory.example.net
mallory.example.net replays bob.e.o's signature to Alice to establish
its fake identity.
 ----
If the bob.example.org uses the same key for other purposes (e.g.
identity certification, or more generally as a primary key), there are
still other attacks that are possible.
Why design your own protocol?  There are several public-key-based
network authentication protocols (using OpenPGP or not) which already
exist and have been vetted, many of which have free implementations you
can use!  For example, you could use RFC 5081 (TLS with OpenPGP
certificates).  This is not widely adopted at the moment, but it is
implemented in recent versions of GnuTLS.
As a rule of thumb, any asymmetric key which is set up to automatically
sign arbitrary plaintext provided by possible attackers is opening the
door to potential compromise.

@_date: 2009-06-23 14:33:12
@_author: Daniel Kahn Gillmor 
@_subject: Key propagation 
A key is a piece of digital information; as such, it can be transferred
without loss an arbitrary number of times, and there's really no way to
prevent that (witness all the problems record companies have trying to
limit propagation of recordings they produce).
However, if you want to advise people that they should not export
signatures on your key, you can set the "no export" flag, making that
signature "local".
If you were to set that flag on your self-signature, then no one who
respects the intent of that flag would export the key itself, and
reasonable keyservers should not accept or store it, but i've never tried.
I'm not sure what you'd need to do to make sure that the non-exportable
flag was set on your self-signature with gpg.  If you sort it out, it
would be great if you could publish how you did it.
note that this doesn't let you limit it to an arbitrary number of hops.
 it simply requests that people do not propagate the certification (or
the associated key, if it's a self-sig), and reasonable clients should
respect that.

@_date: 2009-06-24 00:21:44
@_author: Daniel Kahn Gillmor 
@_subject: Key propagation 
Right, but a key with no valid self-sigs won't be imported either,
right?  If all self-sigs were marked non-exportable, wouldn't that limit
the import (if not export) of the key itself?

@_date: 2009-06-24 12:28:53
@_author: Daniel Kahn Gillmor 
@_subject: Any UNIX API for GPG available? 
Communicating a well-defined syntax across a process boundary doesn't
need to be inelegant.  There are many good implementations of various
tools that take advantage of the natural segmentation that the OS
provides via distinct processes.
One advantage for gnupg, for example, is that secret key material is
never loaded directly into the memory of the parent process, so it
cannot be copied or tampered with from there.
This is not to say that the GPGME arrangement is perfect, just that the
process separation model itself isn't inherently a bad one.
There are several, but none are in terribly good shape for generic use
from what i can tell.
 OpenPGPSDK (sponsored by nominet, a UK DNS registrar) links against
OpenSSL for most of its crypto, and doesn't yet produce a shared library
(you can build statically-linked apps though).  Targets RFC 4880 (the
latest OpenPGP RFC), but still has substantial gaps in its coverage of
the RFC.
   Crypt::OpenPGP is a perl module, but it requires Math::Pari.
Unfortunately, the author of Math::Pari seems to think that you should
need to rebuild perl itself to use his module, so this doesn't lend
itself to binary redistribution (.debs and .rpms).  Crypt::OpenPGP only
implements RFC 2440 (the older version, deprecated).
   OpenCDK used to be a separate library, but the latest versions seem to
be bundled with the GnuTLS source. It uses gcrypt for its crypto, but
has been stripped down to do just what GnuTLS needs.  Reviving it as a
separate project with its own life would be nice, i think.  It's also
GPL'ed, which is nice if you want to link it to GNU software.
  (i can't even find an upstream OpenCDK link anymore, so:
     )
FWIW, i've recently started trying to revise the dependencies of
Crypt::OpenPGP to get it to work without Math::Pari (upstream has been
non-responsive to a couple of queries), and OpenPGPSDK folks are
receptive to hearing about problems, though the project seems starved of
developer time to actually fix things; some patches offered languish
unapplied.  I need to investigate more into the history of choices
behind OpenCDK's evolution, but have not yet done so.
If anyone knows of other free implementations, i'd be happy to hear
about them too.

@_date: 2009-06-26 10:39:06
@_author: Daniel Kahn Gillmor 
@_subject: Question of a beginner: DSA/ElGamal or RSA/Elgamal with a higher 
The defaults are about to change to RSA 2048/2048 (with good reason), so
i think you're right to want to do something different than the current
(old) defaults when creating a key you plan on using for the next
several years.
However, i also echo Robert Hansen's advice to avoid the --expert flag
unless you're really already sure of what you want to do.
 * use plain ol' "gpg --gen-key" (don't use --expert)
 * select RSA (Sign-Only)
 * ask for 2048 bits
 * create your key as usual, and get back out of gpg.
Then, assuming your new key is $KEYID,
 * gpg --edit-key $KEYID
 * addkey
 * choose an RSA subkey, for encryption, and make it 2048 bits
This should make gpg do what you want it to do without getting into
--expert territory.

@_date: 2009-06-28 16:55:11
@_author: Daniel Kahn Gillmor 
@_subject: New Revocation Certificate... 
I'm assuming you're asking about the revocation certificate for your
your entire GnuPG-generated OpenPGP key.
That revocation certificate is designed to revoke the primary key.
Without a valid primary key, all associated subkeys are considered
invalid.  So you should not need to re-generate your revocation
certificate based on a new subkey.
This is because the action triggered by the publication of the
revocation certificate is the invalidation of the primary key.  Make sense?
Hope this helps,

@_date: 2009-06-29 11:19:58
@_author: Daniel Kahn Gillmor 
@_subject: unusable public key? 
Hi Debbie--
There are a couple different possible reasons why the key might be
unusable.  Without knowing about the specific key in question, we
probably can't give you specific advice.  But here are a few likely
 * the public key is marked as being only valid for signing and
certification, but not encryption.  (you can see this by doing:
   "gpg --edit-key $KEYID", which will show you something like this:
pub  2048R/ABCD1234  created: 2007-06-02  expires: 2012-05-31  usage: SC
                     trust: unknown       validity: full
(you can type "quit" at the "Command>" prompt to get out of this gpg mode)
the "usage: SC" (at the end of the top line means "signing and
certification only".  If this is the case, your correspondent will need
to create an encryption-capable subkey and bind it to their primary key.
 They can do this with "gpg --edit-key $KEYID", and then use the
"addkey" subcommand, which will walk them through the necessary steps to
create an encryption-capable subkey.
Once they've done this, they should get their updated key to you.  the
easiest way to do this is to publish the updated key to the keyserver.
so they would do:
  gpg --keyserver keys.gnupg.net --send $KEYID
and you (after waiting about 10 minutes for the key to propagate across
the entire keyserver pool) would then do:
  gpg --keyserver keys.gnupg.net --recv $KEYID
If they don't want their key on the keyserver, they can export their key
to a file and mail it to you:
  gpg --armor --export $KEYID
and paste the output into an e-mail.
When you receive that e-mail, just save it to a file, and feed it into
"gpg --import" (e.g. "gpg --import saved-file.txt")
 * another possibility is that the key or its subkeys are expired.  In
this case, the keyholder may need to update the expiration date on their
key (if it's still secure), or they may want to generate a new key and
send it to you (preferably certified by the old key), so you can verify it.
hope this helps,

@_date: 2009-06-29 19:48:06
@_author: Daniel Kahn Gillmor 
@_subject: Exposing email addresses on key servers 
I think that wasn't his point.  I think Werner's point was that when
people send encrypted mail, they use a mail user agent (e.g. thunderbird
with enigmail, outlook with the gpg plugin, claws, mutt, etc).  the MUA
is usually responsible for selecting which key to encrypt the message
to.  It does so by asking GPG to find a key which matches the e-mail
If you choose a user ID which does not exactly match your e-mail
address, gpg (and thus the MUA) has no way of selecting the right key to
encrypt to automatically.
Some user agents include special features for mapping e-mail addresses
to keys manually (e.g. enigmail in thunderbird allows this), but it's
yet another step in an already cumbersome process.
Werner's point (i think) was that by raising the bar still further,
you're simply discouraging people from encrypting mails to you in the
first place, and not protecting yourself that much from harvesters, who
have many other ways to get yer address (from posts to this public
mailing list, for example).
It's a bad tradeoff.

@_date: 2009-05-24 16:54:40
@_author: Daniel Kahn Gillmor 
@_subject: MD5 is an unreliable digest algorithm [was: Re: Key Transition Letter 
Actually, it is fairly common in certain circumstances: Certifying that
another user's key is correctly bound to their User ID (a.k.a. "signing
someone's key") is effectively making a signature over a document that
you did not originate.  The only element in a standard OpenPGP
certification which changes is the timestamp of the certification
itself.  The timestamp is fairly predictable (the hash-clash rogue CA
X.509 MD5 compromise in December 2008 relied on timestamping with the
same granularity that OpenPGP uses).  Furthermore, the timestamp is
*appended* to the element in question that is signed (as are any
additional subpackets that the issuer of the certification elects to
include).  Certifier-authored appended data is less useful for defeating
a collision attack, since signatures are made over digests that are
one-pass.  With a one-pass digest, an attacker needs only to find a
collision in the lead-up to the appended data, and then subsequent
appended data can simply be copied from the tail of one message to the
other to maintain the collision in the digest output space.
MD5 *is* broken in that it does not provide the exepcted level of
security that a digest of its length implies, particularly for
collision-resistance.  The ability to find two messages with identical
digests should be no less expensive than a so-called "birthday attack",
which is 2^64 digest calculations for a 128-bit digest like MD5.  MD5's
collision resistance is demonstrably less than 2^64 today.  Wikipedia
notes attacks that find MD5 collisions in a few hours on a notebook
Collision attacks have significant utility in subverting all kinds of
crypto-systems including e-mail cryptography, particularly because so
many mail clients are willing to ignore invalid or garbage-y data in an
e-mail message.
SHA-1's collision resistance is weakened as well, reportedly to the
level of 2^52 operations (it should be 2^80, since SHA-1 is a 160-bit
hash), but (a) no one has seen an exploit of this in the wild yet, and
(b) 2^52 is a fairly big number anyway (within reach of well-funded
organizations, but not nearly as bad as MD5).
So MD5 should indeed be avoided today, and we should be methodically and
reasonably moving away from reliance on SHA-1 in circumstances where
collision-resistance is necessary.

@_date: 2009-11-14 16:39:38
@_author: Daniel Kahn Gillmor 
@_subject: Trust reference 
If Gajim is doing this, you're quite right to file a bug about it.
Gajim should not be using any ownertrust designations (ultimate or
otherwise) in its decisions about who to send encrypted messages to.
Ownertrust has a very specific semantic meaning:  it answers the
question "how much do i trust OpenPGP certifications made by this key?"
Conflating that meaning with other semantics (like "should i send this
person encrypted IM messages?") is guaranteed to be wrong in many cases.
 Even worse, encouraging people to set any sort of ownertrust for the
sake of doing something unrelated to the trustworthiness of a given
keyholder's certifications is actively bad from a security standpoint --
it encourages people to adjust their tools to accept certifications that
they otherwise would not accept.
Calculated validity is related to (but quite different from) ownertrust.
 Calculated validity says "do i believe that this key really belongs to
the person identified by the User ID?"
It would be reasonable if Gajim wanted to use the calculated validity of
a key/userid to determine whether to encrypt messages with the key when
sending to a remote party identified by the User ID.  After all, if you
don't know if a given key really belongs to the person you think you're
talking to, encrypting to that key is meaningless.  It's meaningless
because someone masquerading as the remote party could control the
dubious key, and then your encryption *doesn't* do the job of hiding the
message to anyone but the intended recipient.  Gajim (quite reasonably)
wouldn't want to let the user think they were encrypting messages that
could actually be intercepted.
Feel free to forward any of this to your bug report if you find it useful.
Unfortunately, i don't know of good detailed references describing these
concepts.  DETAILS (from the gnupg source) doesn't have much to say
about "ultimate", though it seems like a reasonable place to look.  If
no one else can point to good docs, we should write some.
PS just what does ultimate ownertrust mean?
Ultimate ownertrust is a superset of full ownertrust.  Full ownetrust
says "Assuming i calculate this key to be valid (to have successfully
calculated validity over at least one user ID on the key), any
certification made by this key is to be considered acceptable for
further validity calculations."  Ultimate ownertrust removes the
requirement for the key to be already-valid in order to trust the
certifications.  It's the OpenPGP equivalent of X.509's "Trusted Root
Certificate Authority", and it's probably *not* what anyone wants for
most keys.

@_date: 2009-11-21 17:47:13
@_author: Daniel Kahn Gillmor 
@_subject: How to check the trust level 
For the typical way that GPG manages ownertrust, that information is not
published (or publishable) at all.
In the unlikely event that your contact has made a Trust Signature
(tsig) [0] (and did not mark it as non-exportable) then the signature
could be found on public keyservers, and viewed in gpg with gpg
--list-sigs.  A trust signature will have a number immediately to the
left of the key ID indicating the depth of the indicated trust.  If your
key is DEADBEEF, and the other person is DECAFBAD, and they indicated a
depth=1 trustsig it would look like this:
test at foo:~ $ gpg --list-keys DEADBEEF
pub   4096R/DEADBEEF 2008-06-02 [expires: 2012-06-02]
sig 3        DEADBEEF 2008-06-02  Me Me Me! sig        1 DECAFBAD 2009-02-20  That other guy note that the column with the "3" in it shows the strength of the
certification, as David Shaw mentioned -- your self-signature is
normally certified strongly, as in "i have done very careful checking".
The column with the "1" in it is the trust depth.  in this case, it says
"i believe in the certifications made by this key, but i'm not willing
to accept tsigs made by this keyholder."
If you want even more details about the trust sig, you could feed your
key through "gpg --list-packets" like this:
 gpg --export DEADBEEF | gpg --list-packets
You should be aware that very few people use trust signatures to
indicate ownertrust with gpg.  Most people use the privately-held,
simpler trust designation.
Also, using a trustsig leaks additional information to the general
public that simple certification does not include.  namely, it indicates
a statement of belief in someone's ability to make proper certifications
(and avoid improper ones), in addition to a statement of belief that the
identity of the keyholder is correctly stated.
PS this entire message refers to ownertrust.  As David Shaw has already
mentiond, this concept is entirely different from the concept of
calculated validity, or strength of identity certification.
[0]

@_date: 2009-11-23 09:02:17
@_author: Daniel Kahn Gillmor 
@_subject: GPG self signature missing error 
This key is not available from the public keyserver network, so i can't
see what its actual self-signatures look like.  Is it possible that its
only self-sigs were made by an algorithm unsupported by gpg 1.2?
i'm not sure which algorithms were introduced between 1.2 and 1.4, but
that would be useful information for this question.

@_date: 2009-11-30 16:27:01
@_author: Daniel Kahn Gillmor 
@_subject: dumping a gpg message 
You might be interested in gpg --list-packets, or in the pgpdump package
(found upstream at:

@_date: 2009-09-30 18:00:50
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
The current gpg behavior is to use the first key with a matching User
ID, regardless of the validity of that User ID.  So this causes (at
best) warnings and alerts about using an invalid key or (at worst) lets
someone with marginal ownertrust abuse the user by taking precedence
over a fully-trusted certification if the keyring happens to be ordered
in a certain way.
PS i hear you about being paranoid and preferring to only trust my own
certifications.  but the larger pool there is of people who understand
the two simple concepts, the more comfortable i am granting trusted
individuals marginal ownertrust, and taking advantage of the WoT to
verify identities i've yet to directly verify myself.  It's way better
than trusting $DEITY-knows-who that comes pre-configured by default in
web browsers these days ;)

@_date: 2009-10-14 16:17:31
@_author: Daniel Kahn Gillmor 
@_subject: GNUPG HELP please 
Hi Connie--
This suggests that your configuration file may be readable or writable
by other users.  You can view the permissions on that file with:
  ls -l /home/lawbr/.gnupg/gpg.conf
You can lock it down with:
  chmod go-rwx /home/lawbr/.gnupg/gpg.conf
(note here that "go-rwx" means "remove (-) read (r), write (w), and
execute (x) from group (g) and all other users (o)" )
If you're not sure about the concept of filesystem permissions, it's
worthwhile to think about them a bit.  they'll come up fairly often on
unix systems.  wikipedia has a good start:
This is due to a directory being potentially readable or writable by
other users.  You can lock down the "enclosing directory" with:
 chmod go-rwx`/home/lawhr/.gnupg/
Search for "insecure memory" in the gpg manual page (try "man gpg") for
more information about this error under the BUGS section.  You may
either want to make gpg setuid root (if secure memory is important to
you) or to tell gpg to ignore this particular error by adding the
relvant option to your gpg.conf file.
have you read this?  It's worth reading!  You might be interested in
section 6.1 in particular:
  this is likely because you've imported the "REWARD" key into your remote
system without indicating any particular "ultimate" ownertrust.
gpg does a fair amount of work to make sure that keys belong to who you
think they should belong to -- it doesn't make any sense to encrypt data
to a key if you aren't sure whose key it is.
Presumably, there is someone who is making reasonable assertions about
which keys belong to which entities, and signing those keys.  You
probably want to designate "ultimate" ownertrust for that certifier on
your server.  For example, if you hold key DECAFBAD privately
(off-server), but you use that key to sign the REWARD key, you could
import the DECAFBAD public key on the server, and then (still on the
server) do:
 gpg --edit-key DECAFBAD
  trust
and then choose "ultimate" ownertrust.  Make sense?
i dunno why this is coming up; what operating system are you running
this on?  what version of gpg?  did you build it yourself, or is it the
version provided by your OS?

@_date: 2009-10-14 17:40:41
@_author: Daniel Kahn Gillmor 
@_subject: GNUPG HELP please 
Hi Connie--
I'm glad that was useful.
It sounds to me like you might be confusing validity with ownertrust.
In my earlier note, i suggested that you *trust* the keyholder of some
key that will certify the keys you are encrypting to.
Instead, it looks to me like you've chosen to try to *sign* one of the
keys you're encrypting to directly from the server.
It helps me to separate out these concepts into two ideas:
 0) who do you know (i.e. who can you identify)?
 1) who do you trust to identify others?
And since you're dealing with two different gpg installations (one on
the server and one that you control elsewhere) you probably want to
think about those from separate perspectives.
I don't know what you're planning to do on your server, but i'll pretend
for the moment that you're working with a web application which is
expected to recieve information over the web, and then encrypt it to
someone.  I'll refer to that someone as the "encryption target".
from the webapp's view, how does it know it's encrypting info to the
right person?
let's say you're the administrator of such a system, and you want the
webapp to believe you when you certify that a certain key belongs to a
given person.  Then you (as the admin) would have your own OpenPGP key,
stored off of the server (probably on your own workstation someplace).
Let's assume that key is key ID 0xDECAFBAD. You'd upload the public part
of 0xDECAFBAD to the server, and import it into the webapp's keyring.
After import *as the webapp user* you'd say "i trust the sysadmin to
identify encryption targets" by doing:
  gpg --edit-key 0xDECAFBAD
   trust
and then designate "ultimate" ownertrust.
Then, you'd use your own key to certify the key belonging to the
encryption target -- you'd "sign the target's public key" with your own
key.  Then you'd upload the target's public key (with your
certification) to the server, and import it into the webapp's keyring.
Does this make sense?  The advantage of this arrangement is that now
your webapp can be used to encrypt to a variety of people -- you'll just
need to sign their keys, and they can be encryption targets as well.
hope this helps,

@_date: 2009-10-30 14:22:35
@_author: Daniel Kahn Gillmor 
@_subject: Question about syntax of a command 
I think you want:
 gpg --cipher-algo 3DES --symmetric test.txt

@_date: 2009-09-10 10:31:48
@_author: Daniel Kahn Gillmor 
@_subject: howto secure older keys after the recent attacks 
I've asked this before, but without any satisfactory answer, i'm still
curious:  Why do the digest defaults in 1.4.10 and 2.0.13 list SHA-1
above SHA-512, SHA-224, and SHA-384?
I don't believe that the mere existence of hardware acceleration of
SHA-1 is sufficient to warrant its default preference over stronger,
widely-implemented digests.
Users who have (and prefer to use) accelerator hardware for any
particular digest can change their published preferences to explicitly
prefer that hardware, right?  Are SHA-1 accelerators so widespread that
people have them (and gpg uses them) without being aware of them?
Is there some other reason to rank SHA-1 like this?

@_date: 2009-09-10 12:22:30
@_author: Daniel Kahn Gillmor 
@_subject: howto secure older keys after the recent attacks 
Unless i misunderstand the context, I think I disagree with your
characterization here, Robert.
The Key ID is a substring (either the last 8 or 16 hex chars) of the Key
Fingerprint (which is 40 hex chars).  The Key ID is used nowhere in the
internals of the OpenPGP specification, from what i can tell.
The fingerprint itself is used only in the designated revocation key
[0], which is an acknowledged weakness of the cryptosystem [1].  It's
not used anywhere else that i can tell.
So I think Philippe Cerfon's characterization is pretty accurate,
actually.  The fingerprint (and to a weaker extent, the keyID) is useful
where the mechanical implementation meets the human mind.  But I don't
think either are used internally to the OpenPGP cryptosystem in many
places at all.
[0] [1]

@_date: 2009-09-10 20:38:20
@_author: Daniel Kahn Gillmor 
@_subject: howto secure older keys after the recent attacks 
Worse than this: the devices could produce measurably "good" entropy
that happens to be predictable to a malicious individual in control of a
special secret.
For example, if such a key were to contain a copy of the secret, and
somehow retain the current time (e.g. a battery and a clock?), it could
produce a new output stream each second with:
 AES(secret + time())
(first cleartext block is just "secret + time", and next cleartext block
for that second is just the previous ciphertext block XOR'ed with
"secret + time" -- reset every second as time() changes)
This would produce a predictable stream that (like all good ciphers) has
high-entropy output.
Then, if this was used to provide random numbers to the kernel, which in
turn provided them to gpg, an attacker who knows the secret associated
with your entropy key, and the time you generated the key (that
information is published with your public key) could probably reproduce
the stream of "randomness" that was used for your key generation, and
therefore stumble upon your private key.

@_date: 2009-09-10 22:55:09
@_author: Daniel Kahn Gillmor 
@_subject: howto secure older keys after the recent attacks 
Agreed!  I was just pointing out that the lack of true entropy might not
be as obvious as the proposed card that always returned "0x00" when
asked for a random byte.
There is also open hardware for random number generation, for whatever
that's worth:
 i've never used any of these devices myself.

@_date: 2009-09-22 13:11:21
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
when encrypting messages to a user ID with multiple matching keys with
full calculated validity, gpg seems to just choose the "first" matching
key, for some definition of "first" -- i think it's decided by
chronological age of first import into the local keyring.
This does not seem to be the best heuristic.  here are some other
proposed heuristics for choosing among multiple keys with full
calculated User ID validity during encryption:
 0) choose the most recently-created key
 1) choose the key with the strongest supported encryption-capable
subkey (by bitlength?)
 2) encrypt to *all* matching keys
The current implementation does what seems to be the Wrong Thing in the
use case where the recipient is going through a key transition, and has
two keys (one older, deprecated but not yet expired; and one newer,
stronger, preferred).
Any thoughts on this?  Should i open it as a ticket?

@_date: 2009-09-22 16:40:07
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
thanks for catching that, John.  It appears that if the first key with a
matching User ID doesn't have full calculated validity, the user gets a
scary warning that "There is no assurance this key belongs to the named
user", and then:
    It is NOT certain that the key belongs to the person named
    in the user ID.  If you *really* know what you are doing,
    you may answer the next question with yes.
It does this even if there is a full-valid match later in the keyring!
This doesn't seem like friendly or reasonable behavior for the power
user, let alone the novice user.
i'm assuming you mean "gpg --edit-key 0xDECAFBAD" followed by the
"disable" subcommand.
What do y'all think should actually be happening here?

@_date: 2009-09-22 17:06:41
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
this is not what gpg does.  gpg simply chooses the first key with a
matching user ID, whether or irrespective of the calculated validity of
the User ID in question.

@_date: 2009-09-22 18:54:23
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
well, i'm living proof that it can confuse people, and that people can
misunderstand it.  It took me a while to sort out:
 a) what it was doing specifically (i originally thought it was sorting
by key creation date)
 b) how to change the ordering of keys in a keyring (so far, i've only
figured out how to move a given key to the "end of the list":
   gpg --export --export-options export-local $KEYID > tmpfile
   gpg --delete-key $KEYID
   gpg --import --import-options import-local < tmpfile
I suppose i could do arbitrary bubble-sort-ish reorderings with this
primitive, too; is there another way?)
 c) that gpg is even willing to settle on a key with a matching User ID
with no calculated validity (e.g. if i added a user ID of "Daniel Kahn
Gillmor " to my key, even if no one else
certified it, then anyone who had met me before meeting you would need
to specify your key by key ID, instead of by e-mail address!)
I hear you.  I've offered some concrete examples of ways that the
current behavior breaks things.  Can you give me an example of a script
that has this behavior "baked in" to the point where adopting a better
heuristic would break it?
Also, i believe this behavior is *only* relevant in situations where the
user asks gpg to encrypt something to a name or User ID.  Is that right?
 or are there other circumstances in gpg where the "choose the first
matching User ID" heuristic is used?
Thanks for thinking through this with me,

@_date: 2009-09-23 09:34:10
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
OK; if i'm proposing one specific alternative, it would be:
  Select the most recently-generated valid key that has a non-revoked,
  non-expired encryption-capable subkey, and has a matching user ID with
  the highest-available-class of calculated validity for the given User
  ID.
That is, if you have the following keys with matching User IDs and
non-expired, non-revoked encryption-capable subkeys (or
encryption-capable primary-keys):
 * A: unknown calculated validity, primary key created 2005-02-01
 * B: marginal calculated validity, primary key created 2004-01-02
 * C: full calculated validity, primary key created 2003-08-01
 * D: full calculated validity, primary key created 2003-05-02
 * E: marginal calculated validity, primary key created 2004-10-30
then C would be the most reasonable default choice for encryption, due
to its full validity and creation date.
If C and D weren't in the keyring, then E would be the next-best choice.
A simple algorithm for doing this is to walk through the keys in the
keyring with a matching User ID; keeping track of the "current best"
key.  When you look at a new key, compare validity with the "current
best".  If the new key has better validity, use it instead of the
"current best".  If the new key has worse validity, pass it over and
move on.  If the new key has the same validity as the "current best",
compare primary key creation dates: if the new key was created more
recently, use it instead of the "current best".
list-keys merely produces a list of *all* matching keys, and the
documentation makes no promises about ordering; i don't much care what
order they come out in this case.
For edit-key and sign-key, the proposed heuristic makes less sense;
there are already significant usability concerns with using either of
these subcommands when specifying a key by an ambiguous User ID, and i'm
not sure that this specific change would have any effect (good or bad)
on the usability of these commands.
At any rate, the usability concerns there seem less worrisome than the
security concern associated with sending data encrypted to the wrong key.
I hear you that the historic default is "first valid key", but there is
little documentation about keyring ordering in the man page, nor is
there any documentation that the in-keyring ordering can have
significant security consequences.
And i could find no documentation about how to change the order of keys
in any keyring.  Since the ordering is currently relevant in several
places, i'd assume there would be a way to change it explicitly, but i
can't seem to find it, other than the export/delete/import "push-to-end"
procedure i noted earlier.  Is there any other interface to change the
keyring ordering that i've missed?

@_date: 2009-09-23 13:04:05
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
Has this been made this clear to collaborating MUA/plugin developers?  I
think the "auto select a key" step for MUAs or plugins is often
implemented as "let gpg pick the key based on the user ID".
I observed this exact behavior from enigmail, and it changed when i
re-ordered my keys in my gpg keyring.  You can see the discussion here:
 So it sounds like enigmail is relying on gpg at some level to do key
selection among multiple User ID matches.  It seemed to me that I could
ask enigmail to improve their key selection process (fixing things just
for enigmail users), or i could ask gpg to change the selection process
(fixing things for enigmail users and all other gpg users).
thanks, done:

@_date: 2009-09-23 18:32:25
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
What makes you think that non-ASCII characters would break a match?
Presumably, all the tools are passing UTF-8 strings to each other, and
GPG can easily find a match based on such a string.
For example, it certainly works fine from the shell:
0 dkg at pip:~$ echo test | \
:pubkey enc packet: version 3, algo 16, keyid 30CFDDC732319538
:encrypted data packet:
gpg: encrypted with 2048-bit ELG-E key, ID 32319538, created 2000-10-16
      "Ingo Kl?cker "
gpg: decryption failed: secret key not available
2 dkg at pip:~$
I haven't dug into it deeply, but what i observed from my tests was that
if i switched the order of keys in my gpg keyring, enigmail selected a
different key for a recipient who had two keys with matching User IDs.
So i suspect that Enigmail is indeed passing the e-mail address at least
(if not the name) to gpg to select a reasonable key for encryption.

@_date: 2009-09-25 10:04:36
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
hm; 0xCB0D4CAF looks to me like it expired 5 years ago; and 0xAB1BC4E6
doesn't appear to be available on the public keyservers at all.
Do you have any examples that are both public and still valid?  RFC 2440
(over a decade ago) mandates UTF-8 for user IDs:
  8-xdigit key IDs are fairly easy to replicate with today's hardware, so
relying on their uniqueness is not a good idea from a security
perspective.  Full 40-xdigit fingerprints are probably effectively
unique for the time being, though.
You're not the first person to suggest that supplying the key ID (or
fingerprint) directly is the best approach, but doing this just moves a
 serious problem from GnuPG onto the shoulders of the user (or their MUA
or other tools).
The problem that gets shifted in this case is: what key should you use
to encrypt data to a specific person?  This is a potentially complicated
problem, and the right answer changes in the face of
changed/updated/revoked certifications, expirations, altered trust
relationships, etc.  Asking the user (or their MUA) to hard-code a
single key ID means that you're asking them to ignore all these possible
changes when they happen.
Asking every MUA to implement their own mapping from User IDs to key IDs
 seems like a recipe for either weird divergence (should kmail select a
different key than enigmail for foo at example.org?) or plain insecure
mappings (e.g. an MUA developer who doesn't understand the problem of
certificate validation as well as the GnuPG developers).  Since most of
these tools rely on gpg as a backend, implementing a more-reasonable
choice in gpg seems like a good idea.

@_date: 2009-09-25 15:40:11
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
just to be clear: these are two keys with User IDs corresponding to the
same e-mail address, right?  And that person knows Baker, and Baker has
verified them with the keyholder, so presumably they're held by the same
How does the keyring holder indicate full trust in charlie and dan
without them being present in the keyring?  Have they done some sort of
weird gpg --import-trustdb operation without pulling in the key itself?
 Is this something people normally do?
If the user is assigning trust to charlie and dan explicitly during the
key imports you describe, does that make the change in key selection
behavior less confusing?
Your implication here is that it doesn't make sense to someone who
doesn't understand the WoT and OpenPGP. i think you're correct, sadly.
But i think that the current behavior also doesn't make sense to those
same people; if you haven't thought about how to choose a key based on
the user ID, the whole process doesn't make sense.  In that (admittedly
confused) state, it's even more important that the tools make healthy
What's more, there are (unusual) use cases for the current behavior that
result in confusion and dangerously bad security.  For example, Charlie
imported Alice's key a few years ago, and he imported Bob's key more
recently.  Charlie has certified both Alice and Bob's keys, so from his
perspective they both have full calculated validity.  Charlie granted
Alice marginal ownertrust, because he think she's pretty good at making
reasonable certifications.
Charlie conscientiously runs a "gpg --refresh" every so often, and  one
day Alice adds some new User IDs to her key (one of which matches
"Bob"'s User ID).  Every message Charlie now sends to Bob is going to be
encrypted to this bad User ID.  Bob won't be able to read them.  Even
worse: if Alice has the ability to tamper with the mail stream between
Charlie and Bob, she can intercept the messages, decrypt them, and
re-encrypt them to Bob.
Even if Charlie hadn't granted Alice marginal ownertrust, after he
updated her key, every time he tried to encrypt data to Bob, he'd get a
big warning about using a key with a poorly-bound User ID.
Yeah, i think this is reasonable.  I think the simple description of the
behavior is:
  Any time you encrypt data to another person, gpg figures out which
  key to use for them.  To make sure gpg can decide well, be sure to
  keep your keyring up-to-date and only mark keys with "ownertrust" if
  you seriously believe the keyholder will only issue valid
  certifications.
People who want further detail gets into "how does gpg make that
decision?" (with the exact algorithm description)  and "what if i want
to map names or e-mail addresses to keys differently?" (answer: use
another tool that can do the bindings for you; that tool should specify
full key fingerprints to gpg for encryption)
I'm glad to see that werner thinks this might be possible for 2.1:
  can you or Werner point to more documentation about how the keybox will
work with OpenPGP certificates as well as X.509?  Or should i just read
the source?  I'm interested to learn more about how you break that down.

@_date: 2009-09-27 18:51:46
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
ok, thanks, those are not expired, though i only see non-unicode in
three of them:  104B0FAF and F661F608, and 91190EF9.
Those keyholders should probably create a new User ID that *is* UTF-8,
with the same e-mail address as the non-UTF-8 one, and encourage the
people who have certified the old User ID to re-certify the new one.
Once enough certifications are through on the new, valid one, they can
revoke the old one and move forward with a fully OpenPGP-compliant key.
This seems like a reasonable stance for authors of MUAs and Plugins to
use.  Werner, it looks like you're the upstream author on GpgME; does
GpgME do any different selection technique than GPG?
If the user hard-coded a specific key (by fingerprint) to the Alice User
ID, then of course GPG should respect that preference (and it should
emit warnings if the key ever becomes invalid),  but i don't think that
users should be asked to make permanent choices like this, since they
might become invalidated by future circumstances; how will they know
that another (maybe better) choice is available, or should be made?
I hear what you're saying, but i think there are two problems with it:
 0) for many users, they are being asked to make a choice that they
don't understand; there are few things more frustrating than this.  If
the tool *can* make a good choice based on the knowledge available to
it, it shouldn't need to pester the user, who may or may not have as
much understanding of the problem space.
 1) users are being asked to make an effectively permanent decision,
even though relevant circumstances may change in the future.
Presumably, this binding will produce warnings (with the option to
change the binding) if the bound key suddenly actually drops into
unknown calculated validity (for example, if you decide to revoke
ownertrust on a relevant intermediary; has this been tested?)  But there
might be other changes that make this selection suboptimal without
causing it to throw warnings.
so i'm not a big fan of prompting users to hardcode bindings in general
(though i certainly support allowing users to hardcode bindings if they

@_date: 2009-09-29 18:10:38
@_author: Daniel Kahn Gillmor 
@_subject: choosing an encryption target from a User ID 
Thanks for the discussion, Ingo!  This is really useful to me, and i
appreciate the thought you've obviously put in here.
will she?  will Alice know how to resolve the problem?  If she sends Bob
her new key, and Bob imports it, that would be great.  They've already
had to do some work manually.  Let's say that Bob even takes the time to
properly certify Alice's new key.  You're now asking Bob to take an
*additional* step of "re-binding" the new Key ID to the User ID -- why
would he need to do that, when he's already certified the key?
if you're doing explicit, hard-coded keyID-to-UserID bindings, you're
not using the WoT.  You're using your bindings, perhaps with a smidgen
of the WoT to make sure that the key isn't totally invalid or revoked.
The way i'd like to see the WoT actually used is to get people to think
about two things which are well within the range of normal human activity:
 a) who can i identify?
 b) who can i rely on to identify others?
and then let reasonable, well-thought-out mechanisms draw the links for
the people automatically, without them having to think about it.
If the tools don't do the Right Thing by default, then we start to ask
users to think about a bunch of extra arcane ideas beyond a and b (ideas
that folks on this list have actually thought about in-depth).  Those
are tough to understand, and non-experts are justifiably confused by them.
This is why we need the tools to draw the right patterns by default, not
an argument to use hard-coded bindings or some centralized PKI that asks
the user to make none of these decisions at all.
I agree that it's not currently a common situation.  here are the few
legitimate situations with multiple keys that i know of:
 * several people are going through key transitions right now, for the
same reasons that the defaults are changing in gpg.  These people often
have two keys for a period of time.
 * Some people also have old keys that they have accidentally lost
access to.  once that happens, it's too late.
Malicious people can upload keys with arbitrary User IDs to public
keyservers; if a user fetches one of those from a search (perhaps to
check the validity of any attached signatures), it's still in their
keyring, possible before the valid key of the corresponding user.
If we say "it's not a common situation, so we won't worry about extra
hassle; only a few people will have to deal with the hassle", but anyone
can inject material into the public keyservers that trigger the hassle
for anyone else, i think that's a problem, even if no one has chosen to
exploit it yet that we know of.

@_date: 2009-09-30 09:38:00
@_author: Daniel Kahn Gillmor 
@_subject: Mismatch between binary and ASCII-armored output for encrypted 
OpenPGP encryption is a hybrid model:
 first, a random session key is generated.
 then the random session key is used with a reasonable stream cipher
(3DES, AES, etc) to symmetrically encrypt the data in question.
 then the session key is asymmetrically encrypted (once for each
recipient's key).
The resultant block is the concatenation of the ciphertext and the
encrypted session keys.
Note that the first step involves some randomization (as it should!) --
this means that each encryption of the same cleartext will yield
radically different ciphertext.
I suspect this difference is what you're seeing, not any issue with
does this make sense?

@_date: 2010-04-24 11:16:41
@_author: Daniel Kahn Gillmor 
@_subject: Elliptic curves in gnupg status? 
So, if you're interested in getting this support underway, you should
pprobably offer feedback on the I-D outlining how ecc should work with
  the IETF OpenPGP Working Group is probably a good place to offer feedback:

@_date: 2010-04-27 16:10:25
@_author: Daniel Kahn Gillmor 
@_subject: Time output format 
Hi Jeff--
if you are mechanically parsing the output of gpg, you probably want to
use --status-fd or --status-file and compare the info from there.  You
might want to read the DETAILS file (/usr/share/doc/gnupg/DETAILS.gz on
debian and debian-derived systems) for more information if the stuff in
the man page isn't sufficient.

@_date: 2010-08-25 12:58:55
@_author: Daniel Kahn Gillmor 
@_subject: Modified user ids and key servers and a possible security risk? 
keyservers do no cryptographic verification whatsoever.  I think this is
(historically) for several reasons:
 0) the clients receiving the OpenPGP certificates need to verify the
material anyway, and
 1) adding the cryptographic checks to the keyservers is a non-trivial
amount of work, and
 2) there is no guarantee that the keyservers will support any specific
cryptographic protocol.  For example, as elliptic curve keys get rolled
out for OpenPGP, what should cryptographic-capable (RSA, DSA, and
ElGamal) keyservers do with such new keys?  what should they do with
certifications over old keys made by such keys?  And
 3) With the exception of self-signatures, it's entirely possible that
the keyserver does not have a copy of the issuer's key, and so can't
compute the validity of the signature in the first place.
So: is this a cryptographic risk? no, not for clients who verify things
on their own.  Is it a risk of cruft accumulating in the keyservers?
yep.  Does it mean you shouldn't trust the information you see published
in a keyserver web page without fetching the keys and verifying them
locally?  yes, but that remains true whether or not you believe that the
keyserver is implementing cryptographic checks, as the keyserver itself
could be compromised.
On balance, i think we should probably start considering adding crypto
to keyservers, with the knowledge of these particular constraints.  But
it's not there yet.
As always, i'd be happy to hear other people's perspectives on this stuff.
[0]

@_date: 2010-08-25 13:27:18
@_author: Daniel Kahn Gillmor 
@_subject: Modified user ids and key servers and a possible security risk? 
You could also create bogus signatures that claim to be from
non-existent keys and upload them to the keyserver.
my key would still be fetchable from the keyserver, but the bogus user
IDs wouldn't get imported.  The non-bogus material would be accepted by
the client, though.  One busted component doesn't invalidate the entire

@_date: 2010-08-25 14:37:08
@_author: Daniel Kahn Gillmor 
@_subject: Modified user ids and key servers and a possible security risk? 
Keyervers receive relatively few new certifications each day, certainly
a small fraction of the number of requests they emit.
Compared to offering hkps service (HKP-over-TLS on port 443), i doubt
we'd notice a big computational cost differential, but i have no
quantitative data on that.

@_date: 2010-08-25 17:49:18
@_author: Daniel Kahn Gillmor 
@_subject: Modified user ids and key servers and a possible security risk? 
this isn't very meaningful -- data is data, and you can't actually tell
if it's been touched by a hex editor.
for self-sigs of algorithms that the keyserver understands, that's
certainly a reasonable requirement.  This would allow keyservers to cull
bogus self-sigs, bogus primary key revocations, and any associated data
(e.g. be willing to drop any user ID that has no valid self-signature
associated with it).
Note that there are some potentially weird corner cases here: if what
used to be an invalid User ID becomes valid at some point in the future
(because a true self-sig shows up), then other third-party
certifications over that uid+key will suddenly become acceptable.
It opens a range of questions, including:
 * How do we distinguish a self-sig from a non-self-sig? (the presence
of certain subpackets indicates that a sig must be a self-sig, but the
absence of such subpackets does not necessarily indicate a non-self-sig)
 * What about self-sigs that use considered-weak digests? (these could
potentially be forged by malicious parties)  and which digests are
considered weak?
 * What about self-sigs of asymmetric keys whose algorithms the
keyserver doesn't support?
 * If the above are policy questions for the owner of the keyserver,
then we have an additional protocol-level question for gossip peers --
how do we interact with gossip peers who make different policy decisions
than we do, or who have implemented different a different set of
asymmetric cryptographic algorithms?
And that's *just* for the self-signatures.  Deciding how to cull the
non-self-signatures is an even larger can of worms.
ugh, no, please.  i'd rather not turn keyserver operators into
certifying authorities.  This would also introduce massive syncing
problems, since each keyserver operator might choose to rely on a
different set of peers, and would therefore accept a different set of
Pretty much the main job of the keyservers is to store signatures.  That
is, the contents of an OpenPGP certificate exist largely in the form of
embedded signatures over key material.  I can't think of any additional
data that a keyserver would need to request or save.

@_date: 2010-08-25 19:50:07
@_author: Daniel Kahn Gillmor 
@_subject: Modified user ids and key servers and a possible security risk? 
there's also a question of how it would affect the gossip protocol (that
is, server-to-server, not client-to-server), if one party declines to
accept some certifications.

@_date: 2010-08-25 22:02:34
@_author: Daniel Kahn Gillmor 
@_subject: Modified user ids and key servers and a possible security risk? 
That makes sense.  i wasn't originally trying to be that ambitious, but
i see where you're going with this.
 [...]
yup, that's a clever way to get rid of the non-self-sig case entirely --
by turning them into self-sigs effectively.  So you guarantee that you
have the public key material available to check the certifications with
i think you mean "only add *non-self-sigs* that have a "Third Party
Confirmation" from the original keyholder".  But yeah, i think this is
an interesting angle to pursue.
Would wide adoption of this kind of confirmation create another angle
that people could use to "force" signatures on a known text?  If so,
that might be a concern for digests that are known to have weaker
collision resistance (e.g. the kind of exploits used in the hashclash
efforts against MD5 back in Dec 2008 [0]).  Do other people see this as
a concern?
[0]

@_date: 2010-12-03 12:45:18
@_author: Daniel Kahn Gillmor 
@_subject: GPF Crypto Stick vs OpenPGP Card 
JPEGs themselves are problematic because of the ability to embed
arbitrary data in the metadata fields (EXIF, etc [0]).  So unless Are
you willing to try to display arbitrary metadata on your externalized
device, you're in trouble there too.
my laptop display is pretty small, and i read what i sign on it ;)

@_date: 2010-12-03 12:50:00
@_author: Daniel Kahn Gillmor 
@_subject: GPF Crypto Stick vs OpenPGP Card 
[...]
sigh.  I may read what i sign, but apparently either my grammar or my
proofreading skills are still below par :P

@_date: 2010-12-09 13:01:39
@_author: Daniel Kahn Gillmor 
@_subject: multiple subkeys and key transition 
Sorry, but i have to disagree with Robert on this (yes, i'm the author
of the blog post you linked to earlier).  If you want to switch to
stronger algorithms, now is a reasonable time to do it.
That we know of, anyway.  Nonetheless, its use for digital signatures
has been strongly deprecated by groups like NIST.  See [0] for links to
NIST recommendations.
This discussion currently seems to be idle, so i would not wait on it.
We need to get the discussion going again, certainly.
This statement seems to assume that the RFC can't or won't be updated in
a way that people could make the transition using the same key material,
assuming they were using strong enough keys and digests in the first place.
My own personal bottom line: i've been using digests from the SHA-2
family for well over a year now (and larger RSA keys for twice that
time) and have had no interoperability problems.

@_date: 2010-12-09 14:12:38
@_author: Daniel Kahn Gillmor 
@_subject: multiple subkeys and key transition 
RIPEMD-160 is another 160-bit hash, same size as SHA-1.  I don't think
that it has undergone as extensive cryptanalysis as SHA-1; i'm sure
others on this list can give more intelligent commentary on its properties.
I prefer signatures made over digests longer than 160 bits (as do newer
versions of gpg, which default to stating SHA256 as a preferred digest).
That's probably because your primary key (the one doing signing and
certifying) is a standard 1024-bit DSA key (the original DSA standard
itself, FIPS-186 [0], specifies 1024 bit keylength -- longer DSA keys
come from later revisions of the standard, and are collectively known in
gpg as DSA2, if i understand it correctly).
But FIPS-186, as defined, only operates over 160-bit digests.  So longer
digest algorithms won't work with DSA1 keys.
The transition push is to make sure we have a functional WoT available
when SHA-1's collision-resistance is ultimately publicly broken in a
practical attac.  If that happens to re-ignite the WG discussion, that's
fine.  AFAICT, the only cryptographically-relevant places where the
current standard (RFC 4880) has SHA-1 "baked in" are:
 0) the fingerprint-calculating mechanism
 1) the designated-revoker sub-packet, because it references the
 2) that SHA-1 is the only official "must-implement" digest algorithm
A defeat of SHA-1's collision-resistance shouldn't have an effect on
point 0 because fingerprints are generated by a single party, on their
own -- there's no way for me to convince you to generate a key with a
specific fingerprint.  (a preimage attack against SHA-1 would be
devastating, though)
 The loose consensus seems to be that point 1 should be trivially
resolvable by defining a new version of the designated-revoker subpacket
that embeds the revoker's entire key (instead of just the fingerprint)
but no one has done the work to make that happen yet.  This wouldn't
even need a new version of the entire spec, it would just be an update
to the spec, claiming a new subpacket type from IANA.  And an example
implementation in a popular tool like GnuPG wouldn't hurt either, of
course. :)
 point 2 is a potential cause for concern, but in practice all OpenPGP
implementations distributed in the last 5 years have been able to
support SHA-256.  It seems like some folks in the OpenPGP WG would
prefer to wait until NIST's SHA-3 contest's results are announced and
settle on that outcome as a new must-implement digest for the next major
revision of the standard.
But that shouldn't stop you from using stronger digests today.
i don't know, but it doesn't seem out of the question to me.  There may
need to be a translation (and possibly re-certifying) step to move
existing strong keys to a new version when that comes out, but i don't
think it should require discarding those keys.  Weak keys, on the other
hand, will probably not be translatable.
i don't see the advantage of having two encryption-capable subkeys
myself, but it's your call.
i think we are at least as likely to switch to elliptic-curve as an
asymmetric algorithm than to ever start defaulting to 4096- or 8192-bit
RSA keys, but that's too far in the future for my crystal ball to see
[0]

@_date: 2010-12-09 15:48:33
@_author: Daniel Kahn Gillmor 
@_subject: multiple subkeys and key transition 
the things that get revoked are OpenPGP certificates.  the certificates
themselves contain key material.  The math that makes the key material
effective for encryption, decryption, signing, or verification doesn't
know or care about the revocation of the certificates.
We *interpret* those revocations to give us some reasonable real-world
guidance about whether to rely on a given key for encryption, signature
verification, or authentication.  But the underlying asymmetric crypto
operations will continue to work regardless of whether the certificates
are revoked.
It was addressed to anyone who wants to implement it, actually.  Anyone
looking to cut their teeth on this kind of stuff could pick this up as a
reasonable project.
Here's a previous discussion to get you started:

@_date: 2010-12-09 16:02:30
@_author: Daniel Kahn Gillmor 
@_subject: multiple subkeys and key transition 
Maybe we're not talking about the same thing, but i don't understand the
attack you describe.   Why would a weakness in the old certificate
format would be able to invalidate the same key under a new format?
Note: i am *not* talking about a weakness in the underlying ciphers,
digests, or asymmetric algorithms involved.
A weakness in the certificate format itself would certainly make me wary
of relying on certificates in the weak format, but why would it mandate
Could you give a more detailed example of such an attack?
Could you point to a reference that explains why a person with a v3 key
considered sufficiently-strong by that day's estimation (say, 1024-bit
RSA) would have had to create an entirely new key instead of just
migrating their old key to v4?
Thanks for clarifying,

@_date: 2010-12-09 17:32:52
@_author: Daniel Kahn Gillmor 
@_subject: multiple subkeys and key transition 
Again, can you give an example of such an exploit?
This sounds confused mainly because you're not distinguishing between
public key material and certificates.  I grant that the distinction may
well not be understood by lawyers and judges, but the conflation of the
terms here makes it needlessly confusing.
"That is not my certificate.  It was revoked (marked as superseded) on
$date.  I continue to use the same key material in a different certificate."
And if addressing a hopelessly legally-minded audience in the USA, you
could add: "of course i didn't make that signature; it uses
$deprecated_algorithm, which i haven't used since NIST deprecated it
back in 2010."
Unless, of course, you didn't follow NIST's guidelines and continued to
use the deprecated algorithms.  Then you couldn't make that claim.
Could you cite a reference for this?
There are lots of attacks that can be used against a clueless judiciary,
including things like creating a new key and associating it with your
victim's user ID, generating back-dated signatures and certifications,
etc.  That doesn't make the clueless judiciary a good argument against
the use of User IDs or timestamped signatures and certifications, though.
Except that you've now broken entirely with the past, which is itself a
human factor.  Smooth migration, phased upgrades, and planned
transitions are all good things from a human factors perspective.
Propagating a key across certificate formats might be a reasonable
approach for some of these goals (and of course, there may be other ways
to accomplish them too).
As part of the plans for a new OpenPGP certificate format, i certainly
hope we'll address ways to make the transition to the new format as
smooth as possible for most existing users.
OK, how about "were recommended to", or any other reference that
discusses the topic for that key version transition?
My point here is to avoid the creation of FUD around a potential new
version of OpenPGP causing a lot of work, or discouraging people from
using stronger crypto.
The possibility (probability) of a new certificate format coming down
the pike eventually should *not* be used to discourage people from
migrating away from known-weak and deprecated cryptographic algorithms

@_date: 2010-12-11 18:49:23
@_author: Daniel Kahn Gillmor 
@_subject: multiple subkeys and key transition 
"prevent snooping" means "only me and the remote server i'm connected to
has access to the communication".
if you don't know who the remote server actually *is*, you cannot
prevent snooping by a man-in-the-middle.

@_date: 2010-12-12 10:23:19
@_author: Daniel Kahn Gillmor 
@_subject: Best Practices 
Really?  i've got several certifications over my key's user IDs that i'm
pretty sure don't use SHA1 at all.
i note that gpg seems incapable of certifying subkeys using anything
other than SHA1, but that doesn't seem required by the standard.
What part of OpenPGP certificates require SHA-1?

@_date: 2010-12-12 15:03:42
@_author: Daniel Kahn Gillmor 
@_subject: Best Practices 
what do you mean by "V4 certificate checksums"?
These are not part of the OpenPGP certificate format.
yeah, this is serious, but it's not embedded in the certificate.  if we
were to come up with a new fingerprint format, it would not invalidate
any existing certificates -- it would just change how we refer to them.
agreed.  but this is not part of the certificate format.

@_date: 2010-12-12 18:37:36
@_author: Daniel Kahn Gillmor 
@_subject: Best Practices 
i thought that you might be referring to 5.5.3, but that is also not
part of the OpenPGP certificate format.
It's part of the secret key packet format, and it's not a part that is
cryptographically-signed either.  It looks to me like that checksum is a
way to verify that you've decrypted the key properly, and it's made over
material that you generated yourself.   If you've retained physical
control over your secret key material, this is certainly not a
cryptographic concern.
We can (and some of us do) use OpenPGP certificates and exchange
encrypted and signed material without relying on SHA-1 already.
The *fingerprint* format probably will need to change eventually (though
i haven't seen any indication of preimage attacks against SHA1 yet), and
the designated revoker subpacket is acknowledged to need an overhaul.
But you still haven't pointed to anything within the OpenPGP
*certificate* format itself that embeds SHA-1.
RFC 4880 mandates SHA-1 as a "must-implement" for compliant
implementations, but (aside from the rarely-used designated-revoker
subpacket) it doesn't require you to actually use it anywhere in the
certificates, as far as i can tell.  If i'm wrong about that, i
certainly hope to be made aware of it.
Again, the entire reason i'm engaging in this thread is to encourage
people to move to stronger cryptographic algorithms *today*.  I see no
good reason to wait for a new revision of the OpenPGP specification to
take advantage of stronger algorithms now.

@_date: 2010-12-12 23:50:24
@_author: Daniel Kahn Gillmor 
@_subject: Best Practices 
In the discussion last year on the IETF list, the general consensus
seemed to be that the fingerprints of primary keys were not endangered
by a weakening of SHA-1's collision resistance.  (This is in stark
contrast to digital signatures and certifications, where weakened
collision resistance in an algorithm represents a real threat [0]).
But as far as i know, no one has yet reported a significant practical
concern about SHA-1's resistance to a pre-image attack, which suggests
that reliance on SHA-1 for fingerprints is probably reasonable until
SHA-3 is selected.
Nonetheless, the purpose of the fingerprint is just to help humans
identify and communicate keys.  It is not embedded in the parts of the
spec for any part of the certificate format (aside from desig-revoker,
an acknowledged flaw in RFC 4880).  So i see no reason that when SHA-3
comes out, we couldn't define a new form of fingerprint (call it v5 if
you want) based on SHA-3, produce/consume that fingerprint alongside the
traditional v4 fingerprint for a reasonable time period, stop producing
v4 fingerprints, and then ultimately stop consuming v4 fingerprints.
Presumably when rolling out the new fingerprint format, we'd also
specify that SHA-3 is the new "must-implement" digest for compliant
implementations.  Clearly, anyone capable of providing an SHA-3-based
fingerprint has a tool capable of calculating SHA-3.
These strike me as updates to the specification, certainly ("we now
calculate fingerprints in the following way; We now require SHA-3 as the
lowest-common-denominator digest").  But this is not a change of the
certificate format.
Can you help me understand why a change in the choice of fingerprint
technique and a change in the must-implement-digest-algorithm would
require a change in the certificates themselves?
[0]

@_date: 2010-12-13 12:23:16
@_author: Daniel Kahn Gillmor 
@_subject: Best Practices 
FWIW, i don't particularly care about the secret key packet format.  My
focus in this discussion has been on the certificate format -- that is,
the public primary key packet format and the certifications binding
public primary keys to their User IDs, User Attributes, and subkeys.
Avoiding a systemic change to the certificate format seems like it would
be a Good Thing in that people could participate in a global smooth
transition, without requiring a hard cut-over or a global interruption
of existing networks of identity verification.
Given that the truncated keyid in the PKESK packet is only advisory
material to help the recipient choose which key to use to try to decrypt
(and not of sufficient length to provide cryptographic assurances even
if it was intended to do so), i think this packet could stay as it
currently stands, even if we choose to calculate the human-readable
fingerprint in some other way.
Wait -- i've been saying all along here that aside from
non-cryptographic uses like the MDC, and the primary key fingerprint
format itself (which is not vulnerable to weakened
collision-resistance), we *can* use OpenPGP with something other than
SHA-1 today.  As far as i understand it, that was the point of building
algorithm flexibility into OpenPGP in the first place.  Do you think
this has failed?
The IETF discussion last year reviewing the OpenPGP spec for use of
SHA-1 didn't turn up anything other than the parts we've been talking
about in this thread, right?

@_date: 2010-12-13 16:40:56
@_author: Daniel Kahn Gillmor 
@_subject: Best Practices 
I was assuming that new certificates come with new keys, and that new
keys could not certify or be certified by existing (old) certificates.
Are v3 keys able to certify or be certified by v4 certificates?
That sounds like what i would expect as well.
i agree.  That's why i've been proposing that people transition to new
algorithms without trying to wait for a format change that is likely to
take years to even begin, plus many more years to complete.

@_date: 2010-12-20 14:35:47
@_author: Daniel Kahn Gillmor 
@_subject: multiple trust signatures 
Hi Imran--
you're asking good questions, but your example might be more complicated
than you need it to be.  More interleaved below:
Note that there are two underlying questions involved here:  ownertrust
and calculated validity.
GnuPG internally assigns ownertrust to a *key* (that is, "how strongly
are we willing to rely on OpenPGP certifications made by this key?").
But validity is calculated over a User ID and its primary key (that is,
"How sure are we that this primary key (and consequently, all of its
properly-bound subkeys) belongs to the real-world entity referred to by
the User ID in question?").
With that in mind...
trust depth(3).
In this case, B's certification of D's key+UserID is sufficient on its
own for the user to believe that D's key belongs to D's User ID.  (this
is a question of *calculated validity*.)
This is because A's tsig on B implies a delegated full ownertrust of
depth >= 1.
So much for calculated validity.  Let's move on to ownertrust.
Directly-assigned (i.e. not via tsigs) full ownertrust is always
implicitly of depth 1.  That is, we're willing to accept certifications
made by this party, but we're not willing to rely on chaining through
their tsigs.
If this is the behavior you're seeing, it sounds like a bug to me.  From
the above, i would expect gpg to treat D as having a trust depth of 2 at
"full" -- this is because A's delegation to B of (full, depth 3) would
drop one depth level, across B's full tsig on D.
so the path through B is (full,3)_(full,3) ? (full,2)
and the path through C is (marginal,2)_(marginal,2) ? (marginal,1)
Combining the two paths should leave us with the strongest trust: (full,2).
For a single trust path, i'd expect the chaining rule to be:
if you start with:
 (level_n,depth_n) on X
and encounter the next-hop tsig (from X to Y) of (level_m,depth_m), it
seems like the trust value for Y should be:
  (min(level_m,level_n), min((depth_n-1),depth_m))
But if you have multiple independent trust paths to Y, the general
merging case is unclear to me.  And with non-independent trust paths to
Y (i.e. where some paths share more than one node), the merging case is
even more unclear.
I would think that if any one path resulted in a depth no less than
other, and with a higher trust level, the trust values from that path
should be chosen.
trust signatures are made over the key+userid pair.  i touched on this
briefly earlier in the year in my post to gnupg-devel titled: "WoT
Proposal: double-counting suppression":
  You might also be interested in the spec for trust signatures:
  hope this is helpful,

@_date: 2010-12-20 16:13:48
@_author: Daniel Kahn Gillmor 
@_subject: multiple trust signatures 
These are my intuitions about how trust path calculations *should* work,
not evidence from any particular code.
if you're referring to a code path, can you reference the specific
version, file, and line numbers you're asking about?

@_date: 2010-02-25 14:01:48
@_author: Daniel Kahn Gillmor 
@_subject: How to sign an email in PHP? 
Please file bugs against the PEAR libraries in question so that they can
be fixed.  Thanks!

@_date: 2010-01-06 00:34:42
@_author: Daniel Kahn Gillmor 
@_subject: Changing expiration time of subkeys 
Hi taurus--
sub-keys are not bound to any particular uid ("user id"), but rather to
the primary key itself.  selecting any particular uid shouldn't have any
effect on any particular subkey.
The things you're underlining here (it's not really aligned using a
monospace font, so i'm not sure) appears to be the "created" field, not
the "expires" field.  this is confusing.
Looking at C9CFBFA0 on the public keyservers, i don't see your signing
subkey (ED88A3D8) on it at all.  is it possible that has not been
published?  (your jpeg UAT is also not published, afaict)
i think the usual recommendation is to not bother updating expiration
dates on subkeys; just make a new subkey with the intended usage flags,
and set a new expiration date.  This should work fine for both signing-
and encryption-capable subkeys as long as you re-publish your entire
OpenPGP cert to the keyservers after adding the subkey, and your
correspondents know how to update their keyrings.
is there a reason that you need to keep any particular subkey in use?

@_date: 2010-01-06 01:17:08
@_author: Daniel Kahn Gillmor 
@_subject: Changing expiration time of subkeys 
I think the argument goes like this: do you have a way of getting
updates about your key to your family?
If you do, then you should be able to get them updates about new
subkeys.  So you don't need to update the expiration date of the old
If you don't have a way to get updates about your key to your family,
then updating the expiration dates of the old subkeys is irrelevant,
because they'll never get the updated expiration dates anyway, so they
won't know about them.
Anyway, it's up to you, of course, but i don't think the key being
private or certain other people using it are terribly strong arguments
for keeping a particular subkey instead of just creating a new one
(though i do think that stronger arguments exist for doing this in some

@_date: 2010-01-06 20:39:53
@_author: Daniel Kahn Gillmor 
@_subject: Formalizing the Facebook Web of Trust 
Interesting!  thanks for pointing it out.
I like the idea of using Facebook as a transport/distribution mechanism.
 I'm less confident in their use of Facebook to encourage keysigning.
For example, i'm not even sure i understand the part here where they
talk about "photos of Devin taken by his friends":
 from the facebook app on page 7 of the presentation:
Also, the authors of the presentation seem to have gotten the semantics
of keysigning confused with ownertrust.  Standard OpenPGP key signatures
certify *nothing* about the issuer's belief in the subject's capacity as
a keysigner, but their facebook app suggests otherwise (also on page 7):
These concepts (the difference between key/uid validity and ownertrust)
are already pretty confusing; it would be a shame if facebook users were
introduced to the OpenPGP concepts by this sort of a mixed message.
That said, OpenPGP does have many of the properties that make social
networking appealing.  it'd be a Good Thing to use existing social
networks to bring people into the Web of Trust online, if done carefully.
PS their pidgin work is unclear from the paper, so i don't really know
how to evaluate it.  if all they did was fetch keys from facebook,
that's a little weird (since they could already fetch keys from the hkp
network).  i'm also not convinced that OpenPGP messages are the best
technological choice (without *significant* extra thought and UI work)
for instant messaging.

@_date: 2010-01-07 10:45:04
@_author: Daniel Kahn Gillmor 
@_subject: Web of Trust itself is the problem 
I beg to differ.  anyone who has ever conducted online business has a
strong incentive for communications secrecy with a remote party with
whom they do not yet have a trusted relationship.
At the very least, the transfer of payment credential information is
something most people would prefer was only seen by the other party in
the transaction.
The fact that most online transactions like this happen through the
world wide web these days, and not e-mail, is perhaps a reason that the
WoT does not have wider adoption, since the WoT is not used for the www
(yet -- some of us are working on that).
Online transactions are only one of many examples, but probably the one
that people are most familiar with.  The WoT also provides a method to
handle situations like key loss or revocation, and subsequent new keys
without forcing the keyholder to meet up in-person (or otherwise secured
out-of-band) with every one of their contacts.
Why is this all relevant?  There are good reasons why you might be
interested in knowing that someone specific signed something public , of
course (e.g. software signatures, advice on mailing lists or other fora,
etc).  But for non-public communications: you *must* know who the remote
endpoint is in order to have truly secret communications.  Without that
knowledge, you are communicating with an unknown party, so who are you
keeping things secret from?
"secret" communications with an unknown remote party over a
trivially-compromised communications medium are anything but secret.

@_date: 2010-01-07 12:02:45
@_author: Daniel Kahn Gillmor 
@_subject: Web of Trust itself is the problem 
agreed, key continuity checking is itself a useful tool, and maybe more
OpenPGP implementations should provide ways to facilitate that for keys
that *aren't* well-bound to the Web of Trust by the user's current trust
Key continuity checking doesn't solve the problem of initial contact,
though.  And it doesn't cope well with re-keying in the event of a
compromise.  So having functional, cryptographically-valid
infrastructure available to handle those important cases is a good thing.

@_date: 2010-01-15 14:55:50
@_author: Daniel Kahn Gillmor 
@_subject: weird behavior of symmetrically encrypted file 
Hi Tobias--
I suspect what you're seeing is a function of the way the OpenPGP
standard handles passphrase calculations for "Symmetrically Encrypted
Data Packet" [0].
Basically, the data that is being symmetrically encrypted is prefixed
with an IV that contains a duplicated chunk of 16 bits for a
non-normative "quick check" that the session key was correct.  This
means that 1 out of 2^16 choices of session key will falsely pass the
quick-check purely by chance, even though the material is actually not
correctly decrypted.
I don't know what brute force method you were using, but i suspect you
had about 5 bits of entropy per character in your enumerations.  For
example, all lower-case letters plus numbers is a total of 36
possibilities, which is just about 5 bits (2^5 == 32).  With 4-character
passphrases at 5 bits per character, you would run through 2^20
passphrases.  So it's likely that you exhausted 2^16 passphrases, and
stumbled into one of the "quick check" false positives.  This does *not*
mean that your data is insecure.  It means the quick check is advisory
at best.
(see also the security considerations related to this "quick check" [1])
hope this helps,
[0] [1]

@_date: 2010-01-18 13:35:19
@_author: Daniel Kahn Gillmor 
@_subject: weird behavior of symmetrically encrypted file 
Hi Tobias--
You're welcome!  Glad to be helpful.
my understanding of the steps involved is slightly different -- i don't
think you'll be able to speed things up much the way you describe.  (if
you could, it would certainly reflect poorly on the OpenPGP packaging
I think the steps needed are:
 * generate the key from the proposed passphrase, using whatever S2K
technique is indicated by the file; you can get this from
  gpg --list-packets

@_date: 2010-07-22 16:32:12
@_author: Daniel Kahn Gillmor 
@_subject: plausibly deniable 
Yes: do not sign your messages.
OpenPGP signatures are inherently designed to be non-repudiable.  This
is not what you want if you want deniability.

@_date: 2010-07-23 10:32:17
@_author: Daniel Kahn Gillmor 
@_subject: plausibly deniable 
[...]
I think there is some confusion in this post about the nature of public
key cryptography.  There is no way to cryptographically prove the
authorship of an arbitrary encrypted document.  Anyone with access to
the public key material (which is to say, anyone in the world) can
encrypt messages to a given key.
There is no way to "prove that you did not encrypt" a message.

@_date: 2010-07-23 10:51:40
@_author: Daniel Kahn Gillmor 
@_subject: gpg --batch --yes --edit-key trust 
If i understand you correctly, I think you want --import-ownertrust.
feed it the equivalent of the output of  gpg --export-ownertrust, and
you should be able to do what you're looking for.
You'll need to know the key's full fingerprint, though.

@_date: 2010-05-31 19:18:04
@_author: Daniel Kahn Gillmor 
@_subject: ...key belongs to ... 
Please do not follow Dan Mahoney's suggestion here :/
The prompt you're trying to address is about fixing gpg's perceived
calculated validity of the key, *not* about how much you trust the owner
to make proper certifications.   Trust signatures or edited ownertrust
should not be used to adjust the validity of a single key's user ID,
since an adjustment like that will have other unintended consequences
(e.g. the holder of the key whose ownertrust is elevated will now be
able to fool you into thinking that other key+uid combinations are
actually valid).

@_date: 2010-06-10 11:32:05
@_author: Daniel Kahn Gillmor 
@_subject: Keyserver spam example 
Hi Joke--
This is exactly what David said in his initial e-mail, yet your replies
in this thread come off as though you are arguing with or dismissing his
For the record, i also got spammed with a similar message to the one
David quoted; i don't remember which keyserver was indicated as the
source, though.
And i should probably add that it is indeed an infinitesimal drop in the
bucket compared to the other spam i receive; i'm not concerned about it.

@_date: 2010-06-10 12:22:07
@_author: Daniel Kahn Gillmor 
@_subject: [OT] spam avoidance via IP-based filtering at the MTA [was: Re: 
Please cite this RFC.  All IP addresses are "dynamic" in some sense --
you cannot guarantee that the same organization or entity will control
them in a few years' time.
This is now sufficiently off-topic for gnupg-users, so i'm not going to
reply on this thread anymore.

@_date: 2010-06-14 12:50:32
@_author: Daniel Kahn Gillmor 
@_subject: auto refresh-keys 
I think something like this would be a good idea.  I've found that many
users (even sophisticated users) of GnuPG never refresh their keyrings
manually, which means that they use a good strong tool to (for example)
encrypt messages to known-revoked keys (in a recent case, to a key whose
revocation certificate was published over 2? years ago).
This is bad security for those users.  GnuPG should help those users to
Do The Right Thing as automatically as possible.
here's a proposal: gpg could keep track of the last time it refreshed
any given key from a public keyserver.  when the user tries to use that
key, if the last-refreshed time is more than X days ago, the key is
refreshed (and the associated part of the trustdb updated?) before use.
 Upon succes, the last-refreshed time associated with that key should be
Network or keyserver failures during an auto-refresh should be accepted
and the rest of the operation should continue (though the last-refreshed
time shouldn't be updated).
What if the network and keyserver are both available, but the keyserver
has never heard of the key in question?
Sounds good to me.  i could even imagine this being a per-key setting,
but that might be more complexity cost than is worth incurring for the
(minimal) gain.
for signature data coming from keyservers during an auto-refresh, i
could see doing the following triage to avoid storing gigabytes of
unnecessary stuff:
 * discard all certifications made by keys which we do not have a local
copy of (since they are meaningless for computing calculated validity of
a key).
 * discard all certifications which are not cryptographically valid, or
are executed with cryptographic algorithms we do not support, or which
rely on known-weak cryptographic algorithms.
 * discard all certifications which are larger than some
Certifications fetched are either over:
 0) a User ID and a primary Key, or
 1) a primary key and an associated subkey (these are usually self-sigs
or revocations), or
 2) a primary key itself (also usually self-sigs or revocations)
For each thing being certified:
 * for cryptographically-valid certifications (or revocations) from any
given public key (or its associated subkeys): only store the
certifications with the most-recent certification date.  This prevents
fetching, say, 1000 certifications from an abusive certifier.
What do other folks think about this?  The more we can make gpg do the
right thing automatically (and this includes picking up revocations and
updates), the more useful it will be in terms of providing real secured
communications for its users.

@_date: 2010-06-14 13:19:58
@_author: Daniel Kahn Gillmor 
@_subject: auto refresh-keys 
sorry, this thought didn't get finished.  it should have said:
* discard all certifications which are larger than some pre-defined
value (e.g. do no not bother processing certifications that are > 512KB
in size, as there are currently no certifications that need to be
anywhere near this size.
The goal, again, is to avoid auto-refresh from chewing up too much space
on the local disk.

@_date: 2010-06-14 20:46:30
@_author: Daniel Kahn Gillmor 
@_subject: auto refresh-keys 
Your disks might be in excess of a terabyte.  The large majority of mine
aren't.  Even if mine were, given that i'd like to see GnuPG easily
available on mobile telephones and similar devices, i think disk space
is a relevant metric.  And even on the machines i use or administer that
do have disks in excess of 1TB, disk I/O is a regular source of
bottlenecks.  Writing useless material to disks in any regular fashion
is behavior to avoid.
Plus, if we can demonstrate that GnuPG cares about minimizing costs to
the user in terms of disk space, we also stand in a better rhetorical
position to encourage development (or adoption) of alternate keyserver
fetch requests that could apply similar minimization heuristics to

@_date: 2010-06-16 13:10:17
@_author: Daniel Kahn Gillmor 
@_subject: auto refresh-keys 
I was considering the same heuristics that i outlined here (though
they'd be relative to the keys that they *keyserver* knows about, rather
than the keys that the user knows about, of course).  This would be a
species of "fetch-reduced"
Your "fetch-minimal" would probably only fetch the latest
cryptographically-valid self-certifications made by the key itself (or
its subkeys.  This would facilitate fetching revocations, expiration
updates, changes in algorithm preferences, etc.
a "no-UATs" flag (what i think you mean by "no-photos") might also be
useful in minimizing bandwidth if the mechanism doing the checking has
no way of dealing with UATs.
Do you have other suggestions?  We should consider bringing a
prioritized form of these to the sks-devel list.  Probably
"fetch-minimal" would have the best work-to-reward ratio, though it
would involve teaching SKS about how to compute the crypto.

@_date: 2010-06-17 10:15:24
@_author: Daniel Kahn Gillmor 
@_subject: undefined symbol: =?UTF-8?B?Z2NyeV9tZF9oYXNoX2J1ZmZlcuKAjw==?= 
no, you went it on the right one first -- this is a gcrypt question, not
a gnupg question.
i've answered you on gcrypt-devel.  Sorry that no one else has answered
in the meantime.s

@_date: 2010-06-17 12:21:32
@_author: Daniel Kahn Gillmor 
@_subject: Can we use GNUPG with PGP for commercial use 
Hi Prakash--
GnuPG is a tool which provides an RFC 4880-compliant implementation of
the OpenPGP standard.  It is free software (under the terms of the
General Public License), and you can use it for whatever purposes you
want.  It is interoperable with other OpenPGP implementations which
comply with RFC 4880.
PGP is a proprietary tool sold by PGP Corp.  It also implements the
OpenPGP standard, and should interoperate with GnuPG (and other OpenPGP
implemetnations), as far as i understand it.  I do not know specifically
what PGP Corp's licensing restrictions are for their PGP tool.  You
should probably ask them directly; this list is a GnuPG discussion list,
and has no affiliation with PGP Corp.
Hope this helps answer your question,

@_date: 2010-06-17 13:00:21
@_author: Daniel Kahn Gillmor 
@_subject: Can we use GNUPG with PGP for commercial use 
If your goal is to be able to sue someone over proprietary software, i
strongly advise you to read the relevant EULA first:
 section 9 in particular is illuminating about the scope and duration of
whatever minimal warranty you get from having purchased a license.
If you need commercial support, there is no reason to avoid free
software.  Several companies offer commercial support for GnuPG:
  Please don't spread the false idea that only proprietary software is
available with commercial support.

@_date: 2010-06-22 00:25:15
@_author: Daniel Kahn Gillmor 
@_subject: local signatures: should they be importable by default in some 
Why is it more reasonable to auto-import local signatures if the secret
key of the issuer is available than otherwise?
I'm trying to understand the use case that you guys both seem to have
intuitively picked up.  Some of the common use cases i've seen for
non-exportable sigs definitely do *not* have people importing them from
keys they control, so i'm not seeing why it's a special case.
Can you help me understand?

@_date: 2010-06-22 02:36:26
@_author: Daniel Kahn Gillmor 
@_subject: local signatures: should they be importable by default in some 
non-exportable certifications are simply certifications which keyservers
have been instructed to ignore.
I'm thinking of a situation involving three people: Alice, Bob, and Charlie.
Alice has met Bob in person and has verified his key.  Alice does not
want this information to be publicly available (e.g., she has concerns
about exposing a transparent social graph via the keyservers).  However,
Alice knows and trusts Charlie and wants to put Bob in touch with
Charlie, even though Charlie and Bob have never spoken before, and
certainly have not verified each others' keys.
Alice makes a non-exportable certification over Bob's key+userID, and
mails it to Charlie (in an encrypted message, of course).  Charlie
imports the certification.  Now even if Charlie does something like "gpg
--send $BobsKeyID", the fact that Alice has met Bob will not be publicly
Seem like a reasonable use case for non-exportable certifications?

@_date: 2010-06-30 13:06:58
@_author: Daniel Kahn Gillmor 
@_subject: How to sign a remote repository, i.e. forward agent 
[ ... ]
I maintain several signed apt repositories.  I never forward an agent to
maintain them, and my secret key never leaves my trusted physical
console. My workflow is:
 * do reprepro work against my local copy of the repo (including signing
the relevant indexes)
 * rsync -avz --delete dists pool owner at remote.test:/path/to/archive/
that is, i transfer already-signed files (the relevant ones, namely the
contents of dist/ and pool/) via rsync to the remote host that provides
public downloads.
Does this workflow work for you?  if not, why not?

@_date: 2010-06-30 14:17:53
@_author: Daniel Kahn Gillmor 
@_subject: How to sign a remote repository, i.e. forward agent 
If you're worried about collisions/race conditions, you could reduce the
race window to an arbitrarily small timeframe by having your sync
scripts hold an advisory lockfile on the public-facing machine.
Then, assuming everyone is using the same publishing scripts and has
access to the archive's secret key, you can ensure that you're
transmitting only the latest updates.
In that case, you probably want to sync conf/ and db/ (in addition to
dists/ and pool/) to ensure that everything is updated properly.
(you'll also want to ensure that everyone is using compatible versions
of reprepro).
OK, this is OT enough for gnupg-users now that i recommend following up
off-list if you need to.

@_date: 2010-03-03 13:25:04
@_author: Daniel Kahn Gillmor 
@_subject: key question 
Can we not go down this line of argument, please?  Not everything that
"the authorities" frown on is criminal, and not every action in
opposition to the law of some given state is necessarily immoral.  I'm
sure this isn't true about $yourowncountry, but please consider the
situation for citizens of $thatevilcountry.
OpenPGP is a tool for encrypted and/or authenticated communications.  If
we were to declare from the outset that OpenPGP is not (and will never
be) a good tool for use by people struggling against oppressive regimes,
we would strand a significant proportion of people who have a strong
legitimate need for encrypted and authenticated communication.
What a waste that would be!
If the community in question is a geographically-distributed one, and
the tools are used wisely, OpenPGP can actually be a pretty good choice.
Speaking as one user of OpenPGP, I do not share your assumption.
The "Open" in OpenPGP refers to the nature of the standard: the standard
is public, well-documented, and peer-reviewed.  Anyone is free to
implement it, and there are public discussions around the nature of the
standard itself.
The "Open" in OpenPGP does *not* refer to any broader sense of
transparency among its userbase, or even a requirement for
implementations of the standard itself to be open (GPG is free software,
but other implementations of OpenPGP are not).

@_date: 2010-03-04 12:45:44
@_author: Daniel Kahn Gillmor 
@_subject: Changing & verifying the --max-cert-depth in Windows 
I think you're not reading that data the way that it was intended to be
read.  (this is not your fault, the docs are pretty thin).
That line says "of the certificates that are depth 0 from you (meaning
they effectively *are* you), there is exactly one valid OpenPGP cert,
and it has been granted ultimate ownertrust" -- this is a description of
*your own key*, actually.  the "signed: 0" bit suggests that your key
has made no certifications over the userIDs of any other OpenPGP key.
When i run gpg --check-trustdb, i get an additional line of output:
0 dkg at pip:~$ gpg --check-trustdb
gpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model
gpg: depth: 0  valid:   1  signed:  83  trust: 0-, 0q, 0n, 0m, 0f, 1u
gpg: depth: 1  valid:  83  signed: 128  trust: 70-, 1q, 1n, 10m, 1f, 0u
gpg: next trustdb check due at 2010-03-07
0 dkg at pip:~$
So my first line (depth: 0) looks similar to yours, but points out that
my key has made certifications over the userIDs of 83 other keys.
that second line (depth: 1) says:
  of the certificates that are 1 hop away from you, 83 of them are known
to be valid (these are the same 83 that i've personally certified).
none of them have ultimate ownertrust (otherwise that key would be
listed in the depth: 0 line), one of them has full ownertrust ("1f'), 10
have marginal ownertrust ("10m"), 1 has explicitly *no* ownertrust
("1n"), 70 i've never bothered to state ownertrust ("70-"), and 1 has
explicitly-stated "undefined" ownertrust ("1q" -- i'm not really sure
how this is different).
I'm also not sure what the "signed: 128" suggests in the "depth: 1"
line.  Surely of all 83 keys i've certified, they have collectively
issued more than 128 certifications themselves.  maybe someone else can
explain that bit?
so, your max-depth is being respected -- you're nowhere near 3 hops away
from your key.  in fact, it looks like you've issued no ownertrust to
any key other than yourself, so changing the max depth won't have any
current effect.
Here's my understanding:
 * when you certify the userID of a key, you're saying you believe that
the real-world entity referred to by the User ID does in fact control
the secret part of the key.
 * in particular, you say *nothing* about whether you feel you can rely
on certifications made by that key.
 * internally to GPG, you can also assign a level of "ownertrust" to any
given key -- this tells your OpenPGP toolset how much you you are
willing to believe certifications made by that key.
 * Your own key is marked by default as having "ultimate" ownertrust,
which means that any userID/key combo certified by your key will be
considered to be valid.
 * Note that GPG will not apply ownertrust to a key (even if you've
specified it) unless it already believes that at least one User ID on
that key is valid.
So to reach a depth of 2, you'd have to have assigned ownertrust to at
least one key that you had not personally certified (but was certified
by other keys in which you've placed ownertrust).  To reach a depth of
3, you'd have to have assigned ownertrust to one of the keys that are
depth 2 from you, etc.
hope this helps,

@_date: 2010-03-04 13:20:30
@_author: Daniel Kahn Gillmor 
@_subject: Changing & verifying the --max-cert-depth in Windows 
doesn't the "1u" in the output above indicate that he does have an
ultimately-trusted key?

@_date: 2010-03-04 15:52:59
@_author: Daniel Kahn Gillmor 
@_subject: Changing & verifying the --max-cert-depth in Windows 
I've got a large-ish keyring (>1300 keys), and it's fairly regularly
refreshed.  i'm pretty sure that of the 83 keys that i've signed,
they've made more than 128 certifications in aggregate, even if we only
count keys themselves and not UIDs (that is, even if a key with multiple
certified User IDs only counts once).
Is there another explanation?

@_date: 2010-03-05 10:43:35
@_author: Daniel Kahn Gillmor 
@_subject: Migrating from PGP to GPG question 
I think the simplest thing for you to do is to modify the ownertrust of
your old signing key on the new installation.  That is, you say that all
the keys are signed, presumably by some particular key that you used in
your PGP installation.  Let's pretend that key's ID is 0xDECAFBAD.
You'd do:
 gpg --edit-key 0xDECAFBAD
and then from the gpg subshell, do:
 trust
which will give you a menu like this:
Please decide how far you trust this user to correctly verify other
users' keys
(by looking at passports, checking fingerprints from different sources,
  1 = I don't know or won't say
  2 = I do NOT trust
  3 = I trust marginally
  4 = I trust fully
  5 = I trust ultimately
  m = back to the main menu
indicate that this installation should trust your signing key
"ultimately", and then type "save" into the gpg subshell.
Now, you can encrypt to any key that has been certified by 0xDECAFBAD
and you won't get that warning, because gpg trusts the certifications
made by your signing key.

@_date: 2010-03-16 10:38:58
@_author: Daniel Kahn Gillmor 
@_subject: Should I set cert-digest-algo? 
Hi Grant, i'm the author of that post.
I've used cert-digest-algo SHA512 (even more likely to cause interop
problems than SHA256) ever since i wrote that post, and i have gotten no
complaints at all about my certifications being unusable.
this may have something to do with who i interact with, though (mostly
other free software folks);  you might have a different experience if
you have contacts who are locked into ancient software for one reason or
I think that SHA256 should be pretty unobjectionable these days.

@_date: 2010-05-06 23:15:10
@_author: Daniel Kahn Gillmor 
@_subject: Wrong signature hash detection? 
What makes you say this is "obviously not an SHA1 signature" ?  When i
pipe it through pgpdump, i get this:
Old: Signature Packet(tag 2)(332 bytes)
and gpg --list-packets shows this:
:signature packet: algo 1, keyid 395845F67F637E7B
Both of which suggest that the digest used is in fact SHA1.
Are you judging based on the size of the block?  RSA signatures are
significantly larger than DSA signatures, even though they sign over the
same digest algorithm.

@_date: 2010-05-08 19:07:00
@_author: Daniel Kahn Gillmor 
@_subject: Help me to import my secret key please 
I'm afraid these are not the same key :(
The former key is a 4096-bit RSA key.  The latter key is a 1024-bit DSA
key with a 4096-bit ElGamal subkey bound to it.
Also, the former key has an X.509 certificate assoiated with it, while
the latter keys are bound to your identity via OpenPGP certification.
While it's possible to have both X.509 certificates and OpenPGP
certificates from the same key (we're doing it for TLS servers in the
monkeysphere project), it's not common.  And in your case, it's not what
you've done anyway, since these are clearly different keys because of
their different keylengths and algorithms.
If you have no way of recovering your old ~/.gnupg/secring.gpg, you have
most likely lost control of your old key.  In that case, i recommend
publishing the revocation certificate you created when you made your key
(hoping that you have such an old revocation certificate for 1F03B55A
stored someplace accessible to you).
Sorry to be the bearer of bad news,

@_date: 2010-05-09 09:33:24
@_author: Daniel Kahn Gillmor 
@_subject: Help me to import my secret key please 
Yup, Charly is correct about this.  You can actually have as many keys
as you like with the same UID in the public keyservers.
I'm not sure exactly what Charly means here, but i strongly recommend
you do *not* put this kind of remark in the comment section of the User
ID for your new key (between the name and the e-mail).  A better
approach is to make a key transition document that describes the
situation, sign it with the new key, and post it publicly.  For example:
  (if you still had access to your old key, you could have signed the
transition statement with it too)
So why do i think you shouldn't put it in the comment section of your
new User ID?  Your User ID is the linkage between your key and your
real-world identity.  When you ask people to "sign your key", you are
asking them to certify (a) that this key belongs to you, and (b) that
they believe this User ID does really belong to you too.  If your User
ID contains a string that does not really relate to you, you're asking
people to certify something unusual and potentially meaningless.
Also, consider the situation 5 years from now -- hopefully you'll still
be able to use the key you made today.  Do you really want a remark
about this legacy key to follow you for 5 years?
Lastly, since you can't revoke the old key outright, you might consider
contacting everyone who has already certified it and asking them to
revoke their signatures on the key.  You can point them to your
published key transition document as a start, but you'll probably want
to also contact them offline -- this is also a good opportunity for you
to ask them to certify your new key.  That way, in the future, there
will be no valid certifications on your old key, and which key people
should choose for you should become clearer.

@_date: 2010-05-09 22:35:00
@_author: Daniel Kahn Gillmor 
@_subject: Help me to import my secret key please 
OK, but how many such comments should we use?  (see below...)
True.  And anyone who wants to can also create and upload a key with his
exact User ID and no expiration date, and that bogus key will also haunt
him forever.  Should he include a comment about not using that
maliciously-uploaded key as well?
What if 10 bogus keys are uploaded with his User ID?
If Joe User's real key is actually 0xDECAFBAD and he still has control
over it, what should other users do if they see a key uploaded with the
User ID of:
  Joe User (Do Not Use 0xDECAFBAD) (remember that anyone can upload such a key) ? Should people care about
or rely upon those comments?  Or are they noise?
The point is that people who haven't exchanged keys directly need to
rely on certifications, not on "oh, this key happens to have a
relevant-looking user ID bound to it".  Since they already need to rely
on certifications, it's best to just treat the bad/old key as though it
were one of the malicious keys that anyone could upload.
The most useful response is to make sure that your proper key is
well-certified, and that any bogus keys are not certified.

@_date: 2010-05-11 18:44:37
@_author: Daniel Kahn Gillmor 
@_subject: Encryption to key with multiple subkeys 
But UIDs aren't bound to subkeys (they're bound to the primary key, just
as the subkeys are bound to the primary key), so i'm not sure we have a
good way to handle the use case you describe in OpenPGP at all.
you mean by keyID or fingerprint?  that's brittle and unintelligible for
most people.
I'm not suggesting that joke's proposal of
encrypt-to-all-encryption-capable-subkeys is the right choice, but it's
not clear that there's any particular reason to prefer one key over
another (perhaps if you were introducing a new asymmetric algorithm,
you'd want to keep your old RSA encryption key around for users who
don't have support for the new algorithm).
I don't see any guidance in RFC 4880 about how to select an
encryption-capable subkey if there is more than one (but maybe i'm not
looking in the right place)

@_date: 2010-05-11 19:26:09
@_author: Daniel Kahn Gillmor 
@_subject: Encryption to key with multiple subkeys 
I haven't gotten your point either, then.  Perhaps you could explain in
more detail?

@_date: 2010-05-11 20:08:27
@_author: Daniel Kahn Gillmor 
@_subject: Encryption to key with multiple subkeys 
yup, i think this is a good argument for your proposed behavior.  what i
haven't seen yet (haven't thought through yet) is what the
counter-arguments might be.
For example, consider the introduction of a new encryption-capable
asymmetric algorithm X that has "better" properties than RSA (pretend
for a moment that some flaw is found in RSA).  I might want to have an
RSA encryption-capable subkey for all the deployed RSA-only
implementations to use, since using RSA is better than nothing.  But i
might want tools that *do* support X to use my encryption-capable X
subkey, and not the RSA key.
(the same argument can be made for old, small keys and newer larger
keys, if the larger key sizes do not have wide adoption, i think)
So that's one (albeit mostly fictional) scenario where you wouldn't want
to encrypt to both.

@_date: 2010-05-12 16:48:34
@_author: Daniel Kahn Gillmor 
@_subject: Help me to import my secret key please 
even this comment would be superfluous, since the key has a "Created on"
timestamp built in.  Also, his statement isn't really part of a person's
identity, which makes it more dubious to put it in the User ID as well.
Yes, it is.  Furthermore, if Alice had stored a revocation certificate
in a safe place, she could simply revoke the old key without needing to
rely on CACert (or any other certifier, for that matter).
Expiry dates on keys are only useful as a safeguard against accidental
destruction of the secret key material, not against loss of control of
the secret key material to a malicious party.  Once an attacker gains
control of the primary key's secret key material, she can update the
expiration date by issuing a new self-sig.
This whole scenario is a good argument for what is already accepted
best-practice: generate a worst-case-scenario revocation certificate
immediately after generating your key, and store that revocation
certificate securely in an offline place (e.g. print it to good paper
and destroy the digital copy).  This means there are no extra keys to
manage, and no third parties to rely on (unless you want to send a copy
of your revocation certificate to a trusted friend for use in an emergency).

@_date: 2010-05-17 15:11:41
@_author: Daniel Kahn Gillmor 
@_subject: Comment fields in the User ID [was: Re: Help me to import my secret 
I've been asking myself the same question; i haven't come up with a
clear answer.  The closest i've come is when someone uses the comment
field to state an organizational affiliation specifically for use with
that key, to differentiate from another key, such as:
 0xDECAFBAD
   Maria Lopez (Foo Corp. Administrator)  0xDEADBEEF
   Maria Lopez (Personal Use) Even these messages might be better stored some other way, though.  For
example, as OpenPGP notations in the self-signature.
What do you think?  When are comments in the User ID field actually useful?

@_date: 2010-10-31 19:24:57
@_author: Daniel Kahn Gillmor 
@_subject: Please remove pgp.mit.edu from keys.gnupg.net 
hi gnupg folks--
I just noticed that the keys.gnupg.net pool currently contains
pgp.mit.edu as one of the members.
This keyserver is not properly syncing with the rest of the global pool.
 For example, there are keys that have been in the global pool for
several weeks that have not migrated into pgp.mit.edu.  As a a result,
people pulling data from this keyserver will be unlikely to receive
updates, re-keying, and revocation events.
The broken sync appears to be bi-directional: people sending their data
to this keyserver will be unlikely to have their updates forwarded to
the rest of the pool (which means their correspondents will fail to get
the updates).
pgp.mit.edu has already been removed from pool.sks-keyservers.net.
I recommend you remove pgp.mit.edu (18.9.60.141) from the keys.gnupg.net
DNS round robin until the server begins re-syncing properly with the
global pool.

@_date: 2010-11-09 16:41:00
@_author: Daniel Kahn Gillmor 
@_subject: changing usage flags on a primary key 
Hi GnuPG Folks--
Let's say i have an OpenPGP primary key with usage flags ECSA set (some
keys like this have been known to be generated by GUI tools).
Say i wanted to convert this key into a decent primary key with a
reasonable/standard set of usage flags (e.g. CS or just C); is this
something i can do with GnuPG?
Basically, i'm asking about creating a new self-sig packet with a
modified key usage flags subpacket on a key that i control.  How would i
do that with GnuPG?

@_date: 2010-11-10 14:58:13
@_author: Daniel Kahn Gillmor 
@_subject: changing usage flags on a primary key 
hrm, even if i can do this, it probably isn't very convincing for most
people following gnupg-users :(
do you have a link handy?

@_date: 2010-11-11 23:19:19
@_author: Daniel Kahn Gillmor 
@_subject: gpg --verify detached signature from two file descriptors? 
Hi GnuPG folks--
i'd like to use gpg to verify a detached signature, but for various
reasons i don't want to put either part (the body or the signature) in
the filesystem (i have the data queued in two otherwise anonymous file
if i put the body on FD 0, i can verify the detached signature with:
 gpg --verify sig -
but i still need to have the signature in a file in the file system.  Is
there a way to tell gpg to read the sig itself from a file descriptor as
On some operating systems (in some configurations) it looks like i can
use (e.g.) /proc/self/fd/3 to read the signature from file descriptor 3,
but it would be nice to be more portable than that.
Any suggestions?
Thanks for gpg,

@_date: 2010-11-12 00:15:28
@_author: Daniel Kahn Gillmor 
@_subject: gpg --verify detached signature from two file descriptors? 
Hi Robert--
i don't think this solves the problem i'm looking to solve, but i might
be misunderstanding.
i'm hoping to use a detached signature precisely because i do *not* want
gnupg to have to find the delimiters between the data and the signature

@_date: 2010-11-12 17:20:30
@_author: Daniel Kahn Gillmor 
@_subject: gpg --verify detached signature from two file descriptors? 
i was actually hoping to avoid *me* having to do the extra work of
figuring out how to concatenate the data with the signature.
Do you have a suggestion for how to make such a concatenator for
arbitrary 8-bit data?  Do i need to build an OpenPGP data packet from my
input stream first?  Is there example code of such a concatenator someplace?
I grant that my own code is more likely to be buggy than gpg's.  that's
another good reason for me to not write a concatenator :)
Are you saying there is no way to pass a detached signature via a file

@_date: 2010-11-18 12:10:45
@_author: Daniel Kahn Gillmor 
@_subject: gpg --verify detached signature from two file descriptors? 
Hrm, but it doesn't seem to work for me to use the special filename for
the signature itself:
What am i doing wrong?  i'm using gnupg 1.4.11 from debian experimental
on i386, if that makes a difference.

@_date: 2010-11-20 21:02:39
@_author: Daniel Kahn Gillmor 
@_subject: OT: unusual mail reply header templates [was: Re: Gpg4Win 2.0.4 with 
Yes MFPA always seems to do that, for no reason that i understand.  I
find it unusual, unhelpful, and disorienting, but: meh.  Not worth
fighting about, and it's certainly not on-topic for this list.  I'm
responding to the list here to respect your Reply-To header, Jerry, but
please respect mine on this thread and follow up off-list if you must
follow up at all.
Let's keep gnupg-users about helping people use GnuPG, not about
discussing unusual mail user agent configurations that have nothing to
do with OpenPGP or S/MIME.

@_date: 2010-11-21 02:18:58
@_author: Daniel Kahn Gillmor 
@_subject: gpg --verify behaves differently when multiple signatures present 
when i have a set of OpenPGP signatures bundled together which have
different validities, it looks like gpg behaves differently depending on
if --batch is set or not.
In particular, an invalid signature seems to terminate the entire
--verify process (skipping later valid signatures) when --batch is set,
but it does not terminate the verification process otherwise.
Attached are two files: one is a simple shell script to demonstrate the
problem (with embedded data and signature material), and a fake key used
in the demonstrations.
When i run it, i get the following output (AB means the good sig from
the fake key occurs first, BA means the bad sig from my own key
(D21739E9) happens first:
And if i use a test user that doesn't actually have a copy of D21739E9
in its keyring, then i get feedback from both signatures even in order
BA with --batch (i suppose because the keyring can't tell that the
signature for D21739E9 is bad).
I see no good reason for --batch to cause gpg to terminate on the  first
badsig it sees, and no documentation justifying this behavior, so it
seems like a bug to me.
I tested this with gpg 1.4.11 and 2.0.14 on i386 GNU/Linux systems
running the current debian testing (gpg itself from debian's
experimental archive)

@_date: 2010-10-05 14:11:46
@_author: Daniel Kahn Gillmor 
@_subject: How to delete a signature from a key with delsig? 
how does it fail?
to be clear, if this sig is already pushed to the keyservers you cannot
delete it effectively, and your best bet is to revoke it.
It's not terribly obvious, but i think what you want to do within the
gpg --edit-key prompt is a multi-line approach:
 uid  delsig
 save
and then you should be back at your shell's prompt.

@_date: 2010-10-06 12:02:44
@_author: Daniel Kahn Gillmor 
@_subject: Encrypt Error - There is no assurance this key belongs to the 
This is not about trust for this key -- it is about validity.
The point is that the key does not have a valid binding to its User ID,
so encrypting "to the User ID" isn't going to work without prompting.
If the User ID + Key have been certified by some third party whose
certifications you're happy to rely on (and whose key already has a
valid binding to its user ID), you should mark that third party as fully
trusted.  Then their certifications will be acceptable, and the target
key will have a valid binding to its User ID.
Note that you'll need at least one key in your keyring to be marked as
"ultimate" ownertrust, in order to get the chain started someplace.
Usually, you'd mark your own key with ultimate ownertrust, since
(presumably) you know for sure which key is yours.

@_date: 2010-10-06 15:04:03
@_author: Daniel Kahn Gillmor 
@_subject: Remove key from an encrypted file? 
it's possible, but it's a bit clumsy.  you could use gpgsplit to handle
the situation:
 mkdir cleandir
 cd cleandir
 gpgsplit < $message
 rm 00000X-001.pk_enc  (make sure this is the one you want to remove!)
 cat * > $message
if you're not sure which pk_enc packet is the one you want, you can see
which key belongs to which with gpg --list-packets.  If $keyID is the 16
hex-digit ID you want to strip out, then the following should work:
  for foo in *-001.pk_enc ; do
   if [ "$keyID" = \
 $( gpg --list-packets < $foo | grep ^:pubkey | sed 's/.*keyid //' ) ];
   then
     rm "$foo"
   fi
  done
(these scripts are untested -- please test and verify before using them
in production!)
you could also do this, though it would require you knowing one of the keys.
note that neither method will protect you if the user in question has a
local copy of the encrypted file that still has the old info.
yes, this is right.  What you're calling the "random" key is known as
the session key.
Each of the *-001.pk_enc is a "Public-Key Encrypted Session Key Packet":

@_date: 2010-10-11 22:20:00
@_author: Daniel Kahn Gillmor 
@_subject: Confirmation for cached passphrases useful? 
I agree this would be useful, with a few notes:
 0) clients that have full access to the X session (or terminal, or
whatever mechanism is used for the prompting) can probably auto-accept
the prompt.  So malicious clients with this access wouldn't actually be
prevented from unauthorized access.  However, not all clients
necessarily have this level of access, so it can still be useful from
security perspective.
 1) gpg-agent might not be able to determine useful information about
requesting processes in some configurations, and on some operating systems.
 2) users should be able to specify which passphrases (or secret keys?)
they want to trigger a prompt for (some might not need or want a prompt).
 3) it would be nice for the prompting facility to be flexible enough to
support alternate prompt techniques (possibly differing from the
pinentry used to supply passphrases in the first place).  For example,
it would be nice if a prompt could only be accepted by some physical
response from the system (assuming the malicious client doesn't have
superuser access, in which case all bets are off anyway), even if the
alert for the prompt shows up via the windowing system or the console.

@_date: 2010-10-11 22:44:41
@_author: Daniel Kahn Gillmor 
@_subject: Confirmation for cached passphrases useful? 
If you already have root access on the system, then yes -- all bets are
off.  but that's the case anyway when the malicious attacker has root
It would help against the situation where the malicious client does
*not* have superuser access and cannot directly override the prompting
mechanism through other mechanisms.
Many standard X11 desktops today don't have such protections in place
(e.g. one process can send a simulated mouseclick to another process
pretty easily) but that doesn't mean no one is running with a
well-isolated gpg-agent.

@_date: 2010-10-11 23:05:45
@_author: Daniel Kahn Gillmor 
@_subject: Confirmation for cached passphrases useful? 
re-entering the passphrase each time is significantly more annoying than
confirming its use in a reasonable context.  (and re-entering the
passphrase every time the secret is used is less secure than a simple
confirmation prompt, since it trains the user to type their passphrase
over and over again)

@_date: 2010-10-12 01:54:00
@_author: Daniel Kahn Gillmor 
@_subject: Confirmation for cached passphrases useful? 
yes, of course this isn't going to be able to protect the user from
someone with full access to their user account or their current session.
Agents like gnupg-agent and other socket-driven services are capable of
being exported over heavily-constrained connections, where only access
to the agent's socket is given to the attacker.  For example, you can
forward ssh-agent over the network to a process on a remote host, or set
up a simple socket-forwarding service within a machine to grant access
to your gnupg-agent to other user accounts.
As an example, I know people who run their web browser in a
heavily-constrained mode, e.g. under a separate user account, in a
virtual machine or VNC session.  If such a browser (or a plugin to it)
wants access to the principal user's agent, it has only one recourse,
which is to talk to the agent's socket.  (This sort of constraint is
much more effective with the ssh-agent model, where secret key material
never leaves the agent, as opposed to the traditional gpg-agent model
where the agent is only a passphrase cache; it sounds like gpg-agent is
planning to adopt the ssh-agent model as of 2.1, which is great news.)
If the specialized/jailed account has access to such a forwarded agent,
then an attack against it *is* an issue.  It would be good to be able to
grant gpg-agent access to the constrained service when it requests it
reasonably, and to be able to deny it when it requests access unreasonably.
Conversely, people won't run well-isolated subsystems if the tools we
provide don't support reasonable separation and control in the first
place.  Do we want to build tools that support secure use?  If so,
implementing Hauke's suggestion at least in the GPG 2.1 branch is a good
idea.  And previous branches would be nice too, though the classic
gpg-agent communication model (passphrase-cache-only) is too weak for
the proposed confirmation prompt to enable well-isolated use.

@_date: 2010-10-12 03:05:56
@_author: Daniel Kahn Gillmor 
@_subject: Confirmation for cached passphrases useful? 
I think that grabbing mouse and kbd prevents other tools from *reading*
the kbd and mouse events.  It doesn't prevent synthesized events from
triggering those inputs (e.g. clicking "OK" on a button).
As a simple example, try:
  sleep 3 && xdotool key Return & echo GETPIN xxx | pinentry
The backgrounded process hits the enter key on a foregrounded (grabbed)
So while it's useful to protect passphrase entry from other snooping X11
applications, i don't think that the kbd/mouse grab approach is
sufficient protection for a simple confirmation prompt dialog box.
I'd be happy to be corrected on this if i'm wrong, of course.

@_date: 2010-10-13 11:51:57
@_author: Daniel Kahn Gillmor 
@_subject: Confirmation for cached passphrases useful? 
i'm not convinced it's moot, especially if i understand the model you're
advancing for the agent for 2.1 correctly.
If i run the agent locally, and forward access to it to a constrained
account, then the constrained account (which is talking to the agent)
*does not* have the ability to simulate such X11 events.
From a different perspective, i could run the agent itself in a
constrained account, and replace the prompting tool with a tool that
requires, say, an ACPI event, or a special keypress (not an X11 event)
from a designated hardware button.  in that case, malicious code with
access to the X11 session could detect that a prompt had been made, and
possibly dismiss it or hide it from the user, but could not force
acceptance of the keypress without superuser access (at which point,
game over anyway).  To take a vulnerability from a malicious use of
secret key material to a simpler denial of service attack strikes me as
a move in the right direction.

@_date: 2010-10-14 10:18:47
@_author: Daniel Kahn Gillmor 
@_subject: Confirmation for cached passphrases useful? 
This strikes me as the worst suggestion on this thread so far.  Please,
do not store the passphrase to your secret key in the clear in a file on
your computer, and do not suggest that other people do so.  That's even
worse than writing it on a post-it note and taping it to your monitor.
Passphrases are your last line of defense against a compromise of your
secret key material.

@_date: 2010-10-14 16:54:56
@_author: Daniel Kahn Gillmor 
@_subject: Confirmation for cached passphrases useful? 
Yes, that'd be nice, if that hardware is available and convenient for
the user.
But far more people have access to a laptop with system-handled ACPI key
combinations than have access to card readers with integrated keypads.
card readers with integrated keypads are also bulky, awkward to
transport and use in mobile context, and tend to be significantly slower
at performing secret-key operations than modern computers (laptop or
card readers with integrated keypads are also additional points of
failure, and have a non-negligible financial cost over and above the
cost of the hardware on which to run GnuPG.
Back to the original point: a confirmation prompt for the agent has the
potential to be useful in many cases, particularly with the agent model
described for the upcoming gnupg 2.1, and to a lesser extent with
earlier versions of the agent protocol.  I'm not denying that there are
other approaches which might solve the same problem, but there are
tradeoffs to all of them which may not be suitable for any particular user.
I remain perplexed at the opposition this reasonable feature proposal
has received.

@_date: 2010-09-24 10:00:40
@_author: Daniel Kahn Gillmor 
@_subject: multiple keys vs multiple identities 
note that if you want to keep the identities dis-associated (that is,
you don't want people to know that they belong to the same person, you
should not attach them to the same primary key.  I know at least one
person who did this, and as a result found their online private identity
permanently and publicly associated with their work identity, which was
not intended :(
Unless i'm misunderstanding your suggestion, there is no need for such a
notation -- OpenPGP certifications are made over a single User ID and
its associated primary key.  If you certify someone's key and they have
three User IDs, and you only can vouch for two of them, you should only
certify those two.
GnuPG makes this possible by asking "really sign all User IDs?" when you
gpg --sign-key $KEYID.  if you say "N" to the question above, it will
drop you to a shell where you can select the User IDs you want to
certify.  enter '1' to select the first User ID, '2' for the second, etc.
When you've marked all the User IDs you want to certify, then type 'sign'.
Note that the primary keyholder can add new User IDs at any time.  If
you were certifying the primary key itself (and only by implication all
User IDs, instead of each one explicitly), then the primary keyholder
could (after the fact) add an entirely bogus User ID which it would look
like you had certified.  That would be a Bad Thing.  OpenPGP doesn't
work that way.

@_date: 2010-09-24 11:23:01
@_author: Daniel Kahn Gillmor 
@_subject: per-user data signatures [was: Re: multiple keys vs multiple 
ah, gotcha.  sorry for the misunderstanding.
yeah, this makes sense.  in the context of debian packaging, the
material signed is relevant.  if your changelog says "unstable" then
debian will accept it.  if you're uploading it to some other repo, that
repo would presumably be named something other than "unstable".
fwiw, it wouldn't be difficult to propose such a notation, and it should
be possible to implement it quickly in debsign using gpg's --set-notation.
However, testing right now, it doesn't seem to work with gpg for regular
data signatures:
 echo test | gpg --sign --set-notation 'test at example.org=test' | \
  gpg --list-packets
does not show the notation :(
Werner, David, is this expected behavior?  am i doing something wrong?

@_date: 2010-09-24 12:47:32
@_author: Daniel Kahn Gillmor 
@_subject: per-user data signatures [was: Re: multiple keys vs multiple 
Ah, so there is!  Thanks, David.
Weird.  What am i doing wrong?  what version of gpg are you using?
Here's my full transcript:

@_date: 2010-09-24 13:17:47
@_author: Daniel Kahn Gillmor 
@_subject: per-user data signatures [was: Re: multiple keys vs multiple 
yup, that was it.  i don't recall putting that in my gpg.conf explicitly

@_date: 2010-09-24 13:25:18
@_author: Daniel Kahn Gillmor 
@_subject: force-v3-sigs [was: Re: per-user data signatures] 
hrm.  g10/options.skel contains the following:
Now i'm extra confused.
Removing the force-v3-sigs line from my gpg.conf enabled me to make a v4
data signature.
but the above text seems to suggest that i need to *add* an option to
make that happen.
at any rate, shouldn't the use of contradictory options (e.g.
--sig-notation with --force-v3-sigs) raise an error or a warning to the

@_date: 2010-09-24 15:58:00
@_author: Daniel Kahn Gillmor 
@_subject: how long should a gpg --import of 886 users take? 
I just started with a clean gpg homedir, imported one key (my own), and
then imported the full keyring of all debian developers:
 mkdir -m 0700 test
 export GNUPGHOME=test
 gpg --keyserver keys.gnupg.net ( --recv D21739E9
 gpg --import < /usr/share/keyrings/debian-keyring.gpg
this last step imports 886 keys.  gpg then processes for a *long* time
before returning control to the calling shell.
Overall, the process consumed over 3 hours of CPU time on a 900MHz
Celeron (it took more than 3 hours by clock time  because i was trying
to use the machine for other work concurrently).  Less than half of that
was during the import step (that is, before the "Total number processed:
886" line was emitted).
This is a reasonably interconnected set of keys, but 3 hours of CPU
seems like a really long time.  Should i expect that?
This is with gnupg 1.4.10-4 and debian-keyring 2010.06.08, if anyone
cares to try to replicate the results.  If you do, i doubt my initial
one-key import is relevant, but i don't feel like trying the whole thing
over again right now because i need my CPU back :)

@_date: 2010-09-24 16:21:10
@_author: Daniel Kahn Gillmor 
@_subject: multiple keys vs multiple identities 
"trust" is a different issue than the validity of User IDs, and both are
unrelated to data signatures.
When GnuPG talks about "trust", it's usually referring to the concept of
"ownertrust", which is a value associated with a primary key.
"ownertrust" addresses the question "how much am i willing to rely on
identity certifications made by this key?"
"Validity" is a concept associated with the binding between a User ID
and its public key.  "validity" addresses the question "how much do i
believe that the entity named by the User ID is in fact the entity who
actually controls the secret part of this key?"
Put another way, "validity" addresses the question "does this key really
belong to X?" (where X is the entity referred to by the User ID)
If none of the User IDs on a given key are considered to be valid, then
i believe that GnuPG will refuse to honor any ownertrust set on that key
(unless the key itself is marked with "ultimate" ownertrust).
Note that "ownertrust" says *nothing* about whether a data signature
made by a given key is trustworthy.  By "data signature", i mean a
signature over regular data, either text or binary -- as opposed to an
identity certification made over another User ID and key.  That is, I can:
 * believe that you are who you claim to be, and
 * that the key in use is actually your key, and
 * decline to rely on any other identity certifications you make, and
 * still find it useful to know whether your key signed a given document
These are nuanced concepts, but they're worth understanding.  I hope
someone will correct me if i've made any mistakes in the above.

@_date: 2010-09-24 16:29:16
@_author: Daniel Kahn Gillmor 
@_subject: how slow are 4Kbit RSA keys? [was: Re: multiple keys vs multiple 
i'm curious to see some quantitative data about what "dreadfully slow"
For starters, i tried verifying an SHA512-sum signature on a reasonable
size message (the text of a previous message in this thread), made with
a 4096-bit key.  The message itself is 1819 bytes, with --clearsign
attached it is 2696 bytes total.
I tested on two fairly low-powered machines:
a) ASUS eeePC900
   900Mhz intel celeron M CPU
   1GB DDR2 400MHz RAM
b) Linksys NSLU2 (de-underclocked)
   266Mhz ARM CPU (no FPU)
   32MB of RAM
Both are running reasonably up-to-date versions of debian squeeze, with
gpg 1.4.10.  The file i was verifying was already in the fs cache, so
disk contention wasn't an issue.  I verified the message from a
GNUPGHOME whose pubring contains a single key (my own) and no secret
keys, like this:
 mkdir -m 0700 testhome
 GNUPGHOME=testhome gpg --keyserver keys.gnupg.org --recv D21739E9
 cat > /dev/null < testfile
 time GNUPGHOME=testhome gpg --verify < testfile
on machine (a), the results were:
real	0m0.027s
user	0m0.020s
sys	0m0.004s
on machine (b) the results were:
real	0m0.154s
user	0m0.130s
sys	0m0.020s
I'd be curious to hear other people's results.
fwiw, 154ms doesn't seem "dreadfully slow" to me, given that my rtt ping
times to gnupg.org have a mean of 117ms.  and i don't know that many
smartphones are significantly underpowered compared to the NSLU2.
What *does* change the speed of such an operation is having a large
keyring.  If i import 866 keys from /usr/share/debian-keyring.gpg, then
remove my key from the keyring and re-append it to the end, verifying
the same file on machine (a) takes:
real    0m0.384s
user    0m0.307s
sys     0m0.075s
(more than 14x slower than the same hardware with one key in the public
keyring).  I didn't try this on machine (b) because of how long the
866-key import took on (a) (see the other thread from today).
My conclusion from the above data points is that if we're concerned
about computational inefficiencies, 4096-bit RSA keys are not
particularly bad offenders.
Are there other interpretations of the above results?  does anyone else
want to post comparable data points on different hardware?  How powerful
is a typical smartphone anyway?  What kind of a cutoff are people
willing to accept in terms of CPU cycles per signature validated?  or am
i measuring the wrong thing entirely?

@_date: 2010-09-27 09:59:58
@_author: Daniel Kahn Gillmor 
@_subject: how slow are 4Kbit RSA keys? [was: Re: multiple keys vs multiple 
ah, ok.  i'll add encrypting messages to the benchmarking script i'm
building.  (i aim to publish it shortly so other people can post their
Sounds better than my NSLU2 :)  I'm happy folks are still using old
hardware.  The hardware upgrade treadmill sucks.

@_date: 2010-09-27 15:33:36
@_author: Daniel Kahn Gillmor 
@_subject: how slow are 4Kbit RSA keys? [was: Re: multiple keys vs multiple 
It's true that we really do care about "real", but that measurement is
confounded by other factors (human password entry, CPU and I/O
contention, etc) that gnupg developers have no control over.
So in terms of "what kinds of responsiveness can we expect from GnuPG",
i think measuring user+sys is the way to go.
So i think the tradeoff is the cost of the algorithms that require
secret-key use (decrypting, signing) vs. the cost of the algorithms that
require public-key use (encrypting, verifying).
David Shaw pointed out that RSA excels in speed at the pubkey
operations, but is fairly slow on the secret-key operations, if i
understand correctly.
so if you're just exchanging signed mails with a group of N people,
that's 1 expensive operation (signing) per message, and N cheap
operations per message (verification).
if you're sending encrypted e-mail to someone, that should be 1 cheap
operation per message (encryption) and one expensive (decryption).
If you receive lots of encrypted mail, and you have to decrypt it each
time you read it on a weak device, that could certainly be expensive
None of this seems to preclude using large/strong primary keys alongside
weaker/shorter, time-limited subkeys, though, afaict.
It sounds like the only concern is about doing your own secret key
operations on low-powered devices.  So concern that your correspondents
might be using OpenPGP on a low-power device shouldn't constrain your
own choice of key strength, since your secret key won't be used on that
device anyway.
Does that seem like the right analysis?

@_date: 2010-09-29 00:02:03
@_author: Daniel Kahn Gillmor 
@_subject: Benchmarking OpenPGP operations with GnuPG [was: Re: how slow are 
i'd be interested in seeing the results, even if the mechanism is clunky
(btw, you could also use a webcam or other digital video and count
frames, if you want sub 1Hz resolution) -- it's still wall-clock
measurements, and not CPU usage measurements, but it's a reasonable data
I just wrote a test script that generates a bunch of tabular data,
comparing the four different operations (encrypt, decrypt, sign, verify)
against different algorithms and keylengths.
It's a bash script that you can fetch here:
 My OpenPGP signature is available for the script here:
 If you'd rather just check the checksum of the file, itshould have the
sha1sum of 5ae139246aee983a3d9b7e7ba6975191d09ba0ae.
you'll need to make it executable before running it, of course.  And it
shouldn't require any special system privileges, nor should it tamper
with any files outside of the log it creates and a working directory
that it also creates.
If you run it, it will generate a plaintext report.  if you mail me back
the report (off-list), i'll use your data in a summary of results that
i'll post to the list.
If you do this, please let me know what kind of machine you were running
it on (e.g. "this is my smartphone", "this is a server", "this is my
little embedded router").  I'm particularly interested in the marginal
cases -- systems that are significantly low-powered.
Be aware that on low-powered machines, the full set of benchmarks may
take quite a long time, and hammer your CPU.  If battery life is a
concern for your computer, please only run this when the computer is
plugged in.

@_date: 2011-04-07 13:44:05
@_author: Daniel Kahn Gillmor 
@_subject: Signing a key (meaning) 
I'd say you've learned something about the reliability of this other
person's OpenPGP certifications.  If you were to publicly identify them
(in a forum where they have a chance to respond, to be polite), I think
you'd be doing a favor to everyone who might have otherwise considered
relying on these certifications.
I can understand this.  It seems like a losing game, especially since
you can't control whether they decide to revoke or not.  Besides, it's
not your fault or your problem if they made an unverified certification.
I don't understand this.  What are you trying to protect yourself from?
 Will you phase out this new key when one of your correspondents uploads
it to the public keyservers?
How do you plan to distribute updates or revocations to your correspondents?
I have no problem with forms of paranoia that helps keep people's
communication safe.  I do have a problem with paranoia that makes
communications more problematic and does nothing to make things more
safe or reliable.  Why advocate the latter?

@_date: 2011-04-07 15:08:44
@_author: Daniel Kahn Gillmor 
@_subject: gpg: encryption failed: public key not found 
Or, have your cronjob switch to being the correct non-privileged user
before doing any of the rest of its work.
I don't think this is either necessary or advisable.  If i understand
the docs correctly, it is equivalent to setting ultimate ownertrust on
the key, which has other consequences you might not intend.

@_date: 2011-04-07 19:49:50
@_author: Daniel Kahn Gillmor 
@_subject: How to verify the e-mail address when certifying OpenPGP User IDs 
The standard way i've seen e-mail address verification done is with caff
("certificate authority fire and forget") from the signing-party package
in debian.
caff works like this:
 0) during an in-person meeting, you verify the person's identity (often
by checking official ID) and get their claimed fingerprint.  You note
this down in some way that you can unimpeachably retrieve it (e.g. on a
slip of paper, in your own handwriting, and that does not leave your
physical possession).
 1) afterward, when you have some time, you take your piece of paper,
and for each fingerprint, run "caff $FINGERPRINT".  caff presents you
with the person's name and claimed e-mail address.  You verify the name,
and that the e-mail address seems at least plausible.
 2) if you've said it seems ok, caff then makes an OpenPGP certification
on your behalf, creates an introductory e-mail message explaining what
this is, attaches the certification, encrypts the e-mail message to the
keyholder, and sends the e-mail.  The certification stays in a special
caff-specific keyring (not your own everyday keyring).
If the keyholder actually does control the e-mail address in question,
they'll receive the message, decrypt it, and then be able to add your
certification to their own key.  Then, if they choose, they can upload
your certification to the public keyserver (so you and everyone else can
see it) or they can mail it back to you (if they only want to complete
the handshake for you in particular, but want to keep the association
otherwise temporarily private).
Make sense?

@_date: 2011-04-07 20:32:13
@_author: Daniel Kahn Gillmor 
@_subject: How to verify the e-mail address when certifying OpenPGP User 
I have made no claims anywhere about legality or illegality (i also
haven't specified legal jurisdiction, for that matter).
Do you mean "should legitimately have access", or something like that?
The verification test caff proposes is "Does the keyholder have the
ability to read mail sent to the address in the User ID?".  This is
pretty close to what i want to know, actually.
It does not try to test things like "does the e-mail address in question
use a good passphrase for access" or "is it hosted on a reliable mail
host" or "are all steps of SMTP delivery STARTTLS-capable using X.509
certificates with sensible trust anchors" or "is legally-entitled to
under US law".  These other tests are all rather subjective, potentially
impossible to automate, and of dubious usefulness anyway.
So i'm pretty happy with the caff methodology, though i'd be open to
hearing other concrete proposals that answer relatively clear-cut questions.
I do have some problems with the caff user interface, but that's another
story :/

@_date: 2011-04-08 14:00:22
@_author: Daniel Kahn Gillmor 
@_subject: Do not conflate key+userID certification with "vouching" [was: Re: 
"Vouching" for someone usually means that you think you can rely on the
person, and that you think they're somehow "good", "on our side",
"trustworthy", etc.
Making an OpenPGP certification ("keysigning") is *not* the same as
"vouching" for them.  An OpenPGP certification is a simple assertion of
two things: {identity (which may include an address), and ownership of a
An OpenPGP certification says nothing about whether you think the
keyholder is a good person, whether you would trust them with your
children, whether they are a good software engineer, whether you would
vote them into public office if you happen to live in a democracy, or
even whether you are willing to rely on the OpenPGP certifications they
produce. [0]
You are free to assert these other qualities in many other ways, of
course.  For example, I could write, sign, and publish a document that
says "Alice  has strong moral fiber".  This sort of
"vouching" would be distinct from my certification of Alice's OpenPGP
key.  Note that I am *not* saying that Alice's key has strong moral
fiber.  My statement is vouching for *Alice*, not her key.
Keeping the semantics of keysigning restricted to a simple assertion of
identity and key ownership makes it possible to do reasoned inference
over a set of certifications, to establish (via intermediate parties,
such as "mutual acquaintances") a level of reliable identity and
key-ownership between people (and other entities!) who have never
physically met.  It also makes OpenPGP certification less fraught with
doubt or confusion, and it reduces the amount deep social relationships
published on the public keyservers.  This is good.
If you mix non-identity, non-key-ownership notions into your OpenPGP
certifications, making a certification becomes radically harder (because
the other notions are significantly less objective), and your ability to
do effective reasoned inference about identity and key-ownership drops
away as certifications themselves become rarer and more entangled with
subjective measurements of "vouch-worthiness".
Ironically, this means that mixing concepts of "vouching" into standard
OpenPGP certification makes it *harder* to effectively "vouch" for
someone, because it is harder for them to establish their identity in
the first place.
Vouching for people is great, and useful in many contexts.  But it
should not be conflated with identity certification.
[0] Yes, you can actually assert your willingness to rely on the
keyholders' own OpenPGP certifications, using so-called "trust
signatures".  Currently, very few people issue trust signatures, and
those who use them responsibly issue them very rarely.  If you aren't
confident on standard OpenPGP certifications, you should probably avoid
issuing trustsigs entirely.  They are public declarations of social
relationships that most people prefer to keep private.

@_date: 2011-04-08 15:35:56
@_author: Daniel Kahn Gillmor 
@_subject: Do not conflate key+userID certification with "vouching" 
Or, more simply, An OpenPGP certification is "vouching for someone's
identity"; it is not "vouching for someone".
But given the easy confusion and the level of nuance required to tease
the concepts apart, i think we're better off avoiding the term "vouch"
entirely, and talking about "assertions of identity and key ownership"
instead.  Why use a term likely to sow more confusion in an already
confused topic?
Actually, i think using a signing policy and certification levels to
refer to non-identity,non-key-ownership characteristics is *also* a mistake.
Here are the descriptions of the conventionally-defined "certification
levels" (from  :
Note that none of these levels make any reference to anything other than
identity and key ownership.  They refer to levels of certainty (of the
issuer) of identity and key ownership (of the subject).  But not to any
other statements like "has strong moral fiber" or "has been my best
friend since birth" or "is trustworthy around dogs" or "loves sauerkraut
as much as i do".  [0]
Again, if you want to assert these things publicly, you're free to do
so.  But regular public OpenPGP certifications are probably the wrong
place to do it.
OpenPGP certifications should be about identity and key-ownership.
[0] Note that i *could* give a "positive" certification to my best
friend since birth, since i certainly have done substantial verification
of his identity, but that doesn't work bi-directionally: every
"positive" certification doesn't have to mean "best friend since birth".
 Moreover, making that kind of assertion would leak some additional
information about my perception of our relationship, and  (since our
tools don't make use of this information) it would not provide any
additional benefit to either of us.  So why would anyone make such a
public certification?
If someone can describe an actual benefit, i can decide whether it's
worth the tradeoff that comes from the extra data in the social graph
implied by the WoT.  But as it stands, i don't think there's even a
tradeoff to be made.

@_date: 2011-04-08 18:27:08
@_author: Daniel Kahn Gillmor 
@_subject: Signing a key (meaning) 
But if an attacker puts his e-mail address on a key he claims to be
mine, he won't get my mail sent to (or encrypted to) him.
Many people already know Bob's e-mail address; if they're sending mail
do bob at example.net, they're not going to encrypt that mail to a key that
has "Bob " as the only User ID.
OTOH, if Eve suspects she might at some point get access to a message
that was sent to Bob, it's in her interest to put *Bob's* e-mail address
on a key and try to get people to accept it as Bob's (rather than
putting her own address on it).
You're right that if Eve *already* has access to Bob's inbox, then the
e-mail access check won't be a terribly useful test (though as soon as
people start encrypting mail to Eve's key and mailing it to Bob, Bob
ought to notice).  But the e-mail access control check *does* protect
against the attack scenario where at the time of keysigning, Eve does
*not* have access to Bob's inbox.  It protects the contents of the inbox
(because people send messages encrypted to the correct key) when some of
Bob's mail accidentally leaks to Eve later.
This is pretty critical in some contexts.  E-mail is a (mostly) unique,
global identifier.  "John Smith" is not.

@_date: 2011-04-08 18:48:21
@_author: Daniel Kahn Gillmor 
@_subject: default keyserver-options [was: Re: keys not available for signed 
Thanks for these pointers, John.  If you think these are good options,
maybe we should advocate for changing the defaults to include them?
I support setting include-subkeys and include-revoked to on by default.
 The only reason these aren't more seriously problematic right now is
that SKS (the dominant HKP implementation today) automatically searches
subkeys and includes revoked keys.  That is, these options have no
effect when querying SKS keyservers.
As a keyserver client, i think gpg should make it clear that it wants
these options by default, in case any keyservers attempt to honor them.

@_date: 2011-04-11 11:23:11
@_author: Daniel Kahn Gillmor 
@_subject: default keyserver-options [was: Re: keys not available for signed 
[...]
I think this last point is the main reason *for* setting include-revoked
to "on" by default.
Otherwise, if the keyservers supported the include-revoked=off option,
Bob could prevent anyone from finding Alice's actual key unless they
knew the configuration option.
 Alice has key 0xDECAFBAD.  she uploads it to the keyservers.
 Bob creates a key, puts Alice's name on it, and uploads it to the
 Bob uploads a faked (invalid) revocation certificate for 0xDECAFBAD.
 Charlie searches for a key with Alice's name on it, and finds exactly
one: But it's Bob's key!
This seems like a bad arrangement.  defaulting include-revoked to "on"
would make it so Charlie can see both keys.

@_date: 2011-04-14 00:05:18
@_author: Daniel Kahn Gillmor 
@_subject: Creating signatures with expiration time 
Look in the man pages for --default-cert-expire and --ask-cert-expire.
If these do what you want, you can also set them in ~/.gnupg/gpg.conf so
that you don't have to supply them on the command line every time.

@_date: 2011-04-19 23:03:17
@_author: Daniel Kahn Gillmor 
@_subject: Batch gpg encryption : prompt 
The right way to solve this problem is to instruct GPG that the key you
are encrypting to is in fact the key owned by the relevant party.  That
is, gpg wants to see full *validity* of at least one User ID on the key
in question.
If you're encrypting something to yourself, the simplest thing is to
mark your own key with "ultimate" ownertrust (which will have the side
effect of setting all User IDs on your key to full validity).
If you're encrypting to someone other than yourself, you should set your
own key to "ultimate" ownertrust, and then ensure that your key has
certified at least one User ID on the key in question.
You can adjust the ownertrust level of your key like this (replace
$MY_KEY with your own key or your user ID):
 gpg --edit-key "$MY_KEY" trust
when you've selected the correct value, enter "save" in the gpg prompt.
You can inspect the validity of the key you'll be encrypting to with
(replace $TARGET_KEY with the relevant key ID or a user ID you expect on
that key):
 gpg --list-options show-uid-validity --list-keys "$TARGET_KEY"
hope this helps,

@_date: 2011-04-24 23:10:54
@_author: Daniel Kahn Gillmor 
@_subject: Question about details of key sigining 
Each User ID is signed separately.
For a certification over a Key + UID, the public key, user ID, and any
other subpackets (chosen by the certifier) are digested against a
specially-chosen prefix (a different prefix than the prefix used for
data signatures).
I believe you're interested in this section of the OpenPGP specification:

@_date: 2011-04-26 16:19:24
@_author: Daniel Kahn Gillmor 
@_subject: Updating signature cert-level 
The OpenPGP spec says that only one certification of a given key+UserID
from a particular primary key is valid -- it is the one with the most
recent certification creation time.
Each certification indicates what you're calling the "cert-level" in the
signature type, which is of course part of the message that is
cryptographically signed.  So you'll be issuing a new certification
instead of "updating" an old one.
Consequently, there is also no need to revoke an old certification
before issuing a new one, since the new one supercedes it.
Before you start doing --ask-cert-level generally: ask yourself what you
expect to gain from it.  Ask also what you expect your
peers/correspondents to gain from it.  Does the extra complexity give
you anything concretely worth more than the hassle/confusion it introduces?

@_date: 2011-08-25 08:27:48
@_author: Daniel Kahn Gillmor 
@_subject: a Question about Key Servers 
This sort of situation is one which a better toolset could automate.
If you have suggestions about how/when gpg could automatically refresh
keys, you might consider adding them to this bug report:

@_date: 2011-08-25 09:36:50
@_author: Daniel Kahn Gillmor 
@_subject: a Question about Key Servers 
Yes, i do this myself, but with a large keyring, a full --refresh-keys
takes ages and thrashes my machine.  Also, some people may care that
requesting a specific set of keys from a single keyserver providing a
way for that keyserver to track them.
Having gpg (or some other tool) keep track of when it last updated a
given key (and when the key is about to expire) and choose smart times
to do updates against a configured pool of keyservers would be a nice thing.
Folks interested in this topic may also be interested in parcimonie,
which is under active recent development:

@_date: 2011-08-25 10:28:40
@_author: Daniel Kahn Gillmor 
@_subject: a Question about Key Servers 
Yes, it's true, and yes, i'm an outlier.  At the moment.
Except that, quite clearly, most users have no idea it is their problem
and the problem remains unsolved.
Why not try to solve the problem, or at least enable users to choose one
of a pre-defined set of reasonable refresh heuristics for gpg to
implement on their behalf?
Please read  for decent
arguments about why this is the right thing to do.
I agree that handling it within gpg is the best option -- gpg is in the
best position to do key management.  However, tools like parcimonie show
that it's possible for a third-party to handle certificate refresh.
It's just a lot of overhead and tracking outside of gpg itself.

@_date: 2011-08-25 13:26:33
@_author: Daniel Kahn Gillmor 
@_subject: Signing multiple keys 
if you have a list of fingerprints and the signing-party package
installed, you can do:
 caff $FPR1 $FPR2 ...

@_date: 2011-12-14 05:39:18
@_author: Daniel Kahn Gillmor 
@_subject: Leaving comments with subkeys? 
My first thought was to look up the list of standardized "key usage
flags", which are defined here:
  But there is no "this key may be used to sign code" usage flag, which it
sounds like you'd really want, and 0x02 ("This key may be used to sign
data") is generic enough to cover both your cases (it only excludes
making other OpenPGP certifications, which is covered by 0x01).
Given that allocating new bits for the key flags field is an unwieldy
and awkward process, i don't think this is the way to go.
Instead, you could add a notation to the subkey signatures.
  Concisely and precisely defining (what exactly counts as "source code"?
 what if an e-mail contains a tarball with source code?  what if an html
e-mail contains javascript? etc...) the notation you want to use and
getting it embedded in some tools is going to be a bit of work, but not
necessarily an insurmountable task.
You might want to discuss it with the (very low-traffic at the moment)
working group:
  IETF OpenPGP Working Group Let me also ask the sort-of-nagging questions: what is your endgame
here?  do you want a subkey whose signatures over anything *but*
sourcecode will be rejected for certain purposes?  What about a tarball
of source code?  a gzipped tarball?  an lzma-compressed tarball? a blog
post containing a 20-line shell script?  Do you want a subkey whose
signatures over anything *but* e-mail will be rejected?  (e.g. if i copy
and paste your e-mail into a text file, and then --verify it, should it
fail?)  Will you be happy with people deciding to accept the key's
signatures over *any* source code you distribute, or are you concerned
about a particular project?
Your answers to these questions should help you think through the best
way to proceed to get what you want.

@_date: 2011-12-16 12:50:53
@_author: Daniel Kahn Gillmor 
@_subject: keyserver spam 
yes, this is correct. :(
nope.  flooding like this is currently possible. :(
nope, this is also possible. :(
well, there's the JBARSE key, which i vaguely recall having been created
in a joking way to threaten character assassination, but i can't find
any keys that it has actually signed, nor any documentation to explain
why i have this recollection, so please take with a grain of salt.

@_date: 2011-02-03 02:28:05
@_author: Daniel Kahn Gillmor 
@_subject: learning which symmetric cipher via --status-fd when --decrypting 
Hi GnuPG folks--
is there a way to get information about which symmetric cipher was used
on an encrypted message when decrypting?
for example:
< test.pgp gpg --decrypt --batch --status-fd=2 >/dev/null
if i add --verbose, i get additional info, but i think that's from the
--logger-fd, not --status-fd:
is there a way for a program that parses --status-fd to get this
information, or does the program need to parse --logger-fd as well to
find this out?

@_date: 2011-02-03 15:13:08
@_author: Daniel Kahn Gillmor 
@_subject: learning which symmetric cipher via --status-fd when --decrypting 
This looks great.  Thanks, Werner!  Can we expect this in the 1.x and
2.0.x branches as well?

@_date: 2011-02-03 15:59:57
@_author: Daniel Kahn Gillmor 
@_subject: moving user ID Comments to --expert mode 
Hi folks--
I'd like to propose that GnuPG only prompt the user for a "Comment" for
their User ID under --expert mode.
Here's why:
 * most people just need a simple identity-driven OpenPGP certificate,
one that matches their name and e-mail address.
 * new users see the prompt and think they need to enter something
there, without understanding why or what to put there.  This leads to
people either making a witticism (e.g. "No Comment"), repeating their
actual name, redundantly describing their e-mail address (e.g. "gmail
address"), or saying something like "this is cool software", which then
becomes part of their User ID and goes on the keyservers, associated
with them permanently.
When keysigning, if i get asked to certify a key with a "comment" like
this, i don't know what to say.  What am i certifying if i say that this
key really belongs to "Joe Schmoe (no comment) " ? "Joe
Schmoe " i can understand and certify, but the
intervening comment doesn't seem sensible or verifiable.
There are indeed some possibly legitimate uses of comments, but many of
them would be better handled with notations attached to subkeys or
notations attached to particular user IDs.
What do other people think?
If moving the Comment: prompt to --expert seems to radical, a more
conservative proposal would be to change the prompt from:
 Comment:
 Comment (leave blank unless you are sure you need this and know what
you are doing):
 Comment (most people should leave this blank):
The example User ID prompt should also be changed (in english) from

@_date: 2011-02-03 16:30:00
@_author: Daniel Kahn Gillmor 
@_subject: moving user ID Comments to --expert mode 
my "user survey" is from several years of trying to personally help
dozens of people of all skill levels learn how to use OpenPGP for secure
messaging.  Regardless of the intelligence or technical savvy of the
people i've personally helped get more comfortable with OpenPGP, i
believe all of them have been baffled by the Comment: prompt.
If anyone thinks that removing this prompt would be a Bad Thing, I would
love to have a clearer explanation of the Comment prompt that i could
refer to when i try to de-baffle people in the future.
Looking through my keyring, i see many more useless comments (clutter)
than i see comments that might possibly be useful.
Of the comments in user IDs in my keyring that might possibly be useful,
most of them would be better communicated in some other way than as
assertions of their personal identity.
I invite you to look through the User IDs in your own keyring, from the
perspective of a potential certifier, and ask yourself "what does it
mean for me to certify these comments?"
Omitting the baffling prompt entirely would be the most terse, which is
what i propose.  Do you object to that?
Yes, that would be an improvement over the current situation.  i suspect
it will cause a non-negligible proportion of users to use the string
"optional" as their comment, but you can't win 'em all :(

@_date: 2011-02-03 17:47:02
@_author: Daniel Kahn Gillmor 
@_subject: moving user ID Comments to --expert mode 
Just to clarify this point:
If i meet Robert in person, show him my gov't IDs, my fingerprint, and
we exchange e-mails, Robert would probably be fine certifying this User ID:
 Daniel Kahn Gillmor But i suspect he would not want to certify this User ID:
 Daniel Kahn Gillmor (I am really Robert Hansen) And he would be right to do avoid certifying it.

@_date: 2011-02-04 10:51:13
@_author: Daniel Kahn Gillmor 
@_subject: moving user ID Comments to --expert mode 
Indeed, i had no idea that this was the case.  Thanks for the tip.
Yep, fixing the GUIs is a separate task, and i agree it's a worthwhile
one.   I'll take it up with the GUIs i encounter.
This change in behavior sounds reasonable to me.
Some translation changes might still be worth doing; I would like to see
the example User ID lose the comment (including "(Der Dichter)" in an
english prompt is not helpful), and i think the wording should also be
adjusted, since the User ID does not identify the key -- it identifies
the user.  But i'll happily pursue translation changes as a separate
topic if we can do away with the Comment prompt by default.
i'm sure that's true :(  We can point them at this discussion, though.

@_date: 2011-02-06 14:46:30
@_author: Daniel Kahn Gillmor 
@_subject: moving user ID Comments to --expert mode 
Yes, that's what i mean.
Yep, and those keys should probably be clearly marked.  Obviously, the
malware *won't* self-identify, but there are legitimate keys whose users
are not individual humans (like debian's archive signing key), and those
do have legitimate User IDs.
A User ID for such a key properly identifies the entity which has
control over the secret key.  It does not identify the key itself.
The User ID is the most commonly-used way to *find* the key -- but it
does not identify the key.  It identifies the user.  The fact that
people are willing to cryptographically bind the User ID to the key (via
OpenPGP certifications, a.k.a. keysigning) is what identifies the key.
I realize these are subtle, nit-picky questions of language.
Nonetheless, i think they're important to get right.  OpenPGP can be a
confusing environment for people, and choosing words carefully for one
of the major implementations can help to reduce confusion and make the
path to adoption less difficult.

@_date: 2011-02-07 00:37:11
@_author: Daniel Kahn Gillmor 
@_subject: moving user ID Comments to --expert mode 
Here are some legitimate User IDs that do not correspond to a single
 * "deb.torproject.org archive signing key"
 * "Debian Archive Automatic Signing Key (6.0/squeeze)
These are legitimate to my mind because the unambiguously identify an
entity responsible for the key (despite the fact that the entity is not
a single individual).  Note that the latter happens to be an RFC
822-style e-mail address, but the former does not.  The e-mail address
form is *not* relevant to the legitimacy of the User ID, other than its
ability to disambiguate potentially-conflicting claims to the same name
(e.g. there might be multiple "John Smith"s, but there is only one
john.smith at example.org if you subscribe to the global namespace
described by DNS).
User ID is short for "User Identifier".  The User ID is not only
friendlier than the key ID -- it actually refers to something outside
the cryptographic realm in which the key operates.
This is the point of a PKI, whether it is OpenPGP or X.509 or whatever:
you want to be able to bind mathematical constructs (e.g. public keys)
to non-mathematical entities (e.g. the entities referred to by User IDs).
As their name implies, the Key ID identifies the key, and the User ID
identifies the User (or keyholder).
Yes, *and* that the real-world entity in question actually controls the
associated key.
An OpenPGP certification is made over a (Key + User ID) combination.  It
states "the owner of the key is in fact the person described by the User
  The User ID identifies the user, but it might be (and in fact is
trivially) spoofed.  To decide whether you're willing to believe that a
given User ID is correctly associated with a given key, you can use the
known certifications of the key+userID combination, and your state of
knowledge/belief about the certifiers themselves.  These certifications
cannot be (practically) spoofed.
This is how the web of trust operates.

@_date: 2011-02-07 12:33:24
@_author: Daniel Kahn Gillmor 
@_subject: moving user ID Comments to --expert mode 
While i think this terminology is unfortunate (how do we refer to the
key without any additional metadata attached?), i agree with you that
the use you describe is widespread.
The term "OpenPGP Certificate" seems significantly less ambiguous than
"OpenPGP Key" to me, which is why i try to use that term instead, but i
concede that the common usage intends to conflate the two concepts.
Anyway, the User ID still identifies the keyholder, not the "key" in
either sense of the term.
The analogous data in an X.509 certificate, the Subject field (or
SubjectAltName extensions), does not identify the certificate itself --
it identifies the subject of the certificate.

@_date: 2011-02-09 15:00:02
@_author: Daniel Kahn Gillmor 
@_subject: gpg --check-sigs should indicate if a signature is made by a 
gpg --check-sigs produces information about whether a certification was
revoked, but not whether the certification was made by a key which
itself was revoked.
This seems troublesome to me.
Consider this scenario:
Alice has key A, and Bob has key B.
Alice's key gets compromised by Mallory.
Alice notices the compromise, and revokes her key, indicating that it
was compromised.
Mallory makes a new key, M, attaches Bob's user ID to it, and makes a
certification over (Bob,M) with key A.
Charles knows Alice, and wants to communicate with Bob.  He fetches key
M, and runs "gpg --check-sigs Bob", which shows Alice's signature.
The output of --check-sigs shows no warning that A has been revoked
(marked compromised).
Maybe gpg should emit the same "X" that it currently emits for revoked
certifications as it does for certifications made from revoked (or at
least revoked-due-to-compromise) keys?

@_date: 2011-02-09 16:46:38
@_author: Daniel Kahn Gillmor 
@_subject: gpg --check-sigs should indicate if a signature is made by a 
ah, thanks for helping me RTFM :)  sorry i missed that.  is the same
thing true about key expiry?
yes, it would be good if people did that.
yeah, i think the problem is that people don't think about these
different ways that manual checking can fail.  By not reporting key
expirations, --check-sigs puts the extra burden on the user -- this
might be a performance hit, but it's way more of a performance hit if
the user then has to go and manually look up each key, no?

@_date: 2011-02-14 09:20:11
@_author: Daniel Kahn Gillmor 
@_subject: how to store the public keys in a db? 
fwiw, it doesn't really "work fine" with many thousand keys. i've got
1785 keys in my pubring, and performance is noticeably poor.  This may
be due to my running somewhat older/low-end hardware (900Mhz Celeron M
processor, 1GiB RAM), but it's bad enough that i've taken the step of
setting no-auto-check-trustdb, and running --check-trustdb manually from
a nightly cronjob.  otherwise, with the amount of signed and/or
encrypted mail that i get, and the fact that i'm signing software and
using it to verify ssh connections and web connections, my machine would
be regularly blocked on gpg for many many tasks.
I'm looking forward to the speedup promised by the keybox format; i hope
the trustdb recalculations can be comparably sped up as well.
Thanks for working on this, Werner.

@_date: 2011-02-14 12:52:03
@_author: Daniel Kahn Gillmor 
@_subject: how to store the public keys in a db? 
I agree.  and frankly, the nightly cronjob isn't really what i want
either; i'd like gpg to pick up the validity of a key's user ID as soon
as it sees the new key, without waiting a day or manually-invoking the
minutes-long check-trustdb.
Do you expect that we'll be able to run with auto-check-trustdb once you
make the transition to keybox?

@_date: 2011-02-15 11:26:53
@_author: Daniel Kahn Gillmor 
@_subject: GPG (MingW32) defaults to revoked key/uid 
I think this discussion is relevant to your question:
 which resulted in the following bug report:
 Your best bet is to remove the old keys from your keyring entirely, so
that your preferred key is the first one in the output of gpg
--list-keys (if they get re-imported later, they'll show up later in the
i agree, this is a suboptimal situation, i'm just sharing the
workarounds that i've found.

@_date: 2011-02-15 23:35:58
@_author: Daniel Kahn Gillmor 
@_subject: on possible ambiguity in Key IDs [was: Re: Help with OpenPGP plugin 
You're quite correct that the key ID provides a handle that references
the actual public key, and is not the public key itself.
However, the key ID is not guaranteed to be unique.  In fact, short key
IDs (of the form 0xDEADBEEF) are trivial to find collisions for -- there
just aren't enough of them, so the search space is small enough to
exhaust with very commonplace hardware.
Long-form keyIDs (of the form 0xDECAFBADDEADBEEF) are significantly
harder to spoof, but easily within reach of a well-funded organization.
the full fingerprint itself (mine is
0EE5BE979282D80B9F7540F1CCD2ED94D21739E9) is much closer to what you
describe as an "unambiguous lookup".  While the spec counsels that it is
also possible for two keys to share a fingerprint, the chances of that
happening are believed to be dramatically closer to 0 than the other
shorter forms:
  Note also that long-form keyID is just the last 16 hex digits of the
fingerprint, and the short-form keyID is just the last 8 hex digits.  So
if you know the fingerprint, you know the other identifiers.

@_date: 2011-02-24 10:32:11
@_author: Daniel Kahn Gillmor 
@_subject: Default hash 
This isn't actually the case.  Aaron's primary key (0x8086060F) is
indeed 1024-bit DSA, but his mail is signed with a 2048-bit RSA subkey
(0xFC04088F), which is perfectly capable of using the stronger digests.

@_date: 2011-02-24 10:38:41
@_author: Daniel Kahn Gillmor 
@_subject: Rebuilding the private key from signatures 
It doesn't depend as much on the digest algorithm used as it does on the
type of public key and the quality of the PRNG used during the signature
process.  DSA keys in particular can be recovered if the random number
generator used to create the signatures turns out to be predictable:
 Fortunately, i don't think that the PRNG used in GnuPG has any known

@_date: 2011-02-24 20:33:11
@_author: Daniel Kahn Gillmor 
@_subject: PGP/MIME considered harmful for mobile 
thanks for the heads-up, Robert.  I'm assuming you're talking about
PGP/MIME signed mail, not encrypted mail.
Has this been reported to wherever this mailreader tracks their bugs?
if so, could you provide a link to the bug report?  I'd like to follow
the discussion.

@_date: 2011-02-24 22:15:56
@_author: Daniel Kahn Gillmor 
@_subject: PGP/MIME considered harmful for mobile 
Hm.  maybe i don't know what you mean here, but i just tried to verify
this with a colleague, and i've come to a different conclusion.
I sent a simple text/plain e-mail wrapped in a PGP/MIME signature,
generated by enigmail (like this one).
that is, the message i sent is structured like this:
???multipart/signed 2181 bytes
 ??text/plain 219 bytes
 ??application/pgp-signature attachment [signature.asc] 1030 bytes
my colleague is using the application named "email", version 2.2.2 on a
stock 2.2.1 motorola droid.
He wrote me back:
So, to be clear:  PGP/MIME-signed plaintext mail did not cause any
problems with rendering on android in my test.  The basic e-mail
application is unable to verify the signature, but i think we knew that
I do *not* consider PGP/MIME harmful for mobile.

@_date: 2011-02-25 00:37:16
@_author: Daniel Kahn Gillmor 
@_subject: PGP/MIME considered harmful for mobile 
heh.  i don't have a "mobile", so i can guarantee that :)
There are good reasons to prefer a PGP/MIME and S/MIME signature
standards over inline PGP.  These standards have been around for a long
time, and modern mail user agents should be able to cope by now, even if
all they do is discard the multipart/signed wrapper and trailing
signature parts.
It would be really useful to hear about specific MUAs that can't handle
PGP/MIME-signed messages like this one, and to get clear descriptions of
the failure modes.
But without these kind of specific reports, vague statements like "most
of those will have difficulty" just sound like FUD to me.

@_date: 2011-02-25 12:29:21
@_author: Daniel Kahn Gillmor 
@_subject: PGP/MIME considered harmful for mobile 
These two statements seem to be in direct contradiction to each other.
Is K-9 mail able to display the body of a text/plain PGP/MIME-signed
message or not?  If answers differ based on the version of K-9 mail,
what versions support it?
I am *not* asking about validating signatures -- I'm just talking about
being able to read the (unvalidated) message contents of PGP/MIME-signed
I don't use K-9 mail, but i would appreciate some clarity so i know what
to recommend to folks who ask me for recommendations.
i'm glad to hear that.  Thanks for working on it!

@_date: 2011-02-25 14:54:45
@_author: Daniel Kahn Gillmor 
@_subject: PGP/MIME considered harmful for mobile 
I just received corroboration of a successful read (albeit without
signature verification) of a PGP/MIME-signed message from another
colleague who is running K-9 Mail 3.318 on CyanogenMod 6.
Patrick, if there is a version of K-9 mail that you've seent hat
actually doesn't display a PGP/MIME-signed message, it would be good to
know more details.

@_date: 2011-02-27 22:51:20
@_author: Daniel Kahn Gillmor 
@_subject: [was: Re: PGP/MIME considered harmful for mobile] 
Please post this bit of useful details to the "Android PGP/MIME test
results" thread started by Grant Olson, which actually has an acceptable
signal-to-noise ratio.
If you could be more specific about versions and application names,
that'd be great (an earlier e-mail from you mentioned "droid
2.2.something", so i'm not sure what to make of the version numbers in
this e-mail).
Thanks for trying to make a useful bug report.  Hopefully someone who
knows more about android can actually get it to the right people and
follow up here about it.

@_date: 2011-01-02 14:43:27
@_author: Daniel Kahn Gillmor 
@_subject: Is self-signing necessary? Basic questions. 
I think a revocation certificate (that is, revoking the primary key, not
just revoking a given User ID or subkey) is also implemented as a
direct-key signature.
I don't know of any other significant uses, though.

@_date: 2011-01-03 11:29:44
@_author: Daniel Kahn Gillmor 
@_subject: defaults / homedir / loal variable / option file etc 
You've found the right location, i think.
You should be able to just create the file in that location with notepad
or any other text editor.

@_date: 2011-01-12 11:15:48
@_author: Daniel Kahn Gillmor 
@_subject: What is the benefit of signing an encrypted email 
providing no
intend to
this is
into a
I agree with Robert that enigmail's choice of defaults (don't autosign
every message) is a good thing, though i think i'd phrase the concern a
little differently.  I wouldn't say "signatures are worthless" (i sign
nearly all of my outbound mail), but i do think that people should only
sign messages they intend to sign and have thought about.
Hopefully, this thoughtfulness extends into thinking about their message
making sense even if it is seen out-of-context. For example, a signed
e-mail message with a Subject: header of "Proposal X" and a body of "I
say we should do it!" can be trivially repurposed by a backer of
Proposal Y to imply that the same person supports Y instead of X (since
only the e-mail body is signed, and not the headers).
If enigmail were to default to signing everything, then it would sign
messages for people that they have not thought about.  As a result, that
weakens the meaning of their signature, to the point where even if they
*have* thought about and decided to sign any given message, the fact
that their signature is attached thoughtlessly to so many other messages
makes it dubious.
So enigmail defaults to not sign every outbound message in order to keep
the value of your signature high by not applying it to things you
haven't thought about.
For those who make the conscious decision to sign all their e-mails, and
think consciously about what they send, there's nothing wrong with
changing the default (though you should get used turning off signing
when you realize you're about to send a message that might not be
context-independent or where the signature might screw something up).

@_date: 2011-01-12 11:24:35
@_author: Daniel Kahn Gillmor 
@_subject: What is the benefit of signing an encrypted email 
As a devil's advocate, i'd point out that a message signed with a valid
key known to belong to someone who is utterly untrustworthy could be
used *against* the signer, by saying something like:
 "look -- here is Mr. X claiming that he is going to poison the
reservoir.  Please take this seriously, and note that it could only have
come from Mr. X because it is signed with his key."
This doesn't mean that Mr. X is actually going to poison the reservoir,
but the signature is a good argument that the reservoir guards should
investigate this particular individual -- that the message is not a
forgery from someone trying to tarnish Mr. X's reputation.
Signing a message makes you somewhat more vulnerable -- it is a
non-repudiable statement bound to your identity, which people can use
against you.  It is also a way of standing behind what you are saying,
and accepting responsibility for it.  This kind of tradeoff needs to be
made consciously, and is one of the reasons that you need to take good
care to protect your secret keys.

@_date: 2011-01-12 11:44:48
@_author: Daniel Kahn Gillmor 
@_subject: What is the benefit of signing an encrypted email 
What do you think you would gain from a signature made by an individual
if they did not think they were making it?  How is this a "hard line of
defense against forgery" ?

@_date: 2011-01-12 12:17:10
@_author: Daniel Kahn Gillmor 
@_subject: What is the benefit of signing an encrypted email 
yes, that's true; but here we've been talking about attacks that don't
require stealing of the key (e.g. taking a signed message and placing it
in another context).  if you sign context-dependent messages as a matter
of course, then it's trivial for me to replay one of those messages and
have it imply an entirely different meaning.  Is this a desirable outcome?

@_date: 2011-01-13 18:19:16
@_author: Daniel Kahn Gillmor 
@_subject: parsing gpg-key block 
Hi Ole--
You're asking about some arcana, and your best reference for details is
probably the RFC -- the OpenPGP format itself is specified in RFC 4880:
  export-minimal will usually produce nothing but:
Public Keys:
  User IDs:
 and self-issued signatures:
 There may also be subkeys (which look like primary keys, but have a
slightly different header), user Attributes (like user IDs, but jpegs
instead of strings), and direct-key signatures.
Signatures can of course have many different kinds of subpackets, which
makes robust parsing of them a bigger project.  But if you just want the
RSA key material, you can ignore the signatures of course.  This would
mean that you wouldn't be able to verify that they key belongs to
whoever you hope it belongs to (at least, not through OpenPGP).  Only
you can say whether that tradeoff makes sense for your particular
You probably want the info about "computing signatures":

@_date: 2011-01-19 16:37:29
@_author: Daniel Kahn Gillmor 
@_subject: signed headers for OpenPGP [was: Re: What is the benefit of signing 
That's a pretty elegant way to solve this problem, actually.  You don't
even need the signed headers to match all the other headers (e.g. the
Received: headers won't be known at sign/send time, not to mention the
other dubious mangling that goes on at the MTA level that Ingo mentioned).
I suspect that many spam engines might balk at an e-mail with a
top-level Content-Type: message/rfc822 though.

@_date: 2011-01-26 16:21:26
@_author: Daniel Kahn Gillmor 
@_subject: Problem with keyserver 
keys.gnupg.net is a DNS round robin.
if one of them fails, the other ones should be responsive at least.
from my perspective on the network, i see:
keys.gnupg.net.		86400	IN	A	129.128.98.22
keys.gnupg.net.		86400	IN	A	193.174.13.74
keys.gnupg.net.		86400	IN	A	209.234.253.170
which are these machines:
129.128.98.22: pgp.srv.ualberta.ca.
193.174.13.74: pgpkeys.pca.dfn.de.
209.234.253.170: zimmermann.mayfirst.org.
the last one (zimmermann.mayfirst.org, which i maintain) is functional
for me, at least.
the first one at least doesn't seem to be responsive at all right now,
though :(
you may also be interested in pool.sks-keyservers.net, which is updated

@_date: 2011-01-26 17:29:43
@_author: Daniel Kahn Gillmor 
@_subject: Problem with keyserver 
hrm, sounds like you are doing some serious fiddling with your settings.
 the names i listed are hostnames, not URLs.  and the DNS round robins
are hostnames that resolve to different IP addresses.  If you're putting
these into some sort of IP-level firewall configuration, please be aware
that the IP addresses of either pool may change frequently and/or
without warning.
The expectation is that HKP keyservers will listen on port 11371, but
port 80 is also widely used:
 Note that these are ports that your client (gnupg, presumably) connects
*to* on those machines, not the other way around.
Is your firewall really limiting outbound access like this?  If your
firewall is only limiting inbound access, you should not have to adjust
it to use HKP keyservers.

@_date: 2011-01-31 07:43:21
@_author: Daniel Kahn Gillmor 
@_subject: two out of three keys.gnupg.net keyservers down? 
============================== START ==============================
if you want the benefits of a DNS round-robin that is kept up-to-date
automatically, you might also try:
 pool.sks-keyservers.net
Werner, how is keys.gnupg.net updated?  I believe Kristian published his
scripts for how the automated updates work for the sks-keyservers pool.
 Is this model something you'd be willing to adopt?

@_date: 2011-07-06 15:09:02
@_author: Daniel Kahn Gillmor 
@_subject: OT: IM encryption options [was: Re: Is the OpenPGP model still 
Hmm, i'm not sure this is the best place for this discussion, so i've
marked the subject line OT for "off-topic" -- if you think there might
be a better discussion list, feel free to follow up there.
Why does this seem unjustifiable to you?  DH and block ciphers are
widely-reviewed parts of the standard crypto toolkit.  Do you have
reason to believe they're generally bad?
Not all of these decisions should be made on purely mathematical
grounds.  Consider, for example, pidgin's old GPG plugin (i dont know
whether it is still in use or under development)
It worked by signing and encrypting each message before it was sent, and
decrypting and verifying each response.
However, IM messages tend to be heavily context-dependent, which makes
them vulnerable to replay attacks.
For example, how many times have you written on IRC (or whatever IM
network you use) the simple phrase "i agree"?
If each message is individually signed and verified, it'd be relatively
easy for an attacker to replay your "i agree" in another conversation,
making it look like you agreed to something you hadn't actually agreed
to.  OTR's stream-based approach ensures that messages are only
authenticated as part of a single, two-party conversation.  There is no
room for a replay attack.
OTR also is designed so that a third-party (one not involved in the
original communication can't conclusively prove that you wrote
something.  this is the "off the record" part of OTR.  It's debatable
how useful this so-called "repudiability" would be in, say, a court of
law; but individually-signed messages clearly do *not* have this kind of
repudiability; anyone in possession of one of these messages can
convince any third party that you did in fact write the message.
Note that we're just talking here about message/conversation signing,
encryption, and verification; iirc, the original thread was asking about
OpenPGP's certification model (that is, how multi-issuer OpenPGP
certificates are used to bind identities to public keys), which is an
entirely different (though related) topic.
hope this helps,

@_date: 2011-07-08 12:49:44
@_author: Daniel Kahn Gillmor 
@_subject: Check that s2k-count has changed 
or you can feed the secret key to pgpdump instead of gpg --list-packets;
pgpdump provides both values (coded and decoded) in its output.

@_date: 2011-07-11 17:08:35
@_author: Daniel Kahn Gillmor 
@_subject: Calculating ciphertext sizes 
Note also that for material encrypted to public key(s), you'll need to
factor in an extra chunk of data for each targetted key (the public-key
encrypted session-key packet [0]); you can expect the size of this to
vary with the algorithm of each targetted key.  This isn't technically
part of the "ciphertext", but it is part of the encrypted,
OpenPGP-formatted message.  Without it, those recipients won't be able
to decrypt the message.
For very short messages, the encrypted session key packets can actually
dominate the contents of the resulting message.
[0]

@_date: 2011-07-14 00:28:24
@_author: Daniel Kahn Gillmor 
@_subject: keysigning parties 
Are you looking for information about how a keysigning party is run
today?  DebConf11 (starting in a little more than a week from today in
Bosnia) will have a KSP.  Info on how it is being organized is here:

@_date: 2011-07-23 19:21:57
@_author: Daniel Kahn Gillmor 
@_subject: Is the OpenPGP model still useful? 
I am struggling with how to respond to your messages since i find them
Are you aware that the purpose of OTR is to allow two parties to
communicate confidentially?
In a confidential communication, a secret message is sent from party A
to party B.  The entire purpose is to share the secret between the two
parties.  They have to share the key to the cipher in order to share the
OpenPGP itself uses this sort of symmetric encryption to encrypt
messages with a random session key, and only uses asymmetric encryption
to encrypt the session key itself.
If you research other popular encryption standards (e.g. TLS), you'll
find this "hybrid" approach is quite common.  If there's a serious
downside or risk to it, could you outline the sort of attack you're
concerned about?

@_date: 2011-06-05 18:15:29
@_author: Daniel Kahn Gillmor 
@_subject: Problem with faked-system-time option 
If you're using debian or a debian-derived operating system (e.g.
ubuntu), you have a choice of faketime or datefudge; both of these
packages can fake the system clock for any dynamically-linked executable.
for example:
0 dkg at pip:~$ date
Sun Jun  5 18:13:19 EDT 2011
0 dkg at pip:~$ faketime 2010-03-05 date
Fri Mar  5 00:00:00 EST 2010
0 dkg at pip:~$

@_date: 2011-06-10 15:05:32
@_author: Daniel Kahn Gillmor 
@_subject: Working with a system-shared keyring 
Could you share these tools?  They sound useful to me.

@_date: 2011-06-13 13:09:43
@_author: Daniel Kahn Gillmor 
@_subject: Generate digest and signature seperately 
it should depend on whether the key usage flags for the subkey (in the
subkey binding signature) include the "Certification" capability.
OpenPGP certifications issued by subkeys without the "Certification"
capability should be no more valid than any other random string of bits.

@_date: 2011-06-15 11:07:22
@_author: Daniel Kahn Gillmor 
@_subject: Problem with faked-system-time option 
I think it is a mistake to make this particular notation, when signature
type 0x40 already exists:
 I'm happy with the proposal to start using notations more, and creating
a culture of publishing well-defined semantics around them; i just don't
think this particular goal is well-served by notations, since it is
already in the core protocol specification.

@_date: 2011-06-15 15:50:20
@_author: Daniel Kahn Gillmor 
@_subject: Problem with faked-system-time option 
Note that if you do decide to use a notation for this, you should mark
the relevant notation subpacket as "critical", so that the signature is
not interpreted by an unwitting implementation as meaning something
other than the specific declaration:
  Currently, the proposal as it stands is to use a notation within the
 domain.  It would be good to get verification from the
maintainers/owners of that domain to know if they're OK with the
specific proposal.
According to whois, that's Werner and g10 code GmbH.  Werner, can you
comment on any policy for use of  notations?  Would it help if
someone set up a registry someplace documenting the specific notations?
I'm willing to set up such a registry on a domain i control, but i'm not
sure people would want to use it because my domains aren't as strongly
associated with OpenPGP as gnupg.org.

@_date: 2011-06-15 17:33:00
@_author: Daniel Kahn Gillmor 
@_subject: Problem with faked-system-time option 
If we're going with the semantics of 0x40 (but without the text/binary
   This signature is only meaningful for the timestamp contained in it.
Then you'd want such a signature only to be interpreted as
valid/acceptable in a context in which the *only* thing being checked
was the timestamp.
For example, if i set up a timestamping service that makes these
signatures with a subkey of my own key,  i would not want those
timestamping signatures to be considered as valid signatures by, say,
the debian build queue.
Another example: If you were to set up such a timestamping service with
a subkey, i would not want my mail user agent to say "good signature
from David Shaw" if an e-mail was signed by that service.
So my point is: mark it as critical; then tools which know what to do
with a timestamp signature will use it fine, and other, existing tools
will not misinterpret it as any other intent.

@_date: 2011-06-16 10:38:06
@_author: Daniel Kahn Gillmor 
@_subject: Understanding the "--refresh-keys" output 
17 keys is a lot of keys to have generated yourself (though there are
some circumstances where i'm sure it makes some sort of sense).  But if
those aren't all your own keys:
If you have been in the habit of assigning ultimate ownertrust to keys
other than your own, you probably want to reconsider that decision.
ultimate ownertrust allows a keyholder to make any certification
whatsoever (including over their own keys) and have you accept their
In general, use full or marginal ownertrust for parties other than yourself.

@_date: 2011-06-16 13:37:02
@_author: Daniel Kahn Gillmor 
@_subject: what does a timestamp signature mean? [was: Re: Problem with 
I don't think this is the general consensus.  Timestamps *are*
meaningful -- they are an assertion by the person making the signature
of what time they made the signature.
That assertion could be false, of course, but then nothing is stopping
you from signing any other sort of false assertion either.  That doesn't
make the assertion meaningless; it just makes it wrong.
What it sounds like you want is an *unforgeable* timestamp indicator.
That is, you want some way to prove "this signature was made at time X"
Due to the imprecision of any mechanical timekeeping device, there will
be some wiggle-room in such a signature, so it's useful to clarify that
this hypothetical claim is actually:
 "this signature was made at time X ? e"
or, alternately, two separate assertions:
 a) "This signature was made after time X-e", and
 b) "This signature was made before time X+e"
let's take these two cases separately for a moment.  (a) is easy to do
with existing tools and some sort of globally-published, inherently
unpredictable data (e.g. the number of words on the front page of some
particular edition of the New York Times, or perhaps the digest of the
most recent block added to the global bitcoin blockchain).  If you want
to specify that as its own notation, i think that's a pretty clean
mechanism to prove part (a).
I think part (b) is much harder to prove effectively, and (alas) it's
probably what people really want to know.  To do that properly, i do
think you'd need some sort of public service, to which you would submit
cryptographically-strong digests of things to be published in such a way
that people could confirm it by date.  It would need to publish all
timestamped signatures in a way that people could verify and accumulate
the digests independently.
I don't think the information for (b) is possible to embed in a
signature on its own, due to the way we experience time (we can
remember/recreate how things were in the past; we can't do the same
about the future).
So if your goal is to have such an unforgeable timestamp, i'd suggest
focusing on a clearly-defined specification for (a) (probably in-scope
for this list and for the IETF OpenPGP WG), and on implementing a global
service for (b) (probably out-of-scope for this mailing list)
FWIW, i actually think the assertion-by-signer part (which we already
have) is more useful and meaningful than any arbitrary "unforgeable
I'd be happy to be wrong about the above analysis.
PS i have omitted questions about relativity, but anyone making a claim
about time should be aware that there are already known practical
problems in dealing with time due to different inertial frames:

@_date: 2011-06-16 14:53:34
@_author: Daniel Kahn Gillmor 
@_subject: what does a timestamp signature mean? [was: Re: Problem with 
Actually, i think usefulness and specification are quite important.
Without them, this discussion is just noise to me.
I actually don't think what i said above is a matter of interpretation.
I'm not actually on this list ("gnupg-users", ahem) to discuss the law;
can we stick to the crypto and its real-world consequences,
specifications, and usefulness (or lack thereof)?  This does mean that
we'll occasionally venture into legal territory, but (a) there are
probably many different jurisdictions represented on this list, and (b)
many of us (myself included) have little to no legal training.
This is (roughly) what i defined as (b) later in my message.  If you'd
like to replace "i saw this" instead of "i made this signature" then
fine; that's a matter of signing policy; or, you could simply make a
document that says "I saw the document with digest XXXX".  At any rate,
we're talking about what the timestamp in the signature means (or can mean).
 [...]
 [...]
i answered your question in the original mail here, i think.
That's not actually that hard; it's just some (somewhat political)
legwork to make sure there is a rough consensus on one decision or the
other, then making that decision, writing up the detailed specifications
publicly in an unambiguous manner.
Writing some code to make it easy to use might be hard, but specifying
it is not particularly difficult, if you decide you want it.
I'm afraid i don't see the analogy.  Can you spell out what you intend
to enable with more specifics, and why it would be useful?
???  When i make a signature with a timestamp in it, i am very much
making (and intending to make) the assertion that the signature was made
at that time.  I see no repudiation in your message, only that "some
people don't know that they are making this claim".  I'd also argue that
some people don't know that when they put a date next to their
pen-and-ink signature, they're making the claim that that pen-and-ink
signature was made on that date.  But it's certainly what most of us
mean by it.
If you say so; i'd like for the code i write to be able to work on
spacecraft or satellites at some point, so it's worth keeping the idea
in mind (again, i'm ignoring the "proceeding" remark because i'm talking
about useful, specified code, not legal proceedings)
right, and this is what i suspect you'd need a global, published
timestamping service for.  Maybe your time would be better spent working
out what such a service would look like.  If you can define the service
itself (centralized, distributed, or whatever), then you'll get a better
sense of what semantics you need from OpenPGP.  Maybe such a service
already exists!  I haven't looked for it; have you?

@_date: 2011-06-23 15:47:23
@_author: Daniel Kahn Gillmor 
@_subject: DH Key 
I think you're getting confused by the (admittedly confusing) terminology.
DH is Diffie-Hellman, which is a form of anonymous session-key exchange.
 It is not a public key crypto algorithm, though it can be used in
conjunction with public key crypto.
DSS is the Digital Signature Standard, which is also known as DSA (the
Digital Signature Algorithm).
So i think you want either 2 or 3 in the menu above.
If you choose 3, you will only have a signing-capable key.  That should
be fine, if the only requirements you have are that you need a
DSS-capable key; DSS is for signatures, not encryption.
However, if you want people to be able to encrypt information to you,
you'll need to add an encryption capable key.  The reasonable choices
for that today are either Elgamal (very similar to DSS, but for
encryption) or RSA.
once your primary key is generated, you can add an encryption-capable
subkey with:
 gpg --edit-key $KEYID addkey
(replace $KEYID with the id of your new key, of course).
hope this helps,

@_date: 2011-02-28 19:09:34
@_author: Daniel Kahn Gillmor 
@_subject: Security of the gpg private keyring? 
the folks in the monkeysphere project have put some thought and work
into trying specify how this sort of thing should be approached.
however, i'm not convinced that hashed user IDs saves much against even
a moderately dedicated attacker, for the same reason that dan bernstein
rightly points out the failure of NSEC3 to avoid zone enumeration:

@_date: 2011-02-28 20:20:46
@_author: Daniel Kahn Gillmor 
@_subject: Restarting gnupg-agent inside X session 
Alternately, since you probably already know the current setting of
GPG_AGENT_INFO, you could just start the agent and link its new socket
to the place where the old one used to be.  Something like (untested):
 old_socket=$(printf "%s" "$GPG_AGENT_INFO" | sed 's/:.*$//')
 mkdir -m 0700 -p $(dirname "$old_socket")
 eval $(gpg-agent --daemon)
 new_socket=$(printf "$s" "$GPG_AGENT_INFO" | sed 's/:.*$//')
 ln "$new_socket" "$old_socket"

@_date: 2011-02-28 20:54:25
@_author: Daniel Kahn Gillmor 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
this is (very roughly) what we came up with too (our approach to
avoiding hash collisions was to use a stronger hash instead of 2 weak
You can pull a copy of a stalled/never-submitted Internet-Draft from here:
  git://lair.fifthhorseman.net/~dkg/openpgp-hashed-userids
If anyone wants to push this further, please let me know.
However, i'm quite serious about the flaws paralleling the failures of
NSEC3 to prevent DNS zone enumeration.  the problem space is slightly
different, but i think the math comes out about the same in terms of the
cost of trying to brute force these things.
Ultimately, i think Hashed User IDs provide only weak benefit against
the equivalent of zone enumeration through the keyservers (which is
presumably the goal), so understanding these arguments and providing a
convincing refutation of them (or outlining an entirely different
benefit) is probably the first task someone would need to take on.
I'm not convinced that the tradeoff is worth it myself, but if someone
wanted to make the argument, i'd be happy to listen.
Having a hashed User ID alongside your non-hashed User ID provides no
benefit at all (unless you consider confusing people trying to
understand and/or certify your OpenPGP certificate a benefit).
This would only be helpful to people who use nothing but hashed user IDs
on their keys.
yes, this is the implementation work that would need to be done.
Whoever wants to pick it up needs to also pay particular attention to
the user experience.  OpenPGP tools are pretty confusing already, so
thinking through how to hide the gibberish (hashed userids) in the
background and present the user with something intelligible would be a
critical step toward making this something anyone might want to adopt.
I wish i had a better solution to offer to this concern.

@_date: 2011-02-28 20:59:45
@_author: Daniel Kahn Gillmor 
@_subject: Restarting gnupg-agent inside X session 
I occasionally like to have multiple agents running, each with different
keys loaded, talking to different processes.  standard-socket wouldn't
let me do that.
i currently play this sort of game more often with ssh-agent than i do
with gpg-agent, but the principle is the same.  It'd be a shame to lose
the flexibility to do this.

@_date: 2011-03-01 20:43:45
@_author: Daniel Kahn Gillmor 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
What are those benefits?  Are they worth the tradeoff of having a large
number of non-human-readable User IDs?

@_date: 2011-03-02 15:14:08
@_author: Daniel Kahn Gillmor 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
it sounds to me like you've simply made it difficult for people to
correspond with you over long periods of time because your e-mail
address isn't likely to continue working.
If your only concern is that you don't want your e-mail address publicly
visible on the keyservers, just make a User ID with no e-mail address at
all, and leave it at that.
You'd still need to do the work of changing, say, MUAs to re-think their
key-selection criteria to include keys without e-mail addresses (maybe
just based on the human-readable part of the To: header?)
But you wouldn't have to do any of the following:
 * specify and try to reach consensus on the syntax of a "standard"
Hashed User ID
 * modify underlying OpenPGP implementations to try digested searches
 * convince third-parties that it is worth their while to certify
digested user IDs

@_date: 2011-03-04 10:24:56
@_author: Daniel Kahn Gillmor 
@_subject: how to find gnupg's DETAILS [was: Re: Non-interactive use of gen-key] 
If you're using debian or a debian-derived operating system, DETAILS is
shipped in /usr/share/doc/gnupg/DETAILS.gz
If you download and unpack the source you should be able to find it in
there as doc/DETAILS.
You can also browse the source via gitweb and find it there:

@_date: 2011-03-10 15:44:00
@_author: Daniel Kahn Gillmor 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
How does hashed user IDs address this particular question?  You don't
need to care about the User IDs on keys if you just want to map
If i'm mapping relationships, and i decide from that mapping that a
particular keyholder is "interesting", *then* the hashed User IDs might
become a minor stumbling block in my figuring out who the keyholder is
in the "real world".
But the point of User IDs is to bind human-intelligible (and therefore
likely low-entropy) "real world" information to keys.  So if i have
reasonable computer resources at my disposal, reversing the digest of
low-entropy material seems like a possibility.
If you want to keep the fact that one keyholder has verified another
keyholder's identity secret, you cannot solve that by obscuring the User
The right way to solve that is with non-exportable OpenPGP
certifications, which must be passed between users explicitly.
For example:
"Hi Bob, I'm Alice.  Charles vouches for my identity as you can see from
this non-exportable cert."
In this example, Charles does not want the world to know that he has
certified Alice's key.  But he's willing to let Alice decide who knows
this information, so he gives her a copy of his non-exportable cert.
After Alice has introduced herself to Bob this way, both B and A know
about the C->A certification, but the rest of the world is still at a
loss.  either B or A could share this certificate with anyone else, of
course.  It's out of C's hands as soon as he gave a copy of the
non-exportable cert to A.

@_date: 2011-03-11 02:50:33
@_author: Daniel Kahn Gillmor 
@_subject: non-exportable OpenPGP certifications [was: Re: hashed user IDs ] 
non-exportable OpenPGP certifications are also known as "local"
To make a non-exportable OpenPGP certification, use:
 gpg --lsign-key frida at example.net
To put that in a file:
 gpg --export-options export-local --export --armor frida at example.net \
    > frida.gpg
Then the receiving party does:
 gpg --import-options import-local --import < frida.gpg
 -----------------
So, for example, if you wanted to mail your certifications over alice's
key to bob without exposing them over the network, you would do
something like:
gpg --export-options export-local --export --armor alice at example.net | \
 gpg --encrypt --armor -r bob at example.net | \
 mail -s 'sekrit info 4 u' bob at example.net

@_date: 2011-03-21 16:18:09
@_author: Daniel Kahn Gillmor 
@_subject: Revoke signature from key 
If i was going to try to indicate more than a simple identity binding
with an OpenPGP signature, i'd define an OpenPGP notation [0] and
include the relevant subpacket in my signature.
This way, the same signing key is capable of making identity
certifications *and* identity+metadata certifications.
For example, to indicate that the holder of $keyid will be employed by
the technical support department of Example Corp for the next year:
 gpg --sign-key --cert-notation 'department at example.com=tech-support' \
    --default-cert-expire 1y "$keyid"
(and proceed with the usual identity checks as well)
[0]

@_date: 2011-03-21 17:17:50
@_author: Daniel Kahn Gillmor 
@_subject: Revoke signature from key 
You are free to disregard any of my certifications you like.  It would
not be unreasonable of you to say "i will disregard all certifications
by dkg that lack a department at example.com notation." if that's what
you're trying to do.
Why is this a manual process?  You would not be inspecting the keys --
you'd be inspecting my signatures, which you have to do anyway (at least
in order to cryptographically verify them).
I grant that GnuPG doesn't have a straightforward way to filter
certifications based on notation.  I think that's a missing feature,
though -- not necessarily a reason to create entirely new keys that will
themselves need to be integrated into the web of trust, and which have
entirely different semantics for their OpenPGP certifications.
Using a separate key for this scenario creates other problems with
GnuPG's existing WoT resolution mechanism as well.
For example, consider Bob an admin of the tech support dept. at Example
Corp.  Bob has his own personal key B, and manages a department key with
alternate certification semantics, D.
If Alice works for Example Corp, she might decide to set marginal
ownertrust on D to increase her WoT into the tech support department.
But if she knows Bob personally as well, she may want to grant marginal
ownertrust to B.
If Alice's trust model says "3 certifications by marginally ownertrusted
keys -> full key+userid validity" (the gpg default), then Bob's keys now
have the ability to provide 2/3 of a full certification instead of
Alice's expected 1/3.  If Bob also happens to manage the department key
for the Billing department of Example Corp, and Alice applies marginal
ownertrust to that, then Bob can forge key+userID combinations that will
be fully accepted by Alice, despite her having never granted him more
than marginal ownertrust.
In short: if your goal is to represent something in addition to identity
information in an OpenPGP certification, i think it's a good idea to
represent that metadata explicitly.  Notations are a reasonable way to
do that.  If GnuPG doesn't provide a reasonable way to solve your use
case, let's fix GnuPG to make it better.
Note that I am *not* actually recommending putting anything other than
identity information in an OpenPGP certification in most real-world use
cases.  There are significant drawbacks (e.g. surveillance by social
graph trawling) to representing non-identity metadata in certificates,
and the tradeoffs should be weighed carefully.

@_date: 2011-05-01 20:15:44
@_author: Daniel Kahn Gillmor 
@_subject: Syncing Keys between multiple computers? 
if your changes to your keys and user IDs aren't supposed to be secret,
(i.e. they are not non-exportable certifications, and you have not added
any new secret subkeys or primary keys) then you can just push your
updates to the keyservers when they happen:
 gpg --send $CHANGED_KEYID
and then when you switch to a different machine, you can just ensure
everything is up-to-date:
 gpg --refresh
These commands probably want a keyserver; so if you don't have a default
chosen already, add the following line to ~/.gnupg/gpg.conf (on both
 keyserver pool.sks-keyservers.net
If you change ownertrust, add new secret keys (either primary keys or
subkeys), or make non-exportable certifications, then you'll want to do
the export and import steps.  on the origin machine:
 gpg --export-ownertrust > ownertrust
 gpg --export-options export-local --export-secret-keys > secring
 gpg --export-options export-local --export-keys >pubring
and on the destinaton machine:
 gpg --import-ownertrust < ownertrust
 gpg --import-options import-local --import < secring
 gpg --import-options import-local --import < pubring
note that you might have some trouble updating your secret keys like
this, due to a known bug:
 so if something changes in your secret key (e.g. new subkeys), you might
need to move the old secring out of the way or do more complicated
merges with gpgsplit (if you've had the misfortune of generating new
subkeys on both systems).

@_date: 2011-05-03 11:50:46
@_author: Daniel Kahn Gillmor 
@_subject: Syncing Keys between multiple computers? 
I wouldn't consider this a reasonable approach if any secret keys are
involved.  Keep your secret keys private!  Dropbox exposes your secret
keys to dropbox employees (and anyone who can convince them to snoop):

@_date: 2011-05-05 09:15:40
@_author: Daniel Kahn Gillmor 
@_subject: Storing secrets on other people's computers 
The internet seems like a wider (and cheaper) distribution method than
the NYT.  So what are you waiting for?  I hereby volunteer to cover your
costs for posting your secret key to this mailing list :P
PS If Robert follows through on this, he certainly wouldn't be the only
person to publish his secret key.  Search for "BEGIN PGP PRIVATE KEY
BLOCK" in your favorite search engine.

@_date: 2011-05-06 11:05:56
@_author: Daniel Kahn Gillmor 
@_subject: Best practice for periodic key change? 
This is a critical observation.
expiration dates are safeguards against a key becoming inaccessible to
the legitimate keyholder -- not against compromise.
There are other safeguards against keys becoming inaccessible, including
a safely-stored revocation certificate.
Expiration dates have the advantage over revocation certificates that
you do not need to keep track of anything or maintain safe and secure
longterm storage.
A safely-stored revocation certificate *also* protects against key
compromise, though, so you really ought to have one anyway.  Consider
the expiration date as a safeguard against simultaneous loss (not
compromise) of the key and loss of the revocation certificate.

@_date: 2011-05-06 17:59:37
@_author: Daniel Kahn Gillmor 
@_subject: https://lists.gnupg.org X.509 certificate is expired 
When i point a web browser at  i get a warning
that the server's X.509 certificate is expired (it has a CN of
trithemius.gnupg.org and several subjectAltNames, including
I'm not a fan of the CA cartel, but it would be nice to have some
up-to-date way of verifying the server, especially for people already
well-connected in the web-of-trust.
If the administrator of the server would publish the host's key in an
OpenPGP certificate, and sign it, then we could verify it that way.
Here's a quick intro for how to do that:
 If this isn't acceptable for some reason, could you at least update the
certificate to one with a reasonable expiration date?

@_date: 2011-05-10 00:18:15
@_author: Daniel Kahn Gillmor 
@_subject: Best practice for periodic key change? 
I doubt it -- the bytestring signed during OpenPGP key+userid
certifications has a different prefix than the bytestring signed during
a data signature.
But i think the data signed by a hardware implementation is a digest of
the bytestring, not the bytestring itself.  I don't think a smartcard
would be able to tell the prefix of the underlying bytestring from the
digest it receives as a signature request.

@_date: 2011-05-10 00:41:09
@_author: Daniel Kahn Gillmor 
@_subject: Best practice for periodic key change? 
As i understand the process, i think it would be necessary to pass all
the data through the card in order to for the card to know which type of
signature it was making.
I know nothing of the details of how these cards are implemented,
though.  Maybe they do this already?  it seems like performance would be
problematic if you were signing something like a multi-MiB document,
given the speed of most smartcards.
Maybe one of the folks with experience implementing these devices can
give more concrete details?

@_date: 2011-05-12 14:34:08
@_author: Daniel Kahn Gillmor 
@_subject: More than 1 secret key: how do I specify which one --sign uses? 
The man page suggests --default-key or --local-user:
 [...]

@_date: 2011-05-17 13:36:39
@_author: Daniel Kahn Gillmor 
@_subject: bug: gpg fails to allow update of OpenPGP certification after 
My certification on a key+userID recently expired.  I went to re-certify
it, and gpg failed to allow the re-certification, with the following
Note that no additional certification was added.
There were two certifications by D21739E9 on the key in question already:
 A) one certification from 2008 with no expiration date
 B) a certification from 2010 with an expiration date in early 2011
Given the OpenPGP standard, B should supercede A.
It appears that what happens is that when the user says "y" to the
prompt, gpg effectively deletes signature B from the temporary view of
local keyring, leaving it with A.  It then decides that A is sufficient,
and declines to do anything.  Since no changes have been made, it
doesn't even save the updated local keyring.
I have two workarounds:
0) manually delete A from my local keyring first, with something like:
 gpg --edit-key $KEYID
  1
  delsig
1) use gpg's --expert flag to force my way through.
I note that if i use either of these methods to create a new
certification, then my local keyring ends up without (B) at all (though
it is of course re-fetchable from the public keyservers).  I consider
this is surprising behavior, though given that i'm in workaround
territory, i suppose any surprises should be expected.

@_date: 2011-05-17 21:16:25
@_author: Daniel Kahn Gillmor 
@_subject: GPG keys listed are not correct. 
Hi Lucelio--
 [...]
I think you'll need to ask these questions to either the kpackage kit
folks (whatever that is) or the Fedora folks; gpg just provides the
tools these projects use to verify their software downloads; the gnupg
project doesn't distribute their particular keys.
Note: if these problems arose from running something from the command
line (i don't know if you were using a GUI package manager or a command
within a terminal emulator), you might want to provide more context for
whoever you contact next.
Here are some useful tips for getting troubleshooting help for working
from the command line:

@_date: 2011-05-27 11:50:17
@_author: Daniel Kahn Gillmor 
@_subject: I can't stop encryption being done with a wrong key 
I'm glad you got it resolved!  I think this is more of a demonstration
that fixing this to do the Right Thing by default in gpg itself would
have been a boon to both kmail and enigmail (and any other frontends).
If you have thoughts on what gpg should have done in the first place,
there's an open bug report titled "better heuristic for choosing an
encryption key based on a User ID":
  You might want to add comments there describing your preferred behavior.

@_date: 2011-05-27 19:16:03
@_author: Daniel Kahn Gillmor 
@_subject: A better way to think about passwords 
A computational linguist's rebuttal to Baekdal's post:
 The takeaway: Baekdal's analysis only holds for extremely na?ve brute
force attempts.  Please don't assume that all attackers will be so
        --dkg

@_date: 2011-11-01 13:20:03
@_author: Daniel Kahn Gillmor 
@_subject: How can I know all the recipients of a GPG encrypted message 
feed the message body (not decrypted) itself through gpg --list-packets.
You should see output like this:
dkg at pip:~$ gpg --list-packets 2>/dev/null < .mail/msg.12345
:pubkey enc packet: version 3, algo 1, keyid 77A0D9461321E649
:pubkey enc packet: version 3, algo 1, keyid 1FE3FFC22D967C01
:encrypted data packet:
dkg at pip:~$
Each of the "pubkey enc packet" stanzas identifies a particular key to
which the message was ostensibly encrypted.  You may find that you need
to fetch the relevant keys to learn more about the identity of the
Without holding the corresponding secret keys, of course, you can't tell
for sure that the message has been actually encrypted to the listed key.
 It's possible to create a pubkey enc packet with bogus data in it, so
that it looks like the message has been encrypted to DEADBEEFDEADBEEF,
but in fact it cannot be decrypted by the holder of that secret key.
Note also that it's possible (e.g. with --throw-keyids or
--hidden-recipient) to craft messages that don't advertise the people to
whom the message was encrypted.  These kind of messages are a hassle for
the intended recipients, however, because a recipient needs to try each
of their secret keys against each pubkey enc packet to see if any
decryption is possible.
In short: there's no way to be absolutely sure of all the intended
recipients; but in common practice you can have a reasonable guess.

@_date: 2011-11-12 13:29:51
@_author: Daniel Kahn Gillmor 
@_subject: Convert a .sig file to .asc file (is it possible)? 
ascii armor is just a standard header and footer, wrapped around
base64-encoded data plus a checksum:
 If you have perl installed, you can use the attached script to convert
from a binary version to an ascii-armored version.  Invoke it like:
  openpgp-armor-convert < foo.sig > foo.asc

@_date: 2011-11-18 17:10:45
@_author: Daniel Kahn Gillmor 
@_subject: Key File for GPG 
first, do:
gpg --import < localfile.key
then do other gpg stuff, referring to the key by its ID or by the user
ID associated with it.
a single file could contain multiple independent keys, or a single
primary key with a bunch of subkeys, so it doesn't make sense to use the
file itself to indicate which key to use.

@_date: 2011-11-20 23:14:37
@_author: Daniel Kahn Gillmor 
@_subject: keys.gnupg.net 
keys.gnupg.net is a DNS round-robin which points to a number of OpenPGP
keyservers, each of which syncs with each other.
there are other DNS round-robin pools as well (one well-known one is
zimmermann.mayfirst.org (a.k.a. keys.mayfirst.org) happens to be a
member of multiple pools.  (i'm one of the administrators of this machine)
If you visit a keys.gnupg.net again, you might very well end up at a
different keyserver; that's the nature of DNS round-robin.
As for the hkps -- it's significantly more complicated to do a dns
round-robin between TLS-secured hosts in different administrative zones.
 So instructions for the use of hkps at the moment tend to encourage the
use of a single hostname (rather than a pool).

@_date: 2011-10-04 10:02:19
@_author: Daniel Kahn Gillmor 
@_subject: MS Exchange server corrupting PGP-MIME emails 
suggests that:
   The entire contents of the multipart/signed container must be treated
   as opaque while it is in transit from an originator to a recipient.
   Intermediate message transfer agents must not alter the content of a
   multipart/signed in any way, including, but not limited to, changing
   the content transfer encoding of the body part or any of its
   encapsulated body parts.
But the example messages you gave are not multipart/signed  -- they're
encrypted messages, which are ascii-armored (base64-encoded) blobs in
the first place, which are being re-wrapped in another layer of base64.
Given that compliant MUAs should strip off the outer layer of base64
before handing the message, i don't think this should be a problem.
I'd be more concerned with their switch from Content-Disposition: inline
to Content-Disposition: attachment, which seems likely to make compliant
MUAs not want to pass the message to an inline renderer at all.

@_date: 2011-10-09 08:00:19
@_author: Daniel Kahn Gillmor 
@_subject: Is there a way to browse the GPG web of trust? 
Running a keyserver isn't terribly hard.  But you'll need a chunk of
disk space (10G at least), a decent amount of RAM (1G), and a reliable
network connection (ideally with a static IP).
The dominant free keyserver these days is sks,  You should subscribe to
the discussion list for that project if you plan to run an OpenPGP
  SKS development list

@_date: 2011-10-09 08:09:46
@_author: Daniel Kahn Gillmor 
@_subject: Is there a way to browse the GPG web of trust? 
I can pretty much guarantee that it is in fact broken, given the range
of possible User IDs and various --list-options that could be applied in
gpg.conf to affect the human-readable format.
I suppose it's possible that no one has actually hit a broken case, or
(more likely) that no one has bothered to report such a breakage.
Has anyone tried to use sig2dot with a User ID that contains an embedded
newline?  Or with show-notations or show-keyserver-urls or
show-uid-validity set in --list-options?
Anyone looking for a quick way to make a contribution to this corner of
the OpenPGP toolset could just permute these kinds of changes until you
can coax sig2dot into a bad state, and then file a bug report to the
upstream author suggesting the use of the machine-readable format (or
the perl module GnuPG::Interface, which uses the machine-readable format
already, and should handle most of the parsing for you).
Just because it currently works in the "normal" case doesn't mean it
behaves properly in all cases.
Hoping i'm wrong about sig2dot,

@_date: 2011-10-30 17:03:46
@_author: Daniel Kahn Gillmor 
@_subject: MS Exchange server corrupting PGP-MIME emails 
Assuming that standards-based arguments carry any weight at all, you'll
have a stronger argument if you *do* limit your scope to the
multipart/signed mime parts:

@_date: 2011-09-07 08:36:39
@_author: Daniel Kahn Gillmor 
@_subject: WARNING: digest algorithm MD5 is deprecated 
fetching your key from the keyservers and inspecting it with pgpdump, i
see nothing about MD5 either.  here's what i did:
 gpg --recv 27FB1E3581B856269450EAFC25178AB4B9466FB4
 gpg --export  27FB1E3581B856269450EAFC25178AB4B9466FB4 | \
    pgpdump | grep 'Hash alg'
Can you show a full transcript [0] of what you did that produced the
[0]

@_date: 2011-09-08 15:02:32
@_author: Daniel Kahn Gillmor 
@_subject: displaying decrypted plaintext on screen instead of output to file 
you could try using stdin and stdout.  For example:
 gpg --decrypt < file.asc
 (or pipe that into your favorite non-caching pager, e.g. /usr/bin/less)
 gpg --encrypt --armor -r $recipient
 (then type your message, and end with a ctrl-D after the last newline)

@_date: 2011-09-08 16:33:38
@_author: Daniel Kahn Gillmor 
@_subject: displaying decrypted plaintext on screen instead of output to file 
it looks like you didn't hit return after the recipient address?
hitting return on just the command i wrote invokes gpg, which will be
waiting for data on its standard input.  Then, you type what you want to
encrypt, hit return, and then ctrl-d to indicate end-of-file.  gpg
realizes its input is done, processes the material, and dumps the
encrypted output to stdout.
Alternately, you could feed your data directly on stdin from the command
line with a pipe, like this:
 printf "just a test" | gpg --encrypt --armor -r $recipient
If you're not down with these patterns, i recommend getting comfortable
with stdin and stdout.  The time spent will be repaid immensely if you
plan to work with UNIX-like systems in the future.  I recommend reading
up on the basics of the concept:
   and maybe also searching around on the 'net for some tutorials.  Playing
with pipes and redirection in your favorite shell is probably the best
way to really internalize the concept, of course.

@_date: 2012-04-05 17:56:49
@_author: Daniel Kahn Gillmor 
@_subject: List-packets help 
the output of "gpg --list-packets" tends to make a lot of implicit
references to the tables and packet type information found in RFC 4880
and other standards.
 Are you looking for answers to a specific question?  If so, you might
have better luck getting those answers by asking the question
explicitly; people on this list might be able to point you to the
relevant section of the standards, and to help you figure out how to
answer your own questions from reading the standards in the future.

@_date: 2012-04-16 22:22:42
@_author: Daniel Kahn Gillmor 
@_subject: FAQ references deprecated option --list-ownertrust 
Hi folks--
The GNUPG FAQ references --list-ownertrust here:
but that option appears to be deprecated:
0 dkg at pip:~$ gpg --list-ownertrust | head -n2
gpg: WARNING: "--list-ownertrust" is a deprecated option
gpg: please use "--export-ownertrust" instead
# List of assigned trustvalues, created Mon 16 Apr 2012 10:22:02 PM EDT
# (Use "gpg --import-ownertrust" to restore them)
0 dkg at pip:~$
Could the FAQ be updated to match current best practices?

@_date: 2012-08-05 10:13:40
@_author: Daniel Kahn Gillmor 
@_subject: looking for reading material 
i note that your subkey should have the "signing" usage flag set.  That
is, it should show up under gpg --edit-key with "usage: S".  Otherwise,
that subkey has no business signing data and its signatures *should* be
 key usage flags:
  Note that signing- or certification-capable subkeys should also have an
embedded primary key binding signature, to indicate that they really do
belong to the primary key.
 primary key binding sigs:
  sure, those steps seem reasonable.
i don't think your X.509 analogies are as close as you'd like them to
be.  In standard TLS connections, each peer hands their certificate (and
any intermediate certs) to the other peer as part of establishing the
Most data signed via OpenPGP does not have *any* certificate ("openpgp
keyblock") directly attached to it.  The common assumption in this model
is that public key material has been exchanged via some other mechanism
What you describe does sound like a bug in rpm's signature validation
policy.  I haven't tested it myself.
Most OpenPGP signatures contain the 64-bit keyid of the signature issuer
in an "issuer subpacket":
 Technically, multiple keys can have the same 64-bit keyid -- the 64-bit
space is too small to avoid collisions made by a determined attacker
(among other possible threats).
But in the common use case, this is sufficient to greatly reduce the
number of keys the verifier needs to consider when checking the signature.
I'm not sure what you mean by "go through the whole keyring" -- if rpm's
keyring, like gpg's, is unindexed, then rpm will need to go through the
keyring to find the key that matches the keyid found in the issuer.  It
does not need to check the signature against any of the non-matching
keys, though.

@_date: 2012-08-18 10:36:21
@_author: Daniel Kahn Gillmor 
@_subject: how vulnerable is "hidden-encrypt-to" 
It's worth observing that you can still detect the algorithm used and
the size of the key, even when the keyid is all zeros.  So if someone
has a particularly unusual key size (or is an early adopter of an
unusual key type, like ECC), the pool of possible known recipients could
actually be pretty small.
And it's also possible to rule out a given person as an intended
recipient, e.g. if they have a 2048-bit RSA key and the ESK packet
targets 4096-bit el gamal.

@_date: 2012-12-20 15:48:51
@_author: Daniel Kahn Gillmor 
@_subject: Unable to run GPG from PHP gpg: WARNING: unsafe ownership on 
Hi Roberto!
is your web server user running as the same user account you expect it
to be?  often, on shared servers, the web server runs as www-data or
some other user.  Fortunately, www-data does not have write privileges
inside other users' gnupg home directories.  And making ~/.gnupg
writable by www-data would open your account up to a whole new level of
other problems if anyone else can write scripts that run as the web
server user.
I suspect what you want is to get the web server to run as a dedicated
user specifically for your account.  I don't know how to do that from
within cpanel (and i'm sure you can find a better cpanel forum than
I understand that this is a test script, so i will not enumerate the
ways in which the above can go horribly wrong if any of the relevant
variables are replaced by user-supplied data.  I just hope you don't
plan on using anything like this in production.  Shell script injection
vulnerabilities are bad news.
Do the above explanations and concerns make sense?
Good luck with your project!

@_date: 2012-12-23 16:31:01
@_author: Daniel Kahn Gillmor 
@_subject: OpenPGP Authentication Protocol? 
the ssh specification declares the use pgp-style certificates:
  but does little to indicate how peers should consider them for
authentication purposes.  the majority of OpenPGP-verified ssh
connections in use on the net today are probably using raw keys on the
wire, but certifying them out-of-band via tools like the Monkeysphere.
RFC 6091 documents a mechanism for using OpenPGP certificates as peer
endpoints for a TLS session.
 But similarly to the ssh situation, it may be simpler to pass "dummy"
public key placeholders (e.g. those that are well-formed X.509
certificates) and do the conversion to OpenPGP certificates on the
backend/out of band.

@_date: 2012-12-23 17:17:35
@_author: Daniel Kahn Gillmor 
@_subject: OpenPGP Authentication Protocol? 
The key format is different than "pure" (i would call "raw") SSH keys --
but these OpenPGP certificates still act as a carrier for RSA or DSA key
objects, which are mathematically and conceptually the same beasts as
"raw" SSH keys.  In SSH, the signature each peer provides when offering
an OpenPGP certificate is expected to be an OpenPGP binary signature
format (instead of a stock SSH-formatted RSA signature).  Beyond that,
the rest of the SSH protocol remains the same.
I don't know of any ssh implementations that support the openpgp
certificate format specification, or of anyone who uses it actively.
otoh, as a monkeysphere developer, i can attest to the existence of ssh
peers that use OpenPGP certificates during authentication/authorization
while still handling "raw" SSH keys and signatures on the wire.
With RFC 6091, even the handshake signature data itself is unchanged --
only the certificate format differs, and the rest of the TLS handshake
remains the same.
? Why should a session protocol define which keys a user should trust?
Beware of the term "trust" in this context -- it's a slippery one, and
it is very easy cause confusion with it.  I think you mean "which keys a
peer should consider for authentication and authorization".  For
example, when i ssh to evilhost.example.org, i might verify the host's
identity successfully via an OpenPGP certificate, and i might even go
ahead and connect to it with SSH, but that wouldn't mean i "trust" the
host in any broader or more human sense of the term "trust".
Anyway, I agree with your implication that a session protocol
specification has no business mandating a specific policy for
authorization or authentication.  But many people considering these
challenges assume that authn/z policies should be bundled with the
protocol spec; so i wanted to make that distinction clear.

@_date: 2012-12-27 11:14:12
@_author: Daniel Kahn Gillmor 
@_subject: ASCII armor plus? 
This isn't the case, as far as i can tell.  Recent versions of mailman
all play fine with PGP/MIME.  See, for example:

@_date: 2012-02-26 16:44:42
@_author: Daniel Kahn Gillmor 
@_subject: courier re-writing of mime boundaries, verification fails 
This sounds like a bug in the Courier MTA, according to the MIME
standards for encrypted/signed mail:
    Multipart/signed and multipart/encrypted are to be treated by agents
   as opaque, meaning that the data is not to be altered in any way
See also:
  These questions ar probably better asked on the courier mailing lists:
  hope this helps,

@_date: 2012-02-29 13:18:58
@_author: Daniel Kahn Gillmor 
@_subject: small security glitches 
============================== START ==============================
The above two steps are clear so far.
i'm assuming that the intended recipient sends the "gibberish" back to
the original sender encrypted, right?  if they send it in the clear,
it's hardly the fault of the cryptosystem that the cleartext was exposed.
eh?  how does it follow that the attacker has both of these?  afaict,
the attacker has:
 A) the original ciphertext
 B) the modified ciphertext (which they supplied arbitrary data for)
 C) a re-encrypted version of the modified cleartext (reencrypted
    against a different session key, presumably).
I don't understand how this follows either.  where does XOR come in?
Which part of OpenPGP is using XOR here?
At any rate, this is indeed about message integrity; if you want
encrypted integrity, you need your peer to supply an MDC (gpg does this
by default).  If you want verifiable message provenance with message
integrity, you need your peer to sign their messages.
If Alice does something like take an un-verified message, decrypt it,
and then post the plaintext somewhere anyone can look at it, then the
cryptosystem hasn't failed; but alice has stopped using the cryptosystem.

@_date: 2012-01-08 16:56:43
@_author: Daniel Kahn Gillmor 
@_subject: Encryption with key ID 
even better, if you prefix the keyID with 0x gpg will automatically
interpret it as such.
Read the "HOW TO SPECIFY A USER ID" section in the gpg manpage for more

@_date: 2012-01-09 17:30:37
@_author: Daniel Kahn Gillmor 
@_subject: Encryption with key ID 
What operating system are you using?  What version of gpg?
It looks to me like "the limit is ..." was removed over 10 years ago --
are you using an up-to-date version of gpg?

@_date: 2012-01-24 10:21:35
@_author: Daniel Kahn Gillmor 
@_subject: Why hashed User IDs is not the solution to User ID enumeration (was: 
What you're looking to do with this proposed hashed-user-id scheme is to
find a way to avoid allowing people to enumerate e-mail addresses or
User IDs from the data contained on the keyservers.  Right?  I'd also
like to be able to do that, but i don't think hashed-user-ids is an
effective way.  Here's why:
I worked for a while with a group of people (several of the other
monkeysphere devs) to spec something like this out, to try to address
this very issue.
However, after thinking about the various possible solutions, and
reading more, i started to think this all smelled very similar to
another problem:  DNSSEC zone enumeration.
DNSSEC zone enumeration is a byproduct of the way that NXDOMAIN
responses must be signed in order to be provable; the original proposal
required the signed NXDOMAIN response to indicate the range of names
which were excluded.  this makes it easy for an attacker to jump from
name to name via NXDOMAIN records, and enumerate all records in the
zone.  So far, this looks very much like the current keyservers, which
allow for trivial enumeration of IDs.
DNSSEC tried to fix this with NSEC3 records, which work differently;
instead of listing the boundaries of the requested NXDOMAIN range, they
listed the boundaries in a hashed space.  that is, instead of saying
"there are no records of any type between bar.example.com and
foo.example.com", they say "there are no records of any type whose
labels hash to somethng between 8a367d741d7a9a904ef6f92fd99de3d57ded1203
and cb17eb75226ca198afec4ea1170f02fade354e3e".  So now, the attacker who
wants to enumerate the zone has to reverse the hash to uncover the
The trouble is that domain names (and e-mail addresses, and human names)
are very low-entropy things, and actually are pretty easy to enumerate
and test.  Dan Bernstein wrote a tool called NSEC3walker that can
practically enumerate a DNSSEC-signed zone that uses NSEC3 records,
using pretty low-end hardware, and doing few network queries:
  A comparable tool could be made to attack any sort of hashed-user-ids
scheme, which means that anyone who wants to harvest or enumerate
addresses this way could probably do it.  Certainly, the bar is raised
for User ID enumeration, but only slightly.
So, as someone who was similarly eager for such a scheme, i have to ask
myself: does the marginal gain in address-enumeration-protection
outweigh the costs in complexity and confusion that the scheme adds?
Certainly, the keyservers will continue to support non-digested User
IDs, so now tools will need to be able to handle both of them; we'll
also need a policy for end-user agents to answer questions like "when
looking up this e-mail address, do i send it only in digested form to
the keyservers for lookup?  or do i send it in cleartext form as well,
thereby leaking the e-mail address to the keyserver operators (and to
anyone on the network path)?  How do we explain or expose policy
questions like that to users who already struggle with the concepts
behind OpenPGP?  or do we modify the keyservers themselves to index
digested forms of cleartext User IDs, and respond to digest lookups with
cleartext responses, thereby turning the keyservers into a
digest-reversing oracle for those non-hashed User IDs which exist?
Ultimately, i don't think the tradeoffs for this scheme are worthwhile
for the marginal and limited gain that the proposal provides.  I'd love
to find a solution to the User ID enumeration problem, but i don't think
hashed-user-ids is it.

@_date: 2012-01-25 17:55:12
@_author: Daniel Kahn Gillmor 
@_subject: hashed user IDs redux [was: Re: Creating a key bearing no user ID] 
i've given a fairly detailed technical writeup of why i've stopped
pursuit of this particular goal.
If people use e-mail addresses like this, then they could probably just
derive the high-entropy-portion of their e-mail address from their key's
fingerprint directly, and attach only a User ID like "anonymous".
  dkg--noenum-0EE5BE979282D80B9F7540F1CCD2ED94D21739E9 at fifthhorseman.net
Then no keysigning would be needed as anyone who knows the e-mail
address already knows the key to use, and the key is fetchable from the
keyservers by keyid directly.
This can all be done with the current toolchain, without modification,
afacit.  The only problem is that you'd have to adjust your MUA to tell
it which key to use explicitly for mailing to addresses like this.  If
you think this is the way to go, maybe you should talk to MUA
developers, or propose a mechanism or heuristic gpg could use to
pre-select keys from e-mail addresses like this.
Clearly people are interested in the idea and have done some work to
think about it how it can be done, and what would be the right way to
go.  No one who implements something someone else suggests is going to
want to do it without a concrete, well-discussed spec beforehand.
Several of us have had the discussion that resulted in my deciding that
the tradeoffs for the scheme we came up with (hashed userids) wasn't
worth the extra complications.
Please propose an alternate scheme that you think would be an
improvement if you think such a scheme exists.  Hopefully, it will get
critiqued, though there are no guarantees that anyone will implement
whatever scheme (if any) finally overcomes the objections raised during

@_date: 2012-01-25 18:19:56
@_author: Daniel Kahn Gillmor 
@_subject: Why hashed User IDs is not the solution to User ID enumeration 
Hi Vedaal--
i'm confused by your proposal.  some clarifying questions follow:
This seems like it might just be an elaborate way to ask for a random
number, but i'm not sure what the intent is.  Is it just trying to get a
decent-sized chunk of randomness?  or is there another purpose?  if it's
just about randomness, rephrasing more simply might make this clearer.
What is the "preferred key name" ?  are you expecting users to name
their keys?
What happened to the hash here?  are you suggesting that the User ID is
the digested form or the non-digested form?
OpenPGP certificates are handed to the keyserver as is; the keyserver
chooses how to index them.  What do you mean by "identify the key to the
server by the hash" ?
I'm still not sure i follow.  Can you explain more?  How would these
keys be identified by a user searching for them?  How would third
parties verify the user ID before signing?
how does your proposal above compare to David Shaw's (seemingly simpler)
proposal, or to the proposal i outlined elsewhere in this thread?

@_date: 2012-01-25 20:35:52
@_author: Daniel Kahn Gillmor 
@_subject: Why hashed User IDs is not the solution to User ID enumeration 
Compared to the complexity and confusion downsides on a protocol that is
already complex and confusing, yes, i believe the potential gains here
qualify as marginal.
It only takes one party to reverse the User IDs and publish the reversal
for everyone to be able to trivially enumerate them already.
which, as i documented in the earlier message, is no better defense
against enumeration than NSEC3.
how?  where?  via what mechanism?  how do you determine that the right
key is associated with the relevant User IDs?
eh?  are you talking about modifying the keyserver protocol?  are you
aware that full keyserver dumps are available for the taking, and that
anyone can run a keyserver?
I remain unconvinced that this is a serious proposal, unfortunately.

@_date: 2012-07-11 22:10:11
@_author: Daniel Kahn Gillmor 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
If the attacker can convince you to sign a chosen text (perhaps one that
looks reasonable), then a failure in the digest's collision-resistance
could very well be used to replay that signature over a different (but
colliding) text (which may not be something reasonable).  This does not
require a preimage collision.
I'm not saying these attacks exist practically today against SHA1 (i
don't know if they do), but collision-resistance is the relevant
property, not resistance to pre-image attacks.
The places where it is thoroughly "baked in" are the MDC (not relevant
cryptographically) and the V4 fingerprint (where the relevant property
is resistance to a preimage attack instead of resistance to generated
Where exactly has the original poster signed anything over an MD5 digest?

@_date: 2012-07-12 10:59:47
@_author: Daniel Kahn Gillmor 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
some other points (from memory):
 * Issuer subpacket should use a full fingerprint, rather than a short keyID
 * designated revoker signature should embed full key instead of

@_date: 2012-07-24 10:08:10
@_author: Daniel Kahn Gillmor 
@_subject: asymmetry of 'adduid' and 'deluid' 
possession of the secret key is not required for deluid, actually.
look at it this way:
deluid is just an edit of your local keyring -- it removes a handful of
packets (note that if the key is already on the public keyservers or
someone else has a copy, they will still have the user ID that you deleted).
adduid, on the other hand, requires the creation of a new cryptographic
signature: the self-sig made by the primary key over the user ID.  To
create this self-sig, gpg needs access to the secret key material for
the associated primary key.
make sense?

@_date: 2012-07-24 13:41:20
@_author: Daniel Kahn Gillmor 
@_subject: charset weirdness with non-ascii User IDs 
Hi folks--
i'm seeing some strange behavior with the keyservers on GNU/Linux
systems that don't have a UTF-8 locale, or when LANG is set to something
0 dkg at pip:~$ LANG=C gpg --keyserver keys.mayfirst.org --search '=Andrew Lee (? ??) '
gpg: searching for "=Andrew Lee (?????) " from hkp server keys.mayfirst.org
(1)	Andrew Lee Keys 1-1 of 1 for "=Andrew Lee (???) ".  Enter number(s), N)ext, or Q)uit > q
0 dkg at pip:~$ LANG=C gpg --keyserver keys.mayfirst.org --search '=Antoine Beaupr? (work) ''
gpg: searching for "=Antoine Beaupr?? (work) " from hkp server keys.mayfirst.org
gpg: key "=Antoine Beaupr? (work) " not found on keyserver
0 dkg at pip:~$ Note that the --search for Andrew's UTF-8 User ID succeeds, but
Antoine's fails.
This behavior happens on both gpg 1.4.12 and 2.0.19, and it happens with
or without debian's gnupg-curl packages installed.
Given that User IDs must be UTF-8-encoded, i'm not sure what the right
thing to do is here.
I tried searching for this bug on  but i'm
getting an error when i search for the term "charset" for some reason.
Any suggestions for the right direction for a fix?
        --dkg

@_date: 2012-07-25 13:12:10
@_author: Daniel Kahn Gillmor 
@_subject: GPG key to authenticate to SSH? 
yes, this is correct.
This isn't actually how "monkeysphere subkey-to-ssh-agent" (or, more
concisely, "monkeysphere s") works; instead it actually extracts the
authentication-capable subkey, reformats it in accordance with what ssh
expects, and feeds it to ssh-agent using the standard ssh-add.
reading sshcontrol's documentation in the texi doc, it occurs to me that
this indication of which key should be used for ssh should in many use
cases be visible to ssh servers as well.  If for some reason the
authentication-capable flag isn't sufficient to indicate this, perhaps
some sort of OpenPGP notation in the binding signature would be useful?

@_date: 2012-07-28 10:53:29
@_author: Daniel Kahn Gillmor 
@_subject: [OT] Multi-user hierarchical password management via pki 
I don't think this precisely meets all of your specs, but it comes
remarkably close:
 you can get the source here:
 git://git.sarava.org/keyringer
I've cc'ed the lead author (Silvio Rhatto) here, in case he wants to
follow up.

@_date: 2012-06-21 12:39:33
@_author: Daniel Kahn Gillmor 
@_subject: choice of encryption algorithms 
completely agreed.
i don't think this is the case.  default-preference-list describes the
default preferences used for new keys.  That is, for keys created by the
local installation of gpg, the embedded preference list stored in the
self-sig is chosen by this value.
The personal-*-preferences settings, on the other hand, allow the user
of gpg to override the recipient's self-sig's stated preferences,
allowing to use the highest-personally-ranked algorithm that the
recipient has stated that they can handle.
The description in the gpg man page for these options describes them
quite well, and it doesn't mention any relationship between them.  If
there is indeed a relationship, the manual probably needs to change to
reflect it.

@_date: 2012-06-21 16:38:31
@_author: Daniel Kahn Gillmor 
@_subject: idea.dll 
unfortunately, this is indeed the case.  v3 keys have a serious
vulnerability in that their fingerprint mechanism is trivially gamable,
so long keyid collisions are easy.
You should retire your v3 key, as should anyone else with such a key.

@_date: 2012-06-27 10:24:54
@_author: Daniel Kahn Gillmor 
@_subject: migration paths from SHA-1 [was: Re: idea.dll] 
For the key's fingerprint specifically, a pre-image (where the attacker
crafts a new text that shares a digest with the victim's key material)
is the thing to worry about, not a crafted collision (where the attacker
generates two texts that share a digest).
My read of [1] is that the attack is a collision technique, not a
pre-image technique, which would imply that "eventually" is still
actually a little ways off for fingerprints at least.
Not by default.  In testing today with an empty profile, gpg 1.4.12
still defaults to making key certifications (where the attacker controls
the digested material completely) and data signature with SHA1.  These
are areas where a successful collision attack can do serious harm.
i'd be happy to see gpg migrate to defaults of SHA-256 for data
signatures and key certifications; these digests have been available to
users (of both GPG and PGP) for many years now.  I've been using SHA-512
for my data signatures and key certifications for a few years and have
never gotten a complaint.
[1]

@_date: 2012-03-02 02:50:24
@_author: Daniel Kahn Gillmor 
@_subject: small security glitches 
what you meant to send me?" then the
Have you read the paper you reference above?  If not, i recommend
reading it.  It's a good paper, and clever cryptanalysis.
That said, the attack described does indeed rely on the victim
decrypting arbitrary text sent by the attacker and sending it back in
such a way that the attacker can read the cleartext.  Quoting the paper:
Do you see how the above suggests that the victim must transfer the
(apparently-garbled) cleartext to the attacker for the attack to proceed?
Yes, the Modification Detection Code packet was formally introduced in
RFC 4880 as a mechanism to defend against producing garbled decryption
like that shown in the referenced paper:
  I believe that GnuPG had its own implementation of such an integrity
check before the standardization was settled.
This attack (or class of attacs) can only be fully prevented by the
victim;  A responsible crypto user should only quote from encrypted
messages (when replying) if the original message was signed by the
person to whom the sender is replying.  So the fix isn't "always sign
messages" (though that's nice and helpful), it's "don't quote when
replying to unsigned encrypted messages".
The clever move by Jallad, Katz, and Schneier was to show a way that a
ciphertext could be modified such that its "cleartext" would look like
gibberish to the victim, but could also provide a decryption oracle for
the attacker.  Since the "cleartext" looks like gibberish to the victim,
they might be more willing to forward it to anyone (incluing the attacker).
However, comparable attacks could still work in situations with
significantly less cleverness than that shown by Jallad, Katz, and
Schneier.  For example, Alice could send Bob an unsigned,
integrity-protected encrypted message which says:
If Eve were to intercept this message (preventing it from reaching Bob),
and then simply replay it to Bob with her address in the "From:" field
instead of Alice's, and Bob decides to respond to Eve with:
Then Eve has taken advantage of Bob's credulousness to compromise the
confidentiality of Alice's original message.
Note that even the MDC does nothing to prevent the above attack.
If Alice wants to help Bob avoid this kind of breach of confidentiality,
she can (and probably should) do all of the following when sending
encrypted mail:
 0) use an MDC
 1) sign her messages
 2) make sure the encrypted content of her messages always clearly
indicates that they are coming from her (e.g. concluding the message
with something like "Regards, Alice")
However, even if Alice always does all of those things, if Bob isn't
paying attention (to the warnings from his OpenPGP implementation, to
whatever warnings his MUA shows that highlight discrepancies between the
message signer and message "From:" address, to the content of the
message, to general common sense), he might well still leak the contents
of the message.
This is an unhappy state of affairs, but Bob might also be in the habit
of reading his e-mail out loud to himself at the pub, in which case even
the message interception and replay are unneeded. Eve just needs to show
up at the right hour and drink a pint from a nearby stool :(
For a message to remain confidential, both the sender and the recipient
need to exercise care.
I believe the original responses you're referring to were correct.  I
don't think that the paper you cite above suggests otherwise.

@_date: 2012-03-05 13:12:06
@_author: Daniel Kahn Gillmor 
@_subject: invalid gpg key revocation 
Without pointing to the key in question and the associated revocation
certificate, there isn't much that folks on this list can do to help
you.  Can you post a link to the key, or attach it to e-mail here?  or
publish it to the public keyservers, and refer to it by keyID?
If you aren't willing to share the key publicly for other folks to take
a look at, you might want to review the revocation certificate to be
learn a few things:
 * what key issued the revocation certificate?
 * when was the revocation issued (according to its internal timestamp)?
 * what cryptographic algorithms were used by the revocation
   certificate?
 * were the cryptographic bits correct?
 * what was the encoded reason for revocation?
You might find some clues to the above by exporting the key from your
public keyring and piping it to gpg --list-packets:
 gpg --export $keyid | gpg --list-packets
FWIW, if someone did compromise your secret key material, creating a
revocation certificate for your key is possibly the nicest thing they
could do with it.

@_date: 2012-03-05 18:23:38
@_author: Daniel Kahn Gillmor 
@_subject: invalid gpg key revocation 
as pranks involving compromise of the secret key go, this is the
least-nasty prank i can think of.
But it's ok to use the cached signing passphrase for making bogus
identity certifications?  For signing ersatz love letters?
What's to stop the malefactor from just querying the passphrase directly
out of gpg-agent and absconding with both it and the secret key material
to do whatever they want later?
I don't think making the proposed limitation is a helpful one.

@_date: 2012-03-06 15:04:39
@_author: Daniel Kahn Gillmor 
@_subject: invalid gpg key revocation 
So much mystery involved here!  You're making everyone guess at the
situation by not identifying the key.  I understand you might have
reasons for this caginess, but please realize that your reluctance to
spell out the details of the situation makes this process take much more
of your time and of the time of other people on this list.
You might not be aware that keyservers don't check the correctness of
any of the cryptographic material placed on them.  So it's possible to
upload something that looks like a revocation certificate but would be
rejected by any reasonable OpenPGP client implementation, since it would
not validate.
Anyone with possession of an OpenPGP certificate can upload it to the
public keyservers.
I understand your hesitation to import the revocation certificate to
your public keyring, though you can probably clean it up with some of
the subcommands of gpg --edit-key .
Alternately, you could create a new GNUPGHOME directory and work
temporarily from that.
mkdir -m 0700 ~/tmpgpg
export GNUPGHOME
... do your work here, you'll start with an empty keyring ...
rm -rf ~/tmpgpg
unset GNUPGHOME
No, you could also just fetch the key from the keyserver via http, and
feed it to gpg --list-packets directly.  Here's me doing that with my
own key (you'd need to replace the long keyid with the keyid you care
wget -O- \
 '
 gpg --list-packets \
 less
however, importing it into a gpg keyring is probably a better idea,
since it would let you verify whether the revocation certificate is valid.

@_date: 2012-03-07 15:16:25
@_author: Daniel Kahn Gillmor 
@_subject: Proper revocation 
If your frontend doesn't give you a feature you want, you could use gpg
from the command line to create a new revocation certificate with the
features you're looking for.
If gpg doesn't want to let you create a new revocation certificate
(probably because you've already imported an old one), you could try
deleting the old revocation certificate from your local keyring (delsig
from --edit-key, i think), saving, and trying again.
"editing" a revocation certificate doesn't make much sense, since if you
modify the certificate, you'll invalidate the signature.  Better to
think of it as discarding an existing revocation certificate and
creating a new one.

@_date: 2012-03-07 15:45:05
@_author: Daniel Kahn Gillmor 
@_subject: invalid gpg key revocation 
As i understand it, this is true for gpg-agent for gpgsm (S/MIME) in
general, and for all operations (including OpenPGP) using the
as-yet-unreleased gpg 2.1.  But for those of us using gpg-agent for
OpenPGP operations for gpg 1.x or 2.0.x, you can indeed extract the
passphrase from the agent. :/
Looking forward to a transition to gpg 2.1,

@_date: 2012-03-17 12:31:55
@_author: Daniel Kahn Gillmor 
@_subject: this list 
From  i searched for "gnupg-users", which yields one search result:
  This points to:

@_date: 2012-03-18 14:23:32
@_author: Daniel Kahn Gillmor 
@_subject: comments on uid 
I suggest that you probably actually don't want the comment at all.  The overwhelming majority of the comments that i've seen on User IDs are at best unnecessary, and at worst an explicit distraction and a reason for other people to not want to certify your User ID.

@_date: 2012-03-24 16:30:49
@_author: Daniel Kahn Gillmor 
@_subject: Do I have to install gpg before using gpgme library? 
Yes, i believe you do need to have gpg installed on the computer which you expect to use libgpgme on.  This is because libgpgme forks a background process to invoke gpg directly to do most of its work.

@_date: 2012-03-25 09:18:37
@_author: Daniel Kahn Gillmor 
@_subject: signature verification data 
you can use the --status-fd or --status-file arguments to direct machine-readable signature verification messages wherever you like.
But sending it to the same file as the text is a bad idea.  Don't do it.
For example, here's me dumping the decryption to stdout so that it flows around the message:
0 dkg at pip:~$ gpg --status-fd 1 -d x.2
gpg: Signature made Sun 25 Mar 2012 09:01:48 AM EDT
gpg:                using RSA key 0xCCD2ED94D21739E9
gpg: please do a --check-trustdb
gpg: Good signature from "Daniel Kahn Gillmor "
gpg:                 aka "Daniel Kahn Gillmor "
gpg:                 aka "[jpeg image of size 3515]"
gpg:                 aka "Daniel Kahn Gillmor "
0 dkg at pip:~$ cat x.2
[GNUPG:] PLAINTEXT 74 0
[GNUPG:] SIG_ID chNvlYWvyBS3mjoLtZ3oEC2SQho 2012-03-25 1332680508
[GNUPG:] GOODSIG CCD2ED94D21739E9 Daniel Kahn Gillmor [GNUPG:] NOTATION_NAME issuer-fpr at notations.openpgp.fifthhorseman.net
[GNUPG:] NOTATION_DATA 0EE5BE979282D80B9F7540F1CCD2ED94D21739E9
[GNUPG:] VALIDSIG 0EE5BE979282D80B9F7540F1CCD2ED94D21739E9 2012-03-25 1332680508 0 4 0 1 10 01 0EE5BE979282D80B9F7540F1CCD2ED94D21739E9
[GNUPG:] TRUST_ULTIMATE
0 dkg at pip:~$
Here's why this is a bad idea:
Once you've stuck the verification data into the same file as the message, how do you tell which parts are message body ends and which are verification data?
You might assume that all the lines prefixed with [GNUPG:] are from the gnupg signature verification process; but what if the original message contained such lines (e.g. what if you were piping this message through the signature verification process)?
By combining the data you're trying to verify with the results of the verification, you open yourself to pretty easy exploitation from anyone who chooses to craft their message in a certain way.  For example, i could just insert lines in my message that imply a good signature from you, and place a well-formed (but bogus) cleartext signature around them.  Your verification process would emit my data into the file, including my fake claims of verification.  Someone scanning that file later will believe that you signed it.
So yes, there's a way to do what you're asking.  But you shouldn't do it.

@_date: 2012-05-04 18:38:54
@_author: Daniel Kahn Gillmor 
@_subject: non-interactive expiration of a key using --batch? 
Hi folks--
I'm having trouble setting up non-interactive expiration updates of a
key with a passphrase.  I think i should use the --batch argument
because i want to ensure that gpg doesn't try to hang waiting on user
interaction, but when i use the --batch argument, the update isn't
let's say the passphrase is contained in the file "pw".
As you can see below, saving an update to 12 weeks without --batch
advances the expiration date to 2012-07-27, and a following --list-keys
shows the update.  Subsequently, saving it to 13 weeks with --batch
shows the change to 2012-08-03, but a following --list-keys shows the
expiration date reverted to 2012-07-27.
this is with gnupg 1.4.12-4, from debian testing.
Any ideas what's going on here?  Am i wrong to try to use --batch in
this instance?
    --dkg
0 wt215 at pip:~$ gpg --list-keys
pub   1024R/20819466 2012-05-03 [expires: 2012-07-27]
uid                  blab blab (DO NOT USE!) 0 wt215 at pip:~$

@_date: 2012-05-07 10:31:24
@_author: Daniel Kahn Gillmor 
@_subject: non-interactive expiration of a key using --batch? 
here you go, with --status-fd 2 (wrapped in --list-keys so you can see
that the expiration date doesn't change):
I don't see anything in the --status-fd output that gives me more of a
clue, unfortunately.
Any pointers?

@_date: 2012-05-23 01:03:47
@_author: Daniel Kahn Gillmor 
@_subject: gpgsm: (pinentry:24664): GLib-GObject-CRITICAL **: Object class 
Hi GnuPG folks--
I'm experimenting with gpgsm.  I'm using pinentry-gtk, and all packages
are from debian testing or unstable.
I'm running "gpgsm --armor --export-secret-key $KEYID > key.pkcs12".
I find that after each passphrase entry, i get the following warning on
gpgsm: (pinentry:24664): GLib-GObject-CRITICAL **: Object class GtkSecureEntry doesn't implement property 'editing-canceled' from interface 'GtkCellEditable'
This seems like noise to me -- is there a way to avoid it?  Can i
provide any other debugging diagnostics that would help?
     --dkg

@_date: 2012-05-25 10:26:58
@_author: Daniel Kahn Gillmor 
@_subject: Secret key not available 
yes, that is one plausible explanation.  Another possibility is that you
don't actually have your secret key on the computer you're currently using.
sure, you could use gpg --list-packets, and redirect standard input to
pull from the file in question:
0 dkg at pip:~$ gpg --list-packets < test.gpg
:pubkey enc packet: version 3, algo 1, keyid DF7B7722C193565B
:encrypted data packet:
gpg: encrypted with 2048-bit RSA key, ID 0xDF7B7722C193565B, created
      "Werner Koch "
gpg: decryption failed: secret key not available
2 dkg at pip:~$

@_date: 2012-05-29 11:51:06
@_author: Daniel Kahn Gillmor 
@_subject: changing the default for --keyid-format [was: Re: getting an encrypted 
i've seen a lot of these mistakes where people seem to think that 32-bit
keyids are somehow collision-resistant.  For example:
 Perhaps GnuPG should change the default of --keyid-format from "short"
to "long"?  certainly, the 64-bit keyID itself is not as
collision-resistant as the full fingerprint, but it does raise the bar
for an attacker (and discourages users from just parrotting the 32-bit
keyid if they don't understand what they're looking at).
I think switching the default to "long" would be on balance a Good Thing.
What do other people think?

@_date: 2012-05-29 15:34:33
@_author: Daniel Kahn Gillmor 
@_subject: changing the default for --keyid-format [was: Re: getting an 
Right, which is why gpg should default to not processing/accepting v3
keys either, frankly.  The window for v3 being deprecated started long
ago.  If we expect people to rely on gpg for any sort of key management,
it ought to have reasonably safe and sane defaults.
dropping v3 unless explicitly overridden, and defaulting to displaying
64-bit keyids in the places where it must show keyids seems like it
would be a reasonable choice.
Yes, it might break compatibility with some existing docs.  Those docs
are likely to be out-of-date, and many of them may well encourage bad
practices anyway to someone who doesn't understand what they're seeing.
fwiw, i agree with Werner that we should avoid displaying keyids to
users wherever we can -- they're not human-friendly identifiers.  But if
we're going to expose them, we should be exposing them in ways that at
least make them somewhat collision-resistant.

@_date: 2012-11-05 10:04:54
@_author: Daniel Kahn Gillmor 
@_subject: [ANN] Hockeypuck: OpenPGP Keyserver 
Cool, i'm glad to hear of it.  Does this sync with any of the existing
SKS network?  I saw no mention of peer synchronization in the README or
the project page.

@_date: 2012-10-06 12:34:23
@_author: Daniel Kahn Gillmor 
@_subject: Is it possible to construct a GPG Certificate from an existing 
from the monkeysphere package, you might want to use pem2openpgp.  the
man page should explain the details.

@_date: 2013-04-01 13:46:29
@_author: Daniel Kahn Gillmor 
@_subject: How difficult is it to break the OpenPGP 40 character long 
this is a 160-bit SHA-1 digest of the public key material and the
creation date, with a bit of boilerplate for formatting.  This is not
gpg-specific, it is part of the OpenPGP specification:
  A better place to discuss issues related to OpenPGP in general is the
IETF's OpenPGP mailing list:
 It is a good idea to review their archives for fingerprints and digest
algorithms before posting, though.  Much of what you asked has been
discussed in some detail on that list already.
This is called a second-preimage attack.  I am not aware of any
published second-preimage attacks against SHA-1's 160-bit digest that
bring the computation within tractable limits.  A theoretically perfect
160-bit-long digest algorithm would require ~2^160 operations to arrive
at a particular digest.  SHA-1 is almost certainly not theoretically
perfect against this sort of attack, but does not appear to be
practically broken by anyone who is publishing about it.
the underlying material is 160 bits -- it does not need to be
represented as 40 chars.  And if the digest algorithm was known to be
weak (e.g. if it was a simple CRC), then even fingerprints 10 times as
long would not be enough.
However, for the purposes of key fingerprints in particular, SHA-1
appears to be reasonable in the near term.
For future OpenPGP drafts, there has been some discussion about moving
to a longer digest (on the IETF list i mentioned above).  Those
decisions have not reached a consensus, from what i can tell.
Predicting computing power or the state of mathematics itself 100 or
1000 years into the future seems like a dubious proposition.  Consider
the state of mechanical computation and mathematics 100 or 1000 years
ago.  Do you think that even a skilled mathematician at the time could
have predicted where we are today?
The longevity of any public key cryptosystem should probably be
estimated in years or decades at the longest if you want any confidence
in your answer.

@_date: 2013-04-02 12:45:30
@_author: Daniel Kahn Gillmor 
@_subject: Vanity Key 
Conceptually, looking for a key with a given fingerprint suffix or keyid
seems like a similar idea.
People already do this:
PS the copy of your e-mail that i received appears to be addressed with
the following header:
 To: Jay Litwyn on GnuPG-Users I'm not Jay Litwyn, but i hope you don't mind my responding anyway. ;)
Maybe your addressbook needs a tuneup?

@_date: 2013-04-04 16:56:50
@_author: Daniel Kahn Gillmor 
@_subject: Fingerprint of the subkey just created? 
the fingerprint of a subkey is actually well-defined.  I don't know the
answer to Jack's original question, but you can find the specification
for subkey fingerprints in RFC 4880:
   Jack, gpg will emit the fingerprints for the subkeys if you supply the
--fingerprint argument twice.  So you might try parsing the output of:
 gpg --list-keys --with-colons --fingerprint --fingerprint
--fixed-list-mode $PGPID
the lines that start with sub: indicate the subkey (and include creation
timestamps in field 6), and the lines immediately following them that
start with fpr: contain the full fingerprint in column 10. If you just
keep track of the most recent creation timestamp and remember its
fingerprint you could find the most recent subkey.
It's probably 2 or 3 lines of awk if you're into that kind of stuff :)

@_date: 2013-04-05 13:38:18
@_author: Daniel Kahn Gillmor 
@_subject: gpg for pseudonymous users [was: Re: gpg for anonymous users 
This is practically the definition of a pseudonym, not anonymity.
Anonymity involves trying to avoid leaving any traces of identity
whatsoever.  I really do think it's worth distinguishing between the two
cases, since they're quite different.
From WordNet (r) 3.0 (2006) [wn]:
  pseudonym
      n 1: a fictitious name used when the person performs a
           particular social role [syn: {pseudonym}, {anonym}, {nom de
           guerre}]
  anonymous
      adj 1: having no known name or identity or known source;
             "anonymous authors"; "anonymous donors"; "an anonymous
             gift" [syn: {anonymous}, {anon.}] [ant: {onymous}]
      2: not known or lacking marked individuality; "brown anonymous
         houses"; "anonymous bureaucrats in the Civil Service"
I agree with you that the WoT is not useful for people who truly wish to
be anonymous.
However, the WoT still can be useful for people who wish to establish a
It establishes a history of someone doing work and being active using
that name.  Given that it includes an e-mail address, it is effectively
globally unique (modulo problems with the DNS). If there are two such
entities, using two separate keys, that's entirely possible.  My
certification would indicate which one is the one i have come to know as
"adrelanos ".
Well, i already know a Werner Koch, and i don't think i would sign any
colliding user IDs without good reason.  If i'm dealing with User IDs
that are clearly non-global, have no difficult-to-forge corroboration
(e.g. gov't issued ID), etc, and i have no prolonged experience
interacting with someone using that identity, i'm likely to decline to
make that certification.
I said 5 years as an example, not as a magic threshold where my
confidence in someone's persistent identity kicks in.   I suspect that
each person has their own sense of this, and can make their own
decisions about when making a public statement of known identity is
warranted.  One of the nice things about OpenPGP is that there is no
requirement for everyone to have the same certification policy.
I hope it's clear that my certifying anyone's OpenPGP certificate is a
statement about who i believe uses a given name and address and what key
they use.  It is *not* a statement of political affinity, friendship, or
a technical endorsement.
I am happy to sign the keys of people with whom i have fundamental
disagreements.  My saying "this is adrelanos' key" does not say anything
about "adrelanos works for the FBI" or "adrelanos does not work for the
FBI" any more than it says "adrelanos is my friend" or "adrelanos is a
milkman" or "adrelanos babysits my children" or "adrelanos writes
awesome software" or "I can't stand that adrelanos character"

@_date: 2013-04-07 10:19:56
@_author: Daniel Kahn Gillmor 
@_subject: gpg for pseudonymous users 
But in fact, no one identifies in either way; "Enemy" and "Friend" are
relational terms, and are not identities.  Neither of them belong in the
If you want to make a statement about whether someone is your enemy or
your friend, an OpenPGP identity certification might not be the right
way to do it.
  The problem is that "adrelanos" doesn't
I think we're talking about pseudonyms, not "anonymous identities".
You seem to think that names of the form "Stan Tobias" and "Daniel Kahn
Gillmor" and "Werner Koch" are somehow more "real" names than
"adrelanos".  You also seem to think that people's identities are
immutable over time.  I'm not sure i believe either tenet is universally
true.  That's fine, and i'm not trying to convince you otherwise --
that's why it's good that we each get to have our own certification
Some people believe that names like "Daniel Kahn Gillmor" are more
"real" because of their government endorsement (e.g. via
difficult-to-forge identity papers).  I will grant that endorsement by a
government plays a significant role in my willingness to accept that a
person holds a given identity.  However, I am unwilling to constrain my
beliefs about identity to only cover government statements.  Some people
have deeply-held identities that their government refuses to certify,
and some governments are quite willing to issue fraudulent identity
papers under a variety of circumstances.  So i prefer to reserve the
right to use my own judgement, and to be able to rely on other
information besides government endorsement as well.
But let's bring this discussion back out of the metaphysical territory
of "what is the true nature of identity".   In response to adrelanos'
question, I tried to give an example of what sort of
non-government-issued evidence a cautious and open-minded individual
might consider.  What evidence are you willing to consider to establish
belief in someone's identity?
all the best,

@_date: 2013-04-08 12:45:49
@_author: Daniel Kahn Gillmor 
@_subject: The Lord of the Keys 
that's not guaranteed, i'm afraid.  each key (the primary key and each
subkey) is locked with its own passphrase.  in common practice, gpg
keeps those passphrases synchronized across a given primary key and its
subkeys, but it has to deal with the possibility that the subkeys have
different passphrases than the primary key.

@_date: 2013-04-12 15:45:23
@_author: Daniel Kahn Gillmor 
@_subject: OT [was: Re: Biggest Fake Conference in Computer Science] 
[ bizarre and off-topic background stripped ]
I understand that you have a problem with this situation, and that you
feel it is important, but it's really not relevant to the gnupg-users
mailing list.  Please stay on-topic here, so that this channel remains
relevant for the purposes of discussing GnuPG and does not drown under a
flood of unrelated-yet-important messages.
If you reply to this message, please reply to me personally, not on-list.

@_date: 2013-04-17 18:25:59
@_author: Daniel Kahn Gillmor 
@_subject: question on decryption with missing passcode 
This message suggests that there is a problem in the filesystem, not a
problem with a missing passphrase.  Do you have a copy of the file in
question?  do you know what the symmetric passphrase is supposed to be?
if so, can you try to decrypt it and provide a paste of the full
terminal transcript (see [0] for suggestions on how to do a reasonable
terminal transcript) of you doing the following commands?
 ls -l rwu.dbdump_Nov2012.sql.gz.gpg
 gpg --decrypt rwu.dbdump_Nov2012.sql.gz.gpg
you'd need to run these commands from the directory where the file is
is it possible that the file just needs to be made readable, or needs a
change of ownership?
hope this helps,
[0]

@_date: 2013-04-17 20:28:47
@_author: Daniel Kahn Gillmor 
@_subject: question on decryption with missing passcode 
on further reflection, this might also indicate that the file does not
exist in the location (or with the name) that the operator is indicating.
For example:
0 dkg at alice:~$ gpg --decrypt does.not.exist.gpg
gpg: can't open `does.not.exist.gpg'
gpg: decrypt_message failed: file open error
2 dkg at alice:~$
make sure you know where your file is, and that you are passing the
correct filename to gpg.

@_date: 2013-04-28 08:01:20
@_author: Daniel Kahn Gillmor 
@_subject: Confusion with signature digest type. 
I don't think this recommendation was made to defend against preimage
attacks.  Avoiding the use of SHA-1 in certifications in general is a
step towards defend against collision attacks, which is territory that
SHA-1 is heading into.  (i agree that if sha-1 falls victim to preimage
attacks we have much much bigger problems).
That is: if SHA-1 becomes vulnerable to collision attacks, you'd like to
update as many OpenPGP clients as possible to avoid relying on
signatures made over an SHA-1 digest.  If (when?) that transition
happens, everyone whose self-sigs are made using SHA-1 will find their
keys considered invalid by updated clients because they have no
correctly-bound User ID.
So ensuring that your self-sig uses a stronger digest than SHA-1 is
worth doing because it prepares you for such a transition.
PS MD5 *is* vulnerable to collision attacks (and has been actively
exploited [0]), and those attacks are cheaper to execute with each
passing year.  At the moment, gpg still accepts certifications made over
MD5, which arguably makes it vulnerable to compromise in the same way
that regular web browsers that accepted MD5 certs were vulnerable to the
bogus CA created in [0].
For example, if you place ultimate trust in Gene Gotimer's key
0x7833F0F5, then gpg is willing to rely on an MD5-based certification
made by that key to prove identity validity:
The only warning a gpg user gets is that this is happening (if they're
not careful) is two lines during key import that says:
 gpg: WARNING: digest algorithm MD5 is deprecated
 gpg: please see  for
more information
It does not indicate which certification(s) in particular is using MD5,
or that gpg is actually accepting that certificate when doing its WoT
[0]

@_date: 2013-08-22 10:15:23
@_author: Daniel Kahn Gillmor 
@_subject: Serpent? 
Camellia in OpenPGP is now a published part of the spec, complete with
symmetric algorithm number assignments from the IANA:
  And the best way to do get started on the path to standardization is to
provide a patch for an existing implementation (probably using an
algorithm number from the experimental range [0] that implements it, to
demonstrate feasibility.
Using RFC 5581 as a template for the proposed draft would probably be
the quickest path to getting it documented and agreed upon in an
acceptable way.
[0]

@_date: 2013-12-12 13:00:15
@_author: Daniel Kahn Gillmor 
@_subject: a maximally simplified GUI for OpenPGP (no code) 
What do people think about changing the default of show-uid-validity to yes?
I would support this change; i think it would help users of gpg to
better-understand their keyring.  and users who really don't want to see
it can always set it back to no in ~/.gnupg/gpg.conf

@_date: 2013-12-13 15:24:43
@_author: Daniel Kahn Gillmor 
@_subject: show-uid-validity default to yes 
this sounds like an argument for being willing to change the
human-readable output on the shell -- there are not many people looking
at it anyway, and most of those people are sophisticated user.
I think for a piece of critical security infrastructure, GPG has been
supporting some insecure practices for far too long.
If we want to support insecure practices as a way to allow people to
deal with outdated, insecure peers, or older, insecure stored data, we
should be expecting those users with those needs to modify the
configuration to make gpg more insecure specifically, rather than
leaving all users insecure by default.
If you're referring to a specific script, please point me to it and its
authors; i'll badger them as well; that's not a fun job, and there is no
reason you should do it solo.
If this is a general complaint (which i can easily imagine), then it
presumably relates to people who *do* use gpg from the command line
(they're actually scripting it!), and should know better.   The way to
get people to learn about it is to go ahead and improve the UI.
There's no reason that developers who do not listen to clear,
well-formed suggestions about what kind of commitments are made to an
API should get to hold the rest of the userbase hostage.
Most people do not read FAQs either. :(
thanks as always for your work on GnuPG, and for the discussion.

@_date: 2013-12-13 17:51:15
@_author: Daniel Kahn Gillmor 
@_subject: show-uid-validity default to yes 
yes, in this example, that's most likely the short path to an insecure
configuration.  I think most users don't really understand the default
trust model, and that makes it more difficult for them to use the tool
securely.  Exposing the UID validity is a step toward making the trust
model calculations more visible to users, which is necessary for

@_date: 2013-12-14 13:28:25
@_author: Daniel Kahn Gillmor 
@_subject: Revocation certificate for sub key? 
If you are comfortable with either the GNUPGHOME environment variable or
gpg's --homedir option, you should be able to make what you're looking for:
Make a new temporary gnupg homedir.  import your primary secret key and
your subkey into that homedir.  from that homedir, take Hauke's advice
and then export the key to a text file someplace safe.  this text file
will contain the revocation for the subkey.  delete/purge/get rid of the
temporary homedir.
if/when you need to revoke your subkey, you can just gpg --import the
stored text file, and then --send-key to push it to the public keyservers.
does this make sense?
PS your e-mail client appears to be breaking message threading (no
for your quoted text (i had to re-insert that hauke was the source of
the good advice above).  This makes it more difficult for people to
carry on a conversation with you over e-mail.  Please consider fixing
your client or choosing a different one that supports proper message
threading and attribution.  thanks!

@_date: 2013-12-16 15:35:53
@_author: Daniel Kahn Gillmor 
@_subject: X.509 certificates for https://gnupg.org [was: Re: Another step 
Regardless of how you feel about the CA cartel in general, StartSSL is
not the only member of the cartel offering gratis certs, particularly
for well-known free software projects  (Also, as a business in Israel,
StartSSL is the target of an ongoing international boycott due to
Israeli domestic policy -- Other members of the CA cartel that offer gratis certificates
(particularly for free software projects) include:
          A not-insignificant cost for all of this stuff (regardless of whether
the cert itself is gratis or not) is understanding and compliance with
the terms of service of the particular CA, keeping the certificate
up-to-date, and figuring out which silly rules each CA happens to impose
(for example, some CAs appear to only issue certs over the end-entity's
RSA key if it has 2048-bits or 4096-bits, but they will not accept any
keylength in between; other CAs require certain fields to be present in
the CSR that are meaningless, but must be filled in with "NA" (meaning,
presumably, 'not applicable'), and so on).  Some gratis certificates
become non-gratis after the first year, and some CAs change their
policies from year to year as well.  Some of these issues may be less
bad when dealing with CACert.
I'd argue that none of these cartel members are actually any more
reliable than CACert, but it may still be useful to get a certification
from a cartel member just because of the existing lock-in situation.  In
the meantime, other mechanisms (like DANE or monkeysphere) can provide
parallel certification paths for people who do not want to rely on the
I'm happy to see more advocacy for stronger crypto by default for as
many public-facing services as possible.  But i don't think we should be
advocating for use of a single vendor, particularly one in the dominant
CA cartel.
Werner, if i can help with configuring or maintaining the web server for
gnupg.org to address some of these issues, please let me know.

@_date: 2013-12-17 10:07:11
@_author: Daniel Kahn Gillmor 
@_subject: Another step towards crowdfunding 
If the expected volume is low-ish (e.g. no more than once a week or so)
i think that would be a great thing to do.

@_date: 2013-12-17 11:09:33
@_author: Daniel Kahn Gillmor 
@_subject: encryption algorithm 
Hi Matt--
OpenPGP has "algorithm agility", meaning that it's possible to use
different encryption algorithms at different times in the same
cryptographic framework.  encrypted OpenPGP messages are generally also
"hybrid" messages -- that is, the bulk of the message is encrypted with
a symmetric encryption algorithm (using a random key), and that random
key is encrypted to the recipient's public key using an asymmetric
If you want more details, you might be interested in the list of
symmetric key algorithms:
 or possibly the asymmetric algorithms:

@_date: 2013-12-17 12:52:16
@_author: Daniel Kahn Gillmor 
@_subject: X.509 certificates for https://gnupg.org 
I think it depends on what flavor of IE you're using (and what version
of the underlying OS you're using as well).  The version of schannel in
Windows XP doesn't support ECDHE (or AES(!)) at all, and i don't think
any version of schannel supports DHE-RSA if i'm reading these tech
reports correctly:
Cipher Suites in Schannel
 Schannel Cipher Suites in Windows Vista:
 TLS Cipher Suites in Windows XP and Windows Server 2003:
Secure Sockets Layer Protocol (v2 and v3) in Windows XP and Windows
Server 2003:
If you want to be able to support these systems, you may need to add a
low-priority "Lowest Common Denominator" ciphersuite to match them.
Sadly, that seems likely to be  TLS_RSA_WITH_3DES_EDE_CBC_SHA, unless
you somehow can score a DSA certificate for the service as well (since
TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA seems to be the only PFS ciphersuite
supported by XP's native TLS stack).  I've never even tried to get a DSA
certificate for a web server from any member of the CA cartel.  Have you?
If you want to discourage clients from picking the
lowest-common-denominator ciphersuite unless it's the only one they
support, you should probably set "SSLHonorCipherOrder 1" in your pound
Thanks, i've forwarded that to

@_date: 2013-12-17 15:57:54
@_author: Daniel Kahn Gillmor 
@_subject: encryption algorithm 
Sure, and so-called export ciphers for TLS are probably effective
against the overwhelming majority of attackers too.  But we recommend
people disable export ciphers and prefer stronger algorithms, because
the goal of cryptographic tools is to help as many people as possible,
even when attacks are rare.  so strong algorithms by default is a good idea.
I'm not sure how you get this claim from these reports, but that's not
what it looks like to me.  For example, ECRYPT 2012's report sees
2432-bit RSA as equivalent of 112 bit symmetric cipher, which it claims
is acceptable for ?20 years.  Please see section 7.2:
  For ?30-year protection, the ECRYPT authors recommend the equivalent of
128-bit symmetric ciphers, which they say corresponds to 3248 bit RSA
(see the table on page 30).
So according to ECRYPT's recommendations from two years ago, the current
GnuPG default RSA key size is above the "legacy standard level" (?10
years) but below "Medium Term protectsion" (? 20 years).
If you are generating a key whose private key will be stored on a smart
card, you should clearly generate a key that will fit your smartcard.
The smartcard does secret key work (decryption, signing).  None of the
public key operations (signature verification, encryption) will be done
on the smartcard, so smartcard constraints need not be a concern there.
So users of constrained devices can choose their own tradeoffs for
secret-key operations (decryption, signing).  What about public-key
operations?  For signature verification, an implementation on a
constrained device that interacts with a human could simply defer
signature validation until a human decides the tradeoff of verifying the
signature is worth the computation cost.  For encryption, users would
need to be made aware of the costs of any additional message recipient.
So I don't think constrained devices are a good argument for weaker
default keys, though clearly the smartcard case is a good argument for
gpg still being able to create and handle those keys.
According to ECRYPT 2012 (same report referenced above), RSA 1024 falls
in at the equivalent of about 73 bits of symmetric cipher.  According to
the authors, this is  "Short-term protection against medium
organizations, medium-term protection against small organizations", not
"a First World government".
While i don't agree with adrelanos' entire draft, i do agree that the
default key size for gpg should be larger.  A default key size of 3072
or 4096 bits for RSA keys sounds reasonable to me.
I also think that the default certificate digest algorithm should be
SHA-256 instead of SHA-1 (see section 10.2 of the ECRYPT document above
for reasons why we should deprecate the issuance of signatures over
SHA-1).  Users stuck with OpenPGP implementations unable to process
SHA-256 that also rely critically on the network of identity
certifications known as the "web of trust" (do such users actually
exist?  That intersection seems likely to be vanishingly small) may need
to upgrade.  Users who can't process SHA-256 certifications but willing
to manually indicate which keys are valid manually/locally (or who
manage a "trusted" keyring) should still be able to carry on as before.
We do not do the users of GnuPG any favors by continuing to generate
weaker-than-expected keys and certifications by default.

@_date: 2013-12-17 19:07:42
@_author: Daniel Kahn Gillmor 
@_subject: encryption algorithm 
I never attributed RSA-1024 to you: i'm merely pointing out that good
enough for "virtually all users" and "virtually all purposes" is the
wrong way to select choices that we want to cover the most vulnerable
Thanks for the clarification.  I get this sort of thing screwed up
myself sometimes too, so i'm glad to be the one setting the record
straight for once :)
ECRYPT has some pretty decent conceptual frameworks, engineering, and
mathematics to explain how they arrived at their strength equivalences.
 Chapter 6 has details.  None of us can predict where the mathematical
advances will happen next, of course, but these are hardly arbitrary
"opinions" pulled from thin air.
Arguably, it's probably also worth being more skeptical about guidance
coming from NIST specifically, since they are known to have taken advice
from the NSA, and the NSA is now known to have deliberately misused
NIST's position of trust.  This is a bad situation, but Werner's earlier
line today about "a direct line to Maryland" seems apposite.
If you're into figuring out which is the "outlier opinion" and assessing
these things by conensus of authorities, i invite you to look at table
3.1 on page 22 of the ENISA algorithm report. NIST and SECG equate 112
to 2048-bit RSA.  Lenstra and the IETF (RFC 3766) and ECRYPT all suggest
that 2048-bit RSA is weaker than 112-bit symmetric ciphers.  NIST and
SECG (in which NIST played a prominent role) hold down the low end of
the scale.
Regardless of which group is "right", none of these authorities believe
that 2048-bit RSA is in the range of a 128-bit symmetric cipher, just
112-bits at most.  Do we care about the idea that a cryptosystem is as
secure as its weakest link?
I note that we don't generally support any symmetric ciphers with less
than a 128-bit key (3DES with keying option 2 would use 112-bits -- but
GnuPG uses keying option 1: 168 bits, derived from 192 bits).  If we
want to "even out" the crypto so that no one part is clearly weaker to
attack than the others, we ought to to increase our RSA keylengths by
default.  RSA keys are currently the weakest link according to any of
the authorities anyone has cited in this discussion thus far.
Additionally, since breaking a long-term asymmetric key can effectively
decrypt all messages encrypted to that key, breaking the RSA key has
more value to an attacker than breaking any single symmetric cipher.  So
if there is going to be a strength difference, i'd expect it the other
way around.  A reasonable hybrid cryptosystem like OpenPGP should make
the asymmetric part *stronger* than the symmetric part, since it
presumably is a more valuable target anyway.
Finally, in the face of adversaries who possess incremental (not
catastrophic) mathematical or computational advances beyond what we know
about, increasing keylength beyond what we think is strictly needed is a
reasonable defense.  In
 "it's pretty easy to stay a few steps ahead of the NSA
by using ever-longer keys. We're already trying to phase out 1024-bit
RSA keys in favor of 2048-bit keys. Perhaps we need to jump even further
ahead and consider 3072-bit keys."  The next day, Schneier announced his
new 4096-bit RSA key:
Do we want the asymmetric key length to be the weakest link for users of
GPG's default choices?
I think i've made it abundantly clear that i don't think it's trivial
for anyone to break a 2048-bit key.  My arguments here are not about
protecting my e-mail contents from a hobbyist attack.  I'm interested in
trying to build cryptographic defenses against powerful adversaries.
While we the systems programmers are choosing default key sizes for the
overwhelming majority of users, we could put the onus on those who need
*less* security (due to constrained devices or terribly-old
interoperability concerns) to explicitly weaken their own tools, rather
than requiring people who need stronger security to become cryptographic
experts and figure out what needs to be done.  If someone is choosing to
use OpenPGP to secure their messaging or data, whether for
confidentiality, integrity, or authenticity, the tools should offer
strong security choices against powerful attackers, by default.
The other two objections to stronger defaults that have been raised in
on this list today are:
 0) the cryptosystem isn't the weakest link for most people, and
 1) we don't want huge keys because they're inefficient
(0) is clearly true, and it *should remain true*.  That's the whole
point of using cryptography, not to leave open the possibility that
someone who happens to have more compute power or better math can
decrypt your messages or impersonate you without bothering to do any of
the other stuff.  That is, the security of my data should depend on my
operational security, *not* on my cryptography.  The cryptography should
be standard, background stuff.
So (0) is not an effective argument for why we should have default
public key lengths that are widely acknowledged to be weaker than the
symmetric keys we routinely use.  The goal is to avoid having the math
be the weakest link, for any potential attacker.
As for (1), i'd find it easier to accept claims about efficiency and
performance concerns if gpg was plausibly efficient or high-performance
in other realms.  Two obvious areas come to mind where efficiency and
performance have not historically been a priority for gpg: key selection
from even medium-sized keyrings, and the programmatic use of gpg as a
backend to other tools.  GPG's subprocess model, coupled with its need
to do linear scans of a key ring each time any asymmetric mechanism is
triggered leads to seriously low performance in many contexts.  The
performance difference between, say, a single 2048-bit RSA operation and
a 3072-bit RSA operation (NIST's 128-bit-equivalent) is small compared
to the cost of pulling the keyring off the disk, parsing all the keys,
selecting the right(?) key, evaluating the trust model, etc.  If it's
worth arguing that 3072-bit is too expensive to be the default, then we
probably need major work in giving gpg a plausible library (not
subprocess) interface or proper indexed key storage (which i hear is
coming for 2.1, and i'm quite happy about that, though i have yet to get
to play with it).  GnuPG and gcrypt's underlying crypto primitive code
has also never been the fastest code, even among the free software
variants available, and Werner has (rightly, i think) typically declined
to prioritize speed over other development goals (like information
security).  I'm excited to see the recent speed improvements in gcrypt,
though.  As gcrypt's speed improves, maybe we can take advantage of the
faster speeds to switch to stronger asymmetric keys and message digests
by default as well?

@_date: 2013-12-17 21:20:49
@_author: Daniel Kahn Gillmor 
@_subject: encryption algorithm 
from ?20 years to ?30 years, if we believe ECRYPT.  Of course it's not a
forever solution.  It's still a significant improvement, and its one we
can afford.
sigh.  "weakest link" analysis is clearly useful, and just as clearly
not the only analytic tool to use.
I argued: right now gpg's weakest links are the default RSA key length
and the digest used in cryptographic certification.  Let's improve them
Your argument in response seems to be "whoa! if we improve them all the
way to the symmetric cipher length it would be computationally infeasible!"
This is not an argument for not improving the weakest link.  I agree
with you that RSA doesn't scale well computationally as we approach
equivalence to 256-bit symmetric ciphers.  I'm not suggesting we take
that step.
so, how much weaker are you ok with?  3072-bit keys are functional and
available now, and even according to NIST's standards (i'm glad you
still feel they're trustworthy, even in the context of them having
issued a deliberately bad RNG, and their keylength recommendations being
weaker than everyone else's!)
Of course when ECC is available, we may want to shift to ECC.  But ECC
is not currently available, and even when it becomes available, RSA will
be the dominant key type for years.
This is a terrible argument for not improving the default RSA key length
today.  It costs very little to change the default, and it signals the
user community that we take the existence of well-funded adversaries
[from your other followup]
We're engineers talking about building safety and security
infrastructure here.  Of course we may not get it right; bridges built
with what they thought was a 200% safety margin have collapsed due to
unforeseen factors.  But we can make sure that we build in what we
currently believe is a safety margin beyond what we believe anyone
*should* need, and it is the responsible thing to do.  Targeting exactly
at the 99% percentile is irresponsible when we can safely and reasonably
To be clear: i'm not advocating for moving to 15000-bit or 30000-bit RSA
keys by default.  I'm advocating having a baseline
128-bit-symmetric-equivalent security by default, on all aspects of the

@_date: 2013-12-17 21:26:00
@_author: Daniel Kahn Gillmor 
@_subject: Another step towards crowdfunding 
I believe the answer for public-key-pinning is the same as for HSTS.
That is, if you've already implemented the possible footgun that is
public-key-pinning on your web site via the standard HTTP headers, and
you have demonstrated that it works for you, you can send patches to agl
(ironically, src.chromium.orgdoesn't appear to signal support for safe
TLS negotiation via RFC 5746, sigh)

@_date: 2013-12-17 23:11:38
@_author: Daniel Kahn Gillmor 
@_subject: encryption algorithm 
Dual_EC_DRBG was widely acknowledged as bad even when it was released.
It's bad simply because it's far slower than other comparable RNGs that
were standardized at the same time.  I did *not* claim it was
deliberately backdoored, and i certainly didn't claim it was backdoored
by NIST.
I happen to love what NIST stands for (i'm a standards nerd because i'm
a communications nerd, and i care that when i say "1 meter", you know
what i mean), and i want to be able to trust them.  But we do know that
a powerful agency who is *not* NIST has been deliberately attempting to
fiddle with the recommendations generated by this standards body.
I'm not slandering NIST to say that Dual_EC_DRBG is bad.  But it is
indeed bad.  It's bad because it's particularly slow, and it's bad
because it *could be* backdoored if someone knows a special key that the
rest of us don't know.  These are not mistakes that standards agencies
should make, though of course any organization of people is bound to
make mistakes, especially ones that have people deliberately trying to
make them make mistakes.  NIST has acknowledged that Dual_EC_DRBG was a
bad standard by withdrawing it.
All the more reason to change the default keylength now, no?
And if that comes up, we have an answer to that: "ECC is now available,
and it wasn't before."
But honestly, when the first version with ECC support is released, i
strongly doubt gpg will switch to that as the default public key
algorithm immediately, for the same interoperability concerns you're
raising right now.    So if gpg 2.1 releases in 6 months (i'm making
this date up, of course), how many months will it take for the default
algorithm to be changed to ECC?   What about for the old branches
(1.4.x, 2.0.x) that won't support ECC?
What i'm saying is: even if you believe that somehow it would be bad to
change defaults twice within a year of each other (which i don't), i
don't believe that we will have ECC as the default public key type
within a year, certainly not for the 1.4 branch.
It has; let's keep it up.
Come on now, what does this hyperbole do for your argument?  I'm not
asking for airplane tickets that cost a million dollars.  I'm asking for
a minimum level of 128-bit-symmetric-equivalent security by default.  Do
you really think that's the equivalent of a million dollar airplane ticket?
Have i asked for perfection?  I feel like you're arguing with someone
else here. I even wrote (in the very paragraph to which you are
responding) "Of course we may not get it right".
I'm asking for a strong baseline set of defaults with a reasonable
security margin based on current knowledge.  This isn't perfection, it's
(fallible, human) engineering.

@_date: 2013-12-18 02:18:05
@_author: Daniel Kahn Gillmor 
@_subject: encryption algorithm 
Sorry, but NIST does face a crisis of trust, particularly in the area of
cryptography, whether either of us wants that to happen or not.  I don't
think we should pretend otherwise.  NIST certainly isn't pretending
otherwise; it is taking the situation seriously:
Because it takes a long time for these fixes to trickle into downstream
distributions and reach wider adoption, and longer still for the users
of those systems to adopt new stronger keys and integrate them into
their workflow and their certification networks.
You don't plant a tree now because you want fruit tomorrow; You plant a
tree now because you want fruit in 3 years.
People are already rewriting tutorials and manuals and standard
operating procedures.  They're doing it because gpg isn't updating the
defaults.  That work is under way right now, it exactly in the ways that
you've expressed frustration about on this thread, because the authors
of manuals and tutorials want to provide their users with a strong
safety margin, particularly in light of recent disclosures about
powerful attackers who have access to large amounts of traffic and
outlandish compute power.
The best manual would say "Use a reasonably up-to-date version of GnuPG,
and use the defaults.  They are strong, and functional, and provide a
security margin that everyone can rely on."  That wouldn't require much
updating if the defaults track the current cryptanalysis and
publicly-acknowledged threats.
sigh.  Of course i could do this, but i don't want to, because i would
rather that gnupg have a set of defaults with a forward-looking safety
margin built in to begin with.
Except that i'm not asking for anything that has extreme costs.  There
are larger costs involved with just scanning and parsing a keyring with
a few dozen keys than in the difference between a 2048-bit RSA operation
and a 3072-bit RSA operation.
2048-bits is *at most* 112 bits of keyspace, depending on whose analysis
you rely on.
ENISA and ECRYPT both explicitly recommend 128 bit equivalence (but not
112-bit) as a "Good, generic application-indep. recommendation" (ECRYPT)
and "secure for future use" (ENISA).  We know that modern machinery can
do this level of work without serious drawbacks, and we know that it's
possible to change the defaults for gpg.
Looking past RSA keysize, the default certification mechanism uses
SHA-1, which has only 80-bits of protection against collision attacks
(and is known to have cryptanalytic results that bring this figure down
to the mid 60s).  Fortunately, preimage attacks on SHA-1 appear to still
be out of reach, and it's harder to exploit the cryptosystem as a whole
with a collision attack than it would be with a preimage attack.  But
effective collision attacks possible against OpenPGP certifications
could still be devastating, since users are signing data provided almost
entirely by a potential attacker.  Switching to a widely-supported
stronger algorithm like SHA-256 by default for OpenPGP certificates
would address this even weaker link.
Look, i'm *not* a bitsize fetishist.  I'm not advocating for 512-bit
equivalent security everywhere, or 30Kbit RSA keys, or anything like
that.  I'm reading the same standards you are, aware of the same news
you are, and trying to make plans for what we both know is a long
upgrade cycle so that we don't have a bunch of users whose security is
compromised in the mid-term future.  If you want to continue to cite the
weaker of the public standards, and ignore the advice in the stronger
ones, and argue that we don't need to upgrade now because no one has
demonstrated any attacks publicly, i guess that's your call.
I want gpg to take the lead on this, to make it clear that we continue
to take our users' information security seriously, and provide a healthy
safety margin given our long-term stability and commitment to maintenance.
We can't fix any user's operational security if it's terrible, but we
can make sure that anyone who uses a reasonably modern version of gpg
won't be burned by the crypto itself, even if they have a large
organization as an adversary.

@_date: 2013-12-20 15:30:31
@_author: Daniel Kahn Gillmor 
@_subject: Import "Raw" RSA Secret Key? 
I'm always happy to have people read the source code, but you could also
just "apt-get install monkeysphere" and read the pem2openpgp manpage. ;)

@_date: 2013-12-26 14:24:36
@_author: Daniel Kahn Gillmor 
@_subject: Printing PGP Businesscard 
Please use a QR code that contains the full fingerprint (no spaces)
prefixed with OPENPGP4FPR: -- this is the mechanism used by the
monkeysign project and other mechanisms:
  Most humans don't really cope well with long strings of hexadecimal or
any other high-entropy arbitrary data.
Using machine-readable QR codes makes it easy for humans to feed the
data directly into their trusted machines.

@_date: 2013-12-26 15:27:39
@_author: Daniel Kahn Gillmor 
@_subject: Printing PGP Businesscard 
As long as you have a separate line for the fingerprint, and that line
is prefixed with "OPENPGP4FPR:", then monkeysign should be work fine
with your QR code.

@_date: 2013-12-27 20:03:31
@_author: Daniel Kahn Gillmor 
@_subject: Printing PGP Businesscard 
[rearranging top-posted-ness for chronological sanity]

@_date: 2013-02-07 11:54:46
@_author: Daniel Kahn Gillmor 
@_subject: influence of signature type on trustdb 
one reason to be wary of any changes to the trust model are that most
humans i've talked to about this (including ones who have spent a decent
amount of time thinking about it) are often surprised even by the
current standard trust model.  Sometimes this is due to not thinking
through the consequences of their choices, sometimes it's due to not
really understanding how the standard trust model actually works.
Making the trust model even more complicated without improving
comprehensibility to the user seems like trouble.
PS i actually think that the standard trust model is decent, though i've
proposed a few changes to it myself.  I think anyone interested in
improving the trust model should probably try to think through how to
make an improved user interface for people who are trying to inspect the
trust model.  This is a hard problem.  But reinforcing good user
intuitions about what's going on would probably be a bigger win than an
algorithmic adjustment (and might make algorithmic adjustments easier in
the future).

@_date: 2013-02-20 17:40:53
@_author: Daniel Kahn Gillmor 
@_subject: Piping tar into gpg 
if you want to pipeline like this, i don't think you want the "f" flag
for tar.
I also don't think you're using find and tar together properly -- i
think you want xargs in the mix.
here's a functional example, along with a verification step (i'm using
gpg-agent to prompt for the symmetric passphrases):
0 dkg at alice:/tmp/cdtemp.cD3zXc$ mkdir t
0 dkg at alice:/tmp/cdtemp.cD3zXc$ echo test > t/a
0 dkg at alice:/tmp/cdtemp.cD3zXc$ echo whatever > t/b
0 dkg at alice:/tmp/cdtemp.cD3zXc$ find t -type f -print0 | xargs -0 tar
czv | gpg --symmetric > foo.tgz.gpg
0 dkg at alice:/tmp/cdtemp.cD3zXc$ gpg --decrypt < foo.tgz.gpg | tar tz
gpg: CAST5 encrypted data
gpg: encrypted with 1 passphrase
gpg: WARNING: message was not integrity protected
0 dkg at alice:/tmp/cdtemp.cD3zXc$

@_date: 2013-02-24 15:58:49
@_author: Daniel Kahn Gillmor 
@_subject: options files 
Some of us are collecting "best practice" suggestions over here:

@_date: 2013-02-25 22:51:36
@_author: Daniel Kahn Gillmor 
@_subject: Questions about OpenPGP best practices 
You should use hkp:// instead of   Using http:// implies a
simple web request (e.g. , while hkp:// implies the structured key
lookups keyservers are known to use.
and you may want to use ha.pool.sks-keyservers.net (this is a
high-availability pool -- only keyservers that operate behind HTTP
reverse proxies are included.  this mode of operation is considered a
best-practice for sks keyserver operators).
i agree with grant olson that there is no need to double-encrypt.  you
may also be interested in using paperkey to generate a minimized chunk
of data for offline backup:
  yes, this host is certified by its operator (Kristian Fiskerstrand) via
the OpenPGP web of trust.  one way to verify it is with the monkeysphere
validation agent (msva-perl, in debian) and the monkeysphere firefox plugin.
sks-keyservers.net is not a keyserver itself -- it is the site that
describes the various pools.

@_date: 2013-02-25 23:10:58
@_author: Daniel Kahn Gillmor 
@_subject: Questions about OpenPGP best practices 
which docs suggested that should work?  what operating system are you
expecting it to work for?
if you're using debian or a debian-derived system like mint or ubuntu,
and you want to add a CA to the "system trusted root store", you
actually want to add the file with a .crt extension (not .cert) to
as the superuser.
Please read:
 /usr/share/doc/ca-certificates/README.Debian
on your local system for more details.
gpg's keyserver-option ca-cert-file's default for hkps is dependent on
the TLS library libcurl linked to from libcurl in the handler in
libgnutls26, which currently has no default root CAs.
newer versions of gnutls have a standard default root CA set that maps
to the system provided above by ca-certificates.
If and when gnupg-curl builds against libgnutls28-dev (the next major
API change in gnutls), it should adopt those changes.

@_date: 2013-02-25 23:50:40
@_author: Daniel Kahn Gillmor 
@_subject: Questions about OpenPGP best practices 
hmm, i don't use ubuntu myself, but i believe that documentation is
wrong, particularly this section:
  That page also seems to loosely imply that secret keys and X.509
certificates generated by one implementation (GnuTLS's certtool) won't
be interoperable with other implementations (e.g. OpenSSL).
I don't think this is the case, and if it is, i would hope it would be
reported as a bug.
this is pretty off-topic for gnupg-users now, but it would be great if
someone who uses ubuntu would fix that page.
No, there are multiple system-wide solutions.  In the long term, for
traditional X.509 certificate verification, curl-gnutls will hopefully
be linked against libgnutls28, which will use its system root CAs by
in the nearer term, you could also use msva-perl with hkpms (if you want
to verify remote hosts via the OpenPGP web of trust).
and you can also modify /usr/share/gnupg/options.skel to change the
default options for new accounts (though i think this won't have an
effect on any existing GnuPG homedirs).

@_date: 2013-02-26 00:14:13
@_author: Daniel Kahn Gillmor 
@_subject: Questions about OpenPGP best practices 
please report this to the sks-devel list, where Kristian has been
supporting these pools.  I think he would appreciate hearing about the
problems you're describing:
 SKS development list If you could set "keyserver-options debug" in ~/.gnupg/gpg.conf that
might provide you with more detailed output as well.
If your definition of "works" includes staying well-synced with the
strong set, pgp.mit.edu does not have a great record of working.
Keyservers need to stay up-to-date to be useful.

@_date: 2013-02-26 10:36:38
@_author: Daniel Kahn Gillmor 
@_subject: Questions about OpenPGP best practices 
This is not correct.  As noted on the web site [0], the public key
associated with the X.509 certificate can be verified through the
OpenPGP web of trust.  It is certified by Kristian's own personal key.
If you know Kristian's personal key, you can verify the web site's
certificate on a debian system by using the msva-perl and
xul-ext-monkeysphere and iceweasel packages.
[0]  and

@_date: 2013-01-01 21:02:33
@_author: Daniel Kahn Gillmor 
@_subject: Obtain a signature ID with only a sig file? 
If you're talking about the "SIG_ID", then i don't think that's
possible.  According to the DETAILS file
(/usr/share/doc/gnupg/DETAILS.gz on debian-ish systems):
And you can't have a signature that's "verified okay" if you don't have
the data that was signed, since the OpenPGP signature block doesn't
contain the digested data itself (v3 data signatures contain the two
leftmost octets of the digest, but that's certainly not enough to
calculate the SIG_ID).

@_date: 2013-01-02 13:50:10
@_author: Daniel Kahn Gillmor 
@_subject: [Enigmail] Problem with automated decryption of encrypted drafts? 
Bug reports or suggestions about pinentry behavior should probably go to
a gnupg list (i've cc'ed gnupg-users here, please follow up appropriately)
Do any gnupg contributors have suggestions about the "fails to cache my
'cancels'" concern Sini raised above?  I'm not sure how the pieces could
fit together to improve the user experience without breaking
expected/desired behavior in other contexts.

@_date: 2013-01-02 14:36:22
@_author: Daniel Kahn Gillmor 
@_subject: Obtain a signature ID with only a sig file? 
this does not produce the sig id.  it produces the key ID of the issuer
of the signature, which is a different thing.

@_date: 2013-01-05 14:26:59
@_author: Daniel Kahn Gillmor 
@_subject: gnupg not working with RHEL 4 
GnuPG is software for working with OpenPGP material (keys, signatures,
and encrypted messages).  Newer versions of GnuPG will continue to work
with pre-existing OpenPGP material.
This means that you should not need to generate another OpenPGP key just
because your version of GnuPG was upgraded.  Your existing OpenPGP key
should continue to work.

@_date: 2013-01-08 17:21:58
@_author: Daniel Kahn Gillmor 
@_subject: embedded  public key in signature as in smime. 
Not that i know of.  Why do you think this would be useful?
You could do all of this within the existing OpenPGP specification, but
to make it actually useful (and not just bloat your signatures in ways
that no one else bothers to take advantage of) you might want to modify
GnuPG a bit.
Here are some thoughts on how you might approach it if you think this is
a worthwhile goal.
OpenPGP notations: To send this sort of thing, you'd just need to pick a standard name for
the notation, and use gpg's --sig-notation argument in some reasonable
way.  Reading gpg(1), it seems like you might want to extend the
%-escaping to make some code (e.g. %X) include the full key in some format.
That's just the sending side.  then you'd have to take care of the
receiving side.
If you wanted gpg to interpret something like this automatically, you'd
need to consider the concern that now the previously read-only activity
of evaluating a signature has side effects that might modify your
keyring.  This is has some of the same issues (except for the "web bug"
concern) as gpg's "--keyserver-options auto-key-retrieve" option, as
well as "--verify-options pka-lookups" though, so it has some precedent
in the existing codebase.
So to extend gpg, you might add some other --verify-options directive
like import-embedded-key-notation.
make sense?

@_date: 2013-01-16 11:54:33
@_author: Daniel Kahn Gillmor 
@_subject: Problem with keys 
I note that your key 0x46EEEA4C06CD1637 is a bit unusual in that its
subkey is marked as signing-capable.  with the default gpg --gen-key
creation, the primary key is usually marked as capable for signing and
certification, and the subkey is marked as just encryption-capable.
how did you create this key?
Despite it being unusual, it's entirely reasonable and within the
OpenPGP spec to have a signing-capable subkey.
You should tell mpex.co that their system needs to support
signing-capable subkeys.
Feel free to point them to this discussion, and to encourage them to ask
here if they're unclear about what that means or how they might do so.
no, your primary key is not offline unless you've taken steps to put it
offline (you would know if you had done so).  Hauke was making a
suggestion of something else you could do.

@_date: 2013-01-16 21:48:44
@_author: Daniel Kahn Gillmor 
@_subject: Problem with keys 
i'm afraid i don't know what "the normal circumstances" are for MacGPG

@_date: 2013-07-11 17:46:47
@_author: Daniel Kahn Gillmor 
@_subject: charset weirdness with non-ascii User IDs 
Digging this old message up as i try to do some triage.  i don't think i
ever heard a response about this.
I'm still seeing the same problem, only with some UIDs and not others:
0 dkg at alice:/tmp/cdtemp.fre2o5$ LANG=C gpg --keyserver keys.mayfirst.org --search ='Andrew Lee (???) '
gpg: searching for "=Andrew Lee (?????) " from hkp server keys.mayfirst.org
(1)	Andrew Lee Keys 1-1 of 1 for "=Andrew Lee (???) ".  Enter number(s), N)ext, or Q)uit > q
0 dkg at alice:/tmp/cdtemp.fre2o5$ LANG=C gpg --keyserver keys.mayfirst.org --search ='Antoine Beaupr? '
gpg: searching for "=Antoine Beaupr?? " from hkp server keys.mayfirst.org
gpg: key "=Antoine Beaupr? " not found on keyserver
0 dkg at alice:/tmp/cdtemp.fre2o5$ I've now reported this as:
 Any ideas?
  --dkg

@_date: 2013-07-12 10:31:16
@_author: Daniel Kahn Gillmor 
@_subject: charset weirdness with non-ascii User IDs 
Yes, they do.  they also both work fine if i use my standard locale
(en_US.UTF-8), and don't set LANG=C.
I think this is only an issue when searching for non-ASCII User IDs
(i.e. User IDs that use some UTF-8 characters outside of the ASCII
range) when the locale is not UTF-8, and even then, it's only for *some*
non-ASCII User IDs.
Very odd.

@_date: 2013-07-16 10:58:12
@_author: Daniel Kahn Gillmor 
@_subject: encrypting multiple files into a single output file 
what is the format of the archive you were used to creating with PGP?
Are you talking about PGP's "self-decrypting archive" format?
Or some other format?  If you're not sure about the details, can you
send a small example archive (containing non-sensitive material,
obviously) to the list, or to me privately?

@_date: 2013-07-16 11:24:29
@_author: Daniel Kahn Gillmor 
@_subject: encrypting multiple files into a single output file 
Hi Ira--
I don't have PGP, so i still don't know what the resultant file format is.
I did find this man page description (the X.509 certificate for the web
site is expired):
but it doesn't describe the structure of the archive.
could you send me (privately) one such archive with two small,
non-sensitive text files in it?
You can encrypt the archive to me using my key by fingerprint, after
first fetching it from the public keyservers:
 0x0EE5BE979282D80B9F7540F1CCD2ED94D21739E9

@_date: 2013-07-24 10:13:52
@_author: Daniel Kahn Gillmor 
@_subject: Multiple email addresses - any alternative to ask everyone to 
While i agree with Einar that signing three keys isn't a big difference
from signing one key with three user IDs, I will note that if you have
three separate keys, i (as one example) am less likely to be willing to
rely on your certifications.  That is, i'm less likely to "trust" your
keys (which is quite a different thing than signing them) even if i
believe you tend to make reasonable certifications.
DISCLAIMER: I do not know Einar at all and have no way of assessing his
reliability as a certifier; therefore would not assign any non-null
ownertrust to his keys anyway. i'm talking here about a hypothetical
situation where i had some existing reason to be willing to partially
rely on einar's OpenPGP certifications.
My reluctance to rely on a certifications from a user with several keys
is due to GnuPG's trust model; I rarely (if ever) assign full ownertrust
to other people's keys.  I usually mark other people's keys with
marginal ownertrust if i think their certifications are reasonable.
GnuPG will then consider a key+userid combination as "valid" if three
marginally-trusted keys have certified it.  If you control three keys,
and i mark them all as marginally-trusted, then i've effectively granted
you full ownertrust.
So i'm left with a few choices:
 0) go ahead and grant you full ownertrust on all your keys anyway, if
i'm fine with you having full ownertrust
 1) grant marginal ownertrust on all your keys and hope you don't
triple-certify anyone else's key+userid pair to take advantage of the
 2) grant marginal ownertrust on just one of your keys, thereby
instructing GnuPG to ignore certifications from the other two (in this
situation, i hope that you actually *do* triple-sign every key+userid
you verify because that way i'll get the maximum reach in my set of
validated OpenPGP certificates).
 3) do not assign any ownertrust to your keys; your certifications will
not be useful to me in this scenario.
I don't think any of these situations are horrible, but they do exclude
the (otherwise more-likely) situation where i think "oh, Einar does
reasonable certifications", and just grant you marginal ownertrust and
be done with it.
Have you thought about how you plan to certify other people's keys and
user IDs while operating with three separate keys?

@_date: 2013-07-31 10:24:39
@_author: Daniel Kahn Gillmor 
@_subject: "Certify" only master key 
Note that if you have access to the secret key material of the primary
key in an OpenPGP certificate  (what you're calling the "master key"),
there is nothing stopping you from reissuing the certificate itself with
different usage flags set.
So while you can omit usage flags on the primary key as guidance for
other people, that omission does nothing to protect you against an
attacker who manages to compromise your primary key.

@_date: 2013-07-31 16:46:34
@_author: Daniel Kahn Gillmor 
@_subject: gpg use in Debian popcon 
hi Bill--
thank you!
Maybe you want the --no-options flag?
 --no-options
    Shortcut for --options /dev/null. This option is detected before
    an attempt to open an option file.  Using this option will  also
    prevent the creation of a ?~/.gnupg? homedir.
I don't know about this. --keyring is still present in gpg 2.0.20, and i
don't see it going away in the master branch (which will become 2.1)
unless i'm missing something.   Hopefully Werner can speak to these plans.

@_date: 2013-06-03 13:20:43
@_author: Daniel Kahn Gillmor 
@_subject: How difficult is it to break the OpenPGP 40 character long 
i thought that bitcoin didn't hash the public keys at all, but rather
used the full elliptic curve public key, since it is smaller than
comparably-strong RSA or DSA keys.  I don't know much about bitcoin
though so i could be mistaken here.
The OpenPGP standard supports elliptic curve keys directly:
  GnuPG will add support for these keys in version 2.1 (now in beta).  If
you wanted to make an assertion about your ownership of a given bitcoin
purse it seems like you might be able to do that.
however, the specific curves used seem to differ:
According to    For ECDSA the secp256k1 curve from
 is used.
 refers to NIST curve
P-256, which i think is different :/
Still, it seems like it wouldn't be difficult to use your OpenPGP
identity make assertions about your possession of any given bitcoin
wallet, they just wouldn't be digested into the global bitcoin
transaction log.
Does this address what you were asking about?  if not, what problem are
you trying to solve specifically?
PS your MUA seems to think that this list is named "Jay Litwyn on
GnuPG-Users " -- you probably want to update your
addressbook :)

@_date: 2013-06-08 13:03:06
@_author: Daniel Kahn Gillmor 
@_subject: Recommendations for handling (multiple) user IDs - personal and 
fwiw, some people might not be comfortable certifying a User ID
("signing a key") with such a comment, since it is not actually a part
of the user's identity.  How is an OpenPGP certifier supposed to
validate the correctness of this comment?
In general, i think that comments in User IDs should be discouraged, as
i've suggested publicly:

@_date: 2013-06-08 16:16:18
@_author: Daniel Kahn Gillmor 
@_subject: Recommendations for handling (multiple) user IDs - personal and 
People simply won't use tools that they aren't comfortable with.  This
is a delicate tradeoff, but if you're willing to sacrifice everyone's
comfort to build a system, that system simply won't get used.  The end
result?  decades of cleartext e-mail, long after we had the tools to do
better :(
Including a certification level, given the state of modern OpenPGP
implementations, is meaningless and serves only to leak information
about the social graph which otherwise wouldn't be leaked.  I think it's
also a bad idea, and i'm grateful to Werner and the rest of the GnuPG
crew that it is not a question asked by default, as i've also argued
publicly recently:
  If you want to be able to do machine-level inference about user identity
(so that a user's computer can tell them with confidence "This is Sally,
you know this because Joe said so"), and you insist that policy URLs are
critical then you probably also need machine-readable policies; and you
need to define a way that users can declare their sentiments about
specific policies, in addition to declaring their sentiments about how
well they think some other keyholders can effectively implement each
flavor of policy encountered.  This sounds like a complicated mess, and
afaict no one is working on this.  it is another barrier to
participating in the OpenPGP network of certifications.
Learning the basics of what it means to responsibly hold a secret key
and make (or choose to not make) identity assertions with it is already
too complex for most people.  Adding layers of complexity to the system
will simply make the user base smaller.  This is particularly disastrous
with systems that rely on the network effect for any sort of public
I would argue "it doesn't make it better" because it confuses people
about what User IDs are, which makes it harder for them to participate
in OpenPGP's network of certifications.  Clearly, we disagree here.
It sounds like you're saying that the presence of some comments in User
IDs make it so that no one else is supposed to certify those User IDs,
for some sort of legal reason ("signature law") which i don't know about
or understand.  If this is correct, this sounds like yet another reason
for me to not want to get into the habit of certifying any User IDs with
comments in them.
I'm wary of the term "secure" -- can you be more specific about what
benefits we gain as a community from a comment in a User ID like "I have
this primary key offline"?  Are there no other ways to gain those
benefits without putting the comment in the User ID?
If you think that policy URLs should be shown by default, you should
make the case for that.  I suspect they're not currently shown by
default because they are an additional source of confusion in an already
too-confusing interface for most people.  Who do you want to be able to
participate in the public network -- just a handful of experts steeped
in the arcana?  or everyone capable of operating a computer at a
reasonable level?
clearly, we disagree about this.  But the overwhelming majority of
comments in User IDs on the public keyservers are exactly of the
ridiculous types used as examples in that page.  Try looking at them
sometime, it's pretty depressing.
This suggests to me that this feature (the "comment" prompt when
generating a new User ID) is causing more confusion and difficulty than
it is providing benefit.
You'll note that i'm not objecting to statements about key security in
general.  I'm objecting to placing them in the User ID.
You can make these statements in other forms than placing them in the
User ID.   For example, you can put a signed message on your web site
about your key maintenance habits, which other people could refer to
when they want to learn from you.
again, it sounds like you're asking for something that would make an
already-too-cumbersome process even more cumbersome.  I don't think
that's to the advantage of the community as a whole.

@_date: 2013-03-03 15:05:03
@_author: Daniel Kahn Gillmor 
@_subject: Re-signing keys with higher owner trust 
note that what you're trying to do here is to change the certification
level, which is entirely different from changing the "owner trust"
mentioned in the subject line.
certification level indicates how carefully you verified identity
information.  this is a subjective measure, and is not actually used by
gpg other than to ignore "casual" (sig1) certifications. The
certification level might be used by some other OpenPGP implementations,
but "generic" certification is so common that those implementations
should probably have a reasonable behavior even without a specified
owner trust, on the other hand, is a private indication (usually only
visible to your GnuPG implementation) of how much you are willing to
rely on other OpenPGP certifications made by keyholder.
These are distinct and orthogonal concepts -- please don't conflate them!
or just supply the --expert option to gpg, which should permit you to
make a second certification.
While this is true, it's worth noting that the second certiifcation will
be preferred because it is more recent than the first, not because of
the higher chosen cert-level.

@_date: 2013-03-03 18:38:49
@_author: Daniel Kahn Gillmor 
@_subject: "gpg: Signature made <date time>" tamper resistant? 
The signature time is signed with the signer's private key, so you can
verify the date/time that the signer intended to put there.  There is no
way to verify the origin of the timestamp, though (that is, you can't
prove that it was taken from the machine clock).  Even if LD_PRELOAD
hacks like faketime or datefudge didn't exist, a user with physical
control of the machine could just reset the clock to whatever they
wanted, make the signature, and then reset the clock again.

@_date: 2013-03-03 22:59:52
@_author: Daniel Kahn Gillmor 
@_subject: "gpg: Signature made <date time>" tamper resistant? 
Take a look at I have no experience with them, but they've been discussed before in
this list, if you want to review the archives.
You might also be interested in the relevant wikipedia article:

@_date: 2013-03-26 10:50:14
@_author: Daniel Kahn Gillmor 
@_subject: Dump all the properties of a key? 
it's not clear to me what you're looking for, but here are a few options
that might provide you with useful information:
gpg --export-options export-minimal --export $KEYID | pgpdump
gpg --export-options export-minimal --export $KEYID | gpg --list-packets
if you are interested in the list of other people's certifications (or
old self-certifications) you could omit the "--export-options
export-minimal" arguments.
If you're looking for some piece of information in particular, asking in
more detail can make it easier for other people to help you get the
answer you're looking for.

@_date: 2013-03-29 13:30:48
@_author: Daniel Kahn Gillmor 
@_subject: gpg for pseudonymous users [was: Re: gpg for anonymous users - 
I've changed the subject line to indicate that this thread is about
establishing a pseudonym, *not* about anonymous users.  This is a subtle
but important difference.
I'm afraid that the term "web of trust" tends to lead people into
misunderstandings about what this network of public identity
certifications does.
These certifications do *not* imply trustworthiness of the people who
hold the keys, and it doesn't make much sense to speak of a given key
being "trustworthy" on its own -- what would you trust it to do?
Rather, the system provides a way to determine the publicly-stated
identities associated with each key.
For a pseudonymous author who wants to establish a credible claim to a
given identity, one way would be to encourage the people who have been
following the work of that author to certify the key.  In that case, how
would they know it's the right one?  This is a shade different from
other scenarios, but if, for example, if i had been using tool X for 5
years, and had been corresponding with the author (e.g. bug reports,
thank you notes, feedback, etc) over that time and all the
communications and versions of the tool that i received consistently
demonstrated that the person on the other end had control of the key in
question, i would have no problem certifying that identity.
However, the original poster can't quite ask all her long-standing users
to sign her key publicly, because her users by definition are interested
in retaining their own anonymity, and signing the key of a pseudonymous
author of anonymity-providing tools can draw unwelcome attention to the
So i think the original poster's best bet is to contact well-known
anonymity and privacy advocates (who are not themselves anonymous or
pseudonymous) and encourage them to follow and engage with her work.
This can be done by participating in relevant online communities (like
this one), providing constructive feedback to other projects, making
sure your work is useful, etc.  When these relationships are
well-established, the original poster could approach her non-anonymous
peers, and ask them to publicly certify her OpenPGP key.
I'm an example of a non-anonymous advocate for private and anonymous
communication; there are probably others on this mailing list.  However,
i have never heard of the original poster or her project before this
thread, and i don't have the time right now to review or follow the
project, so i'm not the best candidate for this particular engagement.

@_date: 2013-05-01 22:16:26
@_author: Daniel Kahn Gillmor 
@_subject: Confusion with signature digest type. 
It doesn't facilitate a collision attack against that specific
certification; but if a collision attack is possible against a
particular digest, then *any* signature made over that digest becomes
That is, should a collision attack become viable against a particular
digest, there's no way to tell whether any given signature that uses
that digest was made before or after the collision attack was possible.
So responsible clients that want to ensure that their certifications
(including self-certifications) are acceptable to their more
security-conscious peers should ensure that their certifications don't
use digests that are at risk of collision attacks.
For example, let's say you're in the habit of regularly signing a
changing collection of data for $job, and those signatures use SHA1.  An
exploit comes along against SHA1 that renders it vulnerable to collision
attacks.  Eve manages to inject data into your collection that makes the
data collection have the same digest as a particularly weird User ID
when bound to your primary key (i'm handwaving past the details of the
OpenPGP boilerplate involved in a self-sig here).
Eve waits for you to make your regular data collection signature, and
then rips it out and attaches it to your primary key, thereby creating
an assertion that you have a new identity that you wish to be public and
associated with your old ones.
granted, this is not the end of the world (we all know that your e-mail
address isn't really president at whitehouse.gov), but anyone who believes
SHA-1-based certifications won't be able to tell whether rjh thinks he
is the President of the USA or whether the President thinks he is rjh.
You can avoid all of this by making all of your certifications
(including your self-sigs) over a widely-accepted digest that is not
thought to close to the risk of collision attacks; SHA-256 seems like a
reasonable choice.
There is no good reason for anyone interacting with modern
infrastructure to make their default certifications with anything weaker.
For the few people who need to ensure that their key can be accepted by
legacy systems that don't support SHA-256, systems that want to be
legacy-compatible could issue each self-sig in duplicate form: one using
SHA1, timestamped at N-1 seconds since the epoch, and the other using
SHA256, timestamped at N seconds since the epoch.  Modern tools that can
interpret the SHA256 certification would use it (and ignore the older
cert that uses the weaker digest) and  legacy SHA2-incapable systems
could interpret the older cert.
does this make the concern (and one approach to addressing it) more clear?

@_date: 2013-05-01 23:49:53
@_author: Daniel Kahn Gillmor 
@_subject: Web of Trust in Practical Usage 
Peter Lebbing's thoughtful consideration of the issues in this thread
was spot-on, imho.  Thanks, Peter!
One person's "falsely-inflated signature counts" is another person's
"well-established participant in the keysigning culture", i'm afraid.
One of the beauties of OpenPGP's certification model is that no one can
require anyone to consider any particular certification (or set of
certifications) to be acceptable or valid.  And this is a good thing,
because if you tell me that the "most popular" key is just the one
signed by the most other keys, and the key you're looking for belongs to
a user named "Alice ", then all i have to do is scan
the keyservers for such a key, see that it has certifications from N
keys on it, and then create a new key with User ID "Alice
", plus N+1 new keys, and have them all certify the
new key+userid.
when the cost of a new "sockpuppet" identity is nil, voting systems
(like "most popular key") tend toward being gameable.
what specifically are you trying to do in the bigger picture?  maybe
folks here can give you some suggestions if we can see what you're
trying to accomplish in the abstract?

@_date: 2013-05-02 00:33:18
@_author: Daniel Kahn Gillmor 
@_subject: Confusion with signature digest type. 
if it was a preimage attack (even for SHA1), then yeah, it'd be game
over in a lot of horrible ways i don't want to think about in detail
right now :)
It's a collision attack based on the idea that:
 a) Eve can inject arbitrary data into the collection that she expects
you to sign, and
 b) Eve can inject arbitrary data into the self-sig that she's crafting
(e.g. in a "tumor" in non-critical subpackets of the Eve-generated
So Eve's work is to manipulate both X (the data repository) and Y (the
self-sig she's crafting) until she can coax them into a collision.  She
doesn't care what the collision is, so she's not involved in a pre-image
As i understand it, this is roughly analogous to the attack used against
rapidssl in  which exploited
cryptogrpahic weaknesses in MD5's collision resistance to mint an
exploitable intermediate CA.  In that attack, they manipulated X (the
expected serial number and timestamp and distinguished name in the X.509
cert generated by RapidSSL) and Y (the "tumor" in their bogus,
handcrafted intermediate X.509 CA cert) until they found an MD5
collision, and then got RapidSSL to issue the predictable cert at the
expected timestamp with the expected serial number.  Once the X.509 cert
was issued, they spliced the good signature onto the bogus cert, and had
themselves a cert that any browser would accept.
If you think this analogy doesn't hold, please let me know where it
falls apart.
I still maintain that encouraging people to use SHA-1 for any
certification (including self-sigs) is leaving the coffeepot on, but the
house is not yet on fire.  Let's turn off the coffeepot :)
SHA-1 is a fine digest for fingerprints, which are generated from
material entirely under the user's control, and cannot be influenced by
an outside party, and can never be confused or substituted by such
things.  this is because fingerprints rely on preimage resistnace,   But
it is ill-advised to make new signatures over any digest that has
significantly weakened collision-resistance; this is particularly true
when stronger digests are widely available, as is the case with SHA-256.

@_date: 2013-05-02 01:00:38
@_author: Daniel Kahn Gillmor 
@_subject: Confusion with signature digest type. 
the same can be said of X.509 certificates.  there is a lot of structure
in them too, but nonetheless a collision attack was sufficient to mint a
new certificate from rapidSSL's predictable signing policy.
The User ID itself does have well-defined structure, it's true -- in
particular, it has to be a valid UTF-8 bytestream.
However, the selfsig is made on a digest over many things, only one of
which is the User ID.  for example, it could contain an arbitrary
OpenPGP notation subpacket, which can itself include an arbitrary
bytestream in the value field, particularly if notation flag 0x80 is
cleared.  Compare this to the X.509 ASN.1 "tumor" used in
This is an attack against the digest's collision-resistance, not against
its preimage resistance.

@_date: 2013-05-05 00:10:14
@_author: Daniel Kahn Gillmor 
@_subject: Web of Trust in Practical Usage 
even if you care about high quality entropy, new keys are pretty cheap.
If you don't care about high quality entropy (you just want new keys and
don't care how hard they are to guess) new keys are *outrageously*
cheap.  This isn't something you can rely on to just do aggregate
voting, unfortunately.

@_date: 2013-05-09 14:25:37
@_author: Daniel Kahn Gillmor 
@_subject: Web of Trust in Practical Usage 
This is trivial to do.  I suspect the main reason no one has bothered to
do it is because no one is currently (that i know of) trying to use some
sort of voting scheme in what is effectively an infinitely large pool,
which would make them vulnerable to this attack.
Please don't start using (or encouraging other people to use) such a
voting scheme.  It is not a reliable or responsible mechanism in this space.
if you're counting distinct paths, those paths can start anywhere in the
chain.  so if you say "i will make this more difficult for an attacker
by only having ever signed the key of Alice", then your adversary just
needs to get one key signed by Alice before they start injecting false
identities, rather than getting a key signed by you.  This is not
significantly more difficult, and you have no way of knowing if it is
happening or not.
The responsibility ultimately rests on you to decide whose identity
certifications you are willing to rely on.  using a voting scheme is
nearly equivalent to saying "anyone who has a key, i will rely on in the
same way as anyone else".  This choice is disastrous in an environment
where it is easy to create and control "sockpuppet" accounts with their
own keys, and those accounts/keys are indistinguishable from "real"

@_date: 2013-05-29 10:26:50
@_author: Daniel Kahn Gillmor 
@_subject: certificat for a key pair 
what e-mail client?  what version?  does the e-mail client support
OpenPGP natively, or does it need a plugin?  if a plugin, which plugin
are you using?  what version?

@_date: 2013-05-29 13:39:24
@_author: Daniel Kahn Gillmor 
@_subject: [OT] Why are you using the GPG / PGP keys? 
[re: startssl]
is this really the case?  There is no way to supply them with a certreq
without the secret key material?  I would find that really surprising,
and it should be better publicized if that's so.
actually, startssl is based in israel.  whether that's better or worse
than being based in the US, i leave as an exercise to the reader.

@_date: 2013-11-03 14:13:41
@_author: Daniel Kahn Gillmor 
@_subject: Quotes from GPG users 
As a Debian user, I rely on GnuPG to ensure that the software I install hasn't been tampered with.

@_date: 2013-11-04 02:13:37
@_author: Daniel Kahn Gillmor 
@_subject: Changing default digest algo 
these steps look right to me, though i don't see the updated preferences on the public keyserver network yet.
your key has four signing-capable subkeys and two encryption-capable subkeys.  It also has two user IDs.  This means that there should be eight self-signatures (4 + 2 + 2 = 8).  Above, you're only showing 6 self-sigs with SHA-1.  I suspect that your User IDs (where the preference subpackets are stored) are actually being certified with a stronger digest, but your subkey binding signatures have not been adjusted.
I just tested with an example profile using configuration options similar to the ones you've described above, and found that newly-created subkeys (after the config change) are bound with a subkey binding signature over the preferred cert-digest-algo.  so one approach (if there are no other suggestions for re-creating new subkey binding signatures on the existing subkeys) is that you could generate new subkeys and revoke the old ones.
PS as an aside, having two 4096-bit encryption-capable subkeys is probably not useful.  Your peers who encrypt traffic to you will need to choose one to encrypt to, and they will just choose the most recent one.   I recommend revoking all but the most recent.  If you have a good reason for keeping all 4 signing-capable subkeys (e.g. you are distributing signing-capable subkeys to separate devices which you want to be able to revoke if those devices become compromised), that's fine.   If that's not the case, you probably want to revoke most of those signing-capable subkeys too.
PPS you may be interested in:

@_date: 2013-11-04 11:52:02
@_author: Daniel Kahn Gillmor 
@_subject: trust your corporation for keyowner identification? 
Yes, it does make a difference.
Let's say I make key X and attach to User IDs to it:
  * Daniel Kahn Gillmor   * Alice Munroe You meet me, check my identity, verify that i'm actually dkg, and just sign the first User ID (because you have been unable to verify whether i am also somehow Alice Munroe). (in fact, i am not Alice Munroe, but i would like to be able to read her mail)
At some point, you find you want to encrypt a message to Alice Munroe (who you met at a conference, perhaps).  If you had certified both User IDs on my key, gpg would be happy to encrypt the message to my key instead of Alice's actual key.  If i get a copy of that message, i would be able to read it.  This would be bad.
An OpenPGP certification (a "keysigning") is an identity assertion, over *both* the key and the User ID.  It says "this key K belongs to the person known in the real world by the User ID U", and it is cryptographically signed by the person making the assertion.
If you substitute some arbitrary other User ID for U, the meaning of the certification changes radically (and the cryptographic certification breaks).  This is an intended feature.

@_date: 2013-11-07 13:40:22
@_author: Daniel Kahn Gillmor 
@_subject: trust your corporation for keyowner identification? 
if we're talking about gpg's concept of "ownertrust", please do not muddy the waters with "entrust X with my life"?  gpg's "ownertrust" is much more narrow than that: it says "I am willing to rely on OpenPGP certifications made by the holder of this key".
"entrust with my life" is not simply a superset of all other trust.  I have friends who would take care of me if i was deathly ill.  I would place my life in their hands.  But they have never thought about how to do rigorous cryptographic identity certification, and I would not rely on their OpenPGP certifications.
An OpenPGP certification says "I believe that Key X belongs to the person identified by User ID U".  Most people would not want to make that statement publicly without having thought about it and convinced themselves somehow that it is true.  What it takes to convince each person may well vary, which is why we assign different ownertrust to different people.  When making a public assertion like an OpenPGP certification, it is also probably reasonable to ask what the parties involved (or the rest of the world) gains from making that statement. Just because you believe a statement to be true doesn't mean you need to make it publicly, with strong cryptographic assurances, and it may have bad consequences.
Also, consider that certifications are not necessarily forever.   If Alice relies solely on Carol's certification to believe that key X belongs to Bob, and Alice then certifies (Bob,X), what does Alice do if Carol revokes her certification?  If Alice doesn't pay attention and revoke her own certification, then she is announcing as fact to the world something that she should no longer believe to be true (assuming that she was relying only on Carol's certification for that belief). This sounds like an untenable maintenance situation I personally would rather avoid, which is why i do not make public certifications based solely on other people's certifications.
The depth parameter is useful even without trust signatures.  Peter Lebbings response upthread describes the scenario.

@_date: 2013-11-15 12:23:09
@_author: Daniel Kahn Gillmor 
@_subject: reproducible builds [was: Re: BitMail.sf.net v 0.6 - Secure Encrypting 
Robert's right that reproducible binary builds are a non-trivial task.
However, they're not impossible, and this is an active and ongoing field
of work.  For those interested, i recommend this as a jumping off point:

@_date: 2013-10-05 22:21:47
@_author: Daniel Kahn Gillmor 
@_subject: [Announce] [security fix] GnuPG 1.4.15 released 
My understanding is that enigmail does not update gpg on its own.  The
version number of enigmail is not tied to the version number of gpg at all.
You should update gpg manually.

@_date: 2013-10-10 14:02:39
@_author: Daniel Kahn Gillmor 
@_subject: my gpg key does not conform to rfc4880? 
your key 0x9771109462F2B970 appears to be an OpenPGPv4 key, not an
OpenPGPv3 key, so i'm not sure what the person you were talking to was
talking about.
that said, 0x9771109462F2B970 claims to have been generated on
1998-02-16, and is a 1024-bit DSA key.  This is a weak key by today's
standards, and the fact that it has been in use for over 15 years makes
me think that you should probably generate a new primary key anyway.
You don't have to revoke your old key immediately, of course, but you
probably want to move to something stronger sooner rather than later.

@_date: 2013-10-10 15:22:46
@_author: Daniel Kahn Gillmor 
@_subject: my gpg key does not conform to rfc4880? 
none of the above concerns should keep you from creating a new, stronger
key and starting to gather certifications on it.  You can still keep
your old key for places where more certifications matter, and start
using your new key in places where stronger keys matter.  Do this until
you feel comfortable that your new key has gathered enough
certifications to be useful in both places, at which point you can
revoke your old key.

@_date: 2013-10-10 23:25:48
@_author: Daniel Kahn Gillmor 
@_subject: First steps with GPG, am I off to a good start? 
This is absolutely correct.  You should not be re-using the same RSA key
for two different usages if at all possible.  See, for example
You can fix this by simply revoking this subkey and adding two new
subkeys, one for encryption and one for signing.  GnuPG will
automatically select the right one to use for whichever purpose.
I also agree with this.  An expiration date of 3 years is reasonable.
If you're using the key actively and you do not believe it has been
compromised two years later, it should not be much extra work to extend
your expiration date for another two years.
The expiration date on your primary key gives you a failsafe endpoint in
the event that you lose all copies of your secret key material and your
revocation certificate.  (you do have a revocation certificate generated
and stored someplace safe, right?  i didn't notice that in your list of
You can resolve the lack of expiry on your primary key just by setting
an expiration date directly with:
 gpg --edit-key 0x22581BA6DC329876 expire
You can make your revocation certification with:
  gpg --gen-revoke 0x22581BA6DC329876
store it in a safe place!
I disagree with these last recommendations from hauke.  Take that as you
I don't think such policy information in the User ID is particularly
useful to other people (i'd be interested to hear of a situation where
that communication actually changes peoples actions and where it can
only be made through the User ID as opposed to, say, on a web page, a
blog post, in-person communication during keysigning, etc), and adding
comments like this to the User ID makes it more difficult for others to
decide whether to certify your key (since they may not be able to verify
the claim you're asking them to assert).
Implementing and abiding by nuanced policy documents that you set
forward in your policy-url also doesn't seem worth the labor, complexity
and maintenance involved, since the advantages it provides (either for
yourself or for others) are not clear.  Questions to ask yourself: Have
you ever checked someone else's policy URLs?  what would you do
differently if you could check them?  have you ever audited the claims
of someone's policy URL in any way?
Lastly, do you even have a preferred keyserver?  if not, setting
--default-keyserver-url doesn't make any sense in the first place, and
you should just use the global pool.  Even if you do have a preferred
keyserver, including such a keyserver URL in your self-sig is in some
senses equivalent to a "web bug": you're asking the user of the key to
make a call to your preferred server when they access your key.  People
who do not want to have their activity tracked will probably set
no-honor-keyserver-url in their ~/.gnupg/gpg.conf, and will expect to
get updates from arbitrary members of the public keyserver network, or
from their own preferred private, non-logging or otherwise
privacy-preserving server that is peered to the public keyserver network.
i hope this analysis is helpful,

@_date: 2013-10-31 16:31:02
@_author: Daniel Kahn Gillmor 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
ENISA (the European Union Agency for Network and Information Security)
recently issued a report recommending that non-legacy systems using RSA
start with keys that are >= 3072 bits (see page 30 of the PDF):
Clearly, any OpenPGP implementation needs to deal with legacy systems,
so being able to interact with older, shorter keys is a necessity.  But
the authors of that report do seem to suggest that the default for RSA
keys should be 3072-bits going forward (though they don't mention
OpenPGP explicitly at all).
The fact that the report comes from a fancy governmental web site
doesn't mean it's correct, of course.  I'm just offering it as a data
point in the discussion :)
        --dkg

@_date: 2013-09-06 09:44:35
@_author: Daniel Kahn Gillmor 
@_subject: problems opening .asc file 
Hi Matt--
It sounds like you may have been sent a PGP/MIME-signed message.  The
message i'm sending now is PGP/MIME-signed.  These kinds of messages
show up in some Mail User Agents that don't know about PGP/MIME as
though it is a message with an attachment, instead of a single signed
In fact, the signature part is not an "attachment" in the traditional
sense of the word, and it can only be evaluated in the context of the
message it was sent with.
For more detail on PGP/MIME, see this is probably because the data it is signing is missing (i.e. you are
evaluating the signature without the message body itself)
If you want to be able to verify these message signatures, you should
set yourself up with a Mail User Agent that can handle PGP/MIME-signed
messages.  Some examples are:
 * thunderbird with the enigmail plugin
 * evolution
 * claws mail
 * outlook with gpgOL (
 * notmuch

@_date: 2013-09-10 10:59:14
@_author: Daniel Kahn Gillmor 
@_subject: message digest for signed emails 
the lines above look like they indicate your preferences as you describe
these lines aren't relevant for data signatures.
gpg is not a mail user agent.  what are you using to send mail?  how is
it connected to gpg?  Your original message claims:
X-Mailer: Microsoft Outlook 15.0
You need to provide more details about your mail user agent and how it
interacts with GnuPG -- it sounds like the behavior is being introduced

@_date: 2013-09-10 14:29:51
@_author: Daniel Kahn Gillmor 
@_subject: Upgrading keys to larger than 1024 
There's no way to directly upgrade if your primary key is weaker than
you'd like.
You should create a new keypair and go out in the world and meet people
who will sign your key.  it doesn't have to be a pain :)
Ana wrote up some good suggestions about how to do a key transition:

@_date: 2013-09-10 14:35:53
@_author: Daniel Kahn Gillmor 
@_subject: message digest for signed emails 
sorry, i don't know much about mutt or how it integrates with gpg.
maybe someone else on the list can help you with that, or you could ask
on a mailing list that's dedicated to mutt?

@_date: 2013-09-10 15:09:43
@_author: Daniel Kahn Gillmor 
@_subject: Should the use of multiple UID per key be discouraged? 
Please try out monkeysign (version 1.0 is in debian testing right now).
 It targets exactly this problem:
  If you think it is not user-friendly enough, the developers are active
and friendly folks, and they would be happy to receive suggestions for
new features.
I do not think this discouragement would be a good idea, since moving to
multiple keys imposes other costs and difficulties.  There are good
reasons to use separate keys for separate identities (e.g. if you want
to have  key you can hand over to your job when you leave there, or if
you want to operate under a pseudonym).  but there are also good reasons
to use one key for multiple identities (simpler key management, more
direct paths through the WoT for people who know you under one alias or
There are tradeoffs involved in key and identity management, and people
need to be free to make the tradeoffs that make sense for them.

@_date: 2013-09-11 10:07:30
@_author: Daniel Kahn Gillmor 
@_subject: --list-options show-notations does not work with --with-colons 
I'm trying to programmatically look at the notations in all the
self-sigs in an OpenPGP certificate.
gpg --fingerprint --fingerprint --fixed-list-mode --list-options show-notations --with-colons --check-sigs "$fpr"
does not show me the notations.
if i omit --with-colons, then i get the notations in human-readable
form, but i don't want to try to parse that.
Should i be able to see the notations when using --with-colons somehow?
       --dkg

@_date: 2013-09-11 12:38:45
@_author: Daniel Kahn Gillmor 
@_subject: --list-options show-notations does not work with --with-colons 
Thanks, that does produce a tremendous amount of info, and within it i
can find the subpacket i'm interested in (though now i'll have to write
another sub-parser just for that line).
should we note in the documentation that show-notations doesn't work in
--with-colons mode?  or would folks be interested in a patch to support it?

@_date: 2013-09-11 18:07:14
@_author: Daniel Kahn Gillmor 
@_subject: Is it possible to remove capabilities from an existing key? 
i believe GnuPG uses the most-recently-updated subkey that it believes
to have signing capability, unless you force the subkey in question via
--local-user or --default-key with a ! suffix (see the "By key Id."
section in gpg(1)).

@_date: 2013-09-12 01:35:33
@_author: Daniel Kahn Gillmor 
@_subject: Where is ECC in gpg2 (specifically gnupg-2.0.21 
GnuPG 2.1 (still currently in beta, afaict) is the first version to
include ECC support for OpenPGP.  the 2.0.x branch does not include ECC
for OpenPGP.

@_date: 2013-09-12 19:22:13
@_author: Daniel Kahn Gillmor 
@_subject: lsign produces exportable signatures when used for self-sigs 
GnuPG is currently not able to create a non-exportable self-sig.  If you
try to do this, it gives an error:
  WARNING: the signature will not be marked as non-exportable.
But: some people might never want their keys to be published to the public
keyservers, or have some User IDs that they keep locally that they do
not want to be transmitted via the keyserver network.
AIUI, keyservers should reject keys that do not have a self-signature.
Keyservers should also honor the "non-exportable" marker by rejecting
OpenPGP certification packets that have the "exportable" subpacket
included and set to 0.
So the sensible thing for a keyholder who wants their key to stay off
the keyservers would be to issue a non-exportable self-signature.
The attached patch (against the 1.4.x branch, since that's what i'm in a
good position to test) allows a user comfortable with --expert mode to
add a non-exportable self-sig.
so the creation of such a key is possible with:
 --gen-key
 --expert --edit-key
   uid 1 # select uids that you do not want distributed
   lsign
   delsig # remove all signatures not marked non-exportable
this obviously isn't a great workflow, but with this patch it is at
least possible.
      --dkg

@_date: 2013-09-13 10:29:03
@_author: Daniel Kahn Gillmor 
@_subject: lsign produces exportable signatures when used for self-sigs 
It is possible to share non-exportable signatures between private users.
 see --import-options import-local in gpg(1).  I know there are GnuPG
users who prefer to avoid having their keys on the public keyservers
entirely, and who are willing to accept the costs of doing manual key
distribution using non-exportable certifications.
those keys will not be accepted by anyone as valid, and users will have
had to jump through hoops to create them as such, so they know what
they're getting themselves into.
Nearly every key created by GnuPG in the last decade has had the
no-modify flag set.  There was never consensus about exactly what it
means, or how to interpret it: does it mean that keyservers need primary
key approval before publishing a third-party certification on an OpenPGP
cert?  if so, how does the primary keyholder express that approval?  And
no keyservers ever implemented it, because there was no unambiguous
mechanism *to* implement.
interpreting it to mean "do not publish on the keyservers at all" would
mean almost no keys would be on the keyservers.
We have that already.   It's having the "exportable" subpacket included
in the certification, with the content set to 0, meaning
"non-exportable".  That's what i'm trying to do.

@_date: 2013-09-13 10:42:13
@_author: Daniel Kahn Gillmor 
@_subject: lsign produces exportable signatures when used for self-sigs 
yes, pretty much anything can be published as long as the keyservers do
not do crypto.  That's something that the keyservers need to fix, as it
would prevent other problems as well.
In the meantime, we can produce certifications that won't be
misinterpreted by the keyservers as they currently exist, and can be
validated by any future keyservers that do proper cryptographic checks.

@_date: 2013-09-13 10:43:19
@_author: Daniel Kahn Gillmor 
@_subject: lsign produces exportable signatures when used for self-sigs 
I'm not advocating for keyservers to traffic in (or for gpg to export or
import by default) keys with unsigned user IDs.  That would be a Bad Thing.
What i'm asking for is to make it possible for people who do not want
their key on the keyservers, ever, to be able to explicitly state it in
their self-signatures.  I hope this will not be a large class of users,
but i know it is a non-empty set.

@_date: 2013-09-13 12:35:38
@_author: Daniel Kahn Gillmor 
@_subject: lsign produces exportable signatures when used for self-sigs 
Because I want to be able to make it clear *to the keyservers*, not to
"the circle of contacts" that are using the key.  People make mistakes;
people change allegiances; people can be coerced.
I am talking about a statement made by the keyholder, about how they
want their key to propagate or not propagate.  We have a standard that
makes clear how to express this intent.  It makes sense to embed the
desired instructions in the key itself.
I don't think anything that I have proposed here is in any way against
the standard.

@_date: 2013-09-17 09:21:53
@_author: Daniel Kahn Gillmor 
@_subject: Sign key and export for each UID 
Again, please see Monkeysign [0] -- it is under active development, and
it aims to address problems 1 and 3 explicitly.
It is written in python, so it is possible that someone who actually
uses a Windows platform and has sufficient motivation and time could
sort out what is needed to port it to a non-unix OS.  If you would like
to help solve these problems, i'm sure the monkeysign developers would
be really happy to have your help.
You can follow up about monkeysign on the monkeysphere mailing list:
  Monkeysphere Developers Thanks for thinking about and trying to solve these critical problems.
[0]

@_date: 2013-09-17 10:17:11
@_author: Daniel Kahn Gillmor 
@_subject: How to find and verify a trust path? 
No, it doesn't sound right because one key ? one person.  It is possible
for one person to hold many keys.
If I hold n keys, and i certify with all of them, and you grant all my
keys marginal ownertrust, then all it takes is 1 person to be deceived
(me) and you will be misled.
I won't even go into here the difference between "n people would need to
be deceived" and "n people would need to be (convinced to be)
malicious", but it's worth considering what your actual threat model is.
Trust is not a mechanical or universal process.  Different people have
different perspectives, different information, different allies, and
different adversaries.  Any system which claims that there is a
universal trust perspective would need some *very* convincing (and
highly surprising) arguments to seem plausible.

@_date: 2013-09-17 15:17:55
@_author: Daniel Kahn Gillmor 
@_subject: Signature timestamp ordering and dissecting 
You can see seconds since the unix epoch (which is the only timestamp
granularity supported by RFC 4880) by using GnuPG's --with-colons
argument (incidentally, this is also nice because it is
machine-parseable, and does not vary across locales).
When using --with-colons, you probably also want to be sure to include
For more info, read DETAILS from the source (or

@_date: 2013-09-18 16:20:18
@_author: Daniel Kahn Gillmor 
@_subject: How to find and verify a trust path? 
Given that the above link is cleartext (http instead of https), you're
also trusting every machine connected to the network path between you
and web.archive.org to not imperceptibly MITM your connection.

@_date: 2013-09-19 12:36:24
@_author: Daniel Kahn Gillmor 
@_subject: Sign key and export for each UID 
It seems like either one or the other is likely to be the Right Thing to
do with any particular User ID.
Do you have any desired behavior to recommend as a middle ground?
Should caff or pius or monkeysign or similar tools ask the user during
signing about which of the e-mail-containing User IDs they are already
confident about somehow, and use that feedback from the user to either
(if confident) to store the new certifications in the user's main
keyring, or (if not confident) to require the round trip through the
keyservers?  If this is what you want, how would you ask the user that
question in a comprehensible way for each User ID?
or is there some other approach you'd like to see happen?

@_date: 2013-09-22 16:30:52
@_author: Daniel Kahn Gillmor 
@_subject: Generation of key ID's 
the key IDs are the low-order bits of the fingerprints.  the
fingerprints are an SHA-1 digest of the creation date of the key plus
the public elements of the key plus some boilerplate/formatting.
You can read up on the specifics in the standard:

@_date: 2013-09-22 16:45:19
@_author: Daniel Kahn Gillmor 
@_subject: CryptoList - Looking for beta testers 
Very cool to see that you've done this work and that you want to see
something like this happen.  It raises a lot of questions for me,
though: how does your system know whose keys are whose?  what if a key
expires?  how does it handle new subscribers?  who gets access to the
lists?  are they archived?  what about messages that can't be delivered
right away?  How do i as a user know what keys to encrypt to?  how do i
as an admin make sure my user's confidential data doesn't leak to
outside parties?
I'm not saying that mailman is perfect, but there are some legitimate
reasons that mailman is complex.  Dealing with store-and-forward message
delivery in a dynamic network is challenging in its own right, let alone
getting the key management right for lists that deal with crypto.
Taking on all those tasks and getting them right is a tall order!
Abhilash Raj  has done a bunch of work on
Mailman over the last few months, working toward integrating Mailman and
OpenPGP.  I'm quite sure he would be happy to collaborate with you if
you're interested in working as part of a team on a project that other
people will help maintain :)

@_date: 2013-09-25 12:25:33
@_author: Daniel Kahn Gillmor 
@_subject: OpenPGP card, gpgsm, decrypt 
i don't know how to do this with OpenSSL (afaict, the "openssl ca"
command does need an CSR to produce a cert).
But if you have access to the secret key for the CA, and you have the
raw public key of the would-be end-entity, you can produce a cert using
certtool (from the gnutls-bin package):
certtool --load-ca-privkey=ca-secret.key \
         --load-ca-certificate=ca-cert.pem \
         --load-pubkey="ee-pubkey.pem" \
         --generate-certificate

@_date: 2014-04-07 00:05:43
@_author: Daniel Kahn Gillmor 
@_subject: Encrypted file-size approximation with multiple recipients 
[...]
It sounds to me like you might be setting up some sort of automated
encrypted JSON message-passing scheme.  If so, you should be aware that
if any of the encrypted JSON could be controlled by an attacker, that
attacker could possibly learn information about the other parts of the
message that are not controlled by them when using compression, just by
inspecting the size of the traffic.
This is essentially how the CRIME attack against TLS works, but the
theoretical framework of the attack itself isn't necessarily limited to TLS.
Please make sure you understand the CRIME attack against TLS and your
mechanism's use cases well enough to be certain that a comparable attack
isn't applicable, or just explicitly turn off compression for your
OpenPGP-encrypted data if you can afford the extra bandwidth and are
unsure about the use cases to which other people might put your protocol.

@_date: 2014-04-07 01:39:16
@_author: Daniel Kahn Gillmor 
@_subject: Using an RSA GnuPG key for RSA ? 
i think you might be interested in openpgp2pem from the monkeysphere
I don't think this question is actually the question you want to ask.
"pure" RSA is extremely limited, and a secret RSA key is usually only
used for either signing or decrypting symmetric session keys, whether
that's in TLS or OpenPGP or CMS or any other place where RSA is used.

@_date: 2014-04-08 01:57:05
@_author: Daniel Kahn Gillmor 
@_subject: Use GnuPG in an automated environment? 
sorry to not get into the GnuPG specifics, but how are you managing the
apt repository?
the reprepro APT repository management tool includes mechanisms for
specifying which key to use for signing and automatically triggers
signing when something has changed in the repo (or you can ask it to
re-sign if you need that).
  (the debian reprepro package is just fine for this)
i recommend using reprepro to manage the APT respository unless you have
a compelling reason to manage all the rest of this stuff yourself.
You can use reprepro locally to build the repository someplace where you
have access to the signing key and then use rsync or the equivalent to
push out the updates to any network-accessible mirrors.

@_date: 2014-04-08 07:47:46
@_author: Daniel Kahn Gillmor 
@_subject: Use GnuPG in an automated environment? 
sorry for the off-topic aside, i'm glad to see that you've considered
reprepro.  I don't know what the use case is for multiple versions of
the same package in the same repo, but it does sound like if you need
that it's a compelling reason to manage to repo by hand for now.
The key selection you're asking about is done by gpg in its best-effort
way.  Here's my understanding of its approach:
if you specify a key or a user ID, it first tries to find the primary
key associated with that specification (see "HOW TO SPECIFY A USER ID"
in gpg(1) ).  Then, when making a regular data signature (which is what
Release.gpg is), given that selected primary key, it checks to see if
there is a signing-capable subkey that has a newer creation time than
then primary key, and it uses that one.
If you want to specify a particular subkey or primary key as the signing
key, you should be able to do so by appending a "!" to the end of the
key ID:
  When using gpg an exclamation mark (!) may be appended to  force
  using  the specified primary or secondary key and not to try and
  calculate which primary or secondary key to use.
(note that the ! may need to be escaped to avoid your shell interpreting it)
If you can stand one more off-topic aside: I also recommend that for
important use cases like a software repository, you take care to
identify the signing key using a full fingerprint instead of a short
keyid.  short keyids are trivially spoofable, and if you ever update
your gnupg keyring from a public keyserver, it's possible for that
keyserver (or anyone in control of the network path between you and the
keyserver) to push an update into your keyring that matches the short
Key ID in question (even a secret key can be pushed in, i think).

@_date: 2014-04-09 19:34:44
@_author: Daniel Kahn Gillmor 
@_subject: Heartbleed attack on Openssl 
Chromium (from which chrome is based) actually embeds a copy of openssl,
but doesn't use it for its TLS implementation, which is where the bug
would be triggered.  (i'm not sure why they do this embedding actually,
i haven't reviewed it).
even if they were accessed via https, this bug wouldn't have caused any
problem greater than a malicious attacker on the network being able to
see what packages you were downloading, and/or making you fetch an older
version of the repo you're looking at (or giving you "this repository
can't be authenticated" warnings).  This is the same situation you're in
when you download via HTTP, though, so it's not a big deal in this context.
Your software updates for apt and yum are secured by OpenPGP signatures
over the archives themselves, which are made (for responsible
repositories anyway) via secret keys that aren't exposed to the web
servers that host the archives.

@_date: 2014-04-22 17:44:39
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
These proposals from Peter have the merits of simplicity and clarity.  I
like the idea of starting from this place, and allowing users to dig in
deeper if they want to.
We could do a much better job of facilitating keysigning to reflect
users' beliefs in a robust way as well, whether that's done with
non-exportable signatures from hidden signing keys or some other way.
This would make Peter's proposal even more usable for the novice user
and be convenient for experienced users too.

@_date: 2014-04-22 17:58:58
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
I can give an example where i know that the same person holds exclusive
access to multiple keys, but i grant different levels of ownertrust to
each key.  I do this because of the rules of how GnuPG interprets
signatures in the WoT, not because the keyholder has any different
policy about the two different keys:
 My friend X does a decent job at checking identities.  I wouldn't want
to rely on X's certifications directly, but i consider them useful as
corroboration from other friends.
 X has an 8-year-old 1024-bit DSA key (key "A") that has collected a lot
of certifications, and X is attached to it.
 X also has a 2-year old 4096-bit RSA key (key "B") that doesn't have as
many certifications.
 both A and B are in active use, because X is trying to transition from
A to B, but hasn't completed the transition.
 My intent is to grant "marginal" ownertrust to X, meaning that i'm
willing to consider a (key,uid) pairing as valid if it has
certifications from X and at least two other marginally-trusted friends.
If i grant "marginal" ownertrust to both A and B, then X only needs one
other friend to collaborate to get my gnupg implementation to accept
certificates that i'm not intending to accept.
X might even be in the habit of certifying keys with both A and B (this
would be reasonable for as long as X is actively using A and B, since
some of X's peers might know about and rely on certifications from A
only, and some might know and rely on B only).
I actually know several people who meet X's description (the pool of
debian developers is moving from older, weaker keys to stronger keys).
So, my current policy for dealing with this for people like X is that i
set "no ownertrust" on A, and "marginal ownertrust" on B;  i also
explain to them that if they want to make a certification that i can
rely on, they should make it with their newer, stronger key.
if GPG was closer to a contact manager, its implementation of ownertrust
could be made more sophisticated, to address this situation, by having
an abstract concept of "peers" where each peer could have an arbitrary
number of keys.  You could even approximate something like this by
matching User IDs and discounting cumulative marginal ownertrust if the
two certifications come from keys that are each bound to the same User ID.
I'm not suggesting that we make these changes right now to the gpg WoT
caluculation model, because i think there is more important work to be
tackled first, though.

@_date: 2014-04-22 18:38:36
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
I understand your argument, and i agree that this reflects a technical
weakness in the GnuPG cryptographic certification mechanism based on
what it knows about keys, and how it makes validity calculations.  Did
you see my two proposals at the end of my note about ways it could be
improved if anyone has time and effort to put into it?  the "same owner
if both assert the same user ID" fix might be the least-fiddly one,
which would catch a large fraction of the cases in question.  But it
still wouldn't cover circumstances where you know someone who has a
"work key" and a "home key" where the User IDs are disjoint.  What would
you think about work key/home key distinctions?  what if the work key
was stored on a machine administered by the local sysadmin?
Adding in a separate "person" concept to the gpg keystore seems much
more fiddly and complex in terms of UI/UX, unless gpg is willing to
commit to being a full contact manager (which i don't think it
necessarily should be).
So anyway, i think i generally agree with you that the concept itself
should stay at "ownertrust", though i do have some concerns about the
work/home split, where i can imagine different levels of care taken by
the same person in different contexts (perhaps by enforced workplace
policy, even).
thanks for the discussion,

@_date: 2014-04-23 09:24:45
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
or vice versa, actually.  You might think someone is personally inclined
towards sloppiness, but will obey the rules of an organization they're
part of, and that organization might have stricter criteria for making
certifications with keys associated with the org.
I agree with this; also, the reason that your willingness to rely on one
key or the other are associated with who you think really "owns" the
key.  even if an individual holds both keys, if the organization can
exert control over the use of one of them, there's a sense in which the
"ownership" of that key is different.

@_date: 2014-04-24 14:18:09
@_author: Daniel Kahn Gillmor 
@_subject: best practice for pgp mail service, revoking keys 
I'm glad you're thinking about these key and account lifecycle questions
in your design.
note that with expiring keys (option 4) you can always extend the
expiration date if the account is still in use as the expiration date
draws near.
You could make each key with a 1-year expiration date, and if the
account is in use with less than 3 months until the expiration, it could
move the expiration out another year.
Combine this with a policy that a terminated e-mail account's address
can't be re-used within a year (this sort of "fallow" period is a good
idea for other, non-crypto-related reasons too), and it would seem like
you're in pretty good shape.
Please also recognize that *anyone* can put a public key with a given
User ID on the public keyservers.  So while you're taking reasonable
steps to try to limit the confusion that your own system causes for your
users, you probably can't prevent other people from create a key with a
matching User ID and uploading it anyway if they want.
This is why your users ultimately want to rely on strong identity
certifications, and not just the presence of a key on the public keyservers.

@_date: 2014-04-25 12:47:46
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
with the possible exception of "self" indications, which i can see as
useful for key transitions and multi-key-holding individuals, i don't
want to see any of these other relationships embedded in the network of
identity certifications which are published.  The social graph exposed
by the public keyservers is rich enough to be useful for networked
identity certifications, but no richer.  it should stay that way, since
rich published social graphs can be used against their participants, and
it's not clear how to use the additional relationship information in an
effective way.
There are many other ways that people can decide how and whether to
publish their relationships with other people.  I don't think folding
this additional complexity into OpenPGP identity certifications is going
to make the identity certifications any easier to use or understand.
let's keep it simple, and minimize the amount of social graph leakage.
PS MFPA's original idea of using a notation to link two primary keys is
interesting, and i see how it could be useful, but i don't think it
belongs in the public keyservers either.  Perhaps something like that
(using full fingerprints, as hauke suggests) could be made by a
non-exportable certification directly on the primary key itself (not
over User IDs).  But this should only be done if there is an algorithm
in place to make use of this information.  Anyone implementing this kind
of cleanup should probably start simpler and just handle the
identical-valid-user-id case first.

@_date: 2014-04-25 12:58:03
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
yes, users *should* ignore --ask-cert-level:
why is this strange?  a certificate that binds a key to an e-mail
address is authentic iff the owner of that e-mail account controls that key.
Accepted implies that there is someone doing the accepting.
"Acceptable" might be better, but it still leaves me asking "acceptable
to whom?" and "acceptable for what?"  -- if it's in a context where it's
obvious that the answer is "acceptable for me to encrypt messages to it,
or to verify message signatures from it" then that might not be too bad.
i agree that this is confusing.  It also confuses people that we
continue to call certificates "keys", and then sometimes we actually
want to talk about the keys themselves, and also call those "keys"
the term would need to apply to the  combination, not to the
userid in isolation.

@_date: 2014-04-25 13:02:05
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
trust that key to do what?  to belong to some mystery person?  to make
valid OpenPGP signatures?  to send you good stock tips?  to be a
reliable source of cryptographically-signed tasty noodle casserole
recipes?  to be controlled in an operationally secure fashion?  to have
been created on the date it claims to have been created?
we're all aiming for clarity and simplicity here, but using a simple
ambiguous term when we need to distinguish at least two very specific
cases from each other and from many other meanings of the word "trust"
seems like a recipe for failure (instead of noodle casserole).

@_date: 2014-04-25 15:07:23
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
I can see that "authenticity" is in some ways more appealing as a term
than "validity".  But i agree with Peter that trying to redefine
"validity" to then mean something else is likely to be asking for
trouble, given the existing established terminology.  I also wonder what
term you would propose using as the opposite of "authentic".  "valid"
can be opposed cleanly with "invalid".  Would you say "inauthentic" or
"unauthenticated"?  I prefer the latter term, but in that case, perhaps
the positive version should be "authenticated" rather than "authentic".
Also, i think it is a problem to say a key is valid or authentic.  It is
not the key that is valid or authentic, it is the combination of the key
and a given user ID.
An OpenPGP certificate as a whole contains one master key and one or
more User IDs.  So the certificate itself may contain some
valid/authentic  combinations, and some
invalid/unauthenticated  combinations.
In some scenarios, you want to talk about the certificate as a whole,
and sometimes people want to make assertions about the validity or
authenticity of the certificate itself, even though it may be in this
mixed state.  For example, when a user applies ownertrust to a given
certification-capable master key, GnuPG still only relies on
certifications made by that key if the certificate containing the key
has at least one valid  combination.  So in some sense,
GnuPG considers a certificate as a whole (and by implication, its
primary key) as though it it has a validity by taking the maximum of the
validity of all of the certificate's user IDs.
I'm not proposing that we expose this detail to the end user, though,
just laying out to the detail-oriented people on this list so that we
have a common understanding.

@_date: 2014-04-25 15:14:49
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
did he understand the other consequences of setting ownertrust for
pgpca at ct.heise.de?  It's one thing to say "it worked!" but he may not
understand that whoever controls the pgpca at ct.heise.de can now trick him
into believing any OpenPGP identities that they want.
Or, you could have said "you need to validate the certificates" -- i
don't know exactly how the conversation would have followed from there,
but you wouldn't have led him to trust a key that he is not willing to
rely on for certifications.
i don't see how the surprise follows from the ideas above.  trusting a
certificate-signing authority is distinct from validating a certificate.
But these are distinct concepts.  conflating them by using the same word
does people a disservice.

@_date: 2014-04-28 14:35:34
@_author: Daniel Kahn Gillmor 
@_subject: Managing Subkeys for Professional and Personal UIDs 
No, i think you need to use separate primary keys if you want to be able
to separate encrypted work messages from encrypted personal messages.
But I also want to point out that some employers may have a legitimate
need (even a legal compulsion) to be able to decrypt communications
coming to your work-related e-mail.  One reasonable solution to this is
to provide them an escrowed copy of your encryption-capable subkey,
perhaps locked in a way that you would need to be informed (or perhaps
deceased?) that they were making use of the escrow.
However, i see *no* legitimate need for any employer to be able to forge
data signatures or identity certifications from your work-related key.
escrow only make sense for encryption-capable keys in limited contexts.
If you are in a situation where you are forced by employment to engage
in key escrow, you should take steps to ensure that only your
work-related encryption subkey is escrowed, and not your primary key, or
any signing or certification-capable subkey.

@_date: 2014-04-30 11:23:43
@_author: Daniel Kahn Gillmor 
@_subject: Get expiration date by searching on keyservers 
If you want cryptographic proof of the expiration date, you'll want to
fetch the keys locally anyway (the keyservers do no cryptographic
verification, and even if they did, you would have to decide to trust
their report, which you might not want to do).
I think fetching the keys you're interested in and handling them locally
is your best bet.

@_date: 2014-04-30 17:48:30
@_author: Daniel Kahn Gillmor 
@_subject: Access to www.gnupg.org only via TLS 
I like this analogy, but it only covers one part of the CA's
relationships -- the relationship with the subscriber.  But the CA also
has other relationships, including its relationship with the so-called
relying parties.
Another way to put it is: the CA's job, in the bigger picture of the
X.509 ecosystem, is to say *only true things*.  Anywhere that a CA says
untrue things, it is failing its job, and relying parties cannot rely on
it.  A CA isn't obliged to say *all* true things, but it is obliged to
say *only* true things.
So a CA who learns that a statement that it has made is untrue *should*
revoke that statement as soon as it finds out (oh, i wish our revocation
infrastructure actually worked properly too, but that's a different
rant).  The fact that a CA knows that one of its outstanding statements
is untrue, but it will not revoke it until someone else has paid it to
do so should be deeply disturbing for anyone who is a relying party on
that CA.
(and since Startcom is pre-loaded in almost every major trust store,
that means that everyone is a relying party on Startcom by default)

@_date: 2014-08-23 03:18:18
@_author: Daniel Kahn Gillmor 
@_subject: email verification as casual checking? 
as others have noted in this thread, this behavior is what the "PGP
Global Directory" does.
I'm not convinced this service needs to be a keyserver itself: it could
just be a keysigning e-mail service, which sends its certifications back
to the requestor, who then gets to decide what to do with them (upload
them to the public keyservers, keep them local, whatever).  Such a
service could of course remember recent certifications and avoid making
new ones over a given period, so it could not be used to flood the
That is: this sounds like a certification service, not a keyserver
service to me.
I also don't think that such a service should mark its certifications as
"casual signing" -- cert-levels aren't actually useful in today's
environmet, as i've written before:
 if this particular service has a signing policy that just verifies the
e-mail parts but not the full name, then people deciding whether to rely
on its certifications can factor that signing policy into their
fwiw, PGP Global Directory certifications are all "generic
certifications" (i checked by looking at Doug Barton's keys on the
public keyserver), which i think is reasonable.
well, it could provide some level of validation about *something* about
the keys, for people willing to rely on a set of third-parties and networks.
Typical OpenPGP certifications cover a primary key and a User ID.  Since
the User ID is a UTF-8 string, which is (by convention) a human-readable
name with an RFC 822 e-mail address (but can be anything).  Such a
service would clearly need to limit the types of User IDs it certifies
(and never certify user attributes).
I'm not sure i'd want to rely on this service myself, but it doesn't
seem like it would be hard to implement (though some of the anti-DoS
measures might be a bit tricky), and having a reasonably-implemented
service like this in existence wouldn't cause me any heartburn.

@_date: 2014-12-01 09:47:06
@_author: Daniel Kahn Gillmor 
@_subject: Order/changing of subkeys derogates compatibility!? 
You are testing a modern tool that aims to be standards-compliant
against an unmaintained, known-broken program that was out of date
before the standards were even settled.  When you found an
incompatibility, you reported the problem against the modern,
standards-compliant tool.
That approach seems unlikely to get any fruitful results.
I don't know the best place to get copies of older, out-of-date versions
of this piece of proprietary software.
GnuPG-users is probably not the best place to find this information.
Have you tried speaking to anyone at Symantec about this?

@_date: 2014-12-03 19:41:44
@_author: Daniel Kahn Gillmor 
@_subject: Different gpg.conf files for 1.4 and 2.1 
gpg 2.1.0 will look for the following files in $GNUPGHOME and choose the
first one it finds:
 gpg.conf-2.1.0
 gpg.conf-2.1
 gpg.conf-2
 gpg.conf
gpg 1.4.18 will do the same sort of search:
 gpg.conf-1.4.18
 gpg.conf-1.4
 gpg.conf-1
 gpg.conf

@_date: 2014-12-08 11:46:48
@_author: Daniel Kahn Gillmor 
@_subject: Convert GPG key to ssh key 
the gpgkey2ssh script isn't particularly well-documented or
well-supported, unfortunately.
Is they key you're looking to convert an RSA key or a DSA key?
The above suggests that it is not. (see the list of publickey algorithms
for OpenPGP [0]).
Are you trying to convert a specific subkey?  are you identifying the
subkey explicitly?
You may also be interested in the "openpgp2ssh" conversion script in the
monkeysphere package [1].
[0] [1]

@_date: 2014-12-10 11:57:57
@_author: Daniel Kahn Gillmor 
@_subject: Release scheduling 
Yes, i think releasing 2.1.1 even if we haven't fixed all the bugs is a
good plan.  Clearly there are a lot of improvements that would be good
to have in a released version.
Thanks for your work on this, Werner.

@_date: 2014-12-10 12:10:28
@_author: Daniel Kahn Gillmor 
@_subject: Release scheduling 
Can you provide more detail (or a link to a bug report) about the
problem with hkps in 2.1.0 ?

@_date: 2014-12-10 12:50:23
@_author: Daniel Kahn Gillmor 
@_subject: Release scheduling 
kristian's suggestion works for 2.1.0 already.  I currently use 2.1.0
with hkps just fine.
did you update ~/.gnupg/dirmngr.conf with a value for hkp-cacert ?

@_date: 2014-12-14 20:11:30
@_author: Daniel Kahn Gillmor 
@_subject: Signature-notation %-expandos expanding to strings of zeros 
Yes, i'm also seeing this with 2.1.0, though i haven't looked into it in
more detail yet.

@_date: 2014-12-18 11:49:27
@_author: Daniel Kahn Gillmor 
@_subject: Refreshing private key 
There are clearly tools that you can use to make larger keys than
4096-bit RSA, e.g. gnutls-bin + monkeysphere:
certtool -p --bits 8192 | pem2openpgp 'Test User '
(this will produce a binary-formatted OpenPGP key on stdout, so you
probably want to send it to a file or something)
but I don't recommend trying to do this, because these larger RSA keys
are expensive to use compared to the marginal extra security, and their
signatures are large.
I recommend sticking with 4096-bit RSA for now; for stronger keys you'll
eventually want to move to a large ECC key (though the choices we have
at the moment for ECC have some shadow of suspicion over them).
"primary subkey" doesn't make much sense.  I'm pretty sure Robert means
"primary key".

@_date: 2014-12-18 17:20:51
@_author: Daniel Kahn Gillmor 
@_subject: latest version build error 
I think you mean gnupg, not gnupgp :)
You don't mention what platform you're on, but given your recent reports
in the debian BTS, i think you're using debian.  The package you're
probably looking for is libgpg-error-dev.

@_date: 2014-12-19 02:11:56
@_author: Daniel Kahn Gillmor 
@_subject: latest version build error 
how is it installed?  if you're using debian testing or unstable, it's
probably best to just do:
 apt-get install libgpg-error-dev

@_date: 2014-12-31 11:54:44
@_author: Daniel Kahn Gillmor 
@_subject: Key selection 
The short version of the story is that its best guess really isn't very
good for any existing version of gnupg.
Its "best guess" is just based on a linear scan of the keyring,
returning the first certificate with a matching user ID.  The linear
scan is based on the date that each key was first added to your keyring.
While this is a disappointing guess, it's also very predictable (within
one known keyring), and controllable.  One way to control it is to
export all the old keys to a file, then delete them from your keyring,
then re-import the file.  Now you'll have all the keys available, but
the first one in the keyring will be the one you want.  If you have any
local (non-exportable) signatures, make sure you pass "--export-options
export-local" when exporting them, and "--import-options import-local"
when re-importing the file.
Ideally, GnuPG would use more sophisticated mechanisms to select the
"right" key (e.g. by considering calculated validity and expiration and
revocation information).  And conceivably, it could return an error if
there were multiple matches.  These are fixes that are much more likely
to be possible with the keybox format used by the 2.1 series, though, so
if you want to see that happen, please try to test out GnuPG 2.1.  the
wider deployment it gets, the better chances we'll have to improve
matching in general.

@_date: 2014-02-04 09:47:55
@_author: Daniel Kahn Gillmor 
@_subject: making the X.509 infrastructure available for OpenPGP 
fwiw, the answer here is "they haven't".  Roumen Petrov's X.509 patches
remain outside of OpenSSH mainline, and there seems to be very little
chance for upstream adoption.  Some distributions may include those
patches, but not all of them, and upstream has held the line against
them, even implementing their own certificate format instead of adopting

@_date: 2014-02-04 11:09:42
@_author: Daniel Kahn Gillmor 
@_subject: making the X.509 infrastructure available for OpenPGP 
I'd also be interested in a CA that is willing to certify a public key
with both the X.509 and OpenPGP certificate formats.
We have such an indicator format going in the opposite direction
(pointing from X.509 to the related OpenPGP cert).  In particular, it's
the X509v3 extension known as PGPExtension (OID:
1.3.6.1.4.1.3401.8.1.1), which is the creation date of the key (in
seconds since the UNIX epoch).  given the value from this extension and
the public key information, you can reconstruct the key's OpenPGP
fingerprint, and from the OpenPGP fingerprint, you can find it on the
I've been meaning to write a patch to make it easy to add this extension
via GnuTLS's certtool, but i haven't gotten around to it for well over a
year now :(
I don't know of a formalized way to do the other mapping, but it seems
like it would be pretty straightforward to embed the full X.509
certificate in a notation packet on a self-sig (presumably a self-sig
over the OpenPGP User ID that matches the X.509 Subject or something).
I have never heard a user wonder whether a given CA's certificate as
shipped by their browser (for example) is valid.  At best, i've heard
people wonder whether a given CA should be relied on ("put in the root
store", "trusted", etc).  So i don't think the OpenPGP verification step
gains you anything here.
I think these two questions are distinct.  If there is a public CA that
is willing to offer OpenPGP certificates, i would like to know about it
(whether they offer them with the same key they use for their X.509
activities or not).
I'm not sure how the gap would be closed.  From my perspective, the
S/MIME convenience stems from near-ubiquitous integrated deployment as
much as it does from the (problematic and untrustworthy) "i don't have
to think about it" certificate validity model.

@_date: 2014-02-05 00:03:23
@_author: Daniel Kahn Gillmor 
@_subject: making the X.509 infrastructure available for OpenPGP 
if the X.509 certificate is already available, nothing else needs to be
done.  you can compare the MPIs for the public key directly.
why not?  many of the main cartel CAs routinely set up special keys for
sub-CAs whose job is to make certain kinds of certifications.  Perhaps
such a sub-CA could be made for issuing OpenPGP certifications?
I'd love to see it the other way around, actually (though maybe i'm
misunderstanding you again) -- It would be great to use S/MIME as the
message transport and encapsulation, but use OpenPGP for the certificate
model.  This takes advantage of all the existing message parsing and
packaging in any existing S/MIME client, and reduces OpenPGP support to
a key management and certificate validation plugin.
To do this, i'd likely want to add a pair of S/MIME-specific subkeys to
my OpenPGP certificate (one for encryption, one for signing), so that i
can avoid re-using key material across different cryptographic messaging
schemes (i.e. not use the same signing key for both OpenPGP messages and
S/MIME messages).
Werner recently (in message ID 87zjmv127f.fsf at vigenere.g10code.de)
indicated his acceptance of a notation named extended-usage at gnupg.org
with a value that can be set to "bitcoin".  Maybe the same notation
could be used to indicate "s/mime-sign" or "s/mime-encrypt" for these
sorts of keys?

@_date: 2014-02-05 13:22:16
@_author: Daniel Kahn Gillmor 
@_subject: making the X.509 infrastructure available for OpenPGP 
If you're interested in this sort of hybrid approach, please take a look
at the monkeysphere validation agent's msva-perl git repository, which
contains a perl script "openpgp2x509" :
 git://git.monkeysphere.info/msva-perl
I also have rather half-baked code called "2ca" that operates a
minimalist "dual-stack" certificate authority which creates certificates
in both OpenPGP and X.509 forms.  In particular, it takes an OpenPGP
certificate, certifies selected User IDs on it, and then produces an
X.509 certificate derived from the relevant key (or subkey) based on the
User ID and key usage flags:
 git://lair.fifthhorseman.net/~dkg/2ca
I'd welcome patches or suggestions or fixes.  Please don't try to deploy
this in any sort of production environment without understanding it
fully and thinking it through.
If you want to follow up in detail about these projects, and if Werner
feels it's off-topic for this list, followup on the Monkeysphere
development list would be fine:
 Monkeysphere Developers

@_date: 2014-02-05 15:32:37
@_author: Daniel Kahn Gillmor 
@_subject: making the X.509 infrastructure available for OpenPGP 
To further clarify:  "Domain Validation" (how the overwhelming majority
of cartel-issued X.509 certificates are "verified" today) nominally
consists of proving that you can read e-mail sent to any of:
 * the e-mail addresses associated with the domain in question (as found
in whois), or
 * any of a set of "administrator" e-mail addresses in the domain,
including hostmaster at example.org, webmaster at example.org,
admin at example.org, ssladmin at example.org, postmaster at example.org, etc.
In practice, this means that any of the following can get a certificate
 * anyone who can spoof whois to the CA
 * anyone who can spoof DNS to the CA (changing the MX record)
 * any mail system administrator who has access to any of the above
e-mail addresses
 * any passive sniffer of outbound e-mail traffic from the CA's MTA if
the CA doesn't enforce STARTTLS for outbound SMTP.
 * if the CA enforces STARTTLS for outbound SMTP, but doesn't check
certificates: any active attacker in control of the CA's MTA's network
connection (or anywhere between the CA and the receiving MTA)
 * anyone who knows the password to any of these e-mail accounts
and so on...  Remember also that (barring certificate pinning or TACK),
someone who wants a cert does not have to attack a single CA -- they
only have to attack the most sloppily-administered CA in all the public
root stores.
The bar for regular X.509 certification is much much lower than pretty
much any common OpenPGP certification guideline.

@_date: 2014-02-10 14:05:02
@_author: Daniel Kahn Gillmor 
@_subject: Error "Need the secret key to do this" Encountered During adduid 
--export only emits the public keys, not the secret keys.  You'd want
--export-secret-keys if you wanted to transfer the secret keys as well.

@_date: 2014-02-12 14:27:47
@_author: Daniel Kahn Gillmor 
@_subject: Trying to understand the bond between master and subordinal key 
it's a bad idea to use the same key for multiple mechanisms.  keeping
the uses distinct is the most reliable way to avoid cross-protocol
attacks.  For a given key, it's very difficult to effectively mandate
that everything uses "proper padding" or that different uses will use
distinct padding from every other use.  Being able to associate keys
with your primary identity that might be used in other contexts (c.f.
recent discussions about bitcoin and otr) is a useful feature.
here are four reasons at least that are not specific to any particular
public key cryptosystem.  there are probably more:
 * offline primary keys
 * subkeys that are incapable of being abused to make fraudulent OpenPGP
identity certifications
 * subkey-specific export: you can make a key, let an agent use it on
your behalf in one context without allowing that agent access to any of
your other keys.
 * frequent expiry/rollover of encryption or signing subkeys while the
primary key (and thus the user's identity) stays constant.  this can
deal with a heavily-used signing public key, for example, to mitigate
attacks that scale with volume of visible signatures.  for encryption
keys, this can also potentially be used as a (weak) form of forward
secrecy, assuming the user actually destroys the secret key when it expires.

@_date: 2014-02-18 00:42:39
@_author: Daniel Kahn Gillmor 
@_subject: Safe curves in gnupg? 
It is perhaps open for discussion whether djb's criteria for
"safecurves" can be defined as "secure ECC", but you can find recent
discussion about the use of edwards curves (EdDSA) in OpenPGP on the
IETF mailing list, starting here:
 short version: it's under consideration and Werner has indicated active
work on it.   No released version of gnupg has support for it yet though.

@_date: 2014-02-26 00:19:17
@_author: Daniel Kahn Gillmor 
@_subject: key generation: paranoia mode - explicit random input 
If i was an attacker who was compromising your software and i knew the
software had this verification mode, i would make my modified software
generate keys "correctly" when in this verification mode (clearly the
software can tell when the entropy source is not /dev/random), and when
it was not in this verification mode i would do my devious known-key
So i don't see how this proposed change would let anyone sleep easier at
night, unfortunately.

@_date: 2014-01-03 12:50:47
@_author: Daniel Kahn Gillmor 
@_subject: sign encrypted emails 
If someone's opsec is based on the question of whether a message was
encrypted or not, then they've probably got their cart before their
horse too.
opsec requirements should indicate whether you encrypt, not the other
way around.
Yes, all OpenPGP signatures generated by standards-compliant tools
include a timestamp:

@_date: 2014-01-03 13:02:32
@_author: Daniel Kahn Gillmor 
@_subject: sign encrypted emails 
it sounds to me like you might be interested in what the S/MIME
community calls "triple-wrapping", which is used to provide
cryptographic proof-of-origin and attribute-handling for intermediate
transport agents:
  That said, triple-wrapping (or similar approaches) have tradeoffs that
we might not want to encourage.
For example, they leak metadata about who signed the message to anyone
who observes it in transit; this is not the case for the traditional
sign-then-encrypt layering.  metadata gathering is a fruitful
surveillance technique.
but at its core, i think the problem you're raising is related to a
fundamental (but probably common) misunderstanding: people assume that
if something is encrypted to them then that is related to some signal
from the message author, even though asymmetric encryption has nothing
to do with authenticity or verifiability.
I don't think you're going to solve that particular problem by having
some e-mails have an extra layer of signature on them.

@_date: 2014-01-03 19:31:29
@_author: Daniel Kahn Gillmor 
@_subject: sign encrypted emails 
As you've noticed, the sender cannot verifiably communicate their intent
by their choice of encryption key.  If the sender wants to communicate
their intent in a way that the recipient can verify it, they'll need to
sign something.
In your example, the fact that a message was encrypted makes the
recipient treat it as though the sender had indicated something specific
about the message because it was encrypted.  This is bad policy, since
there is no indication that the sender encrypted the message themselves,
or even knew that the message was encrypted.

@_date: 2014-01-04 19:38:00
@_author: Daniel Kahn Gillmor 
@_subject: keysigning: lsign and offline master key 
You have at least two approaches available to you:
 0) --export-options export-local on your air-gapped system, combined
with --import-options import-local on your "regular" system.
 1) create a secret key that lives only on your "regular" system; give
it ultimate ownertrust, but never publish it.  Use it to make
non-exportable signatures.
Would either of these workflows meet your goals?

@_date: 2014-01-17 14:33:25
@_author: Daniel Kahn Gillmor 
@_subject: Reusing signed user ID or attribute 
I think you're conflating revocation of the primary key with revocation
of a user ID.
Revocation of a primary key is permanent and cannot be overridden.
Revocation of a user ID can be overridden as long as the primary key
(the one making the certification) is not itself revoked.

@_date: 2014-01-19 11:21:14
@_author: Daniel Kahn Gillmor 
@_subject: Reusing signed user ID or attribute 
I don't know what a "privacy list for a chat user" is.  You should
probably try to document what you are trying to achieve more clearly,
and present it in a public forum where people can help you think through
possible ways to achieve it.
This thread started off by asking about user IDs or attributes, which
seems to assume that this is the only way to provide the information
you're looking for.  But an OpenPGP notation (stored within the
self-signature) could also provide that information directly.
User IDs and User Attributes are for information that you need or want
third parties to confirm and certify.  Information in an OpenPGP
notation does *not* need to be confirmed or certified by third parties.
 So if Alice wants to indicate something about her preferences about how
to use chat, she can do so in a notation subpacket within her self-sig.
does this make sense?

@_date: 2014-01-20 18:00:46
@_author: Daniel Kahn Gillmor 
@_subject: =?UTF-8?B?UmU6IGdudXBnIGJpbmFyaWVzIHRvbyBiaWc/IC8gT3BlbkJTRCBNb3Y=?= 
=?UTF-8?B?QmVybnN0ZWluIENyeXB0bw==?=
gnupg already can produce gpgv, which (on debian at least) is 356KiB,
though it also dynamically links to libresolv and libz and libbz2 and
libc.  I'm sure you could reduce that further if you wanted to tune it.
Debian's package manager (apt) has been using signed manifests for
years, and makes good use of gpgv for this.  I'm sure OpenBSD could do
the same if that was their goal.
djb's Ed25519 signature mechanisms aren't bad, though, and if the goal
is a particular targetted deployment (like it sounds like for openbsd's
package management) then it shouldn't be too awkward (though it sounds
like their implementation does some funny things with memory to be able
to apply djb's code to their particular workload).

@_date: 2014-01-23 10:01:23
@_author: Daniel Kahn Gillmor 
@_subject: time delay unlock private key. 
Nope; the IBM system was an active system; the GnuPG private keyring is
an on-disk data format.  If the gnupg executable (which is an active
system) were to implement its own timeout/falloff, anyone who wanted to
crack the file in question would just recompile their own gnupg without
that timeout/falloff, so it wouldn't be an effective countermeasure
against an attacker.
However, you can make each single attempt significantly more expensive
by playing with the s2k-count argument (assuming a reasonable choice for
s2k-mode and s2k-digest-algo and s2k-cipher-algo).
See the manual page notes about those options for more details, and the
specification's string-to-key section for a description of what those
arguments do to the underlying data:

@_date: 2014-01-24 12:15:40
@_author: Daniel Kahn Gillmor 
@_subject: Non email addresses in UID 
There are already systems that make use of the flexibility in this
field.  For example SSH hosts can publish their RSA host key in an
OpenPGP certificate using the monkeysphere (i'm a contributor to the
monkeysphere project):
 Other people advocate including a human-readable name without an e-mail
address as a User ID, so that you can refer to a person without making
any claim about e-mail addresses (i'm don't find the utility of this use
case particularly convincing myself, but it doesn't seem terrible).
So the general question you're asking about is being done already.  As
for facebook or openid or webforums other identifiers, i don't think
those have been particularly well-thought through yet.  Under what
circumstances would you use them?

@_date: 2014-01-24 17:16:28
@_author: Daniel Kahn Gillmor 
@_subject: Non email addresses in UID 
what do you mean "complete connection security via OpenPGP"?  OpenPGP is
not a stream-based communications protocol, it's a specification of a
message format and a certificate format.   Inventing a new stream-based
communications protocol from scratch and shoehorning it into OpenPGP
doesn't sound like a great idea to me.
Monkeysphere uses OpenPGP's certificate format to provide a way for
people to verify the keys used in SSH and TLS (and elsewhere -- OTR
would be a lovely addition, for example).  It does not intend to
supplant those communications techniques.
how are other people going to verify these propose User IDs?
If you make a data element a subkey or a notation in your
self-signature, you are not asking other people to attempt to certify it.
If you make the same data element a User ID or User Attribute, then you
are effectively putting it out there for other people to attempt to
verify and then certify.
If you came to me and said "I am the person who blogs at
 , how am i supposed to verify that?
 when would you want me to certify it?

@_date: 2014-01-27 16:05:41
@_author: Daniel Kahn Gillmor 
@_subject: RFC3156: "application/pgp-keys" support enigmail, gnus etc 
Hi Uwe--
This seems like a question you'd want to ask the MUAs themselsves.
when you say "enigmail does not recognize the key", how did you test it?
in icedove+enigmail 1.6, if i right-click on an attachment that is of
type application/pgp-keys, i get a menu option "Import OpenPGP Key",
which seems like it does what you would want to do with an e-mailed key.

@_date: 2014-01-30 02:09:44
@_author: Daniel Kahn Gillmor 
@_subject: Setting up shared access to gpg on a UNIX server 
Every user in the group could also destroy the secret key, if the
directory itself is still mode 777 -- write access on a directory means
you can unlink files from that directory, even if you don't have write
access to those files in particular.
A user just has to do:
 rm /opt/app/apps/dbmprod/gpg/secring.gpg
and it seems likely that you will be unable to decrypt any further
messages (unless someone has already leaked the secret key as NdK
suggests, in which case maybe you could ask them for a copy :P)

@_date: 2014-07-03 23:22:27
@_author: Daniel Kahn Gillmor 
@_subject: riseup.net OpenPGP Best Practices article 
I think you're talking about personal-cipher-preferences here, which
Alice uses to govern the cipher she uses.  Note that she could even put
IDEA first here.  Are you suggesting that she *removes* all other cipher
algorithms from her advertised preference list as well, or does she
actually advertise all ciphers her openPGP implementation is capable of?
well, OK.  Alice could also publish the cleartext on her blog, and Bob
would never know it if he doesn't read her blog.  Bob can't control what
Alice does; what he can do is to advertise his preferences in a
cryptographically-verifiable way, and set *his own*
personal-cipher-preferences to prefer stronger ciphers.
then, unless Alice has actively removed all ciphers from her advertised
preferences except for 3DES, Bob's personal-cipher-preferences will take
precedence in the messages that he sends.
I feel like i shouldn't have to point this out, but:
 * This is what the best practices page we've been discussing is suggesting.
This is the right thing to do, and Bob should do it, regardless of
whatever bad advice Alice has bought into.
Arguing that it's hopeless/pointless/harmful to prefer stronger ciphers
yourself because one of your correspondents might be tricked into
disabling stronger ciphers makes no sense from either a security or
interoperability perspective.  I'm really sorry to hear about your
graduate student debt, Rob, but this is not the best way to pay it off :P
Of course.  And we should make our defaults better and encourage
stronger mechanisms for everyone, instead of trying to claim that using
well-known, widely-adopted, clearly-specified, longstanding algorithms
is somehow "breaking the spec".
I'm sure you're not trying to claim that AES is actually a worse cipher
than DES, or that members of the SHA-2 family are actually worse digests
than SHA-1.  So i think the scenario you paint above reinforces the
points made by the riseup best practices document.

@_date: 2014-07-04 00:57:53
@_author: Daniel Kahn Gillmor 
@_subject: Key distribution via NFC 
it is cool indeed.
You can also get all of the above properties, plus the ability for
(sighted) humans to detect any deliberate interference, and to know when
the device is reasonably shielded from eavesdroppers, with a QR code or
other medium-density bar code for which free readers are available.
The monkeysign project and the guardian project are both doing good work
in that direction.  Moving the signalling from visible light to the RF
part of the spectrum seems like it would be a regression to me.

@_date: 2014-07-04 01:01:23
@_author: Daniel Kahn Gillmor 
@_subject: riseup.net OpenPGP Best Practices article 
Of course.  And Alice can always send Bob cleartext too.  does that mean
that Bob shouldn't offer any encryption key at all because there's no
guarantee that it will be used?
stronger keys are not about guaranteeing any particular level of
security -- they are about *permitting* that level of security (or, more
likely, about providing that much larger of a buffer against unknown
mathematical advances), should the other actors in the game do something
GnuPG's current default of a 2048-bit RSA key is roughly 103-bit
symmetric equivalent.  When using keys of that size, breaking the key is
more likely to be accessible to a well-funded attacker than breaking the
symmetric cipher itself.  And consider the value of the different parts
of the cryptosystem: breaking the asymmetric key lets you break all the
ciphertexts ever encrypted to that key, whereas breaking the symmetric
cipher only allows access to a single ciphertext...
Except that you can't even rely on 112 bits of keyspace at all.  even if
alice doesn't just send cleartext, she could select bad keys for 3DES,
or have a compromised RNG, or lots of other failure modes.  You can't be
certain of any of it.  What you *can* do is offer stronger keys so that
the buffer against attack is able to be larger should the other aspects
hold up.
let's look at it the other way: if you do assume that the symmetric
ciphers in use give you 112-bit security, wouldn't a lot of people blink
a few times and ask "well, why would use an asymmetric key with 1/500th
the resistance to brute force attack?"

@_date: 2014-07-14 10:35:02
@_author: Daniel Kahn Gillmor 
@_subject: Bug report:data lost 
This does sound like a problem.  it would be good to know if this is an
issue with gpg archiving mechanism, or something to do with the gpg4win
graphical interface.
I don't have a windows machine handy, but I would like to try to
replicate the problem on a unix-like platform.
Can you give an example of filenames that get lost?
Also, have you tried using the command line tools to create the archive?
 I don't know what the command is called in gpg4win, but on unix the
command would be:
 gpg-zip --encrypt --output test.tar.gpg -r WHOEVER FILE1 FILE2
(replace WHOEVER with the name of the recipient, and replace FILE1 and
FILE2 with the filenames to be included in the archive)
hope this helps,

@_date: 2014-07-20 01:17:56
@_author: Daniel Kahn Gillmor 
@_subject: Fwd: [Enigmail] [ANN] Enigmail v1.7 available 
Enigmail 1.7 is already packaged and present in debian unstable and
debian testing.
I'll look into backporting it to debian stable later this week.

@_date: 2014-07-21 10:16:08
@_author: Daniel Kahn Gillmor 
@_subject: even after deleting the 1st key pair, owner's trust is defaulting 
Any key created by GnuPG is automatically set to "ultimate" ownertrust
by default, on the assumption that this is your key, so you are willing
to believe any certifications that you make.
If you want the 2nd key to have some other ownertrust than the first
one, you should change that explicitly.  But since it sounds like it is
your personal key (and your only key), i don't see why you'd want to
reduce the ownertrust from ultimate.

@_date: 2014-06-02 11:37:05
@_author: Daniel Kahn Gillmor 
@_subject: Why create offline main key without encryption capabilities 
gpg does this, yes.  but when someone is encrypting an OpenPGP message
to you, you don't know what tools they're using.  they could be using
another OpenPGP toolkit that wouldn't have this same default.

@_date: 2014-06-04 13:02:28
@_author: Daniel Kahn Gillmor 
@_subject: Engimail & Thunderbird 
If you can state the problems you're seeing more specifically, we can
probably help better.
Can you describe your system in more detail?  what versions of the
relevant software (thunderbird, gpg, enigmail) are you using?  where did
you get the software from (e.g. from the ubuntu archives, downloaded
from the web, from AMO, etc)?
When you try to use OpenPGP, what specifically are you trying?  what do
you expect to happen?  What happens instead?  What used to happen?  what
versions were you using before the upgrade?

@_date: 2014-06-05 12:55:43
@_author: Daniel Kahn Gillmor 
@_subject: New user needs some help 
We've had this same discussion recently, i think on this very list.
please also review the archives.
The latest version of PGP supports SHA-512 just fine:
I haven't done a review of when that was originally introduced, but i
suspect it was years ago.  If anyone knows the timeline for this, please
send a pointer to it.
I suspect you got this configuration from
 -- on that page,
there is a link to an explanation about it.  you can read the rationale
for it here:

@_date: 2014-06-06 12:15:24
@_author: Daniel Kahn Gillmor 
@_subject: New user needs some help 
including this notation allows a remote peer who receives a signed
message from you to reliably distinguish between two cases:
 0) this signature is bad
 1) this signature status is unknown and i just don't have the right key
Without the extension, a signature verification process has no way to
determine which of these scenarios is the correct one when the signature
doesn't appear to validate.
Without the extension, an attacker willing to do a fair amount of work
(2^64 operations -- not out of reach of an organization willing to
devote some time and resources) can create a key with a colliding long
keyID.  If the party verifying a signature is verifying against the
new/colliding key instead of the proper key, then all the signatures
will appear in this broken state.
few OpenPGP signature-verifying tools make this check currently; but
your messages may be verified by systems that you don't know about
(including systems in the future).  If you want to provide those tools
with an way to reliably distinguish between the two cases, you should
use the notation.
        --dkg

@_date: 2014-06-06 13:22:09
@_author: Daniel Kahn Gillmor 
@_subject: New user needs some help 
I don't know if anyone is going to introduce another extension with
roughly the same semantics in the future.  It also seems likely that
future revisions of OpenPGP (OpenPGPv5, though that may take years) will
change the issuer-keyID subpacket to just include the full fingerprint
(there might also be a different fingerprint mechanism by that point).
Anyway, this is the only currently proposed mechanism to provide this
information -- and no one else has suggested an alternative that i have
If you're going to use the cert-notation, i think you'd want to use the
exact same name -- the point is that the label offers the full
fingerprint of the issuer, so changing it from issuer-fpr to issuer-crt
doesn't seem like a good idea.
So, should you include this notation in your certifications as well as
your data signatures?  The use cases i tend to see for ambiguity in data
signatures (e.g. "e-mail signature can't be validated, but we do not
know whether that is because we have the wrong key or we have a bad
signature") seem different in how they're presented to the user from the
way that unverifiable certifications are presented.
In particular, only fully-verified certifications should ever be used by
certification-checking mechanisms, and those that fail to verify should
probably be ignored, whether it's because they were bad, or because they
are from an unknown key.
what do other folks think?  would this distinction be useful in

@_date: 2014-06-16 17:59:49
@_author: Daniel Kahn Gillmor 
@_subject: [Enigmail] 15 June nightly build 
Hi Philip--
over on enigmail-users,
is there a file named "test-message" ?  you can find out with:
 ls -l test-message
If that doesn't exist, you can create a simple text file with "example"
in it with:
  echo example > test-message
are you doing this from within a terminal emulator in a graphical
environment, or are you doing this entirely from a text-mode virtual
You might do better to debug this problem with gpg over on gnupg-users
(i've cc'ed them here).  If you want to follow up on that mailing list,
you'll probably need to subscribe first at:

@_date: 2014-06-18 09:43:57
@_author: Daniel Kahn Gillmor 
@_subject: Order of keys attempted to decrypt 
see the --try-secret-key option or the --default-key option as described
in gpg(1).
This is a "hidden recipient" in the public key encrypted session key packet.
from  :
   An implementation MAY accept or use a Key ID of zero as a "wild card"
   or "speculative" Key ID.  In this case, the receiving implementation
   would try all available private keys, checking for a valid decrypted
   session key.  This format helps reduce traffic analysis of messages.

@_date: 2014-06-18 12:27:16
@_author: Daniel Kahn Gillmor 
@_subject: Order of keys attempted to decrypt 
Sorry -- i think try-secret-key is only available in gnupg 2.1, but
seems to have erroneously made it into the man pages for gpg 1.4 and 2.0
the thread from October 2013 with  " gpgtwoone macro not working
in gpg.texi?" on gnupg-devel suggests that this documentation issue was
already fixed, but it looks to me like the documentation wasn't actually
The fix appears to have been backported into the 2.0 branch in commit
d03df688 earlier this month (not yet released) and doesn't seem to be
applied to the 1.4 branch at all.
Werner, are you ok with cherry-picking a15c35f into the 1.4 branch as well?

@_date: 2014-06-26 11:22:21
@_author: Daniel Kahn Gillmor 
@_subject: riseup.net OpenPGP Best Practices article 
That's a great point.  I've just proposed a pull request on that page to
emphasize keeping your GnuPG implementation up-to-date.
however, if you *do* keep your software up-to-date, it would be a shame
for the crypto itself to be flawed enough to be broken by a
well-resourced attacker.  So standardizing on stronger crypto by default
seems reasonable to me.  The point is to ensure that the math itself is
not the weak point.
These choices are not pulled out of thin air or made up out of arbitrary
fancy.  There are people who do have the education and experience to
determine reasonable keysizes, like the ECRYPT project.
    suggests (on pages 30-32) that the current GnuPG default of 2048-bit RSA
provides roughly 103-bit-equivalent security, which falls in the middle
of "legacy standard level" (?10 years of protection) and "medium-term
protection" (?20 years of protection).
ECRYPT's "Good, generic application-indep. recommendation" is at the
128-bit level, which they note for RSA keys is 3248 bits. The Riseup
guide suggests a marginally more conservative 4096-bit RSA keysize.
In practice, i've never found a modern cryptographic system that can't
handle 4096-bit RSA keys.  I have, however, found modern systems that
*can't* deal with 3248-bit RSA keys (X.509 certificate authorities who
expect the bitlength of any key to be a power of two for some unknown
and probably stupid reason).
So if we want to make a good, generic recommendation, the riseup
recommendation doesn't seem to be a bad one to me based on my reading of
ECRYPT II.

@_date: 2014-06-26 11:26:16
@_author: Daniel Kahn Gillmor 
@_subject: riseup.net OpenPGP Best Practices article 
Of course you can't, but this is a terrible argument.  You can't forbid
your correspondent from sending you mail in the clear either.
At any rate, the document under discussion also encourages people to
advertise preferences for stronger ciphers, so correspondents using
tools which respect those advertised preferences (like GnuPG) *will* get
the increase in strength described.
The goal of this document is to encourage people to make sure that
crypto is not the weak point in their communications.  brute forcing
anything at a 2^103 security level [0] is likely infeasible, yes, but
brute-force isn't the only possible means of attack.  we don't know what
cryptanalytic improvements are known privately, but if anyone has a
speedup on the order of 2^30 (about a billion), then increasing the
keysize by about the same amount seems like a pretty reasonable safeguard.
Please read Bernstein's paper suggesting larger keysizes as a defense
against common parallel constructions (one form of speedup):
  As for arguments about use on smartcards -- if you plan to get a
smartcard, and you have a primary key that is too large for it, you can
always generate and publish new subkeys that will fit in your smartcard.
 If that's the tradeoff that seems the most secure for you, that's fine,
and the fact that you were using stronger keys in your non-smartcard
implementation doesn't hurt you at all.  Smartcards are not a good
reason to object to larger keysizes for people who don't use smartcards.
The pushback of "don't bother using stronger crypto, something else will
be your problem" seems silly to me.  It's like saying "don't bother
fighting sexism, people are going hungry!"  We can (and should) push on
all of these fronts concurrently.
[0] 2048-bit RSA is roughly equivalent to 103-bit symmetric crypto
according to ECRYPT-II:
 page 30 of

@_date: 2014-06-26 14:25:26
@_author: Daniel Kahn Gillmor 
@_subject: On the advisability of stronger digests than SHA-1 in OpenPGP 
to be clear: clients that support stronger digests than SHA-1 are *also*
standards-compliant.  I don't know of any modern OpenPGP client that
doesn't support SHA-256 or SHA-512.  Pretty much anything built today
should be using libraries for their digest algorithms, and all
reasonable libraries that support SHA-1 also support SHA-256 and SHA-512.
If you know of a modern OpenPGP implementation that supports SHA-1 but
not SHA-256 or SHA-512, please point it out (and no, creating one just
to be able to point to it doesn't count :P)
What you're proposing would indeed be slightly more widely-compatible,
and it would work like this:
 0) every self-certification made by GnuPG would be issued twice: once
using SHA-1 (selfsig A), and once using a stronger digest algorithm
(e.g. SHA-512) (selfsig B).
 1) selfsig A should probably have a timestamp that is strictly earlier
(probably by 1 second, since that's the quantum that the OpenPGP spec
recognizes) than selfsig B, so that implementations that prefer the most
recent self-sig and support the stronger digest algorithm will know to
prefer it. (this works around any buggy clients that might get confused
by two self-sigs with the same timestamp -- if we want to be widely
compatible, we should probably cater to them too)
 2) While you're at it, you could create selfsigs with each supported
digest algorithm, rather than just 2 -- that would make the signature
even more widely-compatible, because it would work for clients who
implement, for example, RIPEMD-160 but not SHA-256.
But i don't think the additional complexity and bulk (these OpenPGP
certs would be larger) are worth the tradeoff, because (a) any OpenPGP
implementation that only supports SHA-1 in 2014 should be upgraded and
fixed, not coddled (they're probably vulnerable to implementation errors
at least if they're that out of date) and (b) i don't think they exist.
SHA-1 is within range of collision attacks by sophisticated attackers.
By the time someone decides it is unreliable (that is, that they will
not rely on certifications made using SHA-1), people should have
*already* moved on.
It's conceivable that someone who wants to reject SHA-1 certifications
in general could make an exception for selfsigs (as distinct from
third-party certifications) since the worst thing that an attacker can
do if they can forge a selfsig is to make you assert an identity for
your key that you don't actually control.  But this is still an attack,
however silly, and the complexity of splitting out what digests you'll
accept in self-certifications from what digests you'll accept in
third-party certifications smells like trouble to me.
So i think that the simplest practice is best: use a single self-sig,
made over a single strong, widely-supported digest algorithm.  SHA-512
meets that requirement.
I hope this analysis is useful.

@_date: 2014-06-26 17:57:57
@_author: Daniel Kahn Gillmor 
@_subject: On the advisability of stronger digests than SHA-1 in OpenPGP 
PGP 8 was released over a decade ago, that's hardly a modern implementation:
 In what ways is its support for SHA-256 limited?  I'm having a hard time
finding documentation for it.
How many people use it?  Can you share where you got your "surprising
number" reference?   Are there software vulnerabilities in it or any
support or maintenance at all?
To paraphrase Werner elsewhere in this thread: The more important case
is to read security announcements and update your OpenPGP implementation.
Why should anyone cater to users of PGP 8.x in 2014 when we have an
opportunity to provide a stronger cryptographic baseline for everyone else?

@_date: 2014-03-01 08:40:56
@_author: Daniel Kahn Gillmor 
@_subject: key generation: paranoia mode - explicit random input 
Asking the end users to routinely choose a novel high-entropy seed for
randomness *without* relying on OS-level feature like /dev/random or
It reduces the problem of breaking the encryption to that of figuring
out what data was used as the seed for randomness.  How do you prevent
users from choosing the same seed multiple times?  How is the user
supposed to come up with this entropy?  In practice, i think this won't
happen reliably, and users will be exposed to all the usual attacks
possible against broken RNGs if they try to use this proposed feature.

@_date: 2014-03-13 09:49:19
@_author: Daniel Kahn Gillmor 
@_subject: Multiple Subkey Pairs 
Hi Martin--
ultimately, the problem here is that the people who correspond with you
don't know what device you're going to be reading the encrypted message
on, so they cannot choose which encryption-capable subkey to encrypt to.
In practice, it doesn't make sense to have more than one
encryption-capable subkey active at a time; for signing-capable subkeys,
you can have one per device as you describe.
So here is what i consider to be best practice for those people who end
up using more than one machine:
 0) a master certifying key (possibly offline)
 1) an encryption-capable subkey (shared across all machines)
 2) one signing-capable subkey per device (never shared)
in the event of machine compromise, use the master certifying key to
revoke the encryption-capable subkey and the signing subkey specific to
the compromised machine; add a new encryption-capable subkey and
distribute it to your remaining non-compromised devices.  Publish all
these changes to the public keyservers (as well as any other channels by
which you've normally published your keys).
You can also choose some schedule to regularly revoke (or expire) any of
the subkeys and replace them with new ones as a matter of routine
maintenance if you're concerned about key leakage through overuse, or
you just prefer to pre-emptively rotate keys.

@_date: 2014-03-13 12:39:37
@_author: Daniel Kahn Gillmor 
@_subject: Multiple Subkey Pairs 
what is the advantage of this approach?  what threat are you trying to
defend against?
I'll work from the assumption that you are worried that an attacker
might compromise one of your machines, copy that machine's decryption
key, and then use its key do decrypt messages that had been sent prior
to the compromise.
In this case, having your recipients encrypt every message to all three
keys is *exactly* as risky as having a single key shared across all
machines -- a compromise of any one of the machines results in a
decryption of all messages.
so what are the differences between the two approaches (separate
"per-machine" vs a single "shared" encryption keys)?
 0) per-machine keying is more work for your peers -- they have to
encrypt to K keys instead of 1.
 1) on compromise, per-machine keying means you need to revoke a single
key, and do no extra secret key distribution.  shared keying means
revoking a single key and doing a bit of extra secret key distribution.
even if it was easy to convince clients like enigmail or other
mechanisms to encrypt to multiple keys for a single user (i don't think
it is), i don't think the per-machine approach to encryption-capable
keys makes any sense.

@_date: 2014-03-13 18:24:01
@_author: Daniel Kahn Gillmor 
@_subject: Multiple Subkey Pairs 
it tells your shell to avoid interpreting the ! as a shell
metacharacter.  If your shell doesn't care about ! then the backslash is
unnecessary but shouldn't be a problem (standard shell escaping will
swallow it before passing on the literal ! to the shell's subprocess
(gpg in this case).

@_date: 2014-03-17 10:39:58
@_author: Daniel Kahn Gillmor 
@_subject: Can't check signature, DSA key 9C973C92 requires a 256 bit or 
This is a signature ostensibly made by a 2048-bit DSA key, made over an
SHA-1 digest.  DSA keys larger than 1024-bits should generally make
signatures over stronger digests than SHA-1.
See section 4.2 of FIPS-186-4
 for similar
Perhaps the folks who publish zinc need to --enable-dsa2, or to remove
any mistaken "digest-algo sha1" from their signing routines?  You could
point them at this thread in the gnupg-users archives if you think it
would be useful.
That said gpg seems to still accept signatures made by even stronger RSA
keys over SHA-1.  And it even accepts (with a warning) signatures by
stronger RSA keys over MD5, which is even weaker than SHA1.
So gpg's behavior seems to be non-uniform here.  That said, i'd love to
be able to tell gpg to ignore or explicitly reject signatures made by
strong keys with MD5 digests.

@_date: 2014-03-25 09:30:15
@_author: Daniel Kahn Gillmor 
@_subject: Trouble importing secret subkeys 
Hm, i just ran through the instructions at
 with a dummy/test user, and they seemed
to work for me.  so something else is going on.
can you show the output of "gpg --list-packets < subkeys" or "pgpdump <
subkeys" ?
the output of either of those commands isn't technically sensitive, but
you may want to redact the salt and IV and s2k count from any secret key
packet output, just to avoid giving anyone a way to start some sort of
dictionary precomputation that would be useful should they find a way to
get a copy of the subkeys file in the first place (i don't think this is
a serious risk).
or, if you don't want to broadcast it, you can send me that output
offlist (you may encrypt it to my key,
0x0EE5BE979282D80B9F7540F1CCD2ED94D21739E9) and i can look over it
privately, and see if i see any problems.  if i find anything, i'd
report back to you and you could then share with the list.

@_date: 2014-03-25 11:08:24
@_author: Daniel Kahn Gillmor 
@_subject: Trouble importing secret subkeys 
aha, this is likely to be the problem!  RFC 4880 states that a valid
transferable key needs to have at least one User ID:
You can see from your --list-packets dump of subkeys that no user ID is
(take a look at your example dump from the test account and you'll see
an extra user ID and signature packet)
gpg has some rough edge cases when dealing with changed secret keys.  I
don't know how you've updated the key, or transferred the key between
machines, etc, but it's entirely possible that you ran into something like:
 when combined with a move from a separate home directory.
The best advice i know of here is pretty clumsy:
i'd use gpgsplit on your two separate files to break out the distinct
packets, and then use cat to combine the uid and self-sig packets from
the pubkeys file with the secrets from the subkeys file, feeding the
result into gpg --import.
so something like this:
 mkdir pubpackets subpackets
 (cd pubpackets && gpgsplit < ../pubkeys)
 (cd subpackets && gpgsplit < ../subkeys)
 cat subpackets/000001-005.secret_key \
     pubpackets/000002-013.user_id \
     pubpackets/000003-002.sig \
     subpackets/000002-007.secret_subkey \
     subpackets/000003-002.sig \
     subpackets/000004-007.secret_subkey \
     subpackets/000005-002.sig \
 gpg --import
please let the list know if this works, or if you have any questions
about it.

@_date: 2014-03-27 09:30:11
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG encryption with key file 
Yes, but you will need to translate the binary file into a long ascii
string first (which means the exact same transformation needs to be done
on the decrypting side too, or else decryption will fail).
Here is an example, using "base64 -w0" as the translator, while creating
the key file from /dev/urandom:
0 dkg at alice:~$ dd if=/dev/urandom of=key bs=256 count=1
1+0 records in
1+0 records out
256 bytes (256 B) copied, 0.000288545 s, 887 kB/s
0 dkg at alice:~$ echo secret info > secret.txt
0 dkg at alice:~$ base64 -w0

@_date: 2014-03-28 09:08:31
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG encryption with key file 
sorry, i think my assumption of the common scenario was very different
from yours, or i wouldn't have recommended the conversion i did.
i'd assumed that anyone using a "key file" was using it as the
equivalent of a kerberos keytab -- a shared secret with some other party
that would be closely guarded and kept secret.  I sort of took it for
granted that the base64-encoding of, say, /bin/ls on any version of any
well-known operating system is not a secret and would never be used as a

@_date: 2014-05-01 23:34:30
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
Because i think that the keyservers are the most useful and predictable
and minimally leaky when we keep the data on them as simple as possible.
of course, the data is already not simple (OpenPGP is a huge sprawling
mess of a format), but that doesn't mean we should add new forms of
assertion to the data hosted there, especially if that data could be
used to flesh out the social graph in potentially worrisome ways.
I can see wanting to assert that i personally have control over both
keys, and making that assertion publicly (perhaps from both keys).  but
i don't see the advantage of someone else publishing claims that i am
the same person holding two different keys.  That looks to me like
people using the keyservers to document social relationships that they
are not involved in; i don't think that's a good idea.
yes, exactly.
i don't see how including the UserIDs in such a certification makes any
sense, let alone adds any extra security.  One way that gpg makes
certifications directly on the primary key itself is when you revoke a
key.  I don't know if there are other mechanisms in gpg to expose that
sort of thing.
I tend to see it the other way; i'd want to know specifically how the
proposed information is supposed to be useful *first*, and then (if it's
a compelling enough case) we can talk about how to specify it.
--ask-cert-level fails this test, for example.  We don't actually make
use of that data in any certificate validation algorithm, so publishing
it just produces a richer social graph than we need to publish, and
doesn't benefit anyone other than folks who want to data mine the social
graph on the keyservers.  That's a net loss in my opinion.
I make this argument in more detail about --ask-cert-level here:
ugh, unicode canonicalization :P  You're probably right, but: ugh!

@_date: 2014-05-01 23:39:26
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
I don't think this is the case.  In the ideal situation, i'd want to say
to gpg: "here is some data; please encrypt it to ", and
then gpg would figure out what key to use.  gpg *does* know the intended
recipient, and it *does* know the validity of every key we know that
happens to be associated with that user ID.
whether the OpenPGP certificate happens to have other user IDs
associated with it, and whether those User IDs are valid or not is
irrelevant in this case.

@_date: 2014-05-01 23:48:08
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
We're talking about building infrastructure here.  That means that (by
definition) we're making choices for some people who will never know the
details of the infrastructure.
The greater the complexity of the infrastructure, the more fragile it
is, and the more corner cases it's likely to have.
And infrastructure which supports social graph publication is inherently
more leaky than infrastructure which declines to define a way to do so.
I know you and i disagree on this Hauke; it's not the first time.  But i
want to make sure that we build simple authentication infrastructure
where possible, and i want to ensure that we don't make it easy for
users to do things without thinking that might be harmful in the future.
If i was designing a road in a mountainous region, i'd want to build the
road with guard rails too, even though some people might prefer to drive
off the edge.
This discussion has had some interesting highlights for me: including
encouraging avoiding the whole delegated certification infrastructure
itself (encouraging new users to avoid the WoT calculations entirely at
first).  this is good, simplifying stuff.  I *still* haven't heard an
argument that makes sense to me for why the added complexity of
certificate signing policies and certification levels are things that
will help users use these tools.  The added complexity hurts rather than
helps adoption and use.

@_date: 2014-05-02 18:18:38
@_author: Daniel Kahn Gillmor 
@_subject: Managing Subkeys for Professional and Personal UIDs 
You're saying instead of doing escrow of encryption keys?
The only problem with that approach is that you have no control over the
people who are encrypting messages and sending them to you.  So you're
bound to get some messages that the Boss wouldn't be able to decrypt later.
It should be *possible* with OpenPGP to prepend a new PK-ESK packet on
any received message, but i know of no tools that do that.  also, once
you leave the organization, messages could still come in encrypted to
your key by people who want to talk to the org, but don't know that
you've left.  in that case, the organization couldn't get those
messages.  (in some cases, this may be the Right Thing; in other
business relationships, that might be really problematic)
I'm not saying that all employers *should* do escrow of all their
employees' encrpytion-capable keys.  In fact, i think the majority of
employer/employee relationships should probably never require any kind
of key escrow.  But there are some relationships where key escrow makes
sense, and i wanted to clarify that it *only* makes sense for
encryption-capable keys, not personal signing or authentication keys.

@_date: 2014-05-02 19:10:42
@_author: Daniel Kahn Gillmor 
@_subject: Signature without policy meaningless? (was Re: UI terminology 
Furthermore, what would such a machine-readable statement of "i would
never rely on his identity certifications" be useful for?
You can already make such an assertion if you want to, but it won't be
machine-readable.  For example, you can write and sign a text document
that says as much, and publish it on your blog, tweet it, put it in the
newspaper, whatever.
Having such an assertion cryptographically bound to the OpenPGP
certificate in parseable form implies in some sense that you think a
mechanical process (e.g. WoT calculated validity) should be able to make
use of it.  But how would that work?  It sounds like you'd want to ask
an OpenPGP to introduce an additional concept on top of the notions of
validity and ownertrust (which are already confusing): some sort of
meta-ownertrust: instead of ownertrust's question of: "how much am i
willing to rely on NdK's identity assertions", meta-onwertrust would ask
"how much am i willing to believe NdK's assessments of certification
practice quality?"  Who is going to understand this question?  What kind
of UI would you suggest for it?
*and* by creating a standardized mechanism, you're encouraging further
leakage of more-nuanced relationship information than would be found in
a the traditional simple identity certification model.
Sounds like a lot of protocol and UI complexity, with not much of a
benefit to me.

@_date: 2014-05-02 21:53:53
@_author: Daniel Kahn Gillmor 
@_subject: Managing Subkeys for Professional and Personal UIDs 
This business use case could be better handled by ensuring that whoever
is filling my shoes for three weeks has their own key and has a
relationship with the customers/clients/vendors that they need to work
with.  Cryptography aside, that's a just a better and more honest way to
do business, rather than trying to pretend i'm not actually on vacation.
So i mean, sure, i can definitely imagine a company doing it the way you
describe.  I just don't think it's a good business practice.
OTOH, if the key was a role key (that is, if the User ID on the key was
just "Yoyodyne Sales ") then it's no longer a
personal key and sharing the associated signing or certifying key with
other people who fill that role wouldn't be unreasonable.
Tangentially: there are still cleverer ways to manage role keys like
that, if you want to provide accountability and smoother transitions --
for example, the role key's certifying public key could be managed
strictly by the sysadmin, and she could add separate signing subkeys for
each member of the Yoyodyne sales force.  Then if a message is signed,
you know which of your team actually signed it.  And if someone leaves
the team, you can just revoke their signing subkey, (if the role key had
an encryption-capable subkey, though, you'd still need to rotate that
subkey -- revoke the old subkey, create and distribute a new subkey --
since that subkey would be shared by all members of the team in a role
key scenario).

@_date: 2014-05-03 16:15:13
@_author: Daniel Kahn Gillmor 
@_subject: UI terminology for calculated validities 
There is a good default for certifying someone else's key. the default
is "generic certification" (signature type 0x10), which is the same as
the "I will not answer. (default)" selection in the "gpg
--ask-cert-level" interface.  In my keyring of a little over 2000 keys,
the overwhelming majority of all User ID certifications that aren't
self-sigs use this signature type.
This default interoperates just fine with the existing WoT.

@_date: 2014-05-05 10:21:20
@_author: Daniel Kahn Gillmor 
@_subject: typo on http://gpg4win.org/download.html 
hi gnupg folks--
 says:
   Please note: Does not use portable applications - especially crypto
   applications - on potentially infected systems.
I think you want to change "Does" to "Do" to turn the note into an
   Please note: Do not use portable applications - especially crypto
   applications - on potentially infected systems.
If the gpg4win web site is under revision control someplace, i'd be
happy to send a diff for future edits like this.  If so, please let know
where i should look for it.
Thanks for making gpg4win available for people stuck on Windows.

@_date: 2014-05-10 13:06:38
@_author: Daniel Kahn Gillmor 
@_subject: Best practices for securely creating master RSA key 
Hi Tomer--
Your steps above seem pretty sensible to me, especially if you don't
already have a trust-worthy, trusted machine that runs gpg.  I would
only adjust the creation and storage of the revocation certificate(s).
first: i think you only need one revocation certificate, not several; in
particular, you should make a generic "this key has been compromised"
certificate for your primary key.  This certificate is capable of
invalidating all your user IDs and subkeys.
second: I don't think it makes sense to store the revocation certificate
on the same medium (the encrypted USB stick) as the primary secret key.
If you need to revoke, and the encrypted USB stick is still available to
you, then you can just use the primary secret key to generate a new
revocation certificate (which can even be clearer about the specific
reason for revocation, if you want it to be.
If you need to revoke, and the encrypted USB stick is not available
(e.g. it is physically lost, destroyed, or you no longer have access to
the passphrase), then you won't be able to get to the revocation
So that suggests that you probably want to store the revocation
certificate someplace else.  I'd argue that you probably want it to be
*more* available than your master secret key.  If your revocation
certificate is compromised, the worst that an attacker can do is
invalidate your key.  This is a bad thing, but not nearly as bad as what
a compromise of the master secret key could do.
You could print out the revocation certificate and store it in a safe
place, or entrust it to a technically-proficient and responsible friend.
 Or do both :)
When printing, you could use plain ascii text (the armored certificate)
or you could pass it through a tool like optar (or other
machine-readable encoding mechanisms) to make it more easily recoverable
from paper.  I'm not sure that the machine-readability is particularly
useful.   It's a lot of work to type in an ascii revocation certificate
by hand (esp. with large RSA keys), but if you ever have good cause to
use your revocation certificate, you will probably have much more work
to do (repairing your digital identity) and typing in a dozen lines of
base64 will seem simple by comparison :P
All the best,

@_date: 2014-05-12 12:52:47
@_author: Daniel Kahn Gillmor 
@_subject: Best practices for securely creating master RSA key 
I think they're not different approaches.  you need the secret key to
make a revocation certificate, but it applies to the full OpenPGP
certificate anchored by the primary key.
there are different kinds of revocations that you can make: a revocation
that revokes a subkey or a user ID is narrower than a revocation that
revokes a primary key.
If you still have exclusive access to the primary key, then you can
always issue one of the narrower certifications yourself directly.
So the only thing you need a revocation certificate for is for the
primary key.  Does that make sense?
There are indeed lots of documents in existence that touch on these
ideas, but that's understandable since there is no one single best way
to create an OpenPGP certificate for ever: too many circumstances that
have different goals and requirements.  I think it's entirely legitimate
to write up a high-quality reasonable suggestion for a common use case
though, which is what it sounds like you're aiming for.
And maybe some (or all) of it should go in the FAQ, but i'll let Robert
(who maintains the FAQ, iirc) weigh in on that.

@_date: 2014-05-22 13:26:18
@_author: Daniel Kahn Gillmor 
@_subject: How are primary key  binding signatures (0x19) handled by gpg? 
The subkey here (0xC2B1EA06E3BD3FC7) does not have any key usage flags
subpacket associated with it at all.  As a result, it looks like gpg
treats it as having all usage flags available.
So gnupg treats this key as though the signing usage flag is present,
but it's not yet clear to me that it's willing to accept signatures or
certifications from it in the absence of a cross-certification.
gpg(1) suggests that --require-cross-certification is the default, so
signature or certifications made by the subkey should be considered
invalid.  Do you have signature or certification made by that subkey
that you can verify with?

@_date: 2014-11-04 13:09:20
@_author: Daniel Kahn Gillmor 
@_subject: Help needed to setup Passphrase with GNUPG 2.0.26 on Solaris 10 
[...]
I'm sorry, but i don't know enough about Solaris to make sense of the
information you've provided.
Perhaps someone else on the mailing list will be able to help you better.
PS I agree with Samir Nassar on both points:
 a) if this is a system accessed remotely without a graphical UI, you
really only want the curses interface for pinentry
 b) you should not publish your passphrase to a public mailing list.
(you also shouldn't use a "famous phrase" as a passphrase, since it's
more easily guessable) -- I hope you'll choose a different passphrase.

@_date: 2014-11-06 11:17:11
@_author: Daniel Kahn Gillmor 
@_subject: GPG 2.1.0/Win32: keyserver lookup problems 
have you converted your keyring to pubring.kbx and moved away the old
This was discussed already on gnupg-devel on 10 oct 2014 (subject:
performance of gpg --list-secret-keys with large keyrings)

@_date: 2014-11-10 09:25:12
@_author: Daniel Kahn Gillmor 
@_subject: DSA key sizes 
Nobody may have used Dual_EC_DRBG "in the first place" (since of course
it didn't exist before it was proposed), but that doesn't mean that
nobody used it.
Despite its terrible performance, RSA's BSAFE library used Dual_EC_DRBG
as the default CSPRNG for 9 years (most of them well after Shumow and
Ferguson's results), removing it only in 2013 when forced to by leaked
documents confirming the backdoor:

@_date: 2014-11-13 07:22:07
@_author: Daniel Kahn Gillmor 
@_subject: Detached signature ambiguity 
thanks for doing this, Werner.
i'm glad to hear this.
yes, please.  This is an important security hardening, and it shouldn't
depend on which branch people are using.
If people have tools that break because of this change, those tools were
probably vulnerable to even worse breakage (silent breakage where things
they thought were validated weren't actually validated), so this is a
valuable fix, even if there's short-term difficulty.

@_date: 2014-11-13 18:11:02
@_author: Daniel Kahn Gillmor 
@_subject: Help needed 
Hi David--
You sound frustrated.  hopefully we can help you figure things out.
Some of the details of what's happened on your machine(s) sound unclear
to me, and we'll be able to help you better with more precise information.
What backup program did you use?  What version of gnupg were you using
on your old computer?  what platform was your old machine?  what
platform is your new machine?
If you feel comfortable sharing any of this information, i'd be curious
to see the outcome (on both old and new machines) of any of the
following series of commands:
 uname -a
 ls -la ~/.gnupg
 gpg --version
 gpg --list-secret-keys 0xAAD8C47D
 echo test | gpg --clearsign -u 0xAAD8C47D
If it looks like this information is too sensitive to post to the list,
but you feel ok sending it to me privately, you're welcome to send it to
me privately (my OpenPGP fingerprint is at the bottom of this mail if
you wish to encrypt it).
I can say based on personal experience that this is not the case.  I
have done several such transfers, for myself and for other people.
I'm going to treat this paragraph as you expressing your frustration,
instead of reading it as an attack on the developers of GnuPG.  Other
people might read it differently, and may find it demotivating in terms
of helping you with your current situation.
Please remember that there are human beings on the other side of your
e-mail, people who are remarkably committed to helping others, but who
also have their own feelings.
OpenPGP Fingerprint: 0EE5BE979282D80B9F7540F1CCD2ED94D21739E9

@_date: 2014-11-17 11:31:24
@_author: Daniel Kahn Gillmor 
@_subject: Receiving keys as root user 
what version of dirmngr are you running?  gnupg 2.1.0 needs to use
dirmngr 2.1.0 (found in the gnupg 2.1.x source now, instead of the
separate distribution).
btw, i strongly recommend against using short Key IDs as desscribed
above ("--recv-keys EAE999BD") -- these are trivial to spoof, and using
them as you do above makes it quite likely that you'll pull in keys from
the keyservers that you do not want in your package manager's trusted list.

@_date: 2014-11-21 17:33:34
@_author: Daniel Kahn Gillmor 
@_subject: correct usage of gpg param 'throw-keyid(s)' ? 
As long as the prefix substring is unique, gpg will accept a truncated
That is, the full option is --throw-keyids, but gpg will accept
--throw-keyid as an alias for it.
It should also accept --throw-keyi and --throw-key and --throw-ke to
mean the same thing, but it doesn't due to a quirk of the source code
(i've just mailed a patch to gnupg-devel to fix that).
Good documentation should always use the full option, to avoid ambiguity
with any potential future updates.  I'd say the GNU privacy handbook
should be updated to use --throw-keyids instead of --throw-keyid.

@_date: 2014-11-25 04:39:27
@_author: Daniel Kahn Gillmor 
@_subject: Pros and cons of PGP/MIME for outgoing e-mail? 
This is also a violation of RFC 3156, which extends
   Multipart/signed and multipart/encrypted are to be treated by agents
   as opaque, meaning that the data is not to be altered in any way [1].
Which goes all the way back to RFC 1847 from October 1995 :/
This is supposed to be  which is
claimed to be resolved.
If it's not resolved, someone needs to let the python devs know about it.

@_date: 2014-11-26 11:37:01
@_author: Daniel Kahn Gillmor 
@_subject: Setpref is not working or is it a bug or something? 
If anyone is running debian sarge (or even lenny, which came after
sarge), they have other problems.  Those versions of the debian
operating system have not been maintained for years, and i'm sure that
there are outstanding critical bugs in that software.
We should not avoid anything for the sake of compatibility if "Debian (<
sarge)" is the main concern.  The onus should be on people running those
systems connected to the modern network to deal with their own problems.

@_date: 2014-11-26 13:59:51
@_author: Daniel Kahn Gillmor 
@_subject: Security patches and gpg 1/2 development 
patches should go to gnupg-devel at gnupg.org, or to a bug report if you
file one here:
 Hopefully Werner can weigh in on what to do if you have a sensitive
security issue that you want to embargo (this should probably also be
added somewhere prominent on they're all branches in one repository:
  git clone git://git.gnupg.org/gnupg.git
and take a look at:
 git branch -a
You might also be interested in some of the info here:

@_date: 2014-11-28 16:38:51
@_author: Daniel Kahn Gillmor 
@_subject: Can I convert a V3 key and is it even worth doing? 
I'm sure it's possible to do.  I don't think it's a good idea.  For one
thing, if you converted it, the OpenPGPv4 fingerprint would be a
different fingerprint than the v3 key, so it would appear as a different
key to most people anyway.  You might as well create a new key.
Yes.  the OpenPGPv3 key fingerprint mechanism is trivial to spoof.
OpenPGPv3 also implies the use of MD5 as a digest algorithm for signatures.
lots of us have historical keys on the keyservers.  It's not a problem
worth worrying about.
Looking on the public keyservers, there appear to already be 3 different
keys with your e-mail address, so adding one more (that was made this
millenium) doesn't seem like it's particularly worrisome..
And if it makes you feel any better(?) anyone can upload another key
with your user ID attached to it.

@_date: 2014-10-02 14:28:53
@_author: Daniel Kahn Gillmor 
@_subject: producing GnuPG keys as proof of work 
No, this is not a good idea.  Searching for a particular OpenPGP keyid
or substring of a fingerprint is functionally equivalent to searching
for a substring of any other SHA1 digest.
gpg's delay in generating a key is due to trying to generate keys with
specific characteristics, drawn from suitably robust entropy.  It's not
possible in the general case to observe from the generated public part
of the key (much less the fingerprint) whether those constraints were
respected or not, so someone wanting to fake the proof of work could
simply ignore the gpg constraints, use a weaker (or nonexistent) entropy
source, and rapidly generate public keys that a naive (or
resource-constrained) observer couldn't distinguish from a real key.
This effectively cheats the proof-of-work scheme.
If you want proof-of-work, there are many better-evaluated mechanisms
available than using OpenPGP fingerprints.

@_date: 2014-10-31 17:04:53
@_author: Daniel Kahn Gillmor 
@_subject: Help needed to setup Passphrase with GNUPG 2.0.26 
your screenshot suggests that you're doing all of this on some remote
machine via ssh (it looks like you're using putty on windows).  You
haven't mentioned what operating system you're using, though.
Anyway, gpg might want to use pinentry to gather the passphrase from the
user, and it's not clear that you have the right environment set up for
whatever package manager you have, can you install pinentry-curses and
try again?
PS "Excellence is not an Adjective but a Verb" -- it's actually a noun :)

@_date: 2014-09-01 20:01:23
@_author: Daniel Kahn Gillmor 
@_subject: [Announce] GPA 0.9.5 released 
Thanks for the updated release, Werner!
I noticed a couple things from a brief review of 0.9.5:
keyserver helpers and gpg 2.1
As reported here:
if no gpg-agent is available, i see the following two dialogs from a new
I guess GPA should probably detect the absence of an agent, and either
warn the user of its absence or start one up automatically.

@_date: 2014-09-01 21:29:36
@_author: Daniel Kahn Gillmor 
@_subject: [PATCH] GPA: add a File|Close option to the card manager 
All the other windows have a File|Close option, but the card manager
only has File|Quit.  As a result, a user who tries to close the card
manager from the menubar will most likely shut down all of GPA, which
may not be their intent.
 src/cardman.c | 12 ++++++++++++
 1 file changed, 12 insertions(+)
diff --git a/src/cardman.c b/src/cardman.c
index c752442..844a44a 100644
--- a/src/cardman.c
+++ b/src/cardman.c
 -624,6 +624,15  watcher_cb (void *opaque, const char *filename, const char *reason)
 }
+/* Handle menu item "File/Close".  */
+static void
+file_close (GtkAction *action, gpointer param)
+  GpaCardManager *cardman = param;
+  gtk_widget_destroy (GTK_WIDGET (cardman));
 /* Construct the card manager menu and toolbar widgets and return
    them. */
 static void
 -638,6 +647,8  cardman_action_new (GpaCardManager *cardman, GtkWidget **menubar,
       { "Card", NULL, N_("_Card"), NULL },
       /* File menu.  */
+      { "FileClose", GTK_STOCK_CLOSE, NULL, NULL,
+	N_("Close the window"), G_CALLBACK (file_close) },
       { "FileQuit", GTK_STOCK_QUIT, NULL, NULL,
 	N_("Quit the program"), G_CALLBACK (gtk_main_quit) },
 -652,6 +663,7  cardman_action_new (GpaCardManager *cardman, GtkWidget **menubar,
     ""
     "  "
     "    "
+    "      "
     "      "
     "    "
     "    "

@_date: 2014-09-07 01:10:54
@_author: Daniel Kahn Gillmor 
@_subject: Is it possible to sign a message with multiple digest algorithms? 
It should also be possible from a file format point of view to just
produce two signatures (or two certifications) that differ only in the
digest algorithm.
Presumably, if you're doing certifications (OpenPGP identity assertions)
you might prefer to mark the stronger digest more recent than the weaker
one (the finest resolution in the signature timestamps is 1 second, but
that should be ok for most uses).  This is because most implementations
only consider the most recent valid certification; so an implementation
that knows how to interpret the stronger digest should prefer it, while
one that only knows how to do the older digests should just ignore the
more recent digest which it can't confirm and stick with the weaker one.

@_date: 2014-09-15 16:52:58
@_author: Daniel Kahn Gillmor 
@_subject: encrypting to expired certificates 
I think Hauke is explaining that he is already in this third case; he
figured out what was wrong (his peer doesn't have the means to update
the cert's expiration date right now, but does not believe the key is
compromised), and is now trying to get to the "proceeding" part.
But the obvious path to proceed is to go ahead and use the key anyway,
which gnupg isn't letting him do (without, say, a reset of the system
clock or libfaketime or something).
I agree with Hauke here that GnuPG should not be this strict for this
circumstance, particularly because it is not setting strong policy
I consider encrypting to a key with no certifications on it at least as
problematic as encrypting to a key whose well-certified cert has
recently expired.  GnuPG lets you encrypt to the former, but not the
latter.  There are reasonable policy use cases (e.g. opportunistic
encryption) that suggest that both mechanisms should be available
(though they should both produce a warning under default policy for sure).

@_date: 2014-09-16 09:58:17
@_author: Daniel Kahn Gillmor 
@_subject: encrypting to expired certificates 
I've been in a situation where i'm sitting with a friend, talking about
a project we're hoping to work on together, and i wanted to send them
confidential information about the project to read later.  I know they
have an OpenPGP cert, so i fire up an e-mail, only to discover that
their cert is expired (they don't use it often, and hadn't noticed).
I point it out to them, they blush and say "yeah, that's on my laptop,
which is fine, but it's at home.  I'll update the expiration date when i
get home".
Now i have to wait for that to happen, for them to publish the update,
for it to propagate on the keyserver network, for me to fetch it, and
then finally i can send the mail.  A dangerous flaw?  no.  But it's one
of the thousand papercuts that make it more difficult to use the system
than it needs to be.
That's three real-world use cases now.
And i've got another one (this one from last week, actually):
A friend asked me for an introduction to another friend about an
employment issue.  Both have OpenPGP keys.  One of them was expired.  I
contacted the friend with the expired key via other (admittedly
insecure) means and had a chat about the expired key, which they
promised to put on their stack of things to do, but they couldn't get to
right away (i don't know the details about why they couldn't drop
everything else they were doing and update their expiration, but hey,
people have things they need to work on, and for many people, just
looking up how to extend the expiration date is a major context switch
from their regular work).  But the introduction seemed like it was
time-sensitive, and needed to go out, so i went ahead and made the
introduction in the clear, since i couldn't encrypt the message to both
If i could have encrypted to the expired key, i would happily have done
that.  Instead, I sent the message in the clear.
Of course, i had some other options: i could have mailed an encrypted
message to the requester with the other contact's info, and then mailed
a cleartext introduction to the one with the expired key; that would
have reduced some of the cleartext traffic, at the cost of a more
complicated e-mail setup (and broken threading on the eventual replies
between the two of them).  I could have waited until whatever was
blocking the expiration date got cleared up, and then made the
introduction.  I could have nagged hard to encourage them to update
their expiration date.  I could have done a little "training" about how
to do it so that they were sufficiently annoyed at the interruption in
their work that they just copy/pasted the commands i told them to run
without thinking about it just to get me to stop.  Maybe some of these
choices would have been better than what i ended up doing.
But again, a thousand papercuts.
So that's four real-world use cases where the ability to override would
have meant easier or more confidential communication.

@_date: 2014-09-16 10:26:31
@_author: Daniel Kahn Gillmor 
@_subject: encrypting to expired certificates 
"incredibly contrived" suggests that the people who are reporting the
scenarios have made them up.  I did not make up either example, and i
doubt that Peter or Hauke did either.  They simply happened, and we
experienced them and are reporting them.  Do you really think any of us
made them up?
Yes, it is trivial to update the expiration and publish it if (a) you
know how, and (b) you don't have an offline master key.
In fact, for updating the primary key, it is just:
 gpg --edit-key $PGPID expire
 gpg --send-key $PGPID
But sometimes, it is the encryption-capable subkey that is the thing
that expired.  in that case, it's a little bit more complex:
 gpg --edit-key $PGPID
  gpg> key 1
  gpg> expire
  gpg> save
 gpg --send-key $PGPID
of course, it might be "key 2" or something else if you have more than
one subkey.
i've definitely seen people update their primary key's expiration date
and fail to update the expiration date of their subkey, so they have a
valid cert, but it still can't be used for encryption.  So they have to
go back and do the second step later, after a poke from someone more
knowledgeable about OpenPGP who figures out why no one can encrypt
messages to them.
Is it getting complicated enough yet for you to believe these real-world
The cost is not just the time to do it, it's the time to:
 0) understand what needs to be done
 1) figure out the interface to do it
This is non-trivial, for most people: the context switch alone from
"regular work" to "thinking about key management" is expensive and
distracting.   And it is also scary -- people who understand a little
about key management have probably heard that if you screw it up, you
can screw up pretty big, in unrecoverable ways.
So there are both cognitive and emotional barriers to overcome, in
addition to the time it takes.
Do you know of any tools that do this easily for users who don't already
think about key management daily?  I don't, unfortunately.  And even if
they exist, some people might not have access to them.
I'm all for building those friendly key-management tools, i would love
to see them.  But we need to also let people use the tools we have in
light of real-world scenarios.

@_date: 2014-09-16 10:31:36
@_author: Daniel Kahn Gillmor 
@_subject: Automated Revocation Key Generation 
You probably want to look into the --batch and --passphrase-fd or
--passphrase or --passphrase-file options.

@_date: 2014-09-18 16:36:53
@_author: Daniel Kahn Gillmor 
@_subject: gmail list replies [Re: Keeping .gnupg folder in cloud] 
You put this part of your message below your .sig, so many people might
not have seen it.
I don't use gmail, but perhaps one of the other people who use gmail on
this list can give you pointers on how to interact with mailing lists
like this one through their web interface.

@_date: 2015-04-06 14:18:38
@_author: Daniel Kahn Gillmor 
@_subject: Splitting a GPG private key 
Hi Alfredo,
It's not clear from this what your goals are.
Do you want to require multiple people to come together to use that
secret key?  or do you want them each to have the ability to use the key
independently from each other?
The answer about what to do would depend on how you want the key to be
It's not clear to me that we have a functional workflow to support the
first scenario (where multiple people must come together to use the
secret key) without a lot of overhead for the users.
My understanding is that the Tails community does something like this,
but they are a highly-technical group who are willing to custom-build
their own tools and to endure quite a bit of tedious and inconvenient
process to protect the safety of their users.
Consider that anyone who ever has access to the raw secret material of
the shared key can effectively make a copy of it and then use it
elsewhere in the future.
If you can define your desired use cases more clearly, maybe someone on
this list can propose an effective workflow for you.
I'm not convinced that any of the s2k-* options are relevant to this
particular question.  I recommend leaving them as the defaults, and
thinking more about what properties you really want from your tools and
your workflow first.
hope this helps,
           --dkg

@_date: 2015-04-07 09:14:55
@_author: Daniel Kahn Gillmor 
@_subject: Making the case for smart cards for the average user 
The above is neither an RFC 5322 addr-spec nor an RFC 5322 name-addr.
That is, it would not be considered acceptable in the To: line of an
e-mail header:
  We could invent arbitrary ways to structure a User ID that includes an
e-mail address, but writing code to extract the e-mail address from
these things seems like a lot of heuristics at best, and there are all
kinds of ways that it could fail.
We know how to structure a proper name-addr and an addr-spec, and it's
not difficult.  If you want an e-mail address to be recognizable to
automated tools, you should structure it in a recognizable way.
The above UID is simply a mistake, and i don't think GnuPG should try to
accomodate it.
    --dkg

@_date: 2015-04-07 09:58:19
@_author: Daniel Kahn Gillmor 
@_subject: Splitting a GPG private key 
This is still ambiguous to me.  I described two distinct cases, and i'm
not sure which one you are agreeing to.  From the rest of your message,
i think you're agreeing to the first question, but not the second.
I don't know what "the encryption group" means.  can you explain
further?  I think you might mean that everything encrypted to any key
will also be encrypted to this key; and that some especially sensitive
material will *only* be encrypted to this key.
 * Is not owned in a usable format by any single individual. It is split
   cryptographically using gfshare.
  gfshare is: If you have more questions about how they this, you may wish to ask them
to the tails folks themselves:
 I find that their mailing lists and IRC channel (see "Support List" and
"Chat" at the bottom of the page) are usually pretty helpful and
responsive to well-framed questions.
           --dkg

@_date: 2015-04-28 11:12:32
@_author: Daniel Kahn Gillmor 
@_subject: Notes from the first OpenPGP Summit 
agreed, this does seem suboptimal, but it's better than the current
case, where things simply don't work at all.
GKD's goal is to provide a smooth user experience, where all the user's
passwords are handled as silently as possible, behind the scenes.
However, they do not appear to have the resources to track the full
functionality of gpg-agent, so they're falling down on that front.
tracking the functionality of pinentry should be a simpler task.
Every environment is free to implement its own pinentry, and we've never
discouraged that (indeed, gnupg upstream ships several pinentry
variants).  If a pinentry variant chooses to implement its own
passphrase cache, that is up to that pinentry variant, no?
           --dkg

@_date: 2015-04-28 12:17:50
@_author: Daniel Kahn Gillmor 
@_subject: Notes from the first OpenPGP Summit 
OK, that's good!
Well, gnupg currently distributes four different pinentries:
 pinentry-gtk2
 pinentry-qt4
 pinentry-curses
 pinentry-tty
:)  I'm assuming that Neal is adding this hook to pinentry-gtk2, and not
to the others, but i haven't checked.
BTW: thanks, Neal!
     --dkg

@_date: 2015-08-04 19:05:12
@_author: Daniel Kahn Gillmor 
@_subject: Proposal of OpenPGP Email Validation 
Hi all---
Sorry to take a while to respond to this thread.  I think a proposal for
an e-mail-validating keyserver/mail-loop can be evaluated in several
different ways.  unfortunately, none of them look to me like they'll
solve the concerns of the c't editor automatically without introducing
other problems.
Some ways of looking at the problem:
 0) is it OK to run an autonomous validating OpenPGP certification
    agent?
I think the answer here is clearly "yes".  OpenPGP keys make
certifications based on their own policies, and if you set up something
like this, you can set the policy to whatever you like.  Some people
might even use it, like people used their PGP Global Directory as a
public attestation service.
 1) What (if any) technical structure should there be for an autonomous
    validating OpenPGP certification agent?
This thread discussed several options, including e-mail pingbacks,
requirements of PoW, notation data, etc.  I don't have a strong opinion
on this, and i tend to think that a bit of experimentation with actually
running such an agent would be more fruitful than abstract discussion.
 2) Should existing OpenPGP clients be willing to rely on certifications
    made by such an autonomous validating OpenPGP certification agent?
    if so, which one(s) ?
This is now asking the same question as "should browsers/OSes come with
a built-in list of X.509 trust anchors?"  From the perspective of the
global network, where many people use the same tools but have different
and non-aligned goals and interests, the answer is clearly "no" to me.
But of course the practical answer to most deployed software
installations is "yes", because even extremely technically-sophisticated
people don't understand how to (or have a way to) configure their trust
anchors to align with their own interests.
Should OpenPGP implementations follow this model?  I'm not convinced it
should: it creates high-value targets (the widely-relied-upon
certification agents), and provides little to no mechanisms for
oversight/auditing of those targets.
That said, the possibility of assigning marginal ownertrust to such an
agent, coupled with the existence and common usage of the keyserver
network makes it possible provide a bit more oversight on the use of
these high-valued keys than we have in the (current CT-less) X.509
In summary, i would not want the responsibility of running one of these
agents myself.  If one existed, i would be fine submitting my own
OpenPGP certificate to it for its certification, assuming its
certifications don't bloat my cert too much, and i'd be happy to give
feedback about its workflow/security posture to whoever is operating it.
I don't think that any special notations are necessary for such a use.
Just treat it as a special certification-only OpenPGP cert, and document
its certification policy clearly.
I'd be disappointed if GnuPG or other OpenPGP tools were to decide that
they "trusted" such an agent on behalf of all users.
So, does this solve the problem that the c't folks had?  Not without a
lot of other tooling and incentives that don't exist yet.  Could such an
agent be a useful contribution to a larger certification ecosystem?
Possibly, but we won't know that until someone is willing to step up to
be responsible for such an agent, and to try it out.
          --dkg

@_date: 2015-08-05 00:33:51
@_author: Daniel Kahn Gillmor 
@_subject: no valid user IDs after changing key expiration time 
can you share the fingerprint of the key in question?  have you tried
this with a more recent version of GnuPG than 2.0.25 ?
     --dkg

@_date: 2015-12-07 07:56:03
@_author: Daniel Kahn Gillmor 
@_subject: Cannot revoke a certificate 
You should try adding "--cert-digest-algo sha1" arguments before the
--gen-revoke command to make a SHA1-based certificate revocation.
             --dkg

@_date: 2015-12-07 09:12:56
@_author: Daniel Kahn Gillmor 
@_subject: GPA - unsupported certificate 
hm, i'd say that if gpa knows that gpg needs to be run first, and it
hasn't been run, it should run it on the user's behalf instead of
expecting that they know this bit of esoterica.
Dark Penguin, if you're experiencing problems with GPA integration with
the rest of the OS, I encourage you to report a bug to debian.
On a debian system, you might use the "reportbug" utility to do this.
If these packages must be installed in a certain order, the package
manager should know about that order.  if it does not, this is a bug in
the stated dependencies of the packages in question.
For example, if gpa won't work without the gnupg2 package installed,
but it doesn't state that it explicitly depends on gnupg2, that would be
a bug in gpa.
        --dkg

@_date: 2015-02-09 14:34:07
@_author: Daniel Kahn Gillmor 
@_subject: Revoked keys and past signatures 
Yes, the revocation reason *is* stored in the revocation signature, in
the "reason for revocation" subpacket:
   My understanding was that gpg actually does use the revocation reason,
but i'm aware that this disagrees with what Peter Lebbing said. i
haven't gone ahead and tested this lately.
For example, here's an old key of mine that was revoced with the reason
0 dkg at alice:~$ gpg --export-options export-minimal --export 0x8974E514A54B6365 | gpg --list-packets | grep revocation\ reason
0 dkg at alice:~$ the *date* of your "key was superceded" revocation is relevant, though.
Any certifications that claim to have happened after the date of the
revocation *should* be considered invalid, whereas revocations that
happen before that date (but after the key creation date) should retain
their validity.
           --dkg

@_date: 2015-02-10 13:01:17
@_author: Daniel Kahn Gillmor 
@_subject: (bug?) Revoked keys and past signatures 
fwiw, you said "assign trust" above, but then in your example, tried to
do "lsign", which is an entirely different operation from assigning trust.
your certifications (whether local or exportable) themselves have a
timestamp in them.  It would be silly to certify a key and its user ID
after it was revoked by the owner; you'd be claiming "i believe that
right now this is the correct key", which is not the case.
I understand the semantics of what you're trying to do, but i'm not sure
that OpenPGP has syntax to represent it.  The closest OpenPGP comes
would be to forge a certification yourself from *before* the revocation.
 gpg --faked-system-time 20100105T153023 --lsign 1BFBED44
This isn't exactly the same semantics (it says "on January 5 2010 i
thought that this key was correct") but it's close.
 --dkg

@_date: 2015-02-10 17:53:05
@_author: Daniel Kahn Gillmor 
@_subject: moving up from 2.0.26 to 2.1.1 
The questions you're asking are very much the sort of thing that
distributions are designed to address.
What distro are you using?  what version?  2.1.1 has been packaged for
some distros already (as have some of these dependencies), and you might
be able to save yourself a lot of pain by choosing a path with a
maintainer familiar with your system :)
     --dkg

@_date: 2015-02-10 18:24:19
@_author: Daniel Kahn Gillmor 
@_subject: (bug?) Revoked keys and past signatures 
I suspect this is widely held to be the semantics of the "signature
created on" timestamp, based on the following two sections of RFC 4880
5.2.3.4.  Signature Creation Time
   (4-octet time field)
   The time the signature was made.
   MUST be present in the hashed area.
5.2.3.10.  Signature Expiration Time
   (4-octet time field)
   The validity period of the signature.  This is the number of seconds
   after the signature creation time that the signature expires.  If
   this is not present or has a value of zero, it never expires.
The implication here is that the time of signature creation is the start
of the signature validity period.
It sounds to me like you're asking for the standard to separate out
"signature creation time" from "signature validity start time".
This is an interesting proposal, and i can see why it would make sense
for this scenario.
I can also see it introducing a lot of subtle bugs in what is already a
very nuanced and subtle area (certificate timestamp checking; not just
in OpenPGP either -- the ongoing x.509 discussions about overlapping
windows of certificate validity).
I'm not sure about the tradeoffs here.
      --dkg

@_date: 2015-02-11 09:19:11
@_author: Daniel Kahn Gillmor 
@_subject: Sign key with externalized master key 
The fact that you're using a FAT volume is the root cause here; FAT
filesystems do not have ownership or permissions, so when a modern OS
mounts them, it has to fake permissions for these files.
If you mount the filesystem manually, you can usually specify tighter
permissions.  I don't know the exact syntax for OS X, but on GNU/Linux
systems, that would be:
 mount -t vfat -ouid=$USERNAME,umask=077 /dev/sdx1 /Volumes/FSF
umask is the relevant option here to set the default permissions.
Alternately, if your umask is set properly before mounting the
filesystem, i think mount(8) will just default to it.
            --dkg

@_date: 2015-02-11 15:16:17
@_author: Daniel Kahn Gillmor 
@_subject: moving up from 2.0.26 to 2.1.1 
You don't say how you searched specifically, so i can't say what's gone
wrong in your case.
Here's what i see:
0 dkg at alice:~$ apt-cache policy gnupg2
  Installed: 2.1.1-1
  Candidate: 2.1.1-1
  Version table:
 *** 2.1.1-1 0
          1  experimental/main amd64 Packages
        100 /var/lib/dpkg/status
     2.0.26-4 0
        500  jessie/main amd64 Packages
        200  sid/main amd64 Packages
0 dkg at alice:~$         --dkg

@_date: 2015-02-11 15:22:36
@_author: Daniel Kahn Gillmor 
@_subject: (bug?) Revoked keys and past signatures 
For reference, X.509 does not provide the signing time at all, but has
notBefore and notAfter fields.  Other signed objects that use CMS can
potentially have all three, which is potentially confusing:
  X.509 public key certificates do not specify the time of signature
  generation, but do specify a validity period using the notBefore and
  notAfter fields. For each of the X.509 certificates, the notBefore
  time in the certificate should be used as the digital signature
  generation date.
  The digital signatures on the CHUID, biometric, and security object
  are all encoded as Cryptographic Message Syntax (CMS) external digital
  signatures, as defined in RFC 3852. RFC 3852 defines the signingTime
  attribute, which specifies the time at which the signer (purportedly)
  performed the signing process. If present in a particular object
  (i.e., the CHUID, biometric, or security object), the signingTime
  attribute should be used as the signature generation time. For any
  object that omits the signingTime attribute, the notBefore time
  encoded in the corresponding PIV Authentication certificate should be
  used as the signature generation time.
(the above is slightly out of date, and should reference
 instead of RFC 3852)
        --dkg

@_date: 2015-02-12 18:44:03
@_author: Daniel Kahn Gillmor 
@_subject: MIME or inline signature ? 
This part appears to be out of date:
   Since PGP/MIME can't reliably be sent to the three largest GnuPG
   mailing lists, it?s hard to claim that PGP/MIME is ready for
   widespread usage. For now, it?s best to use inline traffic unless you
   can be certain that PGP/MIME messages will not be mangled in transit.
I don't know if this is true for PGP-Basics, but it is certainly not
true for enigmail or gnupg-users.  Please update the FAQ!
     --dkg, noting the irony of the parent message being sent with
       S/MIME, an entirely different standard

@_date: 2015-02-13 14:03:49
@_author: Daniel Kahn Gillmor 
@_subject: Key keeps showing unknown trust 
I don't think gpg 2.1 will use any pubring.gpg if pubring.kbx exists,
gpg2 --list-keys for me looks at /home/dkg/.gnupg/pubring.kbx even
though /home/dkg/.gnupg/pubring.gpg exists.
       --dkg

@_date: 2015-02-13 16:06:46
@_author: Daniel Kahn Gillmor 
@_subject: moving up from 2.0.26 to 2.1.1 
you should, as long as all of those dependencies are satisfiable in
either debian experimental or ubuntu trusty.  debian experimental is not
guaranteed to have dependencies satisfied internally (debian unstable
users should be able to install experimental packages without trouble
apt will refuse to start the install if it can't satisfy the
dependencies though, so you can try it out without worrying that it'll
leave you in a half-broken state.
I suppose so, but i don't know how you installed 2.0.26 either, so i
don't know how to remove it, sorry!
      --dkg

@_date: 2015-02-13 17:42:34
@_author: Daniel Kahn Gillmor 
@_subject: Sign key with externalized master key 
FAT, alas, is the portable filesystem that you're looking for.
UDF, mentioned elsewhere in this thread, is a read-only filesystem, and
i think it doesn't have ownership or permissions either.
I see two approaches:
 a) figure out how to get each operating system to mount the volume with
    tighter permissions
 b) convince gpg that looser permissions on fat32 filesystems are
    acceptable
I think (b) is the wrong way to go -- gpg is pointing out, rightly, that
your sensitive data is exposed.
So that leaves (a), which probably needs to be fixed anyway.  Your
operating system is exposing sensitive data from your USB stick (which
is supposed to be only yours, since you plugged it in while you were in
control of the machine) to any other user account on the computer.
Reporting this bug to your OS vendor would be a good thing, because it
would help other users of the same OS.
        --dkg

@_date: 2015-02-13 17:23:03
@_author: Daniel Kahn Gillmor 
@_subject: SSH generic socket forwarding for gpg-agent 
Encouraging this kind of use seems risky.  I certainly wouldn't want to
do it without being able to have gpg-agent prompt me on my local machine
for each use of the key.  Its current silent operation once the
passphrase is cached seems ripe for abuse by anyone in control of the
remote account.
Could gpg-agent have a setting (per-key? per-agent?) that would have it
use pinentry for prompting?
The traditional argument against this sort of feature is that someone
with control over your local socket would most likely have control over
your graphical environment, and therefore could dismiss or hide any
prompt that comes up (so the prompting is a false sense of security).
I'm not sure i buy this argument in general (i see it as
defense-in-depth rather than a false sense of security, since it's one
more hurdle the attacker needs to clear), but it certainly doesn't hold
when there is a clear security boundary like gpg-agent forwarded over a
network socket.
        --dkg

@_date: 2015-02-13 23:14:45
@_author: Daniel Kahn Gillmor 
@_subject: Tilde (~) in valid email address 
have you tried adding the --expert flag when doing --gen-key?
if that doesn't work, have you looked into doing batch key creation?
see the "unattended key generation" section of the manual for
explanation of how to do that:
        --dkg

@_date: 2015-02-14 11:26:27
@_author: Daniel Kahn Gillmor 
@_subject: [Announce] GnuPG 2.1.2 released 
Thank you, Werner!  2.1.2 is now in debian experimental, where it builds
cleanly on all architectures:
 Users of debian sid or jessie should be able to upgrade to it from the
experimental archive.  For more information, see:
  The transition to automake 1.14 was painless on the packaging side for
me.  This modernization is much appreciated.
I'm happy to hear this, and glad to see the project getting some of the
support it has long deserved.
All the best,
    --dkg

@_date: 2015-02-15 15:26:24
@_author: Daniel Kahn Gillmor 
@_subject: MIME or inline signature ? 
I feel the same way.
if we're talking about signed messages with the possibility of an
adversary who can modify the messages, then the the fact is that inline
PGP messages have no way of securely indicating the character encoding
in use.  This means that an attacker can actually modify how the
cleartext message is interpreted by fiddling with data *outside* the
message body.
If we're talking about encrypted messages, the same problem holds.
I demonstrate this in the "Message tampering through header
substitution" section here:
 the lesson here is: if you care about getting the intended textual
message through to your peer, you need to embed some information about
the formatting *within* the signature.  PGP/MIME provides a clear,
well-defined way to provide that information.
If we're talking about PGP/MIME encrypted messages, this is not correct.
When having this debate, some people are talking about encrypted
messages; others are talking about signed messages.  there are lots of
ways to talk past one another with this stuff, so please be clear about
whether you're talking about encrypted or signed messages.
     --dkg

@_date: 2015-02-16 00:08:35
@_author: Daniel Kahn Gillmor 
@_subject: SSH generic socket forwarding for gpg-agent 
To clarify what i meant:
My suggestion is to do prompting, but not to require the full passphrase
for each use.
requiring full passphrase for each use often discourages the use of
strong passphrases, esp. if the key is used repeatedly.
I've recorded this suggestion here:
          --dkg

@_date: 2015-02-16 02:41:06
@_author: Daniel Kahn Gillmor 
@_subject: SSH generic socket forwarding for gpg-agent 
Yes, of course.  But the remote machine you're connecting *to* (and
forwarding your agent to) is outside of that trust boundary.
In situations where you want to make sure that you know (and approve of)
the use of the agent by the remote machine, you'd like a prompt to
appear within your (local, trusted) environment.
       --dkg

@_date: 2015-02-16 04:15:10
@_author: Daniel Kahn Gillmor 
@_subject: SSH generic socket forwarding for gpg-agent 
Because saying "i want to forward my agent to remote system X so that i
can sign a couple of specific messages on that host" is different than
saying "i want to forward my agent to remote system X so that X can make
as many uses of my agent's secret key material as can be pushed down the
network pipe".
We're now explicitly enabling people to forward the agent
(e.g. --extra-socket in gpg-agent(1)); we should be providing
appropriate usage controls to accompany that functionality.
   --dkg

@_date: 2015-02-17 19:14:51
@_author: Daniel Kahn Gillmor 
@_subject: Extract passphrase hash 
This is not how OpenPGP passphrases work.  there is no embedded hash of
the password.
For details about how the password is used to unlock the secret key
material, please see:
Secret-Key Packet Formats
 Secret-Key Encryption
  String-to-key (S2K) specifier types:
  In particular:
   Encryption/decryption of the secret data is done in CFB mode using
   the key created from the passphrase and the Initial Vector from the
   packet.
You can use pgpdump or gpg --list-packets on your secret key to see what
the S2K parameters and IV are, and then test passphrases by generating
keys and testing them against encrypted MPI and trailing checksum.  This
is unlikely to work on your GPU cluster without custom coding.
   --dkg

@_date: 2015-02-18 14:13:31
@_author: Daniel Kahn Gillmor 
@_subject: 2.1.2: keyserver route failure 
Reasonable IPv6 stacks should return an ENETUNREACH (Network is
unreachable) error message when trying to connect() to an address for
which there is no route, which should already cause dirmngr to failover
I'm not convinced that it's gnupg's job to compensate for
unreasonably-configured IPv6 stacks that think they have a route but
actually don't.
Should gnupg also try to detect whether the IPv4 networking
configuration is actually correct?  That seems like an operating system
level task.  I certainly don't want all of my client software to always
try to second-guess my netwoking stack, that sounds like a recipe for
         --dkg

@_date: 2015-02-18 14:24:52
@_author: Daniel Kahn Gillmor 
@_subject: Please remove MacGPG from gnupg.org due to serious security 
that's a bummer :( In the Debian Project, we now have a simple framework for including
upstream signing keys and automatically checking them when fetching new
  If you see a debian package that could make use of this but isn't
currently configured to do so, please file a bug report in the debian
BTS (or drop me an e-mail).
If it would help with arguing the case within FreeBSD to see how debian
does it, i'm happy to talk with any FreeBSDers about it too.
    --dkg

@_date: 2015-02-21 11:54:35
@_author: Daniel Kahn Gillmor 
@_subject: Whishlist for next-gen card 
If the malware is keeping the session keys around, it can just keep the
session keys for everything you ever decrypt, and use them anyway to
access your encrypted documents, independent of your button-presses.
You're right in the abstract: the bandwidth of the "canary button" (one
bit of LED output "secret key action requested", one bit of input "ok to
use secret key") is too limited to protect against the sophisticated
attack you describe, and increasing the bandwidth of the channel
(e.g. on-device display screen, keypad) makes the UI/UX even more
infeasibile.  At some point, you just have a second computer attached to
your computer, and now there is room for that second computer to be
compromised :/
None of these tools are perfect, and the goals of a "canary button"-like
scheme are (a) defense in depth, and (b) increased chance of detection.
An adversary *could* mount the sophisticated attack you describe above,
but it's an awful lot of work.  It's much easier to exploit a card that
just accepts the (possibly malware-cached) PIN without one.  The
sophisticated attack is also a piecemeal re-use of secret key material,
and not a flood.  And, if the attacker slips up, it's much easier for
the legitimate user to notice that something funny is happening.
I don't think anyone is claiming that this sort of scheme renders the
device impervious to misuse -- it's connected to a general-purpose
computer with all of its complexity! -- but it raises the bar to an
attacker and provides more defense than an unguarded device.
The non-crypto parts of the system are unlikely to reach the level of
guarantees that modern crypto is capable of providing.  But that doesn't
mean we shouldn't try to improve them.
    --dkg

@_date: 2015-02-21 14:11:55
@_author: Daniel Kahn Gillmor 
@_subject: Unattended signing 
there are risks with unattended signing in general, related to what
messages you allow to get passed to your system.  I'm sure you've
already thought about this, but i'll just put it out there in case
someone else reading this later hasn't thought about it enough.
Using a dedicated key for your system would clearly be better than using
your own personal key, but i don't know if it meets your other
requirements (we don't know your requirements for the system).
Using a subkey is a reasonable approach, and rotating (and destroying)
the secret key of the rotated subkey is not a bad idea.
Take a look at --export-secret-subkeys and the --export-options
"export-reset-subkey-passwd" in the gpg manual for your next steps.
Please report back here if you have any problems.
        --dkg

@_date: 2015-02-21 19:19:32
@_author: Daniel Kahn Gillmor 
@_subject: Question about group line use in GnuPG 
I believe it is supposed to do this already.  It works for me.
What version of GnuPG are you using?  On what platform?  can you share
the exact configuration and commands you're running?  It's hard to help
debug from just the example info you provide here.
      --dkg

@_date: 2015-02-24 17:16:20
@_author: Daniel Kahn Gillmor 
@_subject: Unattended signing 
If your subkey is used for signing, and the subkey is expired, then you
know that you will never want to make signatures with that key again.
That is, only a malicious person who manages to compromise that key
material can make signatures with it.  So why are you keeping it around?
setting a suitable expiry date *should* be enough, but destroying it is
safer, and you have no need to keep the secret part of that key.
           --dkg

@_date: 2015-02-27 10:39:21
@_author: Daniel Kahn Gillmor 
@_subject: Unattended signing 
Signatures are verified with the public part of the key.  I was only
suggesting to destroy the secret part of the key.
           --dkg

@_date: 2015-02-27 21:05:04
@_author: Daniel Kahn Gillmor 
@_subject: Thoughts on GnuPG and automation 
The only part of the UI that the agent controls is prompting the user
for use of the key, and passphrase entry upon unlock.
Why does this break mailpile?  I prefer the agent to have separate UI
from the tool that uses the agent, because i want don't want tools that
use the agent to be able to mask the agent's UI.
I'm quite happy that enigmail (for example) appears to be dropping plans
for non-agent use of secret key material.  this should be a simplifying
change, and it should make it easier for systems to integrate OS-level
prompting and feedback to the user independent of which application uses
the secret key store.
            --dkg

@_date: 2015-02-28 15:09:39
@_author: Daniel Kahn Gillmor 
@_subject: strength of voice authentication [was: Re: German ct magazine 
We had this discussion recently over on messaging at moderncrypto.org.
It's far from "trivial", but breaking voice-based authentication
(particularly in the already-noisy realm of mobile phone calls) with
high probability doesn't seem to be beyond serious researchers.
I recommend reading the thread and the referenced papers:
    --dkg

@_date: 2015-01-14 08:40:23
@_author: Daniel Kahn Gillmor 
@_subject: Are there cases where gpg --verify will exit 0, 
This is not the case.  all processes have a return code, whether they
are invoked by a shell or by other processes.  The return code is a
critical part of the output of a program.
gpg does use the return code to indicate failure of signature
consider the results of:
    echo test1 > test1.txt
    echo test2 > test2.txt
    gpg --detach-sign --armor test1.txt
    gpg --verify test1.txt.asc test1.txt
    gpg --verify test1.txt.asc test2.txt
the return value of the first --verify should be 0, but the second
--verify invocation should return 1, indicating that the signature
cannot be verified over the (different) contents of test2.txt
       --dkg

@_date: 2015-01-15 16:37:00
@_author: Daniel Kahn Gillmor 
@_subject: Subject: cannot build database in GPA in ubuntu and won't 
I'm not seeing this with debian unstable, gpa version 0.9.5-2.  what
version of gpa are you using on what version of ubuntu?
        --dkg

@_date: 2015-01-20 21:36:49
@_author: Daniel Kahn Gillmor 
@_subject: different passwords for subkeys of the same masterkey 
Yes, it is possible.  with gpg 2.1, you can create new subkeys and give
each of them a different passphrase.  I haven't tested with 1.4 or 2.0.
The thing that you're signing with is a key.  it's either your primary
key, or a signing-capable subkey.  Your User IDs are all associated with
your primary directly (and with your subkeys indirectly, through the
primary key).
The OpenPGP standard defines a way to embed the preferred user ID in a
given signature using a "signer's user ID" subpacket [0], but it has
several drawbacks:
 * i'm not sure how to do it in GnuPG, which enigmail relies on for the
   OpenPGP parts, and
 * it's not clear what a receiving MUA should do with that information,
   even if it was present.
So i don't think this is a feature request that makes a lot of sense,
really.  Can you explain more what you'd hope to gain from such a
   --dkg
[0]

@_date: 2015-01-20 22:31:34
@_author: Daniel Kahn Gillmor 
@_subject: gpg-connect-agent querying max-cache-ttl 
You might be interested the command-line tool gpgconf.
For example:
   gpgconf --list-options gpg-agent | grep '^max-cache-ttl:'
the gpgconf(1) manual page has more details.
        --dkg

@_date: 2015-01-20 23:52:24
@_author: Daniel Kahn Gillmor 
@_subject: lock-obj-pub.arm-none-linux-gnueabi.h 
Interesting.  This seems to be identical to the already-present
src/syscfg/lock-obj-pub.arm-unknown-linux-gnueabi.h -- do we actually
need both?
     --dkg

@_date: 2015-01-21 10:50:56
@_author: Daniel Kahn Gillmor 
@_subject: different passwords for subkeys of the same masterkey 
yes, what you're trying to do is rather unusual; enigmail intends to
deliver a smooth and easy experience for the common use case.  It would
be a mistake for enigmail to try to expose something like this.
I don't recommend doing so directly, no.  Your best bet is to simply
choose one of your keys that you want to use going forward; add two new
subkeys to that key; and then set a short expiration date on the other
one or explicitly revoke it.
yes, this is right.  Sorry that i misunderstood your question.
This is a really good point, and i hadn't looked at the enigmail
keysigning experience that way.  I note that you're mailing the
gnupg-users mailing list about this, though, and it's really a question
of the enigmail interface.  GnuPG itself does let the user select which
User IDs to certify during keysigning.
It's probably best to continue this discussion on the enigmail mailing
list (cc'ed here).
I've just filed  to track
the problem.  Feel free to follow up there as well.
        --dkg

@_date: 2015-01-22 15:08:31
@_author: Daniel Kahn Gillmor 
@_subject: Crypto device where I need to confirm every operation? 
Yes, this is certainly possible.  I think some of the yuibkey devices
[0] may support this feature, and it should also be possible (with a bit
of hardware hacking) to do it with the FST-01, which is the platform for
the gnuk [1].
[0]  -- i
    haven't tested, though!
[1] If anyone is considering adding this kind of feature to the FST-01, i'd
be happy to test and debug it with them.
   --dkg

@_date: 2015-01-22 16:55:53
@_author: Daniel Kahn Gillmor 
@_subject: Crypto device where I need to confirm every operation? 
[...]
The attack you describe is significantly more complex and more visible
than the attack the original poster outlined.
Yes, in the long run, if you can't trust your endpoint, you can be
But this is a game of defense in depth, and the proposed changes seem
like a useful step in raising the bar for an attacker.
     --dkg

@_date: 2015-01-22 20:20:39
@_author: Daniel Kahn Gillmor 
@_subject: Crypto device where I need to confirm every operation? 
Awesome.  the expansion port should be usable for wiring up the button:
We might also want an independent LED to signal that the "user presence
test" is demanded -- so that LED indicators for device activity aren't
confused with the request for user presence.
I haven't looked into what it will take to make the "user presence test"
a part of the signing process, though.  Maybe NIIBE Yutaka can chime in
about the best way to do that?
      --dkg

@_date: 2015-01-23 10:22:52
@_author: Daniel Kahn Gillmor 
@_subject: Talking about Cryptodevices... which one? 
I don't know that it supports x.509 certificates explicitly right now,
but the gnuk (running on the FST-01) has free firmware and is under
active development.  gniibe (who i think is active on this list, but i'm
cc'ing here anyway) is lead on development for that project.
"Certificate support" is a bit of an odd question, because the cards
specifically deal with secret key material, which isn't any sort of
certificate at all -- the certificate is a wrapper around a public key
that happens to be associated with the secret key.
You can have a secret key that is associated with both an OpenPGP
certificate and an X.509 certificate if you like.
the FST-01 is available for a little under $40 USD, depending on the
physical form factor you want:
             --dkg

@_date: 2015-07-02 12:40:13
@_author: Daniel Kahn Gillmor 
@_subject: [Announce] Pinentry 0.9.5 released 
is the purpose of these experiments to build skills with software
compilation or other system management? one approach is to wait a couple days for one of us to get around to
packaging it for debian :)
there should be no reason to do the build in /usr/local explictly.
by default, pinentry doesn't install any shared libraries or development
headers at all.
        --dkg

@_date: 2015-07-19 01:42:34
@_author: Daniel Kahn Gillmor 
@_subject: High resource usage when verifying a signature 
Hi Johannes--
what version of gpg2 are you using?
I suspect what's taking a long time is an update to the trustdb.  one
workaround is to put no-auto-check-trustdb in ~/.gnupg/gpg.conf, and
then have a nightly cronjob that runs "gpg2 --check-trustdb".
     --dkg

@_date: 2015-07-22 11:46:44
@_author: Daniel Kahn Gillmor 
@_subject: [openpgp] Unuploadable Keys 
if we were to have a cryptographically-validating keyserver, there's no
way that the certificate could be verified.
I'm not clear what the use case for this is. people who "want their
public key to be not-public" probably actually care more about:
 * avoiding publication of their User ID, and
 * avoiding publication of a persistent identifier that can link
   communications together
both of these things would probably fail if the key (even obscured) was
published to the public key servers.
I don't see how this proposal solves the identified concern (though it's
possible that i'm misunderstanding the identified concern).
  --dkg

@_date: 2015-07-29 12:34:52
@_author: Daniel Kahn Gillmor 
@_subject: Is there a way to comment a key locally? 
That's exactly what i do with a small (fairly clumsy) script "lcert":
read -e -p 'lsig reason: ' reason
gpg2 --lsign --cert-notation "lsigreason at notations.openpgp.fifthhorseman.net=${reason}" "$1"
the main issue is when the cert i'm making such a notation on has
multiple user IDs and then gpg falls back to prompting whether i want to
sign all uids or not -- if i say "no", then i have to select the
relevant uids, and then type "lsign" and "save" in the gpg subshell.
note that this has the side effect of marking every lsigned key+user id
as valid (since i'm certifying it with my own key).
If that's not what you want, you can also just keep a separate text file
(or addressbook or whatever data storage you're most comfortable with)
with your own notes about the person/key in question.
   --dkg

@_date: 2015-07-29 21:02:17
@_author: Daniel Kahn Gillmor 
@_subject: Is there a way to comment a key locally? 
Sure, that would work.  But if you're going to do that, why not just
keep the info in your associated addressbook or other handy
database/textfile?  the GnuPG keyring isn't the most efficient data
store for arbitrary data.
      --dkg

@_date: 2015-06-02 10:43:36
@_author: Daniel Kahn Gillmor 
@_subject: man page refers to "conventional encryption" -- does this mean 
Hi GnuPG folks--
I just noticed that a couple places in doc/DETAILS and doc/gpg.texi
refer to "conventional encryption".  Does this mean "symmetric
encryption" or something else?
More concretely, i'm assuming it refers to "SKESK[0]-prefixed SEIPD[1]
packets".  Is this correct?
In 2015, i'm not sure whether this is any more "conventional" than
PKESK-prefixed SEIPD packets.  Should the term be explained somewhere?
   --dkg
[0] Symmetric-Key Encrypted Session Key Packets
    [1] Symmetrically-Encrypted Integrity Protected Data packets

@_date: 2015-06-02 13:29:42
@_author: Daniel Kahn Gillmor 
@_subject: s2k-cipher-mode default 
I agree with you that these comparisons are a decent rough estimate when
considering attacking a single ciphertext.  But i don't think the
argument holds looking at the bigger picture.
Let's consider an adversary that can store as many OpenPGP-encrypted
messages as it has access to.  Maybe it sniffs SMTP traffic as well?  If
the attacker is interested in breaking the crypto of any *one* of these
messages, it can reduce the amount of work it has to do significantly.
As djb put it:
 -- Note that he's describing a known-plaintext attack; this might be
relevant, for example, if there is a standard prefix of the data being
encrypted (perhaps a common MIME header?  or if you're doing regular
backups of a standard filesystem, the beginning of the tar format?).
Of course, there aren't 2^50 AES-128-encrypted known-plaintext OpenPGP
messages today that such an attack would work on.  but why would we want
to leave users open to this?
Is the above argument enough for you?  Remember that these AES128
ciphertexts are likely to exist well into the future, and attacks only
get better with time.
            --dkg

@_date: 2015-06-02 14:37:29
@_author: Daniel Kahn Gillmor 
@_subject: s2k-cipher-mode default 
To be clear, it's not "one of my keys" in the asymmetric key sense,
where you, rjh, have only a handful over your lifetime.  Every time you
send an encrypted message, GnuPG generates a new AES key to encrypt that
message with.  So "one of my messages' keys" is more accurate.
And (sorry Rob) i don't care only about your keys (or your messages'
keys).  I care about all the messages ever generated by GnuPG.  If an
attacker can do 2^78 computations, I'd prefer it if they couldn't
break even one of the messages ever created by GnuPG.  I don't get to
decide which of our users to throw under the bus in that case.  But if
we move to AES-256, we remove this attack, which means that none of our
users get thrown under this particular bus.
Given that these calculations are not a bottleneck for users, we should
move them all to the stronger cipher by default.
[ note that the argument here is now heading toward "what should the
  default cipher be?", though i started with "what should the default
  s2k cipher mode be?" -- I still want to focus on the s2k mode
  question, because it protects secret key material, and i think that's
  higher priority and an even more-obvious win; i'm happy to broaden the
  discussion as long as it doesn't distract from the s2k-cipher-mode
  question ]
I don't think so.  He is thinking about the whole field, though, rather
than thinking about "what are the chances that a baseball will happen to
land right where i'm standing right now?"  I also care about the whole
        --dkg

@_date: 2015-06-02 18:44:00
@_author: Daniel Kahn Gillmor 
@_subject: s2k-cipher-mode default 
I mentioned the possible interoperability concern in my first post on
this thread.
This is not true.  symmetric algorithm selection during decryption is
done based on the metadata parameters stored in the SKESK packet, which
indicate which cipher to use.  As long as the peer can do AES256 (and
all reasonably modern OpenPGP implementations can), no additional
configuration is needed:
0 dkg at alice:~$ echo test | gpg2 --symmetric | pgpdump
Old: Symmetric-Key Encrypted Session Key Packet(tag 3)(13 bytes)
New: Symmetrically Encrypted and MDC Packet(tag 18)(58 bytes)
0 dkg at alice:~$         --dkg

@_date: 2015-06-03 10:01:27
@_author: Daniel Kahn Gillmor 
@_subject: s2k-cipher-mode default 
I think you're referring to:
        These describe so-called "related-key" attacks, where the attacker knows
that two AES keys are related to one another in a specific way
(e.g. they know the XOR of the two keys), and can force operation of the
cipher with these two keys:
  OpenPGP in general (and GnuPG in specific) does not have any mechanism
whereby an attacker can force a user to use two symmetric keys that it
knows to be related to one another.  I don't think these attacks are
        --dkg

@_date: 2015-06-03 17:08:02
@_author: Daniel Kahn Gillmor 
@_subject: Problem compiling gnupg on Ubuntu 14-04 
You haven't described how you set up your build environment, or how
you're approaching the build process at all.
Do you have libgcrypt20-dev installed? [0]
On debian-derived systems, i'd expect a build to look something like:
as root, get the expected build dependencies:
  # apt-get build-dep gnupg2
as a normal user:
  $ tar xzf gnupg-2.0.28.tar.gz
  $ cd gnupg-2.0.28/
  $ ./configure # your options here...
  $ make
  $ make check
is this what you're doing, or are you doing something else?
   --dkg
[0]

@_date: 2015-06-10 15:27:10
@_author: Daniel Kahn Gillmor 
@_subject: Installing GnuPG 2.1.4 in Debian Experimental 
So this is a dependency issue: jessie is debian stable, but gnupg2 is
built against unstable, which has changed since jessie was released.
In particular, gpg-agent, dirmngr, and scdaemon all use
assuan_sock_set_sockaddr_un() if available, which was only introduced in
assuan 2.2.0, which is only available since assuan 2.1.4; jessie only
has 2.1.2.
This can be addressed for jessie in one of two ways:
 0) we can create a backport for more a modern version of libassuan,
    which should allow installation of the experimental package directly
 1) we can create a backport for gnupg 2.1.x direclty, using jessie's
    version of libassuan.
approach (1) won't work right now because jessie-backports only allows
packages that are already in testing, and 2.1.x is only in experimental.
I'm cc'ing the pkg-gnupg-maint team in debian to see whether Eric
Dorland (the team member who has been most responsible for assuan in
debian) thinks there are any problems with approach (0).  If not, maybe
he'd be up for maintaining a jessie-backports version of the more recent
libassuan, which should let all debian jessie users install gnupg2 2.1.x
from experimental.
     --dkg

@_date: 2015-06-11 00:01:07
@_author: Daniel Kahn Gillmor 
@_subject: State-of-the-art way to setup a shared security@ email with 
Hi Simon--
Thanks for the interesting use case.
I like this approach for encryption to the team; i think it's definitely
better than the server that does decryption/reencryption.
Another (much weirder) remailer approach that doesn't expose the content
to the remailer itself uses El Gamal keys that have a known relationship
to each other.  The remailer can transform the PKESK in such a way that
it is readable to each peer, without being able to recover the
This is the approach used in PSELS:
   This still has the awkward key distribution step when new members join
the team -- you have to generate their encryption-capable secret key and
get it to them.
But for revocation for user X in this case, you'd just tell the server
to stop PKESK translation for the corresponding offset for user X -- no
certificate update is necessary, and no redistribution to every
remaining team member.
I note that you're asking here only about the encryption-capable
subkeys, and not signing subkeys -- it's quite possible that your
correspondents would like to be cryptographically confident that the
reply messages come from the team, and not from an imposter.
Interestingly, the case for signing-capable subkeys is not symmetric
with the case for encryption-capable subkeys.  It should be possible for
each of your members to contribute a distinct signing-capable subkey,
and you'd attach all of them to the primary key.
There are two approaches to this:
 a) you could have each person generate their own signing capable
    subkey, create the binding cross-sig with it to the primary key, and
    send the public part + the cross-sig to the team keyring maintainer,
    who would bind it as a subkey and publish the updated cert.
 b) during generation of the per-person encryption-capable subkey, you
    could go ahead and generate a separate signing-capable subkey for
    that user and pre-install it on the smartcard.
the advantages of this individualized signing-subkey scheme (using
either approach above) over a single-shared-signing-subkey are:
 0) you can do individualized revocation without reissuing new
    signing-capable subkeys for everyone else.
 1) you don't have to keep the signing-capable subkey on hand at the
    keyring management site in order to enroll new team members.
 2) when a message coming from the team is signed, you can identify
    which team member made the signature.
        --dkg

@_date: 2015-06-15 13:33:06
@_author: Daniel Kahn Gillmor 
@_subject: Installing GnuPG 2.1.4 in Debian Experimental 
while  is https, the mirrors it points to
are cleartext http.  And indeed, debian has little control over the
mirrors we link to, since they're provided by (hopefully friendly) third
the recommended way to verify packages is by using apt.
yes, it would.  This is a tradeoff between running "stable" and running
no, apt does not downgrade by default.
no, upgrades from stable to testing are usually something that works
fine (with the caveat being the lower stability of the testing distro).
yeah, we're probably off-topic here by now.  hopefully these general
outlines are useful to others reading the list or the archives, though.
         --dkg

@_date: 2015-06-29 12:45:34
@_author: Daniel Kahn Gillmor 
@_subject: Adding a subkey notation 
i've done this myself by clearing all the usage flags and using
--cert-notation.  But see the gnupg-devel thread from 2013 starting at
into.   Hopefully they're all fixed by now, but external verification
would be welcome.
you generally don't want to change already-existing subkeys.  You can
just create a new subkey and set the notations on it.
The IANA registry currently contains no entries:
        --dkg

@_date: 2015-03-02 00:34:55
@_author: Daniel Kahn Gillmor 
@_subject: Decrypting PGP/MIME on the command line 
python's email module is quite good for programmatically handling mime
parts if you want to manipulate an e-mail (though it may not be so good
for reconstructing it in some sort of bytewise exact fashion).
You should also note that any decryption like this is likely to remove
any OpenPGP signature as well, for those MUAs that do the
encryption+signing step all in one OpenPGP piece (i believe that the
gpgtools mail.app plugin places the OpenPGP signature inside a
multipart/signed MIME message, which is then itself encrypted, rather
than placing encryption and signatures all in the OpenPGP part
A tool that transforms an OpenPGP encrypted+signed MIME message into an
OpenPGP-signed MIME message while retaining the original signature would
be a really nice tool to have.
 --dkg

@_date: 2015-03-17 13:38:03
@_author: Daniel Kahn Gillmor 
@_subject: Making the case for smart cards for the average user 
This might be a bug (or at least a well-warranted feature enhancement)
in GnuPG.
I've just opened  to track it.
     --dkg

@_date: 2015-03-17 18:26:02
@_author: Daniel Kahn Gillmor 
@_subject: Defaults 
For debian stable, this is likely to be the case because of where we
were in the release cycle when 2.1 was finally released.
I hope to have 2.1.x in debian testing and unstable shortly after we
manage to release jessie, and hope to move to it as the default either
for "stretch" (the release after jessie) or (if things turn out to be
much more complicated than i'd like) stretch+1.
I agree that defaulting to brainpool-512 right now would be a mistake.
Defaulting to RSA 3072 seems reasonable to me, though.
    --dkg

@_date: 2015-03-17 18:53:48
@_author: Daniel Kahn Gillmor 
@_subject: Defaults 
by this argument, you should have pushed for RSA 3072 during the last
defaults change, since it would have lasted longer than 2048 ;)
Except that by the time we're ready to adopt ECC by default we may very
well want to use Goldilocks (Hamburg's 448-bit curve), since that seems
to be the high-strength curve that the CFRG is heading toward (yes,
goldilocks is not yet specified for OpenPGP; we'd need to do that
Brainpool-512 is incompatible with some of the other work going on in
the OpenPGP ecosystem (e.g. yahoo and google's work on the e2e webmail
app, which supports P-256 and P-512).
At any rate, changes are afoot, and i don't think we should be afraid to
update the defaults if we think a new set is reasonable.
   --dkg

@_date: 2015-03-17 19:28:47
@_author: Daniel Kahn Gillmor 
@_subject: Defaults 
Is this correct?  I think we should be defaulting to SHA-256 for RSA
certifications these days.
If we want to cater to users who really want their certifications to
have compatibility with buggy 10-year-old clients that don't have
SHA-256, we should make it easy for them to make a SHA-1 certification
with a 1-second-earlier timestamp.
I think you mean signatures *by* (EC)DSA keys, not *on* (EC)DSA keys,
  --dkg

@_date: 2015-03-17 21:28:36
@_author: Daniel Kahn Gillmor 
@_subject: what is the proper way to load gpg-agent with systemd 
I don't know what "pass" is, but i guess it's how you trigger pinentry
to talk to your agent?
it sounds to me like you're saying that the agent started by systemd
doesn't know how to find your X11 session properly, so it doesn't know
how to launch pinentry on its own.
Does that sounds like an accurate characterization?
have you tried adding the following line to the [Service] stanza in your
.service file?
Try that, and then a full machine shutdown, restart, and login.  It's a
workaround at best (your $DISPLAY won't always be :0) but if it works
for you, you'll know that this is at least the right diagnosis.
    --dkg

@_date: 2015-03-17 21:43:18
@_author: Daniel Kahn Gillmor 
@_subject: Making the case for smart cards for the average user 
This discussion has been about gnupg and its own keyring, not
necessarily about keyservers.  The bug report i filed referred to local
gpg activity, not keyserver activity.
    --dkg

@_date: 2015-03-18 08:38:14
@_author: Daniel Kahn Gillmor 
@_subject: What am I doing wrong? 
the -u myuser at domain.net is not doing anything here, because this is
doing encryption and not signing.  so no secret key material is used in
this step.
It sounds to me like you imported your public key but not your secret
Does your key show up in the output of "gpg --list-secret-keys"  ?
     --dkg

@_date: 2015-03-18 18:18:53
@_author: Daniel Kahn Gillmor 
@_subject: SKS Keyserver, HKPS, and GnuPG 2.1 
It looks to me like you're using the server's certificate as the CA
certificate.  I don't think that's going to work.  Maybe you want to use
the Addtrust root cert (attached here)
and then point hkp-cacert to that?
    --dkg

@_date: 2015-03-20 14:47:49
@_author: Daniel Kahn Gillmor 
@_subject: Email-only UIDs and verification (was: Making the case for smart 
There are a lot of proposals in this thread, and you didn't trim the
quoted text to isolate just one of them; can you be specific about which
one you're talking about?
I think you're talking about the proposal to have a verification service
send regular e-mails asking users to follow up on them.
If the followup is just "click this link" then i agree it's probably
encouraging bad habits.  What if the suggested followup was an e-mail
reply?  What if we require the verifier to sign its outbound messages,
and tell users "don't do this unless the message is signed by the
I'm still not sure how useful this is in the big picture -- is such a
verifier only for first-contact, or is it supposed to be useful
longer-term as well?
        --dkg

@_date: 2015-03-22 16:27:51
@_author: Daniel Kahn Gillmor 
@_subject: Error Installing gnupg-2.0.27 on Debian Squeeze 
Hi Angel--
it's looking for libgcrypt20, which is not available in squeeze.  Maybe
you've tried to build it pointing at the wrong libgcrypt?  squeeze
only has libgcrypt11, version 1.4.5.
what is the output of:
  dpkg -l 'libgcrypt*
It should show you a -dev package and a regular non-dev package as well,
most likely of libgcrypt11.
You'll either need to backport a new libgcrypt, or to point the compiler
(during ./configure time?)  toward the right libgcrypt-dev variant.
        --dkg

@_date: 2015-03-31 17:33:55
@_author: Daniel Kahn Gillmor 
@_subject: Instructions for converting keyring for 2.1 
============================== START ==============================
This doesn't appear to have been updated upstream yet, but i agree with
Peter Lebbing's suggestion here.  Would presenting the patch in some
other way (e.g in git format-patch style?) be helpful?
        --dkg

@_date: 2015-05-01 09:57:27
@_author: Daniel Kahn Gillmor 
@_subject: How to get my GNUPG Elgamal private key exponent? 
pgpdump shows that x is encrypted.  pgpdump isn't capable of decrypting
If you remove the passphrase from your secret key, you should be able to
produce a file that pgpdump can parse for you.
however, note that this places your secret key material is a very
exposed place -- anyone who gets that file can trivially compromise your
Since el gamal keys are usually subkeys, you might try *only* exporting
the subkey without a passphrase, so that at least you do not expose the
secret key material for your primary key.
Using gpg 1.4.x or 2.0.x, that should be possible with:
gpg --export-options export-reset-subkey-passwd --export-secret-subkeys ${SUBKEYID}\! | pgpdump
yes, that is a literal ! at the end.  so if your subkey ID is
0x1234567890abcdef, then you would run:
gpg --export-options export-reset-subkey-passwd --export-secret-subkeys 0x1234567890abcdef\! | pgpdump
        --dkg

@_date: 2015-05-01 22:36:47
@_author: Daniel Kahn Gillmor 
@_subject: Multiple Smartcards - Signing 
I think this is the crux of your issue.  It sounds like a bug to me.
I've opened a bug report about it:
         --dkg

@_date: 2015-05-03 15:16:40
@_author: Daniel Kahn Gillmor 
@_subject: Multiple Smartcards - Signing 
I don't have much of a preference.  Such a message should probably
appear if the user has asked for --debug-level basic at least, though.
       --dkg

@_date: 2015-05-15 10:36:40
@_author: Daniel Kahn Gillmor 
@_subject: What Linux kernel configuration options are required by GPG for 
shouldn't dirmngr know enough to stop trying v6 addresses when v6 isn't
shouldn't dirmngr know enough to stop trying v4 addresses when v4 isn't
These seem like parallel problems to me, but maybe i'm missing
something.  Can you explain why the situations are different?
And just to clarify, which of the following best characterizes the bug
(or something else?):
 0) dirmngr can't talk to keyservers on networks it does not have access
    to.
 1) dirmngr tries to access keyservers on networks it does not have
    access to.
 2) dirmngr reports errors when trying to access keyservers on networks
    it does not have access to.
 3) dirmngr fails to try other addresses on networks it does have access
    to when some addresses fail.
        --dkg

@_date: 2015-05-15 15:23:08
@_author: Daniel Kahn Gillmor 
@_subject: Removing hkp from server 
Sorry, you probably can't get them removed.
I suspect you mean hkp://keys.gnupg.net, which is an alias to the main
keyserver pool, which is described here: The keyserver pool is deliberately append-only.  See for example, this
         --dkg

@_date: 2015-05-21 12:23:20
@_author: Daniel Kahn Gillmor 
@_subject: [Enigmail] Popescu and keys 
At least one of the keys he claimed to have broken is a degraded copy of
one of H. Peter Anvin's actual subkeys, as Hanno B?ck pointed out here:
 To my knowledge, Mircea (cc'ed here) has not retracted this particular
claim, despite having issued at least three updates to his initial
report about this key (which is not behind a paywall at the moment):
   Which key does he claim to have broken?  If Mircea has broken your
encryption-capable subkey (0xB8A6B74C001892C2) then he might only be
able to decrypt messages sent to you, but not sign them.
To provide him with an opportunity to demonstrate this (Hi Mircea!),
i've produced this message, encrypted to rjh's encryption-capable
Mircea, if you can decrypt it, you should find a secret message, signed
by me, which includes within it the message-id of the e-mail i'm
replying to.
You can either produce the session-key (e.g. with gpg
--show-session-key) or produce the signed message to demonstrate that
you have control of Robert's secret key material:
Given the poor communication patterns and lack of retraction of
unfounded claims, i'm not currently worried that this is a real attack.
I am prepared to take it seriously if Mircea can follow up effectively
on either of the challenges here, though.
        --dkg

@_date: 2015-05-21 15:21:10
@_author: Daniel Kahn Gillmor 
@_subject: OPENPGP URI PROPOSAL 
This proposal appears to be trying to do a lot of different things.  I'm
not convinced that they are all reasonable goals, or that gnupg-users is
the right mailing list to discuss them on.  The openpgp at ietf.org is a
mailing list where different people discuss the standard in general.
The example you give toward the end of the spec (uri handlers in web
browsers) is an important example for arguing why something like this is
concretely useful.  Have you tried to implement this?  Can modern web
browser handlers work with arbitrary length data?  When i try to trigger
a local handler for an unknown schema in iceweasel (firefox) i see this
with no option to choose an external handler or anything.
Chromium, on the other hand, offers to launch "xdg-open" with that URL
as the parameter, which fails because no handler is registered for the
scheme in question.  Is this the intended mechanism, or something else?
There is already a vCard spec for a full pubkey -- though you might
actually mean "transferable public key" or OpenPGP certificate:
  When is this useful?
what about a message that is both signed and encrypted?  how should it
be represented?
These seem more likely to be handled by vCard or some similar approach
to me.
These fingerprints are only 128 bits long, which matches the OpenPGPv3
fingerprint format.  OpenPGPv4 fingerprints are 160 bits long, and any
new fingerprint standard might be longer still.
Your proposal here doesn't mention any sort of versioning for
fingerprints, or take into account other concerns.
A large discussion about fingerprint encodings for low-bandwidth
transmission can be found here:
    --dkg

@_date: 2015-05-21 15:45:06
@_author: Daniel Kahn Gillmor 
@_subject: [Enigmail] Popescu and keys 
I've been informed by Mircea offlist that he has no interest in
continuing this conversation, so i'm dropping him from CC here.
It appears to me that he has nothing concrete to demonstrate, and he has
shown an inability to correct factual errors he has already published.
Not very impressive :(
I think there's nothing interesting to see here, but if i hear anything
more substantive, i'll be sure to follow up on this thread to let people
  --dkg

@_date: 2015-05-22 10:54:02
@_author: Daniel Kahn Gillmor 
@_subject: OPENPGP URI PROPOSAL 
Hm, i asked "have you tried to implement this?", but it doesn't sound
like you have.  Maybe it's worth trying to get something working, and
then report back with what you've found?
What is the issue, exactly?  Have you or someone else reported it to
firefox?  How should firefox behave?
sure, but about:preferences doesn't show me openpgp: at
all, and i see no way to add such a handler.
     --dkg

@_date: 2015-05-22 12:03:09
@_author: Daniel Kahn Gillmor 
@_subject: Lower Bound for Primes during GnuPG key generation 
I think you're calculating the wrong thing.  That same link points out
that the number of primes less than x can be approximated as
pi(x) = x/(log(x)-1).
Very rough approximation below, dealing with this stuff in integer so i
don't have to worry about floating point precision:
import math
def pi(x):
    return x//(int(math.log(x) - 1))
print(pi(2**2049) - pi(2**2047))
That's a lot of primes to choose from! :)
Why should GnuPG reject these primes?  Surely, it wouldn't want to both
elements of a pair like that (i.e. for RSA you don't want q = p+2
because it's a trivial test to factor that composite), but is there a
reason to reject using a p that meets these categories with some other,
unrelated q?
          --dkg

@_date: 2015-05-22 13:34:47
@_author: Daniel Kahn Gillmor 
@_subject: Lower Bound for Primes during GnuPG key generation 
]
there's no risk that GnuPG will choose a Sophie-Germain prime with its
corresponding safe prime, because as Werner said, it chooses the size of
the primes (in bits) and then sets the highest bits to 1.  Since the
sizes are the same, the S-G/safe pair isn't possible (the safe prime is
always 1 bit longer than the S-G prime).
That leaves the twin prime case.  I don't know whether GnuPG rejects
that selection, but the chance of stumbling into a twin prime pair
during random prime selection seems staggeringly low to me.
             --dkg

@_date: 2015-05-27 16:41:25
@_author: Daniel Kahn Gillmor 
@_subject: Random Seed for Generating PGP Keys 
Wikipedia sees itself as not a place to publish original research, and
they frown on self-linking to avoid .
However, i think NeuG is clearly a valuable reference for people trying
to understand HWRNGs, and my linking to it is not a self-link.
So i've added a citation there:
  Thanks for your work on this, gniibe!
       --dkg

@_date: 2015-05-27 22:40:44
@_author: Daniel Kahn Gillmor 
@_subject: Trying to install version 2.1.4 
Sorry, i'm aware of this but terribly behind on a lot of other
projects.  I do hope to get to it "real soon now", but i don't know how
long that will take.
     --dkg

@_date: 2015-05-28 01:45:03
@_author: Daniel Kahn Gillmor 
@_subject: Trying to install version 2.1.4 
OK, i've uploaded 2.1.4 to debian/experimental.  I wanted to upload it
to debian/unstable, but we have more planning to do before i make that
move, and it seemed faster to just get 2.1.4 in place.
please let me know if you have any problems with the 2.1.4 package from
experimental once it hits the repositories (hopefully within a day).
happy hacking,
      --dkg

@_date: 2015-05-30 23:04:36
@_author: Daniel Kahn Gillmor 
@_subject: Trying to install version 2.1.4 
============================== START ==============================
No offense taken, and it turned out to be a useful nudge for me anyway

@_date: 2015-11-27 11:27:56
@_author: Daniel Kahn Gillmor 
@_subject: gpg-agent prompt slow to show up 
I have yet to be able to replicate this myself, but i've seen other
people have this problem when they're using pinentry-gtk-2 or
pinentry-gnome3 and they have something wrong with their dbus setup
related to localization (l10n) or accessibility (a11y).
In particular, there appears to be a 25000 millisecond (25 second)
timeout in some gtk frameworks while trying to look for the dbus service
named "org.a11y.Bus".
I think: in a proper installation, dbus would either provide a
connection to this service (if installed) or immediately reject the
request (if not installed) so the 25 second timeout should never take
effect.  But i've never been able to replicate this problem myself.
On the (debian unstable) machine of my colleague where we tracked it
down this much, the problem was resolved after reinstalling
at-spi2-core, but it didn't return after we removed it again.
Sorry to not have a clearer diagnosis, but hopefully this will help
point you in the right direction.
If you figure out the problem and what it's related to, i'd love to hear
more details so we can avoid it happening to other people in the future.
     --dkg

@_date: 2015-10-01 10:29:14
@_author: Daniel Kahn Gillmor 
@_subject: AW: Seperate Session Key and Encrypted Data 
The OpenPGP standard leaves this sort of approach open.  GnuPG
facilitates some part of it, but not everything.
First, take a look at --show-session-key and --override-session-key --
this makes it possible to extract a session key from an existing PKESK
or SKESK packet, and to use a known session key to decrypt a packet.
You should be able to use the gpgsplit tool to take a stream of packets
and split it into individual files.  You can use /bin/cat to collect a
set of individual files and reassemble them into an OpenPGP packet
So the only functionality GnuPG is missing to assemble the workflow
you're describing would be a new GnuPG command named something like
--generate-pkesk-with-session-key.  If that command was available, the
full workflow described by the original poster would be something you
could probably cobble together with a couple shell scripts.
Note: this is *not* something i'd want people to do as part of the
normal user interface of GnuPG.  This is a feature that would be useful
for GnuPG as an OpenPGP programming toolkit.  The fact that GnuPG is
widely used as both a user-facing tool and as a programming toolkit is
one of the things that makes it less convenient for both use cases :(
      --dkg

@_date: 2015-10-03 12:30:18
@_author: Daniel Kahn Gillmor 
@_subject: AW: Seperate Session Key and Encrypted Data 
AES is a cipher for a single block.  For files larger than the block
size, you'll need to use it in some sensible mode like AES-GCM.  All
modes of course require a high-entropy key and some of them require a
well-chosen nonce or IV (initialization vector).  Please use caution in
making these decisions!
       --dkg

@_date: 2015-10-03 12:16:23
@_author: Daniel Kahn Gillmor 
@_subject: AW: Seperate Session Key and Encrypted Data 
Do you mean "more generalized" than generate-pkesk-with-session-key?  Do
you have a spec for what you want this command to be?  Can we open a
ticket about the feature to keep track of the objective?
       --dkg

@_date: 2015-10-31 07:57:47
@_author: Daniel Kahn Gillmor 
@_subject: "invalid option: --agent-program" 
[...]
Looks like it's a documentation issue to me.  this option is present in
2.1.9-2.  There are other bugs with the 2.0.x documentation, i think,
where features from the 2.1.x branch slipped into the 2.0 docs.
We're in the process of moving off of the 2.0.x branch to the 2.1.x
branch in unstable, and this is a minor documentation bug, so it's
unlikely to be fixed in the jessie (stable) release.
sorry about this,         --dkg

@_date: 2015-09-08 14:19:26
@_author: Daniel Kahn Gillmor 
@_subject: Temporary lock files? 
I don't know of any such cronjob in debian.  Would you expect this to be
something system-wide, or run on a per-user basis?
for lockfiles that are relevant only to the running system (as this
would seem to be, since it has the hostname in it), the usual place
these would go on a modern distro is $XDG_RUNTIME_DIR (typically
ephemeral, involve no disk access for filesystem modifications, and are
automatically cleaned up upon restart.
Should we be changing the default location of the lockfiles on modern
linux/unix distributions of GnuPG?
For home directories accessed on multiple machines simultaneously
(e.g. NFS-mounted homedirs), are the locks required to work across
              --dkg

@_date: 2015-09-10 18:15:51
@_author: Daniel Kahn Gillmor 
@_subject: plaintext non-ssl distribution - who things this is a good idea? 
This is not an either/or scenario, please don't pit the one project
against another.
Both can be addressed by dealing with the CA cartel.  It's frustrating
to do this, because we all know that the CA cartel is not particularly
trustworthy as a whole.  But this is a "trusted introducer" problem, and
the cartel is the only set of trusted introducers available to people
who don't already have GnuPG.
There is already discussion about getting HTTPS set up for gpg4win.org.
Bernhard Reiter (cc'ed here) knows about it, and other offers of help
have already been made over on gpg4win-users-en at wald.intevation.org,
which is a better place to discuss gpg4win-specific issues.
It's more an issue of getting an admin to spend a couple hours coaxing
the website into compliance and dealing with the fallout from the SNI
Bernhard, is there anything else the rest of us can do to get this ball
        --dkg

@_date: 2015-09-14 10:43:05
@_author: Daniel Kahn Gillmor 
@_subject: uploading subkeys 
a Transferable Public Key (aka "keyblock" and "OpenPGP certificate") is
defined here:
           --dkg

@_date: 2015-09-16 23:25:11
@_author: Daniel Kahn Gillmor 
@_subject: [HowTo] use gpg2.1 with an onion service 
These are reasonable recommendations.  thanks for documenting how to use
dirmngr with tor.  (use-agent isn't necessary for gpg 2.1, but it
doesn't hurt)
We may at some point get a --use-tor flag for dirmngr, which should
simplify things further.
and if you don't use a .onion address, the exit node operator and anyone
on the network path between the exit node and the keyserver could be
able to figure it out as well.
Right, though the plan within debian at least is to change that and ship
2.1 as /usr/bin/gpg, hopefully before we release stretch.
All the best,
    --dkg

@_date: 2015-09-24 23:09:28
@_author: Daniel Kahn Gillmor 
@_subject: unlock keychain with pam authentication 
You might be interested in libpam-poldi:
 I'm not sure if it meets your particular goals/use cases, though.
There are some conceptual caveats to what you're proposing: Note that a
user's GnuPG secret keyring potentially contains multiple secret keys,
and each secret key could be encrypted with a different password.  which
secret key would need to be decrypted to make that work?
Potentially even scarier, if i can convince you to import key material,
i could give you a secret key that is set with a passphrase that i
know.  Once you've done that, if the PAM module allows me to connect
if i can unlock any key, then i could use it to unlock your account!
You could also consider a more integrated desktop environment like
GNOME, which has a single keyring/password manager that is integrated
with account login.  GNOME's keyring can be used to also talk to
gpg-agent if both tools are configured to do so.
        --dkg

@_date: 2015-09-28 13:03:10
@_author: Daniel Kahn Gillmor 
@_subject: unlock keychain with pam authentication 
This suggests that you're interested in a pam module that verifies that
you can unlock any secret key associated with the ID stored in
~/.password-store/.gpg-id, then the user can log in.  Does that sound
Or maybe you want your PAM module to test that given ~/.gnupg and
~/.password-store, the user-supplied password is capable of decrypting
some specific entry in pass?
either way, i think you're asking for something that is custom to your
i send you a file dkg.asc that contains my OpenPGP certificate, and ask
you to import it into your keyring.  you do "gpg --import dkg.asc".
But in that file, in addition to my actual OpenPGP certificate, i've
included an additional certificate that has your own user ID on it
("SGT. Garcia "), uses a novel secret key, and
that secret key is encrypted by a password i know (let's say it's a
terrible password, like "bananas").
Now, if your proposed setup is in place, and ~/.password-store/.gpg-id
contains "SGT. Garcia ", i will be able to log
in to your account with the password "bananas".
Does this attack make sense?
     --dkg

@_date: 2015-09-28 13:05:38
@_author: Daniel Kahn Gillmor 
@_subject: An update on poldi? [was: Re: unlock keychain with pam authentication] 
Cc'ing gniibe, who might be able to give us some feedback on the state
of poldi.
   --dkg

@_date: 2015-09-28 14:35:58
@_author: Daniel Kahn Gillmor 
@_subject: unlock keychain with pam authentication 
if you want it to happen on user login, you're asking for an additional
PAM module that would authenticate you to the local system.
With PAM, you could configure your system to do this as an additional
authentication step (in which case it's the same as your current
scenario, but you're prompted by the login greeter instead of your own
shell initialization scripts) or as the only authentication required
(in which case my attack against your local user account applies).
The attack i described is an attack against your local user account,
though i suspect it could be leveraged into an attack against your
e-mail account as well.
       --dkg

@_date: 2015-09-28 16:10:10
@_author: Daniel Kahn Gillmor 
@_subject: unlock keychain with pam authentication 
There is no phoning home.  Do you ever import keys that other people
send you?  or keys you find on the web?  or keys attached to e-mail
messages?  Are you sure the things imported can't include a secret key?
Apparently i'm not doing a great job at communicating this scenario to
you.  sorry about that.  Maybe someone else can try to explain it more
clearly than i can.
I understand what you're asking for, and i see how it would be a useful
thing.  However, i think you should constrain it much more tightly than
what you appear to be asking for, and i don't think that such a thing
already exists.  It would be a bit of engineering work to make sure that
it's functional, but i'd be happy to review something like this if
somebody wants to propose it.
         --dkg

@_date: 2015-09-29 10:28:17
@_author: Daniel Kahn Gillmor 
@_subject: unlock keychain with pam authentication 
I'm surprised to hear that notmuch has this feature, and i haven't seen
it happen myself.  I'm one of the people who helped contribute to
notmuch's OpenPGP mechanisms.
This sounds like something to be raised on the notmuch mailing list,
        --dkg

@_date: 2015-09-29 20:37:01
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG User ID expiry 
Hi Jens--
with 2.1.8, i get an expiration prompt for the user ID if i use:
  gpg2 --full-gen-key
However, i agree with you that it seems like the following command ought
to generate an expired key:
 gpg2 --faked-system-time 20100101T000000 --default-cert-expire 1y --quick-gen-key 'Test Key '
But in my tests, it does not.  This seems like a bug in the
implementation of --default-cert-expire.  Maybe someone? should file it
at  :)
You can do this with "gpg --edit-key $KEYID"
In the subprompt GnuPG provides, use "1" (or "2", etc) to select which
user ID you want.  then use "expire" to change the expiration for that
user ID.
       --dkg

@_date: 2016-08-01 16:37:23
@_author: Daniel Kahn Gillmor 
@_subject: Which GPG version? 
fwiw, i agree with Peter that 2.1 appears at the moment to be better for
all use cases except for parsing archives of old documents that use
formats we currently believe to be at least partially broken.
        --dkg

@_date: 2016-08-02 11:06:40
@_author: Daniel Kahn Gillmor 
@_subject: improvements for "Git Access" page 
but a permanent HTTP 301 or 302 redirect to a URL that matches the
current state of the world is OK, right?
        --dkg

@_date: 2016-08-03 16:18:08
@_author: Daniel Kahn Gillmor 
@_subject: Novice mistake; 
firefox)
Try clicking the ? icon (downward-pointing arrow) to the left of the
firefox address bar to see the recent downloads drawer, or pressing
ctrl+shift+Y (or whatever your system's native keybindings are) to open
up firefox's downloads window.
from there, you should be able to see all the things you've downloaded
and do operations like "open containing folder" which should help you
find it.
     --dkg

@_date: 2016-08-04 09:13:38
@_author: Daniel Kahn Gillmor 
@_subject: Advice on key set-up for work at employer 
yes, this is a sensible plan.
Even better -- if you need to leave the workplace, you can:
 0) revoke the primary key entirely and publish the revocation.
 1) destroy the primary secret key.
 2) give your employers the secret key material for the
    *encryption-capable* subkey only.
The rationale for this is that while they may need access to your
confidential work-related communications, they don't need to be able to
masquerade as you (signing documents, certifying other keys, etc).
           --dkg

@_date: 2016-08-04 18:30:18
@_author: Daniel Kahn Gillmor 
@_subject: Please, fix batch mode for gpg --edit-key-trust 
another way to do this would be to use --import-ownertrust:
  echo $FINGERPRINT:$VAL: | gpg --import-ownertrust
where $VAL is pulled from this list (see g10/trustdb.h; i don't know
whether it is documented anywhere else):
 TRUST_MASK	 15
 TRUST_UNKNOWN	  0  /* o: not yet calculated/assigned */
 TRUST_EXPIRED	  1  /* e: calculation may be invalid */
 TRUST_UNDEFINED   2  /* q: not enough information for calculation */
 TRUST_NEVER	  3  /* n: never trust this pubkey */
 TRUST_MARGINAL	  4  /* m: marginally trusted */
 TRUST_FULLY	  5  /* f: fully trusted      */
 TRUST_ULTIMATE	  6  /* u: ultimately trusted */
 TRUST_FLAG_REVOKED        32 /* r: revoked */
 TRUST_FLAG_SUB_REVOKED    64 /* r: revoked but for subkeys */
 TRUST_FLAG_DISABLED      128 /* d: key/uid disabled */
 TRUST_FLAG_PENDING_CHECK 256 /* a check-trustdb is pending */
 TRUST_FLAG_TOFU_BASED    512 /* The trust value is based on
                                      * the TOFU information.  */
I do note that when VAL=0 in the above formulation, --import-ownertrust
doesn't touch the value for $FINGERPRINT, though -- so i don't know
whether there's a way to use --import-ownertrust to revert to a fully
"unknown" state  ("2" is probably the closest equivalent).
        --dkg

@_date: 2016-08-08 02:11:02
@_author: Daniel Kahn Gillmor 
@_subject: [Sks-devel] [Announcement] SKS 1.1.6 Released 
great, thanks!
it's not clear to me what this means: are these settings that should be
added to sksconf if they weren't already there and you're using an
existing database without rebuilding?
what if those variables are already set in the sksconf file but they
have different values?
what if they weren't set, sks was upgraded, and the database wasn't
rebuilt?  what sort of failures should server operators expect?
has some very strange text in it:
Is there a reason for the newline and leading whitespace?  That causes
debian/watch to fail to discover the new tarball.
This doesn't actually validate the retrieved signatures, fwiw.  you
probably want --check-sigs instead of --list-sigs.
        --dkg

@_date: 2016-08-08 10:25:35
@_author: Daniel Kahn Gillmor 
@_subject: [Sks-devel] [Announcement] SKS 1.1.6 Released 
Thanks for the clarifications, Kristian!
followup below about bitbucket:
i've opened
  feel free to nudge them on it -- as a lead on the project they might be
more receptive to your prodding than to mine.
  --dkg

@_date: 2016-08-08 17:29:52
@_author: Daniel Kahn Gillmor 
@_subject: Moving from RSA to Ed25519 
that is correct.
Now is not a good time to migrate, especially if you want to keep all of
your certifications intact.  Many people do not have access to a version
of GnuPG that is capable of supporting elliptic curve crypto, even on
the public side (encrypting data, verifying signatures).
You'd be better off waiting to migrate unless you have a very specific
use case with a group of peers who you know will be able to use those
keys with you.
     --dkg

@_date: 2016-08-08 19:53:06
@_author: Daniel Kahn Gillmor 
@_subject: Signing statement with master key? 
yes, it is certainly possible.  I'm not sure what you mean "is it safe"

@_date: 2016-12-01 23:49:38
@_author: Daniel Kahn Gillmor 
@_subject: Proof for a creation date 
One approach i've seen recommended is to create a
cryptographically-strong digest of the signed document in question and
then post it to a public, append-only log somewhere.
For example, take the SHA256 digest of the document, pretend that value
is the address of a bitcoin wallet, and throw a little bit of bitcoin
into it (this value will never be recoverable because no one knows the
corresponding secret key). This puts the digest into the blockchain at a
acertain date for anyone to see.
Your subsequent argument is that one of the two possibilities must hold:
 (a) you have some ability to perform a collision attack against
     SHA-256, or
 (b) the signed document existed at some point before the bitcoin
     transaction was publicly logged.
since most people won't believe (a), (b) looks pretty likely.
You could use any other globally-visible log that allows for injection
of a bitstring long enough for a strong digest (32 octets is probably
sufficient), it doesn't have to be the bitcoin blockchain.  for example,
if you can get something into a public X.509 certificate, you could post
it to one of the certificate transparency logs.
        --dkg

@_date: 2016-12-10 18:31:05
@_author: Daniel Kahn Gillmor 
@_subject: Can't import new public keys (can't write tu pubring.kbx) 
this sounds like a permissions problem to me.  what are the permissions
of Dokumenty/key.asc?  what are the permissions of
are you running "gpg --import" from?
    --dkg

@_date: 2016-12-10 20:19:56
@_author: Daniel Kahn Gillmor 
@_subject: Can't import new public keys (can't write tu pubring.kbx) 
This key has a zero-length User ID.  that is, the User ID is the empty
string ("").
You can see this with:
0 dkg at alice:/tmp/cdtemp.Ok5Ijz$ wget -q -O- ' | pgpdump
Old: Public Key Packet(tag 6)(269 bytes)
Old: User ID Packet(tag 13)(0 bytes)
Old: Signature Packet(tag 2)(284 bytes)
Old: Signature Packet(tag 2)(284 bytes)
0 dkg at alice:/tmp/cdtemp.Ok5Ijz$ i suppose someone could argue that a zero-length user ID is valid, but i
don't see any use for it, and i can imagine it causing problems in a lot
of situations.  So i think on balance i'm that gpg rejecting it by
default is doing the right thing.
          --dkg

@_date: 2016-02-24 18:45:18
@_author: Daniel Kahn Gillmor 
@_subject: A problem in the web of trust model or a gnupg bug? 
according to  :
   If a key has been revoked because of a compromise, all signatures
   created by that key are suspect.  However, if it was merely
   superseded or retired, old signatures are still valid.  If the
   revoked signature is the self-signature for certifying a User ID, a
   revocation denotes that that user name is no longer in use.  Such a
   revocation SHOULD include a 0x20 code.
so the reason for revocation should affect whether signatures made
before the revocation are worthy of consideration.  however, "no reason
specified" should default to the safer/harsher situation, where all
signatures made by that key are no longer considered, regardless of
   --dkg

@_date: 2016-02-26 03:49:26
@_author: Daniel Kahn Gillmor 
@_subject: Specify UID for --sign-key 
Hi Muri--
In GnuPG 2.1:
       --quick-sign-key fpr [names]
       --quick-lsign-key fpr [names]
              Directly sign a key from the passphrase without any further user
              interaction.  The fpr must be the verified  primary  fingerprint
              of a key in the local keyring. If no names are given, all useful
              user ids are signed; with given [names]  only  useful  user  ids
              matching  one  of theses names are signed.  The command --quick-
              lsign-key marks the signatures as  non-exportable.   If  such  a
              non-exportable  signature  already  exists  the --quick-sign-key
              turns it into a exportable signature.
              This command uses reasonable defaults and thus does not  provide
              the  full  flexibility of the "sign" subcommand from --edit-key.
              Its intended use is to help unattended key signing by  utilizing
              a list of verified fingerprints.
        --dkg

@_date: 2016-02-25 21:45:48
@_author: Daniel Kahn Gillmor 
@_subject: FAQ maintenance 
I consider it a bug that GnuPG uses the 64-bit keyid as the internal
identifier, and that the packet structure uses the 64-bit keyid as well.
there's simply no justification for "saving those bits" on any modern
hardware.  We shouldn't embed the assumption that these limits will be
permanent in our documentation.
Why is it more resource intensive?  the user will be copying and pasting
this string one way or another, we should have them copy/pasting
something cryptographically strong, not something that is marginal and
only getting weaker with time.
     --dkg

@_date: 2016-02-26 04:49:47
@_author: Daniel Kahn Gillmor 
@_subject: What are key helpers? 
they're separate programs that operate over more-or-less well-defined
interfaces (stdin/stdout text-based interaction, usually), most of which
are shipped as part of the GnuPG suite.
take a look at the execpath in your installed system
(e.g. /usr/lib/gnupg/ or /usr/lib/gnupg2/ on debian systems) for
examples.  many of the helpers in gnupg 1.4.x are related to connections
to keyservers.  in 2.1.x all the network connections are handled by
dirmngr, so they aren't needed.
in 2.0.x and 2.1.x, gpg-check-pattern is an example -- its --help
output shows:
Syntax: gpg-check-pattern [options] patternfile
Check a passphrase given on stdin against the patternfile
 -v, --verbose   verbose
     --check     run only a syntax check on the patternfile
 -0, --null      input is expected to be null delimited
        --dkg

@_date: 2016-01-23 18:01:26
@_author: Daniel Kahn Gillmor 
@_subject: Different SHA1 Checksum using Microsoft file checksum integrity 
Hi Wyatt--
on any modern version of windows, you should be able to do checksum
verification with certutil.exe using the -hashfile subcommand:
 Note that the lengths are different, which suggests that they might be
different digest algorithms entirely. I believe that fciv.exe is
calculating the MD5 checksum, while the download site is using the SHA1
Indeed, i see the MD5 sum matching the value you found with fciv.exe,
while the SHA1 sum matches the published data:
0 dkg at alice:~$ gpg2 --print-md MD5 < gpg4win-2.3.0.exe 4A 88 F9 0A 01 B0 BA 8E  3E B0 07 3F 7B 6A 4B FB
0 dkg at alice:~$ gpg2 --print-md SHA1 < gpg4win-2.3.0.exe 88D9 0EE9 A1EA 3E66 B198  EA86 6063 140B 8824 44D5
0 dkg at alice:~$
So i think your download is most likely ok (assuming that fciv is doing
what i believe it is).
fwiw, MD5 and SHA1 are both old digest algorithms, and are not as strong
as they should be.  I recommend that anyone using checksums for file
integrity switch to SHA256 as soon as possible.
Also, the OpenPGP signature published at
 itself uses SHA1
internally.  This is also a bad idea.  signatures published today should
use at least SHA256, as every modern OpenPGP implementation has been
capable of verifying SHA256 signatures for years now.
        --dkg

@_date: 2016-01-24 14:30:07
@_author: Daniel Kahn Gillmor 
@_subject: SHA-1 vs. SHA-256 checksums (was: Different SHA1 Checksum 
SSH key fingerprints are a different thing than software distribution
checksums because the material digested in ssh originates entirely from
one party, whereas the software distribution checksums can potentially
be influenced by multiple parties.  right, this is not a cryptographically-strong verification :)
if they don't check more digits, then we can't help them.  but it'd be
nice to offer a way for people to do a cryptographically-strong check if
they decide to do so.
but in general, i agree with you that published checksums are stopgap
measures at best, mainly fit for detecting corrupted downloads, and not
particularly useful against a targeted attack.
 [...]
great, thanks!
       --dkg

@_date: 2016-01-25 08:59:53
@_author: Daniel Kahn Gillmor 
@_subject: Master Key Best Practice with SmartCard 
If you don't want people to encrypt messages to your D693C37C subkey,
you should revoke that subkey (and only that subkey), and publish your
updated certificate to the keyservers.
Just deleting the subkey from your certificate locally won't delete the
associated copy on the keyserver, or provide anyone else with any
indication that you don't intend to continue using it.
This will just create additional confusion for you, because there will
now be two certificates associated with your name.  It's not the end of
the world, but i don't think it would solve your problem as cleanly as
the above approach.
    --dkg

@_date: 2016-01-26 13:30:13
@_author: Daniel Kahn Gillmor 
@_subject: AW: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
] You said that you are running in a Jessie VM.  Depending on the type of
VM, it's possible that there are few events that are feeding the
kernel's entropy pool (no virtualized hardware or software or anything
similar).  GnuPG relies on the kernel's entropy to initialize the key
generation process, and it consumes rather a lot of it.
I don't know what kind of virtualization you're using, so i have no
concrete suggestions for how you could increase the entropy in the VM
you're using, other than the usual tricks of typing into keyboard and
wiggling the mouse.
you can see the state of the Linux kernel's entropy by looking at the
contents of the file /proc/sys/kernel/random/entropy_avail -- if that is
staying close to 0, it's likely that this is the problem.
For testing purposes only, you might be interested in using the
--debug-quick-random flag, which would avoid waiting on the kernel's
blocking RNG.
I note that you're passing the root of the filesystem as your preferred
      const char * CONFIG_DIR = "/";
This might be a mistake, because it's unlikely that a normal user can
write to the root directory, and you almost certainly don't *want* to
use the root directory as your gpg config dir.
gpgme_set_engine_info() accepts NULL as the HOME_DIR parameter, which
asks for the engine' default homedir to be used.
gpgme and gnupg are not intentionally tightly coupled.  I wouldn't try
to update them until you've figured out what's going on here.
If the delay is still happening for you even with a system with entropy
available, you might also try looking at the process table to see what
is going on -- if there's a backgrounded gpg or gpg2 process, you could
try attaching to it with strace ("strace -p $PID", where $PID is the
process ID of the gpg process) to see what it's doing.
        --dkg

@_date: 2016-07-05 17:23:55
@_author: Daniel Kahn Gillmor 
@_subject: gpg-agent and ~/.ssh/config IdentityFile 
You're right, this really is a better question for OpenSSH users.
Do you have a .pub file of the public part of your identity?  try
pointing Identities to that file.
if you don't have such a file, you should be able to do:
   ssh-add -L
filter the output to the line you want, save the filtered output to a
file named "foo.pub" and then try with "ssh -i foo.pub remotehost"
     --dkg

@_date: 2016-07-05 23:17:09
@_author: Daniel Kahn Gillmor 
@_subject: Pinentry UI bug 
Hi Titus--
pinentry most likely cached the password with your system's
SecretService using libsecret, which can be implemented in different
ways (though the common mechanism i've seen has been one implemented by
the GNOME desktop, and which is accessible via gnome-keyring).
   on debian, there should be a libsecret-tools package that allows you to
query the SecretService, though i don't have enough experience with it
to help you beyond that pointer.
   --dkg

@_date: 2016-07-13 14:13:02
@_author: Daniel Kahn Gillmor 
@_subject: gpg-preset-passphrase not working with 2.1 
Hi David--
there have been significant changes to GnuPG between 2.1.7 and 2.1.13.
can you try upgrading to 2.1.13?
    --dkg

@_date: 2016-06-01 16:36:42
@_author: Daniel Kahn Gillmor 
@_subject: secret key not available 
You don't mention whether you have any secret keys available.  What
do you get by running:
 gpg --list-options show-usage --list-secret-keys
Are there any signing-capable secret keys listed?
        --dkg

@_date: 2016-06-07 13:22:34
@_author: Daniel Kahn Gillmor 
@_subject: How to install GnuPG-2.1.12 in Ubuntu? 
In debian testing or unstable, you should use the gnupg package from the
experimental repository.
        --dkg

@_date: 2016-06-09 15:59:27
@_author: Daniel Kahn Gillmor 
@_subject: How to convert (ancient) key in "version 2" to more modern 
Hi Bjoern--
So there are two things you might want to do with these mails: verify
their signatures and decrypt them.  Right?  Is it possible that
signature verification for old (likely weak, and quite possibly
compromised) keys isn't relevant?  If so, then the problem space becomes
focused on decryption.
I think there are serious usability risks to providing live decryption
capability for *new* material that is sent encrypted to known-weak keys,
but i can understand the use case you describe.
Perhaps the better approach is to have a one-time tool that can either
(a) translate your encrypted messages into a newer encrypted form
(e.g. replacing the PKESK packets with ones encrypted to a newer,
stronger key), or (b) extracting the session key from the encrypted
object and storing it in a separate lookup table, so that the old secret
key isn't relevant any longer.
Either of these approaches would also be useful to people who want to
destroy their old secret key material without losing access to their
data, while making it harder for people to start interacting with
bad/old keys.
        --dkg

@_date: 2016-03-08 10:33:06
@_author: Daniel Kahn Gillmor 
@_subject: Remove photos from OpenPGP key in the keyservers 
Sorry, but no.  The keyservers are globally-synced and append-only.  you
will not be able to remove stuff once it's posted there.
The MIT keyserver has a good succinct FAQ about why this is:
    --dkg

@_date: 2016-03-17 15:44:55
@_author: Daniel Kahn Gillmor 
@_subject: SHA-1 checksums to be replaced with something better at 
FWIW, the threat model of digest algorithms being published on an HTTPS
website that then links to the file to be downloaded is much easier to
work around than by compromising SHA-1's preimage resistance (or even
collision resistance for that matter).
However, it makes more sense to me to just move everything to sha-256
today.  Anyone who actually checks the digests should be capable of
using sha256 today, and it would avoid this sort of question coming up
in the future.
        --dkg

@_date: 2016-03-18 10:45:28
@_author: Daniel Kahn Gillmor 
@_subject: SHA-1 checksums to be replaced with something better at 
On any modern Windows installation (since Vista at least, i think) there
is "certutil.exe"
  the syntax is:
  certutil -hashfile FileToHash.ext sha256
Looks like there's an older version available even for Windows XP (not
that i recommend anyone use that) via something called "Windows Server
2003 Administration Pack":
  (appears to require javascript, sorry)
Right, but surely you wouldn't advocate only displaying the first and
last few digits of the SHA1 digest just because most people aren't going
to look at anytihng else.  Right?
At any rate, checking the first and last X digits of SHA-256 is probably
better than checking the first and last X digits of SHA-1, for any value
of X.  SHA-1 has worse cryptographic properties than SHA-256 (and about
a decade more of intense analysis that reveals flaws).  Likewise, i'm
glad that we at least offer SHA-1, even though it's longer and harder to
read than MD5, which itself is longer and harder to read than CRC32 :P
We cannot force anyone to compare anything, but we can choose whether we
give them the information that is capable of strong comparison. (while
understanding that it's not meaningful in the face of webserver
        --dkg

@_date: 2016-03-23 13:48:22
@_author: Daniel Kahn Gillmor 
@_subject: EasyGnuPG 
I'm entirely open to packaging gpgme-tool separately from the -dev
package, if there is a clear and compelling argument for it.
If you feel that this is something particularly useful that you want to
happen for debian, please file a debian bug report against the gpgme1.0
source package (e.g. "reportbug gpgme1.0").
        --dkg

@_date: 2016-03-23 14:30:21
@_author: Daniel Kahn Gillmor 
@_subject: EasyGnuPG 
the monkeysphere project encourages the creation of on-disk
authentication subkeys.  While that may be uncommon, i don't think it's
"really uncommon".
               --dkg

@_date: 2016-05-27 12:40:27
@_author: Daniel Kahn Gillmor 
@_subject: problem with make in gpg2 
is it possible that you're building against a different version of
libgpg-error than you have installed on your system?
             --dkg

@_date: 2016-05-27 11:32:19
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG - Encryption process issues. 
It sounds to me like the installation of gnupg that you are using is
misconfigured.  GnuPG depends heavily on a "keyring" -- a collection of
public key material (and sometimes private key material, if decryption
or signing is needed), which it maintains in the .gnupg directory within
the running user's home directory (found by the environment variable
If you've started with a normal user account, but have then run gnupg as
root (e.g. using "su") without resetting $HOME to root's actual homedir
(usually /root on the systems i use), then it's possible that you've
created ~/.gnupg with the wrong permissions.
Or, it's possible that the .gnupg directory is *only* available within
root's homedir.
Does your non-privileged user have a ~/.gnupg directory?  if so, does it
have read and write access to it?
What error messages do you get from invoking gpg directly?
     --dkg

@_date: 2016-05-31 11:04:43
@_author: Daniel Kahn Gillmor 
@_subject: no passphrase request 
This sounds like a Mutt issue more than a GnuPG issue.  You might try
the Mutt mailing lists or the Mutt wiki:
          --dkg

@_date: 2016-05-31 13:47:41
@_author: Daniel Kahn Gillmor 
@_subject: Fw: GnuPG - Encryption process issues. 
Hi Carlos--
Please reply in the original thread, to make it easier for people to
follow the discussion.
I've added some References: headers back in here so some mailers might
merge the threads, but this won't work for everyone.
Also, when sharing terminal transcripts, sending mail without
unnecessary line-wrapping will make them much easier for your readers to
It looks like you're trying to sign the file (that's what the "-s" part
of "-se" means).  For whatever reason, the signature itself is likely to
be what is failing, and not the encryption.  If you drop the signatures
in your test (using -e instead of -se) do they all complete cleanly?  To
be clear: I'm not saying you shouldn't sign at the same time as
encrypting, i'm trying to help you narrow down the cause of the problem.
I also see you fiddling with the ownership of ~/.gnupg/random_seed --
you really shouldn't need to do that, and ideally each user will control
their own random_seed automatically -- you shouldn't be sharing a gnupg
home directory between to different user accounts unless you absolutely
need to.
     --dkg

@_date: 2016-11-07 11:54:41
@_author: Daniel Kahn Gillmor 
@_subject: gpg is destroying my messages ... 
You probably want to ask this question on the enigmail mailing list:
  Enigmail user discussion list Enigmail is responsible for integrating GnuPG with Thunderbird.
         --dkg

@_date: 2016-11-09 10:44:24
@_author: Daniel Kahn Gillmor 
@_subject: Specifying different pinentry based on caller? 
fwiw, this is taking advantage of the "curses fallback" in whatever
pinentry you're using -- it is not using a different pinentry.
But in general, i think it's better to let the agent do its thing
independent of gpg.  why do you want a terminal-based pinentry in other
contexts?  secret key isolation is one of the big advantages of the
2.1.x gpg-agent, and trying to mix the agent's interactions with the
process that's using the agent makes that isolation less effective.
If you really want to do this, though, i note that unsetting DISPLAY
won't work for all graphical pientry programs.  In particular, the
development branch of pinentry-gnome3 (and the versions in debian
testing and unstable) use d-bus to talk to the GNOME system prompter,
and don't interact directly with the X11 session.  I don't know what
pinentry you're using, but if your goal is to force the curses-fallback,
you might want to also explicitly point DBUS_SESSION_BUS_ADDRESS at
something that isn't a dbus socket; this will cause anything that tries
to talk to d-bus to fail, which should result in a curses fallback.  At
the same time, you also need to ensure that GPG_TTY is explicitly set,
otherwise the curses fallback will fail if the tool that ultimately
invokes gpg has no access to a tty directly (or if you invoke gpg with
stdin and stdout bound to non-pty pipes).  So i think you want:
    DISPLAY= DBUS_SESSION_BUS_ADDRESS=/dev/null GPG_TTY=$(tty) gpg2 [?]
If you know that gpg is going to be in a position to prompt the user
directly, and you're running 2.1.15 or later, you can also try adding
the --pinentry-mode=loopback argument to your gpg command.
But again, i recommend *not* trying to do this.  let the agent be
effectively isolated!
Hope this helps,
     --dkg

@_date: 2016-11-14 11:18:24
@_author: Daniel Kahn Gillmor 
@_subject: gpg password and/or agend messed up 
What platform are you using?  What version of GnuPG?  do you have
multiple versions of gpg installed ?  (e.g. "gpg" and "gpg2")?
         --dkg

@_date: 2016-11-18 16:16:43
@_author: Daniel Kahn Gillmor 
@_subject: Primary and Signing Key on Different Smart Cards 
I believe this bug is tracked upstream at
 -- it would be great if someone
wanted to propose a patch to fix it.
       --dkg

@_date: 2016-11-18 16:04:41
@_author: Daniel Kahn Gillmor 
@_subject: Fresh OS installation 
Please be aware that if you take Robert's advice above, and your home
directory is world-readable, then other accounts on the system will be
able to read gnupg-backup.tar, which means they'll be able to get a copy
of any secret information happens to be there.
If that's a problem for you, you might want to set the umask to 077
("umask 077") before the initial "tar cf", and ensure that the
permissions on the file in your new directory are similarly restricted
(theehy should not be readable by "group" or "other".
        --dkg

@_date: 2016-11-18 17:54:02
@_author: Daniel Kahn Gillmor 
@_subject: gpg password and/or agend messed up (gnupg: message 2 of 20) 
These versions are not the versions that are part of Debian jessie.  are
you running a mixed environment, or are you actually running Debian
        --dkg

@_date: 2016-11-22 15:09:46
@_author: Daniel Kahn Gillmor 
@_subject: How to prevent passphrase caching in 2.1 
fwiw, the same concerns hold for a shared gpg-agent passphrase-cache
from pre-2.1 versions of gpg as well, right?
your model sounds like it needs to use a separate agent per user,
regardless of which version of the agent you're using.
           --dkg

@_date: 2016-11-23 12:24:13
@_author: Daniel Kahn Gillmor 
@_subject: How to prevent passphrase caching in 2.1 
in 2.0, the agent is a passphrase cache.  in 2.1, the agent is a proper
cryptographic agent, which does not release any secret key material to
the calling process.  This isolation is actually offers reduced risks in
the contexts in which gpg is expected to be invoked (by a single user,
who is managing their own keys).
that said, i understand why it doesn't meet your needs.  unfortunately,
you're using these tools in a framework that they generally weren't
expected to be used.
You've said already that you don't want to run a different gpg-agent for
each user account that is currently authenticated to your server.  can i
ask why not?  the agent is a pretty lightweight process, and setting one
up on login and tearing it down on shutdown seems like it could be a
fairly convenient approach.
    --dkg

@_date: 2016-10-03 09:40:02
@_author: Daniel Kahn Gillmor 
@_subject: Terminology - certificate or key ? 
as a native en_US-speaker, I can confirm that the most precise term here
is "slam lock".  however, i've found that term is not particularly
widely-known or understood, which probably makes it a bad choice for
explanatory metaphor :(
fwiw, i disagree with Werner that X.509 certificates and OpenPGP
certificates are radically different.  There are differences for sure --
chief among them the composability (and decomposability) of OpenPGP
certificates, as well as their multi-issuer nature.  But conceptually
both formats provide transferable, cryptographically-verifiable
assertions about bindings between identities, capabilities, and public
key material.  This is roughly what "certificate" means to most people,
and that's the right term to use in my opinion.
            --dkg

@_date: 2016-10-04 11:26:59
@_author: Daniel Kahn Gillmor 
@_subject: Agent forwarding failure when the socketdir was autodeleted 
If you're not logged in, then how does the remote forward work?  aren't
you actually still logged in (via ssh) as long as your remote forward is
    --dkg

@_date: 2016-10-04 15:34:25
@_author: Daniel Kahn Gillmor 
@_subject: Agent forwarding failure when the socketdir was autodeleted 
Hi Andre--
so /run/user/ exists upon ssh connection, but
of the pipe can't auto-create the remote socket -- is that the concern?
agreed, that sounds clunky and annoying.
I wonder whether ssh's remote socket forwarding ought to try to
automatically create the parent directories if they don't already exist.
This doesn't solve your problem in the near term if you can't update the
remote host, but it seems like the right place to fix this problem.
Maybe that's worth asking on openssh-unix-dev at mindrot.org ?
right, session termination (or machine reboot, etc) should clean up
$XDG_RUNTIME_DIR, aiui.
                  --dkg

@_date: 2016-10-05 13:46:51
@_author: Daniel Kahn Gillmor 
@_subject: Agent forwarding failure when the socketdir was autodeleted 
The trouble is that the socket directory needs to be created before ssh
tries to forward the socket.  when doing a forward from the command
line, the ssh channel that does socket forwarding is often established
before the channel that runs any shell or other interactive behavior.
I really think this ought to be handled in OpenSSH.
  --dkg

@_date: 2016-10-11 10:20:37
@_author: Daniel Kahn Gillmor 
@_subject: Private key export for SSH 
fwiw, monkeysphere doesn't explicitly support exporting OpenPGP secret
key material to arbitrary formats.
Rather, modern versions of monkeysphere (the ones that support gpg 2.1)
include agent-transfer, a tool that knows how to export secret key
material from a running gpg-agent and import into a running ssh agent.
See the agent-transfer(1) manual page for more details.
    --dkg

@_date: 2016-10-11 23:23:43
@_author: Daniel Kahn Gillmor 
@_subject: gnupg pinentry 
It's not clear what this means.  are these descriptions of symbolic
links?  If so, i don't know what you're trying to do here.  Is there a
reason to have /usr/local/bin/pinentry at all?  on ubuntu, i recommend
just installing the pinentry-* package that matches your preferred
desktop environment and allowing it to be automatically selected.
        --dkg

@_date: 2016-10-12 17:51:30
@_author: Daniel Kahn Gillmor 
@_subject: Private key export for SSH 
It looks to me like you're referring to
 , which was marked as "resolved".
I just re-opened it to "chatting".
  --dkg

@_date: 2016-10-13 20:59:26
@_author: Daniel Kahn Gillmor 
@_subject: Gnupg-users Digest, Vol 157, Issue 15 
sorry, i'm confused, and i don't have the context for this, or why
you're asking me in particular on the gnupg-users mailing list.  Can you
explain what you're asking about?
if you're asking whether that's the "right" md5sum for the
pinentry-gnome3 binary (i.e., /usr/bin/pinentry-gnome3), all i can tell
you is that it doesn't match my binary.  but this isn't a useful
question for a bunch of reasons, including:
 * you might have a different operating system than i do
 * you might have a different hardware platform than i do
 * either you or i might have built the binary independently or with
   different options
and so on...
if this is related to your earlier question about symlinks(?) that i
also didn't really understand, i'm still puzzled.
What problem are you trying to solve?  What behaviors have you observed?
What behaviors were you expecting to observe?  What debugging steps have
you tried?
here are some useful pointers for effective bug-reporting:
  confusedly yours,
     --dkg

@_date: 2016-10-14 20:54:32
@_author: Daniel Kahn Gillmor 
@_subject: Secret key Questions regarding expiration and backing up 
This is exactly correct.  see:
   The Secret-Key and Secret-Subkey packets contain all the data of the
   Public-Key and Public-Subkey packets, with additional algorithm-
   specific secret-key data appended, usually in encrypted form.
        --dkg

@_date: 2016-10-17 11:41:43
@_author: Daniel Kahn Gillmor 
@_subject: regular update of all keys from a keyserver 
The only disadvantages are if you don't want to reveal the contents of
your keyring to the public keyservers, or to announce your presence on
the network.
If you prefer to do these things in an anonymized way, you might prefer
a tool like parcimonie, or if you're a coder (or have ways to encourage
other coders to work on things you think are interesting), you might
want to to look into ways to try to address
    --dkg

@_date: 2016-10-17 21:19:55
@_author: Daniel Kahn Gillmor 
@_subject: using with su/sudo 
so the use of script here is to allocate a new pseudoterminal, to get an
independent tty, right?
this seems like a pretty roundabout way to get the result the user is
naively looking for.  is it possible that we could offer some other
easier/simpler mechanism for users invoking gpg-agent for its ssh-agent
emulation across user accounts?
      --dkg

@_date: 2016-10-19 17:22:35
@_author: Daniel Kahn Gillmor 
@_subject: Invalid packet/keyring. How to find out what's responsible? 
Hi Kevin--
what version of apt?  what version of gpg?  it sounds to me like you
have some public keyring that is ascii-armored instead of raw.  you
might manually (individually) test /etc/apt/trusted.gpg and
for example:
    grep 'BEGIN PGP' /etc/apt/trusted.gpg /etc/apt/trusted.gpg.d/*.gpg
        --dkg

@_date: 2016-10-19 18:44:53
@_author: Daniel Kahn Gillmor 
@_subject: Why are my expiration dates different? 
[...]
the difference here is looking at secret keys and public keys.  in
gpg version 1.4.x or 2.0.x, those are not well-synchronized.  the
expiration date seen in the pubring.gpg is the thing that any other user
will see, so that's the one to rely on.
in gpg version 2.1.x or later, the metadata is synchronized across
secret keys and publicly (more specifically, the view of the secret keys
shows the date that comes from the public keyring).
      --dkg

@_date: 2016-10-26 09:39:59
@_author: Daniel Kahn Gillmor 
@_subject: Cant decrypt in IIS hosted wcf service but works fine in console 
Is IIS running as the same user account as the console application?  If
they're different user accounts, it seems likely that they'd have access
to different secret keyrings.
   --dkg

@_date: 2016-10-26 16:51:40
@_author: Daniel Kahn Gillmor 
@_subject: ways to ensure that GPG public key belongs to right person in 
Hi Martin--
It depends on how much involvement you want the IT department to have.
There are a few more options:
 * if Alice and Bob can meet in person, they can give each other
   business cards with their fingerprints on them.  If this is how Alice
   finds Bob's e-mail address in the first place, this is a natural
   place to exchange cryptographic details as well.
 * the two companies could use WKD (web key directory), which is in its
   infancy, but is at least supported by GnuPG 2.1.x.
 * Alice and Bob could submit their keys to a third-party notary like
   Symantec's PGP Global Directory (if such a thing still exists)
 * Alice and Bob could publish their public keys in the public
   keyservers (e.g. gpg --send-key $FINGERPRINT) when they create their
   keys.  Then they could look each other up in the public keyservers;
   if Alice finds only one public key associated with Bob's e-mail
   address, she might just decide to assume it's the right one.
These all have slightly different security properties and failure modes,
which might have different value to Alice and Bob, depending on their
threat model and any other economic or logistical pressure they're
      --dkg

@_date: 2016-10-28 12:40:08
@_author: Daniel Kahn Gillmor 
@_subject: web-based manpage version? 
Hi all--
I just noticed (from interactions on IRC) that the web-based manual page
for GnuPG isn't clear about which version of GnuPG it documents:
     I believe it's either from the "classic" or "stable" branch, but it
doesn't say so explicitly.  As a result, it documents things like
"--force-v3-sigs" even though the "modern" branch of GnuPG explicitly
How is the web-based manpage maintained?  Can we update it to contain
relevant information like the above option deprecation?
    --dkg

@_date: 2016-10-30 15:20:11
@_author: Daniel Kahn Gillmor 
@_subject: web-based manpage version? 
Sure, here you go:
    It would be great to make this happen automatically at each release.
        --dkg

@_date: 2016-09-05 23:17:27
@_author: Daniel Kahn Gillmor 
@_subject: Key import issues 
this sounds like an OpenPGP public key whose self-signature contains
either a subpacket with type in range 128-255:
    [0] this implies that the subpacket is critical.
This sounds exactly like what it says.  Barring malice, the most likely
cause is clock skew between the machine that generated the key and the
machine that is consuming the key.
It would be great to see the specific OpenPGP public certificates, and a
description of how they were generated.
        --dkg

@_date: 2016-09-12 02:52:25
@_author: Daniel Kahn Gillmor 
@_subject: gpg-agent only works when started in terminal 
Hi Antony--
A few diagnostic questions might help other folks on this list point you
in the right direction:
this command should not cause the pinentry to appear; what command are
you running that actually causes pinentry to appear?  what operating
system are you running?  are the gnupg packages supplied by the OS or
have you built them by hand?
what does the output of the following command show?
   gpg --list-secret-keys 0E98CD22ADB13E99
how about:
   gpg --version
(you've already showed gpg2 --version which reports 2.1.15, but plain
gpg might show something different)
What do you have pinentry-program set to in gpg-agent.conf?
If it turns out that gpg is version 1.4, and has access to the secret
key, but 2.1.15 does not, then you can try importing your secret keyring
into your 2.1.15 secret keyring to solve the problem.  That'd look
something like:
   gpg2 --import < ~/.gnupg/secring.gpg
hope these questions and suggestions are useful.
     --dkg

@_date: 2016-09-12 19:12:20
@_author: Daniel Kahn Gillmor 
@_subject: What happened to this signature? 
Indeed, i believe it does.  I use notmuch-emacs, which also uses
mml-mode for composition; and that setup used to be the default
configuration before i switched over to using a native notmuch fcc
approach (see the notmuch mailing list thread starting on Message-Id:
<1465599772-10297-1-git-send-email-markwalters1009 at gmail.com> is a good
example of using notmuch-specific fcc, which removes the risk of
        --dkg

@_date: 2016-09-13 01:02:05
@_author: Daniel Kahn Gillmor 
@_subject: Javascript and smartcard 
You might consider writing a patch or extension to OpenPGP.js that knows
how to talk to gpg-agent for use of secret keys.  That way gpg-agent
could delegate the work to the smartcard via scdaemon, and OpenPGP.js
wouldn't need to know anything about the secret key material.
         --dkg

@_date: 2016-09-14 16:24:01
@_author: Daniel Kahn Gillmor 
@_subject: What is a reliable way to backup/restore my keys and test? 
Thanks for the very thorough walk-through, Robert.
Perhaps GnuPG ought to produce some kind of interchangeable backup
automatically on its own that it can re-consume, so this kind of
involved process isn't necessary.
A couple notes below:
the above two steps should include the arguments "--export-options
export-local" just before "--export".
The above two steps should include the arguments "--import-options
import-local" just before "--import".
        --dkg

@_date: 2016-09-15 15:56:41
@_author: Daniel Kahn Gillmor 
@_subject: What is a reliable way to backup/restore my keys and test? 
It should but the current sks keyservers do not do this right, and an
attempt to fix this has been stalled for years:
    --dkg

@_date: 2017-04-07 12:08:43
@_author: Daniel Kahn Gillmor 
@_subject: Display a gpg signature as a string of zeros and ones? 
any data can be represented as a string of ones and zeros, but there are
many different convention for how to order and group such a thing.
the xxd tool will take any input and convert it to arbitrary forms.  for
ones and zeros, you can use -bits.  for example:
0 dkg at alice:~$ echo this is a test | xxd -bits
00000000: 01110100 01101000 01101001 01110011 00100000 01101001  this i
00000006: 01110011 00100000 01100001 00100000 01110100 01100101  s a te
0000000c: 01110011 01110100 00001010                             st.
0 dkg at alice:~$
you can use this technique on anything, including an OpenPGP signature.
    --dkg

@_date: 2017-04-10 02:37:37
@_author: Daniel Kahn Gillmor 
@_subject: Display a gpg signature as a string of zeros and ones? 
My confusion stems from the fact that you seem to be asking both about
"display" and about size compression.
you can't actually display any of the ones or zeros without converting
them to some form that humans can understand, which typically means
expanding them significantly (e.g. looking at the data in hex or base64
So if you're talking about minimizing size of an OpenPGP signature, you
want to avoid ASCII-armoring the signature.  this will still be more
than 2048 bits because the OpenPGP signature format has some framing
structure around it.  If you remove that framing structure, the
bitstring you have left won't be safe to interpret because it will look
like arbitrary noise that happens to be a useful input to some
particular algorithm.
To put it another way: an OpenPGP signature is more than just a
mathematical/cryptographic object.  it's also a protocol object, and the
protocol details take up space too.
Does this make more sense?
         --dkg

@_date: 2017-04-17 14:37:50
@_author: Daniel Kahn Gillmor 
@_subject: How can I change the passphrase on our secret keys? 
We need more info about the host where this failed to help you :)
 * What operating system? (and what version of the OS?)
 * What version of gpg?
 * What version of pinentry are you expecting to use?
 * If you do the following command from the shell, do you see a pinentry
   show up anywhere?
      printf "option ttyname $(tty)\ngetpin\n" | pinentry
        --dkg

@_date: 2017-04-19 11:46:58
@_author: Daniel Kahn Gillmor 
@_subject: Prefer a currently available signing subkey? 
The open report is I've just moved this to priority "high" since it seems to continue to
affect people.
       --dkg

@_date: 2017-04-19 12:20:23
@_author: Daniel Kahn Gillmor 
@_subject: Cannot encrypt to reenabled key after migration 
Hi MFPA--
I've just opened a bug report about this at      --dkg

@_date: 2017-04-26 21:28:06
@_author: Daniel Kahn Gillmor 
@_subject: Prefer a currently available signing subkey? 
I agree that these seem related, though T1983 has smartcard-specific
concerns.  I've tested the patch for T1967 in a non-smartcard situation,
but haven't tested it with a smartcard yet.  I'd be happy to hear the
results of such a test, if anyone has a smartcard handy for testing.
    --dkg

@_date: 2017-04-26 22:37:56
@_author: Daniel Kahn Gillmor 
@_subject: Bad passphrase with gpg 2.1 - works fine with gpg 1.4 
Hi Fredrik--
gpg 1.4.x and 2.1.x use different secret keyrings.
the first time that 2.1.x runs, it tries to import secret key material
from the 1.4.x keyring, but it's possible that this happened before the
previous key generation.
You can encourage 2.1.x to try that migration again with:
    rm ~/.gnupg/.gpg-v21-migrated
    gpg2 --list-secret-keys
modern GnuPG (v2.1) is designed to only use the agent.  on this branch,
gpg itself never handles secret key material at all.
I'm not sure that this is related to your other question.  but if you
really prefer to only be prompted in the terminal, you can change the
version of pinentry that you have installed to pinentry-curses or
pinentry-tty.  If you're using this from a graphical environment though,
i do not recommend making this change.  Stick with the graphical
passphrase prompt!
you can use gpg 2.1.x while your correspondents use gpg 1.4.x.  but
trying to use 2.1.x yourself while also using 1.4.x (the "co-installed
case") doesn't work very well in my experience, since there are
different secret keyrings, and in practice there can be different public
keyrings as well (2.1.x prefers ~/.gnupg/pubring.kbx, but 1.4.x only
knows about ~/.gnupg/pubring.gpg).
      --dkg

@_date: 2017-04-30 12:01:13
@_author: Daniel Kahn Gillmor 
@_subject: Trouble installing Version 2.1 on Debian Jessie 
I agree with Wouter here.
There are actually several different backports needed to make this work,
and it's non-trivial, which is why i haven't gone ahead with the full
backport myself yet -- my focus is currently on upstream and on stretch
I agree with the other poster in this thread that if you want GnuPG 2.1
on debian, you should really be using stretch itself today.
   --dkg

@_date: 2017-08-01 14:35:59
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG and standard output 
Thanks for the suggestion, i've recorded it here:
I agree this seems like a non-useful behavior, but if you're planning on
using gpg in an automated way and you want machine-parseable output, i
recommend including at least the following arguments in addition to
whatever else you want gpg to do:
    --no-tty
    --batch
    --quiet
    --with-colons
    --fixed-list-mode
        --dkg

@_date: 2017-08-14 11:14:45
@_author: Daniel Kahn Gillmor 
@_subject: fingerprint of key 
"gpg --fingerprint" displays the fingerprint of a key that is already in
the user's keyring.
you'll need to "gpg --import public-key-file.asc" first, and then ask
for its fingerprint, especially with older versions of gnupg.
If you really want to isolate the imported key, you can use an ephemeral
GNUPGHOME directory, like so:
    export GNUPGHOME=$(mktemp -d)
    gpg --import < public-key-file.asc
    gpg --fingerprint
    rm -rf $GNUPGHOME
with more modern versions of gnupg, you can just use:
    gpg --with-fingerprint --import-options show-only --import < public-key-file.asc
        --dkg

@_date: 2017-08-14 16:58:53
@_author: Daniel Kahn Gillmor 
@_subject: fingerprint of key 
I didn't think that was what i was saying, but there have certainly been
bugs in the documentation in the past.  Is there specific text that you
think is wrong?  do you have a suggestion about what it should be
changed to?
        --dkg

@_date: 2017-08-14 17:05:38
@_author: Daniel Kahn Gillmor 
@_subject: fingerprint of key 
the trouble with these two invocations of gpg is that they offer no
command.  Each invocation of GnuPG is supposed to include exactly one
command and zero or more options.  As the gpg(1) manpage says:
    gpg [--homedir dir] [--options file] [options] command [args]
--with-fingerprint is a GnuPG option, not a command.  When you give gpg
no command, you're basically saying "hey, gpg, do whatever you think is
more recent versions of gpg will complain:
    gpg: WARNING: no command supplied.  Trying to guess what you mean ...
Please see  for more discussion of this
situation and why it is problematic.
the latest release of the 2.1 branch is 2.1.23.  show-only was added in
        --dkg

@_date: 2017-08-14 19:50:04
@_author: Daniel Kahn Gillmor 
@_subject: fingerprint of key 
I think this is an interesting choice, but i don't understand why you've
made it.  Can you say more about why you don't want to import the key,
and why you prefer to fetch it each time?
I'm not saying it's "bad" -- it's just not what --fingerprint does.
       --fingerprint
              List all keys (or the specified ones) along with  their  finger?
              prints.  This  is  the  same  output as --list-keys but with the
              additional output of a line with the fingerprint.  May  also  be
              combined  with --list-signatures or --check-signatures.  If this
              command is given twice, the fingerprints of all  secondary  keys
              are  listed  too.   This  command also forces pretty printing of
              fingerprints if the keyid format has been set to "none".
So it's like --list-keys, which says:
       --list-keys
       -k
       --list-public-keys
              List the specified keys.  If no keys  are  specified,  then  all
              keys from the configured public keyrings are listed.
in other words (or maybe it's not as explicitly stated as it should be),
"list all the keys in your keyring that match the specification".  This
command is not intended for listing fingerprints of keys that come in on
stdin, or of an external file.
That said, you could combine it with:
    --no-default-keyring --keyring /path/to/file.gpg
(as long as the file wasn't ascii-armored, and as long as you weren't
concerned about updating your trustdb by accident, etc).
Again, i'm not saying this is particularly user-friendly, i'm just
trying to help you understand the current state of the tool.
If you have specific suggestions for how to improve the tool, please
suggest them!
        --dkg

@_date: 2017-08-17 19:49:23
@_author: Daniel Kahn Gillmor 
@_subject: Is it possible to certify (sign) a key using a subkey? 
I recommend re-considering this approach, because there is likely to be
software out there that:
 (a) doesn't expect to see certifications from subkeys at all, or
 (b) can't handle ECDSA
aiui, your main goal was because the certifications are smaller, but
you're still requiring people to fetch your larger primary key.  if you
want to really minimize the size, just make a new OpenPGP key that is
ECDSA-only.  That will still leave you on the outs with people using
software in the (b) category, but you won't have to worry about the (a)
category of software at all, and you will decrease the size of the
necessary transfered data even further.
          --dkg

@_date: 2017-08-17 20:20:35
@_author: Daniel Kahn Gillmor 
@_subject: fingerprint of key 
I also prefer this kind of "subcommand" syntax -- it matches what tools
like git and notmuch use.  However, that's a pretty radical departure
from the historical GnuPG command line, and it's likely to break all
sorts of existing things that expect to use the canonical interface.
If we're going to make radical departures like that, perhaps we should
be specifying an entirely new interface that just does "the sensible
bits" without all the rest of the arcana.
      --dkg

@_date: 2017-08-17 20:18:01
@_author: Daniel Kahn Gillmor 
@_subject: fingerprint of key 
You're not the only person with this perception.  But i'm afraid i think
it's a mistake, unfortunately.
Actually safely curating an OpenPGP keyring with GnuPG is a non-trivial
task.  As an example, here's a damned-if-you-do, damned-if-you-don't
Do you refresh the OpenPGP certificates in the keyring regularly
(e.g. from the keyservers)?  if you do not, then you risk missing notice
of revocations, so you probably have some revoked keys in your keyring
which you didn't know you had.
If you do refresh them regularly, then it's possible that things (new
user IDs, etc) get added to the certificates in your keyring during the
refresh (or possibly whole new certificates get added entirely), and it
contains things you've never actually vetted.
So, how to resolve this?
The short version is that you should treat your GnuPG keyring as an
untrusted collection of OpenPGP certificates that you know about.  But
you can explicitly mark the certificates that you think are legitimate
by certifying them ("signing the keys").  In particular, you can make
non-exportable ("local") signatures over the key+userid combinations
that you have actually confirmed out-of-band.
Even better, if you do that with a key which you have marked with
"ultimate" ownertrust, then GnuPG will report a "validity" for those
user IDs you've signed that matches what you intended to do, which is to
curate a list of known-valid key+userid combinations.
But treating the whole local keyring as a curated store is a mistake.
GnuPG doesn't work that way, and it doesn't expect to work that way :(
If you fetch the key each time you download something that you want to
check against the key, how do you know it's the right key over time?  If
it's "the right key" because it was fetched over a secure channel from
Oracle, why not just fetch the software over that channel?
The advantage of having a key stored locally is that you only have to
risk that network-fetch once; then you can make a local certification
over its sensible VirtualBox User ID, to mark it as the expected key (If
the User ID is *not* sensible, please complain to VirtualBox!).  Then all
future updates can be verified against the same key.
Do you see how that's better than fetching the key each time?
If a major change is going to happen in GnuPG, it will be in the 2.1
branch (or in 2.3 once 2.2 is released).  the older branches of GnuPG
(1.4.x and 2.0.x) receive very few changes from upstream.
You don't sign with a UID, you sign with a key.
Again, i'm not sure what you mean by "sign from a UID".  can you be more
clear?  You're signing your friend's key+uid, from (or "with") your
primary key.
Sounds reasonable to me, except that you had to use --recv-keys, rather
than just selecting the key to fetch from the --search interface.
here's a transcript of me fetching a key that appears to be yours from the keyservers:
0 dkg at alice:~$ gpg --search duane at nofroth.com
gpg: data source: (1)	Arlen Duane Whitty (Duane) Keys 1-1 of 1 for "duane at nofroth.com".  Enter number(s), N)ext, or Q)uit > 1
gpg: key E25FA6BF14571B64: public key "Arlen Duane Whitty (Duane) " imported
gpg: Total number processed: 1
gpg:               imported: 1
0 dkg at alice:~$ Note that i just typed "1" at the prompt, and it pulled your key in
directly (no need for a subsequent --recv-keys invocation).
        --dkg

@_date: 2017-08-17 23:14:07
@_author: Daniel Kahn Gillmor 
@_subject: fingerprint of key 
nope, GnuPG took the conservative approach and just produced a warning
while still trying to make a guess at what you meant.
Please don't underestimate the value of suggestions and questions from a
user.  Free software gets better because its users talk about it and
share ideas about how it can improve.  You don't need to have
contributed code to contribute ideas :)
            --dkg

@_date: 2017-08-17 23:25:26
@_author: Daniel Kahn Gillmor 
@_subject: Is it possible to certify (sign) a key using a subkey? 
I still don't think this is a good justification, fwiw.  If you think
you'll be making these certifications for other people to consume,
please do those other people a favor and just use your primary key.
The OpenPGP world has a habit of trying to make things too fancy.  Keep
it simple!
Where are you trying to save these bytes?
I don't know of a way to change usage flags on an existing subkey with
GnuPG without modifying the source.
You can add a new subkey with your chosen usage flags in --expert mode,
though.  But i don't recommend it.
        --dkg

@_date: 2017-08-17 23:19:58
@_author: Daniel Kahn Gillmor 
@_subject: fingerprint of key 
If you're going to manage a keyring manually, this is the right way to
do it, regardless of how many OpenPGP certificates you have in your
keyring.  (it's actually easier to do when you only have a few)
Note that nothing i outlined in my earlier suggestions involved you
setting "trust levels" (a.k.a. "ownertrust") at all.
setting "full trust" on a key means "i'm willing to accept identity
assertions made by the owner of this key" -- it's equivalent to "adding
a root CA to your browser" in some sense.
You can use GnuPG for years without ever setting any sort of ownertrust
on any key but your own (and if you generated your key in gpg, it
probably already has ultimate ownertrust).
Start with "whose keys do i believe i've checked?" -- that's plain
then, only later, if you really want to get into the whole web-of-trust
thing, should you consider setting ownertrust.
well said :)
i see, so you're talking about signing with a different key (not a
different uid).  You might want to look into adding the --default-key or
--local-user options before you do your next --edit-key operation.
All the best,
    --dkg

@_date: 2017-08-18 01:35:20
@_author: Daniel Kahn Gillmor 
@_subject: Edit key in batch mode 
Hi Ahmed--
I recommend using GnuPG 2.1 and --quick-add-uid for this purpose.
  --dkg

@_date: 2017-12-18 11:47:09
@_author: Daniel Kahn Gillmor 
@_subject: Upgrading from gpg1 to gpg2: lots of trouble, need help 
can you explain more about this use case?  it sounds to me like you
might prefer to just keep your secret keys without a passphrase in the
first place.
i might be "someone on the internet" :)
I can pretend it's a non-systemd system if you like -- that means you
simply don't have functional per-user session management, and it's now
on you to figure out session management yourself.  Without going into detail on your many questions, it sounds to me like
your main concern has to do with pinentry not seeming well-matched to
the way that you connect to the machines you use, and the way you expect
user interaction to happen.
Let me ask you to zoom out a minute from the specific details you're
seeing and try to imagine what you *want* -- ideally, not just in terms
of what you've done in the past.
for example, do you really want to have keys stored on a remote machine,
or do you want them stored locally, with the goal of being able to *use*
them remotely?  do you want to be prompted to confirm the use of each
private key?  do you expect that confirmation to include a passphrase
entry?  how do you conceive of your adversary in this context?  are you
concerned about leaking private key material?  auditing access?  some
other constraints?
      --dkg

@_date: 2017-12-20 09:52:14
@_author: Daniel Kahn Gillmor 
@_subject: Upgrading from gpg1 to gpg2: lots of trouble, need help 
Hi raf--
OK, so your preferred outcome is some way to enable a key for a limited
period of time.  is that right?
there should be only one S.gpg-agent.ssh socket, and therefore only one
agent.  If you were using systemd and dbus user sessions, those system
management tools would make sure that these things exist.  This is the
entire point of session management.  It's complex to do by hand, and
choosing to abandon the tools that offer it to you seems gratuitously
masochistic.  But ok?
I'm still not sure i understand your threat model -- apparently your
theorized attacker is capable of compromising the account on the
targeted host, but *only* between the times before you enable (and after
you disable) gpg-agent.  Is that right?
Why do you need these multi-detached operations?  by "multi-detached" i
mean that your sequence of operations appears to be:
 * attach
 * enable gpg-agent
 * detach
 * other things use?
 * attach
 * disable gpg-agent
 * detach
wouldn't you rather monitor these potentially-vulnerable accounts (by
staying attached or keeping a session open while they're in use)?
so what is the outcome if the gpg-agent is disabled when these
reboots/restarts happen?  how do you coordinate that access?
this approach seems congruent with my single-attach proposal:
 * you log into "key management" host (this enables the systemd
   gpg-agent user service)
 * on "key management" host, enable key access using
   gpg-preset-passphrase or something similar
 * you trigger restart of public-facing service
 * public-facing service connects to "key management" host, gets the
   data it needs
 * you verify that the restart of the public-facing service is successful
 * you log out of "key management" host.  dbus-user-session closes the
   gpg-agent automatically with your logout, thereby closing the agent
   and disabling access to those keys.
can you explain why that doesn't meet your goals?
I think there are other ways to address your redundancy concerns that
don't involve giving each of the redundant backup servers access to the
cleartext of the secret key material at any time; so i'm not going to
address this redundancy concern.
Here, i think you're making an efficiency argument -- you want to
prepare the "key management" host in advance, so that during the boot
process of the public-facing service, it gets what it needs without
you needing to manipulate it directly.
I'm trying to extract high-level, security-conscious, sensible goals
from your descriptions, so that i can help you figure out how to meet
them.  It's possible that your existing choices don't actually meet your
goals as well as you thought they did, and newer tools can help get you
closer to meeting your goals.
This may mean some amount of change, but it's change in the direction of
what you actually want, so hopefully it's worth the pain.
yes, i've tested it.  it works.
gpg1 only "works" with versions of gpg-agent as a passphrase cache, but
modern versions of GnuPG use gpg-agent as an actual cryptographic agent,
which does not release the secret key at all.
This is actually what i think you want, as it minimizes exposure of the
secret key itself.  gpg1 has access to the full secret key, while gpg2
deliberately does not.
gpg-preset-passphrase only unlocks access to secret key material in the
agent -- that is, it does *not* touch the passphrase cache.  This means
that it is incompatible with gpg1, as noted in the manual page.
where did you read this?  imho, gpg1 is now mostly only useful for
people with bizarre legacy constraints (like using an ancient, known-bad
PGP-2 key to maintain a system that is so crufty it cannot update the
list of administrator keys).
i advise against this approach.  please use the modern version.  it is
well-maintained and should meet your needs.
                --dkg

@_date: 2017-12-29 15:55:46
@_author: Daniel Kahn Gillmor 
@_subject: How to batch generate ECC key 
for modern gnupg, i think what you want is:
   gpg --quick-gen-key 'alice ' ed25519
and then, taking the generated fingerprint as $FPR, do:
   gpg --quick-add-key $FPR cv25519 encrypt
this is documented in the gpg(1) man page.
Normally, i'd just have suggested to use just quick-gen-key's
"futuredefault", but i just ran into:
   while testing, so i'm giving you the more complicated version here..
     --dkg

@_date: 2017-02-03 21:43:33
@_author: Daniel Kahn Gillmor 
@_subject: effect of revuid 
revuid does not delete a User ID, it revokes a user ID.  On a typical
OpenPGP certificate, a revoked User ID is still present, but it is
marked clearly and verifiably as having been revoked.
It's still possible to emit a "cleaned" version of the cert without any
of the revoked User IDs on it, of course.
Note that if you just do your revocation locally and don't find a way to
get it to your correspondents (e.g. by publishing to the keyservers, and
hoping that they all refresh regularly) then no one will know about it,
and from their point of view the User ID will not be revoked.
The primary key and its subkeys are still valid, yes.  If you revoke the
last User ID, then arguably a cleaned version of your certificate
(without any User IDs) will not be considered a valid "transferable
public key" because it will have no User ID associated.
even if your certificate as a whole is explicitly revoked, the
mathematical object that is the secret key still exists, and can still
perform whatever operations you require of it.  So yes, you should be
able to decrypt anything encrypted to any secret key you hold,
regardless of whether the certificates that contain those keys are
valid, revoked, expired, or whatever.
make sense?
       --dkg

@_date: 2017-02-03 22:09:16
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG to create CSR 
I'm sorry, i don't know the answer here, as this is a platform i don't
use myself.  hopefully someone else on the list here who uses GnuPG on
Windows and Kleopatra can give you some feedback or suggestions for how
to debug further.
        --dkg

@_date: 2017-02-03 22:21:30
@_author: Daniel Kahn Gillmor 
@_subject: Paper backup of all keys 
Sure, but it would likely be a pain to type the whole thing in.
You might be interested in the "paperkey" tool, written by David Shaw,
which does a good job at minimizing the typing you'll need to do
(assuming that all of the public parts of the certificate itself can be
recovered from the keyservers or your correspondents).
If you use debian or a debian derivative, just use "apt install
paperkey", but otherwise there's:
          --dkg

@_date: 2017-02-04 02:18:39
@_author: Daniel Kahn Gillmor 
@_subject: Unecrypted download of public keys 
as of 2.1.18, gnupg does use https by default to connect to the
keyserver network. :)
In particular, if you do not supply a --keyserver argument, it will use
hkps://hkps.pool.sks-keyservers.net as the default keyserver, and should
verify the certificates only against the pool-specific CA.
       --dkg

@_date: 2017-02-04 17:27:54
@_author: Daniel Kahn Gillmor 
@_subject: Unecrypted download of public keys 
it's not a config change -- it's a defaults change.
in the old arrangement, if you didn't specify a keyserver, you couldn't
get anything at all, so many people put some keyserver in their
configuration manually.
if you have a "keyserver" listed in your config manually, then you are
*overriding* the default.  And yes, if you list foo.example.com, it will
connect to that server in the clear (just as if you put
hkps://foo.example.com then it would connect using TLS).
Did you try this with no explicit "keyserver" directive?
It may be an issue with your distro, i don't know how arch has packaged
all the best,
        --dkg

@_date: 2017-02-13 11:34:44
@_author: Daniel Kahn Gillmor 
@_subject: Questions about --throw-keyids 
Agreed that the recipient's side is the tough part of the problem to
You don't mention gpg's --try-all-secrets, --try-secret-keys, and
--skip-hidden-recipients options, which are all attempts to provide some
guidance to gpg about how to handle these things during decryption.
Maybe you want to read up on those too?
Unfortunately, I have yet to see a functional, non-aggravating workflow
for users who have multiple secret keys who receive encrypted messages
with hidden keyIDs.
It's almost like decryption of messages with hidden keyids and
per-decryption passphrase prompting (or even confirmation) are mutually
incompatible workflows :/
I'd love to be convinced otherwise.
       --dkg

@_date: 2017-02-13 18:06:00
@_author: Daniel Kahn Gillmor 
@_subject: Questions about --throw-keyids 
how about "--try-cached-secrets", by analogy with --try-all-secrets or
I like this idea.
Right, this makes sense.  It's also possible that the combination of the
tool invoking gpg and gpg itself can be cleverer about proposing
candidate keys.  For example, if the PKESK uses RSA, and the value is
4096-bits in size, and the thing being decrypted is an e-mail address
with a certain Date: header and specific addresses in the To: and Cc:
fields, then you could filter secret key material by creation/expiration
dates and User IDs and usage flags and key sizes.  This might also turn
out to mean that of all secret keys held, only one is even remotely
likely, in which case it could just be tried anyway.  You could use the
inbound e-mail address (enclosed in <>s) with --try-secret-key, but i
don't know how you could pass it the hints from the Date headers.
I wonder whether anyone is trying to do anything like this currently.
If so, i'd be happy to hear details about what you've tried and what you
think might be necessary to make it even better.
    --dkg

@_date: 2017-02-13 19:23:37
@_author: Daniel Kahn Gillmor 
@_subject: Questions about --throw-keyids 
for an API, there's nothing wrong with explicitly specifying the thing
that people should *want* to be doing as a separate interface.
GnuPG has some level of difficulty because it's trying to offer both an
API and a user interface.  For this discussion, i think we're pretty
clearly talking about the API, though.
You don't get the luxury to decide on this transition yourself, i'm
afraid.  Mailpile has to deal with *other* MUAs doing throw-keyids, just
like those other MUAs have to deal with it if/when Mailpile starts doing
it :/
     --dkg

@_date: 2017-02-14 09:27:06
@_author: Daniel Kahn Gillmor 
@_subject: Questions about --throw-keyids 
I'm open to other suggestions about how to achieve this behavior.
GnuPG's general stance appears to be that the only way to interact with
the suite is through the command line.  It also has historically tried
to avoid making breaking changes to the behavior based on existing
options.  This doesn't appear to leave much room for fixing problems or
adding functionality *without* new command-line switches.
       --dkg

@_date: 2017-02-14 18:31:35
@_author: Daniel Kahn Gillmor 
@_subject: Questions about --throw-keyids 
I absolutely agree with this assessment, and i also agree with Bjarni's
approach to defending bcc addresses by sending distinct e-mails.
Bjarni's suggestion could theoretically be done in two ways:
 0) do the symmetric encryption once, and then pick and choose which
    PKESK OpenPGP packets to prepend to it depending on which message is
    being generated.
 1) simply re-encrypt the same cleartext multiple times (using different
    symmetric session keys)
afaict, GnuPG only supports (1) at the moment (this is probably OK).
Presumably each message would use the same Message-Id, so that replies
thread properly, etc.
However, gpg is a tool that's used not only in e-mail contexts, so it
does still need to support the --throw-keyids option, since non-email
contexts are not guaranteed to be wrapped in equivalent metadata the
same way as an rfc822 message would be. :/
     --dkg

@_date: 2017-02-15 12:12:23
@_author: Daniel Kahn Gillmor 
@_subject: GPG homedir path length limit 
Hi all--
sorry for the late followup on this thread:
Why does this need to be created manually?  Why not try to create it if
possible the first time there's a chance to use it, no matter what?
or, if "no matter what" is too aggressive, why not at least try to
create the ephemeral it if it's clear that the non-ephemeral location is
longer than the max socket length?
I personally like the simplicity and uniformity of "if /run/user/$(id
-u)/ exists and is writable, then we will use it for the socketdir."
What does GnuPG gain from having a known failure mode that requires a
manual fix?
        --dkg

@_date: 2017-02-15 12:21:20
@_author: Daniel Kahn Gillmor 
@_subject: GPG homedir path length limit 
[?]
So one possible issue with my proposal is that by requiring explicit use
of --create-socketdir you remind the user that they're also responsible
for figuring out when to --remove-socketdir.
However, that shouldn't be necessary either.  If gpg-agent or dirmngr
terminates knowing that they should remove their own sockets, they can
do that and then just rmdir(2) on the ephemeral directory path.
If rmdir returns ENOTEMPTY, that's fine -- presumably some other daemon
is also using that path.  if it returns successfully, then the directory
is cleaned up, as it should be.
In --supervised mode, the deamons should not be responsible for removing
any sockets, so they would also not be responsible for cleaning up the
parent directory either.
does this make sense?  Are there any downsides that i'm missing?
       --dkg

@_date: 2017-02-15 13:46:13
@_author: Daniel Kahn Gillmor 
@_subject: Expanding web-of-trust with subkey 
right, so your use of "trust-model direct" switches the meaning of the
"trust" flag from its usual "ownertrust" semantics to be what we'd
normally call "validity".
Note also that when you mark a key itself as "trusted" in this way,
you're asking GnuPG to treat *all* user IDs on it as valid.
So if the keyholder updates their key at some point in the future to add
a new User ID, your GnuPG installation is going to blindly accept that
User ID as legitimate.
Please see A405E58AB3725B396ED1B85C1318EFAC5FBBDBCE as an example of
this kind of thing.  The keyholder cheekily added a new User ID "Satoshi
Nakamoto ( " after his OpenPGP
certificate was created.  I have met the keyholder, and i do not believe
he is actually Satoshi Nakamoto ;)
please be aware that if you switch from "trust-model direct" to
"trust-model tofu+pgp", then your previous assignments of "trust" will
transform into indications of "ownertrust".  So someone whose OpenPGP
certificate you previously meant to indicate was valid can now certify
*other* OpenPGP certificates, and the pgp trust model will accept those
certificates as correct :(
Transitioning between trust models without overhauling the ownertrust db
is not a workflow that seems particularly well-supported, unfortunately.
   --dkg

@_date: 2017-02-15 16:19:38
@_author: Daniel Kahn Gillmor 
@_subject: Should we trust "MyMail-crypt for Gmail" Chrome extension? 
for Gmail"):
I've never heard of it.  Mailvelope is what i've heard people recommend
for the use case you describe.
    --dkg

@_date: 2017-02-16 19:29:09
@_author: Daniel Kahn Gillmor 
@_subject: GPG homedir path length limit 
this is a clever approach to *connect* to such a socket, on some
But if you ever use getsockname (e.g. common/sysutils.c and
dirmngr/dns.c), the long socket path names are bound to fail on *any*
system, right?
        --dkg

@_date: 2017-02-16 19:53:47
@_author: Daniel Kahn Gillmor 
@_subject: GPG homedir path length limit 
If it's an exception, it's infrequent.  So by definition, we won't be
cluttering /run/user/$(id -u)/gnupg/ with many directories.
If we clean up the directories automatically as i recommended when the
daemons terminate, it won't leave a cluttered residue.
The one common work pattern that this misses is this one:
 * create a temporary GNUPGHOME for experimentation
 * when done, do:   rm -rf "$GNUGHOME"
Without the socketdir creation, the daemons will work as long the path
is short enough, and they terminate cleanly when the temporary homedir
is destroyed.
With the socketdir creation, the daemons will work regardless of the
path length, but they won't terminate cleanly if the temporary homedir
is destroyed.  That would be unfortunate.
So my current proposal for GNU/Linux systems for daemons like gpg-agent
and dirmngr when using a non-standard $GNUPGHOME is:
  * daemons create the ephemeral socketdir automatically if possible.
  * clients try the ephemeral socketdir first, then fall back to
    in-$GNUPGHOME sockets (i think this is already the case).
  * daemons watch the $GNUPGHOME with inotify, and auto-terminate if the
    $GNUPGHOME itself is destroyed.
  * daemons try to rmdir() on the ephemeral socketdir on termination,
    failing quietly on ENOTEMPTY.
I've documented this as a bug report at:
   What's non-portable about it?  If it's not possible to create the
directory, we don't create it, and fall back to trying locally.  if it
is possible, we do create it and use it.
This thread should probably move over to gnupg-devel at some point, i
   --dkg

@_date: 2017-02-17 14:43:06
@_author: Daniel Kahn Gillmor 
@_subject: powertop(8) Points at gpg-agent. 
We're shipping these patches in debian testing and unstable right now,
and i don't think i've seen any problems with the current set.
You can find the current set at:
  You can also find a set of similar patches for dirmngr, which has the
same issue:
  I would be happy to merge any of these upstream if the upstream team
wants them.
        --dkg

@_date: 2017-02-17 15:18:14
@_author: Daniel Kahn Gillmor 
@_subject: GPG homedir path length limit 
That would be a way to advance this conversation, i think :)
However, path length may only be one concern.  What about other
scenarios, like trying to operate with a read-only $GNUPGHOME ?  Is that
something we want to support?  What about a $GNUPGHOME that resides on a
network-mount drive, or a filesystem that doesn't support unix-domain
but they're still there!  if they're not necessary, we should remove
them.  useful diffs with more -'s than +'s are very nice contributions
to any complex software project :)
        --dkg

@_date: 2017-02-21 22:24:36
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG2.1 is using the wrong signing subkey 
When signing, gpg prefers the most recent subkey that is
signing-capable.  Please see:
   for ongoing discussion and a possible patch that's waiting for review by
more knowledgable developers.
    --dkg

@_date: 2017-02-21 23:25:44
@_author: Daniel Kahn Gillmor 
@_subject: Announcing paperbackup.py to backup keys as QR codes on paper 
Hash: SHA512
Hi Gerd--
this is a cool idea.  however, it seems like you might be backing up
more than most people would need.  For most folks, their OpenPGP
certificates (public keys) are stored on the public keyservers.  Or at
least their friends have a copy of them :)
Even if you want the whole certificate, you've duplicated most of the
material here -- just the data produced by --export-secret-key should be
sufficient to reconstruct everything.  Probably, putting less data in
your qrcode backup will make the backup more robust during recovery..
So for most folks, the critical backup that they need is likely to be
only the secret key material itself, since the public key material and
signatures and the like can all be retrieved from from the keyserver
network or from friends.
Are you aware of David Shaw's paperkey?
  This produces significantly less data (still in text form, though), so
it could be combined with your approach to have a nice big, robust,
scannable recovery mechanism.
thanks for publishing your work!
          --dkg

@_date: 2017-02-22 17:48:27
@_author: Daniel Kahn Gillmor 
@_subject: export-minimal doesn't affect export-secret-key? 
I just confirmed this.  I've put it in the bugtracker so it doesn't get
   Thanks for reporting it, Peter.
       --dkg

@_date: 2017-02-23 14:40:51
@_author: Daniel Kahn Gillmor 
@_subject: Announcing paperbackup.py to backup keys as QR codes on paper 
humanity and science thank you for your efforts :)
happy hacking,
         --dkg

@_date: 2017-02-23 14:47:05
@_author: Daniel Kahn Gillmor 
@_subject: OpenPGP third-party certifications do not imply trust [was: Re: 
[ not on-topic for this thread, hence the subject change ]
I'm calling this out because it's a common misconception, and i don't
want it to lie here unchallenged when someone is browsing the archives.
The people who "sign your key" (who have created an OpenPGP
certification that binds your primary key to your User ID) are only
identifying you and your key.  They have said nothing about "trust" by
making those certifications.
For example, I am happy to certify the identity and key of someone who i
do not trust at all, as long as i know who they are and they've asserted
their key to me in-person, or across some reliable, non-forgeable
So the fact that Alice has a dozen certifications on her key and Bob has
two doesn't mean that Alice is trusted by more people than Bob at all.
It just means that more people have been willing to publicly assert that
they know Alice's identity and key than have been willing to publicly
assert the same information about Bob.
    --dkg

@_date: 2017-02-25 14:08:10
@_author: Daniel Kahn Gillmor 
@_subject: Real-world current impact of disabling SHA1 
[ ... ]
To be fair, we should have been *deprecating* SHA1 many years ago (since
Wang et al in 2005).  we're late.  if we'd been deprecating it for years
it would be easier to consider disabling it now.
Thanks for doing this, it's good to have concrete datapoints.
fwiw, i ran with --weak-digest SHA1 for several months back when we
introduced --weak-digest to see how it would work for me.  It turned out
to be a rough user experience, because there were enough tools out there
that were still generating things with SHA1 :/
I just ran some similar tests myself with GnuPG 2.1.18 (libgcrypt
1.7.6-beta) on a keyring with 3402 OpenPGP certificates.  In
preparation, i did the following in an empty directory on a tmpfs (if
everything is RAM-backed i don't have to worry that i'm confounding
measurements with with disk I/O performance):
    gpg --export > keys-to-import.txt
    gpg --export-ownertrust > ownertrust.txt
    mkdir -m 0700 normal without-sha1
    echo weak-digest SHA1 > without-sha1/gpg.conf
Then i ran my comparison tests, like so:
    for GNUPGHOME in normal without-sha1; do
      export GNUPGHOME
      printf "=====%s=====\n" "$GNUPGHOME"
      time gpg --quiet --batch --import < keys-to-import.gpg
      time gpg --quiet --batch  --import-ownertrust < ownertrust.txt
      time gpg --batch --check-trustdb
      time gpg --with-colons --list-keys | grep -c ^pub:
    done
Full output is at the end of this e-mail.
A little more than half of the certificates in my test keyring had no
self-sigs with anything other than SHA1.  Since GnuPG discards certs
with no valid self-sig at import time, the without-sha1 keyring is
significantly smaller.
Still, i went from 123 valid certificates to 89 valid certificates when
i dropped SHA1.
I suspect that the self-sig issue is the main concern -- *not* links
between keys.  People can fix their self-sigs just by re-signing their
own keys.
it's also possible that debian developers are disproportionately
overrepresented in my keyring, and this is a group of folks who have
been actively migrating away from SHA1 already, which would explain why
my results aren't quite as terrible as Phil's are.
For m, the timing for each stage of the test is comparable for what we'd
expect, given the sizes of the different keyrings -- so the timing is
significantly faster for the SHA1-less keyring, not the other way
around.  i don't see any evidence that the workflow i used shows any
performance degradation when used with --weak-digest sha1.
The difference between my test and Phil's test is that i've done a clean
import, so the keyring i'm working with is already pruned. i wonder if
the performance penalty comes from gpg discovering keys that it
considers invalid already in the keyring.
If so, it'd be nice to find a way to fix this performance problem.  At
the very least,         --dkg
Here's the results from my own tests:

@_date: 2017-02-25 10:52:40
@_author: Daniel Kahn Gillmor 
@_subject: file size change in trustdb.gpg after recovery 
I don't know about the size change of the trustdb.gpg -- hopefully
someone else can weigh in on that.
But i want to point out that 6468 ulimately-trusted keys is a *very*
unusual arrangement.  any one of these keys can certify any other key
and gpg will rely on those certifications.  You should think of ultimate
ownertrust in the same way that you think of adding a new root CA to
your X.509 certificate validation stack (e.g. for your web browser).
Anyone with this capacity can pretty easily inject itself in your
communications stream by adding OpenPGP public keys ("OpenPGP
certificates") that your tools will happily believe are valid for the
identities they claim.
I'm not saying that this is *never* what anyone would want to do, but
i've never seen a use case present itself where this was what the user
actually wanted to enable > 6K parties to be able to do.
        --dkg

@_date: 2017-02-25 10:45:31
@_author: Daniel Kahn Gillmor 
@_subject: SHA1 collision found 
I think the reason that a majority of keys have "round" key sizes is
habit, and that the tools make it easy to generate them that way.
The size variation that vedaal describes is due to the definition of the
v3 fingerprint:
    The fingerprint of a V3 key is formed by hashing the body (but not
   the two-octet length) of the MPIs that form the key material (public
   modulus n, followed by exponent e) with MD5.
As a toy example, consider the case where p = 0x1411304f and q =
0x141120c5, so n = 0x0192af7bf8830ccb and e = 0x010001
These MPIs are stored in full octets, so the material hashed for the v3
fingerprint is (in hex)
    01 92 af 7b f8 83 0c cb 01 00 01
--------- n -----------|-- e ---|
if i want to find a key with the same v3 fingerprint, i just need to
vary the boundary between the two, for example like this:
    01 92 af 7b f8 83 0c cb 01 00 01
--------- n --------|---- e ----|
the bytestring hashed (and therefore the fingerprint) is exactly the
same as before, but n is 8 bits shorter, and e is 8 bits longer.
now, it's probably obvious to anyone who bothers to inspect the public
key that this is not a good key -- at the very least, n is clearly not
the product of two primes ;) But RSA will still work with it.  If the
goal is to produce a key with the same fingerprint, it's trivial to do.
This is one of the reasons why the modern GnuPG suite no longer supports
these archaic keys.  it's simply not a reasonable or safe-to-use format.
The OpenPGPv4 fingerprint includes explicit sizes of the components in
the material hashed, so it doesn't have this problem.
      --dkg

@_date: 2017-01-03 02:55:46
@_author: Daniel Kahn Gillmor 
@_subject: File perms for conf files 
I think this is going to result in a warning about too-loose permissions
for the .gnupg directory itself, which should probably be 0700.
    --dkg

@_date: 2017-01-03 09:05:19
@_author: Daniel Kahn Gillmor 
@_subject: export encryption (subkey) only? 
yes, the documentation is correct.  When using export-secret-subkeys,
the primary key is exported with a stripped set of secret key
parameters, so it is importable, but not usable.
If you want to inspect this to ensure it's correct, you can look at the
exported transferable secret key with gpg --list-packets (which will
show the stripped secret key material as using "gnu-dummy S2K") or
pgpdump (which will show the stripped secret key material as "GnuPG
gnu-dummy (s2k 1001)").
While this might be marginally more usable by some of your
organization's staff, it sounds significantly more complicated and
confusing to the external parties who your staff is going to talk to.
You should stick with a single public certificate per user (containing
the two keys that you describe) so that your users' correspondents don't
have to juggle multiple keys per person they communicate with.
     --dkg

@_date: 2017-01-04 17:46:50
@_author: Daniel Kahn Gillmor 
@_subject: exported subkey usage? 
the "public key algorithm" is "RSA (Encrypt or Sign)".  The usage info is
stored in the "key flags" subpackets in self-signatures (over uids for
the primary key, and binding signatures for the subkeys).  Please see:
    the "public key algorithm" values 2 (RSA Encrypt-only) and 3 (RSA
sign-only) are deprecated.
           --dkg

@_date: 2017-01-13 16:40:35
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG to create CSR 
When you say "does not seem compatible with Microsoft CA", i don't know
what that means.  Is there a specific Microsoft CA product that you're
using?  can you provide pointers to it?
can you provide error messages, warnings, or behaviors that indicate
that the CSR you generated is incompatible?  What specific steps did you
take with the Gpg4win gui to generate the CSR?
If you want to use a command-line part of the GnuPG suite to create an
X.509 CSR, the tool "gpgsm" should be capable of doing it.
   gpgsm --gen-key
and follow the prompts.
If it asks you "Create self-signed certificate? (y/N)", you want to
answer "N" (no) because you want the csr instead.
For example (this is not on windows, this is on a GNU/Linux machine, but
it should look similar to what you see in the windows cmd.exe shell:
0 dkg at alice:~$ gpgsm --gen-key
gpgsm (GnuPG) 2.1.17; Copyright (C) 2016 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Please select what kind of key you want:
   (1) RSA
   (2) Existing key
   (3) Existing key from card
Your selection? 1
What keysize do you want? (2048) Requested keysize is 2048 bits
Possible actions for a RSA key:
   (1) sign, encrypt
   (2) sign
   (3) encrypt
Your selection? 1
Enter the X.509 subject name: CN=bananas.example
Enter email addresses (end with an empty line):
Enter DNS names (optional; end with an empty line):
Enter URIs (optional; end with an empty line):
Create self-signed certificate? (y/N) These parameters are used:
    Key-Type: RSA
    Key-Length: 2048
    Key-Usage: sign, encrypt
    Name-DN: CN=bananas.example
    Name-DNS: bananas.example
    Name-DNS: Proceed with creation? (y/N) y
Now creating certificate request.  This may take a while ...
gpgsm: about to sign the CSR for key: &C6962BE32BF3CA7C3207BCECC0FC1CD3C24CC2E7
gpgsm: certificate request created
Ready.  You should now send this request to your CA.
-----BEGIN CERTIFICATE REQUEST-----
-----END CERTIFICATE REQUEST-----
0 dkg at alice:$ Then you'd copy/paste the stuff between the
"-----BEGIN CERTIFICATE REQUEST-----" and
"-----END CERTIFICATE REQUEST-----" lines (including those lines as
well) into a file that you can import into your CA.
make sense?
     --dkg

@_date: 2017-07-05 20:56:56
@_author: Daniel Kahn Gillmor 
@_subject: Fwd: which program use: gpg or gpgv? 
more recent versions of debian will use gpgv for verifying integrity of
downloaded system packages, and do not need gpg itself for this purpose.
If you want to verify packages signed by other developers, you'll need
to get their keys, though, and that requires knowing their keys.
According to the versions at  it looks
screen 4.5.1 has been signed with key
0x71AA09D9E8870FDB0AA7B61E21F968DEF747ABD7, while the most recent
version of screen (4.6.0) has been signed with
Which of these keys is a legitimate key to validate versions of screen?
I don't know!  They're both listed in
though, so perhaps they're both acceptable.
If you fetch the maintainers' file from savannah, and convert it into an
OpenPGP binary form, you should be able to validate the screen package
against it:
    wget -O screen-keys.asc '
    gpg --dearmor < screen-keys.asc > screen-keys.gpg
    wget      gpgv --keyring $(pwd)/screen-keys.gpg screen-4.5.1.tar.gz.sig screen-4.5.1.tar.gz
This should show you something like:
    gpgv: Signature made Sat 25 Feb 2017 10:50:15 AM EST
    gpgv:                using RSA key 71AA09D9E8870FDB0AA7B61E21F968DEF747ABD7
    gpgv: Good signature from "Alexander Naumov "
Note, however, that you've only moved the responsibility from verifying
the package to verifying which keys actually are the legitimate keys for
the maintainers of GNU screen.  So it's a win, but it's not perfect.
        --dkg

@_date: 2017-07-11 19:55:52
@_author: Daniel Kahn Gillmor 
@_subject: gpgme - raw RSA operation using GPG public/private keys? 
you're right -- gpgm is only for higher-level protocol operations,
whether they're OpenPGP or CMS (cryptographic message syntax).  it
doesn't offer low-level crypto primitives.
if you want low-level crypto primitives that are GPL-compatible, you can
use libhogweed (from the nettle project) or libgcrypt.
Modern GnuPG uses libgcrypt for its crypto primitives, fwiw.
       --dkg

@_date: 2017-07-16 09:30:03
@_author: Daniel Kahn Gillmor 
@_subject: gpg-agent/pinentry: How to verify calling application 
pinentry itself doesn't know the source of the request, but gpg-agent
could use getsockopt(SO_PEERCRED) to get at least the requesting
process's pid, uid, and gid.
the pid is kind-of usable (with some possibility of a race) to learn
something about which process made the request, which gpg-agent could
pass on to the pinentry.
I don't think there's currently any plan to do anything like this, but
if you want it to happen, i recommend documenting the idea in a ticket
on  so that there's somewhere to keep track of it
and potentially collect proposed patches.
   --dkg

@_date: 2017-06-04 16:20:50
@_author: Daniel Kahn Gillmor 
@_subject: Question for app developers, like Enigmail etc. - Identicons 
Hi Stefan--
I think you're asking about two sort of different things.
on the one hand, you're asserting that the 32-bit keyid isn't sufficient
for any sort of cryptographic verification.  that's absolutely correct,
and enigmail really shouldn't be exposing the 32-bit keyID to humans
where it can avoid doing so.  I've written more about this here:
  You're also asking about graphical representations of the cryptographic
identity -- a graphical representation of a fingerprint, basically.
The community has seen several different proposals of graphical
fingerprint representations in the past, and every one i've seen
gets stuck when faced with the hard questions.  In particular:
 * is the goal *recognition* of the fingerprint (i.e. "does this
   fingerprint look sufficiently similar to the one i've seen in the
   past for me to remember it?"), or is the goal *distinguishing* from a
   maliciously-crafted fingerprint (i.e. "am i certain that this
   fingerprint is an exact match of one that i expect to see from the
   peer who i think should have been signing this e-mail?")
 * In the "recognition" model, it's not clear that any
   cryptographically-strong guarantees are made to the user.  So why tie
   the visual identity to the cryptographic identity if we think it's
   spoofable?
 * in the "distinguishing" model, it's not clear that any of the schemes
   i've seen are actually better for most humans against a dedicated
   attacker who crafts fingerprints to make visual identities that look
   similar.  do you have any studies showing this capability against a
   motivated and technically capable attacker?
I'd generally think that if you're looking for a tool to help people
remember and recognize keys that they've seen before, then a mail user
agent is in a great position to do exactly that: just tell the user
explicitly what they've seen before, how often, etc.  why depend on the
human visual cortex or on human ability for numeric recall?
      --dkg

@_date: 2017-06-05 16:26:56
@_author: Daniel Kahn Gillmor 
@_subject: Fwd: Re: Question for app developers, 
what does "bullet-proof" mean, specifically?  I ask this not for
pedantry's sake, but because clearly stating the problem makes it
possible to know whether a specific solution is applicable.
It sounds to me like you're saying that you find the key verification
and certification steps as implemented by enigmail to be
difficult-to-use.  You wouldn't be the only person who has that
But i don't see how a graphical icon solves that problem.  Isn't it a
workflow problem, and not a visual-comparison problem?  If there's a
standard thing (comparison, lookup, verification) you expect to be able
to do with the tool, the tool should make that thing easy and simple to
What specifically is the thing that you're trying to do when you click
"Details" and verify the fingerprint (from what list?)?  Enigmail itself
can compare fingerprints far better than you or i can, even if there is
a graphical representation involved :) Maybe there's a different
question or different interface Enigmail ought to offer in the "Details"
view entirely?
i agree with you that users won't look at mail headers closely, which is
why the e-mail client (the "mail user agent", or MUA) should be the
thing to do the comparison, and to make it very clear to the user when
something is amiss.  But that still doesn't answer the question of what
the MUA should actually be trying to compare and what results it should
be highlighting.
   --dkg

@_date: 2017-06-05 22:11:27
@_author: Daniel Kahn Gillmor 
@_subject: Fwd: Re: Question for app developers, 
here's one way to try to frame the question: Imagine the situation as a
game, where you have two players on one team, "defense" named Alice and
Bob; Alice wants to send a message to Bob.  Another player on the
opposing team, "offense", is named Mallory, is trying to send a message
to Bob as well, but trying to trick Bob into thinking that the incoming
message comes from Alice.
The way the game is played, either Alice or Mallory gets to send a
message.  Bob has to decide whether the message actually came from
Alice.  If Bob gets it right, the "defense" wins.  If Bob gets it wrong,
the "offense" wins.  The game is played multiple times.
Is that the scenario you're thinking of?  If so, does the defense need
to win 100% of the time over thousands of games?  or is it acceptable
for offense to win occasionally?
In any case question is: how much work does Mallory need to do to get
Bob to make a mistake?  How frequently can Mallory trick Bob into
accepting mail from her as though it were from Alice?  Conversely, how
many messages that were actually from Alice can Bob accidentally reject
without making Alice upset enough to give up on the entire
communications scheme?
When you frame the problem this way, you can start thinking more
concretely about what "bulletproof" means, and you can actually design
user trials to test proposals.
There are probably other ways to concretize the problem, this is just
one that i've come up with.  But without a concrete way to understand
what we're looking for, words like "bullet proof" or "easy to read" or
"cryptographically secure" are tough to get people to agree on.
I suspect (as discussed upthread) that TOFU will have better metrics for
"defense" at the game described above than any attempt that involves
asking people to visually distinguish deterministically-generated
identicons.  But i don't know, because i haven't tested it.
                   --dkg

@_date: 2017-06-08 11:12:17
@_author: Daniel Kahn Gillmor 
@_subject: How to show fingerprint in email header? 
This is probably more of a question for your mail user agent than for
GnuPG, since GnuPG doesn't send mail.  What program do you use to send
        --dkg

@_date: 2017-06-19 17:36:05
@_author: Daniel Kahn Gillmor 
@_subject: How to join pubring.kbx and pubring.gpg? 
for the record, pem2openpgp works with both public keys and private
        --dkg

@_date: 2017-06-20 13:56:57
@_author: Daniel Kahn Gillmor 
@_subject: Having trouble adding gpg key to apt keyring in Debian 9.0 
Hi Rex--
While it's a common recommendation, "apt-key add -" is generally a bad
idea, because it mixes the fetched keys in with all the other keys.
It's a better idea to fetch the keys for a given repository separately
and mark them as acceptable only for this specific repo.
Since you're using debian stable (stretch), you might want to read:
    From its suggestions, if you want to add the sublime repo (which i have
never vetted and am not personally recommending here), you might prefer
to do the following on debian stretch:
    wget -O /usr/share/keyring/sublimehq-pub.gpg.asc     gpg --dearmor < /usr/share/keyring/sublimehq-pub.gpg.asc > /usr/share/keyring/sublimehq-pub.gpg
    echo 'deb [signed-by=/usr/share/keyring/sublimehq-pub.gpg]  apt/stable/' > /etc/apt/sources.list.d/sublime.list
This makes it so the sublime repository key is not accepted for
certifying the main debian repos (which it should not be doing).
I suspect that the problem you were having may have to do with the
ascii-armoring on the fetched file, which is why i've included the
--dearmor line in the middle of the three steps above.
hope this helps,
     --dkg

@_date: 2017-06-21 14:03:00
@_author: Daniel Kahn Gillmor 
@_subject: Revoking a certificate (--edit-key + revsig) 
That action would be me saying "i no longer believe that this key is
only controlled by the entity that corresponds to the identity in the
User ID"
in the abstract:
 * i learned via some channel i consider trustworthy that this key isn't
   appropriate for use with this User ID any more.
more concretely:
 * "I had lunch with Sarah and she told me she'd lost access to her
   secret key and didn't have a revocation certificate available."
 * "Acme Corp. just published a press release on their https website
   indicating that there was a break-in on their server "astrid".  I
   happen to know that the user account "archivemaster" on "astrid" has
   a copy of their software-signing secret keys, but they haven't
   revoked them publicly.  I no longer have confidence that this key is
   controlled solely by Acme Corp, so i'm removing my public attestation
   of it."
Does this make sense?  From the point of view of the person evaluating
the third-party signature, they can't tell the difference.  they just
know that before they saw the revocation, they know that "dkg says this
key belongs to Sarah" or "dkg says that this is Acme Corp's
software-signing key", and after they see the revocation, they know "dkg
doesn't have anything useful to say about the identities on this key --
they could belong to anyone".
     --dkg

@_date: 2017-06-30 14:26:27
@_author: Daniel Kahn Gillmor 
@_subject: [HELP] pinentry-curses breaks SSH auth, 
============================== START ==============================
Hi Ryan--
setting GPG_TTY only works for clients that know to interpret it and to
pass its value along to gpg-agent.
when ssh is speaking to gpg-agent, it's using the ssh-agent protocol,
which has no mechanism for passing this info to the agent.
as a result, the agent (which *isn't* running attached to the current
tty) can't tell pinentry which tty to use.
have you tried doing this:
    GPG_TTY=$(tty) gpg-connect-agent updatestartuptty /bye
from the current terminal before trying to use ssh?
i consider this a workaround (which isn't satisfactory for easy everyday
use without better integration), but it's probably better than nothing.
please let the list know if that workarund works for you!
     --dkg

@_date: 2017-03-13 21:35:01
@_author: Daniel Kahn Gillmor 
@_subject: private-keys-v1.d 
what version of gpg did you have on the old system?  what version on the
new system?
the steps you took sound reasonable to me, as long as the new system had
gpg 2.1.x, so i'm a bit puzzled as to why the import failed for you.
with a bit more info, maybe we can get to the bottom of things,
    --dkg

@_date: 2017-03-15 17:16:28
@_author: Daniel Kahn Gillmor 
@_subject: Security doubts on 3DES default 
and some of us have experimented with running this kind of configuration
(at the very least with --weak-digest SHA1) for quite some time now.
take rjh's caveat with a grain of salt -- GnuPG's interest is in
protecting its users.  If the project knows something is bad, we're
going to try to protect users from it.
that said, data in a store-and-forward format (or for persistent
backups) makes it tricky to fully remove something.  Should GnuPG refuse
to decrypt a symmetrically-encrypted message that uses 3DES ?  probably
not, but it should probably decline to generate such a thing, in the way
that it defaults to generating signatures using SHA256 these days.
     --dkg

@_date: 2017-03-20 11:21:32
@_author: Daniel Kahn Gillmor 
@_subject: Need Help. 
Usually --import needs two leading hyphens, not one.
it's not clear to me what "NT\MSSQLAgent" is supposed to mean -- the -u
flag is to identify an OpenPGP User ID, which isn't relevant for the
--import operation.
It looks like you're trying to use it to switch user accounts, which
GnuPG won't do.  You'll need to use your operating system's mechanism to
switch user accounts first, and then run gpg from the other user.  In
Windows (which it looks like you're using) that'd be "Run as?" or
something like that.
          --dkg

@_date: 2017-03-20 11:30:12
@_author: Daniel Kahn Gillmor 
@_subject: dirmngr failes with missing file 
What version of gpg?  what version of dirmngr?
can you please paste the exact error message?
what specific kind of failure are you seeing -- does dirmngr itself
actually fail, or does it just produce the warning and continue?
         --dkg

@_date: 2017-05-01 12:32:10
@_author: Daniel Kahn Gillmor 
@_subject: How to export private ed25519 subkey to the SSH format 
I don't think that monkeysphere's openpgp2ssh tool handles ed25519 at
the moment (i'm part of monkeysphere upstream).  It'd be great if it
        --dkg

@_date: 2017-05-09 12:38:56
@_author: Daniel Kahn Gillmor 
@_subject: gpg hangs when asking for passphrase 
Hi Joey--
are you using systemd?  do you have dbus-user-session installed?  how
are you logged into the machine (e.g. X11 via gdm, wayland with gdm, a
text-mode-only vt console, etc, ssh session only)?  do you have
libpam-systemd installed?  are you logged into the machine in multiple
concurrent sessions?  does "gpg-connect-agent" on its own hang, rather
than giving you a "> " prompt that you can interact with?  what version
of the debian package are you running?  when you say you've tried
several pinentry variants, how did you try them all?
        --dkg

@_date: 2017-05-09 12:59:44
@_author: Daniel Kahn Gillmor 
@_subject: gpg hangs when asking for passphrase 
hm, masking the user units really shouldn't be necessary.  if you can
explain your system setup to me (see the questions asked elsewhere in
the thread), i'd be happy to try to replicate the problem and give a
better diagnosis.
        --dkg

@_date: 2017-05-10 11:09:00
@_author: Daniel Kahn Gillmor 
@_subject: Error on gnupg-2.1.20 installation 
On most GNU/Linux systems, this inotify definition is typically made
available by either your libc development package, or by headers
supplied by Linux dev packages.
On debian, you'll need the libc6-dev package, which i can't imagine you
could have even gotten this far without having it available.
This line should also only be compiled if the C preprocessor has defined
HAVE_INOTIFY_INIT, in which case you should already have , which is where the IN_EXCL_UNLINK definition is
typically located.
So i'm perplexed why you'd be running into this.  perhaps your copy of
inotify.h is really old or something?  what OS are you using?
if you "grep -r IN_EXCL_UNLINK /usr/include" does anything show up?
   --dkg

@_date: 2017-05-10 14:10:27
@_author: Daniel Kahn Gillmor 
@_subject: debugging systemd user services for gpg-agent and dirmngr [was: Re: 
Hi Joey--
thanks for these details!
cool, we actually have fairly similar setups -- i'm also running
systemd, debian testing/unstable, with dbus-user-session, and
libpam-systemd, and i use openbox as well :)
However, i'm not seeing the behavior you're seeing.
One difference i note is that you're using ~/.xsession, and i'm just
relying on the alternatives system to launch openbox:
    0 dkg at alice:~$ readlink -f $(which x-session-manager)
    /usr/bin/openbox-session
    0 dkg at alice:~$ ( For the programs that i want launched per-graphical-session that can't
  be handled as systemd user services, i include them in
  ~/.config/openbox/autostart )
Do you think you could try that approach (with the systemd user services
unmasked) and see whether the agents respond properly?  if so, it'd give
us something specific to debug (we would look into your .xsession to try
to figure out how it differs from the standard startup).
also, when the systemd user services are unmasked, what is shown by:
    journalctl --user-unit gpg-agent dirmngr
        --dkg

@_date: 2017-05-10 13:59:51
@_author: Daniel Kahn Gillmor 
@_subject: undeclared function identified during make - gnupg-2.1.20 
Hi Dustin--
Please see my response on-list to Antonino Augusta
 earlier today -- it sounds like y'all are
seeing the same issue.
       --dkg

@_date: 2017-05-10 22:58:21
@_author: Daniel Kahn Gillmor 
@_subject: debugging systemd user services for gpg-agent and dirmngr [was: 
i wasn't trying to suggest that you should transition ~/.xsession
entirely to systemd user services.  I was aiming to suggest that you
could move most of whatever's in your ~/.xsession to
~/.config/openbox/autostart and see whether that changes anything.  Feel
free to ignore creation of any new systemd user services in the meantime
as you guessed, this was the command i meant to have you run.  thanks!
my guess is that you have no /var/log/journal directory, so everything
stored by the journal will be in the ephemeral /run/log/journal.
users (this is an outstanding request for enhancement for systemd:
That said, you can still examine the stuff in /run/log/journal as root
    journalctl _SYSTEMD_USER_UNIT=gpg-agent.service _UID=1000
(assuming that your non-privileged user ID is 1000).
yes, please!
thanks for checking up on this,
       --dkg

@_date: 2017-05-11 16:28:43
@_author: Daniel Kahn Gillmor 
@_subject: Keyring corruption with GnuPG 2.1.20 
[...]
on debian and derived systems, you can also use the helper tool:
   migrate-pubring-from-classic-gpg
which should be slightly more robust and also simpler to use than the
multistep sequence outlined in the FAQ.
Debian-specific note: 2.1.20 is only in debian's experimental
repository; the above patch should be present in 2.1.20-4, which was
uploaded to the experimental repo yesterday.  If you're running any
previous version of 2.1.20 from experimental, please upgrade!
thanks for the heads-up, Justus!
        --dkg

@_date: 2017-05-16 23:26:38
@_author: Daniel Kahn Gillmor 
@_subject: debugging systemd user services for gpg-agent and dirmngr [was: 
yay, glad to hear it!  I'm still a bit perplexed by what happened there,
but hopefully having this note in the archives will help folks find it
if they have a similar problem with an older version of systemd.
     --dkg

@_date: 2017-05-20 13:27:29
@_author: Daniel Kahn Gillmor 
@_subject: Reviving a userid with revoked key 
This is the case if the *user-id* was revoked, while the key itself was
not revoked.  If the OP revoked the old key itself, then they need to
just make a new key.
The old contacts should also be able to re-certify, no?
     --dkg

@_date: 2017-05-30 16:05:57
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG 2.1.19 output 
please see my earlier message on gnupg-devel, complete with a
Archived (with followup discussion) at:
        --dkg

@_date: 2017-05-30 17:25:46
@_author: Daniel Kahn Gillmor 
@_subject: Obtaining sig2 and sig3 signatures 
I don't recommend that anyone make a sig1, sig2, or sig3 for any
third-party certification (sig3 is fine for self-signatures, where the
keyholder asserts their own identity).  sig0 -- the default, generic certification -- is fine, does what people
need of it, and doesn't intentionally leak any more of the social graph
than it needs to.
In GnuPG, this is accessed via the "--ask-cert-level" flag.  I explain
my reasoning further in a blog post titled "gpg --ask-cert-level
considered harmful":
          --dkg

@_date: 2017-05-30 18:48:04
@_author: Daniel Kahn Gillmor 
@_subject: scdaemon coredumps 
Hi Yuriy--
 [...]
So we're not seeing that crash on the experimental build daemons in
debian.  that makes me think that something is amiss with the
dependencies in jessie, or maybe we've failed to indicate some
dependency correctly.
gniibe (cc'ed) is usually the person to sort out scdaemon issues --
perhaps he can suggest some next-steps for debugging?
fwiw, my messages were recently bouncing from this mailserver too -- i
had to fiddle with some DNS records for my own mail relay to get
kerckhoffs to accept mail.  it's possible that the spamfiltering rules
have been tightened up recently, or the DNS resolver has changed.
I note that 195.159.176.226 has no PTR record at all.  maybe the gmane
folks need to add a reverse DNS record via their hosts at powertech.no?
          --dkg

@_date: 2017-05-30 21:33:48
@_author: Daniel Kahn Gillmor 
@_subject: scdaemon coredumps 
I'm not entirely sure about the build daemons, but when i build it on
amd64, i definitely get no segmentation faults.  I suppose i can try
firing up an i386 builder and see if i can replicate the problem from
unstable directly.  have you tried to build the experimental package
against unstable yourself, or only on jessie?
ugh, right, that seems like something worth noting to Eric Dorland
(cc'ed), who is maintaining both automake and npth for debian, iirc.
   --dkg

@_date: 2017-05-30 21:27:30
@_author: Daniel Kahn Gillmor 
@_subject: scdaemon coredumps 
i'm aware of this common convention (without commenting on how useful it
is at actually defeating spammers), but i'm surprised to see it
happening with two mail servers that both have sent messages to GnuPG
mailing lists in the not-too-distant past.  it's possible that both of
those mailservers have changed at the same time, i guess.  there
certainly was a recent change for my own mail relay.
         --dkg

@_date: 2017-05-31 09:05:00
@_author: Daniel Kahn Gillmor 
@_subject: Obtaining sig2 and sig3 signatures 
also agreed.  I'd love to see someone spec out how to encourage the use
of this more sensible workflow.
   --dkg

@_date: 2017-05-31 15:47:08
@_author: Daniel Kahn Gillmor 
@_subject: Errors at ECC key generation in non-interactive mode 
Hi Ryru--
do you see the same error messages when you use the more modern --quick
command-line syntax?
    fpr=$(gpg --with-colons --quick-gen-key "Test user " ed25519 | awk -F: '/^fpr:/{ print $10 }')
    gpg --quick-add-key $fpr cv25519
what version of gpg are you running when you see those warnings?
     --dkg

@_date: 2017-10-02 11:39:39
@_author: Daniel Kahn Gillmor 
@_subject: 1024 key with large sub key 
It was introduced in 2014 in git commit
534e2876acc05f9f8d9b54c18511fe768d77dfb5 on STABLE-BRANCH-1-4, which was
subsequently ported to master.
see also  and here's the commit log:
commit 534e2876acc05f9f8d9b54c18511fe768d77dfb5
Author: Daniel Kahn Gillmor     gpg: Add build and runtime support for larger RSA keys
    * configure.ac: Added --enable-large-secmem option.
    * g10/options.h: Add opt.flags.large_rsa.
    * g10/gpg.c: Contingent on configure option: adjust secmem size,
    add gpg --enable-large-rsa, bound to opt.flags.large_rsa.
    * g10/keygen.c: Adjust max RSA size based on opt.flags.large_rsa
    * doc/gpg.texi: Document --enable-large-rsa.
    --
    Some older implementations built and used RSA keys up to 16Kib, but
    the larger secret keys now fail when used by more recent GnuPG, due to
    secure memory limitations.
    Building with ./configure --enable-large-secmem will make gpg
    capable of working with those secret keys, as well as permitting the
    use of a new gpg option --enable-large-rsa, which let gpg generate RSA
    keys up to 8Kib when used with --batch --gen-key.
    Debian-bug-id: 739424
    Minor edits by wk.
    GnuPG-bug-id: 1732
        --dkg

@_date: 2017-10-02 13:12:22
@_author: Daniel Kahn Gillmor 
@_subject: 1024 key with large sub key 
I agree that there's no good reason to enable it by default.
But in terms of being willing to make changes to the GnuPG option space
that break backward compatibility for some users in order to improve the
overall state of GnuPG crypto, removing --enable-large-rsa isn't
anywhere *close* to the top of my list.
Note that --enable-large-rsa still only allows creation 8Kibit RSA keys,
not 10Kibit or 16Kibit keys like those reported in the original bugs, so
it doesn't actually cater to the hard-core "keylength-fetishist" crowd.
         --dkg

@_date: 2017-10-02 15:14:48
@_author: Daniel Kahn Gillmor 
@_subject: 1024 key with large sub key 
sure, it's a simple recompile away (or installation of old versions) for
folks who want to enable it during key creation.  why would we encourage
those folks to run unmaintained versions, even if we think that their
long-key-fetishism isn't particularly well-motivated?  keeping the
two-stage thing in place makes it clear that this hard boundary is a
deliberate design decision, and some accomodation has been made, but
that we have explicit defaults for a reason.
Anyway, nothing on any list that actually deliberately "breaks backward
compatibilty for some users" is acceptable in GnuPG's current
development model afaict.
if that's not the case, then we should probably start by specifically
making a shared list of breaking changes and trying to prioritize them.
            --dkg

@_date: 2017-10-05 12:06:25
@_author: Daniel Kahn Gillmor 
@_subject: auto-key-retrieve usefulness/annoyance 
A more user-friendly approach (setting aside current architecture and
privacy concerns) would be to fire off a retrieval in the background and
to return immediately with seomthing like "unknown key, retrieval
Even better would be to have some sort of asynchronous callback that
happens after the key is effectively retreived, so that whatever user
interface displays the response could update when (if) the key comes in.
gpg isn't currently constructed to do this kind of asynchronous user
interaction, however.
             --dkg

@_date: 2017-10-10 02:26:10
@_author: Daniel Kahn Gillmor 
@_subject: FAQ and GNU 
Is there a specific patch to consider?  I wouldn't agree to a blind
s~Linux~GNU/Linux~g replacement, but for specific instances it's likely
to be a quite reasonable request.
Not all instances of "Linux" are generically replaceable by GNU/Linux --
for instance, if we're talking specifically about the kernel, then it
should remain just Linux (e.g. "Android uses the Linux kernel").
However, if the GnuPG FAQ is talking about an operating system built
from the Linux kernel and the GNU userland (coreutils, libc, etc), then
"GNU/Linux" is not only the respectful term to use, it's the more
accurate and precise term.
Note that GnuPG also builds against (and runs on) other operating
systems that use GNU but do *not* use Linux, such as Debian's
GNU/kFreeBSD and GNU/Hurd ports.
      The FAQ should be both accurate and precise.  We don't want users
thinking that GnuPG will run on Android just because Android is a Linux
operating system.
        --dkg

@_date: 2017-10-10 09:48:29
@_author: Daniel Kahn Gillmor 
@_subject: gnupg on read-only filesystem 
Stretch currently ships 2.1.18-8~deb9u1.  please update ;)
it looks like you're trying to decrypt a file.  it also looks like you
don't have any public keys stored on this machine.
so maybe you're trying to decrypt a symmetrically-encrypted
(password-protected) file?
I'm assuming that you have a writeable filesystem somehwere
(e.g. /tmp).  You could try the following:
    export GNUPGHOME=$(mktemp -d)
    gpg -d file.gpg
    rm -rf "$GNUPGHOME"
        --dkg

@_date: 2017-10-10 12:45:17
@_author: Daniel Kahn Gillmor 
@_subject: FAQ and GNU 
Thanks for going through the specific instances of Linux in the FAQ,
Leo.  This is what i was asking for when i was wondering whether a
concrete diff has been proposed.
(where is the FAQ maintained, btw?  how is one expected to submit
I agree with all of Leo's conclusions except for the following:
I suspect that many minimal Linux-based operating systems (particularly
one that uses sbase instead of the GNU userland) will *not* feature a
suitable GnuPG tool.  So the statement above is probably more accurate
if you change it to GNU/Linux.
Do you have a list of sbase+Linux distros that we can look at for
Certainly, the Linux distro known as Android does *not* feature a
suitable GnuPG tool :(
Again, i think this FAQ section is actually talking about GNU/Linux
systems, and it would be more appropriate to say that explicitly, rather
than to pretend that this covers every Linux-based operating system (it
clearly does not).
     --dkg

@_date: 2017-10-10 12:56:56
@_author: Daniel Kahn Gillmor 
@_subject: FAQ and GNU 
Debian actually does ship a "port" that uses the FreeBSD kernel and the
GNU userland, and it calls it GNU/kFreeBSD.
  This naming clarity is useful to distinguish it from the FreeBSD
operating system, which uses the FreeBSD userland with the FreeBSD
There is no single userland required for any kernel (though some
userlands do require a specific kernel).  When we're talking about
GNU/Linux distros, we should name them for what they are.
     --dkg

@_date: 2017-10-10 13:04:06
@_author: Daniel Kahn Gillmor 
@_subject: Working with an Online and Offline Computer when using GnuPG - 
The link you're looking for is:
   their documentation for transfer between machines is here:
      --dkg

@_date: 2017-10-10 14:23:23
@_author: Daniel Kahn Gillmor 
@_subject: FAQ and GNU 
There's no "must" that a GNU system contain GnuPG.
For example, on Debian ("GNU/Linux"), it's possible in the "testing"
version to have no gnupg package installed at all if you want a
particularly minimal system.  One narrowly-scoped tool from the GnuPG
suite (gpgv) is required if you want secure software updates, but you
can even do away with that if your updates are handled some other way
(or if it is a one-shot system that will never be updated).
That said, on most standard Debian systems, GnuPG is indeed installed by
default, and even on systems where it isn't installed by default, it's
a simple "apt install gnupg" away.
So I think this FAQ is more correct if it's re-written to say
"GNU/Linux" here and in the other place i mentioned.
Amazing how much people want to comment on the color of this particular
Can we get back to improving GnuPG itself?
   --dkg

@_date: 2017-10-11 10:42:38
@_author: Daniel Kahn Gillmor 
@_subject: gnupg on read-only filesystem 
Modern GnuPG delegates passphrase caching and secret key management to
the gpg-agent co-process.
The gpg-agent process should disappear as soon as you remove the
ephemeral home directory.
Why do you care whether gpg is one process or two processes?
    --dkg

@_date: 2017-10-11 10:40:42
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG on Android [was: Re: FAQ and GNU] 
I've been asked about this repeatedly myself, and my impression aligns
with what Neal is saying, but i'd be happy to be wrong.
here's the project i was thinking of that was farthest along in terms of
system integration on Android is:
   At any rate, it sounds like the details here might be something that we
want to put in the FAQ :)
Clearly it is *not* the case that most Android-based Linux systems
(which is to say, most Linux-based systems, when measuring by
installation count) come with GnuPG installed by default, alas. :(
    --dkg

@_date: 2017-10-27 00:43:17
@_author: Daniel Kahn Gillmor 
@_subject: gpg 2.2.x devuan jessie no TOFU TLS 
what versions of these packages did you install?  can you provide more
explicit details?
the debian packages build fine on stretch and later, but i'm reluctant
to try to backport them to jessie myself these days.  Such a port would
introduce too many platform-level incompatibilities.
         --dkg

@_date: 2017-09-06 13:59:43
@_author: Daniel Kahn Gillmor 
@_subject: Configuring dirmngr 
What version of gnupg are you running?
after making that configuration file, have you explicitly restarted
dirmngr?  the simplest way is:
    gpgconf --kill dirmngr
then subsequent uses of gpg should automatically spawn a new dirmngr,
which will pick up the new configuration.
     --dkg

@_date: 2017-09-10 10:36:58
@_author: Daniel Kahn Gillmor 
@_subject: [Feature Request] Multiple level subkey 
this is the right place, welcome!
I'm not sure how the proposed multi-level system is an improvement over
an offline primary key.  It's certainly more complicated, but complexity
is a bug, not a feature.  can you explain why you think it's better?
with an offline primary key, you only put subkeys on any device that's
used regularly.
That said, even offline primary keys aren't super easy-to-use at the
moment, more work could be done to streamline that use case.
are you asking about secret key sharing (between devices controlled by
the same person) or public key distribution?
    --dkg

@_date: 2017-09-12 12:01:11
@_author: Daniel Kahn Gillmor 
@_subject: [Feature Request] Multiple level subkey 
I understand that you're trying to make *your* life easier.  But the
choices you make also have an impact on the people who look at your
public keys.  An OpenPGP certificate with a single master
certification-capable public key and several different
signing/encrypting/authenticating subkeys is already pretty complex, but
we have toolchains that are (starting to be) able to deal with that
If you try to introduce this multi-level arrangement, you're pretty
likely to force *other* people (whose toolchains you have even less
control over) into situations that will be LESS EASY and
NON-AUTOMATABLE.  I don't think this is a great tradeoff for the
Keep it simple :)
Please don't default to using a woman as the canonical example
non-technical/clueless user.  The computer security community already
has enough problems with gender bias.  It's unfriendly and unwelcoming
in ways that we need to outgrow.  And it's wrong -- real-world
housewives (and "moms" and "grandmas" to name a few other common sexist
"female clueless user" tropes) are often expected to figure out many
things that are outside of their field of expertise and then aren't
given any intellectual credit for navigating complex and changing
requirements and exepctations.
If you need an example of someone who doesn't really understand things
at a technical level but needs to have stuff Just Work for them anyway,
i've seen Cory Doctorow suggest using "your boss" as the canonical
example :P
All the best,
    --dkg

@_date: 2017-09-18 17:37:13
@_author: Daniel Kahn Gillmor 
@_subject: using --keyserver but still getting gpg: no keyserver known (use 
what version of gpg?  what version of dirmngr?
modern versions of gpg should default to the hkps pool, and shouldn't
need any explicit configuration.
     --dkg

@_date: 2017-09-18 17:45:37
@_author: Daniel Kahn Gillmor 
@_subject: Automating and integrating GPG 
GnuPG upstream developers tend to recommend the use of GPGME for system
integration projects that require a stable interface.
If you're using python, the GnuPG team maintains gpgme bindings for
python, available in debian and debian-derived systems (e.g. ubuntu) as
I don't know how much smartcard interaction gpgme supports, though.
        --dkg

@_date: 2017-09-21 17:05:35
@_author: Daniel Kahn Gillmor 
@_subject: Houston, we have a problem 
The way the universe works is that once data is public, other data might
refer to that public data, and even the person who created the first bit
of data can't prevent it.
An OpenPGP certificate is, at minimum:
 * a public primary key K
 * a User ID U
 * a signature from K that binds U to K
Once this data is published, anyone with a different key X can make a
new certification, which also claims that U is correctly bound to K.
This is what "signing a key" means.
Your choice of software implementation can't prevent those third-party
certifications from being produced, nor from being published, nor can it
prevent other people's software from discovering them and making
inferences based on them.
There are some good (and some bad) arguments that software capable of
interpreting OpenPGP certificates should only accept third-party
certifications that the first-party (the party being certified) has
explicitly endorsed, which might come close to meeting your requirement
here.  But no one has spec'ed out exactly how to do that or written such
a constraint, and existing OpenPGP software will continue to exist even
if new (improved) software is developed and distributed.
If by "key-id" you mean your actual public key, then the cryptography
behind OpenPGP does actually enforce this already.  It's not believed to
be possible to forge an OpenPGP signature from any reasonably strong
modern OpenPGP key.
If by "key-id" you mean the 32-bit long thing like "D21739E9", then
there's no way to cryptographically secure that -- it's just too
low-entropy.  I've written elsewhere about why key ids are bad:
    Hope this helps to clear things up,
     --dkg

@_date: 2017-09-22 16:12:50
@_author: Daniel Kahn Gillmor 
@_subject: automatic conversion from keyring to keybox  files? 
On debian systems, you can run:
     migrate-pubring-from-classic-gpg
And it should handle things sanely.
    --dkg

@_date: 2017-09-28 13:13:10
@_author: Daniel Kahn Gillmor 
@_subject: onwnertrust and trust signature (tsig) interactions [was: Re: 
Yes, ownertrust and trust signatures do interact.
a trust signature (tsig) made by a key that you have set ultimate
ownertrust on delegates some of that ownertrust via trust signatures.
I thought that was also true for full ownertrust, but i'm unable to
replicate it with an experimental keyring.  Perhaps Werner or someone
else closer to the trust management code can comment on the expected
        --dkg

@_date: 2017-09-28 14:27:13
@_author: Daniel Kahn Gillmor 
@_subject: onwnertrust and trust signature (tsig) interactions 
I understand where you're coming from, and i think your interpretation
is a (very) sensible one.  And indeed, the only place that i've actually
used trust signatures (monkeysphere-authentication) uses them directly
from an ultimately-trusted key.
I hope that my own idea about them chaining from non-ultimately-trusted
keys is simply wrong :)
If your interpretation is how GnuPG implements them, then the right way
to introduce/avoid them in a training is:
 * don't bother with trust signatures or worry about them.  As long as
   you don't issue any yourself, and as long as you don't assign
   ultimate ownertrust to any keys that you do not control, they won't
   have any effect on you.
that's already too complicated :(  But i agree that it's way better than
"oh yeah, and if you assign full ownertrust to someone else, then they
can trivially delegate it away at infinite depth " -- yikes!
hopefully we'll get some clarification (and hopefully your
interpretation matches the intended implementation)!
  --dkg

@_date: 2018-04-03 12:21:57
@_author: Daniel Kahn Gillmor 
@_subject: Installation error with libgpg-error-1.28 
Hi Jukka--
what operating system are you using?
I suspect you want to explicitly pass this ./configure invocation a
--with-libgpg-error-prefix argument that matches your libgpg-error
installation prefix.
but really, if you're not an expert i recommend using pre-packaged
versions of all of these tools, if sensible versions are available from
your operating system vendor.
             --dkg

@_date: 2018-04-16 15:49:21
@_author: Daniel Kahn Gillmor 
@_subject: pinentry problems 
this doesn't look right to me.
in particular, it's going to remove the "execute/traverse" permission on
~/.gnupg/private-keys-v1.d/, which means that gpg-agent isn't going to
be able to get a list of all available secret keys.
Probably, you want to do the following (as your normal user account):
    find ~/.gnupg -type d -exec chown 0700 '{}' ';'
    find ~/.gnupg -type f -exec chown 0600 '{}' ';'
if you do that, then you should be able to see some files whose names
end in ".key" in ~/.gnupg/private-keys-v1.d/, like so:
    ls -l ~/.gnupg/private-keys-v1.d/*.key
if that's the case, then i recommend you ask your running gpg-agent to
shut down because it's probably confused:
   gpgconf --kill gpg-agent
a new gpg-agent should start up again afterward as soon as you need it.
you can also try to see which secret keys are available like this:
   gpg --with-keygrip --list-secret-keys
You should see that the keygrips listed match the files found in the
"ls" output above.
If that doesn't work for you, please report back and we'll try to debug
further :)
        --dkg

@_date: 2018-04-17 08:48:57
@_author: Daniel Kahn Gillmor 
@_subject: pinentry problems 
yep, sorry, that should have been "chmod", not "chown" -- my mistake!
     --dkg

@_date: 2018-04-18 12:28:13
@_author: Daniel Kahn Gillmor 
@_subject: dirmngr timeout 
i think you mean:
    systemctl --user import-environment http_proxy
Please read the "Environment Commands" section of systemctl(1) for more
Another alternative is to add an Environment= directive to
dirmngr.service -- you can do this with:
    systemctl --user edit dirmngr.service
or simply by putting the following two lines in
~/.config/systemd/user/dirmngr.service.d/proxy.conf :
    [Service]
    Environment=http_proxy=
        --dkg

@_date: 2018-04-18 13:02:19
@_author: Daniel Kahn Gillmor 
@_subject: dirmngr timeout 
Hi Laszlo--
I'm afraid we don't know the details of how your docker instance is set
up; which versions of which packages you have installed inside docker
vs. outside of docker, what's bind-mounted, what the networking
constraints are in place.  this makes debugging remotely a bit more
if a standard user runtime dir is mounted on /run/user/$UID , the
dirmngr socket could be mounted there.  It sounds like that is probably
not mounted, so gpg is falling back to the socket location in the home
but if no dirmngr is running listening on the expected socket, then gpg
normally tries to launch it itself.
for example, i'd expect to see the following:
    gpg-connect-agent: no running Dirmngr - starting '/usr/bin/dirmngr'
    gpg-connect-agent: waiting for the dirmngr to come up ... (5s)
    gpg-connect-agent: waiting for the dirmngr to come up ... (4s)
    gpg-connect-agent: connection to dirmngr established
But i don't see that in your logs.  What version of GnuPG is installed?
how did dirmnger get installed on this docker system?  how did gpg
itself get installed?
what is the output of:
     gpgconf --list-dirs
(within the docker instance, that is)
        --dkg

@_date: 2018-04-18 13:09:50
@_author: Daniel Kahn Gillmor 
@_subject: pinentry problems 
I'm glad it's working now.
can you explain the pinentry problem you're seeing?  I'm afraid the bad
ownership of your files was distracting from any other problems you were
One simple way to test pinentry (without gpg or gpg-agent in the mix)
     echo getpin | pinentry
that should show you a dialog box that prompts you for a password.  you
can put in whatever you like, and it should be emitted on the console
where you ran the above command.
      --dkg

@_date: 2018-08-28 14:22:29
@_author: Daniel Kahn Gillmor 
@_subject: Issue with pinentry GUI agent 
can you give a little bit more information about your system (OS,
version, version of gpg, version of pinentry, etc), and how you're
accessing it (e.g. via ssh, via a graphical environment, etc)?
have you terminated your gpg-agent program ("gpgconf --kill gpg-agent")
after updating your settings in ~/.gnupg/gpg-agent.conf  so that the
settings would take effect?
         --dkg

@_date: 2018-08-30 10:26:12
@_author: Daniel Kahn Gillmor 
@_subject: [Announce] GnuPG 2.2.10 released 
thanks for this work!
I note that  does not list 2.2.10
yet, though the file is already there.
Can you make refreshing that index a part of the standard release
process?  it would help automated tools that scan that directory looking
for new releases to pick up the new release.
    --dkg

@_date: 2018-12-13 18:28:38
@_author: Daniel Kahn Gillmor 
@_subject: Importing keys into GnuPG 2.2 series 
I'm confused by this e-mail, hopefully the notes and questions below can
start to un-confuse it a bit.
This appears to be a question about OpenKeychain verifying signatures,
which has nothing to do with passphrases.  it might be better asked in
an OpenKeychain forum, as i don't know what user interface OpenKeychain
expects for dealing with detached signatures.
GnuPG 1.4.23 and 2.2.11 do not really interoperate well, when sharing
the same homedir. I recommend that you choose one and stick with it.
2.2.11 is the better choice.
you haven't described what action you're doing that makes you think that
you need a passphrase in the first place, or how you are connected to
your computer in such a way that "tty over ssh" is a meaningful
question.  please show more of what you're doing!
this sounds like a very complicated route to take, and it results in you
having multiple outstanding keys, which is likely to confuse some of the
people you communicate with.  i'd try to keep it simpler if possible.
       --dkg

@_date: 2018-02-03 21:23:12
@_author: Daniel Kahn Gillmor 
@_subject: Can't import public key 
gnupg 1.2.1 is positively ancient (over 15 years old) with many many
known problems.  please upgrade to a newer version of GnuPG.
        --dkg

@_date: 2018-02-14 17:30:41
@_author: Daniel Kahn Gillmor 
@_subject: How can we utilize latest GPG from RPM repository? 
This sounds like a problem for your operating system and/or package
manager.  GnuPG has a chain of build dependencies which often makes it
difficult to just import directly from a single RPM.
If you were running a more recent operating system, you'd likely get
something from the GnuPG "modern" branch as well anyway.
Perhaps you want to ask your operating system vendor what their
recommendation is for "backports" of specific packages?
          --dkg

@_date: 2018-02-17 23:15:57
@_author: Daniel Kahn Gillmor 
@_subject: Configuration for offline usage - best practice tips? 
GnuPG's defaults should be fine for the common, simple backup case.
However, i note that you're talking about "today's public key" -- that
suggests that you're imagining a regularly-updated key that your backup
tooling will know about.  This is in some sense antithetical to "offline
usage" -- how will the backup scripts learn about the new keys if they
can't go online to fetch them?
It sounds like you're proposing an OpenPGP primary key that has a series
of relatively short-lived, expiring encryption-capable subkeys.  Is that
For further clarity, it'd be useful to understand what you see as the
goal of key rotation here.  Do you plan on deleting older secret
subkeys?  if so, how will you recover backups that were encrypted to the
destroyed secrets?
In an e-mail or messaging context, you can decrypt messages as they
arrive, caching either the cleartext or the session keys; this allows
you to rotate the asymmetric keys, destroying the old asymmetric secrets
as they expire, which provides something approximating "forward
secrecy".  (see the recent improvements in version 0.26 of the notmuch
mail user agent as an example of first steps on the way to implementing
this strategy).
But for backups, this is a slightly more complicated story.  It
certainly can be useful if you want to be able to robustly *destroy*
backups that might be stored on servers that you don't have full control
over.  That is: encrypt the backup to public key X, send the encrypted
copy to "the cloud", and then when you're sure you don't need it any
more, delete the secret key corresponding to X to ensure that it's not
recoverable.  But most people have a hard time just getting their
backups to happen on a reasonable schedule, and don't have a reliable
schedule for backup destruction.  Do you have such a plan?  Or do you
envision some other reason for the proposed key rotation?
         --dkg

@_date: 2018-02-19 10:45:52
@_author: Daniel Kahn Gillmor 
@_subject: Why Operating Systems don't always upgrade GnuPG [was: Re: How can we 
Here's one last try to explain the situation.
GnuPG (and the libraries it depends on) are used by (aka "depended on
by") other libraries and tools, both those integrated into the operating
system itself, and those that might be externally installed.  Some of
these dependencies are "brittle".
Brittle software dependencies
The problems described above point to problems in the ecosystem *around*
GnuPG, but it also points to concerns about GnuPG's presentation of its
capabilities *to* the rest of the ecosystem.  To the extent that GnuPG
offers features that other tools might want to use, when those features
are not part of an explicit, documented API, the ecosystem apparently
*does* try to manipulate them anyway, with all the attendant brittleness
that you can imagine.
How can GnuPG contribute to fixing this problem?  The traditional way
that many other projects have taken is to define their core programmatic
functionality into a library with a strict interface guarantees, and
have explicitly deprecated other use.  The closest that GnuPG comes to
this technique is GPGME, which is not feature-complete (as compared to
the gpg executable), and has its own history of both difficult upgrades
and unclear/surprising semantics.  It also doesn't have bindings in many
popular programming languages.  When programmers in those language want
to use GnuPG, their shortest path to "something that works" often
involves shelling out to gpg, rather than binding to GPGME. :/ Another thing that would help would be to explicitly and succinctly
document the preferred ways of interacting with GnuPG in ways that other
developers find useful.  Perhaps GnuPG could also itself try to detect
when it is being used programmatically in an unstable way and produce
Yet another complementary approach might be to aggressively police the
ecosystem by finding other software that deends on GnuPG in any of the
aforementioned brittle ways, and either ask those developers to stop
using GnuPG entirely, or to provide them with stable, well-supported
ways to do what they're looking to do.
I welcome discussion/suggestions on how we can improve this situation,
and i *definitely* welcome help in doing the kind of
ecosystem-perspective work necessary to make it easier to maintain an
up-to-date branch of GnuPG.
But shrugging and suggesting it's uncontroversial to upgrade arbitrary
machines to the latest version of GnuPG doesn't appreciate the scope of
the problem involved with software maintenance in an active and
interdependent ecosystem.
        --dkg
[0] examples of breakage:

@_date: 2018-02-20 19:53:57
@_author: Daniel Kahn Gillmor 
@_subject: Why Operating Systems don't always upgrade GnuPG [was: Re: How 
I think this misses the point that it's not just *what does gnupg depend
on* but it's also *what depends on gnupg*.  The dependencies work in
both directions.
The basic idea behind "snap" and "flatpak" and other similar tools is
what many people call "bundling" or "vendoring" -- you ship the program
together with all its dependencies, regardless of what dependencies are
on the host system.  it's not a new idea at all, and is quite common on
many platforms, including in some flavors of cowboy web development.
As with docker containsers, this approach doesn't address the other
direction of the dependency graph.  In addition, all of these approaches
have maintenance costs and open questions about responsibility.  if
every app ships with its own bundled copy of libfoo, and a flaw is found
in libfoo, then it needs to be fixed.  can you be sure you've found and
fixed all copies?  Who is responsible for fixing each specific copy?  Do
those maintainers have enough time/attention/living expenses to make
sure vulerabilities and software flaws get patched in all of their
dependencies?  are they willing to re-ship the entire bundle/snap/docker
image for each dependency that needs an upgrade?
I recently heard bundling/vendoring/snaps/docker containers
characterized in the following way, which resonated with me:
    Hm, maintaining a complex operating system is hard.  I know, we can
    fix that by trying to maintain 100 complex operating systems
    instead!
To be clear, i believe that there are contexts where bundling is
actually the right approach.  But it is not an obvious win to me in most
        --dkg

@_date: 2018-02-20 21:35:12
@_author: Daniel Kahn Gillmor 
@_subject: Why Operating Systems don't always upgrade GnuPG 
We're not in disagreement, actually :) I explicitly said that what was
has been lacking was a "*fully-featured* stable API".  I didn't say that
the API was not stable.  But the UI has features that the API does not,
and this results in people using the UI as though it was an API, or
mucking about with the innards of the local storage.  As one example, I
know this because i've been through that when working on early versions
of monkeysphere; i was using bash around GnuPG and yeah, in a few cases
i ended up stuffing a pipeline of "commands" into a gpg invocation
because it was there and seemed to do roughly what i wanted. The GnuPG stable API is much more fully-featured today (thank you for
the --quick-* commands!), but that has not been the case historically.
And we're paying the cost for that with legacy applications that have
ossified around wrong assumptions about how to interact with GnuPG :/
Sorry, but building a state machine in external code to model the
internal state of a tool is not a functional API that we can
realistically expect developers to use.  If a module has state, it needs
to express that state to the user and make the transitions clear and
functional, with comprehensible and easily-handlable error cases.  To
Even the folks like me, who read manuals and examples and descriptions
of proper use will eventually just go ahead and do what seems to work :/
The goal of using someone else's code is to *relieve* yourself of
needing to know exactly how that code works.  I know that there are some
people that end up sending patches upstream for every project they
touch.  But most developers don't have time or energy for that, and they
need simple, clear interfaces.
This is why (for example) i've argued in the past for making the return
code for gpgv simple and closely aligned with the boolean tests what
people are likely to want (  Not
everyone wants to write a parser for a text stream to find out if a
signature is valid.  Some folks just want to know whether a signature is
valid, and are happy to punt on the details.
And even if everyone *did* want to write a parser, how many different
parser implementations do you think would need to be created?  how many
of them would be bug-free?  checking a return code is much harder to get
very true.  it's quite difficult to write robust programs, even when
interfaces are simple and clear and don't have sneaky side-effects or
behavioral changes due to rarely-changed environment variables.  And
even if you test with LC_ALL=C, did you test with LC_ALL=C.UTF-8 ? :P
yes, these are great things!  thank you for them!
I know.  I can't count how many times i've said it either.  It's pretty
frustrating!  I think it's aggravated further by the fact that we don't
have a clear rule like "do not touch anything inside ~/.gnupg" -- those
kinds of rules end up riddled with caveats like "well, except for
sshcontrol and gpg.conf" or "oh, you want to do custom subkey
management? let me tell you how to poke around in private-keys-v1.d/" :/
did you look at the bug reports i already cited?  Those are definitely
examples of overly-brittle wrappers around GnuPG.  You might also be
interested in Request-Tracker's brittle bindings
( or pretty much anything in debian that
explicitly Depends: gnupg1 today.
I'd be game to cc you every time i hold a project's hand through some
tricky problem if you'd like.  I've even succeeded at convincing some
developers to post their problems to this mailing list, or to open
reports on  though i've also sometimes seen people
discouraged by responses that come across as "the thing that bothers you
is intended to bother you, deal with it".  Those folks generally don't
come back to ask more questions, and just figure if they can make it
"seem to work" that's good enough. :(
Anyway, here's one concrete example (hinted at above) of a programmatic
gap that is much easier to achieve by mucking around with the internal
state rather than by the programmatic interface:
 * I want to introduce a new signing-capable subkey, and i want to
   distribute it widely, but i don't want to start signing with it just
   yet.  Maybe the subkey needs some time to "burn in", or it needs to
   be reviewed before importing into the debian keyring, or maybe it's a
   new algorithm that i don't think all of my correspondents can verify
   yet.  I'm willing to start using it at some specified future date D,
   but i need it to exist and be distributed *today* so that i can be
   confident that everyone will have a copy of it by the day D rolls
   around.
Here are the options i see:
 * the programmatic approach:
    a) export the secret key to a temporary staging ground
    b) generate the subkey
    c) export the new, augmented secret key to a "future backup" file
    d) delete the secret key entirely (leaving the public part)
    e) re-import the temporarily staged secret key
    f) at date D, re-import the "future backup" file
 (note that there's a point in this workflow (between d and e) where i
  actually don't have access to *any* of my secret keys!  what side
  effects will happen there if my key is also in use by other
  tools/processes in the background?  if the transition fail at that
  point (for whatever reason), what happens to me then?)
 (note also that i haven't even tried to write down how i would attempt
  to do this programmatically)
 (note also that if i'm doing this with multiple keys concurrently
  (e.g. today i add a new signing-capable subkey; tomorrow i add an
  authentication-capable subkey), then maybe i've introduced a
  collision.  have i?  and before the "modern" branch of GnuPG, it
  wasn't even possible to merge secret keys, so to be compatible there,
  i'd need to add a step between e and f where i delete the entire
  secret key again.  now we definitely have opportunities for
  collisions!)
 * the "bad" approach (mucking about with the local data store):
   1) generate the subkey, learning its $keygrip
   2) mv ~/.gnupg/private-keys-v1.d/$keygrip.key{,.restore-at-D}
   3) at date D, mv ~/.gnupg/private-keys-v1.d/$keygrip.key{.restore-at-D,}
Guess which approach i'm going to be tempted to take if i write a tool
that attempts to automates sensible secret key management with GnuPG?
And i'm someone who knows better!
Alternately, i might try to use the "disable" subcommand within
--edit-key, but gpg(1) says this controls the "entire key", and it
appears to refer specifically to "encryption", but i'm interested in
sigining.  so that probably isn't right.
What i'd really like is a way to programmatically, privately mark a
secret key as "do not use before date D".  As far as i know, this
interface doesn't exist.  And I'm not asking for it yet because i know
that developer time is limited, and there are so many other outstanding
API improvements (e.g. the gpgv return code example mentioned above)
that i don't want to distract from :/
Right.  they're using the UI as though it was an API, because we have
failed to effectively communicate what the API is actually capable of,
presented in a way that was appealing for developers to adopt :(
yep :/  We're getting there, though! :)
It's definitely possible to write bad library interfaces, or a library
interface that makes it easy for the developer to make mistakes.  Good
library API design is an art, and not a settled one at that.
I like many of the suggestions made by the libabc developers:
   I disagree with some of them too :) But they do present a predictable,
orderly approach that lessens the cognitive load on the developer, and
lets the developer "encapsulate" the behavior of the library in their
One example of a terrible library interface is the classic OpenSSL
interface.  We have many concrete examples in the free software
ecosystem of people who finally "just got it working" in OpenSSL and
then have refused to ever touch that part of the code again, despite the
fact that they actually didn't manage to communicate their actual
programmatic intent to the library properly.
To their credit, the OpenSSL team has made significant improvements in
the interface that they encourage developers to use over the last few
years, and are now in a position to actively deprecate many of their
older mistakes.  It's still going to take us years to rip out the old
cruft from the ecosystem and replace it with "good" use of OpenSSL, or
other TLS implementations, though.  These things have a long shelf life.
The point is, usable programmatic interface design that encourages
stable/sane use (and actually guides developers into doing the right
thing) is a non-trivial task.  It is also potentially exacerbated when
the programmatic use is quite close to other common ways of interacting
with a tool (e.g. a UI).  In that case, developers have a tempting
"quick fix" of just pretending the UI is an API.  Do we really expect
them not to reach for that cookie, when it's just sitting there on the
shelf next to their head?
Some of us have been doing this kind of work for a few years now, even
before the 2.2 release.  If you'd like to collaborate or strategize
about how we can do that better, i'd be happy to continue to work on it
with you.
        --dkg

@_date: 2018-02-20 22:04:18
@_author: Daniel Kahn Gillmor 
@_subject: Solaris 11 install libgpg-error make install hangs 
You can see logs of an example build on the Debian OS for gpg-error
   Your build is likely to differ in the details (compiler flags, etc), but
perhaps you could identify similar stages and give feedback about where
the build process seems to be hanging?
or, you could post your build log to a pastebin like
 and point the list to it, so we could compare
it and try to see where it might be hanging.
Please persist!  we'll get it working eventually. :)
   --dkg

@_date: 2018-01-02 14:26:12
@_author: Daniel Kahn Gillmor 
@_subject: Ascii-armor in paper - question 
Hi Egon--
sorry for the delay in responding to you here.
OpenPGP ASCII-armor does not provide any additional redundancy -- the
"CRC" check at the end of ASCII armor will help you determine if there
was an accidental transcription mistake, but it is *not* capable of
helping you recover from such an error.
ASCII-armor is at its core just base64 encoding.  If you have a binary
document that you want to print to be able to reconstruct byte-for-byte,
you could just as well use the "base64" program to convert it to a
printable sequence.
You don't mention whether your document is OpenPGP-encrypted or
OpenPGP-signed.  I'm assuming in this discussion that the only thing
OpenPGP-related for this document is the ASCII-armoring, since that's
what you mention above, but if there are other OpenPGP characteristics
you care about, you should probably mention them.
converting a large document to a smaller document is best done with
compression (e.g. gzip or xz).  You can do this compression before
converting to OpenPGP format, or you can do it as part of the OpenPGP
conversion.  I recommend doing the compression independently of OpenPGP
paperkey is specifically designed for OpenPGP keys, correct. It will not
help you produce a more minimal form of the ascii-armored document that
is not an OpenPGP key.
I think what you're looking for is twofold:
 * error correction
 * easy re-digitization
You might find that QR codes attempt to tackle both of these problems.
Take a look at
   for a discussion of that approach, with some pointers.
hope this helps,
    --dkg

@_date: 2018-01-03 14:21:07
@_author: Daniel Kahn Gillmor 
@_subject: Modernizing Web-of-trust for Organizations 
Hi Lou--
backing up a bit here -- what kind of "trustworthiness" are you talking
about in your proposal?  your description includes several uses of the
word "trust", but no clear explanation of what that trust entails.
saying that keys are "trusted" doesn't mean much on its own.  What is a
"trusted" key allowed to do that an "untrusted" key is not allowed to
        --dkg

@_date: 2018-01-05 11:45:25
@_author: Daniel Kahn Gillmor 
@_subject: Upgrading from gpg1 to gpg2: lots of trouble, need help 
this is the part that i'm unable to reproduce.
Are both of these processes running as the same user account?
does something at some point destroy or mask the standard socket created
by the first process, so that a new gpg invocation decides to start up a
new instance of gpg-agent?
if your old session was being terminated, then you'd expect the first
agent to actually disappear.  that's not happening.
and neither of these agents is beign launched by systemd, because if it
were it would have a --supervised .
are you su'ing with a login shell (i.e. with - or -l or --login), or
why is there no /run/user for this user?  if you're running a modern
version of systemd, and your user has actually started a session, there
should be a /run/user created automatically.
       --dkg

@_date: 2018-01-08 11:38:33
@_author: Daniel Kahn Gillmor 
@_subject: Tool: Sherpa: (Re: Import keys from .gnupg folder) 
note that there are two things that could/should be migrated when moving
to 2.1.x or later (the "modern" development branch of GnuPG):
 * secret keys (from secring.gpg to private-keys-v1.d/*.key --should
   happen automatically)
 * public keys (from pubring.gpg to pubring.kbx)
public key migration currently does not happen automatically because the
"modern" branch can use both pubring.gpg and pubring.kbx, and there is
an (i believe misguided) desire to facilitate co-installation of the
"classic" branch with the "modern" branch.
debian's GnuPG packaging supplies
migration in a safe way and leave the user without any legacy
          --dkg

@_date: 2018-01-09 12:14:38
@_author: Daniel Kahn Gillmor 
@_subject: Tool: Sherpa: (Re: Import keys from .gnupg folder) 
it's a shell script -- the tool is the source :)
at the moment, you can find it at
though that's likely to migrate to salsa.debian.org soon, as alioth (the
machine that hosts anonscm.debian.org) is going away this year.
        --dkg

@_date: 2018-01-11 08:26:04
@_author: Daniel Kahn Gillmor 
@_subject: Upgrading from gpg1 to gpg2: lots of trouble, need help 
this is deliberately launching a second agent, outside of the basic
supervision that should already be in place.
If you want to use the standard system agent, please do not launch a
separate agent.
This should be as simple as:
  screen -- sudo -u thing --login
or, if you're doing this as root already, then you don't need sudo at
all, and it could just be:
  screen -- su - testuser
If this is run from cron, it will spawn a new session, and that session
will have a systemd session manager capable of spawning gpg-agent as
unfortunately, it will not spawn a new session if run from an existing
session, see the discussion at
 .
if you want to manually start a new session for a new user from within
an existing session on a machine managed by systemd, apparently
machinectl may be the way to go, but i haven't explored that in full.
hope this helps,
        --dkg

@_date: 2018-01-11 08:48:19
@_author: Daniel Kahn Gillmor 
@_subject: Extract signature key ID with gpgme 
I don't see a way to do this with gpgme besides first trying to verify
the signature, parsing the results, and using the info from those parsed
But i can see why you'd want to do this, particularly if the thing
signed is large and potentially expensive to verify.  anyway, i've
opened an issue to track this feature request:
           --dkg

@_date: 2018-01-16 09:54:07
@_author: Daniel Kahn Gillmor 
@_subject: a step in the right direction 
while i agree with rjh that destruction of the current SKS-based
keyserver network (either by technical or legal means) would today be a
net loss, this statement goes too far.
the debian package manager does not directly use the keyserver network,
and debian archive signing keys are themselves distributed as debian
the keyservers can occasionally be used as a way to find updated keys
for a system that has been offline for years, to "re-bootstrap" the
package manager, but dpkg and apt are certainly not reliant on the
keyserver network to do their thing.
Third-party repositories also do not need the keyservers to function
properly, if they're configured in a sensible way:
            --dkg

@_date: 2018-01-16 13:40:36
@_author: Daniel Kahn Gillmor 
@_subject: key distribution/verification/update mechanisms other than keyservers 
While i think we disagree on "has outlived its usefulnesses", i would
agree that planning and preparing for catastrophic keyserver network
failure is a good idea.  What i haven't seen in this thread is a list of
the variety of proposals for OpenPGP key distribution that do *not*
require the global append-only keyserver network.
So in the hopes of making this a productive discussion, i'll list a
few.  Already briefly mentioned are:
 * Web Key Directory (WKD)
     Mail provider publishes public keys of users via https to a
     well-known location.
      * Keybase
     social media and other avenues for key publication, identification,
     and corroboration.
     A few other approaches are:
 * DNS OPENPGPKEY records
     DNS lookups of public keys (or hashes of public keys for
     confirmation)
      * Autocrypt
     In-band key exchange (in every e-mail message) removes the need for
     external distribution mechanisms for all messages but the first.
      * VVV
     DNS (SRV) discovery of HKP service operated by the mail provider.
     I'm sure i've missed some other distribution/verification/update
mechanism, and would be happy to see constructive pointers.
Of the above, i'm most leaning toward Autocrypt today, because it does
not require involvement of any third party -- as long as both sides of
the e-mail use an autocrypt-capable client, there is no additional
information leakage.
Note that the different schemes have different properties in terms of:
 * information leakage
 * cryptographic verification
 * third-party control
 * censorship
 * ...
The keyserver network (or some future variant of it) can of course play
a role in parallel to any or all of these.  for example, keyservers are
particularly well-situated to offer key revocation, updates to expiry,
and subkey rotation, none of which would necessarily involve names or
e-mail addresses.
It would be interesting to see a network of keyserver operators that:
 (a) did cryptographic verification, and rejected packets that could not
     be verified (also: required cryptographic verifications of
     cross-signatures for signing-capable subkeys)
 (b) rejected all User IDs and User Attributes and certifications over
     those components
 (c) rejected all third-party certifications -- so data attached to a
     given primary key is only accepted when certified by that primary
     key.
This would basically be a network that facilitates
update/revocation/key-rotation, without exposing any names or e-mail
addresses to the public by default; it could be run in parallel with the
existing keyserver network.  i don't know how well we could bridge the
two networks, though and it'd be a shame to have to upload updated
keys to both networks manually. :/
anyway, hopefully this gives some concrete, positive next steps that
folks who want the keyserver network to go away can take, rather than
trying to burn it all down :)
   --dkg

@_date: 2018-01-16 19:20:49
@_author: Daniel Kahn Gillmor 
@_subject: key distribution/verification/update mechanisms other than 
the advantage is spam-abatement -- the keyservers have to keep track of
what is attached to each blob they transport/persist.  if all signatures
that they transport for a given blob are cryptographically certified,
then only the original uploader of that blob can make assertions about
it; other people can't spam the blob to make it untransportable.
    --dkg

@_date: 2018-01-16 23:31:53
@_author: Daniel Kahn Gillmor 
@_subject: Will gpg 1.x remain supported for the foreseeable future? 
hi there!  what kind of manipulation are you doing of secure apt
repositories with gpg?
are you talking about signing the repo as an author? or about
configuring for a client? or distributing public keys for the repo?  or
about verifying signatures as a client?
each use case is slightly different, but there should be reasonable,
non-head-explode-y tooling available for all of them.
        --dkg

@_date: 2018-01-16 23:36:56
@_author: Daniel Kahn Gillmor 
@_subject: Will gpg 1.x remain supported for the foreseeable future? 
apt always uses the "transferable public key" form for its OpenPGP
dependencies, which is specified in RFC 4880.  a simple linear
concatenation of these transferable public keys is a "keyring", which
apt knows how to ingest.
The "keybox" format is not used by any tool outside of the GnuPG suite,
and it doesn't have nearly as much documentation or history as the
transferable public key format.
i tend to treat *.kbx the same way i treat private-keys-v1.d -- as part
of GnuPG internals, not as part of its public interface.
If you want to generate a clean "keyring" it should be straightforward
to do so with any version of GnuPG just by using --export.  You can
import a keyring into any version of GnuPG with --import.
if you're in the habit of using GnuPG in order to create some file
within its internal "home directory" and then extract that for some
other use (like sending handing some internal file from there to apt) --
please don't do that.  The internals of the GnuPG homedir have never
explicitly been part of the publicly-exposed API.
     --dkg

@_date: 2018-01-17 10:32:05
@_author: Daniel Kahn Gillmor 
@_subject: key distribution/verification/update mechanisms other than 
please see also the thread on sks-devel from december 2016 with the
subject "nokeyserver annotation" -- if we're designing a new, parallel,
more narrowly-focused keyserver network we should make sure to include
that as well.
I think you're describing a way to permit such a narrowly-scoped
keyserver to be slightly more broad -- to allow third-party
certifications to be published.
i don't think you need an extension to OpenPGP at all to do this -- you
just need policy.  The policy could be (for example):
 * if a third-party certification is present, discard it unless all of
   the following are true:
   a) it has the "issuer fingerprint" subpacket in the hashed subpackets
   b) the issuing key is itself is known to the keyserver
   c) the certification is cryptographically correct
   d) there is an Embedded Signature subpacket in the unhashed
      subpackets from the primary key, over the existing signature
      *with unhashed subpackets discarded*
   e) the embedded signature is cryptographically valid
but the simplest thing would be to start without third-party
certifications at all -- making this strictly for self-certification
updates (expiry, revocation, key-rotation).
        --dkg

@_date: 2018-01-17 18:25:32
@_author: Daniel Kahn Gillmor 
@_subject: key distribution/verification/update mechanisms other than 
read in the context of the discussion in the thread (i know -- it's 90
messages long, hard to keep up!), we're talking about a parallel
keyserver network here, so the policy would be applied at upload time
(which also means it happens at "replication" time).
I think a better way to consider retrofitting to existing keyservers
would be if existing keyservers could maintain the idea of two
filtersets concurrently.  then, if they're gossiping with a peer who
insists on filterset A (the existing dominant filterset), they work only
with the certificate material that belongs to that particular filterset.
if they're gossiping with a peer who can do the new constrained
filterset (we'll call it B), then they work only with the certificate
material that belongs to that filterset.  but internally they know about
the union of all of that certificate material.
If we had a few keyservers capable of that kind of operation with both A
and B, then we could keep the B-only keyservers in sync during a
sadly, i don't have such an implementation and i don't know how to do
that work in the time i have available.
     --dkg

@_date: 2018-01-17 20:20:30
@_author: Daniel Kahn Gillmor 
@_subject: Will gpg 1.x remain supported for the foreseeable future? 
cool, your user story all makes sense to me except this bit:
(itym 'man apt-secure', right?)
if you're expecting ubuntu (or any other non-debian) users to install
this, then you're actually increasing their attack surface, because this
package will place debian archive keys as "trusted" keys automatically
(meaning "any archive that is signed by them is considered legitimate),
when they weren't present on the system before.
I don't see the part of apt-secure(8) that says anything about needing
this, and i don't see how it "leverages the web of trust" -- can you
explain this more?  Without a clear justification, i think you should
remove this dependency.
what i'm not hearing is an explicit example of how you are using gpg --
as the archive maintainer, surely you manage the archive itself on a
system of your choice.  for me, that would be a debian stable system,
with reprepro or something like that, which should already know how to
call out to gpg.
as the developer of the foobar-archive package, you shouldn't need to
invoke gpg at all in your package build scripts other than just --import
and --export, which should be pretty standard across all versions of
your end users don't actually need full-blown gpg at all -- modern
versions of apt depend explicitly (and minimally) on gpgv, since all
they do is verify signatures based on a set of acceptable keys.
yep, agreed.  (which is why i'm surprised to see your dependency on
debian-archive-keyring) You may also be interested in
 fwiw.
All the best,
    --dkg

@_date: 2018-01-18 22:52:28
@_author: Daniel Kahn Gillmor 
@_subject: Will gpg 1.x remain supported for the foreseeable future? 
i don't know -- what are you importing?  if the thing you're importing
is already a clean Transferable Public Key, then you are right: you can
deploy it with /bin/cp or /bin/cat or /usr/bin/install :)
trust packets aren't part of a Transferable Public Key -- if you're
seeing trust packets, then the thing you're working with was never a
Transferable Public Key in the first place :/
hm, that pesky "trust" word again ;) -- let's be clear what we mean
about it.
The actions you describe above mean that the user is willing to rely on
this key to certify the archive listing from your APT repository.
this is a narrowly-scoped "trust", because it also means that the user
will *not* accept signatures from the key in question on any *other*
This is good -- in the security sense of "trusted", we want to *reduce*
trust, not expand it, right?  things that you trust can violate that
trust and you're helpless.
if this is the only thing happening, apt will indeed fail, because it
has never heard of the "new key" that was just created -- why should it
accept signatures from that new key?
how are you configuring the target system to point to the repo?  how are
you telling it where to find the key?
I'd expect somewhere in there to be a "gpg --export" of the
newly-created key, into a simple file that can be picked up later.
this looks strange to me -- you seem to be using a --keyring that is
*inside* the GNUPGHOME that you've set
that GnuPG homedir is really not part of the GnuPG API contract -- and
anything you put in that homedir could potentially be overwritten by
GnuPG itself.   How is
This seems like the sticking point to me.
there's no need to mark any keys as "trusted" with GnuPG for apt's sake.
Apt represents its "trust" (willingness to rely on a key to generate
acceptable signatures over an archive) in one of two ways:
 a) placement in /etc/apt/trusted.gpg or /etc/apt/trusted.gpg.d/*.gpg
 b) placement elsewhere in the filesystem, pointed to by a signed-by
    option in a line in /etc/apt/sources.list or
    /etc/apt/sources.list.d/*.list; or pointed to by a Signed-By: header
    in a stanza in /etc/apt/sources.list.d/*.source (see sources.list(5)
    for more details about the way that signed-by can be presented).
the keys placed in the filesystem at the locations described in (a) are
acceptable for making signatures over *every* apt repository configured
on the system, except those with an explicit signed-by directive, which
are more constrained.
The keys referred to via signed-by are the only acceptable keys for the
associated apt repo.
does that make sense?
     --dkg

@_date: 2018-01-22 11:34:10
@_author: Daniel Kahn Gillmor 
@_subject: Why exactly does pinentry fails with gpg-agent and ssh support? 
the systemd user service takes care of automatically launching the
gpg-agent when the user connects to it via the ssh-agent protocol, so
this isn't required when using systemd.
     --dkg

@_date: 2018-01-22 12:53:45
@_author: Daniel Kahn Gillmor 
@_subject: Why exactly does pinentry fails with gpg-agent and ssh support? 
It may also depend on how the session itself is started.  Maybe one of
you is starting the user session in non-graphical mode (either a vt
login, or maybe ssh?), while the other one is starting it directly from
a graphical display manager?
do you have dbus-user-session installed?  (it is recommended)
   --dkg

@_date: 2018-01-24 13:05:16
@_author: Daniel Kahn Gillmor 
@_subject: Keys clean of all signatures except those made by others I trust 
please don't script based on the output of gpg without using
--with-colons.  the "human-readable" form is subject to change, but
--with-colons offers a stable API. so a stable bash script would look something like:
  for fpr in $(gpg --with-colons --list-keys | \
               awk -F: '/^fpr:/{ print $10 }'); do \
      gpg --edit-key "fpr" clean save; done
hope this helps,
     --dkg

@_date: 2018-01-24 13:36:43
@_author: Daniel Kahn Gillmor 
@_subject: failed to convert unprotected openpgp key: Checksum error 
Thanks for the diagnosis, Phil and Simon.
Please file a bug report about this at  so that
this edge-case doesn't get lost!
     --dkg

@_date: 2018-01-30 23:19:50
@_author: Daniel Kahn Gillmor 
@_subject: Why do Key Fingerprints include Creation Timestamp? 
This is a great question, and one that i've struggled with over time.  I
currently think that including the creation time in the fingerprint is a
*good* thing, but i have felt otherwise in the past.
The first thing to realize is that an OpenPGP certificate (a
"transferable public key" in the text of RFC 4880) is not an immutable
object -- it consists of a series of packets, and that collection of
packets can change over time (or some people can hold some packets of a
cert and other people hold others, so they see slightly different
certs), though the fingerprint remains constant.
So, including the creation date in the fingerprint means that if you
know the fingerprint and your tools depend on it (or it's included in
things like the signer fingerprint subpacket as modern implementations
do), you've locked down the key's creation date, and it cannot be
modified or replaced in the future regardless of how the certificate
changes.  Also, it cannot seem to be created at one time to some people
and another way to other people.  knowing the cert creation date can
useful because it provides a bound on what kind of signatures are
sensible.  (e.g. a signature made before your key was created is super
If your goal is to detect colliding key material, *you can do that too*,
just by looking at the MPIs themselves directly.  But given that the
fingerprint kind of "locks in" the data that it covers, and it can be
handy to know that the creation date of an OpenPGP certificate is
does that make sense?
     --dkg

@_date: 2018-01-31 11:00:05
@_author: Daniel Kahn Gillmor 
@_subject: Using GnuPG when switching users 
the problem you're running into is that pinentry is unable to prompt you
for a password.
as a workaround, you could create your own pinentry that provides a
password, or that can prompt you in some other way.  You might be
interested in some dummy pinentry implementations:
   For an actual fix, you've got quite a set of constraints here, and they
might just mean that you cannot solve the problem without a workaround.
Please note that the 2.0.x branch of GnuPG is no longer supported by the
I *strongly* recommend that you try to get the 2.2.* branch installed
and then you'll be able to use the loopback pinentry-mode.  And you'll
be running supported software.
    --dkg

@_date: 2018-01-31 10:54:45
@_author: Daniel Kahn Gillmor 
@_subject: AW: Why do Key Fingerprints include Creation Timestamp? 
I think you mean "to generate fingerprints", not "to generate keys" --
right?  in particular, i think you're talking about the computational
expense of searching the fingerprint space for certain properties.
fwiw, cryptographic material generation itself is also super cheap these
days (in particular, ecc keys just need a small and predictable amount
of entropy to find).  And if you're trying to do something devious where
you don't care about the security of the key, even key formats that
require searching for primes don't have a large cost.
These are great reasons to never use key IDs for any purpose [0].
They're not particularly compelling reasons to avoid including the
creation date, given that the computational expense of fingerprint
search is basically the same whether you include the creation timestamp
or not.  If the goal is to increase computational expense of fingerprint
search, there are better ways to do that (though they require changing
the spec for OpenPGP, and most proposals i've seen to do so incur
additional costs at other places in an OpenPGP workflow, which may or
may not be a cost worth paying).
        --dkg
[0] i agree, and i've argued this more comprehensively here:

@_date: 2018-01-31 17:02:28
@_author: Daniel Kahn Gillmor 
@_subject: Using GnuPG when switching users 
the only message i see from you about getting gpg to work on solaris is
from back in September:
   Subject: "Insecure memory" (yes setuid set) and "get_passphrase failed"
I don't see any issues about compilation there, though -- sorry if your
messages were missed.
sounds like a functional workaround for the moment, but it doesn't get
you into the realm of running software with active support :(
aiui, GnuPG *intends* to support platforms like Solaris.
      --dkg

@_date: 2018-06-08 14:29:52
@_author: Daniel Kahn Gillmor 
@_subject: [Announce] [security fix] GnuPG 2.2.8 released (CVE-2018-12020) 
I'm having the same problem.  Werner, what is the passphrase for this
test example?
     --dkg

@_date: 2018-06-08 15:01:52
@_author: Daniel Kahn Gillmor 
@_subject: [Announce] [security fix] GnuPG 2.2.8 released (CVE-2018-12020) 
ah, the passphrase is "abc"
    --dkg the mad haxx0r

@_date: 2018-06-12 03:21:54
@_author: Daniel Kahn Gillmor 
@_subject: Stripping expired subkey during export? 
dredging this up from the past:
This is now underway, and will hopefully make it into the next release:
      --dkg

@_date: 2018-06-13 09:43:14
@_author: Daniel Kahn Gillmor 
@_subject: key distribution/verification/update mechanisms other than 
sorry for the blast from the past here, but in re-reading this thread, i
thought i'd follow up on this.
the proposed revocation distribution network wouldn't allow any user IDs
or third-party certifications, so most of the "trollwot" would not be
if someone wants to upload their own key and make it unfetchable by
appending garbage to it, that's probably OK (at least, it's a strict
improvement than the current situation, which is that they can append
garbage to *any* key).  and if they use weak key material (or publish
the secret someplace), then sure it's a noisy blob that anyone can
append to.  But no one will care, because they aren't likely to be
relying on that key.
does that make sense as to why this proposal is potentially useful?
        --dkg

@_date: 2018-03-01 23:20:43
@_author: Daniel Kahn Gillmor 
@_subject: entropy gathering daemon 
On the GNU/Linux platform, /dev/random is basically a legacy interface
at this point.  See the modern documentation in random(4).
early boot.  However, GnuPG and gcrypt don't know whether the're being
used in the early boot process or not.  Therefore, according to
random(4) they should be using the getrandom(2) system call with no
flags set.
Is there any chance that gcrypt will adopt this approach on GNU/Linux
systems, or at least make it available so that GnuPG can use it?
     --dkg

@_date: 2018-03-15 22:39:55
@_author: Daniel Kahn Gillmor 
@_subject: Stupid Symantec 
or, if what you really care about is file-level encryption on a
GNU/Linux desktop and you *don't* care about files being OpenPGP
formatted, you could look into ext4's native encryption features (see
e4crypt(8) and related docs to get started).
     --dkg

@_date: 2018-03-16 01:16:49
@_author: Daniel Kahn Gillmor 
@_subject: Stupid Symantec 
note that for fike-level encryption, i was not talking about ecryptfs,
but rather about e4crypt.  these are different technologies, and i would
suspect (though i haven't profiled it) that e4crypt would be
significantly more performant than ecryptfs.
fwiw, i think that block-device level encryption (e.g. dmcrypt with
LUKS) is orthogonal to file-level encryption (e.g. e4crypt).  they have
different use cases against different adversaries, and there's no clear
argument that i've seen that you shouldn't use them in concert with one
for example, consider the "fast secure delete" functionality that you
get from file-level encryption -- delete the inode of a file (which
contains the file's key) and then the on-disk data for the file will be
unrecoverable.  this isn't achievable with block-device-level crypto --
as long as the block device is unlocked, the old blocks are still
        --dkg

@_date: 2018-03-23 20:46:37
@_author: Daniel Kahn Gillmor 
@_subject: Using gpg-agent --supervised with systemd 
it sounds like you might have created the systemd unit files yourself.
If you're running GnuPG from a distribution-supported package, that
package should have shipped them for you already (see for example the
packaging in debian).
even if you're building it yourself, or if your distro doesn't ship
them, i recommend starting from the example unit files in
doc/examples/systemd-user/ in the source tree.  can you compare those
unit files with your own unit files?
I'm assuming that sysu is some sort of local alias for "systemctl
--user" please let the list know if that's not the case.
these are not the standard socket locations, which is probably why gpg
isn't finding them for you.
try using the shipped user service units instead :) If that doesn't work
for you, or if you have any suggestions for improvements, i'm happy to
help review and debug.
    --dkg

@_date: 2018-05-17 10:49:55
@_author: Daniel Kahn Gillmor 
@_subject: AW: Users GnuPG aims for? (Re: Breaking MIME concatenation) 
I don't know about Ubuntu Bionic, but for Debian Buster this is simply
Buster relies on gpgv (which is part of the GnuPG suite) for validating
archive signatures.
apt-key has been deprecated for a while now.  I don't think i've seen a
secure use of apt-key that i can really encourage anywhere.
If you want to do sane cryptographic controls on repositories, you
should (a) place the key for a given repo somewhere sensible in the
filesystem (e.g. /usr/share/keyrings/REPONAME-keyring.gpg), and (b) add
a Signed-By: line to your .sources file (or a signed-by option to the
line in your .list file).
See sources.list(5) and
 for more details.
See also  for suggestions about
improvements to scoped cryptographic authorities for the default
installation of debian repositories.
Again, this is simply not true.  e-mail itself (let alone encrypted
mail) is not an essential system part, but cryptographic software update
verification *is* an essential system part, and debian continues to
depend on gpgv for that purpose.
        --dkg

@_date: 2018-05-17 15:48:33
@_author: Daniel Kahn Gillmor 
@_subject: Breaking MIME concatenation 
given that the OS package verification use case is relevant for millions
of server installations, i'm not convinced that Linux on the Desktop is
really what rjh was referring to.
       --dkg

@_date: 2018-05-17 15:58:17
@_author: Daniel Kahn Gillmor 
@_subject: AW: AW: Users GnuPG aims for? (Re: Breaking MIME concatenation) 
I recommend not relying directly on apt-key, whether online or offline :)
yes.  furthermore, per-repository pinning of keys avoids the possibility
of one repository owner signing a Release file for a different
repository.  This paves the way for a local administrator to put
meaningful constraints on a given external repository (e.g. pinning
which packages can be shipped from that repo, or restricting maintainer
scripts from running).
I welcome any and all help in continuing to drive the ecosystem down
this path.
        --dkg

@_date: 2018-05-18 14:45:26
@_author: Daniel Kahn Gillmor 
@_subject: Breaking MIME concatenation 
they won't be OK once the switch to ed25519 happens :/
     --dkg

@_date: 2018-05-18 14:52:45
@_author: Daniel Kahn Gillmor 
@_subject: AW: AW: AW: Users GnuPG aims for? (Re: Breaking MIME 
I'm actually advocating avoiding trusted.gpg.d entirely as well, and
moving to explicit per-repo keyrings.
So keep trusted.gpg and trusted.gpg.d completely empty, and populate
    deb [signed-by=/usr/share/keyrings/debian-archive-keyring.gpg]  buster main
You're asking the right questions.  But please read
and the other sections on that page in more detail for the answers :)
Another benefit is that it is a necessary prerequisite if we want to be
able to constrain some .debs (e.g. and  based
on their origin.  This is still more work to be done, but if we can't
isolate repos from one another than it'll never work.  So please don't
discount this work just because we haven't achieved all the rest of the
isolation yet.
The journey of a thousand miles begins with a single step, as they say.
    --dkg

@_date: 2018-11-12 06:34:19
@_author: Daniel Kahn Gillmor 
@_subject: Update FAQ about revocation certificates? 
fwiw, i agree with Damien that the existing text in the FAQ about
generating a revocation certificate should be removed.
I think that there should be some text like "where can i find my key's
revocation certificate?" which could be added to the FAQ.
However, situations like these:
Sound like corner cases to me, and they will clutter the FAQ.  The FAQ
is not designed to answer all possible situations (and certainly not
general file system management questions, etc).  It will be better
(clearer, simpler) if it is targeted on the truly frequently-asked
questions.  For the corner cases, there is the man page, and there is
DETAILS.gz, and there is the mailing list, and there is the source.
I salute Damien's effort to get the FAQ into a more maintainable and
accessible state.
   --dkg

@_date: 2018-11-12 10:45:22
@_author: Daniel Kahn Gillmor 
@_subject: Exporting/ importing changes expiration date of subkeys... 
Hi there--
1.423 is not a valid GnuPG version, so i assume you meant GnuPG 1.4.23.
the "classic" version of GnuPG (the 1.4.x series) not only does not
support merging secret keys effectively, it does not support modern
asymmetric cryptographic mechanisms like curve25519 and ed25519.
If you upgrade to the modern version of GnuPG on your windows machine,
and then try to re-import, i think you'll find the merge issue resolved.
You'll also get better support going forward.
       --dkg

@_date: 2018-11-12 16:16:17
@_author: Daniel Kahn Gillmor 
@_subject: Exporting/ importing changes expiration date of subkeys... 
It's difficult for me to tell what you're asking about.
For each import/export operation you're asking about (both successes and
failures), could you give the following information clearly:
 * Are you exporting secret keys?
   or exporting public keys?
 * where were the secret keys originally created? (on what program does
   the original export happen?)
 * which program is doing the import?
 * does the program doing the import modify the OpenPGP certificate in
   any way?
 * does it re-export the OpenPGP certificate?  if so, is that
   re-exported certificate loaded back into the original program?
If possible, please include these screenshots as decently-sized (small)
attachments, rather than linking to a potentially ephemeral site like
imgur!  we want these archives to be ueful even after imgur dies or gets
bought :)
it is not normal for the primary key to be marked as
authentication-capable ("A").  If you have a tool that is doing that,
please report back what tool that is, on what platform and what version!
        --dkg

@_date: 2018-11-13 17:50:47
@_author: Daniel Kahn Gillmor 
@_subject: Exporting/ importing changes expiration date of subkeys... 
have you reached out to the r2mail2 author about this?  it sounds to me
like it's possible that gpg 1.4 is exporting multiple binding signatures
per subkey, and r2mail2 is only seeing one of them (or something like
does the same thing happen if you export public key material, without
the secret key material?  If it does, that might be easier to debug,
because you should be able to send just the public key material to
someone else who can help debug (i'd understand you being unwilling to
send the secret key to someone else).
I've cc'ed Stefan from r2mail2 here, in the hopes that he can take a
This sounds like a bug in gnupgpack, but i don't see a good way to
report bugs at the URL above.  I would generally not recommend such a
well, you said that they imported correctly into other programs, right?
so maybe the issue is at the intersection of r2mail2 and classic GnuPG.
GPGrelay should really upgrade to the modern GnuPG suite.  Maybe as a
user you can ask the author what's blocking them from upgrading?
    --dkg

@_date: 2018-11-14 04:52:56
@_author: Daniel Kahn Gillmor 
@_subject: Exporting/ importing changes expiration date of subkeys... 
Hi MFPA--
Can you please point to the specific URL where there is a broken link?
Or, even better, offer a patch against the git repo cloned from
 ?  I think you're talking
about web/software/swlist.org in that repository.
      --dkg

@_date: 2018-11-14 04:58:37
@_author: Daniel Kahn Gillmor 
@_subject: Exporting/ importing changes expiration date of subkeys... 
all the more reason to move away from it then.  security software that
deals with complex data structures passed around the public internet
needs to be actively maintained :(
      --dkg

@_date: 2018-11-14 13:03:30
@_author: Daniel Kahn Gillmor 
@_subject: Exporting/ importing changes expiration date of subkeys... 
thanks, i've reported this as  so that
hopefully someone resposible for the web site will actually fix it.
feel free to make bug reports like this directly to
 in the future!
          --dkg

@_date: 2018-11-16 08:03:09
@_author: Daniel Kahn Gillmor 
@_subject: WoT question - policy 
OpenPGP identity certifications ("keysignings") make no claims one way
or the other about a person's moral character.
Such a certification is simply an assertion that the person holding the
indicated identity also controls the corresponding cryptographic key
This kind of confusion is exactly why i think cert-levels are a
"solution" in search of a problem.  People already find it hard enough
to reason about a distributed network of identity assertions (the "web
of trust") *without* having to factor in certification levels.
Keep it simple.  (or, don't bother)
   --dkg

@_date: 2018-11-16 11:31:35
@_author: Daniel Kahn Gillmor 
@_subject: WoT question - policy 
I think you're talking about this:
I confess i do not understand what this has to do with sig0.  Surely the
same "attack" can be mounted via sig2?  I also don't know what "advise
from the blog" means, and i don't think the word "trust" in the final
question is well-defined -- what third party gains what kind of trust?.
Sorry to be so dense!
In response to the situation i *think* you're describing, i'd say:
   If you rely on mere quantity of any type of certification from
   parties you cannot identify and have no clear reason to trust, then
   you are open to a trivial Sybil attack.    [
eh?  I have never said (and would never say) that X.509 is "simple".
it's grossly overcomplicated for what it's typically used for, even
worse than OpenPGP.
I think you're referring to this part of
The middle paragraph is exactly the point i was making in my earlier
mail -- definitely agree. :)
But i fail to see what any of this has to do with minors specifically
(surely the good guidance applies after reaching the age of majority as
well), or how law enforcement happened to sneak in at the end there.  I
suspect you're imagining some specific scenario that i don't know about,
but i don't know what it is or how it relates to OpenPGP certification.
    --dkg

@_date: 2018-10-06 21:01:20
@_author: Daniel Kahn Gillmor 
@_subject: Utilizing facts of homedir organization (was: Exact definition of 
I think you're right that this is an "always-correct" option.
But i note that when assembling an initramfs, you have to choose which
version of GnuPG you put in it.  And i also note that the initramfs is
typically never modified once created: rather, a new one might be
created and swapped in.
This suggests that at time of initramfs creation, you can use your
suggested "--no-default-keyring --keyring foo.kbx --import" approach
(using the version of gpg that you are also packing into the initramfs),
and you can be confident that it will work in the initramfs, because the
version of gpg and the keyring will match.  In this case, you only need
to --import at initramfs creation time, and you can avoid the extra
--import at initramfs-run-time.
Does this make sense?  you just need to make sure you tie the version of
gpg and the keyring into the same initramfs build time.
I don't know the answer to this about using concatenated TPKs as
keyring.  Maybe Werner can weigh in?
But GnuPG *will* forever continue to consume concatenated TPKs via
--import -- that's the OpenPGP interoperable format, and if GnuPG stops
consuming it on --import, it would no longer be an OpenPGP
         --dkg

@_date: 2018-09-04 12:10:23
@_author: Daniel Kahn Gillmor 
@_subject: Issue with pinentry GUI agent 
to be clear, keep-display means that all requests made to the agent that
require interaction with X11 will show up on the original display that
the agent was started with.  This isn't desirable in all cases
(e.g. where an agent is shared across multiple X11 displays)
i think you're saying that "pinentry-qt --display :124" doesn't honor
the "--display :124" argument, but that doesn't seem to be true to me
with pinentry 1.1.0:
    0 dkg at alice:~$ pinentry-qt --display :124
    qt.qpa.screen: QXcbConnection: Could not connect to display :124
    Could not connect to any X display.
    1 dkg at alice:~$ or do you mean something else?
   --dkg

@_date: 2018-09-05 10:20:59
@_author: Daniel Kahn Gillmor 
@_subject: Issue with pinentry GUI agent 
I'm unable to replicate this.  here's a transcript of my session,
testing pinentry-qt 1.1.0-1+b1 and gnupg 2.2.10-1 on debian
0 dkg at alice:~$ DISPLAY= pinentry-qt OK Pleased to meet you
D monkey
0 dkg at alice:~$ DISPLAY= pinentry-qt --display :0
OK Pleased to meet you
D monkey
0 dkg at alice:~$ unset DISPLAY
0 dkg at alice:~$ pinentry-qt --display :0
OK Pleased to meet you
getpin D abc123
0 dkg at alice:~$ pinentry-qt OK Pleased to meet you
D abc123
0 dkg at alice:~$ The two entries with --display caused a graphical display to pop up.
the other two caused the curses fallback.
if you can sort out a clearer replication, please report it on
 !
    --dkg

@_date: 2018-09-07 15:19:34
@_author: Daniel Kahn Gillmor 
@_subject: Issue with pinentry GUI agent 
i wasn't testing on a full-blown desktop environment -- my test
environment was openbox, plus a typical dbus-user-session arrangement,
and a systemd --user manager connected to the session.  (not that i
think any of that is likely to matter for testing pinentry-qt itself).
      --dkg

@_date: 2018-09-23 16:19:22
@_author: Daniel Kahn Gillmor 
@_subject: Utilizing facts of homedir organization (was: Exact definition of 
I appreciate that you're asking for clarification about what is the
scope of GnuPG's "API", such as it is.  We do need more clarity here.
i don't have the authority to answer your questions about the contents
of ~/.gnupg/private-keys-v1.d/, but i'd always thought that the
internals of ~/.gnupg/ were *not* part of the "API", and generally
should not be relied upon.  I hope that Werner or someone else more
closely related to the project can clarify here.
The former statement is a way to create a simple, exported OpenPGP
"transferable public key" (TPK) of the form described in RFC 4880.  This
is the most interoperable form, if you're looking to export a specific
key for transfer into any other implementation (including other versions
of GnuPG).  This is not only "acceptable" but it is normal,
standardized, and widely interoperable.
Traditionally, GnuPG keyrings have been just a linear concatenation of
TPKs interspersed with "Trust Packets".  The more modern keybox (the
default in 2.1 and going forward) is different from that format, though.
The latter statement doesn't even have a GnuPG command on the tail end
of the pipe, but i assume you intended for it to be --import.  is that
In that case, it creates a keyring of whatever format the current
version of gpg uses by default.  But the real question is: why do you
need this, and what do you intend to do with it?  creating a keyring for
a specific version of GnuPG may be useful in some contexts, but it's
also pretty dicey to use in many other contexts.
Perhaps explaining what you're looking to do with this file you're
creating would help to decide whether the latter form is better for your
        --dkg

@_date: 2018-09-24 10:18:44
@_author: Daniel Kahn Gillmor 
@_subject: Utilizing facts of homedir organization (was: Exact definition of 
The part of those pages about "generating subkeys" does use the GnuPG
So I think the question you're asking is "what is the official
recommendation for deleting the cryptographic secret associated with the
master key?"
I agree that it would be nice if there was a clear, supported API for
doing that.  I suspect it would be something like:
  gpg-connect-agent "delete_key $KEYGRIP" /bye
(and you probably want to get the keygrip via
   gpg --with-colons --with-keygrip $FINGERPRINT
This clearly isn't a usable situation for most users, so it's primarily
important to document it so that more usable tools can be written that
know how to safely interact with GnuPG under the hood.
     --dkg

@_date: 2019-04-11 11:29:28
@_author: Daniel Kahn Gillmor 
@_subject: How do I delete secret subkeys correctly? 
I agree with Peter that delkey doesn't do what you want it to do.
I was trying to figure out how to do it through the user interface, and
it's pretty clunky, with some scary failure modes.  I've opened
 about it.
I know that with the version of GnuPG that you're using right now, you
can delete the secret key by learning its keygrip and asking gpg-agent
to delete it for you.
Start by getting a snapshot of how GnuPG sees the key:
    gpg --with-keygrip --list-secret-keys "$YOUR_FINGERRINT"
Then take the keygrip of the subkey you care about as $KEYGRIP and do:
    gpg-connect-agent "delete_key $KEYGRIP" /bye
(note that gpg-agent might prompt you about deletion when you do this)
Now you can verify that this worked by running the snapshot again and
comparing it with the earlier run:
    gpg --with-keygrip --list-secret-keys "$YOUR_FINGERPRINT"
The difference should be that you should see a " appear after the
"ssb" line that talks about the associated subkey.  the " means "no
secret key available."
        --dkg

@_date: 2019-08-01 09:27:45
@_author: Daniel Kahn Gillmor 
@_subject: allow-non-selfsigned-uid issue with key from keys.openpgp.org 
We're already in uncharted waters with the inevitable abuse of SKS, we
need to figure out how to stabilize the ecosystem.
If the PGP implementation of OpenPGP has bugs or doesn't behave well in
the context of a minimized/stripped certificate, let's ask them to fix
those bugs.  The bugs in how that implementation interprets data are
irrelevant to data that Here's one use case (i've got others if you want):
 * You have my OpenPGP certificate (with userid with e-mail address),
   but it is not published in full publicly because i do not want people
   to be able to find anything related to my e-mail address online.
 * It has an encryption-capable subkey "X" that expires in 1 year, which
   i use to be able to have deletable messages.  I will destroy the
   secret component when X expires.
 * As the year draws to a close, i create a new subkey "Y" and i attach
   it to my OpenPGP certificate, and i push the updated certificate to
   an abuse-resistant keystore (like keys.openpgp.org), again declining
   to allow it to publish my e-mail address.
 * After the expiration of "X", you want to send me an encrypted mail
   (as is your habit when mailing me).  You follow best practices and
   refresh your keyring (fetching certificate updates by primary key
   fingerprint) from a public, abuse-resistant keystore.  Does your
   OpenPGP implementation learn about "Y" when it pulls in the update?
   It should.
If it does not, you will end up sending me cleartext e-mail,
pointlessly, because your local client had the opportunity to know (for
certain -- with cryptographically-verifiable evidence!) that a
non-expired encryption-capable subkey was available, associated with the
given primary key.
        --dkg

@_date: 2019-08-27 19:17:13
@_author: Daniel Kahn Gillmor 
@_subject: Storing custom signed data in the key 
Hi Tomasz--
As i understand it, signify uses ed25519 public keys.
For this specific use case, i'd recommend attaching your signify public
key as a signing-capable subkey directly to your OpenPGP
certificate.  Or, if you don't want it to look like it's signing-capable
for the purposes of OpenPGP signing, you could attach it as a subkey
with an empty key flags subpacket.
If you want to include a notation that indicates that this key is for
use with signify specifically, you could then include a notation in the
subkey binding signature.
This seems like the most prinicipled way to include the key in your
OpenPGP certificate, and the best way to avoid having people get
confused about third-party certification claims, since third-parties
can't attach subkeys.
Doing this specifically would require some conversion capability between
the signify format and the OpenPGP format for Ed25519 keys.  I haven't
tried to do that, but if it's something that you're interested in, i'd
be happy to look at it with you.
   --dkg

@_date: 2019-12-16 14:01:22
@_author: Daniel Kahn Gillmor 
@_subject: pinentry-gtk-2 dialog doesn't appear before getting input 
just to clarify, i think you're talking about pinentry-gnome3, not
gtk3.  Right?
My experience is that pinentry-gnome3 is much better-integrated with any
modern desktop installation than pinentry-gtk2 is, so this outcome is
not surprising to me.
    --dkg

@_date: 2019-02-25 18:03:52
@_author: Daniel Kahn Gillmor 
@_subject: git.gnupg.org: Certificate expired 
It's probably a fine place.  The last time this happened was on November
24 (3 months ago!) and it was reported on gnupg-devel:
   Message-Id: Perhaps the certificate update mechanism (it appears to be Let's
Encrypt) needs to be automated into refreshing the webserver when a new
certificate is issued.
Thanks for the report.
            --dkg

@_date: 2019-02-25 18:47:08
@_author: Daniel Kahn Gillmor 
@_subject: Weird locale at passphrase step 
[ image of cyrillic glyphs and U+FFFD REPLACEMENT CHARACTER symbols ]
It sounds to me like the gpg-agent process that is running on your
system has a different locale.
GnuPG asks the agent for a new passphrase, which in turn displays the
unfortunately, it depends on how your gpg-agent is initialized, which we
don't have enough information on here.  perhaps it was launched before
your locale was set to en_US.UTF-8?
One thing you can try as a workaround is to kill off the gpg-agent and
it should get manually restarted on subsequent use:
   gpgconf --kill gpg-agent
maybe someone with more info about how MacOS and Homebrew manage
per-user services can weigh in on better workarounds, or suggest a more
principled fix for that platform.
       --dkg

@_date: 2019-02-26 01:45:51
@_author: Daniel Kahn Gillmor 
@_subject: gpg vs gpgv and trustedkeys 
I think your description here is missing some background: why do you
need the public OpenPGP key in your OS image?
If the goal is just to use it with gpgv (e.g. to verify software updates
or some other post-build artifact that you'll fetch over the network)
then i recommend just explicitly pointing gpgv at the curated keyring
using --keyring, and not bothering with public.gpg or anything else.
This is the best approach because it lets you precisely control what is
being checked against, and you don't have to worry that other uses of
~/.gnupg/trustedkeys.{gpg,kbx} might end up polluting the specific check
you're hoping to make strong.
if you want an analogous example, check out the best-pratice guidance in
 about using
isolated keys per repository (with apt's Signed-By: options).
        --dkg

@_date: 2019-02-26 02:35:25
@_author: Daniel Kahn Gillmor 
@_subject: Why Signing key part of Master key 
"best practice" for some is "unusable complexity" for others :) If it
works for you, it's probably not unreasonable to keep the primary key
offline in cold storage.  But remember that what that does is to protect
the primary key itself -- if you've got subkeys that are capable of
acting as you (with the exception of making OpenPGP certifications),
those subkeys are not protected by keeping the primary key offline.
sure, but there's nothing stopping an "SC-capable" primary key from
*also* certifying another S-capable subkey, and using that one, if the
primary key is kept offline.
the "change-usage" subcommand to "gpg --edit-key" might be what you're
looking for.  it's documented in more recent versions of the gpg(1) man
            change-usage
                     Change the usage flags (capabilities) of the primary  key
                     or  of  subkeys.   These usage flags (e.g. Certify, Sign,
                     Authenticate,  Encrypt)  are  set  during  key  creation.
                     Sometimes  it is useful to have the opportunity to change
                     them (for example to add Authenticate)  after  they  have
                     been  created.  Please take care when doing this; the al?
                     lowed usage flags depend on the key algorithm.
Note that if you do this after having sent messages signed by the
primary key, it's not clear what the behavior will be for someone who
reads those signed messages after fetching your updated OpenPGP
certificate.  Should the message signature be invalid because the
primary key is no longer signing-capable?
Also note that OpenPGP certificates are built and updated by
aggregation.  So if you change your primary key's usage flags, that'll
simply be a new set of self-signatures that makes this change.
Anyone who wants to build a composite OpenPGP certificate from your key
material by filtering out this change can easily do so, producing a
certificate that is appears to still be SC-capable.  Reasonable OpenPGP
clients that see this certificate *and* your updated one will merge them
and respect the most recent usage flags. But does everyone you
correspond with use a reasonable OpenPGP client and have access to your
update certificate?  (exercise left to the reader?)
           --dkg

@_date: 2019-01-08 11:12:41
@_author: Daniel Kahn Gillmor 
@_subject: gpg > addphoto 
I think you're recommending making a change to that default value.
Do you have a new default value that you want to propose for future
versions of GnuPG?
Have you tried reducing it to your new proposed default value and
experimented with it, to let us know what it does to, say, photos larger
than that value already stored in your keyring?
have you tried looking at statistics of what sizes of images are present
in the public keyserver dumps?
those would all be reasonable next steps if you want to present a
convincing case for action here.
   --dkg

@_date: 2019-01-14 15:06:22
@_author: Daniel Kahn Gillmor 
@_subject: [SOLVED] gpg doesn't import secret keys for me any more 
to be clear, i think the issue that you were having is that both
commands use pinentry-tty, but the former command has stdin coming from
the redirected file, not the tty.
fwiw, if you use --batch with --import, there will be no attempt to use
pinentry, ever, which should make both commands work without complaint.
         --dkg

@_date: 2019-01-15 15:53:01
@_author: Daniel Kahn Gillmor 
@_subject: [SOLVED] gpg doesn't import secret keys for me any more 
right, that's a requirement for most secret keys, because the secret
keys need to be re-encrypted into the OpenPGP-style export format.  The
standard locked form of the secret keys stored in
~/.gnupg/private-keys-v1.d is not compatible directly with the OpenPGP
secret key specification, so decryption and re-encryption is needed.
otoh, --batch can work with --import because of a special case, where
GnuPG is willing to (temporarily at least) just store the
OpenPGP-wrapped secret key in private-keys-v1.d/ without converting it
to the standard locked form.
    --dkg

@_date: 2019-01-19 11:23:33
@_author: Daniel Kahn Gillmor 
@_subject: Discrepancies in extracted photo-id images from dumps 
jpegextractor looks like it uses a simple heuristic to find jpegs.
in particular (quoting from
     jpegextractor uses the fact that valid binary JPEG streams start
     with the byte sequence ff d8 ff and end with the byte sequence ff
     d9. It copies all of those streams to new files. As jpegextractor
     simply looks for the two sequences it does not have to know the
     format of the encapsulating file and thus works with all formats
     that embed JPEG streams.
consider that a lot of OpenPGP key material is high-entropy -- public
keys, cryptographic signatures, etc are all essentially random bytes.
hand-wavy approximations follow, i'd be happy if someone wants to make
them more rigorus.
If we look at triplets of three consecutive octets, each such sequence
should appear roughly once every 2^(8*3) == 16777216 triplets.  and
any specific pair of octets will appear roughly once every 2^(8*2) ==
65536 pairs.
So about every 16 million octets of high-entropy data, you'll find that
starting "ff d8 ff" triplet, and much more frequently you'll find the
ending "ff d9" pair.
So assuming that the bulk of a 1GiB dump is high-entropy data *with no
actual JPEGs in it at all*, you should expect to see jpegextractor have
at least 1G/16M == 64 false positive matches.
that doesn't quite add up to the number of extras that you're seeing
from jpegextractor, but it suggests that there will be a large number of
false positives by that mechanism at any rate.
have you tried looking at the jpegs that jpegextractor produces?
     --dkg

@_date: 2019-01-21 13:21:35
@_author: Daniel Kahn Gillmor 
@_subject: Discrepancies in extracted photo-id images from dumps 
How indeed.
Justina, please keep discussion on-topic and friendly for this mailing
list.  Too many of your posts to the list are full of invective,
threating assault, or incoherently off-topic, none of which is
appropriate here.
Let's keep the list welcoming and relevant to users of GnuPG.
All the best,
    --dkg

@_date: 2019-07-02 11:00:26
@_author: Daniel Kahn Gillmor 
@_subject: keyserver-options: self-sigs-only, import-clean, import-minimal 
It sounds like you are saying that the order of operations --
import-then-clean vs. clean-then-import is part of the API spec that
GnuPG is committed to.
However, as Teemu points out, the order of operations is clearly the
cause of the problem here.
If you're saying that "clean-then-import" is technically difficult to
implemente, that is a different answer -- it would be good to understand
why it is difficult, so that we can consider how to fix it.
But "clean-then-import" is clearly a preferable approach to any of the
workarounds described so far.
Surely GnuPG could validate each certification without first storing the
certificate in the keyring.  "clean" means that the certificates already
stored in the keyring are used to validate incoming signatures.  right?
or am i misunderstanding something?
            --dkg

@_date: 2019-07-25 16:10:46
@_author: Daniel Kahn Gillmor 
@_subject: Where is the "INTEROPERABILITY WITH OTHER OPENPGP PROGRAMS 
It appears to be in the info page, which (on my system) i can access
with "info gpg" and then searching for "interoperability".  In the
manual page (gpg(1), accessed via "man 1 gpg") the section is titled
just "INTEROPERABILITY" (why this difference between info and man?  I
don't know or understand!)
I reproduce the current version out of info (from 2.2.17) below.
        --dkg
INTEROPERABILITY WITH OTHER OPENPGP PROGRAMS
GnuPG tries to be a very flexible implementation of the OpenPGP
standard.  In particular, GnuPG implements many of the optional parts of
the standard, such as the SHA-512 hash, and the ZLIB and BZIP2
compression algorithms.  It is important to be aware that not all
OpenPGP programs implement these optional algorithms and that by forcing
their use via the '--cipher-algo', '--digest-algo',
'--cert-digest-algo', or '--compress-algo' options in GnuPG, it is
possible to create a perfectly valid OpenPGP message, but one that
cannot be read by the intended recipient.
   There are dozens of variations of OpenPGP programs available, and
each supports a slightly different subset of these optional algorithms.
For example, until recently, no (unhacked) version of PGP supported the
BLOWFISH cipher algorithm.  A message using BLOWFISH simply could not be
read by a PGP user.  By default, GnuPG uses the standard OpenPGP
preferences system that will always do the right thing and create
messages that are usable by all recipients, regardless of which OpenPGP
program they use.  Only override this safe default if you really know
what you are doing.
   If you absolutely must override the safe default, or if the
preferences on a given key are invalid for some reason, you are far
better off using the '--pgp6', '--pgp7', or '--pgp8' options.  These
options are safe as they do not force any particular algorithms in
violation of OpenPGP, but rather reduce the available algorithms to a
"PGP-safe" list.

@_date: 2019-07-29 09:43:54
@_author: Daniel Kahn Gillmor 
@_subject: allow-non-selfsigned-uid issue with key from keys.openpgp.org 
Hi MFPA--
A bit of background first, since the documentation around
allow-non-selfsigned-uid appears to be confusing/mistaken.
the manual says:
       --allow-non-selfsigned-uid
       --no-allow-non-selfsigned-uid
              Allow the import and use of keys with user  IDs  which  are  not
              self-signed.  This is not recommended, as a non self-signed user
              ID is trivial to forge. --no-allow-non-selfsigned-uid disables.
But in fact the default (--no-allow-non-selfsigned-uid) does not
actually disallow the import or use of an OpenPGP certificate with a
user ID which is not self-signed; it simply strips any non-self-signed
user IDs from the certificate, and then deals with the remaining
trimmed-down certificate as it would have had those user IDs not been
But none of this means that a certificate *without* any user ID at all
is the same as a certificate with a user ID that happens to be
unsigned.  (though it's trivial to get from the former to the latter by
injecting an arbitrary user ID packet into the certificate stream)
before any subkey packets.
RFC 4880 mandates a user ID in any "Transferable Public Key" (aka
"OpenPGP certificate"):
    However, there is an expectation of relaxing this in the next revision
of the standard:
    GnuPG currently rejects OpenPGP certificates that lack any user ID at
all, in part because it is more difficult to manipulate them (they have
no user ID to refer to them by), and in part because "we've always done
it that way", i think.  Perhaps Werner can provide more background on
why GnuPG is generally resistant to holding OpenPGP certificates that
have no User ID at all in its local keyring.
All that said, it's possible for GnuPG to merge a uid-less certificate
(including e.g. subkeys, revocation certificates, etc) with a
locally-held certificate (i.e., in the "keyring") that *does* have a
user ID, so long as both certificates share the same primary key.  The
resultant merged certificate will have a user ID, and can be reasoned
about using the same logic that GnuPG already expects, even if the
incoming uid-less certificate would have been ignored if it were
imported into an otherwise empty keyring.
Doing such a merge would be super helpful, particularly for receiving
things like subkey updates and revocation information from
abuse-resistant keystores like keys.openpgp.org.
The good news is that there are patches outstanding for GnuPG to do so:
    If you're using debian or a debian-derived installation of GnuPG, those
patches have been merged as of version 2.2.16-2 (ses
 and i'm currently trying to get them
merged for the next stable point release of debian "buster" (see
  Hopefully GnuPG will follow suit
upstream, as these patches provide critical security defenses for users
who refresh their keyrings to check for revocations and subkey rotation.
    --dkg

@_date: 2019-06-09 18:18:34
@_author: Daniel Kahn Gillmor 
@_subject: how to integrate ca-certificates with gpgsm (for email s/mime 
Hi Gregor, everyone--
I agree that this is not only tedious -- it's an impossible question for
users to answer, especially if the signature verification is done at
indexing time, when the user doesn't even have a smidgen of context.
See also  for a mutt+gpgsm example of this
kind of frustration. (i'm cc'ing that bug report since it has seen no
decisive action; perhaps this discussion will help move things along
The current behavior is:
   The user sees "do you ultimately trust XXX to correctly certify user
   certificates?", with "cancel" and "yes".
   If they answer "yes", they're asked "please verify that the
   certificate identified as XXX has the fingerprint YYYY", with
   "cancel", and "correct"
i can't imagine any situation where a user is equipped to answer the
first question -- even if they believe that it's being asked in good
faith.  and the second question is somehow even more impossible.  What
certificate?  How is the user supposed to know what to verify here?
I'm one of the debian maintainers for gnupg, and i admit that i haven't
put a lot of work into the gpgsm system integration.  I did a bit of
digging just now, and i've got some ideas, but be warned that i haven't
dug deeply into the tradeoffs here yet.  i welcome feedback!
looking at the documentation for trustlist.txt in gpg-agent(1) (it seems
odd to have it documented there, since i thought gpg-agent was for
secret key material only, weird!), it looks like trustlist.txt has an
`include-default` option, which maybe defaults to
`/etc/gnupg/trustlist.txt` on debian (i haven't done much testing!)
Of course, gpgsm has to learn about these root certificates somehow as
well, and i think doesn't have an easy way to make use of a separate
keybox (perhaps Werner or another GnuPG dev can correct me on this).
Read gpgsm(1), i see that /usr/share/gnupg/com-certs.pem could be set up
as a symlink to /etc/ssl/certs/ca-certificates.crt.  But this only works
to import those root certificates at the initial creation of
pubring.kbx, so it won't work in an ongoing way (e.g. when
ca-certificates gets updated, they won't be updated.
So, what can Debian do to improve this integration?  here is a series of
suggestions of changes to the gnupg2 source package in debian (i have no
code to back them up yet, commentary and patches welcome):
 * make sure gpgsm Recommends: ca-certificates
 * add /etc/ca-certificates/update.d/gnupg to the gpgsm package (see
   update-ca-certificates(8) for a description of this hook), which
   should maintain /var/lib/gnupg/trustlist.txt and
   /var/lib/gnupg/ca-certificates.kbx .  (Maybe add a postinst script to
   invoke this as well?)
 * consider adding a symlink (a conffile, yuck):
   - /etc/gnupg/trustlist.txt ? /var/lib/gnupg/trustlist.txt
 * add a symlink to the gpgsm package:
   - /usr/share/gnupg/com-certs.pem ? /etc/ssl/certs/ca-certificates.crt
 * (maybe) change the default of gpg-agent's allow-mark-trusted to be
   false, rather than true.  This is both a safety precaution, and a
   usability improvement, since i can't think of a context in which the
   user is well-prepared to actually answer these questions in the way
   that they're presented.
This is still imperfect (the client has no way to learn of certiifcates
added via ca-certificates after they've first populated their
pubring.kbx), but it strikes me that it would be a strict improvement
over the status quo.
What do you think?
After doing a brief review, i have a bunch more questions for GnuPG
upstream too:
 * Could i convince you to search for trustlist.txt in
   /var/lib/gnupg/trustlist.txt as the system default, if
   /etc/gnupg/trustlist.txt is not found?
   That is, if no trustlist.txt is present in $GNUPGHOME, or if
   $GNUPGHOME/trustlist.txt has the include-default directive, it looks
   first for /etc/gnupg/trustlist.txt.  if it is found, it uses it.  if
   it is not found, it looks in /var/lib/gnupg/trustlist.txt.
   That would relieve me of needing to maintain a conffile in the debian
   package, which i would strongly prefer.
 * if i have an auto-generated /var/lib/gnupg/ca-certificates.kbx that
   is kept in sync with the system trustlist, is there a way that i can
   coax gpgsm to use it as a secondary (read-only) keyring by default?
   (i'm not asking for presence in this keyring to be used to infer
   trust; just that these certificates are always known, and can
   therefore be referenced (or deliberately ignored or marked
   untrustworthy) in the user's trustlist.txt.  Is such an option
   available already?  the gpgsm(1) manpage doesn't even mention
   --keyring, but it seems to support --keyring anyway.  so maybe there
   are other options i'm not aware of that could do this already, like
   some sort of --system-keyring ?
 * can i convince you to disable "allow-mark-trusted" in gpg-agent by
   default?  What is the use case where this seems like a sensible thing
   to offer?
 * can we improve the documentation of trustlist.txt?  From the comments
   auto-written to this file, it looks like it's intended to be part of
   the GnuPG family's "API" -- users are told how to deal with this file
   when editing it directly.  If that's the case, we really need to know
   what it is supposed to do, in a concise and easily findable way.
   gpgsm(1) refers to it, but doesn't direct the user toward any other
   documentation.  The comments written into the file when it is
   auto-generated are unclear.  what does the 'S' and 'P' and '*' flag
   mean?  (in the codebase, i see that they mean "S/MIME" and "PGP" and
   either, but that's still unclear.  what is the fingerprint *of* -- is
   it the X.509 certificate?  if so, what could 'P' possibly mean? Is it
   the OpenPGP v4 fingerprint?  if so, what could 'S' possibly mean?
   What would this fingerprint mean for '*'?  if it's 'P', does that
   mean it has an effect on gpg and not just gpgsm?)
   doc/debugging.texi claims:
      You may use the  flag in  to
      accept the certificate anyway.  Note that the fingerprint and this
      flag may only be added manually to    And yet, when i use:
      gpg-connect-agent "$DIGEST S whatever" /bye
   it seems to add the "relax" keyword.
   The header auto-written into trustlist.txt is not only bulky -- it's
   prone to falling out of date.  If this were better documented, and
   that documentation were placed someplace stable by the installed
   package, then when writing out a trustlist.txt, you could just have a
   one-line header pointing to the documentation.
To be clear, my goals here are similar to my goals for gpg:
 * default user configuration should be as close as possible to no
    configuration at all
 * the default system configuration should also be as close to no
   configuration as possible.
 * the package should ship with good documentation in a stable,
   easily-findable place.
 * the defaults should be well integrated into the host operationg
   system.
 * it should be possible for the user to have their user account diverge
   from the system defaults as narrowly as possible, while still
   receiving updates to the system defaults during package upgrades that
   retain their divergences.
 * it should be possible for the system administrator to have the system
   defaults diverge as narrowly as possible from the package defaults,
   without doing a lot of work at package upgrade to retain that
   divergence.
Happy to hear any feedback about these suggestions and questions!
     --dkg

@_date: 2019-06-21 16:49:30
@_author: Daniel Kahn Gillmor 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
There might be an impedance mismatch here, depending on what you think
the goals are.
SKS has no validation policy by default, and SKS-style reconciliation
assumes that all peers have the exact same filtering policy.  So: what
exactly is the data that these servers would reconcile between each
other?  Since multiple validating keyservers haven't actually seen the
same validation steps, it's not clear how they'd decide what to filter
in terms of validated data.
it may help to think about the different sorts of things that people use
keyservers for.  we don't have to solve all different use cases at once.
I've written quite a bit more technical detail over here:
But there are basically three main use cases for OpenPGP keyserver
clients (i'm setting aside the use case of people who want to publish
their certificates):
 a) validating a signature that comes from a certificate that the user
    doesn't yet have access to.
 b) finding a certificate to associated with a peer the user wants to
    communicate with (e.g. lookup by e-mail address).
 c) learning about the status of a certificate that the user already has
    (expiration, revocation, new subkeys, etc)
There's a good argument to be made that use case (a) is simply a broken
workflow.  If i'm shipping you a signature, and i have no way of
ensuring that you already know my certificate, i can just ship my
certificate along with the signature.  If i don't do that, and you can't
verify the signature, it's not clear that any keyserver network *should*
be the thing to solve that problem.
Use case (b) is intimately tied to the address validation process, which
introduces the set reconciliation difficulty i allude to above.  (b) is
also well-suited to distributed discovery mechanisms, like DNS
OPENPGPKEY or WKD, at least for users of domains that are willing to
offer such a delegated publication mechanism.  so it might not be a
necessary component for a keyserver network long-term.
But the data required for use case (c) on its own is eminently
reconcilable, with relatively simple and clear filtering logic, and is
likely the most worrisome part for the SPoFailure/Denial/Surveillance
concerns that Werner rightly raises.
So if we decide we only want to address use case (c), then it doesn't
seem too crazy to imagine reconciliation among multiple installations of
all the distributed, cryptographically-validated *non-identity* data
that hagrid is designed to distribute.  And this should be
fully-compatible with hagrid's implementation; each instance which can
simply augment the reconciled data with the identity information that it
has independently verified.
    --dkg

@_date: 2019-06-25 11:37:07
@_author: Daniel Kahn Gillmor 
@_subject: Change socketdir from ~/.gnupg to /run/user/ 
Ideally, you'd ensure that /run/user/$(id -u) is created during the
session launch within the docker container, so that it's present from
the beginning.
If you already have an agent running from before /run/user/$(id -u)
exists, you can kill it with a SIGTERM.  A new agent will be launched
appropriately using /run/user/$(id -u) automatically when it is needed.
all the best,
              --dkg

@_date: 2019-06-25 11:34:16
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG on debian [was: Re: GPG/YubiKey/CentOS7] 
this is pretty out of date, debian has shipped modern GnuPG as "gpg"
since the current stable release (about two years ago now).  Please
update your documentation :)
all the best,
  --dkg

@_date: 2019-06-25 11:57:41
@_author: Daniel Kahn Gillmor 
@_subject: missing root certificate, SMIME spanish government 
I agree that gpgsm integration with the system keyring is lacking.
Please see  for discussion on how that
might be improved.  I'd love to hear any feedback or thoughts there.
(and would be even happier to receive patches i could review).
   --dkg

@_date: 2019-06-25 11:12:43
@_author: Daniel Kahn Gillmor 
@_subject: gpg-agent systemd user service [was: Re: GnuPG and SSH_AUTH_SOCK 
If you're using gpg-agent as a systemd user service, please use the
systemd unit files (.service and .socket definitions) that ship with
GnuPG itself.
There are a number of subtle (and not-so-subtle) problems with your
proposed gpg-agent systemd user service definition.  In contrast, the
upstream one has been fairly widely tested.
If the standard upstream service doesn't work for you for some reason,
please explain why it doesn't work for you, and report it as a bug so
that we can fix it for everyone.
While you're of course free to use custom variants like this for
yourself, please don't recommend that other people use them, because it
makes it much more difficult for the GnuPG project to support other
All the best,
      --dkg

@_date: 2019-06-25 11:54:07
@_author: Daniel Kahn Gillmor 
@_subject: Adding notations with quick commands 
I don't know of a way to do this automatically if there is already a
certification from the current issuer over the OpenPGP User ID in
question, unless the old certification is local (non-exportable), and
the new one is not.  in that special case, gpg seems fine with issuing
the new certification (and will respect --cert-notation or
--set-notation when doing so).
I've opened  to track this bug.  Please
follow up over there.
     --dkg

@_date: 2019-06-25 11:30:35
@_author: Daniel Kahn Gillmor 
@_subject: Infinite loop? 
Without having access to your pubring.gpg, it's hard to say what is
triggering this loop.
I also note that gpg version 2.2.5 is fairly old -- is it possible to
try to upgrade to a newer version?
The repetitions at 475 actually end at 8144, and different things appear
to be happening in that debug log up until you sent it an interrupt to
Is it possible that your pubring.gpg is corrupt?
Can you replicate this with a minimal GNUPGHOME?
Can you try migrating from pubring.gpg to pubring.kbx and see if you
still have the same problem?  A script for doing that migration is here
if you want to try:
    (you might want to back up your ~/.gnupg/ before trying)
All the best,
    --dkg

@_date: 2019-06-25 12:46:11
@_author: Daniel Kahn Gillmor 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
One concrete proposal for a mechanism for how to do this at the protocol
level is "First-party-attested Third-party Certifications", documented
    To make this feasible requires some work on the client side.  The
protocol implementation is likely to be the easy part.  The hard part is
the UI/UX work to make this something that a normal human can understand
and do without too much pain.
    --dkg

@_date: 2019-06-25 18:47:11
@_author: Daniel Kahn Gillmor 
@_subject: Infinite loop? 
Interesting!  my pubring.kbx is 147MiB, but GnuPG still should not run
forever when doing --list-keys.  It takes 17s to complete the listing of
my pubring.kbx, as measured by "time gpg --list-keys > /dev/null"
gpg should not take forever to list a 20MB keyring.
If you still have a copy of the corrupt 20M pubring.gpg, it might be
interesting to see it as an example, because it sounds like it's
tickling a bug.
however, sharing your keyring might be sensitive, and 20MB certainly
won't fit in a message on this mailing list.  If you are willing to
share it privately so this can be tracked down, feel free to reply to me
privately and we can figure out the details.
         --dkg

@_date: 2019-06-26 01:34:56
@_author: Daniel Kahn Gillmor 
@_subject: Infinite loop? 
i'm glad you have a sense of humor about it, but this sounds
unacceptably slow to me.  --list-keys isn't even doing any cryptographic
processing, right?  the timing you show above suggests that --list-keys operates at ~100
keys per minute, or not even 2 keys per second.
And why on earth is so much time spent in the kernel?  for my own run,
the breakdown is:
real	0m17.555s
user	0m17.367s
sys	0m0.184s
But yours appears to have > 50% of its time spent in "sys".  Can you use
strace -T or some other profiler to see what system calls it's making
that makes it spend so much time in the kernel?
numbers like 5K keys and 241MiB are not large for a machine of this
caliber.  my own kbxutil --stats looks like:
Total number of blobs:     4166
               header:        1
                empty:        0
              openpgp:     3787
                 x509:      378
          non flagged:     4165
       secret flagged:        0
    ephemeral flagged:        0
If you import your larger keyring on the X1 Carbon, what is the output
of "time gpg --list-keys > /dev/null" there?
If the issue is just a large keyring, i can generate that myself pretty
easily, thanks.  I was concerned by the OP that there was an acual
infinite loop somewhere.  But if the run is just taking a long time
because of unoptimized code, we should try to address that as a separate
        --dkg
ps fwiw, i think even 17s is too long for my own 4K keys, esp. with a
   hot fileysystem cache.  that's still only ~220 per second, but it's
   managable, and i've had enough other things i want to get fixed in
   GnuPG that i haven't dug in too deeply to see where the problem is or
   how it could be sped up.  But it's nothing near the order of
   magnitude that you're describing.

@_date: 2019-06-26 07:03:19
@_author: Daniel Kahn Gillmor 
@_subject: gpg-agent systemd user service [was: Re: GnuPG and SSH_AUTH_SOCK 
That's correct, systemd depends on the Linux kernel, and does not run on
Sorry that the thread diverged that far from your original request.
     --dkg

@_date: 2019-06-28 04:23:29
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG and SSH_AUTH_SOCK value 
Can you give more details?  I know that some older systems did rely on X
or startx or something being setuid, but i think more modern systems
don't require that.  On a debian testing (buster) system, for example, i
don't believe that any of the binaries are suid.
      --dkg

@_date: 2019-06-28 08:53:41
@_author: Daniel Kahn Gillmor 
@_subject: GnuPG and SSH_AUTH_SOCK value 
I also use startx on buster systems, but i don't have
xserver-xorg-legacy installed, so i think this is not the strict
dependency it sounded like originally.  I know that i used to depend on
a setuid X server, so i'm gratefuly to the folks who did the work to
remove that setuid requirement!
Anyway, i think we're pretty far off-topic here, so i'll drop off this
thread, just wanted to confirm that i hadn't missed something.
all the best,
    --dkg

@_date: 2019-06-30 13:06:25
@_author: Daniel Kahn Gillmor 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
so, how do we get there?
WKD is mighty nice, but it is not necessary.  For example, if you don't
care about first-contact, Autocrypt is a totally reasonable key
discovery mechanism.  It also has a significantly reduced metadata
footprint compared to WKD or DANE OPENPGPKEY, since all messaging is
It has other problems, of course, but it can be used directly today (not
just "short to medium term").
If you know something specific about Apple failing PGP/MIME in some
capacity i hope you'll be more explicit about it, because i don't know
what you're talking about.
Of course they're both search engines and storage rpositories, and they
are not and have never been authoritative.  Anyone who claimed
keyservers were authoritative in the past was either confused or
misleading you.
i'd be curious to read any specific guidance about how you think a
sensible keyserver would make those decisions.  If you want to propose
changes to
i'd be happy to incorporate them too.
    --dkg

@_date: 2019-03-01 01:45:33
@_author: Daniel Kahn Gillmor 
@_subject: gpg vs gpgv and trustedkeys 
You could write a small script or binary for your system that knows
about the specific location for the curated keyring and wraps the
invocation of gpgv.  Then encourage those engineers to use your wrapper
rather than gpgv directly.  This has the added advantage that you can
enforce additional policy (e.g. "--weak-digest sha1", or
timestamp-specific enforcement based on --status-fd, etc) in the wrapper
itself, and roll out that policy without retraining people.
fwiw, if you're checking cryptographic signatures, i *strongly*
recommend caring about precise control.  "works as expected" is a pretty
sloppy test -- often people will think it just means "approves
legitimately-signed files".  But for strong cryptographic verification,
you really also need to know that it "disapproves all else", right?
The "trust" that gpg knows about in its keyring is "willingness to rely
on OpenPGP certifications made by the keyholder".
This is entirely orthogonal to "willingness to accept a data signature
in some specific context".
frankly, i agree with you that the existence of gpgv's default
"acceptable certificates for making data signatures" --
~/.gnupg/trustedkeys.{kbx,gpg} is a dubious feature.  If i'm checking a
signature on software package X, i care *very much* that it's not just
signed by any key i know about, but by (one of) the key(s) that is
associated with the authors of software package X.  Likewise, i'm also
checking on a new upstream release of software package Y, i *don't* want
the authors of X to have any say in the matter.
     --dkg

@_date: 2019-03-01 17:01:46
@_author: Daniel Kahn Gillmor 
@_subject: Using gpg in an automated environememt 
Hi Geoffrey--
In the future, if it's possible, please send the text of such a
screenshot as text.  it makes it easier to index, to search, and to
reply to.
I think you're talking about this part of the FAQ:
   It looks to me like you might not have followed step 4:
     Copy secring.auto and the public keyring to a test directory.
but i confess i also don't really understand this entry in the FAQ.  it
looks overly complicated to me, and seems to expect there to be a
"secret keyring", which is decidedly not the case for any modern version
of GnuPG. (modern GnuPG stores its long-term secrets in
~/.gnupg/private-keys-v1.d/ )
Perhaps if you could explain more about what you're trying to do,
someone here could point you to documentation that suits your goals
all the best,
        --dkg

@_date: 2019-03-03 11:53:49
@_author: Daniel Kahn Gillmor 
@_subject: gpg vs gpgv and trustedkeys 
right.  If you have the capacity to make a thoughtful design of the
internal image validation script (both its API and its internal
codebase), then the validation script itself can serve as useful
tooling and explanatory guideposts for your engineers.
This is an interesting suggestion, and i wonder whether GnuPG upstream
would be willing to consider it for some API-breaking new revision of
gpgv (or some alternate signature-verifying tool).
I've proposed a new process-level OpenPGP signature-verifying API over
    and you're right, it doesn't assume a default keyring, but rather
requires an explicit designation of which keys are acceptable.
I agree with you that the documentation should be improved, and i think
that upstream would welcome patches to that effect.
I've just submitted one improvement (to documentation about gpgv's
keyring selection) here:  One path toward actually deprecating the default keyring would be to
warn if the default keyring is used, probably in main() in
yikes.  I can imagine some unusual circumstances where that would be
reasonable, but it sounds particularly dangerous in contexts where you
care about who the signature comes from.
The best way to create a set of keys that can validate is to explictly
and deliberately *export* (not import!) the keys that you know you care
about into a file.
so, verify that you get *only* the keys you want:
    gpg --list-keys $FINGERPRINT
and then if it looks good:
    gpg --output curated.pgp --export $FINGERPRINT
then you can pass curated.pgp to gpgv's --keyring argument.
Note that gpgv has weird non-standard semantics for its --keyring
argument, though -- if the filename has no "/" in it, it's assumed to be
found in the homedir (typically, ~/.gnupg/), rather than in the current
working directory, so i always specify keyrings with an absolute path.
in the shell, you can often launder it through realpath(1), so this
should be safe, regardless of how $KEYRING gets set:
    KEYRING=curated.pgp
    [?]
    gpgv --keyring "$(realpath "$KEYRING")" "$signature" "$object"
Note also that the semantics of gpgv's return value may not match what
you want.  In particular, they make it difficult to ship additional
signatures during a time of key transition, because gpgv will return
non-zero if *any* discovered signatures are "bad" [0]. Additionally, gpgv
has some odd semantics around key creation time, expiry, revocation,
    So you really do want to use --status-fd and parse its output to
determine what happened, and not just rely on its return code.
          --dkg
[0] explanation of the lifecycle of a signed series of updates:
 * at time T, clients fetch update U_T with signature bundle S_T.  the
   clients all verify that S_T is signed by one of the keys they know
   about.
 * initially, all clients know only about signing key K_0.
 * So, at early time A, a client fetches update U_A and signature S_A
   and verifies that S_A is made by K_0.
 * at some future time B, the authors introduce a new signing key K_1,
   but not all clients know about it yet.  S_B contains signatures from
   both K_0 and K_1.  Unupdated clients verify S_B over U_B based on
   K_0, while updated clients verify S_B over U_B based on K_1.
 * later, at time C, once all clients are known to be updated (or are
   explictly unsupported), the authors drop or revoke or destroy K_0,
   and sign new updates only with K_1.
between times B and C, any verification mechanism that depends on gpgv's
return code will break for clients that don't know about *both* K_0 and
K_1.  This requires software vendors to ship their preferred signing
keys well before they start actually distributing signatures with them,
which is a surprising workflow.

@_date: 2019-03-09 18:05:35
@_author: Daniel Kahn Gillmor 
@_subject: Multiple dev one signing key 
This really depends on the development workflow and practices of your
team, and the security requirements of your users.  So there's no one
clear answer.
 * Does your team have a single release manager, who is responsible for
   deciding when a release is fully-baked?  If so, let the release
   manager hold the signing key, and no one else.
 * Do many different people cut releases in your team?  If so, you
   could:
    a) share a secret signing-capable subkey among all the people who
       make releases
    b) if the primary key is signing-capable, share the associated
       secret key among all the people who make releases.
    c) make an OpenPGP certificate with multiple signing-capable
       subkeys, one per release operator
 * Do you you need *multiple* people to sign off on a release?  In that
   case, you might need some fancier approach (or you might need to
   modify how your users or downstreams are expected to verify the
   releases).
Does this make sense?  Sorry to not have One True Answer? for you!
     --dkg

@_date: 2019-11-09 15:39:15
@_author: Daniel Kahn Gillmor 
@_subject: A place for discussing WKD spec clarifications? 
I spoke with Werner about this last week, and he agreed that gitlab was
a reasonable place for the discussion.
I've just set up  for this
purpose -- it has an issue tracker and a proposed git repo (though it is
of course up to Werner whether he wants to use that git repo or keep
with the gnupg-docs repo for this draft).
I'll follow up with more details on openpgp at ietf.org, because i think
this draft is important for the entire OpenPGP ecosystem, not just
        --dkg

@_date: 2019-10-16 14:49:50
@_author: Daniel Kahn Gillmor 
@_subject: GPG Agent discarding cache before ttl/max ttl 
It would be great to learn what the most common lid-closing events on
popular platforms are, so that gpg-agent can do this cache-flushing
behavior automagically at least for users on those platforms.
On systems with D-Bus, following the freedesktop.org IPC standards, it
looks like the following signal appears on the system bus when the
machine goes to sleep:
destination=(null destination) path=/org/freedesktop/login1; interface=org.freedesktop.login1.Manager; member=PrepareForSleep
   boolean true
Debian systems these days typically use the dbus standard -- and i'd be
happy to try to integrate detection of this signal into the debian
gpg-agent packaging, if anyone wants to propose a way to do it. i'm not
a D-Bus guru by any stretch of the imagination, so i'm not sure what the
right next step is, guidance is definitely welcome.
This is the default, but its presence in gpg-agent's configuration file
is also used as a signal in some OSes (debian at least) as for whether
to export an SSH_AUTH_SOCK that points to gpg-agent's ssh-agent
emulation socket.  See /etc/X11/Xsession.d/90gpg-agent for more details.
        --dkg

@_date: 2019-10-16 14:30:09
@_author: Daniel Kahn Gillmor 
@_subject: A place for discussing WKD spec clarifications? 
WKD is a useful spec, and an increasingly important part of the OpenPGP
If we want general e-mail discussion about WKD concerns, i'd suggest
using the openpgp at ietf.org mailing list, as it will reach implementers
of more WKD clients than just gnupg-users.
That said, e-mail discussion is not the same as a tracker that allows us
to keep a list of currently-known issues and concerns.
If  is not appropriate for that sort of issue
tracking, perhaps we could set up an issue tracker on gitlab associated
with the WKD spec?  I'd be happy to set up such a tracker at (say)
 if folks are OK
with it.
Werner, does that sound OK to you?
As usual for any IETF-related interoperability discussion, i'd expect
any major issues to *also* go to the mailing list for visibility and
robust archiving, but i think that having an actively-maintained,
publicly-accessible issue tracker related to this important work would
be concretely useful.
        --dkg

@_date: 2019-10-22 21:25:15
@_author: Daniel Kahn Gillmor 
@_subject: are angle brackets around email address allowed for 
Yes, i can confirm the same misbehavior with GnuPG 2.2.17 (though i
don't think that edward-en at fsf.org is actually correctly published via
WKD, so i tested with dkg at fifthhorseman.net):
130 dkg at alice:/tmp/cdtemp.pipIPp$ gpg -e  -r '' foo.txt gpg: : skipped: No public key
gpg: foo.txt: encryption failed: No public key
2 dkg at alice:/tmp/cdtemp.pipIPp$ gpg -e  -r 'dkg at fifthhorseman.net' foo.txt gpg: removing stale lockfile (created by 29177)
gpg: key F20691179038E5C6: "Daniel Kahn Gillmor " 1 new user ID
gpg: key F20691179038E5C6: "Daniel Kahn Gillmor " 8 new signatures
gpg: Total number processed: 1
gpg:           new user IDs: 1
gpg:         new signatures: 8
gpg: no ultimately trusted keys found
gpg: B0A9B7B2D8D2CE47: There is no assurance this key belongs to the named user
sub  cv25519/B0A9B7B2D8D2CE47 2019-01-19 Daniel Kahn Gillmor  Primary key fingerprint: C4BC 2DDB 38CC E964 85EB  E9C2 F206 9117 9038 E5C6
      Subkey fingerprint: 88DE 0083 5288 C784 E73A  C940 B0A9 B7B2 D8D2 CE47
It is NOT certain that the key belongs to the person named
in the user ID.  If you *really* know what you are doing,
you may answer the next question with yes.
Use this key anyway? (y/N) y
0 dkg at alice:/tmp/cdtemp.pipIPp$ Yes, in the future, please report this sort of bug directly so that we
can track the problem.  i've opened  now --
please add any additional information there!
Thanks for the report,
     --dkg

@_date: 2019-10-22 21:28:53
@_author: Daniel Kahn Gillmor 
@_subject: A place for discussing WKD spec clarifications? 
Werner, can you give some indication of whether this sounds reasonable
to you?  This is an important spec, and i'd like to have a place where
we can keep track of implementer concerns.
        --dkg

@_date: 2020-05-28 15:35:49
@_author: Daniel Kahn Gillmor 
@_subject: gpgsplit/pgpdump replacement 
pgpdump was never part of GnuPG, it ships in its own package.
The gnupg-utils package contains /usr/bin/gpgsplit.
For more detailed examination of OpenPGP-related objects, in addition to
the other free software projects mentioned on this thread, you might
also be interested in python3-pgpy (if you are comfortable with python).
   --dkg

@_date: 2020-10-13 13:02:24
@_author: Daniel Kahn Gillmor 
@_subject: Show that an encrypted message was signed, without decrypting it 
The traditional answer for supporting this kind of workflow for e-mail
is called "triple-wrapping" -- see RFC 2634.  That is, there is an inner
signature, then a layer of encryption, and an outer signature that is
intended to be visible to the transport agents handling the encrypted
message.  Those transport agents (or procmail, or autoresponders, or
whatever) may may routing or handling decisions based on the outer
signature without any knowledge of the inner signature.  However, i have
not seen triple-wrapping in wide-spread, interoperable use.  Most MUAs i
have experience with do not generate triple-wrapped messages, and i've
found very few transport agents that interpret using them.  IIUC, the
only triple-wrapping implementations out there use S/MIME cryptographic
e-mail, not PGP/MIME.
More common on today's e-mail interactions is "Domain-keyed Internet
Mail" or DKIM -- see RFC 6376.  This is a cryptographic signature over
the entire message that is typically added by the sender's relaying
transport agent -- the first transport agent that handles the e-mail
Subsequent transport agents can verify the DKIM signature using the DNS
as a form of proof-of-origin (typically, this is managed at the domain
level, though domain operators may carve up the "selector" space for
outsourced transports, or may also permit users to manage their own
selectors [0]).  This isn't exactly the same as an individual sending a
message that is signed by the message origin, because DKIM signing tends
to happen away from the originating endpoint.  But for spam abatement
and reputational systems, knowing that a message is signed by the domain
itself is often good enough in practice.
[0]     So there isn't really a good (or reasonable) way to do what you're
asking for with OpenPGP directly.  Given that mail is a complicated
interoperability space, you're probably better off conditioning your
procmail filters or autoresponder based on DKIM signature validity
(though i advise reading and understanding the associated DMARC
specifications before choosing to aggressively reject mail).
Hope this helps,
     --dkg
