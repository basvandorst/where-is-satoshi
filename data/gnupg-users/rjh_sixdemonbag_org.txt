
@_date: 2006-04-02 00:07:46
@_author: Robert J. Hansen 
@_subject: ElGamal: key length vs performance 
This one can best be answered with a giant "it depends".
GnuPG is a hybrid cryptosystem.  It uses both symmetric and asymmetric
cryptography to encrypt your file.  The asymmetric component is going to
be dog slow, but the good news is that only a few bytes of data are
encrypted with it.  The rest of your file is decrypted using symmetric
crypto, which is really quite fast.
For small files, the asymmetric component will take up most of the time
and it makes sense to ask how encryption/decryption times vary with key
lengths.  For large files, the symmetric component will dominate, and it
won't make sense to ask how encryption/decryption times vary with key
The best general advice I can give you is "this isn't something you need
to worry about".  Even with a 4kbit key on an old Pentium-II, the
asymmetric operations are fairly brisk.  It's quite usable.

@_date: 2006-04-03 02:05:07
@_author: Robert J. Hansen 
@_subject: Meaning of rvk in --fixed-list-mode? 
When looking over the output of --fixed-list-mode --with-colons
--list-sig, I discovered that one key which has a designated revoker
listed did not have a "rvk:" row in the key output.
According to doc/DETAILS, rvk is used to designate revocation keys.
So... what am I missing here?  What are the precise semantics for rvk?

@_date: 2006-04-10 01:43:59
@_author: Robert J. Hansen 
@_subject: More questions about: "gpg: WARNING: message was not integrity 
Forgive me for being pedantic, but I'd like to make a small
clarification here for the benefit of people who don't understand what
key sizes mean.
The key is twice as large.  That doesn't mean there are twice as many
keys.  It has considerably more than that.
AES256 has about 100,000,000,000,000,000,000,000,000,000,000,000,000
times as many possible keys as CAST5.  The difference between the two is
almost incomprehensible.
Again, apologies for the pedantry.  :)

@_date: 2006-04-24 05:47:32
@_author: Robert J. Hansen 
@_subject: Modifications to key 
No apologies necessary.  Welcome to the GnuPG community.  :)
Same answer--yes, it will change your key; no, it will not render it
useless.  If something is added to the key, it doesn't invalidate
existing copies of the key.  They'll still work perfectly fine.
As an example, let's say that I have key 0x5B8709EB on my website for
download.  (I do, so this isn't too much of a stretch.)  Let's say that
I want to add a user ID.  I do so, and after modifying the key send it
on to the keyserver.  Someone who gets my key from the keyserver will
get the updated version with the new user ID on it; someone who gets my
key from my web page will get the old version without the new user ID;
but both keys can be used to encrypt messages to me, or to verify the
messages I sign.
If you have any other questions, feel free to holler.  :)

@_date: 2006-08-02 01:40:16
@_author: Robert J. Hansen 
@_subject: solaris certification 
An answer is already found in the GNU General Public License, where it
basically says there is no warranty whatsoever.
If you need a single throat to strangle in case things go wrong and your
high-availability system goes astray, you may wish to consider
contracting with g10 Code, who will be better able to provide you with
things like warranties and guarantees of functionality and merchantability.

@_date: 2006-08-15 08:27:51
@_author: Robert J. Hansen 
@_subject: GPG and 1024-bit (or multiple) subkeys 
GnuPG defaults to 2048 bits for new RSA and El Gamal keys.  (It may
default to 2048 for DSA now, as well; if so, this is a new addition in
the last few weeks.)
However, there's nothing in GnuPG that prohibits the use of shorter keys.
Not especially.  Subkeys don't exist in isolation.  They only exist as
part of a larger key.
Your customer's request doesn't appear to be particularly well-phrased.
 That's going to limit any help anyone on the list can provide.

@_date: 2006-08-19 21:36:03
@_author: Robert J. Hansen 
@_subject: Don't store your key on a flash drive! [was Re: GnuPG (GPG) 
Let's not use the word 'compromised'.  Let's call it 'loss of control'.
If I leave my wallet on my desktop for an hour while I go to a meeting,
are my credit cards compromised?  I think we'd agree that they're
probably not.  If I get mugged and my wallet stolen, are my credit cards
compromised?  I think we'd agree that they are.
Compromise usually means not only a failure of access controls, but a
strong likelihood of unauthorized persons exploiting the failure of
access controls.
Losing a dongle doesn't necessarily mean it's been compromised.  It
means you have a problem, yes, one that's in need of addressing, but it
doesn't necessarily call for a key revocation.
Having a revocation certificate is totally unrelated to the issue of
whether one uses a USB dongle or a cryptographic card.
The entire point of a passphrase on a key is so that even if the
attacker _does_ have a supercomputer cluster it will be of no use.  An
OpenPGP card may allow you to get away with a weaker passphrase, but
there's nothing inherently dumb about putting a private key on a USB
dongle as long as the passphrase is sufficiently strong.
Given the choice between trusting flash memory to wipe itself, and
trusting that strong cryptography is going to stand up to even dedicated
cryptologic attacks, I'll put my money on the latter any day of the week.
I have a two gig USB dongle on my (physical) keyring right next to my
car and office keys.  If that gets stolen, trust me: I'll know.  Whereas
if you were to go through my wallet and randomly pilfer one of my cards,
I might not know it for a while: while I use my ATM card almost daily, I
can't remember the last time I needed to pull out my amateur radio license.
What it boils down to is this: there are no silver bullets.  There is
more than one way to do it.  If the OpenPGP card works for you, then
great, go for it.  But if the OpenPGP card doesn't work for someone
else, then you're wasting their time by telling them "oh, don't do that,
use an OpenPGP card."
Speaking for myself, I have doubts about the long-term security of
RSA/1024.  I much prefer RSA/2048 instead.  Thus, the OpenPGP card fails
to meet my own security policy... whereas storing a copy of my private
key on my USB dongle, with a high-security passphrase, is a far better
solution than an OpenPGP card.

@_date: 2006-08-20 16:12:32
@_author: Robert J. Hansen 
@_subject: GnuPG neophyte inquiries. 
We can't answer this question with a 'yes' or a 'no'.  Decisions about
security are up to you.  We can hopefully give you some questions which
will help you make your decision, though.
1.  Do you trust your roommate?
2.  Do you trust Windows XP?
If both questions are answered 'yes', then it's very unlikely sharing a
Windows XP box with your roommate would present a security concern.  But
if you don't trust your roommate, or you don't trust Windows XP, then
pretty much anything you do on your PC needs to be considered
suspect--not just GnuPG.
Usually, you run GnuPG on the same machine you receive email on.  If you
do that, then there are many mail clients that offer excellent GnuPG
integration.  (Shameless plug: Mozilla Thunderbird, available from
 has a GnuPG plug-in called Enigmail, available from
  I have had excellent results with this setup.)
That depends on what security issue is discovered.  If it's a bug in how
the keys are generated or stored, then you may have to generate a new
pair.  If it's a bug elsewhere in GnuPG, then your keyring, public key,
private key, configuration file, etc., will be absolutely unchanged.
Bugs of the first sort are very rare.  To my recollection there's only
been one such bug since GnuPG hit 1.0, and it affected only about 1,000
You may want to look into something called Portable Thunderbird, which
is a Thunderbird + Enigmail installation meant to be run from a flash
drive.  Without knowing particulars of your environment it's hard to
give you simple answers, but I can tell you that many people use
Portable Thunderbird in such environments with strong success.
However, I'd strongly recommend keeping anti-virus software on your home
PC and checking your flash drive for infection whenever you come back
home after using a campus PC.  University computers tend to be breeding
grounds for all sorts of nasty things.

@_date: 2006-08-20 16:16:38
@_author: Robert J. Hansen 
@_subject: Don't store your key on a flash drive! [was Re: GnuPG 
... I'm sorry, I'm scratching my head over here trying to figure out how
a flash drive doesn't also share these properties.  In fact, given the
limited space available on a smartcard, the limited application support
for them, etc., it seems flash drives are the clear winner in this context.

@_date: 2006-08-21 12:53:21
@_author: Robert J. Hansen 
@_subject: Don't store your key on a flash drive! [was Re: GnuPG 
All of which is true.  However, the bit to which I was replying was:
"A smartcard is very convenient as far as it's a multi application
device, so you can store much other info apart from GnuPG keys, i.e.
Mozilla passwords or such."
... And I'm still trying to figure out how that's different from a flash
drive.  Maybe there is a difference and I'm not seeing it.  Or maybe
there isn't one.

@_date: 2006-08-21 14:53:15
@_author: Robert J. Hansen 
@_subject: Don't store your key on a flash drive! [was Re: 
Alphax wrote
A few years ago Rainbow Technologies came out with a device they called
the iKey.  Smartcard with a USB connector, about the same form factor as
a car key.  Lovely hardware, but programming for it is a bear.

@_date: 2006-08-21 14:58:19
@_author: Robert J. Hansen 
@_subject: Don't store your key on a flash drive! [was Re: 
... and in a follow-up to my own follow-up, apparently Rainbow got
bought out by SafeNet.  The iKey is still available and the specs
haven't changed from the last I used them some years ago.  They're handy
little devices.  Any possibility of supporting this from GnuPG?  If so,
it might be a good compromise between smartcard and flash-based solutions.
Of course, it still only supports RSA/1024.  Sigh.

@_date: 2006-08-23 08:17:20
@_author: Robert J. Hansen 
@_subject: why cissp says this about PGP/GnuPG? 
Be warned that the CISSP certification is not universally loved.  Many
people feel that it is of dubious quality.
Excellent question, given that AES has been certified for use with TS
material, and the recent SHAs are on the fast track for similar
approval.  I think this reflects more the prejudices of the book author
and/or the CISSP exam than it does actual reality.

@_date: 2006-08-24 16:49:29
@_author: Robert J. Hansen 
@_subject: why cissp says this about PGP/GnuPG? 
Many.  Google for "CISSP criticisms" and you'll find a lot of reasons to
suspect the CISSP, along with some well-regarded alternatives to it.
CISSP nominally requires four years of industry experience in computer
security before they'll grant a cert, but in reality their definition of
"industry experience" is very broad and permissive.  I'd much rather
judge someone on the basis of the industry experience they used to get
their CISSP than I would on the basis of the CISSP itself.
This is not true.  The OpenPGP standard was designed to stand up to
absolutely brutal cryptanalytic attacks.  When it comes to email
cryptography standards, OpenPGP really is the gold standard.
I don't mean to sound sarcastic or caustic, but I really wish people who
advocate steganography would first read the academic literature on it.
I'm fond of Moulin and O'Sullivan's "An Information-Theoretic Analysis
of Data Hiding".
Steganography does not have a strong theoretical foundation.  As such, I
think it's dangerous to think steganographic implementations are ready
for prime time.

@_date: 2006-08-28 05:37:37
@_author: Robert J. Hansen 
@_subject: Help! Gnupg can't run in php program 
Hash: SHA512
In which .gnupg directory, though?  Your web server probably runs as a
different user.

@_date: 2006-12-05 12:20:16
@_author: Robert J. Hansen 
@_subject: Questions from a newbie 
No.  I use a set of RSA keys to encrypt and sign data.  All that it
means is you need to create your set of encryption keys in a separate
step from creating your signing keys.
When creating DSA/Elg keys, both the signing and encryption keys are
created at the same time.  RSA keys are created differently.  Don't
really know why it's that way, but that's the way it is.
The term 'Elgamal' has an unfortunate multitude of meanings.  It refers
to the Egyptian-American researcher Taher el Gamal, whose name has been
Americanized as Elgamal.  He did a lot of fundamental research into an
entire family of cryptographic algorithms, which have since been called
the Elgamal family.
Elgamal is also used to describe a particular algorithm within the
Elgamal family.
The Digital Signature Algorithm, DSA, is part of the Elgamal family.  So
when you see "DSA and Elgamal", please don't think of them as two
different algorithms; think of them as two very closely related algorithms.
Anyway.  You were wondering if the Elgamals are equally secure to RSA.
The short answer is the Elgamals are believed to be comparable to RSA.
Or maybe we should say RSA is believed comparable to the Elgamals.
Either way, they can be used with confidence.
PGP 5.0 or better, yes.
No, they would not.
The secret key is stored in an encrypted format.  The passphrase is
needed to decrypt the secret key so that GnuPG can then use it.
The cipher used to encrypt the secret key is of comparable strength to
the cipher used to encrypt a PGP message.  This means that as long as
your passphrase is strong, you could publish your secret key in the _New
York Times_ and still be confident that nobody would be able to read
your email.
For this one, we need to know what operating system you're using.

@_date: 2006-12-05 20:01:01
@_author: Robert J. Hansen 
@_subject: encrypt the sent folder 
This is not a task for GnuPG.  This is a task for an encrypted file
system.  On OS X, look into using encrypted home directories (System
Preferences-->Security).  On Windows, I've found TrueCrypt to be a
pretty good solution.  On Linux, look into cryptoloop.
It does.  You need your IMAP server to run the encrypted file system.

@_date: 2006-12-05 21:28:21
@_author: Robert J. Hansen 
@_subject: encrypt the sent folder 
There isn't.
If you want a program that does this, you're going to need to write it
yourself.  It seems like it could be done in just a couple of hours of
Perl.  But once you do that, you're going to need to hack on
Enigmail/Thunderbird in able to support text searches through encrypted
data, then you're going to need to... etc., etc.  It's a nontrivial
amount of work.
Also remember that OpenPGP is a wire protocol.  The protocol is not
meant for mass storage.  Sure, you can use GnuPG to encrypt files, but
once you start dealing with large numbers of them you're generally going
to be better off using a system that's purpose-built for the task.
Like, say, an encrypted filesystem.

@_date: 2006-12-05 21:50:44
@_author: Robert J. Hansen 
@_subject: encrypt the sent folder 
I probably should have said 'primarily'.  It wasn't my intent to give
the impression it was exclusively a wire protocol.
In other ways it doesn't work very well, since each email is encrypted
separately, requiring complex bignum math for each decryption.
Searching through large numbers of emails could potentially be very
Compare this to an encrypted filesystem, which is typically much more

@_date: 2006-12-05 23:04:52
@_author: Robert J. Hansen 
@_subject: Christmas is upon us again. 
Hash: SHA256
Whether you're secular or religious, atheist or devout, I think we can
all agree that the time of the year known as Christmas will soon be upon
us.  This is historically a time for personal reflection and charitable
giving.  We reflect on how fortunate we are, and we give in order to
show our thanks and appreciation for that which we have received.
This year, I'm grateful that we have a Free Software implementation of
the OpenPGP protocol.  I'm also grateful that the development process is
fairly open and I'm grateful that, by and large, the people in the
community are friendly.
This year, I'm giving $10 to the Free Software Foundation
( in the name of the GNU Privacy Guard, as my way of
telling the developers "thanks".
If you feel like joining me in this, well... feel free to say thanks
on-list, or to write off a note to the developers.  Likewise, I hope
you'll give a small donation to the charity of your choice in the name
of the GNU Privacy Guard.
Merry Christmas to everyone.  May we have peace on Earth and goodwill to
all humanity.

@_date: 2006-12-06 12:12:06
@_author: Robert J. Hansen 
@_subject: encrypt the sent folder 
Hash: SHA256
Your best alternative at this point is to hire a professional
information security consultant.  Your needs are highly specialized.
That means that nobody here can give you good advice on what to do,
since none of us here are fully briefed on your infrastructure, your
operations, your business, your threats, or any of the other dozens of
things that go into a risk management plan.
You're also going to need to address problems with public-key
infrastructure if you want to deploy this for your employees.  PKI is
the big elephant in the middle of the room that nobody talks about;
existing PKI designs are, speaking generally, absolutely terrible.
Deploying PKI is something you'll want a specialist for.
GnuPG is a tool.  It is not a solution.

@_date: 2006-12-06 16:13:21
@_author: Robert J. Hansen 
@_subject: encrypt the sent folder 
Infeasible: "we have the manpower, we have the tools, we have the
talent, but the architecture is working against us in a big way."
Unreasonable: "our manpower is stretched so thin that all infeasible
RFEs are unreasonable expectations of us."
As is unfortunately common with open-source projects, there's a major
lack of manpower on Enigmail.  If you know Javascript and would like to
get your hands dirty with Enigmail, why not volunteer over on the
Enigmail list?  :)

@_date: 2006-12-07 16:56:38
@_author: Robert J. Hansen 
@_subject: Problem building 2.0.1 
Minor correction; OS X 10.4 has iconv already.  For 10.3 and previous,
iconv is not part of the operating system.

@_date: 2006-12-18 20:11:23
@_author: Robert J. Hansen 
@_subject: Very Newbie Questions 
Henry, this response would've been considerably better if it had been
considerably shorter.  As it is, it's a very hard read.  For that
reason, I'm going to confine my remarks to just one thing.
Your typical OS X application will not use these.  A well-packaged OS X
application typically installs into /Applications as a self-contained
bundle.  Resources and the like typically go into /Library or $HOME/Library.
typically native OS X apps use other locations instead.

@_date: 2006-12-18 21:43:32
@_author: Robert J. Hansen 
@_subject: Very Newbie Questions 
Some of this is probably going to sting.  If it does, it does so only
because I was not able to find a kinder way of expressing the same level
of accuracy.
A good rule in writing instructions is to aim for 95% of the users, and
tell the other 5% of the users where they can find the specialized
information they need.
John's advice (which, if I understand correctly, boils down to "let the
installer do its magic") is very simple and covers the needs of 95% of
users.  That makes it reasonably good advice.
Your advice is much more technically detailed and much more demanding of
the user, all so you can cover a few users more.  Not only that, but how
many users will in the course of these instructions completely screw up
their box, and then come here saying "I tried to do these instructions
and it failed, now somebody help me figure out how to undo it"?
All this makes it bad advice.  You're sacrificing enormous amounts of
simplicity just so you can cover epsilon more users.
Don't spam people with unnecessary detail.  If they have special needs,
they'll come back here and ask.  It's what this mailing list is for.
As soon as you're the one asking for help, then we'll be happy to give
you advice that takes into account your needs.
Nobody's asking.  Nobody cares.
We've been saying this in computer security for thirty years or more.
This mantra has done us very little good.
So how about if I drop the PKCS1-1.5 standard in your lap, a good
reference on the untyped lambda calculus, RFC2440, the FIPS that specify
SHA-1 and DES, and tell you to write your own OpenPGP implementation
from nothing more than raw Assembly instructions and the S- and
After all.  That's laying it all out for you.
This is an absurdist argument.  It's absurdist for a reason: if you're
going to say "best to lay it all out for them and allow them to make
their own decisions", that's what lies at the end of that road.
Clearly, some things should be beyond the realm of the end-user.  The
only question is where we put that marker.  You want to carry that
marker far, far further on down the road than I think is necessary, or
even safe.
If you don't trust Microsoft to get it correct, then stop using
Microsoft products and advise other people to do likewise.
If you don't trust a vendor, then there is literally no level of
precaution you can take which will make that vendor's products
It is morally disingenuous of you to give advice on how to "secure" a
system you believe to be inherently insecure.
How is this Windows-specific advice?
Best for whom?  I distrust almost all broad, sweeping generalizations
about security.
Please cite chapter and verse for this.  When you describe it as
"correct", that strongly implies there's some authoritative reference
that says what's right and wrong.
There may be an authoritative reference saying this is correct.  If
there is, I would like to see it for myself.
Sturgeon's Law: 90% of everything is crap.
Sturgeon's Corollary: There are no guarantees about the remaining 10%.
Just because 90% of Win32 programs do something doesn't mean it's right.
 It could just be a very widely-held stupidity.  Most professional
programmers have seen enough of these widely-held stupidities to be very
cautious about making any definitive statements about good practice just
on the basis of what the other guys are doing.
Please be careful when you speak for the community.  The outside world
judges us not on the basis of our best advocates, but on the basis of
our worst.  If you're going to speak for the community, please keep your
remarks brief, clear, and so obviously true that few people would
disagree with them.
This is something that Eben Moglen is excellent at.  If you've never
attended one of his talks, he starts off with simple statements that
everyone can agree with, and shows how following those statements leads
directly to the ideals of free software.

@_date: 2006-12-23 13:51:01
@_author: Robert J. Hansen 
@_subject: controlling the use of subkeys 
This may be bad policy on your part.  The average Gentoo user is not
going to be an expert on cryptography or the OpenPGP protocol.  Keeping
things as simple as possible for them is probably better than getting
clever with subkeys, especially since there are some interesting edge
cases there.
Generally speaking, people don't sign keys; they sign user IDs.
Use the "!" symbol to explicitly specify a subkey.  E.g.,
"gpg -u 0x205D3103! --clearsign ..."
I would suggest rethinking your strategy, however.

@_date: 2006-12-23 19:11:57
@_author: Robert J. Hansen 
@_subject: controlling the use of subkeys 
The best way to minimize management is to reduce the amount of stuff
that needs to be managed.
There almost certainly exist specialized applications where key expiry
makes a lot of sense.  But in general, I think most people who set their
keys to expire do so without really thinking about what clear benefits
it gives them, or what specific problem of theirs it will solve.
If you can point to a specific requirement or need of the Gentoo
community which key expiry will help address, then by all means, go for
it.  Otherwise, simplify your management by removing expiries.

@_date: 2006-12-23 19:50:42
@_author: Robert J. Hansen 
@_subject: controlling the use of subkeys 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
This is not the case.  The only (required) binding between a subkey and
a UID comes from the fact that each UID has a self-signature.  If you
create a new subkey, there's no explicit binding between that and a UID.
I hate to sound like an arrogant son-of-a-so-and-so, but it sounds like
you're attempting to do complex things with OpenPGP without
understanding OpenPGP very well.
My suggestion: figure out exactly what you need it to do and send it on
to the list.  If you need more than one sentence to do it, you may not
understand your basic problem very well.
For instance: "End-users need assurance that the package is really part
of Gentoo."
Or, "I need some way to separate my Gentoo maintainer identity from my
personal identity."
Or... etc., etc.
Come up with a single sentence describing your problem, and you'll get a
ton of responses by people with ideas for how to solve it.  After a
while, you'll see some consensus emerge about which ideas have merit and
which are the products of overactive imaginations.  (This being the
internet, there may be a lot more of the latter than the former.)
Then choose the simplest, most clearly-explained idea which has merit.

@_date: 2006-12-23 20:33:50
@_author: Robert J. Hansen 
@_subject: controlling the use of subkeys 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
When you start doing advanced and sophisticated things with a tool, you
need to invest the time in understanding that tool.  This is true for
pretty much any tool, not just GnuPG.
This is sensible.
This strongly counter-indicates using a new subkey.
After all... when someone sees a signature with your new subkey, they'll
then have to find the master signing key and import that before they can
verify your signature.  And since your personal identity is connected
with that master key, you're going to conflate your personal identity
with your Gentoo identity.
Generate a new keypair and use that instead.

@_date: 2006-12-28 00:01:51
@_author: Robert J. Hansen 
@_subject: Issues w/Daylight Savings Time in 2007 ? 
In doc/DETAILS, it says that soon GnuPG will migrate to an ISO time
format.  What are the motivating reasons for this?  What's the timeframe
for the changeover?  I've seen this warning in the DETAILS file for
quite some time, so I'm kind of wondering if that's still the plan or if
it's been forgotten about.

@_date: 2006-12-28 00:19:19
@_author: Robert J. Hansen 
@_subject: Issues w/Daylight Savings Time in 2007 ? 
Well, before the changeover happens, I'd appreciate it if a switch would
be added to preserve the current behavior.  Seconds since epoch is dead
simple and very familiar to programmers, and I suspect it might be
better for machine parsing.

@_date: 2006-12-29 14:57:11
@_author: Robert J. Hansen 
@_subject: USB vs Smart Card? 
Yes and no.  USB is just an interface specification.  Depending on
what's on the other end of the USB device, it could be completely
equivalent to a smartcard.  E.g., the Rainbow Technologies iKey 2000 is
a smartcard that uses a USB interface.

@_date: 2006-07-12 05:55:58
@_author: Robert J. Hansen 
@_subject: How do I check if a file is a valid encrypted file before I 
I'm not sure what you're asking here, to be honest.  What's an invalid
encrypted file?  If I send you an encrypted file containing nothing but
random data, the successful decryption of the valid file will be
statistically indistinguishable from trying to decrypt it with an
incorrect session key.
And in some other respects, the OpenPGP standard makes it very easy for
an implementation to detect bad or corrupted data and to bail out early.
So without knowing precisely what you mean by 'validity', I don't know
what to tell you, I'm sorry.

@_date: 2006-07-12 12:13:30
@_author: Robert J. Hansen 
@_subject: How to verify the file was successfully encrypted... 
Forgive a silly question, but what's wrong with decrypting the file as a
way of verifying the encryption worked?
If you're already sitting at your desk at 3AM doing encryptions, then
doing a decryption shouldn't be a terrible additional step.
If you've got a Perl script that's doing the encryptions, then have your
Perl script do the verification step, too.

@_date: 2006-07-25 12:34:12
@_author: Robert J. Hansen 
@_subject: Driving licence as identification and accepting signed 
Simple answers like "sufficient" or "insufficient" are tempting, but
they utterly lack context.  When it comes to these questions, you need
to carefully assess your needs and then establish a security policy that
meets those needs.
So: start from the beginning.  What's your threat model?  What do you
need an OpenPGP key signature to represent?  How paranoid do you need to be?
Once you know that, then start looking for other people with similar
policies and ask them for arguments for or against to help you decide.
But asking strangers with completely unknown policies is unlikely to do
much but confuse you.

@_date: 2006-07-29 11:34:31
@_author: Robert J. Hansen 
@_subject: Security of truncated hash functions 
Hash: SHA512
Assuming an idealized hash function, they're of equal strength.  If each
bit of the hash algorithm is effectively random with a 50/50
distribution, then a truncated hash is just as good as a full-size hash.
In the real world, hashes aren't idealized and this may not be good advice.
Just another instance where theory and practice are subtly different
from each other...

@_date: 2006-03-05 09:18:31
@_author: Robert J. Hansen 
@_subject: Questionnaire about GnuPG usage 
This semester I'm taking a course in Human-Computer Interactions, under
Prof. Juan-Pablo Hourcade.  The course is mostly about how to design
humane interfaces--how to make GUIs that help you get work done, instead
of getting in your way.  A couple of people in the class are crypto
freaks, and so we decided to see if we couldn't put together a
high-quality user-friendly GUI for the GNU Privacy Guard--or, at the
very least, some good ideas of what a user-friendly GUI would look like.
Thus, I'm asking the list: if you're willing to take a questionnaire and
give feedback on your needs and requirements for a GnuPG UI, please
email me _off-list_.  Your reports will be stripped of all identifying
data and your answers will be compiled into aggregate results.  The
final report, in addition to being turned in for class credit, will be
released under the Creative Commons Noncommercial Attribution Sharealike
license, for the benefit of the entire GnuPG community.
Thanks much!  :)

@_date: 2006-03-28 10:43:10
@_author: Robert J. Hansen 
@_subject: Linculti 0.1 
Feedback from people has so far been generally positive, although
karmically negative: just after getting a good grade back on our problem
assessment and UI proposal, the laptop with our assessment and proposal
on it suffered a hard drive failure.  We still have all of the
results/feedback/final conclusions; it's just that we only have them in
hardcopy now.  We're going to be shooting for an April 20 release for
those--we have to re-type them.
However: we have Occulti working on Linux, OS X and Windows.  On Linux
and OS X it looks kind of slick (especially on Fedora Core 5), even.
Since large parts of the GUI are done, we're releasing what we have so
far so that people can stay abreast of our progress.  First will come
the Linux build, since that's the one we've debugged the most.  OS X and
Windows builds will be coming in days to come.
Please note that this version is barely functional.  This is a preview
of the Occulti UI; it's not a preview of Occulti functionality.  Lots of
stuff simply doesn't work yet.  Updating keys from keyservers works (but
only from the File menu)--but basically nothing else that modifies your
keys does.
Anyway.  Enough said.  Download it for yourself at:
Of course, you shouldn't trust software that comes without a
signature--so grab the detached signature at:
As a word of warning: Linculti expects to find gpg in one of the usual
places: /usr/local/bin, /opt/local/bin, /usr/bin or /opt/bin, checking
in that order.  If it's not there, expect it to malfunction, maybe even
badly.  It also expects you to already have a keyring: if you don't,
expect it to malfunction, maybe even badly.
We welcome all feedback!  If you have thoughts on the UI design of it,
please send it on to me.  Thanks a lot!

@_date: 2006-11-02 22:49:08
@_author: Robert J. Hansen 
@_subject: Question about use of --cipher-algo AES & --openpgp when 
Hash: SHA512
Add "-vvvv" to the command-line and you'll get a ton of useful output.
rjhansen:~ rjh$ gpg -vvvv foo.gpg
gpg: using character set `US-ASCII'
:pubkey enc packet: version 3, algo 1, keyid 97B2C95A0569E3E6
        data: [2048 bits]
gpg: public key is 0569E3E6
gpg: using subkey 0569E3E6 instead of primary key FEAF8109
You need a passphrase to unlock the secret key for
user: "Robert J. Hansen"
gpg: using subkey 0569E3E6 instead of primary key FEAF8109
2048-bit RSA key, ID 0569E3E6, created 2005-02-22 (main key ID FEAF8109)
gpg: public key encrypted data: good DEK
:encrypted data packet:
        length: 311
gpg: encrypted with 2048-bit RSA key, ID 0569E3E6, created 2005-02-22
      "Robert J. Hansen"
gpg: AES encrypted data
:compressed packet: algo=1
:literal data packet:
        mode b (62), created 1162504119, name="rand.cc",
        raw data: 472 bytes
gpg: original file name='rand.cc'
gpg: decryption okay
gpg: WARNING: message was not integrity protected
... Looks just fine to me.  :)

@_date: 2006-11-03 16:38:20
@_author: Robert J. Hansen 
@_subject: Summary: Windows GUI recommendation for USB disk 
This may be just my own personal quirk, but it seems misleading to me to
describe AES256 as "stronger" than, say, AES128.  The threshold just to
break AES128 is so immense that it may as well be a brick wall;
describing AES256 as "stronger" just means the brick wall is, well,
still a brick wall.  Once you reach a certain threshold point as far as
resistance to brute-force attacks, to really make something "stronger"
requires introducing resistance to other kinds of attacks.
E.g., I'd say that an 3DES hardware token guarded by a fireteam of armed
Marines is far stronger than an AES256 key stored on a PC running
unpatched Windows 95 on an always-on unfirewalled Internet connection,
despite the fact the AES256 key has about 144 bits more keyspace.
Let's just describe 7zip as using strong crypto, and leave it at that.  :)

@_date: 2006-11-03 17:37:54
@_author: Robert J. Hansen 
@_subject: Summary: Windows GUI recommendation for USB disk 
Welcome to the Second Law of Thermodynamics!  Enjoy your stay.
By the Second Law, every time a bit of information is erased you have to
pay the entropy tax of (kT * ln 2) J.  Let's assume that for each key
you try, you have to erase 1000 bits of information--this is wildly
optimistic, given how complex key schedules usually are, but it'll make
for nice numbers.
On average you'll have to brute-force 2**127 keys before you find the
proper 128-bit AES key.
1000 = 10**3
2**127 approx. eq. 10**38
10**41 * (3 * 10**-21) = 3 * 10**20 J
A one-megaton nuclear weapon liberates approximately 10**15 J of energy.
3 * 10**20 J divided by 10**15 J = 300,000 megatons
By comparison, the 1863 Krakatoa explosion liberated about 21,000 megatons.
If you're interested, we can also do a quantum-mechanical analysis of
the minimum time required to do this computation.  It gets equally silly.
... It's true that quantum computers and reversible computing will both
reduce this number considerably.  However, if you're going to talk about
science fiction--which is what large-scale quantum and reversible
computing is nowadays--then why not go whole-hog and posit the existence
of a psychic who's 100% effective in predicting keys?

@_date: 2006-11-05 16:27:57
@_author: Robert J. Hansen 
@_subject: How to enable a block cipher or hash algorithm for a keypair? 
While Alphax gave you some good advice, it may also be unnecessary
advice or irrelevant advice.
You don't need to do anything, really, to enable a different cipher or
digest.  They're all enabled.  It isn't as if, should you receive
BLOWFISH-encrypted traffic, that you need to make sure your key is set
to read BLOWFISH.
The available algorithms--all of which are enabled--can be found just by
For instance, I get:
Pubkey: RSA, RSA-E, RSA-S, ELG-E, DSA
Cipher: IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH
Hash: MD5, SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224
... If what you want is to start using a different algorithm, a better
idea than using --cipher-algo and --digest-algo is to use the algorithm
preferences.  Try adding these two lines to gpg.conf:
personal-cipher-preferences TWOFISH AES256 AES192 AES128 3DES
personal-digest-preferences SHA512 SHA384 SHA256 SHA224 RIPEMD160
... Also, you may want to consider whether you really want to start
using SHA512.  There's nothing wrong with it, but only very recent
versions of PGP understand it.  If interoperability is a concern, you're
much better off with SHA256, which is understood by PGP 8.1 and later.

@_date: 2006-11-06 02:44:27
@_author: Robert J. Hansen 
@_subject: gpg error messag 
It will help us out considerably if you can tell us more about your
problem.  What operating system are you using?  What version of GnuPG
are you using?  What hash algorithm does the message say it's using?
What program generated the message in question?  What version of
Enigmail?  What... etcetera?

@_date: 2006-11-17 02:38:51
@_author: Robert J. Hansen 
@_subject: OpenPGP Card implementation 
The first bit of this is to Janusz; the second is to Johan.
You're asking computer and crypto geeks a legal question.  You have as
much chance of getting a good answer as walking into a meeting of the
American Bar Association and asking them about the differences between
PKCS1-1.5 and PKCS1-2.1.
If you need a legal opinion, you should ask a qualified lawyer.  Please
do not trust any legal opinions you get from internet sources.
This is factually wrong.  No author known just means the author has to
be discovered.  The legal system offers ample tools to do just that.
Subpoenas are routinely issued by courts precisely so potential
litigants can discover whom to name in a lawsuit.
Do not believe that you can remain anonymous for long if a major
corporation or government wishes to find you out.  The best way to
remain anonymous is to avoid coming to the notice of those whom you wish
to be unaware of your existence--not to tweak their nose and say "nyah,
nyah, you can't find me".

@_date: 2006-10-22 01:28:26
@_author: Robert J. Hansen 
@_subject: GPGDisk campaign 
I'll be the bad guy and rain on the parade, and give the reasons why
this is very unlikely to come to pass.
0.  It is not what GnuPG targets.
GnuPG tracks conformance to RFC2440, the OpenPGP standard, and
implements additional parts (smartcard drivers, etc.) as needed to give
a good user experience for RFC2440 tasks.  A cryptographic file system
has no relation to RFC2440.  Why should GnuPG support it?
1.  There are no standards for cryptographic file systems.
GnuPG has always focused on conformance to standards.  The GnuPG
developers probably do not want to come out with yet another
incompatible file system.
2.  There already exist strong Free Software implementations.
On UNIX there are many different Free Software encrypted file systems,
from encrypted loopback devices to plug-ins for the ReiserFS file system
to TrueCrypt (Linux only) to... etcetera.  On Windows, TrueCrypt offers
good support for encrypted partitions, much in the same way PGPDisk does
3.  The GnuPG developers may not find it sexy.
Writing good software is work.  It's a hell of a lot of work, in fact.
The thing that gets most Free Software developers going is their
affection for the subject matter.  The GnuPG developers like getting
their hands dirty with Internet wire protocols like OpenPGP.  Do they
like getting their hands dirty with filesystem drivers?  I don't know,
but my guess is no.
... And, of course, the short version of it is this: if you want it done
that badly, then grab the source and hack it yourself.  It's GPLed for
exactly that reason.

@_date: 2006-09-01 01:36:27
@_author: Robert J. Hansen 
@_subject: Problem with gpg --batch --gen-key 
Not necessarily.  GnuPG 1.4.2-1.4.4 (at least) are known to have
problems when scripted from Java, mostly dealing with I/O operations
randomly blocking.  I know I've complained about this a couple of times
on the list; might be worth searching the archives to see if anyone else
has solutions to it.

@_date: 2006-09-11 00:34:56
@_author: Robert J. Hansen 
@_subject: Need non-writable --homedir 
Hash: SHA512
Locking is a concurrency mechanism.  As such, as long as you can
guarantee that only one process will ever use the keyring, you should be
fine regardless of what you do.
Concurrent encryptions should be safe as well.
With good reason.  Random number generation is important, and if you
keep the same seed values it's possible for the same values to be
generated, in which case it's not very random at all.
My first idea, and I think the best suggestion, is to look into
rearchitecting your solution so that this kind of lockdown isn't
necessary.  Barring that, I'll defer other suggestions to the core GnuPG

@_date: 2006-09-11 22:26:32
@_author: Robert J. Hansen 
@_subject: Need non-writable --homedir 
Hash: SHA512
A few reasons, any one of which would be sufficient.
1.  /dev/random isn't available on all platforms.  GnuPG's random number
generator is.
2.  /dev/random is exhaustible.  This is a Bad And Wrong for crypto
3.  /dev/random is, as I understand it, an ad-hoc design.  Many people
who need crypto software need vetted, certified designs (even if the
software itself isn't certified).  E.g., some people may require ANSI
X9.17 RNG.  With a software RNG, it's fairly easy to just drop in
whatever RNG you need.
I'm not sure what can cause the trustdb to be updated, I'm sorry.  For
instance, if GnuPG sees that the system clock has advanced to the point
where a key has expired, does GnuPG cause the trustdb to be updated?
Etcetera.  For this question, you're going to have to ask the GnuPG
developers, since it depends on GnuPG internals.
That said, my intuition--and beware of taking anyone's intuition too
seriously--is that as long as you avoid modifying operations, the
warning will be insignificant.
Platform-dependent.  Obviously, --no-random-seed-file won't force
(e.g., Win32).  You need to tell us the precise system environment
before we can really answer these kinds of questions.
I'm having a cognitive disconnect here.  How does the _client's_
inability to modify the keyring affect the _server's_ ability to request
unencrypted data?

@_date: 2006-09-12 00:26:43
@_author: Robert J. Hansen 
@_subject: Need non-writable --homedir 
GnuPG has been ported to many platforms.  BeOS, OpenVMS, Win32, and many
more that have no /dev/random.
As Daniel Keys Moran wrote in _The Last Dancer_, the mark of a
half-assed software design is its inability to fail gracefully.  Most
software today would be lucky to be even half of that.
GnuPG may fail well in that situation.  But will _all_ your applications
fail well in that situation?  Especially ones which can't afford to
block for minutes until the /dev/random pool replenishes?
Being a good software citizen means being sparing in your use of limited
systemwide resources.  Thus, apps should avoid using /dev/random unless
there's a clear and critical need.
Again, you're missing the point.
If /dev/random is set up to be access for a radioisotope RNG on one
system, you have absolutely no guarantee it'll be a radioisotope RNG on
all systems.  You have absolutely no guarantee it'll be a radioisotope
RNG even on all UNIX systems.  Depending on how often you upgrade your
hardware, you may not even be able to guarantee it's a radioisotope RNG
on _your_ system.
GnuPG has no control over how each UNIX handles /dev/random.  If GnuPG
has no control over that, then GnuPG isn't going to rely on that.
GnuPG _can_ rely on its own internal pseudorandom number generator.  And
thus, it gets a random seed from some believed-good source (varies from
platform to platform), and successive calls to the PRNG just use that
You need to recognize that GnuPG is not a Linux-only platform, and
considerable work has gone into it to make it work on as many platforms
as possible.  This means disregarding certain OS features that would tie
it narrowly to one specific operating system.

@_date: 2006-09-12 21:09:23
@_author: Robert J. Hansen 
@_subject: Need non-writable --homedir 
Hash: SHA512
I apologize if this email seems snarky.  However, I'm getting tired of
repeating the same answers over and over again.
Your question is predicated on a "well, I'm on UNIX with a /dev/random,
so why doesn't GnuPG just use /dev/random for everything?"
You got an accurate answer to your question.  If you can't understand
the answer, then perhaps you should re-think the questions you're asking.
Ah, yes, UNIX Programmer's Disease.  I suggest you look into getting cured.
If you care only about UNIX systems, that's your lookout.
It's not the lookout of the GnuPG developers.
Please re-read my answer.
GnuPG _doesn't_ diminish /dev/random when encrypting, because it uses
its own pseudorandom number generator, which is why it uses random_seed.
The reason why it doesn't use /dev/random is because it's being a good
citizen and not using up limited resources, when it can do the same job
without using up any of that limited resource.
You always have a choice.  I'd suggest rearchitecting your solution.
Your current solution does not strike me as particularly sound.
Please consider this very carefully:
_GnuPG has absolutely no way of knowing the internals of /dev/random._
None.  Nada.  Zilch.  Zero.  GnuPG doesn't know, doesn't care.
Also, please consider this very carefully, too:
_There is no such thing as an 'average' GnuPG system._
What's an average GnuPG system?  Is it BeOS?  Win32?  Debian GNU/Linux?
 Fedora?  FreeBSD?  OS X?
Because it has no other choice.  It needs highest-quality random values,
and it can block indefinitely until those values are available.  (In
fact, it warns you it might block for a while.)
When encrypting messages it _does_ have a choice, and so it chooses the
option with the least impact on limited system resources.
See above.
While I am certain answers exist to be found, I am not certain the
answers will do you much good.

@_date: 2006-09-21 14:57:49
@_author: Robert J. Hansen 
@_subject: DSA2 
Hash: SHA512
The problem with describing anything as a 'new algorithm' is, where do
you draw the line for new?  Changing just one line in a specification
could be enough to categorize something as 'new', if you wanted to
define it that way.
It's more apt to say that DSA2 is very closely related to the original
DSA.  DSA2 is a logical outgrowth of the older DSA specification.
And better hash algorithms.
DSA is part of a United States FIPS (Federal Information Processing
Standard).  In this FIPS a scheme called DSS, the Digital Signature
Standard, is defined.  DSS specifies that DSA with SHA-1 will be used
for all signatures.
At the time DSA was designed, 1024 bits of the Discrete Logarithm
Problem was widely considered to be enough for all practical purposes.
It isn't considered to be so any longer and various attacks are being
discovered against SHA-1 (which DSS requires to be used with DSA), so a
revised FIPS was put out addressing these two concerns.
Because this is the new upper limit in the FIPS.
If you're asking why the FIPS chose 3072-bit keys as the upper limit, I
suspect their reasoning is that attacking 3072-bit DLP is a pipe dream
now and for the foreseeable future.
For whatever it's worth, some critics of OpenPGP point to the lack of a
hash function firewall in DSA and DSA2 keys as a big unresolved security
issue.  These critics are of the opinion the RSA signature specification
is better-defined.  While I haven't looked at the spec enough to see if
DSA2 still lacks a hash function firewall, the criticism should probably
be brought up and considered, especially if you're thinking of migrating
your key to a different signature algorithm.

@_date: 2006-09-21 20:46:17
@_author: Robert J. Hansen 
@_subject: DSA2 
In the real world we don't sign an entire message with our private key.   Instead we take a hash of the message and sign the hash.  Then we post the original message and our signature.  Other people can hash the original message and compare it against our signed hash.  If the two compare identically, then clearly it's a good signature, right?
But there's one detail we're handwaving.  How do you know what hash algorithm to use?  There has to be some piece of data telling you "use SHA512" or "use SHA-1" or...
Let's think of an attack against this scheme.  Let's say that our message format puts _in the message_ "use SHA-512" or whatever, and there's no data _in the signature_ about what hash was used.  Let's also say that I'm using a good hash algorithm, RIPEMD-128 [*].
How could we you the fact our format puts the hash data in the message to your advantage?
Hmm.  Well, you could use a very weak hash algorithm, such as MD4 [**].   You take a good signature off a message I've already signed, and you construct a forged message whose MD4 hash comes out identical to the RIPEMD-128 hash of my original (good) message.
"Hi!" the message now reads.  "This is Rob, and I'd like to donate megabucks to the Society of Evil Geniuses Working Together For a Better Tomorrow.  Please empty my bank account.  Hail Eris!  Hail Discordia! Oh, and use MD4 to verify this message."
You then take your forged message to the bank.  They verify the (forged) signature to recover the original hash value.  _They have no way of knowing it was originally a RIPEMD-128 hash_.  So when they MD4-hash the message and see it's identical to the hash value in the signature, the bank takes it as a valid digital signature and empties my bank account.
That's what it means for a signature scheme to lack a hash function firewall.  A good hash function firewall makes this impossible.
A hash function firewall means the signature carries data about itself, protected by a digital signature to make it tamper-resistant.  If, in our previous example, the signature said "use RIPEMD-128", the bank would know to use the right hash algorithm... a strong one, resistant to cryptanalytic attacks.
Without a hash function firewall, any critical compromise of any hash algorithm in the signature system puts the entire system in jeopardy. With a hash function firewall, only signatures using that compromised hash algorithm are jeopardized.
This is why some critics think signing keys need to support firewalling.
I don't know off the top of my head whether DSA supports firewalled hash functions or not.  I believe that the last time I checked the spec, I came to the conclusion it did not.
RSA signing keys, on the other hand, do support firewalling.
This entire post has been a tremendous simplification of an esoteric area of cryptology.  There are a great many nuances to the subject.  I also haven't taken a magnifying glass to the OpenPGP spec in at least eighteen months, maybe more; things may have changed since then. Corrections from people who are up-to-date on the latest revision of the spec are always appreciated.
[*] RIPEMD-128 is a 128-bit shortening of RIPEMD-160.  It is at present believed cryptographically secure.  It shouldn't be confused with RIPEMD, an earlier 128-bit hash, which is no longer considered cryptographically secure.
[**] You can create collisions in MD4 with pen and paper.  I'm not sure if MD4 is really weak enough for this example, but it's just a thought experiment, so let's assume it is.

@_date: 2006-09-22 03:21:03
@_author: Robert J. Hansen 
@_subject: DSA2 
If memory serves, the HFF is part of PKCS-1, which OpenPGP references
heavily for its implementation of RSA signatures.
ObWarning: I haven't studied it closely in quite some time.  My memory
may well be in error.

@_date: 2006-09-27 02:20:03
@_author: Robert J. Hansen 
@_subject: three computers and one secret key? 
Hash: SHA512
Open up a Terminal window (Terminal is in your Applications/Utilities
folder) and type the following:
gpg --armor --export-secret-key [your key ID] > priv.asc
gpg --armor --export [your key ID] > pub.asc
mkdir mykeys
mv priv.asc pub.asc mykeys
zip -r ~/Desktop/mykeys.zip mykeys
rm -rf mykeys
This will create a zipfile on your desktop called mykeys.zip.  Copy that
to your other machines and unzip it there.  You'll find inside it the
files "pub.asc" and "priv.asc".
On your other Macs, copy it to your desktop and unzip it.  Then open up
another Terminal window there and type:
gpg --import-secret-key ~/Desktop/mykeys/priv.asc
gpg --import ~/Desktop/mykeys/pub.asc
gpg --edit-key [your key ID] trust
This last line will start up a GnuPG key edit menu.  Type '5', then 'y',
then type 'save'.
Your key is now copied to your other Mac, and trusted on your other
machine, too.
WARNING: I'm giving you shell commands here.  Do not _ever_ follow
random shell commands you get from unknown people on the Internet.  You
can really screw up your computer that way.  Wait for other people on
the list to take a look at what I'm telling you to do, and wait for a
consensus as to whether I'm giving you good advice or bad advice.
And yes, there really are such losers on the Internet as who try to get
people to do stupid things that will damage their own machine.
That said, Terminal is an incredibly powerful and useful tool, and it's
worth your time to learn it, if you haven't already.  :)

@_date: 2007-04-01 15:05:37
@_author: Robert J. Hansen 
@_subject: comment and version fields. 
Hash: SHA256
The signed message _is_ protected entirely against unauthorized  changes.  Or, rather, as close to "entirely" as you can get with our  current level of cryptography.
The signature block is just a private-key encryption of the digest of  the message, plus a few additional bits of information of use to  OpenPGP.  That private-key encryption of the digest of the message is  the signature.  Everything else is, to some degree, irrelevant, with  some things being more irrelevant than others.
If you alter a comment field, you're not altering either the original  message nor the private-key encryption of the digest of the message.   So what's the complaint?  How is this tampering with the signature

@_date: 2007-04-02 09:46:12
@_author: Robert J. Hansen 
@_subject: comment and version fields. 
Hash: SHA256
This is a nonissue.  I can't think of a stronger way to put it.  The  mutability of the comment and version string is well known and  clearly documented in the RFC.
If you wish to use a tool, you are responsible for knowing the  operation of that tool.  If you wish to be ignorant, you will remain  forever exploitable.  There is no technological cure for this.  All  technological attempts to cure this are doomed to fail.
For every human-factors problem there exist technological solutions  which are cheap, easy and wrong.

@_date: 2007-04-02 10:46:17
@_author: Robert J. Hansen 
@_subject: comment and version fields. 
Then this isn't even a GnuPG problem, is it?
Find an email client and plugin which makes this sort of thing  possible, and then go complain to them.

@_date: 2007-04-03 13:55:12
@_author: Robert J. Hansen 
@_subject: comment and version fields. [Long] 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
I would think the line "----- BEGIN PGP SIGNATURE -----" would be a  tipoff to the fact that the signed portion of the message has ended  and data meant for an OpenPGP application's internal use is now  beginning.  Thus, yes, I do think it's flamingly obvious that  anything in the signature block is not part of the signed message.
Which is the entire reason why we have those "----- BEGIN" lines.  So  that people can see the markers delineating which portions of the  message are protected.
As has been repeated here ad nauseam, this is not a GnuPG problem.   This is not a PGP problem.  This is not an RFC problem.  This is, at  best, an MUA problem and should be brought up with MUA authors who  present signed data in a format that makes it easy to mistake things.
Please, if you want to continue to beat this drum, please beat it in  front of the right people.
Then take it up on the Enigmail list.  This is the GnuPG-Users list.

@_date: 2007-04-03 17:20:29
@_author: Robert J. Hansen 
@_subject: comment and version fields. [Long] 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
I'm sorry, at this point I can't take this discussion seriously.
Calling these things "hints" is like saying "a red octagonal road sign
with the word STOP written on it is a hint that you should decrease your
velocity to zero".  While true, nobody would ever say it.  Nor would
anyone say that it's the car's fault you drove through a stop sign
because you couldn't be bothered to learn the semantics associated with
the stop sign.
No.  This is "go talk to the correct people".  This is not a GnuPG issue.
If that's what you want to do, then join the IETF OpenPGP working group
and start talking about it there.  Talking about it here will not change
a blessed thing.  Talking about it there might actually achieve something.
The IETF OpenPGP WG and the various mailing lists for the various MUAs
are the right place to be discussing this issue.  Not here.

@_date: 2007-04-03 17:30:59
@_author: Robert J. Hansen 
@_subject: no, it's not an email client problem, it's what I said at the 
Hash: SHA512
It's a GnuPG bug if and only if it is not behavior specified by the RFC.
 Given that GnuPG is correctly implementing the RFC here, that
means--drumroll, please--it is not a bug in GnuPG.
Nor, for reasons I've already explained, is it a bug in the RFC.
Although if you want to continue to argue that it is, please take it to
the IETF OpenPGP working group mailing list.  Beating the dead horse
here will do nothing except give the poor beast postmortem bruising.
The IETF OpenPGP WG mailing list is the place where change can actually
It is not feasible to undetectably remove, add, or modify text in a
clearsigned message.
Your example adds, modifies, etc., text in the _signature_.
The _message_ remains protected.
I have explained this in clear English several times.  This is not a
GnuPG bug; this is not an RFC bug; this is not something the developers
need to fix; this is, at best, an issue for the IETF OpenPGP WG and the
mailing lists for the various MUAs.  Please take it there.

@_date: 2007-04-05 21:29:38
@_author: Robert J. Hansen 
@_subject: How to sign mail and news under Windows system by using GnuPG? 
Hash: SHA256
Typically, this is done with the assistance of an email plugin.   Probably the most popular Windows email client that has GnuPG support  is Thunderbird ( with the Enigmail plug-in  (  I've used this combination for years  with great success.
The Enigmail mailing list is also a very newbie-friendly place.   There are lots of people there who will be able to help you in  getting Enigmail set up and configured appropriately.

@_date: 2007-04-12 22:50:11
@_author: Robert J. Hansen 
@_subject: How to protect private keys? 
Clearly, you don't trust the computer you share with other users.  So  why, exactly, are you running GnuPG on it?
Running GnuPG on a computer you don't trust is folly.  If you don't  have physical security over the machine, there is no possibility of  electronic security in your communications.
Beware of all other answers you receive to this question.  Before you  try to fix the "GnuPG problem", fix the much bigger and more pressing  problem about how you're trying to run security-critical software on  a computer you don't physically control.

@_date: 2007-04-17 23:59:01
@_author: Robert J. Hansen 
@_subject: Lost passphrase 
That's making some really big assumptions about the security policy  of the person making the key.
There are also a lot of perfectly good alternatives which should  perhaps be excluded first.
Also, a two-year expiration date will do very little to help people  who forget their passphrases within a few weeks of creating keys.   Once you remember the passphrase for a few weeks, it'll be in your  head forever.
A key which cannot be found is a liability, not an asset.  The  keyservers exist to be used.
There are two responses to this, both of which are factually accurate:
1.  We are unlikely to ever be able to brute-force a 256-bit  keyspace.  Ever.  Not until computers are made of something other  than matter, occupy something other than space, run on something  other than energy, according to rules other than physics.
2.  This is a reason to advocate forethought when generating keys,  not a reason to advocate just one method of solving the problem.

@_date: 2007-04-18 09:05:22
@_author: Robert J. Hansen 
@_subject: Quantum computing 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
They've been "about to provide" a break in factorization for the last  30 years.
We're already factoring 256-bit numbers.  Fortunately, I didn't claim  256-bit composites would forever be secure.  I claimed 256-bit  keyspace searches would be secure.
Keyspace search is a different set of problems than factorization.   For a brute-force search the best we can do is Grover's quantum  database algorithm, which reduces it down to an equivalent 128-bit  keyspace.  From there we use quantum thermodynamics--namely the  Margolus-Levitin theorem--to get some reasonable bounds on how much  time, energy, etc., are required to do it.

@_date: 2007-04-18 09:14:03
@_author: Robert J. Hansen 
@_subject: Quantum computing 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Going off the top of my head, the DLP is known to be greater than or  equal to the difficulty of the IFP.  You can make strong arguments  that they're equal difficulty in a computational-theoretic sense, and  you can make strong arguments that in real silicon DLP will be  stronger due to our current lack of understanding of how to  efficiently use the general number field sieve for the DLP.  The  current state of the art in the GNFS requires a large amount of  storage overhead for the DLP, while the storage overhead for the IFP  is comparatively minimal.
As a word of warning, comparing DLP to IFP is a spectacularly black  art.  There are so many nuances to it that just expressing some of  the ideas in English is difficult.
As further warning: it's 9:10am, I haven't yet had my morning cup of  coffee, and I'm working without my references.  This being the  internet, there's also a nonzero chance that I'm barking mad.   Confirm this information before relying on it.

@_date: 2007-04-18 19:56:48
@_author: Robert J. Hansen 
@_subject: Quantum computing 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
I'm going to talk about Grover's algorithm and Shor's algorithm, plus  a good bit on computational complexity theory.  The two algorithms  are completely different and tackle completely different problems.   When I talk about computational complexity theory I'll tie the two  algorithms together to show how and when each one is used.
Please bear with me.  This is going to be long.
As mentioned, Grover's is the best we can do for quantum speedups to  brute-forcing.  Grover's algorithm is a technique for using quantum  mechanics to search through a database of N entries in time  proportional to the square root of N, using an amount of storage  proportional to the logarithm of N.
This is important because brute-forcing a key can be thought of as  searching through an unsorted database trying to find the right  entry.  In math we'd say these two problems are isomorphic to each  other.  "Isomorphic", for the purposes of this email, just means that  we can convert one problem into a different problem with some trivial  transformation.  As with most things in math the real definition is a  little more involved, but this one will work for our purposes.
For instance, multiplication and division are isomorphic to each  other.  To divide by 3, just multiply by 1/3.  To multiply by 3, just  divide by 1/3.  Etcetera.  That's isomorphism in a nutshell.  Please  remember what isomorphism means; you're going to see it again later  in this email.
Searching through an unsorted database and brute-forcing a key are  isomorphic to each other.  So we do a trivial transformation on the  brute-forcing math problem to convert it into a database search  problem, and then we sic Grover's on it.
Now, that said, Grover's has limits.  Its first constraint is that it  doesn't make problems trivial.  It just increases our ability to deal  with them.  Brute-forcing a 128-bit cipher using a traditional  computer is a ridiculous proposition, but using Grover's, it becomes  as hard as brute-forcing a 64-bit cipher... hard, but possible.
So the best way to defend against exhaustive key search in a quantum  world is to either (a) trust that quantum computing is going to  remain "in just a couple of years" for the next few decades (which  may very well be true), or (b) multiply your key sizes by a factor of 2.
The principal reason why AES supports a 256-bit key is because of the  possibility of quantum computing and Grover's algorithm.  Brute- forcing a 256-bit cipher with Grover's is as hard as brute-forcing a  128-bit cipher with a conventional computer... absolutely  ridiculous.  :)
Quantum computing poses no threat to symmetric cryptography.   Asymmetric cryptography, however, gets a little funky.
Shor's algorithm uses quantum mechanics to solve the integer  factorization problem (and, I believe, the discrete logarithm  problem) in extraordinary short time.  The downside of Shor's is it  requires an insane amount of memory--you need two qubits for each and  every bit of the number you're trying to factor.  So if you're trying  to factor a 2048-bit RSA key, you need over four _thousand_ qubits.
Our current largest quantum computer is about fifteen qubits.
When this monstrously huge quantum computer was demonstrated by IBM,  it created a huge hue and cry in the press.  Most cryptographers  dismissed this as much ado over nothing.  Schneier is apocryphally  quoted as saying "yeah, any RSA modulus with fewer than eight bits is  now truly fucked."
But wait, the good news doesn't stop there.  Not only is quantum  computing a long way off from being able to tackle RSA and/or El  Gamal, but Shor's algorithm is _only_ applicable against asymmetric  systems built on the integer factorization problem and/or the  discrete logarithm problem.
For instance, Lamport signatures are a perfectly valid asymmetric  signature scheme that are secure even against quantum computing.  If  and when quantum computing develops to the point where a research lab  gets a couple of hundred qubits together, the OpenPGP working group  will almost certainly add asymmetric algorithms that are highly  resistant to quantum computing.
Now for the real head-bending things.  Why is it there's such an  efficient way to solve the integer factorization problem and the  discrete logarithm problem, but such an inefficient way to brute- force a key?
Computational theory is the branch of mathematics that's concerned  with the fundamental limits of what computers can do.  In  computational theory, we have several different classifications of  problems, depending on how much time and space are required to solve  There are _tons_ of different complexity classes.  The ones we're  going to be talking about here are P, NP, and NP-COMPLETE.
A problem is said to be in P if and only if it can be solved in an  amount of time proportional to its input.  For instance, the bubble  sort runs in time proportional to the square of its input.   Bubblesorting one hundred elements takes a hundred times larger than  bubblesorting ten elements.
A problem is said to be in NP if and only if verifying the answer for  the problem is in P.  For instance, factorization is clearly in NP.   If I tell you that 37 and 73 are the two factors of 2701, you can  easily multiply 37 and 73 together to prove it.  Since, once given an  answer, proving the answer is in P, we know that the problem of  finding the answer must be in NP.
NP-COMPLETE means "this problem is one of the hardest problems in  NP".  "Hardest" here has a very precise meaning which I'm going to  mostly gloss over.  You can think of it as "a problem is in NP- COMPLETE if it is isomorphic to another NP-COMPLETE problem".
(This raises the question of "so how do we find the first NP-COMPLETE  problem?"  Ah, well, that's why we have so much respect for Stephen  Cook, who thunked down a couple of hundred pages of mathematical  proof establishing a problem called SAT as the hardest problem in  complexity class NP.  Once Cook had done his heroic feat of  mathematical hacking, all that us Johnny-Come-Latelies have had to do  is show other problems are isomorphic to SAT.)
Finally, you can always punt a problem into a higher complexity  class.  If you want to, you can convert a P problem into an NP- COMPLETE problem... but you can't convert an NP-COMPLETE problem into  a P problem.  That would be a downward punt, and it's not allowed.
Got all that?  Great.  Now it should be easy to follow the rest.
When we brute-force a key, we are effectively punting the problem up  into NP-COMPLETE.  That means it's _really, really hard_.
When we discover mathematical weaknesses or flaws in a cryptographic  algorithm, if there's determinism we can exploit, then we're tackling  the problem in a much lower complexity class.  That means it's much  Shor's Algorithm applies to two specific problems that live in NP.
Grover's Algorithm applies to _every_ NP-COMPLETE problem.
Shor's Algorithm is as fast as it is because it's (a) highly  specialized and (b) solves an easy problem.  Grover's Algorithm is as  slow as it is because it's (a) highly general and (b) solves a very  hard problem.
... One last word.  Computational theory purists will tear this email  to absolute shreds.  After all, how can I talk about quantum  computing without talking about complexity classes BQP or the P=NP  problem or...?
The worst part about it is, _they're absolutely right_.
You're asking a very, very detailed and technical question that  requires a ton of disciplined study just to learn the language needed  to describe the boundaries of the problem.  If you really want to  know this material, you need to take a graduate-level course in  computational theory and a strong undergraduate course in quantum  physics.  You'll also need enough background in mathematics not to go  running screaming from the room when people start talking about  Hadamard matrices and discrete Fourier transforms and everything else  that goes along with it.

@_date: 2007-04-19 11:23:18
@_author: Robert J. Hansen 
@_subject: Quantum computing (Robert J. Hansen) 
I'm not going to talk about this for three reasons.
1.  I've never used Diceware, so I can't talk intelligently
     about it.
2.  The answer will depend a lot on implementation details.
     What s2k algorithm is being used?  What algorithm is
     used to encrypt the secret key?  What... etc., etc.
3.  I've already explained why quantum computing is not
     something we need to worry about.  Be far, _far_ more
     concerned with the physical security of your machine
     more than any hypothetical developments in quantum
     computation.
We tend to obsess over quantum computing.  We shouldn't.  At this  point in time it's science fiction.

@_date: 2007-04-19 19:25:10
@_author: Robert J. Hansen 
@_subject: Quantum computing 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Eh.  I'm still unconvinced.  It wasn't until last year that the final  physics hurdle to large-scale QC was addressed (large systems have a  strong tendency to near spontaneously decohere, turning your quantum  computer into an expensive paperweight).  We still have no idea how  to apply this physics knowledge, however.
Just knowing that something is possible doesn't mean the ability to  do it is around the corner.  We can teleport atoms in laboratories at  the speed of light and we know how to do it for macro-scale items,  but the engineering difficulties are so large that I doubt we'll see  it in our lifetimes.
While I agree that commercial development _may_ lead to developments  in QC, I think it's equally likely that the engineering difficulties  will be insurmountable.  Which means that, from where I sit, we  should just shrug and say "we really can't say with any confidence  what the future will or will not hold".
What do you mean?  Rice's theorem applies to QC.
Computational theory is computational theory.  We've already got very  robust mathematics to describe the computational properties of QC.   We know that BQP is a superset of P, that it does not encompass NP- COMPLETE, that it has some overlap with NP, etc., etc.
It's true that in mathematics there could always be a proof delivered  tomorrow by some hungry graduate student which will utterly shatter  our knowledge of math as we know it.  But this is true for all of  mathematics.  It's not as if this risk is special to QC.  You should  be just as concerned about the prospect of P=NP.

@_date: 2007-04-20 04:41:04
@_author: Robert J. Hansen 
@_subject: Quantum computing 
I forget who said this, but it's my favorite quote about predicting the
future.  "The future never comes to us well-ordered."  It's always
punctuated with unpredictable advances and inexplicable delays.  You can
either obsess over the fact that crypto is a branch of mathematics, and
thus a human endeavor subject to the disordered-future rule, or you can
smile and shrug and say "well, we'll do the best with what we have, and
keep our eyes open for the future."
My best advice is to not worry about it.  :)
There is no such thing as quantum cryptography.  "Cryptography" is a
broad term encompassing a great many subjects, and we simply don't have
that for the quantum world.
Quantum key exchange is an interesting trick of physics.  But that's all
"quantum cryptography" is at this point--a simple key exchange
algorithm.  There are no quantum encryption algorithms, no quantum
signature schemes, no quantum hash functions.  Just quantum key
exchange... which is nowhere near as cool as people make it out to be.
It's an interesting parlor trick.  It's not anything new in the world of
[scratches head] Are you talking about the second Hilbert problem?  That
one generally goes to G?del or Turing.  Rice's theorem is an interesting
bit of work with some deep consequences for computer science, but it's
not anywhere near as big of a shakeup as incompleteness.
What proofs?  There are none.  There are just lines of reasoning which
we believe to have substantial weight, but nobody has delivered an
actual proof of security for any cipher or hash.  To do so you'd have to
prove P != NP, and that's one of the Holy Grails of CompSci.
Look at something as simple as RSA.  There are three major conjectures
that go into RSA.
1.  The RSA problem (RSAP) is equivalent to the integer
    factorization problem.
2.  The Integer Factorization Problem is not in P.
3.  P != NP.
None of those have been proven.  None.  We like to pretend that they
have been, we like to handwave them, but the reality is those
conjectures are unproven... and, in fact,  is probably false.
See Boneh and Venkatesan, "Breaking RSA May Be Easier than Factoring".
Why?  Seriously.  Why?  By and large, cryptanalysis of intercepts is a
dead issue.  Nobody with half a brain does it.
According to the best information available, during the entire Cold War
the KGB and GRU were never able to break a single United States cipher
cleared for top-secret information.  That's not to say the KGB and GRU
weren't reading top-secret cables on a regular basis.  Instead of
cryptanalyzing the traffic, they just sent expensive hookers and good
bourbon to cipher clerks in the American embassy.
There are literally thousands of ways to skin this cat.  Focusing on
purely the mathematical aspect is very shortsighted.

@_date: 2007-04-20 11:13:35
@_author: Robert J. Hansen 
@_subject: Quantum computing 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
I don't mean to sound flip, but as soon as you invent a hypercomputer  I would love to revisit this issue with you.  For now, all our  computational theoretic proofs will be limited by the the lambda  calculus.  I don't mean to sound blunt there, but our current model  of computation is extraordinarily robust, and there are very strong  arguments that hypercomputation is both physically and mathematically  impossible.  (If any problem in UNDECIDABLE can be solved by an  oracle, then math goes from incomplete and inconsistent straight into  pervasively self-contradictory and broken.  That's the rationale for  hypercomputation being physically and mathematically impossible.)
Wikipedia is not an authoritative reference.
"Quantum cryptography" is a nice catchphrase.  I'm unaware of any  respected authority in the field of crypto who takes the phrase  The phrase is used in nontechnical media, and in that environment its  usage is probably defensible.  After all, people reading the  newspaper don't want to be bothered with the details of what QKE is  all about.  But we're trying to be precise here, and for that reason,  let's not talk about quantum cryptography.  Let's be precise and talk  about QKE.
The NSA was breaking the KGB's one-time pads.  Look into Project  VENONA.  Soviet cipher clerks were making technical errors in using  their one-time pads and the NSA was able to start reading their traffic.
So yeah, I'm not sure why you want flawless perfect proofs of  security when reality shows that provably secure systems never are.
It's beyond the realm of mathematical cryptography, but not the field  as a whole.
My day job involves security analysis of electronic voting machines  for the National Science Foundation [*].  We spend far, far more time  scrutinizing the human side of the cryptography than the mathematical  side.  Probably an order of magnitude.
[*] I'm not speaking for the NSF here, obviously, I'm completely  responsible for any errors I make, etc., etc.

@_date: 2007-04-20 12:41:36
@_author: Robert J. Hansen 
@_subject: Movies that get it right 
And while we're handing out movie recommendations, try for a 1974  Francis Ford Coppola movie called "The Conversation".  Easily the  best fictional movie I've ever seen about real-world communications  Phil Alden Robinson's 1992 movie "Sneakers" is also appropriate here,  although "Sneakers" is a little inferior to "The Conversation".
Both those movies are absolutely brilliant when it comes to the  subject of communications security.

@_date: 2007-04-21 17:05:13
@_author: Robert J. Hansen 
@_subject: Quantum computing 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
I wouldn't be so quick to place blame on the difficulty of  implementing the one-time pad.  Implementing the OTP is really pretty  simple: use each pad once and burn it when you're done.  The  difficulty lies in trying to make fallible human nature rise to the  level of competency required to use the OTP.
Anyway, to answer your question, no.  It's based on a couple of things.
1.  Many provably secure schemes are isomorphic to the one-time pad.   This means that the other provably secure schemes share the same  flaws as the OTP.
2.  The provably secure schemes that aren't isomorphic to the OTP  typically get broken pretty quickly.
As an example of  look at IBM's Atjai-Dwork, which was released at  CRYPTO97.  Atjai-Dwork was some nice work, really, with a beautiful  mathematical proof of security.  I emphasize this: _proof_.  It  wasn't built on conjecture.
Within a year there were three different breaks against Atjai-Dwork.   Turns out the axioms Atjai and Dwork used to build the algorithm  weren't quite as robust as they thought.
Moral of the story: proofs of security are nice.  They give us  something to point and laugh at.

@_date: 2007-04-22 01:18:08
@_author: Robert J. Hansen 
@_subject: UID changes (was Key Revocation) 
Hash: SHA256
This will not work if you've sent your key to a keyserver, as is  recommended.  It will also not work if you've sent your key on to  others; if and when you send them your new key, your old UID will  Revocation of the UID is preferred.

@_date: 2007-04-22 21:51:33
@_author: Robert J. Hansen 
@_subject: Generating and storeing keys on usb pen 
Hash: SHA256
I have nothing to add to John's advice, which answers the question just
fine.  I would recommend you think long and hard about storing the keys
on a thumb drive as opposed to your laptop, though.  In all my traveling
I've never mislaid my laptop, because it's expensive and important to me
and it's too big to casually misplace.
I misplace my car keys, and the flash drive that's on them, about once a
You may want to consider whether you'd be better served by just putting
a good, strong passphrase on your secret keys.  Alternately, look into
an encrypted drive.  TrueCrypt works well for Windows and Linux, and
Macs have their own built-in encrypted drive scheme.

@_date: 2007-04-23 09:45:37
@_author: Robert J. Hansen 
@_subject: libgcrypt: Length of IV 
Ask on sci.crypt.  When you do, please make sure to give more  context, such as the algorithm you have in mind, the usage context, etc.

@_date: 2007-04-25 11:04:31
@_author: Robert J. Hansen 
@_subject: Generating and storeing keys on usb pen 
Professional thieves, no.  On the other hand, living on a college  campus I've seen tons of thumb drives get stolen.  Someone leaves  their drive on a table for a few minutes while they're off in the  bathroom, someone else walks along and--"hey, free drive.  I can use  one of these."
There are far, far more thieves of opportunity in the world than  there are professional thieves.
USB is a peer to peer protocol; it requires substantial computing  power on both ends of the connection.  I'm just waiting for the first  virus which targets common USB drives; it would rip through colleges  and workplaces like wildfire.
It seems unwise to advocate plugging USB drives into multiple  machines unless you're comfortable with the idea your drive may be an  infection vector.  And frankly, I don't want my keys to be on the  same token as a token which is going to be shared around a large  number of computers, not all of which I will control.
In some respects it is probably worse.

@_date: 2007-04-25 13:52:41
@_author: Robert J. Hansen 
@_subject: Generating and storeing keys on usb pen 
And then, literally minutes later, this crosses my desk:
"Hackers debut malware loaded USB ruse"
By John Leyden
Malware purveyors deliberately left USB sticks loaded with a Trojan  in a London car park in a bid to trick users into getting infected.
The attack was designed to propagate Trojan banking software that  swiped users' login credentials from compromised machines.
Check Point regional director Nick Lowe mentioned the ruse during a  presentation at the Infosec trade show on Tuesday, but declined to go  into further details, citing the need for confidentiality to protect  an investigation he's involved in.
Mikko Hypponen, chief research officer of security firm F-Secure,  said separately that Trojan code was replacing phishing emails as the  preferred method for fraudsters to rip off users' account details.
Banking Trojans are written for profit and sold through Russian  language websites and elsewhere for between $2,000 and $5,000. Two of  the main groups of Trojan malware authors - Corpse and SE-Code - are  based in Russia and "market" the Haxdoor and Apophis strains of  banking Trojans. An unknown Russian speaking virus writer group is  behind Torpig, another banking Trojan family. Malicious code variants  of the Bancos Trojan are sold by an unnamed group in Brazil.
... Moral of the story: be very careful where you go plugging your  USB tokens into, recognize they are infection vectors and infection  targets, recognize they can be compromised, and act accordingly.

@_date: 2007-04-26 10:02:08
@_author: Robert J. Hansen 
@_subject: Generating and storeing keys on usb pen 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
The better question, at least from a security perspective, is what  evidence do you have that your particular vendor's USB token is not?
I mentioned this a few days ago, but my day job involves security  testing of electronic voting machines for the National Science  Foundation [*].  We have to deal with the issue of whether a given  machine is reprogrammable and under what circumstances it can be  reprogrammed.  History tells us that skepticism is warranted when it  comes to this issue.  See, for instance, the work of Harry Hursti or  Ed Felten.
Most USB token vendors are not concerned with security.  Most of them  don't care if their devices can carry malware.  There are no citizen  review boards to examine the product and hold vendors accountable.
I am deeply skeptical of claims that USB controllers are not  reprogrammable.  I'm not saying they must be reprogrammable... only  that until we see strong evidence that a particular vendor's hardware  is not reprogrammable we should assume that it is.
[*] I'm not speaking for the NSF, all opinions are my own, any  inferences you draw about my feelings towards electronic voting  machines are entirely yours.

@_date: 2007-04-27 03:15:19
@_author: Robert J. Hansen 
@_subject: Sign+Encrypt a message 
Hash: SHA256
gpg --armor --encrypt --sign \
That's meant to be placed all on a single line.  You can have as many  repetitions of --recipient and --local-user as you need.

@_date: 2007-04-27 22:03:36
@_author: Robert J. Hansen 
@_subject: Public key contents 
Hash: SHA256
What do you mean, "view the contents"?  The file is right there for  you to look at.

@_date: 2007-08-07 15:17:53
@_author: Robert J. Hansen 
@_subject: OpenPGP and usability 
(Two of the three points mentioned in this email are Enigmail-specific.
 However, the worst one is an OpenPGP problem, and one that probably
deserves more attention, which is why I'm posting it to gnupg-users.)
I'm sitting in the Hampton Room of the Sheraton Boston right now
attending a meeting of electronic voting researchers.  A few minutes ago
 a big name in computer security--if I gave it, you would probably know
it--finished talking about his experiences with a large voting machine
investigation, and how they were using OpenPGP to secure communications
between researchers.  Or, at least, trying to.
I have his permission to relate his experiences to these lists.  I am
omitting his name because I am going from my memory of the conversation
I had with him, and I may have misunderstood a detail here or there, and
I don't want to do anything that might besmirch his reputation because I
misunderstood things.
Anyway.  The problem, as he said: "forty computer security professionals
can't use GnuPG among them because the [cognitive] overhead is too much."
He had several mailing lists for different tasks in his electronic
voting research.  Roughly 40 people in total were on the mailing lists.
 His ultimate goal was to ensure confidentiality; assurance was not a
major issue, but was a nice side benefit.  He was using Enigmail and
GnuPG, while other people on lists were using GnuPG + gpgol, PGP +
Outlook, or (in one case) a custom Windows PowerShell script gluing
together GnuPG and Microsoft Word.  I do not have version numbers for
any of these.
The good news: he describes Thunderbird + Enigmail + GnuPG as "the best
thing going for email crypto," or words pretty close to that.
Unfortunately, that turned out to be pretty faint praise.
Problem 1: key signatures.  He says he couldn't figure out what he
needed to do with the keys.  Did he need to sign them?  Trust them?
What's validity and otrust again?  Who should be set up as a trusted
introducer?  Why wasn't the cursed thing working?!  As he said, "I know,
I knew what needed to be done, but even knowing what needed to be done,
I couldn't figure out what needed to be done."  Even just talking about
it, months after the fact, he sounded frustrated.
Problem 2: PGP/MIME.  Correspondents who were using PGP/MIME for
attachments found massive interoperability problems.  Apparently,
Enigmail has an idiosyncratic way of doing PGP/MIME which causes
heartache and woe for non-Enigmail users.  (I haven't confirmed this;
this is just according to him.)
Problem 3: Key selection.  They ultimately decided to just go with a
single shared GnuPG key for each mailing list.  The idea here was that
as soon as the project finished, each person could just nuke their copy
of the mailing list key and the mailing list messages would effectively
be put forever beyond use.  However, Enigmail would frequently
encrypt-to-self, or encrypt to the keys of other people on the mailing
lists, or... etc.  Ultimately, he says that his resolution was just to
always show the key confirmation dialog.

@_date: 2007-08-08 13:39:58
@_author: Robert J. Hansen 
@_subject: OpenPGP and usability 
Not quite Whit Diffie, but not that far away from him, either.  :)
Right, I'm not disputing that there is a way to do this.  However, the
person in question was unable to find that solution in the time he spent
researching the problem.  This suggests to me that either (a) the
OpenPGP standard is bad for being too complex, (b) [GnuPG|Enigmail]'s
user [interface|documentation] is bad for not making it easier to
discover these things.  I doubt we can do anything about (a), but all
four cases of (b) might warrant some looking into.

@_date: 2007-08-20 14:46:13
@_author: Robert J. Hansen 
@_subject: Compression routines - please include 7-Zip 
MS's implementation of zip compression is known to be ridiculously slow.
 Most other zip implementations are orders of magnitude faster.
RMS is not a core contributor for the GnuPG project.  He is also not on
the IETF OpenPGP working group.
If you are interested in pitching this, I would suggest pitching it to
the IETF.  GnuPG's typical position is to only support the RFC, without
any embrace-and-extend.

@_date: 2007-08-21 01:43:52
@_author: Robert J. Hansen 
@_subject: Compression routines - please include 7-Zip 
Once more, this mailing list is not the correct forum to raise your
concerns.  Please do it on the IETF OpenPGP WG mailing list.
Given that the RFC cycle has ended and a formal submission made to the
IETF just weeks ago, I do not expect a new submission for at least five
There will likely be a series of -bis releases in the months and years
to come.  If you want to get 7Z in a -bis release, you need to talk to
the IETF OpenPGP WG.
I do not know how to make the preceding more clear.

@_date: 2007-08-22 08:04:17
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
Not especially.
Not to my knowledge.
1. Because the developers don't feel it's necessary, and nobody's yet
   submitted a patch.
2. Why do you need an RSA keypair?  The overwhelming majority of users
   are best served by sticking with the defaults--which, in this case,
   means a DSA/Elgamal keypair.
1. Because the developers don't feel it's necessary, and nobody's yet
   submitted a patch.
2. RFC2440 is officially neutral about the content of a user ID packet,
   except that by convention it's an RFC822-style address.  Speaking for
   myself, I'm glad GnuPG enforces a minimum; it reduces the likelihood
   that some poorly-conformant implementation will have a psychotic
   break from reality when it sees a user ID packet with length 0.
   GnuPG's limit is, as near as I can tell, completely arbitrary.  That
   doesn't make it a bad choice.  If the spec gives no guidance (at
   least, none I can see in section 5.11), then any decision whatsoever
   is arbitrary.  Allow zero-length?  Arbitrary.  Allow only names of 17
   characters?  Arbitrary.  Require at least five-letter names?
   Arbitrary.
   The ultimate metric is not whether the choice is perfect; it's
   whether the choice makes sense for the great majority of users.
There is not, and I recommend against changing your system time just to
get a 'perfect' key.
A key is a mathematical device which allows us to utilize trust
relationships over a widely dispersed network.  A perfect key is one
which best contributes to the confidence and trust of the network.
If I see that you've got a key date of 00:00:00, my first thought is
going to be that you've played hob with your system time and carefully
doctored your key.  That is not going to cause me to have trust in you
or your key.
Doctoring a key in this way is probably ultimately against your own

@_date: 2007-08-22 17:41:16
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
The latest versions of PGP support them.
If you are repeatedly encrypting and/or decrypting enormous files, then
yes, this is potentially an issue.  Otherwise, there is no practical
difference in speed you will notice.
The OpenPGP specification came out in the late nineties.  RSA did not
enter the public domain until August of 2000.  The IETF refused--rightly
so--to make a patented algorithm the default OpenPGP algorithm.
This implicitly casts RSA as being somehow universally superior.  It's
not.  Nor is it inferior.  In a couple of very narrow fields, RSA is
superior.  In others, DSA is probably superior.  In yet others, Rabin
signatures are probably best.  (Me, I've wondered for years why OpenPGP
doesn't support Rabin; it's a beautifully elegant algorithm.  And then I
kick myself and say "duh, to keep the number of algorithms down, just
like with Lamport signatures and WHIRLPOOL!", and go on with my business.)
Because it's a deprecated key style.  There's nothing inherently wrong
with it, but most authorities today recommend using separate signing and
encryption keys.
Only when it comes to recovering from a security-related incident.  If
the cops come by and force you to give the private part of a key used to
encrypt a message, fine, you can do so without yielding your signing key.

@_date: 2007-08-22 22:14:56
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
Hash: SHA512
And yes, there are still people using the very old 6.5.8 codebase.
These people ought to be dragged out into the street and forcibly
introduced into the twenty-first century, but hey, that's just my opinion.
When you're doing a signature, you're signing less than 1k of data with
RSA or DSA.  When you're encrypting a file, less than 1k of data is
being encrypted with RSA or Elgamal.
How does this test show any speed difference between the two?  The time
differential between RSA/DSA/Elgamal is statistical noise given the
much, much larger time spent reading the 4GB of data.
I'd just keep the last clause.  "There's not much of a difference."
Timing of DSA versus RSA will depend heavily on everything from
processor load to disk I/O to the phase of the moon.  Generally
speaking, yes, the first two clauses are correct, but it's impossible to
say with specificity what will happen in your particular environment.
Pretty much.
Not really.  E.g., DSA2048 uses SHA256 as a hash algorithm.  But I can
use SHA512 with an RSA2048 key.  RSA keys offer the best selection of
hash algorithms, but this is mostly a canard.
Newest versions, not version.  I think PGP 9.0 introduced DSA2, and
they're up to 9.5.
Yes, but I am unconvinced that this is something an average user needs
to be concerned about.  (I'm concerned about it, but I freely admit to
being paranoid.)
What does this "better" mean?
Seriously.  You're arguing about whether Godzilla or Mechagodzilla is
more effective at flattening downtown Tokyo.  The answer doesn't matter.
 Whether it's Godzilla or Mechagodzilla, people are still going to run
for the hills.
Likewise, given the astronomical difficulty of attacking either RSA or
DSA, it's hard for me to say one is "better".  The instant an attacker
sees RSA or DSA, the attacker is going to give up trying to forge a
message by cryptanalytic means.
In a lot of ways, I think this is arguing over how many angels can dance
on the head of a pin.
You can have a perfectly OpenPGP-conformant application that treats RSA
messages as noise and silently discards them.
In RFC language, there are a few special keywords that are almost always
MUST: a conformant application is required to...
SHOULD: while not required for conformance, it is good if...
MAY: totally irrelevant to conformance, but worth considering...
NOT: invert the meaning of the preceding word.
DSA is a MUST algorithm, as are SHA-1 and 3DES.
RSA is a MAY algorithm.
It didn't.  You can implement OpenPGP without paying anyone a dime in
patent royalties.
The distinction between "the IETF" and "the people behind OpenPGP" is
not as big as you might think.
The IETF is fundamentally composed of a lot of people who are interested
in technology.  That's all.  Their working groups (WGs) are open to the
public.  Public participation on IETF mailing lists is heavily
encouraged.  I sit on the IETF OpenPGP mailing list just to track the
latest changes.
In Ye Olden Days, when Phil Z. was developing Classic PGP (PGP 2.6,
RFC1991), his attitude towards intellectual property was remarkably
cavalier.  It created an awful lot of problems for PGP 2.6, since
practically everything about it was patent-encumbered.  The patent
problems were one of the driving forces behind the development of a
next-generation PGP technology, which became OpenPGP (RFC2440).
- From the very earliest days of OpenPGP, there has been a strong
commitment to the total absence of patent-encumbered algorithms from MUSTs.
I'm with John Clizbe on this one, although I'd use a different argument.
In the battle between armor and warhead, _always_ bet on the warhead.
Playing defensively and trying to make an email address invisible is
going to be an exercise in frustration.  They always get seen.  They
always get spammed.  Play defensively and you lose.
Whitelisting, graylisting, blacklisting, Bayesian filters, even lawsuits
if you're so inclined--those are all active measures which force the
spammers to adapt to your actions.  That gives you a measure of
initiative back.  You're no longer playing pure defensive.
If you like, I'll ask the antispam research group here at UI if they
think there's anything to be gained by omitting an email address from a key.

@_date: 2007-08-23 06:05:24
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
In an RSA signature, data about what algorithm was used in a signature
is, itself, part of the signed data.  You can't lie about a signature
algorithm without tampering with the message and making the signature
fail to verify.
In DSA, the data is not part of the signed data.  This allows you to
lie.  This has potential problems if one of the supported hashes becomes
so catastrophically weak that second-preimage attacks become feasible.
SHA-1 may be basically dead as far as crypto goes, but it is a _long_
way from a second-preimage attack.
The paranoid interpretation of this:
Let's speculate that tomorrow, Shengdong University continues their
trend of eye-popping crypto research and announces a second-preimage
attack against SHA-1.  You migrate to RIPEMD160 or truncated SHA256 or
what-have-you as a result.
An attacker wants to forge one of your new RIPEMD160-based signatures.
An attacker gets a good RIPEMD160-based signature from you.  This is
basically one very long binary sequence, which says "hey, if the message
you're reading hashes out to this binary sequence, then yes, it's for real."
I construct a new message, saying "I, Sven Radde, agree to pay Rob
Hansen one frosty cold pint of bitters."  I wave the dead chicken over
it, or whatever Shengdong U. says I have to do, in order to make it hash
out to the exact same binary sequence as the one your signature says is
I lift your RIPEMD160 signature and place it on my new forged message.
I proceed to then lie and say "This message used SHA-1 as a digest."
I give it to your local barkeep.  He looks at the message, SHA-1s it,
gets the binary sequence I constructed.  He compares it against your
signature block, which says "hey, if the message you're reading hashes
out to this binary sequence, then yes, it's for real."
Your barkeep pours me a nice cold frosty pint of bitters--hey, I'm a
barbaric American and I drink my beer _cold_, thank you very much--and
puts the bill for it on your tab.
I have now defrauded you by using a forged message.  And it's all made
possible by the lack of a hash function firewall.
The practical paranoid interpretation of this:
A second-preimage attack on SHA-1 would be a mathematical advance of
such massive proportions that worrying about its consequences for DSA
signatures is kind of dumb.
If you stay up late at night wondering what will ever happen to "Deal Or
No Deal" in the days after a meteor hits Earth, then you're probably the
type of person who worries about what happens to DSA signatures after a
second-preimage attack on SHA1.  The rest of the world, however, will
have much more important things to worry about.
... Personally, I myself subscribe to the practical paranoid view.

@_date: 2007-08-23 06:29:56
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
This is not my experience.  I've received spam addressed to my amateur
radio call sign (KC0SJE) at a domain that's not directly associated with
me.  I don't know how it was discovered, but for right now I'm leaning
towards the hypothesis that spammers have made pacts with the Devil and
learned dark arts.
Sure it is.
All of us are constrained by external forces.  We don't have as much
time, as much energy, as much money, as much anything as we want.  We
have to make tradeoffs.  That's called economics.
If I know that one sort of antispam measure is going to reduce the spam
I receive 100-fold over the reduction produced by another antispam
measure... and the 100-fold measure takes the same amount of resources
as the other one... then why should I ever use the second measure?
I get a 100-fold reduction from X amount of time and labor, or a
101-fold reduction from a 2X amount of time and labor.  This is really
simple to me; I'm going to take the 100-fold reduction and spend the
extra X time goofing off, or visiting my nephews, or grabbing lunch with
my sister, or doing thesis research, or...
Use the most effective measures available to you, and know when to stop.
If I had 2X units of time, I still wouldn't use the two measures to get
a 101-fold reduction in spam.  I'd spend X time using the technologies
currently available, and I'd spend X time researching new technologies
to try and kick the 100-fold technology up to 1000-fold.  That'd be a
very efficient and economical use of time.
Whoawhoawhoawhoa.  I don't know where you got this from, but it's very
"User IDs do not provide any authentication", okay, that much is true.
If you want authentication, you're really looking for a trusted
signature on the user ID, fine.
But "security wise they are useless" is just barking madness.  Really.
You are apparently not up to date on something called traffic analysis.
 I suggest you look into it.  What you're talking about here is probably
a pipe dream.
If you're that concerned about getting raided, there are two things you
need to do right now.
1.  Stop posting to crypto mailing lists that keep public archives.
Creating an electronic paper trail of yourself saying "I'm concerned
about getting raided by the cops, please help me figure out how to
protect my electronic privacy" is not a very smart thing to do.
2.  Hire an information security professional.  GnuPG can be part of a
security solution, it can even be a very effective part, but it is not
magic fairy dust.  You will not find privacy or security just by
sprinkling a little magic fairy dust here and there and thinking that it
will "just work".  If your needs are this high-level, you need the
services of an information security professional.

@_date: 2007-08-24 15:00:50
@_author: Robert J. Hansen 
@_subject: Questions about generating keys (hash firewalls) 
We need 22 more people.
In a room of 23 people, there are C(23, 2) different pairs, or 253.
You should probably refresh your knowledge of combinatorics before
talking about the birthday paradox.

@_date: 2007-08-24 15:08:05
@_author: Robert J. Hansen 
@_subject: Questions about generating keys (hash firewalls) 
D'oh.  This will teach me to read things quickly.  Oskar was
specifically saying pairs of which Bob was a part, not total pairs in
the room.
(gets out the brown paper bag)

@_date: 2007-08-24 15:15:18
@_author: Robert J. Hansen 
@_subject: Questions about generating keys (hash firewalls) 
Doing a birthday attack is highly nontrivial.  E.g., to do a birthday
attack on SHA256 requires a minimum, a _minimum_, of over 10**17 joules
to be liberated as heat.  That's about as much as you'd get from an
entire full-out strategic nuclear exchange between the US and Russia.
You're talking global climate change at that point, along with potential
mass extinction of humanity.  It's not pretty.
Historical reasons.  Nobody ever thought DSA would be used with anything
other than SHA-1, so if there's only one approved hash function, there's
no need for a hash firewall.
DSS explicitly requires SHA-1 as a hash.

@_date: 2007-08-24 16:18:28
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
In fact, I was wrong--I said PGP supported creating DSA2 keys, which
apparently it doesn't.  I foolishly thought that just because I'd seen
PGP support using DSA2 keys, that it meant PGP supported creating DSA2 keys.

@_date: 2007-08-24 17:46:34
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
This is not the case.  No one had it except me.
Because there is no such thing as an 'insignificant' amount of
resources.  Everything has a price associated with it.  The trick is to
get the most bang for your buck.
Please read the manual.  I am not confusing the two.
Authentication of a user ID is provided by a trusted signature.  Period,
end of sentence.
No.  You also have to trust that Bob isn't playing a game with you.
Yes.  Like I said: you're really looking for a _trusted_ signature.
Clearly, in this case you do not trust Bob to make signatures that are
in accordance with your security policy.
What world do you live in which offers total assurances of anything
other than the inevitability of death and taxes?
This is not a game of certainties.  Security is a game of probabilities.
 Anyone who insists on absolutes needs to stop using computers.
More importantly in the case you're describing, to whom.

@_date: 2007-08-24 18:17:26
@_author: Robert J. Hansen 
@_subject: Questions about generating keys (hash firewalls) 
Well, except that your attack isn't a birthday attack.
A birthday attack involves making a ton of different messages and
checking _all_ messages created to find _any_ collision.
Your attack involves taking one particular message and creating
permutations of it, one after another, looking for a collision with your
particular message.

@_date: 2007-08-25 00:06:34
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
This is not the definition I have seen in use in the field.  In
formalisms, authentication is usually presented as some variety of
inductive reasoning about trust.
Darn right I wouldn't.
If I had good reason to believe Google was up to something nefarious,
there is nothing in heaven or earth that would cause me to say "yes,
that site is authentic."
Trust is the ultimate dealbreaker.  Always has been, always will be.
Authentication in a nutshell, can be summed up in a single sentence.
Unfortunately, you get two choices in how to finish it.
I believe this thing to be authentic, because...
Choose one of the two statements.  If you choose the latter, then
continue the chain.  An example follows:
When my friend John Hawley receives a signed email message from me, he
might deem it authentic because it has a valid signature.
Why is the signature authentic?  Because the key which made the
signature is authentic.
Why is the key which made the signature authentic?  Because a signature
on that key is authentic.
Why is that signature authentic?  Because the key which made that
signature is authentic.
Why is the key which made the signature authentic?  Because that's
John's own key.
Why does that make the key authentic?  Because he just does, all right?
... Trust underlies all authentication.  Follow an authentication chain
far enough and you will always, inevitably, reach trust, some level
where the answer is "because I just do, all right?"  At that point
you've reached your inductive case.  Everything starts from there.
But, in the absence of that first trust, authentication fails.  This is
why trust is a necessary precondition for authentication.  Without it,
everything falls apart.
Authentication is, for lack of a better phrase, a formal inference
system for trust.  Think PROLOG with different semantics.
Arguing from user interface design, as opposed to first principles, is
something new to me.  In fact, your argument undercuts what you're
trying to argue.  OpenPGP provides such a varied level of trusts
precisely because the calculus of trust is so subtle.

@_date: 2007-08-25 08:00:07
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
How do you know it's created by a particular firm?  Who told you?  How
did you find out?  What's the provenance of your information?  How was
it conveyed to you?
Ultimately, you trust _someone_.  Which is precisely the point I made:
trust underlies everything.  Without that fundamental trust, there's no
point talking about authenticity.
Each person gets to decide for themselves what are the fundamental
questions of trust, as well as answers to those questions.  These are
the holiest of the holies in a security policy; these are heartbeats
that animate every policy and mechanism.  Where does the trust lie, and
what implications does this trust--or lack thereof--have on the rest of
the system?
No disagreement, but a terminology note: the terms "keytrust" and
"ownertrust" appear to be on their way out, replaced by "validity" and
"trust".  Speaking for myself, I like this change; it seems to reduce
confusion in newcomers.
This was pointed out in my post.  At some point you say "I trust them
because I trust them."  If you choose to trust someone despite knowing
they are fundamentally untrustworthy, that's your choice, and I don't
have any say in it.
As for me, I choose not to trust people I consider fundamentally
untrustworthy.  Nobody else has a say in that, either.
This is not about being nice or being a jerk.
Authenticity != trust != niceness.  While authenticity is dependent upon
trust, niceness appears orthogonal to them both.
Correct.  On the other hand, if it's signed by someone you trust
(there's that word again), then there's no reason not to use it.  After
all, its provenance is vouched by the signature... the signature is
vouched by the key... the key is vouched by some trust relationship...
and ultimately you reach the "I trust it because I say so and it's my
choice" point.
The signature only says the certificate owner vouches for the provenance
of the code, not necessarily that the author vouches for it.  Unless you
have the special case where the signer is the same as the author.

@_date: 2007-08-25 08:05:31
@_author: Robert J. Hansen 
@_subject: Questions about generating keys (hash firewalls) 
If all you want is to provide a very high level of authentication for
your messages, just stick with the defaults and you'll do just fine.
Seriously.  GnuPG is specifically designed so that the defaults are
sensible for the overwhelming majority of users.
There is no "best" hash.  My usual metaphor is that arguments over the
"best" hash function, the "best" key, the "best" encryption algorithm,
etc., are about as meaningful as debating whether Godzilla or
Mechagodzilla is more effective at flattening Tokyo.  No matter which
one you choose, Tokyo gets flattened.

@_date: 2007-08-25 16:15:08
@_author: Robert J. Hansen 
@_subject: Questions about generating keys 
Yes--which involves trust.  Do you trust the certificate authority?  Do
you trust that the site in question isn't trying to scam you?  Etc., etc.
Trust lies at the root.  Always.
If I actively distrust the people who are providing me with information,
that's much more fundamental than actively distrusting the information
itself.  Failing to trust information because I actively distrust the
people involved in its production and conveyance makes a heck of a lot
of sense to me.
And without that fundamental trust, there is no possible authentication.
Trust lies at the root.  Always.
If you think disagreeing with someone is the same thing as actively
distrusting them, I feel sorry for you.  It is a very poor way to live.
Clearly, I've had the misfortune of knowing worse sociopaths than you have.
How do you know he's Trevor?
How do you know he is who he says he is?  How do you know he's not
impersonating someone named Trevor?
How do you know you're not being taken for a ride?
How do you know you can trust yourself?
Great.  Prove that you exist.  Offer facts and logical reasoning that
affirms your own existence.  Keep in mind that you can't argue using
facts from existence itself, since that reduces down to an assumption of
a fact not in evidence--that existence exists.
Philosophers have been wrestling with this for a few thousand years,
from Rene Descartes' brain-in-a-jar to Gregory Chaitin's holographic
universe to--I'm blanking on his name, but a philosopher was once asked
to refute solipsism and did so by kicking a rock very hard.  While
hopping around on one foot and cursing, he exclaimed "I refute it thus!"
Epistemological reasoning aside, declarative truth lies at the root of
every piece of inductive logic.  In mathematics, they are called axioms.
Take Euclidean geometry as an example: take the most convoluted
construction in Euclidean geometry and you will reduce it down to the
handful of axioms Euclid declared, such as "parallel lines never intersect".
Why do parallel lines never intersect?  Because Euclid declared they
never intersect.  Declarative truth--an axiom.
By definition, axioms offer neither facts or logical reasoning.  They
simply exist.  "I just do, all right?!" is the root axiom of trust.
Why do you think that authenticity is universal?
It's not.  You don't get any say over whom I trust or to what degree.
That has some real significance for signatures.
Alice: You can trust this message from Charlene.  She signed it.
Bob:   Err--why should I trust her signature?
Alice: Because I verified her key.  So the message has a sig, the sig
       came from a key, the key has sigs on it, each sig came from a
       key, one of those keys is mine.  Perfect chain of trust.  There,
       see?  Charlene's message is authentic.
Bob:   ... who are you, and why do I care if your signature is on
       Charlene's key?
Alice: ...
Bob:   ...
Alice: ...
Bob:   Right.  Well, have a nice day!
Trust is a very personal decision.  If I choose to be satisfied by the
company's declaration, that's my business.  If I choose not to be
satisfied, that's my business.
Yes.  Inductive proofs are like that.  You reason by inductive steps
until you reach a basis case.  It's rather a lot like my instructions
for how to climb down a ladder:
1.  If you're on the ground, stop.
2.  Otherwise, move down a rung and climb down from there.
The fact that inductive cases are not basis cases--and likewise, the
fact that basis cases tend to be axiomatic--is so obvious that I'm
having great trouble seeing what you're getting at.
You're begging the question.
Why is it authentic?  Because you've verified it yourself.  Why does
that make it authentic?  Because you trust yourself.  Why do you trust
yourself?  Because you just _do_, all right?
You're trusting that you're not suffering from untreated schizophrenia
or other mental illnesses that would massively impair your ability to
make rational judgments.
You're trusting your eyes.
You're trusting that your PC is displaying the information accurately.
Your trust here is so implicit that you deny it even exists--but trust
lies at the root.  Always.  If root trust is not present, there is no
possibility of authentication.  Ever.
... At this point, Oskar, I have explained this as thoroughly as I can.
In fact, I think I've probably overexplained it substantially, and in
the process annoyed the living daylights out of several people on this
list who just wish this thread would end.
I am not going to respond to this any further.  Please take your last
shot at it and let's put this to bed so that the list can return to its
usual state of happy quiescence.

@_date: 2007-08-26 01:16:18
@_author: Robert J. Hansen 
@_subject: Questions about generating keys (hash firewalls) 
I think I was the one who made that argument and said the margin was
ultimately not worth considering, so I hope you'll forgive me answering
this one despite it being addressed to David.
Anyway.  Yeah, I think that's a fair assessment.  Is there a benefit?
Yes.  Does the benefit matter?  Not really.
Or, as David said, if your property is surrounded by a 1000-foot fence,
a 1001-foot fence is not going to be much better.  If the bad guy can
clear a 1000-foot fence, the additional foot probably isn't going to
stop him.

@_date: 2007-12-05 13:06:56
@_author: Robert J. Hansen 
@_subject: Decrypt problem with large file 
Unless you have done performance metrics with 1TB datasets, I seriously
doubt the accuracy of this statement.  Backing up 1TB is definitely a
torture test; small effects can grow to dominate.  It is very possible
that the additional overhead of the TrueCrypt virtual device driver
layer will more than offset any gains achieved over 7Zip.
It's also very possible that TrueCrypt would be faster.  I don't know.
I haven't done torture tests of the two side-by-side with the same 1TB
Skepticism is most definitely warranted.

@_date: 2007-12-07 16:56:30
@_author: Robert J. Hansen 
@_subject: 'Tis the season. 
'Tis the season for Hanukkah, Kwanzaa, Christmas, Winter Solstice, New
Year's, or whatever your favorite holiday is.  It's a time to be
gracious and to remember to say "please" and "thank you", and also a
time for charitable giving.
It's very hard--if not impossible--to reward the GnuPG developers for
their labors.  To whom should a donation be given?  To the user who
first spotted a bug, the other user who tracked it down precisely, the
developer who fixed it, the sysadmin who hosts the project?  What about
to the mailing list, where so many questions get answered by people who
have no official connection with GnuPG whatsoever?
There are no good answers to this.  The best that can be done is to
issue virtual beer tokens, to say "thank you", and maybe to do something
for a charity with similar goals to that of the GnuPG crew.
So: to all the developers, to all the bugfinders, to all the people who
patiently answer questions on mailing lists, to everyone who contributes
to signal and diminishes noise--thank you, very much, for making this
community as much fun as it is, and for your role in making GnuPG as
high quality a product as it is.  Consider yourselves to all have a beer
token issued by me, payable on demand should we ever meet face to face.
This year, as with last year, I will be donating to the Free Software
Foundation with a note that it's in thanks for the GnuPG Project.  I
encourage anyone who is interested in doing likewise to take a look at:

@_date: 2007-12-12 12:57:49
@_author: Robert J. Hansen 
@_subject: Redistributing the GnuPG Windows Binary 
GnuPG is distributed under the GNU General Public License (GPL).  As
long as you comply with that license, I'm pretty sure the copyright
holders will bless your actions.  :)

@_date: 2007-12-13 07:35:38
@_author: Robert J. Hansen 
@_subject: Backdoor? 
Why would you trust the opinions of random people you've never met?
You don't know us.  You have no reason to trust our statements,
especially about such an important topic.
The source code is out there.  Inspect it yourself.  Make your own
decisions and compile your own binary if you're concerned.

@_date: 2007-12-20 11:01:48
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG's 10th birthday 
70 years?  1990 doesn't seem that long ago.
For those who are not up on German history, prior to German
reunification the German Democratic Republic was one of the most heavily
surveilled nations on the planet.  Watch "Das Leben der Anderen"
sometime (released in the US as "The Lives of Others"; not sure about
how it's named in other foreign releases).
The movie is definitely worth watching.

@_date: 2007-12-20 11:49:51
@_author: Robert J. Hansen 
@_subject: GPG 1.4.x v.s 2.x 
Depends on what you want to do with it.  If you're only worried about
OpenPGP (RFC2440 or RFC4880) traffic, then the 1.4 tree is the one to
use; it has the longest history, more eyes have looked at it, and the
user community is larger.

@_date: 2007-12-20 11:18:49
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG's 10th birthday 
Hash: SHA256
Prove it.
You're asserting "the right to privacy and the means to enforce that
right are so dangerous to our way of life that they must be restricted
in their scope."
That's an extraordinary claim, and it needs extraordinary evidence to
back it up... extraordinary evidence I have never seen from anyone who
has made this claim.
As soon as you can prove that your opinion is correct, then I'll join
the debate you're so keen to start.  But until that time, you're
fearmongering.  Please stop.  We have enough fearmongers in the world
without you joining them.
Come back over to our side of the fence, Graham.  It's scary over here,
but it's also free.

@_date: 2007-12-20 13:04:06
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG's 10th birthday 
I knew you were referring to the World War Two era; I just thought it
was worth mentioning that many Germans lived in a surveillance society
until fairly recently.
I certainly did not mean to imply the modern-day Germany had any part to
play in the GDR's crimes.

@_date: 2007-12-20 17:46:40
@_author: Robert J. Hansen 
@_subject: Hi to the mailing list 
Welcome, Aldo!
Your English is perfectly understandable.  Don't worry about it at
all.  :)

@_date: 2007-12-20 20:08:37
@_author: Robert J. Hansen 
@_subject: Looking for missing Lib modules 
Why not?
Which bjorked dependencies are this?  And are you certain that comparing
Fink to the lead singer of the Sugarcubes is the right way to condemn
it?  I mean, Bj?rk's got some fine music, I'm a big fan of "Human
Behavior".  :)
Anyway.  From 'fink show-deps gnupg':
To install the compiled package...
  The following other packages (and their dependencies) must be
  installed:
    bzip2-shlibs
    libgettext3-shlibs
    libiconv
    libusb-shlibs
    openldap23-shlibs
    readline5-shlibs
None of these strike me as ridiculous dependencies.
The requirements to build from source via Fink are identical to the
above, with the addition of the correct -dev package, as well as texinfo.
I have not heard of anyone having problems with GnuPG in Fink.  If
you're having problems, I'm sure that Benjamin Reed would love to hear them.

@_date: 2007-12-21 00:49:55
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG's 10th birthday 
I seem to recall PGP 2.3 was distributed under the GNU GPL, but I
believe that was the only version that had proper license provenance.
2.6.3i used MPILIB, which was GPLed; however, I don't recall offhand
whether 2.6.3i was an official release.
It's certainly true that no recent PGP has ever qualified as free
software.  I had hopes for it in the beginning, though.

@_date: 2007-12-21 18:30:51
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG's 10th birthday 
To agree with Mark and add a bit more detail--
The United States government has two major intelligence goals for people
of such extreme interest as bin Laden.  They're not picky about which
goal is achieved, so long as one of them is achieved.
In the early days of the Afghan campaign the Taliban commanders were
coordinating their troops with satellite phones.  We coordinated our
satellite-guided bombs with their satellite phones.  Problem solved.
The survivors have undoubtedly learned not to trust any technology more
complex than a frying pan.
Electronic cryptography is almost certainly not being used in a
substantial way by terror groups.  It will help keep the content of your
communications secure.  It will not help hide who you are, where you
are, nor with whom you're communicating.

@_date: 2007-12-27 23:13:16
@_author: Robert J. Hansen 
@_subject: BZIP2 in 1.4.8 
Hash: SHA256
First, I can't recreate this (on Gutsy Gibbon/x86_64).  Probably because
I have libbz2-dev installed; see below.
Second, Ubuntu ships with 1.4.6.  It's a little bit old, but
serviceable, and Ubuntu is tracking upstream security bugfixes.  If your
correspondent is just interested in security fixes, tell him/her to use
the Ubuntu-supplied GnuPG.
Third, most Linux distros (including Ubuntu) separate files into two
different groups: the files you need to run programs that need a certain
feature, and the files you need to compile programs that need a certain
With bz2 the package "libbz2-1.0" contains what you need to run programs
that use bz2; the package "libbz2-dev" contains what you need to compile
programs that use bz2.
I would suggest the following course of action:
1.  sudo apt-get update
2.  sudo apt-get upgrade
3.  sudo apt-get install libbz2-dev
Then try to recompile GnuPG 1.4.8 and see if that fixes the problem.
(Normally I don't sign my mailing group posts here.  Given that I'm
giving sudo commands, though, I think this time it's probably appropriate.)

@_date: 2007-02-08 11:07:58
@_author: Robert J. Hansen 
@_subject: making a passphrase by doubling a password and tweaking the end 
Stupid?  No.  May not be especially wise, though.  GnuPG passphrases,  like root login passwords, are very high-value secrets.  You should  plan for them to be compromised at some point.  If your root login  gets compromised and your GnuPG passphrase is derivable from your  root login, then you've got two high-value secrets compromised.  Vice- versa is the same way.
So while no, you're not wasting entropy, this may not be wise due to  how it complicates your failsafe plans.

@_date: 2007-02-08 14:58:16
@_author: Robert J. Hansen 
@_subject: GnuPG on MS Vista 
Hash: SHA256
Vista has radically changed the process of compiling code for the  platform.  Neither MinGW nor Cygwin GCC work under Vista without  substantial kludges and workarounds; Microsoft recommends against  VS.NET and VS2003; VS2005 is only supported with the latest service  pack and some known issues.  GnuPG will not build with VS2005 without  some major overhauls to the build environment.
While I know that generally the Windows build system involves Linux  and a cross-compiler for Win32, it's very possible behind-the-scenes  changes in Vista will lead to breakage.  It may be worth considering  telling people that Vista is an unsupported OS for GnuPG 1.4.x.
(goes back to hacking CMake and VS2005's command-line compiler)

@_date: 2007-02-08 16:02:10
@_author: Robert J. Hansen 
@_subject: GnuPG on MS Vista 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
That's up to the GnuPG developers, and whether they have any Vista  boxes available to do regression testing on.  They may have already  tested it against Vista; I don't know.

@_date: 2007-02-08 16:37:05
@_author: Robert J. Hansen 
@_subject: New command line language parameter 
Hash: SHA256
The installer requires Administrator rights to install to the program  files directory, just like every other Win32 program that wants to  install there.  Once installed, GnuPG does not require Administrator  rights to run.
This is unwise from a security perspective.  Messing up a registry  file can have terrible consequences.  If you're advocating that  people make edits to a registry file without understanding the  registry, what they're looking at, what they're changing, etcetera,  then disaster is waiting in the wings.
Regular users should not edit the Windows registry.  Ever.
This is by design; it's an important security mechanism.  Alice  shouldn't be allowed to inspect or modify Bob's registry entries.   Only the Administrator should have access to everyone's registry  Please consider the implications of advocating that people bypass a  security mechanism so they can install a piece of security software.   It doesn't make much sense.
Please do not insult regular users by calling them idiots.
The GnuPG installer is suitable for many kinds of Windows users.   Speaking for myself, I administer a small XP network with several  users, all of whom have GnuPG available to them.  Their user accounts  don't have Administrator privileges.  The installer worked just fine  for us.
Sure.  But if you install it as Administrator, then you need  Administrator privileges to modify the file.  If a malicious attacker  has Administrator access to your Windows box, then it's a game-over  condition anyway and there's nothing GnuPG can do to fix this.
According to the Enigmail folks, their number of Windows downloads  are routinely an order of magnitude larger than their number of UNIX  downloads.  This strongly suggests more people run GnuPG on Windows  than run GnuPG on UNIX.
Again, we don't need to insult either users or corporations as being  Get the zip archive, uncompress it to some directory you own, add  that directory to your own personal PATH.
I'm not a professor.  I'm a pre-comps Ph.D. candidate in computer

@_date: 2007-02-08 16:56:35
@_author: Robert J. Hansen 
@_subject: A question... 
Hash: SHA256
Those two lines are required by OpenPGP and must be present in any  clearsigned message.

@_date: 2007-02-09 00:18:19
@_author: Robert J. Hansen 
@_subject: Random numbers 
While this may be off-topic, sometimes the community needs a good  laugh, and today's XKCD provides a good laugh about random numbers.  :)

@_date: 2007-02-15 12:56:58
@_author: Robert J. Hansen 
@_subject: storing password lists in mails to myself on IMAP? 
Hash: SHA256
Can you point me to an IMAP client which does this?  Or to part of the
IMAP RFC which lists "storing arbitrary data for the client's use on the
server" as a feature?  Or an IMAP server which supports this?
Otherwise, this seems to be paranoid fantasy.

@_date: 2007-02-16 12:16:39
@_author: Robert J. Hansen 
@_subject: storing password lists in mails to myself on IMAP? 
I don't know why you have such an allergy to being shown wrong.  Or  why you think I do.
It works like this: if you can find me a commonly-used IMAP client  that's this stupid, then I will welcome being shown wrong.  And  really, why shouldn't I?  Being wrong isn't the end of the world.
But until you can show me an IMAP client in common use which is dumb  enough to store sensitive and arbitrary data server-side, then I'm  going to continue to say this is a nonissue and you shouldn't worry  about it.
You can also assume the existence of MUAs which, when you encrypt  data, will also send an unencrypted copy to a recipient.  This could  be done while still being perfectly in accordance with the OpenPGP  spec.  And yet, we're not worried about MUAs doing it.  Why?  Because  it's so incredibly dumb that we're going to assume people are smarter  than that.  The same logic applies here.
Once you show me a commonly-used IMAP client that's this stupid, I'll  happily admit that yes, I was wrong, and some IMAP client authors are  this stupid.  But until then, what's the use in fearmongering?

@_date: 2007-02-24 12:42:09
@_author: Robert J. Hansen 
@_subject: Why a subkey? 
Hash: SHA256
Please upgrade.  There have been a couple of security updates since  Why must an encryption subkey be generated?  Because you don't have  one.  If you mean "why doesn't GnuPG create an encryption subkey at  the same time it creates a signing subkey, the way it does for DSS/ ElGamal keypairs", for that one you'd have to ask the developers.   It's never made a lick of sense to me, myself.
Having one key that can be used for both signing and encryption  operations is thought by some to be bad crypto policy.  The problems  with it appear to be mostly theoretical, though.
If your other key was DSS/ElGamal, that's because GnuPG created the  additional subkey for you at the same time as your signing subkey.  :)

@_date: 2007-02-26 10:52:03
@_author: Robert J. Hansen 
@_subject: Update 1.4.6 Mac OS configure error 
The configure script can't find a C compiler.  Make sure you have the  XCode development tools installed.
Once you install them, visit  and sign up  for an Apple Developer membership (it's free).  Then download the  latest and greatest XCode tools.  Once those are installed, then do  the ./configure dance over again.
Alternately, try looking at Fink ( which has a  GnuPG package available.

@_date: 2007-02-26 20:58:25
@_author: Robert J. Hansen 
@_subject: Why a subkey? 
Hash: SHA256
I'm guessing that FC4 isn't getting updates very frequently anymore.   This doesn't surprise me, given that it's either been EOLed or is due  for EOLing.
The current version of Fedora is FC6.

@_date: 2007-02-26 23:13:18
@_author: Robert J. Hansen 
@_subject: Newbie Q: decryption 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
As a general principle, I'm unconvinced of the truth of this as a  general statement.
It's risky within certain security models.  Let's not go about saying  it's universally risky.  Let's also not recommend encrypting swap  space _a priori_ without also warning people of the (massive)  performance penalty that can result from encrypted swap.  I recall  seeing some numbers from OpenBSD that indicated encrypted swap  resulted in a 33% slowdown for swap access compared to unencrypted  swap.  This could be related to OpenBSD internals or it could be  indicative of a deeper problem with encrypted swap.  Either way, the  potential downsides of encrypted swap should be considered before  anyone decides to undertake this.

@_date: 2007-01-04 15:51:16
@_author: Robert J. Hansen 
@_subject: Rephrasing the question 
This may not be a useful answer, but it will be an accurate one.  :(
This question cannot be answered.  What does it mean to be 'compliant'?
 The speaker might be asking whether it implements algorithms specified
in FIPS 140-2 (in which case, yes, it does implement many of them).  The
speaker might be asking whether GnuPG has passed a formal NIST-approved
certification process, in which case to my knowledge it hasn't.
Once you can figure out from the speaker precisely what they mean by
'FIPS 140-2 compliant', then we can give you a concrete response.  But
for right now, I'm afraid I'm drawing a blank.  Maybe someone else can
cast some more light on it.

@_date: 2007-01-05 08:17:26
@_author: Robert J. Hansen 
@_subject: Donations 
Hash: SHA256
I think you should think your advocacy.  Telling someone who's just made
a charitable donation "... well, you really should've sent it somewhere
else!" is churlish and rude.  However, that said:
Christmas is a time for donating to charities, not businesses.  Making
charitable contributions to g10 Code makes about as much sense to me as
donating to DaimlerChrysler.  The FSF, on the other hand, is a
charitable organization and it makes as much sense to donate to them as
it does to, say, Oxfam or the World Wildlife Fund.
I suspect essentially everyone in the GnuPG community understands my
position, and feels that contributing to the FSF is an excellent way to
show my gratitude for the work of the GnuPG developers and maintainers.
If I'm wrong, I invite people to say so, so that I may be corrected.  If
I'm right, I invite people to say so, so that you may be corrected.

@_date: 2007-01-09 11:29:37
@_author: Robert J. Hansen 
@_subject: New in GPG KEY Problem 
If you lose your private key, there is no way to recover it.
If you already created a revocation certificate or appointed a
designated revoker, then you can revoke the key which is on the server.
 Otherwise, you're out of luck.

@_date: 2007-01-18 11:41:10
@_author: Robert J. Hansen 
@_subject: Upgrade from 1.0.4 to 1.4.6 
Hash: SHA256
If you want to do a brute-force-and-ignorance approach, you can add
"trust-model always"
... to the end of ~/.gnupg/gpg.conf.  Please do this only if you have
confidence in all the keys on your keyring.
Also, if memory serves GnuPG changed the way it handled options between
1.0.4 and 1.4.6.  Configuration options are now stored in
~/.gnupg/gpg.conf, not wherever they were stored before.  It might be
worth checking to see if your gpg.conf file exists, and if so, what's in it.

@_date: 2007-01-23 00:55:44
@_author: Robert J. Hansen 
@_subject: Symmetric encypher with private key decypher 
While I agree with you, I've always wondered: what is the appropriate
ISO standard for bogs, and where can I find an ISO-certified supplier of

@_date: 2007-01-23 20:25:39
@_author: Robert J. Hansen 
@_subject: passphrase for symmetric encryption  // ?maximum length 
The effective maximum is when you reach 128 bits of Shannon entropy.
Using conversational English, that means about 80 characters of text.
(I'm using Shannon's estimate of 1.5 bits per English glyph.)  Other
languages will have different rates of entropy, and it's fairly easy to
use creative punctuation, misspellings, etc., to jack up the per-glyph

@_date: 2007-01-24 11:12:06
@_author: Robert J. Hansen 
@_subject: working with bare gpg - how to close the text-block 
Yep.  This is exactly what should happen.  If you want to manually enter
an entire GnuPG message and then hit Ctrl-Z, you'll discover it works fine.
Note that due to normal human error rates, you almost certainly don't
want to do this.  But if you have a bad case of OCD, then go for it.

@_date: 2007-01-24 10:35:27
@_author: Robert J. Hansen 
@_subject: working with bare gpg - how to close the text-block 
Ctrl-Z is the standard Windows end-of-file symbol, if memory serves.

@_date: 2007-01-28 18:37:20
@_author: Robert J. Hansen 
@_subject: explain nrsign & lsign? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
For whatever it's worth, I consider this one to be very strongly  Consider the address kc0sje @ myemaildomain.  It's not exactly one  that would be picked at random.  The only published way to find that  address is to enter my ham radio station ID in at the American Radio  Relay League's web page and find "kc0sje @ myemaildomain" as my  contact info--and it seems unlikely spammers would harvest from the  That email address was up on the ARRL's page for a few months before  I added it to one of my keys.  In under a week, I started getting  spams to that email address.
There are two obvious ways I can see spammers picking it up.  Either  (1) they've got a copy of all American amateur radio station IDs and  are polling the ARRL's information, one record at a time, to compile  them, or (2) they're harvesting addresses off keyservers.  Of the  two,  seems far, far more likely.
I agree to this one, too.

@_date: 2007-01-29 00:18:18
@_author: Robert J. Hansen 
@_subject: explain nrsign & lsign? 
Hash: SHA256
While I agree that in general keyserver harvesting is not a huge  problem for the community, we should be wary about thinking it will  not become a huge problem for the community.  Prudence suggests we  consider both alternatives.
This may only mean that there's only one spam syndicate who's  harvesting keyservers, whereas the countless numbers of other  spammers haven't caught on yet.  This could just as easily mean that  other spammers have considered the option and decided it's a bad idea  for whatever reason, and only one syndicate isn't getting the memo.   Hard to say.
The following is anecdotal experience, so it should be taken with a  grain of salt.  Still, it's worth considering.
I spent some time without an email address listed on my key to test  out for myself whether it would present a usability issue.  Turns out  it didn't; putting OpenPGP kluges in my email headers told my  recipients my key ID, which made it possible for them to grab my key  despite there being no email address associated with it.
Ultimately, I decided that since I was already drowning in spam on  all of my accounts anyway, the added trouble was insignificant, even  if the added benefit was insignificant.  I put an email address on my  key and decided I wasn't going to worry about it any more, since I  didn't see it mattered too much either way.

@_date: 2007-01-29 13:53:44
@_author: Robert J. Hansen 
@_subject: Bug? 
Hash: SHA256
[output snipped]
This is not a bug.  This is the expected behavior.
GnuPG is interpreting your command line as "select the first key that  matches the string PGP, enter the edit-key menu, and then execute the  commands Global, Directory, Verification and Key".
gpg --edit-key "PGP Global Directory Verification Key"
... and see if that fixes things for you.

@_date: 2007-07-04 04:45:49
@_author: Robert J. Hansen 
@_subject: Enigmail ... 
First, I would suggest asking on the Enigmail mailing list, instead of
Second, these instructions will uninstall Enigmail.  They will not
uninstall GnuPG.  Uninstalling GnuPG is different depending on what
operating system you're running, and we don't know what you're running.
That said: you uninstall Enigmail the same way you uninstall any other
"Enigmail" and "Uninstall".

@_date: 2007-07-06 11:13:53
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG 2.0.5 released 
Speaking of, Werner, I always thought it was a FSF requirement that all
GNU packages have copyright signed over to the FSF.  Is GnuPG an
exception to the rule, was some special accomodation reached, what?

@_date: 2007-07-17 09:31:01
@_author: Robert J. Hansen 
@_subject: GnuPG and PGP 5.0 compatibility problem 
PGP 5.0 substantially predates RFC2440, the IETF standard which GnuPG  implements.  In fact, GnuPG doesn't even have a PGP 5 compatibility  mode.  (It has --pgp6, --pgp7 and --pgp8, but nothing for PGP 5.)
PGP 5.0 is very, _very_ out of date.  Please consider upgrading to  something more recent and standards-conformant.
To me, this would cause me to doubt whether I wanted them to have my  financial information at all.
Robert J. Hansen "Most people are never thought about after they're gone.  'I wonder
where Rob got the plutonium?' is better than most get." -- Phil Munson

@_date: 2007-07-17 12:11:51
@_author: Robert J. Hansen 
@_subject: GnuPG and PGP 5.0 compatibility problem 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
GnuPG is an RFC2440-conformant application.
PGP 5.0 is not RFC2440-conformant.  It far predates RFC2440.  The two
applications do not work together well.
That's not to say they can't be finessed into working together.  They
clearly can be.  However, I would not trust my financial data to a
communications system that was built of parts that did not interoperate
That said, your security model is your own lookout.

@_date: 2007-07-17 11:57:24
@_author: Robert J. Hansen 
@_subject: where i can download gpgsm? 
Hash: SHA512
Authenticate the source code, not the site you're downloading it from.
Check to make sure the source code is signed by someone you trust
(whether it be the Debian project, wk, or someone else).  If it is, and
the signature is valid, then use it with confidence.
That said, I don't think gpgsm has an "official site".  It was, IIRC,
part of Project ?gypten, which has since been supplanted by ?gypten2.

@_date: 2007-07-18 11:35:03
@_author: Robert J. Hansen 
@_subject: GnuPG and PGP 5.0 compatibility problem 
Hash: SHA256
 From RFC2440, section 9.1, public key algorithm 16 represents an  encrypt-only Elgamal key.

@_date: 2007-07-18 11:41:52
@_author: Robert J. Hansen 
@_subject: GnuPG and PGP 5.0 compatibility problem 
Also, be careful when you say "standard OpenPGP algorithms".  You're  citing RFC2440bis22 here, which is a draft revision of RFC2440.  It's  still a work in progress, so citing it as a canonical reference is  probably unwise.
The canonical RFC2440 (dating from November 1998) only has symmetric  cipher entries from 0-9 and hash algorithms up to 7.
Robert J. Hansen "Most people are never thought about after they're gone.  'I wonder
where Rob got the plutonium?' is better than most get." -- Phil Munson

@_date: 2007-07-22 13:48:20
@_author: Robert J. Hansen 
@_subject: How Do I Export Secring & Pubring Armored Files? 
I suppose you've tried looking at the manpage?
This looks like a PGP keyfile, not a GnuPG keyfile.  GnuPG uses the .gpg
Assuming that it's really a GPG keyfile, just:
gpg --armor --export > pubring.asc
Again, it looks like a PGP keyfile, not a GnuPG keyfile.
gpg --armor --export-secret-key > secring.asc

@_date: 2007-06-03 22:12:50
@_author: Robert J. Hansen 
@_subject: Can't generate new keys 
Hash: SHA256
Additionally, the command 'chown -R my_user_name:my_user_name .gnupg'  can do magic to fix these problems.

@_date: 2007-06-11 12:11:08
@_author: Robert J. Hansen 
@_subject: Revoke and expire 
Hash: SHA256
It depends on what you mean by "same effect".  You can't encrypt a  message to an expired key, precisely because it's expired.  You can't  encrypt a message to a revoked key, precisely because it's revoked.
If by "same effect" you mean "both keys are equally unusable", then  yeah.  Same effect.
If by "same effect" you mean "they work the same way", then no.   Different.  With one, GnuPG simply sees that the key has expired.   You can unexpire the key just by resetting your computer's clock.   With the other, GnuPG sees the key has been revoked, and unrevoking  it is kind of problematic.

@_date: 2007-06-11 12:08:31
@_author: Robert J. Hansen 
@_subject: PGP software pirated 
Hash: SHA256
All license enforcement mechanisms are fundamentally DRM  technologies.  DRM uses encryption algorithms, but DRM is not an  encryption algorithm.
Pretty much all computer security authorities agree that DRM is a  shell game.  Not only doesn't it work, but it can't work.  There are  some very strong arguments supporting this proposition.
Don't worry about encrypted messages.  There's very little chance  that someone has figured out how to break the crypto going into an  OpenPGP-encrypted message.  All that's happened is a DRM system has  been circumvented... again.
Due to the provisions of the Digital Millennium Copyright Act, this  is a very dangerous question for any U.S. citizen to answer.  An  overzealous federal prosecutor could easily claim that an in-depth  technical explanation amounts to trafficking in circumvention devices.
If other people want to answer you, they certainly can.  However, I'm

@_date: 2007-06-12 12:16:08
@_author: Robert J. Hansen 
@_subject: PGP software pirated 
Because DRM is not the same as encryption.  It's like saying "just
because you saw a car break down doesn't mean there's a fundamental
problem with the wheels that we all use every day."
DRM uses encryption, but DRM has a _lot_ more going on under the hood.
It's far more likely that, _if_ the PGP license key was compromised,
that it was compromised by an insider who knew it, that it was
deliberately leaked, that it was... etc., etc.  Breaking the crypto
involved is literally the last thing on the list to consider.

@_date: 2007-06-13 15:43:18
@_author: Robert J. Hansen 
@_subject: Revoke and expire 
Hash: SHA256
You don't.
Data can only be added to keys on the keyservers.  It can't be  removed.  This is a deliberate design decision on the part of the  keyservers, and helps to prevent certain kinds of attacks.
However, given that revocations typically happen by adding a  revocation signature, by removing the revocation signature from your  own local copy of the key you should be able to make the key usable

@_date: 2007-06-16 12:47:25
@_author: Robert J. Hansen 
@_subject: RSA 1024 ridiculous 
Hash: SHA256
I'll get back to this bit in a moment.  ;)
Not necessarily.  There's certainly a strong argument to be made for  moving to RSA-2048, but just because something is susceptible to an  attack involving an enormous amount of horsepower doesn't mean that  it's useless.  As an example, you apparently have no objection to  signing with SHA1, despite the fact it's subject to an attack  requiring a work factor of about 2**63... which is in the same  ballpark as factoring RSA-1024.
If it takes over a CPU-century of number crunching and  extraordinarily special mathematical properties to be able to break  RSA-1024, then I think the RSA-1024 keys I use for secure SMTP are  just fine.  Likewise, credit card transactions secured by RSA-1024  SSL certs are probably just fine for now; there are far, _far_ easier  ways to get credit card numbers than to rent a year of supercomputing  time just to get the key to _one_ web site.
We should be migrating to RSA-2048, sure.  Just like we should be  migrating to SHA256.  But it's not the case that RSA-1024 is  'ridiculous' or the OpenPGP card is 'a joke'.

@_date: 2007-06-20 12:09:23
@_author: Robert J. Hansen 
@_subject: RSA 4096 ridiculous? (was RSA 1024 ridiculous) 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Yes and yes.
I far prefer PGP 8.1 over PGP 9.0+, and I've heard comments from many  other users who say likewise.  The thing which is killing PGP 8.1 is  its lack of support for creating SHA256 messages, not its age.
Many people still use PGP 6.5.8, which dates back to pre-2000.
PGP 9.6 is the latest.

@_date: 2007-03-06 09:06:55
@_author: Robert J. Hansen 
@_subject: 1.4.7 packages for OS X 
Hash: SHA256
I've taken the liberty of packaging up 1.4.7 for OS X.  (I apologize  to Benjamin if I'm stepping on his toes here; by my recollection,  he's doing packages for 2.0.x, not 1.4.x, so I _should_ be safe.)
They haven't been tested broadly, but so far they've worked on every  system I've thrown them at (five machines, a smattering of Intel and  Please note that these packages include IDEA support, which may  (depending on your jurisdiction) give you some patent troubles.   Please be responsible and download in accordance with your region's  laws and the GNU GPL, and please only use IDEA for reading existing  messages and not for creating new ones.
Signatures for the two packages can be found at:
Clearly, GnuPG.org is the appropriate site to refer people to for  source code.  However, to keep everything according to Hoyle, source  code is also available from:

@_date: 2007-03-06 22:17:43
@_author: Robert J. Hansen 
@_subject: 1.4.7 packages for OS X 
Hash: SHA256
Tiger has been out for two years now; I think it's reasonable to  think that, unless specified otherwise, software will be targeting  Unfortunately, I can't help you.
I would also recommend switching to one of the free Unices if you  don't want to upgrade to 10.4 or 10.5.  Once 10.5 comes out, 10.3  will probably be EOLed and there will be no further security  updates.  Please give serious thought to either (a) migrating to a  free UNIX or (b) upgrading to 10.4/10.5.

@_date: 2007-03-07 11:29:22
@_author: Robert J. Hansen 
@_subject: 1.4.7 packages for OS X 
Hash: SHA256
Thank you for being gracious.  :)
I updated the packages (very slightly) to install into /usr/local,  instead of /usr.  It seems to be a tradeoff--while I know a few OS X  users who have (for reasons inscrutable to me) elected to remove /usr/ local from their PATH, there are a fair number of OS X crypto apps  hardwired to expect it in /usr/local.  Mulberry, GPGMail, etc.
The original links still work; they point to non-IDEA-enabled  builds.  For completeness' sake, the links are all listed here:
Signatures are available at:
Warning: these packages still have not been extensively tested.

@_date: 2007-03-07 11:50:50
@_author: Robert J. Hansen 
@_subject: [Macgpg-users] 1.4.7 packages for OS X 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Usually, these "normal" OS X apps are Cocoa apps.  If it has a nifty- keen GUI on it, odds are good that it's a Cocoa app and is thus  packaged as a .app.  But otherwise, odds are good that it's a regular  UNIX utility and will be packaged like a regular UNIX utility.
For instance, the Apple Developer Tools are packaged both like .apps  and like regular UNIX utilities.  XCode is a Cocoa apps, and as such,  it's packaged as a .app.  But Apple's C compiler is a regular UNIX  utility, and as such, it's packaged as /usr/bin/gcc.

@_date: 2007-03-07 19:39:50
@_author: Robert J. Hansen 
@_subject: 1.4.7 packages for OS X 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
I don't see any real difference between the two, really.  If it's not  legal to distribute the single binary with IDEA, then it's not legal  to distribute the module.  And going the module way, you wind up  getting a large number of support requests saying "I downloaded the  module, but I still can't read IDEA traffic", since people tend not  to be all that familiar with editing gpg.conf.
I should also point out, while I'm at it, that I don't recommend  using IDEA.  But the old RSA/IDEA legacy is unlikely to go away  anytime soon, not as long as there's a ton of poorly-written  anonymity software that depends on PGP 2.6.

@_date: 2007-03-13 14:51:56
@_author: Robert J. Hansen 
@_subject: GnuPG incompatible with windows-vista ? 
For what it's worth, Vista appears to have major problems with any  program which depends on there being a libexec prefix.  Whenever  using a program that uses libexec helper programs, you're going to  have problems--at least, I always did.
I had Vista installed for a few weeks (work-related development) and  ultimately said to hell with it, based on the incredible difficulties  I faced in getting Cygwin, MinGW, GnuPG, etc., to work.
For an example of this affecting MinGW, please see:
... For now, I think it would be prudent to say that GnuPG on Vista  is unsupported and not recommended.

@_date: 2007-03-13 23:47:35
@_author: Robert J. Hansen 
@_subject: GnuPG incompatible with windows-vista ? 
The software needed to build it doesn't exist for Vista.  Either  Cygwin or the MinGW compilers are needed, and neither of them work  with Vista at this point.  (MinGW fails with the same problem that's  afflicting GnuPG, it appears.)
It's possible to build trivial apps with Cygwin/MinGW on Vista.  It's  not possible to do serious work.
For now, the only real solution is to cross-compile for Vista or else  mangle the GnuPG source enough to make it work with MSVC2005.   Neither solution appears optimal.
I think John Moore's the go-to guy for building GnuPG on Windows XP.   I don't know if he has any insights into compiling GnuPG on Vista,

@_date: 2007-03-16 19:52:29
@_author: Robert J. Hansen 
@_subject: HowTo make a donation to gpg... 
This has been asked a few times.  The last time it was asked, the  developers said that it would create a lot of problems.  How should  the money be split up?  While the developers certainly deserve  credit, so too do people on mailing lists who help newbies, so too do  people who search through the code and find bugs, so too do...  etcetera, etcetera.
However, GnuPG is--as you can guess from its name--a GNU project,  which means it's closely affiliated with the Free Software  Foundation.  The FSF is a non-profit charity headquartered in the  United States, and gratefully accepts donations.

@_date: 2007-05-02 19:38:23
@_author: Robert J. Hansen 
@_subject: [Possible SPAM] Re: UID changes (was Key Revocation) 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 > pub   1024D/98E6705C 2005-11-23
 > uid                  Chris Pollock (New email address as of 04/21/07)
 >  > uid                  Chris Pollock No need to put the (New email...) comment in place.  The rule of  thumb is to assume that any UID that's (a) not been revoked and (b)  is signed by someone you trust is a good one, and the others are all

@_date: 2007-05-07 10:54:44
@_author: Robert J. Hansen 
@_subject: Extra key best solution for very insecure locations? 
Hash: SHA256
The (regrettably) short version: there isn't one.
Physical control of hardware is a prerequisite for the safe use of  any security software.  Without that physical control, you're taking  some substantial risks.

@_date: 2007-05-07 21:49:40
@_author: Robert J. Hansen 
@_subject: PRZ hospitalized 
Hash: SHA256
According to Jon Callas, PRZ has been hospitalized for cardiac  surgery.  Callas says there's "no ... immediate danger, but they're  pushing him into the hospital quicker than any reasonable person  would like".
I have no idea how to get well-wishings to him, but his email address  is pretty widely known.  So if you're of a mind to be kind, well,  now's the time.

@_date: 2007-05-10 21:56:52
@_author: Robert J. Hansen 
@_subject: Callas on PRZ 
"[PRZ is] out of surgery, doing well, and the doctors say he'll be  than he's been for ten years."
I have no further information.  Please keep PRZ in your thoughts,  prayers, and superstitions, as appropriate to your beliefs and/or  lack thereof.  :)

@_date: 2007-05-14 05:37:57
@_author: Robert J. Hansen 
@_subject: Old PC as Hardware Security Module? 
What particular type of HSM do you mean?
I'm assuming you're doing something incredibly high-value, like  storing nuclear weapon release codes or voting data or mortgage  contracts or classified material or... etc.  If that's the case, then  you need to talk to a professional and not the sort of more or less  anonymous advice you're likely to get from a mailing list.
If you're not doing these incredibly high-value things, then you may  want to rethink your threat model.  This appears to be excessive  overkill for most threat models I can imagine.
I'm certainly not going to tell you that you shouldn't be doing these  things.  I don't know you and I don't know what you face.  All that  I'm doing is asking you to sit down and think critically about your  model.  I hope I can do that without sounding dismissive of your  The OpenPGP card actually gives you a substantial advantage in this  Let's say that you're running GnuPG on a PC and I'm able to subvert  the box.  I put in a keylogger and snarf your passphrase.  I also  copy your private keyring and mailspool off the box.  I can now read  your mail without ever touching it, except to copy a couple of files  and install a small app.  You're none the wiser.
Compare this to an OpenPGP card, where I have to find you in a dark  alley and have a conversation with your kneecaps to get your card and  PIN.  You will most probably know that something has happened to you.
To my understanding, the OpenPGP card is tamper-resistant.  That's  not to say it's tamper-proof, but it would require substantial work  to get access.  I would not worry too much if your card fell into the  wrong hands, unless those wrong hands happen to belong to a First  World intelligence service, a major international corporation, or  some ambitious CompSci or EE graduate students.
You do know that Werner Koch, one of the central developers of GnuPG,  is German, right?  And that GnuPG at one point took some funding  (long since spent) from the German government?
If you're concerned about Germany involving itself in the crypto  software business, you should probably not use GnuPG.  That said, I  am not concerned about this.
Governments accuse each other of stealing classified material.   Corporations accuse each other of stealing proprietary material.
Force?  No, I can't think of a single one.  Not even the UK's  ridiculous Regulation of Investigatory Powers Act (RIPA) went that far.
On the other hand, they can certainly attempt to persuade.   Patriotism, vanity, greed, fear... there are many ways to motivate  someone to cooperate with you.  Governments are generally very good  at persuasion.

@_date: 2007-05-14 06:45:32
@_author: Robert J. Hansen 
@_subject: Old PC as Hardware Security Module? 
There exist cryptographic smart cards you can actually be safe  against this kind of attack with.  They're pretty cool.  I don't know  if the OpenPGP card is one of them or not, but it's at least possible  with a smartcard.  It's not possible with a PC-controlled setup--at  least, not without a ton of specialized hardware.
My objection to smartcards is more on the basis of RSA-1024 being too  short for long-term security, but hey.
The question isn't whether smart cards are secure--nothing that's got  that much RAM and processor power ever is--but whether smart cards  are a security improvement.  On that one, I think they have the  potential to bring substantial amounts of win to certain kinds of  environments.  To other kinds of environments, they don't.  C'est la

@_date: 2007-05-14 11:37:21
@_author: Robert J. Hansen 
@_subject: Old PC as Hardware Security Module? 
A (very) small display to show the hash that's being signed and an  integrated PINpad.  PC sends data to the smartcard unit for signing,  then signals the SC unit "okay, I'm done, sign now, please".  SC  pauses to display to the user the hash and get the PIN directly on  its own trusted hardware.  If the PIN is entered, SC does the  signature and tosses it back to the PC.  If the operation is  canceled, SC returns some kind of op-cancelled value.

@_date: 2007-05-14 14:52:37
@_author: Robert J. Hansen 
@_subject: Secure text editor? 
Hash: SHA256
Wildly implementation dependent.  POSIX 1003.1b-1993 and 1003.1i-1995  are the canonical references, but different OSes will implement it to  different extents.
The mlock manpage is probably the best place to begin from.

@_date: 2007-05-15 01:58:53
@_author: Robert J. Hansen 
@_subject: Old PC as Hardware Security Module? 
I apologize if I sound terse here, but this conversation has (IMO)  jumped the shark.
Cf. Thompson, K. _Reflections on trusting trust_.  Comm. ACM 27, 8  (Aug. 1984), 761-763.
A digital version of it is currently available at  classics/sep95/, but links tend to be ephemeral, so read it while you  Once you've read it, decide whether you can even trust the compiler  you're using to compile GnuPG.  Finally, come back here and see  whether that same logic can be used to decide whether to trust GnuPG.
If you're chasing a neverending shadow of "well, someone might attack  the system this way...", you're ultimately left hand-hacking machine  instructions for a low transistor count chip whose design you have  personally validated and lithographed onto a sliver of six-nines pure  silicon you smelted yourself.
That's what lies at the bottom of this rabbit hole.

@_date: 2007-05-15 03:11:38
@_author: Robert J. Hansen 
@_subject: Old PC as Hardware Security Module? 
Fascinating.  I'm not sure that it overcomes the problem, but  detection is probably 90% of the fight anyway.  Thanks for the link!
[goes off to read the paper again]

@_date: 2007-05-15 03:42:12
@_author: Robert J. Hansen 
@_subject: Printing Keys and using OCR. 
QR coding is pretty nice.  3kb of binary storage per bitmap, and it's  an international standard: ISO/IEC 18004.  There may be an open- source implementation of it already.  If there's not, you could do  the community a favor by writing one.  :)

@_date: 2007-05-15 04:33:17
@_author: Robert J. Hansen 
@_subject: Old PC as Hardware Security Module? 
'Legitimate' is a bad word to use.  Is it legitimate?  Sure, I guess,  as long as you live in a nation with strong freedom of speech laws.   If you live in Cuba, you might get some inquiries from the police  about your interest in cryptography.  Certainly, nobody here is going  to tell you that you can't talk about these subjects.
But is it wise?  Is it productive?  Probably not.
The idea that there should be a discussion about what level of trust  GnuPG deserves is, frankly, absurd.  It implicitly casts the  discussion in terms of there being a single Platonic ideal for what  GnuPG should do, and a yardstick with which to measure how well GnuPG  matches the ideal.
I don't mean to sound rude here, although I'm afraid it's going to  come out that way.  Please read this as if my tone is calm and  sympathetic, not harsh and bitter.
For you, maybe it should be.  For me, maybe it shouldn't.
As an example, when I was an exchange student in Germany my host  father was a German state prosecutor.[*]  Do you think he would be  more or less likely to use JAP on the basis of his knowledge that it  the JAP folks at Dresden would cooperate with law-enforcement?   Should we think that his opinion is right or wrong, just because it  contradicts your position?
Werner already gave you this answer, more or less.  What he said was:
   "For whatever reasons the JAP folks at the Dresden university  decided that
    they want to help them.  There was no actual need.  I recall a      conversation with the resonsible professor where he told me: yes,  I am
    in favor of anonymity but there needs to be a limit; child porn  is enough
    of a reason to help the prosecution office."
Different people will have different security policies, there's  nothing you can do to change that, and the fact the policies are  different doesn't say anything about whether you're right and they're  wrong or vice-versa.
You get to decide your security policy.  You don't get to decide  anyone else's.  In fact, I think it's unethical to even try to  influence other people's security policy.  I think the most you can  ethically do is calmly present information, separate the things you  can prove from the things you suspect, distinguish objective fact  from subjective opinion, and trust that if enough people do this, we  will all be enriched.
[*] You Germans on the list, you have no idea how much I envy you.  I  left Hildesheim in '94 and I've wanted to return ever since.  It's  the first city I ever found that felt like home to me.  I've missed  it ever since.
Yes.  Because why are you even bothering asking such an important  question like that on the internet?
You don't know me.  For all you know I work for the NSA.  Why would  you put any stock whatsoever in my opinion?
If this is the sort of question you want to ask, then find people you  know, people you know to be wise, people you know to be calm, people  you know to be reasonable.  People you trust.  Ask them, talk it over  with them.
You don't know me and that means you probably shouldn't trust me.   Despite that, you appear to be putting an awful lot of emphasis on  getting me to agree the sky is falling.  This makes me think that you  want to use my opinions as a drunkard uses a lamppost... for support,  not for illumination.

@_date: 2007-05-17 13:59:43
@_author: Robert J. Hansen 
@_subject: Printing Keys and using OCR. 
As an example, the modern paper ballot is about 2,200 years old.  The  reason why we know this is we keep finding them.  They practically  litter archaeological digs around Rome.
That said, for paper to last so long it needs to be archival-quality  paper.  High fiber content, low acid, very enduring inks.  But it's  certainly possible to get 2,000+ years out of paper for under $1 per

@_date: 2007-05-18 06:15:28
@_author: Robert J. Hansen 
@_subject: Java and GnuPG 
I would recommend against this if you're going to be running on Windows.
See, e.g.:
... That bug is still unresolved.  It may still be lurking for you to
walk into, if you decide to write your own Java wrapper for GnuPG.
If you need OpenPGP from within Java, BouncyCastle is probably the
better way to go.  If you absolutely need GnuPG, then (a) don't host
your app on Windows and (b) just treat it like you would any other
Process.  E.g.:

@_date: 2007-05-18 15:37:59
@_author: Robert J. Hansen 
@_subject: Printing Keys and using OCR. 
Not academic at all.  If we know that paper will last for >2000 years  assuming just basic precautions, then we know that the lifetime of  our media will not be the limiting factor on the lifetime of our  private communication.
There's something to be said for the knowledge that one part of your  system is that phenomenally overdesigned.
Robert J. Hansen "Most people are never thought about after they're gone.  'I wonder
where Rob got the plutonium?' is better than most get." -- Phil Munson

@_date: 2007-05-23 21:46:53
@_author: Robert J. Hansen 
@_subject: decryption not possible? 
Without more information, it's impossible to tell you anything  useful.  We need to know a lot more than this.
Robert J. Hansen "Most people are never thought about after they're gone.  'I wonder
where Rob got the plutonium?' is better than most get." -- Phil Munson

@_date: 2007-05-24 11:47:16
@_author: Robert J. Hansen 
@_subject: easy way to confirm email validity 
Hash: SHA256
The obvious way is to suggest they use an OpenPGP application, such  as GnuPG or PGP, to verify your signature.
It all depends on whom you're willing to trust, and how much you're  willing to trust them.
If they need to validate your email, OpenPGP is one of the best ways  to do it.  S/MIME would also work well for the task.
(Given that this is the GnuPG-Users mailing list, any further  comments I make on this will be GnuPG only.  However, honesty  required that I point out alternatives.)

@_date: 2007-05-27 04:02:29
@_author: Robert J. Hansen 
@_subject: Can't run GPG --recv-keys under Windows Vista. 
Hash: SHA256
 > I've installed gpg on Windows Vista recently, but seems not all the
 > functions work well when I try to receive keys from keyserver.  Here is
 > the command I typed:
This is probably because of how Windows Vista has changed how  programs may call other programs.  It is a (semi-)known compatibility  issue with Windows Vista; an awful lot of programs are suffering from  some of Vista's 'improvements'.
For time being, it's best to consider GnuPG on Vista to be  unsupported and not recommended.

@_date: 2007-05-27 19:20:56
@_author: Robert J. Hansen 
@_subject: Can't run GPG --recv-keys under Windows Vista. 
Hash: SHA256
Turning off UAC is definitely not recommended practice, according to  Microsoft.  Microsoft strongly advises UAC be left on, and they have  some good reasons for it.  Any discussion of whether to leave UAC on  or off should at least make mention of Microsoft's advice.
Please try to practice courtesy.  This mailing list has a very high  signal to noise ratio.  Let's all do our best to keep it that way.

@_date: 2007-05-28 05:59:29
@_author: Robert J. Hansen 
@_subject: Can't run GPG --recv-keys under Windows Vista. 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
UAC is Microsoft's answer to 'sudo'.  If you want to call UAC an  extra layer of protection, then you should also call sudo an extra  layer of protection.
With respect to it not working very well, from a user interface  perspective it's a nightmare.  From a technical side it's probably  one of the better improvements in Vista.
If you want to give reasoned, factual corrections, please go right  ahead.  But there's no reason to be rude or mean.

@_date: 2007-05-29 16:15:49
@_author: Robert J. Hansen 
@_subject: Can't run GPG --recv-keys under Windows Vista. 
Anyone who casually dismisses vendor documentation and  recommendations probably does not have much of a future as a  sysadmin.  That's not to say the vendor should always be obeyed, of  course.  But the vendor's recommendations should be read, considered  and understood before deciding whether to throw them away.
Discussion about how to get GnuPG working with Vista is probably  fine, but Windows bashing seems a bit off-topic.
Robert J. Hansen "Most people are never thought about after they're gone.  'I wonder
where Rob got the plutonium?' is better than most get." -- Phil Munson

@_date: 2007-05-31 14:40:40
@_author: Robert J. Hansen 
@_subject: Re-establish keys 
============================== START ==============================
You don't.
It is computationally infeasible to recover a private key from only a  public key.  The key server has half your keypair.  To derive the  other half would require radical breakthroughs in mathematics and  computer science, and/or access to time and energy on a truly cosmic  Robert J. Hansen "Most people are never thought about after they're gone.  'I wonder
where Rob got the plutonium?' is better than most get." -- Phil Munson

@_date: 2007-11-01 13:52:53
@_author: Robert J. Hansen 
@_subject: GNuPG Newb 
GnuPG and PGP both support the OpenPGP specification (RFC2440).  They
also each have some additional functionality.  PGP has a mail proxy as
part of its additional functionality.  GnuPG does not provide this.
I am not fond of the mail proxy idea, myself.
Probably not.  I/O redirection will probably do the job for you.

@_date: 2007-10-31 19:26:15
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
Yes.  E.g., I may wish to give shares to my best friend and my cousin.
This way, even if their homes and/or offices are broken into, or one of
them misplaces/loses their share, I don't need to worry about where that
copy is: I just have the other person burn their share and issue two

@_date: 2007-10-31 19:59:31
@_author: Robert J. Hansen 
@_subject: AS400 PGP 
Right.  This may be an ambiguity in English: 'product' can mean either
'owned by' or 'created by'.  I should have specified "created by g10
Code and the GnuPG community."  It wasn't my intent to mislead anyone
with respect to the copyright holder.  Thank you for clearing up my
clumsy words.  :)

@_date: 2007-10-31 20:50:55
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
Doesn't help if I'm dead.
I have some encrypted traffic which my estate will need to read in the
event of my death.  So I can give my key and passphrase to my lawyer, I
can store a copy in a safe deposit box, I can... etc.
But all options involve leaving my key and passphrase under the control
of a single person.  A single person can make mistakes.  They can be
corrupted.  They can lose it.  They can... etc., etc.
Secret shares make it possible for me to give shares to people I trust
not to conspire against me, as opposed to people I trust to never make
typical human errors.  I am fortunate enough to have a fair number of
the former, but like most people, none of the latter.

@_date: 2007-10-31 21:42:06
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
Fewer things can go wrong.
Secret shared passphrase + private key: what happens if the private key
is unavailable?  E.g., I die when my house burns down and my computer
cooks and even my back-ups are toast.  With a SS passphrase, I have to
make off-site backups of my private key... and then I have to make sure
that those off-site backups are still readable, since CD-Rs tend to go
bad... and if I replace one, I have to make sure the passphrase is the
same as the secret-shared passphrase...
Secret shared paperkey: the private key is available as long as the
secret shares are available.  OCR the SS paperkey, recover the private
key, boom, you're off to the races.
Fewer components, fewer steps, fewer dependencies, longer-term storage:
it's an all-around win.
147 bytes is not an onerous reconstruction job, even if you have to do
it by hand.  Base64 it and it's about 200 characters, or two and a half
lines of text.

@_date: 2007-11-02 13:59:05
@_author: Robert J. Hansen 
@_subject: RSA Weak? 
RSA has never lived up to people's grand expectations.  Advances in
computers and algorithms cause the sorts of RSA keys we can attack to
creep ever so gradually upwards.  It's reasonable to think that within a
decade an attacker with a ridiculous amount of resources will be able to
break RSA-1024.
Our current crop of conventional techniques will likely stall out there.
Not even people with RSA-1024 keys should be doing this.  RSA-1024 is
only insufficient if you have things you need to keep secret from
phenomenally well-equipped people who are willing to spend millions of
dollars to recover your data.
Even if you have adversaries like this, it is still very unlikely they
would ever actually do it.  There are much more cost-effective ways to
get your confidential information than spend millions of dollars
breaking your RSA-1024 key.
This is not something to be concerned about.

@_date: 2007-11-02 15:00:45
@_author: Robert J. Hansen 
@_subject: RSA Weak? 
A keyspace of 1024 bits is double that of 1023 bits.  Prime numbers
become more scarce as they go on.  For instance, there are two primes in
a keyspace of two bits.  In a seven-bit keyspace--which, by your logic,
there should be thirty-two times as many primes--there are only twelve
and a half times as many.
Primes are spaced out further and further as numbers grow larger and larger.
In this case, Arjen Lenstra is closing in on RSA-1024 with great
alacrity.  Lenstra is a reputable cryptographer, and his results are
quite interesting.
Read this:

@_date: 2007-11-02 15:49:07
@_author: Robert J. Hansen 
@_subject: RSA Weak? 
A good first-order approximation for the number of primes with a certain
number of bits is given by the formula:
  X = 2**number of bits
  Y = 2**(number of bits - 1)
  (X ln Y - Y ln X) / ((X ln Y) * (Y ln X))
I don't know what you mean by 'scale by the same factor'.  But hey, if
you want approximations, there you go.  For small numbers this will be
off by a significant amount, but it asymptotically grows better.
If the keyspace grew linearly, it would be a trivial problem to factor.
 Just throw more cycles at it.
The entire point is that the keyspace grows exponentially.  You were
arguing the exponential factor is two, which it's definitely not.  In
reality the exponential factor of difficulty added per bit changes
depending on how large your key already is.  If your key is small,
adding one bit can substantially increase your security.  If your key is
large, adding one bit is a who-cares? proposition.
If it helps, the National Institutes of Science and Technology (NIST)
has estimated a 1024-bit key is roughly equivalent in computational
complexity to an 80-bit symmetric key.
Such as, say, the generalized number field sieve?
This has no connection whatsoever with factoring.  Miller-Rabin is used
to test primality; it does not give you any useful information about the
factors of a number.

@_date: 2007-11-02 16:01:31
@_author: Robert J. Hansen 
@_subject: RSA Weak? 
People who do not know what P stands for should not attempt to whap
other people around with it.
P is shorthand for deterministic polynomial time.  NP is
nondeterministic polynomial time.
Factoring is known to be in NP.  Therefore, it is perfectly fair to say
that it's a polynomial problem, as long as Sven is not claiming that
it's deterministic polynomial, which he isn't.
Nondeterministic polynomial time means it can be solved in polynomial
time by a nondeterministic Turing Machine--a machine that is capable of
making phenomenally lucky guesses.  Deterministic polynomial time means
it can be solved in polynomial time by a Turing Machine that cannot make
phenomenally lucky guesses.
... Incidentally, I'm assuming you meant 'factoring composites'.
Factoring prime numbers is most definitely in P.  It's also in NC and
Context-Free, but probably not Regular; you need a pushdown automata to
parse the number as you read it, which means a context-free language is

@_date: 2007-11-02 16:27:02
@_author: Robert J. Hansen 
@_subject: RSA Weak? 
If you have a proof that P is much smaller than NP, a million bucks is
yours for the claiming.
Factoring, in the general case, is in NP.
Factoring, /specifically applied to prime numbers/, is in Context-Free.
Like most math problems, there are certain special forms of problems
that are easier to solve than others.  If I ask you to factor
2,147,483,647, well, that might take you a very long time.
If I tell you that 2,147,483,647 is a prime number (the eighth Mersenne)
and ask you to factor it, you don't have to do any computation at all:
you just give the number back to me and you're done.  You can skip the
entire computation step.
When numbers are in a special form, there often exist special purpose
algorithms that are much more efficient than the general purpose
algorithms one would otherwise be forced to use.

@_date: 2007-11-02 16:13:44
@_author: Robert J. Hansen 
@_subject: RSA Weak? 
Well, we know it's in NP, since polytime verification is possible; and
there are strong arguments that it cannot be NP-HARD, because then it
would exist in both NP and Co-NP, which would lead to various proofs
that would collapse an awful lot of mathematics as we know it.
It's been (trivially) proven factoring exists in NP and also in Co-NP.
The open question is whether it is NP-HARD or Co-NP-HARD.  If it's
NP-HARD, then everybody is in a whole lot of trouble; a proof of
NP-HARDness would nead to a proof that factoring was NP-Complete, which
would mean that NP = Co-NP.  I'm blanking on precisely the consequences
after that, but I do recall that if NP = Co-NP then a lot of our
commonsense understanding of math gets turned on its ear.
I guess you could say we believe factoring is not NP-HARD because the
consequences of it being so are too catastrophic to consider.  :)

@_date: 2007-11-02 17:21:04
@_author: Robert J. Hansen 
@_subject: RSA Weak? 
P:  the set of all decision problems that can be solved in polynomial
    time on a deterministic Turing machine.
NP: the set of all decision problems that can be solved in polynomial
    time on a nondeterministic Turing machine.
NP: the set of all decision problems whose answers can be verified
    in polynomial time on a deterministic Turing machine.
We're handwaving a little bit by using phrases like P and NP to talk
about finding prime factors of composites.  Factorization is a function
problem as opposed to a decision problem; their analogues are FP and
FNP.  However, the logic still holds, since polynomial-time function
problems can be reduced in polytime to decision problems.
Not 'if they're special primes'.  /Any/ prime.  Factoring any prime is a
special case for factorization.  You don't have to do anything: you just
give the number back.

@_date: 2007-11-04 10:15:23
@_author: Robert J. Hansen 
@_subject: New OpenPGP standard published 
Follow-up question:
Has anyone ever come up with an EBNF for the format of an OpenPGP message?

@_date: 2007-11-05 19:12:23
@_author: Robert J. Hansen 
@_subject: Gen Key command done correctly 
GnuPG uses "key pair" in two distinct senses.  One of them means a
public/private pair; and the other means two sets of public/private
keys, one set used for encryption and one set used for signing.  To
disambiguate, I'll refer to the latter as a key set, and a
public/private combination as a key pair.
By default, GnuPG only creates key sets for DSA/Elgamal keys.  It
creates a DSA key pair for signing and an Elgamal key pair for encryption.
For RSA keys, GnuPG only creates a single key pair--a signing pair.
gpg --edit-key  addkey
... and so on, and so on, and you'll have an encryption key pair added
to your signing key pair, making it a completely usable key set.

@_date: 2007-11-06 17:49:40
@_author: Robert J. Hansen 
@_subject: PGP encryption: block or stream cipher? 
No.  Well, block ciphers, but beyond that nobody can tell you very much.
GnuPG supports a large number of block ciphers--probably too many.
Which cipher is used for a particular message depends on both your
preferences and your recipient's preferences.  GnuPG does a variant of
the stable-marriage problem to find a cipher that's mutually agreeable
to both you and your recipient.  So no, without knowing what your and
your recipient's preferences are, we really can't say which block
ciphers are used.
To see which ciphers your version of GnuPG supports, enter:
gpg --version

@_date: 2007-11-16 15:20:52
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG release candidate 1.4.8 
Does 1.4.8 fix the Vista problems reported with 1.4.7?

@_date: 2007-11-19 19:18:06
@_author: Robert J. Hansen 
@_subject: Enigmail.js errors seen on Console log 
These errors occur when the digest algorithm the message claims it's
using isn't the same as the one it's actually using; or if it uses an
algorithm other than one which must be used.  E.g., you could (pre-DSA2
support in GnuPG) get this error message if you attempted to process a
message that had a DSA signature using SHA256 as opposed to SHA-1 or
Looking at key 0xBA279E56, it appears to be a DSA-1024 signing key.  How
much do you want to bet they're using DSA2 and you don't have
enable-dsa2 in your gpg.conf?

@_date: 2007-11-20 17:27:51
@_author: Robert J. Hansen 
@_subject: GPG Passphrase Caching 
Yes, although this usage is not recommended.
--passphrase --passphrase-file Please note that the former will make the passphrase available to anyone
with enough privileges to read the process table, and the latter will
leave your passphrase around in a file on the system which you're then
responsible for securing somehow.
You may want to simply remove the passphrase from the key, which may be
a superior solution.  At least then there's no false sense of security
which might otherwise accompany either of --passphrase or --passphrase-file.

@_date: 2007-11-22 20:46:30
@_author: Robert J. Hansen 
@_subject: How to remove a key from keyserver? 
Not in your case.  You would need the private key.
The moral of the story is to generate revocation certificates at the
same time you generate your keys, test your keys to make sure they are
exactly what you need, and create backups of your keyring before you
ever send a key to the keyservers.

@_date: 2007-11-24 12:00:26
@_author: Robert J. Hansen 
@_subject: How to remove a key from keyserver? 
I'm not sure how on-topic this is for the GnuPG list, but it talks a
little about online etiquette, and as such it may be useful to the list
as a whole.
First, please do not quote private emails to public mailing lists
without the original author's consent.  Private emails may contain
sender- or recipient-specific information which the original author
would rather not see in a public list that maintains a searchable archive.
Second, what you really forgot to add was a smiley.  Psychologists have
done a ton of studies on how we perceive others via email, and what
they've discovered is that people overwhelmingly are awful judges of the
emotional context of email, and they are also overwhelmingly awful about
recognizing the fact they are awful judges.  People read emails and feel
great certainty about what the 'real' emotional context is.
In the absence of any contextual clues to make it clear you were joking,
John was reading your message straight-up.  When reading your message
straight up, it comes across as being kind of ankle-biting.  Had you
added a smiley, or some note at the end to explain it was a joke, you
probably wouldn't have received that reaction.
All it amounts to is a joke (a) wasn't received by the intended audience
and (b) the intended audience responded as if it was straight.  This
sort of thing happens tens of thousands of times a day on the internet.
 So let's all go back to our respective corners, and return a few
minutes later with an appreciation for the expressive power of the
simple, underutilized, smiley.  :)

@_date: 2007-11-26 09:21:24
@_author: Robert J. Hansen 
@_subject: Encryption keys: RSA vs. ElGamal 
Answering this in detail will require at least a solid undergraduate
degree in either CS or mathematics.  I am coming close to a Ph.D. in
computer science, and I still screw up some of the finer points of the
relationship between the integer factorization problem and the discrete
logarithm problem.
Beware of any straightforward answers you get to this problem.  They are
almost undoubtedly simplified to the point of gross inaccuracy.
Unless you know what you're doing and why, use the defaults.  That is
the absolute best advice I can give, the absolute best advice I think
almost anyone can give.
Not in the opinion of the IETF.

@_date: 2007-11-26 12:50:56
@_author: Robert J. Hansen 
@_subject: Encryption keys: RSA vs. ElGamal 
This is common wisdom; unfortunately, I'm not sure that the common
wisdom is correct.
logarithm problem is harder than the integer factorization problem.
(Probably.  There are a lot of hidden assumptions and suppositions that
go into it.  While I don't find the assumptions and suppositions to be
unreasonable, it does give me the heebie-jeebies when people talk about
one being 'more secure' than the other without ever mentioning the
However, both are so phenomenally hard that any attack against the
system will probably target key management, sloppy communication
protocols, traffic analysis, etc.--and for these sort of attacks,
Elgamal is no better than RSA.

@_date: 2007-11-27 13:11:44
@_author: Robert J. Hansen 
@_subject: WinXP problem with large files was: Re: Decrypt problem with 
Depends a lot on your filesystem.  FAT32 doesn't like files greater than
4GB, no matter what program makes them.  NTFS does not have this limitation.
I have seen 50Gb files processed on UNIX machines without error.  Other
people undoubtedly have seen more (much more).  Once you hit file sizes
like that, you need to start looking a lot at your OS limitations as
opposed to GnuPG limitations.

@_date: 2007-10-09 19:07:43
@_author: Robert J. Hansen 
@_subject: PGP messages getting flagged as spam 
I just received word from one of my regular correspondents that his
email server has begun flagging PGP traffic as spam.  I haven't seen
this come up often (ever?) in the lists before, so I'm operating on the
assumption that this may be a new problem people should be aware of.
SpamAssassin is giving results like this:
    once
So, if you're running SpamAssassin, might want to see about tweaking
some rules.  :)

@_date: 2007-10-16 01:58:46
@_author: Robert J. Hansen 
@_subject: PGP messages getting flagged as spam 
There are two schools of thought on this.
1.  "Beats me.  You get to define your policy, not me."
2.  "If this guy's control of his keys and passphrase is so poor
    that a spammer can use them, then there is no sensible policy
    which would consider that key uncompromised."
Personally, I side with  but my own personal policy is   YMMV.

@_date: 2007-10-16 12:15:03
@_author: Robert J. Hansen 
@_subject: PGP messages getting flagged as spam 
I seem to recall hearing Cerf say one in four, not two in five.
Regardless, the numbers are still shockingly high.
It goes a lot deeper than brokerages, although it doesn't surprise me
that this industry has done a lot of thought about it.  In my day job
I'm finishing a Ph.D. in computer security, using electronic voting
systems as a testbed for research.  I am appalled at how often
well-meaning people ask "well, overhauling all these DRE machines would
cost a fortune, so why not just let people vote from home?"
Vote-from-home over the internet is probably going to happen sooner or
later in some jurisdiction, if only because it is possible for a vendor
to claim huge cost savings and convenience increases.  And what do we do
once we've turned the machinery of democracy over to a network which is
increasingly owned lock, stock and barrel by botnets?
In a similar vein, I have two close relatives who are judges.  It scares
me... I mean, it downright _terrifies me_... that they are unaware of
just how many machines are compromised, or the likelihood that their own
machines are compromised.  Whenever I visit either of them--which I do
with some frequency--the first thing I do is scour their PCs for traces
of infestation.  It's a substantial amount of work, but I would much
rather do this than run the risk of a felon's conviction being
overturned on the grounds of the judge's PC was part of a botnet and
thus we can't trust that the entered opinion was accurate.
The implications of botnets are both wide-ranging and bone-chilling.  I
am quite concerned about the potential impacts of botnets upon the world
at large.

@_date: 2007-10-16 23:31:26
@_author: Robert J. Hansen 
@_subject: PGP messages getting flagged as spam 
Not really.
The instant spammers figure they can sneak past SpamAssassin a
fractional bit more by having a good PGP signature, we're going to see
an explosion of PGP/MIME.  The main body will be random text and have a
valid signature; the attachment will be the permuted-per-recipient
image, and will not.
They need to sign one message and send it to ten million people.  Ten
million people then need to have their spamfilters parse the PGP
signature to see whether to give it the fractional point deduction.
This is classic asymmetric warfare.  In very short order so many
spammers will be using PGP/MIME that just using PGP/MIME legitimately
will raise the point value of your traffic.  Which means that six months
after people start marking down PGP-signed emails, people start marking
the scores way, way up.
I don't feel like sacrificing my ability to send encrypted emails to
someone just to get an additional six months delay in the spam war.

@_date: 2007-10-17 02:39:27
@_author: Robert J. Hansen 
@_subject: PGP messages getting flagged as spam 
So, what, the plan then is to discard any message that's signed by an
unknown or untrusted key?  Or consider that to be a spam indicator?
These cures are just as lousy as the disease.
So _more_ valid OpenPGP data gets discarded?  This plan gets better and

@_date: 2007-10-17 13:12:12
@_author: Robert J. Hansen 
@_subject: PGP messages getting flagged as spam 
A lot of institutions are doing this nowadays.  I expect most
universities to go this way within the next few years--and once
university students get accustomed to it, a few years after that we'll
see the idea gain traction in the real-world election community.
For a look at the problems in the University of Iowa student government
elections, take a look at:
After delivering this report to Student Government, their response was
to bury it, never follow up with us, and the next year hired an outside
contractor to provide vote-by-internet, all on the basis of "the voting
research group here is not willing to be part of a productive working
ObGnuPGRelevance: some of the issues pointed out in the final report
could have been mitigated with GnuPG, although in the end UISG elected
to ignore our recommendations.

@_date: 2007-10-18 03:11:11
@_author: Robert J. Hansen 
@_subject: professionalism, was Re: PGP messages getting flagged as spam 
When giving a software evaluation, you always specify sources and
methods.  Each and every assertion needs a source and a method: who is
your source, and how does your source know this?
With proprietary software, you're mostly stuck relying on your vendor
for information.  Compare "Microsoft says that IIS will scale up to our
server load with our current server configuration" to "the Apache
Foundation isn't making any promises, but I've had Apache running for
the last month on a test server and it's performing flawlessly."
The first statement's source is Microsoft.  Their method is presumably
their own internal testing.
The second statement's source is you-the-engineer.  Your method is your
own internal testing.
Neither evaluation is necessarily better or worse than the other.
Management might trust Microsoft more than you, or you more than
Microsoft.  You're not responsible for making sure Management makes the
right choices--you're only responsible for giving Management accurate
information with which to make their choices.

@_date: 2007-10-18 10:23:46
@_author: Robert J. Hansen 
@_subject: professionalism, was Re: PGP messages getting flagged as spam 
It's a hypothetical.  There do exist vendors that are infamously stingy
with evaluation versions and heavily rely on "trust us".

@_date: 2007-10-22 05:14:18
@_author: Robert J. Hansen 
@_subject: Separate Fingerprint for elGamal-Subkey? 
rjh at chronicles:~$ gpg --fingerprint --fingerprint --list-key 0x5b8709eb
pub   1024D/5B8709EB 2004-05-20
      Key fingerprint = B3FE 45FB 64FD 9C26 8D7D
                        A064 7AE5 1D9C 5B87 09EB
<< uid lines snipped >>
sub   1024g/D0C6AAE4 2004-05-20
      Key fingerprint = AB04 6B60 C352 390A BE98
                        F44D C8F7 33D0 D0C6 AAE4
sub   2048g/71E177DB 2007-03-20
      Key fingerprint = 1946 3571 6DB0 8689 ECBA
                        3F9D 0083 E95E 71E1 77DB
sub   2048D/8D02BBB3 2007-03-20
      Key fingerprint = 400D F79C 49B5 2F00 8EC8
                        225D 7F65 C1CA 8D02 BBB3
Hope this example helps.

@_date: 2007-10-22 05:17:42
@_author: Robert J. Hansen 
@_subject: Public/Private Keys - Consequences 
Short answer: "dwarfed by the benefits" is the best answer.
Long answer: there's a marginal risk of increased spam.  Most people
agree that it will increase the amount of spam you get, but most also
agree that you are unlikely to notice it unless you're _really_ paying
If they have your private key and your passphrase, then they can do
anything you can do.  If they have one or the other, they're out of luck.
If you want a more detailed answer than this, I'd recommend reading some
documentation on how OpenPGP works.  E.g.:

@_date: 2007-10-22 13:24:25
@_author: Robert J. Hansen 
@_subject: For Mac users: the oncoming Mac OS X 10.5 "Leopard" 
I will eat my own hat if GnuPG has any problems whatsoever with Leopard.
 From all that I know of Leopard, GnuPG will continue to work just fine.
I will be getting Leopard very soon after release.  If there are any
problems, I will (a) post them to the list and (b) post my favorite
recipes involving hats.

@_date: 2007-10-26 21:14:07
@_author: Robert J. Hansen 
@_subject: GnuPG 1.4.7 and OS X 10.5 
Hash: SHA256
I'm currently running GnuPG 1.4.7 on OS X 10.5 (Leopard).  While I
haven't done any serious regression testing, routine operations appear
to work just fine.
Thunderbird 2.0.0.6 + Enigmail 0.95.4 also work without problem.
I know some people were concerned about possible problems with the OS X
upgrade.  So far, it appears to be a nonissue.  Some plugins which
depend on Mail.app internals (such as GPGMail) may or may not work; for
those plugins you'll have to ask the developers directly.

@_date: 2007-10-28 04:10:24
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
This is true in practice, too, as long as some caveats are met.
Ack!  Ack!  One time pads!  Ack!
I really, really wish the Vernam cipher was either lesser known or
better known.  If it was lesser known, fewer people would advise ever
using it.  If it was better known, more people would understand its
phenomenal shortcomings.
Point blank: unless you can spend a lot of money on training and
infrastructure, you are almost always better off using conventional
crypto.  The Vernam cipher is /expensive/ to use properly, precisely
because it is so unforgiving of any kind of failing.
The secret sharing idea isn't a bad one, but using the Vernam cipher to
do it is a very bad idea.  The Shamir Secret-Sharing Protocol works
much, much better for this purpose.

@_date: 2007-10-28 04:25:39
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
Just to head a question off at the pass...
I said "yes, it's possible, but totally impractical".  Sven has said
"no, it's not".  As is often the case when talking about crypto, both
answers are totally correct.
Sven is answering the question of "can I recover the private key,
knowing the passphrase".  He's right.  The passphrase doesn't help you here.
I'm answering the question of "can I recover the private key, knowing
the public key".  I'm right.  The task moves from categorically
impossible to theoretically possible.  However, the practical
difficulties are presently insurmountable.

@_date: 2007-10-28 06:08:18
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
A couple of years ago there was some smoke from reliable sources that
the USG was concerned about the possibility of terror cells
communicating steganographically, and for that reason funding would be
available to researchers tackling the problem.  I don't know if the
funding ever took off, but I did see a handful of papers published on
the subject.  Clearly, steganography is on academia's radar.  It's
probably on the NSA's radar, too.
If you are comfortable with the NSA and/or GCHQ wondering why you've got
AES-encrypted data hidden in a JPEG that's floating around the internet,
then go ahead with this.
It's a dangerous toy.
There is a paper I enthusiastically recommend every time this subject
comes up.  To my knowledge, this is the first paper that establishes
formal mathematical limits for steganography--what it can do, what it
can't, what tradeoffs there are, how optimizing a system for one part of
the steganography problem cripples it for another.
As you can imagine, it is a really, really important paper for anyone
who wants to take steganography seriously.  And without exception, I
have yet to meet any designer of a steganographic system who has read
it.  This does not fill me with much confidence for the steganographic
systems out there.
Moulin, P., and O'Sullivan, J.  _Information-Theoretic Analysis of
Information Hiding_.  IEEE Transactions on Information Theory, Vol. 49,
No. 3., pp. 563-593 incl.
Available online at:
Why not?
I do not understand this irrational belief that people have in the
inadequacy of AES to protect their private keys.  Will it make people
feel better if I post my own private key to the list?  (I'm perfectly
willing to, if that's what's necessary to prove a point.)

@_date: 2007-10-28 06:21:22
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
See _The Art of Computer Programming_, Volume 2, section 4.6.4,
"Evaluation of Polynomials".  In my copy it's on page 505; YMMV if you
have a different edition.  Knuth characterizes it as "an important and
somewhat surprising application of polynomial interpolation", as well as
"amazingly simple".
I can vouch for the "amazingly simple" part.  I volunteer at a local
elementary school and help teach their talented-and-gifted fourth
graders.  One of the first things we do each year is go over the Shamir
PGP Corporation also uses it to divide up key shares, if I recall correctly.

@_date: 2007-10-28 07:03:13
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
This would be the PGP Corporation that allows you to download and
compile their source code so that you can run your own tests to ensure
there are no back doors, yes.  It's not open-source, but it's certainly
not a closed-source product.
You should.  There's a great quote from the movie _Strange Days_: "The
question isn't whether you're paranoid, but whether you're paranoid
enough."  There's a sweet spot to hit, paranoia-wise.  Being too
paranoid is just as bad as not being paranoid enough.
At this point it's abundantly clear to me that you've never learned how
Shamir's scheme works.  I don't know how to make a case for Shamir's
scheme to someone who doesn't care how it works, only that their
prejudice is that it's bad.
So far I have given you references to PGP Corporation's use of it, to
Don Knuth's inclusion of it in _The Art of Computer Programming_, to how
fourth-graders in rural Iowa are using it to keep secrets from their
teacher.  It's mentioned quite favorably in _Applied Cryptography_,
_Practical Cryptography_ and the _Handbook of Applied Cryptography_.
At some point, I have to call a halt to it.  If you value warm fuzzies
over math, if you trust James Bond gadgetry ideas over solid and proven
algorithms, then there's nothing I can say to that.

@_date: 2007-10-28 13:30:16
@_author: Robert J. Hansen 
@_subject: Key safety vs Backup : History of a bad day (key-restoration 
Shamir's protocol revolves around being given two points on a grid and
drawing a line between them.  This is not higher math.  This is why it's
described as "amazingly simple".
Nobody's talking about C.  I despise C, honestly.  It's a very useful
language for kernels.  Outside of that I prefer other, better options be
Shamir's algorithm is a very basic crypto primitive.  If it's not part
of your corpus of knowledge, it should be.
If you don't understand the math behind a crypto primitive, you don't
understand the primitive.  There is a big difference between saying
"people I trust say this primitive achieves this objective" and saying
"I've seen the math work for myself".
Except that you don't know C, and thus cannot say these applications
actually do what you want.
The Vernam cipher is not a verifiable system.  That's the entire /point/
of it: it has no way to verify anything.  If there was a way to
verify any part of the Vernam cipher, then it would lose its
provably-secure properties.  You could just try one key after another
saying "is this the right key?" and, as soon as you received
verification that it was, you'd be done.
Not that even without verifiability the Vernam cipher is a very good
system.  Look into the history of Project Venona.  "Provable security"
is a great buzzword, but in practice it means very little.
IBM had an algorithm a few years ago (Atjai-Dwork?) which offered
provable security, but it was broken within a year by someone who
figured out a way to throw the hidden assumptions of Atjai-Dwork on its
As I once said, "proofs of security are nice--they give us something to
point and laugh at."
You are free to use whatever you like.  However, please do not recommend
it as a method to other people when I cannot find one single authority
in either cryptography or software engineering who endorses this method.
The "James Bond gadgetry" was a reference to ideas of steganographically
encoding a key inside a JPEG and letting Google cache it, or keeping it
in your camera, or... etc.  These ideas are infeasible for various reasons.
Insofar as why not to use it for secret sharing, I would think that
reason would be obvious: it cannot be used to implement a general {k, n}
threshold scheme which preserves information secrecy.  If you want to
advocate that it be used for secret sharing, the burden is on you to
establish that it's a safe and effective alternative to Shamir's and/or
Blakley's schemes, both of which have long pedigrees in the literature
attesting to their efficiency, generality and privacy.
This is not "warm and fuzzy".  This is following the best practices of
the field.  The more complex an algorithm becomes, the more difficult it
becomes to implement it successfully.  This is why so few people
implement Elgamal signatures; while the math works beautifully, the
algorithm is so complex and subtle that implementing it is perilous.
The complexity of the Vernam cipher is what doomed it during Project
Venona.  Etc.
Great.  Let's break up the letters ABC among Alice, Bob and Charlie.
Under Shamir and Blakley's scheme, Alice, Bob and Charlie have no
knowledge whatsoever of the ultimate answer: the odds of them
successfully choosing the secret is no better than random.  (In this
case, 26**-3, about 5 * 10**-5.)
Under your scheme, Alice, Bob and Charlie each have two-thirds of the
ultimate answer.  Discovering the secret requires guessing just one
letter... odds of about 4%, making it 800 times more likely that they'll
be able to guess your secret.
I would not consider you to have solved the problem.
This is why the Vernam cipher is such a disastrous failure for secret
sharing.  You're giving away huge parts of the secret.  There's no
provision in it for hiding the secret--only for breaking it up.

@_date: 2007-10-29 15:07:04
@_author: Robert J. Hansen 
@_subject: ECC - how does it compare 
As soon as it gets added to the OpenPGP RFC, then we should.  Until
then, it's premature.

@_date: 2007-10-30 08:54:43
@_author: Robert J. Hansen 
@_subject: Smartcards and Mac OS/X 
Legal or employment reasons.  Some people have smart card usage mandated
to them.  These people tend to be the primary users.
Some people believe storing private keys on smart cards leads to better
physical security than storing them on easily-stolen laptops or PCs.
Others like to be able to carry their private key with them, so they can
use it at whichever computer they happen to be at (as long as that
computer has a card reader attached).
The major drawbacks are that if your card reader breaks, your private
key is inaccessible, and most smart cards are limited to RSA-1024 and a
ridiculously small amount of supporting data.  You will not be able to
carry your keyring around with you on the card.
Smart cards are (mostly) interchangeable; there's a standard for how
they're laid out and how they interface with smart card readers.  The
real question is whether there are good card readers for OS X.
I can't help you with this; I don't use card readers, so I can't give
any recommendations.  However, a quick Google search for 'smart card
reader "OS X"' returned some useful results in the first few links.

@_date: 2007-10-30 09:40:48
@_author: Robert J. Hansen 
@_subject: beginner to gnupg 
By default, GnuPG will export keys in binary format.  This is more
space-efficient, but is not readable to humans.  (I don't think that's a
big loss, given that the human-readable version isn't all that readable
to humans, either.)
gpg --armor --export "key name" > C:\GNU\GnuPG\public.key
... and it should work.
Note that it's "--armor --export", not "--export --armor".  The former
will work fine.  The latter will try to export a key named "--armor",
which will probably not work fine, unless your keyring has far more
interesting people than mine.  :)

@_date: 2007-10-30 14:56:47
@_author: Robert J. Hansen 
@_subject: GnuPG in Linux 
Dunno what that's doing there.  You're right, it should be gpg.conf.
The good news is most of your OS X Terminal.app skills will apply here.
 OS X 10.4 and 10.5 both use a program called 'bash' to provide a
command line.  So does Ubuntu.  Prior to 10.4, OS X used tcsh instead of
bash; if you're more comfortable with 10.0-10.3 behavior, talk to me
off-list and we can get Ubuntu set up with tcsh.
I'd suggest doing 'gedit ~/.gnupg/gpg.conf &' and just editing it that
way.  Gedit is the standard GNOME editor and should be much friendlier
than using nano.

@_date: 2007-10-31 16:48:06
@_author: Robert J. Hansen 
@_subject: AS400 PGP 
============================== START ==============================
This mailing list is for the GNU Privacy Guard, not PGP.  GnuPG is a
product of g10 Code GmbH and the GnuPG community; PGP is a product of
PGP Corporation.
I would suggest asking this question either on PGP Corporation's user
forums or on the Yahoo Groups PGP-Basics list.
Also, as a netiquette issue, the use of all caps is discouraged.  It
tends to come across as screaming and hostility.
PGP Corporation's Knowledge Base:
  PGP-Basics on Yahoo! Groups:

@_date: 2007-09-06 07:11:10
@_author: Robert J. Hansen 
@_subject: RSA or DSA? That's the question 
Not really.  Some places have to conform with regulations or laws which
might demand RSA.  Some people may want to use smart cards, which have
historically been RSA-only.  Some people may... etc., etc.
If you have a specific need to use RSA, and you can articulate both the
need and why it's a need all in a single sentence, then use RSA.
Otherwise, you're far better off sticking with the defaults.

@_date: 2007-09-06 07:26:19
@_author: Robert J. Hansen 
@_subject: RSA or DSA? That's the question 
While I agree that a cryppie's definition of "break" is not the same as
a practical break, I think it's dangerous to make predictions about how
long it takes a cryptographic break to turn into a practical break.
E.g., it took MD5 almost a decade to go from a purely academic break to
an actual collision, but it took SHA-1 under a year.
I don't feel comfortable making predictions about how much an unknown
future attack will cost.  Take the SHA-1 results as an example: using
the original Shengdong U. paper it takes a work factor of 2**69 to
generate a random collision, but just a few weeks later it was down to
2**63.  That's a 98.4% cost savings.

@_date: 2007-09-06 09:41:20
@_author: Robert J. Hansen 
@_subject: losing meaningful whitespaces in an encrypted file 
Have you tried a test decryption on your end?  E.g., encrypt the file
with your own public key and then decrypt that, and see whether the 13
spaces are present?
Also, version numbers would be very useful--both GnuPG on your end and
PGP on the vendor's end.
This may very well be a PGP problem as opposed to a GnuPG problem, in
which case you may be better served on a PGP list such as PGP-Basics at
Yahoo! Groups.
Impossible to say without more information.  My inclination is to think
it's probably on the vendor's end, especially if you're using a recent
version of GnuPG.  There are a lot of PGP 5.0 and 6.5.8 installations
out there, and both of them substantially predate the OpenPGP standard
which GnuPG conforms to.

@_date: 2007-09-06 13:37:08
@_author: Robert J. Hansen 
@_subject: RSA or DSA? That's the question 
Rechberger and Canni?re had some interesting things at CRYPTO 2006--I
don't recall the details, but it sounded like a partial preimage attack,
not just a simple collision.  They only demonstrated it against SHA-1
reduced to 64 rounds, but drew a pretty clear roadmap for how to extend
it to 80.  I'm expecting more results soon.
SHA-1 is facing some scary times.
I don't know I'd agree with that.  In the early '90s when I first
started using PGP 2.6, a 1024-bit key was considered to be ridiculous
overkill.  Most keys of that era were only 512 bits, and were considered
of suitable strength for a great many years.  A generation prior to
that, Ron Rivest's original late-1970s predictions on necessary key
lengths turned out to be wildly optimistic.
We've got two full generations of crypto prophets who have badly
overestimated the long-term security of algorithms and badly
underestimated the unpredictable advances in computing power.  It seems
reasonable to me to ask why the current round of prophecy should be
believed, given the failures of the past.
When Schneier wrote _Applied Cryptography_ in 1992, the Chinese Lottery
Attack was speculative fiction at best.  Today, distributed.net is doing
them every single day.  It makes you think about what William Gibson
said--"the future is already here, it's just unevenly distributed."

@_date: 2007-09-06 13:54:37
@_author: Robert J. Hansen 
@_subject: OT 
Hash: SHA512
Or even in conversational speech.  The contexts in which cryppies are
talked about tend not to be the contexts in which crippies are talked
about.  This seems like a non-issue to me.
English is full of homophonic collisions.  Some people think the phrase
"let's call a spade a spade" is racist, based on the word 'spade' being
a racist epithet for people of a particular skin hue.  This is despite
the fact the phrase is a bad translation of a Greek proverb: "call a
bowl a bowl".
People have lost their jobs for describing their tendency towards
parsimony as 'niggardly'.  That phrase is of Old Norse origin, "hn?ggr",
meaning "stingy".  It's in no way connected to an epithet.
And so on, and so on, and so on.  English takes words and proverbs from
many different sources and conflates them all into one bizarre,
counterintuitive, contralogical, colliding whole.  (Consider that many
consider it bad form to split an infinitive, but the word 'to' has as
much relation to an infinitive as 'the' has to a nominative; so why is
"to boldly go" considered verboten, while "the red car" is acceptable?)
While I'm generally all in favor of being mindful of one's environment
when selecting words, listeners have an equal obligation to be mindful
of the flexibilities of language when deciding whether they ought be
offended.  So yeah, I'm with John: this is a nonissue.

@_date: 2007-09-06 19:24:17
@_author: Robert J. Hansen 
@_subject: OT (resend) 
Thus, Americans should simply dismiss all the words in cryptography
which come to us courtesy of Bletchley Park or GCHQ simply because
they're utterly irrelevant to us except as an academic exercise?
"Cryppie" is in the Jargon File [1], in the Free Online Dictionary of
Computing [2], in USN slang, USAF slang, and even GCHQ slang.  I've
never met a cryptographer or cryptographic engineer, regardless of where
they're from, who does not understand the term "cryppie".
At some point, people have to take the responsibility for looking up a
word they do not know.  If a good definition cannot be found in under
thirty seconds of searching, then I think a strong complaint can be
made.  That is not the case here.
[1] [2]

@_date: 2007-09-07 13:09:30
@_author: Robert J. Hansen 
@_subject: RSA or DSA? That's the question 
Breaking the discrete log problem also breaks the integer factorization
problem.  IFP can be seen as a special case of the DLP.
Breaking DLP breaks every asymmetric algo in OpenPGP.  Breaking IFP may
only break RSA.

@_date: 2007-09-07 13:29:25
@_author: Robert J. Hansen 
@_subject: RSA or DSA? That's the question 
That's not possible today.  Today, it would be extraordinarily difficult
to forge the message.  However, that's no guarantee it will be
extraordinarily difficult in six months or a year.
It is best to migrate away from SHA-1 right now.
Don't buy a smart card unless you need a smart card.  Most smart cards
limit themselves to RSA-1024.  Distributed key cracking plus the
constant forward march of mathematical progress means it's possible
RSA-1024 will fall in the next five years.
If you need a smart card, by all means, get one.  If you don't, you're
probably better off without one, because it gives you more possibilities.
Insofar as what I think you should do, my advice is unchanged.  Stick
with the defaults.  I genuinely do not understand why people spend hours
upon hours laboriously deciding whether to use a DSA or an RSA key.
Drop "enable-dsa2" in your gpg.conf, set your personal hash preferences
to use SHA256, and create a default key.
For most personal/home users, expiration is not necessary.

@_date: 2007-09-07 15:54:03
@_author: Robert J. Hansen 
@_subject: RSA or DSA? That's the question 
Beats me, but I'm sure the other Enigmail users on-list will chime in
with helpful advice.
It's not catastrophic news.  Just because it may be feasible to break
_one_ key that way in five years doesn't mean _all_ keys will need to be
retired.  As an example, I would feel fairly safe using 64-bit symmetric
encryption for my email today, despite the fact distributed.net has
cracked RC5/64.  I don't think people who want to read my email are
willing to invest the thousands of computers and the 18 months that it
took distributed.net, after all.
However, for people who have very, very high security needs, RSA-1024
needs to be considered to be living on borrowed time.
Yes.  No.  You can get a Ph.D. for studying this question.
The current best way to attack the integer factorization problem (the
mathematical heart of RSA) is the general number field sieve (GNFS).
GNFS can also be used against the discrete logarithm problem (the
mathematical heart of DSA and Elgamal), but the memory requirements
become... weird.  Currently we think the memory requirements become
enormous, far far exceeding that required for attacking the IFP, but I'm
aware of no proof that the memory requirement _must_ be that large.
Best advice: don't panic and don't overreact.  If RSA-1024 won't do for
your needs, then DSA-1024 needs to be considered suspect, too.  If
RSA-1024 will do for your needs, DSA-1024 probably will, too.

@_date: 2007-09-12 14:11:31
@_author: Robert J. Hansen 
@_subject: personal-*-preferences 
Apologies for the late reply to this--was cleaning out my inbox and
found this, and couldn't remember whether I ever saw a follow-up
explaining the issue.
This is because these are two different kinds of preferences.
Personal-*-preferences tells GnuPG what sort of algorithms you prefer to
use, and in what order.  Preferences on a key tell correspondents what
sort of algorithms you prefer to use, and in what order.  They are
independent things, although you can make a strong argument that they
shouldn't be.

@_date: 2007-09-28 12:26:53
@_author: Robert J. Hansen 
@_subject: feature request 
I am not a GnuPG developer; they may disagree with me or outright say
"hey, sure, we'll support it".  That said, I think that what I'm saying
here is in rough accordance with their vision of the GnuPG project.  If
I am wrong, I'm sure they'll correct me.  :)
This means going beyond the OpenPGP spec.  OpenPGP has a very specific
format for symmetrically encrypted documents.  If you want something
that is not OpenPGP-conformant, you probably need to go elsewhere.
Unless you're encrypting large blocks of random noise, I don't see how
this is possible.  Even if GnuPG itself doesn't tell me "nope, that key
didn't decrypt the message successfully," I could figure it out myself
from how the output is statistically indistinguishable from random noise.
See, e.g.: Unless you have a graduate degree in mathematics and a background in
breaking ciphers, this is probably a spectacularly bad idea.  Cipher
design is a fabulously black art; even the acknowledged geniuses of the
field screw it up more often than not.
Anyone can make a cipher they themselves cannot break.  It requires a
great deal of study and trial and error and just blind luck to make a
cipher that nobody can break.
Yes, because double ROT-13 is more difficult to read than single ROT-13.
There is a very large corpus of knowledge about cipher composition;
which ways tend to increase the strength of a system, and which only
diminish it.  It is far, far, far easier to diminish the strength of a
system.  The likelihood of an ad-hoc method improving overall security
is vanishingly small.  Almost zero.
GnuPG is not 'part of a larger toolkit'.
GnuPG and its associated libraries provide an implementation of RFC2440,
and is slowly growing to cover a couple of other RFCs (S/MIME, etc.).
That's all, nothing else.

@_date: 2008-04-02 08:52:35
@_author: Robert J. Hansen 
@_subject: 1.4.7 <-> 1.4.8 compatibility 
With the exception of RSA+SHA224 signatures, I know of none.

@_date: 2008-04-08 10:00:34
@_author: Robert J. Hansen 
@_subject: gettext version 0.17 
Not especially.  If you really want to know the nitty-gritty details about the differences between versions, I'd suggest asking on the gettext mailing list.
If you want to proceed with this, I'd recommend using Fink to install GnuPG2 and gettext.  Fink is a much more convenient way to build packages from source.

@_date: 2008-04-08 10:35:31
@_author: Robert J. Hansen 
@_subject: Invalid cross certification? 
Hash: SHA256
I'm beginning to do my own testing of GnuPG 2.0.9, and I'm seeing
something a bit odd.  I have a message encrypted and signed to myself
which GnuPG 1.4.9 decrypts and verifies correctly.  GnuPG 2.0.9 gives a
warning about there being an invalid cross-certification.
Googling was not especially helpful.  Checking the source code,
sig-check.c turned out to have the most useful bit of information:
~   subkey on the primary key.  The idea here is that it should
~   not be possible for someone to "steal" subkeys and claim
~   them as their own.  The attacker couldn't actually use the
~   subkey, but they could try and claim ownership of any
~   signaures issued by it. */
So the obvious questions:
1.  If 1.4.9 and 2.0.9 use the same crypto code for OpenPGP, why is
there this difference in functionality?
2.  How is it possible to put an 0x19 signature on the primary key from
the subkey, in order to get rid of this error message?

@_date: 2008-04-09 02:42:08
@_author: Robert J. Hansen 
@_subject: GnuPG v2.x? 
It doesn't really matter if there were a hundred other S/MIME implementations tested by Sphinx, or if GnuPG's S/MIME implementation was the only one.  The Sphinx evaluation criteria are what matters--not the competition.
If the evaluation criteria are rigorous and demanding, then being the only one to pass is a major accomplishment even if no one else submitted.
If the evaluation criteria are easy, then being the best of hundreds to pass the examination really doesn't amount to much at all.

@_date: 2008-04-09 14:44:22
@_author: Robert J. Hansen 
@_subject: GnuPG v2.x? 
If you're going to misquote someone, at least do it accurately.  The original poster's exact words were "is the only Free Software implementation of S/MIME that has passed the Sphinx interoperability tests."
The parse is ambiguous.  You can read it as meaning "only one Free Software implementation was submitted to Sphinx, and it passed".  You can read it as "other Free Software implementations were submitted to Sphinx, and only KMail passed".
Or you can do what I do, which is recognize that it's an ambiguous parse, and assume that the person speaking is a reasonable human being who is probably not engaging in semantic trickery.  Accusing people of malfeasance when there is no clear evidence any occurred is a McCarthyism into which I do not wish to fall.
Ingo is a reasonable human being.

@_date: 2008-04-12 20:03:02
@_author: Robert J. Hansen 
@_subject: problem in using windows 
I would suggest looking in GPG4WIN to see if the necessary files are
already there.  The GNU C compiler is ABI-compatible with Microsoft's C
compiler; it's only in C++ that the ABIs change.
Otherwise, I'd suggest asking on the MinGW list about using Microsoft's
cl command-line compiler with Autotools.
Finally, Microsoft's C++ compiler is, by default, not a C++ compiler at
all.  If you're working with C++ I would strongly suggest using Intel's
C++ compiler, the GNU C++ compiler, or Sun's C++ compiler, all of which
are available at very low cost to students.
This is rude.  If you're going to come on a mailing list asking for
help, you should read the mailing list in order to see your replies.

@_date: 2008-04-13 21:09:13
@_author: Robert J. Hansen 
@_subject: problem installing gnupg-2.0.9 
There are many, many things it could be.  To help us narrow it down, try
telling us your operating system and version.

@_date: 2008-04-14 12:19:17
@_author: Robert J. Hansen 
@_subject: Miscellaneous questions 
It's not a bug.  It's a deliberate design decision on the part of the
GnuPG authors.
I would not recommend this sort of brain surgery on a key.  If you're
that concerned about the use of SHA1, I would suggest just generating an
entirely new key that is entirely to your specifications.
Hack the source.
Why?  Your reason doesn't make sense.
Sorry.  This is not a statement about anything other than "I'm not
following RFC4880's best practice".
If I see that you're omitting 3DES from your preference list, I'm not
going to think you're making a statement about 3DES.  I'm going to think
you're not following RFC4880's best practice.  Other people in the world
are not telepathic, cannot read your mind, and cannot rationally infer
what you want us to infer.  I will happily send you 3DES traffic
regardless, since it happens to be a high preference of mine and it's
automatically going to be on yours.
Incidentally, if you can't articulate solid cryptanalytic reasons why
3DES is an unsafe choice for you, you really shouldn't be arguing
against 3DES.  There's a joke I often tell the undergrad computer
security course here--"3DES: turning brilliant young graduate students
into burned-out alcoholic wrecks since 1974."
3DES has all the aesthetics of a Soviet worker's housing bloc, and just
as much durability.  It is quite slow by modern standards, but it is
ridiculously overdesigned for its task--_ridiculously_ overdesigned.
If there are attacks against 3DES you're worried about, then please
share them with the rest of us so we can be better-informed.
If you're this concerned about cryptanalytic attacks, I have to ask how
many heavily-armed Marines you have guarding your key.  You're talking
about adding more armor plating to the vault door of your home.  An
attacker is most likely going to pick up a chainsaw and just cut through
the wall.
It's what I'd do.
Do not fetishize cryptography.  It will not save you.  It is not magic
pixie dust.

@_date: 2008-04-14 18:06:49
@_author: Robert J. Hansen 
@_subject: Miscellaneous questions 
There are two responses here:
1.  You didn't ask for the option to allow zero-length UIDs.  If you'd
    asked for that option, I would have given it.  You asked "why does
    GnuPG have a minimum size of five characters", "is this imposed by
    RFC4880", and "where can I report this bug".  Your questions were
    answered.  Don't blame me if you asked the wrong questions.
2.  The beautiful thing about open standards is that anyone can
    implement them.  The beautiful thing about open source is that
    anyone can change it.  If you really think it's so stupid to forbid
    short UIDs, then hack the source and submit a patch.  It's a trivial
    change.
You're misunderstanding the purpose of a specification.
A specification does not set a high-water mark for implementations.  It
sets a low-water mark.  Implementations are free to restrict keys in any
way they want, so long as the low-water mark is met.  If you want to
write an RFC2440 implementation that supports only DSA, SHA-1 and 3DES,
nobody will stop you.  You're meeting the low-water mark.
GnuPG would be entirely within rights to require that all UIDs be set to
"aaaaaaa".  Or to leave them utterly blank.  Or to not give users a
choice in them at all.  As long as GnuPG understands RFC-conformant UIDs
and generates RFC-conformant UIDs, that's all it has to do according to
the RFC.
In reality, GnuPG is guided by concerns beyond just strict RFC
conformance: interoperability, ease of use, and others.
Imagine the interoperability problems you will have when your UIDs do
not conform to the de-facto standard.  If you want to do things that
will deliberately mangle your interoperability, go ahead:
--allow-freeform-uid will let you do that.  GnuPG will, by default, try
to keep you very interoperable.  That's clearly the Right Thing To Do.
Interoperability.  There are a lot of people out there using old,
decrepit versions of PGP and GnuPG.  Old versions tend not to react very
well when people decide to get creative in ways that were not foreseen
back when the old versions were written.
Yes.  Because you haven't written a patch for it.
You're ascribing magical meanings to things.  You're not going to be
safer under your scheme.  It's different--it's not better.
I don't know why GnuPG does it this way.  I strongly suspect it's for
historical reasons and interoperability concerns.
And this is the problem: you _are_ including it.  The RFC requires them
to be present, and if they're not present, requires all implementations
to add them.
You're not communicating anything other than "I am not paying attention
to the best practice outlined in the RFC."  Your correspondents are not
going to say "oh, you don't like 3DES".  They're going to say "oh,
you're using a badly-written OpenPGP implementation, here, let me fix
that for you."
Then join the WG and advocate for this position.  It's an open WG.
Speak for yourself.  My personal-cipher-preferences has 3DES explicitly
listed as my first preference.
I see no reason not to use 3DES and I know 3DES will be supported by
everyone, so why not use 3DES and avoid the risk of a problem existing?
You're assuming 3DES is a weak cipher.  It's not.  It's really quite
grotesquely overdesigned.  The best attack against it, _in thirty-four
years of intense cryptanalysis_, requires:
Assuming a thermodynamically perfect computer running at a nice chilly
three point two Kelvins, you're talking about an energy usage that's
plenty enough to launch you on a one-way trip out of the Solar System.
So please, explain to me: why do you want to be warned when you receive
3DES traffic?
Because OpenPGP has fallen victim to the Second System Effect.  Because
everyone and their grandmother wants to get their own personal pet
algorithm in the mix.  Because people who don't know better scream about
the injustice of TIGER192 being removed from the mix.  Because people
who read somewhere on a web forum that SERPENT is better than Rijndael
and Rijndael is better than AES insist that GnuPG include Rijndael and
SERPENT.  Because...
... Rijndael is AES, incidentally.  Rijndael was the name it was
submitted under to the AES competition.  Once it was chosen as the
winner, it became AES.  And yes, I have seen people passionately
advocating for the inclusion of Rijndael in OpenPGP, despite the fact
it's already there, just under the name AES.
Because Hans Dobbertin kicked MD5 to the curb and went through its
pockets looking for interesting bits of number theory.
3DES is not weaker than AES.  It's different.  It's slower.  It's less
It's not weaker.  Not in any sense that matters, at least.  168 bits of
effective 3DES key versus 128 bits of AES key--which wins?  Past a
certain point additional key length ceases to matter.
Because 3DES is slow, inefficient, and doesn't work well on very small
computers.  Really.  That's the reason.
AES is fast, efficient, and works well in a whole lot of different
environments.  That's why we love AES; it's a great tool across a very
broad swath of the problem domain.
3DES is a more limited tool.  There are certain parts of the problem set
where you just don't want to use it.
Email is not one of these certain parts.  There is no compelling reason
to avoid using 3DES for email, unless you often send very large
encrypted files.
In fact, a lot of people are still using MD5 and IDEA.  The biggest
problem facing OpenPGP's adoption is the enormous amount of ClassicPGP
installations out there which are not upgrading because they see no need
to upgrade.
... Also, to anyone who's thinking "wow, 3DES is really good!" after
reading this: yes, yes it is.  So is AES.  The defaults GnuPG gives you
are safe.  You don't need to tweak them.

@_date: 2008-04-14 18:08:05
@_author: Robert J. Hansen 
@_subject: Miscellaneous questions 
Yes.  No.  Maybe.
HCI (Human-Computer Interaction) is an infamously black art.  What one
person thinks is the most obvious set of options for them is a Byzantine
kludge to another.
It might make sense to you.  It might not make sense to others.  For
now, the best that can be done is for the option to exist, for it to be
documented, and for it to be easy to control.
Vault door, wooden wall, chainsaw.

@_date: 2008-04-14 20:43:14
@_author: Robert J. Hansen 
@_subject: Miscellaneous questions 
It violates a de-facto standard.  That hurts.
The standard allows for terabit RSA keys.  Should GnuPG allow them?
All real-world implementations of real-world standards have to make
decisions about what will be supported and how it will be supported.
This is what engineering is all about.
Take it up with the working group and get the RFC changed.
Depends on who you ask.  A few people on-list (myself being one of them)
think GnuPG supports too much of OpenPGP.
I can think of ten without needing to hit Google.
Yes, but you're still wrong.
If the GnuPG developers had that attitude, GnuPG would have only
supported DSA, Elgamal, SHA-1 and 3DES.  The fact that GnuPG supports
essentially all of RFC 2440/4880, despite the fact the average person
really doesn't need most of it, is strong evidence against your argument.
This is a WG issue.  Take it up with them.
Sure it does.  What do you think SHOULDs and MAYs mean?  Only the MUSTs
in the standard must be present.  Everything else is optional.
Yes.  Where's the problem?
You can play Russian roulette.  You probably shouldn't.
A lot of groups can't do this.  For instance, a bank's insurance company
may require that any software used go through an expensive certification
process.  If it costs $50,000 to get the software certified, you're not
going to want to upgrade for anything short of the direst emergency.
GnuPG is used in a lot of places besides just people's desktops.  In a
lot of these places, upgrading is an uphill battle.
Not at all.  Discuss it all you like.  But if you can't convince the
developers of the correctness of your opinion, why should they spend
time writing code to implement this opinion?
There is something sociopathic about saying "I cannot convince you
to do this, but you should do it anyway, and if you elect to tell me to
do it myself I'm going to say you're denying me my rights."
GnuPG development is done primarily by g10 Code GmbH.  I work for the
National Science Foundation as a researcher in electronic voting
security.  There's no overlap between my work and GnuPG.
Section 13.2 of RFC4880.  "Since TripleDES is the MUST-implement
algorithm, if it is not explicitly in the list, it is tacitly at the end."
If this is what you want the RFC to say, take it up with the WG.
Just because someone disagrees with you vigorously does not make them
"highly conservative" or "narrow-minded".  It very often means they've
been burned more than you have, and want to spare other people the
anguish which will result if you are allowed to play with matches.
No.  You can't.  3DES is appended to the end.  If you want this behavior
to change, talk to the WG.
Then they need to use something other than OpenPGP.
OpenPGP is not meant to be all things to all people.
NIST replaced DES because it was a 56-bit cipher.
3DES is a different beast.
Close enough for jazz.
Please don't try and engage me in a silly freshman-level philosophy

@_date: 2008-04-15 08:03:10
@_author: Robert J. Hansen 
@_subject: Miscellaneous questions 
You may want to consider re-reading your answer a few times and asking
yourself, "why do I feel this way, and why do other people feel the way
they do?"  It may be informative.
There's a reason why University computer science departments are
distinct from the math department.
At a very high level, computer science is just an applied mathematical
discipline.  The reality is that very little programming work is
actually computer science; it's software engineering.
Developing the math behind an algorithm is a mathematical task.
Implementing the algorithm is definitely a software engineering task.
Coming up with a protocol in which these algorithms are used is even
more clearly a software engineering task.
Yep.  Welcome to software engineering.
One of the best techniques available to us for controlling complexity in
software--and definitely the simplest--is to take a chainsaw to the
feature list.  Go through the specification and copy down every single
MUST.  Stop right there.  Implement the MUSTs, make them rock solid
reliable.  Only then allow yourself to start worrying about SHOULDs and
This is how GnuPG was developed, by and large.  In the very early days,
GnuPG supported only the bare minimum necessary to conform to the RFC.
Features like Twofish support were not added until the MUSTs were well
in hand.
Bring it up with the working group.
I am not being sarcastic or facetious when I say that.  I'm absolutely
sincere.  If you feel this strongly about it, then bring it up with the
working group.  However, complaining about the RFC here isn't going to accomplish anything.
I know of at least one major telco which was, for a while, using OpenPGP
to secure billing information on a national level.  That was some years
ago, though, and they may have changed their system since.  (Due to NDA,
I'm unable to disclose the telco name.)
In the event of a security update to GnuPG, they look for ways to limit
the problem without changing source.  If they have to change source,
they backport the fix and go through an abbreviated approval process
which still costs them a good bit of money.
Except for people like you, who say "it's not hard to upgrade GnuPG, so
there's no reason to be concerned about interoperability with old versions".
I'm not going to presume to try to answer for David.  I will suggest
that you change the question.  In English, the kind of question you've
just asked is called "leading", if not outright "loaded".  (A loaded
question is an extreme form of a leading question.)
Try asking instead: "it appears that OpenPGP is a very large
specification, and few people need all of it.  Is this true?  If it's
true, why does GnuPG support so much of it?"
Same question, but not leading and not loaded.  If David chooses to
answer, I'm pretty sure his answer will be insightful and one which both
of us will disagree with.  But hey--he's writing the code, so he gets to
do that.  :)
If it is not in the list, it is tacitly at the end.
Tacit: "implied by necessity."  A tacit agreement is one which no one
has explicitly stated, but which is true nevertheless.
Like many adjectives, it may be discarded from a sentence without
changing the meaning of the sentence.
"Since TripleDES is the MUST-implement algorithm, if it is not
explicitly in the list, it is in the list."
Regardless of whether 3DES is explicitly listed or not, it's going to be
in your preference list.

@_date: 2008-04-15 08:40:17
@_author: Robert J. Hansen 
@_subject: Miscellaneous questions 
If you put GnuPG 3.0 available for download, everyone who's looking for the latest release will grab it.  The people who are quite happy with 1.2, 1.4 or 2.0 won't.
Now imagine that 3.0 breaks backwards compatibility.
Anarchy ensues.  A lot of your users can't talk to each other.  Most of them don't know why.  "I'm using GnuPG 3.0, I don't know why it can't talk to PGP 5.0, I mean, GnuPG 2.0 could...!"
Ensuring a migration path is so critically important in software engineering.  Breaking backwards compatibility is seen as an extreme step.

@_date: 2008-04-15 20:35:46
@_author: Robert J. Hansen 
@_subject: Miscellaneous questions 
As has been mentioned here at least twice now, see section 13.2, where
it explicitly says if the MUSTs are not listed, they are tacitly listed.
I do not understand how much clearer I can make this.  By the plain
black-letter of RFC4880, the MUST algorithms are always present.
Always.  If you want this to change, take it to the WG.
It's unwise to ascribe semantic meaning to a syntactic specification.
The specification says what it says: nothing more, nothing less.
Arguing "GnuPG should support a nonconformant extension to the spec" is
probably not going to get much of anywhere.
Define "security" first.

@_date: 2008-04-19 19:45:06
@_author: Robert J. Hansen 
@_subject: Naming of GnuPG 
Speaking for myself, no.  But I'm pretty far from a normal user.
Regular users are taught to think that bigger version numbers are
better, more recent, more capable, more bug-free, etc.
Windows NT 3.51 --> Windows NT 4.0
Windows 2000 --> Windows 2003 Server
FreeBSD 5.2 --> FreeBSD 6.0
Fedora Core 8 --> Fedora Core 9
GnuPG 1.4 --> GnuPG 2.0
One of those is not like the other, but I think the average user would
be hard-pressed to figure which is which.

@_date: 2008-04-19 21:23:46
@_author: Robert J. Hansen 
@_subject: Naming of GnuPG 
Hash: SHA256
"Better" is a word I did not use and would not use.  Your attempt to put
that word in my mouth tells us a lot more about you than about me.
Given that your message appears to be an attempt to get a reaction from
me, the preceding is the only reaction you will get.  Goodbye.

@_date: 2008-04-19 21:41:15
@_author: Robert J. Hansen 
@_subject: Naming of GnuPG 
Yes: that's the point I was making.  Regular users are taught to think
this.  This is generally true.  GnuPG is not following the regular
versioning conventions.

@_date: 2008-04-19 23:28:15
@_author: Robert J. Hansen 
@_subject: Naming of GnuPG 
GnuPG 2.0 adds S/MIME support, which is a totally different
cryptographic standard than OpenPGP.  If you need FOSS S/MIME, then you
need GnuPG 2.0.
Otherwise, I'd stick with 1.4, for reasons I've mentioned before on
list.  Check the archives from a couple of weeks ago.

@_date: 2008-04-21 08:59:46
@_author: Robert J. Hansen 
@_subject: Naming of GnuPG 
I imagine this idea would get a lot of pushback from 1.4 users.  I know
that I'd be bothered by it.

@_date: 2008-04-21 09:21:50
@_author: Robert J. Hansen 
@_subject: Naming of GnuPG 
My reason, or the general reason?
The general reason... pick your poison, really.  There are a lot of them.
1.  The paranoids.
Read alt.security.pgp sometime and you'll find a bunch of people who are in critical need of getting their tinfoil hats readjusted.  These are people who continue to use PGP 6.5.8 because "obviously, they closed the source in PGP 7 so they could put in a back door."  And then there are people who swear by PGP 2.6 because they heard a rumor somewhere that Phil Z. got off the law-enforcement hook by promising to put a back door in PGP 5+.
Even on this list, we've seen people who have come really close to making accusations against Werner of being complicit with law-enforcement authorities.  (See "Using Old PC as Hardware Security Module" in the archives, from May of 2007.)
If GnuPG 1.4.x suddenly gets marked "deprecated" and begins to be phased out, a whole lot of people are going to start asking "why?  Official word on the GnuPG list was that GnuPG 1.4 was still perfectly safe and would be maintained for some time."  And those are the good ones.  The rest will begin to make conspiracy theories.
2.  The conservatives.
As David pointed out, being conservative in cryptography is often a sign of maturity.  There are a _ton_ of PGP 2.6 users out there who never upgraded because they never saw the need to jump on the bandwagon.  If you mark GnuPG 1.4.x as deprecated, you'll see a lot of users just quietly ignore the developers' decision.
The question is not whether any OpenPGP changes from 2.0 will be backported to 1.4.  They will.  The only question is who will do the backporting.  The instant the GnuPG developers drop 1.4 support, someone else will pick it up... and maybe not someone who's especially competent.  We have already seen this happen with PGP 6.5.8 and Imad Faiad's CKT builds; there is no reason to think the same would not happen to GnuPG.
3.  The installed base.
GnuPG 1.4 is used in a lot of places.  A lot of the installed base simply can't upgrade on a dime.  Ask anyone who's worked in telecom precisely how many forests had to be cut down just to make the paperwork involved in making a small change to the deployed software.  Healthcare is another high-bureaucracy field.  Banking.
... My own reason for pushing back against this idea is   However, don't underestimate  1 and 3.

@_date: 2008-04-21 09:51:05
@_author: Robert J. Hansen 
@_subject: Naming of GnuPG 
You said to phase it out.  The engineering term for that is "deprecation".  When something is marked deprecated, that means it works now but there are active plans to move on to something else.
The latter will not happen, judging from our experiences with PGP 2.6.
 >
Please read what I wrote.  I did not say everything from 2.0 would be backported.  I said OpenPGP changes would be.
They would be backported.  Look at how many hacks people have come up with to the 2.6 codebase to support new ciphers, new hash algorithms, new... etc.  The only question is who backports them.
Keep in mind that I'm not saying wk, David, etc., are forced to do the backporting.  I'm just saying that it will happen even if they wash their hands of it.  1.4 is not going anywhere, for two very big reasons:
Any proposal of "well, we should phase out GnuPG 1.4" needs to address both of those reasons why phasing it out is impractical.
Building on POSIX is pretty easy.  Building on Windows is a torment of the damned -- I think the way the developers do it is with a cross-compiler hosted on a UNIX system.  I don't even want to think about building it on OS/2 or VMS.

@_date: 2008-04-26 02:20:16
@_author: Robert J. Hansen 
@_subject: Naming of GnuPG 
My own two cents' worth:
GnuPG was originally named as such, as I understand it, as a sort of
play on PGP.  GPG was a Free Software alternative to PGP.  The metonymy
(if that's the appropriate word) made it easy to understand how GPG fit
into the software landscape.  PGP.  GPG.  Closely related and
interoperable programs.
I'd like to see GPG remain the name for only 1.4.
GnuPG 2.x introduces a lot of new crypto support that is not related to
OpenPGP.  The original metonymy is no longer appropriate.
Call it GnuPS, for the GNU Privacy Suite.  If additional tools,
technologies, etc., are added to GnuPG 2.x or a future 3.0, then the
GnuPS name can remain unchanged.
In order to limit confusion with the Global Positioning System (GPS), it
should always be spelled out as GnuPS.

@_date: 2008-08-02 08:30:06
@_author: Robert J. Hansen 
@_subject: Starting with gnupg 
They get a bunch of data they cannot distinguish from white noise.  :)
Someone would need:
As long as these two are kept secret, an attacker would have a (very!)
hard time decrypting the message.

@_date: 2008-08-02 09:42:11
@_author: Robert J. Hansen 
@_subject: Starting with gnupg 
The canonical answer is "don't do that, then!"
telnet and ftp are antique protocols that have much better replacements
available to them.  ssh, scp and sftp are all in common usage nowadays.
 Anyone who uses telnet or ftp for any kind of sensitive information is
living dangerously by deliberate choice.

@_date: 2008-08-04 02:49:46
@_author: Robert J. Hansen 
@_subject: [GnuPG-users] identical files -> non-identical encrypted files 
So did you.  This scheme is poorly specified, based on an incorrect
understanding of user needs, as a practical matter can be cracked, is
rife with implementation difficulties, and you seem to have no
understanding of the implicit tradeoffs and compromises which go into it.
It's just not going to work.
Please study the problem domain.
Additional remarks:
  * Key management issues in this are largely handwaved.
  * Rekeying of drive is problematic.
  * BitLocker's architecture may be worth studying
  * Disk keys _do_ change, they _need_ to be changeable, and
    any protocol which does not support this is not suitable
    for real world use.

@_date: 2008-08-04 02:54:39
@_author: Robert J. Hansen 
@_subject: Starting with gnupg 
This means you need to find a competent sysadmin and/or hosting
provider.  If your sysadmin says it's hard to configure the server to
use ssh/scp/sftp, fire your sysadmin and get a competent one.  If your
hosting provider refuses to provide ssh/scp/sftp, take your business
This is irrelevant to ssh/scp/sftp.

@_date: 2008-08-04 22:41:52
@_author: Robert J. Hansen 
@_subject: good practices when using gpg --symmetric? 
All my remarks here are restricted to GnuPG.  Other cryptosystems will
have other answers.
Not especially.
Impossible to answer without knowing more about your particular needs.
For the most part, the answer is "no."

@_date: 2008-08-07 18:09:21
@_author: Robert J. Hansen 
@_subject: MAC Installer for GNUPG? 
The version there is a little out of
date, but it's still the easiest to install package.
A direct link to it is:

@_date: 2008-08-12 22:16:19
@_author: Robert J. Hansen 
@_subject: public newer than the signature 
Time for UNIX systems is generally this way.  Win32 and MacOS (pre-OS X)
have their own ways of storing time.
It is ridiculously hard to come up with a robust time and date standard.
 This is why there are so many different, conflicting implementations
out there.
Note that in some instances, GnuPG will use an ISO date format as
opposed to seconds-since-Epoch.

@_date: 2008-08-13 02:25:27
@_author: Robert J. Hansen 
@_subject: public newer than the signature 
The ODF-OOXML debate really has very little to do with date and time
standards.  If there was an obviously correct way of doing things, both
document formats would support it.
The problem tends to be this: how do you define "time", and how ought it
be incremented?  If you ask a person in the street how long a year is,
they'll say 365 days.  If they're bright, they'll say 365 and a quarter.
 But the reality is leap years only apply in years evenly divisible by
four and _not_ divisible by 25, with the exception of years evenly
divisible by 400.  (No, I'm not kidding.  This is why 2000 was a leap
year, but 1900 wasn't.)
And then we get into the question of leap seconds.  Where should they be
placed?  How should they be accounted for?
That's not even addressing questions like how to make a calendar that
caters to our Gregorian calendar, but can also handle the Jewish and
Islamic calendars, which are defined not in terms of absolute units of
time but in terms of astronomical events.
E.g., in the Gregorian calendar it's pretty easy to tell whether a date
falls on the weekend.  In the Jewish calendar, the Sabbath begins at
sundown on what the Gregorian calendar would call Friday and continues
until the appearance of three stars in the sky on Saturday night (!).
Hence, dates in the Jewish calendar depend not only on your latitude and
season, but also on local weather conditions and light pollution.
(Anyone who says "... well, yeah, but that's an obviously crazy calendar
standard, so we shouldn't care about it" will be roundly thwacked.
Given how crazy the Gregorian calendar has occasionally been, including
downright _missing a couple of weeks_ once, the Gregorian calendar does
not exactly have much room to criticize.)
On top of that, there are technical issues.  If you're just tracking
seconds since an arbitrary point in time, how do you increment this
clock to adjust for leap seconds?  Do you actually increment the clock,
or do you make a note somewhere "the actual time is now offset by a leap
second; the amount of time since Epoch hasn't really changed, though"?
What range of values can the since-Epoch value hold?  Most UNIXes hold
it as a 32-bit signed integer, meaning January 1 2038 we're going to see
a lot of legacy applications crash.  We could switch it to a 64-bit
value, but this is kind of contentious for various reasons (mostly, IMO,
personal prejudice masquerading as technical objections).
What about applications that need to keep rigorous track of time?  For
instance, the UNIX seconds-since-Epoch date/time format is pretty poorly
suited for our modern environment, where GPS satellites need nanosecond
accuracy, and relativistic effects have to be considered for essentially
all satellite communications.
Seconds since Epoch is just a bad date/time format, there's no two ways
about it.  But then again, _all_ the date/time formats are bad.  What
seconds-since-Epoch has going for it is that it's dead simple and
everyone understands it.  Those are two of its strengths, and for that
reason it's not going away anytime soon.
... And on this note, I'm going to stop rambling on this increasingly
off-topic subject.  Hopefully this is a good overview of why programmers
hate all the date/time formats out there, and just how tough it is to do
it right.  :)

@_date: 2008-08-13 05:21:10
@_author: Robert J. Hansen 
@_subject: Importing old PGP key 
I'd start by asking whether you really need that key.  512-bit RSA is
nowhere near modern standards of sufficiency; it is quite likely that in
just a few years such keys will be able to be broken by motivated high
school students.
RSA-512 is grossly inadequate for essentially any serious cryptographic
If you absolutely _must_ have this key in GnuPG, well, we can help you
do it.  But first ask yourself whether you should be migrating to 2kbit
keys.  If so, then now is the ideal time to do it.

@_date: 2008-08-18 16:29:24
@_author: Robert J. Hansen 
@_subject: Publish Certificates 
gpg --keyserver x-hkp://pool.sks-keyservers.net --send-key ... e.g., if your key ID was 0xDEADBEEF, you'd type
gpg --keyserver x-hkp://pool.sks-keyservers.net --send-key 0xDEADBEEF
Hope this helps!

@_date: 2008-08-18 20:06:54
@_author: Robert J. Hansen 
@_subject: Publish Certificates 
Your key ID is 0x8BF7AA16.
You have not jeopardized your traffic by posting this, never fear.  :)

@_date: 2008-08-19 05:53:20
@_author: Robert J. Hansen 
@_subject: Publish Certificates 
1.  Please trim your quotes.
2.  I can confirm John: it's there.
job:~ rjh$ gpg --recv-key 8bf7aa16
gpg: requesting key 8BF7AA16 from hkp server pool.sks-keyservers.net
gpg: key 8BF7AA16: public key "Carlos Williams "
gpg: Total number processed: 1
gpg:               imported: 1

@_date: 2008-08-19 21:12:50
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
Assuming you meant GnuPG, the answer is 'no'.
Assuming you meant PGP, the answer is 'maybe'.  PGP provides a secure
deletion tool, but as far as I know there has never been any serious
independent study of its effectiveness.
I would suggest asking PGP Corporation, or perhaps asking on the
PGP-Basics mailing list over at Yahoo! Groups.

@_date: 2008-08-20 00:53:26
@_author: Robert J. Hansen 
@_subject: Publish Certificates 
First, don't type in commands if you don't understand what they are or
what they're doing.  If you typed in "job:~ rjh$ gpg" just because you
saw it in an email of mine, I can only imagine what you'd do if you saw
"del *.*" in another email.
... Anyway.  It's a UNIX command prompt.  It identifies my machine as
"job", my current directory as $HOME, and my login as rjh.
My naming scheme uses the books of the Bible.  Each machine gets a
unique and easy to remember name, and it makes it quite easy to tell
whether a given system is newer or older than another.  E.g., ezra is
older than psalms.
Ironically, psalms is my iPod.

@_date: 2008-08-20 02:21:24
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
No one in the private sector has ever claimed to be able to recover data
overwritten even once.
Think about it this way.  The next two people you see today, one of them
is carrying my tiger-proof rock, and the other one isn't.  You can't
tell whether my tiger-proof rock is actually working, because there are
no tigers around trying to eat people.  So my tiger-proof rock is really
effective, huh?
The next two hard drives you see today, imagine one of them is shredded
by the Gutmann method and the other one is overwritten just once.  You
can't tell whether Gutmann's method is effective, because there's nobody
able to read either.  So Gutmann's method is really effective, huh?

@_date: 2008-08-20 09:11:16
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
If anyone on the list is an EE or a physics geek looking for a good
paper, it might be interesting to explore using the Curie Point as a
data erasure technique.  For a lot of the exotic magnetic materials used
in modern hard drives, the Curie Point is pretty remarkably low -- it
might be possible to put a drive in a toaster oven, raise the
temperature to the Curie Point, take it out, let the drive cool, and
have the platter surfaces be randomized.
I've been intending to do this one for a couple of years now, but every
time I get around to looking into it I always find something else to
spend money on besides hard drives to destroy...

@_date: 2008-08-20 20:17:05
@_author: Robert J. Hansen 
@_subject: Securely delete files... [going further off topic] 
The idea is that if, say, the CP of the ferromagnetics is 150C, you set
the oven to 160C and leave it in there for a couple of hours.  After a
while, simple heat dispersion through the media would do the job for you.
Like I said, I'm not going to be doing this experiment myself.  It's the
sort of thing which could be interesting, but which would need to be
done in a safe environment.

@_date: 2008-08-20 20:23:47
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
I have a friend who works in Interesting Places who tells me they once
successfully put together a CD-R that had been put through a crosscut
shredder.  As he said, "never underestimate the power of OCD and superglue."
Well, you don't have to slag it -- you only have to raise the
temperature to the point where quantum mechanics says "okay, the
magnetization has all gone bye-bye."  But yes, the general point remains.
The Gutmann shred is overrated (although, curiously, not by Gutmann, who
has consistently advocated for its sane use), and total annihilation
tends to be underrated.

@_date: 2008-08-20 20:36:49
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
For the most part, these tools exist to make people feel better about
doing something to make their data unrecoverable.  I am unaware of any
evidence either that they are effective, or that they are any better
than more commonplace solutions.
For a new drive, pick up full volume encryption software.  Don't let
anything get written to the disk that's not encrypted.  If someone wants
to recover your information later, I wish them luck.
For an existing drive, destroy it.  Just how much you need to destroy it
(a hammer to the drive platters, or thermiting the entire assembly) will
depend on just how well-financed your opponents are.
A while ago there was a decent article at _Computer World_, outlining
data destruction for non-technical types.  You may find it interesting.
 You can find it at the following (really long) URL, or just by going to
Google and entering "site: Hope data destruction".

@_date: 2008-08-20 23:10:32
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
Sure you were.  You were taught -- or should have been taught -- to
discover the facts, and to develop your security implementation in light
of both your policy and the facts.
Fact: there is no effective and reliable way to nondestructively scrub
data from a modern PRML/EPRML hard drive.  (If you could definitely say
"yes, I'm writing data to this particular spot on the hard drive", then
you probably could; but that's kind of a fantasy.)
Imagine you have a one sentence security policy: "hard drives must not
leave traces of old files visible to forensic examiners."
Imagine you have a one sentence security implementation: "hard drives
will scrubbed every week."
Well -- crap.  You just discovered that your implementation is bogus,
because it's at odds with the facts.  You have to head this off at the
pass.  How do you do it?  One option is to use full volume encryption.
Okay, fine: your implementation, version 2.0, is "hard drives will use
full volume encryption."
Now you have to figure out how the policy changeover will work... which
is to say, how to move from version 1.0 to version 2.0 in a way that
will still uphold your security policy.
You copy all the information from the old drives to the new drives.
Congratulations: the new drives never need to be scrubbed.  The old
drives, however... you know people can make forensic recovery from them,
because you know they can't be scrubbed.
So after making sure that you have a correct copy of the data from the
old drives, you thermite them, you shred the disk platters, you etch the
platter surfaces with sulfuric acid... whatever.  You utterly destroy
them, putting the drive permanently beyond use.
I can only speak for myself here, but I strongly suspect Werner, David,
Mark and everyone else who's been chiming in will agree -- we are not
talking about total destruction of hard drives as something you should
want to do.
We're talking about total destruction of hard drives as the _only
realistic way to scrub data._
If you need your data scrubbed, you're going to have to nuke your hard
drive.  It's that simple.  On your new hard drive, you should probably
use some technique to make sure you never need to scrub data -- not
unless you like thermiting hard drives.
ObWarning: many of the techniques we've discussed for destroying hard
drives are really quite dangerous.  Thermite is _not_ a friendly
chemical.  Neither is sulfuric acid.  Even an approach as low-tech as
hammering the platters into oblivion can be dangerous -- see Werner's
statement about all the shards that hit his safety glasses.  Before
destroying a hard drive, learn how to do it safely.

@_date: 2008-08-21 01:34:25
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
Better than some ideas I've heard.  (E.g., use ClF3 to scour the
platters.  Only problem: ClF3 will almost certainly not scour the
materials... but it will probably cause you to oxidize quite nicely.
Along with causing the oxygen in the air to oxidize.  And the fire
extinguishers.  And the sand buckets.  And...)
Strangely, ClF3 is used pretty commonly in the computer industry,
particularly in fab plants.  This is one reason among many why I'm so
glad I'm not an EE.

@_date: 2008-08-21 04:57:20
@_author: Robert J. Hansen 
@_subject: What does the message mean while encrypting? 
Add "--trust-model always" to the beginning of your command line.
E.g., "gpg --trust-model-always ...", followed by everything else.
The warning is worth listening to, however.

@_date: 2008-08-21 06:08:44
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
I am no chemist, but I would not be at all shocked to find that
well-stocked research laboratories have supplies on hand that you or I
would consider ridiculous.
As an example, a few weeks ago I was talking to a fellow graduate
student here.  He was talking about the fun he'd recently had with
fluoroantimonic acid.  This stuff will protanate _methane_.  Of course,
Stephen characterized it as "a lot of fun" and "we should get you into
the lab sometime, Rob!", at which point I realized that I kind of liked
not being dissolved...
("I will not screw with the chemistry grad students, for I am two-thirds
water, and thus am an ambulatory supply of useful if impure solvent.")

@_date: 2008-08-21 15:54:57
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
There are a ton of very efficient ways to destroy hard drives which
everyday users can do.  There's no need to have other people do it for
you -- after all, how can you be sure they'll do it at all?  If you want
your hard drive destroyed, you really have no choice but to do it yourself.
Hammering the drive platters, grinding off the drive surfaces, bulk
degaussers, powerful acids and thermite are all cheap and effective,
albeit all of them requiring some knowledge of safety precautions.

@_date: 2008-08-21 16:07:45
@_author: Robert J. Hansen 
@_subject: Securely delete files... 
Hard drives don't use iron.  They use rare earth oxides.  Much, much
lower CP.

@_date: 2008-08-22 08:42:04
@_author: Robert J. Hansen 
@_subject: " Welcome to the Quantum Internet" - By Davide Castelvecch 
There are no quantum encryption algorithms.  None.
What we have is quantum key exchange, where you use a handful of qubits
to negotiate a random session key in a way that an eavesdropped cannot
listen in on the transaction.  If you're willing to burn up a _lot_ of
qubits, you can turn this into the one-time pad.  But either way, all
you're doing is transferring key material in a way that can't be
eavesdropped upon -- nothing more.

@_date: 2008-08-22 22:07:53
@_author: Robert J. Hansen 
@_subject: " Welcome to the Quantum Internet" - By Davide Castelvecch 
Depends on how pedantic you want to be, and how you define
'transaction'.  Frankly, if I were to have proof of an eavesdropper, I
would consider the transaction to be compromised and I'd scrub it.
Hence, QM makes it possible to have a key transaction between Alice and
Bob guaranteed to be free of eavesdroppers.

@_date: 2008-08-25 05:52:53
@_author: Robert J. Hansen 
@_subject: How can I encrypt with a PGP pub key 
6.5.8 is old.  "Decrepit" might be a better word to use for it.  It
_way_ predates RFC4880, and thus you need to tell GnuPG to work around
PGP 6.5.8's limitations.
Add "--pgp6" to the beginning of your GnuPG command line.  E.g.:
gpg --pgp6 --recipient  --encrypt

@_date: 2008-08-29 07:48:51
@_author: Robert J. Hansen 
@_subject: Installation gnupg on Windows 
Principally, two things:
* The architecture has been redone to make it easier to maintain
* The introduction of S/MIME support
These are the two claims Werner, David and others have made re: GnuPG
2.x.  I have not yet verified either; I have no need for GnuPG's S/MIME,
and I haven't taken a good look at the code.

@_date: 2008-08-29 12:04:42
@_author: Robert J. Hansen 
@_subject: Automate decryption 
It's fairly easy to automate things with Perl.  Biggest concern will be
keeping the file unreadable by other users, though, since your
passphrase will be in the file.

@_date: 2008-11-30 23:40:25
@_author: Robert J. Hansen 
@_subject: Rare condition incompatibility of public key 
This is factually untrue.
Phil Z. left PGP Security, a branch of Network Associates, in early
2001.  This would've been just after the PGP 7.1 release.  Phil himself
has sworn to the solidness of the PGP 7.0 and 7.1 releases.  Despite
there being no source release, most people -- myself included --
consider Phil's word to be good.
Network Associates shut down PGP Security in early 2001.  PGP
Corporation was formed as a completely separate business entity which
purchased the desktop PGP products from Network Associates.  Most of the
key players from PGP Security came on board at the new PGP Corporation.
Phil Z. has officially left PGP Corporation to pursue other interests,
if memory serves.  This doesn't surprise me in the least.  After a
decade and a half at the same job, he's entitled to do other things.  As
of late, secure internet telephony has been his object of interest.
That said, Phil is still in close contact with many of the principal
people at PGP Corporation.
Toyota has a philosophy that when investigating failures, one should ask
"why?" multiple times.
Q.  Why is this failure occurring?
A.  Your friend is using an antique version of PGP.
Q.  Why is your friend using an antique version of PGP?
A.  Your friend doesn't trust versions Phil hasn't worked on.
Q.  Why does your friend mistakenly think Phil hasn't worked on
    7.0 and later versions?
A.  ... I don't know.  You may want to look into this.
As far as engineering maxims go, the Toyota school of thought is pretty
good.  Find the deepest level of failure and fix that, rather than
fixing superficial problems.
Other people have suggested convincing your friend to use a more recent
version of PGP, or a recent version of GnuPG.  It's good advice, as far
as it goes.  I think the problem goes deeper than that, however.

@_date: 2008-12-01 01:00:29
@_author: Robert J. Hansen 
@_subject: Rare condition incompatibility of public key 
Warning to all: I am going to be even more blunt and direct than usual.
 If my usual level bothers you, as I know it does for some people, you
may wish to just hit 'delete' and move on.
It does if your definition of "good" is "Phil Z. worked on it."
I agree that the axiom is crazy, but it doesn't do much good to tell
someone "your axiom is crazy, change it" if they're not capable of
either (a) understanding why their axiom is crazy or (b) how to apply
their new axioms in a consistent way.
In my experience it works better to say "well, assuming /arguendo/ that
you're right and nothing non-PRZ related should be trusted, why aren't
you trusting these things PRZ is involved in?".  That gets people
thinking logically and critically about how their policy decisions
evolve from their axioms.  Once they have some experience at critical
thinking with respect to trust, then it's time to say "so, if we were
going to draft new axioms from scratch, what should they be and why?"
I fully agree that the axiom is somewhere between "crazy" and "grossly
misinformed."  Unfortunately, in my experience the overwhelming majority
of users don't understand trust, don't want to understand trust, and run
away screaming when asked to think about trust in a logical manner.  You
have to bring them to rationality slowly and in infinitesimally small doses.

@_date: 2008-12-01 03:05:24
@_author: Robert J. Hansen 
@_subject: Teaching crypto to newbies (was: incompat.) 
Should we forbid high schools from teaching Newtonian physics?  The
notions of absolute space and absolute time are gross misunderstandings
of reality.  How much harder is it to bring reality to physics once a
well-meaning teacher has fed these misunderstandings?
We use Newtonian physics to teach the scientific method.  Students are
taught to observe, to hypothesize, to create models, to test them, and
so forth.  Once the students have a good grasp of the tools, the teacher
says "... oh, and by the way, Mercury's precession is off.  Hmm.  Maybe
we should look into that." [*]
Similarly, I think there's value in developing the skill of "given these
trust axioms, what actions should we take?" first, and then challenging
people to re-evaluate their axioms.
That said, reasonable people can certainly disagree on this -- we left
objective fact behind us a long time ago, and are pretty far into the
realm of personal opinion.  :)
[*] Well, _good_ physics teachers do, anyway.  (Thank you, Professor
    Lichty.)

@_date: 2008-12-01 07:48:29
@_author: Robert J. Hansen 
@_subject: Rare condition incompatibility of public key 
This is why I believe in the "small doses" approach: over time, they get
the idea that they're changing their own minds.
There's a thoroughly mediocre movie, _The Way of the Gun_, which has a
scene in which two criminals talking with each other sum up my basic
view of human nature:
Longbaugh: But, you know, then you got the other side [of the cops and
       robbers equation]: these trigger-happy [expletive] all about the
       shooting and posturing and "you don't know who I am" kind of
       thing, the "I been to prison..."
Sarno: Yeah, because you got _caught_, you dumb --
Longbaugh: These days, it's almost like they want to be criminals more
       than they want to commit crime!
Sarno: Well, that's... that's not just crime, you know.  That's the way
       of the world.
... There are a lot of people in the world who want to be seen as smart,
savvy people who know how to keep their communications secure from
unwarranted intrusion.  There are a lot fewer people who want to make
the investment of time and effort required to actually _be_ smart, savvy
people who know how to keep their communications secure from unwarranted
I find that learning how to tell the two apart is extraordinarily useful.

@_date: 2008-12-01 16:05:51
@_author: Robert J. Hansen 
@_subject: Teaching crypto to newbies 
My high school physics teacher was an awful teacher, and was a big
believer in this.
My college physics professor was a great teacher, and was a big believer
in teaching process and letting the results evolve from the teaching of
I would much rather be a Lyle Lichty than an Al Craig.
I found enough errors in my math textbooks as a child to always suspect
every instructor of misleading me out of their own ignorance.  I got
along very well with instructors who taught process and rigorous
examination of things which were claimed to be true, and very poorly
with instructors who taught facts.  Quite often, the facts they were
teaching were not facts at all.

@_date: 2008-12-01 19:16:14
@_author: Robert J. Hansen 
@_subject: Teaching crypto to newbies 
On the contrary, it _is_ logic.  It's an exercise in theorem proving.
"Given: I trust Alice to sign keys; Alice has signed Bob's key.  Prove:
I trust the correctness of Bob's key."
The fact we so rarely think of trust in terms of math does not diminish
the fact that in order to accurately talk about trust we need math.
It's kind of like catching a baseball.  Anyone can do it, but if you
want to accurately talk about trajectories and velocities you're going
to need either some really advanced algebra or some elementary
differential calculus.
Most people decide trust issues by intuition.  What I would very much
like to see is for people to take the next step, and determine trust on
the basis of deductive logic.

@_date: 2008-12-01 21:37:00
@_author: Robert J. Hansen 
@_subject: New GnuPT-Version and new WinPT-Website 
In the future, please try Google first.  You'll get answers much more
quickly that way.

@_date: 2008-12-02 23:45:27
@_author: Robert J. Hansen 
@_subject: New GnuPT-Version and new WinPT-Website 
Absurd.  You're assuming the very thing you're trying to prove.  You're
starting by saying "there's no reason for him not to have done it,
therefore he should have."
We're saying "he's already doing you a favor, so take some
responsibility and just Google it already."
People are under no obligation to do you favors just because you think
it's easy and painless for them to do so.  There are dozens of reasons
why he may have made that email as terse as he did.  I've been known to
respond to email on my iPod Touch when the need is great and it's the
only email communication device I have -- trust me, I keep my emails
very short when on that cramped touchscreen keyboard.
Just because you think it's a no-cost proposition for the original
poster to have included more information doesn't mean it actually was.

@_date: 2008-12-03 12:28:42
@_author: Robert J. Hansen 
@_subject: GnuPG 2.0,9 - Error when trying to compile in Linux. 
The problem is fairly simple, but I can't give a complete fix since I
don't have an Ubuntu 8.04 system handy.
The root of it is that you have the files zlib needs to run, but not the
files you need to compile applications which use zlib.  These are
probably going to be found in something named zlib-dev, or something
similar.  (E.g., on my Ubuntu 8.10 system I think it's actually named
"sudo apt-get install zlib1g-dev" might be useful to you, assuming it's
named the same on an 8.04 system.

@_date: 2008-12-10 07:30:11
@_author: Robert J. Hansen 
@_subject: GnuPG feature suggestion 
(Moved to gnupg-users, where it belongs)
Isn't going to happen.  This proposal gets floated periodically: I'd
suggest checking the archives of gnupg-users for more detailed reasons
than "isn't going to happen."

@_date: 2008-12-14 14:55:26
@_author: Robert J. Hansen 
@_subject: How to remove "Version: GnuPG v1.4.9 (MingW32)" using enigmail? 
Easiest way is to add "no-comment" to your gpg.conf file.

@_date: 2008-12-14 17:07:28
@_author: Robert J. Hansen 
@_subject: Which is the path to gpg.conf in windows? 
I should also add for the OP that Enigmail has an option (in the
Advanced tab of the Preferences window) to add its own comment to the
As John Clizbe said, in conflicts between gpg.conf and the Enigmail
preferences, Enigmail wins.  Leaving that option checked means you'll
still get a comment block.
You must uncheck that comment block _and_ set "no-comment" in gpg.conf
in order for all comments to be suppressed.
Further Enigmail questions should probably go to the Enigmail mailing list.

@_date: 2008-12-17 17:03:46
@_author: Robert J. Hansen 
@_subject: using gpg with private keys from openssl certificates? 
It is a _hard_ idea.  It is not necessarily a bad or stupid idea.  Like
most things, whether it's inspired lunacy or just insane depends a lot
on your particular problem domain.  :)
X.509 (the standard used by freemail certs) and OpenPGP use the same
underlying algorithms, but the protocols are dramatically different.
Making them interoperate is hard, and is usually not worth it.
You can't.
Identity cannot be proven.  Evidence can be presented, but someone can
always say, "no, no, I don't accept that as a form of ID."  Just because
some people accept a given method doesn't make the method good, and just
because some people refuse a given method doesn't make it bad.
As an example, I recently needed to get a driver's license for a new
state.  The unhelpful people at the Motor Vehicle Administration told me
I needed two forms of government-issued photographic ID, a copy of my
lease, and a utility bill in my name.  I asked what they were going to
do with my lease and utility bill.
"Just check to see the name matches."
You don't call the utility company, or call my landlord, or do anything
else to check?
"No.  The law doesn't allow us to.  Your privacy is respected."
So --
I stopped myself just in time before I said "-- given that pretty much
everyone has a desktop publishing setup nowadays and can forge these
documents in an hour, why do you bother demanding them if you're not
even going to check them?"
But I decided that would probably get me some Quality Time with a state
trooper, so I shut up.
The best I've found is PGP Corporation's "Introduction to Cryptography."

@_date: 2008-12-17 18:26:31
@_author: Robert J. Hansen 
@_subject: using gpg with private keys from openssl certificates? 
If they're using the same keypair, then they're interoperating.  (For at
least some definitions of 'interoperability.'  Total interoperability is
probably infeasible.)
What you want to do is very hard to do and, in general, not worth it.

@_date: 2008-12-17 23:16:00
@_author: Robert J. Hansen 
@_subject: using gpg with private keys from openssl certificates? 
The paper does not propose a way to allow X.509 and OpenPGP to
interoperate.  It's instead proposing something much different, which is
unrelated to the original poster's request.

@_date: 2008-12-18 07:36:28
@_author: Robert J. Hansen 
@_subject: How encrypt data/text stream instead of a file? 
Painfully.  While technically possible, it is almost certainly a better
idea to use some other technology.

@_date: 2008-12-18 10:04:23
@_author: Robert J. Hansen 
@_subject: using gpg with private keys from openssl certificates? 
And the answer is the same as before: this is possible although very
difficult and usually not worth it.

@_date: 2008-12-18 12:40:41
@_author: Robert J. Hansen 
@_subject: How encrypt data/text stream instead of a file? 
My bad.  I was reading that as the OP needed GnuPG to function as a
stream cipher.

@_date: 2008-12-22 15:30:07
@_author: Robert J. Hansen 
@_subject: 'Tis the Season 
Hash: SHA256
'Tis the season for Hanukkah, Kwanzaa, Christmas, Winter Solstice, New
Year's, or whatever your favorite holiday is.  It's a time to be
gracious and to remember to say "please" and "thank you", and also a
time for charitable giving.
It's very hard -- if not impossible -- to reward the GnuPG developers
for their labors.  To whom should a donation be given?  To the user who
first spotted a bug, the other user who tracked it down precisely, the
developer who fixed it, the sysadmin who hosts the project?  What about
to the mailing list, where so many questions get answered by people who
have no official connection with GnuPG whatsoever?
There are no good answers to this.  The best that can be done is to
issue virtual beer tokens, to say "thank you", and maybe to do something
for a charity with similar goals to that of the GnuPG crew.
So: to all the developers, to all the bugfinders, to all the people who
patiently answer questions on mailing lists, to everyone who contributes
to signal and diminishes noise... thank you, very much, for making this
community as much fun as it is, and for your role in making GnuPG as
high quality a product as it is.  Consider yourselves to all have a beer
token issued by me, payable on demand should we ever meet face to face.
There are several charitable groups that support the ideals of privacy
rights and individual liberties.  I've assembled three of them below.
This year, I will be donating to the Electronic Frontier Foundation with
a note that it's in thanks for the GnuPG project.
Thank you, Werner.  Thank you, David.  And thank you, everyone else.  :)

@_date: 2008-02-04 01:07:46
@_author: Robert J. Hansen 
@_subject: Can you clarify when data compression is used? 
Prior.  Ciphertext from a strong algorithm cannot be compressed.

@_date: 2008-02-04 01:48:14
@_author: Robert J. Hansen 
@_subject: Can you clarify when data compression is used? 
The question is meaningless.  It's predicated on the assumption that
there exists a ranking scheme by which bzip2 will always beat zip for
compression, or vice-versa.  The reality is that compression algorithms
have certain tasks they're good at and certain tasks they're awful at.
E.g., try compressing ciphertext sometime with either bzip2 or zip.  You
won't see any meaningful difference; both are equally awful at this.
Compressing PE/COFF versus ELF binaries will give different results.
Etc., etc., etc.
I can give only two bits of very broad advice, and one piece of specific
advice.  The two generals:
  * In most categories people care about, bzip2 offers better
    compression but is much slower.
  * Bandwidth is cheap.  It's not worth introducing interoperability
    problems just to get a slightly smaller file.
The one specific piece of advice:
  * Unless you can articulate a clear need why the defaults will not
    work for your purpose, stick with the defaults.

@_date: 2008-02-04 12:57:34
@_author: Robert J. Hansen 
@_subject: Can you clarify when data compression is used? 
provide digital encryption and signing services using the OpenPGP
standard.  [GnuPG] features complete key management and all bells and
whistles you can expect from a decent OpenPGP implementation."
To me, that language is pretty clear about where you should look--the
OpenPGP standard, aka RFC4880, or its immediate predecessor RFC2440.
That said, just because I think it's clear doesn't necessarily means it
should definitely be changed to point people in the right direction.
I wonder who the GnuPG documentation czar is.  Hmm.  I don't know if
that's ever been mentioned on the list--David, Werner, who's responsible
for the docs?
Everyone has a ranked list of preferences.  The preferences of all
recipients are considered and the stable marriage problem solved.  The
outcome of that computation is what algorithm GnuPG will use.
3DES is implicitly in everyone's preference list, so it can be fairly
said that 3DES is the default cipher preference.  Even if everything
else goes to hell, 3DES will be available and will be selected.

@_date: 2008-02-04 14:44:33
@_author: Robert J. Hansen 
@_subject: Can you clarify when data compression is used? 
It wasn't my intention to claim the SMP was used directly, but rather
that it was an analogous process.  It's a good introduction to the idea
of mathematical preference matching.  I apologize for any confusion
generated there.

@_date: 2008-02-04 23:12:02
@_author: Robert J. Hansen 
@_subject: Can you clarify when data compression is used? 
As I understand it, it's largely due to engineering concerns than
mathematical concerns.
The RFC which specifies the OpenPGP protocol first came out in 1998.  It
began to receive revisions almost immediately (the -bis series:
RFC2440bis1, RFC2440bis2, etc.).  These -bis series were meant as
previews of the next official RFC, whenever it would be published.
However, the original RFC remained canonical.  That specified DSA-1024.
 In order to closely follow the RFC, GnuPG left the default as DSA-1024.
 This was probably the right call to make for interoperability reasons.
As an example of what happens when people decide to move beyond the RFC,
look at PGP 7.0.  Management at PGP Security decided that Twofish was
the likely winner of the AES competition, and so they put Twofish into
PGP.  This put pressure on GnuPG to put Twofish into GnuPG, in order to
interoperate with PGP.
Twofish is almost entirely abandoned nowadays, but it still exists in
PGP and GnuPG.  Once a bad decision is made in engineering, the
engineers are stuck supporting it forever.  Take a look through the
archives sometime and see how many people have bitterly complained about
TIGER192 no longer being supported, despite the fact it was part of
GnuPG for about three and a half milliseconds.
I suspect--although I do not know--that a similar motivation drove
GnuPG's decision to leave DSA-1024 as the standard.
Now that RFC4880 has come out, supplanting RFC2440, I imagine the way is
clear to make all new keys DSA-2048 or DSA-3072.  After all, now it's
part of the standard.

@_date: 2008-02-05 11:25:54
@_author: Robert J. Hansen 
@_subject: can you see any problem with this? 
At first blush it seems like a case of there being way too much hammer
for the nail you have in mind.
1.  Compose a single message: "the magic words are... [insert passphrase
2.  Write a script to encrypt each message to each recipient's key and
mail it to them.  If this takes more than 20 lines of Perl, something's
3.  Compose your future traffic as normal, but symmetrically encrypt it
and send it on to your recipients.
... Admittedly, I don't know the particulars of your environment, so
this might be inappropriate for your needs.  But it's the first thing
that comes to mind as I read your description of what's happening.

@_date: 2008-02-05 11:36:06
@_author: Robert J. Hansen 
@_subject: Safe decryption with GnuPG? 
Hash: SHA256
GnuPG is almost certainly the wrong tool for your job.  GnuPG has little
control over low-level operating systems details like swap files.  It is
possible for cleartext to be stored in some manner.
[many other requirements snipped]
Many of your requirements belong in the application stack alongside or
above GnuPG, but are pretty much unrelated to GnuPG.  After it leaves
GnuPG it's no longer GnuPG's problem.  Many of your requirements are
also impossible to meet.  I don't mean "impossible" as in "it would
require a lot of engineering", I mean "impossible" as in "it's like
violating the Second Law of Thermodynamics".
There exists no such implementation.

@_date: 2008-02-05 11:43:11
@_author: Robert J. Hansen 
@_subject: Anti-Tempest Fonts, Where? 
Hash: SHA256
First, it's not "tempest resistant".  TEMPEST is the name of the NSA's
standard on Van Eck-resistant hardware.  What you're talking about is
Van Eck surveillance.  I know, I know, PGP Corporation calls it "Tempest
resistance".  They're wrong, too.
Anyway, taking off the pedantry hat...
I am unaware of any empirical evidence that suggests PGP's Van
Eck-resistant fonts really offer much, if any, security against Van Eck
surveillance.  If you're dealing with people who are willing to park a
van down the block and dedicate a crew of surveillance experts and a few
thousand bucks of directional antennas and custom-built FPGAs at you, my
best advice is to (a) run away and (b) build a Faraday cage.

@_date: 2008-02-05 12:14:59
@_author: Robert J. Hansen 
@_subject: Safe decryption with GnuPG? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
On systems where that's supported, sure.  On systems where that's not
supported, it doesn't.  Ergo, tread carefully.
If your hardware is compromised then you are absolutely screwed, and
there is nothing you can do about it.  Bang, period, game over, end of
sentence, end of discussion.

@_date: 2008-02-05 19:59:29
@_author: Robert J. Hansen 
@_subject: Anti-Tempest Fonts, Where? 
An unshielded monitor cable puts out a lot of RF, regardless of what kind of monitor it's plugged into.  LCDs can be Van Ecked, just as can CRTs.

@_date: 2008-02-06 16:18:29
@_author: Robert J. Hansen 
@_subject: SMIME vs PGP 
While you can probably get some good pointers here, if you're looking
for an answer you can rely on you will either need to do a fair bit of
homework or else contract with an outside information security
consultant.  Information security is a subtle subject and many people
who claim to know things actually know very little about those things.
I, of course, am no exception.
S/MIME support (note the slash) is built into virtually every
proprietary email client as a standard feature, and is present in many
of the open-source ones.  Outlook, Thunderbird, Lotus Notes, Apple's
Mail.app, and more, all support it out-of-the-box.
S/MIME integration with mail clients is substantially better than
OpenPGP's integration with mail clients.
On some level, theoretically, sure, given that S/MIME uses X.509
certificates, and X.509 certificates can be finessed into the Web of
Trust.  However, you will need a lot of elbow grease and a really big
crowbar, and the resulting Frankenstein's Monster will not be pretty.
I have never seen this done in practice.  S/MIME and OpenPGP
interoperability is, AFAIK, a theoretical chimera.
I can't answer this without knowing what level of detail you're
interested in, difference-wise.  From an end-user perspective S/MIME and
OpenPGP provide essentially identical capabilities.  Slightly more
involved than that, S/MIME and OpenPGP use many of the same algorithms.
  More involved than that, they handle all manner of internal things
If you want to come to a fairly comprehensive understanding of both, I
would recommend reading RFC3852 (  )
and RFC4880 (  ).  S/MIME is based
upon the former, and OpenPGP is defined by the latter.

@_date: 2008-02-08 09:55:57
@_author: Robert J. Hansen 
@_subject: Key Server 
Add "keyserver x-hkp://pool.sks-keyservers.net" to your gpg.conf file.

@_date: 2008-02-10 01:35:46
@_author: Robert J. Hansen 
@_subject: Can you clarify when data compression is used? 
Bruce recommends against using Twofish for crypto applications.
He has never backed off from either of two claims:
He has said  many times and keeps a page on his site devoted to the
most recent research into Twofish.  He has said  many times,
particularly in his book _Practical Cryptography_.

@_date: 2008-02-10 21:51:03
@_author: Robert J. Hansen 
@_subject: Are DSA2 signing keys backwards compatible? 
I think that's reversed: DSA2 is quickly becoming a de facto standard, but it is not a de jure standard.
De facto: "in fact".  De jure: "in law".  De jure standards exist on paper but are not respected, de facto standards exist in reality but may not exist on paper.
If I am mistaken as to what you meant to say, please correct me.  :)

@_date: 2008-02-11 09:18:35
@_author: Robert J. Hansen 
@_subject: Are DSA2 signing keys backwards compatible? 
Not necessarily.  Imagine you're in an environment where your cipher
selection is constrained by law.  You may be able to produce SHA256,
SHA384, SHA512, MD5, TIGER192 and WHIRLPOOL (just to come up with an
absurdly comprehensive list of hashes), but you may be constrained by
either law or corporate policy to only use SHA-1 for your signatures.
Other people outside this environment who are communicating with you
would not be constrained by those regulations, and could use whatever is
necessary in their environment.
E.g., you may be required to use SHA-1, someone else may be required to
use RIPEMD160, despite the fact both of you are capable of using much
longer (and better) hashes.

@_date: 2008-02-11 09:30:57
@_author: Robert J. Hansen 
@_subject: Are DSA2 signing keys backwards compatible? 
If you are interested, I have about half of a GnuPG user's manual
written up in DocBook format.  Right now it only covers the mathematical
and conceptual side of GnuPG, leaving a lot of practical stuff to be
done, but it may be useful to you.
4880, not 2440.
RFC4880 documents the truncation process pretty well: leftmost bits
only, etc.  The truncation process itself should not be troubling.  Any
set of bits could be truncated--high order, low order, high-order even
bits, low-order odd bits, bit positions that lie along a Riemann zeta, etc.
A hash should be indistinguishable from noise.  Any selection from noise
is just as random as any other selection.
Hash truncation is very well documented within the field of cryptography
and cryptanalysis.  If you like, check the _Handbook of Applied
Cryptography_, which is available for free online or in dead-tree form
from any decent university library.
Showprefs is a hint to GnuPG, not an absolute rule.  GnuPG is within its
rights to reject a preference if GnuPG determines that the preference is
irrelevant to a particular environment.  Document that DSA1024 requires
a 160-bit hash and thus any preference for MD5 will be ignored, DSA2048
requires a 224-bit hash and thus any pref for MD5, SHA1 or RIPEMD160
will be ignored, DSA3072 requires a 256-bit hash and thus any pref for
MD5, SHA1, RIPEMD160 or SHA224 will be ignored.
RSA signing keys may be used with any length of hash.  I think this is
probably a misfeature, but it is what it is.
People have this really annoying habit of believing GnuPG needs to be
tweaked to get good communications security.  It leads people to doing
things like generating a 1024-bit RSA signing key since that's all that
will fit on their smartcard, but using SHA512 as a hash algorithm to try
and 'compensate' for their short RSA signing key.  Just as ridiculous,
IMO, is the conventional wisdom that symmetric key lengths, asymmetric
key lengths and hash lengths should all be 'balanced'.  Etc., etc.
Hence, as you've remarked, my usual curt recommendation to stick with
the defaults and not worry about it.

@_date: 2008-02-13 21:24:14
@_author: Robert J. Hansen 
@_subject: Corporate use of gnupg 
Quoting gnupg at ethen.de:
Same problem exists with PGP's ADK feature, which should really be  named an ARR, for Additional Recipient Request.  While ADK usage can  be enforced within the ADK-using group (mostly: there are some  caveats), emails from outside the group going in to the group are  under no such restrictions.
This message was sent using IMP, the Internet Messaging Program.

@_date: 2008-02-14 08:44:32
@_author: Robert J. Hansen 
@_subject: Safe decryption with GnuPG? 
Not necessarily so.  A lot of people make a big deal out of a couple  of papers published on how much whole-disk encryption slows down  OpenBSD, but the flip side to that is the file and network systems of  OpenBSD are not as efficient as those of many other OSes.  If you've  done your own empirical tests with your own OS and discovered it's too  slow, then by all means, it's too slow.  Otherwise, you may wish to do  some empirical tests.
If the attacker has access to your hardware, then you're out of luck,  the game is over.  The only systems I can think of which may (may!) be  exceptions to this are certain esoteric systems designed to reach the  highest levels of Common Criteria evaluation, where classified and non- classified data operate on entirely different CPUs, entirely different  RAM, etc., etc., with an information diode to control how information  flows between them.

@_date: 2008-02-19 07:25:32
@_author: Robert J. Hansen 
@_subject: Corporate use of gnupg 
PGP Corporation has a patent on ADKs.  That's the number one reason why the other OpenPGP implementations do not support it.

@_date: 2008-02-19 11:54:45
@_author: Robert J. Hansen 
@_subject: Corporate use of gnupg 
US Patent 6314190, for those who want to check it out.
Mostly agreed.
The patent language on  is sufficiently broad that it would
arguably cover this, too, depending on how it's implemented.

@_date: 2008-02-19 15:14:55
@_author: Robert J. Hansen 
@_subject: Corporate use of gnupg 
Again, check the patent and then check with a patent lawyer.  The patent language is suitably broad that this sort of thing might be construed by a court to fall under the patent.
Technical fixes to provide ADK-like functionality are well and good, but if you aren't looking at the patent and creating this new technology with an eye towards avoiding the patent, you're playing the legal version of Russian roulette.
If you want ADK-like functionality, you have two real choices:
Of course, all this is null and void if you live in a jurisdiction where software cannot be patented.

@_date: 2008-02-19 19:34:24
@_author: Robert J. Hansen 
@_subject: ADKs 
Not happening.  GnuPG is already making inroads enough on the server market.  ADK is one of the few features which (a) PGP can claim over GnuPG and (b) businesses want.  If GnuPG implemented ADK-like features, that would likely present enough of a competitive threat to encourage PGP to wave the patent hammer.
The last time I talked to a patent lawyer about software (I had a nifty thing I wanted to implement and needed to make sure I wasn't walking into a patent lawsuit), I paid my $200/hr and got this bit of professional advice: "in today's software market, patents are used a lot more to keep other people out than to bring money in."
Assuming that my lawyer is accurate, the ADK patent would seem like an obvious one to use in such a way: it is more useful to PGP to have it around to keep competitors out of a certain part of the market than it would be to have it around to license to competitors to allow them into that certain part of the market.

@_date: 2008-02-26 11:22:07
@_author: Robert J. Hansen 
@_subject: Corporate use of gnupg 
Unless your day job involves being intimately involved in IP
transactions (not just writing code), you could have _speculated_ on
that.  There's a big difference between what you believe to be true,
what you think to be true, what you know to be true, and what you can
prove to be true.
When dealing with actual dollars and cents, it pays off in the long run
to pay the money required to get opinions from people who can prove the
correctness of their assertions.  This is true whether you're talking
about information security, law, medicine, or just about anything else.

@_date: 2008-02-27 20:36:44
@_author: Robert J. Hansen 
@_subject: Signing people with only one form of ID? 
It may be helpful for you to think about things in terms of not just how many identity documents are present, but the relative difficulty in forging identity documents, as well as your ability to spot forgeries.
E.g., a university ID card is pretty easy to forge.  You also probably don't know what Wayne State University's ID card looks like, so if someone presents it to you, you have no way of knowing whether it's on the up and up or not.
Compare that to a passport.  You might already have a passport.  Even if you don't, it's pretty easy to find out what a passport looks like, what sort of paper is used in it, what security features are present.  You can thus have a lot more confidence in someone's identity if they present you with a passport than if they present you with, say, a university ID card.

@_date: 2008-02-27 20:45:50
@_author: Robert J. Hansen 
@_subject: Signing people with only one form of ID? 
Another couple of thoughts--
If I recall correctly, OpenPGP explicitly has six different certification levels (in the range 0-5), but it does not specify any semantic meaning to each level.  They make recommendations, but those recommendations are not really binding.
To muddy the waters further, many OpenPGP implementations either fail to support certification-level distinctions, or make you jump through hoops in order to do it.  Those hoops are often error-prone.
E.g., GnuPG.  GnuPG's default certification level is a 3.  If I see a signature on someone's key, I know absolutely nothing.  Maybe it's a simple persona-level cert, in which case they should have certified it with a 0 but they just forgot to set the cert level.  Maybe it's a "I have his DNA and fingerprints on file with me and I asked the FBI to check him out", in which case they should have certified it as a 5 but they just forgot to set the cert level.  Etc., etc.
Because of these three factors--no semantic meaning associated with certification levels, some OpenPGP implementations not supporting the distinctions, and many implementations making it easy to forget that such distinctions exist--my default policy is to treat all signatures as unchecked persona-level IDs unless I know the signer personally and know they have a signature policy.

@_date: 2008-01-13 22:40:00
@_author: Robert J. Hansen 
@_subject: Question about history of hash and cipher collections 
The OpenPGP Working Group decided that it didn't bring anything new to the table, especially in light of SHA256 and SHA512.
Strong arguments (IMO, very strong!) can be made that OpenPGP supports way too many algorithms.  Even with as many algorithms as OpenPGP supports, though, the line still has to be drawn somewhere.
Yes.  It never made it into the OpenPGP RFC (RFC2440 and later RFC4880).   If the WG had decided to include Serpent, GnuPG would support Serpent.
There was no second place finisher.  AES won, and everyone else was an

@_date: 2008-01-13 22:46:18
@_author: Robert J. Hansen 
@_subject: Question about history of hash and cipher collections 
He should; he's one of the GnuPG authors.
Serpent was developed by some very smart people.  However, /all/ the AES
finalists were considered to be very competent designs.  What caused
NIST to select Rijndael over Serpent were factors other than
security--speed, ability to fit in a smart card, key agility, etc.
(Rijndael, pronounced "rain-doll", was ultimately selected to become
AES.  When talking about the history of AES, it's helpful to call it by
its old name.)
It wasn't in pgp 2.x, since Serpent came out almost a decade after pgp
2.x.  There has never been an official GnuPG build that has supported
Serpent, to the best of my knowledge.

@_date: 2008-01-14 16:40:49
@_author: Robert J. Hansen 
@_subject: Question about history of hash and cipher collections 
What's wrong with 3DES?  It's ridiculously slow, of course, but even after all these years it's still sturdy as a Soviet workers' housing bloc.
Anyway, to answer your question... not in a way which will interoperate well.  According to 2440, 3DES is the only MUST symmetric algorithm, which means it will be supported by all clients.
If you're willing to take the interoperability hit, I would suggest looking into g10/pkclist.c line 1263, "select_algo_from_prefs".  That appears to be the best place to hack in what you have in mind.

@_date: 2008-01-14 22:32:36
@_author: Robert J. Hansen 
@_subject: Question about history of hash and cipher collections 
Yeah, it's been underway for a while now.  It's been known for years
that the SHA-3 competition was going to happen; now it's actually started.
My take on the IETF OpenPGP working group is that a lot of people have
some serious concerns that RFC2440 and RFC4880 include /way/ too many
algorithms.  While I imagine there is a broad desire among WG
participants to see SHA-3 added, I think some hash algorithms may have
to be dropped.  The way I read the tea leaves, we should expect to see
some tumult in the list of algorithms.
Pretty much everyone agrees that we have too many algorithms.  Hardly anyone can agree on which algorithms should be dropped.  Even TIGER192 (a remarkably useless addition which was mercifully axed from the RFC shortly after introduction) has partisans who think its exclusion is unfair and that it should be reinstated.
If you have strong feelings on this issue, the right place to bring them
up is on the IETF OpenPGP working group mailing list.

@_date: 2008-01-15 14:01:53
@_author: Robert J. Hansen 
@_subject: Question about history of hash and cipher collections 
Ack!  No.  No.  No.
My advice has been the same for years: unless you know precisely what you're doing and why, stick with the defaults.  GnuPG's defaults are excellent.  They make good sense.  They interoperate well.  Don't mess with them unless you know precisely what you're doing and why.
I get asked this question a lot.  The full answer can be found at:

@_date: 2008-01-15 22:23:58
@_author: Robert J. Hansen 
@_subject: Question about history of hash and cipher collections 
And I also say "unless you know exactly what you're doing and why, use the defaults."
It's true that I am not fond of kilobit keys, for reasons I won't go into right now.  I am far, far less fond of people who do not know what they are doing, or why they are doing it, tinkering around with deep magics beyond their kenning.
A Formula-1 race mechanic may be able to tweak a car engine to get a few more percent out of it than the factory settings allow.  Your average driver should not attempt this, because they have better odds of cutting their own brake lines by accident than by realizing any marginal Prudence demands that drivers be strongly encouraged to just drive the car.
Unless you know exactly what you're doing and why, use the defaults. That is all the advice you will get from me.
The OpenPGP standard specifies what algorithms must be present, and to an extent what the defaults must be.  The GnuPG crew is free to exceed those standards.

@_date: 2008-01-16 01:22:27
@_author: Robert J. Hansen 
@_subject: Question about history of hash and cipher collections 
Incidentally, with 1.4.8 it defaults to a 2048-bit DSA/Elg keypair and SHA256.  There is no contradiction between what you read and my "use the defaults!" creed.
That page was written before DSA2 was widespread, and right after some major cracks were showing in SHA-1.  I should update the page to reflect the changes since then.

@_date: 2008-01-19 20:12:09
@_author: Robert J. Hansen 
@_subject: Fwd: is there any remote possibility to recover passphrase? 
Please note how you qualified that: /theoretically./  In practice, given a good passphrase, this is highly nontrivial.

@_date: 2008-01-19 20:14:36
@_author: Robert J. Hansen 
@_subject: is there any remote possibility to recover passphrase? 
Depends.  English text has about 1.5 bits of entropy per glyph, so this is about 37 bits of entropy, assuming English text.  That can be exhausted via brute force.
If the passphrase is totally random, then you're looking at about 150 bits of entropy, which is impractical to exhaust via brute force, ever.
As with so many things in crypto, the answer here is "it depends."

@_date: 2008-01-21 17:23:21
@_author: Robert J. Hansen 
@_subject: IDEA licensing issues 
The first question is why you need IDEA in the first place.  It's a usable cipher, but it's hardly a paragon of modern design.  Better than brute force attacks exist against at least 4.5 of its eight rounds, and more may have been discovered since I last read the literature.
Assuming you need IDEA, the last I heard the terms of the patent license involved it being free for noncommercial use.
The easiest way to get a license for IDEA for commercial use--and probably the cheapest--is to buy a copy of the lowest-end PGP product. Presto, you have a license to use IDEA for commercial purposes.  Compile the idea.c code, drop it in GnuPG, and you're off to the races.
Warning: I am not an IP lawyer, I am not even the equivalent of a drunk IP lawyer.  Consult your own legal counsel.

@_date: 2008-01-24 09:05:47
@_author: Robert J. Hansen 
@_subject: Need tips on how to backup my keys 
> But where should I keep the copy?
I keep mine in a safe deposit box in a manila envelope addressed to my best friend.  Also in the envelope are hardcopies of my private keys, my passphrase, and some instructions.
In the event of my untimely death, my lawyer hands off the envelope to my best friend, who gets access to my keys and passphrase and follows the instructions I've left him.
I think you are badly misunderstanding the problem.  Public exposure is not a big deal as long as you have a strong passphrase on your key. With a strong passphrase you can publish it in an OCR-friendly font in a full-page ad in the _New York Times_ and feel safe in the confidentiality of your messages.
People advocate keeping your private key private and also using a strong passphrase for a simple reason.  If we advocate only one, then people will screw it up and not do it at all.  If we advocate both, then people can screw one up.  No passphrase?  No problem, as long as you keep your key secret.  Share your key?  No problem, as long as you have a strong In any case, a CD-ROM can be stolen, lost and/or misplaced just as easily as a USB drive.  No matter what mechanism you use for those backups, those backups can be mislaid or taken away from you.  Best to make backups and keep them somewhere it is very unlikely anyone will be able to get them.  Like I said above, I use a safe deposit box at my bank.  Other people I know keep copies with their attorneys.

@_date: 2008-01-24 21:47:33
@_author: Robert J. Hansen 
@_subject: Problem with keys imported via DNS CERT 
There's your problem.  Set the key to implicit trust and see if the problem goes away.

@_date: 2008-01-26 17:19:31
@_author: Robert J. Hansen 
@_subject: How true can this be? 
Hash: SHA256
~  1. Completely true.
~  2. Completely false.
~  3. Somewhere in between.
~  4. A quixotically jocular zephyr named "oblong threnody".
~  5. Colorless green ideas sleep furiously.
~  6. The business of the book sleeps eternally.
There is signal and there is noise.  At present, you do not have any way
of distinguishing the two.  That means it's all noise, and the last
three answers are just as meaningful as the first three.
You are looking for simple and pat answers.  They do not exist.  You
need to do a good bit of reading if you want to have a good handle on
this question.
I sent you (off-list) a link to a web page that talks about this in some
detail: the Landauer Bound, the Margolus-Levitin Limit, the
thermodynamic and quantum information theoretical limits of crypto. You
may find some useful information in there. I would suggest two things:
~  1. Read it skeptically.
~  2. Whatever else, don't believe it just because I wrote it.

@_date: 2008-01-27 01:18:07
@_author: Robert J. Hansen 
@_subject: Changing hash on Windows Vista with gpg4win v1.1.3 
Add to your gpg.conf file the line:
personal-digest-preferences SHA256 SHA1
... or whatever your preferences are.  :)

@_date: 2008-01-27 15:39:20
@_author: Robert J. Hansen 
@_subject: How true can this be? 
I hate to rain on people's parades, but that sort of James Bond stuff tends to draw a lot more attention.  Assassination is an extremely ineffective form of censorship.  Historically speaking, effective governments have relied on discredit more than death for controlling their secrets--if someone gets a reputation in the field for being crazy, for being unstable, for being whatever, then nobody will listen to them anyway, so who cares if they're blabbing secrets?
That said, I agree with the claim that it's very unlikely that someone with the clearance to know about the NSA's latest crypto research would talk about it with others who weren't cleared.  Far, far more likely that someone was trying to impress others with a "if only you knew what I knew" fish story.

@_date: 2008-01-29 15:22:26
@_author: Robert J. Hansen 
@_subject: IDEA 
If your customers are businesses, the upgrade pill can be made easier to
swallow by pointing out that AES is a NIST standard and may be required
by future government regulations for some kinds of transactions.  Pitch
it as "we should look into migrating to AES now, rather than do a rushed
job of it at the last minute" and you may find things easier.
While IDEA is for time being a safe choice, it is not a government
standard and is unlikely to ever play a major role in NIST, SEC, NBS,
etc. standards for data protection.

@_date: 2008-01-29 16:36:46
@_author: Robert J. Hansen 
@_subject: adding a new email to a key 
I understand what you're saying, but I don't see the problem.  If you
want to add another user ID (what people usually mean when they say "add
another email address"), then you add another user ID.  Apparently from
your message, you can add user IDs just fine--so where's the problem?
By default, GnuPG will always make a newly-created user ID the primary
user ID.  However, this really shouldn't matter to you--what matters
most is that the user IDs you want listed on your key are on your key.

@_date: 2008-07-05 13:12:56
@_author: Robert J. Hansen 
@_subject: I need a portable GUI for GnuPG 
I would actually recommend against "anti-keylogger" tools like that.
Psychologists tell us that human beings tend not to be risk-averse so
much as risk-adjusting.  For instance, one result of air bags becoming
common automotive equipment is people began to drive faster.
If you decide "well, if I _have_ to use an untrusted machine, then at
least I'll be using an on-screen keyboard", that's all well and good.
But it's a very, very small cognitive leap from that to "I can use this
untrusted machine, after all, I'll be using an on-screen keyboard,"
which is really stupid.
Better to not use the tool at all, and retain your sense of healthy

@_date: 2008-07-06 11:05:45
@_author: Robert J. Hansen 
@_subject: I need a portable GUI for GnuPG 
As a general rule, you can get away with murder as long as you show
people that you've done your homework.  If you write a courteous note
and explain "yes, I understand your general policy is [insert policy
here] because [insert reasons here], but I was hoping that since my use
is a little different, you might be willing to consider granting me
Seriously.  Be polite, understand that you're asking him for a favor,
don't second-guess someone's decisions, and you can get away with
_anything_.  :)
Or say "to hell with it, I'm going to use S/MIME".
S/MIME has the major advantage of pretty much every mail client
supporting it out-of-the-box.  The end users would need to download nothing.

@_date: 2008-07-07 15:38:17
@_author: Robert J. Hansen 
@_subject: I need a portable GUI for GnuPG 
Don't know, don't care.
This entire discussion is analogous to talking about the pros and cons of bringing a condom with you on a trip to Zimbabwe.
Your best defense against disease is to not expose yourself to disease vectors.  The instant a person says "well, it's okay to have a one-night stand with a random person in Zimbabwe, because after all, I've got a condom" is the instant I stand up and walk away.  You see, I'm allergic to folly and I need to find an epipen before anaphylaxis sets in.
Your best defense against malware is to not expose yourself to it.  This much is plainly obvious.  The instant a person says "well, it's okay to use a portable GnuPG on a USB token and plug it into random public kiosks which are probably malware-infested, because after all, I'm using anti-keylogger software" is the instant I dial 911, because I don't think the epipen is gonna save me.
I am not opposed to portable applications.  If you regularly walk around from one trusted machine to another to another, like I do in my daily work, then it can be handy and safe to have apps preinstalled on a portable drive.
But the way some people are talking about using it ... it just unnerves me.  Badly.

@_date: 2008-07-09 11:32:50
@_author: Robert J. Hansen 
@_subject: GPG2 compile problems on cygwin 
Hash: SHA256
At present, the only supported way to build GnuPG on Windows is to do a
cross-compile from a UNIX running the GNU toolchain.
If you're dead-set on doing this from Cygwin (not recommended), I would
suggest beginning on an official GnuPG 2.x release.
If SVN builds fail to compile, this could be because of something you're
doing wrong, or it could be because the SVN code doesn't build.  Most
development crews try to keep SVN code in a buildable state, but
problems have been known to arise.
Learn the process for building a released version of GnuPG 2.x via
Cygwin and/or MinGW.  Once you can do that reliably, then you can apply
those same skills to the SVN branch if you want.

@_date: 2008-07-19 00:52:45
@_author: Robert J. Hansen 
@_subject: [admin] What is top posting, and why should you avoid it? 
I don't know about you, but when I forward an academic paper on to a
colleague, I write a Post-It note and slap it on the front, telling my
colleague various important details about it.
The normal reading order is thus "read the introductory Post-It note,
then read the paper."
As opposed to the subject line,
... which is already too long for a subject line.
I shall continue to top post introductory material when forwarding
relevant information, and eschew top posting all other times.

@_date: 2008-07-21 18:22:23
@_author: Robert J. Hansen 
@_subject: General Posting Questions 
Please do _not_ quote the entire digest.  Quote the part of the digest
that's directly relevant to what you have to say; clearly identify whom
it is you're quoting; and bottom-post as opposed to top-posting.
A good rule of thumb is "if someone were to come to me with this
question, what information would I ask for?"
What information we will need depends on your particular query.  For
most questions, information about your GnuPG version and what OS you're
running it on will suffice.
This is perfectly acceptable, yes.  :)

@_date: 2008-07-21 18:25:30
@_author: Robert J. Hansen 
@_subject: identical files -> non-identical encrypted files 
I fail to see the problem.
GnuPG uses a random session key to encrypt each message.  That means the
payload of each message will be totally different.  This is good, solid
crypto practice, and changing this behavior simply isn't going to happen.

@_date: 2008-07-25 02:45:37
@_author: Robert J. Hansen 
@_subject: removing -----BEGIN PGP SIGNED MESSAGE---- 
Sort of.  PGP/MIME.
If PGP/MIME is not an option for you, then no, there is no way to avoid
it.  Inline OpenPGP signatures require that text to be present.

@_date: 2008-07-28 09:56:47
@_author: Robert J. Hansen 
@_subject: Trying to Understand Keys 
If you want to understand the tradeoffs, you're going to need an
undergraduate math degree at the absolute minimum.
As far as the layman is concerned, the only option you should care about
is (1).
The general rule is "unless you know what you're doing and why, stick
with the defaults."

@_date: 2008-07-31 08:26:07
@_author: Robert J. Hansen 
@_subject: compatible between GnuPG 1.4.7 and PGP 6.5.2 // sorry,	'bad' 
As I understand it, PGP 8's license agreement does not allow for it to
be hosted anywhere other than pgp.com.  This means that obtaining it
from zedz is a copyright violation, and probably should not be advocated.

@_date: 2008-06-07 17:35:44
@_author: Robert J. Hansen 
@_subject: One Time Password and GnuPG 
Search the archives.  These ideas keep on popping up time and time
again, and the same answers always apply.
If you don't have physical security over your hardware, you don't have
anything.  You cannot use GnuPG safely on a malicious machine.  People
keep on trying to invent complex methods that allow them to do this, but
it's like trying to make water not wet or bricks not heavy.

@_date: 2008-06-10 14:23:50
@_author: Robert J. Hansen 
@_subject: Confused about Sub keys. 
Typing something into GnuPG and learning what it does is great: it
teaches you that GnuPG tends to create different keypairs for encryption
and signing.  However, it doesn't teach you _why_, and it's dangerous to
generalize from just that small of an example.
Originally, PGP 2.6 used one keypair to do everything.  OpenPGP changed
it to two keypairs, one for signing and one for encrypting, for one and
only one reason:
Most technical standards committees have a lot of flerbage -- ideas that
have a lot of people backing them, although there's a great diversity of
opinion about why these ideas should be backed.
Some people thought separate keys gave increased resistance to
cryptanalysis.  Some people thought separate keys were cool.  Some
people thought it would be good for the future extensibility of OpenPGP.
 Some people thought it would be good to allow people to let a signing
subkey expire, while leaving the encryption subkey good for the
indefinite future.  Some people needed DSA, and since DSA is a sign-only
algorithm they needed a separate keypair for encryption.  Some people
said "well, PGP 5 does it this way and we need to be compatible."
Etc., etc.
The upshot is "a lot of people thought it was a good idea, even though
there was no clear consensus on why."
Warning: it's been years and years since this discussion took place
within the OpenPGP WG.  While my recollection is there was no clear
consensus on why it was a good idea, it would not be impossible for my
memory to be in error.

@_date: 2008-06-10 20:24:25
@_author: Robert J. Hansen 
@_subject: One Time Password and GnuPG 
Having not seen John's original message come through on GnuPG-Users, I
can only assume that you are taking public something that he sent
off-list, presumably for good reason.
Please do not do this.  It's rude.

@_date: 2008-06-11 12:00:09
@_author: Robert J. Hansen 
@_subject: LD_PRELOAD attack 
My reaction to it has been to yawn.
If you don't have physical security on your machine, you don't have any
electronic security worth talking about.  We've known this for decades
now.  This is just another example of what happens when people think
they can have electronic security without physical control over the

@_date: 2008-06-13 11:37:28
@_author: Robert J. Hansen 
@_subject: Signatures stored as information inside a "public 
Yes.  No.  Neither.
OpenPGP implementations are free to store data however they want.  The
GnuPG keyring file is just a sequence of OpenPGP octets and packets, but
there's no reason why it needs to be this way.  Honestly, I'd much
rather the data was stored in some kind of easily parseable format,
whether it be XML or a simple context-free grammar or what-have-you, but
that's neither here nor there.
It doesn't make any sense to talk about what's "stored on the keyring"
versus what's "stored on the certificate".  Neither is well-defined.
The only thing that's well-defined is the interoperability format.
If your question is really "how does GnuPG do this", well, that gets a
bit different.  GnuPG's keyring file is essentially a long chain of
certificates stored in the interoperability format.  If you want to
export a key, it just grabs the relevant part of the keyring, strips out
local signatures and other installation-specific data, and dumps that.
The preceding is a simplification, but as far as I understand it is
essentially accurate.  dshaw or wk will certainly correct me if I'm
wildly wrong, which has been known to happen from time to time.  :)

@_date: 2008-06-13 13:42:51
@_author: Robert J. Hansen 
@_subject: PGP doesn't import trust signatures w/ depth > 8 on keys exported 
This is the GnuPG-Users list, not PGP-Users.  Generally speaking, we are
not experts on the internal workings of PGP.  You're better off asking
PGP Corporation.

@_date: 2008-06-15 16:22:49
@_author: Robert J. Hansen 
@_subject: PGP bug? Does not recognize primary uid 
There are five answers here:
(a) This is a PGP question, not a GnuPG question.
(b) GnuPG is performing correctly.
(c) PGP is performing correctly.
(d) Implementations are given leeway in deciding how to interpret a
    primary userID.
(e) This behavior is not a bug, much less a ridiculous one.

@_date: 2008-06-16 10:23:17
@_author: Robert J. Hansen 
@_subject: PGP bug? Does not recognize primary uid 
No.  If you have a key created in PGP that's not working in GnuPG, by all means, ask here "hey, what's going on?"
If you have a key created in GnuPG that's not working in PGP, you should probably be asking there.
Or, generally speaking, ask the people who have detailed interior knowledge of the system which appears to not be working right.
No, it doesn't defeat the purpose of a primary UID.  Which UID is "primary" is strictly a matter for the convenience of human beings. OpenPGP doesn't draw that distinction.  It's totally irrelevant to the The totality of the OpenPGP language on user IDs is such:
5.2.3.19.  Primary User ID
    (1 octet, Boolean)
    This is a flag in a User ID's self-signature that states whether this
    User ID is the main User ID for this key.  It is reasonable for an
    implementation to resolve ambiguities in preferences, etc. by
    referring to the primary User ID.  If this flag is absent, its value
    is zero.  If more than one User ID in a key is marked as primary, the
    implementation may resolve the ambiguity in any way it sees fit, but
    it is RECOMMENDED that priority be given to the User ID with the most
    recent self-signature.
    When appearing on a self-signature on a User ID packet, this
    subpacket applies only to User ID packets.  When appearing on a
    self-signature on a User Attribute packet, this subpacket applies
    only to User Attribute packets.  That is to say, there are two
    different and independent "primaries" -- one for User IDs, and one
    for User Attributes.
... There are a couple of other quick offhanded references (packet specifiers, one reference to how a symmetric algorithm may be chosen, etc.), but that's the meat of it.
There is no MUST anywhere in that paragraph.  Implementations are therefore free to do whatever they like with it, including ignore your preference and arbitrarily say "okay, we're going to treat this other one as your primary".

@_date: 2008-06-16 12:57:47
@_author: Robert J. Hansen 
@_subject: passphrases: the police and subkeys scenario 
This is not true.
There is no "middle ground" at borders.  It is still the land of
whatever sovereign nation it stands upon.  That sovereign nation may,
for purposes of its own domestic law, treat the airport differently than
surrounding areas -- but it's grossly inaccurate to say that an airport
is beyond the laws of the host country.

@_date: 2008-06-16 14:37:20
@_author: Robert J. Hansen 
@_subject: passphrases: the police and subkeys scenario 
Keeping this jurisdiction-free, the legal protections people think they
should have and the legal protections they think they have and the legal
protections they actually have are three quite disjoint subject areas.
It pays to keep this in mind when making statements.
Clarity is important when discussing things.  Without clarity, the
process of reasoning is stymied.
My objection is not to your political beliefs or your ideas about what
rights are possessed by Americans.  My objection is strictly one of clarity.

@_date: 2008-06-16 14:44:06
@_author: Robert J. Hansen 
@_subject: info in sigs, comments and header 
If you use Enigmail, you can tell Enigmail to add an email header
indicating your OpenPGP key id.  This seems to be about as low-intrusive
a method as any.
Technically savvy people -- which happens to be the same demographic
which tends to use OpenPGP, unfortunately enough.  OpenPGP's penetration
into the layman's world of computing is practically nil.
A brief "OpenPGP: 0xDEADBEEF" is probably not going to get you any hate
I run my key fingerprint across the bottom of my business cards.  That
way when I meet someone, we trade information and they now have a
trusted copy of my fingerprint, delivered directly from my hand.  Since
I work in a very technical field, most people who get my card understand
what it is -- it's been a conversational icebreaker at several conventions.
It's also very handy for impromptu keysigning parties.  A couple of
weeks ago I was sitting in a coffeeshop with a Canadian doctoral student
in CS, a sysadmin for kernel.org, and a couple of fellow voting
researchers.  I put my passport and a stack of business cards on the
table, and presto, everyone had the opportunity to confirm my identity
and get a copy of my fingerprint.  It was a lot more convenient than if
I'd had to say "hold on a second...", boot up my laptop, grab a stack of
napkins, and laboriously hand-copy my fingerprint from a terminal window
onto napkins again and again for each person who was sitting at the table.

@_date: 2008-06-23 06:44:50
@_author: Robert J. Hansen 
@_subject: About my prefered settings... 
The best way is to take a look at a message you've already sent someone,
but this time use the "-v" ("verbose") flag.  Using it twice will give
more detail.  E.g.:
gpg --verbose --verbose my_encrypted_file.asc
It'll give you more data than you can shake a stick at.

@_date: 2008-06-23 20:43:38
@_author: Robert J. Hansen 
@_subject: About my prefered settings... 
I'd characterize it this way, actually:
The source is free.  You're free to do with it as you like, and most people here will steadfastly defend your right to do these sorts of things so long as you uphold the license agreement for GnuPG.
That said, please, please, please, don't send exotic traffic to people who aren't expecting it.  It annoys them, it increases their frustration with the entire system, and the more frustrated people get the less likely they are to use GnuPG.
And finally, if it breaks you get to keep both pieces.  :)

@_date: 2008-06-24 00:20:18
@_author: Robert J. Hansen 
@_subject: About my prefered settings... 
Six of one, half dozen of another.  I think it's generally for the best
if people use names, since they're easier to read and harder to screw up.
This is not really possible with GnuPG.  setpref is used to advertise
_capabilities_ to people far more than it is to advertise preferences.
It appears to me to be badly misnamed.
personal-thingy-preferences are the actual preference list, but is only
applied to traffic you generate.

@_date: 2008-06-24 17:22:18
@_author: Robert J. Hansen 
@_subject: cipher ID's 
Future use.  Hate to give an answer that's so glib, but that's what it
is.  As of right now, I don't believe there's any consensus on what will
ultimately go there, or if they will ever be used -- but the spec is
including "room to grow", as it were, by telling every implementation
author "don't use those codes for your own OpenPGP extensions, we may
use them someday".
People add ciphers to the OpenPGP suite which are not explicitly
included in the spec.  E.g., Camellia right now, or the people who are
experimenting around with ECDSA, or... etc.
If it was just "add it to the end", then every experimental OpenPGP
platform out there would have problems.  If S14 (to pick a random unused
cipher number) is an experimental implementation of RC6, then what
happens when AES-256.5 (a full 1.414 times stronger than AES256!) gets
assigned to S14?
Fine, the experimental group moves up to S15.  But all of the traffic
they've already generated is still marked as S14.  That means when they
try to decrypt their traffic, they'll be decrypting it with AES-256.5
instead of RC6.  Which means decryptions will fail.  Which means ugly
kluges will have to be written to handle this.  And... etc., etc.
It's easier on everyone if it's done OpenPGP's way.
(Note -- while RC6 is a real algorithm, AES256.5 is not; it's firmly
tongue in cheek.)

@_date: 2008-03-02 20:15:20
@_author: Robert J. Hansen 
@_subject: GnuPG (win32) on a USB stick 
As a rule of thumb, never do any sensitive computer operations on a computer you don't completely trust.
If you think the computers in your campus's IT kiosks are safe and pristine, then this idea is probably reasonably good.  If you think the computers in the kiosks are exposed to a host of unsafe web browsing habits, malware and stupid users 24/7, you may want to rethink this plan.

@_date: 2008-03-04 11:18:10
@_author: Robert J. Hansen 
@_subject: Strength of ciphers in PGP? 
Yes.  IDEA is Godzilla, CAST5 is Moth-Ra and 3DES is MechaGodzilla.
They all excel at stomping cities flat and terrorizing inhabitants.  All
that people in Tokyo need to know about them is "when you see them
coming, run for the hills."
The above answer is tongue in cheek, but there's a lot of accuracy in
it.  Unless you're a professional cryptographer, the various
cryptanalytic analyses of the OpenPGP cipher suite are going to be
pretty much meaningless and unhelpful.  For 99% of other people--myself
included--it really reduces down to "they are all believed resistant
against all known forms of cryptanalysis, and are impractical to brute
If you really want to go down this road, it would help if you clarified
your question a lot.  What sort of comparisons?  How many operations are
involved in an encryption cycle?  Decryption cycle?  How much processing
is involved in key setup?  Relative size of code?  Hardware
requirements?  Efficiency?  Best known cryptanalytic attacks?  Etc., etc.
Your question, as phrased, is far too general to give any sort of
meaningful answer except "as far as the layman is concerned, they're
pretty much identical".

@_date: 2008-03-04 11:20:37
@_author: Robert J. Hansen 
@_subject: IDEA? 
2010, I think.  Even once 2010 comes around, there's no point in using
it.  AES rules the roost for symmetric ciphers nowadays, and for fairly
good reasons.

@_date: 2008-03-10 12:56:19
@_author: Robert J. Hansen 
@_subject: one more question: is there a way to use additional keyring	when 
In Enigmail, I think you mean; Thunderbird itself has no OpenPGP support.  This may seem pedantic, but I don't think the Thunderbird crew would like to be blamed for things that are totally outside of their purview.  :)
The real question is not whether Enigmail can use your USB stick, but whether you can.  Plug in your USB stick and open up a command-line window.  Try to use your secret key that's on the USB stick.  If you can do this, then the bug is in Enigmail and it should be taken to the Enigmail list.  If you can't, then the bug is in your setup or your usage of GnuPG.
Let us know what happens.

@_date: 2008-03-28 10:33:42
@_author: Robert J. Hansen 
@_subject: GnuPG v2.x? 
Well, you sure did pick an excellent one to start off on.  :)
You may not get as complete answers as you want here.  The GnuPG 2.x
authors are on the list, after all, and they are some scarily competent
people.  Some people who haven't migrated might be afraid to voice their
opinions, for fear that people who know more than them will clobber
their opinion mercilessly.
The GnuPG authors are reasonable human beings.  They tend not to do
that.  In fact, I'm so confident of their willingness to tolerate
sincere and reasoned disagreements that I'll give a very complete answer
to your question, and one I suspect they will emphatically disagree
with.  :)
Computer science, like pretty much any highly technical field, has parts
to it that are formally describable in mathematical terms and parts that
exist mostly as rules of thumb and handed-down wisdom.  I use 1.4.x only
because of the latter kind of reasons: particularly, the Small Tools
Principle and the Second System Effect.
The Small Tools Principle: "The more things a program does, the greater
the chance it will fail.  Tools should be small and do one thing
extremely well."
GnuPG 1.4.x is purely an OpenPGP application.  I didn't like it when it
started integrating smartcard functionality, since it seems likely the
vast majority of users will not need it, and it seemed like a violation
of the Small Tools Principle.  When I build my own 1.4.x GnuPG, I
typically turn off all the options I don't need.  The smaller my trusted
codebase, the more reliable the final product will be.
GnuPG 2.x is... well, I guess the better question is what is there GnuPG
2.x doesn't do?  Its capabilities have expanded significantly.  This
doesn't sit well with me.  I don't need the new capabilities of 2.x;
why, then, should I migrate to it?
The Second System Effect: "When designing the successor to a relatively
small, elegant and successful system, there is a tendency to become
grandiose in one's success and design an elephantine feature-laden
monstrosity."  This is a general rule and may not apply to GnuPG 2.x.  I
don't know if it does.  I also don't know if it doesn't.  This is not a
state of affairs you want in security software.
I know wk has said that he was aware of this general rule during 2.x's
development, but I don't trust Werner to evaluate the quality of his own
code.  This is no slight against him.  I don't trust _anyone_ to
evaluate the quality of his or her own code.
When GnuPG 1.0 came out, the very first thing I did was sit down and
spend a week going over the code.  I wasn't bughunting; I was trying to
understand the architecture and design of the system.  As GnuPG 1.0
turned into 1.2 and 1.4, I kept track of the changes.  I've not yet had
the time to study GnuPG 2.x.  I don't know the architecture and design.
Since I've seen no independent evaluations of 2.x and had no time to
personally inspect the code for myself, I feel that I need to consider
the possibility that 2.x is an example of the second-system effect.
... So what you get to, then, is this.  I know GnuPG 1.4.x.  It is
trusted code and I have given it the looking-at I feel it deserves.  I
have come to the belief that it (a) obeys the Small Tools Principle and
(b) does not suffer from the Second System Effect.
I don't know GnuPG 2.x.  It's trusted code but I haven't yet been able
to give it the looking-at I feel it deserves.  I have a nagging doubt
about whether it obeys the Small Tools Principle.  I do not know whether
it's developing the Second System Effect.  If I had a couple of weeks to
study the 2.x code, these concerns might very well get assuaged, but
given I have comps coming up... well, first I have comps, after that I
have a nervous breakdown penciled in, and after that...
Finally, GnuPG 1.4.x does everything I need it to do and does it quite
well.  Why should I change?
... As two last (and hopefully unnecessary!) words of warning: first, do
not interpret any of this as an attack on 2.x.  It's not.  I have
exactly _zero_ evidence of any problems with 2.x.  I have questions,
sure, but a question is not the same as a problem, and people should not
interpret my questions as anything other than what they are.
Second, just because I'm this paranoid doesn't mean you should be.  Only
you get to decide your own security policy.  I don't get a vote in what
your policy should be, and if you were to give me one, the first thing
I'd do after cackling maniacally would be to abstain.
_Do not_ fall into the mistake of thinking "well, Rob has some
articulated some concerns here, so I'd better stay away."  I've
articulated some concerns and reasons why I'm staying away.  Use your
own judgment--don't substitute mine for yours!
Thank you, Werner, David, and others, for GnuPG 2.x.  In time I'll have
the time to look at the code and get my questions answered.  Until then,
thank you for all your hard work, even if I'm not leaping on the
bandwagon just yet.  :)

@_date: 2008-03-28 10:51:39
@_author: Robert J. Hansen 
@_subject: GnuPG v2.x? 
2.x can be used on the Mac, and can be integrated with Thunderbird.  If
you want to use 1.4.x, by all means go right ahead, let me be the last
to complain--but use it because it's what you want to use, not because
you think you have to use it.  :)

@_date: 2008-03-28 11:17:43
@_author: Robert J. Hansen 
@_subject: GnuPG v2.x? 
Beyond "sudo apt-get install gnupg2"?
(The above works on Ubuntu 7.10, which is generally very comparable to Debian.  I have no Debian Etch systems available for testing.)

@_date: 2008-03-28 11:22:30
@_author: Robert J. Hansen 
@_subject: GnuPG v2.x? 
Well, given that I'm part of the Enigmail team... :)
"In order to provide the crypto-features, Enigmail requires GnuPG to be installed. We currently recommend GnuPG version 1.4.8 and/or 2.0.8."
The Quick Start Guide leads people through the process of installing GnuPG 1.4.x, mostly because we've discovered that to be an easier process than GnuPG 2.  However, Enigmail works fine with GnuPG 2, and we have several people who can assist you in getting set up with it.
Why not join the Enigmail list?  We're a pretty friendly bunch over there.

@_date: 2008-05-05 03:36:16
@_author: Robert J. Hansen 
@_subject: how long should a password be? 
Not at all.  At some point the passphrase becomes stronger than the
symmetric encryption algorithm.  Then it's time to stop.
I think if you can't remember a phrase longer than 20 characters, you
should seek immediate psychiatric help.  :)
Throwing out just a few memorable phrases, all substantially long than
20 characters:
* They gave me a medal for dreaming of you.
  (Leonard Cohen, _Book of Longing_)
* Beware the fury of a patient man.
  (John Dryden, _Absalom and Achitophel_)
* The worst are filled with passionate intensity.
  (William Butler Yeats, _The Second Coming_)
* listen: there's a hell of a good universe next door; let's go
  (e.e. cummings, _pity this busy monster, manunkind_)
* Come with me, ladies and gentlemen who are in any wise weary of
  London: come with me: and those that tire at all of the world we
  know: for we have new worlds here.
  (Lord Dunsany, _Prelude to the Book of Wonder_)
* Vor allem: pflanze mich nicht in dein Herz.  Ich w?chse zu schnell.
  (Rainer Maria Rilke, _Sonnets to Orpheus_ 16.)
As these examples will hopefully show you, there's no shortage of
magnificent, easy-to-remember passphrases.
... and why, yes, I _do_ have a liberal-arts degree.  Would you like
fries with that?  :)

@_date: 2008-05-05 03:42:19
@_author: Robert J. Hansen 
@_subject: how long should a password be? 
This is a good question, but unfortunately there's a lot more to it than
As far as GnuPG goes, you aren't entering characters at all.  You're
just entering bytes of data which it processes to create a symmetric
key.  GnuPG can probably accommodate pretty much any character set, as
long as it's not _totally_ ridiculous.
However, if you're using a front-end (GPGshell, WinPT, Enigmail, etc.),
then you might want to ask about what character set the front-end is
using.  If the front-end is using a Cyrillic character set but your
console is using Latin-1, it is possible that things could get a bit
messed up as the two applications talk to each other.  You might think
you're entering the letter R, but is that a Cyrillic or a Latin R?  The
two don't encode the same way.
Moral of the story: character sets aren't a problem, but making sure
everything is speaking the charset can be a problem.

@_date: 2008-05-05 04:44:32
@_author: Robert J. Hansen 
@_subject: GPG 1.4.9 false verification 
The behavior is specified by RFC4880 and is not a security risk.
As an example, I have a small CSS file here that I have clearsigned.
The opening looks like:
*-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Hello, World!
  Enigmail New Site - Main CSS (for SCREEN display on recent browsers)
(I've added an asterisk to the beginning of the -----BEGIN block, to
prevent mail clients from misreading it as a real OpenPGP stanza.)
Now I try to verify it with:
job:~ rjh$ gpg main.css.asc
gpg: invalid armor header: Hello, World!\n
File `main.css' exists. Overwrite? (y/N) y
gpg: Signature made Mon May  5 04:38:51 2008 CDT using RSA key ID FEAF8109
gpg: Good signature from "Robert J. Hansen "
gpg:                 aka "Robert J. Hansen"
Looking at the top of main.css, what I see is:
  Enigmail New Site - Main CSS (for SCREEN display on recent browsers)
... The injected text is stripped.  It is never presented to the user as
verified text.
If a mail client presents the original message, rather than the message
as GnuPG has verified it, then that is a major HCI issue.  I would
suggest filing a bug with the maintainer of your mail client.

@_date: 2008-05-06 14:55:19
@_author: Robert J. Hansen 
@_subject: confused about public key strength 
No.  Asymmetric cryptography has keys that come in public and private
parts, but that doesn't mean the parts can be evaluated in isolation.
It's a system.
No.  The file is encrypted with a symmetric cipher depending on the
preferences of you and your respondent.  This is anywhere between an
effective keystrength of 112 bits (3DES, under a ridiculously
pessimistic set of assumptions) all the way up to 256 bits.
This is, by the way, a _lot_ of protection against cryptanalysis.  Any
talk about breaking this by brute force is deluded fantasy.  It's not
happening, not even with quantum computers and every other staple of the
science fiction literature that people assume the NSA has access to.
The key used to encrypt the file is chosen at random.  You could sit
there with a quarter, toss it 256 times, and have a perfectly good AES
key.  The computer does basically this process.  This random,
one-time-use key is then encrypted with your recipient's public key.
The recipient's public key may be anywhere from 1024 bits up to 4096
bits.  Don't be confused by comparing this to the 112- to 256-bit
symmetric encryption of the file.  It's an apples to oranges comparison:
you cannot say "well, one has 1024-bit encryption and one uses 256-bit,
so clearly one is four times better than the other."
For 99% of users, it doesn't.  Use the defaults GnuPG gives you --
they're good defaults.

@_date: 2008-05-09 12:56:51
@_author: Robert J. Hansen 
@_subject: Protecting private key on USB flash drive: how to? 
Depends on where you are and what you're doing.
I am not a fan of TrueCrypt's hidden volume feature, and I think most
people who are fans haven't thought things through.  Let's say that
you're visiting a repressive country.  For obvious reasons, you want to
put your personal data on a TrueCrypt drive.  You get arrested at the
airport because they think you're smuggling drugs in/working with the
rebels/an American spy/whatever.  You proceed to get the stuffing beat
out of you.
You're willing to divulge your secrets at this point, so you offer your
TrueCrypt password.  However, since you're not really an American spy/an
arms dealer/whatever, the data the interrogator is expecting to find
isn't there.
The interrogator demands you turn over the hidden volume.  You explain
there isn't one.  The interrogator demands you prove it.  You explain
that, by TrueCrypt's design, you can't.
The interrogator decides to keep on beating you until you decide to turn
over the (nonexistent) hidden volume.
Moral of the story: there are times when you very much want to prove
that you _don't_ have certain data.  TrueCrypt's design makes these
sorts of proofs impossible.

@_date: 2008-05-09 13:02:14
@_author: Robert J. Hansen 
@_subject: Protecting private key on USB flash drive: how to? 
Not really.
Imagine a piece of malware that looks for new drives to be mounted.  As
soon as it gets mounted, the malware looks through the drive looking for
interesting data.  Malware such as this already exists and has been
spotted in the wild.
As soon as you mount a TrueCrypt volume, it becomes subject to these
sorts of attacks.  Note that the malware design doesn't have to
accommodate TrueCrypt at all.  The design is simple enough and robust
enough to work regardless of whether you're using TrueCrypt or PGPDisk,
or whether you're plugging in a USB token or a FireWire external hard
drive, or... etc., etc.
I do not think very highly of this idea.

@_date: 2008-05-09 14:26:42
@_author: Robert J. Hansen 
@_subject: Protecting private key on USB flash drive: how to? 
Have you even read Gutmann's paper?
Gutmann's paper is meant for wiping data from physical drives, not
software drives.  The 35-pass number is also a misreading of Gutmann's
paper: you use the proper schedule for whatever your underlying hardware is.
I don't think you've thought this through.  I think trusting a scheme
like this is very unwise.  I think we're also far away from what's
on-topic for GnuPG-Users, so I'll just leave this thread at that.

@_date: 2008-05-10 01:53:55
@_author: Robert J. Hansen 
@_subject: Protecting private key on USB flash drive: how to? 
They are probably not.  I would strongly recommend talking to your local
IT support group and finding out firsthand how much of a malware problem
they've had with publicly accessible computers.
Universities are the computer equivalent of biowarfare research
facilities.  They're some of the most hostile, bot-compromised networks
out there.
Sure.  But it's malware.  It uses exploits.  It's not going to respect
the same rules that you have to play under.

@_date: 2008-05-13 22:11:26
@_author: Robert J. Hansen 
@_subject: Weird error 
Hash: SHA256
I have a message which successfully decrypts and verifies on Thunderbird
and Enigmail, running on OS X.
The same message bombs out at the command line.
gpg: using character set `utf-8'
gpg: armor: BEGIN PGP MESSAGE
gpg: armor header: Charset: UTF-8
gpg: CRC error; 5341CC - DC3534
:pubkey enc packet: version 3, algo 1, keyid 97B2C95A0569E3E6
:pubkey enc packet: version 3, algo 16, keyid 7582ADCB684C50FA
gpg: encrypted_mdc packet with unknown version 255
gpg: quoted printable character in armor - probably a buggy MTA has been
When I try decrypting this message on an Ubuntu 8.04 box with
Thunderbird and Enigmail, it bombs.  When I decrypt it at the command
line on Ubuntu 8.04, it bombs.
This seems highly weird to me.  I have the original message, stripped of
header information and other assorted things, posted at:
Anyone have any idea what's going on here?

@_date: 2008-05-14 16:45:28
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
Hash: SHA256
There are many, many things more important than this.
If you want an encrypted disk partition, many Linux distros provide the
tools for that natively.  OpenSuse 10.3 allows you to encrypt partitions
when you install the OS, for instance.
Regarding key length, anything past 2048 bits of RSA/ElGamal is, IMO,
patently ridiculous.  If it were up to me GnuPG would not generate keys
larger than 2kbit.  You do not gain anything when you move from 2kbit up
to 4kbit except larger RSA signatures.
GnuPG is not a Linux application.  GnuPG works on many, many different
OSes.  Keeping it as a command-line application allows the GnuPG
developers to stay focused on making GnuPG work on a ton of different
systems, and not getting tied to one particular platform.
That said, there are _many_ GnuPG front-ends.  I'm personally very fond
of Enigmail ( which gives excellent GnuPG
integration into email.
Two last words o' warning.
First, I am not a GnuPG developer.  They are, of course, free to do
whatever they like.  That said, I'm pretty sure my representations here
are accurate.
Second, your reply-to is root at somedomain.  This is probably a very bad
idea.  It suggests that you're using the superuser account as your
normal user account.  If you're doing this, then please create a normal
user account as soon as possible and start using that.  It'll save you a
ton of grief in the long run.

@_date: 2008-05-14 16:51:44
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
As opposed to OpenPGP's idiosyncratic CFB mode, which presumably needs
no IV?
It's true that disk encryption uses specialized techniques, but pretty
much every crypto algorithm relies upon good IVs.
I'm sure that if you can articulate a case for it and submit a patch,
the developers would consider it.

@_date: 2008-05-14 17:21:35
@_author: Robert J. Hansen 
@_subject: old default options file 
GnuPG 1.0 through 1.2 (I think) stored the options file in
$HOME/.gnupg/options.  As of 1.4, the options file was changed to
Your options file is misnamed.  Fix that and it should go away.  Don't
just rename the file, though -- check it to make sure that it contains
the options you want.

@_date: 2008-05-14 17:52:02
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
Sure it is.
Adding features "just because it's nice" is a pretty shoddy way to do
engineering.  Changes need to be driven by articulated needs.
We also get posts where people ask "is there any way for me to get
access to my files now that I've forgotten my passphrase?"  Should we
change GnuPG to accommodate their wishes?
Just because people ask for something is not a compelling reason to give
it to them.
I see no reason to add "features" to GnuPG that have no connection to
any real-world need.  Changing the largest keysize, even in expert mode,
has no connection to any real-world need I've ever heard anyone
articulate, and so I'm pretty hostile to the idea.

@_date: 2008-05-14 20:52:57
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
Great -- then you've answered your own question.  If there already exist
high-quality Free Software encrypted disk partition software, then why
should GnuPG reinvent the wheel and do its own?
I wouldn't even go that far.  Windows, for instance, is not especially
POSIX-conformant, and yet it runs GnuPG just fine.
Then you can expect to continue to get helpful warnings like the ones
you've already received.

@_date: 2008-05-15 01:42:56
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
Can you name some?  I'd love to know them.
If 2kbit RSA/DSA/ElG ever becomes attackable either via cryptanalysis,
brute force or developments in large number theory, the solution will be
to move to entirely new algorithm families, not to just tack on another
few bits to the end.

@_date: 2008-05-15 03:10:49
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
You're committing two logical fallacies here: the first is you're begging the question, and the second is the assumption of facts not in This discussion is about tradeoffs, and whether what is to be gained by adopting very large keys would be worthwhile given the sacrifices which would have to be made.  By saying "it's reasonable to choose to use extremely long keys", you're skipping the entire debate and moving straight to the conclusion you want to reach, leaving the original question unanswered.  Namely: is it worth it?
My crystal ball for the future is very hazy.  That's good news, actually.  Everyone's crystal ball is hazy.  I at least know it.
Trying to predict what computing power will be like in 100 years is absolute folly.  It's ridiculous.  It's so silly it doesn't deserve to be taken seriously.  If, in 1870, you were to ask Charles Babbage to prognosticate 100 years into the future for his Analytical Engine, do you really think he would have foreseen the internet, distributed computation, quantum computers, hypercomputation, the Church-Turing Thesis?
If, in 1935, you were to ask Alonzo Church about the significance of his research and where it would take us in 100 years, what do you think he would've said?
Saying "it's reasonable to choose to protect personal secrets for 100 years" is on faulty logical grounds because you _can't_ choose to protect secrets for 100 years.  You can't look that far into the future.
100 years from now the world will be unrecognizable to us.  Scientific, mathematical and technological advances we haven't even imagined yet will be old-hat.  The world of that future will be indistinguishable from magic -- and I am loss for how anyone can defend against magic.

@_date: 2008-05-15 10:54:21
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
The reasonableness of the choice to protect a secret for the rest of
one's life.
I'd like to see some proof offered for this assertion, since it seems
quite broad and far-reaching.
Your crystal ball is a lot clearer than mine is, apparently.
If we're able to ever break large (>2kbit) RSA keys, it will only be
possible by either (a) advances in computational technology so vast they
are indistinguishable from magic, or (b) advances in mathematics so vast
they are indistinguishable from magic.
Look at Ron Rivest's original (1970s) estimates for how long it would
take to break RSA512.  Just thirty years later, those estimates were
overtaken by reality and technologies that in the 1970s would have been
considered magical.
My cellphone is a modern computer, and it disagrees with you.  I imagine
the time to verify would be measured in minutes, not instants.
I also often have to take my cellphone onto 2.5G networks where the
total data rate is about 10kb/sec.  A 16kbit key would thus add
substantially to the delay in receiving my email.
Not ignored, simply not implemented.  The OpenPGP WG is, right now,
discussing how to best add ECC to OpenPGP.
That may be a sign you should think more about the problem domain.
You cannot keep data secret forever.  Anyone who is storing secret data
needs to have disclosure plans -- what to do when, not if, those secrets
come to light.
A good set of contingency plans will do you worlds more good than
tacking a few bits onto your key.

@_date: 2008-05-15 13:05:05
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
Some of Mark Twain's writings are not to be released until 2010.
[shrugs]  The presence of outliers proves nothing other than there are
outliers.  The general point I'm making remains: I consider it an
unproven, unfounded, and overly broad assertion that most people have
secrets they want kept for the duration of their lives.
Both.  By Rivest's original figuring, RSA512 would remain secure for
millions upon millions of years.
Rivest was optimistic, and it took far less time than he had calculated.
 If in the 1970s you had used Rivest's 100-year figures, you'd be using
RSA512 today.
This is Ron Rivest we're talking about here -- one of the brightest
lights in modern crypto.[*]  If Ron's predictions have a track record of
failure, and so does everyone else's, then why are we taking the "16kbit
for a century" predictions seriously?
[*] Also a fine gentleman, with a sense of humor that's positively
elfin.  I suspect he would much rather be known for that than for being
"the big brain on crypto".  :)
Apparently you haven't used an iPhone.  The iPhone supports IMAP, and a
lot of computer geeks I know have their iPhone set up to monitor their
inbox.  It's an awful platform to write emails from, but it's very
useful for mobile work.  Porting GnuPG to the iPhone would be fairly
straightforward -- writing a GnuPG plugin for the iPhone's mail client
would probably not be too hard -- but waiting five minutes for the
iPhone to number-crunch a 16kbit key would be excessive.
Mobile is where things are at nowadays.  A good cell phone is a
surprisingly powerful computer, comparable to a desktop of a decade ago.
It has great connectivity and you can easily get tens of gigabytes of
storage attached.
Don't be fooled by the small displays and awkward user interfaces.
Ask yourself this question: "why, then, is the original poster
recommending the use of RSA, when all that's needed is symmetric crypto?"
As I have said several times, the strongest cipher in the world is no
match for a lonely embassy cipher clerk and a thousand dollar a night
hooker armed with a bottle of eighteen year old Scotch.
The English idiom for trustworthy information, "straight from the
horse's mouth", was originally "straight from the whore's mouth", and
dates from the era where the best military intelligence was collected by
talking to the prostitutes a commander visited.  I've found references
to this sort of intelligence gathering going back all the way to
Hannibal Barca and the Battle of Cannae.  It's effective, reliable and
The NSA spent billions developing new ciphersystems.  The KGB just went
after the cipher clerks.
These sorts of attacks tend to be dramatically effective against
cryptosystems.  Human failings are endemic to the system.
The more we focus on adding another few bits to our keys, the less we
focus on the human factor.  That's where your attention needs to go when
it comes to long-term security.  People talk.  They always do.

@_date: 2008-05-15 17:54:05
@_author: Robert J. Hansen 
@_subject: Linux crypto killer apllication 
I'm not willing to go there.  We can conclude crypto is not often used,
but if you want to talk about why crypto is not often used you're going
to need some foundation other than speculation.  Ed Felten has a paper
out -- I'll dig it up if people are interested -- outlining patterns of
PGP usage in an international, politically-active NGO that had a lot of
secrets to keep, which included interviews asking "so why do or don't
you use PGP?"
Words like "probably" make people think of probabilities; weighted,
measured, quantitative things grounded in objective reality.
That is not the case here.  "Because it seems like a fairly good lower
bound" is more accurate -- and then it opens the door to ask, why
precisely does it seem that way, and how do you know your perceptions
are accurate with respect to the mathematical and technological
developments of a century hence?
I didn't choose the iPhone -- the free market did.  The iPhone's
capabilities are understood, at least vaguely, by most people, which
makes them good for exposition purposes.
Talk to the OpenPGP WG.  The mobile operators are pushing ECC since RSA,
ElGamal and DSA all require unreasonable amounts of time, memory and
procesor power.
Yes, but we're not talking about manipulating spreadsheets. We're
talking about _reading email_, which is clearly something people do with
their smart phones.
Explain the "RSA is more flexible", please.
It is also not easier to protect several documents.  Great, so I take my
several documents, I zip them up, I encrypt the file symmetrically,
bang, Bob's your uncle.
It is also not easier to have shared secrets.  Shamir's scheme is in no
way connected to asymmetric crypto.  You can do a secret sharing scheme
with a small symmetric key just as easily as you can with an asymmetric key.

@_date: 2008-05-23 12:06:15
@_author: Robert J. Hansen 
@_subject: playing with cryptography... 
WoT gives you more options about how to determine trust levels.  This,
to me, is significant.
This is Philosophy 101 sort of stuff.  There is nothing that can prove
_anything_ in the world.  After all, the cosmos may have been created
just last Thursday, and all of our memories are just what we were
created with, etc., etc.
It's not about proof, either.  It's about probabilities.  We're not
looking for a 100% assurance the person involved really is who they say.
A confidence in the high nineties is practically just as good, and can
be achieved fairly easily by asking to see a few different forms of
government ID.

@_date: 2008-05-23 14:16:48
@_author: Robert J. Hansen 
@_subject: import sec key problem 
There is no problem.
The key was imported successfully.
Type "gpg --edit-key " and set the key to the appropriate trust
level.  That's all.

@_date: 2008-05-24 00:58:20
@_author: Robert J. Hansen 
@_subject: Disabling compression when encrypting 
--compress-algo none
Alternately, you can add "compress-algo none" to the end of your
gpg.conf file.

@_date: 2008-05-24 13:12:43
@_author: Robert J. Hansen 
@_subject: Disabling compression when encrypting 
How does it do this?  Does it look for known headers, or does it check the entropy of the source text?  If the former, then what headers does GnuPG know about?  zip, bz2 and gz, I'm assuming, but what about more exotic formats like 7z and the like?

@_date: 2008-05-24 17:55:48
@_author: Robert J. Hansen 
@_subject: playing with cryptography... 
Or, for that matter, some people with graduate degrees.  As I told a
friend of mine a couple of days ago, "I used to be a lot more impressed
by Master's degrees until they gave me one."
An undergraduate degree in CS is basically a certificate that says
you've learned the basics, you've been exposed to some advanced
concepts, and you're ready to begin learning.  There are some undergrads
who know this and are chomping at the bit for more.  They're some of the
most useful and energetic people I know.
There are, unfortunately, an awful lot who seem to think it means
they're done with learning.  These people tend to be the sort you hear
horror stories about.
UI has a surprisingly good program, but we're hardly immune to human
nature.  :)

@_date: 2008-05-26 18:25:41
@_author: Robert J. Hansen 
@_subject: Removing all installed versions of GNUPG 
Depends a lot on your distribution of Linux.
That'll work for at least one of them.
It would be more helpful if you were to let us know which distribution
you're using, and where the gpg executables are located on your system.
Removing GnuPG entirely from a Linux system is not recommended and is
probably a bad idea.  Many distributions use GnuPG to digitally sign
their packages.  Without GnuPG, you have no way of knowing if your
packages are authentic.

@_date: 2008-05-31 16:20:06
@_author: Robert J. Hansen 
@_subject: what if they have my sec key? 
1kbit is a practical key size for most people and purposes.  A kilobit
key may be attackable via a phenomenally well-equipped and well-funded
adversary within the next decade, but if you're concerned more about
rogue sysadmins than rogue governments, a kilobit is plenty fine.

@_date: 2008-11-02 22:33:02
@_author: Robert J. Hansen 
@_subject: Anyone know what became of the Gaim-E Project? 
It died due to lack of interest, mostly.  Some IM protocols require
short message blocks; OpenPGP messages are usually quite long.  Thus,
Gaim-E was never able to support as many protocols as Gaim/Pidgin itself
A different project, OTR, provides confidential instant messaging.  I
have some minor quibbles with it, but all in all, OTR seems to be the
best thing going for IM confidentiality.

@_date: 2008-11-03 07:12:43
@_author: Robert J. Hansen 
@_subject: Anyone know what became of the Gaim-E Project? 
This is increasingly off-topic from GnuPG; let's bring this thread to  a close pretty soon.
I don't buy OTR's hype, which is basically what you're quoting here.   What they're saying is simple: if an attacker eavesdrops on your  secured communications and gets copies of them, then if the attacker  is able to compromise your box, the attacker can get your GnuPG key  and use it to decrypt previously sent Gaim-E traffic.
I also don't buy the argument that an OpenPGP signature is difficult  to deny.  Or, perhaps, the problem is that I _do_ buy the argument.   Signature semantics are the most pernicious part of OpenPGP, if you  ask me.  I can count my hands the number of people I know whom I think  have a good grip on signature semantics.
A correct signature from a valid key belonging to a trusted party  means the reader can feel confident the message is in the same state  as the signer saw it.  That's all.  Nothing else.
Imagine that Alice sends Bob a very short note.  "I love you."  Bob,  who wants to gloat about his romantic victory to his archrival  Charlie, forwards Alice's message on to Charlie... but Bob's mailer  appends a signature to the message.  Now Charlie has a signed message  from Bob in which Bob appears to swear his love for Charlie.  Major  embarrassment ensues because everybody thinks the signature is proof  that Bob wrote the message, when he actually didn't.
The absence of a signature is also not proof of anything other than  the absence of a signature.  Imagine that I'm concerned about people  forging my messages, so I make it a point to sign everything.  A  malicious undergrad, upset over the grade I gave, decides to ruin my  reputation anyway by posting vitriolic, hate-filled messages to a  white supremacist mailing list using my name.  When the Dean summons  me to explain my actions, I say "... but that's not me!  I sign  everything!  I have a years-long history of signing everything!"  The  Dean, who is a smart mathematician, will say "ah, but perhaps you  deliberately left your signature off these messages so you could deny  them later if they surfaced.  You understand that we have to open an  investigation into you, Rob, correct?"
So my objection to OTR's characterization of OpenPGP signatures as  "difficult-to-deny proof" is that it's simply not so.  The public  misconceptions around signatures are so vast that I seriously doubt  the utility of signatures.  Most people don't understand them and  don't especially want to, either.
This message was sent using IMP, the Internet Messaging Program.

@_date: 2008-11-03 12:34:50
@_author: Robert J. Hansen 
@_subject: Anyone know what became of the Gaim-E Project? 
To turn the "I love you" example into an attack, consider this: Alice  sends Bob a message saying "Remember, you need to deliver the product  at midnight."  Bob, who doesn't want responsibility for delivering the  product, cuts-and-pastes Alice's message and sends it on to Charlie,  forging it as being from Alice.  Charlie receives a message that seems  to be from Alice, has a meaningful message, and has a valid signature  from a trusted key.  Charlie delivers the product  The  next day Alice sees the product was delivered, and sends Bob a message  saying "thank you for delivering the product, the check is in the mail."
Presto, Bob gets paid for Charlie's work.
Yes, attacks like these have been spotted in the wild.  Schneier's  blog covered one of them recently, an outfit that used attacks like  these in connection with long distance trucking companies.   Fascinating work, really.

@_date: 2008-11-03 16:50:06
@_author: Robert J. Hansen 
@_subject: Anyone know what became of the Gaim-E Project? 
How is Alice supposed to know what metadata is necessary?  Alice isn't  omniscient.  Even if Alice puts in metadata A, B and C, Bob will just  use an attack that relies on the non-presence of metadata D.

@_date: 2008-11-03 18:38:08
@_author: Robert J. Hansen 
@_subject: Signature semantics (was Re: Anyone know what became of the 
Right, and this much doesn't bother me.  It's when people start  ascribing meaning to bad signatures, or the nonexistence of  signatures, that I begin to get frustrated.  A bad signature doesn't  mean the message was tampered with -- the alteration could have been  in the signature and not the message itself, just to name one  The flaw isn't in OpenPGP, but rather in the popular conception (or,  in this case, misconception) of it.

@_date: 2008-11-04 09:18:22
@_author: Robert J. Hansen 
@_subject: Seals 
It is, quite literally.  The scheme can be thought of as a message  authentication code (MAC), with a shared key that has to be negotiated  ahead of time; and just like with a MAC, anyone who has the secret key  is capable of forging the message.

@_date: 2008-11-04 11:28:28
@_author: Robert J. Hansen 
@_subject: Signature semantics 
Idiot-proofing is a very bad idea.  Systems cannot be made idiot- proof, since we're constantly developing higher and better grades of  idiots.  Systems can be made user-friendly; they cannot be made idiot- (As an example of what suggestions like this lead to in practice, look  at Vista's User Access Control.  HCI studies have shown UAC does not  provide better security.  UAC is designed to give users a last chance  opportunity to prevent programs from running with elevated privileges,  but it does not actually do this.  UAC was not designed to train users  to blindly click "Yes" without thinking at all about what they're  doing, but that's what it actually does.)

@_date: 2008-11-04 13:43:33
@_author: Robert J. Hansen 
@_subject: Signature semantics 
Again, this is idiot-proofing, not making GnuPG user-friendly.  If you  want to do this, GnuPG will let you do this.  It is not GnuPG's  responsibility to hold your hand along the way.  This is a proposal  which would be better suited to an email plugin like Enigmail.

@_date: 2008-11-04 15:15:00
@_author: Robert J. Hansen 
@_subject: Anyone know what became of the Gaim-E Project? 
YASD (Yet Another Subtle Distinction).  Signatures make it possible for
the sender to be authenticated.  However, the sender still has to take
concrete steps so the recipient can enjoy sender authentication.
I like to put small personal details in my signed messages; if I talk
about "hey, I really enjoyed lunch the other day" and the recipient
didn't have lunch with me, that's a clear sign some kind of sender games
have been played.  That's an example of what I'm talking about here.
You can't.  A bad signature conveys the exact same information as an
absent signature.  Maybe the message was tampered with; maybe it wasn't;
maybe it was tampered with innocently; maybe it wasn't; maybe... etc.
The only information a bad signature conveys is that someone -- perhaps
the original sender, and perhaps someone else -- attempted to do a
signature operation.  The informational content of that fact is pretty
much zero.
Yep.  Like I said, I generally don't buy digital signatures.  When used
correctly by people who understand the subtleties of what they can and
cannot do, digital signatures can be very useful.  The rest of the time
I think they're a distraction.
A few years ago over on PGP-Basics, one list member was adamant that
signatures should be used for _everything_, regardless of whether the
recipients had validated your key, met you, or formed any opinion on
whether you were trustworthy.  Speaking the Sweet Voice of Reason did
not dissuade this person, so John Moore, John Clizbe and I did a small
I created a keypair, removed the passphrase from it, and shared it with
John and John.  We did not upload it to the keyservers.  We then used
this keypair to sign all of our traffic to the list... all three of us,
using the exact same key.
It was months before anyone noticed.  Few people cared that our messages
kept on getting flagged as "no key available" and the key wasn't on the
keyserver.  What people cared about was that it was signed, and as long
as it was signed, that was enough.
Now, remember, PGP-Basics is a pretty clueful group.  It's very newbie
friendly, but there are a lot of people there who have years of
experience using OpenPGP.  If they didn't notice the subterfuge, what
chance does a normal user have?
For all I know, someone on this mailing list could be repeating that
experiment right now.  If so, I'm totally blind to it.  This just goes
to show that I'm no more observant than anyone else.
... So yeah.  I am not a believer in the usefulness of digital
signatures.  They're very useful when you have:
If any of those three conditions fail, I think digital signatures are
pretty much useless.  Given how specific and exacting the "useful"
conditions are, I think the only conclusion to draw is that in the
general case digital signatures are magic crypto fairy dust.  Sprinkle a
little on and you're safe from identity theft, message fraud and other
tampering!  Pay no attention to the man behind the curtain!

@_date: 2008-11-04 17:34:35
@_author: Robert J. Hansen 
@_subject: Anyone know what became of the Gaim-E Project? 
This presupposes that (a) there exist a significant number of people who
are qualified to teach, and (b) there exists a large number of people
who want to learn.
I don't agree with either presupposition.  OpenPGP does not do what many
(most, it seems) of its users think it does; and many (most, it seems)
users are just fine with that state of ignorance.
You guys who are willing to put in the work, change your minds, think
critically?  You guys are angels.  Don't ever change.  I just wish you
weren't in the minority.
(The preceding is applicable to a lot of life, and not just OpenPGP.)

@_date: 2008-11-11 12:40:20
@_author: Robert J. Hansen 
@_subject: GPG.conf Cipher Preference 
It can be succinctly described this way:
default-cipher-preferences is a feature.  cipher-algo is a misfeature.
Virtually everyone wants default-cipher-preferences.

@_date: 2008-11-16 21:32:44
@_author: Robert J. Hansen 
@_subject: Question regarding s2k algorithms 
Potentially.  This is why we tell people not to muck about with the
defaults.  If there's an actual critical need to alter the s2k, then
fine, tweak it: otherwise, leave it with the defaults and don't muck
about with it.
By default, GnuPG will use SHA1 for this task.  All OpenPGP applications
are guaranteed to support SHA1, so it's a nonissue.  Further, the recent
attacks against SHA1 are irrelevant in this particular crypto domain.
For this purpose, SHA1 is still as strong as it's ever been.
No.  A random session key is generated.  There's no need to hash random
data; in fact, you can argue that hashing random data will probably
decrease its randomness.
Contradiction.  The stock gpg.conf file does not set this option.  If a
user is going to muck about with the defaults, then they're responsible
for the consequences of that mucking.  You may wish to clarify what you
Beats me.  GnuPG tends to bail out if there's an invalid option in the
gpg.conf file.  I don't know if that's the case for this option, but
that's what's happened to me in the past.
The specific purpose is to be compatible with a PGP 2.6 'feature' which
was really just marketing hype.  As the GnuPG manpage says, this option
does not actually do what people want it to do.  That said, I am
absolutely certain if the GnuPG developers were to remove it there would
be a hue and cry.

@_date: 2008-11-16 23:07:47
@_author: Robert J. Hansen 
@_subject: Question regarding s2k algorithms 
Dunno; this is one of the parts of GnuPG I've never mucked with, so I
can't talk intelligently about it.  However, regarding your observation
that CAST5 is a weird choice, many non-PGP people would agree with you.
Like most of OpenPGP's weirdnesses, this is done to make backwards
compatibility with PGP 5 and 6 easier.
None.  Well... potentially.  A largely theoretical attack has been
demonstrated against SHA1 when used for message authentication purposes;
it is possible this research will spur on attacks against SHA1 when used
for password hashing purposes.  However, I don't find it to be very
likely.  If it were to happen, then /wow/, would it be news.
I can't talk about the community's hedging in general; I can only talk
about my own.
Algorithms get used in a lot of very different ways.  Hash algorithms
get used to provide password hashing and message authentication.  It is
possible for an algorithm to be broken for one purpose and still useful
for another.
For instance, although I consider MD5 to be horribly broken for most
cryptographic purposes, I still use it to create one-time passwords.
The attacks against MD5 focus on MD5 as it is used in one problem
domain; MD5 in other domains is still quite useful.
The same thing is happening to SHA1.  SHA1 for purposes of signatures is
not looking very good.  SHA1 for other purposes is still perfectly fine.
However -- good luck explaining this to people.  It's one of those
infamous "subtle distinctions" I talk about incessantly.  Most people
don't want to spend the time and energy it takes to be a competent
cryptographic engineer.  They just want an answer.  For these people,
"SHA1 is still secure but is not looking good in the long-term; migrate
to something else; SHA256 looks pretty good" is the advice I give people.
And even then, with the subtleties reduced that far, it never fails that
people misconstrue what I say to be "SHA1 is broken!  We must use SHA256
for everything!".
It's kind of frustrating.

@_date: 2008-11-17 14:26:07
@_author: Robert J. Hansen 
@_subject: appending to gpg file? 
First, it's not: those characters are all valid Base64.
Second, these sorts of responses are not exactly helpful.
For the original poster, David Kennedy:
Explaining to us what it is you're trying to achieve, goal-wise, will
allow us to point out ways you can do it, either with GnuPG or with some
other solution.  Otherwise, we're kind of fumbling in the dark here.

@_date: 2008-11-21 18:01:19
@_author: Robert J. Hansen 
@_subject: gnupg compilation problems on Solaris 10 64 bit 
What's the engineering reason for the ASM code as opposed to just
sticking with the C code?  It seems that for the vast majority of users,
there's no difference in performance between the C code and the
ASM-tuned code.  My guess (prejudice?) is that this would really only
make a big difference for high volume operations.

@_date: 2008-11-21 20:06:03
@_author: Robert J. Hansen 
@_subject: gnupg compilation problems on Solaris 10 64 bit 
So wouldn't it make more sense to have --disable-asm be the default?
The increase in portability seems to be a bigger win than shaving two
hundredths of a second off of each public key operation, and if people
need that extra two hundredths, they can compile their own using

@_date: 2008-10-04 16:56:50
@_author: Robert J. Hansen 
@_subject: Adding a UserID to Your Key 
I call shenanigans.
First, if you live in a country where encryption is a privilege, I feel
sorry for you.  Privacy is a human right.  Tools that ensure privacy are
also human rights.
Second, if it's encrypted, how do you propose the authorities will read it?
Why not?  Intelligence agencies are already reading this list.  Why not
smile, wave and say hi to them?
Speaking very broadly, as long as you aren't advocating terrorism, tax
fraud, the drug trade or the exploitation of children, they really don't
... Privacy is a human right.  Stand up for it, and don't apologize for
insisting upon it.

@_date: 2008-10-04 23:30:40
@_author: Robert J. Hansen 
@_subject: Revocation Certificates 
If this is of so much concern to you, you should probably consider
leaving the various crypto mailing lists altogether.  Members of various
national intelligence communities are reading this list, the Enigmail
list, the PGP-Basics list, and others.  Not for any nefarious purpose,
mind you, but because they're privacy enthusiasts.
Remember: the NSA does both communications intelligence and
communications security.  This mailing list is right up the latter
group's alley.  They're great folks.
If you are that concerned about the intelligence and/or law-enforcement
communities seeing what you write, you should be very careful about your
involvement on this, or any of several other, mailing lists.

@_date: 2008-10-05 00:23:01
@_author: Robert J. Hansen 
@_subject: Revocation Certificates 
At risk of continuing this thread more than it should be continued...
This is not a miscarriage of justice.  Even if everything Lawrence has
said is true.  Let's say that someone sends me a message in which they
threaten the life of the President of the United States.  I mention to
someone that I've received this, they tell someone else, and _bang_,
next thing I know I've got an appointment with some Secret Service
agents who want to ask me some very intrusive questions.
That's not a miscarriage of justice.  That's them doing their job.  It
would be a miscarriage of justice if I was indicted for a crime, much
less convicted -- but there's no miscarriage of justice in the police
seeing something which says "hey, something may be afoot here," and
deciding to follow up on it.
In '98, I went down to the sheriff's office to renew my firearms permit.
 While filling out the form I was chatting with the woman behind the
desk, whom I've known for some years.  She asked me how my
then-girlfriend was doing, and I said that I'd recently proposed and
she'd said yes, and we were figuring out a wedding date.
This was a perfectly normal conversation of the sort that goes on every
single day.  However, some sharp-eared deputy sheriff heard me talk
about my fianc?e and noticed I was standing in line for a firearms
permit.  This deputy sheriff reported to his superior, and I wound up
with a thirty-day delay in the paperwork while the county sheriff made
sure that I didn't have murder afoot.  Were they overreacting?  Sure, a
bit.  But they were also doing their job.
Remember that we've only heard Lawrence's side of things, and even then
we haven't heard much about it.  What does Lawrence mean by he got in
trouble?  Did an officer stop by his house and say "hey, we heard
something about this, is there something I ought to know about?", or was
he actually put on trial?  The former is not objectionable; the police
are allowed to do their job.  The latter might very well be.
(Note: I am not asking to know the particulars.  I don't want to know
the particulars.  This entire thing is irrelevant.  But it really annoys
me to see people jump to such wild and unsupported conclusions based on
the flimsiest of evidence and the wildest of accusations.  It is one of
my biggest pet peeves.)

@_date: 2008-10-05 16:05:10
@_author: Robert J. Hansen 
@_subject: Paperkey for Revocation Certificates? (Feature-Request :-) 
I'm not David (obviously), but I don't see the win here.
The problem with paper copies of private keys is they're big.  If
there's an error while OCRing them, it's going to be an ordeal to do an
optical diff between what was printed and what was OCRed.
Revocation certs are much smaller.  They're a few lines of text, nothing
more.  The optical diff is much easier.
Where's the need for this tool?  Where's the use case?

@_date: 2008-10-06 15:01:23
@_author: Robert J. Hansen 
@_subject: Computational Efficiency of GnuPG ciphers and hashes 
AES is the clear winner, with Twofish a close second.

@_date: 2008-10-16 18:16:41
@_author: Robert J. Hansen 
@_subject: add subkey vs generate new set? 
This is not true.
1kbit keys are generally considered safe for now, although they may
become vulnerable to fantastically well-equipped adversaries within the
next decade.
2kbit keys are considered secure for what is effectively the indefinite
future.  We will not break 2kbit keys until we have had such massive
leaps in mathematics or engineering that they would deserve to be called
science fiction.

@_date: 2008-10-21 07:43:38
@_author: Robert J. Hansen 
@_subject: There is no limit on the length of a passphrase, 
This is something you've heard from a lot of people, probably, myself
included.  128 bits is enough until we get some science fiction
Of course, the trick there is 128 bits _of entropy_, not 128 bits _of
passphrase_.  Conservatively speaking, there are probably about 1.5 bits
of entropy per letter of English text, meaning you'd need about an
80-char English passphrase to max it out.  Introducing alphanumeric
characters, punctuation and the like will reduce this considerably.
Think 'centuries.'  The RC5/64 project brute-forced a 64-bit cipher
using 18 months and a very large distributed computing system.

@_date: 2008-10-21 20:26:16
@_author: Robert J. Hansen 
@_subject: Key ID format: short or long? 
Put the entire key fingerprint on the card.  That way, if you give
someone a business card, you're also giving them a known good copy of
your key fingerprint.
Yes, the entire fingerprint does fit on a standard business card; I have
 one of my key fingerprints on mine.

@_date: 2008-10-21 23:10:01
@_author: Robert J. Hansen 
@_subject: There is no limit on the length of a passphrase, 
Be careful of anything you get off the internet.  This article is not
especially good.
[shrugs]  Yes.  No.
The reality is that very few people let a CSPRNG spit out a base-64
password for them to remember (six bits of entropy per glyph).  They're
hard to remember.  Good passphrases are easy to remember but hard to
guess, which means they need to be rather large pieces of text.
Per Shannon's estimates, there are roughly 1.5 bits per glyph of English
That's assuming you're picking randomly from Unicode code pages.  If you
don't mind having "Tamil vowel sign au", "Linear B ideogram B182", "full
outer join", "circled Hangul Pieup A" as your passphrase, then you can
get some pretty good entropy.  The problem comes from having to enter
... well ... Tamil vowel sign au, Linear B ideogram B182, full outer
join and circled Hangul Pieup A as your passphrase.  Good luck
remembering it: I bet you'll forget it in under a month.
UTF8 is supported.  However, your OS may not support it.  That's an
OS-level issue, not a GnuPG issue.  My Mac supports UTF-8 just fine,
including exotics like "circled ideograph wood".
If only you know it, then kiss randomness goodbye.  Someone who wants to
attack your passphrase will focus their attack on symbols from languages
you know.  The only defense is to pick randomly.
Depends on your OS.
Yes, but this is a case of buying a few hundred yards of rope just to
make _sure_ you have enough with which to hang yourself.

@_date: 2008-10-21 20:04:24
@_author: Robert J. Hansen 
@_subject: Key ID format: short or long? 
This may be your policy; it is not a requirement of the system.
Sure they are.  Where do you think the key ID comes from?  It's the  last eight hex digits of the fingerprint.

@_date: 2008-10-22 08:15:13
@_author: Robert J. Hansen 
@_subject: There is no limit on the length of a passphrase, 
I'm a software engineer nowadays, although my college degrees are on the
math-heavy side of theoretical computer science.  I think it's fair to
call me a mathematician, but I'm not sure I can be said to do it
Actually, there's a funny story about the last time I did that.  I was
delivering a paper on destructive visual cryptography, and was stumbling
around to find a 'feelie' to distribute to the profs to make it more
tangible for them.  Then I figured it out: scratch-off lottery tickets,
appropriately marked up.  That led to my last lottery purchase.
Sorry -- explanations follow.
Entropy is uncertainty, represented as the logarithm base-two of how
many possibilities there are.  For a random person, their driver's
license has either 'M' or 'F' as your sex, so they have one bit (log2 of
2) of entropy (uncertainty) in their gender.
  (Fun fact: you can tell mathematicians apart from computer
  scientists by asking them for the fundamental unit of
  entropy.  A CS guy will say the 'bit'.  A math guy will
  say the 'nat'.  The mathematics version of entropy is
  found by computing the natural log of the possibilities,
  not the log-base-2 of the possibilities.  Hence, 'nat'.
  There are about 1.44 bits per nat.)
A good passphrase will have 64+ bits of entropy.  A great passphrase
will have 128 bits.  There's not much point beyond that.
Glyph = one symbol in a language.  It could be a single English letter,
a single Chinese ideogram, or a single Hangul phoneme.  The more glyphs
in your passphrase, the more entropy you have (usually).  English
accumulates about 1.5 bits of entropy per glyph.
CSPRNG = cryptographically secure pseudorandom number generator.  An
algorithm that spits out random-looking garbage.  Different from a PRNG,
in that a cryptanalyst can often "break" (learn how to predict) PRNG
outputs; but CSPRNGs are hardened against these attacks.

@_date: 2008-10-23 12:29:08
@_author: Robert J. Hansen 
@_subject: set type digest mode? plus other query 
Your question is not very clear.  I will try to answer it nevertheless.
Q: Without the --enable-dsa2 option, is DSA limited to SHA1, md5, etc.?
A: The question cannot be answered.
Q: Without the --enable-dsa2 option, what hashes may be used with DSA?
A: SHA1 and RIPEMD160.
Q: Is the note about app support of DSA2 still relevant?
A: Depends on who you correspond with.  There are still a lot of PGP 6
    installs out there.
Q: Should --enable-dsa2 be used?
A: Probably.  The sooner we can convince people using legacy systems to
    upgrade, the better off we'll all be.
This message was sent using IMP, the Internet Messaging Program.

@_date: 2008-10-23 19:06:35
@_author: Robert J. Hansen 
@_subject: set type digest mode? plus other query 
It was the last version of PGP to be released freeware for UNIX.  To
this day, PGP has more brand recognition than GnuPG; people who only
know "I need PGP to do $foo" will more often than not look around for
PGP for UNIX and find 6.5.8.
On the Win32 front, 6.5.8 is available for download from a great many
sites.  7.x isn't available anywhere, you have to really look for 8.x,
and 9.x requires registering with PGP.com, which many people are opposed to.
On top of that, a lot of the OpenPGP software ecosystem (remailers,
mixmasters, etc.) is hardcoded for PGP 6.5.8 support.
PGP 6.5.8, like PGP 2.6, is "good enough for most people and purposes."
 Which means that no matter how much we want to get rid of them, they
simply won't go away.

@_date: 2008-10-23 20:33:09
@_author: Robert J. Hansen 
@_subject: set type digest mode? plus other query 
Try fifteen or more -- and yes, it is.  It's a very, _very_ simple piece
of software; it'll compile anywhere that's even faintly, vaguely, making
noises about being POSIX conformant.  Such as, say, DOS.

@_date: 2008-10-27 10:29:00
@_author: Robert J. Hansen 
@_subject: STrange message... 
Do you mean "what's up with that window appearing"?  Enigmail (a plugin
for Thunderbird, one you apparently have installed) saw a PGP message
header, assumed it contained an encrypted message, and prompted for a
Do you mean "what's a card PIN"?  GnuPG allows keys to be stored on
smartcards, where they are protected by a personal identification number
(a PIN) instead of a passphrase.

@_date: 2008-10-27 12:00:45
@_author: Robert J. Hansen 
@_subject: STrange message... 
Of course not.  If your box gets pwned, the person who pwns it can do  whatever they want to it.
If your box is compromised, you're in a game over state.

@_date: 2008-10-31 13:17:25
@_author: Robert J. Hansen 
@_subject: Use of gen-random 
Without knowing your OS and various other finicky details, it's hard  to say.
On many UNIX systems, the system keeps track of unpredictable inputs,  does various mathemagic to them, and stores the results as a source of  high quality random bits.  These are as close to truly random as can  easily be obtained with computers.  Since they're the result of  physical processes, there are only a finite number of them available.   Using these random bits profligately can result in high quality  randomness being unavailable to other applications that need it.
Most systems also include a fairly good PRNG (pseudo-random number  generator) which is good for most purposes.  But for crypto, you want  the best quality randomness you can get.

@_date: 2008-09-05 17:25:22
@_author: Robert J. Hansen 
@_subject: Protect pubring.gpg and secring.gpg 
It's already encrypted.
If someone is able to plant a keylogger on your machine, the game is
over.  If you don't have physical security over your machine, you have
no electronic security worth talking about.

@_date: 2008-09-05 22:17:10
@_author: Robert J. Hansen 
@_subject: Protect pubring.gpg and secring.gpg 
As strong as any other symmetric algorithm in GnuPG.  Stronger than you
need, in other words.

@_date: 2008-09-08 19:40:21
@_author: Robert J. Hansen 
@_subject: Someone has harvested my address 
One thing that I am really quite surprised the community doesn't talk
more about --
We all know how dangerous it is to do sensitive work on a hijacked PC.
We also know that a tremendous number of desktops are hijacked, usually
with the owner unaware.  Dan Geer, posting on this list, estimated it
between 15% and 30%.  Vint Cerf's numbers have varied between 25% and
40%.  Microsoft says 65%, PC Security 70%, and IDC 75%.
About the only thing we can rely upon is that (a) the numbers are
appallingly, disturbingly, high, and (b) any Windows desktop you see,
including your own, needs to be considered suspect.
The conversation we're not having, which I think we should be having, is
"how can we have trusted communications on a hostile network when we
don't know if we really control our own PCs?"

@_date: 2008-09-09 02:23:20
@_author: Robert J. Hansen 
@_subject: Someone has harvested my address 
I gave them in the message.  Google is your friend.
Dan's message can be found at:
Vint Cerf's numbers from a year and a half ago, where he was saying
between 16% and 25%, can be found at:
PC Tools' (I was in error when I attributed it to PC Security; I
apologize) numbers were covered in ZDNet Australia, among others:
The rest of the numbers, plus more recent estimates by Vint Cerf, can be
found with a quick Google search.  I no longer have the citations for
them on yellow Post-Its on my monitor.

@_date: 2008-09-09 16:32:08
@_author: Robert J. Hansen 
@_subject: Someone has harvested my address 
Well, yes, but that's kind of not really what I was aiming to start.  :)
When confronted with the fact many PCs (typically Win32, but there's no
reason to think exclusively so) are compromised without us knowing it,
what then should our response to it be in terms of effective usage of GnuPG?
(My answer is 'use OS X and/or Linux, and always suspect the endpoints
are leaky'.  Other people's may differ, of course.)

@_date: 2008-09-11 18:22:17
@_author: Robert J. Hansen 
@_subject: Someone has harvested my address 
My rephrasing would be,
"Using GnuPG doesn't make your communications perfectly secure: however,
it potentially makes your communications a heck of a lot more secure
than you'd be without it."
A heavy emphasis needs to be placed on 'potentially'.  The elephant in
the middle of the room is just how much uncertainty there is within that
word.  It isn't so much the uncertainty which bothers me, but how
nigh-impossible it is to pin it down.
This is the sine qua non of communications nowadays.  It's depressing.

@_date: 2008-09-14 12:35:31
@_author: Robert J. Hansen 
@_subject: Req. advice on automated gpg batch job and storage of private 
The best advice I can give you is to hire a professional information
security geek to talk to you about your particular needs and come up
with a detailed plan.
Asking here will get you a dozen different ideas, but you have no real
way of knowing whether the people pitching the ideas are actually
qualified to have opinions.  It is inappropriate to trust the wisdom of
the internet for how to handle sensitive consumer data such as credit
card numbers.

@_date: 2008-09-15 19:58:36
@_author: Robert J. Hansen 
@_subject: Removing UIDs? 
Leave them in place, but revoke them.
E.g., I needed to revoke user IDs 3 and 4 on key 0x5B8709EB.  Thus, I:
gpg --edit-key 0x5B8709EB uid 3 revuid
Then you hit 'yes' at the prompt, explain the reason why you're revoking
it, enter your passphrase, and send your key up to the servers.

@_date: 2008-09-16 02:16:03
@_author: Robert J. Hansen 
@_subject: Removing UIDs? 
"Futility" comes to mind.  If you delete the UID, as soon as you sync
with a keyserver, the deleted UID will come back.

@_date: 2008-09-16 04:23:02
@_author: Robert J. Hansen 
@_subject: Removing UIDs? 
Yes, I am sure.  This is not an opinion, this is empirical observation.
 In fact, if you'd like to test this, you can see the exact same results
that I have.

@_date: 2008-09-16 13:29:10
@_author: Robert J. Hansen 
@_subject: Export secret key from WinXP (GnuPG) 1.4.7 to AIX PGP Version 
Mid-1998, I think.  Mid-2000 is when PGP 7 came out.  PGP 6.5.8's date
of introduction was mid-to-late '98.
Following remarks are meant more for the original poster, rlively:
I'll go one step further and say it's a sign you shouldn't use PGP
6.5.8.  AIX has moved on in the last ten years; it's possible the C
runtime has moved on, too.  The segfault may be a problem with the PGP
6.5.8 code, or it may be a problem with the assumptions the code makes
about the C runtime, or it may be... etc., etc.
The fact it's segfaulting would cause me to harbor doubts about whether
it should be used in a security context.

@_date: 2008-09-16 17:18:11
@_author: Robert J. Hansen 
@_subject: Export secret key from WinXP (GnuPG) 1.4.7 to AIX PGP Version 
This is a PGP 2.6 key, unfortunately.
He is not.  There are two different internet standards for PGP.  The
first one, called RFC1991, dates to the early '90s.  The second one,
called RFC4880, was only officially released a few months ago.  The two
standards are not interchangeable, and RFC4880 brings many more
capabilities to the table.
GnuPG is an RFC4880 application.  PGP 2.6 is RFC1991.  The two are
generally incompatible.  (I've heard talk of people figuring out how to
make them work together, but I've generally been of the opinion they're
talking about a lot of baling wire and bubblegum.)
No greater than downloading and compiling any other FOSS project.
Ask here.  :)  I imagine in short order you'll get some answers from
people using GnuPG on AIX.

@_date: 2008-09-16 23:50:17
@_author: Robert J. Hansen 
@_subject: GnuPG Defaults 
DSA-1024 is a MUST in the RFC, and therefore is interoperable with every
conforming OpenPGP implementation.  Likewise with SHA-1.
AES is a SHOULD, and is interoperable with the great majority of OpenPGP
applications (PGP 7.1+).
As DSA-2048 and DSA-3072 support becomes more commonplace (read: as
people migrate away from older versions of PGP and GnuPG, a process that
takes astonishingly long), you can expect to see the defaults change.  I
don't know too many people who are still enthusiastic about DSA-1024,
although it's still considered infeasible to break it.

@_date: 2008-09-17 00:28:35
@_author: Robert J. Hansen 
@_subject: GnuPG Defaults 
John Clizbe wrote in response to Kevin Hilton:
When PGP 2.6 first came out, there was a big legal kerfuffle over
intellectual property rights to the RSA and IDEA algorithms.
When PGP 5 came out, PGP embraced different, non-encumbered algorithms
(DSA and CAST5).
Since OpenPGP grew directly out of PGP 5, OpenPGP gets a lot of
historical baggage from PGP 5's decisions.
That's the nutshell explanation.

@_date: 2008-09-17 00:36:26
@_author: Robert J. Hansen 
@_subject: GnuPG Defaults 
The preferences on a key are actually not very preferential.  It's a
capability list far more than it is a preference list.  The fact AES
comes before CAST5 matters very little.
personal-cipher-preferences is what you're thinking of.  This gets set
in the gpg.conf file, not on your key.

@_date: 2008-09-17 00:51:57
@_author: Robert J. Hansen 
@_subject: GnuPG Defaults 
That's a question for David and/or Werner to answer.
For whatever it's worth, many people within the OpenPGP community would
really like to see a lot of algorithms go away.  (E.g., if it were up to
me, only DSA, ElG, AES, 3DES, SHA1 and SHA256 would be supported.)  Some
people reduce their advertised capabilities in order to encourage moving
to a smaller algorithm set.
Beats me.  I haven't looked at the source in a while.

@_date: 2008-09-17 02:34:49
@_author: Robert J. Hansen 
@_subject: GnuPG Defaults 
To use a medical analogy, SHA1 has a hairline fracture, not an outright
break.  It's still working fine, although it's certainly not in shape to
take too many more hits.
And this has been the subject of vigorous argument among the members of
the IETF OpenPGP WG.  There's been some talk about devising a minimal
OpenPGP subset, to make implementing it easier -- I don't recall much
talk about that project lately, though.
But anyway, yeah, the WG knows about it, and a lot of people aren't
happy with it.

@_date: 2008-09-17 12:08:40
@_author: Robert J. Hansen 
@_subject: Export secret key from WinXP (GnuPG) 1.4.7 to AIX PGP Version 
Sure.  Both answers are correct; it's a matter of how David and I are
interpreting your question.
David is talking about using classic PGP 2.6-style ClassicPGP keys to
encrypt OpenPGP traffic.  This answer is correct.  You can use
ClassicPGP keys in an OpenPGP environment if both parties are using a
newer version of GnuPG/PGP.
I'm talking about using classic PGP 2.6-style ClassicPGP keys to encrypt
ClassicPGP traffic.  AFAIK, this answer is correct; GnuPG was never
meant to be a conformant ClassicPGP application.  (It's possible that
things have changed in the GnuPG codebase since the last time I looked
at this, though.)
The short version is that David read your message as "can GnuPG be used
to process OpenPGP traffic while using ClassicPGP keys", and I read it
as "can GnuPG be used to process ClassicPGP traffic, using ClassicPGP keys".

@_date: 2008-09-17 17:24:45
@_author: Robert J. Hansen 
@_subject: Changing preferences 
You saw the answer yesterday.
'showpref' is horribly misnamed.  You are advertising your cryptographic
capabilities far more than you are specifying a preference in algorithms.
The way GnuPG picks algorithms is simple.  Walk down through the
_sender's_ preference list.  Find the first algorithm that's listed on
the recipient's _capability_ list.  Use that algorithm.

@_date: 2008-09-18 05:00:42
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Right, but where is this preference actually used?  personal-*-prefs
seems to rule the roost.
Given how often this question ("why is it that updating my key prefs
doesn't change what ciphers I use?") appears on this and other lists,
it's a fair bet that it needs to be looked at again.  It seems to be one
of the most, if not the most, misunderstood feature in GnuPG.

@_date: 2008-09-18 17:30:07
@_author: Robert J. Hansen 
@_subject: Changing preferences 
If AES256 is listed first in personal-cipher-preferences, it doesn't
matter if AES256 is listed first in the recipient's keyprefs or last;
AES256 is what will be chosen.
Since the ordering of the recipient's keyprefs have absolutely no effect
on the ultimate selection of the algorithm, it seems pretty clear to me
we're talking about a capability set as opposed to a preference list.
Preferences are ranked lists; in the absence of that ranking, all we're
talking about is an unranked set of acceptable algorithms.
Unless, of course, I have completely misunderstood how GnuPG selects
algorithms.  Which is always a possibility.

@_date: 2008-09-21 22:57:38
@_author: Robert J. Hansen 
@_subject: Changing preferences 
No, but they may be operating on the assumption their preference list
matters.  (Which it very often doesn't; encrypting-to-self and another
recipient means there's a 50/50 chance their preference list will be
treated as a cap set.  It would appear this ought to be made clear in
the docs.)
GnuPG's preference lists are arcane and counterintuitive, and the source
of a great deal of frustration.  If it would help to get some
documentation written outlining precisely how it works and why, I would
be happy to stop the bikeshedding and actually write it up.

@_date: 2008-09-22 02:37:17
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Imagine a group of people are going to the movies.
"I'd like to see either _Iron Man_, _The Incredible Hulk_, or _The Dark
Compare to:
"I'd like to see _The Incredible Hulk_.  If that's not possible, I'd
like to see _The Dark Knight_.  If neither of them are possible, I'd
like to see _Iron Man_."
The first one says "I'd like to see any of these movies and I don't care
which we choose."  This is a capability set.
The second one says "while I'll watch any of them, I would prefer _The
Incredible Hulk_."  This is a preference list.
In mathematics, a 'set' is usually thought of as a grouping of objects
without regard to order.  A 'list' is usually thought of as a grouping
of objects in a particular order.  This is why we talk about capability
sets and preference lists.
Much of the time, GnuPG will treat key's preference list like a
capability set.

@_date: 2008-09-22 02:47:30
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Remove the option.
Seriously.  I think key preferences ought to be considered analogous to
"--cipher-algo": you can tweak them if you want, but it's not
recommended and should be hidden from the user by default.  If a user
uses the --expert flag while --edit-keying, then present it.  Otherwise,
make an executive decision on a reasonable preference set and be done
with it.

@_date: 2008-09-23 04:50:06
@_author: Robert J. Hansen 
@_subject: [admin] Out of disk space problem solved 
Over the last day, I have received a large number of emails related to
this.  Some of them were nice.  Some of them were not.
It has always bothered me to be blamed for things over which I have no
control.  So, to those who didn't ask me about it, and to those who
asked nicely -- thank you.  To those who were being rude, well -- I hope
you have a nice day.
Also, a thank-you for Werner is appropriate.  This list has been going
strong for many years now with very few problems.  There is nothing
quite like a glitch to show you how much you appreciate years of
reliable service.
So -- thank you, Werner.  :)

@_date: 2008-09-22 05:42:20
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Apologies for the multiple send.  I had a network bounce (or three)
while sending this; apparently, Thunderbird wasn't able to register that
the message had gone through.

@_date: 2008-09-23 16:20:55
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Nope!  There's no need to update your keyrings.  This affects GnuPG's
executable code only -- there are no changes needed to your gpg.conf,
nor any key refreshes that need to occur.

@_date: 2008-09-23 21:33:12
@_author: Robert J. Hansen 
@_subject: Suspect Signatures 
A lot of people disagree with me on this, but so far nobody's been able
to come up with a compelling logical argument why I'm wrong -- the
objections are rooted much more in what people _want_ to be true than
what's actually true.
This is true: only correct signatures from valid keys belonging to
trusted individuals are meaningful.  Everything else is just line noise.
So why should you care if there are signatures on your key from people
you don't know or don't trust?  It's not as if you trust this person.
And if other people want to trust that person, is it really any of your
business to say "no, no, you're wrong, this person can't be trusted"?

@_date: 2008-09-23 21:37:02
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Borda counting.
Once you've gone off and read that, come back and read the rest of this
message.  It will probably not make much sense until/unless you do.
This is a message I sent to David early this morning as a test of the
new algorithm selection code.
Prefs are given here in shorthand: A3-A1 for AES256-128, C for CAST5, B
for Blowfish, T for Twofish, I for IDEA, D for 3DES.  Hashes are S5-S1
for SHA512-SHA1, M for MD5, R for RIPEMD160.  Compression is B, U, ZLIB
and ZIP.  Default prefs will be explicitly shown if not already listed,
if only to make the Borda count easier.
1.  KEY PREFERENCES.
Key ID          Cipher Pref         Hash Pref        Comp Pref
           1  2  3  4  5  6 7 8   1  2  3  4  5   1    2 3    4
0xE33B60D8 A1 T  C  B  D          R  S1           ZLIB Z U
0xFA92497C A1 T  C  B  D          R  S1           ZLIB Z U
0x7E70793D C  D  I  T             S1              Z    U
0xF34F9073 A3 A2 A1 C  D          S1 R            ZLIB Z U
0x3BCA7DD2 A3 T  A2 D  A1 C I B   S1              Z    U
0xD6B98E10 B  D  A3 A2 A1 C I     S3 S5 S4 S2 S1  B    Z ZLIB U
0xFEAF8109 B  D  A3 A2 A1 C I     S3 S5 S4 S2 S1  B    Z ZLIB U
2.  BORDA COUNTS
A1: 1 + 1 + 0 + 3 + 5 + 5 + 5 = 20
A2: 0 + 0 + 0 + 2 + 3 + 4 + 4 = 13
A3: 0 + 0 + 0 + 1 + 1 + 3 + 3 = 8
C:  3 + 3 + 1 + 4 + 6 + 6 + 6 = 29
B:  4 + 4 + 0 + 0 + 8 + 1 + 1 = 18
T:  2 + 2 + 4 + 0 + 2 + 0 + 0 = 10
I:  0 + 0 + 3 + 0 + 7 + 7 + 7 = 24
D:  5 + 5 + 2 + 5 + 4 + 2 + 2 = 25
S5: 0 + 0 + 0 + 0 + 0 + 2 + 2 = 4
S4: 0 + 0 + 0 + 0 + 0 + 3 + 3 = 6
S3: 0 + 0 + 0 + 0 + 0 + 1 + 1 = 2
S2: 0 + 0 + 0 + 0 + 0 + 4 + 4 = 8
S1: 2 + 2 + 1 + 1 + 1 + 5 + 5 = 17
M:  0 + 0 + 0 + 0 + 0 + 0 + 0 = 0
R:  1 + 1 + 0 + 2 + 0 + 0 + 0 = 4
ZL: 1 + 1 + 0 + 1 + 0 + 3 + 3 = 9
Z:  2 + 2 + 1 + 2 + 1 + 2 + 2 = 12
B:  0 + 0 + 0 + 0 + 0 + 1 + 1 = 2
U:  3 + 3 + 2 + 3 + 2 + 4 + 4 = 21
3.  ALLOWABLE ALGORITHMS
Sym intersect:  CAST5 (29 votes), 3DES (25 votes)
Hash intersect: SHA1 (17 votes)
Comp intersect: ZIP (12 votes), UNCOMPRESSED (21 votes)
4.  ALGORITHM SELECTION
Resulting message should be symmetrically encrypted with 3DES, signed
with SHA1 if possible for the signing keys, and compressed with ZIP.
5.  EXPERIMENTAL TEST
(Note that my gpg.conf file explicitly lists local-user D6B98E10 and
local-user FEAF8109, hence my omitting them from the command line here.)
job:gnupg-1.4.9 rjh$ gpg --armor --sign --recipient E33B60D8 --recipient
FA92497C --recipient 7E70793D --recipient F34F9073 --recipient 3BCA7DD2
--recipient D6B98E10 --recipient FEAF8109 --encrypt COPYING
job:gnupg-1.4.9 rjh$ gpg -vvvv COPYING.asc
[much irrelevant stuff snipped]
gpg: 3DES encrypted data
:compressed packet: algo=1
gpg: binary signature, digest algorithm SHA224
gpg: binary signature, digest algorithm SHA1
6.  CONCLUSION
It would appear the code is successful, at least in this example.

@_date: 2008-09-23 21:48:36
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Not to ask a dunce question here, but why not?
It's perfectly safe.  In fact, 3DES is probably the most trustworthy
algorithm on this list.  A few years ago when Schneier was asked for his
pick for "most trusted encryption algorithm," he said something like
"3DES.  Nothing else even comes close."  Sure, use AES for new crypto
software, but if you absolutely _must_ have the most overdesigned,
overbuilt thing out there...
It's been subjected to withering cryptanalysis for coming up on 30 years
now.  It's one of the standard ciphers graduate students are exposed to
in cryptography/cryptanalysis courses.  It has turned a generation of
brilliant young graduate students into burned out alcoholic wrecks.  I
have participated in bar crawls after getting beaten by 3DES.
It is big, clumsy, ungainly and slow.  It has all the aesthetic values
of the Soviet Realism school of art, and processes data about as fast as
a snail coming off a three-day scopolamine trip.
And it is still beating up every cryptanalyst out there and stealing
their lunch money.
If you don't like 3DES because it's slow, okay, fine, I can respect
that.  But objecting to "let's do it three times" is nonsense.  Do you
object to Blowfish because it does it does it 16 times?

@_date: 2008-09-23 22:22:35
@_author: Robert J. Hansen 
@_subject: Changing preferences 
PGP can read Blowfish traffic.  It won't generate Blowfish traffic, but
that's a separate issue.
No, Schneier has recommended people abandon Twofish and move to AES.
A lot of people are still quite fond of Blowfish.  It's a beautifully
simple algorithm, quite elegant, and well-studied.  I have a personal
liking for it just for its simplicity.
The all time best advice re: preferences is "unless you know what you're
doing and why, stick with the defaults."  The defaults work just fine
for the overwhelming majority of users.  Maybe one user in a thousand
will ever need to tweak them.
Names.  Definitely names.  Much less chance of screwing them up and
accidentally doing something like preferring SHA1 over SHA256.

@_date: 2008-09-24 01:04:56
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Theoretically?  None.  Practically?  None yet.  If/when the longer SHAs
are subjected to cryptanalytic attack, "none yet" will change to
"expected soon" before becoming "switch to WHIRLPOOL."
Well, not technically, no, but there's no point in using SHA512 with an
RSA key.  According to NIST, a 4kbit RSA key is roughly equivalent in
brute force resistance to a 168-bit symmetric key.  The rule of thumb
with hashes is to use twice as many bits as there are in your symmetric
key, so a 4096-bit RSA key only needs SHA384.  Past that you're just
putting lipstick on the pig.
(To say nothing of 4kbit keys in and of themselves, which strike me as
being more technofetishism than a measured response to the current state
of the art in cryptanalysis.  But ignore me or else I'll start ranting
I can count on my fingers the number of people I would trust to make any
kind of authoritative statements re: DSA versus RSA.  None of them are
on this list.  Discussing relative strengths and weaknesses of the two
is a spectacularly black art, and unless your name is Adi Shamir or
Taher Elgamal you probably don't know as much as you think you do.
I am _definitely_ included in the ranks of the people who don't know as
much as they think they do when it comes to this.  They are both far,
far stronger than people need them to be; that's all I feel comfortable

@_date: 2008-09-24 01:16:07
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Add this to the list of things Wikipedia has screwed up.
Schneier has repeatedly advocated for AES.  Go read his _Practical
Cryptography_ and see what he says about Twofish, and see what he says
about AES.  I give a lot more weight to his professional writing than an
interview with a journalist -- who knows what got edited out?
Schneier may have, in that interview, meant to say "if people really
like Blowfish, I recommend they look at Twofish, but really, there's no
reason not to use AES."
He could have misspoken; he could have been quoted out of context.  All
that can really be said is that such a sentiment is totally at odds with
what he's said in other venues.
No, a lot of people recommend moving to AES.  If you were to ask me "so,
what algorithm should I use?", I'd tell you the two reasonable choices
were 3DES and AES.
I like Blowfish.  That's an emotional reaction to an algorithm.  The
fact I like Blowfish is totally irrational; really, I ought to use AES
or 3DES.  In fact, the rational part of me says Blowfish really ought to
be dropped from OpenPGP implementations entirely, along with Twofish,
and CAST5 ought to be considered legacy support and read-only.
But I still like Blowfish.  What can I say?  I'm a human being.  I'm
allowed to occasionally be sentimental.  Just don't mistake
sentimentality for sound reasoning.

@_date: 2008-09-24 01:54:11
@_author: Robert J. Hansen 
@_subject: Changing preferences 
False premise.  DES works every bit as well as we expect.  Even today,
the best attack against DES is brute force.
This is historical provincialism.
This is like condemning Einsteinian relativity because Einstein didn't
foresee closed timelike curves, or GPS satellites, or the laser, or how
his theory would ultimately give the first convincing explanation of why
gold has such a lustrous shine.
"The thing I dislike about the relativistic study of the electron shells
in a gold atom is that relativity was not designed to be used that way.
 It's about large systems!"
If you make a groundbreaking advance in any field, that advance will in
turn open the door to new advances which will build on your original
idea.  DES made us consider group theory; we then discovered "hey, you
can chain them together!"; now we do it.  Where's the problem?
It's not a patched DES.  Not in the sense that you're thinking of it.
Tiger-192, which some people on this list love, has two quite different
versions associated with it.
Blowfish had a sign extension error in its first printing.
SHA-1 is a patched SHA-0.  SHA-0 was essentially a patched MD5.  MD5 was
 essentially a patched MD4.  RIPEMD-160 is a patched RIPEMD.
GnuPG itself is built one patch at a time.

@_date: 2008-09-24 09:14:39
@_author: Robert J. Hansen 
@_subject: Changing preferences 
I don't have any problem with people having their own personal likes and
dislikes.  I like Blowfish; I use it, although I don't recommend it to
I have a _big_ problem with people arguing that their personal
prejudices are actually reasonable conclusions to draw.  Like Mark Twain
said, "a lie can be halfway around the world before truth has pulled its
boots on."  In the internet era it's even faster.
When people who sound like they know what they're talking about say
things that are not factually true, newbies remember the sound bites a
lot more than the facts.  The facts: 3DES is ugly, slow, and the most
trusted cipher in the OpenPGP arsenal.  But from the way you're talking
about it, it's a nightmare of engineering rather than a triumph.  Which
do you think the newbie will remember?  Which do you think they _should_
What disadvantages?  It's slow.  That's irrelevant for most OpenPGP usage.
Also, if you really want to call Don Coppersmith and the rest of the DES
design team 'lazy,' well, go ahead, but expect a lot of people to look
at you funny.  Don Coppersmith is widely considered to be one of the
brightest cryppies ever -- he ranks up there with Abraham Sinkov.
That opinion puts you in an enormous minority.
And when you look at the Roman Coliseum, do you think "gee, they really
overengineered that, the design must be lazy and shoddy, and this
doesn't look anything like an I.M. Pei or a Frank Lloyd Wright design,
it's ugly"?
The fact is that the surviving buildings of antiquity have taught us a
great deal about engineering.  They are still deserving of respect, not
to be written off as sloppy and aesthetically unpleasing work.
In DES and 3DES's case, this is almost exactly what we're talking about.
 DES was the cipher that allowed us to discover differential
cryptanalysis, for instance.  Essentially every single attack that's
been devised in the last thirty years was first tested on DES and
discovered not to work.  Then they went to apply it to FEAL, MacGuffin,
or any of dozens of other ciphers, and watched it destroy them.
Both are correct.
3DES is an application of a cryptographic theory which did not exist
prior to DES.
3DES is built using DES as a building block.
Yes.  Just like 3DES.

@_date: 2008-09-24 09:19:27
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Arguably true.
Purely historical reasons.  Also, the SERPENT design team, much like the
Twofish design team, is strongly pushing abandoning the AES also-rans
and using AES.
A lot of people think CAST5's selection as PGP 5's encryption algorithm
was a mistake, given the ready availability of 3DES.  CAST5 is also not
very well known or well liked outside of OpenPGP.  Schneier, for
instance, has said "I give a big 'yuck!' to the design process."  (Some
people think this is because CAST5 is very similar to Blowfish and
Schneier is feeling protective of his own algorithm, however.)

@_date: 2008-09-24 11:38:48
@_author: Robert J. Hansen 
@_subject: Changing preferences 
Insufficient love.
Nobody needs SERPENT, Twofish or Blowfish, so there's a strong
evolutionary pressure to either not include them or axe them from the
spec.  (Tiger-192 fell out of the spec the same way.)
People in the Pacific Rim need Camellia, since it's part of Pac Rim
governmental standards.  Thus, there's love, and people pushing to
include it.

@_date: 2008-09-25 01:32:01
@_author: Robert J. Hansen 
@_subject: Changing preferences 
It should be noted the MitM requires more memory than exists in the
world, with more chosen plaintexts than have ever been encrypted with DES.
If you're assuming the attacker has literally global computational
resources and can make you send petabytes upon petabytes of chosen
plaintexts without you ever changing your encryption key, then yes, it
has an effective 112 bits of entropy.  If those assumptions don't hold,
then you're up to 168 again.

@_date: 2008-09-25 11:09:46
@_author: Robert J. Hansen 
@_subject: Malware targeting GnuPG/PGP Keyrings 
Maarten Van Horenbeeck of the SANS Internet Storm Center delivered a
fascinating presentation at this year's SANSFire.  "Is Troy Burning? An
overview of targeted trojan attacks."  (It was a few months ago, but I
just now got a copy of the slides.)
According to Van Horenbeeck, we are now seeing trojans in the wild which
are searching for PGP keyrings, intercepting passphrases, and sending
the whole mess off elsewhere.  The particular one he used in his
presentation was flagged as malware by:
Sophos 4.27
VirusBuster 4.3.26
... Everything else -- AVG, ClamAV, F-Prot, F-Secure, McAfee, Panda,
Symantec, etc. -- gave it a clean bill of health.  (This doesn't
surprise me very much; generally speaking, antivirus software is wildly
overestimated in its ability to keep you safe.)
At present, it does not seem to target GnuPG keyrings.  It seems like
such an obvious and trivial extension, though, that it would be prudent
to assume it already exists.
Please do not panic.  This is not a "the world is on fire!" post.  It's
been common knowledge for years that these sorts of attacks were
possible and it was a matter of time until we saw real-world examples.
All I'm saying is that we're now at that time.

@_date: 2008-09-25 15:56:25
@_author: Robert J. Hansen 
@_subject: Malware targeting GnuPG/PGP Keyrings 
I would imagine the author thinks people with keyrings are high-value
targets, who will be putting high-value secrets in encrypted mails.  But
that's just a guess on my part.

@_date: 2009-04-14 08:01:39
@_author: Robert J. Hansen 
@_subject: Help Solicited to implement a new pgp key server 
Peter asked an excellent question: "Is there a reason why you can't use
any of the existing keyserver software?"
You may find it useful to try answering it.  You may learn that you
don't need to write one in the first place.

@_date: 2009-04-14 23:45:52
@_author: Robert J. Hansen 
@_subject: Upgrade from GnuPG 1.4.5 to 1.4.9 breaks signature verification 
IIRC, it was regarding John Moore's signatures failing to verify under
PGP 8.x.  This was due to John using SHA512 as a signature algorithm,
and PGP 8.x not supporting that algorithm.
As David says, PGP 6.x is long in the tooth.  It's a decade old at this
point -- more; I think it came out in '98.  IMO, it ought be abandoned
for security reasons.
It was written in '97-'98.  That means it predates even Windows 98.
Windows has changed /enormously/ since then.  Neither Network Associates
nor PGP Corporation ever certified PGP 6.x for use on Windows 2000
machines, and now that we've seen XP come and go, are seeing Vista get
deployed, and have Windows 7 on the way...
... well.
You have to ask some questions.  What are the odds that something PGP
6.x depends upon will have changed in some subtle way over the last ten
years?  And do you really want to take that risk?

@_date: 2009-04-15 08:43:20
@_author: Robert J. Hansen 
@_subject: Keyserver doesn't honour removed signatures 
... that's a truly /ghastly/ little attack against the keyserver  network, and I'm ashamed that I didn't think of it first.
The keyserver network is principally guided by this design goal: do  not ever lose key material.  New data may be entered, but old data  must persist.  Now, if a photo is attached to a key and the photo must  be removed for legal reasons, one of three things will occur:
(a) the keyserver network gets taken down
(b) the keyserver network gets taken over by people trafficking in  illegal images
(c) a way to remove UIDs without the owner's permission is added to  the keyserver network
I don't really like those prospects.  Any of them.
This message was sent using IMP, the Internet Messaging Program.

@_date: 2009-04-16 10:12:39
@_author: Robert J. Hansen 
@_subject: Keyserver doesn't honour removed signatures 
Quoting David Shaw :
I think it's also worth considering just how rare USENET is nowadays.   A lot of places that used to host full USENET feeds are gone.  I  suspect that most people's access to USENET is done through Google  Groups or similar services.
 From what I understand, the two major concerns which led to USENET  being dropped in a lot of places are (a) bandwidth concerns and (b)  the possibility of lawsuits.
(Not just child porn, either: some things that are clearly legal in  one jurisdiction are grossly illegal in another.  E.g., in the United  States the First Amendment protects your right to deny the Holocaust,  but in Germany it's a serious crime.)
Add it all together and USENET was at best a network-choking bandwidth  hog, and at worst was a lawsuit waiting to happen.  And thus, many  full USENET feeds fell off the face of the net.
It might be worth wondering whether the same could happen to the  keyserver network.  It seems less likely, due to how difficult it  would be to share large files that way -- but the possibility should  be considered.
This message was sent using IMP, the Internet Messaging Program.

@_date: 2009-04-18 11:33:36
@_author: Robert J. Hansen 
@_subject: keyservers 
PGP's server doesn't sync.
And broken.  It doesn't play nice with modern keys.

@_date: 2009-04-18 12:03:27
@_author: Robert J. Hansen 
@_subject: keyservers 
gpg --keyserver x-hkp://pool.sks.keyservers.net --recv-key [keyID]

@_date: 2009-04-20 19:08:11
@_author: Robert J. Hansen 
@_subject: OpenPGP digital signature query 
I'll go one step further: asking this query on an internet mailing list
could itself be seen as failure to exercise due care.  You don't know
any of us here and cannot vouch for anyone's legal or technological
acumen.  As far as due diligence is concerned, asking here -- instead of
asking lawyers and security consultants -- is pretty much reckless

@_date: 2009-04-20 22:07:42
@_author: Robert J. Hansen 
@_subject: OpenPGP digital signature query 
"Is it true that you chose as a first source of information a mailing
list where you did not know the people who were responding, nor their
credentials, nor their professional expertise, and none of whom bore any
responsibility for the accuracy of their answers?"
I have a lot of respect for the abilities of attorneys to spin things
all around.

@_date: 2009-04-21 07:38:39
@_author: Robert J. Hansen 
@_subject: OpenPGP digital signature query 
The correct answer is "yes".  On cross-examination you're not allowed to
give exposition.  So now you've just admitted that your first resource,
the group you went to first rather than talking to an attorney, is a
group that would fail to meet the standards of the law -- and from that,
the lawyer argues your pattern of behavior has been similarly slipshod,
etc., etc.
This is a statement about we wish was true about the world, not what is
actually true about the world.  Walking up to one's boss and asking, "so
why did you screw up this project so badly, and why did you ignore all
of our warnings of impending doom, and when are you going to turn around
your managerial style?" is the sort of thing that tends to lead to
conversations about unemployment benefits.
I agree with you that questions can and should be answered in a
dispassionate manner.  I just disagree about that being the way the
world actually _is_.

@_date: 2009-04-24 07:50:23
@_author: Robert J. Hansen 
@_subject: DH/DSS vs ElGame/DSS? 
I don't know how it's used in the S/MIME standard.  However, the Elgamal
encryption algorithm is often misnamed the Diffie-Hellman encryption
The DH key exchange algorithm (DHKEA) came first, way back in the '70s.
 Then an Egyptian-American named Taher Elgamal did some groundbreaking
work in generalizing DHKEA, discovering the mathematical roots of why it
worked as well as it does, and in the process developed a whole family
of algorithms.  This family is often called the "Elgamal family."  He
also developed the Elgamal encryption and signing algorithms.
It is my understanding that the correct name for what OpenPGP uses is
the Elgamal encryption algorithm.  I don't know why PGP Corporation
calls it Diffie-Hellman encryption; it seems to be an idiosyncratic usage.

@_date: 2009-04-24 12:29:37
@_author: Robert J. Hansen 
@_subject: DH/DSS vs ElGame/DSS? 
Many people think Cylink has a history of regrettably close cooperation
with the NSA.  Some people consider their products to be suspect as a
result of this.  Given that, it should be pointed out that PGP
Corporation was licensing the algorithm, not the implementation.  PGP
and GnuPG both use their own independent implementations of the algorithm.
I'm not sure how much faith I put in the Cylink/NSA connection, but I
know that some do.  If you're one of them, you can rest easy.  :)

@_date: 2009-04-24 14:47:26
@_author: Robert J. Hansen 
@_subject: Help with encrypting using my PGP Public key 
This depends on how you use it.  From the perspective of OpenPGP,
everything's a file.  An email message is just a file you send over the
internet via the SMTP protocol.
There is an enormous difference in how you use GnuPG for email versus
how you use it for file storage.  For instance, the Enigmail extension
for Thunderbird lets you use GnuPG in email in a fairly straightforward
fashion.  If you get used to using GnuPG that way, it might be a rude
shock to you when you have to use GnuPG at the command line to encrypt a
file.  This is why I say it depends on how you use it.

@_date: 2009-04-24 17:06:05
@_author: Robert J. Hansen 
@_subject: DH/DSS vs ElGame/DSS? 
Absolutely true.  That said, very few directors of the NSA have gone on
to become CEOs of telephone companies.  William P. Crowell served as DDO
and Deputy Director for the NSA up until he joined Cylink in '98.
He's hardly the only senior NSA type to join Cylink.  When you see that
kind of personnel crossover between the companies, it makes people a
little more nervous than they are about dealing with, say, IBM (which
has had a lot of NSA contacts, too).

@_date: 2009-04-25 09:45:27
@_author: Robert J. Hansen 
@_subject: --encrypt-to usage 
There is a lot of very bad advice out there.  This idea is an example of it.
The more people who know a secret, the more likely it is that secret
will get out.  That's a weakness in human beings, not a weakness in the
So long as you trust that your correspondents are using GnuPG safely and
correctly, and you trust they're not working with your enemies, use
--encrypt-to with confidence.

@_date: 2009-04-25 10:50:53
@_author: Robert J. Hansen 
@_subject: Troubleshooting signatures 
Can't answer re: FireGPG.  However, this is _a_ normal reaction, but not
_the_ normal reaction.
If you got a signature that purported to be from obama at whitehouse.gov,
and it was signed with a key that purported to be from
obama at whitehouse.gov, would you actually believe it was from President
Obama?  Or would you say, "wait a minute, /anyone/ can pretend to be
believe the President is sending me an email"?
That's what GnuPG is warning you about.  There is no evidence the key
really belongs to the person it claims to whom it claims to belong.
Maybe it does, maybe it doesn't, there's no evidence either way.

@_date: 2009-04-25 15:27:26
@_author: Robert J. Hansen 
@_subject: certificate chain depth 
Honestly, it's a little of one and a lot of the other.  The questions of
"whom do I trust and why?" is purely a human factor; the questions of
"... and given I trust them, what can I deduce to be true?" is a
mathematical question.
Generally, trust is the ability to break someone's security policy.
E.g., I've given a friend of mine from college, John Hawley, a trusted
signature.  John can now screw over my local security policy.  If I see
a key which John has signed, I'm going to assume that key is valid.  If
John signs keys that aren't valid, he can break my security policy.
This is why most uses of the phrase "trusted system" give security geeks
the heebie-jeebies.  A trusted system is, ironically, more dangerous
than an untrusted system.  An untrusted system has no capability to
break your security policy; a trusted system can.  That means trusted
systems often need to be watched like hawks.
In a similar vein, many Wall Street brokers were trusted with billions
of client money -- and they should have been watched closely as a result
of that trust.

@_date: 2009-04-25 17:22:25
@_author: Robert J. Hansen 
@_subject: Just a thought 
Yes, although if you want Enigmail-specific answers you may want to ask
on the Enigmail list.

@_date: 2009-04-25 17:45:26
@_author: Robert J. Hansen 
@_subject: certificate chain depth 
This is why signatures can be revoked.
Really?  You already have.  For instance, do you have the capability,
right here, right now, to grow or obtain your own food?  If not, then
you're trusting in your local food distribution system.  If it goes out,
then you're in a world of hurt.  Do you have the capability to obtain
potable water?  If not, then you're trusting your water system.
The question is not _if_ you trust, but _who and what_ you trust, and
whether that trust will be a blind trust or an examined trust.  Blind
trust tends to get people in a lot of trouble; examined trust lets you
prepare for what happens if and when that trust is breached.
There's a reason why I have three days of MREs and ten liters of
drinking water in my pantry.  I trust food distribution and I trust my
water system.  And it's because of that trust that I have backups.
On balance, I think it is better to practice examined trust than
unexamined trust.  But that said... I am an advocate of trust.
Compromise means you have failed to uphold your publicly stated policy.
 If people are able to put you in a position where you have to
compromise your policy, that should be the cause for some soul-searching
about where you erred in your policy.
If your policy is, "I will divulge communications if required to by a
court, or if necessary to prevent lawless action, or to save human
life," and you go out and do just that -- that's not a compromise at all.
If by "secure" you mean "my system is not compromisable and my
communications cannot be intercepted," then none of us are secure.  None
of us are even fairly secure by that standard.
Generally speaking, GnuPG gives excellent protection against one
particular part of the communications security profile.  It is not a
comprehensive solution.
If my system is secure and my communications are uncompromised, it is
only because I have not yet risen to the notice of those who have the
power to change it, while I have simultaneously put myself beyond the
likely reach of amateurs.
To the extent there is a "fairly secure" worth talking about, that's it.
IMO, that's not "fairly secure" at all.  It's best to keep a sense of
proportion about these things, and not to fall into a false sense of

@_date: 2009-04-25 17:59:31
@_author: Robert J. Hansen 
@_subject: Just a thought 
Someone else may have a more definitive answer, but I would not
recommend using bcc'd recipients with Enigmail.  Enigmail is constrained
by the Thunderbird architecture, which puts some severe limits on what
Enigmail is allowed to do.  As long as everything is done in one pass
and it's a simple transform of the data, Thunderbird is quite happy to
work with plugins; but as soon as plugins want to do complex things,
Thunderbird says "no."
E.g., with PGP/MIME messages, Enigmail has to go through some
contortions since it doesn't know before the message is composed which
hash algorithm will be used, meaning that it can't craft the PGP/MIME
headers.  So instead, a dummy message is sent (one which goes precisely
nowhere), which Enigmail then reads to see the algorithm used, which is
then used to construct a proper PGP/MIME header for the real message.
It's a pretty repulsive hack, but it's the only game in town.
Please note that I do not follow the Enigmail source tree, so any and/or
all of this may be incorrect.  It is correct as far as I know, though.
This discussion should probably be moved to the Enigmail list.

@_date: 2009-04-28 22:37:55
@_author: Robert J. Hansen 
@_subject: Subkeys... 
Revoking the subkey is the canonical solution here.

@_date: 2009-04-29 16:48:31
@_author: Robert J. Hansen 
@_subject: compatible? GnuPG & PGP 6.5.8 
Yes, but it's generally easier to go the other way around.  You'll find
that route to be much easier.
Most people in the OpenPGP community will strongly advise you against
using PGP 6.5.8, for very good reasons.  I'm one of them.  :)

@_date: 2009-08-02 11:45:07
@_author: Robert J. Hansen 
@_subject: Help with downloading GnuPG 
People from both GnuPG and Enigmail hang out on this list.  We're very
happy to help you out with downloading and setting up GnuPG.  Welcome to
the community!
The Enigmail project has put together a Quick Start Guide which will
help you get started quickly with Enigmail:
If you have any Enigmail-specific questions, it would be best to ask on
the Enigmail mailing list:

@_date: 2009-08-13 09:59:45
@_author: Robert J. Hansen 
@_subject: Two convicted in U.K. for refusal to decrypt data 
Apparently I don't exist, then.  I have files which were last accessed
by me a year ago, for which I've forgotten the passphrases to the
symmetrically-encoded data.  It's just another example of people
forgetting what they rarely use.
I'm certain there are other people here in the same boat.

@_date: 2009-08-19 14:27:49
@_author: Robert J. Hansen 
@_subject: Practical Advice for those using AES256 cipher? 
To repeat my usual advice:  "Unless you know what you're doing and why,
stick with the defaults."
The AES256 attack does not change that advice.  The attack is incredibly
interesting in an abstract mathematical sense; in terms of the real
world it's not worth thinking twice about.

@_date: 2009-08-27 18:21:10
@_author: Robert J. Hansen 
@_subject: rotating encryption sub keys 
There almost certainly exist people for whom this is a good idea.  That
said, I've never met 'em.  It seems to be massive overkill.

@_date: 2009-08-28 10:06:38
@_author: Robert J. Hansen 
@_subject: rotating encryption sub keys 
Of course, this kind of defeats the entire purpose of perfect forward
secrecy by rotating your subkeys...

@_date: 2009-12-10 11:54:20
@_author: Robert J. Hansen 
@_subject: Secret Key Needed and Location on Mac Leopard 
It will be in a folder called ".gnupg".  By default, this folder will
not appear in Finder.  Once you're in .gnupg, then copy "secring.gpg"
and "pubring.gpg" over to your new machine.  Presto, you're done.  :)

@_date: 2009-12-15 14:53:19
@_author: Robert J. Hansen 
@_subject: Code for javagnupg? 
In 2005, Stefan Richter announced some JNI bindings (Java Native
Interface) for GPGME, which he called javagnupg.  A very early alpha
version of this was uploaded to ftp.gnupg.org, where it's lived in the
alpha directory ever since.
As it turns out, I need JNI bindings for GnuPG.  Rather than start over
from scratch I thought I'd take a look 0.1.2 codebase and
see how much work it would take to bring it up to current standards.
I was surprised to discover there is no code in the jarfile that Stefan
contributed.  It's .class files only, along with some documentation, but
nothing that seems to actually be compilable code.
Does anyone have access to the code for javagnupg 0.1.2?  If so, please
send it on to me.

@_date: 2009-12-15 18:05:45
@_author: Robert J. Hansen 
@_subject: The number of lines of a key opened in a text-editor 
The only stupid questions are the ones that don't get asked.  :)
2048 bits, only 512 bytes.
A "public key" usually has a lot more data than just the key material.
User IDs and signatures are usually present, too.  Some users even
include a JPEG of themselves in their key.
Nope.  :)

@_date: 2009-12-15 18:52:48
@_author: Robert J. Hansen 
@_subject: The number of lines of a key opened in a text-editor 
256 bytes.  Sorry.
[goes off to drink coffee directly from the pot: clearly, caffeine is

@_date: 2009-12-23 02:23:32
@_author: Robert J. Hansen 
@_subject: 'Tis the Season. 
Regardless of your personal beliefs or lack thereof, I think we can
broadly agree that this is a good time of the year to reflect on the
year, what's happened in it, what good fortune we've had and our hopes
for the future.
As with many previous years, I feel that it's been our good fortune to
have GnuPG and an active, involved community.  A lot of people volunteer
their time, effort and knowledge to help people out, to develop new
code, to provide new translations, to... the list of contributors to
GnuPG is legion, and I'm grateful for every single one.
So, to the developers, to the testers, to the people who answer newbie
questions, to the people who generate signal and absorb noise, to the
people who advocate healthy paranoia, and to everyone who cares about
email privacy...
Thank you, deeply and sincerely, for all you've done in this last year.
 Please keep up the good work.  I appreciate it more than you know.
Rather than donate to GnuPG directly -- which, for a lot of reasons, is
really hard to do: how do you decide who should get how much of the
donation? -- I'm making a donation to the EFF this year, since they're a
charitable organization that seems to be very much in line with GnuPG's
goals.  If you're interested in doing likewise, you can donate on-line at:
Just click the big red "Donate" button.  :)

@_date: 2009-12-29 14:10:05
@_author: Robert J. Hansen 
@_subject: PGP encrypt/GnuPG decrypt problem 
The answer to this one is, "it depends."
Really old versions of PGP will have trouble interoperating with new
versions of GnuPG.  Newer versions of PGP interoperate well.

@_date: 2009-02-03 08:21:24
@_author: Robert J. Hansen 
@_subject: Keyserver question...again 
Friends don't let friends use pgp.mit.edu.  It is irreparably broken for
modern OpenPGP keys.

@_date: 2009-02-06 13:19:31
@_author: Robert J. Hansen 
@_subject: What do if forgot password? 
The original poster made it clear he has forgotten his passphrase.
When people are asked to find a "secure and secret" place, they
typically do it very badly due to a lack of experience.
When an investigator looks for your "secure and secret" place, the
investigator typically does fairly well due to having a lot of experience.
You have much better options available to you.  For instance, put it in
a sealed envelope and give it to your lawyer.  Tell your lawyer, "this
is a very important document and must be kept safe."  It is very likely
that your lawyer will have lots of experience at this and be much better
at it than you are.

@_date: 2009-02-06 18:30:16
@_author: Robert J. Hansen 
@_subject: What do if forgot password? 
I try not to join Windows-bashing, IE-bashing, or whatever else.  I'd
much rather stand for something than tear something down.
Standards are good for the internet.  GnuPG and PGP interoperate as well
as they do because of the OpenPGP standard.  Windows and Linux machines
can interoperate on the same network because they each conform to the
TCP/IP standard.  And so on, and so on, and so on.
Standards are good for the internet.  My web pages strictly conform to a
nearly ten-year-old W3C standard.  I don't care what browser you use to
read them.
Often on this list we get questions about how to make PGP 6.5.8
interoperate with GnuPG.  The usual -- and good -- answer is, "PGP 6.5.8
isn't standards conformant, encourage them to get a better application."
Likewise, if your browser isn't standards conformant, you may want to
get a better browser.  :)

@_date: 2009-02-07 18:21:59
@_author: Robert J. Hansen 
@_subject: GPG - how to update keys to a new format? 
You are going to be better served by generating a new keypair.

@_date: 2009-02-09 01:07:51
@_author: Robert J. Hansen 
@_subject: enigmail and gnupg on linux xandros 
This is an Icedove and/or Xandros error.  It is not an Enigmail error.
For that reason, we're not able to help you out very much with it.  We
wish you luck with the reinstallation.  A lot of people report excellent
success installing plain-vanilla Ubuntu on netbooks; it might be worth a
shot as opposed to the highly customized Xandros you're currently running
We recommend reading the Enigmail Quick Start Guide.

@_date: 2009-02-10 13:18:22
@_author: Robert J. Hansen 
@_subject: paperkey  // ? feature request 
This seems to be a misapplication of asymmetric crypto.  Asymmetric
crypto is generally inappropriate for session keys.
Given the secret key, the public key can always be reconstructed.

@_date: 2009-02-10 16:44:01
@_author: Robert J. Hansen 
@_subject: paperkey  // ? feature request 
Right.  This is a use case for symmetric crypto.
So only someone with the private key can decrypt it.  Okay.  How do you
communicate the private key with your intended recipients?  And how is
communicating the private key with your intended recipients different
from the key distribution problem when using symmetric crypto?
USB tokens have GUIDs, Globally Unique Identifiers.  Computers keep
track of what GUIDs they've seen.  If the secret police get access to
the PC, then they know "ah, someone used GnuPG on a USB token, with a
GUID of...", etc.  That USB token can now be connected to you.
Okay, so the obvious tactic is to dispose of it.  But how?  Losing
and/or destroying things reliably is pretty hard.[1]  If you lose track
of your car keys for thirty seconds you'll spend a week finding them; if
you flush a USB token down the toilet a plumber will be called out five
minutes later to find out what's causing the clog.  Call it the spy's
version of Murphy's Law.
Digital forensics is the field which concerns itself with pulling
information you didn't believe existed out of places you didn't believe
it could be found.  Digital forensicists run the gamut from rank
amateurs to hardcore professionals who can recover a CD-R that's been
put through a crosscut shredder.[2]
DF is interesting stuff.  If you're serious about wanting to come up
with effective spy-versus-spy techniques, then I'd strongly recommend
reading up on DF.  The more you know about the capabilities of the
people who are trying to recover your secrets, the more you'll know
about how to make life difficult on them.
[1] I was recently told of a case where a mobster swallowed a micro-SD
card.  The mobster thought the stomach acids would destroy it.  The
authorities held onto him a few days, extracted the evidence when it
made its appearance, and discovered it worked just fine.
[2] I had sushi with a colleague of the guy who recovered the crosscut
CD-R.  They gave that task to him person specifically because of his
severe OCD.  The guy later said it was the happiest month he'd ever
worked: he was allowed to indulge his OCD for 16 hours a day and
everybody left him alone.

@_date: 2009-02-10 18:57:33
@_author: Robert J. Hansen 
@_subject: paperkey  // ? feature request 
The moral of the story is to (a) use the right tool for the job, and (b)
use the tool correctly.
I don't see how you can on the one hand assume that the person is going
to be technologically savvy enough to do all of this, and at the same
time dumb enough to use his mother's maiden name as a passphrase.
You may say "I'm not assuming he'll be dumb, I'm just allowing for the
possibility he will be" -- which is good, and it's a good maxim for
system design.  But making the system more complex (asymmetric crypto is
infamously complicated) in order to make the human factor simpler is a
bad tradeoff.  It's not a choice of system complexity or human
complexity.  Good protocol design reduces both; buying one at the
expense of the other is a bad idea.
"??????, ?????????.  The security footage says you were in this internet
cafe when this treasonous message was sent.  You were at the affected
PC.  You used a USB token.  And shortly afterwards your neighbors saw
you burning something in your backyard, but you didn't put the remains
in the trash.  We know, because we checked.  Would you come with us,
Present them with a fake USB token -- "We're sorry.  The GUID is
different.  Would you care to revise your story, or shall we just send
you to the gulag now for lying to investigators?"
If you're taking heat from serious opponents, you need to drop any
pretense about technology being your friend.  It's not.  If you're in a
serious heat situation, run away from anything with a battery.
The Digital Forensics Research Workshop has some great articles.  The
latest fad is memory analysis: subvert someone's laptop for 30 seconds
to make a dump of memory, then snarf it up and parse through the memory
image at your leisure.
Or consider a hibernation file.  When your laptop goes into hibernation
mode, your laptop copies its entire internal state to disk so that when
you open your laptop again it can pick up right where it left off.  That
hibernation file doesn't get deleted once the laptop is done with it.
Let's say you're storing data on a TrueCrypt container.  The police grab
your laptop.  They're foiled -- they don't have the password!  But then
they look through your hibernation file and find your password hiding
there in cleartext.
Yes, it's kind of impressive seeing this stuff done.  It's also
disturbing and frightening.
If you're interested in hibernation file analysis, the current hot guy
is a French college student named Matthieu Suiche.  He's done a lot of
great work and he's only something like 20 years old.  It's a very new
field and there's a lot of room for dedicated amateurs to make an
Read his papers -- they're very eye-opening.

@_date: 2009-02-10 19:25:55
@_author: Robert J. Hansen 
@_subject: paperkey  // ? feature request 
It's not a disposable session key if the recipients need to contact the
sender afterwards.  If you're assuming a high threat environment, you
kind of need to assume the sender got flipped right after sending the
Timothy McVeigh was tracked through his use of a prepaid calling card...
which he paid for with cash.
I don't know how the FBI and ATF did it, but I'm willing to bet they've
already taught an improved version of the technique to the next
generation of agents.
[shrugs]  Not really.  Consider the cost-benefit ratio for two common
things: military campaigns and child pornography.  Assume lab time costs
 $100/hr., which pays the DF's salary and equipment costs.  We're
looking at about $50,000 for 500 hours of work.
One soldier being grievously injured on the battlefield can cost the
Army easily $5 million in lifetime medical care.  $5 million versus
$50,000 is a 100:1 cost savings.
Consider child porn.  How much is it worth to take a child pornographer
off the street before he or she can exploit another kid?  $100,000?  2:1
cost savings.
How much is it worth to... etc., etc.
Divorce lawyers are getting into the swing of things, too.  I was once
paid to do some data recovery on a hard drive that was an issue in a
lawsuit.  The lawyer was laughing all the way to the bank: my fee paid
for itself many, _many_ times over.

@_date: 2009-02-10 21:40:22
@_author: Robert J. Hansen 
@_subject: paperkey  // ? feature request 
Thank you for the link -- I was going by my recollection of journalistic
coverage after the attack, but apparently either it or my memory was in

@_date: 2009-02-10 21:51:15
@_author: Robert J. Hansen 
@_subject: paperkey  // ? feature request 
Must be my luck, then -- the ones I've looked at have all had per-device
serial Yes and no, I think.  E.g., China's internet cafes are being pressured
heavily to use the government-approved Red Flag Linux.  There's also
been talk in the press about the Russian government pressuring internet
cafes to give "more complete cooperation with law enforcement", which
sounds like it could cover a whole host of badness.  On the other hand,
you have the very lax regulatory situation of the United States, where
that sort of pre-existing relationship is hard to imagine.
I'll ask about it shortly.  It's possible I'll get an answer of "yes, I
was there, I saw it, and no, I can't talk about it," though, in which
case I can't fault anyone for incredulity.

@_date: 2009-02-11 00:33:53
@_author: Robert J. Hansen 
@_subject: where to start? 
You've already done it.  :)  Welcome to the community!  You'll find
we're a pretty friendly bunch here.
I would start by asking whether you want things to "just work" or
whether you want to take a more direct hand in things.  The former
will... well... just work.  The latter will require a lot more work, but
I personally find it more rewarding.
That choice is the first fork in the road.
If you want to go down "just work," the best thing for you to do is use
S/MIME, the Secure Multipurpose Internet Mail Extensions.  If you want
to go down "learn a lot and have control," then I would suggest OpenPGP.
GnuPG supports both S/MIME and OpenPGP, so both are on-topic for this
mailing list.  Let us know what you want, and we'll be in a much better
position to offer you help.  :)

@_date: 2009-02-11 00:49:56
@_author: Robert J. Hansen 
@_subject: paperkey  // ? feature request 
That wasn't his problem.  That was, honestly, mostly irrelevant.
This was his problem: when you're trying to cover your tracks, there are
literally hundreds, if not thousands, of ways you can screw up.  You
have to cover up all of them.  The people hunting you only have to
uncover one.
McVeigh was also undone by the Ryder truck itself.  He thought the truck
would be destroyed in the explosion and not provide any links to him.
Within hours of the blast, though, they found one of the truck's
axles... and it still had a serial number legible on it.  They called
the axle manufacturer and found out what that axle had been put on; they
called up that truck's VIN number and tracked to whom it had been sold.
 Within a day they were serving the rental facility with a ton of
subpoenas and FBI forensic accountants.
If it hadn't been the phone card, it would've been the axle.  If it
hadn't have been the axle, it would've been the enormous ammonium
nitrate purchases he made.  If it hadn't have been the enormous ammonium
nitrate purchases, then the police would've followed up on a neighbor's
complaint about an awful diesel stink by Terry Nichols' home.  If it
hadn't... etc., etc.
There's a lesson in this for anyone who's thinking of ways to be one
step ahead of the secret police.  You'll get tripped up by things you
never thought of, or things you wrote off as being impossible.

@_date: 2009-02-11 19:18:14
@_author: Robert J. Hansen 
@_subject: where to start? 
Please -- just Rob.  I go by "Robert J. Hansen" professionally, to
reduce confusion with some other people in the security community who
are named Robert Hansen.  But everybody just calls me Rob.
Faramir, while I don't disagree with anything you're saying, I think it
might be a good idea to let the new guy drink at his own pace instead of
hitting him with the fire hose.  :)
(Yeah, yeah.  The irony.  _Me_ saying this.  I plead guilty to hypocrisy
and hope that the next time I do the same, people will remind me.)
(Idiom note: in American English, "drinking from the fire hose" means
"being given information more quickly than you can understand it.")

@_date: 2009-02-11 19:51:49
@_author: Robert J. Hansen 
@_subject: Update 
Regarding the shredded CD-R: I talked to my source and reminded him of
our 2005 conversation.  It became clear that further details are not
available for public release.  In light of this, I have to withdraw my
statement.  I can't back it up; and that means regardless of whether
it's true or false, it has to be withdrawn.
However, my source did point me to the 2006 Defense CyberCrime Center
Forensics Challenge, which involved recovering data off a CD which had
been sliced in two.  While a much weaker challenge than reassembling a
shredded CD-R, it is in the same neighborhood, and it's reasonable to
believe that specialist outfits will have better tools available to them
than the DC3 participants had.

@_date: 2009-02-12 11:03:04
@_author: Robert J. Hansen 
@_subject: General Error while checking message signature (Maybe I should 
Yes; it's possible (even likely) Malte's setup is misconfigured.  He's
been using PGP/MIME for his signatures, which requires that the hash
algorithm be included in the MIME header.  I've seen this error occur
before when the algorithm used in the signature is not the same as the
one declared in the MIME header.
I haven't done any checking into the matter, so please consider this
only a possibility.

@_date: 2009-02-12 11:09:59
@_author: Robert J. Hansen 
@_subject: General Error while checking message signature (Maybe I should 
A follow-up:
gpg: using character set `utf-8'
gpg: armor: BEGIN PGP SIGNATURE
gpg: armor header: Version: GnuPG v2.0.10 (GNU/Linux)
:signature packet: algo 1, keyid CA3CCC060F278D6D
Detached signature.
Please enter name of data file: Desktop/malte.eml
gpg: Signature made Thu Feb 12 08:45:26 2009 EST using RSA key ID 0F278D6D
gpg: BAD signature from "Malte Gell "
gpg: binary signature, digest algorithm RIPEMD160
... So according to GnuPG, the sig is using RIPEMD160.  But ta-da, look
at the message header (slightly edited for readability):
The message declares it's using SHA1, the message actually uses
RIPEMD160.  Presto, instant conflict.  GnuPG correctly flags the message
as being suspect, since the message is inconsistent.

@_date: 2009-02-13 12:20:23
@_author: Robert J. Hansen 
@_subject: JAVA Standard API for GnuPG v1.80? 
There is no standard Java interface, nor is there a GnuPG 1.8, nor would
either Sun or Apache be likely to make it even if the preceding two were

@_date: 2009-02-21 18:13:48
@_author: Robert J. Hansen 
@_subject: Command Line Use of GPG 
Why does this matter?
Either you have control of your system, in which case you're not  giving away anything by saying where GnuPG is -- or you don't, in  which case not saying where GnuPG is doesn't help you recover.
Paranoia is great.  Carefully reasoned paranoia is even better.

@_date: 2009-02-21 22:30:33
@_author: Robert J. Hansen 
@_subject: Command Line Use of GPG 
I agree with John.  This is further explanation, not a disagreement.
A couple of years ago, in response to something I posted on this list,  I had an unhinged list member fill my inbox with wild claims that I  was obviously either an FBI informant or a psychiatrist -- and if I  was either he was going to hunt me down and murder me with an axe.  I  didn't take it seriously until he cited my street address and phone  Making things worse, my father is a federal judge.  Given how tight  this guy's tinfoil hat was wound, I thought he might not draw that  much of a distinction between "son of a federal judge" and "FBI  informant."  It was a pretty stressful period for me for a while.
Moral of the story: some people are lurkers not because they're up to  skulduggery, but because they're scared of the fringe element.  And  really, if you're related to interesting people, or if you have an  interesting job... then who can fault you for wanting to keep a low

@_date: 2009-02-22 19:07:03
@_author: Robert J. Hansen 
@_subject: "Please select what kind of key you want" 
In 2006, Lucas's advice was pretty solid.  In 2009, not so much.  The  introduction of DSA2 has resolved most -- if not all -- of the reasons  that motivated him and others to suggest RSA.
Not with a sign-only key.  A sign-only key is only usable for signing;  other people cannot encrypt to a sign-only key.
Elgamal signing keys were  IIRC. They were removed years ago due to  some catastrophic bugs and the community's near-total abjuration of  Elgamal signing keys. (IIRC, the total number of Elgamal signing keys  on the keyserver network was in the neighborhood of 10.)
Because when you generate a new key you /must/ generate a signing  key.   4 and 6 are encryption-only keys, which means they can only  be added to an already-existing signing key.
Why should they be?
If you want to add a new DSA signing key, you can do that.  If you  want to add a new Elgamal encryption key, you can do that.  Where's  the problem?
Nope.  An OpenPGP implementation is not required to support most of  those algorithms.  You can have a perfectly well conforming OpenPGP  implementation which only supports SHA-1, DSA, Elgamal and 3DES.

@_date: 2009-02-23 13:42:32
@_author: Robert J. Hansen 
@_subject: How secure asymmetric encryption to yourself? 
I'm fond of writing down my passwords on the back of a business card  and keeping it in my wallet.  For the overwhelming majority of these  passwords, the site's most confidential information of mine they  possess is my credit card number.  But if my wallet gets stolen or  goes missing, I'm going to cancel my credit cards anyway.
Likewise, you can say, "but you might leave your wallet on your desk,  and a co-worker could steal those passwords."  Sure.  They could also  steal my credit card number, driver's license information, voter  registration ID, or all manner of other things more important than my  This takes care of >90% of all my logins, meaning I can much more  easily memorize those few high-value, high-secrecy passwords.   Memorizing three unique passwords is doable; memorizing thirty unique  ones isn't.
Unlike your solution, my solution works when I'm on the road and  logging on from a coffeeshop's web kiosk.  I don't need to install  anything.  Open up my wallet, fish out the list, and there it is.
The moral of this story is simple -- don't make things more  complicated than you have to.

@_date: 2009-02-23 14:52:13
@_author: Robert J. Hansen 
@_subject: "Please select what kind of key you want" ~~ suggestion to 
There's a discipline in computer science called human-computer  interaction (HCI).  I took two courses in this in grad school: not  enough to make me an expert, but definitely enough to open my eyes.   One of the things my instructor, Juan-Pablo Hourcade, drilled into us  is that we genuinely don't know what will speed adoption of new  technologies.  All we know is what successful technologies look like.
Imagine there's a new hotness in IT.  (IT: Information Technology.)   This new hotness has the potential to change the world in ways that  can barely even be explained to people who don't already have the  technology.  Everyone you meet who has this new technology -- let's  call it "flerbage" -- they've got this magical ability to /know  things/.  Know things they can't possibly know, that they couldn't  possibly have learned.  Flerbage is where it's /at/.
The only problem is that flerbage is ridiculously user-unfriendly.   Most people who use flerbage, this smoking-hot new thing in IT, say it  took them between ten and fifteen years to really learn it.  The  learning curve looks like the freaking Matterhorn.  Also, flerbage  can't be made "easy for beginners to understand."  You want flerbage,  you're looking at a decade or more of serious, concentrated study.   Sure, it's cool, but ... is it worth it?
Would you say flerbage was a successful technology?  Do you think  flerbage will ever catch on?
Flerbage is real, by the by.  You're using it right now, this very  instant.  Scroll down and I'll tell you what it is.
Literacy is the original information technology.  People who are  literate have an enormous advantage over those who aren't.  Wherever  you look today you see signs, posters, advertisements, menus,  whiteboards, warnings, labels and every other thing imaginable that's  written down.  Literacy gets taken for granted by almost everyone --  despite the fact that it takes most of your childhood and teenage  years to get good at it.
So no, I don't agree with your proposition.  OpenPGP doesn't need to  get easy for beginners to use.  If it was that simple, we'd be there  What needs to happen is the populace needs to understand the risks of  electronic communication, and needs to become committed to doing  something about it.  If you can achieve that, then you will have done  something great for humanity.
But the world doesn't need another "easy to use GnuPG interface."   You're essentially saying, "what the world needs is a really good  book!"  What I'm saying is, "the world first needs to learn to read."

@_date: 2009-02-23 15:56:56
@_author: Robert J. Hansen 
@_subject: "Please select what kind of key you want" ~~ suggestion to 
You missed the point.  Refer to my last three sentences.  The world  doesn't need another "easy to use GnuPG interface."  You're  essentially saying, "what the world needs is a really good book!"   What I'm saying is, "the world first needs to learn to read."
With respect to claims of experience, I don't put any stock in them,  really.  Or, as Rodney Whitaker wrote, "do not fall into the error of  the artisan who boasts of twenty years experience in his craft while  in fact he has only one year of experience -- twenty times."
As near as I can see, the principal problems are:
With respect to  one of the most prestigious crypto conferences  out there is called Financial Cryptography.  A few years ago some  enterprising grad students asked each FC attendee to fill out a very  short questionnaire as part of their sign-in process.  The results  were astonishing: 60% of FC attendees did not know if their email  client supported crypto, period -- even fewer knew if it supported  OpenPGP or S/MIME.  Only 50% were interested in switching to email  clients with better crypto support.
If only 40% of FC attendees know if their email client supports  crypto, and only 50% care enough about crypto to consider changing  their email clients, do you really think the general public will jump  on board OpenPGP just if we create a snazzy interface with a lot of  chrome?  That's delusional.
With respect to  Ed Felten has a really good sociological paper  out on the intersection of computer security and the workplace.  He  and some of his grad students interviewed people at a politically- active nongovernmental organization (NGO) with an awful lot of  enemies.  Many (most) of the employees had been trained with PGP and  found it reasonably easy to use.  Despite that, they still didn't use  it for email.  Felten and his grad students wanted to find out why.
It turns out that social disapproval played a very heavy role.  There  were a couple of people in the NGO who were privacy enthusiasts and  active PGP users, and they were considered "paranoids" by the other  workers in the office.  Employees said things to the effect of "yeah,  I know email is dangerous, but I don't want to turn into, you know,  one of _those_ guys."
... the general public does not know what email crypto is, does not  want to know what email crypto is, does not want to care about email  crypto.  They just want to send email.  Making GnuPG "easier to use"  is a fine goal and worth pursuing in its own right, but it's not going  to substantially improve GnuPG's adoption in the world.
Saying "the world needs a good book, that's why book sales are down!"  may be a true statement, and may be worth pursuing in its own right.   However, the real problem is "first we need to learn to read."
"GnuPG needs a good interface, that'll improve its usage numbers!" may  be a true statement, and may be worth pursuing in its own right.  (In  fact, I think it is.)  But the real problem is that people don't know,  don't want to know, and to the extent they do know they really don't

@_date: 2009-02-23 16:24:51
@_author: Robert J. Hansen 
@_subject: "Please select what kind of key you want" ~~ suggestion to 
Required reading:
Some results from this paper were presented at FC2005, but is not the  survey I mentioned in my previous message.  That said, the results are  substantially similar.
The following is excerpted from the paper.  If possible, though, I  highly recommend you read the entire paper; it's an excellent overview  of why secure email has failed to take off.
Our survey consisted of 40 questions on 5 web pages.  Respondents were  recruited through a set of notices placed by Amazon's employees in the  Amazon Seller's Forum.  Participation was voluntary and all  respondents were anonymous. ...  A total of 1083 respondents  [participated], with 417 of those respondents completing all five pages.
Average age of our respondents was 41.5.  Respondents were highly  educated, with more than half claiming an advanced or college degree.   Most described themselves as "very sophisticated" (18.0%) or  "comfortable" (63.7%) using computers and the Internet.  Roughly half  the correspondents had obtained their first email account in the 1990s.
The majority of respondents (94.4%) used computers running Microsoft  Windows for email.  The two other leading platforms were Apple  Macintosh (8.5%) and some kind of mobile computing device such as a  cell phone (5.8%).
... A majority (54%) of respondents understood the difference between  digital signatures and sealing with encryption; that prior receipt of  digitally signed mail significantly increased understanding of that  difference; and that having previously received digitally signed email  from Amazon increased respondents' overall trust in email.
... The majority (59%) didn't know [if their email client supported  encryption], while another 9% chose the answer, "what's encryption?"
... Respondents with S/MIME-capable mail readers were more than twice  as likely to know that their programs were capable of encryption, and  half as likely to select the answer "What's encryption?"   Nevertheless, the majority of [S/MIME-enabled] correspondents (54%)  did not know the cryptographic capabilities of the software they were  Almost half of our respondents (44.9%) indicated that they would be  willing to upgrade their client in order to "get more protection" for  their email...
... Although roughly half of our respondents indicated that they  didn't use cryptography because they didn't know how, the free- response answers from the more knowledgeable respondents indicated  that they either didn't think that encryption was necessary or else  that the effort, if made, would be wasted.

@_date: 2009-02-23 17:25:14
@_author: Robert J. Hansen 
@_subject: "Please select what kind of key you want" ~~ suggestion to 
And let's add to that:
Again, read the entire thing.  Email crypto is seen as the mark of a
fearful or paranoid mind.  The excerpt here should give you an idea of
the paper, and will hopefully inspire you to read it for yourself.
Abe worked in development. ... Because he handled financial data, Abe
used encryption frequently, particularly when he received records from
online donations ("I tend to try and be sure I PGP everything that has a
credit card number on it").  He also communicated with an external
vendor for recruitment.  They used encryption to protect financial data
when they synchronized their copies.  Abe believed this setup was
simple; he also thought some people ... needed to be more vigilant.  He
described how he tried to convince the head of campaigns in his home
country to use encryption:
Despite his reasoned argument, his colleagues were uncooperative: "most
people see this as more work and want things simpler."
Many of the employees interviewed ... had limits to their willingness to
be more secure.  In fact, moving beyond that limit was seen as abnormal
or paranoid.  ... Abe explained how someone could "go overboard" when he
described how a representative of the PGP Corporation visited [the NGO].
 Instead of a typical password authentication, the representative took
off his necklace and used a removable flash drive that held his private
key.  The demonstration discouraged Abe:
He was not sure whether this vigilance was justified.  In fact, he
associated it with being fearful, perhaps irrationally fearful.  Abe
reiterated this when asked to speculate on why a colleague sent every
e-mail message encrypted.  He figured this man has an automated system
for encrypting e-mail "or else he's nuts."
[big snip here, switching to a different employee, 'Jenny', who has used
PGP in the past and understands its use in contexts where secrecy is
Jenny also thought it was abnormal to encrypt non-secret information.
When the interviewer abstractly explained that people in security
suggest all users encrypt all messages, Jenny was baffled:
Jenny emphasizes "normal people."  _Normal_ people wouldn't encrypt
normal messages.

@_date: 2009-02-27 07:53:18
@_author: Robert J. Hansen 
@_subject: future proof file encryption 
Let's not use words like "algorithm" and "program", since they have
fairly precise technical meanings and I don't think you want to get
bogged down in jargon.
You need to know the key, and you need a decrypter that's compatible
with whatever you used to encrypt.
GnuPG conforms to the OpenPGP standard for cryptography.  That means
there are ... what ... 14 or so compatible implementations.  You don't
have to rely on GnuPG; there are a lot of other options out there.  This
is very good for purposes of long-term storage.

@_date: 2009-02-27 10:24:32
@_author: Robert J. Hansen 
@_subject: future proof file encryption 
Err.  What?
With a 256-bit cipher, if you're missing 3 bits, there are only eight
possible keys.  This is not an obstacle.
The moral of the story is not to avoid encrypting your backups, but to
keep multiple copies of your backed-up data.

@_date: 2009-02-27 11:25:56
@_author: Robert J. Hansen 
@_subject: future proof file encryption 
After a little thought, it occurred to me that perhaps Sven meant there
are three errors and it's not known where.  This turns into a slightly
more complex case, but still within the realm of possibility: just over
twenty-two million possible combinations (2.7 million combinations, with
each set of three bits possessing eight possible states).

@_date: 2009-02-27 17:56:53
@_author: Robert J. Hansen 
@_subject: future proof file encryption 
I cannot for the life of me see what's leading you to give this counsel.
Would you care to share your reasoning?
Why?  A good archiver will keep a running CRC, allowing you to identify
which files are good and/or bad.  Fuzzy hashing will potentially narrow
it down to a few bytes within the file, making it possible for a good
archivist to recover/restore most of the damaged area.
Needless overkill for most purposes.  The lifespan of HD media is
surprisingly long: you can fairly easily recover data off a 30-year-old
hard drive.  You might have trouble finding an MFM or RLL bus, but once
you find it you're in pretty good shape -- especially if basic archival
protections were taken.
(For instance, don't vacuum-seal hard drives.  Put them in heavy-duty
antistatic bags, purge with very dry nitrogen, and seal it up.  You
could now store the hard drive underwater for years and still expect it
to work when you hooked it up.  Imagine how much better it will work
kept in a safe deposit box.)
Optical media can also be high reliability.  I'm not sure I'd trust a CD
that had been sitting on my dashboard for six weeks, but a CD stored in
a lightproof envelope kept in a dry nitrogen environment will be good
for decades.
Yes, no -- it certainly can't hurt them.  Also, image formats are
usually about ten years in the past -- it's the nature of the beast, the
image industry wants very stable formats -- which means they're also
generally behind the curve on compression.  Compare this to compression
software, which is getting better by the day.

@_date: 2009-02-27 19:22:56
@_author: Robert J. Hansen 
@_subject: future proof file encryption 
I didn't see it.  Looking over it, I still don't.
There are a lot of different kinds of CRC32 -- some designed in an ad
hoc manner and others designed to the standards of engineering.  You're
using one right now, probably: Ethernet frames incorporate a CRC32.  If
it's good enough for Ethernet, it's good enough for me.
You're also missing the part about how GnuPG includes a hash of the data
in its symmetric encryption.  You don't need public key encryption to
get a hash on the data.
Hard drives tend not to crash or overheat when they're powered down,
properly mothballed, and put in long-term storage.
If you're seriously advocating spending $300 for hard drives alone to
back up your data, then you've just priced your scheme beyond the reach
of most people.  I make good money at my day job and let me tell you, I
wouldn't /think/ of spending $300 on backups.  What happens in two
years?  You think I should be out another $300 in backups alone?  An
amortized cost of $150/year for backups is probably about 150 times too
My suggestion is, IMO, at the edge of practicability -- and it costs
under $100 of outlay for enough equipment to do about 100 long-term
nitrogen-purged backups.  ($50 for a 10 cu. ft. cylinder of argon, $20
for 100 antistat heat-sealable bags, $20 for a big stack of DVD-Rs.)
As a rule of thumb, the more complex and expensive your backup system
becomes, the less likely it is that anyone will actually follow the
I said 'about'.  JPEG was standardized in 1994; PNG in 1996; SVG in 2001.
Wavelets.  Fractals.  Arithmetic coding.  The data compression field is
alive and well and constantly getting better.  Check out the literature.
Some of these have already been incorporated into newer graphics
standards.  E.g., JPEG has no support for wavelet encoding, but JPEG2000

@_date: 2009-02-27 20:31:25
@_author: Robert J. Hansen 
@_subject: future proof file encryption 
There also seems to be a tendency to misread what I think are very
neutral statements as being very dry snark.
E.g., when I said I didn't see the reasoning, and having reread it I
still didn't, it wasn't meant to be insulting: it was meant quite
literally.  If there was a line of reasoning there, I missed it on both
the first and second reads-through.  Maybe that means there was no
reasoning, maybe that means I wasn't astute enough to read it.
With all that said, I have discovered it is generally best to read
people's statements in a way that gives them the benefit of the doubt.
W.r.t. my experiences, I'll just quote Rodney Whitaker again: "Do not
fall into the error of the artisan who boasts of twenty years experience
in his craft while in fact he has only one year of experience -- twenty
times."  I make errors as easily as anyone else.
E.g., I was wrong a couple of weeks ago about why there was no choice in the subkey generation menu; I said that if memory served it belonged
to Elgamal signing keys, which have since been removed -- bzzt, wrong.
A couple of months ago David Shaw and I had a very vigorous argument
about some of the engineering choices in the OpenPGP specification.
After mulling it over for a couple of weeks, I've come around: David's
arguments were more persuasive than mine.  I'm not sure if I was wrong,
per se -- we were arguing about a matter of personal opinion -- but I
certainly had the weaker arguments.
Beware of all experts.  Experts are wrong as much as anybody else.
Experts are just wrong with much greater authority.

@_date: 2009-02-27 20:37:53
@_author: Robert J. Hansen 
@_subject: future proof file encryption 
(Replying to David, but it's really for Joseph)
Depends a lot on the paper and dye you use.  Most consumer-grade inkjet
prints will begin fading after only a few years.  Even if they don't,
they react with the atmosphere and their color palette changes.
If you've ever seen an old Polaroid that makes you think the 1970s were
an era of muddy-looking colors, well -- that's what's happened to it.
The original photo was vibrant, but light and atmospheric oxygen has
changed it.
For long-term photographic storage, make a print from photographic film
on archival-quality print stock.  Also, I'm given to understand that
black and white photographs survive the aging process much better than

@_date: 2009-01-01 18:15:34
@_author: Robert J. Hansen 
@_subject: how-to 1) remove a key, 2) avoid spam, 3) add a principal UID 
I think the OP was looking for "gpg --delete-key" and "gpg
Might also be worth mentioning that the idea of "primary UID" is kind of
poorly defined.  No OpenPGP application (that I know of) does anything
special with them.  All it affects is which UID GnuPG and PGP will
display first.  Nothing more.

@_date: 2009-01-02 14:41:12
@_author: Robert J. Hansen 
@_subject: [linux] Which Mail Server To Use? 
Unfortunately, my only suggestion is to ask on FireGPG's forums and/or
mailing lists.  They'll be much better able to help you than this
mailing list.
(Much the same advice is given to people who come here looking for help
with Enigmail or any of many other GnuPG-related pieces of software, so
please don't think this is either a personal slight or an expression of
disdain for FireGPG.)

@_date: 2009-01-02 23:51:06
@_author: Robert J. Hansen 
@_subject: installing gpg on Mandriva 2009 
I have no answer for you -- I don't use GnuPG 2.0 -- but it is _very_
_very_ _important_ that you not use 'root' as your regular user.
UNIX has a lot of safeguards to keep you safe from malware on the
internet.  However, when you run as root, many of these safeguards vanish.

@_date: 2009-01-08 12:38:21
@_author: Robert J. Hansen 
@_subject: Initial pass at a BNF 
Pursuant to a discussion on gnupg-devel, I'm looking for exotic,
esoteric, and just plain broken keys.  I need keys with X.509
certificates, keys with public key data packets, keys with signature
subpackets, and any key that you feel is an aberration against anything
from your chosen deity to the laws of physics to the guidelines of just
good sense.
My goal here is to provide an accurate Backus-Naur Form (BNF, a
programming tool) for people who need to parse GnuPG keyrings.  The more
 crazy keys I get, the more confident all of us can be in the accuracy
of the finished product.
Please send them to me directly.  Let's not spam the list.  Thank you
all very much for your help!

@_date: 2009-01-09 07:50:05
@_author: Robert J. Hansen 
@_subject: PGP on Window 2003 
We can't help you.  This mailing list is for the GNU Privacy Guard
(GPG), not Pretty Good Privacy (PGP).  The two programs are
interoperable, but they are not the same, and their setup is totally
You may want to ask PGP Support.

@_date: 2009-01-09 11:28:13
@_author: Robert J. Hansen 
@_subject: PGP on Window 2003 
We need to know a lot more details.  Let's start with:
1.  What version of GnuPG are you using?
2.  From where did you get it?
3.  What errors are you getting?
4.  Does it work from the command line?

@_date: 2009-01-09 13:34:59
@_author: Robert J. Hansen 
@_subject: PGP on Window 2003 
This version is very old and has some known security problems.
Upgrading to 1.4.9 is definitely recommended.
The error message you've attached indicates the problem is with your
Perl installation, not your GnuPG installation.  Particularly, the
module Mail::Sender does not appear to be installed.

@_date: 2009-01-09 18:59:26
@_author: Robert J. Hansen 
@_subject: PGP on Window 2003 
Bizarre; his emails to me are showing up as being cc'd to the list.
Perhaps he's not a subscriber, and thus his emails to the list are being
held pending moderation?
If this is the case, Paul, it will do the list a favor if you subscribe
to the list.

@_date: 2009-01-09 19:02:28
@_author: Robert J. Hansen 
@_subject: Paperkey on windows 
Not quite.  The GPL doesn't require you to give source with the binary.
 It just requires that if you give someone a binary, you make sure they
know they can also get the source from you.
Trust is a dodgy thing.  My best advice is to say exactly what you've
said here: "I trust the guy who compiled it, but I don't have any proof
that he didn't do evil things to it."

@_date: 2009-01-09 19:07:02
@_author: Robert J. Hansen 
@_subject: encryption bloats file 
Option 1: they're not using compression and they're ASCII-armoring the
file.  You can expect to see a large size swell.
Option 2: they're sending a file that's carefully crafted to blow up.
I've seen a ridiculously tiny zip archive (a couple of K) that expands
into hundreds of terabytes.  There are sixteen zip archives in that zip
archive, each zip archive expands into another sixteen zip archives,
each of those zip archives expands into several gigs of zeros, etc., etc.

@_date: 2009-01-09 20:27:30
@_author: Robert J. Hansen 
@_subject: encryption bloats file 
I was assuming that "about double" was a term of art, and it was perhaps
possible that it was being stretched to mean a much smaller increase.
D'oh!  Right.  Sorry.

@_date: 2009-01-12 18:11:14
@_author: Robert J. Hansen 
@_subject: Question of using GNUPG on Win OS 
Calling the command.  You may find Perl to be very useful for this.
I assume you mean GUIs, as in Graphical User Interface.  (GUID is
another acronym: Globally Unique Identifier.)  Yes; Google for WinPT or

@_date: 2009-01-13 08:45:32
@_author: Robert J. Hansen 
@_subject: recover private key 
(This email is for jakse, although I'm responding to Faramir's email.)
An ideal signature requires four things:
The more of these requirements that are missing, the less utility there
is in a signature.  If I send a signed email message to, say, Faramir,
well ... Faramir barely knows me at all.  I don't know if he trusts me.
 (I'd be surprised if he did; it's not like I ever bought him a beer.)
He hasn't verified my key fingerprint, either directly or through the
WoT.  And in an era where 20%+ of all desktops are hijacked, how can he
be sure of Add up all the ways in which we're departing from the Platonic ideal and
you can tell that my signature on a message to Faramir really counts for
astonishingly little.  Signing posts to a mailing list is much the same:
of all the people who receive it, hardly anyone will know you, trust
you, or have verified your fingerprint.
Usually when people sign mailing list posts they are doing one of three
 and  are both great ideas and I'm all in favor of it.  It's okay to
 sign your messages if you're doing so to make sure that you understand
how it's done.  Someday you'll need signatures, and when that day comes
the practice will pay off.  Likewise, showing public support for email
cryptography is a Good Thing and should be encouraged.
Unfortunately,  is true much more often than it's not.
Probably the biggest myth about signatures is they provide either
repudiability by proxy.  Even very intelligent and experienced users
fall victim to it.  A lot of people will say, "I sign everything so that
if later on someone tampers with my messages I can prove I didn't write it."
Unfortunately, digital signatures don't provide this capability.
Imagine that I'm back in grad school teaching a class and I give a
student a poor grade.  The student decides to get revenge on me by
posting to notorious white supremacist message boards in my name, then
conveniently blows the whistle on "my" activities.  I get hauled into
the Dean's office where I get told I'm being suspended pending the
"But I didn't write those!" I say.  "I sign absolutely everything!  Were
those messages signed?  They were either missing a signature or had a
bad signature, right?  Clearly, obviously, I didn't write them!"
"Ah," the Dean answers, "but you're a smart guy, Rob, and you're smart
enough to have deliberately omitted a signature, or put a bad one, on
incriminating messages you wanted to later repudiate.  The lack of your
signature, or the presence of a bad one, doesn't prove anything about
whether you wrote it.  Sorry.  We'll have the investigation wrapped up
by next semester."

@_date: 2009-01-13 18:21:26
@_author: Robert J. Hansen 
@_subject: Subject: Re: recover private key 
Yes and no.  If I ask "Avi, did you really say 'I liked Yasser
Arafat'?'", you might present me with this message:
... But unbeknownst to me, you /did/ actually say "I liked Yasser
Arafat.  I liked him quite a bit, really.  I often had him over for tea
and scones and we would talk about our families."
When confronted with the quote "I like Yasser Arafat", you wanted to be
able to deny saying it.  So you wrote up an innocuous text message
involving the Munich Massacre, reset your computer clock back, signed
it, and then presented me with the doctored message as proof of what you
_really_ said at that point in time.
You cannot use signatures to put excerpts in context, not in the general
case.  The timestamp problem is a killer.
If the person presenting you with a quote also includes the signature of
the message they're quoting, though, then yes, this becomes possible.
But if they're excerpting you, odds are good they don't have your signature.

@_date: 2009-01-13 22:34:36
@_author: Robert J. Hansen 
@_subject: Subject: Re: recover private key 
The OpenPGP time stamp is not a trusted timestamp and should not be
relied upon for any trusted purpose.
Assuming you still have a copy of the message, yes.  But in the case
you're talking about, what does the signature buy you?  "Yes, I did
write that, but in the full context (available at this link...) you see
I meant something quite different."  That's as effective with a
signature as without.  So I don't see how this is an example of the
utility of a signature.
There's no pre-creation necessary in the scenario I outlined.  Maybe I
just know an uncommon class of scoundrels, but that level of
skullduggery is fairly tame in my experience.

@_date: 2009-01-14 11:47:58
@_author: Robert J. Hansen 
@_subject: Dan Brown - Digital Fortress book 
The book is almost wholly fiction with the occasional bit of
name-dropping thrown in to make it sound authentic.  The idea of a
cipher that shifts over time and thus making it unbreakable is patently
ridiculous.  All you're doing is making a timestamp part of the
encryption key, nothing more or less.
The TRANSLATR machine does not work and cannot work, not under the laws
of physics as we know them to be.
The description of life in a secure high-reliability datacenter is also
absurd.  E.g., the book mentions several times how they use Freon to
cool the machinery.  Real datacenters explicitly forbid Freon.  When
Freon catches fire it decomposes into phosgene, a nerve gas, which makes
it kind of hard to fight the fire.  In the book, a fire ravages the
datacenter and yet somehow people in it aren't dead from phosgene exposure.
The portrayal of the NSA doesn't even rise to the level of a caricature.
The book is a miserable, insufferable, abysmal waste of time.  A friend
of mine once gave me a copy with the caveat that I wouldn't be able to
finish it.  I did, but only to prove him wrong.

@_date: 2009-01-14 14:10:30
@_author: Robert J. Hansen 
@_subject: Dan Brown - Digital Fortress book 
Off-topic, but hey, we all need to unwind and relax sometime, right?
All these books are, IMO, absolutely excellent, and all connect in one
way or another -- in intelligent and accurate ways -- to computer security.
Charles Stross, _The Atrocity Archives_.
  This one's an excellent mix of Len Deighton spy thriller and
  _Dilbert_.  It's also rife with mathematical in-jokes for people
  astute enough to notice them.  Bob Howard is one of geekdom's
  great characters: he's every single tech nerd who's ever worked
  in a large, faceless bureaucracy.
Neal Stephenson, _Cryptonomicon_.
  It's a little dated now, but when it came out this book was an
  excellent slice of the Zeitgeist of the dot-com boom.  Most of
  the crypto holds up relatively well; the algorithms have been
  broken, but the principles are sound.
Rudy Rucker.  Just about anything, really.
  Rucker is a mathematician and computer scientist.  It shows in
  his writing.
Greg Egan, _Permutation City_.
  Words fail me when I try to describe it.  I guess you could say
  it's one long discourse on Nick Bostrum's simulation hypothesis,
  or maybe the implications of the 't Hooft holographic hypothesis.
  No matter how you slice it, this book will bend your mind.
Daniel Keys Moran.  Just about anything, really.
  Moran is a database geek in Los Angeles.  In the late '80s and
  early '90s he published a trilogy of books.  Trent's discourse on
  the root causes of network failure, and the consequences of
  widespread network failure on a networked society, is one of the
  best technology-explained-for-the-layman things I've read.
... For movies, the best one is hands-down _Sneakers_, a 1992 crime
caper starring Robert Redford and Ben Kingsley.  In 1992, Kingsley
talked about how he might be able to crash the entire world economic
system with the aid of computers and some carefully chosen bad
information.  We laughed at it then: what he was talking about was pure,
utter science fiction.
In 2009, we're seeing that happen all around us, and few of us are laughing.

@_date: 2009-01-15 09:52:00
@_author: Robert J. Hansen 
@_subject: Dan Brown - Digital Fortress book 
First responders -- the people in the office who rush to the fire armed
with fire extinguishers -- don't wear respiratory equipment.  This is
why data centers don't use Freon; in case of fire, it's hazardous to the
people evacuating and especially to the people who are trying to slow
the fire's spread.
In the book, several people without respiratory equipment are exposed to
large doses of Freon in a large building fire without harmful effect.

@_date: 2009-01-15 11:56:13
@_author: Robert J. Hansen 
@_subject: Dan Brown - Digital Fortress book 
Possibly: it wouldn't be the first time he used terminology glibly to
the point of gross error.  That said, the last time I looked into Halon
fire systems they were advertised as not producing thermal shock, which
would seem to indicate they wouldn't be effective coolants -- which was
the purpose the book gave to the Freon, they kept TRANSLATR cold.
(For anyone who's confused about thermal shock: take a wineglass and
heat it to a few hundred degrees in your oven.  Then dunk it in ice
water and watch it shatter.  Thermal shock is the culprit.  The same
thing happens in data centers when there's a fire raging.  The servers
get heated up and the liquid Freon cools them down in a big hurry.)

@_date: 2009-01-15 13:57:17
@_author: Robert J. Hansen 
@_subject: Dan Brown - Digital Fortress book 
You don't.
into PSPACE.  Once you leave NP behind you, your next stop is the
one-time pad.
Delivering a false message to your enemies is a classic tactic in the
history of communications security.  In recent history, that's how we
knew to intercept the Japanese fleet at Midway Island.  Going back to
classical history, it's one of the ways Belisarius kept the Germanic
tribes divided, facilitating his successes during the reign of Justinian.
To the extent people are inspired by it to think critically about
crypto, I'm glad.  But I cannot recommend it be read as an exposure to
concepts in crypto.  _Cryptonomicon_ (and Jon Evans' _The Blood Price_,
which I should've listed on my recommended books before) are much better
for that.

@_date: 2009-01-16 08:57:03
@_author: Robert J. Hansen 
@_subject: Dan Brown - Digital Fortress book 
Right.  But in the book, the Freon is explicitly said to be a _cooling_
agent.  The cooling cables come loose in the fire and Freon sprays
everywhere.  It's not Freon being deliberately released as a fire
suppression agent.
I don't know about every Halon out there -- maybe there are some which
can do double duty as cooling agents.  But the fact the Freon is
ascribed as a coolant first and has no fire-fighting properties Brown
sees fit to talk about makes me think he intended for it to be coolant
gas which was escaping, not a fire suppression system which was activating.

@_date: 2009-01-16 15:26:20
@_author: Robert J. Hansen 
@_subject: End of Line characters disappear after decryption 
Yes -- give us the command line you're using.  :)  Knowing that you're
using 1.4.9 is a good start, but we need more information.

@_date: 2009-01-19 07:57:54
@_author: Robert J. Hansen 
@_subject: storing gpg keys on a database 
A couple of options:
1.  Create a regular SQL database with an email address as part of a
composite primary key, and a binary blob as an unindexed column
2.  Run your own local keyserver and run your queries against that.
 will probably be easier;  seems like it will probably be faster and
more reliable.  I did some looking into this a few years ago
That said, database engines tend to handle binary blobs very poorly.
You'll probably want to strip as many signatures as possible from the
keys before you import them, to keep their size down.
This is why you export the keys, and import them into the database, in

@_date: 2009-01-19 08:00:03
@_author: Robert J. Hansen 
@_subject: storing gpg keys on a database 
Weird: could've sworn I finished that sentence.  Please add,
"... and it was pretty clear that for my needs,  was the way to go.
Your mileage may vary."

@_date: 2009-01-19 10:12:40
@_author: Robert J. Hansen 
@_subject: storing gpg keys on a database 
This is O(n) lookup, isn't it?  If Ramon is looking at a db or a custom
solution, I was assuming he needed something a lot faster.  But yes, if
O(n) is good enough, the right thing to do is to just let GnuPG handle it.

@_date: 2009-01-21 06:30:47
@_author: Robert J. Hansen 
@_subject: Passphrase problem 
This is not possible.  If it were possible, there wouldn't be much point
in a passphrase in the first place.

@_date: 2009-01-22 08:51:23
@_author: Robert J. Hansen 
@_subject: OT: virus on the wild? 
It's probably off-topic for here, but then again, Werner, David and the
others have generally been fairly indulgent of off-topic posts.  Still,
let's do them a favor and not continue it longer than necessary.
Yes.  No.  Moo.  Ten pounds of flax.  Getting accurate intelligence
about the spread of malware is a very difficult task.  Vendors like to
sound authoritative, but the reality is they're often almost as much in
the dark as the rest of us.
How do you know that it actually did?  AV software has false positives
and false negatives.
People tend to put much more faith in AV software than they should.

@_date: 2009-01-23 15:34:00
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
Camellia is not yet part of the OpenPGP standard.  The standardization
process for it is still underway.  Once it's standardized, GnuPG will
support Camellia the same as any other algorithm -- but please don't use it.

@_date: 2009-01-23 15:39:42
@_author: Robert J. Hansen 
@_subject: Silly question about secure deletion of files 
Not really.  It's more a question of context.
With a defrag, if you successfully rearrange 95% of the affected blocks
then you've substantially improved your drive performance.  Sure, it'll
report that it's done 100%, but who cares, really?
With disk overwriting, if you successfully overwrite 95% of your
sensitive data, you may still be putting yourself at substantial risk.
Especially since it will report that it overwrote all your data.

@_date: 2009-01-23 15:55:20
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
There's no real reason to avoid Camellia, by the way.  It's a trusted
algorithm, cryppies have a lot of confidence in it -- I'm just part of
the (vocal) minority which screams that OpenPGP has way too many
algorithms and we need to start cutting algorithms out.  I would like
GnuPG a lot more if it only supported 3DES, SHA-1, SHA256, and DSA/ELG
keypairs in 1k and 2k sizes.
There is a (less vocal) majority which seems to think I am crazy,
though.  :)

@_date: 2009-01-23 17:14:15
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
I actually don't, but for policy reasons.  My local policy is "have
total control over what I send, but don't assert control over what I
receive."  I guess you could call it my small-l libertarian philosophy
as applied to OpenPGP.
Whatever traffic someone decides to send me, if it's valid OpenPGP
traffic, I want to be able to make sense of it.  However, when it comes
to sending traffic, I tend to be much more restrained: I have most of my
machines set up with a personal-cipher-preference of 3DES, and a
personal-digest-preference of SHA256.
I don't mind if we as a community decide to restrict OpenPGP to a
smaller subset of algorithms.  I don't think I should try to coerce my
prejudices on the traffic sent to me by others.  I think the best way to
restrict algorithms is by community consensus, not by me restricting the
list of algorithms in my key preference list.

@_date: 2009-01-23 18:49:41
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
Yes, which sort of demonstrates the point that the preference mechanism
is just needless complexity.  It's a recommendation mechanism without
either enforcement mechanism or standardized semantics.  Should the key
preference list be Borda-counted with the sender's preferences?  Should
the sender use the first sender preference that's in the recipient's
preferences?  The last?
If I send 3DES to absolutely everyone, then I'm still respecting their
preferences, even if I never bother to read their preferences.  That
seems pretty weird to me.  If I give you a plate of General Tso's
chicken without even asking you what sorts of food you like, I don't
think it's reasonable for me to say I've taken your preferences into
I take objection to the "so that."  That ascribes to me motives I don't
possess.  If someone waved a magic wand and said, "okay, OpenPGP now
uses only AES, RSA and WHIRLPOOL," I'd consider it to be an improvement,
despite the fact the ciphers you're alleging I favor would now be
removed from the spec.  My goal is simplicity -- which algorithm suite
is used is really an afterthought.
This should also explain why I care so little about preference lists.  I
don't care if someone wants to send me AES256, IDEA, 3DES or CAST5
traffic.  IMO, they're all perfectly defensible choices.  But I care a
lot about the complexity generated by supporting all those ciphers.  (As
an example, look at what happened with Elgamal signing keys.  That bug
would have never been introduced if the GnuPG devs had said "Elgamal
signing keys are rare, they're not required by the spec, and we're not
going to support them.")
What I want is simple: a smaller GnuPG codebase and a smaller OpenPGP
standard.  Changing my preference list will not advance either cause one
iota, so I don't see the point in changing things.
On the other hand, if there's a community consensus that RFC4880 has
grown too complex and needs to get pruned, then I think that consensus
could turn into a smaller spec, a smaller codebase, and more trust.
If you can think of a way to use the existing mechanisms of RFC4880 to
achieve my goals, I'd love to hear it.  Maybe there is some way to do it
yet and I've just been too dumb to see it -- it's been known to happen.

@_date: 2009-01-23 18:56:49
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
That "provided" is the sticking point.  Small is beautiful, IMO.  YMMV.
There is an apocryphal story about the United States Navy and the United
States Air Force.  In the 1970s, the USAF and USN made an agreement that
they were going to field the same jet fighter.  This would make it
easier for Navy and Air Force pilots to work together, to simplify
logistics, and so forth.
Two jets made it to the finalist stage: the YF-16 and the YF-18.  The
Navy decided on the YF-18, a twin-engine jet fighter.  They liked the
fact it had two engines: after all, if one engine goes out, the jet
could still get back to the carrier on the other engine.
The Air Force was shocked by this and canceled their cooperation in the
program.  They learned from the F-4 and the F-15 that twin-engine
aircraft had more than twice the engine problems of single-engine
aircraft.  The downside of the extra complexity was greater than the
upside of having a second engine.  They refused to buy any YF-18s.  The
single-engine YF-16 was far superior.
And this is, according to the story, why the Navy flies F-18 Hornets and
the Air Force flies F-16 Falcons.

@_date: 2009-01-23 22:57:32
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
First, I've said the algorithms are safe enough to use.  I've never said
GnuPG's implementation of them is correct and error-free.  There's a
_big_ difference between saying "3DES is a trusted algorithm" and saying
"GnuPG correctly implements 3DES."
I think GnuPG's implementations are probably good; I don't have any
evidence to suggest they're not.  But I can't say they're good.
Second, please don't trust a word I say.  Seriously.  I make a ton of
mistakes every single day.  I might be making one right now.  Do your
own research, find out facts for yourself.
Yes.  Please note that I'm not saying either of them made a right or
wrong choice.  They each came to the table with certain basic
assumptions and came to very different conclusions.
David and I disagree pretty substantially on the subject of the size of
the OpenPGP spec, and how much of it GnuPG should be implementing.  I
think both he and I are being sensible.  We're just coming to very
different conclusions.
In the world of Free Software, he who writes the code gets to make the
decisions.  For GnuPG, that means David and Werner.  I don't begrudge
them that one bit.  It's their barbecue, and on the whole the barbecue
is good.  I don't want anyone to mistake me on this.
My quibbles are not with GnuPG.  My quibbles are with the OpenPGP spec.
 I think GnuPG is the best implementation of OpenPGP out there right now.

@_date: 2009-01-24 00:44:35
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
The ability to use multiple algorithms is independent of how many
algorithms are in the spec and in each implementation.  Algorithm
agility is a great idea and I think protocols ought be designed with it
in mind; but at the same time I think protocols ought to focus on a
minimal set of algorithms.
An extension mechanism is a great idea.  I don't think that should be
carte blanche for a spec throwing the kitchen sink into the RFC, though.
Yes.  We're in total agreement that algorithm agility is a good idea.
Looking over RFC4880, 3DES is the only MUST symmetric cipher, but it
makes mention of Twofish, Blowfish, CAST, IDEA and AES.
Better, in my mind, to reduce this to 3DES (or AES, take your pick,
algorithm agnosticism and all).  Move the others to an appendix.  Note
them for history and interoperability with old versions, but encourage
implementors to not use old algorithms for new traffic unless there is a
compelling reason not to.
I don't see how to use preference lists to argue for that transformation
in how the implementor community views the standard.
This is actually what I do.  If someone sends me traffic that's
encrypted with an exotic, well, I'll use my system's GnuPG (as opposed
to the one living in $HOME/bin) to decrypt it.
... I'm motivated, to some degree, by my own frustrations in
implementing RFC2440 for a telco back in '99.  My implementation was
simple: 3DES, SHA1, DSA/ELG, no compression, no MDC, no nothing, but it
was -- as far as I could tell; it's been ten years, please understand my
memory isn't perfect -- standards-conformant.  I could send traffic to
PGP and GnuPG, PGP and GnuPG could, with the proper settings, send
traffic to me.  Success.
It was not enough of a success for Management.  They insisted on
supporting IDEA, CAST, MD5, RIPEMD160, etc. -- when I got knocked down
on a performance review because I hadn't yet implemented double-width
SHA or HAVAL, I knew they were viewing each and every algorithm as a
checkbox. [*]
This is obviously far, far more a failing of management than a failing
of the spec.  That said, I think the spec contributes to this kind of
misreading and misunderstanding.
This bit of work history anecdote should not be read as any kind of
argument for or against anything.  It's just a where-I've-come-from sort
of thing.  That said, if you ever have the chance to write software for
the telephone company, don't.
[*] For people on the list who don't remember the state of the RFC from
the '99-'00 era, double-width SHA and HAVAL were mentioned in RFC2440.
To the best of my knowledge, though, nobody ever actually implemented
them.  (In the case of double-width SHA, I don't know if the algorithm
even existed.)

@_date: 2009-01-24 13:29:06
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
To quote one of the best, most promising, and most vastly underused,
statements in engineering:
Hmm.  I need to think about that...
This doesn't explain Twofish, Blowfish, RIPEMD160, etc., etc.  These are
well-designed algorithms that very few people use, and they're still
littering the standard.  I don't think it's at all unreasonable to say
"Camellia has users supporting it, sure, but before we go about adding
new algorithms, let's prune out old ones."  The cruft needs to be
removed, and I don't see the WG addressing the problem.  (I'm on the WG
mailing list, although I rarely speak up there.)
Clear to you, yes.  Clear to me, yes.  It seems that it is not clear to
others.  People say "well, CAST5 is in the RFC, so I'll use it," not
"well, CAST5 isn't a MUST, so I shouldn't depend on it being present."
I favor it being defined for the people who need it.  I also favor
putting in forty-eight-point boldface type "don't depend on other people
supporting this because they probably won't and it's probably a good
idea not to support it unless you have a pressing need."
You say this is already conveyed by the fact it's optional.  I disagree.
My counterargument of, "it's a conformant implementation that matches
all the MUSTs of the RFC, that's what I said I'd do, that's what I did,"
fell on deaf ears.  After all, how could be be a conformant
implementation if it didn't have double-width SHA or HAVAL?  They're
right there in the spec, after all.
If I had said, "I have total coverage of the entire spec, the appendices
are optional, that's why they're in appendices," I think it would have
gone over better.  However, counterfactuals being historical fiction, I
can't definitively say it would have helped, only that I think it would
As simple as we tend to think MUST, MAY, SHOULD, etc., are, Management
is often not capable of understanding those words.

@_date: 2009-01-24 20:04:31
@_author: Robert J. Hansen 
@_subject: A question about Camellia 
The story is apocryphal, so it doesn't make much sense to talk about the
motives of the people involved -- it's fiction.  But even were it true,
I'd be hard-pressed to agree that it shows ignorance on the part of the
AF engineers.  It shows the AF engineers and the Navy engineers looked
at the same data and drew two completely different conclusions -- and
both of them were right.

@_date: 2009-01-26 10:01:38
@_author: Robert J. Hansen 
@_subject: Safety of the key and it's length 
A 2048-bit number is just 256 bytes of data.  There's a lot of stuff
which goes into a key, of which the secret values are only the smallest
Impossible to say from this information.
Even a small key, 1024 bits, is probably much more secure than you are.
If your traffic is encrypted with even a 1k key, the likelihood of
someone attacking your traffic cryptanalytically is about zero.  They'll
decide to try other means instead.
It's best not to obsess over key size.  Larger is not better, but it's
not as if it hurts you, either.

@_date: 2009-01-26 12:07:26
@_author: Robert J. Hansen 
@_subject: Safety of the key and it's length 
Depends on your threat model.  Secure against a casual snoop?  Probably.
 Secure against someone who knows what they're doing and is willing to
put a little thought and effort into it?  Not at all.

@_date: 2009-01-28 12:26:04
@_author: Robert J. Hansen 
@_subject: Series of minor questions about OpenPGP 5 
Werner has already answered most of this, so I'll confine my remarks to
just this --
Anyone who uses the Mersenne Twister to generate cryptographic
pseudorandom values is living in sin.

@_date: 2009-01-28 12:36:10
@_author: Robert J. Hansen 
@_subject: Series of minor questions about OpenPGP 5 
True randomness exists in nature, but so far we're unable to detect it.
 (Seriously.)
Imagine you have a Geiger counter and a radioactive sample.  Over each
time frame, the Geiger counter reports how many decays it measures.
That number becomes your random value.  So far, so random, right?
But a Geiger counter has a reset time.  Once it clicks, there's a small
time window in which it's unable to detect new decay events.  This has
the effect of introducing a bias into your random number generator: some
decay events will be transformed into non-events.
There are some tricks of physics and mathematics you can use to get very
high quality values out of this kind of radioisotope setup, but the
basic problem remains: even when measuring a totally nondeterministic
event, determinism in the detection mechanism will undercut you.  You
can get really, really close to truly random numbers, but you can't get
Linux has support for some hardware RNGs, yes.  I don't know offhand
which ones.  OpenBSD apparently has support for a lot of them.

@_date: 2009-01-28 15:50:38
@_author: Robert J. Hansen 
@_subject: randomness  //  how important is it 'really', 
Sure.  John von Neumann, one of the Grand Old Men of computer science,
once said something to the effect of "anyone producing random numbers by
algorithmic means is, of course, living in sin."  (Which is also why I
used the "living in sin" wording a couple of posts ago; it was an homage
to von Neumann.)
The interesting questions are then, (a) how do we do it, (b) what
constraints are put on it, (c) how many resources it will take, and (d)
if there's anyone smart enough to figure out (a) through (c).
Somewhere between "not at all" and "run for the hills."  Wish I could
give a more precise answer than that.
The pace of mathematical and technological development is not linear.
It's a series of plateaus and enormous jumps.  E.g., for a long time
SHA-1 was one of the strongest hashes out there, up until some
researchers from Shengdong University blew us all away.  Plateau, and jump.
It is possible that tomorrow someone will discover an attack against the
Merkle-Damgard construction and all the hashes in GnuPG will become
vulnerable.  And it's just as possible that we'll be in a plateau for
the next ten years.  It's impossible to say with any certainty.
Not that we know of.  Yet.  Maybe tomorrow, maybe in ten years.

@_date: 2009-01-28 18:44:00
@_author: Robert J. Hansen 
@_subject: Selection of digest algorithm 
Evolution's GnuPG support is in many ways broken, FYI.  I have
repeatedly had troubles with it misreporting inline signed messages as
having bad signatures, misreporting inline signed and encrypted messages
as being only encrypted, as misreporting trust levels, as... etc., etc.
Evolution's core developers seem to believe RFC3156 is the be-all and
end-all of OpenPGP support, and even then, it's a somewhat idiosyncratic
3156, if I recall correctly.
What sort of smartcard are you using, and what does it support as far as
hash algorithms?

@_date: 2009-01-29 09:22:18
@_author: Robert J. Hansen 
@_subject: Selection of digest algorithm 
No.  Jeff Anderson, Evolution's main GnuPG author, told me directly they
supported RFC3156.  He went on at great length about how inline traffic
is stupid and it isn't RFC-approved for email use, and how RFC3156 was
the One True Way regardless of what people wanted.
So yeah, taking Jeff at his word, he implemented RFC3156.  He's just
artificially restricting which hash algorithms can be used, which has
the added side effect of completely breaking Evolution for DSA2 keys.
Evolution cannot sign messages with a DSA2 key -- or at least, I've
never found a way to do it short of going in and hacking up the source code.
I do not think very highly of Evolution's OpenPGP support.
I found out just by writing a tiny shellscript wrapper which echoed the
arguments given to GnuPG.
These would be the parts they're not setting on the command line.
At last year's USENIX, in a panel discussion, Dan Wallach of Rice
declared Enigmail the best thing going in terms of OpenPGP integration.
 That's high praise coming from a very well-respected guy in computer
This was said as part of a sidebar he made about the difficulty in
getting 30+ Ph.Ds in computer science to all use PGP for a particular
mailing list.  Some were using Evolution, some were using ancient PGP,
some were using modern PGP, some were using plugins, others were C&Ping
into a Microsoft Word document then using some weird Word PGP plugin,
some were using Enigmail, etc.  He capped it off with an exasperated
sigh, then recommended Enigmail to people who needed OpenPGP
integration, as Enigmail gave the least troubles.
It is.  But it's not /severely/ hampered.  E.g., address book
integration doesn't work because the address book internals are such a
maze of twisty little passages, all alike.

@_date: 2009-07-01 17:22:13
@_author: Robert J. Hansen 
@_subject: Anyone afraid of quantum computer? 
Our largest superpositional computer can store about five qubits.  We'd
need to hit about 5000 qubits before public key cryptography would be in
trouble, and about 10000 qubits before it would be in a lot of trouble.
Once you see IBM put together a 3000-qubit computer, then will be the
time to start worrying about public-key cryptography.
At present, superpositional computation is science fiction.

@_date: 2009-07-07 16:53:37
@_author: Robert J. Hansen 
@_subject: algorithm 11 mistake mac 
Please don't.  Use "personal-digest-preferences SHA256" instead.
digest-algo is an option for experts.  Improperly used, you can  seriously harm interoperability.

@_date: 2009-07-07 17:32:26
@_author: Robert J. Hansen 
@_subject: algorithm 11 mistake mac 
As I understand things, this is largely (almost entirely) irrelevant.   Am I mistaken?

@_date: 2009-07-07 18:10:07
@_author: Robert J. Hansen 
@_subject: algorithm 11 mistake mac 
That's exactly what I was asking.  Speaking for myself, I think it's  preferable to use SHA-256 over SHA-224, even in instances where 32  bits of it are stripped -- mostly for interoperability reasons.  But  other people's mileage may vary.

@_date: 2009-07-08 08:18:03
@_author: Robert J. Hansen 
@_subject: 8192bit RSA keys 
With respect to key sizes, nothing has changed since then.
IMO, keys larger than 2kbit have no practical purpose for >95% of users.
 Keys larger than 4kbit have no practical purpose, period.

@_date: 2009-07-08 22:41:22
@_author: Robert J. Hansen 
@_subject: Opinions on RIPEMD vs SHA? 
The new SHAs have the benefit of about a dozen years of cryptanalytic  research behind them.  RIPEMD160 is very similar to SHA-1, and the  recent attacks against SHA-1 are likely applicable to RIPEMD160.   Those same attacks do not apply against the newer SHAs.
"Romanticism" is exactly the right word to use.
Yes.  It's been in PGP since 6.5.8, and in GnuPG since 1.0.  (Probably  since long before 1.0, but since 1.0 was the first official release,  that's where I trace things back to.)

@_date: 2009-07-26 23:20:49
@_author: Robert J. Hansen 
@_subject: Encryption keys in the OpenPGP spec 
It is conceivable there may exist some highly niche areas which need  the ability to definitively say, "this encryption key may only be used  for this purpose, and that encryption key may only be used for that  purpose."  The spec allows these users to make those sorts of  It doesn't suggest the distinction is irrelevant -- only that GnuPG  doesn't enforce a distinction.  The spec requires some behavior, and  other behavior is left up to implementors to decide whether, and how,  to implement it.
For users who need the sorts of guarantees mentioned in my first para,  they need to use a different product than GnuPG.  That's not a bad  thing: different software packages are aimed at different groups of

@_date: 2009-07-27 09:26:25
@_author: Robert J. Hansen 
@_subject: IT Department having the secure key. 
This sounds quite a bit like the Additional Decryption Key (ADK)  feature of PGP.  It's worth noting that (a) PGP's ADK feature is not  quite what people want to believe it is, and (b) is covered by a  software patent held by PGP Corporation.  If someone's interested in  pursuing this route, it would be a good idea to speak to a good patent

@_date: 2009-07-30 08:45:19
@_author: Robert J. Hansen 
@_subject: Public key crypto by hand 
I am aware of none, and there are some good theoretical reasons to  think there are none.
That said, beware of all theories: when theory conflicts with the real  world, theory must give way.

@_date: 2009-07-30 13:44:10
@_author: Robert J. Hansen 
@_subject: Public key crypto by hand 
We've known since '99 that Solitaire is weak, thanks to the work of  Paul Crowley.

@_date: 2009-07-30 14:04:37
@_author: Robert J. Hansen 
@_subject: Public key crypto by hand 
Solitaire has some serious problems, and is not a public-key  algorithm.  The original poster specifically requested public-key  algorithms, not conventional crypto which can be done by hand.

@_date: 2009-07-30 14:41:53
@_author: Robert J. Hansen 
@_subject: Public key crypto by hand 
The danger comes from assuming you're more sophisticated than the  people who want your information.

@_date: 2009-07-30 19:06:08
@_author: Robert J. Hansen 
@_subject: Changing GPG's default key type? 
The patent never expired.  It was due to expire in September 2000; in  August 2000 the patentholders released it into the public domain.   Some people (myself included) think they did this in order to prevent  the media coverage of patent-expiration celebrations.  I was really  looking forward to the party Network Associates (then the owner of  PGP) was throwing, and then got cancelled.
No; only people using OpenPGP applications that don't support RSA will  have problems.  This is potentially quite a lot of people.  The last  time I tallied it up there were at least ten different OpenPGP  implementations, and some of them only support the bare minimum

@_date: 2009-07-30 21:23:51
@_author: Robert J. Hansen 
@_subject: list of OpenPGP implementations [was: Re: Changing GPG's default 
Wikipedia has a pretty good list, last I checked.  If you're really  interested, check there; my list will not be as comprehensive.
Deployment numbers are both hard to come by and misleading.  GnuPG is  probably overwhelmingly the largest, since it comes standard with  pretty much every Linux distro; but there it's used principally for  package authentication, and few people use it directly.  By  comparison, McAfee is a niche player, but they're pretty big in the  enterprise -- when Network Associates sold off (abandoned) the PGP  desktop suite, they retained the right to sell PGP to enterprise  customers.  Hence, McAfee may be a much bigger player than people think.

@_date: 2009-07-30 21:26:03
@_author: Robert J. Hansen 
@_subject: Changing GPG's default key type? 
I missed the original poster's qualification that 90% of his  correspondents used GnuPG.  Given that, I'll agree with you on this:  RSA won't be a problem.

@_date: 2009-07-30 22:06:35
@_author: Robert J. Hansen 
@_subject: list of OpenPGP implementations [was: Re: Changing GPG's default 
I don't know.
There are a wide number of implementations with various degrees of  conformance, RFC4880 is fairly new and there's no guarantee vendors  have caught up with it, old systems continue to be used despite our  wishes (look at how many 6.5.8 users are out there), and so forth and  so forth.
My judgment is that it's wise to keep some healthy skepticism about  what optional bits of the spec are broadly-supported.  I think the  instant I tell someone "everything uses RSA," they're going to come  back and say "well, my bank uses FooBarBazQuuzPGP, and they can't read  my traffic," Murphy's Law being what it is and all.
Reasonable people may certainly disagree with my judgment.  :)

@_date: 2009-07-31 00:35:37
@_author: Robert J. Hansen 
@_subject: list of OpenPGP implementations [was: Re: Changing GPG's default 
Yes; it was more a general statement about why when talking about  general interoperability with unknown clients I avoid optional bits or  bits newly-added to the standard, rather than a statement about RSA's  support in PGP.
Generally, I agree with you.  My own key is DSA2, for example.  But I  think that in the main, the advice of looking towards interoperability  is a good one, especially if you don't know the capabilities of other  Reasonable people may certainly disagree with me on this.  There's a  strong case to be made that by shifting to new implementations  pressure gets applied to users of outdated implementations to upgrade.

@_date: 2009-06-02 08:37:30
@_author: Robert J. Hansen 
@_subject: Security Concern: Unsigned Windows Executable 
Alternately, he could be implying an active MitM attack, where the
attacker is intercepting both the downloaded hash value (replacing it
with the trojaned version's hash value) and the application itself
(replacing it with a trojaned version).
That said, if you're presently being targeted by people who are capable
of intercepting and modifying your network traffic in realtime, neither
GnuPG nor Authenticode signatures can help you.  You need professional
help: lawyers and security geeks will help you an awful lot more than
HTTPS or Authenticode.
Insert mandatory "reflections on trusting trust" reference here.
The sentiment of "I must build it from source if I'm going to trust it"
is great, but then you have to ask questions about your compiler, your
system libraries, etc., until you're left hand-hacking Assembly
instructions for a low transistor count CPU you've personally
lithographed yourself from your own personal design.

@_date: 2009-06-02 19:02:53
@_author: Robert J. Hansen 
@_subject: Security Concern: Unsigned Windows Executable 
John Clizbe answered, "[i]f you're so committed to this verified and
signed thing that you're unwilling to trust anything, you should
probably look into building some things of your own."  My remark was a
very serious warning: if the OP is so committed, my "philosophical
digression" is what lies at the bottom of that rabbit-hole.
Active MitM assumes that you have an attacker who is technically skilled
and highly motivated.  It is ludicrous to think that an attacker skilled
enough to do active MitM and motivated enough to go after you directly
would for some reason be constrained to play within the carefully
defined box the crypto community has created.  Rule number one of
successful attacks: get outside the box.
If the OP is seriously concerned that there's an active MitM attack
going on against him, he needs get off the internet and obtain the
professional services he needs to end the threat.
No, I'm not kidding.

@_date: 2009-06-02 20:05:45
@_author: Robert J. Hansen 
@_subject: Security Concern: Unsigned Windows Executable 
There is a big difference between hack-in-a-box stunts like that and
serious attacks by people intent on succeeding.
You can't have it both ways.  You can't say, "it's really easy to do
active MitM, you just need to follow these basic instructions," and then
say, "but an attacker wouldn't be able to change sha1sums."  No, of
course they'd be able to: if you're assuming the attacker can inject
whatever they like into the data stream, then you have to assume the
attacker will use that capability intelligently.
And now you're arguing my point for me: there is a big difference
between hack-in-a-box stunts and serious attempts to subvert your system.
You are not understanding the metaphor; that may be my own fault.  "The
box" refers to the popular phrase, "think outside the box."
I do not see that what you are presenting is practical.  The presence of
a serious attacker who can subvert your traffic in ways of the
attacker's choosing is a massive game-changer.

@_date: 2009-06-05 14:19:45
@_author: Robert J. Hansen 
@_subject: Security Concern: Unsigned Windows Executable 
If your threat model is such that you're concerned about an active MitM
who is messing with your traffic in order to deliver trojaned binaries
to you, then you're in a game-over state.  You cannot win.
People like to talk about "an active MitM can deliver trojaned binaries
to you."  Sure, they can do that, but they probably aren't.  They're not
dumb.  The real situation is "an active MitM who has total control over
the traffic I receive and is intent on doing me harm."  This is a much,
much more serious problem.
I do not believe it is possible to ensure the security of your computers
or your communications when in the presence of an active MitM done by a
competent attacker.
I also do not believe it is wise to base your security policy on an
assumption that your attacker is incompetent.

@_date: 2009-06-05 14:33:25
@_author: Robert J. Hansen 
@_subject: Security Concern: Unsigned Windows Executable 
This metaphor is appealing: it's also inaccurate.
Let's say that you want to practice good fire safety in your home.
You've checked the smoke alarms.  You have a fire extinguisher in your
kitchen.  You've invested in electric induction rangetops instead of
natural gas.  Etc., etc.  You believe there are many small, reasonable
things you can do to prevent the risk of fire in your home.  And, to be
honest, you're correct: you are very well prepared for the overwhelming
majority of potential home fires.
Now someone drops a military incendiary bomb on your home.  It crashes
through the roof, lands in your living room, and a timer is counting
down to zero.
You can say, "well, we have fire extinguishers: we should at least /try/
to deal with the fire.  Sure, there's going to be a lot of fire.  But we
can at least deal with the small ones, so long as we're not making it
You can also say, "this is double the worst trouble I've ever imagined,"
and run away so fast you leave a you-shaped hole in the wall on your way
through it.
I heartily recommend the second.
Active MitM is pretty much the military incendiary bomb in the living
room.  A competent attacker who is controlling your network traffic and
wishes to subvert your system has so many ways to do it that you stand
effectively no chance of preventing it.

@_date: 2009-06-05 16:04:55
@_author: Robert J. Hansen 
@_subject: Security Concern: Unsigned Windows Executable 
Neighborhood kids who are playing tricks with your wireless router
clearly know more about your wireless router than you do -- so I
wouldn't be so quick to dismiss their potential.  They are apparently
more competent at penetrating your perimeter than you are at securing
it.  This out-of-hand dismissal seems especially naive.

@_date: 2009-06-06 19:52:32
@_author: Robert J. Hansen 
@_subject: Security Concern: Unsigned Windows Executable 
Yes.  Dodge the MitM.
Crypto aficionados like to talk about MitM as if good crypto can defend
against it.  To an extent it can, but _only if you assume your PC cannot
be hijacked._  If the attacker knows the endpoint and is controlling
your data traffic, then it is folly to assume the MitM will not or
cannot attempt to jack your endpoint.  If you're going to assume the
MitM is going to play nice and not use the best tools in his toolbox,
then while we are talking fantasies I would like it to be assumed I'm
wealthy and am married to Claudia Schiffer.
Dan Geer posted to this list a while ago his estimate that around 30% of
all PC desktops were already hijacked.  Vint Cerf's numbers are in the
same neighborhood.  One think tank in Australia believes the number if
over 50%.  The numbers are genuinely scary.  And keep in mind, these are
not numbers which suppose dedicated attackers who want to subvert your
machine: these are numbers which represent drive-by attacks sprayed at
whoever's convenient.
If you're going to assume the existence of an active MitM who will
deliver you trojaned binaries and will play games with SHA1 sums -- as
the original poster specified -- then you have to assume you are dealing
with someone who is going to attempt to jack your box.  The odds are
quite good that they will succeed.  Once your box is jacked, the game is
over and you cannot win.
OpenPGP is a great standard.  It's very useful.  It's a good tool in the
toolbox.  But it is not magic fairy dust and it cannot work miracles.

@_date: 2009-06-12 18:54:54
@_author: Robert J. Hansen 
@_subject: Security Concern: Unsigned Windows Executable 
The signcode.exe tool is proprietary, but it does not depend on the code
being produced by a proprietary compiler.  IIRC, that is: it's been a while.

@_date: 2009-06-19 17:40:37
@_author: Robert J. Hansen 
@_subject: GnuPG 2 under Windows 
If you look at  you will discover 1.4.9 is the
latest release in the 1.4 series.  There is no 1.4.10, at least not yet.

@_date: 2009-06-22 19:39:52
@_author: Robert J. Hansen 
@_subject: Hibernation and secret keys 
The word "secure" is meaningless except in a carefully defined context.
 What does "secure" mean to you?  Define the word and then people can
give their own two cents worth.
If I could change just one thing about the world of computer security,
it would be the word "secure."  It's used far too glibly, and very often
to the detriment of constructive discussion.

@_date: 2009-06-26 10:05:52
@_author: Robert J. Hansen 
@_subject: Question of a beginner: DSA/ElGamal or RSA/Elgamal with a higher 
Beginners should:
GnuPG is meant to be as straightforward as possible for new users.  You
don't need to worry about the details of which algorithm is used and in
what length and whatnot.

@_date: 2009-06-28 18:11:10
@_author: Robert J. Hansen 
@_subject: Exposing email addresses on key servers 
Because the bank is concerned about the bank's security, not yours.  The
bank exposes itself to no additional risk by sending out HTML email.
You expose yourself to some risk (how much depends on your MUA) by
reading HTML email.
Since the risk is borne by you, and the reward -- in the form of a more
professional-looking communication -- is gained by the bank, it's in the
bank's best interests to send HTML email.

@_date: 2009-06-29 08:51:46
@_author: Robert J. Hansen 
@_subject: Exposing email addresses on key servers 
So what?  The bank's already set to either strip out all dangerous HTML
tags or to render as plaintext only.  The bank knows it's a target of
attack; it's already taken steps to mitigate its risk profile.  Also,
the number of people who communicate with their bank via email is
vanishingly small: many banks outright refuse to deal with customers via
email for reasons of banking secrecy.
The bank has no downside to sending HTML email.
Fine: they lose your vote.  But in the course of looking unprofessional
to you, securitywise, they look quite professional to their other
customers, who either don't know or don't care the risks of HTML email.
Computer security geeks are such an insignificant fraction of the
consumer marketplace that for most purposes we may be safely assumed to
not exist at all.

@_date: 2009-06-29 23:58:00
@_author: Robert J. Hansen 
@_subject: Exposing email addresses on key servers 
I agree wholeheartedly with what John says here.  This is an agreement
and a slight addition, not a dissent.
A Greek named Xenophon wrote, "in the end, the art of war is about
keeping your freedom to act."  In the 2500 years since he wrote that, no
general has managed to improve on it.  As long as you're able to act,
you're still in the fight.  The instant you lose that ability, you're
either a casualty or about to become one.
General spam defenses work very well because even after spam gets
through them, you can still take action.  You can tweak the Bayesian
filter.  You can use a different realtime black hole list.  You can
switch from one filtering system to another.  Even if the spam gets
through, there are still effective actions you can take: you're still in
the game.
As John points out, sheltering your email address doesn't work.  Once it
gets out there even once, then it's out for good.  You're investing time
and work in a battle that you know you're going to lose, which you know
you're going to lose soon.  You have no move once it gets out; once you
suffer any breach, you can't mitigate things.
General spam defenses leave you with freedom to act even after you get
hit.  Suppressing your email address doesn't.
Take a lesson from Xenophon.  Focus on defenses that maximize your
ability to act.

@_date: 2009-03-03 18:26:21
@_author: Robert J. Hansen 
@_subject: surrendering one's passphrase to authorities 
That capability would literally be worth people's lives.  It makes no
sense to think that they would reveal that capability just to bag a
run-of-the-mill child porn aficionado.
It seems rash to draw that conclusion from the offered data.
For the UK, I believe the Regulation of Investigatory Powers Act (RIPA)
is still in effect.  Quite a ghastly bill, really.

@_date: 2009-03-03 18:40:18
@_author: Robert J. Hansen 
@_subject: surrendering one's passphrase to authorities 
Yes.  It's the same as the S2K in OpenPGP, last I checked -- which is
specifically designed to make brute forcers slow.
Let's say the guy has a passphrase with 64 bits of entropy.  Assume you
have a massively distributed network and some truly cutting-edge math,
you could probably do it in two solid years of work.  The RC5 project on
distributed.net took 18 months to do 64 bits, but RC5 wasn't designed to
be very slow to rekey.
Now consider just how many 64-bit keys the US government would like to
crack.  It probably numbers in the millions.
Now consider how high this guy's passphrase stands in the to-do list.

@_date: 2009-03-03 19:31:03
@_author: Robert J. Hansen 
@_subject: surrendering one's passphrase to authorities 
Let me see if I have this clear:
- He knew he was approaching a border
- He knew he had child porn on his system
- He knew his laptop might be searched at the border
- And you think, knowing all this, he'd use a weak passphrase?
If you're talking about a chump who hasn't bothered to think things
through, sure.

@_date: 2009-03-04 17:46:38
@_author: Robert J. Hansen 
@_subject: surrendering one's passphrase to authorities 
Perry is an optimist.  It's considerably worse than he makes it out to be.
Judges are not idiots.  They are very well-trained and have a great deal
of experience at the discovery of truth through Socratic and/or
adversarial questioning.  They are also rather dispassionate, which
stems from the tremendous amount of human evil they come into contact
with on a regular basis.
Juries, on the other hand...
In the American system (and many other systems borrowing from the
British Common Law tradition), the judge is the arbiter of law, but the
jury is the arbiter of fact.
If the judge has any doubt as to whether there's an encrypted volume on
the drive, the judge is probably not going to bother putting the accused
in jail on a contempt charge.  The judge is going to say, "the existence
or nonexistence of material on that drive is a question of fact for the
jury to sort out."
And once the judge says that, you're rolling the dice with twelve plain,
average, human beings -- which is to say, most of them will be
technologically illiterate with little or no college education or grasp
of formal reasoning.
If you look at those twelve men and women and start to explain about
deniable systems and perfect forward secrecy and every other crypto
innovation you've thought of to keep you out of trouble, the jury won't
understand a word of it.  Not a word.
They _will_, however, understand that you're blowing smoke up their ass.
This is a mistake you will only ever get to make once.

@_date: 2009-03-04 21:17:01
@_author: Robert J. Hansen 
@_subject: surrendering one's passphrase to authorities 
Voir dire is the name given to the interview process, not to the
strikings.  A striking can be "for cause" (a juror who says they can't
be impartial, for instance) or for no reason at all in what's called a
"peremptory challenge."
It is unlawful to use peremptory challenges to shape the racial or
religious composition of the jury, but as long as you're not doing that,
you can strike whoever you like for whatever reason you like.
It's even worse than that.
A year ago I was given a jury summons.  The first case, I survived
challenges for cause.  They asked if anyone could describe a millimeter.
I raised my hand, they called on me and I gave them the SI definition.
I was promptly peremptoried.
Plaintiff's counsel didn't just want to avoid people with subject matter
knowledge.  Counsel wanted to avoid anyone who knew anything about basic
physics, and they used the metric system as a test to see who had any
background in physics.
The next trial was a sexual abuse case with some very hideous
particulars.  Defense counsel asked everyone what probability we gave
that her client was guilty.  One woman said 70%, since she was a
schoolteacher and she knew how many layers of bureaucracy were involved
in getting a sex abuse case to trial.  One man said at least 50%, since
otherwise it was a lot of work and taxpayer money for nothing.
I refused to answer the question.  I explained the question had improper
foundations.  Probability is based on prior observations of identical
phenomena.  I didn't know anything about the defendant or the
particulars of his crime, so there was no probability I could assign.
He either did it or he didn't, and I was willing to help determine which
it was -- but I would not attach a probability to his guilt or innocence.
The woman who said 70% and the man who said 50% were both seated on the
I wasn't.
It's true that lawyers will remove a juror with actual knowledge about
the subject matter -- but more than that, lawyers will remove jurors
with actual knowledge.  If you show an ability to think critically and
independently, the lawyers will move heaven and earth to remove you from
the jury pool.
A critical and independent thinker will go their own way in the trial.
That makes them wild cards.  No lawyer wants a wild card in the jury
pool.  They want people who can be led to a conclusion.

@_date: 2009-03-15 22:05:42
@_author: Robert J. Hansen 
@_subject: gnupg vs. gnupg2 
GnuPG 2 is somewhat larger and provides S/MIME support and gpg-agent. That's really about it.
According to Werner, yes.  Me, I wouldn't call GnuPG 2 for Windows ready for prime time.  Over on Enigmail we see a fair number of GnuPG 2 for Windows problems -- or have historically; we haven't had much lately.
Can't answer this one, since I use 1.4.

@_date: 2009-03-18 17:58:46
@_author: Robert J. Hansen 
@_subject: GNUPG 
Unfortunately, we are not mind-readers here.  At the very least we'd need to know your operating system and your current version of GnuPG. Most upgrades are painless, but upgrading from very old systems can have a snag or two.

@_date: 2009-05-01 00:13:49
@_author: Robert J. Hansen 
@_subject: Selecting cipher to generate a key pair 
It's hard to talk about how good it is.  Cryptography is an intensively
mathematical discipline, and most people are not very well-equipped to
discuss those details.
Ultimately, it would be like arguing whether King Kong or Godzilla is
better at urban destruction.  Biologists can argue until the cows come
home which one would be better and why, but from the perspective of your
average inhabitant of Tokyo or New York City the answer is, "Who cares?
 Get out of town _right now_!"
CAST5-128 does the job just fine.  The only instances I'm aware of in
which CAST5-128 doesn't do the job well are ones where bureaucratic
rules require specific algorithms, and CAST5-128 isn't on that
checklist.  That's a bureaucratic failing, though, not a failing of

@_date: 2009-05-01 18:57:34
@_author: Robert J. Hansen 
@_subject: Selecting cipher to generate a key pair 
rjh at chronicles:~$ gpg --enable-dsa2 --gen-key
Please select what kind of key you want:
   (1) DSA and Elgamal (default)
   (2) DSA (sign only)
   (5) RSA (sign only)
If you choose  you will be using, by default, DSA as a signature
algorithm, AES256 as a general-purpose message encryption algorithm,
Elgamal as an asymmetric encryption algorithm, and SHA1 as a hash algorithm.
None of these algorithms are actually used to generate the
private/public keys, though.  The private and public keys are just
numbers.  GnuPG generates those numbers from a cryptographically secure
pseudorandom number generator, then subjects the numbers to a battery of
mathematical tests to make sure the keys are safe to use.
Is it possible for you to tell us what algorithms your correspondent
expects you to use?  Knowing that might help us out quite a bit.

@_date: 2009-05-01 19:21:40
@_author: Robert J. Hansen 
@_subject: Selecting cipher to generate a key pair 
It probably does, actually; PGP just, for marketing reasons, calls it
Diffie-Hellman/DSS.  (Long story, but yes, they're the exact same thing.)
That said, your customer does not appear to understand how GnuPG or PGP
work.  _All_ OpenPGP-conformant applications (GnuPG, PGP, and others)
can handle 3DES; and 3DES has absolutely nothing to do with how you
generate your public key.

@_date: 2009-05-01 19:39:19
@_author: Robert J. Hansen 
@_subject: Selecting cipher to generate a key pair 
Okay, that much makes sense now.
I would suggest adding:
cipher-algo 3DES
... to your .gnupg/gpg.conf file.  This is a sledgehammer solution, and
not one I'd generally recommend; however, the downsides are pretty
minimal.  Then encrypt a message using their public key and send it on
to them.  If they can read it, great.  If they can't, then the problem
is their proprietary implementation of OpenPGP is shoddy.
Incidentally, if your customer is a telecommunications firm, I think I
may know the implementation they're using and some of its more egregious
misfeatures.  Other than that one and PGP Corporation's offering,
though, I have no experience with proprietary OpenPGP offerings.

@_date: 2009-05-01 19:59:22
@_author: Robert J. Hansen 
@_subject: Selecting cipher to generate a key pair 
You're assuming the customer's key is correctly advertising their
preferences.  If their proprietary implemention is a shoddy one, then
maybe it advertises capabilities they don't really have.
You'd hope so, yes -- but I think we might want to consider the
possibility the customer's implementation is terribly broken.

@_date: 2009-05-02 11:42:16
@_author: Robert J. Hansen 
@_subject: Selecting cipher to generate a key pair 
This process will vary from operating system to operating system.  What
works for Fedora isn't the same as what works for Ubuntu isn't the same
as what works for FreeBSD isn't the same as what works for Windows.
I don't know how Fedora works, so I'm not able to answer this question.
 I would suggest asking on a Fedora mailing list.

@_date: 2009-05-02 16:43:00
@_author: Robert J. Hansen 
@_subject: Use other hash than SHA-1 
Not much.  They're both 160-bit Merkle-Damgard hashes.  RIPEMD160 comes
out of Europe, SHA-1 comes out of the National Security Agency.
Some people distrust anything that comes out of the NSA.  For these
people, RIPEMD160 is a good option.
I think the reason why RIPEMD160 has survived so long is due to the fact
hardly anybody is looking at it.  Given all we've learned about
attacking hash functions from the SHA-1 and MD5 papers, I think it's
fair to be a little skeptical of RIPEMD160's long-term prospects.

@_date: 2009-05-07 01:45:43
@_author: Robert J. Hansen 
@_subject: Can GPG 1.4.9 be used for commercial purposes ? 
Yes.  GnuPG places no restrictions of any kind on how the program may be

@_date: 2009-05-07 02:45:02
@_author: Robert J. Hansen 
@_subject: How to import a key from GPG 1.4.9 to PGP ? 
This is generally not worth doing.  It can be done, but it is not
Is there any possibility of installing PGP 9.x on your XP machine instead?

@_date: 2009-05-10 18:00:06
@_author: Robert J. Hansen 
@_subject: Problems changing hash algo for clearsign 
Please don't.  This is usually the wrong solution.

@_date: 2009-05-14 23:40:58
@_author: Robert J. Hansen 
@_subject: Photo's in keys? 
Is there any guidance on what size PGP expects it to be (in terms of
screen dimension, not size)?

@_date: 2009-05-16 10:49:41
@_author: Robert J. Hansen 
@_subject: problems with PGP/MIME 
We're glad your problem has been solved.  :)  However, in the future,
could you please trim your quotes?  I would appreciate it, as would I
think many others.

@_date: 2009-05-16 18:41:56
@_author: Robert J. Hansen 
@_subject: There are actually two public keys? 
There are two keypairs.  One keypair is used for signing, and the other
is used for encrypting.  The private part of the signing keypair is used
 to generate signatures; the public part is used to verify them.
Likewise, the private part of the encryption keypair is used to decrypt
documents; the public part is used to encrypt them.

@_date: 2009-05-16 21:33:10
@_author: Robert J. Hansen 
@_subject: There are actually two public keys? 
The shift from single keypairs to multiple keypairs was motivated by a
lot of concerns.  IMO, most of those concerns failed to materialize.
For instance, some people say that separate signing and encrypting keys
is best, since if an encryption key gets compromised you can just revoke
the encryption part and leave your signing key intact.  In reality,
compromise tends to be an all or nothing affair: either the entire cert
is suspect or it's not.

@_date: 2009-05-21 10:59:21
@_author: Robert J. Hansen 
@_subject: AW: Re: laying groundwork for	an eventual migration away from 
This subject is increasingly off-topic for -devel.  I've cc'd this
message to -users; let's see if we can't move the thread there.
With a high-quality forged passport I can not only travel -- I can also
vote, run for (most) public offices, get utilities in my name, open bank
accounts, and so on.  Those secondary pieces of documentation won't be
forgeries, they'll be real -- and once I have them, I destroy my forged
passport and settle into my new assumed identity.
If the attacker is smart enough and savvy enough to get a high-quality
forged passport, there's no way they'll present it for inspection to
someone who's actively looking for a forged passport.  They'll present
their real (obtained illegally and containing incorrect information, but
quite real) identity documents instead.
Further, you won't find 100% security anywhere.  Pursuing it is an
ephemera.  You won't get there, and if you obsess over it your obsession
will ultimately hurt your security.

@_date: 2009-05-21 14:24:53
@_author: Robert J. Hansen 
@_subject: laying groundwork for an eventual migration away from SHA1 with 
(also cc'd to GnuPG-Users.  This thread seems like it's more appropriate
there; let's continue it there if possible.)
I chose the example I did because I couldn't find information on
Arkansas driver's license security features in a five minute web search.
 Other states may be different, I don't know.
Yeah, that's why I show up to the keysigning BoFs at conventions.  :)

@_date: 2009-05-23 22:15:13
@_author: Robert J. Hansen 
@_subject: Key Transition Letter 2009-05-21 
Sorry to be so late to the party --
As of this writing, no algorithm supported by GnuPG has been
compromised.  Even MD5 is still on its feet.
That said, the SHA-1 and MD5 algorithms are both looking a little shaky,
and generally the recommendation seems to be to move away from those
All other algorithms supported by GnuPG are in good shape.
Please don't do this.  The defaults are the defaults for a very good
reason: they're good defaults.  With the exception of "move away from
SHA1", please do not mess around with the defaults more than you
absolutely have to.

@_date: 2009-05-24 02:15:39
@_author: Robert J. Hansen 
@_subject: Key Transition Letter 2009-05-21 
It depends on what sort of threat you're facing.  In this case, the MD5
attack is predicated on the victim signing documents they did not
originate.  This is often considered bad policy, since it tends to
facilitate attacks like this.  This usage case is kind of rare for GnuPG

@_date: 2009-05-24 18:09:20
@_author: Robert J. Hansen 
@_subject: MD5 is an unreliable digest algorithm [was: Re: Key Transition 
Yes.  And then if you take a look at how often this happens with MD5 in
OpenPGP, you'll find the answer is effectively never, since SHA-1
generally gets used instead.  So this attack is mostly a nonissue for
OpenPGP usage.
I am getting pretty frustrated with how people are misreading,
misinterpreting, or outright not listening to the qualifications I am
putting on the things I'm saying.
My original text was, "it's kind of a stretch to say that it is entirely
broken for purposes of email cryptography."  The word "entirely" is
pretty important there.
Algorithms are not, as is commonly believed, to be either "secure" or
"insecure".  OpenPGP in particular is used in a variety of different
ways.  There is a continuum of "secure for all known uses of OpenPGP" at
one end, and "insecure for all known uses of OpenPGP" at the other, and
a lot of gray area in the middle where "secure for some uses" lives.
MD5 is in that continuum.  It is not /entirely/ broken, as seems to be
the common misperception.
Yes.  Which is exactly what I've been saying.

@_date: 2009-11-02 10:19:56
@_author: Robert J. Hansen 
@_subject: No secret key under different account 
I will stay out of this except to say options A and B are substantively
identical.  Beyond that, this is a system administration question.  I
know nothing of your system, and that means the best thing I can do is
to stay out of it.  :)

@_date: 2009-11-04 09:28:03
@_author: Robert J. Hansen 
@_subject: FSFE Fellower Card + LUKS on Startup 
It is likely not his fault.  The last two times this has happened it's
been because the GnuPG mailing list's server has run out of disk space.
 The server gets wedged and begins to act out in this particular way.
Let's all take a deep breath, back off, and wait for word from Werner
about what happened.  And let's especially not dogpile on the newcomer:
that's not a very nice thing to do.
The last time the mailing list got wedged like this, I was the one who
wrote the email that got sent out dozens of times.  You'd be appalled at
how many rude, profane and offensive messages I received from people
telling me to stop spamming the list.

@_date: 2009-11-05 11:59:33
@_author: Robert J. Hansen 
@_subject: Interesting article on password guessing via cloud computing 
An even more trivial way is to use a strong passphrase.  It's generally
wise to use the smallest hammer necessary to drive in the nail.

@_date: 2009-11-07 21:44:23
@_author: Robert J. Hansen 
@_subject: gpg rejects SHA224 with DSA-2048 
Your key is not on the keyserver network, so that will impair our
ability to help you out with this.
It appears that your key is actually 14CA0E78.  To tell it to use a
particular subkey, you need to append a "!" to the subkey ID.
Otherwise, I believe GnuPG's behavior is to look at the certificate that
subkey belongs to, and use the largest signing subkey on that
certificate.  If you have a 3072-bit signing subkey on 14CA0E78, this
would explain your problem.
~ $ gpg -u A39CE7E5! --digest-algo H11 -b test.txt

@_date: 2009-11-08 22:17:52
@_author: Robert J. Hansen 
@_subject: gpg rejects SHA224 with DSA-2048 
When did this changeover take place, and is there any way to get the old
behavior back?

@_date: 2009-11-08 23:11:01
@_author: Robert J. Hansen 
@_subject: gpg rejects SHA224 with DSA-2048 
Conformance with corporate IT policies.  Many corporate IT policies are
drafted by people who don't really understand the underlying
technologies.  They see the NIST drafts and say "ah, 224-bit hashes are
to be used with DSA-2048," and proceed to require SHA224 to be used with

@_date: 2009-11-09 10:09:56
@_author: Robert J. Hansen 
@_subject: gpg rejects SHA224 with DSA-2048 
I agree with you about the need to make policy decisions, which is why I
wasn't asking for an option to be added or for the change to be
reverted.  Saying when the change was made and how to revert it is
enough for me -- if it becomes important to someone, the knowledge is
out there waiting for a Google search.
Thanks, Werner, for the code extract.  I appreciate it.  :)

@_date: 2009-11-11 22:43:06
@_author: Robert J. Hansen 
@_subject: Error importing public key 
There certainly are bugs in GnuPG.  If there weren't, they wouldn't need
to release a 2.0.13 or beyond.  It seems unlikely that your problem is
caused by a bug, though: we would expect to see many other users with
the same problem.  The best thing we can do is to run down all the ways
that misconfiguration can create a failure.  Once all those things are
eliminated, then let's wonder about bugs in GnuPG.

@_date: 2009-11-13 22:40:26
@_author: Robert J. Hansen 
@_subject: gnupg support of google wave 
This is all a ton of cart-before-the-horse.
Let me ask a simple question.  "If someone enters into the wave, should
they be able to read previous traffic?"  Some people say yes, some
people say no.  Some use cases say it's obvious, others say obviously not.
It's rash to talk about supporting a particular protocol within Wave
before there's a consensus on what behaviors we want.

@_date: 2009-11-14 18:43:47
@_author: Robert J. Hansen 
@_subject: Key practice 
GnuPG best practices, in a single sentence:  "Unless you know what
you're doing and why, stick with the defaults."
This one sentence is useful for about 95% of new users' questions.
GnuPG is meant to be secure by default: you don't need to know a ton of
niggling little details just to use it safely.
You're in good company.  :)  People who write these sorts of articles
mean well, but it's very hard to figure out which authors actually know
what they're talking about and which are just talking a good game.  On
top of that, even if you find an article written by someone who knows
the subject, the author's recommendations might not make sense in your
particular environment.
DSA is not a Bad Thing.  Whoever it was who told you this did you a
disservice.  If you'd like to tell us what you've heard about DSA, we
would be happy to correct the misinformation you were given.
My suggestion is to "gpg --gen-key".  At each step of the way, if you
ever don't know what to do, just hit RETURN and go on.  GnuPG will
produce a high-quality keypair for you.

@_date: 2009-11-14 20:06:52
@_author: Robert J. Hansen 
@_subject: Key practice 
Don't believe the hype.
I don't like DSA-1024, for a lot of reasons similar to the ones in the
website you linked.  However, there's a big difference between saying "I
don't like DSA-1024," and "DSA-1024 is insecure and shouldn't be used."
At present, it appears that breaking DSA-1024 is within the realm of
plausibility for ridiculously well-equipped adversaries who are willing
to spend astronomically absurd sums on breaking your key.  Some people
think this means "DSA-1024 is broken, don't use it."  This seems to be
pretty ignorant of history.
During the Cold War, the NSA spent absurd amounts of money designing
beautiful, elegant ciphers, and training very skilled cipher clerks.
The KGB spent small amounts of money on beautiful, elegant women and
sending them to these lonely, far-from-home cipher clerks.  You can
figure out who was in the habit of winning those games of Spy-Vs.-Spy.
The moral of the story: no one with two brain cells to rub together is
going to attack DSA-1024 cryptanalytically.  Not now, and not for the
reasonable future.  It's going to be much, much faster and cheaper to
use other kinds of attacks, attacks which are just as useful against
RSA-4096 as DSA-1024.

@_date: 2009-11-14 20:13:33
@_author: Robert J. Hansen 
@_subject: Key practice 
Also --
Keep in mind that I am not criticizing that weblog entry.  I am only
saying, "don't believe the hype."  Much of what it says is accurate: it
is a good idea to migrate towards better digest algorithms.  Just don't
believe anyone who tells you that DSA-1024 is insecure: it isn't.
That said, you can migrate to a different digest algorithm quite easily.
 Add these two lines to your gpg.conf file:
personal-digest-preferences SHA256 RIPEMD160 SHA1
Ta-da!  Simple.  :)

@_date: 2009-11-16 03:09:24
@_author: Robert J. Hansen 
@_subject: Multiple Identities 
You will need your key ID for this.  For instance, my key ID is
0xD6B98E10.  Substitute your own key ID for mine in these instructions.
gpg --edit-key 0xD6B98E10 adduid
Enter the name, email address and comment you want associated with the
key; follow the prompts.  It's pretty straightforward.  Once you have it
done, send it to the keyservers so that everyone can find your key under
your new email address:
gpg --keyserver x-hkp://pool.sks-keyservers.net --send-key 0xD6B98E10
Presto, done.

@_date: 2009-11-16 09:24:47
@_author: Robert J. Hansen 
@_subject: avoid gnupg questions 
This problem will go away if you sign the recipient's public key.
Alternatively, you can add "trust-model always" to your gpg.conf file.
The former is generally preferred, but either one will do.

@_date: 2009-11-17 16:20:43
@_author: Robert J. Hansen 
@_subject: Is it possible to decide what is a gpg file? 
If you mean, "a reliable way to tell that something is not an
OpenPGP-encrypted file," then yes: check the OpenPGP header at the
beginning of the message.
If you mean, "a reliable way to tell that something is not an encrypted
file, period," then no, not really.
There are a lot of qualifiers on the "no, not really."  A lot of Ph.D.
theses have been written on this subject: it ties into some really deep
areas of theoretical computer science.  If you want to learn more about
the qualifiers, I'd suggest reading up on algorithmic randomness and
Kolmogorov-Chaitin complexity.  It won't be easy reading, but speaking
personally, I find this stuff fascinating.

@_date: 2009-11-17 16:29:02
@_author: Robert J. Hansen 
@_subject: Problem with the agent, gpg2 
GnuPG 1.4.7 or later (? on the precise version  supports longer DSAs
and better hash algorithms.  You don't need GnuPG 2.x for that.
You are free to call it GNU/Linux if you wish.  Likewise, Charly is free
to just call it "Ubuntu" or "Fedora" or "Linux Mint" or whatever else is
clear and unambiguous, depending on what he wishes.  Let's not start a
holy war over what the One True Name of the operating system is.

@_date: 2009-11-17 20:53:57
@_author: Robert J. Hansen 
@_subject: Is it possible to decide what is a gpg file? 
What you've described here isn't deniable encryption, not as I know it
to be.  This shouldn't be too surprising, given there are tons of things
I don't know about.  :)
Salting is something that's done to hash functions.  Are you sure you
mean that you want to add salt to a cipher?
This will be supported by effectively any modern cipher, especially for
small files.  If you can distinguish ciphertext from random noise,
that's usually considered to be a strong sign the cipher is weak.
(Note that I'm talking about modern symmetric ciphers.  Asymmetric
ciphers may very well be distinguishable.  I *think* they are, but I
can't summon up a reference now for the life of me -- take this as
unsubstantiated speculation.)
See above remarks: this is a fairly basic test for symmetric ciphers.
Note that I'm talking only about pure cipher algorithms.  Once you add
headers, magic numbers and so on -- all of which OpenPGP does, as will
many other crypto applications -- then both  2 and 3 fail.

@_date: 2009-11-17 21:58:12
@_author: Robert J. Hansen 
@_subject: Problem with the agent, gpg2 
Can't be done.  The OpenPGP standard requires that it be present.  Even
if you explicitly remove it, any OpenPGP-conformant application will
silently add it to the end of your preference list.

@_date: 2009-11-18 20:34:14
@_author: Robert J. Hansen 
@_subject: digital signature primary key and encryption subkey 
Japanese: ??????????????????
English:  "If you ask, you'll feel stupid for a minute.
           If you don't, you'll be stupid forever."
(The translation is pretty far from literal.)

@_date: 2009-11-19 21:28:42
@_author: Robert J. Hansen 
@_subject: Is it possible to decide what is a gpg file? 
Pierre Moulin's got a whole sheaf of really good steganography papers,
and yet most people I've met who advocate steganography have no idea who
he is.  This is kind of like meeting someone who says they're designing
a cryptosystem, and they've never heard of Claude Shannon or read any of
his papers.
Speaking generally, most people who develop cryptosystems don't bother
to read the crypto literature, and most people who develop
steganosystems don't bother to read the stegano literature.  Kind of
sad, really.
(Please do not misconstrue my remarks as applying to either the OpenPGP
authors or the GnuPG developers.)

@_date: 2009-11-25 16:13:11
@_author: Robert J. Hansen 
@_subject: Backup of private key 
We were all new once.  :)  Welcome to the list!
The good news is your private key is already encrypted with a symmetric
cipher.  The passphrase you type to use your key is really the
passphrase needed to decrypt it.
If you are sure that no one will ever guess your passphrase, then you
could safely publish your private key in the _New York Times_.  That
would be a really extreme case, but you could do it.

@_date: 2009-11-25 17:10:02
@_author: Robert J. Hansen 
@_subject: Backup of private key 
Correct.  You just have to make *absolutely certain* your passphrase is
unguessable.  If someone is able to grab your private key and your
passphrase, then you're in a world of hurt.
*All* of the ciphers used in GnuPG are secure enough to not worry about
them being broken.  :)  Some of the algorithms GnuPG uses are even rated
by the United States government as being suitable protection for
classified material.
That said, I think the particular algorithm used is CAST.  I might be
mistaken.  It used to be CAST, but it may be AES now.

@_date: 2009-11-28 01:50:53
@_author: Robert J. Hansen 
@_subject: Backup of private key 
"Secure" is not a very good word to use.  It means so many different
things to so many different people.  "Secure" really means "in
accordance with my security policies" -- the use of the word is
inherently subjective.
Let me try giving you an answer that doesn't involve the word "secure,"
but will still hopefully answer your question.
"For any symmetric cipher used in GnuPG, for any purpose supported by
GnuPG, there is *no* effective way for someone who has the ciphertext
and *only* the ciphertext to recover the plaintext without knowing the
The qualifiers are very important.  For clarity's sake, I'll restate
them here, very directly:
* I am only talking about GnuPG
* I am excluding gratuitously stupid things you can do by abusing
  the "--expert" flag
* We are assuming the adversary has *only* the ciphertext
* The adversary has *no* ability to execute side-channel attacks
  against you

@_date: 2009-11-28 12:37:16
@_author: Robert J. Hansen 
@_subject: GnuPG private key resilience against off-line brute-force attacks 
There are some empirical facts which may be useful, though -- like
observing the RC5-64 project was able to break a 64-bit key via a
massive distributed project that took 18 months of runtime.
That's not a recommendation, just a data point which may be useful to
people in making their own estimations.

@_date: 2009-10-05 13:54:41
@_author: Robert J. Hansen 
@_subject: beginner type questions 
The differences are irrelevant to the overwhelming majority of users.
Arguments about whether RSA or DSA are better pop up from time to time.
These arguments have always struck me as being kind of like arguing
over whether Godzilla or King Kong is better at urban destruction.
Maybe you like Godzilla, maybe I like King Kong, but at the end of the
day either one of them will get the job done in style.
This is expected.  New versions of GnuPG are being released all the
time.  Most releases offer very, /very/ small improvements over what
came before.  Ubuntu keeps track of what's changed in GnuPG since 2.0.9
was released.  If something major was added or a security bug was fixed,
Ubuntu will modify their version of GnuPG appropriately.  Otherwise,
Ubuntu's policy is generally, "wait until late October for Karmic Koala
to come out, and that will have the latest version of everything you want."
Uninvolved.  The email addresses exist to make the keys easier for human
beings to use.  By and large, the computer doesn't use the User ID at
all.  :)

@_date: 2009-10-05 17:33:38
@_author: Robert J. Hansen 
@_subject: email hashes in PGP keys as protection against spam 
Estimating how many email addresses are released to spammers via the
keyservers is a black art.  It has been attempted, though.  See, e.g.,
John Clizbe's result.
For your proposal to work, you can never have an email address exposed.
Ever.  Anywhere.  The instant you screw up and your email address gets
out, the game is over.  Soon a spammer will discover it.  Within days
all the spammers will have it, since spammers share email lists with
each other.
In the end, you haven't done anything to stop spam.  All you've done is
bought yourself a little time, and paid a very high price for it --
you've made it very difficult for people who want to talk to you to get
in touch with you.
Objective reality is the same for everybody.  The objective reality of
the situation is that as soon as your email address gets exposed
anywhere, spammers will get it.  Closing off just one avenue of address
collection is absurd; it's like facing a horde of army ants and thinking
that just by stomping on one you're going to do something about the swarm.
It already _is_ up to the user.  Nobody forces you to put an email
address on your key.  You can leave it off if you want.  If you're
really that concerned about keyserver spam, then feel free.  Be my
guest.  The protocol accommodates you.
But I think it's a very bad idea to start changing the protocol just to
appease the phantom fears of a small number of users.  Once you do that,
then everyone who has a phantom fear will demand the protocol be changed
to support them.
You may be fooling yourself.
I have cc'd GnuPG-Users on this one.  There doesn't appear to be
anything in this thread that's related to ongoing GnuPG development, so
continuing it on -devel seems inappropriate.  Let's move it over there.

@_date: 2009-10-22 10:42:17
@_author: Robert J. Hansen 
@_subject: verification/installation 
Perhaps you shouldn't; GnuPG is not part of OS X.
gpg --keyserver x-hkp://pool.sks-keyservers.net --recv-key 1CE0C630
This has been tested on OS X 10.6.1.

@_date: 2009-10-25 11:19:10
@_author: Robert J. Hansen 
@_subject: A Couple of Questions... 
No: only those users who want to be able to verify your signatures, or
who want you to be able to send them encrypted email.

@_date: 2009-09-02 09:04:11
@_author: Robert J. Hansen 
@_subject: 1.4.10rc1 vs. OS X 10.6 
I can recreate this bug on 1.4.9 and 1.4.10rc1 on a MacBook Pro running
Snow Leopard.  I can also confirm that John's fix of passing
"--disable-asm" to the configure script works.
Can we get an  for Darwin to replace the ASM blocks with compiled
Happy compiling!

@_date: 2009-09-02 17:27:05
@_author: Robert J. Hansen 
@_subject: 1.4.7 packages for OS X 
I did builds for only a very brief period of time: once he got 1.4.7
packages built, I stopped.  He does a great job with MacGPG, and I've
got no desire to duplicate work that's already being done well.
Thanks, Benjamin, for all your work.  The Mac users really appreciate
it.  :)

@_date: 2009-09-03 12:01:29
@_author: Robert J. Hansen 
@_subject: Encrypting and signing in the same run 
It's possible that your partner has phrased things poorly.  It may be
your partner meant to say, "We want the file to be encrypted and then
signed, not encrypted and signed in the same run."
The way you are doing things, GnuPG will (in effect) combine encryption
and signing into a single step.  Some groups have policies that say this
is a bad idea.  For these people, you need to explicitly break it up
into two steps:
gpg --encrypt --recipient 'Your Recipient' filename
gpg --sign --local-user 'Your Key' filename.gpg
This _may_ be the problem.  I make no guarantees.

@_date: 2009-09-08 02:04:02
@_author: Robert J. Hansen 
@_subject: RSA only enable to sign 
There are some Spanish-speakers on this list who might be able to give
you a Spanish answer.  If you don't mind an English answer, I'll try to
answer it.
You need to add an RSA encryption subkey.  Go ahead and create a
sign-only RSA key.  Then:
At the prompt, choose "(6) RSA (encrypt only)".  It may be numbered
differently on your machine.
Go through the rest of the steps and you will have add an RSA encryption
 subkey.  Send the updated key on to the keyserver network and your
friends can now use that encryption subkey to encrypt data meant for you.

@_date: 2009-09-08 02:50:39
@_author: Robert J. Hansen 
@_subject: RSA only enable to sign 
A GnuPG "key" isn't just one piece of data.  It's a whole lot of pieces
of data.
All GnuPG keys -- what we should really call "certificates" -- have a
signing key.  That's the most basic, fundamental thing in the
certificate.  If you want to be able to encrypt, you have to add an
encryption subkey.
Up until GnuPG 1.4.10, GnuPG would create a DSA signing key and an
ElGamal encryption key for you as one single operation.  You executed
"--gen-key", and GnuPG created the signing key, added the encryption
subkey, and you were done.
RSA was considered to be for advanced users.  Advanced users were
believed to be capable of generating their signing key, and then adding
their own encryption key later.

@_date: 2009-09-09 21:05:37
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
Add these lines to your gpg.conf file:
personal-digest-preferences SHA256 SHA224 SHA384 SHA512 RIPEMD160
personal-cipher-preferences AES128 3DES
... This will tell GnuPG that you'd much rather use a newer SHA than you
would SHA-1; and if for some reason GnuPG has to use a 160-bit hash, to
use RIPEMD160 instead of SHA-1.  It will also tell GnuPG to use AES128
for message encryption.  If for whatever reason your recipient can't
read AES128, it should fall back to 3DES.
Some people will tell you that 3DES is an old, antique and outdated
cipher.  This is true.  Some will tell you it's slow.  This is an
understatement.  3DES is ugly, crude, and inelegant.  It has all the
aesthetics of the Soviet Socialist Realism school of art.  It has also
been turning brilliant cryptanalysts into burned-out alcoholic wrecks
for three decades straight, and that reputation is solid gold.
Some people will undoubtedly advocate much more complex schemes.  I
suggest avoiding them.  Simple and effective solutions are usually much,
much better than complex and effective solutions.

@_date: 2009-09-10 09:59:47
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
Not really.  If there were good reasons to believe OpenBSD's entropy
collector was better than Linux's, the Linux crew would fix the code,
maybe even borrowing OpenBSD's entropy collector.
Arguing whether RSA or DSA2 is better is kind of like arguing whether
King Kong or Godzilla is better at stomping cities flat.
Yes.  No.  Not really.  Kind of.
RSA gives you a lot of freedom, yes.  You could put SHA512 on an RSA-3
(as in "three bits of key") signature and it won't bat an eyelash.  It's
_stupid_, but it won't bat an eyelash.
So, sure.  RSA gives you more freedom with hashes than DSA2, but that's
not necessarily a good thing.
Beware of those numbers.  I don't know anyone who takes them seriously.
They are conjecture and speculation.  Educated conjecture and
speculation, sure: some of the brightest minds out there worked on the
conjecture and speculation -- but they're still conjecture and
That said, there's nothing wrong with using those numbers as long as you
remember that they're conjecture.
Probably.  But it isn't as if it matters much.
If memory serves, the key generation code is identical between the 1.4
and 2.0 branches.

@_date: 2009-09-10 10:28:31
@_author: Robert J. Hansen 
@_subject: (Off topic) News on quantum computers cracking crypto 
Hasn't been for many years.  The advancement is in reducing the size of
the quantum computing device, not in factoring a larger number.
We factored 15 via Shor's algorithm in ... what, 2001?  But it was a
huge, expensive, multimillion-dollar, special-purpose apparatus.

@_date: 2009-09-10 10:54:46
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
Probably.  However, if SHA-1 gets totally broken we'll have a lot bigger
things to worry about than OpenPGP.
As soon as you find an attack, then we can discuss it.  Unfortunately,
we can't really talk intelligently about vague fears.
Nope, it's pretty pervasive in the system.
If SHA-1 gets totally broken, pretty much everyone with a computer more
powerful than a pocket calculator is screwed.  We won't be the only
Hans Dobbertin proved MD5 was weak in 1996.  In 1997, Network Associates
(who then were pretty much the only game in town, as far as PGP goes)
decided the Dobbertin attack was worrisome and that MD5 needed to go.
By the time the MD5 attacks became practical, PGP had _long_ since
migrated to SHA-1 and RIPEMD160.
The same thing is happening today with OpenPGP.  Everyone knows about
the SHA-1 attacks.  For right now, the SHA-1 attacks are impractical.
The people behind OpenPGP are working on a new OpenPGP proposal that
will use a stronger, better hash algorithm.
They're on it.  Relax.  :)
If you want to follow the discussion yourself on the official mailing
list for the RFC4880 standard, feel free.  It's a public list and
everyone's welcome.

@_date: 2009-09-10 11:04:34
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
Copyright protects the way an idea is expressed, not the idea itself.
If Linux had a better entropy collector than OpenBSD, the OpenBSD folks
would study the Linux version.  They'd learn how it works, they'd learn
how it was designed.  The Linux developers would probably help them out
in this.  Once the OpenBSD folks knew exactly how the Linux collector
worked and why, they'd go off and hammer out their own version of the
Linux collector.
It wouldn't take them long.  The hardest part of programming is
understanding the problem and how the solution you're writing interacts
with it.  Once you've got that down, the code almost writes itself.  It
comes together really, really quick.
IANAL, if you're doing serious software development talk to your own IP
lawyer before you take this seriously, etc., etc.

@_date: 2009-09-10 16:21:44
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
I understood him to mean the "key ID" as the fingerprint of the
certificate's primary signing key, rather than checking each bit of the
certificate's primary signing key individually.

@_date: 2009-09-10 18:39:14
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
"Specifically"?  I don't have the time to list everywhere that will
break.  SHA-1 is used in a ton of places, and often not places you'd
immediately expect.  For instance, computer fuel injection timings are
controlled by software.  Auto enthusiasts would like to be able to
customize them, but can't.  If SHA-1 breaks, auto enthusiasts will be
able to forge their own signatures and deliver their own "updates" to
their engines.
Skype will potentially break.  Many P2P networks (including the ones
Skype is based upon) use a mathematical construct called a "distributed
hash table" to figure out how to route data.  If the hash algorithm is
bad, well, you're out of luck.
Filesystems will suffer.  There exist some filesystems that avoid
storing redundant data by tracking a hash of each file.  If the file
you're writing matches a hash that's already on the disk, the filesystem
just puts in a soft link.
That's three examples of things that will unexpectedly break if SHA-1
falls.  A complete laundry list would go for pages and pages and pages.
 I'd suggest reading comp.risks; they might have something on point.
Imagine that in 2010, the OpenPGP Working Group publishes a new key
specification.  v5 keys use SHA256, not SHA1.  I revoke my current key
and migrate to a new v5 key.
In 2015, the SHA-1 attack becomes practical.  Someone goes back to my
old messages and lifts a signature off something I've written.  They
construct a new message that hashes out the same as my old message, and
put my old signature on a new message.  "Look, look!  He signed a
message in 2009 claiming that he'd pay me $1 million in 2015!  Pay up,
Mr. Hansen!"
No one would take such a forgery seriously.

@_date: 2009-09-10 19:18:42
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
Sharing media is a great way to spread malware.  Don't do that to your
friends.  Use the keyserver network.
SHA-1 is in trouble, but it's not dead yet, and regular users should not
be worried about it.

@_date: 2009-09-12 22:18:53
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
[puts on his voting security hat]
This is part of some voting protocols.  Let's say you have two
candidates who tie in an election.  Each candidate sends their own
representative to the election with a ten-sided die (you can find these
in any hobby store).  The election commissioner collects the dice, then
distributes them out randomly to the representatives.  Everyone throws
the dice and the numbers are added up together modulo 10.  If it comes
up 0 through 4, candidate A wins the election; if it comes up 5 through
9, candidate B wins the election.  Thanks to the magic of random
distributions and modulo math, as long as there's one fair die in the
system, the entire system is fair.
Anyway.  This is apropos of nothing except to show you that such schemes
really are used in the real world.  :)

@_date: 2009-09-12 22:18:59
@_author: Robert J. Hansen 
@_subject: howto secure older keys after the recent attacks 
[puts on his voting security hat]
This is part of some voting protocols.  Let's say you have two
candidates who tie in an election.  Each candidate sends their own
representative to the election with a ten-sided die (you can find these
in any hobby store).  The election commissioner collects the dice, then
distributes them out randomly to the representatives.  Everyone throws
the dice and the numbers are added up together modulo 10.  If it comes
up 0 through 4, candidate A wins the election; if it comes up 5 through
9, candidate B wins the election.  Thanks to the magic of random
distributions and modulo math, as long as there's one fair die in the
system, the entire system is fair.
Anyway.  This is apropos of nothing except to show you that such schemes
really are used in the real world.  :)

@_date: 2009-09-16 15:46:14
@_author: Robert J. Hansen 
@_subject: IDEA patent vs the recent USPTO memorandum 
The memorandum in question is eight pages, twenty slides and two flowcharts.
As a ballpark estimate that would mean it would take an IP lawyer about
two days to figure out what this means for the specific subject of
patented cryptographic algorithms.  It would take the non-experts on
this list many times that long, if we could do it at all.
There may be patent lawyers on this list who are familiar with the
memorandum in question who are willing to speak in a public forum about
it.  Weirder things have happened.  But speaking for myself, I do not
have the time it takes to (a) become an expert on U.S. patent law, (b)
read the memorandum, and (c) consider how it changes the U.S. patent
system, and (d) write up my results.
If this is important to you, I would suggest speaking with an IP lawyer.

@_date: 2009-09-16 16:15:23
@_author: Robert J. Hansen 
@_subject: IDEA patent vs the recent USPTO memorandum 
Some people use remailers and other tools which depend on PGP
2.6/RFC1991 traffic.  There are some people who would very much like to
see GnuPG fully support RFC1991 so it can replace the very long in the
tooth PGP 2.6.
Admittedly, I think the correct response is to say, "GnuPG /did/ replace
PGP 2.6, the same way RFC4880 replaced RFC1991, now come into the 21st
century with the rest of us."  But many of the die-hard PGP 2.6
advocates resist changing.

@_date: 2009-09-16 17:02:31
@_author: Robert J. Hansen 
@_subject: IDEA patent vs the recent USPTO memorandum 
Gave up the asking, more likely.  I still get one or two emails a year
inquiring about if/when GnuPG will support this.  (No, I don't know why
they email me, and I wish they wouldn't.)
That said, I share in your sentiments.

@_date: 2009-09-17 12:41:23
@_author: Robert J. Hansen 
@_subject: IDEA patent vs the recent USPTO memorandum 
This is doable.  I did this in '99 for GnuPG 1.0.  I haven't done it
since, but given the codebase is still in the same ballpark, size-wise,
I find it hard to believe it's impossible today.
It seems strange to imagine there's someone not capable of auditing the
GnuPG code, but is capable of auditing the PGP 2.6 code.
Having read both codebases (albeit not a recent GnuPG codebase), I found
GnuPG's code to be much clearer and easier to understand than PGP 2.6's.

@_date: 2009-09-21 23:53:53
@_author: Robert J. Hansen 
@_subject: IDEA patent vs the recent USPTO memorandum 
It is more accurate to say it has already been abandoned.  Very few
people today use IDEA as a symmetric cipher for OpenPGP messages.

@_date: 2010-08-04 13:57:57
@_author: Robert J. Hansen 
@_subject: Gnupg good for big groups? 
It is also worth noting that PGPNET has some very big problems with key
management.  PGPNET users are apparently comfortable wrestling with
these problems (more power to them for that), but we shouldn't pretend
the problems don't exist.
In a completely connected graph of N nodes there are (N^2 - N)/2
different edges.  Or, in English, 40 members equals 780 separate
communications links, each one of which can fail and produce problems
for other people.  The network begins to get spammed with "that last
message wasn't encrypted to my new key, please re-send."  The network
slowly begins to drown with communications overhead: key
synchronization, resend requests, failure notifications, etc.  PGPNET is
probably operating pretty close to the limits of OpenPGP.  At some point
the math bites you hard and doesn't let go.
A couple of years ago at USENIX Dan Wallach of Rice University talked
about his difficulties getting 30 Ph.Ds in computer science to all
communicate on an OpenPGP-encrypted mailing list.  His precise phrasing
was, "it was the torment of the damned."

@_date: 2010-08-04 20:57:08
@_author: Robert J. Hansen 
@_subject: Gnupg good for big groups? 
I'm not going to try to tell you what your feelings on the issue should be.  However, I strongly suspect that rather than being a minor issue this is in fact the largest issue shaping the group's development.  It's kind of like gravity.  You don't notice it very much, but it shapes your entire universe.
Completely connected graphs tend to evolve along similar lines.  So long as it remains under a certain membership level the communication overhead is tolerable.  Add one or two people past that and it becomes intolerable.  People drop off the network because it's stopped becoming useful to them.  The ones who leave tend to be the ones who have derived the least benefit from being part of the network -- their tolerance is not as much as those who have gained from being part of the network.  The effect of this is that churn tends to be among new members, not among long-standing ones.
Once the network shrinks to a state of usability, people stop leaving.  More people sign up, and more people leave.  Etc., etc.  This is all pretty basic networking theory, and it's why completely connected networks are rarely used in the real world.  You can only build it out so far before hitting a brick wall of self-limiting behavior.
It's no big deal *for you*.  If you want to make a blanket statement of it being no big deal, you need to take into account the churn on the periphery: all those people who joined and then left because the key management problem was nontrivial.
That's not especially relevant.
The network was entirely voluntary.  Only way to do it, really.  I'd like to see anyone get thirty Ph.Ds to do something in concert which they didn't want to do -- I'd rather try and teach manners to a cat.
I suspect if you look at the churn you'll discover many are not able to, and leave for that reason.
Again -- my remarks here are not meant to be critical of the mailing list.  Nothing of the sort.  People who are on the list and like it should stay on it and I hope they keep liking it.  My remarks here are of general applicability to completely-connected graphs.  The stuff I talk about here is the sort of stuff you can expect to occur on any large OpenPGP-encrypted mailing list.  I really don't want to give the impression I'm turning this into a referendum on PGPNET's existence.

@_date: 2010-08-05 15:32:37
@_author: Robert J. Hansen 
@_subject: Gnupg good for big groups? 
Networking theory is like that.  It takes a while to understand the
math, but once you do you see applications everywhere.
Yes and no.  Generally speaking, the number one reason why nodes drop
out of networks is the benefit is exceeded by the cost.  Or, in plain
English, "it just isn't worth the headache."  Marriages end for this
reason.  So do friendships.  Political alliances come apart.  Etc., etc.
So the question isn't whether key management is the major reason why
people sign up and don't hang around -- the question is more whether key
management is a major expense which adversely affects the cost-benefit
As an example, if I were to start posting tomorrow's winning lottery
numbers to PGPNET, you'd hardly see any churn at all.  The benefit is
worth the cost.  But, as you've observed, the network's purpose is
generally social.  It's pleasant, but it's not exactly winning lottery
Returning back to general discussion about networks and OpenPGP, the
usefulness of the information will be a (although perhaps not *the*)
major factor which will drive the network's growth.  The headache
involved in key management will be a (although perhaps not *the*) major
factor limiting the network's growth.
See above.
Good.  :)  My thanks to the various PGPNET guys for being good-natured
about this.  The group is a good laboratory for discovering and
understanding problems that arise in real-world OpenPGP deployments.
Some years ago I offered to write a tool for the group which would help
manage the key problem.  (Kind of.)  The idea was to write a small
Windows app that would automatically download the membership list once a
day and update Enigmail's pgprules.xml file.  This meant Enigmail users
would no longer be maintaining per-recipient rule lists by hand (which
is tedious, error-prone, and frustrating for newbies).  The process
would be entirely automated.
It sounds like a great idea, up until you consider that even if the spam
overhead problem is reduced by a factor of 10, that gain gets
obliterated once a few more people join the network.  The spam overhead
follows an exponential growth.  When dealing with exponential curves,
linear reductions -- even large linear reductions -- are pretty much
Ultimately, the group decided not to take me up on the offer -- the
overwhelming opinion was that they'd rather get experience editing
pgprules.xml by hand.  C'est la vie.  :)

@_date: 2010-08-06 13:42:38
@_author: Robert J. Hansen 
@_subject: Message was not integrity protected. 
The Right Thing is, of course, to fix your script -- but until you can
get that done, --disable-mdc should suppress that warning message.  (I
think.  It's been a few years since I've needed to do this.)

@_date: 2010-08-06 13:59:43
@_author: Robert J. Hansen 
@_subject: Message was not integrity protected. 
Thank you, yes, my error.  One of those occasions when I knew the right
answer, it just escaped onto the screen as something wrong.
Apologies to the Alex for leading him (briefly) astray.

@_date: 2010-08-07 14:22:19
@_author: Robert J. Hansen 
@_subject: Gnupg good for big groups? 
One person said they would use it.  The overall reaction was negative.
These things happen.  Sometimes, the tool you think people need isn't
the tool they want.  :)

@_date: 2010-08-08 03:45:23
@_author: Robert J. Hansen 
@_subject: Gnupg good for big groups? 
This is expected, and it's not specific to PGPNET.  Communication links
that get used tend to be better-maintained than ones that don't: small
problems are discovered and fixed in the natural course of using them.
Compare to a link you don't use for six months -- by the time you need
it, everything has changed and your link totally fails.
It's one of the reasons why any communication channel you plan on
relying on in an emergency should be regularly tested to make sure it
performs the way you expect.
(We are arguably getting pretty far afield from GnuPG, but I believe
this conversation is still germane to GnuPG usage.  If people object,
say the word.)

@_date: 2010-08-08 12:44:21
@_author: Robert J. Hansen 
@_subject: Gnupg good for big groups? 
Again, network theory to the rescue.  Generally speaking, nodes that
carry little traffic are responsible for more problems than those that
carry a lot.  There are of course exceptions.
Right, but at that point you're coming close to cherrypicking --
disregarding data points in order to reach a result that's more in line
with your preconceptions.  Nobody ever wakes up and says, "today I think
I'll cherrypick."  It's almost always a subconscious process: "well, I
can disregard that data, it's clearly anomalous because..."
Sometimes, data really /is/ anomalous and has to be thrown out.  If you
were to pick a random sample of 100 people and come to an average of
their incomes, you should disregard Bill Gates if he happens to be in
your data set.  More often than not, though, anomalous data isn't
anomalous at all -- it just illuminates a part of the problem you didn't
know existed.

@_date: 2010-08-08 12:55:30
@_author: Robert J. Hansen 
@_subject: batch program to find my password - help please!!! 
Ten lines of Perl will do it.  However, you might be waiting a really
long time.
If you have lost your passphrase, there is effectively nothing anyone
can do to help you.

@_date: 2010-08-09 13:55:41
@_author: Robert J. Hansen 
@_subject: Gnupg good for big groups? 
You would have to ask Paul.  I suspect, though, that with only a
low-thirtysomething number of nodes and a total number of messages in
the neighborhood of six hundred, that there's not much confidence to be
had in any trend.
Gross behaviors (the combinatoric explosion of edges as new nodes enter
the graph, churn in the fringes, etc.) are fairly easy to recognize in
even small data sets.  Subtle behaviors (figuring out precisely what the
problem die-off is) are difficult to discover and require some pretty
sophisticated knowledge of statistics -- far beyond my own capabilities.

@_date: 2010-08-11 08:17:51
@_author: Robert J. Hansen 
@_subject: gnuPG 
Download and install that.  Once you have it installed, uninstall and then re-install Enigmail.  Enigmail will automatically detect your GnuPG installation, and things should just work.
You may also want to consider asking on the Enigmail mailing list:
Hope this helps!

@_date: 2010-08-11 15:58:02
@_author: Robert J. Hansen 
@_subject: Build Gnupg2 to have bin name gpg 
The filename is set, I believe, in g10/Makefile.am.  Look for a line
called "bin_PROGRAMS".  You will also need to adjust certain targets:
for instance, "gpg2_SOURCES" will become "gpg_SOURCES", "gpg2_OBJECTS"
becomes "gpg_OBJECTS", and so on.
It is not especially hard to do, but it requires a little fluency with
the GNU Autotools.

@_date: 2010-08-12 11:10:06
@_author: Robert J. Hansen 
@_subject: GPG decryption issues on WINDOWS 2003 SERVER 
Microsoft is not planning on any further service packs, but the OS is
still supported until 2015.  Mainstream support has ended, but extended
support is still available.
Even if 2003 had been totally EOLed, this advice would still not be
particularly useful.  Migrating a server to a new OS is not something to
be undertaken lightly.  Given a choice between simply writing off an
application as "doesn't work on our system" and migrating to a new OS,
many places will choose to write off the application.

@_date: 2010-08-12 20:32:34
@_author: Robert J. Hansen 
@_subject: GPG decryption issues on WINDOWS 2003 SERVER 
Let's scale back the imprecations a little bit.  Criticize errors, not
people.  For instance:
This article is ten years old and is out of date with respect to current
Java best practices.  Since Java 1.5, the preferred method is
ProcessBuilder, which was meant to replace most uses of Runtime.exec().
As a "real developer", I do this almost every workday.
You do not know whether the original poster was using this for a
deployment system, or as a prototype to explore the problem space.
Exploration, testing the limits of your knowledge, and discovering how
code works are all parts of the development process.

@_date: 2010-08-12 21:17:01
@_author: Robert J. Hansen 
@_subject: Decryption Error 
I am sorry that no one else has given you a useful answer.
To answer your question: no, there is no special configuration for GnuPG
on Windows Server 2003.
Calling GnuPG from Java is a little ... problematic.  I have tried to do
this several times, with varying levels of success.  The root of the
problems (at least, the problems I've run into) have been that GnuPG
expects there to be a TTY, and when using Runtime.exec or
ProcessBuilder, there is no TTY.
The same problem occurs in C
The last two times I asked on this list for help getting past this, I
received no response.  I wish I had answers for you.  All I can do
instead is tell you your best bet will probably involve writing JNI
wrappers for GPGME.

@_date: 2010-08-13 08:50:24
@_author: Robert J. Hansen 
@_subject: Decryption Error 
It may be.  I was looking at ftp://ftp.gnupg.org/gcrypt/alpha/gnupgjava, which shows no updates since 2005.  It may be worth dropping a README in there directing people to Stefan Richter's git repo.
I have never used gnupg-for-java, so I can't comment on it.

@_date: 2010-08-18 13:32:33
@_author: Robert J. Hansen 
@_subject: Adding keys 
MacGPG works just fine on OS X 10.6.  I use it daily.
gpg --import-key [secret key file]
... doesn't work?

@_date: 2010-08-20 09:20:03
@_author: Robert J. Hansen 
@_subject: gnuPGP Setup 
One detail that Simon omitted: do not copy public keys into Word files.
 It must be transmitted as-is, without any of the data mangling that
Word does behind-the-scenes.
Alternately (and IMO, preferably), use the keyserver network.
gpg --keyserver pool.sks-keyservers.net --send-key 12345678
Then, a few hours later, the correspondent can use recv-key to get the key:
gpg --keyserver pool.sks-keyservers.net --recv-key 12345678

@_date: 2010-08-23 17:06:57
@_author: Robert J. Hansen 
@_subject: Difference between different key types 
All asymmetric cryptography is built on math problems that are so hard
they cannot be solved unless you already know part of the answer.  For
instance, factoring a number is hard: what two prime factors go into
2,701?  But if I give you one of those prime factors (37), it's really
easy to figure out the other one (73).
RSA is built on the Integer Factorization Problem (IFP).  This is pretty
much exactly what's described above.
DSA and Elgamal are built on the Discrete Logarithm Problem (DLP).  This
is a different kind of problem involving computing discrete logarithms
in a finite field -- another problem that's widely considered to be
intractable unless you already know part of the answer.
That's the big difference between DSA/Elgamal and RSA.  From a purely
functional perspective, they are almost entirely equivalent.  (One might
be a few milliseconds faster for encryption, one might be a few
milliseconds faster for decryption -- but that's hardly a big deal.)
"Better" is a subjective term.  I don't know what "better" means to you,
so I can't answer it.  A lot of pointless holy wars have erupted over
which key type is "better", and my best advice is to ignore the question
GnuPG has sensible defaults.  You don't need to override them.

@_date: 2010-08-25 13:19:04
@_author: Robert J. Hansen 
@_subject: Modified user ids and key servers and a possible security risk? 
[good reasons 0-3 skipped]
4) Asymmetric cryptography is computationally expensive.  I would not
want to think about the CPU load of a keyserver that did verification of
every new certificate, user id, user attribute, etc., etc.

@_date: 2010-08-25 15:38:44
@_author: Robert J. Hansen 
@_subject: Modified user ids and key servers and a possible security risk? 
Initial syncs would be prohibitive.  After that, syncs would probably
not be too obnoxious, but the initial setup would just be awful.

@_date: 2010-08-31 08:09:14
@_author: Robert J. Hansen 
@_subject: how to change the default symmetric cipher 
First, think about whether you need to.  Most people don't.  GnuPG works
just fine out of the box without any tweaking.
That said, look at adding the line:
... to your gpg.conf file.  For instance, if I'd like to use Blowfish
whenever possible, and 3DES if the person I'm communicating with doesn't
understand Blowfish, I'd put:
... in my gpg.conf file.

@_date: 2010-11-30 19:43:22
@_author: Robert J. Hansen 
@_subject: Passwords are unwillingly being saved throughout session 
This is expected behavior.
In GnuPG 2.0 and later, passphrase caching is handled by a program called gpg-agent.  If you want to set timeouts and whatnot, that's the program you'll need to configure.

@_date: 2010-12-08 16:54:02
@_author: Robert J. Hansen 
@_subject: Protecting IDs at a key signing party 
For me, I bring a passport and a driver's license.  If anyone tells me
"that's not enough for me!", well, okay: it's not enough for them.
There are plenty of other people at the keysigning party, and I might
not want to have a signature from someone quite that paranoid and
tinfoil-hatted, anyway.  :)
The best way to protect the ID is to not let it out of your sight.  If
someone wants to hold onto your ID to inspect it, let them: but don't
let them walk away with it.  Sounds stupid, but it works.
Honestly, the biggest ID risk at a keysigning party is people
accidentally walking away with each others' drivers' licenses.

@_date: 2010-12-09 09:08:24
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
My best counsel is: don't, at least not yet.
First, there are no imminent practical attacks on SHA-1.  Second, the
OpenPGP Working Group ("the WG") is currently figuring out how to get
SHA-1 out of the OpenPGP spec and how to replace it with something better.
If you do a transition now, it's possible you'll want to transition
again in six months or a year once the WG updates the RFC.
I'd hold off on this, at least for now.

@_date: 2010-12-09 12:35:00
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
Security is a subjective criteria.  If you don't know what his threat
model is, you're in no position to be making pronouncements like this.

@_date: 2010-12-09 14:17:02
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
My suspicion is RIPEMD-160 is broken, we just don't know how.  It has an
awful lot of mathematical similarities to hashes that have been broken:
it is my suspicion existing attacks will be successful when tweaked to
apply to RIPEMD-160.
Dunno, ask the WG.
IMO, quite high.  If you use the same key material, then if the old
OpenPGP certificate format ever becomes weak an attacker can simply take
an old certificate of yours, upgrade it to the new format, and bang
they're off to the races.
If/when the time comes for SHA-1 to be completely removed from OpenPGP,
the migration path will quite likely involve new keys -- the same way
that the V3/V4 migration path in the past necessitated new keys.
It is unlikely it ever will.  3K RSA keys are believed to be equivalent
to a 128-bit symmetric key.  If computational power ever develops to
that point, the solution is going to involve moving to entirely
different algorithms instead of just tacking on another couple of bits.

@_date: 2010-12-09 14:18:58
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
Not true.  Per the OpenPGP spec, it will simply truncate a longer digest
down to 160 bits.

@_date: 2010-12-09 14:42:27
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
This is premature.
It could be any of the following:
* You do not have a personal-digest-preferences in your gpg.conf
* You do not have enable-dsa2 in your gpg.conf
* Any of dozens of other reasons
Check the first two.  :)

@_date: 2010-12-09 16:33:06
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
I did not communicate the idea well.  In retrospect, I communicated it
quite poorly.
Imagine a certificate that depends on a trivially weak hash -- say MD5
was used instead of SHA-1 for self-signatures, etc.  Fine: that
certificate is now out there in the wild.  The signatures it makes are
quite suspect.
A new certificate standard comes out.  You migrate your old certificate
material to a new cert.  You want to continue using it, after all.
(Why, I don't know: it isn't as if it's hard to generate new certs.)
Great, except that your old cert is, in many jurisdictions, legally
enforceable against you.  You haven't revoked it: in fact, you continue
to assert that it is usable (albeit in a new cert format).
Someone else exploits the old, insecure cert format in a way you don't
like.  Now you're stuck arguing, "wait, that's not my cert... well, it
because that's an old insecure format..."
So far I've handwaved all different kinds of interesting issues and
questions -- and I've *still* gone over the heads of the vast majority
of lawyers and judges who would be arguing over the question of, "is
this signature enforceable?"  Remember, in the eyes of the U.S. federal
court system, MD5 is considered a strong hash with no known attacks
against it.  I don't trust the courts to understand these subtle nuances.
There is a big difference between something that is possible and
harmless in a technical sense, and something that is possible but not
recommended in a human sense.  Technically, yes, it's possible.  From a
human factors perspective I would revoke the old cert, create a new one,
make a clean break with the past and move forward.  Less opportunities
for human factors to bite me in the posterior.
*Have* to?  None.

@_date: 2010-12-09 18:45:53
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
Here is where I get to say either of, "I don't have to," or "pick one,"
or "you're the one who's positing the attacks."  All I'm positing is
some future attack that will allow people to abuse a cert in a way you
don't like.  You're counseling that people move away from SHA-1 *today*
based on the fear that somewhere someone has already done
chosen-preimage collisions against SHA-1 in a reasonable timeframe.
My assumption is quite a lot weaker than yours.
If the law in your jurisdiction recognizes such and the court has
precedent to lean upon, this argument will fly.
Speaking just for myself, I have no desire to be the first person to
make such an argument.  The instant you re-use key material, it opens
the door to someone saying, "Your Honor, the existing precedent doesn't
apply.  He's still using the same certificate!"  And now you're
depending on a judge having better technical acumen than many of the
people on this mailing list.  Ultimately, it will reduce to a battle of
the dueling expert opinions.
"You made it with that signature because you wanted to be able to
repudiate it later.  You're trying to deceive the Court."
On the one hand, what you say is perfectly reasonable.  On the other
hand, so is what I say.
_Sanders v. State_, 191 S.W.3d 272 (Tex. App. - Waco 2006) (cert. denied
549 U.S. 1167, 127 S.Ct. 1141, 166 L.Ed.2d 893)(2007)
_State v. Morris_, 2005 WL 356801 (Ohio App. 9 Dist. Feb 16, 2005).
_State v. Cook_, 777 N.E.2d 882, 886 (Ohio App. 2002), including the
money quote "In the present case, there is no doubt that the mirror
image was an authentic copy of what was present on the computer's hard
drive" -- the hard drive was imaged using EnCase, and MD5 was used to
ensure the accuracy of the data.
Also, check the Federal Rules of Evidence.  You may also want to read
_Daubert v. Merrell Dow Pharmaceuticals_.
Yes.  Which is why we don't create more of them without good cause.
There's a difference between saying, "we have to play Russian Roulette,"
and, "let's put another few rounds in the cylinder first."
If your migration path can't accommodate a planned, scheduled change of
key material, it is quite likely you're doing it wrong.

@_date: 2010-12-09 18:55:57
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
Back in 2000 or so, the consensus was that ECC was too new and rested on
some dicey conjectures.  Since the proof of the Taniyama-Shimura
conjecture (or, as it's now called, Wiles' Theorem), ECC's theoretical
underpinnings seem to be on fairly solid ground.
The National Security Agency has approved ECC for use in its Suite B of
cryptographic algorithms, and has authorized it for protection of the
highest levels of state secrets (TS/SCI) when used with 384-bit ECC keys.
John's information (that Suite B was authorized for SECRET) is correct:
he was looking at the bit about Suite B that relates to 256-bit ECC keys.
The NSA is quite good about publishing its real information security
policies.  They have a *lot* of contractors who work with them, and
keeping the rules for how to secure classified information hidden would
ultimately only harm overall operational security.  They *want* people
to know the right way to take care of TS/SCI material.
They never want to hear someone say, "sure, I sent that TS/SCI file in
plaintext.  Wait, I wasn't supposed to do that?  I was never told!  Why
aren't those rules on your website?"

@_date: 2010-12-09 18:57:43
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
Correct.  Truncating a hash does not introduce any flaws in the
algorithm.  If you truncate a bad hash, you now have a truncated bad
hash.  Truncate a good hash and you have a truncated good hash.  :)

@_date: 2010-12-09 21:40:47
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
Suite A is still classified.  Suite B is pretty thoroughly documented.  :)
From  :
"AES with 256-bit keys, Elliptic Curve Public Key Cryptography using the
384-bit prime modulus elliptic curve as specified in FIPS PUB 186-3 and
SHA-384 are required to protect classified information at the TOP SECRET
... TS/SCI, which is usually thought of as "above TS", is really just TS
with some additional conditions and qualifiers on it -- so Suite B is
usable with TS/SCI material.

@_date: 2010-12-09 21:53:31
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
He just repeated the work of Landauer, Margolus and Levitin.  Basically,
for a digital computer working in base N, the amount of energy required
to clear a unit of information is kT*lnN -- the Boltzmann Constant,
multiplied by the temperature in kelvins at which the computer runs,
times the natural log of the computer's numerical base.
For a conventional digital computer, it requires about 10^-23 joules to
erase a bit.  That energy must be radiated as heat.  If you're going to
brute-force a 128-bit keyspace, you're going to be erasing 64 bits per
key.[*]  About 10^-21 joules per key must be radiated, multiplied by the
10^38 attempts you'd have to try on average, gets you 10^17 joules of
heat... or about a 100-megaton nuclear explosion.
Since Fort Meade is not a smoking radioactive sea of glass, I conclude
the NSA is not brute-forcing 128-bit keys.  :)
In reality the thermodynamic analysis is even more ridiculous than this,
since we're assuming you're not tampering with memory in any other way
than just to set bits for a key.  That's wildly unrealistic.
In theory you can break the Landauer Bound with things like adiabatic
computing and supra-Turing processing, but those things are so far out
in the realm of science fiction they deserve to be called... well...
science fiction.
[*] You could brute-force the keyspace in a way that only requires you
to erase fewer bits per key, but then the defender would just choose a
key close to the end of your brute-force schedule.  Hence, it's most
efficient to do them more or less at random...
Roughly logarithmic.  As the moduli get larger, the number of primes get
fewer and fewer.  This is why a 1024-bit key is roughly proportional to
an 80-bit symmetric key, a 2048-bit key is roughly proportional to a
112-bit symmetric key, and a 3072-bit key is roughly proportional to a
128-bit symmetric key.  Three times the asymmetric key length only gives
you half-again the symmetric length.

@_date: 2010-12-09 23:32:08
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
My personal opinion -- can't back it up with anything more than my own
meandering experience -- is that many OpenPGP users are way too attached
to their certificates.
Sooner or later you *will* have a key compromise event, you *will* need
to revoke keys in a hurry and you *will* need to find some way to
re-establish a WoT with your core correspondents.  The question is not
if, the question is only when.
If you never revoke-and-reissue certs (perhaps out of a desire to
preserve your WoT), then when the time comes not only are you going to
be stressed out and not thinking clearly, but you'll be performing a
task that's unfamiliar to you.  This isn't something I'd think wise.
Every couple of years I open a binder, flip to the Cert Revocation
Checklist, and go down the list.  It's a dry run for a for-real event.
By the end of the event I've discovered places the checklist fails and
needs to be fixed, found "oh, heck, Bob's entered my WoT since I last
wrote this, I need to update that!", etc., etc.
The one time I've needed my Cert Rev Checklist for-real, I was really
glad I had it.
I find this to be a useful exercise.  Your mileage may, and probably
will, vary.  If you have a very well-developed WoT and don't want to
jeopardize breaking other people's WoTs, then you might not want to do
this.  :)

@_date: 2010-12-10 09:41:28
@_author: Robert J. Hansen 
@_subject: Best Practices 
Don't.  :)  The keyservers don't have a problem with this litter.  I
wish people showed more care with their certificates, but that's because
I get too many "I forgot my passphrase, help!" emails, not because I
think the keyserver network is getting clogged.
Well, you have one subkey, it's just that the subkey is capable of both
signing and encryption.  You don't have separate subkeys for separate
tasks, if I understand you correctly.  Some people think this is a bad
idea, since if you're compelled to produce an encryption key to the
authorities (so they can decrypt an email sent to you) you've also
provided them with your signature key (so they can now impersonate you).
Add a new UID and revoke the old.  You don't need to generate a new
certificate.  RSA-4K is, IMO, phenomenal overkill for the vast majority
of users.  Breaking RSA-2K is believed comparable in difficulty to
breaking 3DES, and that prospect is ... let's just say "implausible."
RSA-3K is roughly comparable to breaking AES-128.  RSA-4K is not very
much harder than that.  Given all this, I really don't see any point in
going past RSA-2K.  Adding another 2,000 bits to the key in order to get
about another 20 bits of symmetric-key equivalent just strikes me as bad
There is not.  In twenty years we will see commonplace attacks that
today are just speculative science fiction.  It's incredibly hard to
make good long-term predictions about crypto.
It is possible that in twenty years national governments will have
large-scale quantum processors.  Once that happens, RSA, DSA and ElGamal
all die horrible screaming deaths.
As an example: almost twenty years ago Schneier wrote in _Applied
Cryptography_ of the Chinese Lottery Attack.  It involved putting a
small processor in every Chinese television set, which could be
programmed by broadcasts from Party headquarters.  Each processor would
crunch a small part of the keyspace, and as soon as a hit was achieved
the television would tell the viewer, "You have won!  Call Party
headquarters with this authorization number: [insert key here]."
Twenty years ago the Chinese Lottery Attack was an interesting thought
experiment, but nobody took it seriously.
Today we have RC5-64, distributed.net, seti at home, botnets, Amazon EC2
and all manner of other massively distributed computing frameworks.  The
question today isn't whether a Chinese Lottery Attack is possible: the
question is how much it will cost you to rent your server time.
The future is a scary place.  But fun, too, and I look forward to
getting there.  :)
Sure, but you don't need to create a new cert to use new hash algorithms.

@_date: 2010-12-10 19:11:53
@_author: Robert J. Hansen 
@_subject: Best Practices 
Answered your own question there.  :)
RSA-3K is practical for a lot of problem domains, but I wouldn't
consider it a good general recommendation.  For instance, there are a
lot of smartcards that don't play well with 3K keys.  As a general
recommendation, I think 3K is a bad idea.

@_date: 2010-12-11 11:24:46
@_author: Robert J. Hansen 
@_subject: Best Practices 
None that I've found.
Err -- "yes."
A certificate is just a block of key material plus some associated data.
 SHA-1 is used internally by the certificate to sign some parts of the
data, as well as for computing a key fingerprint.  You can to some
extent mitigate how much SHA-1 gets used, but you can't remove it
You can also choose to use SHA-1 to sign messages and files.  Here, you
can remove it completely in favor of some other hash algorithm.

@_date: 2010-12-11 21:15:50
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
Otherwise the snooper could just use a MitM and you'd be none the wiser.
When you visit Amazon.com, both you and Amazon need some way to ensure
you're talking to the real McCoy.  Amazon authenticates you by having
you provide a username and password.  You authenticate Amazon by
checking their SSL cert and seeing that it was issued by a trusted
If you didn't check the SSL cert, I could provide a self-signed SSL
cert, have you accept it, and then do a MitM on your connection.  Next
thing you know, you've paid for all my Christmas shopping...

@_date: 2010-12-11 21:21:43
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
The entire idea of a "self-signed certificate" is kind of a non
sequitur.  The question isn't whether a certificate is self-signed or
signed by Verisign.  The question is whether the certificate is signed
by someone you trust.  If you know the certificate issuer, you've
verified the certificate fingerprint with the web site owner, etc., then
you can use a self-signed certificate with great confidence.
With respect to your hypothetical scenario, sure.  Getting marks to
trust people who plan on betraying that trust is a ploy that's about as
old as the hills.  I think Samson might have something to say about
Delilah, and Holofernes' troops might have something to say about
Judith, just to name two instances...

@_date: 2010-12-11 23:25:39
@_author: Robert J. Hansen 
@_subject: multiple subkeys and key transition 
The two are generally synonymous.  Whether a user *should* trust the
same CAs as their browser vendor is a very good question -- however, the
fact is the overwhelming majority of users *do*.  If the browser says "a
trusted CA certifies this site is for real," the user is going to
believe it.
Can't please everybody.  If it was an involved process the vast majority
of users wouldn't bother.  Instead, it's just a "check for a padlock and
a yellow address bar."

@_date: 2010-12-12 02:58:12
@_author: Robert J. Hansen 
@_subject: Best Practices 
personal-digest-prefs is probably a bit off.  For instance, if for any
reason SHA512 is unavailable it will degrade to SHA-1, which you
probably don't want.  It's generally best to include all the algorithms
you'll accept, in whatever order you like.  E.g.:
personal-digest-preferences SHA512 SHA384 SHA256 SHA224 RIPEMD160 SHA1
This way you have a natural degradation in hash preferences: rather than
immediately degrading to SHA-1, it gives you more options to keep on
using strong hashes.

@_date: 2010-12-12 11:21:13
@_author: Robert J. Hansen 
@_subject: Best Practices 
... At first blush, V4 certificate checksums, symmetrically encrypted
integrity protected data packets, the MDC system in general, certificate
fingerprints, etc.  I just grepped through the RFC looking for any
hardcoded SHA-1; David is probably a much better reference than I am on
Probably the most annoying -- to me, at least -- is the fingerprint
requirement.  If a preimage collision is discovered in SHA-1 then it's
all over.  I can take your signature on my enemy's key, graft it onto my
own impersonator of my enemy's key, and then get others to believe it.

@_date: 2010-12-12 11:22:48
@_author: Robert J. Hansen 
@_subject: Best Practices 
But why would you want to?
Humans should use tags convenient for humans.  Machines should use tags
convenient for machines.
Not if all he's changing are the personal-*-preferences.

@_date: 2010-12-12 15:51:10
@_author: Robert J. Hansen 
@_subject: Best Practices 
Read the RFC.  It's in there, and does a better job than I can do of
explaining it.  Section 5.5.3.
I am very skeptical of this claim you seem to be making, that we can
just upgrade-in-place.

@_date: 2010-12-12 18:52:47
@_author: Robert J. Hansen 
@_subject: Best Practices 
Not so long as you're looking up key IDs by fragments of SHA-1 hashes,
you're not.
That's not the point of this thread.  In fact, as near as I can tell
that's *never* been the point of this thread.  The original poster
wanted to create an entirely new certificate in order to migrate, and my
advice to him was that if he wanted to create an entirely new
certificate that he should wait until the next revision, otherwise he'd
likely be doing another new certificate in a year or two.
I have *never* claimed that we shouldn't move away from SHA-1.  Heck, I
was even the one who told the original poster to use enable-dsa2 in
order to get access to the stronger hash algorithms.
I maintain my original point: if you're thinking of creating an entirely
new certificate just in order to get access to better hash algorithms,
then you are best off waiting for the new revision: otherwise, use the
existing technologies.

@_date: 2010-12-13 20:26:43
@_author: Robert J. Hansen 
@_subject: Best Practices 
*What* hard cut-over or interruption of existing networks?  The v3/v4
transition was seamless because there was neither a cut-over date nor an
interruption: people migrated at their own pace, when they were ready
to, and not before.  v3 keys are still used today, although they're
increasingly niche.
v4/v5 will coexist the same as v3/v4 coexist.  In fact, it's quite
likely v3 and v5 will coexist.

@_date: 2010-12-13 20:28:24
@_author: Robert J. Hansen 
@_subject: Best Practices 
And no one is arguing against this.  All people are arguing against is,
"I want to migrate to a new certificate in order to avoid SHA-1."  To
the extent it is possible to avoid SHA-1, it can be avoided today
without migrating to a new cert; and for the rest, it cannot be avoided
today even if one migrates to a new cert.

@_date: 2010-12-13 20:30:29
@_author: Robert J. Hansen 
@_subject: Best Practices 
The Berkeley BOINC framework can be pretty easily adapted to do this.
Off by about a factor of 100 there.  RSA-2048 is roughly equivalent to a
112-bit symmetric key; RSA-1024 is roughly equivalent to an 80-bit key.
 32 bits of difference equals a factor of four billion.  It's way harder
than you think.

@_date: 2010-12-14 12:11:54
@_author: Robert J. Hansen 
@_subject: best practices 
There are a few of them on the keyservers, IIRC.  Whether this is the
result of a deliberate and carefully chosen policy, or rampant paranoid
schizophrenia, is an open question...

@_date: 2010-12-14 13:12:48
@_author: Robert J. Hansen 
@_subject: best practices 
What tool was used really doesn't interest me very much -- you can
create them with GnuPG, too, if you're willing to tweak the source a
little bit.  What I find morbidly fascinating is contemplating what kind
of deranged individual would actually do this.  :)

@_date: 2010-12-14 13:41:20
@_author: Robert J. Hansen 
@_subject: best practices 
To underline and agree with what David said -- the entire field of
communications security requires crystal balls.  It sounds neat and
simple to say, "the weakest part of the system must be stronger than the
adversary's ability to break it," but in reality it's messy and complicated.
The weakest part of the system, in your estimation, may not be the same
as the weakest part in the enemy's estimation.  If you don't know what
your enemy's capabilities are, well, figuring out what the enemy will
consider "weakest" requires a crystal ball.
For that matter, you may not know who your enemies are.  If you're
worried about the FBI eavesdropping on your email, you might be totally
blind to J. Random Sysadmin who gets his jollies from planting
keyloggers on systems.  Just knowing who your enemies are requires a
crystal ball.
You may... etc., etc.  It's an incredibly difficult and Byzantine problem.

@_date: 2010-12-14 18:49:03
@_author: Robert J. Hansen 
@_subject: best practices 
Sure.  But someone could also think, "since they make both high proof
whiskey and fast cars, and they're each perfectly safe, there's no harm
in mixing them."
Thinking, "if they make a 256-bit symmetric algo, there should be a
reason for that," is quite correct as far as it goes.  Thinking its
existence means you need to use it, though, is not.  :)

@_date: 2010-12-18 13:22:53
@_author: Robert J. Hansen 
@_subject: 'Tis the Season -- again. 
Every December I write one of these emails to the list, about how the end of the year makes a good time to reflect on what's happened this year, how much good luck we've had, how much fraternity and community we've enjoyed, and what might happen next year.
I feel we've been fortunate to have GnuPG.  Just reading the newspapers is enough to give you the willies nowadays: there's all this sensationalism about our constantly eroding privacy, about how governments want ever-extending powers to surveil, how Facebook is luring people into giving up all kinds of personal information just for some virtual currency in Farmville and Mafia Wars, how...
Reading this mailing list is a good restorative after reading all of that.  It's beautiful to know that people care about privacy, that people care enough to write privacy software and share it freely with the world as their gift to human knowledge.  It's beautiful to know we do not have to settle for the world which we are given.  It's beautiful to know the outcome of all this is not and never has been preordained.  Privacy is one hell of a social battle to be fought, but it can be fought and it can even be won.  As disheartening as it might be to realize that privacy is losing, it is also immensely cheering to know it has not lost, and the outcome is still in doubt.
This year, as with previous years, I'm donating money to the EFF in honor of GnuPG, the developers, the community, and the privacy fight.  I wish I could donate to GnuPG directly, but that's infeasible for a whole lot of reasons and I suspect the EFF is as good a proxy as any.
Thank you all.  Keep up the good work.  :)

@_date: 2010-12-23 15:20:55
@_author: Robert J. Hansen 
@_subject: Block cipher mode? 
OpenPGP specifies a kind of messed-up and strange variant of CFB.  Don't
get me wrong, it /is/ a CFB mode, it's just messed-up and strange.
Cryptanalytically strong, just very much different from what most people
call CFB mode.

@_date: 2010-12-29 13:51:20
@_author: Robert J. Hansen 
@_subject: How to process a big file of encrypted mails? 
We will have an easier time helping you if we have more information.
Such as, is only inline encoding used?  Is PGP/MIME ever used?  Which
operating system are you running?  Which version of GnuPG are you using?
 Etc.

@_date: 2010-12-29 16:51:56
@_author: Robert J. Hansen 
@_subject: How to process a big file of encrypted mails? 
Makes it a lot easier.  Yeah, your best bet here is probably some
scripted solution.  Shouldn't be too hard: an hour or two of
$weapon_of_choice should do the job.
(For non-programmers, $weapon_of_choice can be read as "your preferred
programming language, and I really don't want to get into arguments
about which one people /should/ prefer.")

@_date: 2010-02-24 15:26:46
@_author: Robert J. Hansen 
@_subject: How to sign an email in PHP? 
Outlook Express is deprecated, and many people here throw deprecations
against it -- but Outlook Express is still one of the most common MUAs
in existence, and for that reason alone the PGP/MIME interoperability
problem should be taken seriously.

@_date: 2010-02-25 15:23:30
@_author: Robert J. Hansen 
@_subject: key question 
What you're advocating here is "DRM on the honor system."  Don't copy
the key, don't distribute the key, don't upload the key, don't do
anything with the key, without the explicit permission of the key owner.
Me, I consider DRM on the honor system to be the exact same as any other
kind of DRM -- something to be overcome and then ignored.
If someone asks me nicely, "please do not upload this key," I will
probably say yes.  But it is a *huge* leap to go from there to "do not
upload keys without the owners' permission."

@_date: 2010-02-25 22:24:29
@_author: Robert J. Hansen 
@_subject: key question 
What in life is automatic, besides death and taxes?
We are not talking about automatic here.  We are talking instead about
what is reasonable and in accordance with the general expectations of
the community.  I've not heard any organized outcry for "DRM on the
honor system", and I've not heard any good arguments for it.  I've heard
a loosely organized outcry for sharing public keys widely, and good
arguments for it.  Based on this, I'm going to follow the community
practice of sharing keys widely, unless there are compelling reasons to
do otherwise.
I suspect most users are in the same boat.
I invite you to look at my key and figure out with whom I communicate
securely.  Looking over the key I use now and the keys I've used in the
past, I don't see any signatures there from people I've traded more than
a handful of secured emails with.  You might think the signatures on
0xFEAF8109 are indicative of something -- but really all that it's
indicative of is that I attended the keysigning party at OSCON 2006.
You *must* be kidding.
Listen, if there's some sociopath who likes raping eleven year olds on
camera, and my name happens to be in his address book, or he happened to
sign my key, or my name is *in any way* connected with his, then yes, I
like the idea of my government coming around to ask me, "do you know
anything about this?"  When it comes to hideous crimes being perpetrated
against children, I kind of support the idea of law-enforcement officers
doing their jobs.
Sure, sure, there are a ton of other more questionable investigations
they could be conducting -- but your examples here are *awful*.
If you want to keep your association with someone private, give it a
local (non-exportable) signature.
Exportable signatures are meant for the case where the signer *wants* to
attest to the world their association.

@_date: 2010-02-26 11:24:22
@_author: Robert J. Hansen 
@_subject: key question 
I'm scratching my head here trying to figure out how you can reasonably
affirm the claimed identity of the person who controls the key if you
are in no way associated with them.
A signature on a key says, "I believe this key really corresponds to
this person."  But if you have no association whatsoever with that
person, how can you make a signature?  The existence of the signature
necessitates at least *some* association.
Even a trusted timestamp service that makes signatures without any human
intervention makes an association claim: "at this date and time, someone
sent this document to me for signing."

@_date: 2010-02-26 12:04:36
@_author: Robert J. Hansen 
@_subject: key question 
This isn't persuasive.  It's been hammered out tons of times, and no one
has ever presented a strong argument for keeping email addresses secret.
 Usually the same arguments are marshaled against it again and again,
and those are the same arguments that have not been persuasive.
Why?  Because they have a key on the keyservers?  If this is what you're
worried about, rest easy: there are so many easier ways to learn whether
someone uses encrypted email that I can't imagine competent
law-enforcement searching the keyservers.
For instance, in the United States the authorities can get your email
headers without a warrant.  That means to, from, subject, routing
information, and all the kluges.  Check the kluges on this email and I'm
pretty sure you'll see kluges related to Enigmail.  Presto, at that
point people know I'm using a crypto-aware MTA.
Investigators also don't develop very many leads based on "gee, this
person uses crypto."  Many more leads are developed based on kludge
investigation -- what security geeks call "traffic analysis."  If they
nab a child pornographer and discover that you always emailed him
between one and three days before the child pornographer uploaded a new
set of images, well... that's the kind of interesting coincidence which
will start a federal investigation.  The fact you have a crypto key, not
so much.
That image can only be portrayed if the viewers are ignorant of how the
WoT works.  What you are saying here is, "we must change the way we act
in order to accommodate the prejudices of the ignorant."
Did that in high school -- it was the most disastrous social experiment
of my life.  I've seen nothing in the last twenty years to make me think
I should repeat this experiment.
The second sentence is a tautology.  "OpenPGP technologies will probably
not be used by people who don't use OpenPGP already."  It's trivially
true, which is to say that it's a true statement which leads nowhere.
Speaking for myself, I've used the keyservers on several occasions.
I'll meet someone in person, they'll give me their key ID and
fingerprint, and then later on I'll pull down their key ID, verify their
fingerprint, and then use it for communication with them.
I have my OpenPGP fingerprint at the bottom of my business card for just
this reason.  When I hand out cards at conferences, I not only tell
people how to contact me, but I give people all the information they
need to contact me securely.  I know several other people who do the
same thing.
I don't think we agree that's your statement.  Not everybody believes
the world is round, or that the Earth orbits the sun.  You can always
find at least *one* person who believes some nonsense, and the fact that
not *everyone* agrees is not evidence that these minority fringe
viewpoints should be allowed to substantially influence mainstream usage.
The fact you are arguing so passionately for this point of view leads me
to believe you have a horse in this race, and that you want to persuade
other people to not upload keys by default.
If all you're saying is, "there are people in the world who do not
understand the keyserver network and get unhinged when others upload
their public keys to it," then sure, I agree.  Thread's dead, next
subject, we'll continue to use the keyserver network and they'll
continue to get unhinged.

@_date: 2010-02-26 13:05:56
@_author: Robert J. Hansen 
@_subject: key question 
You can say you're not advocating DRM -- but if it looks like a duck,
swims like a duck, flies like a duck and quacks like a duck, then it's a
"Digital": yes, the public key is in a digital form.
"Rights" : yes, you're advocating the owner possesses intrinsic rights.
"Management": yes, you're advocating the owner should be allowed to have
   total control over how the key gets distributed.  That's pretty
   extreme management.
But, hey.  If you don't like DRM on the honor system, I'm happy to call
it ORCON ("Originator Controlled").  ORCON material doesn't get copied,
shared, promulgated, forwarded on, without the originator's explicit
permission.  It is the most extreme form of DRM imaginable.  I thought I
was being generous by saying you were advocating DRM on the honor system
instead of ORCON -- ORCON is much more onerous.
My exposure to ORCON material came from my work with electronic voting
systems.  Government officials are sometimes willing to give electronic
voting geeks a peek behind the curtain, so long as there's an ORCON
agreement signed in blood with the Devil himself as an eyewitness.
You're advocating public keys be treated like the inner secrets of how
electronic voting machines work.  So am I.  It's just that you're
advocating they all be kept secret by default and publication being an
exception to the rule -- and I'm advocating they all be kept public by
default and secrecy being the exception to the rule.
You're claiming they have a reasonable expectation that, if they share
data that is clearly marked *public*, the recipient should understand
*public* means "clear it with me first"?
I don't think that's a reasonable expectation.  The key says "public"
right at the very top, and I think it's unreasonable to expect people to
infer that it means "no, don't share it."
This is why the burden is on the key provider: if you don't want the key
shared, you have to explicitly tell someone about it.  If you don't tell
someone about it, they are allowed to think the phrase "public" means
just that.
That's not the key sharer's problem.  That's the problem of the person
who provided the key.  If you know it would be unlawful for you to share
information, don't share it.
By implication, then, I lack a proper respect for individual privacy.
At this point this seems to be dropping straight into the ad-hominem range.

@_date: 2010-02-26 16:14:58
@_author: Robert J. Hansen 
@_subject: key question 
You are asserting that (a) the person who created the public key owns
the information, (b) the person owns the information has the right to
control how it is disseminated, and (c) that if someone shares the
information in violation of the owner's wishes they are doing something
morally and/or legally wrong.
You have to assert (a).  Ownership is the legal and/or moral right to
control how a resource is utilized.  I own my car because I have the
legal and moral right to control who drives it.  You are claiming the
originator of the key material has the legal and moral right to control
how it is disseminated: therefore, you are making a claim the originator
of the key *owns* the information contained in that key.
You have to assert (b).  It follows logically from (a).  (a) implies (b).
And you are asserting (c).  You're dressing it up in polite rhetoric
about the right to privacy, but at the end of the day you're asserting
that people are doing something wrong if they violate the information
owner's wishes.
In other words, you're in the same boat as the MPAA.  Looks like a duck,
swims like a duck, quacks like a duck: it's a duck.
You are presupposing the expectation is reasonable.  I am not willing to
grant that as a given.
Again, you are begging the question.  We're trying to figure out whether
it is reasonable to expect people to keep public keys secret without the
owner's permission.  What you're saying here is, "it's reasonable
because I think it is reasonable."  You're assuming the truth of the
proposition in question, and using it to try and establish the truth of
the proposition in question.
It's an indicator the key owner has not uploaded it to that network.
For instance, what if the key has been uploaded to PGP's keyserver
(which, last I checked, did not sync with the network, but is publicly
accessible), but not the global network?  Is that evidence the key owner
wants it publicized, but just not publicized on the global network?
Etc., etc.  There are a *ton* of edge cases here.
The absence of a key on the keyserver network is, itself, only evidence
that it's not there.  It doesn't show motive, any more than my having a
shotgun in my closet shows my motive to commit murder.
I am unaware of your qualifications to talk about universally-applicable
law.  I cannot accept your expert opinion on this subject without it
first being established that you are an expert.

@_date: 2010-02-27 01:11:29
@_author: Robert J. Hansen 
@_subject: key question 
There is a perceived need for $150 bowls of soup, as evidenced by dozens
of high-priced gourmet restaurants in major cities.  The existence of a
market for a service is not evidence that the service is generally
useful or needed.
First, the status quo doesn't need arguments in its favor.  The status
quo exists.  *Changing* the status quo is what requires arguments in its
Second, then you don't have to include it in yours.  Why are you
bringing this up?  I don't care what your UID is, and I don't want you
to have a vote in whether I put an email address in mine.
In which case you're still hosting it publicly, so why not use the
This is not "taking you to task."  This is listening to your claims, and
giving strong arguments against them.
My father is a judge.  Growing up, if I were to assert the sky was blue
he would ask how I knew the sky was blue.  (No, I'm not kidding.)  It's
a weird way to grow up, but it's served me very well in my life.  All
claims must be scrutinized and examined.  If they survive the scrutiny,
good.  If they don't, then let's make note of them and remember not to
waste time on these claims in the future.
You've set up a straw man.  Nobody is arguing the keyserver network is
the best platform.  What is best will depend on each person's individual
valuation of the many factors that go into this question.
That said, it is broadly true that it's a good idea to send keys to the
keyserver network.  The reasons why have already been well-explained.
Your reasons why not are either unfounded or debunked.
In your voluminous defense of privacy rights, you've not given any
numbers for what fraction of users need or want to keep their public
keys private.  If you're arguing that the "good idea" we've advocated is
not a good idea, you need to show there are substantial numbers of users
who will be negatively impacted.  You haven't.
You've talked about the danger of reputation being slandered by
implication of association: but as David Shaw has pointed out, if
someone wants to do that there are much easier ways to do it than with keys.
You've talked about making it easy for law enforcement to learn who
communicates securely with whom: but as I've said, law enforcement (at
least in the US, and probably also the UK) has much easier ways to learn
You've talked about spam: but as John Clizbe has pointed out, although
keyservers do get harvested for addresses there is no statistically
significant difference in the spamflood between putting a key on the
server or keeping it private.  You'd have to ask him about his
methodology and his precise numbers, but I'm sure he'd be willing to
provide them if you asked.  (I used to share your concerns about spam,
up until John showed me his numbers and convinced me.)
The status quo is, "it is generally a good idea to send your key to the
keyserver network."  If you want to change that, the burden is on you to
present persuasive evidence supporting a change.  So far I've not seen
it, which means the status quo stands.

@_date: 2010-02-27 11:22:27
@_author: Robert J. Hansen 
@_subject: key question 
No.  You're right, that's clearly easier.  However, that only tells you
whether someone has the technical capability to use encryption -- much
the same way that a shotgun in my closet tells you I have the technical
capability to commit murder.
Generally speaking, law-enforcement is much more interested in whether a
capability is exercised than if a capability exists.  Checking the
keyserver network reveals the capability; it doesn't reveal if it's been
As a result, the possibility of law-enforcement officers checking the
keyserver network doesn't seem to be a strong argument against the use
of the keyserver network.
The major exception is if you live in a jurisdiction where possession of
crypto is itself a criminal offense.  If you live in Cuba and you're
using GnuPG, then you should not have your key on the servers and you
have a perfectly reasonable fear about people uploading your key there.
His position seems to have shifted.  At some points he's said,
"What's not to agree with in my statement that not everybody wants to
put their keys on the keyservers?"
I fully agree with this.  However, he also seems to be advocating the
advice of "generally speaking, it's a good idea to put keys on the
keyservers" be changed to "generally speaking, it's not a good idea to
share public keys without the key owner's explicit permission."
This is a pretty big change in the conventional wisdom.  Before I'll
sign on to that I'll have to see some strong reasoning, and I haven't.
MFPA has made it clear his objection applies to any kind of sharing of
public keys without the owner's consent.  It's not limited to the
keyserver network.  He considers it the equivalent of passing on
someone's home address to a complete stranger.  ("I would no more
deliberately publish somebody's key without their consent than I would
pass on their phone number or address.")
For myself, I do not send keys up to servers without first checking it
with the recipient.  This seems like good manners to me.  However, I
don't view it as mandatory and I don't think we should view it as the
appalling breach of morality that MFPA seems to.
That the status quo ante is upheld.  Status quo ante being, "the
keyservers are generally a good idea, and generally speaking they should
be used, and people should expect their public keys will wind up on them
sooner or later, either through their direct action or through the
accidents of others."
It is not universally applicable advice, but I think that as far as
general advice goes it's pretty good.

@_date: 2010-02-27 15:03:15
@_author: Robert J. Hansen 
@_subject: key question 
The status quo has something going for it: it works.  95% of all new ideas are awful and should be discarded.  New ideas are how the status quo changes for the better, but that doesn't mean we should throw out the status quo just because an idea comes along which happens to be new.
It's an interesting idea, but I don't see any facts to back it up.  How many users are dissuaded?  Is this a major concern, or not a concern?  What does the published literature say about it?  And so on, and so on.
Speculation is great, but speculation isn't fact -- and we need to change the way we do things based on facts, not on speculations.  We can agree on facts, but our speculations will likely not overlap very much at all.
The same way the shotgun in my closet clearly has the potential to be used as a murder weapon.
Potential != actuality.  All manner of potential things do not come to pass.  Before we change the way we do business, I'd like to know that we're changing to address a real problem, not merely a potential problem where no one really knows if it's a real problem or not.
The world has enough interesting problems to solve without us having to go off chasing ghosts.
I don't think I said it was "acceptable."  I would find it to be in poor taste, myself, if it were done deliberately.  However, I don't think it would amount to a moral or ethical failing.
Let's say that Joe downloads your key from the web page.  Joe then syncs his entire keyring with the keyserver.  (This is a feature in PGP; you can also do the same thing with GnuPG, if you don't mind getting a little crazy with awk and sed scripts.)  Your key then gets on the server, and... etc.  Maybe Joe is doing it deliberately.  Maybe he has a misconfigured installation.  Maybe he thinks he's doing you a favor.  Whatever.  The point is, the world is full of Joes, and sooner or later your key will wind up on the server.
Once you make any public release of your key, it is only a matter of time until that key winds up on the keyserver network.  You can either keep your public key very secret and only give it to people who have need-to-know and make them sign a nondisclosure agreement written in the blood of their children, or you can accept the fact that it will be put on the keyserver and take appropriate steps.
This is an argument from emotional conviction.  That doesn't mean it's invalid or inappropriate or that you shouldn't have this response -- don't get me wrong.  I like emotions; emotions are pretty cool things.  I just don't like arguing from emotional conviction, because I either share in the response or I don't.  If I do, then you don't need to say anything because I'm already on your side.  If I don't, then you don't need to say anything because you can't persuade me into having that particular emotional response.  I either have it or I don't.
But just like there's nothing you can say to *me*, there's nothing I can say to *you*.  The instant you say "I will never be converted!", well, okay: thanks for letting me know.  I won't try to persuade you, because you've made it clear you won't be persuaded.
So the lack of evidence is, itself, evidence?  That sounds more like a conspiracy theory.
This is an idealistic view of the world.  I like idealism.  I admire idealism.  I just think it's impractical and destructive.
What you're saying here is, "even if the advice were sound for one million users, and destructive to the privacy of just one, I still would not change because any key I encounter could be that one."
The perfect is the enemy of the good.

@_date: 2010-02-27 15:23:25
@_author: Robert J. Hansen 
@_subject: key question 
Yes and no.  I think the presence of an Enigmail header, for instance, is probably more indicative of encrypted traffic than just someone's key being present on a server.  Still, this is kind of a side show.  What started this was MFPA's contention that just by having your key on the keyserver network you could be bringing yourself to the attention of government investigators.
When a murder victim is found, the police start looking for the murder weapon.  They don't start by looking at all possible murder weapons and hope to find a murder victim nearby.  Likewise, if the police find encrypted traffic on a suspect's laptop they will begin to search for the originator of the traffic.  They're not likely to start by rounding up the usual suspects found by harvesting the key server.
There are exceptions to this rule.  I mentioned Cuba, where possession of crypto is itself a crime (or was, last I heard: if there are any Cubans on the list, I would love to know if this is still true).  That said, exceptions to a rule are expected -- there are few rules so general they do not admit exceptions.
I likewise have suspicions and doubts about conventional wisdom.  (You could just as easily say, "conventional wisdom is that you can tell a lot about someone by the signatures on their key" -- I can see an argument being made for that being conventional wisdom.  It's *wrong*, but that doesn't keep it from being conventional wisdom.)
However, on the scale of conventional wisdom, where on one end there's "never get involved in a land war in Asia" and "never go against a Sicilian when death is on the line," [1] and on the other there's "the signatures on a key tell you a lot about a person", I think the conventional wisdom of "generally speaking, it's a good idea to put keys on the keyservers" is closer to the former category than the latter.  :)
Admittedly, I am no arbiter of what's conventional wisdom.  The preceding is just my own personal interpretation of what prevailing CW is.
[1] I think it's a great example of a clear exception to a general rule.
Not really.  That's a side issue.
The real question is this:
"The status quo is that new users are routinely told, 'generally speaking, it is a good idea to upload your key to the keyservers.'  Does this need to change?"
He says "yes and here's why," and I say, "your arguments do not appear sound, and here's why."

@_date: 2010-02-27 16:10:19
@_author: Robert J. Hansen 
@_subject: key question 
The hypothetical Cuban had a lot bigger problems the instant he shared his public key with people he shouldn't have trusted to keep it secret.
Keep it on the list, please, and not in private mail.

@_date: 2010-02-27 16:16:14
@_author: Robert J. Hansen 
@_subject: key question 
Oh, ack.  I completely misread the To- line, and didn't see the cc: to gnupg-users.  My error, and my apologies to MFPA.  :)

@_date: 2010-02-28 01:20:46
@_author: Robert J. Hansen 
@_subject: key question 
More like, "since you are reacting emotionally and refuse to even entertain the possibility of being persuaded, there is no point in continuing this conversation."
I wish you a pleasant day.

@_date: 2010-02-28 16:59:17
@_author: Robert J. Hansen 
@_subject: key question 
It's a pretty common engineering maxim.  It's not a statement about morality -- or, at least, it wasn't my intent for it to be taken as such.
For an excellent engineering example of the difference between perfect and good, compare Project Xanadu to the World Wide Web.  Project Xanadu's obsession with getting everything right has massively impaired its adoption.  The Web's willingness to say, "this is a problem and we don't know how to fix it but we're going to go ahead regardless" has been instrumental in its widespread adoption.

@_date: 2010-01-04 01:17:06
@_author: Robert J. Hansen 
@_subject: Encrypting with an message expiration date 
There are, as near as I can tell, only three options: either (a) you
trust the sender's clock, (b) you trust the recipient's clock, or (c)
you trust a third-party clock.
Once you know which clock the system is trusting, attack the clock.
Subvert and/or impersonate it, rewind time back, and view the message again.
Every time-based security scheme I've found has had this failure mode.
It seems to be impossible to avoid.

@_date: 2010-01-07 12:23:55
@_author: Robert J. Hansen 
@_subject: Web of Trust itself is the problem 
The fact that "free credit reporting services" are making a ton of
money, as are services like LifeLock and whatnot, plus the huge media
impact of identity theft, etc., all points to people knowing their
privacy is at risk and feeling stressed out about it.
However, most people lack the skills necessary to do anything about
their privacy, and lack the inclination (time, energy, or even
self-confidence) to do anything about their lack of skills.

@_date: 2010-01-10 16:01:09
@_author: Robert J. Hansen 
@_subject: Web of Trust itself is the problem 
Crypto is not like this.  Sure, you don't need to understand Feistel
networks or large number theory in order to use crypto, but look at what
you *do* need to understand:
* Identity verification
* Document verification
* What a hash is
* How hashes are used
* How hashes are misused and shouldn't be used
* Out-of-band verification
* Type I versus Type II error
... and so on, and so on, and so on.  I stopped at seven; I could easily
go on for another seven, or more.  These are all things that are
necessary to use GnuPG successfully.
As an example, a fairly tech-savvy friend of mine made a habit of
signing all her emails.  Her reasoning was, "if people ever see a
message that's not signed, they'll know it's not from me."  This
reasoning sounds good, and many people on this list would probably agree
with it.  The problem is that it's incorrect.
If someone using her name were to post a racist, hate-filled screed on
the internet, would she really be able to persuade people she didn't
write it just by saying "look, I didn't sign it"?  Or would her critics
say, "of course you didn't sign it, you wanted to be able to deny
writing it!"?
Likewise: people tend to be interested in who has signed a given key...
but why?  Anyone can sign anything, regardless of whether the key owner
consents.  There are all kinds of credibility attacks you could do on
someone by putting a fake "StormFront Identity Verification
" signature on a key -- and thus, have people
infer from that signature that the key owner is a member of a racist
hate organization.
Crypto is a /highly/ demanding field.  The skills required to use it
effectively, and avoid incorrect and/or dangerously false reasoning
about documents, are far, far beyond the realm of most users.
OpenPGP is in many ways a failed standard.  It's big, it's complex, it
has a lot of subtle edge cases, and so on.  However, for all its faults,
I think it is by far the best email encryption standard we have.

@_date: 2010-01-10 23:37:12
@_author: Robert J. Hansen 
@_subject: Web of Trust itself is the problem 
Read this paper:
Also read this paper:
Once you've read them, then let's have this conversation again.  The
obstacles we face in crypto adoption are not related to user interfaces.
 They're related to users.
There's a lot of good papers in the literature covering this problem.
Those two papers will helpfully point you in the right direction.
I didn't write this; you're misquoting someone else's words and
attributing them to me.
Likewise; David Shaw wrote this.  That said, I agree with him, and HTTPS
is /very/ invisible to most users.
A few years ago a fellow grad student of mine, Peter Likarish, developed
a really cool anti-phishing technology.  (I don't know if it's been
cleared for publication, or if he's still wrestling with it privately,
so I can't talk about how it works.)  It was a phenomenally effective
phishing-detection engine.  For testing purposes, he packaged it up into
a Firefox plugin.
When a user visited a phishing site, a small red bar would appear across
the top of the screen.  "Warning: this site appears to be impersonating
another site," it would say.  He figured users would see it.  He
recruited a number of normal, everyday users to test the plugin.  He
gave them a computer preinstalled with Firefox and the anti-phishing plugin.
*Not one of them* saw the red bar across the top.  They all considered
it to be visual noise and filtered it out.
Peter decided the solution was to make the bar grow steadily bigger over
time.  The user could click on the bar at any time to make it vanish;
but if the user ignored the bar, the bar would grow and grow until it
took over a third of the screen.
He repeated the test, and this time videotaped people as they were
interacting with the system.
*Not one* saw the bar.  According to Peter, when watching the videotape
you could watch users' eyes scroll down the screen as the bar grew.
There was no question that on some level they were seeing the bar,
processing it.
Peter's hypothesis was that Flash ads are to blame.  Users have become
conditioned to having Flash ads appear on the screen, take over real
estate, and so on.  Therefore, users were subconsciously filtering out
this big red alert bar and it was never percolating up to the conscious
level where users could make an informed decision about the risks.
Yes.  HTTPS is invisible.  Users typically do not have anywhere near the
visual recognition of web interface that people like to think they do.
ObDisclaimer: Peter told me this about two years ago now.  My memory is
not perfect; I may be off on details.  However, I am confident the
salient parts of the story are correct.

@_date: 2010-01-11 01:26:08
@_author: Robert J. Hansen 
@_subject: Web of Trust itself is the problem 
I've seen computerized votes authenticated by MD5 hash... sent over
email... in the same message as the official vote record.  As in, "the
attachment has MD5 hash XXX, if your version hashes out to XXX then the
vote record is authenticated."  I just about had a heart attack.  The
voting authorities thought this was just fine, and a perfectly correct
use of hashes.
False positive versus false negative.
If there's a transmission error in the sigblock *but not in the source
text*, you can have a bad signature with a completely intact message.
Therefore, the fact a signature is bad doesn't automatically tell you
the message was tampered with.
If the message was altered somehow, the signature will be bad.  However,
if the signature is bad, that doesn't necessarily mean the message was
altered somehow.
A lot of people miss this point.  It's kind of important.
What should be true is a question for religion, philosophy and ethics.
Engineering is about asking what *is* true.

@_date: 2010-01-20 01:11:04
@_author: Robert J. Hansen 
@_subject: distributing ones public key (email) 
Some email clients (Thunderbird+Enigmail, for instance) let you put a
kind of note to other users hidden in the email headers.  These things,
called "kludges," are one of the preferred ways to do it.
If you really want to do it in a signature block, I'd suggest adding
something as simple as "OpenPGP: 0xDECAFBAD" or whatever the heck your
key ID is.  :)

@_date: 2010-01-23 12:50:25
@_author: Robert J. Hansen 
@_subject: Incomplete mailing list archives? 
A while ago I downloaded the entire archives of the GnuPG-Users mailing
list, from the first message to the present.  (Having this archive makes
it a lot easier to refer people to older threads that addressed the same
Strangely, though, it seems the list archives are incomplete.  According
to it, my first post to the list was on March 5, 2006 ("Questionnaire
about GnuPG usage").  This seems strange, since I've been around for
some years before that.
Does anyone have any idea what's happening here?
Please note that I'm not claiming the list archives have been edited,
altered, or anything else like that.  There is no Orwellian "memory
hole" here.  I'm sure there's a reasonable explanation.  :)

@_date: 2010-01-23 19:28:56
@_author: Robert J. Hansen 
@_subject: Incomplete mailing list archives? 
This seems ... strange.  It does not jibe with my memory at all, not one
bit.  Then again, it wouldn't be impossible for my memory to be in error.

@_date: 2010-01-29 00:35:38
@_author: Robert J. Hansen 
@_subject: Revocation certificates 
Good!  :)
The original revocation certificate will work on the modified key pair.

@_date: 2010-07-06 12:52:11
@_author: Robert J. Hansen 
@_subject: GPG clarification 
Please consider upgrading to 1.4.10.  There have been a lot of changes
since 1.4.5, including better support for DSA2 and quite a few minor
I don't mean to sound acerbic, but the contents are exactly what's
stamped on the tin.
DSA is the Digital Signature Algorithm -- a U.S. federal standard for
digital signatures.  Per the federal standard in existence when 1.4.5
was written, DSA keys were allowed to have either 512 or 1024 bits.
GnuPG is simply letting you know the DSA keypair you're creating will
have 1024 bits.
More or less.  Getting into more detail will require mathematics and
talk about inverse functions and whatnot.  "More or less" is accurate
enough for most purposes.
No.  It's the ID of the key used for signing data.
It means "there is another set of cryptographic keys associated with
this signing key."  Without seeing the particular subkey I can't promise
that it's a set of encryption and decryption keys.  However, given what
you've said so far, I think it's likely.
They are intimately related, but not identical.
ssb is to sub as sec is to pub.
ssb = Secret Subkey.
Yes.  If you wish to do this, I'd suggest looking into a tool called
All algorithms used by GnuPG are considered safe against all known forms
of cryptanalysis.  And by "safe," I mean "really, anyone with half a
brain will find another way to get the information out of you, it'll be
so much easier that way."

@_date: 2010-07-22 16:26:45
@_author: Robert J. Hansen 
@_subject: plausibly deniable 
No.  Plausible deniability depends entirely on what your adversary finds
plausible.  "I didn't sign that!  Look -- I have Thunderbird configured
to automatically sign *everything*, and I have no passphrase on my key.
 Someone got access to my system and sent out a message that got
automagically signed by my key!"
Such things have happened before.  Werner himself has received
PGP-signed spam, from some hapless person whose machine had been
hijacked and was being used as a botnet to send messages through a PGP
signing proxy.  Some people will find this explanation plausible.
Others will merely find it convenient.
Since there is no agreed-upon definition of plausible deniability, GnuPG
cannot be said to provide plausible deniability.

@_date: 2010-07-22 17:28:28
@_author: Robert J. Hansen 
@_subject: plausibly deniable 
And I think that's a true statement.  :)  Plausible deniability is so
context-sensitive that without a lot of context data, nothing can be
said to provide it.

@_date: 2010-07-22 21:53:50
@_author: Robert J. Hansen 
@_subject: plausibly deniable 
It's considerably worse than that.
Thanks to the deniable encryption features of TrueCrypt, there is no way
to account for all the data.  Is that empty space in your container, or
is there a small hidden container that you're not confessing?
Ultimately, you can't make the interrogation stop *even if you confess
all the information the interrogator wants* -- because the interrogator
might (reasonably!) think you're holding out.
Deniable encryption is a useful tool, but it is not a universally good idea.

@_date: 2010-07-23 00:09:30
@_author: Robert J. Hansen 
@_subject: plausibly deniable 
The point is not about torture.  The point is about interrogation.
Imagine this scenario: you've been sending innocuous encrypted traffic
to a correspondent.  Unknown to you, your correspondent is involved in
drug trafficking.  You're arrested on suspicion of drug trafficking and
brought to speak with the prosecutor.  You happily decrypt your
innocuous emails.  The prosecutor now asks to see the contents of your
TrueCrypt container.  You comply, since there's nothing illegal in there

@_date: 2010-07-23 20:56:52
@_author: Robert J. Hansen 
@_subject: plausibly deniable 
This is not true.  There are documented instances where people have been
tortured to turn over crypto keys.
You are assuming the torturer is a rational human being who has enough
technical chops to know what a keylogger is and how to use it.  In
reality, torture is often the recourse of irrational human beings who,
due to stress, ignorance, or any of dozens of other factors, do not
immediately see a superior way to obtain the information.
Yes, if the authority is rational and technically skilled they will have
many better options than torture.  I just disagree that all authorities,
or even most of them, are both rational and technically skilled.

@_date: 2010-07-25 22:24:19
@_author: Robert J. Hansen 
@_subject: plausibly deniable 
This is not really plausible deniability.  "You say you didn't write it?
 Fine.  I guess we'll prosecute both you /and/ Jones, then!"
Let's say SmithJones at aol.com gets involved in something the authorities
don't like -- let's say narcotics trafficking.  What happens is Smith
and Jones *both* face charges of conspiracy to traffic, since the
collusion before to produce a shared keypair is prima facie evidence of
cooperation to hinder prosecution.
Is it rebuttable?  Sure.  Is it a nightmare for both of them?  Yes.
Does it make their communications plausibly deniable?  Not even close.

@_date: 2010-07-26 10:50:43
@_author: Robert J. Hansen 
@_subject: Can't open PGP file with Gnupg 
I believe Charly is in error.  The line ending convention is specified
in RFC4880, and both GnuPG and PGP conform to that.

@_date: 2010-06-10 20:22:24
@_author: Robert J. Hansen 
@_subject: Keyserver spam example 
[lots of discussion deleted]
I think it's safe to say the list moderators are now well aware of
what's going on, and how many people are bothered by it.  Let's table
this discussion for a week and see what the list moderators do.  If they
don't do anything, then let's re-open this can of worms.  Otherwise,
let's just keep cool and let the list mods do what they're best at.  :)

@_date: 2010-06-15 21:00:30
@_author: Robert J. Hansen 
@_subject: Fwd: [Full-disclosure] Introducing TGP... 
There is no formal spec for TGP which I've been able to find.  I did not
see any links to source on the site.
While no source and no spec doesn't automatically mean TGP is bogus, it
doesn't engender much confidence in the product.

@_date: 2010-06-17 19:21:32
@_author: Robert J. Hansen 
@_subject: encryption bloats file 
This is not unheard of.
First, compression only works when the data hasn't already been
compressed.  Many data formats (.jpgs, .pdfs, etc.) incorporate
compression, and so cannot be further reduced.
Second, if the sender is using ASCII armoring for their message, that
will result in an enormous increase in file size.  (On the plus side, it
means the message is a text message, which is more convenient for some

@_date: 2010-06-18 08:13:56
@_author: Robert J. Hansen 
@_subject: Multiple signatures 
gpg --armor -u signer -u signer2 -u signer3 --clearsign filename
Warning: these signatures will break old versions of PGP.  6.5.8 and the
6.5.8CKT builds will crash when trying to verify them.

@_date: 2010-06-21 10:48:34
@_author: Robert J. Hansen 
@_subject: Multiple signatures 
Perhaps I'm in error here, but -- isn't a clearsign the command I specified?

@_date: 2010-06-21 20:34:06
@_author: Robert J. Hansen 
@_subject: openpgp to sexp conversion .. 
Explain 'sexp', please?  When I hear someone talk about sexps, I think
they're talking about LISP S-expressions.  I don't know if that's what
you have in mind.

@_date: 2010-06-22 22:20:16
@_author: Robert J. Hansen 
@_subject: IDEA Status? 
By modern standards, IDEA is not considered a promising cipher.  There
are some very good theoretical attacks against it.  Between the varying
patent expiration dates (2011 or so in some countries, IIRC) and the
thin safety margin, the GnuPG community has generally decided IDEA is
not a priority for inclusion.

@_date: 2010-06-22 23:21:34
@_author: Robert J. Hansen 
@_subject: IDEA Status? 
I am correct, but I am not authoritative.  I'm not one of the GnuPG
developers, so I have no authority to make declarations on behalf of GnuPG.

@_date: 2010-06-22 23:25:54
@_author: Robert J. Hansen 
@_subject: IDEA Status? 
A little digging around revealed the United States patent expiration:
January 7, 2012.
I am not a patent attorney, I don't pretend to be an authoritative
source on patent law.  All we can say definitively is the original
patent expires January 7, 2012: subsequent patents may have extended
this date.

@_date: 2010-06-23 15:04:59
@_author: Robert J. Hansen 
@_subject: IDEA Status? 
Sure, but that makes it incompatible with the GPL -- and that
incompatibility puts some severe restrictions on redistribution.  There
are some (arguable) workarounds around it, but by and large it's best to
avoid the entire can of worms.
We don't need IDEA, so why wrestle with the Patent Monster?

@_date: 2010-06-28 18:20:11
@_author: Robert J. Hansen 
@_subject: On the fly encryption of files possible? 
This seems like a use case for whole disk encryption software, or
encrypted virtual drive software, and not GnuPG.
To the best of my knowledge, no one has such a tool involving GnuPG.
You may want to look into TrueCrypt instead.

@_date: 2010-06-29 12:32:46
@_author: Robert J. Hansen 
@_subject: On the fly encryption of files possible? 
The desired use case is to have a folder on disk where anything written
to that folder will be piped through GnuPG first.  You've already got to
deal with drag and drop, the possibility of multiple applications trying
to get access to the directory, race conditions, resource contentions
(how many GnuPG invocations will be going at once? is there enough
secure memory for them all?), and so on and so on.  You can probably
hack together a userspace solution that kind of works, but to do it
right you really need a kernel driver.
Kernel programming is hard and unforgiving.  Bugs don't crash your
application, they crash your entire operating system.  The pace of
development is excruciatingly slow.  If a userspace program segfaults in
development, I lose a few seconds.  If a kernelspace program segfaults
in development, I have enough time to brew a cup of coffee while I'm
waiting for my OS to reboot.  Multiply this by how many times a program
segfaults during development, and...
Sure, it's only a few thousand lines of C.  But I wouldn't call it
"trivial".  Not in the least.  I can count on one hand the number of
programmers I'd trust to do a good job of this.

@_date: 2010-06-29 13:30:54
@_author: Robert J. Hansen 
@_subject: On the fly encryption of files possible? 
That is not the use case I read in the original poster's message.  He
called for "on-the-fly encrypt"ion of files that "are to be saved into a
distinct folder with a public key".
Could you hack together a userspace app that served as a drag-and-drop
target and copied those files in encrypted form to a specified
destination directory?  Sure, I guess -- so long as you don't mind your
application not integrating with anything other than drag and drop.
Given it sounds like the use case is, "I want to be able to save my Word
document like normal, except that if I save it into this particular
folder, it should be encrypted before writing to disk," I think my
original remarks are correct.

@_date: 2010-06-29 20:41:26
@_author: Robert J. Hansen 
@_subject: On the fly encryption of files possible? 
The surest way to discover whether something is easy is to try it.  If
it's easy, then it's easily done.  If it's not, then it's not.
I don't want to sound as if I'm putting myself up as some kind of expert
on this.  (Beware of all experts: an ex is a has-been, and a spurt is a
drip under pressure.)  My only direct experience with this has been
writing a Win32 kernel driver to do ROT13 disk access: it isn't like I'm
an authority on filesystem implementation.
All this being said, "I wouldn't have thought it would be that hard..."
is the sort of thing I found myself saying, oh, a few *hundred* times
while writing that toy little Win32 driver.  Just sayin'.  :)

@_date: 2010-02-28 20:09:46
@_author: Robert J. Hansen 
@_subject: key question 
Go for it.  It's public data.  Assuming there's nothing intensely personal in there, I'll pass the results on to the list.
My point regarding the signatures don't tell you much -- if anything -- is there is no guarantee that a signer has had any contact with the key holder.  It's foolish to make conclusions about someone's social network based on their key material.  If I have a signature from a person, it is not a statement that I know that person, that I approve of that person, or that I would ever associate with that person.

@_date: 2010-02-28 22:31:40
@_author: Robert J. Hansen 
@_subject: key question 
This is assuming the signature is known to not be someone attempting a credibility attack, or that the signer didn't sign it by accident while intending to sign a different key, etc., etc.  I agree that once those assumptions are made you can learn an awful lot, and I agree that these assumptions are usually correct.  Not too many people sign keys by accident, or do credibility attacks, etc.
Maybe it's an artifact of my upbringing.  I see the world as broken up into things you can prove, things you suspect, and things that might be.  Signature analysis lets you know a lot of might-bes, and might be a good basis for suspicions, but without those preconditions I think it's pretty hard to prove things.
I imagine we're in agreement here.  I still look forward to seeing your results.  :)

@_date: 2010-02-28 23:54:46
@_author: Robert J. Hansen 
@_subject: David's findings 
David and I apparently had a bit of a misunderstanding.  I thought he was going to attempt to figure out information based solely on the key material: he was using it as a springboard for other research.  I think that both of us are correct, given the assumptions we were making.  If you have an email address and a name for someone, OSINT ("open source intelligence) is a hellishly powerful research tool -- especially when applied against people who have a substantial presence on the net.  However, the keyserver material *by itself, only referencing other keys* is not very useful and proves very little.
David did not give confidence assessments for his statements.  I have no way of knowing which ones he suspected, versus which ones he felt were proven.  Some of them would be quite easy to prove (or, at least, have very high confidence).  Others would be much more difficult.
* My father's name
* My father's military history (in broad strokes)
* My father's current occupation
* He was within 7 years of my father's age
* My mother's name
* My parents' location
* My brother's name and relative age to me
* The age of my parents' house
* My age, accurate to several years
* I was in Las Vegas in 2005
* I was at a keysigning in Portland in July 2006
* My educational background
* My ham radio license, and that it was issued west of the Mississippi
* That I'm a fairly advanced OpenPGP user
* The color of a vehicle owned by my parents
Things that he was wrong about:
* My religious upbringing
* My religious affiliation
* That I use GnuPG rather than PGP [1]
* That I'm a fan of Bungie Software's "Halo" games
... This may sound impressive, but most of it could have been more easily developed via Google.
Googling for "Robert J. Hansen" (with quotes) gives you my homepage as the first hit.  That tells you I graduated from Cornell College, gives you my exact birthdate, that I have three nephews, an awful dot-bomb experience, and that I maintain a software project called Djinni.
Googling for "Robert J. Hansen Cornell College" (without quotes) gives you all kinds of information about my father, along with my mother's name and the fact I have an older brother.  Once you have my father's name and the fact he's a federal judge, you just have to visit Wikipedia in order to get Dad's biography: his full name, his military history, his current position, his age, and so forth.
When you Google for "Robert J. Hansen Cornell College", you'll discover the third link down tells you I was in Las Vegas in 2005, delivering a talk to Black Hat.
Googling for "Robert J. Hansen Djinni" tells you that I spoke at CodeCon 2006 (in San Francisco) and at OSCON 2006 (in Portland).  Given that I have a cluster of signatures on one of my keys, all issued during the same time CodeCon 2006 was going on, it's a pretty easy guess that I attended a keysigning in Portland in July 2006.
The only things that I do not believe he could have discovered in a five-minute Google search were (a) my ham radio license, (b) that I'm a fairly advanced OpenPGP user, and (c) that I attended a keysigning in Portland in 2006.  Everything else could have been found more easily with basic Google searches.
So, the overall score: developing OSINT with Google, really cool.  Developing OSINT by studying key material, not as productive.
I would like to thank David for taking the time to do this test.  The conclusions that I've drawn are my own: I do not speak for him.  I'm certain he'll give his own conclusions.
Please be very careful when using this to support broad, general statements.  This is only one test, it was informal and very quick-and-dirty.
[1] I use both PGP and GnuPG.  I'm ecumenical.  Most of my emails are sent via Enigmail+GnuPG, but I've paid for PGP releases ever since 5.0.  The only major version I've skipped was 9.

@_date: 2010-03-01 19:11:41
@_author: Robert J. Hansen 
@_subject: David's findings 
You phrased it in your email to me as two sentences, and I was cutting back and forth between reading your email and composing the email to the list.  "Bullet point: raised Methodist, no, Episcopal," cut over to the compose window, go back, "Bullet point: no, I am not at present a Methodist," cut over to the compose window, etc.
It's not my intent for those bullet points to be read as any kind of a score.  That would be giving the appearance of a rigor I don't think this test possesses.  :)  The results are interesting, but not rigorous.
Be less trained, yes.  However, I think my example of how doing those same tasks using pretty obvious Google searches shows that the threshold of difficulty is already quite low.  The information is out there, and people who keep their keys off the keyservers because they want to preserve their privacy need to realize they're not fighting a losing battle -- they've already lost.
I disagree, but beyond that I can't comment.  It's no longer my privacy, but my parents'.

@_date: 2010-03-02 23:00:24
@_author: Robert J. Hansen 
@_subject: Migrating from PGP to GPG question 
Ever since the very early days, PGP has supported a cryptographic algorithm called IDEA.  Back in the early '90s IDEA was considered a strong, promising cipher.  Time has not been kind to it.  The current judgment of IDEA is that it is strong *enough*, but not really strong, and it is not considered especially promising.  It is also subject to software patents.  For these reasons, the current revision of the OpenPGP specification does not require or recommend that implementations support IDEA.
(The OpenPGP *specification* is not the same thing as PGP or GnuPG, which are *implementations* -- in the same way that Outlook and Thunderbird *implement* email protocols, but those protocols are *specified* in other places.)
Anyway.  By default, GnuPG does not support IDEA.  PGP does, mostly because they still have customers who need it.  Different strokes for different folks.
What GnuPG is warning you about is, "your current key says that other people can use IDEA when sending you encrypted email.  I can't read IDEA.  This will be a problem if anyone sends you IDEA-encrypted traffic.  Would you like for me to change your key so that other people can know not to send you IDEA traffic?"
I'm hedging my bets a little bit, since I don't know enough about your specific needs to speak with certainty.  That said, I believe it is safe for you to answer "yes" here.

@_date: 2010-03-03 01:41:57
@_author: Robert J. Hansen 
@_subject: How to give the keyword from command line.   David Shaw 
This sounds like a use case for TrueCrypt or Linux's encrypted loopback filesystem or BitLocker or PGPdisk or... (insert many other options here), not GnuPG.  Use the right tool for the job: don't try to drive a nail with a microwave oven.

@_date: 2010-03-03 13:49:53
@_author: Robert J. Hansen 
@_subject: key question 
I agree that OpenPGP implementations can be useful tools for the
advancement of human rights -- but I also think Mark is (almost) right.
 It isn't that using OpenPGP implementations to commit crimes is kind of
stupid: it's that *naive* use of these implementations is kind of
stupid.  But that just means OpenPGP implementations are no different
than any other kind of tool.
I fully agree.  I would just add that we as a community need to
emphasize the importance of good tradecraft, in addition to the
importance of email crypto.

@_date: 2010-03-03 13:52:17
@_author: Robert J. Hansen 
@_subject: key question 
It is not reasonable that their definition of privacy will overlap with
yours, no.  I don't get to define what "privacy" means for anyone other
than me.  You don't get to define what "privacy" means for anyone other
than you.
Since there is no shared definition of privacy, there can be no
reasonable assumption that people who use and promote what *you define
to be* privacy-enhancing software will value and respect privacy
*according to your definition*.

@_date: 2010-03-03 23:47:41
@_author: Robert J. Hansen 
@_subject: Continued PKA problems on Windows 
Telling someone to change their entire operating system just to resolve a bit of undesired behavior seems pretty extreme.
Linux, FreeBSD, etc., all have plenty to recommend themselves without us needing to characterize Windows, Solaris, etc., as not a "real" operating system.  For that matter, I'm writing this from a true-blue, certified UNIX: OS X.  I think it's quite real, despite the fact major parts of the desktop are closed-source.

@_date: 2010-03-05 10:50:42
@_author: Robert J. Hansen 
@_subject: manipulating the set of keys that can decrypt a file/message 
If memory serves, the codebases are identical with respect to this.
Shouldn't matter which one you use.
I am not a GnuPG developer.  I have no say in what they will or will not
do.  However, my impression is that GnuPG tends to only adopt features
that will be broadly useful to a number of users.  This seems like a
really niche case.
If you think this feature should be merged into GnuPG, I would suggest
by finding ten people who have an actual, real need for this feature.
Not "I think it would be cool if...", but "I need this right now
because...".  If you can present real users who have real needs, that
will do a lot to increase the chances of it being merged into the mainline.

@_date: 2010-03-05 16:30:05
@_author: Robert J. Hansen 
@_subject: Memory forensics 
For quite some time we've known that hibernation files present risks for
information security.  However, there are always those who say "until I
see an actual demonstration, I won't believe it."
The upshot: we now have an actual demonstration.  The takeaway is that
you should be very, very careful about hibernating your computer while
passphrases are cached, or while GnuPG is actively processing a file.

@_date: 2010-03-05 17:18:53
@_author: Robert J. Hansen 
@_subject: Memory forensics 
Note Jesse's phrasing: "volatile memory forensics."  Swap space is
nonvolatile storage.  Hibernation files are just dumps-to-disk of the
state of volatile memory when the laptop lid is closed.  Extracting keys
from swap space is a solved problem: hit Google Scholar and search for
"file carving" and you'll get a lot of relevant papers.
(While you're at it, check Google Scholar and search for "memory
forensics kornblum" -- Jesse is pretty widely published in memory
forensics.  That doesn't mean he's automatically right, but he's not
just some random LiveJournal account, either.)
Further, two co-workers of mine have spoken in person with the
investigators involved in this prosecution.  These co-workers report to
me that the investigators have confirmed it was hibernation file analysis.
If you want to know specifics, I'd suggest calling the prosecutor and
asking for copies of the indictment.  It's a public record and the
prosecutor is required to provide a copy upon request.

@_date: 2010-03-06 02:02:24
@_author: Robert J. Hansen 
@_subject: Memory forensics 
Err -- why?
Volatile Systems is behind the Volatility framework, which is probably the best FOSS tool going right now for Windows memory analysis.  (Admittedly, it only works on Windows XP... but given XP's userbase, even today, that's not a huge loss.)  If you want to learn about what memory analysis can do, you could do a lot worse than to look into Volatility.
Volatility can also inspect Windows XP's hibernation file and recover data structures from it.  I seem to recall that Volatility was the toolkit used by the Madison investigators, but don't quote me on that.  I may be barking wrong.

@_date: 2010-03-11 10:43:03
@_author: Robert J. Hansen 
@_subject: Implications Of The Recent RSA Vulnerability 
You might as well ask, "what's the point of OpenPGP at all, if it's so easy to Van Eyck your monitor?"  Or, "if it's so easy to plant a keylogger?"  Or, "if it's so easy for someone to whisk me up off the street into a dark van and play the bongos on my kneecaps until I tell my secrets?"  Or? the list goes on and on.
OpenPGP assumes the endpoints of the communication are secure.  If they're not, there's nothing OpenPGP can do to help you make it secure.
If you think this is a problem, then I would observe your microwave oven does a really lousy job of keeping your beer cold.  All tools have preconditions: the existence of a precondition doesn't mean the tool is broken.  The precondition for a microwave oven is, "the food must need heating."  The precondition for OpenPGP is, "the endpoints must be secure."

@_date: 2010-03-11 10:46:54
@_author: Robert J. Hansen 
@_subject: Off-The-Record Email 
Not really.  OTR uses DHKEA for symmetric key negotiation.  This is an interactive protocol: you send some information, the other person sends some information back, back-and-forth a few times until a symmetric key emerges from the mathemagic.
Email is not an interactive protocol.  You could probably invent a way to do OTR via email, but it would probably be a horrible kludge.

@_date: 2010-03-12 07:03:05
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
Sources, please: I'd like to see citations for "people get convicted ... based on spoofed emails and plain-text emails all the time."  Based on plain-text emails, sure.  Spoofed emails, though, that's a bit of a stretch and I'm going to need to see cites.
Either way, this kind of raises the question, "so why do you want to use OTR, anyway?"  If the entire point of OTR is PFS/R, and you don't believe OTR can solve PFS/R, then why use OTR?
The question isn't whether you can.  The question is whether it's wise.  The principle of using one credential to authorize the use of another credential is about as old as the hills.  The ways to exploit this are about as old as the hills, too.  I'm out the door for work in a few minutes so I can't spend the 20m looking up a definitive cite, but I'd suggest looking in Ross Anderson's _Security Engineering_.  It's pretty comprehensive; it's where I'd start looking.

@_date: 2010-03-12 14:31:31
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
Sure.  But the problem here isn't spoofed emails.  The problem here is living in an area where basic human rights aren't respected.  The spoofed emails didn't get them convicted: the spoofed emails were cooked up to provide political cover for a conviction that was preordained.
So I think the statement, "people get convicted ... based on spoofed emails ... all the time" is overreaching.  The basis for their conviction is they're members of a persecuted minority -- not spoofed emails.
Which leaves the question unanswered: since OTR exists to provide PFS/R, and you ignore PFS/R, why use OTR?
This is kind of trivial.  When an accused criminal is arraigned, they are given the chance to plead guilty or not guilty.  The only way to get a trial is to plead not guilty: if you plead guilty you go straight to the sentencing phase.  So yes, in every criminal trial there's a defendant who is making his or her best effort to claim innocence.  Some are innocent, some are guilty, and it's the jury's job to figure out guilt or innocence.
So yes, I agree with you.  I just don't understand what you're getting at.
If you live in a place that does things like this, they can already throw you in the gulag under any pretense they want.  What you need is to either (a) move somewhere else, (b) foment a revolution, or (c) keep your head down and pray the government doesn't notice you.
GnuPG won't help you out with (a) or (c).
GnuPG might help you out with (b)... but only by helping you keep information safe between the endpoints.  If you're concerned about the secret police kicking down the door and practicing field expedient dentistry on you, you don't need GnuPG, you need a CNN camera crew and an AK-47.  This does not mean GnuPG is defective.  It means you need to understand your problem, your solution, and what tools you need to enact your solution.

@_date: 2010-03-13 01:00:57
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
Semantics.  A security hole is a way by which the security policy may be violated.  Most people don't bother to think about policy in the first place.  This devolves into a philosophical question of, "is the fact most people don't bother to think about their security policy a way by which their security policy can be violated?"  It turns into a how-many-angels-can-dance-on-the-head-of-a-pin thing.  But it is at the very least a problem and you'll find few people here disagree with that.
A serious question here -- have you considered writing Immigration and Customs Enforcement or the Border Patrol (or equivalent groups, wherever you are) and asking them for information on how to distinguish real passports from forgeries?
Most governments are very willing to tell people what to look for.  It's in their best interests for official identity documents to not be forged, and for forgeries to be discovered as quickly as possible.  When I've asked the United States government about this they've always been cooperative.
You'd be amazed what you can learn just by having the chutzpah to walk up to someone who knows and saying, "hi, could you share?"  :)
It is also a far weaker form of authentication than is often recommended for OpenPGP keys.  Not that this makes the technique invalid, but the weaker authentication needs to at least be considered.
The United States has 1400 independent daily newspapers, each of whom employ a large number of people whose job it is to look.  On top of that you have groups like the Innocence Project that look for abuses in criminal courts, you have groups like ACCURATE that look for abuses in voting, you have...
The Western tradition of government usually involves a lot of people looking.  This is certainly not to say that abuses don't happen -- they clearly do -- but they do not occur at the frequency many fear.

@_date: 2010-03-13 01:10:20
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
The passport isn't used to verify the OpenPGP key.  The passport is used to verify *identity*.  The key fingerprint is used to verify the OpenPGP key.
A signature is a statement of "I believe this person is associated with this OpenPGP key."  To do that, you have to first verify the person is who you think they are (the passport); you have to verify the key is what you think it is (the fingerprint); and then you make a statement about the two being associated.

@_date: 2010-03-13 01:11:56
@_author: Robert J. Hansen 
@_subject: updprefs command and changing key 
Kind of, but it's not recommended.
"--cipher-algo AES" will do it, but please don't.  This kind of brute force approach is almost always the wrong thing to do.

@_date: 2010-03-13 01:13:17
@_author: Robert J. Hansen 
@_subject: updprefs command and changing key 
--cipher-algo [something other than 3DES] won't do it?  Faramir was asking only about disabling it when encrypting: I was under the impression --cipher-algo could be used to do that.
Not that I think people should, of course.  :)

@_date: 2010-03-13 02:30:11
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
It's a question of degree, not kind.
How do you know the secret is known only to him?  Most "secrets" really aren't; a good investigator can discover an awful lot of "secret" information about someone.  Shared-secret authentication is one of the weakest forms out there.  It's better than nothing, but it's not something that ought be relied upon.  People tend to vastly overestimate how secret their secrets are.
As an example, a few years ago I saw in a spy novel (set in the modern day) two protagonists negotiating a phone number over an insecure line.  "Hey, that guy we know who did X?  Take his phone number, subtract this number from it.  The resulting phone number is what you need to call."  It sounds great and reliable: it's a shared secret.  The problem is it's totally bogus.  Phone numbers aren't random.  In the United States, for instance, phone numbers follow the NPA-NXX format.  That reduces this question down to a glorified Sudoku: a skilled investigator could figure it out in just a few minutes.

@_date: 2010-03-13 02:44:56
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
Cites, please.  Show me studies showing how often immigration officials get duped, and how often they correctly flag false passports.
When verifying an identity document, the null hypothesis is "this document is invalid."  Rejecting a good passport is a Type I error; accepting a bad passport is a Type II error.  Please show me published estimates of Type I and Type II errors by immigration officials.  When you say "all the time," it seems that you mean the Type II error rate is through the roof, and I'm going to need evidence before I accept that claim.
Even then ? so what?  Let's say the Type II rate is 25%.  That's a very high Type II rate; most people would think that failing to recognize one set of fake IDs per four is a really bad error rate.  Yet, if you're at a keysigning party where there are five people independently applying a 25%-faulty test, the likelihood of accepting a fake ID is under 1%.  See previous message.
There is a difference between being skeptical and being cynical.  I am all in favor of skepticism, but modern cynicism is a puerile philosophy and I'll have none of it.  Skepticism insists on evidence at each step and follows that evidence wherever it leads.  Modern cynicism believes it already knows where that evidence must lead, and thus there's no need to discover evidence and reason concretely about one's discoveries.

@_date: 2010-03-13 11:34:28
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
99.6%; a little different.  The binomial theorem gives us the correct numbers.
0 failures: 31.6%
1 failure: 42.2%
2 failures: 21.1%
3 failures: 4.7%
4 failures: 0.4%
Anyway.  This handwaves the fact that 99.6% of the time, someone at the keysigning party will say, "hey, that's weird!" and show it to everyone else at the keysigning party.  Even if your very high Type II error rate is correct, then assuming there's not some deep systemic reason for the failure (i.e., all trials are independent), you still have nothing to worry about.  You can have a test that immigration officials screw up 25% of the time, and still have it be perfectly suitable for a keysigning party.

@_date: 2010-03-13 11:43:44
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
Only because the news doesn't report on people who get arrested based on false identity documents.  By the very nature of journalism, it pays more attention to the extreme and the unusual than it does the mundane and humdrum.  If a madman shoots 14 people in a shopping mall in Oconomowoc, that's news: if 1,400 people die of cancer nationwide that day, it doesn't even get a mention.  Following the news would lead you to thinking you needed to buy body armor, not that you could stand to lose a few pounds and you should stop smoking.
Be careful about forming your opinions of normalcy from watching news reports.

@_date: 2010-03-13 21:38:43
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
You don't.
If person A and person B disagree on whether something is fake, the
operating assumption is that it's fake.  The burden is on the person
claiming it's *not* fake to persuade the person claiming it *is* fake
that they're wrong.
Alan: "Hey, Bill, did you see this ID?  It looks fishy."
Bill: "It looked good to me."
Alan: "It doesn't look good to me."
Bill: "Okay.  Let me show you why I thought it was good, and let's take
       it from there..."
There is a word for someone who keeps their mouth shut about fake IDs at
keysigning parties.  That word is *conspirator*.
If you're assuming everyone else at the keysigning party is a
conspirator, then sure, you're out of luck.  But in that case, you were
out of luck before you even stepped in the door.

@_date: 2010-03-14 03:49:05
@_author: Robert J. Hansen 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
No.  "Given a population of four inspectors, there is a 68% chance of
one or more failures *due to their actions, inactions and random chance*."
Think about a busy street.  If there's a 50% chance of a pedestrian in
the crosswalk getting turned into a new decoration on the front grill of
the cross-town bus, that doesn't mean you should put on a blindfold
before stepping out on the street.  That would just be crazy.  Yet, if
the likelihood is 50% "regardless of what actions they may or may not
take to influence their chances of making a mistake," then not only is
it not crazy to put on a blindfold -- why not put on an iPod, too?
Yes.  But so far you've failed to even present the *normal* Type II
error rate.  I'm willing to stipulate a very high normal Type II error
rate, but if you want me to believe there's a systemic Type II problem
I'm going to need to see citations.
Of course we are.  That's the entire point of statistics.  If I know the
average IQ is 100, and the standard deviation is 16 points, then if I
pull a random person out of a hat I'm about 95% likely they score
between an 84 and a 116.
Nicholas Taleb (a pretty well-respected statistician and epistemologist)
divides the world into Mediocristan and Extremistan.  In Mediocristan,
the law of averages dominates.  In Extremistan, the bell curve exists
but its tails are so bizarrely shaped that many statistical tools fail.
Independent error is Mediocristan.  Systemic error tends to lead to
Extremistan.  Independent errors are highly predictable and can be
accounted for.  Systemic error destroys independence, and the entire
system comes off the rails shortly thereafter.
I'm willing to posit independent error here, and even a really high rate
of independent error: but before I say "document inspections are in the
land of Extremistan," I'm going to need to see some numbers backing that up.
Err -- why wouldn't they?
This is a keysigning party.  It is in everyone's best interests to
accept all good IDs.  If I see an ID that I believe is false, then it is
in my own best interests to bring it to the attention of everyone.  If I
reject an ID incorrectly and refuse to sign, then I am damaging my own
standing in the Web of Trust.
You keep on inventing ever-more new and exotic ways to suggest systemic
bias, without ever giving numbers supporting the claim.
If *everyone* is incompetent, stupid, lazy, unsure or unaware, then yes,
you've got a really interesting keysigning party (in the "may you live
in interesting times" sense of the phrase) and I suggest getting out of
there as soon as possible.  But that's a stretch I'm simply not willing
to grant you.

@_date: 2010-03-18 01:03:32
@_author: Robert J. Hansen 
@_subject: Science News on statistics 
A while ago we had a discussion here about the use of statistics ---
particularly, Type II error rates.  It turns out that /Science News/ has
a pretty good article on statistics and its limitations
. It's accessible to the layman: it might be a little much to swallow in
places, but by and large if you survived high school math you'll survive
the article.
If you don't want to click on the embedded link (and who could blame
you), then C&P this link:

@_date: 2010-03-19 17:30:24
@_author: Robert J. Hansen 
@_subject: Secure unattended decryption 
Only if you design your database poorly.  This is a solved problem in
both database design and filesystem design.

@_date: 2010-03-19 19:44:38
@_author: Robert J. Hansen 
@_subject: AUTO: Richard Hamilton is out of the office (returning 03/22/2010) 
More often than not, these sorts of problem can be fixed more
effectively by the list owner unsubscribing the offending email address.
 Let's let the list owners handle this, and not run the risk of a
half-dozen of us calling this guy's workplace and getting him in trouble
just because he had a braino when he left on vacation.

@_date: 2010-03-20 08:34:52
@_author: Robert J. Hansen 
@_subject: AUTO: Richard Hamilton is out of the office (returning 03/22/2010) 
There are a fair number of jobs that would.  Let's not make
presumptions, and let's let the list moderators handle this.

@_date: 2010-03-20 08:58:55
@_author: Robert J. Hansen 
@_subject: AUTO: Richard Hamilton is out of the office (returning 03/22/2010) 
Scenario 4:
He is not the boss and is on the list with his company's permission.
However, like many businesses, his company is very sensitive to
complaints from outside.  He probably doesn't lose his job or anything,
but does get a dressing-down from the folks who sign his paychecks, and
winds up thinking about this list, "gee, what a bunch of rude and
insensitive people -- as if *they've* never made an error before."
... The more we talk about this, the more we damage the list's signal to
noise ratio.  Originally, he just sent *one* off-topic message to the
list.  That has now spawned an entire thread of off-topic messages.  Why
are we still talking about this?  Let's let the list moderators handle
it, and go back to on-topic discussions.

@_date: 2010-03-20 10:00:11
@_author: Robert J. Hansen 
@_subject: Secure unattended decryption 
You're doing it wrong.  Keep searching.  I know there's at least one
paper readily findable in Google Scholar that tells you exactly how
BitLocker does it.
Most academics are incredibly vain types.  If an academic tells you that
he or she knows a paper exists, odds are good that's because he or she
either wrote it or contributed to it in a significant way.  Given this,
you might want to try doing a Google Scholar search on '"Robert J.
Hansen" encryption'.  Once you find a paper name and an author, try
Googling on that and see if the paper author doesn't have a free version
up available for download.
Basic research is a skill worth learning.  Good luck!

@_date: 2010-03-20 20:09:15
@_author: Robert J. Hansen 
@_subject: Keyservers 
"Best" is inherently subjective.  However, many people here use
pool.sks-keyservers.net and are happy with it.  It's as good a choice as

@_date: 2010-03-20 22:15:37
@_author: Robert J. Hansen 
@_subject: Generating a new key 
ObAdvice: it's probably best to stick with the defaults unless you've
got clear needs the defaults don't meet.  Or, if you just like to tinker
around with things.  You don't need to tinker with settings in order to
make GnuPG work well.  All that said:
Large keys like this may give you some headaches down the road.
Increasingly, we're moving to a handheld culture: whether a BlackBerry,
an iPhone or an Android, the cell phone is becoming increasingly
important as an electronic communications tool.
It's reasonable to think that in the next five years OpenPGP will come
to cell phones in one way or another.  If so, you will discover that 4k
encryption keys are painfully slow on handheld devices.

@_date: 2010-03-21 19:06:13
@_author: Robert J. Hansen 
@_subject: Generating a new key 
There is, although the name is unofficial and not widely used.
When people migrated from MD5 to SHA-1, there were a lot of protocols
that only had 128 bits reserved for the hash.  A common hack was to use
SHA-1 and drop 32 bits.
RIPEMD-128 is RIPEMD-160 with 32 bits dropped, and RIPEMD-128 is an
officially recognized name.  A fair number of people applied the same
reasoning to SHA-1, and thus SHA-128 was born.
Unlike RIPEMD-128, SHA-128 was never official.  The name never took off,
although the hack was pretty commonly used.

@_date: 2010-03-25 13:06:36
@_author: Robert J. Hansen 
@_subject: Issue with GnuPG -> PGP, self signature, new key 
It is most likely a compatibility issue.  PGP 6.5.8 is well over a
decade old; PGP 5 is even older.  Those versions are not especially
compatible with RFC4880, which is the IETF standard which defines the
OpenPGP protocol.
You may want to consider adding "pgp5" to your gpg.conf file, which you
can find in your .gnupg directory.

@_date: 2010-05-24 19:25:58
@_author: Robert J. Hansen 
@_subject: new Installation... configure issues 
Unfortunately, this is a Solaris system administration issue and not a
GnuPG issue.  You will be better served asking on one of the OpenSolaris
mailing lists.
That said, I believe the package you need to download is the SunStudio
compiler suite.  That will provide you with a C compiler.

@_date: 2010-11-10 12:37:15
@_author: Robert J. Hansen 
@_subject: Import .p12 key file 
Depends on what particularly you wish to use GnuPG for.  By and large,
GnuPG is used for the OpenPGP.  PKCS-12 files (.p12) are not used in
Recent versions of GnuPG support S/MIME, which *may* use PKCS-12.  (I
don't recall offhand for a fact: I just have a vague impression they
do... or maybe it's PKCS-7 I'm thinking of.)
Basically, are you looking to use GnuPG for OpenPGP support or for
S/MIME support?  If the answer is "OpenPGP" or "neither", then you
probably need to rethink your plan of using PKCS-12 files.

@_date: 2010-11-11 23:44:02
@_author: Robert J. Hansen 
@_subject: gpg --verify detached signature from two file descriptors? 
This may be more hammer for your task than you really need, but I would
consider making a memory-mapped file object.  Read the data from the two
anonymous FDs, concat them into the memory-mapped file object, and pipe
those contents to GnuPG.
(Note that most people use MMFOs to populate memory blocks with file
contents, but there's no requirement it correspond to a physical file on
disk: anonymous FDs should work.  Also note that I haven't done POSIX
memory mapped files in quite some time: my recollections may be off.)

@_date: 2010-11-12 07:28:13
@_author: Robert J. Hansen 
@_subject: gpg --verify detached signature from two file descriptors? 
Not really, no.
I am not trying to tell you what your problem really is or how it ought
be solved -- you're the guy who knows the ins and outs of it, after all.
 :)  That said, I will just repeat three well-worn bits of generally
applicable advice:
1.  Don't optimize code that isn't a bottleneck -- there's nothing wrong
with making GnuPG do unnecessary work so long as that part isn't the
2.  Don't make assumptions about where your code bottlenecks.  Profile it.
3.  GnuPG is a very mature project that's had a lot of people hammering
on it.  Your own code is probably much newer with far fewer people
hammering on it.  "Potentially falling prey to ... bugs in gpg's code"
by making GnuPG be clever about the data pipeline may be safer than
making your code be clever about the data pipeline.
... I don't have any answers for how you might approach this, other than
what I've already mentioned.  Sorry!

@_date: 2010-11-13 09:15:20
@_author: Robert J. Hansen 
@_subject: problem with german umlauts 
Is that the client charset for GnuPG, or the client charset for
Thunderbird itself?  Keep in mind Thunderbird can display data in many
different encodings, too.
If Thunderbird is expecting ISO-8859-1 and you're passing umlauts in
from GnuPG as UTF-8, you'll get some strangeness.

@_date: 2010-11-15 16:21:28
@_author: Robert J. Hansen 
@_subject: Examine a key file 
Never tested it, but this should work (or come close to working):
gpg --dry-run -vvvv --import pubkey.asc
This will spam you with a *ton* of information, all in textual format.
It can be parsed out with flex/bison pretty easily, or munged with your
Swiss Army chainsaw of choice.

@_date: 2010-11-17 08:34:05
@_author: Robert J. Hansen 
@_subject: GPG on Windows 7? 
Hash: SHA256
Given this message is composed and signed on a Win7/64 box, the answer
is "yes."

@_date: 2010-11-17 11:46:18
@_author: Robert J. Hansen 
@_subject: GPG on Windows 7? 
As near as I can tell, there is no basis for the claim "inline PGP is
It is deprecated in the minds of some people, but that's not the same as
it being deprecated.  RFC3156 (which most people cite when talking about
inline PGP being deprecated) has been out of date for quite some time
and is not all that compatible with RFC4880.
For instance, from RFC3156, "OpenPGP signed data":
    "Currently defined values are 'pgp-md5', 'pgp-sha1',
     'pgp-ripemd160', 'pgp-md2', 'pgp-tiger192', and
     'pgp-haval-5-160'."
Strict RFC3156 conformance means the only two GnuPG hashes you can use
are SHA-1 and RIPEMD-160, neither of which has strong long-term
prospects.  This, alone, should be enough for us to say RFC3156 should
not be considered normative of PGP usage.
Speaking only for myself, I consider RFC4880 normative, and RFC3156
It most definitely is /not/ deprecated.  According to Microsoft [1], it
will not enter end-of-life until 2012.
[1] Never seen it happen myself, and I find it unlikely.  Win 7/64 offers a
complete set of 32-bit libraries.

@_date: 2010-11-17 14:18:38
@_author: Robert J. Hansen 
@_subject: GPG on Windows 7? 
The authoritative sources on the deprecation of inline OpenPGP would be
the IETF working group for OpenPGP, and/or the authors of RFC4880.  To
the best of my knowledge neither group has made any statement about this
deprecation: therefore, if you want to claim it is deprecated, you will
need to present statements from either group stating such.
Just because some people on mailing lists that Google crawls say inline
OpenPGP is deprecated doesn't make it so -- any moreso than the fact
9/11 truther mailing lists get crawled by Google mean 9/11 was an inside
Speaking for myself, I would advise you to describe your problem and
what you have tried to resolve it.
Most problems result from user error and/or misconfiguration.  Very few
problems require the user upgrade GnuPG.  In many instances, upgrading
GnuPG is simply not an option (e.g., enterprise users, or installations
that have to exhaustively test all software before it goes on servers).

@_date: 2010-11-18 11:49:54
@_author: Robert J. Hansen 
@_subject: Gpg4Win 2.0.4 with GnuPG 1.4.11?? 
Search the mailing lists -- you'll find many people have had problems
with 2.0.x, usually with respect to gpg-agent.  The goal was to reduce
the complexity of the codebase, but it seems it came at the expense of
simplicity of use.
Like most things in engineering, there are no pure wins, only tradeoffs
to be optimized.

@_date: 2010-11-18 11:59:07
@_author: Robert J. Hansen 
@_subject: Gpg4Win 2.0.4 with GnuPG 1.4.11?? 
Not true.  For instance, WinZip is a 32-bit application, yet it
integrates just fine into the context sensitive menu.
If your applications do not work properly under Win7/64, that's probably
due to a flaw in the applications themselves rather than in a limitation
of Windows.
(Yes, I'm writing this on a Win7/64 machine with 32-bit WinZip installed.)

@_date: 2010-11-18 17:51:44
@_author: Robert J. Hansen 
@_subject: Gpg4Win 2.0.4 with GnuPG 1.4.11?? 
Winzip 15.  9.0 is /way/ old and likely is having problems operating
with the quite-new Windows 7.  Microsoft made some very substantial
changes to the way Windows works during the XP-to-Vista transition: I
suspect that's what's hanging you up.
Unless you're paying someone money for a software product, odds are very
good they're developing/maintaining it on their own and they'll get
around to feature enhancements if and when they can.  People who give
you the fruit of their labor for free are under no obligation to keep on
doing it in the future to keep current with changing Windows releases.

@_date: 2010-11-18 19:38:17
@_author: Robert J. Hansen 
@_subject: Gpg4Win 2.0.4 with GnuPG =?UTF-8?B?MS40LjExP8K/?= 
"You keep using that word.  I do not think it means what you think it
Deprecation is usually applied to API calls and/or software features,
not software as a whole.  It means something still exists but has been
superseded and should be avoided in effectively all contexts.  For
instance, the Win16 API is deprecated: Windows programmers should not
use it and should not rely on it existing in any future version of
Windows.  Windows 3.1 is not deprecated, though, despite being older
than some people on this mailing list: it's just been EOLed.

@_date: 2010-11-20 09:51:18
@_author: Robert J. Hansen 
@_subject: Help with GNU PGP - no password prompt when sending e-mails 
It seems you're confusing encryption and signing.  No passphrase is ever
needed in order to encrypt a message to someone.  You only need a
passphrase when signing a message, to verify that it comes from you.

@_date: 2010-11-20 15:31:16
@_author: Robert J. Hansen 
@_subject: Gpg4Win 2.0.4 with GnuPG 1.4.11?? 
Given that the same message arrived in my mailbox from the list, sent to
the list and cc'd to you, it seems you are in error.
Whenever something seems absolutely obvious, nine times in ten it is not
quite so.

@_date: 2010-10-05 16:04:31
@_author: Robert J. Hansen 
@_subject: Encrypt Error - There is no assurance this key belongs to the 
Is this an error (something that actually prevents you from encrypting),
or is it just a warning (letting you know about something, but not
preventing the encryption)?
This is done by validating the key and signing it with your own key.
If you want to shut off all validation checks, putting "--trust-model
always" on the command line will do that.
None worth mentioning, but I believe a security vulnerability has been
discovered which affects version 1.4.5.  You may want to consider
upgrading to the latest 1.4 (1.4.10 as of this writing).

@_date: 2010-10-06 15:04:51
@_author: Robert J. Hansen 
@_subject: Remove key from an encrypted file? 
Possible?  Probably.  Practical?  Probably not.
Your best bet is to re-encrypt the material to the remaining two keys.

@_date: 2010-10-07 12:36:37
@_author: Robert J. Hansen 
@_subject: Seahorse 
During grad school I did a few semesters of human-computer interface
(HCI) design, particularly with respect to OpenPGP user interfaces.
It's a fascinating subject but ultimately left me very, very cynical.
Here's why.
[sets the rant switch to ENGAGED]
The reason why user interfaces suck: crypto is hard, making good user
interfaces is hard, the OpenPGP spec is human-unfriendly, and there is
an enormous resistance in the community to newer and better interfaces.
Consider signatures on a user ID.  A signature issued by someone you
don't trust is utterly meaningless.  It's noise.  There are a couple of
possible use cases (e.g., trying to find ways to connect two disjoint
webs of trust, or mapping out a target's social network), but those are
pretty niche when compared to average users and their needs.
So, already, one way to make interfaces simpler: omit all untrusted
signatures.  If a signature doesn't contribute to the overall trust
calculation on a key, don't display it -- reduce the cognitive spam.
Another culprit: we've now got about 15 years of experience with a
really awful user interface that should have never been fielded.
Unfortunately, that interface has now become standard, and any attempt
to change it will get pushback from users.
Table-oriented data is principally useful in two conditions:
non-interactive interfaces and contextual views.
In non-interactive interfaces (like printed almanacs), all the data has
to be visible all the time.  If I want to look up the population of
Zimbabwe, well, the almanac can't interactively ask me the country I'm
looking for.  It has no option but to present all countries, and give me
a user interface that makes it possible to find what I'm looking for.
In contextual views (like Excel spreadsheets), the data in one area is
contextualized with information from another area.  When looking at a
business's profit-and-loss statement, it's useful to be able to
immediately see how much each business unit contributed to the bottom
line.  Or, in your email client, it's useful to be able to see your
emails in chronological order: the sequence in which they arrived is
contextual information relevant to each email.
So... consider the traditional OpenPGP certificate management interface.
 It presents all these certificates in an enormously complex tabular
format.  Click on a certificate and it reveals user IDs and subkeys.
Click on a user ID or a subkey and it reveals signatures.  Etc., etc., etc.
This interface is user-hostile.  There are two compelling reasons to use
tabular data -- noninteractive interfaces and contextual data -- and
neither of them applies to OpenPGP certificates.  The key manager is an
interactive interface, and if I'm looking at certificate 0xDEADBEEF I
really don't give half a damn about 0xDECAFBAD, 0xBADD00D5, or
0xBADF00D5... so why am I getting cognitively spammed with information
about them?
Unfortunately, PGP 5.0 presented all certificates to the user in this
tabular format -- and ever since, that's what users have demanded.  It's
what they know, it's what they want, and if you seriously suggest
getting rid of a table view people will refuse to use your interface.
At the end of the HCI course I had a prototype key manager that avoided
the table widget and ruthlessly suppressed useless data.  It consisted
of pretty much just a search box into which you could type an email
address, a certificate ID, a user name, a comment, whatever.  Once you'd
narrowed your certificates under a dozen, a list would pop up showing a
certificate ID, the best-matching user ID on the certificate, and its
trust level.  Double-click on an element in the list and bang, a
certificate editor appeared, with helpful wizards to walk you through
the process of validating a key, uploading it to a key server, etc., etc.
Ultimately it was just a prototype: it was never a fully functional
certificate manager.  Two things convinced me to let this project die
and not pursue it further.  One was there was a strange problem
involving GnuPG refusing to communicate via a pipe with Java.  The
problem strongly appeared to be in GnuPG.  Ultimately, that's a minor
The real downer came when I showed long-time GnuPG users this interface.
 Opinions ran about five to one, "hey, this is a really sweet interface,
and I like it -- but it'd be even better if there was a big table widget
with all my certificates there.  I'd use that instead.  I'm familiar
with that user interface!"
... I should point out, BTW, that although being told "don't make a
better interface, make it just like the interfaces we know" is a downer,
I'm not faulting people one bit for it.  People have invested a lot of
time and effort in learning these bad, broken, user-hostile interfaces.
 It is *absolutely* reasonable for them to want to use an interface they
know, rather than learn yet another interface -- even if I'm immodest
enough to claim these new interfaces would be vastly better.  :)

@_date: 2010-10-07 15:25:37
@_author: Robert J. Hansen 
@_subject: What's the best way to test a long list of passphrases? 
At one per second, it'll take about nine hours.  Your fastest solution
involves spend the rest of today polishing the script, and letting it
run overnight.  Slow and stupid wins.
The smart and fast way involves doing the s2k computations yourself and
checking prospective keys one after another, but even then this will be
slow.  The s2k computation involves a lot of iterated hashing in order
to slow down brute force attempts like this.  You'll waste more time
writing code than you'll gain by a faster algorithm.
Basically, if you do things the slow and stupid way you'll be done by
morning.  If you do things the smart and fast way you might be finished
by the end of the week.  You can view this as an instance of "worse is
Good luck!

@_date: 2010-10-07 20:02:02
@_author: Robert J. Hansen 
@_subject: What's the best way to test a long list of passphrases? 
Given the amount of time required to write a multithreaded application
that intelligently divides up work units across cores, versus the eight
hours for a single-threaded, single-cored version...
There's an old rule of thumb about not using more hammer than you need
for a given nail.  Tacks get tackhammers and railroad spikes get
sledgehammers, but it's foolish to drive tacks with sledges or spikes
with tackhammers.
This is a tack problem.  Use a tackhammer.

@_date: 2010-10-11 10:32:21
@_author: Robert J. Hansen 
@_subject: Seahorse 
This is one of the things we were specifically warned against in HCI.
Give people two interfaces and the new interface will never supplant the
old.  When new users encounter problems and ask for help, the first
thing the old-timer will do is say, "well, first, go back to the old
interface, that's the one I know the best."  The newcomer will do so and
won't switch back afterwards, both out of a spirit of "all the experts
use the old interface" and "nobody can help me with this new interface,
so I'd better use the old."
If you want people to use a new interface, you have to start by getting
rid of the old... and the PGP 5.0-style UI is simply never going to be
gotten rid of.
Kind of sad, really.

@_date: 2010-10-11 22:20:39
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
The most obvious way I see to circumvent this involves throwing a
trampoline on the UI library and bypassing this code entirely. It's a
two-hour hack, assuming you already have root access to the system.  It
might make users *feel* more secure, but it doesn't actually help
overall system security -- IMO, at least.  YMMV.

@_date: 2010-10-12 00:34:48
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
This attack mode appears to me to be so niche that I don't see any point
in defending against it.  If my attack gives me local access I'm going
to shoot for remote.  If my attack gives me unprivileged access I'm
going to escalate it to root.  This is straight out of the malware
playbook, and malware authors have a great many ways to achieve it.
Heck, this doesn't even defend against an *unprivileged* attack.  Give
me unprivileged access to your user account I'll edit your .profile to
put a .malware/ subdirectory on your PATH and drop my trojaned GnuPG in
there.  Once the malware executes, delete the hidden subdirectory,
restore your original PATH, and send the passphrase it intercepted off
towards my C4I server.
And if we're assuming I've instead subverted an unprivileged non-user
account (like a jailed service), then this "attack" is a nonissue, so
why are we trying to solve it?
This seems like an niche solution to a problem which, as of right now,
is nonexistent.

@_date: 2010-10-12 09:25:50
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
These two attack modes (root and user access) cover the overwhelming
majority of instances today, so already this hypothetical attack is an
exotic.  On top of that, your imagined situation seems to involve a
compromised machine communicating with a trusted server over a socket.
If the trusted server sends back a confirmation request, what's to keep
the malware from simply saying, "OK," in response to these requests?
Please do not mistake this for snark.  It's not.  I'm using an absurd
position here to try and make my objections clear, not because I'm
trying to denigrate your views.
That said: "People will also not use GnuPG as a personal flotation
device in the event of a water landing if GnuPG does not float."
GnuPG is not a personal flotation device and, unsurprisingly, doesn't
have any features related to that.  This said, if users want GnuPG to
offer pontoon functionality in 2.2 they are certainly welcome to make
their opinions known.  If more than a dozen people say, "yes, I need
GnuPG to serve as a personal flotation device," I will happily get out
of the way and encourage it to be added.
But to talk about how the people need personal flotation support in
GnuPG, without actually hearing from users who genuinely need it... I
might have great respect for the speakers and might even agree with
their opinions: but in the absence of user demand, I wouldn't think we
should do it.

@_date: 2010-10-14 00:54:25
@_author: Robert J. Hansen 
@_subject: Paranoid People's User Group? 
Welcome to the community!  As a minor cultural note, PGP is a
proprietary software product put out by PGP Corporation.  GnuPG is a
compatible product available under a free/open-source license.  The two
software products each conform to what is called the OpenPGP Standard
If you're interested in PGP in particular, I'd suggest the PGP Forums or
PGP-Basics over at Yahoo! Groups.  For GnuPG and/or OpenPGP, though,
you're definitely in the right place.  :)
Quite the opposite!  It gives you an enormous advantage.  People who
have high-value secrets have to make very conservative choices about
what they do and how they do it.  If you don't have anything that
absolutely must remain secret, that gives you the freedom to experiment
and do crazy things and learn from what happens, without needing to
worry about your secrets getting published in the _New York Times_.
PGPNET.  They're a rather welcoming group, all told.

@_date: 2010-10-15 13:42:05
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
I seem to recall saying something similar to this a few days ago.  :)
I'll go one step further: so far I haven't seen anyone present a
plausible intersection.  I've seen some hypothetical intersections, but
none that I think are plausible.
This seems like a nonsolution to a nonproblem.

@_date: 2010-10-15 15:36:51
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
This can still happen with a confirmation prompt.  Confirmation cannot
protect against malware running under your account.  If the agent pops
up a dialog box, then all I have to do is intercept the dialog box and
answer 'yes.'

@_date: 2010-10-15 18:23:04
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
Which means that six months after this feature gets implemented, the malware authors will write exploits that intercept the dialog box.
Arms races are inevitable, but stupid arms races should be avoided.
I'm not.  This idea isn't good.

@_date: 2010-10-15 19:12:21
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
This seems to be an argument from implication of hypocrisy: as if, were I a user of ssh-agent, my opinion regarding gpg-agent could be safely dismissed on the grounds of my hypocrisy by not bringing the same issues up to the ssh-agent authors.
The answer to your questions are, "no, I do not," "I have not looked at it enough to have an informed opinion," and "I reject out of hand all argument by implication of hypocrisy."

@_date: 2010-10-15 19:14:20
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
It does not.  It states that at present the OS infrastructure we have makes implementing this a losing proposition.
As soon as the OS infrastructure changes enough to make this a winner, then we should revisit this decision.

@_date: 2010-10-15 19:39:26
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
Then that's the user's own problem.  They're the one who decided to enable passphrase caching and to set a large timeout window.  They get to make their decisions, and it's foolish of us to try to protect them from it.
In fact, I would argue this "feature" would cause more problems than it claims to solve.  The number of people who would benefit from it is relatively small.  The number of people who discover their automated scripts no longer work would be large.
No choice comes without consequences.  This feature enhancement is no exception.

@_date: 2010-10-17 22:47:24
@_author: Robert J. Hansen 
@_subject: Confirmation for cached passphrases useful? 
If a feeling of security comes as the result of *real security*, this is good.
If a feeling of security comes as the result of *no improvement in your situation*, this is bad.
By this logic every user should have a big piece of Scotch tape on the center of his or her screen.  If the piece of tape is ever missing, then you know someone's been tampering with your machine.

@_date: 2010-10-26 23:19:14
@_author: Robert J. Hansen 
@_subject: Seahorse 
Conjecture is nice.  Evidence is better.  Put together a study testing
the continued validity of the hypothesis.  If it turns out the
hypothesis is false, I and many others will certainly sit up and pay
As for me, though -- I have enough on my plate without taking on this
task.  I'm going to believe the question is settled, on the basis of
existing evidence, until such time as new contradicting evidence is

@_date: 2010-09-24 09:44:01
@_author: Robert J. Hansen 
@_subject: multiple keys vs multiple identities 
Like most things in life, the answer is, "it depends."  There are some
use cases where multiple certificates make sense, and some use cases
where multiple identities make sense.
Generally speaking, more often than not multiple identities is the right
way to go.
Stick with the defaults unless you have a compelling reason not to.

@_date: 2011-03-31 20:41:41
@_author: Robert J. Hansen 
@_subject: Hi 
Let's be a little careful about our language.  Thanks.  :)

@_date: 2011-04-01 09:01:03
@_author: Robert J. Hansen 
@_subject: Hi 
If it bothers you that Microsoft's corporate name gets turned into puerile jokes, it seems the way to counter that is to correct people when they do it.  Otherwise you're just raising the stakes of childishness.  Other people who come along will see your comments and feel there's nothing wrong with slinging some mud at their own personal subject of distaste, and the next thing you know we're all back in the monkey house flinging poo at each other.
I had a miserable time in high school.  I left that behind me almost twenty years ago: I have no desire to see us revert back to that level of thinking.

@_date: 2011-04-02 13:25:43
@_author: Robert J. Hansen 
@_subject: Deniability 
The difference between TrueCrypt and 7-Zip is that no one ever claimed
7-Zip is security software, and no one seriously advocates using 7-Zip
in regimes where there are secret police who see nothing wrong with
torture.  I suspect if you were to ask the 7-Zip folks, they would
(quite reasonably) say, "we don't know anything about that, we're just
trying to write a high quality data compressor."
My general rule of thumb is that the secret police might be monsters,
but they will be *reasonable* monsters.  Not reasonable because they
believe in human rights or anything like that -- reasonable because they
want to succeed and believe reason is a good way to get it.
If you're in the hands of total authority and total capriciousness, then
yes, you're absolutely hosed and there's nothing you or anyone can do
about it.  There's no point in even trying to defend against it because
once you're there the fact you like orchids can be seen as evidence
you're an enemy of the state.
But if the secret police are reasonable monsters, they have an incentive
to behave in certain ways, and a disincentive to behave in others.  In
the case of you getting an email by accident, you could tell the secret
police, "I have no idea what this is about, I've never talked to this
person before in my life!" -- and, after some investigation, the secret
police would probably let you go.
In a repressive regime, there are *always* more potential enemies of the
state than there are trusted agents to ferret out these plots.  They
have to use their limited manpower in a way that best serves the end of
the State.
The real risk is not that you will come to the attention of the secret
police by some random accident.  The real risk is you will come to their
attention by doing something *you had no idea was a crime*... which is a
much more serious thing.

@_date: 2011-04-03 12:31:25
@_author: Robert J. Hansen 
@_subject: Deniability 
I don't see what this has to do with anything, but assuming for the moment you're serious:
In most Western nations ignorance cannot excuse you from the burden of conforming with the law, but it can be used to excuse you from being punished.  The term is /mens rea/, or (loosely translated) "criminal intent."  If you don't have the active intent to do something you know is wrong, then it's pretty hard to get a conviction for doing it.
When I was in Mexico a couple of months ago, I got put up against the wall, searched, my bag searched, and my camera searched, because a police officer thought I took a photograph of a bank.  (I didn't.)  Now, I don't know much about the Mexican system of justice, but I think that even if I had photographed a bank, no Mexican judge would've put me in jail over it: the judge would've let me go with a stern warning.  I clearly had no intent to break the law, therefore it's impermissible to put me in jail.
If I was in the People's Republic of Berzerkistan and a cop sees me take a photograph of a bank, then it literally *does not matter* that I had no idea it was a crime: I'm still going to do ten to fifteen years in a Berzerkistani prison camp for it.  I can't rely on any sort of leeway from the judge (or, for that matter, getting to see a judge at all!).
This is what I mean when I say the real risk in an authoritarian regime is that you will come to the secret police's attention by doing something you had no idea was a crime.

@_date: 2011-04-08 11:23:16
@_author: Robert J. Hansen 
@_subject: keys not available for signed messages in this maillist 
"Should" is maybe the wrong word to use.  I've never seen "should" mean
anything other than, "I want" or "I expect."  The universe doesn't much
care about what we want or expect, though.  Justice should prevail and
the sun should rise in the east: but I don't think for a second either
of those "shoulds" means much.  :)
Still, let's try this instead: "why are so many certificates not
available on the keyserver network?"
One answer is, the certificate owners might not want their certificates
on the keyserver network.  Some people much prefer to give their
certificates via biglumber, or person to person, or... etc.
We may agree or disagree with their reasons, but the decision is theirs
to make: we just have to respect it.  :)

@_date: 2011-04-08 12:51:43
@_author: Robert J. Hansen 
@_subject: keys not available for signed messages in this maillist 
SHOULD and MUST do.  They're presented in all-caps in RFCs to make sure
people know they're being used in a formal context as opposed to a
conversational English context.
If you want to say certificates SHOULD be uploaded to keyservers, we can
have a good, healthy debate on that subject.  If you want to say
certificates should be uploaded to keyservers, my response to that is I
should have a pony, too.

@_date: 2011-04-09 10:30:38
@_author: Robert J. Hansen 
@_subject: Signing a key (meaning) 
As a minor nit -- the protocol you've outlined is a good one, is
commonly used, and is highly recommended -- but it is not the only one,
and special use cases may involve their own different protocol.
There is more than one way to skin this cat.  :)

@_date: 2011-04-16 23:02:24
@_author: Robert J. Hansen 
@_subject: [OT] passphrases Was: Re: Allowing paste into pinentry-gtk-2? 
The best numbers I've seen regarding passphrase entropy suggest that plain English text has in the neighborhood of 1.5 to 2.5 bits of entropy per glyph.  Just FYI.  You can find these numbers in Shannon's original works on entropy, among other places.

@_date: 2011-04-17 15:32:58
@_author: Robert J. Hansen 
@_subject: [OT] passphrases Was: Re: Allowing paste into pinentry-gtk-2? 
English has about two bits of entropy per glyph, so a ten-character English passphrase will have about twenty bits of entropy regardless of what algorithm you use to hash it.  You can't make an insecure passphrase suddenly 256 bits of entropy strong by using SHA-256.  :)

@_date: 2011-04-17 18:58:13
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
I am giving a great big yuk to his methodology.  There's no reference to the entropy of text, for instance.  His example of a three common word password, "this is fun," amounts to a total of 11 letters: this will be around 22 bits of entropy, or 4 million combinations.  @ 100 attempts per second, that requires 40,000 seconds, or about 11 hours.  He claims it'll take 2,357 years.  Let's just say I'm skeptical.
Also, look at his claims for a six-character "common word."  Okay, so this has at most 10 bits of entropy or so: any more and it wouldn't be common.  10 bits of entropy equals 1000 possibilities, @ 100 per second equals ten seconds to break it -- not the 3 minutes he claims.
His math doesn't work.  I call shenanigans on the entire thing.

@_date: 2011-04-17 19:40:56
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
Yeah, more or less.
Elsewhere on his site he says that if you can't use spaces in a password, you should use dashes rather than just concatenate letters together: "this-is-fun" as opposed to "thisisfun."  He's quite adamant this is necessary for the security of your password.  Unfortunately, it just isn't so: if I'm running a Markov chainer to generate possible plaintext passwords, what symbol(s) I use as interword marker(s) is(are) completely arbitrary: it doesn't significantly affect the time to generate text.
So, yeah, like I said: I give a big yuk to his methodology.

@_date: 2011-04-17 20:15:12
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
The idea of "use several words in a combination that's only meaningful and predictable to you" is a good one.  That's not in debate.  The idea of "this is fun" being a passphrase that will require 2,500 years of attacks to break is just absolute balderdash.
Can't be answered.  In what kind of a system?  What kind of technology can the attacker employ?  Does the attacker have any knowledge about what the key material is probably like ("cribs", in cryptanalytic jargon)?  What kind of budget?  What's the attacker's skill level?  What's... etc.
If we assume the attacker knows you're using English or something close to it, then I'm going to estimate it at about 2.5 bits of entropy per glyph, or about a billion combinations for a 20-character passphrase.  This is enough to stymie a high school student who's running a brute-forcer he wrote in pure Python running on a single terminal in his high school computer lab, but it's literally seconds of work for a major corporation that can easily throw a thousand terminals running hand-tuned Assembly brute-forcers at it.

@_date: 2011-04-17 23:42:22
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
Depending on who you refer to, English words have between 1.5 and 2.5 bits of entropy per glyph.  There are a ton of different credible resources, all of which have different answers: Wikipedia says that it's between 0.6 and 1.5 bits per glyph.  Assuming 2.0 bits per glyph is optimistic, but it's within the realm of possibility.
An 11-character password has 22 bits of entropy, or about four million possibilities.  Four million divided by one hundred attempts per second (the number this guy claimed was reasonable for login attempts per second to a web service) equals 40,000 seconds, or just over 11 hours.
With that, you can do the math yourself to make your own back of the envelope calculations.  Don't trust my math: trust your own math.  :)
And, like I told you, without a lot of context this question literally cannot be answered.

@_date: 2011-04-18 12:11:24
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
I know lots of people who have memorized their 23-digit credit card +
expiration date + security code.  A Base-64 encoding of a 128-bit hash
algorithm is 22 characters long.
Strong passphrases are well within the realm of human feasibility.  They
just require a level of work most people are not willing to give.  But
if you need a 128-bit passphrase, you can do it: it will just take a few
hours of drill and memorization repeated over a few days.
Really, what it boils down to is this: there are no shortcuts to making
high-entropy easily-human-memorizable passphrases.  Sooner or later,
you've got to pay the piper...
Not only this, but it also produces an ideal environment for attackers.
 It sets the security administrators up as the enemy of the people who
are actually doing the work -- which means that the people "in the
trenches," so to speak, will develop an us-versus-them culture in which
the security mechanisms are deliberately subverted just in order to get
work done.  In that environment, a malicious attacker who comes in and
begins subverting mechanisms looks no different than an authorized user
who is executing a legitimate task -- and the attacker will likely be
able to deceive authorized users into helping the skulduggery ("hey, can
I borrow your login and password, the damn system's rejecting mine

@_date: 2011-04-18 14:29:40
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
YMMV, but to me a glyph is a glyph is a glyph.
The date is usually encoded as four digits.  On mine, for instance, it
reads 0112.  A 16-digit number, a four-digit number and a three-digit
number turns into a 23-digit number.  I personally chunk it into five
groups of four and one group of three.
c2l4 IHdv cmRz IGxv bmcu Cg==, as six chunks of four, took me about
fifteen minutes spread out over ninety minutes to memorize.  However, it
is not beyond the realm of possibility that I am a freak of nature.  :)

@_date: 2011-04-18 18:56:46
@_author: Robert J. Hansen 
@_subject: [OT] passphrases Was: Re: Allowing paste into pinentry-gtk-2? 
As I've said a few times now, no question about "is X really sufficient to protect a passphrase from being broken?" can be answered without a lot of context.  Who are you worried about breaking it?  How hard will they try?
To give you an example, RC5-64 was a giant distributed network of computers run by hobbyists using spare CPU cycles, trying to brute-force a 64-bit key.  Their volunteer network was much larger than anyone outside of megacorporations or First World intelligence agencies or major crime syndicates have.
It took them eighteen months.
64-bit crypto isn't good for long-term storage, but if you want to foil someone who doesn't have megacorporation-level resources for a period of months or years, it'll do just fine.  Against First World intelligence agencies it might take a few seconds.

@_date: 2011-04-18 23:15:26
@_author: Robert J. Hansen 
@_subject: [OT] passphrases Was: Re: Allowing paste into pinentry-gtk-2? 
First, thanks for the correction on the RC5-64 project.
Short answer: no, I am not asserting a group exists that can brute-force a 64-bit key in a few seconds.  I am asserting that it's plausible such a group might exist, and if so it is probably a First World intelligence agency.
The EFF's DES cracker ("Deep Crack"), built in 1998 using now 13-year-old technology, exhausts a 56-bit keyspace in nine days at a cost of $250,000.  A 64-bit keyspace is only a factor of 250 harder, and brute-forcing is parallelizable.  Set up 250 Deep Crack-style machines in parallel and you're out $60 million, plus building space and personnel... call it $100 million total.  Scale this machine up to $1 billion and you're looking at some pretty quick keyspace exhaustion.  Megacorporations will probably not be willing to drop that kind of coin on dedicated key crackers, but if bin Laden's current GPS coordinates were protected by RC5/64 you'd see Fort Meade's chip fab line working round-the-clock shifts.

@_date: 2011-04-19 01:07:21
@_author: Robert J. Hansen 
@_subject: [OT] passphrases Was: Re: Allowing paste into pinentry-gtk-2? 
Tactical communications are at essentially zero risk for brute-forcing or cryptanalysis unless the key is ridiculously small or the cipher ridiculously simple.  By their very nature, tactical communications involve very short periods of time: "attack the beach at dawn" is a message that only needs to be secure until dawn.  By the time you break the crypto the traffic is no longer of value to you.
Strategic communications are at huge risk for brute-forcing.  "If you agree to sell us oil at $4 below market rate for the next 30 years, we will look the other way as you annex Berzerkistan" is the kind of communication that needs to be kept secret for decades.  That means all different kinds of cryptanalysis and brute force become feasible.

@_date: 2011-04-19 09:54:24
@_author: Robert J. Hansen 
@_subject: [OT] passphrases Was: Re: Allowing paste into pinentry-gtk-2? 
If there exists a difference, I'm unaware of it.
And that's exactly what we want to do when we break a passphrase: recover the plaintext of the (encrypted) private-key material by trying all possible decryption keys within the keyspace of the symmetric key which encrypts it.  The passphrase generates the session key.
I emphatically disagree.

@_date: 2011-04-19 21:53:54
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
Gibson's reputation in this area is mixed.  That doesn't mean what he says is wrong, but I'd suggest listening with skeptical ears -- which, you know, you really ought to be doing with everyone on the internet anyway.  :)

@_date: 2011-04-21 08:38:38
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
Historically speaking, this has shown not to work.  I'll try to dig up the HCI references if people really want, but the gist of it is people don't want to have to learn and understand: they just want to get their work done.  The instant you make compliance voluntary and education-based, the vast majority of users say "meh" and choose "password" as their login credential.
The belief that security problems can be solved by educating users is a common one: it is also a deluded one.  It handwaves the very serious problem of most users not wanting to be educated and being actively hostile to it.  "Why do I have to learn all this propellerheaded geek stuff?  I just want to get my work done!"

@_date: 2011-04-21 14:57:17
@_author: Robert J. Hansen 
@_subject: backend found 
Don't panic.  :)  This is not a defect in GnuPG, but rather an infection
by a piece of malware.
Hopefully you'll be able to deal with the malware quickly and
effectively.  Good luck!

@_date: 2011-04-22 14:17:45
@_author: Robert J. Hansen 
@_subject: A better way to think about passwords 
Let's have a thought experiment: your particular situation is such that
you want attackers to face at least a 9-bit keyspace, but you also want
to disqualify easy, commonly-used keys.
Answer: tell users their passwords must be any number between 0 and 999
inclusive, except that it can't be in the range 0-9, or be any two- or
three-character repeating password (no 11, no 222, no 33, but 331 is
fine).  This is meant to keep people from choosing weak passwords.  This
has the net effect of striking 10 (0-9) + 9 (11+22+33... etc.: note that
00 is already struck under the "no 0-9" rule) + 9 (111+222+333... etc.)
= 28 possibilities.
You've reduced the original 9.97-bit keyspace to 9.92 bits, which still
exceeds your requirements.  At the same time, you're preventing users
from choosing trivially weak and easily guessable passwords.
Your observation is correct only if excluding certain passphrases causes
the entropy of the keyspace to drop below your requirements.  Otherwise,
there's no problem with strategy enforcement.

@_date: 2011-04-27 09:10:22
@_author: Robert J. Hansen 
@_subject: Keylogers 
In fact, it's quite a bit worse than that.  Your traffic is secure only so long as both endpoints are secure.  Depending on who does the numbers, 15%-30% of all desktops are pwn3d.  Even if your desktop is safe, the odds aren't good the other end will be, too.
There are many reasons why I feel OpenPGP is more or less irrelevant in the world today, outside of some very special case scenarios.  This is one of the big ones: OpenPGP's necessary precondition -- that our endpoints are both securable and secured -- is not met.

@_date: 2011-04-27 09:48:00
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still useful? 
(The subject line may be provocative, but please don't think I'm arguing that it's not useful.  I don't know.  I just had an idea a couple of days ago, and I figure it might be worth some discussion.)
OpenPGP takes its origins from ClassicPGP, which in turn comes out of a military threat model of the sort that was more or less standard policy everywhere from WW2 forwards:
Attackers can apply significant resources to interception, and they already know who they want to intercept
Communication technicians are trained, skilled and motivated
Communication channels are centrally defined and structured
Communiqu?s must be secure for decades or more
There are other elements, but these four are what interest me right now.  OpenPGP defends quite neatly against point one, point two explains why it's okay for OpenPGP to have a learning curve like the Matterhorn, the Web of Trust (which is to say, a loose confederation of CAs) follows from point three, and long-term security is point four.
Now, while there are still environments in which those four criteria hold, the modern day seems to mostly be governed by four different principles:
Attackers need distinguishment more than interception
Defenders are unskilled and perhaps incompetent
Communication channels are ephemeral, media-hopping and ad hoc
Most people don't care if an individual email ? or even a series of them ? gets compromised
"Distinguishment versus interception" may need some explanation.  Intercepting communications is not very hard: finding what communications need to be intercepted is a labor of Hercules.  We are, figuratively speaking, drowning in a sea of irrelevant and useless data.  The major task is not being able to read the information, but being able to pick signal out from noise.  Distinguishment ? differentiating signal from noise ? is more important than interception ? picking up the signal once you know what it is.
With respect to communication channels being ephemeral, media-hopping and ad hoc: today it's not unusual for a conversation to begin in SMS, hop to Facebook, migrate to email, and finish on IM.  Whatever tool we use to secure our messages needs to be as media-agile as our conversations.
And finally, most people simply don't care if their emails get read.  Open a stand outside a McDonald's offering "FREE BIG MAC AND FRIES FOR YOUR EMAIL SERVER PASSWORD" and see how many coupons you give away.  Odds are good that the loudest voices of outrage would come from Burger King and Wendy's, and they'd shut up once you set up booths outside their restaurants, too.[*]
... So, finally, here's my Modest Proposal.  Encrypt each communication (Facebook post, SMS, whatever) with a random 40-bit key.  Throw the key away.  Send it.  The only way for your recipient to recover the key is to brute-force the message.  By our existing standards this would be absolutely crazy: and yet, it would foil large-scale Hoovering of email messages (adding that work factor to each email message would make large-scale analysis difficult), would address point 2 by getting rid of the learning factor ("install this plugin and that's all you have to do"), would address point 3 by being broadly applicable over a large swath of the problem domain, and if someone recovers a particular message anyway... well, as point 4 shows us, "meh."
(Note: if the phrase "Modest Proposal" wasn't enough of a giveaway, this is not a serious proposal.  It's a thought experiment, just something I found to be interesting enough to spend a few minutes contemplating.)
[*] Some years ago while teaching a computer literacy class, I had the undergrads reading David Brin's "The Transparent Society."  In it, Brin suggests offering a free Big Mac with a mouth swab and driver's license, and plugging these DNA samples into a database of unsolved crimes.  He cheerfully argues there are no privacy concerns since it is so obviously a bad idea, and yet people will voluntarily choose to do it anyway despite knowing it's stupid.  The class had a good talk about this.  The next Monday a couple of students talked to me after class.  "After class last week, we went down to the Pita Pit.  We were sitting around talking about how stupid Brin's idea was and how he was wrong and nobody would be that stupid ... and then we realized we were saying this while we were filling out credit-card applications in order to get a free pita."  When I asked them what they did next, they shrugged.  "We felt kind of stupid.  But we filled them out, got our free pita, and started talking about something else."
You can lead a horse to water, and you can even give the horse a straw, but...

@_date: 2011-04-27 09:41:26
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still =?UTF-8?Q?useful=3F?= 
Yes.  E.g., OpenPGP messages cannot be reduced to fit in an SMS message:
you'd need to break them apart multiple SMS messages.  Different media have
different technical requirements.
Strongly disagree.  Figuring out the difference between signal and noise
seems to be highly nontrivial.
No.  Encryption -- even weak encryption -- is not pervasive.  It's my
position that pervasive weak encryption would make large-scale data
analysis difficult (further hammering the differentiation issue and making
a hard problem harder), while impacting regular users only slightly.
My problem with HTTPS, SMTPS, etc., is they typically have scalability
problems.  Asymmetric crypto is CPU intensive.  I'd like to see, e.g.,
HTTPS for commerce, but if I visit Slashdot go to a weaker system that's
not CPU-intensive but would still make mass surveillance problematic.
Yes, absolutely.

@_date: 2011-04-27 09:43:43
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still =?UTF-8?Q?useful=3F?= 
Sure.  Consider it CC BY-ND.  Repost how you like, commercial use OK.  :)

@_date: 2011-04-27 10:55:16
@_author: Robert J. Hansen 
@_subject: Keylogers 
On Wed, 27 Apr 2011 12:56:19 -0400, Mike Acker Already exists: a copy of md5deep and the forensics signature database
will do it for you.
Unfortunately, as people have learned, this technique doesn't actually
work -- at least, not reliably.  False positives abound all over the place.
The problem is the signature db: it simply cannot work the way people
think it should.  Some system patches use data from the host system as part
of the patch.  (As an example, your processor ID might be used as a unique
identifier somewhere within the code.)  This means the updated executables
will not have a reproducible hash: each machine will report a slightly
different one.
You can get around this somewhat with fuzzy hashing, but in the main this
is an unresolved problem in computer forensics.  You can easily tell when a
file is known-good, but just because a file isn't on the known-good list
doesn't mean it's bad -- and telling the bad apart from the good is a
Herculean task.
My next door neighbor (okay, so he lives a block away) is pretty big in
the digital forensics community: if you like, I'd be happy to ask him about
the latest research in this the next time we go out for beers (probably
Monday, to celebrate his Sunday marathon).

@_date: 2011-04-28 08:49:30
@_author: Robert J. Hansen 
@_subject: No, it is not. 
I doubt this.  For instance, my communications with my priest,
stockbroker, doctor and lawyer all require the communications to be
secret, but our identities and relationships are public.
Likewise, if I were married I would have a serious need for privacy in
my communications with my wife: but my wife's identity would be part of
the public record.
Likewise, when I place an order from Amazon I only want my credit card
number to be secured.  I really don't care if someone knows that I'm
buying from them: they could discover that just from getting access to
my credit card purchase history anyway.
The list goes on and on.  I doubt that most people who need
confidentiality in their communications also need confidentiality in
with whom they are communicating.

@_date: 2011-04-28 09:23:32
@_author: Robert J. Hansen 
@_subject: No, it is not. 
It's not?  (My apologies to him if it's not.)
I understood what he said as, "for most individuals who need to protect
their communication, keeping secret the identities of correspondents is
as important as keeping secret the correspondence itself."
I understand that point of view.  I just think it's bogus.

@_date: 2011-04-28 10:22:09
@_author: Robert J. Hansen 
@_subject: No, it is not. 
Err -- yes.  Even if I'm having an affair, my wife's identity is part of
the public record.  Even if I'm having an affair I need confidentiality
of communications with my wife, but not confidentiality of my wife's
(ObReminder: the preceding is a hypothetical.  I am neither married nor
having an affair.)
The point being discussed is whether most people who need
confidentiality in their messages also need confidentiality in the
identities of their correspondents.  I believe the evidence is lacking
for this claim.  There are certainly instances in which confidentiality
of identity is important, but I never claimed otherwise: only that it
seems dubious to me that *most* people who need confidentiality of
messages also need confidentiality of identity.

@_date: 2011-04-28 13:29:28
@_author: Robert J. Hansen 
@_subject: nothing so dramatic 
This is at odds with my understanding of the Rules of Civil Procedure
and the Constitution.  Could I please get a cite to a case which
establishes this as being correct?
To my understanding of United States law, a subpoena can always be
refused on Fifth Amendment grounds.  If you have a reasonable fear that
divulging a document in a civil suit will expose you to criminal
charges, you *always* have the right to refuse on the grounds of
self-incrimination, and that refusal may not be used against you in any way.
IANAL: my only credential here is growing up around a federal judge who
heard an awful lot of subpoenas and challenges to them.

@_date: 2011-04-29 09:12:43
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still useful? 
The barrier to usage is still high with OTR: users still have to
authenticate, and you can get horrible sync issues.  Plus, let's not
forget the wacky hijinks that occur if you're logged into IM from two
places at once -- although this is explicitly supported by some IM
protocols (Jabber), with OTR it causes no end of troubles.
The thought experiment here -- it's not a real proposal -- is, "what
would happen if we discarded authentication entirely, and went purely
for a require-brute-force approach to discover the random session key?"

@_date: 2011-08-04 09:21:42
@_author: Robert J. Hansen 
@_subject: Extract numbers from a key 
The PRIMES algorithm can be expressed in Mathematica, and provides an
exhaustive check.  Mathematica's built-in tools don't provide PRIMES,
but it can be added by a modestly proficient Mathematica user.

@_date: 2011-08-04 10:51:45
@_author: Robert J. Hansen 
@_subject: Extract numbers from a key 
PRIMES isn't the name of an algorithm: PRIMES is the name of a problem
in computer science.  "the PRIMES algorithm" isn't "the algorithm named
PRIMES," but "the algorithm which solves PRIMES" -- either the AKS
primality algorithm or else Miller's test.  There might be some new
additions to that list, but those are the only two fast deterministic
primality tests I know of.
I'm sorry if I was unclear.
Didn't even try: that question doesn't interest me.

@_date: 2011-08-24 00:52:33
@_author: Robert J. Hansen 
@_subject: Extract numbers from a key // wrong pgpdump link :-( 
Cygwin isn't necessary: it compiles just fine under plain MinGW.  I've
got a native Win32 version I've cross-compiled from an x64 Fedora 15 box.

@_date: 2011-08-25 09:00:51
@_author: Robert J. Hansen 
@_subject: a Question about Key Servers 
It would seem the proper place for this is to leverage existing system
automation tools, not inventing something new.
proverbs:~ rjh$ crontab -l
30  2  *  *  *  gpg --refresh-keys >/dev/null 2&>1
You can do equivalent things on Windows with Task Scheduler.

@_date: 2011-08-25 10:04:11
@_author: Robert J. Hansen 
@_subject: a Question about Key Servers 
Define 'large keyring', please: I mean no offense, but that's a pretty
vague word.
proverbs:~ rjh$ gpg --list-keys|grep "^pub"|wc -l
     288
proverbs:~ rjh$ time gpg --refresh-keys
[output snipped]
real	2m0.274s
user	0m40.273s
sys	0m0.972s
Now, maybe you have thousands of keys on your keyring and it takes a
ridiculous amount of time, but I suspect you're a bit of an outlier.  At
almost 300 keys I suspect I'm still well beyond the average user's
use-case.  (Note these are suspicions: I haven't polled users.)
The problem for any system of automated certificate refreshment is
making it general enough to accommodate power users with thousands of
certificates, and yet simple enough for the 95% of users who have
X-or-fewer certificates (where I suspect X < 50).  That's a very
difficult problem and I'm happy for GnuPG to kick this one to the users
and say "refreshing the keyrings is your problem."
Alternately, it might be a good thing to add certificate refreshment
into GPGME.  That way GnuPG, instead of forcing a One True Way on the
end users, could make it possible for other people to write their own
certificate refreshment utilities, with whatever policies and actions
they want.
Absent hooks in GPGME, I don't think there's much opportunity for third
parties to write certificate refreshers.  Doing so would require support
from GnuPG (adding a "last refreshed field" to each certificate on the
keyring) and some way to parse the GnuPG keyring independently of
GnuPG/GPGME, which is ... problematic.

@_date: 2011-08-25 11:22:41
@_author: Robert J. Hansen 
@_subject: a Question about Key Servers 
Now that you mention it, I'd like to reject the premise outright: that
this is a problem.  How do we know it's a problem?  I don't doubt that
for some people it's a serious problem, but does the average user have a
problem with certificates that need refreshing?
I'm willing to stipulate that it is good that certificates be
periodically refreshed, but I'm unconvinced we need much in the way of
customization here.  It would be fairly simple for GnuPG to keep a
"last-refreshed" file in the ~/.gnupg dir, and upon invocation check to
see if more than 30 days had passed since refreshing.  Pop up a small
dialog box (ala pinentry) and say, hey, it's been six months since we've
refreshed your certificates, would you like to do this now? (or click
here to disable reminders).
Even if it's computationally intensive and takes an hour to run, a
process that runs in the background once every six months isn't all that
onerous.  In fact, by moving to just checking a file's touchdate, it
makes it possible for third parties to write solutions without relying
on GnuPG at all.
So, yeah -- I don't really see the problem, nor why this needs to be
solved within GnuPG.  It appears to me (at my current levels of
ignorance and prejudice) that it's possible to hit the 95% usecase
without very much effort at all.  Given the choice of hitting the 99.9%
usecase, or hitting the 95% usecase with only a tenth the effort, I
think the latter is the way to go.
Heck, if people want I'd be happy to take a stab at writing a Windows
service to do this.
I have.  I'm unconvinced.

@_date: 2011-12-21 10:00:39
@_author: Robert J. Hansen 
@_subject: Holidays 
Christmas is upon us.  This is traditionally a time for family, charity,
giving and thankfulness.  For myself, I'm thankful for GnuPG and all the
work that Werner and others have put into it -- as are many of us.
Let's remember them this holiday season and put out a big round of
"thank you"s.
Further: in recent years I've encouraged people to donate to the
Electronic Frontier Foundation, the Free Software Foundation, or other
similar electronic charities, since there was no effective way to donate
to GnuPG directly.  Thankfully, this is no longer the case.  If you have
a PayPal account you can contribute directly towards GnuPG development
by visiting GnuPG's "Donations" page, at:
So far, GnuPG has received sixteen donations this year totaling 358
euros.  Frankly, that amount seems way too low to me.  Let's see if we
can't increase those numbers.  :)
This holiday season, let's all remember -- it's far more blessed to give
than to receive!

@_date: 2011-12-28 07:45:14
@_author: Robert J. Hansen 
@_subject: Short ID Collision 
There is no problem.  We've known for quite a long time that short key
ID collisions are possible: that's why you can't rely on a short key ID
as a fingerprint.
There's room for some healthy debate on whether GnuPG should be sending
full fingerprints to query for keys, but honestly, calling this a
"problem" is really overstating things.  There's some behavior that some
users find less than optimal, but that's not the same as saying there's
a bug in GnuPG that can cause crashes, reveal your data, or anything
else like that.

@_date: 2011-12-29 10:19:49
@_author: Robert J. Hansen 
@_subject: How to sign my own public key? 
Per spec, it must be.  GnuPG enforces this.  However, it's possible to
find some (likely deliberately mangled) certificates that are missing

@_date: 2011-02-03 09:56:28
@_author: Robert J. Hansen 
@_subject: Add/remove recipient without re-encrypting 
Technically, yes, although you would need to write the tool yourself.
GnuPG does not have this functionality.

@_date: 2011-02-03 14:21:13
@_author: Robert J. Hansen 
@_subject: Is commerical PGP.com compatible with Gnupg ??? 
Generally, yes.  PGP holds a patent on the Additional Decryption Key
functionality (which GnuPG developers have said will not be implemented
in GnuPG, even if it weren't patented), though, so that's an example of
one of the minor incompatibilities between the two.
I am unaware of any certified laboratory which has declared GnuPG
conformant to any FIPS.

@_date: 2011-02-03 16:07:40
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
Whenever people talk about what "most users" need, I have to ask to see
the user survey that's showing this.  History has shown that technically
sophisticated users' ideas of what "real users" need tends to not
correlate very tightly with what "real users" say they need.
Terse is beautiful.  I think something like
Comment (optional):
... would suffice, and would be a modest improvement on the current prompt.

@_date: 2011-02-03 17:10:58
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
I'm in a similar position to you, except this is my twentieth year of
helping people with PGP.  (I started way back in 1991, when PGP first
came out and was distributed friend-to-friend on floppy disks... five
and a quarter floppy disks.)
I have never seen anyone be baffled by the 'Comment:' prompt.  Some
people have asked, "What should I type here?", and I usually explain,
"nothing, just hit return," and they do.  Those who ask what the
"Comment" field means generally understand it very quickly.
The problem with using anecdotal evidence as opposed to surveys is
there's all different kinds of cognitive biases that go on inside the
mind of the person relating the anecdote.  With surveys, you can go back
to the original documents and say, "User  said this: what do we think
about this user's remarks?"
Ultimately, I think arguing from anecdote that "we need to change the
comment prompt" is unpersuasive.
"Just like a user ID allows you to tell people your email address and
your real name, it also lets you put a note in there in case there's
anything else you really want people to know.  You can skip this: just
hit 'return.'"
Zero.  Comments don't get certified.  All my signature means is I have
met this person face to face, have seen two forms of government
identification, have confirmed a fingerprint and exchanged an email at
that address.  There's nothing in my signature policy that addresses
comments, nothing at all.
Without a good basis, yes, I do.  If you change this prompt you will
also break a ton of scripts that expect this prompt.  Not only that, but
since key generation is a rare occurrence the breakage may occur months
or years after the change is made.  This isn't something to be done lightly.
You can't prevent people from being gratuitously foolish idiots.  Some
people think they're tremendously clever by doing things like this, and
they'll continue to do it no matter how you change the user interface.
It is unwise to Fisher-Price the interface in the hopes of preventing
fools from being clever.

@_date: 2011-02-03 17:54:39
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
This is not a clarification: this is a confusion.
Yes.  And my signature would mean exactly that: I'd seen two forms of
government ID, seen you face to face, verified fingerprints, and
confirmed your email address works.
Correct.  Because the presence of my signature means something.  The
*absence* means *nothing at all*, and you're smart enough to know that.
I am under no obligation to make any signatures, and I am free to add
whatever conditions I want to it.  Maybe I don't want to sign your
certificate because you're a redhead, and I've never been able to find
it in my heart to ever trust a ginger.[*]  Maybe I don't want to sign
your certificate because it's a Thursday.  Maybe I don't want to sign
your certificate because I've just had a bad day and I can't be
bothered.  Maybe ...
If you see a signature from me, you know what it means.  If you don't,
then you can't draw any inferences whatsoever.  Why do you want people
to draw inferences from my unwillingness to sign a certificate, when
it's plainly obvious there are no inferences to be drawn from that?
[*] Quite tongue in cheek, given that I'm a redhead myself.

@_date: 2011-02-03 18:02:56
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
This is not how either OpenPGP or GnuPG work.
Certifiers get to define what their certifications mean.  Bang, period,
end of sentence.  There are *no* certification semantics in OpenPGP:
there is only a rich and comprehensive set of syntactic primitives.
It's true that, say, a persona-level signature is different
syntactically than an I-have-done-extensive-checking signature: but
OpenPGP quite wisely says *nothing* about the level of checking which
goes into each signature level.
If you see a certification and you assume you know what the certifier
intends, then you are living in sin.  Ask the certifier what for their
policy: that's the only way to know.  Some people will make
certifications willy-nilly ("well, I've traded emails with the guy a few
times...").  Some will make certifications only very carefully.  Some
will make totally unreasonable certifications because they don't know
any better, and some will not make reasonable certifications because
they have an abundance of paranoia.  Unless you ask the certifier, *you
do not, and cannot, know*.
By certifying the full user ID, I am making a statement that is derived
from my own local certification policy.  That's all.  Nothing else.

@_date: 2011-02-03 18:32:45
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
This.  I may agree with the comment, I may disagree with it, but either
way I am not vouching for it.

@_date: 2011-02-03 19:40:04
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
Because with a comment like that, my impression would be that he was
aiming to deliberately yank my chain: and why should I put up with that?
To use that as an example, and to simultaneously lose sight of the "you
know, I'm kind of being a jerk here, and why should do me a favor by
making a certification if I'm being a jerk to him?" factor, is to reduce
humanity to automation.  It implicitly says, "you must do this, because
to be otherwise is illogical."
I demand logic in technical matters.  In social matters, I embrace my
humanity, which is to say my right to be inconsistent.  I heartily
recommend this course of living to everyone.

@_date: 2011-02-03 20:10:51
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
The problem with anecdote is everyone's anecdote is different.  As a ham
radio operator (KC0SJE), I have a fair number of keys that have comments
of "Amateur radio: KC0SJE".  (A former cert of mine had "Amateur Radio"
tagged on my kc0sje at my.domain address, for instance.)  And yes, I do
find it helpful to have someone's ham call on their key: when I'm
sending a contact report to someone, it's nice to be able to grep
through my keyring looking for their call sign and get the email address
it should go to.
The user community is huge.  Just because you don't see it doesn't mean
other people don't use it.

@_date: 2011-02-03 20:23:20
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
You're moving the goalposts.  That was responding to someone who denied
the usefulness of comments at all.  If I'm establishing there are
communities who use comments, and these communities often exist under
the radar of list members, then it's disingenuous to say "but they can
just use expert mode."
Whether it should be in normal mode or expert mode is a completely
different question from whether there exist a significant number of
users who find the comment field useful.
As long as we're moving things into expert mode, I'd like to see all
non-default options moved into expert mode, including key lengths.  I've
never seen anyone outside of the intelligence community who had a need
for a 4096-bit key: why do we support generating them?  I've seen people
screw up expiration dates more often than I've seen them use expiration
dates as part of a sane, rational security policy: why is this option
part of the default, why isn't setting an expiration date reserved for
expert users?  Etc., etc.
If you open up the "well, I think it ought to be in expert mode," there
are a lot of other things that ought to be moved over there first.

@_date: 2011-02-03 20:52:40
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
Because it does not recognize the validity of a well-answered question.
 When a question is asked and answered, it is good form to recognize the
answer, rather than say "... well, but!...".  Moving the goalposts, in
addition to being a logical fallacy, tends to persuade people that
you're not really interested in the answer.
... E.g., "Lee Harvey Oswald didn't kill Jack Kennedy!  The shots
weren't fired from the Texas Book Depository."  Well, in point of fact,
his co-workers saw him going up to the floor where he fired from, and a
lifelong hunter co-worker of his was exactly one floor below and heard
the gunshots, the shooter working the bolt of the rifle, and the brass
ejecting on the floor.  "But there's no way any human being could fire
those shots that quickly and accurately!  That's the work of a military
sniper, not a deranged gunman!  Oswald couldn't have been the shooter!"
 Well, now you're moving the goalposts: but, while we're talking about
it, the Warren Commission was able to find an Army specialist[*] who was
able to not only fire faster than that, but with better accuracy.  "But
what about the grassy knoll and the fourth gunshot?!" ... Listen, you're
not really interested in having a discussion about this, are you?  For
every claim of yours that gets refuted, you just move the goalposts
somewhere else.  I'm done talking: it doesn't matter what answer I give,
you're going to keep subscribing to these ridiculous and refuted
conspiracy theories.
[*] Non-Americans: 'specialist' is a rank in the United States Army,
just barely above a raw recruit.  Instead of being a "specialist
shooter," as you might think from the phrase "Army specialist," it
really means, "the Warren Commission found a young soldier who was
barely able to tie his own shoes without a sergeant's help, and even
*he* was able to do a better job than Oswald."

@_date: 2011-02-04 02:35:33
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
I wasn't responding to Daniel.  I was responding to Matt Goins, as was
shown in my message, who said he had never seen any comment that helped
him identify the owner of a key in a meaningful way.
To that statement, pointing out the ham radio community's use of comment
fields to store license numbers is on point.  Moving the goalposts to,
"but ham operators can still set comment fields with --expert," is not.

@_date: 2011-02-08 18:34:19
@_author: Robert J. Hansen 
@_subject: moving user ID Comments to --expert mode 
Let's stop talking about 'legitimate' user IDs, because there is no
authority that can determine for all users what are or are not
'legitimate' user IDs.  Each user/group gets to determine for themselves
what it means to be a 'legitimate' user ID.  This explosion of
authorities means this line of discussion is unlikely to be fruitful.
De facto standard.  There is no canonical authority on what a user ID
should be, or which ones are legitimate and which ones aren't.

@_date: 2011-02-15 17:14:39
@_author: Robert J. Hansen 
@_subject: ld.so.1: gpg: fatal: libusb.so.1: open failed: No such file or 
There is no "UNIX" operating system.  I am guessing that you're running
some version of x86_64 Solaris, but am uncertain of this.  We'll have a
much easier time helping if you answer these questions:

@_date: 2011-02-15 17:30:39
@_author: Robert J. Hansen 
@_subject: ld.so.1: gpg: fatal: libusb.so.1: open failed: No such file or 
Which does not answer any of my four questions, and does not help me
solve your problem.

@_date: 2011-02-15 17:44:28
@_author: Robert J. Hansen 
@_subject: ld.so.1: gpg: fatal: libusb.so.1: open failed: No such file or 
Once again, there is no "UNIX" operating system.  There are many
different vendors who provide operating systems that conform to varying
levels of the UNIX specifications.  For instance, my Macbook Pro
conforms to the UNIX specifications, but I wouldn't say my operating
system is UNIX: I'd say it was Mac OS X.
The reason why I'm asking is because different operating systems handle
things differently.  It *looks* like you're using Solaris: but so far I
don't have much confirmation of this, nor do I know which version of
Then that might be your problem.  Get a GnuPG package for your version
of Solaris, either from the Oracle open-source download page or from
Blastwave, install that, and see if it works better for you.

@_date: 2011-02-15 23:44:00
@_author: Robert J. Hansen 
@_subject: on possible ambiguity in Key IDs [was: Re: Help with OpenPGP 
IIRC, Jon Callas says an accidental long-ID collision has occurred.  I
don't recall the details.  Still, the point is that collisions don't
just happen by deliberate attack.

@_date: 2011-02-16 00:48:15
@_author: Robert J. Hansen 
@_subject: ld.so.1: gpg: fatal: libusb.so.1: open failed: No such file or 
Some of us read quite well: others less so.
David was responding to the information he had available.  The message
you're quoting was sent *after* David sent his.
When a system isn't working, it pays to be very cautious about making
assumptions about what's broken and what's working.  There's a big
difference between saying "it might be this, and here's a test we can do
to see if it is," and saying "IT IS ON THE SYSTEM!" -- unless you've
done more checking, you really shouldn't say it this confidently.

@_date: 2011-02-19 14:55:14
@_author: Robert J. Hansen 
@_subject: Some SHA-2 news 
Usually, algorithms are added due to existing users with a strong need

@_date: 2011-02-20 17:19:09
@_author: Robert J. Hansen 
@_subject: Some SHA-2 news 
Some mobile devices use 64-bit processors.  E.g., the Cell processor is
64-bit, as are some Atom variants.  As more 64-bit processors get thrown
into mobile devices, fast 64-bit code becomes more important.
At present 64-bit procs are a substantial minority, but this will change
quickly in the next few years.  Apple seems pretty married to 32-bit ARM
architecture for their mobile devices: the rest of the world seems
pretty eager to shift.

@_date: 2011-02-20 17:34:47
@_author: Robert J. Hansen 
@_subject: Some SHA-2 news 
Agreement and addendum: it also increases the amount of code that has to
be supported going into the future.
There's a rule in software engineering, usually called the "second
system effect."  In essence, the first release of a software release has
a tendency to be better than subsequent releases.
The first release only does what it absolutely has to do: subsequent
releases get weighted down by all the bells and whistles people want but
which never actually get used.  Look at Microsoft Word: as time has gone
on, Microsoft Word has exploded in complexity to the point where it
might actually be bigger and more complicated than Windows itself.
(Before anyone accuses me of MS-bashing, Free Software has lots of
examples, too.)
Good software engineers fight the second-system effect tooth and nail.
Part of that means limiting what new bells and whistles get added.  So,
yeah: in addition to what John says about the risk factor, there's also
the second-system factor.

@_date: 2011-02-21 17:40:06
@_author: Robert J. Hansen 
@_subject: Some SHA-2 news 
There are no hard and fast lines here: it isn't as if there are
canonical definitions that delineate where one ends and the next begins.
The core of the idea matters much more than what name is put upon it.

@_date: 2011-02-24 07:10:50
@_author: Robert J. Hansen 
@_subject: Default hash 
Add these two lines to your gpg.conf file:
personal-digest-preferences SHA256
(enable-dsa2 may no longer be necessary as of recent GnuPG versions, but it will certainly not harm anything.)

@_date: 2011-02-24 09:13:13
@_author: Robert J. Hansen 
@_subject: Rebuilding the private key from signatures 
It is theoretically possible to rebuild your private key if someone has
access to *one* signed mail.
It is also theoretically possible to rebuild your private key using a
fifth of gin and a Ouija board.
These two theoretical possibilities are of roughly the same magnitude.
Don't worry about it.  :)

@_date: 2011-02-24 20:20:17
@_author: Robert J. Hansen 
@_subject: Default hash 
"setpref" is, IMO, a badly misnamed command.  The preferences you attach
to your certificate are more like a ranked set of capabilities: they are
what you advertise to the world as what you're capable of accepting, and
(to an extent) in which order you prefer them.[*]
The default-*-pref in your gpg.conf file is how you tell GnuPG what
algorithms you wish to use, and in which order.
E.g., if you encrypt a message to someone, the setprefs on your
certificate are never even looked at: after all, you're only using your
*recipient's* certificate.  But if you have a default-*-pref, then GnuPG
will (almost) always read and respect that.
[*] The OpenPGP spec does not require it be treated as a preference
list, but only as a capability set.  GnuPG does a modified Borda count,
IIRC, to determine which algorithm to use -- basically, the union of
sender and recipient capabilities is considered, and each of sender and
recipient get to cast a "vote" on which algorithm is used.  This is
GnuPG-specific behavior: don't expect other OpenPGP implementations to
do likewise.

@_date: 2011-02-24 20:22:03
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
Just as an FYI to the list --
On Android's mail application, PGP/MIME attachments are nigh-unusable.
It won't render even the plaintext portions: it has to be downloaded and
opened with a text reader.  If you're concerned about your mail being
readable on a mobile device (which is increasingly important nowadays),
you might want to consider switching to inline signatures.

@_date: 2011-02-25 01:39:48
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
No, since I didn't discover it until I was in the airport checking my
email on my Droid X.
Notably, I haven't been able to view your messages at all: all I get is
an empty message and an icon showing attachments.  I have to manually
d/l the plain text portions, then open them in either HTMLviewer or
QuickOffice.  If people doubt this, I'll be happy to show images.

@_date: 2011-02-25 01:43:50
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
My problem is reproducible on a stock Droid X running 2.2.something --
just got off a very long flight, funeral in the morning: I'll dig the
precise version number tomorrow.

@_date: 2011-02-25 01:45:40
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
And vice-versa.  In inline's defense, it *works*, and PGP/MIME often

@_date: 2011-02-25 21:39:33
@_author: Robert J. Hansen 
@_subject: Default hash 
Bruce himself recommends AES over TWOFISH.
Why?  Bruce himself has said that if speed isn't a concern, nothing else
comes close to the trust level of 3DES.
FWIW, I don't much care for the Cult of Schneier.  He's a good cryppie,
a good writer, a top-notch communicator -- but the idea of "supporting"
him is, IMO, a little crazy.
No.  A modified Borda count is used.
With respect to your prefs, my standard advice applies: unless you know
what you're doing and why, stick with the defaults.

@_date: 2011-02-25 22:46:30
@_author: Robert J. Hansen 
@_subject: Default hash 
_Practical Cryptography_.  Read it.  Other people on this list can
provide a page ref: I'm at a funeral in the middle of nowhere and don't
have my books handy.
Many times.  It's not hard to find these recommendations: Google is your
I don't have the exact quote from sci.crypt handy (as mentioned, I'm in
the middle of nowhere).  I'll look for it once I'm back on the East
Coast.  I'm sure there are many people here who could provide it for
you, though.
Regardless, you really need to pay attention to the fine print.  First,
the numbers you cite are for *two*-key 3DES, and OpenPGP specifies
*three*-key 3DES be used.  3DES's meet-in-the-middle is at 112 bits of
security -- plenty enough for almost any purpose.
Second, that meet-in-the-middle on 3DES requires 2**32 known plaintexts,
2**113 operations, 2**90 encryptions and 2**88 memory.  This is so
unrealistic it deserves to be called fantasy.  Miss any of those and
you're up to a work factor of 2**168.
So, yeah.  3DES's effective security is 168 bits, unless you're up
against the space aliens from Zarbnulax, in which case you're SOL no
matter what algorithm you use.
3DES's history is instructive.  NIST has declared it "dead in 20 years"
more often than Netcraft has declared BSD to be dying.[*]  At this
point, I'm unaware of anyone who seriously believes 3DES will be gone in
20 years.  Most people seem to be of the belief that in about fifteen
years NIST will say, "and 3DES is believed strong through 2050."
[*] A humorous reference to a Slashdot meme.  BSD partisans, relax, I'm
not seriously suggesting this...

@_date: 2011-02-26 01:36:33
@_author: Robert J. Hansen 
@_subject: Default hash 
And, I forgot: I have my Kindle with me.  _Practical Cryptography_ isn't
available on Kindle, but _Cryptography Engineering_ is (also by
Schneier).  Quoting from 3.5.6, "Which Block Cipher Should I Choose?"
     The recent cryptanalytic advances against AES make these a
     tough choice.  Despite these cryptanalytic advances, AES is
     still what we recommend.  It is fast.  All known attacks
     are theoretical, not practical.  Even though AES is now
     broken academically, these breaks do not imply a significant
     security degradation of real systems in practice.
     ...
     There are probably circumstances in which 3DES still is the
     best solution.  If you have to be backward-compatible, or are
     locked into a 64-bit block size by other parts of the system,
     then 3DES is still your best choice.
... So, yeah.  There's Schneier himself, saying "use AES if at all
possible: and if you have to have a 64-bit block size cipher, use 3DES
even over Blowfish, CAST5, IDEA, or any other 64-bit block cipher I
mentioned in _Applied Cryptography_."
Hopefully this puts the nail in the coffin, and we can end this thread.

@_date: 2011-02-26 16:16:36
@_author: Robert J. Hansen 
@_subject: Edit key 
At the edit prompt:
uid 4
(enter passphrase, etc.)
Once that's done:
gpg --keyserver x-hkp://pool.sks-keyservers.net --send-key 4A00352C
... to send your updated certificate to the certservers, so the entire
world can see your former UID has been revoked.

@_date: 2011-02-27 12:21:35
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
* IT DOESN'T HANDLE ATTACHMENTS.  That's fine with me: 95%+ of my
messages don't require attachments.  Any technology that can hit 95% of
the use case is fine by me.
* IT DOESN'T LIKE CHARACTER ENCODINGS.  Works fine for me with Latin-1
and UTF-8.
* FORMAT=FLOWED DOESN'T WORK RELIABLY.  I don't use format=flowed in the
first place.
... and so on and so on.  When I look at the objections to inline PGP,
the more I realize inline PGP hits the sweet spot for me and for a great
many other users.

@_date: 2011-02-27 14:27:11
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
1.  Why are you sending them signed emails anyway?
2.  And seeing strange MIME attachments doesn't confuse people?

@_date: 2011-02-27 14:48:33
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
You may want to reconsider this practice.
Signatures have value if they are correct, originating from a validated
key, belonging to a trusted individual.  If any of those are absent the
signature is more or less just line noise.  You cannot make any logical
inferences from a signature that is bad, that comes from a non-validated
key, or an untrusted individual.
The overwhelming majority of signatures I've seen have been somewhere
between irrelevant and useless.  People tend to fetishize them something
Show me the HCI study, please.  This may be a true claim, but I'm not
willing to accept it as such on the basis of one person's anecdotal

@_date: 2011-02-27 20:31:06
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
"Should" usually just means "I want."  The world should be a just place and freedom should prevail: I want the world to be a just place and I want freedom to prevail.  We should expect MIME to be correctly implemented in MUAs: we want MIME to be correctly implemented in MUAs.
It's a great sentiment, one I happen to agree with: but it is not the world we live in.  Broken and buggy MIME implementations are a fact of life, and I think it is worth mentioning that, "the default mail app on a Verizon Droid X running Android 2.2 has broken MIME support."

@_date: 2011-02-27 20:35:33
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
I would love to see such a study.  However, I never made that claim.  :)
Someone else made the claim PGP/MIME is superior because inline OpenPGP signatures confuse people.  Okay, I'll stipulate the latter: but to argue that inline OpenPGP signatures confuse people but PGP/MIME signatures don't (or that they confuse people much less) seems to me to be kind of a stretch.
If someone is arguing either that PGP/MIME signatures confuse people more or less than inline OpenPGP signatures, well, it's a neat hypothesis, but I want to see usability data before I'll sign onto that.

@_date: 2011-02-27 21:38:43
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
I used to believe this, up until John Moore, John Clizbe and I did a small experiment on PGP-Basics.  We all shared a certificate and used it to sign our emails.  It was literally weeks before anyone noticed.
Continuity is a great idea, but based on my own (limited and anecdotal) experience, it does not play a significant role in the real world.  Unfortunately, I don't have anything more empirical to stand upon than that one ad-hoc experiment!

@_date: 2011-02-27 22:05:13
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
Yes: but one would hope that on PGP-Basics those "limited subsets" would be present in significant numbers, much as on GnuPG-Users.
I'm not sure this is reasonable.  If the real Martin doesn't care about what I'm saying, what motive does he have to check the signatures on my messages?

@_date: 2011-02-27 22:27:06
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
Then we're at an impasse, because that claim wouldn't fly with me.  Let's imagine Fake-Martin and Real-Martin (FM and RM).
FM: [message]
RM: Hey, that's not me!  I'm me.  See?  I've signed this with the same cert I've used for everything else on this list.
FM: No, I'm the real Martin.  I didn't sign up for this mailing list until last week.  You signed up here a long time ago and posted messages pretending to be me, so that when I came on the list you could falsely claim to be me!
RM: But I'm the real Martin!  I've been posting here for months!
FM: Prove it.  You can't!  Therefore, I'm the real Martin.
RM: But you can't prove it either!
We like to view signatures as purely mathematical things.  If certain preconditions are met, then a signature has this semantic meaning, etcetera.  Unfortunately, signatures are also social constructs, and social machinery tends to be full of people behaving irrationally.  Given this, I would have to say, "I don't know who's real and who's fake.  They both make very credible claims.  If I wanted to do a credibility attack on Martin, you'd better believe I'd make it a point to get on the mailing list first."

@_date: 2011-02-27 23:06:38
@_author: Robert J. Hansen 
@_subject: [was: Re: PGP/MIME considered harmful for mobile] 
As I have said a few times now, I have been out of town at a funeral.  I have just now returned and am for the most part exhausted.  For the most part, the messages I've been replying to have not demanded much out of me: nothing more than just a couple of facts off the top of my head and a little bit of logical thought.  Putting together a formal bug report, complete with screen shots and whatnot, is a little more demanding.  I'll get to it when I no longer feel wrung-out and exhausted from burying my uncle.  Thanks.  :)

@_date: 2011-02-28 00:48:27
@_author: Robert J. Hansen 
@_subject: Android PGP/MIME test results 
Verizon Wireless.
Droid X
Unknown: just the default Verizon Wireless email messaging app.

@_date: 2011-02-28 11:27:34
@_author: Robert J. Hansen 
@_subject: Security of the gpg private keyring? 
It should be emphasized that *can* is not the same thing as *does*; and
it doesn't necessarily allow you to do it with a high degree of
confidence.  Not that I'm disagreeing with David here: I just want to
make sure people don't misinterpret.
This was, IMO, ultimately an ambiguous result.  There is nothing that he
was able to derive from my certificate that he couldn't have figured out
from visiting my webpage, reading the GnuPG archives, and so forth.  The
usefulness of the certificate as a source of data was not
well-established, IMO: the usefulness of OSINT was quite well-established.
Rather than rehash the old debate, read the original discussion:
 at gnupg.org/msg13052.html

@_date: 2011-02-28 11:58:02
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
I have never understood the tendency of people, particularly on this
list, to assume that people who are technologically skilled and up to no
good will not devote more than thirty seconds to coming up with
effective methods of skulduggery.

@_date: 2011-02-28 12:01:03
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
That depends a lot on what those prior conversations are.  If I've built
up trust in RM because I think he's been up-front and candid, and FM
comes along and presents a credible threat to RM's identity, then yes, I
have to revisit my trust decision in RM: I can no longer be confident
he's been up-front and candid.

@_date: 2011-02-28 17:09:11
@_author: Robert J. Hansen 
@_subject: request information about symetric crypto 
Yes (up to 4096).
Read the source for these details.
There is no universal standard, but GnuPG does follow the best practices
for random number generation.
I don't understand these questions.
Which library -- gpgme, libgcrypt, which?  As far as Linux goes, I've
seen it work on both 32- and 64-bit architectures.  As far as Windows
goes, I've only ever seen them come in 32-bit versions.
In the future, *please* consolidate your questions into one email message.

@_date: 2011-02-28 17:23:28
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
Yes: but I suspect that may be a big "if."  If you see a message is
signed by an unknown key 0xDEADBEEF, do you really notice the 0xDEADBEEF
and go, "hey, that's my own key ID!", or do your eyes just gloss over it?
A few years ago, a fellow Ph.D. candidate named Peter was doing some
research into new anti-phishing technologies.  His research was good:
his HCI results were positively stunning.
He packaged his anti-phishing toolkit into a Firefox extension.  When
visiting a page, if the toolkit decided it was probably a phishing page
it would display a red bar across the top of the page: "This might be a
phishing site."
He set up an HCI experiment to see how easily people would notice.  Of
his 25 test subjects (all of whom were "regular users" -- non-geeks who
weren't especially tech-savvy), not one chose to avoid the site when the
warning bar came up.  In post-experience interviews, *all 25* said they
didn't see the bar at all.
So, Peter figured he'd make the bar bigger.  Same results -- except this
time it was like 21, 22, or so, didn't see it.
So, Peter figured he'd get really obnoxious.  The bar started off at a
discreet size, but steadily grew and grew until it took over a full
third of the browser window.  You had to click on a "I know this may be
a phishing site, go away!" button to close it.
20+ users, if I recall correctly, still didn't report seeing the warning
bar at all.
Finally, in a fit of deepest, darkest frustration, Peter followed-up
with people and asked, "WHY?  WHY didn't you see this?  I couldn't make
it more obvious, could I?  Did I need to rent out a parade and send up a
parachute flare while the Marine Corps Marching Band plays a selection
of Sousa marches?"
He then learned that his users thought the banner across the top was
"just another one of those annoying Flash ads," and they tuned it out.
When Peter told me about this, I didn't believe it.  It's a pretty
incredible story.  But given he'd videotaped the users' interactions
with the system...
Anyway.  The lesson I draw from this is when experts say "of course
users will notice!", well... it's very likely the users *won't* notice.
(ObWarning: I am going on memories that are now a few years old.  Doing
a little hunting, I see that he published a paper on his experiences.
Likarish, Peter, et al.  B-APT: Bayesian Anti-Phishing Toolbar,
published in _Proceedings of the International Conference on
Communications_.  He had another paper on a similar thing, BayeShield:
Conversational Anti-Phishing User Interface, in the _Proceedings of the
Symposium on Usable Privacy and Security_.  If you're concerned about
this stuff, read Peter's original papers: don't trust my own memory!)

@_date: 2011-02-28 17:47:32
@_author: Robert J. Hansen 
@_subject: PGP/MIME considered harmful for mobile 
First it was, "even signatures from non-validated keys belonging to
non-trusted persons can be significant, because it establishes
continuity of communications."  Now it's, "a question on trustworthiness
is outside crypto."
Which is it?  Are signatures from non-validated keys belonging to
non-trusted persons significant, or is trust outside the world of crypto?
Ultimately, it's perfectly reasonable to say "I trust that RM is not
screwing with me, and I trust that the key with fingerprint [...] really
belongs to him," and from there bootstrap into getting significant
signatures.  But that doesn't invalidate the point of signatures needing
(a) be correct, (b) come from validated keys which (c) belong to trusted
persons.  You're just saying, "I will trust whom I will trust, and I am
assuming the validity of this key."

@_date: 2011-02-28 17:50:25
@_author: Robert J. Hansen 
@_subject: Security of the gpg private keyring? 
It doesn't.  User IDs are freeform text fields.  Put Morse code in there
for all I, or anyone else, cares.  Just don't expect others to do
likewise, or for the developers of certificate server software to drop
everything and write extensive patches in order to accommodate your

@_date: 2011-01-02 00:46:45
@_author: Robert J. Hansen 
@_subject: Default GPG Encryption Algorithm (symmetric cipher) is? 
Forgive what may seem like a silly answer, but "whatever you told GnuPG
to use as a default."  If you want CAST5-128, 3DES, AES256 or whatever,
just add:
default-cipher-preferences [algo name]
... to your ~/.gnupg/gpg.conf file.
To get a list of algorithm names, type "gpg --version" at a command line.

@_date: 2011-01-02 03:21:32
@_author: Robert J. Hansen 
@_subject: Default GPG Encryption Algorithm (symmetric cipher) is? 
And the answer here is exactly what I said: whatever you tell it to be.
Computers are complex beasts.  Two installations of the same operating
system will be very similar in some ways and very different in others.
For some kinds of software, you can get away with saying "the default
is...".  Security-related software is different: assuming that your
installation is just like somebody else's installation is dangerous.  If
something's important to you, then you need to take steps to take direct
control of it.
But, since you're asking: by default it's CAST5-128.  Don't depend on
this.  This is what's true on my Ubuntu 10.04 LTS system: it may not be
the same for yours.

@_date: 2011-01-02 05:35:23
@_author: Robert J. Hansen 
@_subject: Default GPG Encryption Algorithm (symmetric cipher) is? 
It will respect default-cipher-preference.  Certificate prefs are not
used during symmetric encryption, since certs themselves are not used at

@_date: 2011-01-02 19:19:56
@_author: Robert J. Hansen 
@_subject: Signing 
There is no fixed semantic meaning for a signature.  Each signer is
responsible for deciding what their signature means.  Some people sign
keys and mean nothing more than, "I have successfully exchanged emails
with this address."  Some people are quite a bit more paranoid.  :)

@_date: 2011-01-05 14:01:10
@_author: Robert J. Hansen 
@_subject: --digest-algo ignored on gnupg-1.4.9? 
Using --digest-algo is pretty dangerous.  It's easy to create messages
your recipients can't parse.  --personal-digest-preferences is what you
want to use instead.
Anyway, I can't recreate this bug:
[rjh at localhost]$ gpg --list-packets test.asc
:symkey enc packet: version 4, cipher 2, s2k 3, hash 2
gpg: 3DES encrypted data
:encrypted data packet:
gpg: encrypted with 1 passphrase
:compressed packet: algo=1
:literal data packet:
gpg: WARNING: message was not integrity protected
SHA-1 is used in the symmetric packet, as is expected.  See RFC4880,
section 5.13: "Symmetrically Encrypted Integrity Protected Data Packet":
SHA-1 is the only option for digest algorithms for this particular packet.
--digest-algo will let you determine which algorithm to use, whenever
there is a choice of which algorithm to use.  There is no choice here.

@_date: 2011-01-05 16:51:20
@_author: Robert J. Hansen 
@_subject: --digest-algo ignored on gnupg-1.4.9? 
You might want to reconsider using IDEA: although it was the bee's knees
for the early 1990s, the past twenty years (good /grief/ it's so strange
to say that!) have not been kind to it.  Don't misunderstand me: I am
not saying "IDEA is broken, move away from it."  IDEA's margin of safety
is presently razor-thin, but it still holds up.  It's just that nobody
likes a razor-thin safety margin.  :)
Notice that?  That's present in your packet list, but not in mine.
You're not using integrity-protected symmetric encryption, so the bit of
the RFC I quoted at you doesn't apply.  :)
Try sharing your gpg.conf file.  The answer is probably found in there

@_date: 2011-01-06 09:23:30
@_author: Robert J. Hansen 
@_subject: PUBLIC KEY NOT FOUND 
Many Java programmers do this, but it is not what Oracle recommends.
Check java.lang.ProcessBuilder instead.
When you run it from the terminal, which user are you running as?
When you run it from your IDE, which user are you running as?

@_date: 2011-01-11 09:03:49
@_author: Robert J. Hansen 
@_subject: What is the benefit of signing an encrypted email 
Not quite.  Signatures let you verify the content has not been altered
since someone else saw it.  If the signature doesn't check, you don't
get that verification, but that *doesn't* mean the message was tampered
with, or that someone is doing an impersonation.  There are tons of
innocent things that can mangle a signature, from a misconfigured MTA
mangling PGP/MIME attachments, to the original author remembering
something at the last moment and adding content after it had been
signed, to... etc.
Signatures can verify a message as good, but they cannot flag a message
as bad.

@_date: 2011-01-11 12:13:46
@_author: Robert J. Hansen 
@_subject: How to create non-standard key pair 
If your requirements are accurate, then RSA is probably not an
appropriate choice.  Use elliptical curve cryptography instead.
What exactly are you trying to accomplish?

@_date: 2011-01-12 10:57:27
@_author: Robert J. Hansen 
@_subject: What is the benefit of signing an encrypted email 
Only if certain conditions are met.  The signature must (a) be correct (b) issued from a validated key (c) belonging to a trusted party.
A bad signature makes no guarantees, not even a guarantee the message has been tampered with.  (After all, the error could be in the signature itself, leaving the message intact.)
A good signature from a non-validated key makes no guarantees.  (After all, who does the key really belong to?  How can you have any confidence in the signature?)
Good signatures from validated keys belonging to untrustworthy people make no guarantees.  There are a couple of people in the world who, even though I know their key fingerprints and have verified them face-to-face, I wouldn't trust signatures from.  My immediate reaction would be, "I have no confidence they're not pulling some kind of trick on me."  Their signatures are worthless and make no guarantees.
Speaking for Enigmail, it's because 99% of the time signatures are worthless.  They contribute to the illusion of data integrity while actually providing no guarantees.  It's best if you only sign messages you deliberately intend to sign, messages where you believe all three conditions are met and the signature contributes to the overall integrity of the communication.  We believe this is the responsible thing to do, rather than encouraging our users to buy into a false sense of security.
If this bothers you, you can go into your account settings window, click on your account, click on "OpenPGP Security," and tell it to sign messages by default.

@_date: 2011-01-12 11:13:44
@_author: Robert J. Hansen 
@_subject: What is the benefit of signing an encrypted email 
In my case, it's "I think these individuals are mentally unstable and violent," but yes.  :)
Show me the worth in a signed message that has any of (a) an incorrect signature, (b) from an invalid key, or (c) from someone you believe is utterly untrustworthy.

@_date: 2011-01-12 11:49:10
@_author: Robert J. Hansen 
@_subject: What is the benefit of signing an encrypted email 
Doesn't work.
Here's the thought experiment I've been using for years.  Imagine that I'm a teaching assistant and I manage to make some of my undergrads very unhappy.  They bomb a test or something, and decide to get back at me.  So they sign up with Stormfront (a notorious hate site) using the one-off email of robert.j.hansen at somewebmailservice.com, create a user account for me there, and make all kinds of hate-filled racist screeds.  They write these things from a coffeeshop across the street, one where I am often known to sit around and do my grading while sipping on a latte.  Once they have a few weeks of this, they come to the Dean and say, "you have to fire Mr. Hansen, he's a racist!"
I get hauled into the Dean's office.  He's a reasonable man, a mathematician by training, and he'll give me a fair hearing.  I tell him, "Dean, I didn't write those messages and I don't know who did.  But I didn't write them.  You can be sure of that, because they're not signed with my PGP key, and I sign everything."
The Dean, not a fool, points out, "well, Rob, that doesn't actually mean anything.  These opinions are so incendiary that if I wrote them I would make it a point not to sign them, either, so that I could repudiate them later.  The lack of a signature means absolutely nothing.  The IP address goes to House of Aromas, the posting times match up with times you were seen in there grading and drinking lattes.  It doesn't look good.  I'm going to have to remove you from teaching duties."
Moral of the story: signatures do not protect against forgeries.  They protect *individual messages* against being *modified without detection*.  That's all.  It is very possible to forge traffic from someone, even if they are known to be a regular user of OpenPGP.
... The other reason this is a nonstarter: you're now increasing the complexity of the system.  OpenPGP already has a learning curve like the Matterhorn.  People just don't want to use it: it requires too much technical knowledge, too much thinking, too much study.  Adding more levels of complexity to it will just hurt the adoption curve even more.

@_date: 2011-01-12 13:52:02
@_author: Robert J. Hansen 
@_subject: What is the benefit of signing an encrypted email 
As I recall, Werner has a story about receiving PGP-signed spam.
Apparently, a home user had PGP set up to sign all outbound mail using
the PGP mail proxy service, this user's machine got pwn3d and joined a
botnet, and the spammer was pumping out Viagra mails that went through
the PGP proxy...
Automatic signing policies are bad not just because of emails you write
but don't mean to sign, but because of emails you *don't* write.  :)

@_date: 2011-01-12 16:09:13
@_author: Robert J. Hansen 
@_subject: What is the benefit of signing an encrypted email 
Mr. X has a conspirator, Ms. Y.  Mr. X deliberately avoids installing an
OS patch so that Ms. Y can pwn the box.  Now that you've made this
accusation against Mr. X, Mr. X reveals "hey, my box was cracked!  I've
been rooted and I've been sending out signed emails without my
knowledge!  How /dare/ you impugn me without having all the facts!"
Or, a less contrived example: imagine that Mr. X is a stockbroker.  He
conspires with Ms. Y to pwn the box.  You receive a signed message from
Mr. X saying, "I want to buy 1000 shares of Yoyodyne from you at
$10/share."  On the basis of this, you send him 1000 shares.  Yoyodyne
immediately tanks.  A week later Mr. X returns.  "Hi, I was off in Bali
on a beach sipping mai tais.  Anything interesting happen while I was
gone?  What the heck?  My box got pwn3d!  I didn't place that order!
Ack!  I'm so sorry about this.  Here, take your 1000 shares back, and
I'll take my $10,000 back."  (Of course, if Yoyodyne had gone up in
value, Mr. X would not have repudiated the signature.)
OpenPGP's nonrepudiability is largely a myth.  I have never seen it
tested in court.  Given the fragility of our computer systems and how
easily they're compromised, I think it's worthwhile to be very skeptical
of any analysis that's predicated on nonrepudiability.

@_date: 2011-01-12 22:54:25
@_author: Robert J. Hansen 
@_subject: Prosecution based on memory forensics 
When you close a laptop, Windows (or Mac OS X, or Linux, or what-have-you) takes a snapshot of memory contents and writes it to disk.  This can be a really big problem, since encryption keys, passphrases, and so forth are written out in the process.  For instance, if you have gpg-agent set up to cache your passphrase, your passphrase will probably be written to the hibernation file, unless the GnuPG devs have taken heroic measures to prevent this.
Last year we saw the first prosecution based on evidence recovered from a hibernation file.  The case is now over: Rajib K. Mitra has been convicted of eight counts of possession of child pornography and two counts of sexual exploitation of a child, according to the detective who was handling the case.
This is not something new: many people have been warning about hibernation files for years.  However, there are always people who will refuse to believe it until it's demonstrated in the real world.  That time is now.

@_date: 2011-01-15 12:40:57
@_author: Robert J. Hansen 
@_subject: What does the "sub" entry of a key mean? 
(Responding to David, but this is really meant for the OP)
Some time ago I wrote up a BNF for the machine-readable format, and
posted it to gnupg-devel.  You might want to search the archives for it:
you might find it useful.

@_date: 2011-01-18 09:31:30
@_author: Robert J. Hansen 
@_subject: What is the benefit of signing an encrypted email 
Why?  This seems like you're saying, "I reserve the right to decide what
someone else's security policy is, particularly which messages they
trust and which they distrust."  Which is totally bogus.
A good signature from a validated key belonging to a trusted person can
do this.  But that's it.
It is an argument against believing that it does -- as in your example
where the absence of a signature causes someone to distrust a message.
A signature or the lack thereof cannot demonstrate that a message is
A good rule of thumb is that nobody is as smart as they think.  Master
criminals are few and far between.  People make mistakes, and
malcontents are no exception.  Claiming, "I never signed up for that,
look at that email address, would I do that?", would receive a response
of, "Rob, are you forgetting I've had you in some of my classes?  I've
You don't get to decide this.  The receiver gets to decide his or her
own policy.
I doubt you will find many people who agree that your proposal does not
increase the technical complexity.

@_date: 2011-07-04 03:53:31
@_author: Robert J. Hansen 
@_subject: Len Sassaman 
Len Sassaman, a former employee of PGP (during the 1998-2001 time
period) who was also instrumental in writing the Mixmaster anonymous
remailers, died yesterday in Belgium in an apparent suicide brought on
by severe depression.
I knew Len: not as well as many, more than most.  We had a conflicted
and mixed history.  That said, no one who knew him could doubt his
commitment to anonymity and privacy.  These issues occupied a great deal
of his time and life, and our community is stronger for his
participation in it.

@_date: 2011-07-06 13:49:52
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still =?UTF-8?Q?useful=3F?= 
Why is this a problem?
"Coherent" and "secure" are in the eyes of the beholder.  Your statement
doesn't lend itself to a "yes, you're right" or a "no, you're wrong" answer

@_date: 2011-07-06 23:47:15
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still useful? 
You must not know many United States Marines.  They're a screwy bunch.
They kind of like getting shot at: it keeps them on their toes.  On the
other side of the coin, consider someone suffering from combat-related
post traumatic stress disorder, for whom there is literally no
environment that allows them to feel safe.  One group of people finds
even "obvious live threat situations" to be invigorating and they feel
quite confident about their ability to thrive in such situations, and
another group of people considers all situations, even "obviously" safe
ones, to be mortal threats.
I think we ought be very careful in making universal statements about
what all people agree upon with respect to security.  It seems to me to
be quite likely there are no such things.
As with so many things in life, IDOYTM.  Define your threat model, and
then we can talk about "coherency" and "security."  Not before then.

@_date: 2011-07-11 13:26:07
@_author: Robert J. Hansen 
@_subject: Calculating ciphertext sizes 
The short answer is "yes," but it's hard to give a more precise answer
without knowing a lot of specifics.  For instance, assuming you're running
AES in ECB mode, your ciphertext will be of size ceil(size/16)*16.  Running
3DES in CBC mode, your ciphertext will be of size (ceil(size/8)+1)*8. Etc., etc.
For any given encryption algorithm and operation mode the output size is
well-defined, but it's hard to give general answers for how it's computed.

@_date: 2011-07-11 18:29:42
@_author: Robert J. Hansen 
@_subject: Calculating ciphertext sizes 
Then this isn't a question related to encipherment: this is a protocol question.  Once you start looking at the protocol layer, other things have enormously more impact than just encryption operations.  For instance, if your wire protocol requires data be 7-bit clean binary data will expand out significantly.  If your wire protocol supports compression, the transmitted data might substantially decrease.
In the case of SCP, the OpenSSH geeks do their best to obfuscate the size of the transmitted data.  They do this in order to make traffic analysis more difficult, but also makes predicting the amount of data sent more difficult.

@_date: 2011-07-11 19:06:10
@_author: Robert J. Hansen 
@_subject: Calculating ciphertext sizes 
AES is a 128-bit block cipher: it is incapable of producing outputs except in multiples of 128 bits (16 bytes).  ECB mode is the simplest of all cipher operation modes: you read a block of plaintext (in this case, 16 bytes), if you read less than a block you null-pad it out to a block, you encrypt it, you move to the next block of plaintext.  Hence, for a given size of plaintext, the AES-ECB output will be 16*ceil(size/16).
3DES is a 64-bit block cipher: ditto, except now it's 8 bytes.  If you're running it in CBC mode then your first block of output is actually the initialization vector you're using for the output stream.  So this will be 8*ceil(size/8) + 8, which I algebraically reduced to 8*(ceil(size/8) + 1).
A good crypto reference book (I'd recommend _The Handbook of Applied Cryptography_: it's old, but it's aged well) will describe the various operation modes.  Once you understand how the modes work and what the block size is of your cipher, you can start crunching the numbers.  The algebra is pretty simple, but understanding the modes and what kinds of output they create can sometimes be a pain in the posterior.  Some modes are very straightforward (ECB, CBC, etc.), and others are fairly complex.  I'll pay $5 to anyone who can recreate Sophie Germain Counter Mode [1] from memory.  ;)
[1]

@_date: 2011-07-12 13:31:25
@_author: Robert J. Hansen 
@_subject: Invoking gpg2.exe from C# script 
I'd suggest using P/Invoke on GPGME.  Doing this from within managed
code is going to bring you nothing but tears.

@_date: 2011-07-13 07:52:32
@_author: Robert J. Hansen 
@_subject: Invoking gpg2.exe from C# script 
Examples of what?  P/Invoke?  For that, check MSDN.  (If you Google "p/invoke," it's the third or fourth link.)  Of GPGME?  Check the documentation.
Of using P/Invoke with GPGME?  Not aware of any: the technique is sufficiently straightforward, once you understand P/Invoke and GPGME, that it doesn't need much documentation.

@_date: 2011-07-13 08:45:49
@_author: Robert J. Hansen 
@_subject: Why sign as well as encrypt files stored on untrusted drives? 
In case your needs change in the future.  That's really all there is to it.
(Also, where did you read this?)

@_date: 2011-07-14 00:15:47
@_author: Robert J. Hansen 
@_subject: keysigning parties 
What sort of information do you need?
If it's, "how do I find one?", the best answer is, "throw one!"  Turn it into a social event: do something like host a doubleheader of _Sneakers_ and _The Conversation_, tell people to BYOB and bring printed slips with their certificate fingerprints.
If it's, "how do we share certificate fingerprints quickly?", the general protocol is this.  Before the party, everyone gets told a headcount for attendees.  Each participant is required to bring a number of printed copies of their fingerprint.  Each copy has the person's name, the identity documents they'll be presenting, and their preferred email address.  (I have my email address and fingerprint on my business cards: for me, I just write down "passport + DL" on the back and I'm done.)
At the party, divide the attendees into two equal groups.  Assemble them into two lines facing each other.  Each pair of people verify each other's identity documents and pockets the other person's fingerprint slip.  If for whatever reason you want to reject an identity document, you put a strikethrough on that part of the slip.
After a couple of minutes, each pair of people will be finished.  The line moves down one, and the person who just 'fell off the end' cycles back to the first position.  Repeat this until the entire line has been completed.
* Why paper slips? -- because the fingerprint is really all you need to circulate: with the fingerprint the recipient can find it on the keyservers.  Also, if you share media you open the door for propagating malware, and that's a Bad Thing.
* Why put the documents you're presenting on each slip? -- because if you're collecting papers and fingerprints from 25 other people, it's handy to have a way to remember, "ah, right, key 0xD6B98E10 -- I saw Rob's passport and his driver's license."  This sort of information is useful: it may enter into some people's security models.
* Why reject documents? -- because people are allowed to have their own security policies, and some people may say, "I don't know what a valid Connecticut driver's license looks like, so I'm going to reject this DL because I have no way of telling if it's real."

@_date: 2011-07-14 00:43:50
@_author: Robert J. Hansen 
@_subject: keysigning parties 
If by "a" you mean "one particular," I have no objection: if by "a" you mean "in general," I object.  :)
There are techniques that focus on "let's get this over with as soon as possible, even if it requires copious prep ahead-of-time and special equipment like projectors," and techniques that focus on "well, this is largely an ad-hoc thing, so let's depend on as little special equipment as possible, and a simple system that everyone understands."  I think it's best to choose a method that fits your particular needs, and to err on the side of simplicity.

@_date: 2011-07-18 21:57:24
@_author: Robert J. Hansen 
@_subject: Can version 1.4.11 be configured to use IDEA? 
Is there some particular reason why you send messages in an obfuscated format?
That said: on Windows you can usually find it in %APPDIR%\Roaming\GnuPG, at least for Win 7.  Otherwise, I'd suggest familiarizing yourself with Windows' facilities to search for a file by filename, and search through %APPDIR% looking for gpg.conf.
Also, you really ought consider upgrading.  1.2.2 is really, really old.  Many bugfixes have come and gone since then.

@_date: 2011-07-19 15:04:06
@_author: Robert J. Hansen 
@_subject: secring and dropbox 
Depends entirely on the strength of your passphrase.  With a strong enough
passphrase you could publish your secret certificates in the newspaper of
your choice and still be confident of their safety.

@_date: 2011-07-19 15:14:07
@_author: Robert J. Hansen 
@_subject: GPG on Windows 2003 
I would recommend upgrading.  GnuPG currently comes in two 'flavors': the
1.4.x track, and the 2.0.x track.  Speaking very broadly, 1.4.x is better
for servers, while 2.0.x is more suited for desktop deployments.  Which one
you choose doesn't really matter so much, so long as you upgrade to either
1.4.11 or 2.0.17.  :)
Version 1.2.2 is *old* -- like eight years old.  It doesn't track the
latest changes to the OpenPGP standard, and many bugfixes have come and
gone since then.
Gpg4win may be in version 2.1, but the version of GnuPG shipped with it is
2.0.17 (I believe).
Existing key files and so forth may be migrated to a 2.x installation
quite easily.

@_date: 2011-07-19 21:25:36
@_author: Robert J. Hansen 
@_subject: secring and dropbox 
Generate 16 random bytes, base-64 encode them, memorize the output.  I use a Python script to generate high-value keys.  Works pretty well wherever there's a /dev/random device that can be read.  I'm sure there's a way to do it for Windows, but I almost always have a UNIX terminal handy so I haven't bothered.  :)
I'm presenting the script here in case someone else finds it useful, but really, it's embarrassingly simple.
 python
# genrandkey -- generates high-randomness 128-bit keys
# Contributed to the public domain.
# Be careful with this script: each time you run it you consume
# sixteen bytes from the system's high-entropy source.  Only
# generate random keys when you need them!
# If you need to generate a lot of keys, you may want to use
# /dev/urandom instead.  The keys won't quite be of as high
# quality, but should be plenty good enough for almost all
# purposes.
# Usage example:
# proverbs:~ rjh$ ./genrandkey # EDTnI9Awc6Y19Rysg2+H+g==
from base64 import b64encode
if __name__=='__main__':
    with open('/dev/random') as fh:
        print b64encode(fh.read(16))

@_date: 2011-07-19 22:42:33
@_author: Robert J. Hansen 
@_subject: Where are those stubs.. 
It applies to those lists which have a policy on HTML mail identical to that of the Fedora mailing list.  This is not the same as "all lists."
This is a canard.  Given most of the bandwidth is taken up by spam, the tiny fraction that you can save by shifting messages from HTML to raw text is utterly insignificant.  It's a rounding error.
By that logic I should block plain text emails, based on how many malicious emails I get in those formats.
There are certainly reasons to avoid HTML email, but these reasons don't strike me as especially persuasive.

@_date: 2011-07-20 21:01:23
@_author: Robert J. Hansen 
@_subject: Where are those stubs.. 
Please don't claim to speak for the entire FOSS community.  You don't.  No one does: not even RMS, Linus or Jordan Hubbard.
Further, a lot of people within the FOSS community are not opposed to proprietary software: for instance, the BSDs.  The community has a great deal more diversity of opinion than you think.  Please respect those who hold differing views.  Wasting time in fratricidal sniping does no one any good.
Finally, please take this entire thread elsewhere.  This kind of flamefest is off-topic.

@_date: 2011-07-23 12:24:14
@_author: Robert J. Hansen 
@_subject: Primary Key Security, Old DSA Key 
This is impossible to answer, since we don't know exactly what threats
you're facing.  However, it's worth pointing out that you're correct:
most of us no longer recommend DSA-1K or SHA-1 *for new systems*.
Speaking personally, just for myself, I have not seen any instances
where I thought someone who used DSA-1K needed to switch algorithms
It's probably a good idea to migrate to a new certificate *sometime*.
If right now is a convenient time for you to do it, then sure, go for
it.  But there's no rush.
With respect to which algorithms to use... use GnuPG's defaults (RSA-2K
right now, I believe).  You don't need to tweak GnuPG in order to get a
very high level of assurance from it.  :)
Almost.  The worst that could happen is someone could issue signatures
and pretend they're from you.  But if SHA-1 falls that far, well, we're
all going to have a whole lot of problems above and beyond just that.  :)

@_date: 2011-07-23 13:16:08
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still useful? 
I need to see a citation for this.  What you're claiming is at odds with
everything I've ever learned about how DHKEA operates.

@_date: 2011-07-23 14:43:24
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still useful? 
Yes.  I am quite certain that if, say, Daniel Gillmor were to assert
"the Earth is round" and I were to ask him for a citation, he would
refer me to Eratosthenes's trigonometric analysis of the angles of
sunlight incidence in Syene and Alexandria, and would not find my
request to be in the slightest bit unusual.
There is no fact, however obvious, which is guaranteed to be obvious to
everyone.  When people ask for citations for "obvious facts," the only
thing it means is it is not obvious to them.  The courteous and genteel
thing to do is to provide a citation, so that the person in question
might learn.
What you're saying is at odds with everything I've come to learn about
DHKEA.  What you're saying is extremely nonobvious to me.  Please
present a citation for your assertion that DHKEA shares secrets more
than another competing protocol.

@_date: 2011-07-24 17:57:59
@_author: Robert J. Hansen 
@_subject: Smartcards and readers 
I'm looking into picking up an OpenPGP smartcard and reader for an OS X
system.  The card itself can be picked up from KernelConcepts, but there
seem to be an awful lot of different readers available.
If anyone has any *direct experience* (not "I heard from my friend's
bowling partner that...") with different readers for OS X systems, I'd
love to hear about them.  Which ones work well, and which are best avoided?

@_date: 2011-07-26 21:43:28
@_author: Robert J. Hansen 
@_subject: Is the OpenPGP model still useful? 
It seems to be a straightforward yes or no question.  DKG is just asking
if you're aware of OTR's purpose.
Correct.  In fact, even signatures can be viewed this way. Signature
being just encryption with the private part of the key, the digest of
the message (which is all that's encrypted) can be viewed as analogous
to a session key.

@_date: 2011-07-27 22:30:06
@_author: Robert J. Hansen 
@_subject: Including public key 
As with most things in life, "it depends."  There are almost certainly
environments in which doing so makes a lot of sense.  Competing
standards, such as S/MIME, do something similar to this as a matter of
course, so it's not entirely whacked-out.
That said, in the OpenPGP community usage like this seems pretty rare.
Most people are happy to just use the certificate servers.  :)

@_date: 2011-07-27 23:56:08
@_author: Robert J. Hansen 
@_subject: Smartcard durability? 
Are there any particular problems the durability of a smartcard,
particularly an OpenPGP card?  Are there any damage concerns from wallet
storage, for instance?

@_date: 2011-07-28 18:05:52
@_author: Robert J. Hansen 
@_subject: Creating a quickly expiring signature 
Set your system clock back a year, create a sig that expires in a year,
reset your system to the normal time.  The simplest solution is usually

@_date: 2011-07-28 19:45:52
@_author: Robert J. Hansen 
@_subject: Including public key 
I wunder if iu've red the "Plan for xe Impruvment of Ingliy Speling,"
popyularly atributed to Mark Twain?
(In all seriousness, I share in your general concern: but I'm of the
opinion a small bit of good humor is always on-topic.)

@_date: 2011-06-14 11:35:30
@_author: Robert J. Hansen 
@_subject: Aspects of trust 
These are the two Big Questions, yes: "do I have the correct certificate?"
and, "do I trust the issuer?"  You have these two questions correct.
Kind of.  You can certainly do things with different signature classes to
denote distrust, but few people do this.  You can also set a certificate's
trust to "I do NOT trust," IIRC -- it's been some years since I've needed
to do that.
"I do not find this certificate issuer trustworthy."
basically correct.

@_date: 2011-06-14 15:28:11
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
On Tue, 14 Jun 2011 22:19:24 +0200, Jerome Baum This is also handwaving the bit about how we have extremely effective
social tools for determining how to handle contested signatures: namely,
court proceedings.  This isn't a technological problem so much as a social
one, and modern democracies have developed robust social tools to address
A good rule of thumb is to let technology do what it's good at, and
society do what it's good at, and not expect either to do the other one's
work.  :)

@_date: 2011-06-14 22:26:57
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
More like "the original poster is ignoring..."  I am emphatically in
agreement with your general point, which is that social problems demand
social answers.
My use of "this" was unclear: I apologize for the confusion!

@_date: 2011-06-15 14:32:55
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
Corroboration is simply not possible.  A timestamp cannot be proven good
or bad.  You ultimately have to rely on someone's word: all you get to do
is choose whose word you will accept and why.
This isn't really "corroboration" so much as it is, "I choose to trust
someone else."
And it is, assuming the third party trusts the signer.  If the third party
doesn't trust the signer, then we've left the realm of problems OpenPGP can
solve and we're into the realm of problems legal systems exist to solve. ("I don't trust your timestamp!  You didn't use my preferred timestamping
service!  I'm not going to honor this agreement!"  "Fine, bucko: see you in
Quite probably the signer *shouldn't* refute that.  Refuting claims
doesn't convince anyone of anything except a particular claim is not
supported by facts -- it doesn't prove the claim is actually wrong.  "Okay,
so you've convinced me not to trust this evidence saying the timestamp is
incorrect: but you haven't done anything to persuade me the timestamp is
correct, which is actually the important thing."
(This is also why, e.g., it makes no sense to argue with a conspiracy
theorist: with a lot of effort you can prove the conspiracy theory to be
*unsupported*, but you can't actually prove it *wrong*.)
It can't provide proof.  It can't even provide evidence.  It can only
provide a data point which both parties stipulate as being uncontested --
and nothing is easier to reverse than a stipulation.  ("Well, sure, I
trusted Honest Al's Timestamping Service... up until I saw they signed
THAT.  I repudiate this timestamp!  I don't trust Honest Al's Timestamping
Service any more!")

@_date: 2011-06-15 14:38:00
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
As soon as you're able to prove to a court that a timestamping service's
clock is fair and honest, sure.
But if you're able to prove that a timestamping service's clock is fair
and honest, then the original signer could use the same process to prove
*his* timestamp is fair and honest -- and thereby remove the need for a
timestamping service in the first place.
Your argument leads to a paradox.  If a timestamping service's clock can
be proven to be fair and honest, then there is no need for timestamping
Timestamp authorities are *trusted* to be fair and honest -- but that's
not the same thing as *proven* to be, and nothing in the world is easier to
revoke than trust.

@_date: 2011-06-15 19:51:27
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
Except this isn't a witness: it's the output of a wholly automated
process that has no real connection to temporality except for the ticks
of a system clock which, by everyone's admission, can be set any way the
timestamper wants.
It is no witness at all, in fact -- it doesn't even rise to the level of
a fact.  It is merely a *claim*, unless stipulated by all parties: and
then it becomes something rather more than a claim.
Even that's insufficient.  Show what's *right*.
Then it would seem to me your hypothetical is so poorly considered as to
not warrant further discussion.
... In point of fact, that's *exactly what happens to it*.
If both parties stipulate to the accuracy of the third-party timestamp,
then it's evidence.  If one party doesn't, then it becomes a *claim*,
and it's up to the jury to decide the strength of the claim.
I'm fairly sure it is.  Most of the tricks lawyers use to repudiate
timestamps on physical documents also apply against electronic
documents, and I'm pretty sure contract lawyers are worth their paychecks.

@_date: 2011-06-15 20:29:49
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
You're moving the goalposts: you're changing the terms of what the
statement is meant to prove.  By moving the statement from "A is true"
to "Tom claims A is true", you've moved it back to something both
parties stipulate -- presumably, Tom and Jerry both will agree that Tom
claims A is true.  Etc., etc.
Simply put, if both parties agree that "X, and X indicates the truth of
A, therefore A," then X is evidence for A.  As soon as one party objects
to either the fact (X) or the deduction (the inferential rule), then it
becomes simply a claim to be evaluated by a jury.  Claiming that "well,
it becomes evidence, just evidence for a different thing," is the sort
of thing that, while true, kind of misses the point.
At this point, you need to ask a contract lawyer.  I know enough
contract lawyers to be certain they are very on top of their game, and
they've already given thought to the subject of repudiating electronic
documents -- but I haven't been fascinated enough to go to law school,
As I am given to understand, the major problem with creating documents
in perfect accordance with all extant law and precedent is just how
difficult it is to keep track of everything that's applicable.  It
sounds nice and simple to say "create something in accordance with
signature laws and applicable precedent," but my understanding is that's
a highly nontrivial task.

@_date: 2011-06-15 20:32:02
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
It would mean that you could, in anticipation of a challenge being made,
use the same procedure the "provable" timestamp authority would use: and
thereby remove the need for it.

@_date: 2011-06-15 20:44:17
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
Possibly -- but it still assumes that timestamps can be proven in a way
that makes the impossible to contest.  This really isn't possible, as
evidenced by the fact we continually refer to them as *trusted*
timestamp authorities.
There is no way to prove to someone that a timestamp is trustworthy.
All you can do is present the timestamp authority's methods and let the
person make their own decision as to whether to vest the timestamp
authority with trust.
Even if a timestamp authority were to publish every timestamp signature
in the _New York Times_ on the day of issuing, that would still be
insufficient for some people -- they would say, "well, how do I know the
timestamp authority isn't running a con?", or whatnot.
Ultimately, it always reduces to trust.  If there were a way to *prove*
the timestamp of a message, we wouldn't need timestamp authorities at
all.  Instead, we have trusted third parties who are uninvolved in the
matter of controversy -- and that works well enough for us.

@_date: 2011-06-15 21:08:29
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
There are two main reasons why I'm referring you to a lawyer:
(a) to the extent I know some lawyers' strategies, I am generally
    not at liberty to talk about them, and
(b) to the extent I am at liberty to talk about the rest, I am
    not confident of my ability to present their methods correctly,
    due to the fact I haven't spent ten years learning all the
    intricacies of contract law
Neither (a) nor (b) interferes with my confidence in the statement,
"contract lawyers are well-prepared for repudiating electronic documents."
(To explain (a): a few years ago I worked as the chief sysadmin for a
law firm, and got to sit in on their strategy sessions for how to handle
the changes electronic documents presented for subpoenas, signatures,
and so forth.  I am not at liberty to talk about their methods: I can
only tell you the lawyers I worked for took this quite seriously, and
were confident of their ability to repudiate electronic signatures.)
Your CPA and ISP claim to do this.  Nobody knows whether it truly is
until a court declares it to be so.

@_date: 2011-06-15 21:20:07
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
Your claim would be submitted to a jury for consideration, as it's a
question of fact and not law.  The jury would look at your claim of
mathematical strength, be confused, and proceed to move on to something
else.  Nothing in law is proven until a jury has declared it to be so...
and pretty much everyone in a courtroom hates math.
You can attempt to prove your timestamp is correct: but ultimately,
that's *not within your control*.  It's entirely within the jury's
purview, and if the jury says "we don't buy this," then you haven't
proven a thing.
"Proof," in a mathematical sense, is irrelevant in a courtroom.  Proof
is whatever you can sneak past the judge that will make the jury buy
your claim -- nothing more.  You don't get to declare what proofs are
valid or invalid: only the jury does, and the jury doesn't care what you
Consider this: MD5 is still the standard hash algorithm used in digital
forensics.  Makes all of us have the flaming heebie-jeebies, of course:
it's crazy to use MD5 to authenticate digital data, given the collision
attacks against it.
But for the courts... what the courts think of as "proof" is not what we
think of as "proof."  We think MD5's weakness has been proven: but so
far, juries are still regularly accepting MD5 as a cryptographically
secure hash algorithm, which means that in the eyes of the court *it is*.

@_date: 2011-06-15 21:26:30
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
It's kind of like how in college I saw Professor Lichty derive special
relativity from the Pythagorean Theorem and first principles.  Do I know
it can be done?  Sure, because I remember my eyes popping out of my head
at the elegance and simplicity, and realizing "my God, relativity is so
important because it's /background independent!/"  But if you were to
say, "hey, that's really cool, show me!", I'd tell you that you'd have
to ask Professor Lichty.

@_date: 2011-06-15 21:29:01
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
Submitted before the tribunal, then -- the upshot of it is that *you
don't get to decide what the court does*.

@_date: 2011-06-15 21:37:30
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
No.  It does, however, qualify as "here is where you need to look if you
want to verify my claims," which is the best you can hope for on a
mailing list.  I'm done with this thread: it seems to have devolved
about as far as it can go.

@_date: 2011-06-23 13:05:39
@_author: Robert J. Hansen 
@_subject: DH Key 
For reasons I've never been able to understand, PGP insists on calling
Elgamal "Diffie-Hellman," and insists on calling the Digital Signature
Algorithm ("DSA") the Digital Signature Standard ("DSS").
What PGP calls a DH/DSS key is really a DSA-and-Elgamal key.
Hope this helps!

@_date: 2011-06-23 13:06:58
@_author: Robert J. Hansen 
@_subject: DH Key 
Not quite.  DSA can be used with any 160-bit hash, but DSS specifies the
use of SHA-1.

@_date: 2011-06-28 12:18:48
@_author: Robert J. Hansen 
@_subject: Problem with faked-system-time option 
Just because GnuPG has adopted some feature requests to facilitate
anonymity does not mean GnuPG will, or even should, adopt other feature
requests for the same.  If I buy you a beer I'm not obligated to buy you
Ultimately, if this is important to you then you have two choices:
convince someone to write the patches for you, or else write the patches
yourself.  If you're unable to convince others to do it, then start
teaching yourself C.

@_date: 2011-02-28 20:08:11
@_author: Robert J. Hansen 
@_subject: Security of the gpg private keyring? 
And this isn't even getting into the ways such a feature could/would be
abused.  Once you create an enforceable mechanism to say "this key
cannot be propagated by anyone but the owner," someone will find ways to
leverage that into an attack.  I don't know how it would be done: I
haven't done much thought on the subject.  But my suspicion is that
people much cleverer than I am are already thinking on it.
Also, from a political perspective, it's kind of interesting to see the
debate.  This is fundamentally an argument about DRM: certificate owners
claim certain exclusive rights and want technology to facilitate their
exercise of those rights, much as motion picture copyright owners claim
certain rights and want technology to facilitate their exercise of those
rights.  I'm not drawing any moral parallels between the two groups: I'm
just saying I find the dichotomy fascinating.  :)

@_date: 2011-02-28 21:08:48
@_author: Robert J. Hansen 
@_subject: Security of the gpg private keyring? 
There's a lot of stuff in the literature on this subject.  This sort of behavior is usually called ORCON, for "ORiginator CONtrolled" -- referring usually to intelligence so sensitive the source controls who sees the intel and how it is used.
The first paper I can find on this subject belongs to Graubert, "On the Need for a Third Form of Access Control," _Proceedings of the 12th National Computer Security Conference_.  It's worth reading.

@_date: 2011-03-01 23:07:19
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Here the analogy breaks down.  Generally speaking there is only one telephone directory for a given geographic area, which makes it possible for you to keep your phone number private by keeping it out of that one directory.
Email doesn't work the same way.  There is no centralized directory.  To keep your email private requires that you fastidiously keep it out of thousands, tens of thousands of directories.  This doesn't strike me as very practical.
The benefits of keeping a telephone number out of the directory do not seem analogous to keeping an email address off the certificate servers.

@_date: 2011-03-02 15:06:04
@_author: Robert J. Hansen 
@_subject: Enquiries about GnuPG 
It implements RFC4880.  All MUST functions, as well as the overwhelming
majority of SHOULDs (perhaps all!), are supported.
GNU GPL v3.  How much it costs depends on from whom you buy it.  You can
get it for free from many sources.
Most UNIXes and Win32.  If it follows POSIX, GnuPG can probably be
compiled there.
I don't understand the question.
Depends on from whom you buy it, and/or from whom you buy support.  As
mentioned above, you can get it for free from many sources.

@_date: 2011-03-02 15:27:50
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
The analogy continues to break down.  "Binding," in the context of the
analogy, means "if someone breaks this instruction, they will be hurt."
 Maybe the government will start a criminal prosecution, maybe you have
recourse in a civil lawsuit, but ... ultimately, "if someone breaks this
instruction, they will be hurt."
Okay, fine: who are you electing to be the hurt-inflicter for the
OpenPGP community?  And in the absence of a designated hurt-inflicter,
how can there be a "binding instruction"?
The analogy you're drawing is appealing at first glance, but the more I
look at it the more it breaks down.
I would *far* rather change my phone number than change my email
address.  Probably a total of 50 people have my phone number: if I
change it, big deal.  If I change my email address, I'd probably need to
inform upwards of a thousand people of the change.
It may be true that *for you* it is easier to create new email addresses
than to change phone numbers.  It does not hold true for everyone, and
just how broadly it holds true is unknown.

@_date: 2011-03-02 19:33:27
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
It's not a tangent at all, and for almost the exact reason you cite.
You would say "it can easily be done."  I would say, "it can easily be
enforced."  I'm not seeing an effective enforcement mechanism here.
Without that, I don't see how it can easily be done.
Basically what you're saying is, "I don't want other people to be able
to publicly share data that I feel personally identifies me."  That's a
perfectly understandable want, but you can't make data uncopyable.
Digital information may be easily and near costlessly copied and shared:
that's just its essential nature.
I don't believe 4 is the case at all.  In this era of Facebook, Twitter,
social media and people profligately sharing information, well... this
seems a lot like locking up the barn after the cattle have run off.
You're begging the question: how does it get made ex-directory?  In the
case of a telephone, it's because you have a single point of authority
who will enforce your wishes.  In the case of the certificate servers,
how does it get done?
I'm not saying it shouldn't get done or that I wouldn't like it if it
were done.  I'm only saying that, at present, it doesn't appear it *can*
be done.

@_date: 2011-03-02 19:59:48
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Same here.  I am deeply skeptical, but not unwilling to be proven wrong.
IMPOSSIBLE: means (1) I wouldn't like it and when it happens I won't
approve; (2) I can't be bothered; (3) God can't be bothered.  Meaning may perhaps be valid but the others are 101% whaledreck.

@_date: 2011-03-07 17:32:47
@_author: Robert J. Hansen 
@_subject: "This key may be unsafe" 
A 1024-bit key is believed to be roughly comparable to an 80-bit
symmetric key.  I am comfortable saying this is a reasonable level of
security for the next few years for people who are not worried about
being targeted by people who can afford to drop a few million dollars on
It is not a wise choice for long-term security, but I am not comfortable
calling it "unsafe" for most users.

@_date: 2011-03-09 08:24:12
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
It seems like this is really close to asking for private stream
searching, which would be the next logical step -- some way for the
client to query the database for a record in such a way there is no way
for the database to know what was queried.  This may sound alluring, but
it's an ephemera.  The current best-known PSS algorithm requires about
one zebibyte of traffic to do a ten-character ASCII search.
These sorts of blinded searches are really tempting, but there are
enormous theoretical hurdles to be cleared.  I would respectfully
suggest that if any discussion moves to PSS-type functionality, that
discussion be headed off at the pass.  :)
("Private searching on streaming data" by R. Ostrovsky: PDF available at

@_date: 2011-03-09 08:39:35
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
There are a couple of major problems here:
1.  There's not all that much entropy in an email address.  Let's say
that I want to harvest email addresses.  I create a list of, say, the
top thousand email providers in the world, and then every five-character
lowercase username.  For each five-character lowercase username, compute
the hash for that user name at each of the top thousand email providers.
 For each hash, look it up in the database.  Total work factor: about 11
billion hashes have to be made, probably under a terabyte of data --
very practical.
        (a) And don't forget that with services like Amazon's cloud,
            massive data crunching distributed across hundreds of
            machines costs a few pennies per processor-hour.  This
            has the potential to ruin your entire day: cloud computing
            shifts the fulcrum of computational leverage *immensely*.
2.  To really gain benefit from this scheme, you must:
        (a) have a non-trivially-brute-forceable email address
        (b) want to be able to hide your email address
If you don't care ("b" fails), then this scheme is just an
inconvenience.  If you have a brute-forceable email address ("a" fails),
then this scheme offers no benefit.
3.  Deploying this scheme means:
        (a) people can no longer do fuzzy searches for email
            addresses ("show me all user IDs that look like this
            pattern")
        (b) finding people's certificates may be made more
            difficult due to (a)
4.  My suspicion is the number of users covered by (2) is pretty small.
 My suspicion is the number of users impacted by (3) is pretty large.
My suspicion is we do not have a very good handle on just how difficult
we need to make things, given the resources available to spammers in (1a).

@_date: 2011-03-09 22:10:40
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
I think it should also be noted that if I was serious about trying to
overthrow a government, I'd create a bare certificate without a name or
an email address on it.  I'd also use it as infrequently as possible and
try to avoid any technology more complicated than, say, a wheel, lever,
or inclined plane.
GnuPG will not keep your communications secure against major adversaries
who are willing to torture you for so long you think you've made an
unfortunate lateral career move.  It's just a tool in the toolbox.
You're going to need the rest of the toolbox, too.

@_date: 2011-03-10 00:17:25
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Which brings us back to the elephant in the middle of the room: as far
as I can see there's no consensus on a use case for this feature.
Some people have a knee-jerk reaction to their email addresses being in
any searchable database and want their emails obfuscated.  Against this
threat, the proposed feature doesn't work: email addresses don't offer
enough entropy and the mechanism could be brute-forced.
Some people think they're going to take over the People's Republic of
Berkeley in a military coup and need to be able to deny their
connections to each other.  Against this threat, the proposed feature
doesn't work very well: while you could conceivably come up with an
email address with high enough entropy, it's easier to just use
anonymous services and dead-drop emails.
Has a use case been articulated for this feature, along with how this
feature would substantially advance the use case?  Because if not, one
really needs to be.

@_date: 2011-03-10 00:20:29
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Idiom note for non-Americans: the University of California at Berkeley
is often called, tongue-in-cheek, "the People's Republic of Berkeley."
This is a (hopefully humorous) reference to having a military coup
taking over a college campus.

@_date: 2011-03-10 08:10:32
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Not at all.  Every few days the keyserver network posts complete dumps
of all the certificates in the system.  (Or, more accurately, various
people within the network do.)  This exists so that new volunteers who
want to contribute their services to the community can get their own
servers bootstrapped.
If I want to brute-force the certificates, I'd just say, "hey, I'm
interested in standing up a new keyserver," get a dump of all the certs,
and then do the brute forcing on my own system without ever needing to
hit the network.

@_date: 2011-03-10 08:18:36
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Someone would have to be crazy to write this.  The product liability
lawsuits alone would be daunting.  Remember that a jury trial is often
not so much about the law as it is about blame: if something bad happens
the jury wants to be able to point at someone and say, "that person is
If I were to write this, it wouldn't matter how big of a disclaimer I
put on the cover page: I would live in fear of someone hauling me into
court to say, "Ladies and gentlemen of the jury, I followed his
instructions and I got to spend six weeks discovering what my own liver
tasted like.  I blame him for the fact I was captured and tortured by
the secret police."
This also doesn't get into the problem of there being so astonishingly
few people on the list -- quite possibly *zero* people on the list --
who are competent to write such a thing.  A good rule of thumb in crypto
is to never trust ciphers designed by people who haven't first earned
their bones by breaking them.  The same applies to countersurveillance
and tradecraft: don't take advice from people who haven't first proven
their abilities at finding people who really, really don't want to be found.

@_date: 2011-03-10 08:34:13
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
You've just described the use case for a local certification.
Certifications come in two basic varieties: public and private.  A
public certification is intended as an announcement to the world: "Hey,
world!  I am [name] and I vouch for this certificate!"
If people want to make public pronouncements of social relationship, why
in the world would you want to deploy a technology that makes it
difficult to discover this social relationship?
This doesn't make any sense to me.  Quite possibly I have completely
misunderstood what you're arguing.

@_date: 2011-03-10 08:40:55
@_author: Robert J. Hansen 
@_subject: Signing signature policies required for safe key usage? 
I don't believe it will ever happen.
For all that we like to believe people validate certificates, the blunt
reality is certificate validation is an unusual event.  Certificate
signing is a technical procedure and most users don't do it.  This is
why GnuPG allows for a trust model of "always", where all keys are
treated as validated even though they haven't been.
When the overwhelming majority of users validate keys by fiat, there's
no reason to think they'll either (a) write a policy document, (b) read
another person's policy document, (c) adhere to their own policy
document, or (d) randomly check certificates they've signed in order to
make sure the cert owner is adhering to his or her policy document.
I mean, in an abstract sense, yes, it would be nice if..., but I don't
expect it to ever happen.

@_date: 2011-03-11 08:33:38
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
My complete /var/lib/sks/DB directory comes in at 7.8G.  Not too large.

@_date: 2011-03-11 08:54:57
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
(Did you mean "not necessary" instead of "no use"?)
It is useful to quite a lot of people.  Look at how many people map out
webs of trust for entirely innocent purposes.  In fact, mapping out webs
of trust is necessary for the WoT idea to even work.  "Well, I've signed
Frank's key and I see that Frank's signed Gianna's key, and I trust
Frank so..."
How do you propose determining who really needs those signatures for
validation purposes and who doesn't?  And once you've made that
determination, how do you enforce it?
Those are the two major, outstanding questions, and so far I've not seen
any serious attempts at answering them.  It seems this discussion is
stuck at the stage of "it would be nice if we all had ponies," without
any real answers to questions of "so where will we get the real estate
to house the ponies?" and "who among us is an equine veterinarian?"
I don't know how to respond to this: since we don't have a workable
proposal for how to accomplish your objectives, we also can't discuss
how your proposal will affect existing users.
Because this is not an ORCON system.  The system is built around public
certifications and private certifications.  You're talking about
introducing an entirely new method, something which seems basically like
an ORCON certification: "I'll make the certification, but I get to
control who gets to learn about the certification."

@_date: 2011-03-11 15:39:07
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Don't know, but it would be an interesting thing to test.

@_date: 2011-03-12 15:14:34
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Product liability is civil, not criminal.  Regardless, it doesn't
matter: for all that judges tell juries "your job is to determine the
truth of the accusation," a jury's natural instinct is going to be to
find a responsible party.

@_date: 2011-03-12 15:22:06
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Yes, in fact, they do.
In my past, there's an ex-CEO whom I'll just call "Ben."  Ben made some
really astonishingly bad decisions that put him in prison for eighteen
months, and left me with a permanent distrust for him.  If I see Frank
has signed Ben's certificate, and I trust Frank, am I going to trust Ben?
Of course not.
Trust is not transitive.  If A trusts B and B trusts C, there is no
requirement that A trusts C.  In fact, if it turns out A knows C,
transitivity can break completely.
So far, you haven't produced a mechanism that will do this.  We're still
at the "it would be nice if..." stage of your idea.  Thus, I really
can't respond to statements of what this mechanism would or wouldn't do,
since we don't have a mechanism to analyze.

@_date: 2011-03-12 15:24:34
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Beats me.  You're the one who's assuming someone wants to harvest email
addresses.  Imagining a spammer behind it is just part of a thought
exercise.  Focus on the real issue -- that this scheme you're proposing
is not secure against an even mildly motivated attacker -- not who the
prospective attacker is.

@_date: 2011-03-12 18:06:14
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Yes, it does.
If nobody's looking for people's email addresses, then there's no need
to not publish email addresses.  And if there's a need to not publish
email addresses, that's because somebody's looking for them.
It is not good enough right now to prevent an even moderately skilled
attacker from recovering email addresses.  A work factor of 10 billion
means I write a Perl script, let my iMac work for a week, and fill up a
$100 hard drive.
This scheme offers the illusion of security instead of actual security:
and I feel selling people an illusion is a deeply corrupt act.
"If we use this blinding scheme it will look like it works but in
reality anyone who wants to map out the Web of Trust will probably just
be delayed for a week and the majority of users will think they're secure."
I mean, really, is that what you want to sell?  Or should this be taken
as a, "the idea of blinded UIDs is a good one, but this idea is
inadequate and should be taken back to the drawing board"?

@_date: 2011-03-13 00:43:32
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
Yes.  Like I said, you want an ORCON system.  If you control how people
can use data, then you've entered ORCON.
As soon as you invent an ORCON system, I would love to revisit this
conversation.  I am not being in the slightest bit facetious: I think
ORCON systems are difficult theoretical and practical challenges and I'd
love to see a successful system fielded.
It's just that, as currently drafted, this isn't it.

@_date: 2011-03-13 10:47:23
@_author: Robert J. Hansen 
@_subject: hashed user IDs [was: Re: Security of the gpg private keyring?] 
So at this point you're saying, "I want to convince somebody else to
volunteer their time and energy implementing a bogus solution to a
problem that doesn't even exist."
I'm done with this thread.

@_date: 2011-03-13 23:55:19
@_author: Robert J. Hansen 
@_subject: For Windows 
Well, it's not exactly "unsolicited," given it's a response to something
you said, and it's not hawking any good or service so it's hardly
"commercial."  I think you're going a bit overboard here.
True, but more or less irrelevant.  Consider how long it's taken to kill
IE 6, even when Microsoft's been making IE 7+ free downloads for as long
as can be imagined.  XP is going to suffer much the same fate.  I would
be absolutely gobsmackingly astonished if XP dropped below, say, a 10%
market share before 2015.
Remember what it was that killed Vista -- the perception that XP was
good enough and nobody needed what Vista was offering.  Now consider
that Windows 7 is basically just a rebranded, remarketed Vista.  It
seems highly premature to declare that XP is on its last legs.  It's
transitioned into the end-of-life stage, yes... but there's no knowing
how long it'll hang on.
It has been superseded among the bleeding-edgers.  There are still a lot
of people who insist on using OE on the grounds of, "I don't want to
have to learn a new user interface."
I would agree with you if I thought XP and OE were dead.  I don't.

@_date: 2011-03-14 00:23:15
@_author: Robert J. Hansen 
@_subject: RSA Versus DSA and EL GAMAL 
There are probably only a couple of dozen mathematicians in the entire
world who are really competent to argue about the relative merits of the
concepts underlying each algorithm.  I'm not one of them.  I doubt any
of them are on this list.
For the rest of us, it's kind of like wondering whether King Kong or
Godzilla is better at terrorizing urban centers.  It's an interesting
thought experiment, but we'll probably never reach a consensus.  All
we'll be certain of is that if we need an urban megalopolis thoroughly
cowed, either of the two will do the job just fine.

@_date: 2011-03-14 09:17:59
@_author: Robert J. Hansen 
@_subject: For Windows 
Yes, exactly.  At some point *you* have to move on -- but you don't get
to say if, or when, other people decide to move on.
For the time being, a lot of people are still on platforms that use
outdated software.  In this case, Outlook Express (although I agree with
Doug: I believe Windows Mail still has the same problem).  The question
is whether in our desire to move on we're willing to write off the
possibility of communicating with people who have not yet moved on.
"Dead" is a subjective term, and not one I believe is appropriate here.
Of course not: however, that's not what we're talking about here.  What
we're talking about is inline signatures.  The code for this already
exists, is stable, and isn't going away anytime soon.  The question is
not whether we are going to spend resources specifically targeting OE,
but whether we are going to use *already developed* resources in order
to facilitate communication with OE.
Quite the opposite: one of the big selling points of the free UNIXes is
how well they function on old, outdated hardware.  I could install one
on the very first PC I ever owned, a 386DX/20.  Support for old systems
is a feature, not a bug!
Inline signatures /are/ standards.  RFC 4880 is far newer than RFC 3156:
by your logic, 4880 should supersede 3156 and we should all move to the
current standard and abandon 3156 support.
Note: I'm not advocating everyone use inline signatures, the same way I
don't advocate everyone use PGP/MIME signatures.  Use what works for
you.  At the end of the day, that's the final analysis, the only
interesting result.

@_date: 2011-03-15 09:31:40
@_author: Robert J. Hansen 
@_subject: GPG and PGP 
Substitute "safety margin" for rigor and I'll agree with you.  IDEA is a
competent design by credible people and has had a whole lot of people
beating on it to only limited degrees of success: it seems to me they've
met the requirements for rigor.
I am generally in favor of modular design on general principle: it makes
it easier to write custom additions to GnuPG should the need arise.
Whether an IDEA module should exist or not ... eh.  I've always thought
that if people really needed RFC1991 compatibility, they know where to
find PGP 2.6.

@_date: 2011-03-15 16:16:59
@_author: Robert J. Hansen 
@_subject: GPG and PGP 
This may not be so much an argument for IDEA's inclusion as it might be
an argument for data migration.  How long will we support RFC1991?
There are really only two interesting answers: "forever" and "for a while."
If forever, then sure, IDEA support, v3 keys, etc., etc.
If not-forever, then we should start talking about when precisely we'll
stop supporting RFC1991, and how we can help users migrate away.

@_date: 2011-03-15 23:37:51
@_author: Robert J. Hansen 
@_subject: GPG and PGP 
Given there are no symmetric ciphers in OpenPGP that use more than a
256-bit key, I think the answer here is "yes."  :)

@_date: 2011-03-16 10:12:12
@_author: Robert J. Hansen 
@_subject: GPG and PGP 
The OpenPGP spec requires three-key 3DES, and GnuPG conforms to the spec.

@_date: 2011-03-16 20:17:26
@_author: Robert J. Hansen 
@_subject: compatible with PGP/Desktop 
PGP is a registered trademark of the PGP Corporation.  It's a great
product, but Enigmail doesn't use it.  Enigmail uses GnuPG, which is a
compatible implementation of PGP.
The answer to your question is, "yes."  The only thing you need to be
careful about is that historically Microsoft products have had awful
support for sending messages as encrypted MIME data.  The Enigmail folks
recommend not using that feature when communicating with people using
Outlook Express, Outlook, or Windows Live Mail.
If this doesn't answer your question fully, perhaps you should try
asking on the Enigmail mailing list?  You can sign up for it at:

@_date: 2011-03-19 23:36:57
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
DSA has received comparable scrutiny, IMO.  The Elgamal family (of which
DSA is a member) has an impressive pedigree.
Why?  This is like saying, "I like the bank vault on my front door, but
I wish it was thicker: I want the extra security."  Key length is only a
small part (arguably the smallest part) of communications security.

@_date: 2011-03-21 10:00:01
@_author: Robert J. Hansen 
@_subject: Deniability 
I think you're trying to use a blender as a personal flotation device.
OpenPGP is not meant to provide deniable communications.  It is
concerned primarily with message confidentiality (encryption) and
message integrity (signing).  Just like blenders blend, PFDs float, and
it's unwise to try and make one do the other's job, I think it's unwise
to crowbar OpenPGP into being a deniable protocol.

@_date: 2011-03-21 22:08:29
@_author: Robert J. Hansen 
@_subject: Deniability 
Or she'll just have to kidnap Alice or Bob and beat them senseless with
a lead pipe until they confess.  Deniability is not as useful of a tool
as it is often made out to be.
There is also a flip side: deniable communications put parties in
increased jeopardy.  Imagine Mallory kidnaps Charlene, who is
uninvolved, because she thinks Charlene is involved.  (This sort of
thing happens quite a lot in the real world: for instance, in the '70s
the Israeli Mossad murdered an innocent Norwegian waiter because they
mistakenly identified him as a terrorist.)
Charlene declares her innocence.  Mallory beats her senseless with a
lead pipe.  "I know you're using a deniable system!  Stop denying things
and tell me the truth!"  Charlene tries to prove she didn't receive the
message -- but she can't, because it's a deniable system.  Mallory keeps
on beating her senseless with a lead pipe.  Sooner or later, Charlene
confesses to anything Mallory suggests, just to make the torture stop.
Deniable communications are neat, but there are two huge eight hundred
pound gorillas lurking in the room:
        1.  Deniability doesn't work well against sadists with
            lead pipes.
        2.  Deniability means you can't give the sadists a reason
            to stop.
If this is a thought experiment in how to crowbar deniability into
OpenPGP, I wish you luck.  :)  If you're looking at actually using a
deniable OpenPGP, or recommending others use one, I hope you'll give
serious thought to these two things.

@_date: 2011-03-22 08:28:57
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
"Defensibility" really doesn't enter into it.  My purpose isn't to
persuade someone not to use a 4k key: my purpose is to suggest that people
think critically about why they want a 4k key and what they think it will
give them that a 2k key does not.
And this is where I part ways with you.  There is no reason not to bump
key length up to 4096.  There is also no reason not to use SHA512 with a
DSA-1k key, for instance.  Sure, only 160 bits of SHA512 will be used, but
that's not a reason not to use it.  It's not as if you're making the system
IME, engineering starting from a base maxim of, "why not?", ultimately
leads to curious things that leave you scratching your head (like the
aforementioned, "why are you using SHA512 with DSA-1K?").  This is why I
would much rather start from a base maxim of, "why?"  I'd much rather be
accused of favoring minimalism than maximalism.

@_date: 2011-03-22 08:49:55
@_author: Robert J. Hansen 
@_subject: Deniability 
On Tue, 22 Mar 2011 14:37:16 +0000, Jerome Baum The amount of lead pipe a court can swing at you in many ways exceeds the
amount of lead pipe organized crime can throw at you.  Let's do this
thought experiment again, but this time with a zealous prosecutor who is
sincerely doing what she believes to be her job.  Further, assume you have
a deniable cryptosystem: you can't deny you received the message, but you
can neither prove nor disprove having the ability to read it.
Alice and Bob are plotting a heinous crime -- terrorism, narcotics
trafficking, child exploitation, whatever.  They know their communications
are being monitored and they are using a deniable cryptosystem.  They have
also made plans for what to do if either of them ever gets arrested: they
will do their best to incriminate someone else, so that the surviving
conspirator will have time to go to ground and continue their plans of
Alice gets picked up by the cops.  Paula Prosecutor interrogates her. Alice says, "my co-conspirator was Jerome Baum."  This is a lie, of course,
but all Alice needs to do is give the police someone to chase after for a
few days while Bob goes into hiding.  Alice has sent you some innocuous
messages through a deniable system in order to make you a good candidate
for being made their patsy.
Paula hauls you in.  "Tell us all about your role in $nefarious_crime." You tell Paula that you don't have any role in it.  "Prove it.  Show me
those messages."  Um... well, you see, it's like this: it's a deniable
system, which means there's no way I can prove or disprove ever having the
ability to read it.  Paula is *not* going to say, "oh, well then, I guess I'm out of luck." No, Paula is going to assume you're playing games and Paula's going to
start playing hardball the way only a government prosecutor can.  "Okay. In that case, we're going to have a forensic accountant crawl over your
bank accounts and tax records, have a squad of detectives crawling over
your personal life, we're going to talk to the media and name you as a
subject of the investigation, and you're going to be racking up a thousand
euros a day of legal fees.  But you can make it stop any time.  Just show
me those messages."
And when you scream, *I CAN'T DO WHAT YOU'RE ASKING ME TO DO!*, Paula will
just look at you and say, "That's not my problem."
Prosecutors play hardball.  I would much rather face a gangster in an
alleyway who wanted to get my secrets via a lead pipe than I would ever
want to face a government prosecutor.  I have better odds with the

@_date: 2011-03-22 09:01:15
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
On Tue, 22 Mar 2011 10:45:21 -0400, Scott Lambdin Why would it?  I think the obsession with key length is bikeshedding. Find a level of security that's appropriate for your needs, use that level,
and stop worrying about it.  If you're one of the (very few) who has a
30-year need for security, then yes, a 4K RSA key is useful insurance
against the future.

@_date: 2011-03-22 10:13:32
@_author: Robert J. Hansen 
@_subject: Deniability 
If the prosecutor has plaintext of the emails, it makes your claims of
innocence much easier to believe.  It's when the prosecutor cannot know
what the plaintext is that the prosecutor has an incentive to ramp up the
pressure immensely.
Not at all.  Imagine if you were using a non-deniable system, such as
plain-vanilla OpenPGP.  "This message was sent via a non-deniable system. There, see?  That's a correct signature from Alice, and it was encrypted
with my certificate.  There!  See?  She was just sending me a recipe for
potato chip dip for my Super Bowl party!"
The prosecutor is going to be afraid of what she can't see.  She has
Alice, saying you're in it up to your eyeballs: she has you, claiming
innocence: she has a bunch of messages which you say are deniable and you
can't prove anything but which Alice says "he's lying to you."  Really, I
feel sympathy for Paula: she's in a terrible spot.  Being able to present
your messages is a good way of breaking that logjam: suddenly, Paula's
wrath turns on Alice for her deceptiveness and deceit.
Not as much as you might think.  You could also say that the evidence of
disk wiping programs makes it hard for you to claim, "but I never had that
data in the first place!"  In reality, if the cops search your hard drive
and see Evidence Eliminator, they're going to strongly suspect you of
trying to destroy something important: but if the forensicist comes back
and says, "nope, no evidence he ever downloaded a file wiper," it gives
your claims of innocence more weight.
She and Bob have been overthrowing governments, committing securities
fraud, carrying on a torrid affair without their spouses' knowledge, etc.,
for a very long time, all despite the fact they've never met face to face,
they don't trust each other, and know they're under surveillance by the
secret police.
As one wag said, "a cryptographer is someone who doesn't think Alice and
Bob are crazy."

@_date: 2011-03-22 10:14:51
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
On Tue, 22 Mar 2011 16:13:03 +0000, Jerome Baum No.  Using SHA512 with a DSA-1K system is just as secure as, say, using
RIPEMD160 with a DSA-1K system.  There are no known attacks against either
hash algorithm, and when used with DSA-1K each provides 160 bits of hash.

@_date: 2011-03-22 10:50:55
@_author: Robert J. Hansen 
@_subject: Deniability 
I should add: this is tongue-in-cheek.  Please don't take it as a
recommendation, suggestion, or anything of the sort.  I used EE only for
its infamy.

@_date: 2011-03-22 11:51:24
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
On Tue, 22 Mar 2011 18:11:37 +0000, Jerome Baum If such an algorithm existed in GnuPG, then yes.  You'd need about RSA-16K
to get your money's worth out of SHA512, though.

@_date: 2011-03-22 12:05:28
@_author: Robert J. Hansen 
@_subject: Deniability 
On Tue, 22 Mar 2011 18:07:23 +0000, Jerome Baum Or just fail to respond.  If I received a message saying "the burglary
happens at 5:00am," I would be certain to have a rock-solid alibi for
5:00am, and I might even go to the police with it.
The general rule in the United States is that no one has a duty to help
the police, but there are a lot of caveats.  There's a fine line between
"no duty to help the police" and "accomplice to a crime."
In the United States there are several different thresholds for evidence. Simplified a lot, there are the kinds of evidence the police can use to
justify investigating you, and the kinds of evidence that can be offered in
court to convict you.
If the police have cause to investigate you and they see a counterforensic
tool on your hard drive, that can be justification for further
investigation -- in exactly the same way that if I was being investigated
for murder and they discovered I owned the exact kind of weapon that was
used in the killing, that fact could justify further investigation.
However, the fact you had a counterforensic tool, *by itself*, would
probably not rise to the level of something that would be admissible at
trial -- the same way that, if I was charged with stabbing someone to
death, the fact I own a shotgun would be inadmissible.  There would need to
be evidence of it being used unlawfully, like for instance, evidence
Again, this is extremely quick and dirty.  The Federal Rules of Evidence
are big, confusing, clunky, ungainly, and difficult to understand.  If
you're concerned about United States law regarding the admissibility of
evidence, you really need to consult with a lawyer.

@_date: 2011-03-22 12:16:08
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
On Tue, 22 Mar 2011 19:08:56 +0000, Jerome Baum There may be particular users who have reasons not to use RSA-2K, but as
far as general advice goes, I don't see any reason to go beyond RSA-2K.  If
someone breaks RSA-2K it will be via a breakthrough of such Gaussian
proportions[*] that our proper response will be to migrate to different
schemes altogether, not to tack on another few bits and consider ourselves
safe.  If you're concerned for 30+-year security and you have to use RSA and you
can't use anything else, then yes, use the largest RSA key you can find. The rest of us are better suited by realizing "if RSA-2K ever falls we
should move for the exits, regardless of how large our keys are."
[*] Yes, it's a _Sneakers_ ref.  Seemed appropriate, given the talk of
breaking RSA...

@_date: 2011-03-22 12:20:59
@_author: Robert J. Hansen 
@_subject: Deniability 
On Tue, 22 Mar 2011 19:14:20 +0000, Jerome Baum Several of them.  In all cases I'm aware of, it was alleged the
individuals were using OpenPGP to conceal their activity in a crime. Covering up a criminal offense is, itself, almost always a criminal
offense.  If the government alleges, "this person used OpenPGP to cover up
the crime and make life difficult on the FBI," the government must do two
things: (a) enter into evidence the fact the accused has access to OpenPGP,
and (b) convince the jury the accused used OpenPGP in an attempt to foil a
police investigation.

@_date: 2011-03-22 12:55:20
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
On Tue, 22 Mar 2011 19:33:33 +0000, Jerome Baum I've never said there is *no* reason to ever go past RSA-2048.  There
clearly are special cases where more is necessary.  However, for the
overwhelming majority of users I see no reason to go past RSA-2048.

@_date: 2011-03-22 12:57:11
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
On Tue, 22 Mar 2011 15:43:23 -0400, Lists.gnupg at mephisto.fastmail.net
Or, one can say as I do, "unless you know what you're doing and why, stick
with the defaults."
I would much rather skip all discussion of key lengths and have people
just use the defaults unless they know for a fact the defaults are
insufficient for their purposes.  Then move on to, as you say, more
important considerations.

@_date: 2011-03-22 16:56:56
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
No.  As I said, large default keys have problems in the embedded space:
particularly, they do not work with smart cards, which are getting
increasingly important.  The previous generation of cards were generally
RSA-1K devices.  The current generation is moving towards RSA-2K.
I don't think changing the defaults to something that's incompatible
with smart cards is particularly wise.

@_date: 2011-03-22 17:23:46
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
Not really.  A 3K key is roughly a factor of 50,000 times harder to
brute force.  This is such a slender improvement that it's really not
worth talking about.  If 112 bits of effective security aren't enough
for you, it's quite likely the 128 bits of effective security provided
by RSA-3K aren't enough for you either.
Honestly, I see more sense in RSA-15K than I do in RSA-4K.

@_date: 2011-03-22 17:30:56
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
Simplicity.  Otherwise you get a ton of people screaming, "GnuPG only
lets me generate a 2K key on my smart card!  The default is *4*K!  Why
am I getting only half the bits that GnuPG thinks I need to be safe?!"
And yes, those questions would occur.  Lots.  In order to reduce
confusion, 2K keys seem to be the best bet.  They are safe enough for
the overwhelming majority of users, are the most compatible with
embedded devices, and cause the least confusion.
This is a rudely-phrased question.  I either have to grant that you are,
or have to say that you're not smart enough to ignore the default.
I am going to ignore this question and tell you: unless you need 30+
years of security, use the defaults.  They're defaults for a reason:
they're perfectly sufficient for the overwhelming majority of uses.
Stop trying to justify putting an additional foot of height on your
10,000-foot fence, and start thinking about the folks who are trying to
tunnel underneath it.
And honestly, that's all that I have to say on this.

@_date: 2011-03-22 17:52:39
@_author: Robert J. Hansen 
@_subject: Deniability 
And in the context of that conversation it was clear that there was, in
fact, something illegal to hide.  Quoting: "if the government alleges,
'this person used OpenPGP to cover up the crime...'"

@_date: 2011-03-22 18:18:47
@_author: Robert J. Hansen 
@_subject: 4096 bit keys 
You have to add one bit to your *effective* key size.  Remember, the
primes are not evenly distributed: the larger you go, the more they are
spread out.  This is why for very small keys each additional bit gives
you quite a lot of security, but as keys grow very large more and more
bits have to be added to get that additional boost.
As an example, there are 25 primes under 100: of all the possible
values, you have to check 25% of them.  But there are only 78,498 primes
under one million: you only have to check 7.9% of those numbers.
You might want to look into the General Number Field Sieve (GNFS), which
is a much more efficient way of breaking RSA keys than by simple trial

@_date: 2011-03-22 19:18:11
@_author: Robert J. Hansen 
@_subject: Deniability 
This is cheap ad-hominem.  I said nothing of the sort.  If the
government *alleges* that you *committed a crime*, the government needs
to enter into evidence *how you committed that crime*.
If the crime is evidence spoilation, then yes, the government can enter
into evidence the fact you possessed the tools required to spoil
evidence.  It doesn't mean you're guilty of evidence spoilation: it only
means the jury might find that fact to be interesting and relevant, and
for that reason it should be presented to them.
If I'm accused of stabbing someone to death, the government gets to
enter into evidence the fact I own a knife exactly like the one they
allege was used to murder someone.  This is no different.
I honestly do not understand where you're coming from.  It seems as if
you're deliberately trying to twist around what I'm saying.

@_date: 2011-03-22 19:29:00
@_author: Robert J. Hansen 
@_subject: 4096 bit keys 
Do you have a cite for that?  I know ECC is approved, but I've never
been able to find confirmation one way or another that ECC is the *only*
publicly-acknowledged asymmetric algorithm approved for TS.  Any
heads-up you could give would be appreciated.

@_date: 2011-03-22 19:51:36
@_author: Robert J. Hansen 
@_subject: 4096 bit keys 
No moreso than many other algorithms.  If the algorithm says "this value
must be random" and you don't use a random value, then yes, you're going
to have a very bad day.
ECC is being introduced into the OpenPGP standard.  Pretty much everyone
in the working group wants it to be added: they just want to make sure
it gets added in the right way.
I'll eat my own hat if PGP Corporation doesn't already have an internal
testing branch that supports ECC.

@_date: 2011-03-22 22:23:06
@_author: Robert J. Hansen 
@_subject: Deniability 
Yes: it's a tautology.  A prosecutor is not allowed to make an
allegation in court for which they do not have evidence.  If the
prosecutor says, "this person used OpenPGP to hide evidence of his
crime," the prosecutor must be able to present the spoiled evidence and
demonstrate it was connected to a crime: otherwise that allegation is
barred from the courtroom.
How that evidence should be interpreted, how much weight it should be
given, etc., is solely the purview of the jury.  But if the government
says, "this person used a bloody knife to murder someone," then yes,
that's evidence there's a dead body that was killed with a knife,
because otherwise no judge would allow the prosecutor to make that claim.
It's everything-the-government-does-is-evil claptrap that I have no
patience for.  I am no particular fan of the government, but to think
that it would so nakedly act in such a way is ridiculous.
To repeat what I told you earlier: *there was no such trial*.  This is
an urban legend in the community.  No one has ever been able to produce
a citation for me.  I've asked, quite a lot of times, and I've done my
own digging in Westlaw trying to find it.  To the best of my knowledge,
it doesn't exist.  What exist instead are different trials for evidence
spoilation and related charges, in which the defendant's possession of
those tools is directly related to the charge.

@_date: 2011-03-22 22:34:27
@_author: Robert J. Hansen 
@_subject: Deniability 
I think the best counterargument to this is that it's very easy to come
up with massive invasions of privacy that really do little to nothing
for our security.  The airport security examples more or less write
My own dark suspicion is that what we have always thought of as
"privacy" is nothing more than an inefficiency in information exchange.
 So long as information exchange has a certain cost threshold, it's not
worth my time or effort to share information about you.  As that cost
threshold diminishes, so too does our privacy.  If it cost a penny to
leave a YouTube comment, Rebecca Black would have twelve people
scattered across the world who had said something bad about her.  Since
it's free, though... well, she has no privacy anymore, and I feel very
sorry for her.
If I'm right, then the only way to restore privacy is to raise the price
of information transfer in some way.  OpenPGP can be thought of as this:
to recover a message the attacker has to undertake actions that involve
at least some measure of expense.

@_date: 2011-03-22 23:11:46
@_author: Robert J. Hansen 
@_subject: Deniability 
> Wasn't there that case where the fact that someone ...
        > had some OpenPGP implementation on their computer was
        > admitted into a US court and appeals didn't overturn
        > that admission?
        In all cases I'm aware of, it was alleged the individuals
        were using OpenPGP to conceal their activity in a crime.
        Covering up a criminal offense is, itself, almost always a
        criminal offense.
Written today.  I've done a fair bit of digging into this: no such case
has ever been presented in a United States court.  The case you cited
below was not a United States court: it was state court.
The phrase, "a United States court" means, "a court operating under
federal law passed by Congress."  The phrase, "a state court" means, "a
court operating under state law passed by a state legislature."
I suspect you meant, "a court somewhere in the United States," which
could mean either.
Imagine this: I'm being accused of premeditated murder.  Apparently, I
ran over a man with a car with the specific intent of killing him.  When
the police arrest me, they discover in my apartment I have a sniper
rifle, a hangman's noose, a straight razor, some food that has ground
glass mixed into it, and a how-to manual for committing murders with all
of those tools.  (Note that generally speaking none of these are illegal
in the United States.)  The state wants to enter all of those things
into evidence to support the claim that I committed my crime with
extreme premeditation, that I had the specific and deliberate intent to
Under your theory, that should be barred.  Me, I think that's kind of
weird.  Seems to me like this is the sort of thing the jury should be
allowed to hear and decide for themselves.  Likewise, in this case the
prosecution was alleging something.  The judge believed -- and the
appellate court agreed -- that the presence of PGP was relevant to those
If you don't know what specific fact this evidence was presented to
demonstrate, then you can't say the evidence shouldn't have been
admitted.  We know it was connected to a criminal trial, but we don't
know specifically what the evidence was introduced to prove.  It
could've been something as simple as, "the defendant is technically
sophisticated, as evidenced by...".
I can't argue against this.  This is your emotional reaction to the
situation, and nobody can argue against emotions.  All that I can say is
that, as a matter of law, the decision makes sense and seems rational.

@_date: 2011-03-22 23:13:44
@_author: Robert J. Hansen 
@_subject: Deniability 
Unlikely, but you're kind to say so.  I'll be happy if my mistakes can
just be interesting.  :)
This is very good: I need to think on this.  May I borrow this and
present it to others (with attribution)?

@_date: 2011-03-23 01:02:31
@_author: Robert J. Hansen 
@_subject: Deniability 
Except that *you don't know what that was entered to prove*.  It's quite
possible it was not entered to prove he molested a child.  If I was a
prosecutor, I'd want to argue that he was technically proficient, and
enter the existence of PGP to support that claim.
If the jury then decides, "well, he had PGP on his hard drive, therefore
he's probably guilty," then that's the jury being idiots.  That doesn't
mean the U.S. system is unjust: every nation with a jury system has to
deal with juries being idiots.
The fact he used PGP was entered into a trial about the abuse of a
child: but that doesn't mean that fact was entered into evidence to
prove he abused the child -- it could have (and quite likely was)
entered for something else.  Unless you're looking at the court record,
you don't know.
Because it means four judges, who were quite likely appointed by
different governors and have different political beliefs, came to the
same opinion about the law.  When four judges who don't like each other
and squabble constantly unanimously say, "the law says this," well, I
tend to give that a lot of credit.
I can't talk about the Minnesota state courts: I haven't studied their
system.  At the federal level, appellate judges give the trial judge's
decisions a great deal of deference when it comes to findings of fact --
the rule of thumb is a factual finding must be "as offensive to the
senses as a three-day-old mackerel" for a factual finding to be
overturned -- but zero deference for findings of law.  Literally, zero
You're asking me to demonstrate psychic powers by telling you about a
transcript I haven't read.
However, as a guess, Minnesota may very well have an enhanced penalty
for the use of counterforensic software and/or encryption in the
commission of a crime.  That's an example of something that wouldn't
have any effect on whether the accused committed the abuse, but would be
relevant to how harshly he was sentenced -- and it could be entered into
evidence on those grounds.
That's just a guess.  There are many, many, *many* other ways it
could've happened.

@_date: 2011-03-23 15:32:16
@_author: Robert J. Hansen 
@_subject: Deniability 
I grew up in a small town of under 5,000, where the nearest city of more
than 20,000 was an hour's drive away.  Forget "a hundred years ago":
having been back there recently for a funeral, I can tell you small
towns are still that same way today.
In a sense, I think this validates my thesis.  In a small town the cost
of sharing information about people within the town, to people within
the town, is just about nil: you wind up having these conversations
while you're at the service station filling up your tank, when you're in
line at the grocery store, when you're ... etc.  But having these same
conversations with people outside the town involves effort, which in
turn means that you can travel 100 miles and be reasonably confident
nobody there has heard of you.
I agree that the small-town phenomenon argues against the idea of an
idyllic privacy past.  I just think modern communications means the
entire world is turning into a small-town phenomena.

@_date: 2011-03-23 17:17:10
@_author: Robert J. Hansen 
@_subject: what are the sub keys 
Some do, yes: but your citations don't seem to support that.  NIST says
that for unclassified purposes, 112 effective bits of security is enough
until 2030 (page 65).
Your ECRYPT ref says 80-bit keys are secure until 2012.  128-bit crypto
is defined as "long-term security", for three decades or more (page 32).
Given most people stipulate the need for longer keys for multi-decade
use, I don't see that the authorities you cited suggest "best practice"
is to use, effective today, 3072-bit keys to provide 128 effective bits
of security.

@_date: 2011-03-23 19:11:40
@_author: Robert J. Hansen 
@_subject: Deniability 
Perhaps that should be taken as a good reason for people who are not
familiar with courts in the United States to forego commentary on how
they operate.  I don't know beans about, say, the United Kingdom court
system beyond the broadest possible facts, and so I make it a point not
to comment on the relative justice or injustice of the UK's system.
That practice has served me well so far.
Confusing a state-level court for a federal-level court is kind of like
confusing Malaysia with Uganda: they are potentially that much
different.  For instance, the state of Louisiana operates under a Civil
Law (Napoleonic) system, while the federal courts operate under the
English Common Law system.  This means the two have as much in common,
legally speaking, as the United Kingdom and France.
The rest of the world tends to massively underestimate the amount of
judicial diversity within the United States.  We're quite a bit larger
than Europe: we also have quite a few more different kinds of legal systems.

@_date: 2011-03-25 08:59:32
@_author: Robert J. Hansen 
@_subject: Enquiries about GnuPG 
Your questions were already answered in detail a couple of weeks ago,
the last time you asked this question.  Check the archives.  You might
want to start at:

@_date: 2011-05-01 12:00:21
@_author: Robert J. Hansen 
@_subject: How to open Windows GPG encrypted files on Mac OS X 
Classic Mac OS used a CR only.  Mac OS X uses an LF just like the other Unices.  Given Classic was deprecated over a decade ago and EOLed almost that long ago, Classic can now be relegated to the dustbin of history.

@_date: 2011-05-04 23:34:16
@_author: Robert J. Hansen 
@_subject: Storing secrets on other people's computers 
For the better part of a decade now I've volunteered to publish my private certificate in the _New York Times_ if someone will pay for the advertising space.  With a strong passphrase that's not known to anyone else, the private certificate is about as safe as can be.

@_date: 2011-05-05 01:32:28
@_author: Robert J. Hansen 
@_subject: nothing so dramatic 
That court's opinion was predicated on the fact Boucher had already waived his right against self-incrimination, and for that reason there was no constitutional violation.  It's sort of like testifying in court: the government can't force you to testify in your own criminal proceeding, but if you waive that right the government can cross-examine you.  Likewise, if you *voluntarily give the government your child porn*, you can't really claim that "I'm not going to provide the government with copies of that child porn, because that would incriminate me."
_Boucher_ is nowhere near the death knell for privacy that some people seem to think it is.
(ObDisclosure: a couple of years ago I helped prepare a law review article on _Boucher_.)

@_date: 2011-05-05 07:11:05
@_author: Robert J. Hansen 
@_subject: Storing secrets on other people's computers 
The instant a test costs someone money, they have a financial interest in
making sure the test is accurate.  This increases the credibility (to them)
of the results.  Or, put another way, if I do it for free few people but me
will be convinced.
If I for a second thought that by posting my (well-secured!) private
certificate to the Net I could convince people of the effectiveness of a
good passphrase, I'd do so.  But I'm just skeptical of people's willingness
to accept evidence they get for free.

@_date: 2011-05-05 18:43:47
@_author: Robert J. Hansen 
@_subject: Storing secrets on other people's computers 
You're the one who's talking about basic economics, so let's apply some:
You want me to put my own money at risk (an incredibly small risk, yes, pretty close to epsilon: but not a zero risk) in order so other people can feel better about their GnuPG installations -- but not *you*, since you're apparently already convinced.
Makes perfect sense, economically speaking.  You don't bear the risk, so you have no incentives to consider -- much less accept the existence of! -- the downsides.  From my perspective, I have incentives to think about the downsides (including the drama downside: see below), and I think you're crazy.
First, I didn't say it.  Daniel said it.
Second, there is a contra: a good number of people will accuse me of pulling a stunt that really proves nothing, that a 64-character random hexstring password is orders of magnitude better than what people use in the real world, that it's a completely unrealistic test, etc.  And then, of course, there will be the people who will tell these people, "but that's not what he was claiming, he was only claiming that *with a good passphrase* it's safe."  And then there will be the people who are keeping quiet, rolling their eyes, and wondering why, why, why, I felt the need to open such a can of dramaworms.
In fact, I suspect there are already people *right now* who are rolling their eyes and wondering why I opened such a can of dramaworms.  In deference to them, I'm going to say nothing further about it.

@_date: 2011-05-05 18:46:29
@_author: Robert J. Hansen 
@_subject: Storing secrets on other people's computers 
Because the _New York Times_ keeps records of all the papers it's ever published.  It can be seen as a highly effective, if low-tech, long-term archival solution.  Paperkey the private certificate, publish it in the NYT, verify the accuracy of the published certificate, and presto: your key is archived for the next 100+ years.
Honestly, half the reason why I volunteer to publish my certificate in the NYT is for precisely this reason.  I think it'd be kind of cool to (a) have the NYT be my data archive, and (b) get someone else to pay for it.  :)
(Assuming, of course, the NYT survives its current financial problems.  Which may be a very big if.)

@_date: 2011-05-05 19:43:32
@_author: Robert J. Hansen 
@_subject: Storing secrets on other people's computers 
Space.  I'm perfectly happy to sell you a cubic meter of space somewhere within a lightyear of Betelgeuse.
Before anyone thinks I'm being sarcastic, I'm not.  That's a frank and honest answer to the question.  For something to have zero theoretical cost, it must be available in effectively infinite supply or else have no competing uses to which it can be put.  A cubic meter of space near Betelgeuse meets both criteria: there's an incredibly mind-bogglingly huge supply of them (about 4.45 times 10**47 of them), and there's really nothing you can do with them (since first you'd have to get there).  Effectively infinite supply, zero competing purposes, equals a cost as close to zero as I know how to make.
Sometimes people talk about how "the best things in life are free," but these people have obviously never courted someone.  In my life I've chased a couple of women around and have the credit card bills to show for it.  Likewise, the love of your kids may be free, but saving for college costs a *fortune*.

@_date: 2011-05-05 19:48:07
@_author: Robert J. Hansen 
@_subject: Storing secrets on other people's computers 
Only if you assume that I meant "for free" as in "without cost to myself" -- which, as I hope my other message showed, is not what I believed to be true: there are downsides, not least of which being the potential dramaworms.  There I meant "for free" as in, no cost that I can see other people incurring (perhaps because I have no incentives to consider those potential costs).
Freedom from price is a subjective phenomena.

@_date: 2011-05-05 20:19:55
@_author: Robert J. Hansen 
@_subject: OT: Economics (was: Storing secrets...) 
Necessarily there must be.  Free trade depends on value differentials, after all.  If I have a candy bar that I think is worth $1, and you have $1 that you think is worth a candy bar, I keep my candy bar and you keep your money.  Neither of us has any incentive to make a trade: stasis results.  If I think the candy bar is worth $0.99, and you have $1 that you think is worth a candy bar, we're going to make the trade because it's in both of our interests to do so.
If both parties agree on the true value of something -- no matter what that value is -- trade doesn't happen.  For you to buy my cubic meter of space somewhere near Betelgeuse, even if I value it at nothing, you must value it at something.  And, as you've said, the prestige of owning a cubic meter of space near Betelgeuse might be worth an awful lot.

@_date: 2011-05-06 08:54:44
@_author: Robert J. Hansen 
@_subject: I'm looking for a very beginnerfriendly gpg 
You're in the right place, never fear.  There are a lot of people here who are happy to give you all manner of advice, but before we can begin we need a little more information.  :)
We need to know a little about your use case.  How do you plan on using GnuPG?  Will you be using it to encrypt your local files, will you be using it to encrypt emails?  Etc., etc.

@_date: 2011-05-07 14:56:37
@_author: Robert J. Hansen 
@_subject: Best practice for periodic key change? 
Nothing.  That's the nature of physical signatures.
A physical signature binds tightly to the individual (handwriting being
hard to forge), but loosely to the document.
A digital signature binds loosely to the individual (certificate
repudiation being pretty easy), but tightly to the document.
This is one of the reasons why I generally dislike the way the word
"signature" gets abused in these discussions.  Comparisons to physical
signatures inevitably arise, and the two of them seem quite a bit more
dissimilar than alike.

@_date: 2011-05-07 22:21:41
@_author: Robert J. Hansen 
@_subject: Best practice for periodic key change? 
Within the U.S., the standard doesn't involve signatures /qua/
signatures.  It involves making a mark on a document to express your
will.  A contract signed with a simple mark of "X" is still legally binding.
There's some hoary old story that was, once upon a time, taught in law
schools: but Dad went through law school fifty years ago, so maybe it's
fallen out of fashion.  It involved a lawsuit brought against a bank by
two farmers (in Vermont, I think).  The first farmer owed the second a
quantity of money, so the farmer picked up a grease pen and wrote on a
pumpkin, "Pay this man $10 from my checking account."  The second
farmer took it to the bank.  The bank refused to honor the check.  The
two Vermont farmers were too stubborn to budge: it was a valid legal
document and no rich banker was going to tell them otherwise.  The bank
refused to budge: if a *pumpkin* can become a valid check-writing
instrument, what will that do to their bookkeeping process?
The trial court ruled in favor of the farmers.
(Warning: secondhand information passed on from a source recalling a
story he heard fifty years ago.  I'm led to believe the legal principles
involved are still accurate in today's legal climate, but time and
memory may have made this story a bit apocryphal.)

@_date: 2011-05-16 11:50:19
@_author: Robert J. Hansen 
@_subject: Why is "--allow-non-selfsigned-uid" needed to import this 
This is exactly what it sounds like: according to your certificate, it was
created about five and a half months from now.[1]  To GnuPG, that sounds
like something's hinky and it refuses to allow it to be imported.  You've
managed to get around it by telling GnuPG, "listen, fine, strip off the
hinky signature: /now/ will you accept it?"
And in that case, sure, GnuPG will: but the consequence of it is you've
got a UID that's missing a signature.  Hence, "allow-nonselfsigned-uid"
must be passed on the command line.
[1] As an undergraduate Prof. Hill once mused to me, "Math is funny.  You
tell someone how many seconds are in a year, they forget it immediately. You tell them that accurate to half a percent there are pi seconds in a
nanocentury and they remember it for life."  He was right, I've never
forgotten, and that's made it easy to remember there are 31.4 million (3.14
* 10**7) seconds in a year.  13.8 million / 31.4 million = 137/314 = 0.44
of a year, * 12 = five and a half months, more or less.  Not really
relevant to GnuPG, but a handy factoid for timestamp calculations, if you
ever need to do them in a hurry.

@_date: 2011-05-17 09:13:31
@_author: Robert J. Hansen 
@_subject: can i use gnupg in commercial application ? 
The answer is, "yes, so long as you comply with the terms of Version 3.0
of the GNU General Public License."

@_date: 2011-05-17 19:58:07
@_author: Robert J. Hansen 
@_subject: An Invitation to Neuroscientists and Physicists 
There are two major possibilities here: either the poster is correct, or
the poster is incorrect.  If correct, he deserves our compassion for the
troubles others are inflicting upon him.  If incorrect, he deserves our
compassion for the troubles his own mind is inflicting upon him.
Either way, let's show a little polite discretion.  Thanks.  :)

@_date: 2011-05-24 19:47:30
@_author: Robert J. Hansen 
@_subject: Installing new version of gpg 
No forgiveness necessary.  Simple, straightforward questions are always
nice.  :)
It's hard to say definitively without looking at your particular system.
That said, speaking generally this will work fine.

@_date: 2011-05-26 09:17:27
@_author: Robert J. Hansen 
@_subject: Installing new version of gpg 
It's hard to give concrete answers without seeing your particular
installation, so please consider these to be semi-educated guesses
rather than things I know to be correct.  :)
No.  You never launch these directly: GnuPG launches them -- and GnuPG
knows where they're located.
Well, the GnuPG you have in /usr/local no longer needs them -- but it's
possible other software you have in /usr/local relies on it, so I'd
suggest keeping them until/unless you know for a fact nothing else needs it.
Don't need to worry about them.  I'd keep them, myself, but if you
delete them it won't impair GnuPG's functioning.

@_date: 2011-11-08 10:06:38
@_author: Robert J. Hansen 
@_subject: Why is there a subkey and a selfsig in a new key? 
IIRC, it was a response to laws like the United Kingdom's RIPA which
allows the authorities to demand encryption keys from users.  By
separating encryption and signing into separate subkeys, and making the
signing subkey the 'master' one, it allows users to divulge encryption
subkeys to the authorities when required, then immediately revoke those
encryption subkeys and resume encrypted communications with others.
I may be in error.

@_date: 2011-11-17 15:31:04
@_author: Robert J. Hansen 
@_subject: GPA File Manager 
If this was a public mailing list, I'd agree with you.
This mailing list is owned and operated by private citizens.  We're
guests in someone else's home, and that someone else has established
rules.  The courteous thing to do is to abide by those rules, to the
extent we can do so without running afoul of our own moral code.
Saying, "please do not recommend proprietary software" is not a rule
that gives me the moral heebie-jeebies, so I'm happy to comply with it.
No: *you* would call them intolerant and freedom-of-choice-denying.
Please be careful about making universal statements about what the world
in general would say: the world generally does not conform to our
Do you feel you have the right to stand in the middle of an Audi
dealership and loudly extoll the praises of the Peugeot?  Or would the
dealership owner be within his rights to tell you, "look, I'm very happy
you love the Peugeot RCZ, but you need to take your advocacy of it
somewhere else"?

@_date: 2011-11-17 21:31:31
@_author: Robert J. Hansen 
@_subject: GPA File Manager 
Speaking generally, in English saying something is a "public so-and-so"
means it belongs to the public, not that it is open to the public.  The
opposite, a "private so-and-so," means it belongs to an individual or a
company.  There are exceptions, of course, but this is the general rule.
 I hope this helps.  :)
But that's not what the rule is.  The rule is against *recommending or
encouraging the use* of proprietary software, the same way that in an
Audi dealership you might be forbidden from recommending or encouraging
the use of Peugeots.  The remark that caused the reminder about the rule
was someone advising to look at GPGShell, that it would do everything
they needed and more.  That's not mentioning GPGShell: that's
recommending it.
I can tell you from personal experience I've mentioned proprietary
software here before without running afoul of the rules.  For instance,
"what are the major differences between GnuPG and PGP?"  PGP is a
proprietary piece of software, but since I'm not encouraging the use of
PGP no one really cares.  It's the same way that in an Audi dealership I
might be allowed to ask, "so what's the difference in performance
between an R8 and an RCZ?"

@_date: 2011-11-18 14:07:50
@_author: Robert J. Hansen 
@_subject: GPA File Manager 
Is it really irony at all?  The GPL itself restricts freedom for the
purpose of preserving freedom.  Discussion restrictions seem like a
natural extension: GPLism introduced to the world of written discourse.  :)
(No license flamewars, please: I'm not making any normative statements
here.  I'm just pointing out that such restrictions are not unexpected
given the chosen licensing of GnuPG.)

@_date: 2011-11-21 08:59:10
@_author: Robert J. Hansen 
@_subject: SCR3340 CardReader 
I've not had this problem on any of Fedora 15/x64, Win7/64 or OS X.  I
can't comment re: Ubuntu, though.

@_date: 2011-09-30 22:11:17
@_author: Robert J. Hansen 
@_subject: kernel.org status: establishing a PGP web of trust 
Before people panic, there are no known weaknesses in DSA.  The SHA-1
hash algorithm has some severe problems, but there's nothing in DSA that
requires the use of SHA-1: you can replace it with any 160-bit hash.
Let's not panic, and let's not migrate away from DSA without good
reason.  :)  Migrate away from SHA-1, sure, but DSA is fine.

@_date: 2011-10-01 16:46:55
@_author: Robert J. Hansen 
@_subject: kernel.org status: establishing a PGP web of trust 
This is an argument against having a *bad* DSA implementation, in the
exact same way you shouldn't use a bad RSA implementation, either.  RSA
has just as many warnings -- take a look at how many times PKCS has been
updated to reflect new understandings of RSA's risks.
That's the same level of paranoia that led to Kurt Goedel starving to
death because he was afraid of how everyone around him was trying to
poison him.  I don't think we should recommend that level of paranoia.

@_date: 2011-10-03 06:12:12
@_author: Robert J. Hansen 
@_subject: kernel.org status: establishing a PGP web of trust 
He did, until he ran out of food.  Then he was literally too paranoid to
leave the house to buy groceries.
Clinical paranoia is a brutal mental illness.

@_date: 2011-10-05 07:17:42
@_author: Robert J. Hansen 
@_subject: restoring SmartCard key with off-card copy 
"Never" is one of those words that's best used sparingly.
This is one particular purpose of cards.  It is not the sole purpose.
In my daily work I walk from one lab to another to another.  Some of
these labs have trusted hardware on trusted networks.  Others have
untrusted hardware connected to untrusted networks.  On the trusted
networks I want my certificate there on disk, because it's more
convenient to do that than to keep reaching for my wallet every time I
need to sign something.  On the untrusted network I want my certificate
on a card, because I don't want the secret part of my certificate to
ever touch that hardware.
There are many other use cases similar to this in which it makes good
sense to have certificates on hard drives as well as certificates on
cards.  I'm sure that if you think about it for a while you'll come up
with several other reasonable scenarios.

@_date: 2011-10-05 10:24:17
@_author: Robert J. Hansen 
@_subject: GPG with SMP? 
Short version: wouldn't do you any good even if it did.
Long version: CTAK encryption isn't parallelizable: encrypting block N
successfully depends on successfully encrypting block N-1, which in turn
depends on successfully encrypting block N-3, and so on.  There's no way
to partition it into independent subproblems.  A clever hack lets you
parallelize decryption, but even then it's probably not worth it -- the
amount of time spent doing disk I/O will be multiple orders of magnitude
larger than the amount of time decrypting.

@_date: 2011-10-05 10:42:58
@_author: Robert J. Hansen 
@_subject: GPG with SMP? 
I hate to say "read the fine message, please," but -- well, read the
fine message, please.
CTAK encryption is not parallelizable.  Given that's the mode used in
GnuPG, GnuPG's symmetric encryption is not parallelizable.  There do
exist some parallelizable modes, but GnuPG doesn't use them.

@_date: 2011-10-05 11:05:13
@_author: Robert J. Hansen 
@_subject: GPG with SMP? 
He sent it to both the list and me.  It arrived in my inbox before the
list pushed it out to the rest of the world.  It'll be arriving soon,
I'm sure.
Always happy to help.  :)

@_date: 2011-10-05 13:09:06
@_author: Robert J. Hansen 
@_subject: GPG with SMP? 
Goofs happen, man.  :)
Also, a note for anyone who's confused (what's CTAK? does GnuPG use CTAK
or CFB for symmetric encryption? etc.): CFB stands for "Cipher
Feedback", which is a particular mode of operation for symmetric
ciphers.  CTAK is "Ciphertext Autokey", which is the exact same thing by
another name.

@_date: 2011-10-05 13:41:57
@_author: Robert J. Hansen 
@_subject: GPG with SMP? 
Bureaucrat Conrad, you are technically correct --
        the best kind of correct!
Thanks for the catch.

@_date: 2011-10-06 14:20:32
@_author: Robert J. Hansen 
@_subject: How to use terminal to change mac-cache-ttl 
Although I think that using Terminal.app is fun, natural and sensible,
it's possible that I'm psychotic.
If you *want* to learn how to use Terminal.app, you might find it
enjoyable.  If you just want to make the darn thing work, the more you
wrestle with Terminal.app the more frustrated you'll get.
The good news is that I've put together a small Python script that will
(hopefully) make things a little easier on you.  Give me a day or two to
do more bughunting, and once it's done it should be pretty easy on you
to edit these values.
Anyone who knows both Python and OS X: please feel free to check out --
You'll need Norman Ramsey's Noweb package installed in order to rebuild
from the Noweb source, but you can also just look inside src/ to get a
pre-extracted version (named "agent-alter").  Alternately, just read the
two PDFs.  Any and all bug finds gratefully accepted.  Let's see if we
can't get something ready for this guy by the weekend.  :)

@_date: 2011-10-08 04:52:45
@_author: Robert J. Hansen 
@_subject: Is there a way to browse the GPG web of trust? 
Nobody has said sig2dot needs to be fixed.  Werner asked why the author
of sig2dot didn't use the fixed format, which is much better suited for
this sort of thing.
Saying, "I have spotted something that will someday need to be fixed,"
is not the same as saying, "we must fix it right now."

@_date: 2011-10-09 18:52:30
@_author: Robert J. Hansen 
@_subject: Why revoke a key? 
Whenever you feel the private key has been compromised.
Unfortunately, that just switches the question to "when should I
consider a key compromised?"
Depends on how strong the passphrase is.  I've often said that I'm
willing to publish my private key in the _New York Times_, if someone
is willing to pay for it.
With a strong passphrase, someone getting access to your private key
is not a big deal so long as you can guarantee they will never get
access to your passphrase.

@_date: 2011-10-11 08:27:47
@_author: Robert J. Hansen 
@_subject: Why revoke a key? 
Moore's Law.
For reference, a 40-bit key is breakable today by just about anyone, a
64-bit key is breakable today by people with access to significant
computational resources (hundreds of machines), and it's plausible to
believe fantastically wealthy adversaries can break 80-bit keys.
In 1998, EFF's DEEP CRACK exhausted a 56-bit keyspace in roughly 24
hours at a cost of $250,000.  Assuming Moore's Law holds true, that
means it could be built today with equivalent performance for about $1,000.
A 64-bit keyspace is only a factor of 250 harder: a DEEP CRACK/64 could
theoretically be made at a cost of $250,000.  An 80-bit keyspace is a
factor of 50,000 harder, more or less, putting the price of that at $12
billion, somewhere in there.
This is really rough back-of-the-envelope calculation, but it passes my
sniff test.

@_date: 2011-10-11 10:54:40
@_author: Robert J. Hansen 
@_subject: Why revoke a key? 
Not really.  Imagine if you knew his passphrase was a number, but not
how long it was.  Now he tells you, "it's a seven-digit number."
Okay, fine: you can exclude all six-digit numbers (900,000 of them), all
five-digit numbers (90,000 of them), all four-digit numbers (9,000 of
them), all three-digit numbers (900 of them), all two-digit numbers (90
of them) and all one-digit numbers (ten of them) [*].  You've excluded
900,000 + 90,000 + 9,000 + 900 + 90 + 10 = one million total numbers out
of the possible ten million.  You've reduced the keyspace by 10%.
If his passphrase has zero margin of safety, he's done something
foolish: his passphrase no longer meets his entropy requirements.  On
the other hand, if his passphrase is longer than necessary to meet his
requirements, he can afford to throw out 10% of the potential keyspace
without losing any sleep.
What he's done here is pretty much exactly what I've described, just in
a different numerical base.
Tell you what: I'll put my money where my mouth is.  The low-order bits
of the primes that comprise my private key are both '1'.  Doesn't help
you out very much, does it?  ;)

@_date: 2011-10-11 16:32:18
@_author: Robert J. Hansen 
@_subject: Useful factoid 
Accurate to 6%, there are 2**25 seconds in a year.  Worth remembering:
it makes certain kinds of computations much easier.  (It follows there
would be about 2**35 seconds in a thousand years, or 2**45 seconds in a
E.g., let's say you want to brute-force an 64-bit key on a CPU that can
do a million (2**20) attempts per second.  This requires, on average,
2**63 attempts.  2**63 / 2**20 = 2**43 seconds: 2**43 / 2**45 = 2**-2 =
a quarter of a million years.
I don't know why it took me so long to notice that: seems like the sort
of thing I should've noticed a decade ago.  It makes certain kinds of
computations so much easier.
Anyway, figured I'd throw it out on the off chance there were others who
hadn't noticed it.

@_date: 2011-10-12 16:25:49
@_author: Robert J. Hansen 
@_subject: How to use terminal to change mac-cache-ttl 
It involves editing a couple of configuration files by hand, and
requires you to be a little comfortable with the command-line, yes.
This much is true.  :)
This much is totally bogus.  :)
Laughing at COBOL is sort of like laughing at the Great Pyramids of
Egypt: it tells you a lot more about the person doing the laughing than
it does about COBOL.  Speaking just for myself, I don't laugh at apps
that have been running for five decades without a crash.
That's not for you, friend.  :)  My goal is to give you a tool you can
easily use to solve your problem.  That PDF was meant more for other
people to review and tell me, "no, you're doing it wrong, you
should...".  (And that was very much worthwhile: Werner pointed me
towards the gpgconf tool, which simplified things a lot.)
Anyway.  You might want to take a look at:
Download it, unzip it, and within there will be an OS X app called
"AlterAgent."  Double-click and you might just get the solution to your
problem.  It might also crash horribly.
*I've only tested it on my own machine.*  No warranties express or
implied, etc., etc.  If it breaks you get to keep both parts.
If you have feedback ("it's great, you're so cool!", or "my Mac is now
on fire and it's all your fault!"), please send it to me directly: don't
spam the list with it, please.  Thanks.  :)

@_date: 2011-10-13 06:30:31
@_author: Robert J. Hansen 
@_subject: Useful factoid 
Hold on a second there.  You seem to be making some extremely
unwarranted assumptions.
If I want your secret key material, I'm not going to steal your
computer.  I'm going to use an exploit to bypass your login, plant a
Trojaned version of GnuPG, and laugh all the way to the bank.
Modern-day operating systems are frightening -- terrifyingly --
insecure.  A while ago Vint Cerf estimated that about one desktop PC in
five was already pwn3d.  That's a number that keeps me awake at night.

@_date: 2011-10-13 08:14:49
@_author: Robert J. Hansen 
@_subject: Useful factoid 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
I did.  You said I have to access your computer, to try logging in
through the Internet.  I don't.  I just have to find an exploit.
Saying "my front door is locked" is great, but it's not so great when
you consider a good thief knows how to pick locks.  Against that kind
of adversary a lock isn't much of a prevention device: at best it
delays the thief by a minute.

@_date: 2011-10-13 08:44:48
@_author: Robert J. Hansen 
@_subject: Useful factoid 
At this point it seems to me you're being deliberately obtuse.  Have a
nice day.

@_date: 2011-10-13 10:22:16
@_author: Robert J. Hansen 
@_subject: Useful factoid 
Nope.  Local exploits are enough.
Take a look at the kernel.org exploit as an example.  The current belief
is that one of kernel.org's legitimate users was sshing in from a
compromised box.  That compromised box was running a keylogger.  From
that keylogger, the attacker discovered this user's login name and ssh
credentials.  The attacker then logged into kernel.org as this user and
ran a local exploit to gain root access.  The attacker dropped a
rootkit, a Trojaned ssh/sshd that was harvesting passwords, and all
other kinds of goodness.
Then, since one of the users on my box sshed in from kernel.org, the
attacker got a login credential on my box.  The attacker logged in using
this stolen credential, used a local exploit, and the next thing I know
sixdemonbag.org was rooted.
As you can guess, I'm not talking about some abstract theory here.  This
was a real attack that really compromised my web server.
People tend to grossly underestimate the risks of malware and pwnage.
We talk about it very little to almost none at all, and honestly, I
think it's the eight hundred pound gorilla in the room that everybody is
trying very hard not to notice in the hopes that if we just pretend not
to see it that it will go away.

@_date: 2011-10-17 08:29:01
@_author: Robert J. Hansen 
@_subject: How to use terminal to change mac-cache-ttl 
It will, actually: all I have to do is recompile it for Snow Leopard.
There's nothing in there that's Lion-specific.  I'll see about making a
new build within the next couple of hours.

@_date: 2011-10-17 08:59:33
@_author: Robert J. Hansen 
@_subject: use key, not passphrase, in symmetric encryption 
Other people will explain how to use various command-line options to do
what you want: me, I'm going to offer a hopefully polite correction.
Asymmetric key lengths cannot be directly compared to symmetric key
lengths.  A 128-bit *symmetric* cipher is roughly a trillion times
stronger than a 1024-bit *asymmetric* cipher: in fact, the general
understanding is that a 128-bit symmetric cipher is comparable to a
3072-bit asymmetric cipher.
You can use symmetric cryptography, driven by a passphrase and hashed
with a good algorithm, with confidence.

@_date: 2011-10-17 17:30:48
@_author: Robert J. Hansen 
@_subject: private key protection 
Smartcard and a good PIN.  That's pretty much the gold standard.  It's
not the best way (there is no 'best way'), but it's generally an
excellent place to start from.
Let's be cautious here: if using GnuPG on a Windows PC with an internet
connection is not good, then using GnuPG on a Linux machine with an
internet connection is not good, either.  Turenne once wrote, "when a
general makes no mistakes in war, it is because he has not been at it
long."  The same can be said of system administrators: when a sysadmin
has never lost a box to an exploit, it is because he or she has not been
at the job very long.
I emphatically disagree with this.
"The best way" is almost always a misnomer.  Everyone has different
needs and is targeted by different threats: what's "best" for you will
likely be very bad for someone else.

@_date: 2011-10-17 17:59:26
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
Unquestionably, indubitably, beyond doubt, *yes*.  You are assuming a
level of computer literacy that is beyond 95% of the computing public.
Remember, under 10% of the computing public knows how to use Ctrl-F to
search through a document. [*]
Speaking personally about Enigmail, I routinely get complaints about
Enigmail being broken from people who don't have GnuPG installed,
complaints about Enigmail being too hard to uninstall from people who
have never installed Enigmail (they thought that just by downloading the
.XPI the file was installed automatically), and so forth.  All of us on
the Enigmail user-help team have these stories.  I'll eat my own hat if
the GnuPG devs don't have their own.
Users aren't stupid, not by any stretch of the imagination.  Some of the
worst offenders have been obviously intelligent people who have been
extremely irate about Enigmail, on the grounds that "I'm a freaking
*physician* and I can't understand this, how do you expect regular users
to?!"  To them, all I can say is -- it's not about innate intelligence:
it's about whether you possess the skill of computer literacy.  We live
in an immensely technological society, and very few people are computer

@_date: 2011-10-17 20:27:06
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
And the answer to your question is obviously, "Yes."
As soon as you can figure out a way to do this, I'll take it seriously.
 Until then, this is magic pixie dust.
Everyone has an idea for how to do this: I've yet to see a single one
that actually stands any chance at success.  The more you make the
process automated the more fragile and exploitable it becomes.  The more
you shift the burden to people, the better your chances of resistance to
attack but the worse the learning curve and adoption rates become.

@_date: 2011-10-18 08:22:32
@_author: Robert J. Hansen 
@_subject: private key protection 
Have you looked at how GnuPG stores a keyring?  It's a sequential series
of individual keys, one octet after another.  There is no difference
between an individual private key and a keyring containing one entry.
(Note: this was true as of early in the GnuPG 1.4 days, which was the
last time I seriously looked at the code.  I'm going from a memory a few
years old here.)
What you seem to be saying is "if I steal your decrypted key, which is
to say the raw key material...".  Well, okay: but we already know that's
a game-over state, which makes your statement trivial.

@_date: 2011-10-18 09:05:23
@_author: Robert J. Hansen 
@_subject: private key protection 
A distinction that has been lost on apparently everyone here.  Please
use accepted terminology.
No, it's still a single file ("pubring.gpg", for instance, is the public
keyring).  I just can't promise that it's still a raw stream of RFC4880
I have been: your statement is trivial.
Assuming the passphrase is of high quality, that answer is *absolutely
If the attacker already has read-wherever access to memory, the attacker
can do orders of magnitude worse than steal private key material.
You're saying here, "if you assume the computer is already in a
game-over condition, then it's game-over."  Which is true, but it's also
pretty close to the canonical example of trivial.

@_date: 2011-10-18 09:14:50
@_author: Robert J. Hansen 
@_subject: private key protection 
PIN: Personal Identification Number.
The idea is the secret key material is stored on the card, not on the
PC.  The secret key material is located in write-only memory: from the
PC side, there is no way to read off the secret key material.  When you
want to sign a document the PC computes a hash of the data, then sends
the hash to the card.  The card tells the PC, "ask the user for their
PIN number to unlock my secret key."  The PC gets the user's PIN and
sends it to the card.  If the PIN entered is correct, the card signs the
hash and returns back a signature.
Let's say your PC gets Trojaned.  An attacker can replace the GnuPG
binary with a Trojaned version that will capture the PIN, sure, but
there is literally no way for the Trojaned GnuPG binary to capture the
secret key material off the card.
I'm not saying it's safe.  Safety is, at best, a relative term.
However, this is generally accepted to be as safe an option as any, and
safer than most.
The card disallows any external read access to the secret key material.
Check your assumptions, friend.  ;)
USB sticks make great malware vectors.  Just ask any Iranian nuclear
scientist.  :)

@_date: 2011-10-18 09:19:25
@_author: Robert J. Hansen 
@_subject: private key protection 
This ain't EUROCRYPT or FINANCIAL CRYPTOGRAPHY.  If you're reading
professional journals that are talking about crypto in purely
mathematical terms, then yes, 'key' means that.
However, in the context of OpenPGP and its predecessors there's about 20
years of precedent for using 'key' to reference the collection of
subkeys, user IDs, user attributes, signatures, and so on.  This goes
back all the way to the early 1990s.
Arguably we should be using 'certificate' to describe keys, but
honestly, that's a losing battle: the community's inertia on the subject
of 'key' is immense.

@_date: 2011-10-18 09:49:59
@_author: Robert J. Hansen 
@_subject: private key protection 
I'm going to keep this as short as possible, because we've already hit
the point at which we're casting far more heat than light.
GnuPG depends on you having physical control of the hardware for the
duration of your use of the system.  If this fails, then there's nothing
GnuPG -- or anything, for that matter! -- can do to keep your secret key
material safe.
If I put my secret key on a system that is later compromised, I can
still be confident in the security of my secret key.  If I log into that
machine and use my secret key even once, though, that key needs to be
considered compromised because I've failed to uphold the absolute
prerequisite for GnuPG usage: control of the hardware during my
interaction with it.
Secret key material can only be compromised in two situations: either
(a) someone you don't trust has root on your system while you're using
GnuPG, in which case it's a game-over and the only defense is "well,
don't do that, then!", or (b) someone compromises your PC while you're
not using GnuPG and steals your private key.
(a) is true, but it doesn't lead anywhere useful.  That makes it
trivial.  Why are we even discussing a triviality?

@_date: 2011-10-18 12:18:57
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
As a data point from 2005:
I was teaching computer literacy at the University of Iowa.  The first
day of class I asked the 35 students which of them brought a computer of
any kind to class.  Three people raised their hands: they all said they
brought laptops.  When I asked how many brought cell phones, all 35
raised their hands.  The only people who thought cell phones were
computers were the three who brought laptops.
I then asked if a game console (XBox, Playstation, take your pick) was a
computer.  The class was almost evenly split: half said yes, on account
of how you could surf the web with it.  Half said no, because you can't
write a Word document with it.
Admittedly, this is not a representative sample of college students.
That said, I think it's an informative anecdote.

@_date: 2011-10-19 16:55:06
@_author: Robert J. Hansen 
@_subject: private key protection 
At this point we're throwing conjecture onto conjecture.  If the offline
one happened to be a PowerPC architecture running Yellow Dog Linux, then
the first bit of malware would have to target Windows/x86, the second
would have to target Linux/PPC, and that's even *more* unlikely to be a
common case, and oh, don't forget if we're actually... etc., etc.

@_date: 2011-10-19 18:04:29
@_author: Robert J. Hansen 
@_subject: private key protection 
As an example:
Three years ago I was thrown into a week-long sink-or-swim course on
malware analysis, taught by an instructor who was a principal scientist
at a company that's a big name in that field.  (Due to the subject
matter of this story, I am not allowed to give names: they don't want to
be publicly associated with this story.  You'd recognize the company
name if you heard it, though.)  The first thing we did was crack our
cases to verify that our machines had no network cards.  While we were
doing this, the instructor entertained us with a funny story about why
we were doing this.
A couple of years before that course, a new piece of malware was
reported to the company.  In turn it was sent to the malware analysis
lab, where the instructor was the guy tasked with looking at it.  He was
running a Windows VM within a Linux environment on a computer that was
physically disconnected from the internet and had the wifi card turned
off.   He fired up IDA Pro (a popular debugger) and began studying this
boring, broken piece of malware.  Within a couple of minutes the
sysadmins noticed something wrong and killed all network access in the
building.  All signs pointed to the instructor's machine being the
source of the problem.
The malware was the work of an evil genius.  As input to a PC, it was a
bunch of nonsense that crashed hard before it could do anything.  As
input to IDA Pro, it was a carefully crafted input that hijacked IDA
Pro.  It then discovered it was running inside a virtual machine, used
an exploit to get out into the Linux environment, brought up the wifi
connection and associated with the first network it could.  Wacky
hijinks ensued.
You can find some more on this subject in "The IDA Pro Book," by Chris
Eagle.  NIST also has a brief writeup on it:

@_date: 2011-10-20 08:30:35
@_author: Robert J. Hansen 
@_subject: The problem is "motivational" 
Absolutely agreed.  Shirley Gaw, Ed Felten and Patricia Fernandez-Kelly
had a wonderful paper a few years ago, "Secrecy, Flagging, and Paranoia:
Adoption Criteria in Encrypted Email" which covers this subject.  It's
eye-opening reading, which is why I bring it up as often as I can.  :)

@_date: 2011-10-20 11:52:08
@_author: Robert J. Hansen 
@_subject: The problem is "motivational" 
"Only he who attempts the absurd is capable of achieving the
impossible." -- Miguel de Unamuno
"He who says a thing cannot be done is expressly forbidden from
interfering with one who is doing it." -- Anonymous
I'm sympathetic to your position.  I think it's an impossible goal and
one that will never be realized.  That said, I also think it's possible
I may be mistaken, and for that reason I'm not going to attempt to
persuade smart people to stop attempting the absurd.
By all means, you should direct your energies to where you feel they can
do the most good -- but we should also respect their decisions about
where they feel their energies can do the most good.  :)

@_date: 2011-10-24 11:24:40
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
Although hellfire-and-damnation preachers are a popular cultural idea,
they're really quite rare: most preachers go more for the John 10:10
angle [*].  They've found through centuries of proselytization
experience that things work better if you pitch the benefit of the
faith, rather than the hypothesized penalties if you live without it.
The relevance here should be plain: we need to pitch the benefits of
confidential and assured communications, not the hypothetical penalties
if they fail to take our advice.
[*] "I am come that they might have life, and that they might have it
more abundantly."  John 10:10, KJV

@_date: 2011-10-24 13:25:42
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
(There are two anecdotes here: the first is purely for amusement, the
latter is actually meant to be on-point.)
In an amusing aside, I just got back from lunch at a seafood restaurant.
 While I was sitting there I encountered a street preacher who was
wandering through the tables asking people if they were saved.  She (a
rare case of a woman evangelical pastor) came to my table and asked me
my opinion on homosexuality.
I blinked a few times at her.  "You're asking me?"  She repeated her
question.  "I'm eating *shellfish* while *wearing a shirt made of two
different kinds of fabric* and you're asking me what I think of
something else that's a Levitican abomination?"
Management intervened a couple of seconds later and removed the street
preacher from the premises.
I've learned my lesson: no more citing Scripture right before lunch.  :)
 The strange people you meet in downtown Washington D.C...
With respect to your question: what we offer is privacy, but most people
do not understand privacy, do not care about privacy, and would not care
about privacy even if they understood it.
During graduate school the politically-active members of the Computer
Science department were up in arms over government surveillance.
Flyers, bulletin board notices, EFF fundraising campaigns, and the like.
 Yet, when the Department required all TAs sign up for Facebook, in the
interests of "being accessible to the undergraduates," there wasn't any
outcry.  I was serving as the Area Steward for the graduate student
labor union and tried to drum up some outrage that we were being
*required* to sign up for a privacy-annihilating 'service.'  Nobody was
interested -- not even the people who had flyers on their doors
condemning Total Information Awareness and EFF stickers on their laptops.

@_date: 2011-10-25 08:54:55
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
Years ago W.D. Richter wrote a fictitious interview between the two
fictitious characters Reno Nevada and Buckaroo Banzai.  It sums up my
position quite well.
Q: You lament the decline of the great causes -- civil rights, the
antiwar movement, the war on poverty, the exploration of space -- and
the all-consuming preoccupation with the self in today's culture.  But
what gave birth to these great causes to begin with?
A: Twin utopias, unfortunately: the myth of revolution and the myth of
Q: These are myths?
A: To the extent that people believe in them as utopias, yes, which is
how they were oversold in many cases.  By embracing any utopia, we sow
the seeds of cynicism when things don't work out as advertised.
Q: Not that they've ever been tried...
A: Which is the fallacy -- that big change has to happen on an
institutional or national level.  When it doesn't, you have the
epidemic of cynicism we have today, with bean counters running the
whole shooting match under the rubric of being realists.
Q: So what do we failed idealists do?
A: First, stop being failures.  It's absurd to judge ourselves against
a scale larger than our own efforts.
I reject your premise, which seems to be that we *should* motivate
users, or that it is *possible* for us to do it.  I don't think either
one is true.  I don't think that I -- or any group of us -- has the
capability to do this, so my response to this is to let myself off the
hook for it.
Every now and again I'll meet someone who's interested in learning
about privacy and how to protect it.  I do my best to help these
people along.  That's what I can do, that's what's within my power,
that's the standard I judge myself by -- how well I do what good I can do.
It's made a world of difference in my mental health.

@_date: 2011-10-25 11:09:43
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
I disagree.  The problem with the current proposal is it offers email
providers no payoff for their work.  If it could credibly be said,
"implement STEED and you'll get 25% less spam across your network,"
email providers would be lining up around the block to participate.
As I mentioned before, most people do not understand privacy, do not see
the benefit from privacy, and even if they understood it would not see a
benefit from it.  That's the dealbreaker.  Hundreds of good ideas have
foundered on those shoals: I suspect STEED will turn out to be another.
But I hope I'm wrong.

@_date: 2011-10-25 17:17:23
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
This is what I think.  But
That's where I stand.  This is why regarding STEED, I'm pessimistic but
hopeful.  I doubt it will achieve the hoped-for ends: but I hope that
I'm wrong.  :)

@_date: 2011-10-25 17:19:23
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
[rest of message, which *lacked* a signature, elided]
Wow, that's a wacky error.  Time to file a bug report in Enigmail!

@_date: 2011-10-25 22:02:29
@_author: Robert J. Hansen 
@_subject: STEED - Usable end-to-end encryption 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
This one should be obvious: because a postcard doesn't allow you to
write much more than a Twitter post, and many times people need to
send more than a handful of characters.  In the mid-to-late '90s,
prior to the adoption of email, I was routinely sending my girlfriend
ten-page letters.  The envelope was pretty handy for keeping all those
pages together.
We keep on trotting out the envelope analogy, but perhaps we should do
some more thinking before we do that.  It doesn't appear to me to be
as advantageous to our position as we think.  The envelope gives the
letter author immediate benefits beyond just enhanced privacy.

@_date: 2011-10-28 10:33:39
@_author: Robert J. Hansen 
@_subject: MS Exchange server corrupting PGP-MIME emails 
Likewise.  Older versions of GNU Mailman have a similar bug with respect
to PGP/MIME.
I'd love to recommend PGP/MIME, I really would, but it seems there are
just too many broken MTAs out there for me to be able to do that.  The
open-source MTAs are generally amenable to bugfix requests, but as long
as MS Exchange is a dominant MTA I doubt they're going to be responsive
to requests from a niche market.

@_date: 2011-09-01 08:53:36
@_author: Robert J. Hansen 
@_subject: How to install gnupg-2.0.18 and decrypt gpg files 
You appear to have downloaded a package containing the GnuPG source code,
not the GnuPG executables.
If you go to  you will be able to download the
GnuPG executables.  These work well with Windows 7: I've used them
successfully on Win7 and Win7/64.
Good luck!

@_date: 2011-09-04 19:36:19
@_author: Robert J. Hansen 
@_subject: kernel.org compromise 
Hash: SHA256
Due to the kernel.org compromise, their sysadmin staff (H. Peter Anvin
and John Hawley) are revoking their certificates and issuing new ones.
 I just got off the phone with John: effective immediately he's using
certificate 0x2B466D9D.  It's been uploaded to the keyserver network
and is currently propagating around.
If you're depending on kernel.org GnuPG signatures for anything,
please update your certificates appropriately.

@_date: 2011-09-16 16:26:33
@_author: Robert J. Hansen 
@_subject: windows binary for gnupg 1.4.11 // compilation instructions posted 
Who's to say the one on ftp.gnupg.org wasn't tampered with?  It would be
fairly easy to make a version of GnuPG that always reported itself as
having a good signature.  (See, e.g., Ken Thompson, _Reflections on
Trusting Trust_.  David A. Wheeler had an interesting solution to
Thompson's problem, but in the main Thompson's remarks are still quite
applicable. [1])
And if you're downloading source code and compiling from source -- how
do you know the source wasn't tampered with?  A back door could be
hidden inside the code, making sure that whenever you attempted to
verify... etc., etc.
You can't.  I hate to rain on the parade, but this is simply not
achievable.  At some point you have to accept something on faith.  The
only question is what you'll accept.
In the extreme case, let's say GnuPG hosts a Windows binary and posts an
MD5 sum of it.  How do you know the MD5 sum that's posted is accurate?
Werner's signature on it is meaningless: you don't have a trusted copy
of GnuPG you can use to verify the signature.  The posted MD5 sum could
have been tampered with and you wouldn't know.  Etc., etc.
Ultimately, you have to take something on faith -- whether it's "I
believe this MD5 sum is correct," or "I believe this binary is correct,"
or what-have-you.  That initial trust decision is what bootstraps the
entire process.
If an initial trust decision is necessary, why not host your own GnuPG
binary, or link to the binary on the ftp.gnupg.org site, or...?
This is technically possible but highly daunting.  It involves opening
up a PE/COFF executable in a hex editor and looking at specific offsets
for timestamps, machine-specific identifiers, and so on -- and then
hard-coding those back to the values present in the original binary.  If
the resulting binary is bit-for-bit identical to the original, then
you've got a perfect copy.
This is generally not worth doing unless you're in some
way-beyond-the-next-level environment where you take supply-chain
assurance to crazed levels.
[1]  ... And David Shaw was the one who pointed me towards Wheeler's
paper in the first place, some time ago -- thanks.  :)

@_date: 2011-09-16 19:20:31
@_author: Robert J. Hansen 
@_subject: windows binary for gnupg 1.4.11 // compilation instructions posted 
With MS Visual Studio, or with the command-line cl.exe compiler?  The
last I heard from the Autotools fellows (Ralf Wildenhues, et. al.)
several months ago, they were really close to having a version that
would work with MS tools from within MinGW.  If this reached a usable
version, that would seem like the most obvious way to get a GnuPG
version built with the MS compilers.
My question, though, is -- why?  What do the MS compilers give us?  I
can't see any compelling reason to do this.

@_date: 2011-09-17 01:56:01
@_author: Robert J. Hansen 
@_subject: MS windows and gnupg 
Please forgive my skepticism, but -- well -- I'm skeptical.  I don't
think we've seen a single person post to this list saying "I have the
Visual Studio toolchain installed and need to build GnuPG from source,
but can't, since it's an Autotools-based build: could I get a version
that has a .sln buildfile and works with the Visual Studio compiler?"
I'm generally not in favor of making changes to codebases based on
hypothetical use-cases.  I think changing codebases to accommodate
hypothesized users quickly leads to a deterioration in overall product
Sure, but it already is.  Nobody's arguing that GnuPG shouldn't be
available to MS users.  The question is whether (a) porting to the
Visual Studio toolchain needs to be done and (b) if so, who will do it.
My answer to (a) is "no."
My answer to (b) is, "all the people I know who could do this, won't do
it, for one reason or another -- so isn't this kind of a dead letter?"
I don't share in this view, not at all.  Cross-platform build
environments are *hard*.  Even something like CMake doesn't work very
well: although CMake works well enough for UNIX platforms and MingW, its
Visual Studio solution output looks like something that shambled out of
Frankenstein's laboratory.
For a while I was stuck maintaining a codebase that was 100% ISO C++.
The codebase was clean as could be, and was quite a point of pride.
Then came the mission to "support MS," and the Autotools system compiled
out-of-the-box on MinGW: it was beautiful.  Then came the mission to
"support MS under Visual Studio," we switched to CMake, and I
immediately spent more time maintaining our fragile build environment
than I spent maintaining the codebase.
I suspect GnuPG would be in the exact same boat if it went this route.
This is why I think it's really important that there be no changes until
we hear from actual users who are being adversely impacted by the
Autotools dependency.  Let's not make things more fragile unless we've
got a clear and compelling need.
(Oh, and for the "we must support MS under Visual Studio" project?  The
users who were clamoring for VS support overwhelmingly ignored us when
we had our VS-enabled build.  As near as I can tell, a lot more people
*said* they were interested in building it under VS than ever actually
did it.  In this respect, too, I think GnuPG's experience would likely
be similar.  That's why I think we need to insist on real users with
clear and compelling needs.)

@_date: 2011-09-17 04:33:54
@_author: Robert J. Hansen 
@_subject: MS windows and gnupg 
This is why we have code signing.  Solved problem.  (You can argue that
GnuPG should distribute Authenticode-signed Windows binaries, and there
might be some merit to that argument: but the existing setup of MD5
hashes and GnuPG signatures posted for releases serves the same purpose.)
App distribution should be as an installer package appropriate for the
OS in question, which GnuPG does via NSIS.  Again, I don't see the problem.
Code distribution should be as a build environment that can be used
without undue effort by a modestly skilled programmer.  Again, I don't
see the problem with Autotools: I've yet to meet a Windows C/C++
developer who was unable to get MinGW set up, especially since MinGW
moved to a much more convenient installer model.
Oh, *hell* no.  Forgive my visceral reaction there, but whenever anyone
suggests going back to the bad old days I get a case of the flaming,
fiery heebie-jeebies.
Quoting John Calcote's excellent Autotools book:
    "Originally, configuration scripts were hand-coded shell
     scripts designed to set variables based on platform-specific
     characteristics.  They also allowed users to configure
     package options before running make.  This approach worked
     well for decades, but as the number of Linux distributions
     and custom Unix systems grew, the variety of features and
     installation and configuration options exploded, so it became
     very difficult to write a decent portable configuration
     script.  In fact, it was much more difficult to write a
     portable configuration script than it was to write Makefiles
     for a new project. ...
     In the early 1990s it was apparent to many open-source
     developers that project configuration would become painful
     if something wasn't done to ease the burden of writing
     massive shell scripts to manage configuration options.  The
     number of GNU project packages had grown to hundreds, and
     maintaining consistency between their separate build systems
     had become more time consuming than simply maintaining the
     code for these projects.  These problems had to be solved."
John is a dinosaur, in the best possible sense of the word: he remembers
the bad old days of "simple shell scripts" driving builds, and he
remembers how they turned into complex, unportable messes.  This was one
of the major driving forces behind the development of modern build
systems.  Let's not turn back the clock on progress.

@_date: 2011-09-20 16:48:53
@_author: Robert J. Hansen 
@_subject: windows binary for gnupg 1.4.11 // compilation instructions posted 
If I determine that my work PC and my home PC are both trusted systems,
and I have a single USB stick containing my GnuPG installation and
keyrings that I want to use on both, then I don't see the risk so long
as that USB stick is never plugged into an untrusted machine.
"Secure" and "insecure" seem to be a words that apply to specific uses
of technologies, rather than those technologies /qua/ themselves.

@_date: 2011-09-20 23:20:56
@_author: Robert J. Hansen 
@_subject: Verifying Encryption Algorithms 
Check a program called 'pgpdump'.  Of course, this raises the question
of how can you get a warm fuzzy that pgpdump is [i]really[/i] reporting
things accurately and ... etc., etc.

@_date: 2011-09-22 00:59:35
@_author: Robert J. Hansen 
@_subject: windows binary for gnupg 1.4.11 // compilation instructions posted 
In addition to John's offerings, don't forget Most of the GNU tools exist in native Win32 builds.  Some of them are a
bit old (e.g., their flex is 2.5.4a, current is 2.5.34, their gawk is
3.1.6 and current is 4.0.0, etc.), but they generally work quite well.

@_date: 2011-09-22 13:08:20
@_author: Robert J. Hansen 
@_subject: windows binary for gnupg 1.4.11 // compilation instructions	posted 
Also so that you're not depending on the host machine's MSVCRT.DLL.
That .DLL is often targeted by malware: it makes such a perfect place to
drop hook functions.
(Putting that .DLL on the stick is a healthy practice, not a replacement
for sane practices.  Don't plug a USB stick into an untrusted machine,
period, end of sentence: but in the event that one of your trusted
machines gets compromised, having your own copy of MSVCRT.DLL on the USB
stick may help prevent the spread of infection.  *May*...)

@_date: 2011-09-22 16:07:07
@_author: Robert J. Hansen 
@_subject: windows binary for gnupg 1.4.11 // compilation instructions posted 
Yes.  In fact, EFI/UEFI is more or less a replacement for MBRs.
EFI/UEFI is almost the first thing through the CPU's brain upon booting.
 There's probably some on-chip microcode that executes first, but
EFI/UEFI is, IIRC, the first off-CPU stuff that gets loaded and executed.
The EFI/UEFI designers went to some lengths to harden the system against
malware -- unfortunately they could only harden it, not immunize it.

@_date: 2011-09-22 16:59:12
@_author: Robert J. Hansen 
@_subject: windows binary for gnupg 1.4.11 // compilation instructions posted 
That's kind of like thinking that integrated circuits exist to run
Windows.  Windows is just one particular thing you can do with ICs, the
same way that preventing end-users from installing their own operating
systems is one particular thing you can do with UEFI.
EFI was first developed by Intel for the Itanium processor/motherboards.
 Itanium was Intel's attempt at a clean break with the past, and not
just in terms of architecture but in terms of the boot process.  It was
discovered EFI could be very useful for non-Itanium systems, and so the
UEFI standard came about -- "Unified" EFI, which was able to support a
large variety of systems.
This one's impossible to answer.  Are you in an environment where BIOS
rootkits are common?  How do you know your answer to that question is
correct?  Etc., etc.

@_date: 2012-04-05 20:20:17
@_author: Robert J. Hansen 
@_subject: failed to build a binary for version 2.0.19 please advise 
Building on Windows is explicitly not supported.  You need to build from
a UNIX environment using a cross-compiler.

@_date: 2012-04-10 10:36:42
@_author: Robert J. Hansen 
@_subject: List-packets help 
I am, of course, not Werner, but let's see if I can't take a stab at it.
All --list-packets does is take the input, in a human-unreadable format,
and transform it into a human-readable format.  It performs none of the
computationally expensive mathematics that are required to validate the

@_date: 2012-04-10 15:34:09
@_author: Robert J. Hansen 
@_subject: Incorrect send-from 
I inadvertently sent an email to these lists a bit ago from my work
email account rather than my home one.  My apologies to all who were
confused by the new email address.  I was writing in a personal
capacity, not a professional one.
Since some of these lists reject and/or hold-for-moderation posts from
unknown addresses, I'm reposting the message here:
A few weeks ago I posted a link to a report from Kyrus which called into
question the effectiveness of virtually all antivirus products.  SANS
has done their own analysis, starting from a completely different
methodology, and has reached much the same results.
The takeaway for GnuPG users is this:
        * Keeping your system malware-free is of paramount
          importance.  Once someone else controls your PC,
          it's all over.
        * AV is of very limited utility.  Nobody is saying
          not to use it, nor that it's of no use at all.
          However, at present the evidence suggests none of
          us should consider our machines safe just because
          we have AV installed and keep it up to date.

@_date: 2012-04-12 16:05:53
@_author: Robert J. Hansen 
@_subject: Current key servers 
pool.sks-keyservers.net isn't really very much of a keyserver.  It
doesn't service your requests itself.  Instead, it picks a random
known-good keyserver from the global keyserver network and proxies your
request there.  This way, load is broken up among the entire network.
As new keyservers join the global keyserver network,
pool.sks-keyservers.net adds them to its own list.  So really, that's
the only address you need.  :)

@_date: 2012-04-12 20:47:51
@_author: Robert J. Hansen 
@_subject: [new-user] question 
Turn it around.
The public and the private key are inverses.  Each can decrypt what the
other one encrypts.  When someone encrypts a message with your public
key, only your private key can decrypt it.  And if you encrypt a message
with your private key, then anyone who has your public key can decrypt it.
So if I have a copy of your public key, and it decrypts a message
successfully... then I know it was encrypted with your private key.  And
since you're the only one who has your private key, it means I can have
confidence the message came from you.
Usually this process is called "signing" a message.  This is how
signatures work.  :)

@_date: 2012-04-16 01:59:59
@_author: Robert J. Hansen 
@_subject: new user anxiety 
First, it's an entirely expected thing.  It's not a problem, it's just a
Until you have personally vouched for the fact a certificate belongs to
a certain person, GnuPG will warn you about trusting signatures made by
that certificate.  You haven't vouched for Werner's certificate, so
GnuPG is warning you.  That's all.
You can get rid of the error message by:
    gpg --edit-key 4f25e3b6 lsign
Enter your passphrase, and GnuPG will know that you are vouching for the
fact certificate 0x4F25E3B6 really belongs to Werner.
Try verifying the signature again, and the warning message will disappear.
Hope this helps!

@_date: 2012-04-16 11:45:01
@_author: Robert J. Hansen 
@_subject: IDEA.c and Win32 builds? 
There are substantial disadvantages, too.  IDEA has a razor-thin margin
of security compared to more modern algorithms.  We have
better-than-brute-force against what, 5 of 8 rounds now?  The margin
gets thinner and thinner every couple of years.

@_date: 2012-04-16 20:23:04
@_author: Robert J. Hansen 
@_subject: Search: Applikation to encrypt on the fly 
It would help if you let us know which operating system you intend on using.

@_date: 2012-04-19 09:59:54
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 103, Issue 11 
Hash: SHA256
We'll have none of this, please.  Many people use more than one
operating system.  Sitting at my desktop *right now* there's an OS X
box, a Windows 7/64 box and a Fedora 16 box, with FreeBSD, OpenBSD and
HaikuOS virtual boxes.
I find Mr. Acker's question completely believable, and suggest that
other people consider it likewise.

@_date: 2012-04-19 10:05:18
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 103, Issue 11 
Oh, heavens to betsy, my apologies.  For some reason I thought this
appeared on the *Enigmail* list.
My apologies to the GnuPG listmods.  Obviously, I need more coffee this
You will note the opening tag is not closed.  This is deliberate.

@_date: 2012-08-01 15:22:09
@_author: Robert J. Hansen 
@_subject: trampCrypt family of CLI programs 
Pardon me for being blunt: she's boned.
I've read this a few times and I don't understand the point you're
trying to make, I'm sorry.
If you'll only consider 'authoritative' sources, Werner has said several
times that so-called 'portable' GnuPG installations are too prone to
malware for him to recommend using them.  (I don't recall if his
reasoning is "USB tokens are malware vectors and if you go about
plugging your token into strange computers you'll be sorry", or "any
computer that lets strangers plug in USB tokens is probably already
compromised, so don't use them or you'll be sorry."  It is quite
possibly both.)  I've heard similar remarks from other people. You may
find a brief perusal of the archives to be very illuminating.
Further, malware is a very real concern for GnuPG's architecture.  For
example, consider GPGME: rather than have a shared library that can be
hijacked by Process A (i.e., malware) to compromise Process B's
security, GPGME spawns an entirely new GnuPG invocation and uses the
process barrier to help keep malware from propagating into the core.
Malware is also one of the reasons why GnuPG supports smart cards: smart
cards are much more resistant to exploitation than is a desktop PC.
Because it is the consensus of the community, after much deliberation
and consideration.  Some members of the community disagree and have done
some good work making portable GnuPG installations: perhaps some of them
will be in touch with you to share their knowledge.
You may, of course, do this yourself; the licensing explicitly permits
it.  However, I won't do this for you because I think it's a bad idea
and you haven't persuaded me otherwise.  I imagine many of the people
who are competent to do this work are of a similar mind.

@_date: 2012-08-01 15:47:12
@_author: Robert J. Hansen 
@_subject: October 3: Deutsche Einheit 
A lot of people remember that each Christmas I remind people that 'tis
the season for giving and that it's possible to donate to the GnuPG
project, and/or related privacy charities.  Well, I hate to get into a
rut, so I'm (probably) not going to do that this year.
Instead, I notice that it's now the first of August and Germany's Unity
Day is just around the corner -- a holiday that celebrates the end of
the police state that was the German Democratic Republic and the
restoration of millions of people to a political system that has respect
for basic human rights and civil liberties.  On top of that, the
principal developer for GnuPG is German, so...
Tell you what.
match it. [*]
Privacy is important.  More than that, privacy is a human right.  So
let's celebrate millions of Germans regaining their human rights, and
let's also help guarantee privacy for the future.  Who's with me?  :)
[*] The fine print: as of right now 780 euros have been donated to GnuPG
development in 2012.  On October 4 I will be checking the donations page
again and figuring out the difference.  I'll match the difference, euro
for euro, up to 250 euros total.

@_date: 2012-08-01 19:05:39
@_author: Robert J. Hansen 
@_subject: trampCrypt family of CLI programs 
I would say that it "may be far, far worse," but with that minor quibble
I could not agree more.
By itself, GnuPG is useless.  It may even be worse than useless.  In the
best case GnuPG can be an effective tool for ensuring the
confidentiality and integrity of messages, but in the worst case it's
just cryptographic fairy dust: people think that if they just do X
followed by Y and Z, they will somehow magically be secure.
Feynman warned against this thinking in science.  He called it
"cargo-cult science," after the South Pacific islanders who built
incredibly intricate religions based on imitating the forms of
airplanes, airbases and other things they saw during World War Two.  But
no matter how accurate the bamboo mock-up of a DC-3 cargo plane is,
without an understanding of Bernoulli's Principle, the Navier-Stokes
equations, fluid dynamics, mechanical engineering, Newtonian mechanics
and the like, you can't make a real DC-3 and your bamboo mock-up will
remain something that *looks* like a DC-3 while missing absolutely
everything that makes a real DC-3 what it is.
Cargo-cult cryptography is the exact same thing, just done with software
instead of bamboo.
What makes cargo-cult DC-3 airplanes safe is the fact they never get
airborne.  We know they are clearly, obviously, defective from the
get-go, and so we never trust them.  We might fool ourselves into
thinking we're on the right track and next year's bamboo DC-3 will be
able to take off to fly to John Frum [1] for sure, but this year's plane
is just not working.  Nobody really gets hurt.
But cryptography is not like an airplane, where the fake stuff becomes
evident very early on.  Cryptography is more like an ejection seat.
When you need it, it has to work right, the first time, even while the
aircraft is on fire, breaking up, and about to explode... and even then,
if you go into it without training, you'll probably be dead before you
hit the ground.
The popular understanding of an ejection seat -- "pull the D-rings and
enjoy the ride" -- is completely wrong.  Pilots have to train for
ejection because there are so many things that can screw up.  You have
to get into the right position for ejection because otherwise you'll
shatter your spinal column from the 35+ Gs of acceleration.  And once
you've ejected, with your vertebrae cracked and/or broken, you have to
consider the possibility you may be on fire.  (Seriously.  You were
sitting on top of a rocket motor inside an aircraft that was on fire and
about to explode.  You may be on fire.)
What do you do then?
Your shroud lines may get tangled.  How do you untangle them?  How do
you untangle them with a broken spinal column and your boots on fire?
You may be about to land in hostile territory, injured, and with an army
hunting you.  How do you hide and how do you evade?
The purpose of training is not to give you rote tools.  The purpose of
training is to teach you how these rote tools work, how to use them in
concert, when one tool is disadvised and another is strong, when two
tools can be combined in creative ways, and so forth.  It is to give you
the ability to improvise highly effective solutions to the demands of a
chaotic and ever-changing world.
Pilots call their training "training," and call their knowledge of how
to use their training "the Right Stuff."
In communications security, knowing how to use training is called
"tradecraft." [2]
Whenever I hear someone say that GnuPG is too hard to use, well, I
sympathize with them.  GnuPG is very hard to use.  It has a learning
curve like the Matterhorn.  I have no disagreement there.
But when I hear people say they have a great idea that will allow people
to keep secure against dedicated, serious adversaries while requiring
very little training or knowledge on the part of the user, well...
There is no replacement for tradecraft.
There will never be a replacement for tradecraft.
Tradecraft is always a hard skill to acquire.  (I am a rank amateur, and
I doubt many people on this list are better.)
And you can rely on a dedicated, serious adversary having excellent
tradecraft of their own.
[1] [2]

@_date: 2012-08-02 09:49:23
@_author: Robert J. Hansen 
@_subject: learning curve like Monte Cervino 
GnuPG is not required to be all things to all people.  GnuPG is just
required to be an RFC4880-conformant encryption and signing application.
 It's a tool in the toolbox, nothing more.  It can be used in a broad
variety of ways.  As I pointed out a couple of emails back, it can even
be set up in ways that end-users need to know nothing about the Web of
No.  Read:
That remains the best serious analysis of why encrypted email rates are
so low.
Which confuses me, given that you seem to be saying you want users to
not need to know anything about the underlying crypto, or how it ought
be used for maximum effect.
Google the list archives again for the phrase "threat model."  We tend
to talk about that a lot here.

@_date: 2012-08-04 17:08:28
@_author: Robert J. Hansen 
@_subject: Future of GnuPG 1.x.x? 
I am not a GnuPG developer.  My information is not definitive.  Take it
with a grain of salt.
That said, my understanding is the GnuPG developers wish to end 1.4
support as soon as possible.  This is reasonable, given that 2.0 has
been out for a decade.  When 2.0 first came out I was not a big fan, but
it's become much more stable and useful over the past few years.
However, ending GnuPG 1.4 support 'as soon as possible' is not the same
as 'ending it now.'  They want to minimize impact on end-users as much
as possible.
When 1.4 support ends, expect an EOL date to be announced far in advance
and a lot of help given to people who need to migrate to 2.0.

@_date: 2012-08-21 12:35:25
@_author: Robert J. Hansen 
@_subject: [gnupg-users] Preferred hash algorithm when signing 
Hash: SHA256
Yes and no.
DSA-1024 requires the use of a 160-bit hash.  If the --enable-dsa2
flag is set, he will be able to sign with any hash he likes: it will
just be silently truncated to 160 bits.  Otherwise, yes, the choices
are SHA-1 and RIPEMD-160.
DSA-2048 requires the use of at least a 224-bit hash.
DSA-3072 requires the use of at least a 256-bit hash.
RSA has no requirements on hash length.

@_date: 2012-08-23 13:07:57
@_author: Robert J. Hansen 
@_subject: gpg "simplified"? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA224
As has been pointed out to you by at least two separate people, by
having a single trusted introducer who serves as the gatekeeper for the
entire system this problem goes away.
The problem you are talking about is routine.  I faced it when I was the
chief sysadmin for a law firm and deployed GnuPG to 150+ desktops.
Pretty much anyone who has ever deployed GnuPG and/or PGP has faced it.
 Solutions to this problem exist, are well-known, and pretty thoroughly
Deploying PKI is nowhere near as big of a problem as convincing people
that PKI adds benefit to their lives.
You don't need to understand statics, the modulus of compression, the
difference between shear and torque, the modulus of expansion, or any of
those other things to use a bridge: you just walk or drive across it.
For those who build the systems, of course they need to understand it in
detail.  Users, though, need to be insulated from these things as far as
is practical.
Right now the number one thing killing PKI is the fact nobody wants to
adopt it.  If you state, "well, before someone can use PKI they must
understand the underlying concepts," you're automatically selecting for
the upper 1% of computer users.
I think the other 99% deserve better.
One of the data formats used in GnuPG is PKCS12.  I doubt that anyone on
this list fully understands the PKCS12 data format and protocol.  A
while ago Werner condemned it as "even by ASN.1 standards a nightmare to
parse."  You don't want to hear my opinion on parsing PKCS12: my
language would make the lands near me barren.
If you say Alice *must* understand and have confidence in the data
formats and protocols, well, where do you draw the line?  Because if you
draw the line at a very high level, then you're adopting my position.
If you draw the line at a very low level, then you're saying she needs
to understand how PKCS12 works.  And if you draw the line anywhere in
between, then you're adopting my position but just quibbling over
precisely where you want the line to be drawn.
(Now, it's true that PKCS12 is normally not used as part of OpenPGP;
it's more closely associated with GnuPG's S/MIME code.  But I trust that
the point is made.)

@_date: 2012-08-23 21:52:49
@_author: Robert J. Hansen 
@_subject: GnuPG Support 
Probably the most reputable source of paid GnuPG support is g10 Code
GmbH, a German firm that employs some of the GnuPG hackers.
I'm certain g10 Code is also interested in working with you should you
need something other than their FSF or PDS service offerings.
(I have no relationship with g10 Code.  Not an employee, not a customer.)

@_date: 2012-08-24 16:06:42
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
At risk of sounding dismissive, I really don't care what your pet theory
is until such time as you get out into the field, do a formal usability
study, write up the results and get them accepted to a peer-reviewed
journal.  Once you do that, I will be happy to read your paper, give it
due weight, and refer other people to it.
Until then, the definitive work is "Secrecy, Flagging and Paranoia:
Adoption Criteria in Encrypted Email," by Gaw, Felten and ... one other
author, blanking on it right now.
Everyone on this mailing list has their own pet theory for why PKI
adoption is so lousy.  All of us are probably wrong.  However,
published, peer-reviewed studies of PKI adoption and the forces driving
and inhibiting them are probably less wrong.

@_date: 2012-08-24 19:33:38
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
(other citations clipped)
Thank you, John.  Simson Garfinkel has another one worth adding to the
list, but I'm blanking on it for the life of me right now -- give me a
day or two to dig through my pile of papers and I'll come up with it.

@_date: 2012-08-24 19:43:49
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
For once, I conquered my paper stack in O(n) time.
Views, reactions and impact of digitally-signed mail in e-commerce.
Garfinkel, Schiller, Nordlander, Margrave and Miller.  Originally
published somewhere in LNCS, but I got mine from:
It's worth reading.

@_date: 2012-08-25 12:19:19
@_author: Robert J. Hansen 
@_subject: Why "trouble"? 
This will be my last comment on this thread.  It will also likely be my
last response to Peter.
If you believe a paper no longer represents reality, the burden is upon
you to show that reality has changed.  You can't just say, "well, it's
outdated."  Doesn't work that way.  The original "Why Johnny Can't
Encrypt" paper, for instance, dealt with the PGP 5.0 user interface and
came out in the mid-to-late 1990s; if anything's "hopelessly outdated",
it would be that.  Yet, the PGP user interface hasn't changed very much
since then, and there have been recent studies which have confirmed
those results.
And here you've crossed the line into selective quotation in order to
present someone's position -- namely, mine -- in a false light.
Someone, and I believe it was you, was opining on their own personal
(uninvestigated, unexamined, unsupported by evidence, unsupported by
studies) opinion on what was really holding GnuPG back from wider-spread
adoption.  To that, my response was that if we want GnuPG to enjoy
widespread adoption we have to first convince people that PKI adds
benefit to their lives.
And now you're suddenly using that as an example of the 'silliness' of
the people here, because, after all, "people either feel a need to
protect their privacy or they do not."  Well, okay, fine, but if that's
your position why were you talking about what's holding GnuPG back from
widespread adoption?
You originally came onto this list with a proposal for what you wanted
to call "trampCrypt."  It didn't get any traction.  People on this list,
at least three different ones, pointed out that what you wanted to do,
you could already do.  And yet instead of saying, "well, thank you, how
exactly could I get this to work, and would anyone be willing to help me
get it set up for my users?", you're engaging in this intellectually
fraudulent -- and I don't use that phrase lightly -- form of argument.
As soon as you discover your position is untenable, why, look, you're
arguing something else altogether.  Rather than actually engage people
on the merits of what they say, you casually smear references to the
peer-reviewed literature as "hopelessly out-dated" (without providing
references to more current papers that supersede the old ones), casually
quote people in false light, and so on.
Sir, I believe your style of argumentation is deeply corrupt, and I'm
done here.

@_date: 2012-08-26 18:40:26
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
Well, speaking just for myself, I try not to make that assumption.  I'm
interested in knowing why Johnny can't encrypt, and then further why
Johnny *doesn't* encrypt.  These are two different questions which have
very different answers.
"Why Johnny can't encrypt" is a human-computer interaction (HCI)
problem.  HCI problems are eminently solvable.  The papers have a lot of
exploration of this problem: see, e.g., "Why Johnny Can't Encrypt",
"Johnny 2", and "Why Johnny Still Can't Encrypt" for three examples of
really good peer-reviewed papers that explore this.
"Why Johnny doesn't encrypt" is a social problem.  Social problems are
notoriously intractable.  See, e.g., Gaw, Felten and Fernandez-Kelly's
paper.  They found that even when people were aware of the dangers they
were facing, knew those dangers were real, had easy access to crypto
software and had been trained in its use, they *still* weren't using
crypto... principally because they didn't want to be seen as paranoid.
I really don't want to rain on people's parades.  A lot of these ideas
of "what the problem is" are deeply interesting.  But until you actually
go out into the world and ask real users the question, and observe
workers in their natural environment, then it's a bunch of discussion
over how many angels can dance on the head of a pin.
Seriously, there have been some really good HCI and social-theory papers
mentioned on this list in the last week.  Grab them and spend an
afternoon reading through them.  I found them to be deeply rewarding:
you might, too.

@_date: 2012-08-27 12:34:18
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
When you see someone come onto a mailing list hiding behind a pseudonym
and a disposable email address, saying "I work in this field and if you
only knew what I do"... well.  A little skepticism is warranted.
They're either lying or else they're flagrantly violating their unit's
do-not-ever-talk-about-this policies.  Either way I really don't feel
like giving them a moment of my time.
So, yeah.  My recommendation: shrug, laugh, and move on.  Really isn't
worth it to do anything else.  :)

@_date: 2012-08-28 13:31:21
@_author: Robert J. Hansen 
@_subject: Pseudonym (was Re: what is killing PKI?) 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
I haven't responded to any of No Such Client's emails yet, on account of
them not being constructive.  This email is constructive, though, so
here goes.
I can understand why you'd think that.  To the extent that etiquette is
a subjective decision, I can't even argue against it.  But I'm not
overly concerned by it, either.
The worst trait of academia, in my mind, is the tendency of people
within it to get obsessed on their one particular thing.  I know one
person whom I and my colleagues refer to as "Random"[*].  Whatever
problem we propose, this person says, "You know what would fix this?  A
randomized approach."  This person is technically brilliant but unable
to recognize that this idea does not always work in the real world.  The
feedback cycle, wherein this person should discover "you know,
randomized algorithm theory really didn't help very much here," is broken.
The best way to keep a feedback cycle humming is to go out of your way
to look for evidence that contradicts, rather than supports, your views.
Further, start looking for that evidence immediately.
If you have an opinion about art, I'd love to hear it.  I will entertain
any and all opinions on these, because ultimately it's subjective and
the point of the discussion is not to better understand the world around
us but to better understand each other.  But if you have an opinion
about the physical world, well -- the standards there are different.
We are not our ideas.  Other human beings should be taken seriously: our
ideas, though, must *never* be taken seriously.  They must instead be
thrown into violent collision with other ideas, and we must not be shy
about saying, "this idea doesn't seem to work and/or there's no evidence
to support it, so I'm going to get rid of it."
People are important, precious, special.  Ideas are just ideas.
Venerating ideas and believing that all ideas, regardless of how
poorly-supported they are by evidence, leads you into situations like we
have in the United States where Creationists are trying to hijack school
science curricula.  They demand their ideas that contradict reality be
given equal time and respect to the reality-agreeing ideas of
conventional biology.  I believe these people deserve to be told,
clearly, firmly and politely, "Until your theory makes testable
predictions, I don't care about it."
Peter Segment has his opinions about why PKI adoption is so slow.  These
opinions are at odds with what we know about why PKI adoption is so
slow.  If he were to conduct an HCI study that gave results supporting
his theory, I would take his study and theory with grave seriousness.
But until then -- I don't care about his theory.
And this, here, is the difference.
I did not smear Peter Segment.  I simply told him, bluntly and directly,
that I didn't care about his theory until such time as he had evidence
to back it up and show the existing literature was wrong.  Believe it or
not, most people on this list understand that this is not rudeness: this
is just the way progress in science and mathematics occurs.
You, on the other hand, deliberately employed ad hominem against me, not
against my ideas.  You openly admit that you enjoyed it.  And you seem
to not be able to recognize the difference between us.
I think that says it all, really.
[*] The name and its derivation is slightly changed to protect my
co-worker.  The person and this person's behavior is completely real,
but the object of blindered focus is something different.

@_date: 2012-08-30 18:12:19
@_author: Robert J. Hansen 
@_subject: Ideas and criticism (was Re: Pseudonym?) 
I'm going to be (mostly) staying out of this one, but I think I may have
a couple of useful remarks here --
I can't speak about any institutions other than the ones I've worked at:
but in both graduate school and my employers since, if Alice is able to
demonstrate to Bob that his cherished idea is faulty, Bob buys Alice a
beverage -- not as a way of acknowledging Alice's "victory," but as a
way of expressing a tangible thank-you to Alice for helping Bob become
better at his task.  This principle is not modern: it's about as old as
the hills.  You can even find it in the Tanakh: "As iron sharpens iron,
so a friend sharpens a friend."  (Mishlei 27:17)
Consider a high school student who's wracked with self-doubt over asking
a pretty girl out: will she say yes?  Will she say no?  This student is
so wrapped around the axle over the answer that by the time he finally
gets up the nerve to ask her out they're already facing 30 and are
meeting up at their ten-year high school reunion.  The student cares
more about the answer, and what the answer says about *him*, than he
cares about what the answer is, or for that matter ever getting an
answer in the first place.  If I, today, at age 37, could go back in
time 20 years and give myself at age 17 some advice, I'd say, "Just ask
her out already.  Maybe she'll say yes.  Maybe she'll say no.  Either
way, you'll have your answer and you'll go on with your life.  Please
stop wrapping your self-worth up in decisions that other people will make."
It's really easy for us to think that if we get rejected for a date,
that it somehow means we're defective or faulty or something.  And
that's crazy: rejection is about as personal as junk email.  The first
dozen times or so it stings, then you get really good at laughing over
it, and then you lose your fear of rejection and you start having a lot
more success.  Who cares if you get rejected a hundred times if it means
that on your hundred-and-first try you wind up having the cup of coffee
that ultimately turns into the next sixty years and three kids?
Likewise with ideas.  It's really easy for us to think that if our ideas
get rejected, that it somehow means we're stupid or idiots or foolish or
something.  And that's just as crazy: a bad idea just means that you had
a bad idea.  The first dozen or so times it stings.  Then you get really
good at laughing over it, and the next thing you know you've unleashed a
hundred bad ideas on the world... and one really, really good one that
people will be talking about for years to come.

@_date: 2012-08-30 19:43:08
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
Historically, this is among the most effective ways of getting secrets
out of someone.

@_date: 2012-12-03 00:00:41
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 111, Issue 2 
The best reason to keep your old keypair around is pretty simple: "what
does it hurt?"
If you delete your keypair, then if anyone sends you traffic encrypted
to that keypair you'll be unable to read it.  If you keep your keypair,
then you can.  And it's not as if it takes up a lot of room on your hard
drive or impairs GnuPG's performance.  :)

@_date: 2012-12-03 20:23:47
@_author: Robert J. Hansen 
@_subject: Is it safe to rename file.gpg to `md5sum file`? 
There isn't enough entropy in a filename for an MD5 checksum to give
much in the way of secrecy.

@_date: 2012-12-05 01:20:28
@_author: Robert J. Hansen 
@_subject: Is it safe to rename file.gpg to `md5sum file`? 
Let's not even use the word insecure, since that word is wholly
subjective: there's no agreed-upon definition for what it means.
Instead, let me ask a different question: what, precisely, are you
trying to accomplish?
Sure, of course there's inverse-md5sum -- after a fashion.  Many files
bear names that are just a couple of short words: "Tuesday report.doc",
for instance.  So you go through a dictionary and compile a list of
every one and two--word filename, separating by underscores and spaces,
and using the top 100 file extensions.
There are about 5,000 words in common usage in English.  (A native
speaker will have a larger vocabulary, but you can get by quite well on
5,000 words.)  Every possible one and two-word combo from this list
would amount to about 25 million entries in the database: multiply by,
say, four, to represent different conventions for capitalization and
spacing and whatnot, brings you to 100 million.  Multiply by the top 100
file extensions and you get 10 billion.  Each of those records would
require about 100 bytes of storage, or 1 trillion bytes.
You could easily store it on a $100 hard drive.
This is what's called a "dictionary attack."  There are other much
better ways to attack it: rainbow tables, for instance.  But this is
enough to show you that MD5 is nowhere near as hard to reverse as you
might think.  If you're creating filenames based on the MD5 hash of the
entire file, that would be (probably) nontrivial to reverse: if you're
creating filenames based on the MD5 hash of the original filename,
you're playing with fire.
That said: please don't use MD5.  Please use a better, stronger hash
algorithm like SHA-256, SHA-512 or SHA-3 instead.

@_date: 2012-12-05 18:28:35
@_author: Robert J. Hansen 
@_subject: Is it safe to rename file.gpg to `md5sum file`? 
This falls squarely into the range of theoretical breaks.  Notice that
the attack requires 2**17 chosen plaintexts to all be encrypted with the
same symmetric key.  Since GnuPG uses disposable session keys, this is
pretty much completely irrelevant to GnuPG usage.

@_date: 2012-12-11 07:46:07
@_author: Robert J. Hansen 
@_subject: A Probabilistic Trust Model for GnuPG (2006) 
Forgive the snarky response, but: because no one, yourself included, has
bothered to implement it.
Looking over this paper, it does not seem to pass my sniff test for
academic works.  For instance, there's no thesis statement anywhere on
the first page: they say "In this paper, we will first give a short
overview of the PGP trust model ... to point out some of its inherent
weaknesses and deficiencies."  Okay, fine: but if they can't give a
one-sentence description of what problem they found, it makes me think
they didn't find much of a problem.
This view of mine is mostly confirmed by page two.  The first "major
deficiency" of the WoT they present -- and remember, standard writing
style is to start off with the big things, so we can reasonably infer
this is the major takeaway -- is "the limited levels of trust in PGP
[are] clearly insufficient to reflect possible varying opinions about an
introducer's trustworthiness.  In real life, it may be that among two
marginally trustworthy introducers one of them is twice more trustworthy
than the other.  Unfortunately, the PGP trust model does not support
such a distinction."
I've been using PGP since 1991.  I've used it professionally, I've set
up and deployed sites that use hundreds of certificates.  And never, not
once, have I ever lamented the lack of fine-grained trust decisions in
the WoT.  More to the point, I don't think fine-grained trust is
possible.  You can't say, "Bob is 53% trustworthy and Alice is 55%
trustworthy."  Trust is a human concept, and as such it finds its
manifestation in qualitative rather than quantitative terms.  "Marginal
trust" is a qualitative term: "53% trust" is a quantitative term.
So, their biggest objection to the WoT is, IMO, a dog that won't hunt.
I also agree with Nicholas, who said that he didn't find their
"counter-intuitive" example to be at all counter-intuitive.  I'll go one
step further: anyone who expects to analyze the behavior of a formal
system by means of intuition is living in sin.  Describing the behavior
of a formal system as "counter-intuitive" is sort of like the old joke
about a philosopher who justified a really bad decision on the grounds
that it "felt like the logical thing to do."
So, yeah.  I see this paper as solving a nonexistent problem.  I don't
think it's something the GnuPG developers should tackle: we have other
more important things to spend our limited developer resources on.

@_date: 2012-12-23 11:11:13
@_author: Robert J. Hansen 
@_subject: OpenPGP Authentication Protocol? 
Sure, but most of these documented protocols have all sorts of serious
problems, too: most of them are painfully ad-hoc. If you mean a protocol
that's undergone peer review and is considered by the community to be a
best practice, then no, I'm unaware of any. If you're able to come up
with one I hope you'll share it with the rest of us!

@_date: 2012-12-26 07:42:02
@_author: Robert J. Hansen 
@_subject: ASCII armor plus? 
A word of caution may be in order: PGP/MIME is a fragile format and does
not play nice with mailers (remailers, mailing list software, MTAs,
anything in the chain) that plays with attachments.  There are a
surprising lot of these out there: for instance, the PGP-Basics mailing
list at Yahoo! Groups is configured to strip all attachments, which
means that PGP/MIME signatures on that mailing list are simply impossible.
GnuPG-Users and Enigmail-Users have each within recent memory had
mailing list software (GNU Mailman) which broke PGP/MIME signatures.
When the community's flagship mailing lists cannot reliably use
PGP/MIME, I'm a little cautious about recommending PGP/MIME as a
general-purpose, ready-for-the-end-user solution.

@_date: 2012-12-26 08:22:44
@_author: Robert J. Hansen 
@_subject: OpenPGP card decryption with 4096bit keys bugfix?? 
You will have better luck if you join the list.  I can almost guarantee
you that somewhere in this thread someone will have useful thoughts to
contribute and they will not remember to cc you.
The easiest way to fix your problem is to consider whether 3072-bit
crypto is sufficient for your purposes.  It almost certainly is.
4096-bit crypto does not give you very much of an edge over 3072-bit
crypto.  Per NIST:
NIST doesn't even give an estimate for 4096-bit keys.  My suspicion is
they would come in around 134 bits or so, but that's just a hunch.
This makes 4kbit keys the "odd man out."  If 128-bit crypto is
sufficient for your purposes (and it's sufficient for virtually all
purposes!), then a 3072-bit key is also sufficient.  If you're in one of
the rare niches where 256-bit crypto is necessary then you've got two
choices: use a 15,000-bit RSA key or else switch to elliptical-curve
Either way, there are very few cases where RSA-4096 is necessary.  (I've
personally never seen or heard of one, but I'm not going to claim they
don't exist at all.)

@_date: 2012-12-26 13:58:43
@_author: Robert J. Hansen 
@_subject: ASCII armor plus? 
In my defense, I never said I thought PGP/MIME had no place in the
OpenPGP ecosystem.  I just said I was reluctant to recommend it as a
general-purpose solution, given how dodgy the support for it is in a
great number of different venues.
I readily concur that we have a pretty sorry state of "standards"
nowadays.  A standard that's not widely conformed to is not much of a
The alternative would be to roll our own, and maybe the time has come
for a Mailman replacement.  I've long wanted some piece of software that
allows for threads to be handled either via email or via web forums:
after all, viewing is orthogonal to the content itself.  Content can be
stored in a back-end, and the front-end can/should be a replaceable

@_date: 2012-12-29 14:03:30
@_author: Robert J. Hansen 
@_subject: Privacy selection  Was: ASCII armor plus 
============================== START ==============================
Modern MUAs, yes.  Modern MTAs, no.  The "mail servers play hob with
attachments" issue is very real.  I've personally seen it affect GMail,
Exchange and Mailman, along with half-a-dozen poorly-configured sendmail
and postfix installations.
I'm not telling people to not use PGP/MIME.  I am saying that PGP/MIME
is not as reliable as its proponents would like to believe.  My best
advice is that if you use PGP/MIME, be ready to fall back to inline traffic.

@_date: 2012-01-31 19:04:57
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
Warning: do not take *any* of the numbers here seriously.  They may be
completely divorced from reality.  These numbers are like Monopoly money

@_date: 2012-01-31 19:15:07
@_author: Robert J. Hansen 
@_subject: [META] The issue of the unwelcome CC (please email me if you 
First, thank you for keeping your response civil.  I appreciate it a lot.
I agree with you.  I thought this convention was sufficiently obvious as
to not need pointing out.  In 20+ years of being on the Net, this is the
first time I've ever seen a flamewar erupt over something as ridiculous
as whether it's a mark of mental retardation to have on-list and cc
With respect to GnuPG's "outlier" convention, I've never heard of it.
I've received both on-list and cc's many, many times in the past.
People are, of course, free to request what they want: but this trend of
getting angry and furious at people who do not comply seems to me to be
a social power-play and I want none of it.
Dan Geer had the right approach, I think.  He said, politely, that he
prefers not to receive a separate cc.  I plan on honoring this as far as
my memory allows.  He didn't tell me that I *must* not, or that I was a
'retard' or a 'moron' if I did so.
I don't mind people being argumentative.  (I've been accused of being
brusque many, many times.  Guilty as charged, and unrepentant.)  But the
level here has gone from good form straight into unsportsmanlike
conduct.  I'd like it if we could stop that and de-escalate back to our
usual level of vigorous, impassioned argument.  :)

@_date: 2012-02-01 10:00:56
@_author: Robert J. Hansen 
@_subject: 1024 key with 2048 subkey: how affected? 
Many.  The real question is what level of depth you want.
Googling for "nsa suite b" qould be a pretty good starting place,
probably.  The National Security Agency has approved the use of ECC for
classified material as part of their "Suite B" cryptography package.  As
is the case with most government standards there is ample documentation
about everything from the theoretical to the practical, although it
isn't all collected in one place.

@_date: 2012-02-01 11:19:08
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
Then yes, you are selecting for email users.  There are quite a lot of
people who use GnuPG primarily for themselves -- for instance, a system
administrator who signs each backup, a lawyer who encrypts files when in
transit on a flash drive, etc.
The overwhelming majority of the users you see are using email, yes, but
only because email is the method by which you come to see them.  Users
who never announce their usage (the system administrator, the lawyer,
etc.) are completely invisible to you.
I can't give an estimate on the number of 'invisible' users: they're
invisible to me, too.  But I'm not going to believe they don't exist, or
that they don't exist in good numbers.
A 'serious user' is, to me, someone who will send angry emails if things
break.  If a program can fail and not have an immediate adverse effect
on a user, the program is not important to the user and the user can be
said to not be a "serious user."
If GnuPG breaks, a whole lot of the Linux experience breaks.  You get
warnings left and right about installing packages with bad signatures,
important updates don't happen, etc.  This will result in a lot of angry
people strangling whoever is responsible for breaking their PC.
Yes, this definition means that you're a serious user of your OS kernel.
 And why wouldn't you be?  You demand your PC make thousands of kernel
calls each second.  Is that not serious use?
Think about what you're saying:
Ubuntu will be switching to Thunderbird in 12.04, apparently, so that
takes care of (a).  I doubt we will see a huge surge in Enigmail users
as a result, though, since (b) is unchanged.
As soon as both Thunderbird *and* Enigmail are part of a standard Linux
installation, let me know.  I'd love to know about it.  Until then, I
think Enigmail is going to remain a niche player.
Quite in context, please.  In context, that sentence obviously referred
to Linux users.  Quoting people out-of-context to score points is a pet
peeve of mine.
Well, clearly the install base isn't the point, you've already said
those aren't what you'd call 'serious users'.  And if users who know of,
are aware of, who pay attention to, how GnuPG works behind the scenes
aren't relevant to you, then what is?  Each benchmark I use to represent
a class of users, you reject as being not what you're talking about, so
please tell me precisely what you *are* talking about.
Quite a lot, apparently.  There are a whole lot of people on this
mailing list.  I'm sending a message to all of them, including people I
don't even know.
Your question: "Who will after starting to sign emails start to send
emails to people he is not familiar with?"
The answer is Facebook.  Google+.  eHarmony.  Match.com.  JDate.
Bear411.  ChristianSingles.com.  The list goes on and on and on.  (Note:
my mention of any service is not an endorsement.  If so, I'd be a weird
mess of contradictions: a nice Jewish boy who happens to be a
Pentecostal bear...)
People love to talk and to meet new people.  You can't stop people from
talking to each other.  It's part of the human experience.  Something
about creating social connections tickles something deep in our brains.
 It's like a drug.  It's so much part of the human experience that we do
it even when it's risky and dangerous, and for those who *don't* love to
talk and meet new people we hang words like "misanthrope" or "hermit"
off them -- words with powerful connotations of psychological dysfunction.
Yes, but that's completely irrelevant.  I don't mean to be callous, but
you've missed a very important point.
The people who would be complaining about my conduct would be people who
don't know me from the wind.  *They're* the ones who would have to be
persuaded I was on the up-and-up.  Persuading them would be an uphill
road to hoe.
What would the Dean say to them?  "I've known Rob for three years and
he's never once expressed any sentiments like this?"  They'd point out
that yes, I've never expressed sentiments like that openly around the
Dean because those opinions are so offensive they'd get me canned.
Best case scenario, the aggrieved parties would demand the Dean make a
full investigation.  The Dean would know there would be no investigation
that could either clear me or condemn me: there's simply not enough
evidence to draw conclusions either way.  The Dean would know that I was
on the up and up, but since trust isn't transitive, he couldn't convince
the concerned college community I was on the up and up.
So the Dean would quietly relieve me of teaching duties, give me a
research job in some office somewhere that I didn't have to interact
with anyone, keep me out of public view, and he'd tell the affected
people "the investigation is underway, and until it's resolved we've
relieved him of teaching duties."  Then in a semester or two I'd be
quietly reinstated as a TA.
Welcome to politics.  That's how it works.
Sure it would.  Deniability.

@_date: 2012-02-01 13:37:54
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
I don't know what you mean by a "concerted effort."  Maybe five Enigmail
users count under your definition, maybe fifty: maybe two people within
Mozilla, or maybe nobody has to be within Mozilla, etc.  All I can say
is that at various times people have tried to push for this, but so far
without success.  There seem to be two major reasons for this:

@_date: 2012-02-01 14:40:23
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
I can't vouch for financial institutions.  I can tell you that when I
was working in electronic voting, whenever I asked questions about "do
you verify signatures?" I was always assured that yes, yes they did.
Whenever I asked, "when was the last time you had a bad signature?" I
always received an answer of either "gee, look at the time, gotta go,"
or "we've never had a bad signature on data from a real election, after
all, our systems are reliable and trustworthy."
check signatures" it undercuts confidence, therefore they always say
they check signatures.  If they say "yeah, we had a bad sig last week, a
byte got dropped somewhere, we re-sent the data and it was fine," that,
too, undercuts confidence: they're admitting the system isn't perfect.
I liked hearing the "Gee, look at the time, gotta go" answer.  It seemed
to be the most honest.
YMMV, and banks are definitely different beasts from voting authorities.

@_date: 2012-02-01 15:45:05
@_author: Robert J. Hansen 
@_subject: On message signing and Enigmail... 
Except that it doesn't.  What's to prevent me from creating a
certificate with your name and email address and making posts in your
name, with a signature from a certificate that claims to be yours?
Nothing -- and that signature is every bit as credible as the one that's
from your own certificate.  You might say, "but that certificate's a
fraud, my certificate's real!", but the Christopher Walters impersonator
will say the same thing about you.  There's no way to check.
I understand the desire to give people a way to verify the integrity of
your message, but the way you're going about it has some glaring and
obvious flaws.
I can't argue against a feeling.  No one can.  Feelings are what they
are, and they are immune to the forces of reason.
That said, I consider this sentiment to be a close analogue of feeling
that statements given by argyle-wearing men who speak Occitan with a
lisp are more trusted than statements given by others.  It's crazy.
It's just that it's your particular flavor of it, and I respect that.
Just don't ask me to subscribe to it.  :)
(No perjoration is intended.  We all have our own particular flavors of

@_date: 2012-02-01 16:38:57
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
I have referred to this paper probably five times or more on this list
and other lists.  I really wish people would read it.  I'm getting tired
of answering this -- it's my least-favorite OpenPGP-related question.
Shirley Gaw, Edward W. Felten, Patricia Fernandez-Kelly.  Secrecy,
Flagging and Paranoia: Adoption Criteria in Encrypted Email.
Proceedings of CHI 2006 Conference on Human Factors in Computing
Systems, 2006.

@_date: 2012-02-01 16:53:48
@_author: Robert J. Hansen 
@_subject: On message signing and Enigmail... 
Easily forged, and machines are too easy to compromise.  This idea that
an IP address is clear and convincing evidence of origin is absolute
bonkers.  An IP address is evidence of *routing*.
I personally know fourteen-year-olds who would do this just for the
pleasure of screwing with you.  Consider Anonymous, whose stated raison
d'etre is to do it all for the lulz and because none of them is as cruel
as all of them.  Anonymous gets in the news when it goes after big
targets, but you think a bunch of technically competent high school
students wouldn't direct this against a particularly hated teacher, or
the designated class pariah, or...?
Maybe I have a darker view of human nature than you do, that's certainly
possible, but I think it's a critical mistake to apply rational-actor
theory to criminals.  (It's just as critical of a mistake to apply
rational-actor theory to human beings.  Human beings ain't rational
The only way this argument can be refuted is for me to commit a felony
(breaking the Computer Fraud and Abuse Act).  I'll happily give a
general outline of how it can be done, but I'm not going to commit a
felony just to prove a point.  That way lies madness.

@_date: 2012-02-01 17:08:24
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
Read the paper.
One of the principal reasons the NGO in the study avoided using crypto
was because they were concerned about appearing to outsiders as if
they were paranoids with something to hide.
Why do you want to sign everything?  Because you want to detect if
someone's tampered with your messages.  What are you, some kind of
paranoid who's worried about people screwing with your email?
Seriously.  Read the paper.  It's worthwhile.

@_date: 2012-02-01 17:40:16
@_author: Robert J. Hansen 
@_subject: On message signing and Enigmail... 
No -- because I didn't.
If I said *you* were bonkers and deserved to be locked away in an asylum
and for that reason you're wrong, that would be ad hominem.
Saying that an *idea* is bonkers and just plain wrong is an assertion of
fact.  It's either right or it's wrong.  Consider this: when I make a
connection to the outside world my IP address gets silently transformed
by my router thanks to the magic of network address translation (NAT).
The original source IP address gets erased and replaced with another.
The IP address no longer reports my source correctly.
IP addresses, as originally conceived, would have identified source and
destination.  But NAT is pervasive nowadays, and that means IP addresses
can no longer be relied on for those purposes.
"This idea that an IP address is clear and convincing evidence of origin
is absolute bonkers."  I stand by that.  Feel free to substitute
"clearly wrong" if you prefer, it doesn't change a thing.
Reread my message.
That you get to choose whether to do this is not in any debate.  You do,
and that authority is absolutely respected.  The wisdom of your choice,
though, is a fair subject for discussion.

@_date: 2012-02-01 18:12:24
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
Yes, I'm ignoring Windows, mostly because I have absolutely no idea
where to begin estimating GnuPG users on Windows.  All I can do is
mutter something about "wovon man nicht sprechen kann, dar?ber mu? man
schweigen" and quickly change the subject.  :)
That said, yes, on Linux Enigmail is a niche player.  The major distros
ship either KDE or GNOME desktops.  KDE's default mail application is
KMail, and GNOME's is Evolution.  Both have strong OpenPGP support.  You
don't need to install Thunderbird+Enigmail on those platforms to get
OpenPGP support for email, so most people who want OpenPGP email don't.
Having fielded questions from people stymied by Enigmail installation
for a few years now, I disagree.  I've encountered a lot of people who
find it to be a significant obstacle.  It was much worse in the past,
but since the introduction of Windows installers for GnuPG the problems
have diminished significantly.  We still get a fair number of them, though.
No, but I do sign emails.  There are a fair number of people who can
attest to that.  I just don't sign emails to mailing lists except in
unusual cases (e.g., I'm making a post to the Enigmail list in my role
as a list moderator) or when I've enabled signing by accident.
I don't understand what you're saying.  If cryptography is the reason to
contact someone, then I think we all need to get out more.  :) I contact
people to *communicate*.  Cryptography is just a tool to facilitate that.
World's full of 'em.  God knows I've asserted my right to be a damnfool
idiot from time to time, so I'm inclined to judge them a bit more leniently.
Ask Charlie Sheen, or for that matter anyone who's ever wrestled with
bipolar disorder, drug addiction, or any of a whole host of illnesses
and/or conditions that can cause erratic behavior.  Sometimes the
software running on the gray matter just breaks and people act in weird
ways.  It's part of the human condition.

@_date: 2012-02-01 18:27:04
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
Your statement was, "I just don't understand why someone who has
understood the concept[s] and is capable of [using the software] should
not use that technology for his email."  That's a statement, not a
question: I inferred your question as, "Why is it people who understand
the concepts and are capable of using the software don't use it for
their email?"
And that is, in fact, exactly the question they're answering.  "In this
paper we try to identify additional barriers by interviewing a set of
users from an organization that relies on secrecy.  Our interviews
demonstrate that users' attitudes about encryption, and the social
significance users attach to it, are an important factor in limiting
Their central finding?  It's not a technological problem: it's a social one.
Incorrect.  GnuPG is never mentioned in the paper.  The NGO mentioned in
the paper is PGP-only.  Some of their case studies (Woodward) used PGP
to encrypt files on their desktops: others (Abe) were email-only.  Some
were email-only (Jenny) but abandoned it, others... etc.
Incorrect.  The paper makes it clear they had plugins available to do
the process automatically.  "In addition, [Woodward] distrusted plugins
for email programs, relying on encrypting the text of a message first
and copying it into his email program later."  That sentence only makes
sense if they had access to plugins.  Further, PGP circa 2006 shipped
with email plugins.
Another user, Abe, "used encryption to protect financial data ... [he]
believed this setup was simple."  From that I infer Abe had suitable
tools for the task -- which is quite plausible, given we know they were
using PGP.

@_date: 2012-02-01 20:43:22
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
I'm afraid, Hauke, that I don't understand what you're getting at.
Then you have my response to that: the paper I cited does a good job of
answering that question.
Then we disagree completely, and there's nothing more to be said.

@_date: 2012-02-02 14:46:10
@_author: Robert J. Hansen 
@_subject: Wittgenstein (was Re: PGP/MIME) 
Oh, Wittgenstein's wonderful.  I have a quote from him on a Post-It on
my monitor:
One of the hardest challenges I face with this stuff is figuring out
what I want something to be or mean, and then saying "okay, now I need
to try and prove that wrong, so that along the way I might find out
what's right."  It's tough, but I've found it to be an effective way
of increasing understanding.
One of the hardest things in the human situation is discovering what
we want and why we want it.  Wrestling with it, though, makes us
better human beings -- and ultimately better engineers, too.

@_date: 2012-02-20 16:32:45
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
Mozilla receives funds from Google and others.  The "and others" bit is
Without Google Mozilla would have to find other partners.  I'm willing
to bet cash money on the barrelhead they already have other partners
lined up in the event this becomes necessary.
I doubt that whether you use email encryption is really any concern to
Google.  Invasive, intrusive email scanning exposes them to all manner
of legal risks, from both civil and criminal law.  It's also a public
relations disaster waiting to happen, and could result all manner of
horrific penalties for Google.
Traffic analysis gives them almost as much useful information with much
less risk exposure -- and email encryption doesn't interfere with
traffic analysis.
I'm not a particular fan of Google (or Facebook or what-have-you), but
let's make sure our criticisms of them match up to reality.
You're certainly welcome to.  If you'd like to see Enigmail bundled with
Thunderbird, then please write the Thunderbird developers a
politely-worded email asking them to look into it.  However, talking on
this list (or on the Enigmail user list) about how much you'd like to
see it in Thunderbird is unlikely to achieve anything: the people who
make those decisions are not, as far as I know, on either this list or
Enigmail's list.
There is virtually nothing OpenPGP can do that S/MIME cannot do.  There
are certainly some implementation differences between the two, but in
terms of broad capabilities they're almost identical.  If you want email
encryption capabilities, they're already there.  If you want OpenPGP
specifically, you'll need to find things OpenPGP can do that S/MIME
can't do, and pitch it to the Thunderbird developers on that score.
Windows and OS X are delivered with S/MIME already.  If people aren't
using S/MIME (and they overwhelmingly are not!), why should we believe
the presence of an OpenPGP suite would change their behavior?
I'm not trying to dissuade you, but the people you need to convince are
not on this mailing list.  :)

@_date: 2012-02-21 08:29:27
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
I think this is a mischaracterization of my position.  My position is,
"PKI is hard."  We don't have any tools that can scale up to the size of
the world.
Circles that are increasingly separate from actual physical interaction.
 There are a lot of people in my circles I've never met before, which
makes the problem of verifying their keys rather difficult.
Social media will not solve the PKI problem.  In many ways it makes it
worse.  Social media is predicated around the idea that you have given
up your privacy and anonymity in exchange for being more connected to
the social flow around you.  Before Facebook, people who used encryption
and other privacy technologies were looked at by the population at large
as being kind of kooks.  Now we're being looked at as if we're about to
step off into the woods with Ted Kaczynski.
The things that we value are increasingly out of step with the things
our society values.  And, you know, that's fine: there are *lots* of
communities with values out of step with those of the larger society.
But we should be cautious of thinking that we're going to wave a little
crypto magic fairy dust and suddenly everyone will come to our side of
the privacy fence: they won't, and it doesn't matter how good our
Kool-Aid tastes.
The question is not whether we think it should work well, but rather
whether it *does* work well.  It doesn't.
As long as people have to make a conscious choice to use these tools,
these tools will never become mainstream.
Not really.  S/MIME is as capable of decentralized behavior as OpenPGP.

@_date: 2012-02-23 23:46:40
@_author: Robert J. Hansen 
@_subject: US 11 Circ: 5th Am. & passphrase demands 
The United States 11th Circuit Court of Appeals, which is one small step
away from the United States Supreme Court, has issued a decision in
connection to a grand jury's subpoena requiring the appellant to produce
unencrypted copies of six hard drives.
The appellant attempted to invoke his rights under the Fifth Amendment,
prohibiting anyone from being compelled to testify against themselves in
any United States proceeding.
The court sided with the appellant, and held that he could not be
compelled to produce decrypted data for the government.
Now, this isn't quite a black-and-white issue.  This is not going to
establish new nationwide policy on the matter.  Don't generalize and
think that just because this one case went this way, all similar cases
will in the future.  That said, it's definitely good news for United
States citizens, nationals and residents who use cryptography!
The original decision can be found at:

@_date: 2012-02-24 11:59:08
@_author: Robert J. Hansen 
@_subject: US 11 Circ: 5th Am. & passphrase demands 
No, and let's not talk about the possibility of that happening.  :)
They studiously avoid commenting on current cases or controversies.
Doing so is a breach of judicial ethics on the same level as a physician
violating the confidence of medical information -- they take it dead
seriously and deeply dislike even casual talk of the subject.  There are
a few exceptions in the ethics code for subjects like teaching law (Dad
teaches a "Current Cases and Controversies Before The Court", for
instance), but family members aren't one of them.
Whenever I mention an opinion, a brief, anything of the sort, you can be
confident of two things: (a) it did not come from my judicial relatives
and (b) I don't know what they think of it.
Every family has unwritten rules they rely upon in order to keep things
sane.  This is one of ours.  :)

@_date: 2012-02-25 09:43:30
@_author: Robert J. Hansen 
@_subject: US 11 Circ: 5th Am. & passphrase demands 
Matt Blaze is a fairly credible blogger, and a reputable cryptographer
who's done some very good work.  He also references the United States
Judiciary's 2010 Wiretap Report and Susan Landau's _Surveillance or
Security_.  If you're looking for references to back up his factual
claims, I'd suggest starting in either of those two.

@_date: 2012-01-09 18:37:16
@_author: Robert J. Hansen 
@_subject: First-time gpg compile - compiling gnupg-1.4.11 for Windows - 
Easiest solution: use the binary installer for GnuPG 1.4.11 available at:

@_date: 2012-01-21 17:01:51
@_author: Robert J. Hansen 
@_subject: Protecting IDs at a key signing party 
It's less than trivial: it's a complete nonissue.
If they want to mess with you, they don't need your permission.  As is,
you've explicitly asked them, "would you please sign certificate
0xDEADBEEF, fingerprint so-and-so, here's my credentials."  Then they're
signing it with *their* certificate, backed up by credentials that you
yourself checked.  How is this a problem?
You've been making hay out of this for years and I've yet to see any
realistic example of this being a problem.  Please present one.
Likewise, regarding making hay and a complete lack of realistic examples.

@_date: 2012-01-21 23:02:52
@_author: Robert J. Hansen 
@_subject: 1024 key with 2048 subkey: how affected? 
It depends entirely on what you're doing with it.  Breaking a 1024-bit
key is within the realm of possibility for a ridiculously well-funded
adversary.  It hasn't been publicly demonstrated yet, but it's a matter
of time.
Over a decade ago, the state of the art was to break a 56-bit keyspace
in under 24 hours for $250,000.  A 1024-bit key has about an 80-bit
keyspace, which is a factor of 16 million larger.  Given the advances in
supercomputing in the last decade it is reasonable to believe 1024-bit
keys are either breakable now or will be in the near future, but only at
incredible cost.
If I was signing nuclear weapon authorization codes, I would not trust
1024-bit DSA.  Nor would I trust it if I was signing a 30-year mortgage.
 On the other hand, for most normal email usage 1024-bit crypto is still
plenty enough.

@_date: 2012-01-22 13:36:44
@_author: Robert J. Hansen 
@_subject: Creating a key bearing no user ID 
The OpenPGP spec (RFC4880) says that a transferable public key (one that
can be shared, basically) is required to have one or more user IDs
attached (RFC4880 section 11.1).  If you don't have a user ID on your
certificate, you have no guarantees your certificate will be usable by
other people.

@_date: 2012-01-23 03:09:55
@_author: Robert J. Hansen 
@_subject: Creating a key bearing no user ID 
As am I.  However, it should be pointed out that this is no reason to
avoid using the keyservers.
One of the best ways to evaluate a defensive mechanism is whether it can
recover from a failure.  Consider securing your home.  A lock on the
front door is good, but once the thief is in past your front door the
lock is pointless.  It can't recover from a failure.
Being friends with your neighbor is a much better security mechanism.
If your neighbor doesn't see the burglars breaking in, they still might
see the burglars leaving, or be able to tell the cops "yes, there were
some strange people hanging around that place yesterday, watching it and
stuff, they were driving a...".  Even if in one particular moment your
neighbor fails, your neighbor can still come back to be a useful and
effective mechanism.  Good neighbors are a better security mechanism
than good locks.
(This may count as "old as the hills" wisdom: Proverbs 27:10 says
something like, "Better a neighbor nearby than a brother far away."
I've yet to find any 4,000-year-old proverbs extolling the virtues of
locks, much less any that are as true today as when they were first spoken.)
The same reasoning explains why keeping your email address hidden is a
poor spamfighting technique.  You have to *always* keep the email
address hidden, and the first time it gets published you have to assume
the spammers now have it.  All that time, effort, energy, stress and
frustration you put into keeping your email address unpublished is now
wasted: all you did was delay the inevitable by a few days, a few weeks,
maybe a few months.  Like the lock which, once bypassed, provides no
help whatsoever, your ascetic ways, once bypassed, give no benefit.
On the other hand, good spam detectors have wonderful failure recovery
modes.  If a piece of spam gets through, well, train the spam detector
to do a better job: the next time that spam won't get through.

@_date: 2012-01-23 10:47:34
@_author: Robert J. Hansen 
@_subject: Creating a key bearing no user ID 
All argument from analogy is intellectual fraud, but they can be useful
to illuminate arguments.  :)
So, you keep all your possessions there?  And eight hours a day you
sleep there, so you're completely oblivious to any danger I might
present to you?
Email addresses aren't physical addresses.  The consequence of one
falling into the hands of your enemies is far, far worse than the other.
 And just like a casual criminal doesn't care that a particular address
belongs to you, neither do spammers.
No.  Why would I, when the lock had clearly failed in the role I'd
placed it?  Once a component shows that it's failure-prone, a smart
person revises the plan.
For me, a lock is meant to do two things:
"Keep people out" is not one of them.  :)

@_date: 2012-01-23 12:18:35
@_author: Robert J. Hansen 
@_subject: Creating a key bearing no user ID 
This, of course, handwaves the fact that cryptography more or less
*can't* be implemented properly.  As long as human beings are in the
equation it will be misimplemented.  Consider the NSA's VENONA project,
which was able to break one-time pads when the KGB had a braino and
reused key material.
We're not talking about some high school student sharing a Facebook
password with someone.  This is the KGB, one of the most professional
intelligence agencies that's ever existed.  KGB agents were highly
motivated to practice good tradecraft, because if they didn't they might
get shot in the back of the head in the basement of the Lyubyanka.  So
even with the (substantial) organizational resources of the KGB, with
the (significant) communications security training given to KGB field
agents, with the (extreme) penalties for transgression, even then
somebody was dumb enough to reuse a key pad.
The lesson I take from this is that the phrase "properly implemented
cryptography" is about as useful as talking about absolute zero.  It's
useful to show what the limit is, but it can never be reached, and
anyone who believes they are immune to this is the lawful prey of those
who know otherwise.

@_date: 2012-01-23 13:16:34
@_author: Robert J. Hansen 
@_subject: 1024 key with 2048 subkey: how affected? 
How do you enforce that?  If it is technically possible to sign a
document with your primary key, then good luck telling a judge "no, Your
Honor, this signature isn't valid, it was made with my primary key and I
only use my signing subkey for documents."
You may say the only purpose of the primary key is to sign the subkeys,
but if it's technically possible for the primary key to sign documents
then the purpose of the primary key is to sign documents.
This is why I think it's kind of absurd to have a larger signing subkey
than the primary key.  The weak link in the chain is going to be the
primary key.

@_date: 2012-01-23 14:25:24
@_author: Robert J. Hansen 
@_subject: Creating a key bearing no user ID 
This is not what I read from your first statement.
This claim is false.  There is no such thing as unbreakable crypto: it
does not exist anywhere.  If perfect physical security is impossible and
perfect implementations are impossible, then they're both equally
unrealistic and there's not a lick of difference between them.
The example was not flawed.  What you're seeing as a flaw is the point I
was making, which is that there is no such thing as "properly
implemented cryptography."
As an example, GnuPG is certainly competently implemented cryptography,
but nobody knows whether it is implemented correctly.  Some years ago
there was a critical bug with Elgamal signing keys (which is why we can
no longer generate Elgamal signing keys: the feature was removed).  No
one considers this bug to be a reflection on the professionalism of the
GnuPG developers: the bug was subtle, survived code review by many
people, and could have arisen in any software development process.  But
the fact remains that Elgamal signatures in GnuPG were not implemented
properly and the entire security of GnuPG-generated Elgamal signatures
was in jeopardy as a result.
If you believe GnuPG is "properly implemented," well, all right: but did
you also believe that before the Elgamal bug?  If you did, then
apparently the mechanism by which you come to these conclusions is
defective, and perhaps a little skepticism is warranted.
The phrase "properly implemented cryptosystem" should never be used
except in a context of skepticism that such a beast has ever existed, or
could ever exist.

@_date: 2012-01-23 17:11:21
@_author: Robert J. Hansen 
@_subject: 1024 key with 2048 subkey: how affected? 
Emphatic agreement -- this is clarification, not dispute:
A lot of people like to refer to _Applied Cryptography_ or _The Handbook
of Applied Cryptography_ for information on algorithms, and for very
good reason: they've generally got excellent information.  They are also
old books.  _AC_ is coming up on twenty years old, for instance, and
_HoAC_ isn't much younger.  At the time these books were written the
jury was still out on whether ECC had firm theoretical underpinnings.
Nowadays the jury is back, and ECC is generally recognized as being as
reputable as RSA, DSA or Elgamal. [1]
ECC will be coming to OpenPGP sooner or later, and probably sooner.  I'd
be astonished if we didn't have ECC by, say, 2017.
[1] You can thank Fermat for this.  It turns out that proving Fermat's
Last Theorem was instrumental in establishing the correctness of ECC.
In 1995, Andrew Wiles proved the Taniyama-Shimura conjecture over
semi-stable elliptic curves.  This in turn proved Fermat's Last Theorem,
and directly led to cryptographers having confidence in elliptical curve
cryptography.  So the next time someone presents Fermat's Theorem as a
mathematical curiosity with no practical purpose, tell them the next
generation of encryption algorithms begs to differ...

@_date: 2012-01-23 19:22:49
@_author: Robert J. Hansen 
@_subject: Creating a key bearing no user ID 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Not in the slightest.  The idea is certainly worthwhile.  It's just
that there's no implementation of it, nor even a solid idea of how to
implement it.  If we're going to play a game of "wouldn't it be nice
if," I'd like honest politicians, stronger beer, and lower taxes.
I am skeptical that such a thing can be done, and for that reason
elect to not spend time on it.  But please don't misrepresent my
position, or that of others who share my position, as believing that
"privacy is unimportant."

@_date: 2012-01-23 19:25:53
@_author: Robert J. Hansen 
@_subject: Protecting IDs at a key signing party 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
If you need to know the certificate they use to sign your certificate
contains UIDs related to the credentials you were shown, then you need
to stop using OpenPGP.  You literally cannot get this level of
assurance.  Anyone can sign your certificate and share it with someone
else, and there's no way to change that.

@_date: 2012-01-24 23:35:35
@_author: Robert J. Hansen 
@_subject: Creating a key bearing no user ID 
My own experience may be worth mentioning.  I had (have) an email
account that's only ever mentioned in one place, on a certificate of
mine.  For several weeks it received no spam, and then in the space of a
couple of days the spam volume was indistinguishable from any other
account.  My conclusion from this is once the spammers know they have a
hit, they share your email address quickly.  The deluge goes from "a
trickle" to "a firehose" in the space of a day or two.
While these questions are certainly apt, I'd like to see a firm
theoretical foundation for the idea.  We don't have a solid theory for
how to achieve MFPA's desired end.  Until we do, I think all discussion
about implementation is premature.
Without a strong theoretical foundation, talk about blinded hashes of
email addresses is sort of like talk about perpetual motion machines:
yes, it would be lovely to have them, but we don't have the first clue
how to do it.  The burden is not on the critics of these ideas to prove
they are impossible: the burden is on the advocates of these ideas to
show they are possible.
Casting aspersions as to the motives of critics puts one in the same
ranks as cancer cure quacks who defend themselves against their critics
in mainstream oncology by saying, "well, of course they want you to stay

@_date: 2012-01-26 12:03:14
@_author: Robert J. Hansen 
@_subject: hashed user IDs redux [was: Re: Creating a key bearing no user ID] 
I've not hidden my opinion that I think this is an exercise in quixotry,
but still, never let it be said I wasn't willing to make some
contribution to an idea.  Let's not talk about implementation details:
right now we don't have a good enough handle on the problem to talk
about how to solve it.  So let's see if we can't use a 'Problem',
'Goal', 'Requirements' and 'Constraints' model to focus the conversation
a little bit.
  * Some people want to make it possible to opt out of their email
    addresses being harvestable on the keyservers.
  * Give users an optional way to make their user IDs resistant to
    harvesting.
  * The solution must work within the OpenPGP framework without
    requiring any extensions.
  * The solution must work with SKS without requiring any extensions.
  * The User ID must be searchable (otherwise the solution is trivial,
    create a User ID with a name but no email address).  If a user
    searches the keyserver for exactly a given email address, matching
    certificates must be returned.
  * Key enumeration.  There are only roughly 10 million login names
    five characters or less.  Searching those 10 million login names
    over the top 100 email domains amounts to about a billion queries.
    Split over a botnet of 100,000 elements, each bot would have to
    make 10,000 queries.  Even if each query took one second (an
    unreasonable number: it would substantially impact OpenPGP adoption
    because people would be furious over the slow speed of lookups),
    that means a spammer network could break any such blinded hashing
    scheme in about three hours.
  * Utility.  One way to make a blinded hashing scheme enumeration-
    resistant is to put a large amount of random data in there.
    However, searching for 'zz78gH1Y== is of comparable
    complexity to searching for a certificate ID.  The system must
    work for all reasonable User IDs, rather than requiring User IDs
    to be unreasonable.
... Looking over this, I don't think that what MFPA wants is possible.
I just don't.  The key enumeration issue and the ease of getting past
it, *even if we require each search to take one second to execute*, is
the gorilla in the center of the room that's threatening to pound to a
pulp anyone who seriously tries to take on this problem.
If we discard the "must conform to OpenPGP" and "must be compatible with
SKS" requirements, then maybe we could make it work.  But as is, if I
was asked to evaluate this research project, I would call it extreme
risk for minimal reward.
"Risk", in an engineering management context, usually means "risk of
failure and wasting all the resources invested."  The risk level seems
Even if you succeed, how many people will join up?  How many people will
revoke their old User IDs and create new ones?  Few, I think, which
makes this minimal-reward.  Even if you succeed, you'll impact only a
very small fraction of OpenPGP users.

@_date: 2012-01-26 20:29:07
@_author: Robert J. Hansen 
@_subject: hashed user IDs redux [was: Re: Creating a key bearing no user ID] 
The use is correct.  Spamming is what someone does once they have your
private information: harvesting is the act of collecting.
One windmill at a time, my ingenious gentleman of La Mancha.
"Necessary" is a strong word.  The consequence of extending it is you
get to be the one to write the extensions (both in RFC and source-code
form) and maintain them across a whole raft of other operating systems
and hardware configurations.
A local proxy is not an extension.  An extension means "we're going to
break conformance with the OpenPGP spec" or "we're going to break
compatibility with the SKS keyserver network."
If you break conformance with the OpenPGP spec, then you get to build
the new spec.  If you break compatibility with the SKS network, then you
get to build a new network to replace it.
I have been waiting for you to realize this.
*Even if you solve the key enumeration problem, you solve nothing.*  It
doesn't get you anything, because the email enumeration problem is just
as bad.
And yet, my two unlisted cell phones both routinely get robocalls and
telemarketers.  They, too, work by enumeration.

@_date: 2012-01-28 00:14:49
@_author: Robert J. Hansen 
@_subject: Why hashed User IDs is not the solution to User ID enumeration 
(John undoubtedly knows this, but I suspect a lot of people didn't catch
the implications -- so let me elaborate.)
SKS is a surprisingly lightweight thing: it requires very little in the
way of CPU usage, even when making large updates.  (My keyserver is
currently running with a load of 0.06.)
As soon as keyservers have to do bignum arithmetic on certificates,
you're going to see a lot higher CPU loads.  This doesn't mean "we
should never ever do it," but it does mean before doing such a thing
there would have to be broad consensus from the keyserver community to
do it.
It isn't just that no one's written the code: it's there's no community
consensus to deploy such code, even if it were written.  It would be a
pretty major flag day.  After all, if one keyserver enforces it and
others don't, then that's going to create a pretty obvious syncing problem.
It is, as he said, "a really big step."

@_date: 2012-01-28 03:05:52
@_author: Robert J. Hansen 
@_subject: Why hashed User IDs is not the solution to User ID enumeration 
There's also a human factors element, which we're currently handwaving.
 If I have a copy of 0xDECAFBAD's certificate that has five UIDs, all of
which have trusted signatures on them, and a second copy that has seven
UIDs, five of which I consider valid due to having trusted signatures on
them, well -- which of the two is canonical?
The OpenPGP answer is "neither: validity and trust are not the same as
However, human beings tend to get rather obsessed with canonicity.  Look
at the kerfuffle over our President's birth certificate record.  The
original one is on file somewhere in a Hawai'i government office: a
differently-formatted copy of the birth certificate was given to the
press.  Both documents are equally valid.  Neither document is
canonical.  The U.S. public had a hard time wrestling with that: a whole
lot of people sincerely believed the presence of two equally-valid but
differently-formatted birth certificate records meant something was hinky.
Now imagine explaining to new OpenPGP users that "yes, sometimes you'll
get a copy that has 5 UIDs and sometimes you'll get one that has 7,
depending on which keyserver you query, but both of them are equally
valid."  Same thing.
And before anyone says, "well, yeah, but the huge deal about the
President's birth certificate was the product of a whole lot of
political paranoia by whackjobs," I will point out that one thing our
community has *never* lacked for is paranoid whackjobs.

@_date: 2012-01-28 03:26:07
@_author: Robert J. Hansen 
@_subject: Why hashed User IDs is not the solution to User ID enumeration 
We have two scenarios: either the no-modify keyserver retains all the
now-ignored signatures or else it doesn't.  For sake of argument, let's
call the no-modify keyserver 'Alice', and the old keyserver 'Bob'.
Scenario 1: Alice throws away the now-ignored data.
Bob: Hi, Alice!  Let's sync.
Alice: Hi, Bob!  I see we have different records for 3,731 certs.
Bob: Here you go, Alice!
Alice: Thanks.  [reads 3,731 certs, strips off now-verboten UIDs]
... five minutes later ...
Bob: Hi, Alice!  Let's sync.
Alice: Hi, Bob!  I see we have different records for 3,731 certs.
Bob: Here you go, Alice!
Alice: Thanks.  [reads 3,731 certs, strips off now-verboten UIDs]
[24 hours and a few million redundant cert exchanges later]
Scenario 2: Alice retains the now-ignored data, serving to GnuPG
    clients the version that honors no-modify, and serving to
    other keyservers the full version
Bob: Hi, Alice!  Let's sync.
Alice: Are you a GnuPG client or a keyserver?
Bob: [glazed look in his eye]  I'm sorry, Alice, that's not
    a request I understand.  I'm an SKS keyserver, version 1.1.2.
    Could you repeat?
Scenario 2a: As with 2, but now we have an SKS 1.1.3 that somehow
    identifies itself as being a keyserver and not a GnuPG client.
Bob: Hi, Alice!  Let's sync.
Alice: Are you a GnuPG client or a keyserver?
Bob: Why, a keyserver, of course.
Alice: Cool!  Here, have these certs, complete with the data that
     you shouldn't distribute outside of the keyserver network.
     Remember, that stuff is for us to use for ease of sync, not
     to be given to end-users under any circumstances, or else
     they'll wonder what the point is in the no-modify flag!
Bob: Uh.  Sure.  Whatever you say, Alice.  (Bob, being a 1.1.3
     SKS server, has no idea what Alice is talking about: he
     doesn't support no-modify.)
Scenario 2b: As with 2, but now imagine you have a malicious host,
Mallory, who wants to get full certificates.
Mallory: Hi, Alice!  Let's sync.
Alice: Are you a GnuPG client or a keyserver?
Mallory: [twirls Snidely Whiplash moustache] A keyserver!
Alice: Here, have all these certs, complete with the UIDs that
    shouldn't be distributed outside the keyserver network!
... Short version: for no-modify to work with the existing keyserver
network, everyone would have to make the cutover or else the network
would drown in sync messages.  There's a real possibility that if just a
few hosts didn't make the cutover that the keyserver network could go
down, DDoSing itself into absolute oblivion as it desperately tried to
sync keys infinitely.

@_date: 2012-01-28 10:00:09
@_author: Robert J. Hansen 
@_subject: hashed user IDs redux [was: Re: Creating a key bearing no user ID] 
And, as we've said several times, we run into the key enumeration problem.
This does not address the key enumeration problem.
MFPA, we've already spent much more time on this issue than I think is
warranted.  Your idea would be nice if it could happen, but it does not
appear to me to be possible.  There is no theoretical understanding of
how to solve the problem and no implementation offered that comes
anywhere near to passing my sniff test.
I can't speak for anyone else, but I'm done.  I will not be addressing
this subject again until such time as things change.

@_date: 2012-01-29 20:41:04
@_author: Robert J. Hansen 
@_subject: Netiquette (was RE: Meta) 
The name of the game, to me, seems to be ensuring the lowest common
denominator of communications.  If there's no need for HTML, why use
HTML?  If there's no need for attachments, why use attachments?  If
there's no need for a long subject line, why use it?
The Right Thing To Do appears to me to be UTF-8, plain text whenever
feasible, no attachments whenever feasible, coupled with healthy doses
of "please," "thank you," and a cheerful acceptance of the fact that
ultimately the only communications you control are your own.  :)

@_date: 2012-01-30 10:34:32
@_author: Robert J. Hansen 
@_subject: Enigmail and PGP/MIME (was Re: META) 
There is no "Enigmail-approved" reason.  Everyone on the Enigmail team
who's contributed to this decision has their own reasons for their
support of PGP/MIME or lack thereof.  These are mine.
Fact one: we estimate we have a few tens of thousands of casual users,
many of whom send us their problems directly rather than going through
the mailing list or forums.
Fact two: it's easy to find MUAs, MTAs and other software in the chain
that don't support (or outright break!) PGP/MIME.  Outlook is a good
example of this, and until fairly recently Mailman was, too.  Over time
PGP/MIME support gets better, but today it's still nowhere near perfect.
Add those two facts together and you'll see that I advocate defaulting
to inline PGP for sake of my own sanity.  Speaking for myself, I do not
believe PGP/MIME is ready for mass deployment to end-users.  The
infrastructure isn't there: there are still too many buggy clients.
This has been getting better and it will continue to get better.  Once I
go a solid year without getting a message from a frustrated Enigmail
user telling me that Enigmail has a bug because his or her signed posts
to a mailing list keep on breaking, then I'll support switching to
PGP/MIME by default.
The last time I got one of those messages was November.  Let's hope...

@_date: 2012-01-30 12:15:34
@_author: Robert J. Hansen 
@_subject: Enigmail and PGP/MIME 
Out of the box, Outlook doesn't support PGP/MIME and won't even render
the plain text portions -- or, at least, such was the case the last time
I checked Outlook, which was some time ago: I try to avoid dealing with
Outlook whenever possible.
Thunderbird at least will render the plaintext.
I'm certainly not disagreeing with any of this.

@_date: 2012-01-30 18:40:08
@_author: Robert J. Hansen 
@_subject: PGP/MIME use (was Re: META) 
Well, in defense of that interpretation, RFC4880 just specifies a packet
format and ASCII armoring -- it's deliberately silent on everything from
RFCx822 integration to concerns about using it as the basis for disk
encryption products.
I would favor seeing an "OpenPGP best practices" RFC.  4880 tells us
what's legal OpenPGP traffic, but says nothing about what's worthwhile.
This comes fairly close to my own practices, with one significant
exception: since it's almost impossible for me to know whether all the
MUAs used on a mailing list support PGP/MIME, I feel it's better for
mailing list traffic to be inline.
Of course, I really feel it's better for mailing list traffic to not be
signed at all, since usually all it gives us is a false sense of
security.  A signature from an unvalidated key belonging to an unknown
person whom we don't know from Adam doesn't mean much, if anything at all.

@_date: 2012-01-31 13:46:05
@_author: Robert J. Hansen 
@_subject: PGP/MIME use (was Re: META) 
This works if and only if the "right parties" are a large enough market
to push implementations around like that.  Enigmail isn't.  Assume we
have 50,000 installations.  (This sounds like a lot, but it's a pale
shadow compared to GnuPG installations.)  Of those, maybe 5,000 are
serious users and the rest are casual ones, people who saw it on Mozdev
and got intrigued and installed it and never really did anything with
it.  Those 5,000 users don't represent a single bloc, though: they're
spread out through a whole lot of different communities, where they
represent extremely small minorities within those communities.
As a for-instance, on my old high school class's mailing list I'm pretty
sure I'm the only person who's even heard of Enigmail.  If I were to
tell the list maintainers, "you need to upgrade your version of Mailman,
it's breaking my PGP/MIME signatures," the response I'd get would
probably be, "what's PGP/MIME, and why is it important, and why do all
your messages have those weird attachment things on them, anyway?"
No, you don't.
A few years ago on PGP-Basics one user threw a screaming fit over how
many users were not signing our posts to the list.  He insisted that
signatures were meaningful, that they proved the person with that
certificate is the author, and so on.
John Clizbe, John Moore and I conducted a little experiment.  We created
a single certificate.  All three of us used the exact same certificate
to sign our posts to PGP-Basics.  The person who was most up in arms
about our lack of signing was placated, and thanked us for seeing the light.
It was another few months before anyone realized we were all using the
same certificate.
Honestly, up until that point I thought that maybe there was some
utility to mailing list signatures.  Maybe.  That experiment changed my
mind: I now see no utility to them for the vast majority of uses.

@_date: 2012-01-31 17:54:32
@_author: Robert J. Hansen 
@_subject: PGP/MIME use 
Putting a kludge in email headers or a "OpenPGP Key ID: 0xD6B98E10" in
the sigblock seems to be a more efficient method of achieving this end.
Given this is an awful heavyweight way to achieve an end that's just as
correctly achieved via lightweight means, I don't see this as a reason
to sign messages.  To add a sigblock, sure.  :)

@_date: 2012-07-09 19:12:28
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
I feel like I've said this several times in the past few months.  Let me
say it one more time, loudly:
DON'T USE --cipher-algo OR --digest-algo UNLESS YOU KNOW EXACTLY WHAT
YOU'RE DOING AND WHY.  IT'S EASY TO CREATE MESSAGES YOUR RECIPIENT
CANNOT READ.  USE THE --personal-X-preferences INSTEAD.
I feel like I ought apologize for shouting, but really, this has been
said so many times in the last couple of months that I'm getting really
frustrated with correcting the "oh, just use --X-algo!" misadvice that
gets handed out so often.

@_date: 2012-07-09 23:10:27
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
PGP 8.0 or before.  SHA-256 was introduced in 8.1, if I recall
correctly.  There are still a *lot* of people using 6.5.8.

@_date: 2012-07-10 05:02:34
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
The short answer is, "because it has to, and because you've configured
it that way."
What are the contents of your personal-digest-preferences?
Also note that you're using a 1k DSA key for signing, so is it really so
surprising you're using a 160-bit hash algorithm?

@_date: 2012-07-10 05:19:45
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
It is still substantially accurate and useful, as near as I can tell.
(I still think cert-digest-algo sha256 is unnecessary at this point in
time, but I understand why he believes otherwise, and his perspective is
hardly an unreasoned one.)

@_date: 2012-07-10 10:10:12
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
At the present moment, SHA-1 is just fine.  In the fairly near future,
anywhere between six months to a few years, I expect this will change.
But "SHA1 is no longer secure" is factually untrue, at least where
OpenPGP is concerned.
I don't recommend SHA-1 for new signatures, but if you have a choice
between sending a SHA-1 message which your recipient can verify
or a SHA-256 message which your recipient can't, well -- that math's
pretty easy to do.  SHA-1 isn't a good choice for new signatures, but
it's a lot better than no signature.
The good news is that no one's asking you to.  You're only being
advised, "don't use --digest-algo SHA256, it's unwise and can break
interoperability.  Use --personal-digest-preferences SHA256 instead."
This is the same advice that has been given by the GnuPG developers, by
the Enigmail team, and by many other people within the community.  It's
a best-practices thing for GnuPG.
Don't use --digest-algo.  Use --personal-digest-preferences.  That's all.

@_date: 2012-07-10 16:47:02
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
I apologize for repeating myself here: I don't mean to be condescending,
but apparently my answer was not clear.  I'll try to be more clear.
You're using a DSA-1k key.
It's limited to 160 bits.  That means you cannot use SHA256.  The best
you can get is SHA256 truncated down to 160 bits, but at that point
there's no difference between SHA256 and RIPEMD160.  They both have the
exact same margin of security: there are no known attacks against either.

@_date: 2012-07-10 20:15:32
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
Yes.  This is not the same as being *insecure*, though, which is what
was claimed.  Moving from "cryptographically broken" to "insecure/dead"
is about as large a step as going from "nothing" to "cryptographically
MD5 was cryptographically broken in 1996.  We didn't see major practical
results against it until 2005 or so, and NIST didn't declare it to be
dead and should no longer be used until 2010.  There's some serious
lag time there.  SHA-1 will likely not have as long of a lag time, but
let's not go about pretending there is no lag time or that the lag time
has already elapsed.
There tends to be a lot of scaremongering in the world of crypto.  I
think it's generally wise to be careful in our declarations.  It is
enough to say SHA-1 is known to not meet its design specifications and
that some fairly devastating attacks against it will likely be coming
along in the near future.  That's already a good enough reason to reduce
our usage of and dependency upon SHA-1.  There's no need to fearmonger
about how the algorithm has already collapsed, because it hasn't.
Right now, only random collisions can be generated.  That's not any use
in forging a signature, which requires a preimage collision.  A
cryptographic break is not the same as a practical exploit.
Then you need to stop using OpenPGP altogether, because you're already
generating SHA-1 signatures with your certificate which can be lifted
and dropped onto new messages if/when a preimage attack is introduced
against SHA-1.
Let me make this really clear: if you believe SHA-1 is insecure, you
believe OpenPGP is insecure and you should stop using it.  SHA-1 is
hardwired into the OpenPGP spec in a few different places and, as of
right now, cannot really be removed.  The new V5 key format will almost
certainly change this, but V5 won't be coming out for a good long while yet.
You've *already done this*.
If you truly believe this, stop using OpenPGP.

@_date: 2012-07-10 20:27:54
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
After re-reading this, I need to back off from this paragraph a bit.  I
apologize -- I've been up for almost 24 hours now and my thinking is a
bit hazy.  I know SHA-1 is hardwired into the spec, but without going to
the spec and reading it closely I'm not 100% certain that SHA-1
*signatures* are hardwired into the spec, and frankly I'm too tired to
do a detailed read of RFC4880 right now.
My apologies.
The general point remains, though, that if you believe SHA-1 is insecure
then you need to stop using OpenPGP.  A preimage collision against SHA-1
breaks OpenPGP into a lot of tiny little pieces.  Little kids might
still find those pieces useful for gluing to paper plates and giving to
their parents to hang on refrigerators, but for the rest of us we're
unlikely to have any further uses.  :)

@_date: 2012-07-11 01:56:47
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
As soon as a V5 key spec is released, I'll revise my statement.  Until
then, OpenPGP has an unfortunate dependency on hashes that do not have
good long-term prospects.  :)
V5 discussions will not kick off in earnest until NIST announces the new
hash standard, or so I've heard people from the working group say.

@_date: 2012-07-11 11:03:12
@_author: Robert J. Hansen 
@_subject: On signatures, enforcement and authentication 
First: This is not legal advice.  I am not a lawyer.  Consult a lawyer
in your jurisdiction if you have specific questions.  This is the
rantings of a semi-informed layman.
One of the big elephants in the room when talking about digital
signatures is that we conflate several different things under the name
"digital signature."  The two major ones are *enforceable promises* and
*message authentication*.  These two things are quite distinct.
A digital signature by itself means absolutely nothing.  What's
important is that as a society we have decided we will enforce the
solemnized promises made by our members: slightly less important, that
we have a legal framework to enforce these solemnized promises: and
utterly unimportant, the form in which these solemnized promises
manifest.  There have been successful lawsuits seeking to enforce
financial instruments that have been scrawled in Magic Marker on a
watermelon.  Whether the solemnization is a sworn oath before a notary
public, ink on a page, marker on a watermelon or bits on a hard drive is
really quite insignificant.
For a promise to be enforceable, it must be (a) made (b) unambiguously
(c) by parties able to make enforceable promises (d) and with mutual
benefit.  If I promise you that I'll give you a ride to the supermarket,
that's not an enforceable promise.  If I promise you that I'll give you
a ride to the supermarket and you promise to buy me a Diet Coke while
you're there, that's suddenly become an enforceable promise: we are both
mutually on the hook if we fail to live up to our obligations.
We have social mechanisms in place to support these four requirements.
Yesterday I signed a contract involving a large sum of money, but the
other party refused to simply accept my signature.  I had to go to a
notary public and present two forms of identification before signing the
document in the presence of the notary.  The other party to the contract
required this so that if we went to court I would have a very hard time
saying, "Your Honor, I never signed that contract."
We have other social, cultural and legal things, too -- a detailed list
would go on for literally dozens, if not hundreds, of pages.  The
important thing is that there are *basically* four requirements for an
enforceable promise, and we have a large number of tools to support this.
So, what's the relevance of this to SHA-1 and MD5?
Let me present to you an enforceable MD5 signature.  You and I agree to
a sale of stock.  We want to do it completely electronically without any
paper records.  Neither of us trusts the other, and we're stuck using
PGP 2.6 with its whole slew of problems: MD5, V3 keys and more.
I send you a list of notary publics that I trust.  You choose your own
notary public from that list and visit the notary.  I've already sent a
copy of the document I wish for you to sign to that notary.  The notary
checks your ID, tells you to read the document, and if you wish to
assent to it to electronically sign the document in his presence.  You
do so.  The notary retains a copy of the contract, your digital
signature, a photocopy of your ID and so forth.  On my end, I do the
same thing with a notary chosen from a list of ones that *you* trust.
The notary I trust sends me your signed assent to the agreement, the
notary you trust sends you my signed assent to the agreement.  Now if
either of us wants to break that agreement, how do we do this?  The
notaries will confirm that we read the agreement in their presences and
signed the documents.  Maybe you'll be able to argue that it wasn't you
who signed, but an impostor armed with fake ID.  Maybe you'll be able to
claim the contract was ambiguously worded and should be interpreted in
your favor.  Maybe you can claim you were deranged and should not be
held responsible for your choices.  Maybe you can... etc.
But none of those methods of repudiation have anything to do with
cryptography or the weaknesses of MD5.  And none of those methods of
repudiation would be foreclosed or impossible if you were to use OpenPGP
with SHA256-based signatures.
The preceding is, of course, completely irrelevant when you're trying to
verify the signature on a software package.  Here there's no desire to
enforce a promise.  All that you're trying to do is to ensure the
provenance of a message, and that's where things like MD5 and SHA-1
weaknesses become very, very troubling.  No argument there whatsoever.
In the preceding example, the digital signature is phenomenally robust
because there are trusted parties mediating the entire thing and human
judgment is exercised throughout the process.  In a
verify-the-provenance situation, though, usually it's a completely
automated process without either trusted mediators or human judgment.
The important takeaway is this --
"Digital signature" is a phrase that covers an awful lot of ground.  In
some contexts digital signatures don't need any kind of collision
resistance: just typing in "I agree to the terms of the above" would
both be sufficient and enforceable.  In other contexts you need as much
collision resistance as possible.
Ray Lee once said, "Every truth has a context."  I'm not sure *every*
truth has a context, but declaring certain hash functions as insecure
for use in digital signatures is definitely context-sensitive.  I think
it would be good if we were to keep that in mind when talking about
digital signatures -- it's possible for two people to be using the same
words but have two completely different use cases in mind, and in the
process have two completely different conversations.

@_date: 2012-07-11 11:11:44
@_author: Robert J. Hansen 
@_subject: How to "activate" gpg.conf entries? 
I would suggest "SHA256 RIPEMD160", myself.  There are no known attacks
on RIPEMD160, and if you're in a situation that requires the use of a
160-bit hash it will allow you to fall back to a still-trusted hash
rather than SHA-1.
That's not what cert-digest-algo does.
There's nothing technically wrong with this, but I'd advise doing
something different.  Remember, the preflist on a certificate is
(somewhat) misnamed: it's meant to show both capabilities *and*
preferences.  For instance, you can use Blowfish and Twofish and
Camellia256 and whatnot.  These are all believed to be safe, so there's
really no reason to omit them from your certificate prefs.
Push SHA-1 to the back of your hash prefs, certainly -- but if you don't
have a strong reason to omit believed-safe algorithms from your pref
list, I would consider it best to include them.
Sign a message and send it to the list.
Don't forget to add "enable-dsa2" to your gpg.conf file *if* (a) you're
using a DSA-1k signing key and (b) you want to be able to use truncated
SHA256 with it.

@_date: 2012-07-11 11:13:46
@_author: Robert J. Hansen 
@_subject: scope of standard authority 
The entire point of a standard is to allow interoperation.  That means
there has to be some final fallback mode.  SHA-1 is that fallback mode.
 With luck we'll see this get changed once the new hash standard is

@_date: 2012-07-11 15:41:45
@_author: Robert J. Hansen 
@_subject: How to "activate" gpg.conf entries? 
True, but I'm not certain I believe SHA256 is much better.
Let's look over the history of Merkle-Damg?rd hashes:
MD2 (broken 1997, preimages 2004)
MD4 (broken 1991, preimages 2008, can generate collisions with
     pen and paper!)
MD5 (broken 1996, preimages 2012 presumably, based on public
     reports about Flame)
SHA-0 (broken 1998, no preimages)
SHA-1 (broken 2005, no preimages)
RIPEMD (broken ... uh ... when?)
SHA256 (unbroken)
RIPEMD-160 (unbroken)
History has not been kind to the Merkle-Damg?rd construction.  The fact
OpenPGP only contains Merkle-Damg?rds has always bothered me: I'd feel
much better if WHIRLPOOL had been standardized and included in the list.

@_date: 2012-07-11 16:27:15
@_author: Robert J. Hansen 
@_subject: Intro. 
You may also be interested in joining the Enigmail users mailing list:
As a general rule, you'll get faster responses to Enigmail questions on
that list, and faster responses to GnuPG questions on this list.
Welcome to the community.  We hope you'll find information that's useful
to you!  :)

@_date: 2012-07-11 23:36:02
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
This is not necessarily relevant.
Here's a thought experiment for you.  Someone creates a DSA-1k key and
uses --cert-digest-algo SHA256 and --enable-dsa2.  This creates 160-bit
truncated SHA256 hashes.
This person is at risk from a SHA-1 preimage collision, *despite the
fact they've never generated a single SHA-1 signature*.
All the attacker has to do is create a message which SHA-1s out to the
same value as the truncated SHA-256 of a legitimate message.  At that
point, the forgery becomes possible.
I don't specifically know how you're using SHA-256.  Nor do I especially
want to know.  What I do know is that there are a surprising number of
ways a SHA-1 preimage attack can screw over even people who have never
used SHA-256.
Don't put too much faith in "if I switch to SHA-256 I don't need to
worry about the SHA-1 attacks."  It's probably not true.

@_date: 2012-07-12 00:33:17
@_author: Robert J. Hansen 
@_subject: why is SHA1 used? How do I get SHA256 to be used? 
You're arguing two different contradictory things here:
And then:
The relevant property can be resistance to preimage attack or it can be
collision resistance.  Pick a property and argue it, please.  :)
I am far more concerned about preimage attacks (which are the ultimate
game-over) than random collisions (which affect a smaller fraction of
the userbase).  I'm not saying that random collisions are not troubling
in their own right.
Refer to my subsequent message, where I backed off from that statement
and clarified I was referring to the poster was already relying on the
safety of SHA-1 -- and was just in denial about it.
If you believe SHA-1 is insecure and you want to avoid it at all costs,
you need to avoid OpenPGP.

@_date: 2012-07-12 11:52:17
@_author: Robert J. Hansen 
@_subject: cert-digest-algo clarification 
There's a difference between what you can enforce and what you might be
able to suggest.
The OpenPGP spec requires that no OpenPGP implementation will ever use
any algorithm except those that are listed on your certificate as ones
that your implementation understands.  This list of "I can understand
the following algorithms" can be found by 'gpg --edit-key [keyid] showpref'.
Some OpenPGP implementations, such as GnuPG, will treat that set of
capabilities as a list of preferences.  If your prefs show up as "SHA256
SHA-1", for instance, an OpenPGP implementation would be forbidden from
using RIPEMD160, but would be able to use SHA1.  GnuPG would likewise be
forbidden from using RIPEMD160, but would be more likely to use SHA-1
than SHA256.
GnuPG might still use SHA-1, though!  If the sender is using a DSA-1k
key and does not have --enable-dsa2 active, SHA256 is disallowed for the
signature, so GnuPG will have to fall back to SHA-1.
The takeaway here is that the capabilities shown on your certificate
("gpg --edit-key [keyid] showpref") MAY be used as a preference list,
are not guaranteed to be used as a preference list, and even if using an
OpenPGP implementation that treats it as a preference list you may wind
up getting stuck with SHA-1 anyway.
No.  personal-digest-preferences declares which digest algorithms you
prefer to use and in which order.  The certificate preferences declare
which algorithms you are *capable* of using (and, for some
implementations, which algorithms you prefer *other people* to use and
in which order).

@_date: 2012-07-12 11:55:24
@_author: Robert J. Hansen 
@_subject: cert-digest-algo clarification 
Reverse those two, please.  Clearly I need to go drink coffee directly
from the pot -- I'm making far too many errors today.

@_date: 2012-07-12 12:34:49
@_author: Robert J. Hansen 
@_subject: cert-digest-algo clarification 
(Many people on this list have passionate feelings about HTML email.  I
understand these feelings and sympathize, but sometimes HTML is very
useful for drawing particular attention to text.)
You're quite welcome.
Things will become more clear if you actually do the gpg invocation I
mentioned earlier.  :)  For instance, this is what happens when I type
gpg --edit-key 0xD6B98E10 showpref.  There's a lot of spam in the
output, but the relevant stuff is relatively easy to find and is in
boldface.  (If you want to follow along yourself, just gpg --keyserver
pool.sks-keyservers.net --recv-key 0xD6B98E10, and then run the gpg
--edit-key command.)

@_date: 2012-07-12 12:38:21
@_author: Robert J. Hansen 
@_subject: cert-digest-algo clarification 
The preferences on the key are, as I mentioned, really a capability set,
but other GnuPG implementations will treat it as the algorithms you
prefer other people to use *when creating traffic meant for you*.
personal-X-preferences applies to mail you send others.  The preferences
on your certificate apply to mail others send you.

@_date: 2012-07-12 12:46:11
@_author: Robert J. Hansen 
@_subject: cert-digest-algo clarification 
Hauke, life's too short to be mean.  If you're getting frustrated, then
perhaps it would be best for you to take a step back and let someone
who's not frustrated field the question.  :)

@_date: 2012-07-12 13:59:43
@_author: Robert J. Hansen 
@_subject: cert-digest-algo clarification 
This is not recommended.
The codes are meant for machine use.  They're easy to parse and machines
never get confused between "H1" and "H2".
The names are meant for human use.  They're easy to read, easy to
understand, easy to remember.

@_date: 2012-07-16 09:11:23
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 106, Issue 5 
On Windows Vista and above, look in:
C:\Users\[your user name]\AppData\Roaming\GnuPG
On Windows XP, look in:
C:\Documents and Settings\[your user name]\Application Data\GnuPG
It's not a dumb question at all, and we're happy to help.  :)

@_date: 2012-07-16 18:51:59
@_author: Robert J. Hansen 
@_subject: getting gnupg keys from old computer to new 
Find the GnuPG configuration directory (on Windows XP it's usually
C:\Documents and Settings\[username]\Application Data\GnuPG, on Windows
Vista and beyond C:\Users\[username]\AppData\Roaming\GnuPG) and copy
that to the appropriate directory on your new laptop.
Once you've copied it, go into the directory and delete the random_seed
file.  random_seed should never be copied between machines.

@_date: 2012-07-22 16:52:44
@_author: Robert J. Hansen 
@_subject: KeePass or any other password wallet to store and transport keys 
Not necessarily.  This idea of 'stacking algorithms improves strength'
is tempting, but it can just as easily reduce strength or do nothing.
Imagine you have a simple substitution cipher, where each letter gets
moved up three positions in the alphabet (ROT3).  Then, in order to make
this 'stronger', you re-encrypt it using ROT5.  You're not producing
'two levels' of encryption which have to be broken individually, you're
producing a single ROT8 encryption and fooling yourself about the level
of security you actually have.
Cryptography is a subtle art, and algorithms interact with each other in
deeply surprising and counterintuitive ways.  Before advocating that
algorithms be composed together to achieve certain results, it's good to
make sure that these compositions are cryptanalytically sound.  :)

@_date: 2012-07-22 21:16:25
@_author: Robert J. Hansen 
@_subject: KeePass or any other password wallet to store and transport keys 
"Might," sure, although for modern crypto it's quite unlikely.
Far more likely is a situation where you just don't meet your goals.
For instance, if you encrypt data once with a DES key and then encrypt
it again with a different DES key, you might think this would be 'two
layers' of crypto.  In reality, there is always a third DES key which
will be equivalent to encrypting with the first followed by encrypting
with the second -- it's the real-world analogue of the "ROT3 followed by
ROT5 is just ROT8" example I gave.
The real concern here isn't making the overall system weaker: it's
fooling yourself into thinking you've made the system stronger, when in
reality you probably haven't.

@_date: 2012-07-23 03:25:46
@_author: Robert J. Hansen 
@_subject: KeePass or any other password wallet to store and transport keys 
D'oh.  I don't know offhand which cipher I was thinking of (it's 3:30am
and I'm about to hit the sack), but you're right, clearly I could not be
thinking of DES.

@_date: 2012-07-24 04:39:04
@_author: Robert J. Hansen 
@_subject: Is there a GnuPG command that shows the number of keys on a 
On Linux, FreeBSD, OS X, etc., you can do:
$ gpg2 --list-keys|grep "^pub"|wc -l

@_date: 2012-07-25 01:12:45
@_author: Robert J. Hansen 
@_subject: KeePass or any other password wallet to store and transport keys 
I'm unaware of any reputable reference that recommends this practice.
That's not to say no such reference exists, only that if one exists I'm
unaware of it.
The better question, to me at least, is "why would I want to do this?"
Cryptosystems tend to fail predominantly due to human error, then to
software bugs.  Consider that since PGP 2.6 was released in ... what was
it, '91? ... not one single encryption algorithm used by PGP has ever
been broken.  Although IDEA is not well-regarded by modern standards
it's still a safe cipher; and RSA is still, well, RSA.
If the algorithms are unlikely to be broken but the likelihood of
security-impacting software bugs is essentially certain, then stacking
algorithms would seem to be ill-advised.  Stacking algorithms increases
the complexity of the code, increases the number of keys which must be
managed, and so forth.  Rather than enhancing security, my suspicion
would be that it diminishes it by increasing the complexity of the system.

@_date: 2012-07-26 04:40:56
@_author: Robert J. Hansen 
@_subject: KeePass or any other password wallet to store and transport keys 
My understanding is they at least tolerate each other, but I'm unaware
of any serious analysis that suggests you enjoy increased cryptographic
strength by stacking them.  It wouldn't surprise me if you did, but at
the same time ... as I mentioned earlier, I really don't see the point.
This presumes I'm competent to have an opinion.  I really don't think I
am.  Evaluating cryptographic algorithms is almost as hard as designing
them.  It's the sort of thing that's best done by a handful of experts
all looking at the algorithms through slightly different prisms of
experience and skill.
For instance, I don't like Serpent very much on account of how complex
it is.  My rule of thumb is, "if I don't believe an undergraduate in
computer science can understand this algorithm, how can I expect people
to implement this algorithm correctly?"  So, had I been on the AES
selection committee, I'd have given Serpent a thumbs-down.  Other people
with different perspectives would've given it thumbs-ups and
thumbs-down, and our ultimate recommendation would take into account all
the input of the different experts on the selection committee.
But whenever you ask one person for his or her opinion on a cipher, all
you're getting is one perspective, and you really need more perspectives
than that.
Still, you asked a question, and now that I've spent three paragraphs
explaining why you shouldn't trust my answer I'll give you my answer:
Most symmetric ciphers nowadays are built around Feistel networks.  We
have a lot of experience with Feistel networks: many algorithms built
around them have held up quite well over the years.  (3DES, for
instance, which pretty much every cryppie holds in a mixture of
distaste, disgust, fear, terror, awe and reverence, is built around a
Feistel network.  30+ years, no really meaningful results against it.)
Feistel networks make me happy: who doesn't like a track record of success?
Rijndael is not a Feistel cipher.  That doesn't mean it's bad, far from
it.  But if Feistel networks give me the warm fuzzies, then that means I
need to strike non-Feistel networks from my list.
I don't like Serpent's complexity: I think that leads to difficulty in
implementing it.  By comparison, I've implemented Twofish a couple of
times and have seen undergraduates implement it correctly.
So, yeah, for my money I prefer Twofish.  But I don't think you should
trust my opinion worth a damn.  :)

@_date: 2012-07-26 09:04:13
@_author: Robert J. Hansen 
@_subject: AES vs. Serpent vs. Twofish (was Re: KeePass or any other password 
Yeah, well -- this tends to get written by people who have a thing for
Serpent.  :)  The Serpent submission claimed that they tried to account
for as-yet undiscovered cryptanalysis by having a sort of "safety net"
against future discoveries.  The problem is that if you believe Serpent
on this, then you also probably need to believe Twofish and MARS when
they make similar claims.
My understanding is the AES voting went down like this: those who
preferred speed over larger security margins tended to go for Rijndael,
those who preferred larger security margins over speed tended to go for
Serpent, and pretty much everyone agreed that Twofish was an excellent
second choice.  Under some kinds of voting (approval, instant runoff,
etc.), Twofish would have won the AES competition as being the option
highly preferable to the most people.  Under the rules that were in
play, the first-place finish went to Rijndael.
It doesn't.  We're not talking about which algorithms are good: we're
talking about which algorithms I like.  :)
I like Feistel networks, and for that reason I tend to go for the
Feistel cipher of the three.  The fact Twofish is also simpler
implementation-wise is icing on the cake.
(Note that these lines are all somewhat arbitrary.  A Feistel network
that uses S-boxes is going to be very similar to a
substitution-permutation network, and vice-versa.  But still, Twofish is
pretty clearly Feistel, and AES and Serpent are pretty clearly not.)

@_date: 2012-07-29 10:08:08
@_author: Robert J. Hansen 
@_subject: Possible bug in gpg? 
At risk of seeming condescending --
There is no such thing as a known-plaintext attack on GnuPG.  There are
only known-plaintext attacks against the algorithms in GnuPG.
Since there are no practical known-plaintext attacks against any of the
algorithms in GnuPG, we can conclude this feature does not facilitate
any such attack.

@_date: 2012-07-31 15:25:00
@_author: Robert J. Hansen 
@_subject: gpg "simplified"? 
============================== START ==============================
This is not at all the case.
Set up a trusted introducer/certificate authority and presto, bang,
you're off to the races.  When Alice comes on board at the company, the
local authority generates a certificate for her, sets up her
Thunderbird+Enigmail installation (or choose-your-preferred-MUA), signs
her certificate, and has her certificate recognize the CA as a trusted
All Alice needs to do is choose her passphrase.  She can now communicate
securely with anyone inside the organization.  In order to communicate
securely with someone outside the organization, she calls up the
certificate authority and says, "I need to email some documents to Bob
over at another firm.  Could you please make this happen?"
The CA then calls Bob, does the identity check, fingerprint
verification, etc., and at the end of it signs Bob's certificate and
introduces Bob's certificate to the local keyserver.  The CA calls Alice
back and says, "Grab Bob's certificate from the local keyserver: you're
good to go."
At no point does Alice need to know anything about the Web of Trust.
All she needs to know is --
The rest can all be done automatically.
This cannot be done safely.
You must have physical control over the hardware for GnuPG to be used
safely.  "Drive-by" machines have uncomfortably high malware infection
rates.  Don't use GnuPG except on machines that you physically control
and are confident are free of malware.

@_date: 2012-05-31 23:29:28
@_author: Robert J. Hansen 
@_subject: F17 + smartcards: *not* fixed 
And as a follow-up to the follow-up: this fix does not persist after the
smartcard device is unplugged and reconnected.
This is vexing.  Time to look at it again in the morning.

@_date: 2012-06-03 16:07:38
@_author: Robert J. Hansen 
@_subject: GnuPG 2.1 Windows 7, pinentry does not allow paste, no way to 
Storing your passphrase in the clipboard is generally considered unwise
and harmful.  Your passphrase is a high-value secret: putting it on the
clipboard makes it visible to every other process on your system
(including malware!).
Pinentry's refusal to support C&P is not accidental or an oversight.
It's a deliberate design decision meant to help shield you from malware,
Trojans, and other skulduggery that people may use to discover your
It's fairly easy to hack the source to support C&P.  However, the last
it was asked about on this list the answer was "C&P will not be
supported and patches to enable C&P will not be accepted."

@_date: 2012-06-03 21:40:02
@_author: Robert J. Hansen 
@_subject: FAQ, take two 
The unofficial FAQ is approaching completion.  At this point I think
it's about two-thirds done.  By this I mean most of the writing is
complete.  Every FAQ entry should have at least a couple of sentences of
text.  Some will have more, some less.
This FAQ is not meant to be a GnuPG tutorial, reference manual, or
HOWTO.  For that reason most of the FAQs about "how do I..." are really
just brief sentences listing commands that are useful, with the intent
being people will look those commands up in manuals, HOWTOs, manpages,
or whatnot.
I'm not interested in bikeshedding over grammar or word choices.  If I
let everyone on this list play editor then this FAQ will never get
completed.  For that stuff I've asked a couple of friends with good
technical writing skills to look over it, and their proposals are
probably going to get adopted.
What I *am* interested in, though, are content errors.  It is quite
likely I have a few in there, and maybe even a few howlers.  So please,
take a look and see what you think.
Also, if there are any questions you feel are missing, throw them out
too.  Thank you!

@_date: 2012-06-04 01:05:24
@_author: Robert J. Hansen 
@_subject: GnuPG 2.1 Windows 7, pinentry does not allow paste, no way to 
If your passphrase is stored on a file on your computer, then you may as
well have no passphrase at all, yes.
The only safe place for your passphrase is your memory, and even that
one is fairly easy to crack.  A top-flight hooker costs $5,000 an hour
(according to Eliot Spitzer), a great bottle of Scotch costs $250
(Glenmorangie Signet), and between the two you have a fairly
cost-effective way to recover a passphrase.

@_date: 2012-06-04 12:14:39
@_author: Robert J. Hansen 
@_subject: no password needed to export secret-keys? 
Yes, it is.
Try using the newly-imported secret key.  :)

@_date: 2012-06-04 14:08:52
@_author: Robert J. Hansen 
@_subject: FAQ, take two 
I am unfortunately Solaris-impaired: IPS publisher?  If you could
provide a sentence or two explaining this (preferably in the same
general format/wording as the other sections), I'd appreciate it greatly.
D'oh, yes.  Although I don't know if they support inline signatures yet.
 I know they support PGP/MIME (rather obsessively) and that inline
signatures have been a requested feature, but I'd need someone to
confirm the status there -- as well as whether it supports GnuPG 1.4 or 2.0.
Thank you!
A good point.  I'll introduce it, but for now I'm going to leave the
overall numbering intact -- reorgs should take place once the document
is stable, not while there's still churn.  :)

@_date: 2012-06-04 14:50:54
@_author: Robert J. Hansen 
@_subject: crypto games 
There are some serious problems here, not the least of which is there is
no canonical set of best practices!  There are at best a set of
guidelines, many of which are in violent conflict with each other.  If
it was just a set of rules that had to be followed the field would be
much easier, but as it is it's devilishly hard: the practitioner has to
balance lots of tradeoffs in order to come up with a policy that
maximizes the client's satisfaction.

@_date: 2012-06-04 21:36:30
@_author: Robert J. Hansen 
@_subject: FAQ, take two 
I haven't found widespread belief this is a community norm.  There's a
vocal segment that believes one or more of this is a community norm, it
must be a community norm, it is morally and/or ethically wrong if it is
not a community norm -- but it's a segment, and doesn't seem to be
shared by the whole of the community.
By what right can I -- or anyone on this list -- claim the authority to
declare what members of the community should or shouldn't do?  I'm
writing a FAQ, not establishing community norms.  I don't mind writing
the FAQ, but I do mind trying to impose norms.  It's not something I'm
comfortable with.  (Besides.  If I tried, people would laugh at me, and
deservedly so.)
It's reasonable to present the controversy, and I'll make mention of it
in the next revision.  That's as far as I'll go.
Of course, ultimately Werner is the one who gets thumbs-up or
thumbs-down on this -- if it's to someday become the official FAQ, then
he gets final signoff authority.  So if you disagree, feel free to pitch
it to him, but you've heard my position on it.  :)

@_date: 2012-06-05 06:36:51
@_author: Robert J. Hansen 
@_subject: FAQ, take two 
I'll go one step further: my personal belief is that this pursuit is a
fool's errand.
What people are really asking for is a concept the military calls ORCON,
for "ORiginator CONtrol" [1].  The idea is that with ORCON data the
person or agency that originated the data gets absolute control over how
the data is disseminated and how it may be released.
To do ORCON within the context of public-key certificates, we would need:
Once those three are addressed then I'll take the "I want ORCON" crowd
seriously.  Until then, my response to the ORCON crowd is "I want
stronger beer and honest politicians."
I think it's foolish to try to establish a social norm which offenders
cannot be identified and the norm cannot be enforced.  That doesn't mean
I think Charly's wishes shouldn't be respected: he's made his wishes
clear and I think decent people will respect them.  But there's a
difference between saying "I'll respect the desires of someone who makes
their wishes on this subject clear" and "there is a social norm which
must be upheld."

@_date: 2012-06-05 07:24:54
@_author: Robert J. Hansen 
@_subject: FAQ, take two 
The new text reads,
"Finally, if you have elected to make a normal signature you may wish to
upload the newly-signed certificate to the keyserver network so that
other users may benefit from seeing your assurance of the certificate?s
authenticity. This may be done by typing gpg2 --keyserver
pool.sks-keyservers.net --send-key certificate ID. However, some people
consider it rude or offensive for others to upload their certificates
without their express permission. It may be worthwhile to check with the
certificate owner before doing this."
... Since the text is now relatively stable, it's time for me to begin
doing a detail pass.  As part of this, I'm going to be reorganizing the
text and layout.  If anyone has recommendations about this, please speak
up now.  With luck, we can have this thing to Werner by the end of the
week.  :)

@_date: 2012-06-05 13:22:09
@_author: Robert J. Hansen 
@_subject: FAQ, take two 
I can add these: it shouldn't be a problem.  The reason I'm using XHTML,
incidentally, is to make it as easy as possible for you to convert it
into org-mode: an hour's work with a SAX parser should be able to take
care of most of it.  If I knew the first thing about org-mode I'd write
the script myself.

@_date: 2012-06-06 19:39:05
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
"Best" is a relative term.
The gold standard for validation involves meeting someone who claims to
be Werner Koch, asking him for his passport, checking that his passport
identifies him as Werner Koch and that all the anti-forgery measures are
in place on the document, and having him tell you directly what his
certificate fingerprint is.
Of course, this just establishes you have the certificate of *a* Werner
Koch, and maybe not the one you want.
Certificate validation is a surprisingly hard thing to do.  Sorry.  :(

@_date: 2012-06-07 12:14:11
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
As an FYI, you are consistently misspelling Werner's name.  It's Werner,
not Verner.
The certificate belongs to someone.  If Werner were to appear before me
with his passport and said "I control the certificates corresponding to
these email addresses" and gave me their fingerprints, I would consider
those certificates to be fully validated.

@_date: 2012-06-07 12:52:56
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
Perhaps it would be worthwhile to add a question to the signing process:
"Have you met this person face-to-face and verified his/her identity?
(y/N)"  If the user answers no, display a warning that the user probably
wants to lsign, not to sign, and give the option of making an lsign instead.
It might cut down on certifications such as these...

@_date: 2012-06-07 13:22:28
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
Yes.  And there are doubtless a large number of people who really don't
want to have to type in their new passphrase twice, too.  We make them
do it anyway.
Objecting to it on the grounds of "I don't think it will cut down on
inappropriate signatures," fine, maybe, yes, it would be worthwhile to
consider whether it can actually deliver on what I hope it can.  But
assuming it can deliver, making people type 'y RETURN' in response to a
simple question is hardly an onerous new requirement.  I'm having a hard
time understanding your objection, honestly.

@_date: 2012-06-07 14:29:38
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
Friend of mine, a former law-enforcement officer, is a big believer in
checklists ever since he went into a violent drug raid and discovered
afterwards they'd forgotten to (a) let the ambulance service know they
were about to serve a high-risk warrant, (b) put on his body armor and
(c) chamber a round in his Glock.  After that he wrote down a checklist
on the back of his business card: "Warrant, Correct Address, Backup,
Comms, Ambulance Standby, Weapon, Armor."  Rest of his career he never
went through the door without first breaking out that checklist and
confirming that each and every category had been ticked off.
The moral of the story is that if it's important something always be
done, then it's important enough to add to a routine checklist.
Otherwise, you're sooner or later going to wind up like my friend:
shaking like a leaf and having nightmares for months about how things
could have gone much, much worse.
If people want to implement this feature as "--expert
--disable-sign-sanity-check", okay, then ... fine, I guess, --expert is
quite literally a "don't you dare second guess me just do what I say,
damn it!" flag.  But there's a very good reason why I don't use --expert
and why I've never met anyone whom I think *should* use it.
Sanity-checking validation checks *is* mission-critical.  IMO, at least.

@_date: 2012-06-08 15:04:46
@_author: Robert J. Hansen 
@_subject: Documentation bug 
Set  the  `for  your eyes only' flag in the message. This causes
       GnuPG to refuse to save the file unless the --output  option  is
       given,  and PGP to use a "secure viewer" with a claimed Tempest-
       resistant font to display the  message.  This  option  overrides
       --set-filename.  --no-for-your-eyes-only disables this option.
The text should read "with a claimed Van Eck-resistant font", not "with
a claimed Tempest-resistant font".  TEMPEST is the name of a NATO
standard for hardening hardware against Van Eck phreaking [1].  Thus,
the font is not claimed to be 'Tempest-resistant' because that would
mean resisting the countermeasure.  Instead it should be 'Van
Eck-resistant', because that means the font is the countermeasure.
[1]

@_date: 2012-06-08 16:23:21
@_author: Robert J. Hansen 
@_subject: A Pact with the Devil 
A fascinating paper just crossed my desk: Technical Report 666 from the
University of Cambridge's computer science department.  Although it has
no relevance to GnuPG, it is such a cunningly evil idea -- and presented
so clearly, without any sophisticated mathematics -- that I think many
people here will find it fascinatingly unsettling reading.  It's just a
matter of time until someone takes this (very slight parody) of an idea
and turns it into something disturbingly real...

@_date: 2012-06-08 20:22:39
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
I hate to give an unclear answer, but this either is or isn't a proper
verification, and there's no in-between.  Before you go about thinking
that's a pointless answer, please: I promise you that it's a completely
accurate answer, and understanding why it's accurate will help you
understand the nature of verification.
The ancient Greeks had a branch of philosophy that was concerned with
the nature of knowledge: not just what did we know, but how is it that
we knew it, and on what basis did we trust it?  This branch was called
epistemology, and verification is an epistemological question.  All
right, you have a certificate and you know it's truly Werner's release
signing certificate: but *how do you know it*?
The gold standard of such knowledge involves meeting Werner
face-to-face, checking his passport, verifying that it's a real passport
and not a forgery, receiving his certificate fingerprint directly from
him, emailing him at that address to confirm that he truly has access to
the address listed, and so forth.  If you were to do this many people on
this list would nod appreciatively and say that yes, this is a proper
verification.  Some might shake their heads and say no, it's not: you
only verified you were speaking with *a* Werner Koch who had access to
*the* Werner Koch's email address, not that you were speaking to *the*
Werner Koch.
And, you know what?  They'd be absolutely right.
Ultimately, whether a given verification process rises to the bar of
sufficiency is a personal decision.  There is no absolute standard.  As
a result of this, you can only ever rely on being able to satisfy
yourself -- there will always be people out there who believe your
verification process is insufficient.  And that's why your process
either is or isn't a proper verification, and why there's no in-between.
If you can honestly say that you understand the risks of asking the
list, that you've considered those risks and you're comfortable doing
things this way, then sign that certificate with a clear conscience and
don't let anybody tell you that you're doing it wrong.
Me, I think your process is certifiably crazy and I would never, ever do
it that way.  But you know what?  I don't get to control your
decisionmaking process and I don't think you should put any stock in my
opinion.  After all, I'm just a guy on the internet whom you've never
met.  You have no idea if I'm a bulwark of sanity or if I bark at the
moon on a regular basis.  :)

@_date: 2012-06-08 23:49:06
@_author: Robert J. Hansen 
@_subject: A Pact with the Devil 
It's remarkably easy.  Look at how many people fall for fraudulent "your
computer is infected, clean it for $29.95" pop-up ads.  Look at how many
people click on links in spam mails promising "free access to porn"
(with an unspoken sidebar of "if you'll click this link and visit a web
page that will do a drive-by hijacking of your PC").
As Einstein is apocryphally held to have said, "Only two things are
infinite: the universe and human stupidity.  I'm not so sure about the
"Can't help"?  No.  But just *want* to watch, to feel that kind of
power?  Yes.
At risk of sounding like I have a liberal-arts degree (which I do, and I
can ask "would you like fries with that?" in Pashto to prove it), you
might want to read Plato's _Republic_, Book 2, particularly about the
Ring of Gyges.  Book 2 is largely concerned with the question of whether
people are moral because they are innately moral, or whether morality
emerges from the fear of being punished.  I can't do justice to it in a
summary, I'm afraid.
In my own life, I've found a lot of wisdom in the phrase "character is
who you are when you know you can get away with it."

@_date: 2012-06-09 06:25:19
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
Please consider trimming your quotes.  The amount that's going on here
strikes me as pretty excessive.  I'm not standing on a chair and
screaming that you're doing it wrong, of course: this is just a friendly
request to please trim your quotes.  :)
Not particularly.  The idea behind the Web of Trust is that entities can
introduce other entities.  Everything above and beyond that is just the
projection someone places upon it.
Not necessarily.  For instance, Symantec has a certificate they use to
sign PGP releases.  That certificate does not belong to a person but to
a corporation.  *Entities* come first, but an entity is not necessarily
a person.  Usually it is -- but it's not required to be.
No, it's definitely the validity of certificates that we're checking.
We can agree on how to check the validity of a certificate -- ensure the
fingerprint matches the one provided to you by the entity controlling
the certificate.  We can't agree on how to check the validity of a
person, or even what it even means to do this.  So instead we handwave
it by saying, "prove to your own satisfaction you're talking to the real
entity -- whether this means you've known the person for twenty years,
you've seen two forms of government ID, or Elvis came to you in a s?ance
and vouched for the person and told you he was a swell guy.
That last option is every bit as 'valid' as the other two.  How you
confirm an entity's identity is your choice, and nobody gets to decide
that policy except you.
I don't understand what you're talking about here.  In fact, it seems
quite self-contradictory.  If someone presents themselves as being
Horace Micklethorpe, shows me ID in that name, and then I later discover
this person's real name is Harry Palmer, I'm going to understandably
accuse this person of having been inauthentic with me.
Few of us do.  I harbor some suspicion that Werner's real name is Horace
Micklethorpe.  He might also be Harry Palmer or Bob Howard.  I don't
know.  I also don't particularly *care*, either: what I care about is
what he does, not who he is.
Certificates change over time as UIDs, UATs, signatures and subkeys are
added and revoked.  Certificates are highly dynamic documents: many of
them gain a signature a week.

@_date: 2012-06-09 09:44:06
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
By fiat.  You go through some mechanism and at the completion declare,
"I am satisfied that the likelihood of this *not* being the correct
distribution key is quite low."  I'm not weighing in on what the
mechanism should be: I don't get to declare what anyone else's policy
should be.
Sure it does.  As an absurdist thought experiment, let's think of a
nation -- call it Kochistan.  In Kochistan, everyone is required to have
the name Werner Koch.  Most people in Kochistan are honest.  If you ask
them if they're *the* Werner Koch, they'll tell you no, they're not.
Some people in Kochistan are dishonest.  If you ask them if they're
*the* Werner Koch they will quickly tell you yes, create a certificate
with the same UID on it as the one which signs GnuPG releases, and give
you the fingerprint for *that* certificate.  This Werner Koch will then
call his cousin (also named Werner Koch) who runs an organized crime
outfit, and will tell him that if he can Trojan a copy of GnuPG that
you'll be happy to install it because you're under the impression that
he (Werner-who-is-not-our-Werner) is him (Werner-who-is-our-Werner).
There's a big difference between being *the* person and being *a*
person.  :)
I'll trust crowdsourcing to find me good restaurants in my neighborhood.
 If someone (or some group) subverts that system then I'm out a few
bucks for a meal that doesn't taste very good and I know not to trust
that restaurant review website again.  And I learn about this really
quickly, too -- all it takes is one or two bad meals and I've moved on
to find a better source for restaurant reviews.
I don't trust crowdsourcing to verify GnuPG.  If someone or some group
subverts that system my exposure might be much greater and I might not
learn about it for quite some time.
Well -- not to be rude, but you did.  As you said, "at some point you'll
have to satisfy yourself that you have the correct key."  The process
you use to satisfy yourself will by definition satisfy yourself: that
makes it a proper verification.  But if you satisfy it by a process that
other people consider insufficient or deeply unhinged (in the case of
the s?ance with Elvis), they will say that it is *not* sufficient and
that makes it an improper verification.
Verification is inherently subjective.  A verification can
simultaneously be sufficient and insufficient -- sufficient for yourself
but not others, insufficient for yourself but not others, and so on.

@_date: 2012-06-09 10:29:45
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
An anecdote might work better than an absurdist thought experiment, come
to think of it...
In the United States, the collegiate basketball championships are the
occasion for a lot of betting.  People stake wagers on which teams will
make the semifinals (the "Sweet Sixteen") and the playoffs (the "Final
Four").  As you might expect, a lot of people try to get some kind of
inside information -- they might have a cousin who plays for one team
and their cousin says the University of Nevada at Las Vegas is the one
to look out for or something.  Whenever you've got gamblers you'll have
people who try to get inside information or expert advice.
The University of Iowa's color-commentator for their basketball games is
a great guy -- I met him a couple of times, once when he was playing
ball for UI and a couple of times when I was a grad student at UI.  He's
also a legend in professional basketball, having replaced Michael Jordan
in the 1992 NBA Finals while the Bulls were down by 15 and rallying them
to a 97-93 win.  Anyone who can not only replace Michael Jordan in a
game, but replace him *and* rally the score, is a deservedly legendary
We have the same name, we're both University of Iowa graduates, and we
both have a lot of family in Des Moines.  We both answer to "Bob
Hansen".  (I prefer "Rob," but I'll answer to "Bob" or "Robert".)  Even
our middle initials are similar: he's Robert L. Hansen and I'm Robert J.
Hansen.  It doesn't take a bad case of dyslexia to get those initials
So during Final Four season when people look around for the Bob Hansen
who attended the University of Iowa... well, sometimes they get me.
"Are you Bob Hansen?"
Yes, I am.
"Did you attend the University of Iowa?"
"Are you *that* Bob Hansen who attended the University of Iowa?  Bob
Hansen from Des Moines?"
Well, I'm not actually from Des Moines, no, but yes, I have a lot of
family there.
"OH MY GOD I CAN'T BELIEVE I FOUND YOU.  Quick!  Who are your Final Four
picks?  And are you still tight with Magic Johnson and Michael Jordan?"
Verification is a hard problem.  Even when dealing with someone who is
giving *completely honest answers*, it's still easy to confuse *a* Bob
Hansen for *the* Bob Hansen.  And when it comes to getting good Final
Four picks, you really want *the* Bob Hansen, and not me.  I've seen a
total of two basketball games in my life.
Likewise, you want *the* Werner Koch, not *a* Werner Koch.  When it
comes to getting a correct copy of GnuPG, you really want his
certificate and not some other Werner Koch's!

@_date: 2012-06-09 11:17:25
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
Thank you for giving me the benefit of the doubt.  :)
I'm not interested in the number of Werner Kochs.  I'm interested in the
difference between *the* entity and *an* entity.  The entity that signs
these releases happens to be Werner.  But there are many entities named
Werner, so how do we know we have the certificate belonging to the
correct entity?  It's an identification problem.  Werner's only
relevance to it _qua_ himself is that we acknowledge him as the
definitive authenticator of the code: "yes, that is the code I wrote."
If we're going to rely on a definitive authenticator, shouldn't we
ensure we're actually talking to the actual authenticating entity?  :)
My bootstrap is "I trust my Linux distribution."  My distro is a trusted
software provider, in the traditional security sense of a "trusted
provider".  If I receive software from an official Fedora repo and it is
signed by the repo release team, that's good enough for me.  How did I
come to trust that I have the correct certificate for the repo release
team?  Because it came on the DVD, which is my trusted bootstrap.  I
fully acknowledge this is validation by fiat.  Some people will think
it's a perfectly reasonable way of doing things.  Others will think I'm
crazy.  It's up to the individual to decide.  :)
And as I said, apparently you and I have completely different opinions
on whether crowdsourcing should be trusted for these matters.  And, you
know, that's okay.  :)

@_date: 2012-06-09 14:47:52
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
I don't understand where this question is going.  I would find some
trusted path, obviously.  If I contact the maintainer and am told, "I
download packages and check they are signed with this fingerprint ID,"
well, then I'm already transitively validating-by-fiat that fingerprint
If instead I'm told, "I've personally met the GnuPG release authority
(i.e., Werner) and have signed that certificate," then the release
certificate is validated because it is certified by a trusted introducer.
If I'm told "beats me, Elvis comes to me in a s?ance and gives me all my
answers," then I would have to find some other means.

@_date: 2012-06-09 16:55:29
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
Ah, I see.  I apologize for not understanding sooner: I thought you were
trying to illustrate a point.
I'm generally not comfortable giving advice about what people should do.
 I'm comfortable making factual statements, presenting options, talking
about my own practices or giving perspectives, but I really want to
avoid the recommending-what-people-should-do route.  I'm not comfortable
with that, not unless I'm billing by the hour and have a liability
waiver signed in blood.  :)
That said, I have found it useful as a general principle to avoid
introducing new points of fiat validity.  When possible, new sources
should be certified through existing validated certificates.
Considering my points of fiat validity and minimizing their number has
always served me well.

@_date: 2012-06-10 17:07:48
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
Michael W. Lucas, "PGP & GPG: Email for the Practical Paranoid," No
Starch Press, 2006.
Use whichever link you prefer: I use Amazon, but I know some people
vastly prefer Powell's.

@_date: 2012-06-10 23:25:51
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
David --
Please consider using clear signatures instead of conventional
signatures.  If someone looks in the list archives they'll see a huge
opaque blob of text they can't read.  Likewise if someone tries to
read your email on a system that doesn't have GnuPG installed.
Secondly, your message was 253 lines of quoted text and 14 of your own
text.  This means that 94% of the message was quoted.  This is a
little outr?.  I'd appreciate it a great deal if you'd trim your quotes.
You are certainly free to ignore me on those two counts, but I hope
you'll do me the favor of considering them.  Thank you.  :)
That said --
At least one person who has posted to this list is publicly affiliated
with intelligence services, yes -- it's right there in his official
bio.  That said, there's a *huge* difference between "normal guy who
happens to be associated with the government is on this list" and "the
kind of stuff the conspiracy theorists believe is happening, is
actually happening."
(I will not say who this person is.  I once received a death threat
from someone on this list who was convinced I was an FBI plant,
threatened my life, declared me to be Satanic, and went so far as to
look up my home address and phone number from WHOIS data in order to
make the threat more credible.  Given people like that exist, I feel
being circumspect about this person's identity is the only responsible
thing to do.)

@_date: 2012-06-11 00:03:40
@_author: Robert J. Hansen 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
My apologies: you're sending it with Base64 encoding instead of as
text/plain.  With that correction my comment still applies: it's much
harder for those viewing the list archives to make sense of.

@_date: 2012-06-14 13:09:51
@_author: Robert J. Hansen 
@_subject: Need a GUI for e ncrypt/decrypt in Ubuntu 11.10 
Not exactly.  He's never voiced any dissatisfaction with my mentioning of Symantec's PGP product, for instance, but that may be because I'm use PGP in a spirit of compare-and-contrast rather than advocating people use it.  I believe Werner objects to people advocating proprietary programs, but saying "proprietary program X does Y and the FOSS alternative doesn't, I really like Y, I'd like it if we could do Y" is just fine.
So, let's move this discussion about proprietary programs (GPGShell) into a direction that's useful to FOSS programs.  What is it about GPGShell that you really like?  What makes it superior to the FOSS alternatives?  How can the FOSS alternatives be made superior to GPGShell?  Inquiring minds very much want to know.  :)

@_date: 2012-06-14 13:39:01
@_author: Robert J. Hansen 
@_subject: GPGME C# bindings? 
I'm looking at putting together a mockup of something (if all goes well,
it will ultimately be ISC-licensed), and find myself needing C# bindings
for GPGME.  Now, there already exist a handful of projects that claim to
provide this but they all seem to have the same problems: they're
dormant projects, they have no user community, they haven't been tested
to work with the latest GPGME releases, and they have rarely *ever* been
tested to work on Windows.
So, before I go about embarking on a day's work to download and check
all of them, etc., I figured I'd ask around here.  Does there exist a
GPGME binding for C# which supports the latest version of GPGME, works
on Windows, etc.?

@_date: 2012-06-14 13:48:51
@_author: Robert J. Hansen 
@_subject: RFE: --update-before-use 
Currently, users have a public keyring containing certificates acquired from many different sources.  These certificates are often out of date, sometimes in minor ways, sometimes in large ones.  Since many users now have always-on and fairly reliable internet connectivity, perhaps it makes sense to add a new option: "update-before-use" (and its corresponding "no-update-before-use").
This option would only be effective if a --keyserver option is also in use.
When the update-before-use option is in effect, GnuPG will, before any encryption or verification, attempt to download the latest version of that certificate from the keyserver.  If one cannot be downloaded, GnuPG will display a warning message and continue to encrypt and/or verify using the certificate on the local keyring.
We already have something similar to this in --auto-key-retrieve, and the same warnings about that option probably also apply here.  The principal difference would seem to be that auto-key-retrieve only fetches certificates that are not on the local keyring, while update-before-use would always fetch certificates.
Thoughts?  Objections?  "Sounds good, now write the patch?"

@_date: 2012-06-14 16:34:42
@_author: Robert J. Hansen 
@_subject: RFE: --update-before-use 
As you say, easy to solve: agreed.
An open question and one we'd need to address: agreed.
I'm not entirely sure this is a problem.  If you're concerned about the
keyserver operator knowing that you're acquiring certificates, why would
you use that keyserver?  Why not use a different keyserver instead?  If
there were a single centralized keyserver, or a keyserver hierarchy
where individual nodes took marching orders from those above them, this
would be much more of a problem -- but here, the decentralized nature of
the keyserver network seems to work in our favor.

@_date: 2012-06-16 15:44:04
@_author: Robert J. Hansen 
@_subject: GPG with GPUs 
Be careful about saying this without learning what OS and hardware the
other fellow is running on.
On Windows, for instance, RNGs are provided by ADVAPI32!RtlGenRandom.
(For those who think it should of course be ADVAPI32!CryptGenRandom,
well, rest easy, ADVAPI32!CryptGenRandom calls ADVAPI32!RtlGenRandom to
do its heavy lifting.)  This is, per MSDN, a PRNG.  He's not hitting an
entropy problem with that.
On Linux, the default implementation uses /dev/random, which may
potentially run into an entropy problem, and your advice to invest in a
hardware RNG might make sense... unless he's running on an Ivy Bridge or
later, in which case it already has a hardware RNG built in.

@_date: 2012-06-17 13:02:11
@_author: Robert J. Hansen 
@_subject: why is CAST5 used instead of AES for seckey encryption? 
Because GnuPG predates AES.  When GnuPG 1.0 came out AES has yet to be
invented.  CAST5-128 was the choice back then, and nobody's changed it
yet -- at least partially because it doesn't need to be changed: there
are no known attacks on CAST5-128.
This is impossible to answer definitively, because nobody has a
perspective on what the whole of the GnuPG community is doing with our
gpg.conf files.  That said, I think you will find only a minority of
users do this.  I don't, and I've never heard any of my correspondents
say that they do.

@_date: 2012-06-17 23:31:40
@_author: Robert J. Hansen 
@_subject: GPG with GPUs 
Unless you're testing with 50 certificates, this isn't exactly a fair
comparison.  Here's what I came up with:
System: Intel i7-2600K @ 3.4GHz, 32Gb RAM
Results: 0.31 seconds to encrypt a 256k file containing random binary
Conclusions: there's something amiss here that neither a new GPU nor an
RNG will fix.
I'm including the Python script (works with 2.7 and 3.2) I used for
testing, so that other people who are interested in recreating my
results can check for themselves.  Warning: if you ever write Python
code like this in the real world your programming team will beat you to
[1] dd if=/dev/urandom of=rand.bin bs=262144 count=1
[2] The script to run GnuPG with the huge recipient list is:
from __future__ import print_function
from re import compile as compile_re
from subprocess import check_output as run_cmd
rx = compile_re("^pub:[f-]:.*:([0-9A-F]{16}):")
        (
            "/usr/bin/time /usr/bin/gpg2 " +
            "--trust-model always --armor --recipient " +
            "--recipient ".join(
            [Y.group(1) + " " for Y in
                [
                    rx.search(X) for X in run_cmd(
                        [
                            "/usr/bin/gpg2",
                            "--fixed-list-mode",
                            "--with-colons",
                            "--list-keys"
                        ]
                    ).decode("UTF-8").split("\n")
                ]
            if Y != None][:50]
            ) + "--encrypt rand.bin"
        ).split()
    ).decode("ASCII"))
[3] /usr/bin/gpg2 --list-packets rand.bin.asc|grep keyid|wc -l

@_date: 2012-06-18 06:41:15
@_author: Robert J. Hansen 
@_subject: GPG with GPUs 
My secret shame is that I know neither sed nor awk, which is why I do so
many of these tasks in Python.  :)

@_date: 2012-06-18 06:42:53
@_author: Robert J. Hansen 
@_subject: conditional config file entries (bound to e.g. sender and 
Not to my knowledge.
Show me a use case.  When would this be useful, and to whom?  How are
these people currently being impacted by the lack of such a feature?

@_date: 2012-06-18 23:31:12
@_author: Robert J. Hansen 
@_subject: way to see what cipher/algo was used to create your key? 
Please don't advocate this.  cipher-algo and digest-algo can potentially
wreck interoperability with other OpenPGP clients.  For this reason most
users will be best-served by leaving those options out of their gpg.conf
file.  Specify it on the command line each time if you must.

@_date: 2012-06-19 14:09:14
@_author: Robert J. Hansen 
@_subject: way to see what cipher/algo was used to create your key? 
I won't put it in there.  Once you open the door to that, then you have
to answer questions about "so how do I change these settings?" and then
you're explaining half of the edit-key interface.  You have to draw the
line somewhere.
I draw it at explaining politely and reasonably that the defaults are
safe for the overwhelming majority of users and there's no need to
change them.

@_date: 2012-06-20 13:18:28
@_author: Robert J. Hansen 
@_subject: choice of encryption algorithms 
Nothing.  They can use --cipher-algo to force whatever symmetric algorithm they wish.  This may wind up with a message that you're unable to read -- for instance, if your recipient forces AES256 and you're using PGP 7.0, you'll be unable to read it.  (This is why most of us advise against using --cipher-algo.)
The certificate does list what algorithms you're capable of reading, and most well-behaved OpenPGP applications will interpret that as ranked preferences ("I most prefer this, then that, then the other").  However, this is purely advisory and the sender can easily ignore it.

@_date: 2012-06-21 00:52:25
@_author: Robert J. Hansen 
@_subject: choice of encryption algorithms 
Please don't do this.  It's error-prone.  Those are machine-readable
numbers, not human-readable ones.  Use the human-readable ones: for
default-preference-list TWOFISH 3DES SHA256 SHA224 RIPEMD160
... will set both digest and cipher preferences.  You can also set
compress prefs in that line, too.
Also, default-preference-list is redundant with the other -preferences.

@_date: 2012-06-21 01:47:26
@_author: Robert J. Hansen 
@_subject: choice of encryption algorithms 
No, because this is the sort of thing that usually goes in a gpg.conf
file.  I can't think of a use case for default-preference-list on the
command line -- not saying none exist, mind you, but only that I can't
think of one.

@_date: 2012-06-21 10:27:23
@_author: Robert J. Hansen 
@_subject: "SHA1 Protection" from way to see what cipher/algo was used to 
This may or may not be true, depending on what method of random number
generation is being used.  ANSI X9.17, Yarrow and Fortuna are three
examples of pseudorandom number generators that are built out of
cryptographic algorithms.  libgcrypt supports at least the former:
Linux's /dev/urandom is (I think) Yarrow-based.
Nine in ten says the OP doesn't care about this and was operating under
a misconception, which you and others have ably corrected.  One in ten
says we've been misunderstanding what the OP has been asking, and the
OP's really asking a technical question about PRNG operation.  :)

@_date: 2012-06-21 14:19:05
@_author: Robert J. Hansen 
@_subject: choice of encryption algorithms 
You and David are completely right, and I have no idea what I was
thinking.  Thank you both for the correction!

@_date: 2012-06-21 17:06:33
@_author: Robert J. Hansen 
@_subject: idea.dll 
It's quite a bit worse than that, really.  If I understand things
correctly, the news media and antivirus companies are reporting that the
Flame malware used an MD5 collision to get their malware to report that
it had been signed by Microsoft.  If true, that's a clear sign that
MD5-based signatures of all sorts are now suspect.
I wish I could say that this puts the final nail in PGP 2.6's coffin,
but the reality is there's a huge installed userbase that won't change
for love or money.  All we can do is encourage people to not join them.

@_date: 2012-06-22 12:57:06
@_author: Robert J. Hansen 
@_subject: ideal.dll 
This is, unfortunately, not a trivial fix.
Already people don't pay attention to proper validation because the idea
of checking the fingerprint is alien to them, they don't understand it,
don't understand why it's necessary.  Adding another step of "verify the
keysize, too" will just compound the problem.
If your solution takes the worst part of key validity checking and makes
it even worse, then that's not a fix: that's an emergency stopgap
measure while people move to a better cryptosystem, such as V4 keys.
If you want to call it a stopgap, sure, I'll agree with you.  But I
can't agree that what you're calling a "fix" actually fixes anything.

@_date: 2012-06-22 13:04:14
@_author: Robert J. Hansen 
@_subject: Visible Password 
I was able to recreate this on GPG4WIN Win7/64, incidentally.  The
problem does not appear to be in GPA, but in pinentry.  It can be
recreated with a stock GPG4WIN installation.
This seems to be caused by pinentry not grabbing keyboard focus.  It's a
serious bug, all right.

@_date: 2012-06-22 14:18:13
@_author: Robert J. Hansen 
@_subject: ideal.dll 
If people want to keep using PGP 2.6, let them, but I'm not going to
help them do it.  If people want an emergency stopgap while they migrate
to OpenPGP, I'll happily help.  Unfortunately, at this point essentially
all the people who would migrate have already migrated.
PGP 2.6 is dead, dead, dead, dead, dead, dead, dead, dead, dead, dead.
PGP 2.6 is highly dependent on MD5, for which *we have already seen
in-the-wild signature forgeries*.  That deserves to be underlined and
highlighted and carved in twelve-foot-high flaming letters.  Anyone
using PGP 2.6 today is either in resolute denial of the facts or totally
For this reason, I have no interest in helping out PGP 2.6 users.  If
they really want to migrate to OpenPGP, then yes, let's do what we can
to help in the migration.  But anything that lets them continue to stick
their heads in the sand and deny reality is -- well, without passing
moral judgment on that, I have zero interest in helping.
Were it up to me, PGP 2.6 support in GnuPG would be reduced to
read-only.  So be thankful Werner isn't paying attention to my
preferences.  :)

@_date: 2012-06-22 15:40:54
@_author: Robert J. Hansen 
@_subject: ideal.dll 
Your characterization of "adding the key length is a trivial
[something]" is what irritated me.  As I mentioned, it's not trivial, it
doesn't fix the real underlying problem, it complicates things, and we
should be pushing people to move to v4 keys anyway.  IMO, any time spent
talking about how to 'fix' PGP 2.6 is unserious and wasted.  You can't
fix it.  You can't even mitigate the damage, since forged MD5 signatures
are now known to be in the wild.

@_date: 2012-06-24 21:05:08
@_author: Robert J. Hansen 
@_subject: ideal.dll 
The list may find my own timeline of MD5 to be worth reading -- it might
give some insight into why PGP 2 (in particular the MD5 vulnerabilities)
tend to engender such passionate responses.
1993: Bosselaers and Den Boer present a theoretical break on MD5.
1996: Hans Dobbertin breaks MD5.  His results are immediately dismissed
      as "theoretical" when they are nothing but.  The security of a
      Merkle-Damgard hash (such as MD5) cannot be greater than the
      collision resistance of its compression function.  Dobbertin is
      able to break MD5's compression function in *seconds* on desktop
      hardware.  The MD5 death clock begins ticking down: we know
      (thanks to Dobbertin) that collisions can be generated against
      the full MD5 in seconds, but we don't yet know how.
1997: As an undergraduate, I read Dobbertin's paper and get shocked.
      I start advocating migration to SHA-1 and/or RIPEMD160.  Nobody
      listens to me, and maybe rightfully so: after all, I'm just an
      undergrad.  That said, I'm in good company: lots of other very
      serious cryppies are advocating the same.
1998: Internal debates begin at PGP Security over whether MD5 should
      be considered "deprecated" (technically valid, but advised
      against) or "obsolete" (no longer valid).  (This is according
      to Len Sassaman.)
2001: People are still using MD5 in applications that need a
      collision-resistant hash function.  I begin to get irritated:
      we've had five years to do migrations.  Some important people
      within the community at that time (e.g., Imad Faiad) proclaim
      that MD5 is still secure and the vulnerabilities against it
      are still only theoretical and may never come to pass.  I begin
      to tell people that if we don't see real MD5 collisions within
      five years to never again believe anything I say.
2002: I enter graduate school for computer science and begin working
      in electronic voting.  I see systems being developed at that time
      which rely on the collision-resistance of MD5.  I begin to get
      unhinged.  In order to prove the ineffectiveness of MD5, I begin
      to work on MD5 collisions for my Master's thesis.
2004: Shengdong University publishes the first MD5 collisions.  I have a
      very long and dejected talk with my advisor about my degree
      plans.  I take a Master's without thesis, but I tell my advisor
      I'm looking on the bright side: no one can claim MD5 is still
      safe, right?
2004: People continue to say MD5 is still safe, claiming that the
      Shengdong University attacks are impractical -- they can only
      produce collisions in random data, which means you can't forge a
      particular signature on particular data.
2005: At Black Hat, Dan Kaminsky starts off with the EFF's website and
      the NSA's website.  Dan is able to, in realtime, tweak the EFF's
      website with nondisplaying characters in order to make it look
      unchanged from the original but have the same MD5 hash as the
      NSA's website.  I was there in the audience and my jaw was on the
      floor.
2005: People continue to say MD5 is still safe, claiming that... oh,
      God, I lose track at this point, honestly.  At this point my
      brain shuts down and I begin to believe anyone advocating MD5
      where collision resistance is necessary is living in resolute
      denial of the facts.
2008: The first public disclosure of a forged MD5-based SSL certificate.
2008: US-CERT issues a Vulnerability Notice which says in plain
      language, "Software developers, Certification Authorities,
      website owners and users should avoid using the MD5 algorithm in
      any capacity." (Ref:  )
2012: News reports circulate that the Flame virus propagated by forging
      an MD5-based Microsoft signature.
2012: On this mailing list, 16 years after experts recommended migrating
      away from MD5 and four years after US-CERT categorically declared
      MD5 to be a "do not use" algorithm, we're having a discussion
      about PGP 2.6, which is deeply married to MD5.
After reviewing the past 19 years of results on MD5 and the community's
reaction to them, all I can say is ... nothing, really.  I used to be
able to get a lot of outrage summoned up over this subject, but now I've
been reduced to making faint whimpering noises.

@_date: 2012-06-24 21:13:50
@_author: Robert J. Hansen 
@_subject: ideal.dll 
Forgot to footnote: the slides from this talk are available on the Web.

@_date: 2012-06-25 11:55:23
@_author: Robert J. Hansen 
@_subject: private key protection 
(I do not disagree with Kevin: this is an emphatic agreement.)
There is a minimum energy associated with flipping a bit -- something so
small that a single proton has the energy to flip about a trillion bits.
Let's say you have a remarkably efficient OS that can test a given key
while only flipping 10,000 bits.  Multiply that times the number of
attempts you'd have to make to brute-force a 128-bit key and you get a
really big number, so big that it no longer makes sense to describe it
in terms of nuclear warheads.  The best, most visceral way of saying it
is, "You must have 340 kilos of antimatter to run your computer."
If you happen to have 340 kilos of antimatter lying around, then yes,
brute-forcing is certainly possible.  I deeply hope you don't.  I like
Earth: all my stuff is here.

@_date: 2012-06-25 11:56:03
@_author: Robert J. Hansen 
@_subject: ideal.dll 
If MD5 signatures can be forged (and news reports strongly indicate they
can be), that means the self-signature on certificates is now
susceptible to forgery.
It may make sense to talk about specific things we've discovered about
those two pieces of work (Flame being the other), but let's be careful
using them as adjectives.  We genuinely don't know enough about them: it
will take the public antivirus community years to discover exactly what
and how they do what they do.
Competent malware hides better than Lamont Cranston.

@_date: 2012-06-25 12:00:50
@_author: Robert J. Hansen 
@_subject: private key protection 
Speaking purely for myself, my passphrase is 16 bytes from /dev/urandom
dropped into base64.  It took me a weekend to memorize it, but the peace
of mind has been well worth it.
It is possible, though, that I'm demented.  :)

@_date: 2012-06-27 09:11:11
@_author: Robert J. Hansen 
@_subject: idea.dll 
I am not so sanguine.  Marc Stevens claims [1] he has a working
collision requiring 2**57 compressions: that number is low enough to
make my hair stand on end.  He also says he knows how to make it faster,
and he's been curiously silent on the subject for the last year and a
half.  I think "eventually" is going to come sooner than we think.
[1]

@_date: 2012-06-27 10:32:03
@_author: Robert J. Hansen 
@_subject: migration paths from SHA-1 [was: Re: idea.dll] 
Yes.  And this is exactly what I heard in 2005 from people who were
dismissing the MD5 collision attacks as, "well, you know, they're not
preimages."  It didn't take long to go from that to full-on attacks on
MD5.  I expect the same will occur here.
If by "a little ways off" you mean anywhere between six months to a few
years, then yes, that's reasonable.
I don't expect SHA-1 to fall over dead this afternoon, but the
chaplain's been summoned to its room to deliver the Last Rites.

@_date: 2012-06-28 00:40:36
@_author: Robert J. Hansen 
@_subject: Cross-compiling GPGME 
I have a small Qt application that uses GPGME.  It compiles cleanly
under Linux (on a Fedora 17/x64 setup).  Although F17 has a really
lovely mingw32 cross-compiler, and a pre-built libgpg-error for Win32
that I can use, it's missing gpgme -- meaning I need to cross-compile my
own, so that the mingw32 linker can operate correctly.
This has been a frustrating experience.  Particularly, libassuan is
refusing to build, and since that's a dependency for libgpgme...
Before I go further: I'm calling the configure scripts through the
mingw32-configure wrapper, in accordance with Fedora's guidelines for
cross-compiling.  Likewise, make is called through mingw32-make.
Anyway, regarding libassuan: everything compiles fine, but at the link
stage I'm getting:
libtool: link:  i686-w64-mingw32-gcc -shared .libs/libassuan-0.dll.def
.libs/libassuan_la-assuan.o .libs/libassuan_la-context.o
.libs/libassuan_la-system.o .libs/libassuan_la-debug.o
.libs/libassuan_la-conversion.o .libs/libassuan_la-sysutils.o
.libs/libassuan_la-client.o .libs/libassuan_la-server.o
.libs/libassuan_la-assuan-error.o .libs/libassuan_la-assuan-buffer.o
.libs/libassuan_la-assuan-handler.o .libs/libassuan_la-assuan-inquire.o
.libs/libassuan_la-assuan-uds.o .libs/libassuan_la-assuan-logging.o
.libs/libassuan_la-assuan-socket.o .libs/libassuan_la-system-w32.o
.libs/libassuan_la-assuan-io.o .libs/putc_unlocked.o .libs/memrchr.o
.libs/stpcpy.o .libs/setenv.o .libs/vasprintf.o   -lws2_32
-L/usr/i686-w64-mingw32/sys-root/mingw/lib -lgpg-error  -O2
-Wl,.libs/versioninfo.o   -o .libs/libassuan-0.dll
-Wl,--enable-auto-image-base -Xlinker --out-implib -Xlinker
.libs/libassuan-0.dll.def:5: syntax error
file format not recognized; treating as linker script
syntax error
collect2: error: ld returned 1 exit status
make[3]: *** [libassuan.la] Error 1
make[3]: Leaving directory `/home/rjh/Downloads/libassuan-2.0.3/src'
make[2]: *** [all] Error 2
make[2]: Leaving directory `/home/rjh/Downloads/libassuan-2.0.3/src'
make[1]: *** [all-recursive] Error 1
make[1]: Leaving directory `/home/rjh/Downloads/libassuan-2.0.3'
make: *** [all] Error 2
... Does anyone have any guidance for me here?  I know that GPG4WIN is
built on a Linux system with a cross-compiler: how do the maintainers
build GPGME (and libassuan)?

@_date: 2012-06-28 13:17:38
@_author: Robert J. Hansen 
@_subject: Cross-compiling GPGME 
First, thank you for your response.  I appreciate it.  :)
Second, unfortunately this witchcraft doesn't work on Fedora.  Using
your same --host and --target specifiers, I'm getting the same problems
as before, in the same place as before.  Perhaps it's a bug in Fedora's

@_date: 2012-06-28 13:23:50
@_author: Robert J. Hansen 
@_subject: Cross-compiling GPGME 
Further, if it's any interest, here's the contents of
; assuan.def - List of symbols to export.
; Copyright (C) 2005, 2009 g10 Code GmbH
; This file is part of ASSUAN.
; ASSUAN is free software; you can redistribute it and/or modify
; it under the terms of the GNU Lesser general Public License as
; published by the Free Software Foundation; either version 2.1 of
; the License, or (at your option) any later version.
; ASSUAN is distributed in the hope that it will be useful,
; but WITHOUT ANY WARRANTY; without even the implied warranty of
; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
; GNU Lesser General Public License for more details.
; You should have received a copy of the GNU Lesser General Public
; License along with this program; if not, write to the Free Software
; Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307,
; USA
    assuan_accept                           assuan_begin_confidential               assuan_close_input_fd               I have tweaked the above *very* slightly: originally, 'USA' was not on a
single comment line by itself, but was instead part of the preceding
line.  Word-wrap put it onto a new line when I C&Ped it into email, so I
figured to comment it out in order to make it clear that it wasn't being
What I note immediately is EXPORTS is declared twice.  Now, I'm hardly a
libtool expert, but this seems ... incorrect.  Any ideas?

@_date: 2012-06-29 11:48:28
@_author: Robert J. Hansen 
@_subject: ideal.dll // fixing thread breaking 
Mika is more or less right, except it isn't headers -- it's the PGP/MIME
attachment separator.  Mailman makes a very slight tweak and that's
enough to bollix up the signature.
This mailing list does not play nice with PGP/MIME, the last time I
checked.  (For a long time Enigmail's list didn't, either, but that
problem has since been fixed.)  In general, PGP/MIME with GNU Mailman is
always a roll of the dice.
And yes, Mika is right: that's why Enigmail recommends inline OpenPGP.
We've all seen PGP/MIME break in too many different contexts.  For
instance, I've seen MTAs that strip off attachments, inspect the
attachments for malware, then re-attach them but with very slight
differences that break PGP/MIME.  I've seen MUAs that can't understand
it, mailing list software that breaks it, and so on.
PGP/MIME is a superior technical standard, but it's quite fragile.  We
believe PGP/MIME is the clear choice *if possible*, but given how often
it's not possible we recommend inline OpenPGP by default.
(This message is PGP/MIME signed.  I know my system works correctly with
PGP/MIME and that neither my MUA nor MTA mangle it.  If it's not coming
through, the most likely culprit is the list's GNU Mailman installation.)

@_date: 2012-06-29 13:39:22
@_author: Robert J. Hansen 
@_subject: ideal.dll // fixing thread breaking 
In the language of software engineering, this has moved from a defect to
fix to a lifecycle issue.  "Defect" is the stage where a bug is
reported: "fix" is the stage where the fix is available: "lifecycle" is
the often years-long process of getting the fix out to people who need it.
If I understand things correctly (and I may not be), Werner does not
host gnupg.org himself.  He rents a box in a colo facility for that, and
he's more or less stuck with whatever versions of software the provider
offers.  The provider hasn't offered an updated GNU Mailman, so
GnuPG-Users has this unfortunate situation where PGP/MIME doesn't
reliably work on it.
For what it's worth, my message left here as a correctly-signed PGP/MIME
message.  I received it back from the list as just 'signature.asc'.  A
(partial) diff of the two emails reveals:
<  protocol="application/pgp-signature";
<  boundary="------------enigBE03611A84F54D493777EBD6"
That should hopefully make it clear exactly what the problem is.

@_date: 2012-06-29 13:45:17
@_author: Robert J. Hansen 
@_subject: ideal.dll // fixing thread breaking 
IMO, if your client is showing correct PGP/MIME signatures on this list,
you should file a defect report about your client.  The message has been
changed in transit and is no longer in the exact same state as it was
when the sender issued it.  The change may be trivial, but it's still a
change, and IMO it is not the job of the MUA to try and fix the botchery
inflicted by GNU Mailman.  The correct thing to do, IMO, is to report to
the user the true state of affairs: "the signature is not correct and
the message appears to have been altered in transit."

@_date: 2012-06-29 14:01:39
@_author: Robert J. Hansen 
@_subject: ideal.dll // fixing thread breaking 
That bug turned out to be in Enigmail, not Mailman.  Mailman was
repackaging the attachment in a way that was technically valid but which
Enigmail wasn't expecting.  Patrick fixed that bug about a decade ago: I
think the fix predates the 0.9 release.
There was a different PGP/MIME bug that Daniel Kahn Gillmor [1] reported
to Mailman a while ago, and discovered it had been fixed and was now a
lifecycle issue.
The bug affecting GnuPG-Users may either of those two older ones, or
something completely new -- I've barely looked into it at all.
[1] Daniel, if I'm misspelling your last name please accept my
apologies.  I seem to never remember the correct spelling, and I assume
you like seeing your name misspelled about as much as I like being
called "Rob Hanson."  :)

@_date: 2012-03-04 17:37:00
@_author: Robert J. Hansen 
@_subject: invalid gpg key revocation 
This seems to me to be a simple question wrapped up in a lot of
unnecessarily specific details: "How is it possible for a non-authorized
person to revoke a user ID?"
Those are the three major options that immediately present themselves.

@_date: 2012-03-05 05:46:46
@_author: Robert J. Hansen 
@_subject: Master signing key length 
Yes, no and maybe.
Yes: if a 1024-bit master signing key can be compromised, there's
nothing to prevent the attacker from revoking your 4k subkeys and adding
new 4k subkeys the attacker controls.  This is really just the tip of
the iceberg, as far as attacks go.
No: breaking a 1024-bit master signing key is not trivial.  Nobody with
two brain cells to rub together will try to break a 1024-bit key so long
as any other reasonable option exists.  I would be surprised if any
1024-bit key has ever been broken, and only slightly less surprised if
one were to be broken in the next, say, five years.
Maybe: like Yogi Berra said, "the difference between theory and
practice?  In theory there is no difference: in practice there is."

@_date: 2012-03-05 12:26:59
@_author: Robert J. Hansen 
@_subject: invalid gpg key revocation 
Whenever anyone ascribes 99.9% certainty to a belief, my knee-jerk
reaction is to think the only 99.9% certainty is they've got the wrong
confidence interval.  :)
There are really only a few possibilities here:
1.  User error.  You did it yourself by accident and didn't realize
    it.
2.  Someone has access to your private key and passphrase and
    revoked your user ID.
3.  GnuPG has a critical, showstopper bug.
4.  The algorithm you used has a critical cryptographic flaw that
    someone exploited.
I can't tell you how likely  or  are, but  3 and 4 both seem like
fairly low-probability events.  I would begin by checking to see if
either  or  are in fact the case.  If you want me to believe  or
 are the case, you're first going to have to convince me it could not
have been  or I'll let other people answer the question of what data can be pulled out
of a revocation signature: this is a part of the spec I'm not entirely
up on.  It's possible someone's got some way to do interesting forensics
on revocations that I don't know about.  :)

@_date: 2012-03-06 22:37:26
@_author: Robert J. Hansen 
@_subject: Please help! 
Contrary to your statement on the forum post, it is almost definitely
*not* an Enigmail issue.  This is a straightforward permissions issue.
Somehow you managed to chown everything in $HOME/.gnupg to root instead
of your normal user, and that's borking everything up.
Fix the permissions and this will go away.

@_date: 2012-03-07 21:49:35
@_author: Robert J. Hansen 
@_subject: invalid gpg key revocation 
Let's not forget:
3) This would introduce legal headaches.  So long as SKS has no
   crypto code, it doesn't need to conform to crypto export laws.

@_date: 2012-03-13 08:14:35
@_author: Robert J. Hansen 
@_subject: Symmetric encryption - options? 
CAST5 is the default symmetric algorithm for GnuPG and PGP.  It is
generally accepted to be secure against cryptanalysis.
Broadly speaking, ciphers can be broken down into either "symmetric" or
"asymmetric" algorithms.  A symmetric algorithm uses the same key to
encrypt and decrypt.  If you choose to use a passphrase, for instance,
the same passphrase is used to encrypt and decrypt, therefore a
symmetric algorithm is used.
If you choose to use someone's public certificate to encrypt a message,
they use the private part of that certificate to decrypt it -- different
things for encryption and decryption, thus a different kind of
algorithm, an asymmetric one, is used.
CAST5 is a symmetric algorithm.
RSA is an asymmetric algorithm.
Hope this helps.  :)
Not really.
Integrity protection is only available when using newer symmetric
algorithms.  For instance, if you had selected Twofish or AES256 the
integrity protection feature would be used.  For almost all uses,
though, this is not a big deal to lose sleep over.

@_date: 2012-03-13 08:15:26
@_author: Robert J. Hansen 
@_subject: Symmetric encryption - options? 
This isn't quite right.  He's getting warned about the lack of an MDC,
which is related to the symmetric algorithm choice.

@_date: 2012-03-13 09:50:48
@_author: Robert J. Hansen 
@_subject: Symmetric encryption - options? 
Back when PGP5 was first released, PRZ needed a symmetric cipher to
replace the patent-encumbered IDEA.  He could've used 3DES but didn't,
apparently because there were still some (now-addressed) concerns about
the NSA's involvement in DES.  He could've chosen Blowfish but didn't,
for reasons unknown to me.  He fell in love with CAST5, an algorithm
which is conceptually quite similar to Blowfish, and figured to use that
instead.  PGP 5+ all used CAST5 for symmetric encryption, although they
could also read 3DES traffic.  Twofish was introduced in PGP 7.0, and
AES was introduced in 7.1, I think.
When GnuPG came along, Werner decided to mimic PGP's behavior in the
interests of interoperability.
Many years later, the MDC was introduced.  It was generally not possible
to retrofit this to older versions of PGP and/or GnuPG; it required some
changes in how messages were created and processed.  As a result, GnuPG
will only use the MDC if you're using Twofish, AES, or another one of
the newer ciphers.  At that point GnuPG essentially says, "ah, I see
you're using Twofish.  Clearly this message isn't meant for a PGP5
recipient, so I'll put an MDC on that, then...".
For further details, see RFC4880, section 5.14.

@_date: 2012-03-13 16:15:03
@_author: Robert J. Hansen 
@_subject: Symmetric encryption - options? 
I have answered this question so many times that I'm just going to refer
you to what I wrote on it several years ago:
(You will need to use Firefox or Chrome; IE doesn't support XHTML.  The
math looks best in Firefox.)
I would suggest putting on the brakes, taking a deep breath, and
explaining precisely you're trying to achieve.  My guess is you're
making this a *lot* harder than it has to be.
Speed kills.  Slow down, take a breath.  There are people here who can
help, but before we can help we need to know exactly what problem you
face.  :)

@_date: 2012-03-13 16:36:36
@_author: Robert J. Hansen 
@_subject: Symmetric encryption - options? 
You may be thinking of the Diffie-Hellman Key Exchange Algorithm
(DHKEA).  You're not thinking of RSA, though: RSA unquestionably is an
encryption algorithm.

@_date: 2012-03-14 01:05:53
@_author: Robert J. Hansen 
@_subject: compilation information ? 
GnuPG compiles just fine under the Intel C/C++ compilers, under the GNU
Compiler Collection, under Sun Studio, under AIX's own compiler and
under Clang.  Probably more, too, but these are the only ones I've
checked.  (What's the standard compiler for OpenVMS?)
There are a *ton* of options for how to compile GnuPG on non-Windows
platforms.  Windows is one of the more limited platforms, since you're
more or less limited to MinGW-GCC or Cygwin-GCC.  The last time I used
MS Visual C++ to try to compile GnuPG, the results were pretty awful...

@_date: 2012-03-28 14:14:05
@_author: Robert J. Hansen 
@_subject: sign and encrypt from batch script 
Switch to GnuPG 1.4.12.  This is not a downgrade; both GnuPG 1.4 and
GnuPG 2 are fully-supported, stable code.  Your script will (likely!)
work just fine with GnuPG 1.4.12.

@_date: 2012-03-29 09:53:18
@_author: Robert J. Hansen 
@_subject: sign and encrypt from batch script 
Sure thing.  Just remember that it was a Hawkeye who had to come to
y'all's rescue.  ;)
(For the non-Iowans: I'm a graduate of the University of Iowa, whereas
Mr. Roberts is an employee of Iowa State University.  Describing the two
institutions as having a good-natured rivalry is probably understating
You can add "trust-model always" to the end of your ~/.gnupg/gpg.conf
file and avoid this step.

@_date: 2012-05-03 15:09:42
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
The consensus of the cryptographic community is that beyond 3K keys you
really need to be switching to elliptical-curve cryptography.  A 3K RSA
or Elgamal key is roughly as difficult to break by brute-force as
AES128, and that one's so hard that nobody with two brain cells to rub
together is going to try it.
Although I am not a GnuPG developer, I have never heard anything from
the core devs which would make me think they are planning on revisiting
this limit to allow for extraordinarily large keys.

@_date: 2012-05-04 08:40:31
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
Nor does it change
3. using 8K RSA gives a modest increase to an already formidable
   margin of security
Breaking a 128-bit keyspace is hard.  Like, really, really hard.  The
power analysis on that one is eye-popping: to break a 128-bit keyspace
in anything approaching a reasonable length of time requires an energy
output on the level of a hypernova.  If you want to break a 128-bit
keyspace, please do it in a galaxy far, far away.  So why do we need to
increase a 128-bit keyspace (RSA-3K) to a 192-bit-plus-a-small-amount
keyspace (RSA-8K)?
The obvious response is "to defend against enhanced attacks against RSA,
such as quantum computing and Shor's Algorithm."  But that's just crazy.
 Shor's Algorithm requires 2N qubits to break an N-bit key.  Right now
we've got quantum computers that have, what, eight qubits?  Any RSA
modulus smaller than sixteen is in trouble now, let me tell you.
An effective quantum computer with the 6144 qubits required to break a
3072-bit RSA key is straight out of science fiction.  This quantum
computer would be more powerful than any conventional computer could
ever be: a conventional computer would require 10**1850 bytes of storage

@_date: 2012-05-04 11:13:45
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
No.  It can trash *some* asymmetric algorithms.  There are a good number
of asymmetric algorithms whose decision problem exists outside of BQP.
(McEliece, for instance.  For those wondering what BQP is, it's the
quantum computing analogue to P: it describes those problems you can
solve in a reasonable time with a quantum computer.)
I do not understand how, if you're concerned about quantum computing,
you can believe "it will all be better if we just use larger keys!",
rather than "it will be better if we use algorithms that cannot be
efficiently solved by a quantum computer."
Not half, reduce the strength of symmetric ciphers by a square root.  A
128-bit cipher's strength is not halved (which would make it 127-bit);
it's reduced to the equivalent of 64 bits (the square root of 128 bits).
It's worth noting that, per Suite B, 256-bit crypto is only required for
material that's at the top of the classification pyramid: things like
nuclear weapon release codes and other things that might cause 300
million people to have a really bad day.
128-bit crypto is considered quite sufficient for the rest of the
nation's secrets.
Also, some people are using symmetric crypto for secrets that must be
preserved for 50+ years -- census data, for instance.  If you're
concerned about 50+ years of confidentiality, then yes, it makes sense
to go hog-wild on key lengths.  But for the rest of us, the
confidentiality of our communications will be better-served by many
other measures than just adding more bits to the key.
An Apollo engineer would be unlikely to view a tablet PC as something
indistinguishable from magic.  Nothing about it would be unknown to
them: only the size, the power and the integration would be new.  This
is pretty much the norm in the field: from a pure computer science
perspective there's almost no difference between a Burroughs 5000 and a
modern x86_64.
Introduce quantum algorithms, though, and suddenly quite respectable
computer scientists suddenly start sweating bullets and saying, "uh, I
don't quite know about this, umm, *in theory* it will be kind of like
this, but the practical ramifications are ... hey, look at the time,
gotta go."
6000-qubit quantum computers are a magic so subtle they are
indistinguishable from high technology.  They might, if we are
fortunate, be invented in our lifetimes -- but let's not go about saying
we need 8K RSA keys to defend against 6000-bit quantum computers.  If
quantum computers bother you that much, use McEliece.
The discussion was already profoundly silly: the overt comedic
statements drew attention to this.  Successfully, apparently.
Non sequitur.
Non sequitur.
No, but there's no point in it, either.  Frankly, I'd rather the GnuPG
developers spent their time on pursuits that are more reasonable and
will give a better return on investment.

@_date: 2012-05-04 19:57:20
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
McEliece is almost as old as RSA.  Generations of graduate students have
tackled it in cryptanalysis courses.  Almost a thousand academic papers
have been published on it.  None have shown any significant weaknesses
in McEliece.
Its inventor, Robert McEliece, received the Claude E. Shannon Award a
few years ago.  What the Fields Medal is to mathematics, or the Turing
Prize is to pure computer science, the Shannon Award is to information
On the one hand, we have a cipher designed by a Shannon recipient which
has had almost a thousand papers published about it without any really
significant results.  On the other hand, we have you calling it a niche,
proof-of-concept, poorly-analyzed cipher.
The power and time requirements for computation are well-known.
Circumventing either would require
Any of the four puts us back into the realm of science fiction.  If
you're advocating making keys larger, I'd like to know which of the four
science fiction breakthroughs you expect might happen.  And no matter
which of the four you choose, I'll point out that should your chosen
breakthrough come to pass, we will all have much bigger things to worry
about than whether our 20-year-old communications are still safe.
Halving the strength of a 128-bit cipher leaves you with 127 effective
bits of security.  Rooting the strength of a 128-bit cipher leaves you
with 64 effective bits of security.  The former is still well beyond our
ability to brute-force: the latter is well within our ability to brute
force.  I don't consider this to be a slight difference.
I cannot force someone to not use a 256-bit cipher, true.  I can
certainly point and laugh at people who believe using one makes them
more secure, though.
Nobody has the right to be taken seriously.  That's a privilege that
must be earned.
The dirty little secret of crypto is that we've had a *great* symmetric
cipher ever since the mid-1970s: 3DES.  It's big.  It's ungainly.  It's
slow.  It has all the aesthetics of the Soviet Realism school of art.
It's very hard to code up because there are so many fiddly bits.  And
yet, 3DES has been turning the best minds in crypto into burned-out
alcoholic wrecks for the last 35 years.
It has been undergoing constant attack for 35 *years*.  Entire new
branches of cryptanalysis have been invented just to try and dent it.
These approaches have all failed miserably.
There are a few niches where 3DES doesn't work very well.  If you need a
cipher that can encrypt a 1000baseT connection, you're better off using
something faster.  If you need it on a smartcard, you're better off
using something more space-efficient.  But for the rest of the problem
space, 3DES has been rocking the house for almost as long as I've been
So here's the question: why isn't 3DES used in more places?
Marketing.  Because people -- both in the private sector and in the Free
Software world -- want to be able to say they support the latest and
greatest and best thing.

@_date: 2012-05-05 08:20:19
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
"Rarely used" is not the same as "proof of concept."  Your statement did
not mention "out of the mainstream."  No moving the goalposts, please.
You were also arguing that QC would shred all or most asymmetric
systems.  It turns out that no, QC doesn't, can't, won't: it will only
shred the discrete logarithm problem or problems isomorphic to it, such
as integer factorization.  Other systems, whether multivariate, lattice
or Goppa code-based systems, won't be.  (Well -- lattice systems might:
right now they're only conjectured to be outside of BQP.  But Goppa
codes are well-known for being NP-hard.)
If you're now claiming that I've only presented one system, well, that's
because I wasn't aware you were looking for the kitchen sink.  Do some
reading on post-quantum cryptography.  As I read the tea leaves the new
hotness is in the lattice-based systems, but I think systems based on
Goppa codes will continue to surprise us.
Not at all.
If you're securing nuclear weapon release codes and you ask me, "is it
okay if I use 256-bit crypto?", I will blink a few times and back away
slowly from the thermonuclear weapon while nodding vigorously and making
noises about how they must be secure for fifty years or more, oh and is
that thing releasing radiation right now and where do you plan on
storing this so I can live far away from it.
If you're securing your recipe book and you ask me, "is it okay if I use
256-bit crypto?", I will smile and pleasantly explain that, really, past
about 112 bits it's just an exercise in paranoia.  Use whatever you
like, but managing your keys will be a much more important task than
deciding between 3DES and AES256.
And if you're telling everyone that AES256 will give them a larger
security margin than 3DES, well... at that point I'm going to start
pointing and laughing.  There is enough misinformation and half-truths
floating around the crypto-hobbyist's world: I consider it to be a
polite act towards the community to challenge this when I encounter it.
Old software engineering joke: "legacy code (n): code that hasn't
crashed in the last 40 years."
You call 3DES old.  I call it quite well tested in demanding production
environments.  More often than not when you swipe a credit card, 3DES is
being used to secure the transaction at various critical points.
The best attack against three-key 3DES requires almost 10^27 bytes of
RAM.  This is completely impractical, as even the inventor of the attack
has said.  To the best of our knowledge there is no effective way to
reduce three-key 3DES, which is the only NIST-approved version, below
168 bits of key space.
... I have absolutely no idea what you're talking about here.  None.

@_date: 2012-05-05 09:13:59
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
In that case, everything you're advocating is confusing me.  Yes, if and
when QC comes along many existing systems will need to be considered
suspect.  However, if you're concerned about QC you will get far more
mileage from switching to a QC-resistant asymmetric algorithm than from
adding a few bits to your RSA key.  Why all this focus on longer RSA
keys as a response to QC?  It makes no sense at all.
That's because there are very few objective rules.  Computer security is
dominated by the human element, and human beings do not tend to strictly
follow objective rules.
When it comes to crypto, yes, we can say certain things with great
mathematical certainty.  The instant that crypto gets fielded, though,
the math becomes the least important part of the equation.  The human
element becomes overwhelmingly dominant.
NIST has certified 3DES until 2030: it is quite likely that in 2030 3DES
will be certified for another couple of decades.
I did, and I don't see anything in there that are ugly hacks or
backwards-incompatible.  Choose your keying option (three-key being
preferred), stick with it and you're done.

@_date: 2012-05-05 10:26:09
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
One-key 3DES *is* DES.  It's a DES encryption, decryption with that same
key, then re-encryption with that same key.  One-key 3DES existed to
allow institutions to bootstrap their infrastructure out of DES.  First
they instituted one-key 3DES, which let them transparently upgrade their
infrastructure without impacting business operations.  Once they were
convinced their new 3DES infrastructure was working correctly, they
switched to using two-key or three-key 3DES.  One-key 3DES was never
meant to be used as anything more than an upgrade path.  The backwards
compatibility of one-key 3DES was necessary for upgrade purposes, but
once fully deployed 3DES has never had a problem with backwards
What you said earlier was that 3DES had a bunch of keying hacks and
backwards incompatibilities.  Neither is true.  All the various forms
have been scrutinized quite closely and found to be solid.
One-key 3DES has the benefit of backwards compatibility with DES, which
is useful for upgrade purposes, but it's a gross misstatement of fact to
claim that 3DES has a problem with backwards incompatibility.

@_date: 2012-05-06 04:50:49
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
At this point I genuinely can't tell if I'm being trolled.  I'm going to
assume that I am not, and this will be my last statement on this entire
Two functions may operate quite differently, and yet be considered
completely identical from a computational perspective.  If I ask you to
add the numbers from 1 to 100, you might solve it the long way by doing
one hundred additions or you might do it the quick way by computing
(101*100)/2 or you might do it the fastest possible way by making a
lucky guess of 5,050.
Doesn't matter.  They're all equivalent.  If Function A and Function B
accept the same domain, output the same range, and have identical
surjections from domain onto range, then they can be said to be identical.
DES is an example of this.  Nowhere in the DES validation tests does it
specify, "your code must look like this."  The DES validation tests only
say, "given this input and this key, you must generate this output."  If
your implementation passes the DES validation tests, then
congratulations, you can be certified as a FIPS-compliant DES
One-key 3DES is quite capable of passing the DES validation tests.  This
means that for all intents and purposes it is a DES implementation.
As I said, I don't know if I'm being trolled or if you're just
thoroughly misinformed.  If the former, please stop.  If the latter, it
can be corrected.

@_date: 2012-05-07 09:16:46
@_author: Robert J. Hansen 
@_subject: SSH Agent keys >4096 bit? 
Minor correction: PGP first started using Twofish-256 for marketing
reasons.  The AES competition was in full swing and PGP Security
believed Twofish was going to be the winner, so Twofish-256 was
introduced for marketing reasons.  This was in PGP 7.0, if memory serves.
Once Rijndael was selected, it was introduced in PGP 7.1.

@_date: 2012-05-08 10:41:59
@_author: Robert J. Hansen 
@_subject: Symmetric encryption using multiple keys 
This is not possible.
Symmetric encryption uses one key and only one key.

@_date: 2012-05-22 09:23:36
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
Let's not be mean.
I will be the absolute first person demanding the right to criticize
ideas as harshly as I want.  I'll happily call an idea stupid,
ill-informed, wrong, or anything else.  I do this with a clear
conscience because I know that I'm not my ideas, just like nobody else
is theirs.
But I don't ever want to the the first person to be calling *people*
those things.  People are special, precious, and often fragile.  Our
community is made up of these rare commodities, and it behooves us to
treat other people with dignity and respect and consideration.
Let's not be mean.

@_date: 2012-05-22 09:51:07
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
You might want to re-think talking about this in a public forum.  This
mailing list is open to everyone, including the very people you're
talking about.  The first rule of good operational security is, "don't
draw attention to yourself or your organization."
A 3072-bit key will do that today.  Breaking a 3K key would require such
technological advances that it would be indistinguishable from science
fiction.  There's no point in going past a 3K key because if a 3K key
were to ever fall we'd have to reconsider the mathematical foundations
of cryptography.
No, it's not.
Imagine an automobile.  You might say, "well, I'd like an additional
hundred horsepower so I want to put a V-8 engine in my automobile: why
doesn't my automobile support this?"  But if your car is a Fiat 500,
well, there's simply not the room for such a large engine, nor is the
transmission or powertrain ready for that.  For that matter, even the
wheels would have to be redesigned: sustained high-speed driving on your
average Goodyears will cause them to delaminate and come apart, so you'd
need H-rated sport wheels or Pirelli PZero Neros.
Changing one component requires changes to a lot of other components.
That's what we're facing with changing the maximum key length.  The
mobile experience would be impacted, the embedded market would be
impacted, and even interoperability with other OpenPGP applications
would be impacted (since as far as I know none of them save for PGP
6.5.8ckt support such large keys).
It's all right to ask for larger keys to be supported, but there are
tradeoffs to be made here.
That safety margin is already present.
Yes, and 128-bit crypto is plenty sufficient for that.
Quoting from that page, "128 bits is currently thought, by many
observers, to be sufficient for the foreseeable future."
The Wikipedia page is also in error.  Per the publicly-available NSA
Suite B documents, AES128 is considered sufficient for SECRET data.
There is no AES192 requirement in Suite B.

@_date: 2012-05-22 12:28:49
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
It's worth bringing out Vint Cerf's estimate that between a sixth and a
quarter of all desktop PCs have been completely compromised and are
under the control of botnet operators [1].  That was from five years
ago: the numbers are probably worse today.
And that only covers people targeted randomly!  For those people
unfortunate enough to be targeted for surveillance by an even
semi-competent crew, it's far worse.  Your front door is no obstacle to
someone who's learned how to pick a lock -- or someone smart enough to
look around for a fake plastic rock nearby in which you've placed your
backup key.  I have no doubt whatsoever that a good crew could gain
access, enter, compromise the target's PC and be out of there in under
five minutes without the target ever knowing about it.
So, yes.  If anyone is the target of a serious surveillance campaign
(legal or extralegal, state actors or non-state actors, whatever),
well... you have your work cut out for you defending against that.
GnuPG will not save you, not even with a 16K keypair.

@_date: 2012-05-22 13:10:05
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
I apologize in advance if any of this sounds snarky.  It's not intended
as such.  Everything I've written here is sincere.
Did you know that in the United States, the Fish and Wildlife Service is
an intelligence agency?  Check their jobs postings and you'll see a good
number of them say a security clearance is required.
Your claim may lead people to writing off your movement on the grounds
that one of two things are true.  Either:
It seems unlikely to me that either one will engender much support.  If
people think the former, then the movement is crazy and can be written
off.  If people think the latter, then it's incredibly dangerous to
stand too close to you and no one will show up to your protests.
Not even Nicolai Ceaucescu's Romania or Erich Honecker's German
Democratic Republic were able to get one in six people to serve as
No, it's not what we're looking at.
If we take you seriously, if we really believe what you say, then what
we're looking at is:
If what you say is true, then just by coming onto this list and asking
for help you have put everyone on this list in jeopardy.  Your obsession
with a "little safety margin" seems rather hypocritical.
There are really only two possibilities here.  Either your claims are
substantially true, or they are substantially false.  I believe they are
substantially false, and I encourage you to re-think them.  A correct
estimation of your situation and what sorts of security threats you're
facing will do you infinitely more good than a larger GnuPG key.
And with that, I'm done with this thread.  I wish you luck.

@_date: 2012-05-22 14:40:07
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
I think so, yes.  The question is who's going to write it?  I suspect
Werner doesn't have the time.  If he wants, I would be happy to take a
stab at writing it.

@_date: 2012-05-22 15:14:33
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
It's hubris for an author to refer to his own work.  :)  Also, that FAQ
is in desperate need of a rewrite.  Nothing in it is wrong, per se, but
it needs a rewrite.

@_date: 2012-05-22 15:39:44
@_author: Robert J. Hansen 
@_subject: Testing GPG EMail encryption 
(Responded to on-list so that people can know your request has been
answered, otherwise you'll get drowned in dozens of responses)
Feel free to send an encrypted/signed email my way.  The certificate is
available from the keyservers:
I look forward to helping get you set up and straightened out!  :)

@_date: 2012-05-22 22:03:36
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
I'm not so optimistic.  Factoring is a hard problem.  We may never
develop the technology to factor extremely large composites.  Doing so
would require either (a) the development of extremely large-scale
quantum computing, (b) a mathematical proof of P=NP, or (c) classical
computers that run close to the thermodynamic limits of the universe.
There are no guarantees we will ever develop any of those three
That said, no one has ever proven that the only way to break RSA is to
factor large composites.  That's wholly conjecture, and there's some
evidence that it's not true.

@_date: 2012-05-23 09:24:17
@_author: Robert J. Hansen 
@_subject: Testing GPG EMail encryption 
You may want to move this discussion over to the Enigmail list.  We have
a system set up that does much of this already, called Adele.  We'd be
happy to share.

@_date: 2012-05-23 11:48:23
@_author: Robert J. Hansen 
@_subject: Testing GPG EMail encryption 
According to American legend, a journalist once asked the infamous bank
robber John Dillinger why he robbed banks for a living.  "Because that's
where the money is," he said.
Why should a discussion about Adele move over to the Enigmail list?
Because Enigmail runs Adele, has the source code for it, and the people
who are responsible for it are all over there.  I'm not sure that all
the involved people are on this list.  A discussion about Adele that
involves all the Adele people should probably go over to Enigmail,
because that's where Adele and the Adele maintainers are.

@_date: 2012-05-23 11:51:07
@_author: Robert J. Hansen 
@_subject: Testing GPG EMail encryption 
I don't know.  We have the source and permission to use it -- my
impression is that it's Free Software, but it's been years since I've
taken a look at our Adele code and read the copyright notice.  John
Clizbe would probably have a better handle on its licensing situation
than I do.

@_date: 2012-05-23 12:18:49
@_author: Robert J. Hansen 
@_subject: Draft of nine new FAQ questions 
I have a draft version of nine frequently asked questions ready for
community review:
Note that this draft is in nicely-typeset XHTML5.  This is to make it
easier to proofread.  The final version that I'm going to submit to
Werner will be in plain text, so please, no suggestions about fonts,
visual design, layout, or anything else like that.
Any and all feedback (save for visual design, layout, etc.) will be
gratefully accepted.  Thank you!

@_date: 2012-05-23 15:28:55
@_author: Robert J. Hansen 
@_subject: Testing GPG EMail encryption 
As you were told on the Enigmail list, thousands of people have found
that GnuPG 2 works well with Enigmail on Linux.  I demonstrated this to
you by sending to the list a correctly-signed email written on an Ubuntu
12.04LTS system using GnuPG 2.
If you're having troubles getting Enigmail to work there are many people
who are willing to help you.  However, talking about how GnuPG 2 is
completely broken on Linux, and how Enigmail is clearly too buggy to
use, and everything else, is not exactly constructive.
GnuPG 2 works just fine for the overwhelming majority of Linux users.  I
don't know what your particular problem is, but it can likely be resolved.
If it were encrypting to the private key, this would be a digital
signature.  That's what a digital signature is -- an encryption
operation using the private key.  I don't understand your complaint.  If
you're saying "Enigmail will sign emails," well, yes, it's designed to
do that -- but I don't think that's what you're trying to say here.
I have been using Enigmail with GnuPG 2.x for literally years, and over
that time I have had no trouble interoperating with people using other
Linux distros or even entirely different operating systems.  This is the
first time in all my years of using Enigmail that I have heard anyone
tell me that Enigmail's output is not interoperable with other systems.
 This is not to say that you're not having trouble with Enigmail -- far
from it! -- but claiming there is "no compatibility" is a fairly extreme
claim, and I'm going to need to see some supporting evidence.
GnuPG 2 is not an add-on widget to GnuPG 1.4.

@_date: 2012-05-23 16:45:30
@_author: Robert J. Hansen 
@_subject: Draft of nine new FAQ questions 
Fixed, thank you.
I don't want to seem argumentative (especially because I haven't looked
at the RFC lately), but I was under the impression the RFC was mostly
silent on the subject of algorithms and key sizes -- DSA being a MUST
algorithm, but little guidance beyond that.  Am I in error?
(That said, the text has been fixed: thank you.)

@_date: 2012-05-23 20:22:56
@_author: Robert J. Hansen 
@_subject: Draft of nine new FAQ questions 
Not a whelk?s chance in a supernova.  Those aren?t smart quotes, they?re
perfectly valid UTF-8 typographic marks.
"Straight quotes" and 'straight apostrophes' are artifacts of the
typewriter era, where there was simply not enough space on the keyboard
to provide proper typographic marks.  If you read a book, you?ll
discover they pay attention to things like ligatures, kerning, proper
typographic marks, and all manner of other things.  Centuries of use
have shown that these marks make text easier to read.
The final version that gets submitted to Werner will by necessity be
plain text, and that will probably get downshifted into dumb typewriter
markings.  But so long as I?m going blind on it, reading those rows of
text again and again and again, I?m going to pay attention to the
I encourage anyone who?s writing web pages to abjure dumb typewriter
markings.  In the UTF-8 era, there?s absolutely no reason why any of us
should have to put up with them.

@_date: 2012-05-24 09:20:07
@_author: Robert J. Hansen 
@_subject: Testing GPG EMail encryption 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Every time this has been reported to us, it has turned out to be a bug
in Mailman and not Enigmail.  If you can find a valid PGP/MIME message
that Enigmail is not correctly parsing, we'd love to see it!

@_date: 2012-05-24 20:27:38
@_author: Robert J. Hansen 
@_subject: Draft of nine new FAQ questions 
They may render as 'no such glyph', depending on which font you use.
I'd suggest using a better font.  :)
Also, if your browser is set to render everything as ASCII regardless of
what character set the webpage says it's using, then you'll also run
into problems.  The solution here is to trust the webpage character set.
If you wish for that, I invite you to write your own.
"Maximum audience" is not the same as "maximum usability."  The two are
different properties.  When it comes to the written word, ease of
reading, speed of reading, and comprehension is all improved by using
reasonable typography.  I consider those to be essential usability goals.
If I wanted "maximum audience," I'd try to turn the FAQ into _American

@_date: 2012-05-24 22:20:22
@_author: Robert J. Hansen 
@_subject: PGP interoperability 
Looking over the PGP product offerings after their acquisition by
Symantec, it seems they have dropped support for 2048- and 3072-bit DSA.
 This decision makes no sense to me, and is sufficiently weird that I
wonder if the marketing copy is horribly in error.  However, the
marketing copy is clear -- across the whole of the PGP product line,
DSA2 is no longer supported.  Check the following URLs, click on "System
Requirements," and take a look at the "Public Key Algorithms."  For each
product they offer:

@_date: 2012-05-25 08:35:52
@_author: Robert J. Hansen 
@_subject: Draft of nine new FAQ questions 
I'm comfortable with things as they are.  If and when Heisenberg and/or
the Second Law stop being accurate descriptions of the universe, I'll
have much bigger things to worry about than the FAQ.  :)
Yes, there is.  Unfortunately, the answer is kind of messy.
NIST believes a 112-bit *keyspace* ("bits of security") will be
sufficient until at least 2030, but NIST never gives their reasons why.
 I suspect that's because the committee wasn't able to reach an
agreement on why: one person believed X was the biggest threat and would
come to pass no sooner than 2030, another person believed Y and it would
come to pass no sooner than 2030, another person believed Z.  They all
agreed "safe until 2030," so that's what got put down as a
recommendation -- but NIST reached no consensus on what particular
threat they were worried about.
NIST also believes a 2048-bit key provides a 112-bit keyspace.  There's
a lot of conjecture going on there.  Sure, there may be approximately
2**112 primes that would have to be checked in order to do a brute-force
factoring, but there's some evidence that RSA can be broken *without
needing to factor anything* (!!).  We have no idea how to do it and no
idea how much easier this would be than brute-force factoring.  (In
fact, for all we know it might be harder, although that's considered
unlikely.)  Dan Boneh showed breaking RSA without factoring anything was
probably possible, but it was a nonconstructive demonstration -- we have
no idea where to begin.
So on the one hand, it's possible that brute-force factoring will have
some sort of breakthrough by 2030 (Shor's algorithm, maybe?) that will
end the useful lifespan of 2048-bit keys.  And on the other hand, it's
possible that Boneh's work will have some sort of breakthrough by 2030
that will blow RSA out of the water.  We don't know.  It's kind of
frustrating.  It's this sort of complexity that causes our crystal balls
to be all murky.
Remember, too, that we're talking about predictions *18 years out*.
That's a long, long ways.  I'll be getting senior citizen's discounts at
restaurants by then.  I imagine a lot of the NISTers just didn't feel
comfortable making pronouncements past 2030.
Then you're probably best-served going hog-wild on a 4096-bit key, with
the strong caveat that nobody really has any idea whether even a 4k key
will survive until 2040.

@_date: 2012-05-25 09:24:32
@_author: Robert J. Hansen 
@_subject: Draft of nine new FAQ questions 
Just realized the phrase "nonconstructive" may need to be explained.
The best way to do it is with a story.
Imagine that you and Dan Boneh [1] are in a dark room.  Neither you nor
he have any idea what's in here with you, or if in fact there's anything
in here at all.  You're completely ... in the dark, if you'll forgive
the pun.  You begin to muse about wouldn't it be nice if there was a way
to find out exactly what else was in the room with you.
Dan listens politely, then says: "Well, figuring out what's in the room
with us is a big question.  Maybe we should start smaller: let's find
out if there's *anything* in the room with us."
You scoff at this.  "How are we going to do that?  If we find out
*what's* in the room with us, that will tell us *if* anything's in the
room with us.  How do you propose to figure out *if* anything's in the
room with us but not *what* that is?"
Now, a little-known fact about academics in computer science is that we
are all heavily-armed [2].  This is something you probably wished you
had thought about before you foolishly volunteered to be in this
metaphor, because now Dan Boneh is quick-drawing a Glock 18 with the
sort of grace and precision usually reserved for samurai movies.  As he
fills the room with hot lead at nine hundred rounds per minute,
somewhere in the world Quentin Tarantino stops what he's doing and a
single tear of pride rolls down his cheek, although he is not quite sure
Having fallen over in all the excitement, you quickly pull yourself to
your feet and scream out, "WHAT WAS THAT?"  Somehow, your voice sounds
very tinny and far away.
Dan casually removes his earplugs and explains: "Judging from the
reverberations, we know there are walls.  We just don't know where.
Judging from the sounds of fragile things breaking, we know there were
fragile things -- but we don't know what shape they're in now.  And
judging from the noise of a sucking chest wound, it's a fair bet there
is some other living creature in the room with us."
You take all this in for a moment and exclaim, "Are you telling me you
just /shot another human being?!/"
"No," Dan observes.  "It /could/ have been a werewolf.  True, werewolves
are usually immune to conventional weapons, but I have no way of knowing
whether I was using silver bullets just there.  I /may/ have shot a
human being.  But I'm not ruling out the werewolf hypothesis yet, either."
At this point you look skywards and scream, "GET ME OUT OF THIS
METAPHOR!  I get it already!  A nonconstructive proof doesn't tell us
anything about /what/ or /why/ or /how/, it just says that something
metaphor in a dark room with a raving psychotic!"
Dan helpfully points out as he's reloading that werewolves suffer from
lycanthropy, not psychosis.  As for you, you flee the metaphor for the
safety of a more literal world.
[1] In reality, Dan Boneh is a very nice guy, quite reasonable, and
    nothing at all like I'm portraying him here.
[2]

@_date: 2012-05-25 16:47:11
@_author: Robert J. Hansen 
@_subject: Testing GPG EMail encryption 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
I have an OpenSUSE 12.1 system here on my desktop.  I cannot recreate
I have a Fedora 16 server in the closet.  I cannot recreate this.
I cannot recreate this on either my Ubuntu 12.04LTS laptop, my OpenSUSE
desktop, or my Fedora 16 server.
Them's fightin' words, "convert[ing] open source to proprietary."
No one told you to do this.  Instead, you were told that if you were so
certain this was a GnuPG 2 problem that you should take it to
GnuPG-Users.  People also volunteered to help you discover the root of
your problem with GnuPG 2, but you did not take them up on it.
We try to keep this mailing list free of vulgarity.  I understand you're
frustrated and find these people (e.g., me) to be vexing, but many of us
would appreciate it if you would avoid vulgar language.
As opposed to, "because it doesn't work on my system it must not work,
Which is, you know, *true*.  If you're certain the problem is with GnuPG
2, then complaining about it on the Enigmail list isn't going to be very
productive.  The GnuPG developers are on this list, not that one.
This does not seem to be true.  Which distros are forbidding you from
getting the source code for Seahorse?  If they are doing this then they
are violating the copyright license of the Seahorse code, and I'm
certain the Seahorse developers would take great umbrage at that.
It does not work *for you*.
It does not work *for you*.
The other commonality is you.  It's quite possible you're doing
something wrong.  And to repeat, we would be happy to try and help, but
so far your attitude towards help seems to have been one of angry
My experience, and that of tens of thousands of other Fedora 16, Ubuntu
and Linux Mint users, is different.
I need to see specific instances of their violating the copyright
license attached to the code, please.

@_date: 2012-05-25 21:37:50
@_author: Robert J. Hansen 
@_subject: Testing GPG EMail encryption 
You did not specify which distro was refusing to give the source for
Seahorse.  I've found it in the repositories for Ubuntu, Debian and Fedora.
This is because your problem is not reproducible.  If you are able to
list exactly the steps you took which resulted in this problem, I would
be happy to recreate the problem and find a solution.
It seems strange that you seem to want to count coup on people who want
to help you and are volunteering their time and expertise.

@_date: 2012-05-27 22:12:24
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
That's actually not the problem.  The problem is that if 1 in 6 people
is a plant, then you're going to have endless amounts of embarrassing
blue-on-blue -- one plant decides to do X to prove to his handlers that
he can Get Things Done(tm) and is worth the money he's getting paid, and
one plant, upon hearing that "oh my God, this guy is planning on doing
X!", does everything possible to block X in order to prove to *his*
handlers that he's preventing major incidents and is worth the money
he's getting paid.
The problem isn't the fraction of the population.  The problem is
command and control.

@_date: 2012-05-29 10:41:18
@_author: Robert J. Hansen 
@_subject: problem signing public key, ----- gets converted to - ----- 
The best solution here is to use the keyserver network: it's what it's
there for.  Upload your certificate to the keyservers like so:
Then tell people they can fetch your certificate by typing:

@_date: 2012-05-29 11:02:03
@_author: Robert J. Hansen 
@_subject: getting an encrypted file to show what public key was used 
Oh, cute.  A short ID collision.  :)  Quaero Corporation's, apparently.
Short answer: try using gpg -vvvv sensitive-file.gpg.  This will give
you a large amount of detailed information that might be useful for your

@_date: 2012-05-29 11:28:36
@_author: Robert J. Hansen 
@_subject: getting an encrypted file to show what public key was used 
Can't, but it seems to be the most likely option.
The most likely cause of this seems to be --
I could be wrong, of course, but that's where I'd place my bets.
This goes to underline the importance of proper certificate validation.
If I have the sequence of events correct, then it could have been
avoided entirely if there had been a Step 4.5, "validate the certificate
he just received."

@_date: 2012-05-29 12:24:53
@_author: Robert J. Hansen 
@_subject: getting an encrypted file to show what public key was used 
The protocol is fine, but it seems that the people involved did not
properly validate certificates.  (Note that I'm not certain about this,
hence my "seems".  Maybe I should qualify it as "seems likely.")
Certificate validation uses the full fingerprint.
I apologize for sounding strident here, but that advice is both
malinformed and wrong.
It's malinformed because when something fails, we should learn why it
failed and develop processes to prevent the failure in the future.
Saying "well, just have a do-over" is not consistent with the best
practices of software engineering.
It's wrong because it's the other person whose certificate has a
collision.  He can create all the new certificates he wants but it won't
change a thing.  He may also not be able to persuade the other person to
generate a new certificate: they may have already invested a lot in
their current certificate, and may not want to switch.

@_date: 2012-05-29 12:31:33
@_author: Robert J. Hansen 
@_subject: changing the default for --keyid-format [was: Re: getting an 
Hurts interoperability.  Once someone learns the process on PGP or
BouncyCastle or [insert OpenPGP implementation here], they're going to
want to take those same skills over to GnuPG.  Those other
implementations overwhelmingly display short key IDs; if they come to
GnuPG expecting short key IDs and see long ones, we'll see a sea of
questions of "why did my key ID change when I imported it from PGP to
(Hmm.  "Interoperability" might be the wrong word, but there's not a
good term for "skill portability.")
Anyway, it's not that I think this change is _a priori_ bad, but in
order to diminish the skill portability issues (both in moving from
other implementations to GnuPG and from GnuPG to other implementations)
I think this change should not be implemented without some coordination
with the other major implementations.
Honestly, this seems like something to bring up to the IETF WG.  The RFC
already has a plethora of implementation recommendations: adding an
implementation recommendation of "use long key IDs when possible" seems
to be an entirely reasonable addition.

@_date: 2012-05-29 13:44:41
@_author: Robert J. Hansen 
@_subject: changing the default for --keyid-format 
The problem is that most people developing front ends are making them
pretty darn user-hostile.
A few years ago while taking some HCI courses, I did a usability study
on the most common certificate interface -- the tabular widget.  It
turned out to be just beyond-Godawful.
Tabular data is the Right Thing To Do in two major use cases.
The first is when you have a noninteractive display of identical
field(s) for multiple pieces of data.  Consider a printed almanac: if it
wants to convey a list of countries and populations, the best way to do
it is with a table.  Different records (countries), identical fields
(population), and since the paper is noninteractive, the table is a win.
Now consider if instead of an almanac you have Wolfram Alpha.  Typing
"population of Switzerland" immediately yields *just* the data you want,
and you don't get confused by your eye accidentally jumping a row and
reading the population of Sweden instead.  A table widget is more prone
to misreadings.
The second Big Win for tables is when data must be contextualized by
other data.  Consider a spreadsheet showing profits and losses for
different divisions of a business: if all you know is that a given
division made $X, you don't know if that's your most profitable
division, your least profitable division, or what-have-you.  The other
data is necessary to put the data you're interested in into a larger
Now consider the tabular widget as used in PGPkeys, GPA, the Enigmail
key manager, etcetera.  The certificates don't need to be
contextualized: all the data necessary to evaluate a certificate is
present in the same record as the certificate.  And since it's a
graphical application the interface can be interactive, which means the
other major use-case isn't applicable here.
Enigmail tries to have its cake and eat it too by prominently featuring
a large search box at the top of the window.  But this isn't a very good
solution.  In terms of screen real estate, about five-sixths of the
screen is taken up by the tabular widget.  The search box takes up a
relatively small portion.  The human eye tends to view large things as
more important than small things -- so the center of attention is
naturally drawn to the tabular widget, not the search box.  Further, the
human eye tends to view complex things as more important than simple
things -- so the eye is drawn to the tabular widget again, not the
search box.  I'm grateful Enigmail has a search box in the certificate
manager, but I doubt if new users even notice it.
According to Google's HCI guys [2], 90% of the U.S. internet-using
population doesn't know how to use Control-F to find a word in a
document or a page.  That's the level of skill most people have with
user interfaces -- awful.  And if you count up the number of widgets on
the screen in your average certificate manager, you'll find that there's
more visual complexity there than in Microsoft Word.
Anyway.  If people are interested in what I found out about effective
user-interface design with respect to certificate managers, say the
word.  Otherwise I'll crawl back under my rock and leave the subject
alone for another couple of years.  :)

@_date: 2012-05-29 13:49:35
@_author: Robert J. Hansen 
@_subject: changing the default for --keyid-format 
Whoops, editing error.  Should've been footnote [1], and I should've
listed it as:

@_date: 2012-05-29 14:12:51
@_author: Robert J. Hansen 
@_subject: getting an encrypted file to show what public key was used 
The good news is it's an easy problem to fix.  :)
Get in touch with your contact over there (preferably via a
non-email/non-IM form of contact, like the telephone).  After getting in
touch with the right person and verifying to your satisfaction that
you're really talking to the right person, just ask: "Hey, I need the
full fingerprint of your OpenPGP key.  Not the short ID, but the full
fingerprint.  Would you help me with that, please?"
Write down the full fingerprint.
Then say, "And could you please email me your public key?"
Once the email with their certificate arrives, save it to disk and:
fingerprint.  Make sure it matches what you were given on the phone.  If
it matches, then from the edit-key screen, type 'lsign'.  This will
validate the certificate, and at this point you'll have a fairly high
assurance that you're using the correct certificate.  :)

@_date: 2012-05-29 16:30:33
@_author: Robert J. Hansen 
@_subject: changing the default for --keyid-format 
Absolutely.  The good news, though, is that (at least in the Free
Software world) the 'market' is fragmented.  No one particular key
manager holds a dominant position.  Off the top of my head there's
Seahorse, Kgpg, GPA, the Enigmail key manager, and more.  It's possible
for a new entry to exist without offending the users who are already
happy with the existing/dominant certificate management UI.  They just
won't use the new thing, that's all -- but new users may decide to use
the better-designed interface.
The code we put together was a fairly straightforward UI mockup.  One
version was in Java (in a vain, misguided attempt at cross-platform
support); after that I put together one in Python that directly targeted
GNOME 2.  It would need some work to overhaul it for GNOME 3 (and
possibly a lot of work, given PyGTK has been deprecated in favor of a
different kind of binding).  That said, if you'll forgive me not having
a mockup ready --
1.  The window was almost comically blank:
    ._________________________________________.
 Search for: |                           |
    +-----------------------------------------+
 (room for a line of text, begins blank) |
    +-----------------------------------------+
 (checkbox for 'Show all matches')       |
    +-----------------------------------------+
                                         |
                                         |
          (completely blank              |
          tabular widget)                |
                                         |
    +-----------------------------------------+
In usability tests, people who already had experience with conventional
key managers absolutely hated this arrangement.  They wanted to see all
the information at once.  People who were new to OpenPGP were a little
confused: they weren't accustomed to windows that were mostly blank, but
they had no difficulty understanding that they needed to interact with
the search box first.  An early version of this allowed users to view
all 1000+ certificates on the keyring by clicking the 'Show all matches'
checkbox immediately.  This turned out to be a negative experience for
some users, who immediately felt overwhelmed by data.  For this reason,
the checkbox was originally set as insensitive: only once data was
entered in the search box and the number of matches ranged between 1 and
50 did the checkbox become active.
2.  As users typed things into the searchbox, the line of text would
update.  For instance, if the user typed 'T' the text would say
something like, "55 certificates contain 'T'".  At this point the user
could click on the checkbox if he/she wished.  People seemed to
understand that they should keep typing, though.  Once enough letters
were entered to reduce the matches to under seven certs, the checkbox
selected itself and the matching UIDs populated in the widget.  And, of
course, as soon as the matches went <50 the user could manually select
the checkbox.
3.  Typing 'RSA', 'DSA' and/or 'ELG' would further restrict keys.
Nobody cared about this feature: it was completely unused.  Likewise
with ">=xxxx" and/or "<=xxxx" to restrict by key length.  Nobody cared.
 In hindsight, this was a horrible misfeature -- what if someone's name
contained 'rsa', 'dsa' or 'elg'?  For instance, one of my classmates'
email addresses was  had we used his certificate as
one of our tests, I suspect people would have been driven up the wall by
this misfeature (note the "dsa" in "thetiredsaint").
4.  Searching by a hex string was supported, so long as it was prefixed
with 0x.
5.  Multiple search terms were treated as logical-ANDs, not logical-ORs.
 People didn't want/use ORs: nobody wanted "UIDs matching 'John' or
'Smith'", they wanted "UIDs matching 'John' and 'Smith'" -- e.g., Bob
Smith would match the first but not the second.
6.  Once the tabular widget was displaying UIDs, clicking on a row in
the UID would populate its key ID field.  This further reduced the
cognitive load on people: rather than see 10 UIDs and 10 key IDs (a
widget count of 20 spread across two columns), there was a single column
of 10 UIDs and, *if a row was selected*, a single key ID shown -- a
widget count of 11.  Some people liked this, some people absolutely
hated it.  The ones who hated it tended to be the more experienced
computer users.
7.  Upon clicking a UID, not only would the key ID field populate, but
the line of text would instruct the user "Double-click to view or edit
this certificate."  Upon double-clicking, congratulations, the mock-up
ended -- the mock-up was only meant to test the ease of finding and
selecting the desired certificate.
Our testing was pretty rough.  We had seven test subjects (a very small
sample), one of whom was very tech-savvy and the others were a fairly
normal cross-section of the undergraduates who were shambling around
through the building that day on their way to a university-required math
class.  The surveys showed that they all considered themselves to be
competent with computer interfaces, but only the one considered himself
expert.  They were tested on both GPA 0.3 (the latest version available
at the time) and this mock-up.  From a keyring containing 1000+
certificates, we asked them to find some certificates by email address,
some by name, some by "a name like, but spelled a little differently"
(e.g., "like Bob Johnson, but the spelling of the last name may be
wrong"), and by key ID.
The results were a mixed bag but on balance positive.  The very
tech-savvy subject immediately recognized the column headers in GPA
controlled per-column sorting, and used this to find desired
certificates in approximately the same time as our mock-up.  The others
generally found the mock-up interface to be much faster than GPA's
interface.  One subject could not complete the tasks at all with GPA; he
didn't see GPA's search box (telling us later that it was just one more
widget in a screen full of them), did not know the headers were
clickable, and so forth.  After spending six minutes trying to find just
one certificate, this subject gave up on GPA.
The subject who gave up on GPA began his session by maximizing GPA to
fill the screen.  He was the only subject to do so.  He said he thought
it would be faster if he could look over more entries at a time, but it
appears that all that additional data was more of a cognitive burden
than a blessing.
After these trials with complete newcomers to OpenPGP, I of course
showed the user interface to some veteran OpenPGP users.  A few had some
mild praise for it, but the overwhelming response was a giant "yech" and
a "I hate this interface, it feels so dumbed-down."
So, I guess you could say that we came up with an improved user
interface for newcomers, but hardly anyone who's invested time in
learning the big-tabular-widget style of manager is going to find it an
improvement.  Proof positive that you can't win 'em all, I guess.  :)

@_date: 2012-05-29 22:03:57
@_author: Robert J. Hansen 
@_subject: changing the default for --keyid-format 
As I said, it's useful when data must be contextualized.  For a
spreadsheet, the information in one row must be put in the context of
information in other rows.  This isn't the case for a certificate
manager, though: each certificate is its own self-contained entity.
Whether I have 500 RSA keys or 1 RSA key doesn't matter to me in the
slightest: I just want to look at this *one particular* RSA key, etc.
There may be a use case for contextualization in certificates, but if so
I haven't found it yet.  :)

@_date: 2012-05-29 23:07:54
@_author: Robert J. Hansen 
@_subject: GnuPG 2 + OpenPGP card on F17 
After upgrading to Fedora 17, something weird seems to be going on with
GnuPG 2 and my OpenPGP card.
First, card support seems to be provided by a package called
gnupg2-smime.  That's been installed.
Second, ssh-agent is not running (ps ax|grep confirms).  Just to be on
the safe side I killed off gnome-keyring-daemon as well.
Third, gpg-agent is running (ps ax|grep confirms).
Sometimes I'm able to query my card (--card-status) when running GnuPG 2
with sudo; other times I get "OpenPGP card not available: Not
supported."  I'm not able to query my card at all when running as an
unprivileged user.
Does anyone know what's amiss here?

@_date: 2012-05-30 04:32:14
@_author: Robert J. Hansen 
@_subject: GnuPG 2 + OpenPGP card on F17 
If GnuPG can't access it from the command line, Seahorse isn't going to
have any better luck.
With gnome-keyring-daemon running:
[rjh at isaiah Downloads]$ gpg2 --card-status
gpg: selecting openpgp failed: Card error
gpg: OpenPGP card not available: Card error
[rjh at isaiah Downloads]$ sudo gpg2 --card-status
gpg: OpenPGP card not available: Not supported

@_date: 2012-05-30 04:50:11
@_author: Robert J. Hansen 
@_subject: GnuPG 2 + OpenPGP card on F17 
And, after restarting gnome-keyring-daemon:
[rjh at isaiah Downloads]$ gpg2 --card-status
gpg: selecting openpgp failed: Unsupported certificate
gpg: OpenPGP card not available: Unsupported certificate
[rjh at isaiah Downloads]$ sudo gpg2 --card-status
Application ID ...: D276000124010200000500000D180000
Version ..........: 2.0
Manufacturer .....: ZeitControl
... [snip] ...
It seems nondeterministic.  Which is, I know, not the case -- but it's
incredibly frustrating.  At risk of pointing out the obvious, I'm not a
newcomer to GnuPG: if I was a newbie facing this, I would likely be
overwhelmed by the seeming intractability of getting smartcards working
reliably with GNOME 3.
I'm frustrated and angry, and I'm just going to leave the problem here
for a bit.  If anyone has any advice, I'll be coming back to this
problem tomorrow.  Maybe letting it sit for a while will spur my brain
into solving it.

@_date: 2012-05-30 08:40:10
@_author: Robert J. Hansen 
@_subject: GnuPG 2 + OpenPGP card on F17 
Thanks very much for being willing to help with this.  I appreciate it.
After making the debugging changes to scdaemon.conf and gpg-agent.conf,
I ps ax|grepped for gpg-agent and killed all running instances.  I then
logged out of my GNOME 3 session, in order to bring the state to as
close to pristine as I could without a full reboot.  I removed the card
from the reader, restarted GNOME 3, reinserted the card and tried again.
After running 'watchgnupg --force /home/rjh/.gnupg/S.log | tee
mycombinedlog', I ran 'gpg2 --card-status' and got another round of the
'Unsupported certificate' message.  No output was written to the file
'mycombinedlog', which was zero bytes in length.

@_date: 2012-05-30 08:54:30
@_author: Robert J. Hansen 
@_subject: GnuPG 2 + OpenPGP card on F17 
Also, should this be socket://home... or socket:///home...?
With the former, when I invoke gpg-agent manually I get a message of
"can't connect to `home/rjh/.gnupg/S.log': No such file or directory".
With the latter, I get a "can't connect to `/home...': Connection refused."
Starting over from scratch again I manually removed S.gpg-agent and
S.log.  S.gpg-agent was recreated automatically, but S.log seemed to not be.

@_date: 2012-05-30 10:16:59
@_author: Robert J. Hansen 
@_subject: changing the default for --keyid-format 
Taking a look at GPA, it seems that 0.9.0 no longer compiles on a modern
UNIX -- it expects libassuan-1.x, apparently, and libassuan's now in a
version 2.
I wasn't able to get the git checkout to work, either, due to a gettext
infrastructure mismatch.  The Makefile.in.in came from 0.17, but the
autoconf macros on my system are from 0.18.

@_date: 2012-05-30 10:54:05
@_author: Robert J. Hansen 
@_subject: GPA download site 
You may want to update:
then, as it points off at a site which only offers 0.9.0 for download.  :)

@_date: 2012-05-30 17:30:56
@_author: Robert J. Hansen 
@_subject: Some people say longer keys are silly. I think they should be 
And if the planting *is* coordinated, why in the world would you ever
need a 1 in 6 penetration rate?  I'm sorry, but this is rapidly
descending down the rabbit-hole of conspiracy theory -- where every plea
for sanity and rationality is met by an expansion of the conspiracy
theory in order to explain why sanity and rationality don't work in this
particular case.
The world is not _The Illuminatus! Trilogy_.

@_date: 2012-05-30 21:50:51
@_author: Robert J. Hansen 
@_subject: GnuPG 2 + OpenPGP card on F17 
After more wrestling with this, I'm still no closer to a solution than I
was this morning.  I was able to recreate Nguy?n's difficulties with an
Ubuntu 12.04LTS/64-bit system, though, so we can confirm that one's got
problems and it's not simple user error on his part.  Or, rather, if it
is then I'm making the exact same errors, so...
I don't know what the root cause of the problem is yet.  I don't want
anyone to misread this as "GnuPG 2 sucks," because that's *not at all
what I'm saying*.  But it does appear that GnuPG 2 has serious problems
with smartcards when running under Ubuntu 12.04LTS or Fedora 17.
Maybe we should get the Fedora, Debian and Ubuntu GnuPG package
maintainers in on this discussion?  Perhaps they don't have smart cards
with which to test their packages.  If so, I would be happy to buy them
smart cards and readers for testing purposes.  This is important
functionality and right now it just doesn't appear to reliably work.

@_date: 2012-05-31 13:16:17
@_author: Robert J. Hansen 
@_subject: F17 + smartcards: fixed 
As a summary and follow-up:
Fedora 17 has problems out-of-the-box with the SCR 3310 and the OpenPGP
smartcard.  Any card access will fail with a variety of different
errors: the only way to use it is to run as root.  This is caused by
Fedora 17 having inappropriate permissions on the USB device
corresponding to the SCR 3310 smartcard reader, and not knowing how to
properly configure udev entries.
As a fix:
            /etc/udev/rules/92-local-ccid.rules) with the following:
          # CCID rules for this box
Many thanks to Werner for looking into this.  Most of the debugging and
fix is due to him: I had little to do with it except writing up the hot

@_date: 2012-05-31 15:28:08
@_author: Robert J. Hansen 
@_subject: system migration 
Other people will chime in with precise folder paths.  I no longer have
access to any Windows XP machines, so I can't -- but a little
exploration should reveal them.
Somewhere on your system you'll have a file called "secring.gpg".  In
that directory you'll have some (or all) of --
Copy over all these files except random_seed.  Don't re-use random_seed:
sharing the same random_seed between two different machines can
potentially be unwise.
On the new machine, just install GnuPG from   On
the new machine, find where GnuPG has placed its gpg.conf file.  Drop
all the files from the old machine (except random_seed) into that
folder, overwriting if necessary.
With that, your migration should be complete.

@_date: 2012-11-11 11:18:42
@_author: Robert J. Hansen 
@_subject: gpg is safe? 
Hash: SHA256
As a reminder to the list --
PDFs are not safe attachments.  They can harbor dangerous code and be
used to exploit systems.  Be extremely careful when opening PDFs that
come from unknown sources.
Henry --
I think you will find many more people are willing to answer you if
you'll try asking your question again in a plain text email (no HTML),
and without a PDF attachment.

@_date: 2012-11-13 18:27:01
@_author: Robert J. Hansen 
@_subject: import trustdb.gpg or start from scratch? 
Including random_seed?  I've always been under the impression that's a
big no-no.

@_date: 2012-11-20 21:36:08
@_author: Robert J. Hansen 
@_subject: splot x,y,z,color w pm3d 
I don't know, but I hope you're able to find someone who does.  You may
wish to consider asking on a Gnuplot-related mailing list: this one is
about the GNU Privacy Guard, a piece of cryptographic software to help
secure email and files.  :)
You may want to check out:

@_date: 2012-11-23 11:38:02
@_author: Robert J. Hansen 
@_subject: Possibility of corrupted file? 
Miniscule, to the point where I have not ever heard of GnuPG mangling a
file.  Your file may get corrupted while it's on disk, a stray cosmic
ray may flip a bit, and so on, but GnuPG itself is quite reliable in
this regard.

@_date: 2012-10-02 15:10:50
@_author: Robert J. Hansen 
@_subject: Backup... 
There is.
We do.
Your private certificate is encrypted with a strong algorithm.  Your
passphrase is the decryption key.  If you have a strong passphrase on
your certificate, you could publish the private certificate in the _New
York Times_ and be completely confident of its security.
If you're concerned about people gaining access to your private key, put
a strong passphrase on it.

@_date: 2012-10-03 15:45:15
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
Uff da meg.  "Articles."  If my posts have reached that level of
wordcount, then I definitely need to work on making them shorter.  :)
I don't doubt the existence of this part of the community, but I don't
share in their views.  In fact, I think those views are genuinely
harmful to the advance of privacy and confidentiality.
My position is simple: I want people to understand the realities of
electronic communication, the risks they're facing, what technologies
and methods exist to mitigate these risks, and the prices of these
technologies and methods.  Few people are responsive to a would-be nanny
telling them what they should be doing.
My doctor tells me that my cholesterol is on the high side and I should
rethink my meat intake: I sometimes think about him as I'm eating a
hamburger.  Same thing with privacy advocates who tell people what they
should be doing.  I think the best that can be done is to give people
information, and let them draw their own conclusions.
This, unfortunately, means that most of your post is -- it's not
irrelevant or ill-considered or anything else like that.  It's just that
we're coming at it from such divergent perspectives there's not much I
can really say about it.  My position is simple: provide information and
let people make their own calls.  What people should do, or what we as a
community should be advocating, is really not my lookout.
Thank you -- seriously.  As I said above, I think that information and
education is the best thing we can do.  That applies to ourselves as
well.  :)
I generally agree with you here.  If you haven't read David Brin's _The
Transparent Society_, I think perhaps you'd enjoy it: it covers a lot of
these subjects (and many more) in detail.  I don't agree with Brin, but
he definitely has ideas worth considering.
Personally, I side more with those who believe that a proper balance
between privacy and transparency is what protects us.  The problem here
is that my interest in transparency may conflict with your interest in
privacy -- making it an extraordinarily difficult interaction of
interests to balance.  Schneier's _Liars and Outliers_ discusses this in
more detail: again, you might enjoy it.
Although anecdotes are not the same as data:
My first year of teaching I was assigned to a freshman (university
first-years, for those outside the United States) Computer Literacy
course.  On the first day of class I asked thirty-five freshmen if
anyone had brought a computer to class.  Three hands went up.  I then
asked if anyone brought a cell phone to class.  Thirty-five hands went
up.  I asked one student at random, "So why isn't a cell phone a
computer?"  His answer was, "Because it can only surf the Web.  You
can't write a term paper on it or anything like that."
When I asked for a show of hands for who agreed with that statement,
probably two-thirds of the class agreed with it.
In my experience -- which is absolutely *not* the same as peer-reviewed
research, don't mistake me -- most people don't even know what a
computer is, except in a very superficial "it's a box with a keyboard
and a monitor attached" sense.  So, yes, given the truly dismal state of
computer literacy today, I think it's reasonable to conclude most people
can't encrypt.
Close to the end of that semester I taught the students about S/MIME
(not OpenPGP -- S/MIME is much better supported by email clients).  The
majority were able to get S/MIME certs and install it in their email
clients, but it did take four hours of classroom lecture to get them to
understand what encryption was, what a signature was, and so on.
Happens all the time.  Today I had to give my Social Security Number to
a government agency over the telephone: I had no way of verifying the
person I was talking to really was a government employee.  For all I
know he was working with a Chechen organized crime syndicate.  But,
after reflecting on the risks, I decided to accept the risk and go on.
So, yeah, I can imagine it quite easily.  The problem isn't the lack of
certainty that what we're doing is safe: the problem is the incorrect
certainty that we are safe, that what we're doing can never come back to
bite us.
Sure, but in their defense, they weren't interested in seeing which
users were capable of walking on their own -- they were interested in
seeing which users were capable of standing on their own.  Have to learn
to stand before we learn to walk, learn to walk before we learn to run,
and all that.

@_date: 2012-10-04 11:22:00
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
I have made this analogy before, but --
Imagine there is a new technology.  Call it "Grumpelfnord."
Grumpelfnord technology lets you talk to the dead and with people who
are in far-away places.  Those people who understand grumpelfnord are
seen as possessing almost magical powers.  The world can be divided
into two categories: the ones who know grumpelfnord, and the ones who
don't.  Grumpelfnord is tightly correlated with economic prosperity,
health, and life happiness.  The bad news is that learning
grumpelfnord requires upwards of ten years of intensive, continuous
training by subject matter experts specializing in grumpelfnord.
Everyone agrees that mastery of grumpelfnord is absolutely essential
to our modern society and economy, but people tend to view it as
broccoli: sure, other people should learn and practice grumpelfnord,
but each individual person says they can get by without it.
You can easily substitute "security awareness" for grumpelfnord.  All
you have to do is change what the technology lets you do -- the rest
of the paragraph stands as-is.  Everyone knows security awareness is
essential, but everyone wants somebody else to learn it.
Grumpelfnord technology is real, by the by.  It's called literacy.
Literacy lets us learn from authors who have been dead for thousands
of years, and opens up the world to us via letters, missives and
email.  Literacy is essential to modern society, and is so important
that most Western countries give children ten years or more of
constant practice in it (in the form of compulsory schooling).  And
despite the fact we invest so much in teaching people how to read, in
America the average adult American reads under two books per year.
I don't see there being any quick, easy or cheap solutions to the
problem of how to get people to be more security-aware.  I think
things will only change once computer literacy gets taught in the
public-school curriculum, and treated with the same seriousness that
normal literacy is.  And even then, I think that as soon as people
leave public schools they will willingly and cheerfully let their
computer literacy skills atrophy, just like we tend to let our
conventional literacy skills atrophy.
This is, of course, just speculation.  I have no basis for believing
this beyond my own meandering experience.
Now, if you'll pardon me, there's a copy of Xenophon's _Anabasis_ that
I've been neglecting for far, far too long.  It's high time I re-read
it.  :)

@_date: 2012-10-04 19:22:07
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
Problems do not have to be insurmountable to have serious effects on
regular users.
John Clizbe maintains a 10Mb archive of every message that's ever been
posted to the Enigmail mailing list.  This comprises tens of thousands
of messages.  If each message is encrypted individually, then searching
through that archive could easily take on the order of a minute or more.
 That's simply unacceptable.
There are, of course, ways to mitigate this.  As near as I can tell
they're all just as bad.  For instance, you could say that each time you
receive an encrypted message, you could add it to the existing archive
with the same key.  Depending on which mode you use, though, this could
result in encrypting the 10mb archive for each and every new message
that comes in.  That's something you really want to avoid.  You could
try to get around that by using more exotic cipher modes (e.g., consider
each message's position in the archive to be an index, and use the index
to set a cipher running in Galois-CTR mode or somesuch), but the more
complicated the scheme becomes the more fragile it becomes.
It becomes completely impossible to do enterprise-level spam filtering.
 If I send you email in plaintext, your ISP can check that email against
its spam detection engine and, if my message gets flagged as spam, it
can be automatically redirected to a spam folder.  If I send you email
in ciphertext, your ISP can't do that.
Now, you might say that this is exactly the behavior you want.  If so,
great.  But it's not the behavior that the overwhelming majority of
users want -- I can't count the number of people I know who have
completely switched to Gmail for their email provider just because of
their superb spam filtering.  Many of these people are quite
computer-literate and they know full well that Google is inspecting the
contents of their email to deliver targeted ads -- but that's a tradeoff
they're willing to make if it reduces spam.
Who says we should promote anything?  Nobody ever elected me Grand
Poobah of the Internet.  I don't think anyone ever elected you, either.
 Instead of telling people what they should do, what's wrong with giving
people options and telling them that it's their responsibility to make
informed choices?

@_date: 2012-10-04 21:12:29
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
Yeah, and me, if doing a fulltext search on 100,000 messages takes more
than a fraction of a second, something's quite wrong.  Responsiveness
Of course they would.  They're already running on hijacked systems,
using botnets to send out spam: why would they care about using up a lot
of somebody else's CPU?  They already don't care about using up a lot of
somebody else's network connection.
Yes.  Recommendations are all well and good.  There's a difference
between a recommendation and a should, though.  If I say, "I really
liked this restaurant: they had wonderful seafood," that's different
from saying, "You should go to this restaurant: they have wonderful
seafood."  The first is a statement about how you interact with the
world.  The second is rather rude if you say it to someone who's
allergic to shellfish, or someone who for religious or dietary reasons
must abstain from seafood, or... etc.
This is a meaningless question, because it presumes there's a single
objective standard for what is "safe and sane."  There isn't: all
security decisions are context-sensitive.

@_date: 2012-10-04 21:17:44
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
The task is parallelizable, and botnets are large.

@_date: 2012-10-05 05:59:15
@_author: Robert J. Hansen 
@_subject: collision vs. preimage attacks: policy for signing data created 
The first SHA-1 collisions were published in 2005, somewhere in there.
A team at Shengdong University discovered them.

@_date: 2012-10-06 17:20:53
@_author: Robert J. Hansen 
@_subject: what is killing PKI? 
Yes.  But there's a difference between saying "the ceviche is awesome,
you should try it" and saying "you really should lose some weight."
When you're telling people to eat their broccoli, nobody wants to hear
the word "should."  It's a word best avoided.
Therefore, for this question to be meaningful, you must have doubt as to
whether Werner & Co. are capable of forming an opinion as to what they
consider to be "safe and sane."  Because if there's no doubt, then why
ask it at all?
I do not share in your doubts.

@_date: 2012-10-16 23:52:35
@_author: Robert J. Hansen 
@_subject: lock/backup files 
Although I don't have a way to achieve your goal via your preferred
means, I do have a way to achieve your goal: add a small script to your
Linux startup/shutdown sequence that will remove the lock files from
your directory on boot and on shutdown.

@_date: 2012-10-17 15:42:46
@_author: Robert J. Hansen 
@_subject: compile failure 
You need a few development libraries installed.  These can usually be
installed from your UNIX's package manager, but without knowing what
you're compiling it on our ability to help you is limited.

@_date: 2012-10-17 15:46:43
@_author: Robert J. Hansen 
@_subject: cannot access FTP site to download missing library 
The login is 'anonymous', and the pw is your email address.  Many ftp
sites (GNU being just one of many) provide guest access this way: if you
ever find yourself prompted for a username/pw, that's usually a safe one
to try.

@_date: 2012-10-24 03:27:28
@_author: Robert J. Hansen 
@_subject: FAQ update 
The FAQ that was mentioned earlier this year is still being worked
on/revised.  Werner requested that we shift to using org-mode
formatting, so I took the XML markup and wrote a small script to convert
it to org-mode.
There is a GitHub repo set up for the FAQ at:
There is also a preview version of the HTMLified output at:
Remember, this is not an official FAQ, and it's also a work in progress.
 Any and all constructive criticism will be warmly received.

@_date: 2012-10-27 01:03:10
@_author: Robert J. Hansen 
@_subject: Limit of maximum password length 
There are always limits.  If you're on a system with 4Gb RAM, good luck
putting in a passphrase longer than 4 billion characters.  Admittedly,
1024 characters is much less than four billion, but the point gets made:
there's always a limit somewhere, and the existence of a limit doesn't
really mean very much.  :)
I suppose my question is, why do you think you need such a long
passphrase?  The passphrase is used to create a 128-bit symmetric key,
so giving a passphrase of more than 128 bits of entropy gives you
nothing.  At a rather low estimate of 1.5 bits of entropy per glyph of
English text, that means you only really need 85 characters to get the
maximum entropy.
"To stand divided light at ev'n and poise their eyes, / Or nourish,
lik'ning spiritual, I have thou appear" -- to take two random lines of
random poetry -- is 105 characters and at least 158 bits of entropy.
Plenty enough for any purpose.  :)

@_date: 2012-10-27 02:54:09
@_author: Robert J. Hansen 
@_subject: Limit of maximum password length 
No, I don't.  I think that using passphrases longer than about 80
characters shows you don't understand the problem.  :)
A 1024-character passphrase is so long I doubt you could memorize it
(unless you were to use the full text of some well-known poem, and in
that case it would be a poor passphrase).  That means you've got it on a
file somewhere and enter it via cut-and-paste.  That means instead of
safeguarding just your private key, you now need to safeguard your
private key, the file that contains your passphrase, and the OS calls
that implement C&P functionality.  This is a much, much weaker system
than if you were to use a "normal" passphrase.
Being too paranoid is just as bad, and maybe even worse, than not being
paranoid enough.
You control the entropy by coming to an informed estimate of how much
entropy is present per glyph of text.  Claude Shannon and others did
groundbreaking work in this field, and came up with numbers generally
falling around 2 bits per glyph.  Subtracting a bit to be on the side of
safety gives us 1.5 bits per glyph.
Alternately, you can do something like this:
rjh at flynn:~$ gpg --armor --gen-random 2 16
That "5FNsIpmx..." is an example of a 128-bit passphrase.  That's the
gold standard for passphrases.
I'm not going to comment on external entropy generators.  I don't know
your particular situation, and that means I can't tell you what makes
sense for your particular needs.  Telling you a 1024+-character
passphrase doesn't make sense for your needs is one thing -- telling you
what makes sense for your needs is something else altogether.

@_date: 2012-10-27 04:28:10
@_author: Robert J. Hansen 
@_subject: Limit of maximum password length 
Depends a lot on your operating system.  For most modern OSes it's not
required at all -- I see that you're running on Windows, and there it's
(generally) not required.  There may some exotic systems somewhere that
it is required, but I've never seen it be required for any desktop system.

@_date: 2012-10-27 15:17:47
@_author: Robert J. Hansen 
@_subject: Limit of maximum password length 
You want to use GnuPG 1.4, which does not use gpg-agent for handling

@_date: 2012-10-29 14:34:37
@_author: Robert J. Hansen 
@_subject: new release of GPA 
GPGshell is not Free Software, and for that reason it's not exactly
appropriate to recommend it on this list.  Whether we agree or disagree
with the Free Software Foundation -- I personally disagree with them,
and particularly RMS, an awful lot -- the fact remains that GnuPG is a
GNU project, and we should respect their rules when we're participating
on an official GNU mailing list.  :)
What about GPGshell do you find to be a clear win over GPA?  How can the
GPA maintainers make GPA competitive with GPGshell?

@_date: 2012-10-29 16:41:31
@_author: Robert J. Hansen 
@_subject: new release of GPA 
It is not Free Software.
"'Free software' means software that respects users' freedom and
community.  Roughly, the users have the freedom to run, copy,
distribute, study, change and improve the software. ... 'free software'
is a matter of liberty, not price.  To understand the concept, you
should think of 'free' as in 'free speech,' not as in 'free beer.'"
GPGshell is free-as-in-beer software, but it is not free-as-in-speech
software.  Quoting from  :
"Do you publish your source-codes?
No!  But when you've got the source-code for Windows, you can ask me again."
GPGshell does not make their source code available to their users.  That
means it cannot be considered Free Software under GNU's definition.  And
since this mailing list is associated with GNU, and GNU requests that
people not recommend the use of nonfree software, I think it's only
reasonable that we comply with their request.
"Broken" is pretty strong language.
Not everyone wants a CLI, true.  That doesn't mean GnuPG is broken: it
means that GnuPG does not satisfy the needs of some users.
No, because I use the CLI.
Could you perhaps make a list of, say, the top five features GPGshell
supports that GPA doesn't?  Things that you, yourself, use regularly,
and which would make GPA better suited for you?  I'm sure the GPA
maintainers would be very interested in hearing it.

@_date: 2012-10-29 17:50:14
@_author: Robert J. Hansen 
@_subject: new release of GPA 
Believe it or not, I do not agree with the Free Software Foundation.
(I've said this before: perhaps you didn't see it.)  That does not
change the fact that on a mailing list run by an FSF project, I believe
it is only reasonable to comply with their request that non-free
software, in the FSF sense of 'free software', not be recommended.
Read your own words, please.  You're the one who said the GnuPG product,
not the GPA product.
I never said GPGshell shouldn't be *discussed*.  I said that the Free
Software Foundation would much rather that non-free software was not
*recommended* on FSF-related mailing lists.

@_date: 2012-10-29 21:02:57
@_author: Robert J. Hansen 
@_subject: Limit of maximum password length 
Speaking only for myself, I find these passphrases to be at the upper
limit of what I can reliably memorize, and I can only keep track of four
or five.  But then again, how many extremely high-security passphrases
do any of us need?

@_date: 2012-09-05 10:05:35
@_author: Robert J. Hansen 
@_subject: A safe text editor 
The best bet here is probably to use TrueCrypt or somesuch to encrypt
your hard drive, rather than depending on a text editor to encrypt files
when saving to the hard drive.  That said, if you need this particular
functionality, I think I saw a gEdit plugin a while back that offered
something similar.

@_date: 2012-09-10 17:55:38
@_author: Robert J. Hansen 
@_subject: A safe text editor // why?? 
First, it's "Van Eck phreaking."  TEMPEST refers to a NATO standard for
*defending* against Van Eck phreaking.
Second, no, of course the distro-on-a-stick doesn't defend against Van
Eck phreaking.  The only defenses against Van Eck phreaking involve the
laws of physics, not mathematics.  Working inside a Faraday cage may
(may!) give some benefit.  Not quite sure, myself.[*]
[*] Although a Faraday cage blocks signals from coming *in*, the jury's
out on whether it blocks signals from *leaving*.  As an example, imagine
you have a Faraday cage that's hooked up to electrical ground.  You step
into the cage while carrying a balloon that you've rubbed on your head a
few times.  You're locked in the cage.  To signal your conspirator that
you want out, you touch your balloon to the cage.  The conspirator sees
a couple of picocoulombs of charge stream to ground, and unlocks the
cage.  From inside a Faraday cage you've just electrically signaled
someone outside the cage, thus demonstrating Faraday cages are *not* an
absolute bar against electrical signaling from the inside going out.
Whether this thought experiment is applicable to Van Eck is a different
matter, of course... but the naive "you can't get any electrical signal
out of a Faraday cage" view appears to be wrong, as a matter of physics.

@_date: 2012-09-12 17:29:56
@_author: Robert J. Hansen 
@_subject: A safe text editor // why?? 
Beats me.  The real question is, why are you bringing a mobile phone
into a secure space in the first place?
A smartphone contains a microphone, a camera, a GPS, an always-on
network connection, and a lot of closed-source software you can't
inspect for security holes.  Zero-day exploits exist for both Android
and iOS.  Add it all up and what you come up with is, don't bring mobile
phones into secure spaces.  It's not worth the risk.

@_date: 2013-04-01 16:58:31
@_author: Robert J. Hansen 
@_subject: How difficult is it to break the OpenPGP 40 character long 
(Nothing I am writing here is sarcastic or non-factual.)
At present, the only way to do a preimage attack on SHA-1 (as opposed to
a random collision) is brute-force, so about 2**159 operations.  If
you've got a PC that operates at the thermodynamic limits of the
universe and can compute a SHA-1 hash in only 1000 bitflips, and you
want to achieve this collision within the space of a year, then you're
looking at needing to use about 100 exatons or more of energy.
This is considerably more than the gravitational binding energy of the
earth: as in, 100 exatons is enough to send every single rock in the
Earth flying away from all the other rocks faster than the Earth's
escape velocity.  100 exatons is enough energy to notably warp the local
spacetime continuum and would slightly perturb orbits of other planets.
No one will ever brute-force a SHA-1 fingerprint.  Maybe in five or ten
or twenty or a hundred years someone will figure out a way to do it that
doesn't involve brute-force, but for right now preimage attacks on SHA-1
are well in the realm of science fiction.

@_date: 2013-04-01 17:06:23
@_author: Robert J. Hansen 
@_subject: How difficult is it to break the OpenPGP 40 character long 
Yes and no.  We're not going to get around the Margolus-Levitin limit
(you can't flip a bitstate in faster than h/4E seconds, where E is the
amount of energy you're using) unless we first figure a way around the
Heisenberg Uncertainty Principle, for instance [*].  We're not getting
around the Landauer Bound (establishes a minimum energy for information
erasure) unless someone repeals the Second Law of Thermodynamics [**].
And we're not getting around the Bekenstein limit (establishes a maximum
density for information storage) period full-stop, as near as physics
can tell us.
We have a lousy track record at predicting the rate of technological
advancement, but we have a pretty good track record at discovering
fundamental limits of the universe.
[*]   Okay, so Margolus-Levitin doesn't say energy *precisely*, it can
technically be any conserved quantity.
[**]  Adiabatic computing may offer a way around this, but it's unknown
whether the laws of physics will allow true adiabatic computing to even

@_date: 2013-04-01 20:04:04
@_author: Robert J. Hansen 
@_subject: How difficult is it to break the OpenPGP 40 character long 
This is not a preimage attack, which is what one would need to forge a
certificate fingerprint.

@_date: 2013-04-02 07:17:33
@_author: Robert J. Hansen 
@_subject: How difficult is it to break the OpenPGP 40 character long 
Off by a factor of ln 2 there, chief.  :)  Required energy to destroy a
bit of information (not necessarily flip a bit) is about 3.06 * 10**-23

@_date: 2013-04-15 17:07:54
@_author: Robert J. Hansen 
@_subject: Backing up Private Keys 
Let me apologize in advance for being pedantic.  I understand the
question that I think you meant to ask, but that's not quite the same as
the question you asked.  :)
Whether it is acceptable practice depends largely on your local security
policy.  I can imagine some installations would disallow this, on the
grounds that backups are the sole responsibility of system
administration staff.
Whether it is sensible practice, though, is a different question
altogether.  Without commenting on whether it's acceptable for your
particular situation, I can say pretty confidently that a paper hardcopy
of your private certificate is sensible.
Print it out in a monospace font with the largest point size you can
without causing the lines to wrap.  (If you're wondering why, OCR works
best with monospace fonts, and the larger the better.)
Although I haven't had to recover from a paper backup, I have tested it
a few times using OCR software.  Works fine.  David Shaw also wrote a
tool called 'paperkey' which yanks the unnecessary bits from a private
certificate, leaving behind a much smaller thing more suitable for
printing.  It might be worth looking into.

@_date: 2013-04-15 17:17:25
@_author: Robert J. Hansen 
@_subject: Backing up Private Keys 
No.  This isn't the sort of question that Moore's Law is useful in
addressing.  You need to get down into the physical limits of the
universe -- particularly things like the Bekenstein and Landauer bounds,
the Margolus-Levitin limit, and so on.  This has been discussed at
length on this list before.  A good synopsis can be found at:
It's worth noting that these limits are all physical constraints of the
universe.  As such, if a computer operating at the physical limits of
the universe can't brute-force something, it's fair to say that it
simply cannot be brute-forced.

@_date: 2013-04-15 23:15:19
@_author: Robert J. Hansen 
@_subject: Backing up Private Keys 
This is not correct.
GnuPG keyrings are just a stream of OpenPGP octets in a format that
conforms to an OpenPGP message.  Since RFC4880 fully specifies things
like how to handle endianness and whatnot, GnuPG keyrings are
architecture- and endianness-agnostic.
(And yes, I have migrated .gnupg folders between 32- and 64-bit systems,
including from 64-bit PowerPC UNIX to a 32-bit Wintel environment -- the
trifecta of OS, architecture and endianness all changing.  Zero problems.)
Why?  The private certificates are already secured with AES.

@_date: 2013-04-16 07:00:02
@_author: Robert J. Hansen 
@_subject: Backing up Private Keys 
My error; I thought that was changed a couple of versions ago.  Thank
you for the correction!

@_date: 2013-04-17 19:24:14
@_author: Robert J. Hansen 
@_subject: Privacy concerns 
This has been discussed ad nauseam in the past.  Generally speaking
there are two camps on this subject and neither camp has ever been
successful in persuading the other camp to change their mind.  Check the
list archives for all the gruesome details.
My opinion on this is that arguing about whether it's a problem is
completely useless.  If someone has a concrete proposal to separate
certificates from user identities, and has an actual implementation that
I can download and test, then I'm happy to evaluate that implementation.
 Otherwise, though, talking about this in the abstract is just a recipe
for frustration, stress, and long threads that go nowhere.
(No one has ever produced a proposal that's involved running code, BTW.)

@_date: 2013-04-17 19:37:19
@_author: Robert J. Hansen 
@_subject: question on decryption with missing passcode 
This is almost certainly a file permissions error on their end.  Whoever
is running GnuPG doesn't have the necessary permissions to read the file
they're trying to decrypt.  A quick way to test this would be to try and
open it in Notepad or Emacs (after making a copy, of course!).  If you
can't do that, then the problem isn't with GnuPG but is with the
permissions on the file.
Your assumption is probably incorrect.  Let's look at the source code.
(It's okay if you don't know C: just skip over the source code and go to
the text under it.)
decrypt_message( const char *filename )
    IOBUF fp;
    int rc;
    /* Open the message file.  */
    fp = iobuf_open(filename);
    if (fp && is_secured_file (iobuf_get_fd (fp)))
      {
        iobuf_close (fp);
        fp = NULL;
        errno = EPERM;
      }
    if( !fp ) {
        rc = gpg_error_from_syserror ();
                   gpg_strerror (rc));
        release_progress_context (pfx);
    }
(Some non-essential lines have been removed for ease of reading.)
Your error message appears in here.  It doesn't appear anywhere else, so
we know that this is the source code that's relevant to your problem.[*]
 GnuPG is throwing an error before it's read a single byte of the file.
 It tries to open the file, can't, indicates the problem is disk
permissions ("errno = EPERM"; by long-standing UNIX tradition error
codes start with E), and bails out.
The problem is not that the file has been corrupted; it's that the file
is unreadable.  This is good news for you, since file permission
problems are *much* easier to fix than corruption problems.  :)
Hope this helps.  Let us know if we can be of more assistance.
[*] Technically it does appear other places, but those code paths only
get called for decrypting multiple files.  Here you're just decrypting
one, so the other code paths can be ignored.

@_date: 2013-04-17 19:45:56
@_author: Robert J. Hansen 
@_subject: question on decryption with missing passcode 
Not for a 1Gb file, it's not.  Even FAT32 can handle that, and FAT32's
about as brain-dead a filesystem as you're ever likely to come across.
Further, if it was a file size issue, then how did the file ever get
successfully copied in the first place?
If this turns out to be a file size issue I'll donate 100EUR to g10
Code.  That's how sure I am it's not a file size issue.

@_date: 2013-04-25 23:47:49
@_author: Robert J. Hansen 
@_subject: Confusion with signature digest type. 
Beware of "best practices."  What makes a practice best depends greatly
on the specific threats you face, and unless the author knows your
particular threat model a healthy amount of skepticism is warranted.
Examine each claim critically and ask yourself, "does this practice give
me any real, measurable, quantifiable advantage in the context of my
threat model?"
For my own lookout, I don't see that this practice would give me very
much.  If SHA-1 falls victim to preimage attacks then I'm completely
screwed anyway on a few dozen fronts simultaneously, and my certificate
is the least of my worries.
If I wake up in the middle of the night and discover my house is on fire
I'm not going to care very much about whether I forgot to turn off the
coffeepot.  A preimage attack on SHA-1 is my house being on fire:
avoiding SHA-1 for self-signatures is making sure to turn off the coffeepot.
I suspect that quite a lot of us are in that same boat.

@_date: 2013-04-26 14:54:10
@_author: Robert J. Hansen 
@_subject: Confusion with signature digest type. 
Sure: but what does it gain you?  The answer would seem to be, "on the
balance of probabilities, virtually nothing."
All the hash algorithms in OpenPGP are mathematically similar.  They're
all built around Merkle-Damgard constructions.  History shows us that
when there's a successful attack against one Merkle-Damgard
construction, quite often this attack spurs new equivalent attacks
against other hashes in the Merkle-Damgard family.  This is one of the
reasons why so few people recommend RIPEMD-160, for instance: despite
the fact that there are no effective attacks against it, the consensus
opinion seems to be that RIPEMD-160 is just too similar to SHA-1 and MD5
for there to be real confidence in it.
Let me repeat: *all* the hash algorithms in OpenPGP are Merkle-Damgards.
So if there's not just a collision attack against SHA-1, but a preimage
attack, well... are you really going to have any confidence in your
signatures just because you're using SHA-256?  I wouldn't.  A preimage
attack on SHA-1 would tell me the entirety of the Merkle-Damgard family
is suspect and I need to stop using them immediately.
Yes: and is what you're talking about really a nudge?  Or is it an act
that appears to be a nudge, while in reality achieving effectively zero?
(Note that I'm not expressing doubt.  You're the one who knows your
threat model, not me.  If you tell me that yes, this is a real nudge up,
then that settles the question.  I'm only raising a question: I am
entirely apathetic as to the answer.)

@_date: 2013-04-28 04:26:03
@_author: Robert J. Hansen 
@_subject: Confusion with signature digest type. 
I'm having a little bit of trouble connecting the dots, Daniel.  (This
may be due to the late hour: at 4:30am I'm only awake due to a caffeine IV.)
If I sign my certificate using SHA-1 today, how does that facilitate a
collision attack against that certification?  Collision attacks on SHA-1
seem to be more in the realm of message signatures and automated systems
that may generate a ton of signatures on user-provided data without
human intervention.  It doesn't seem to be particularly relevant to the
case of a certificate signature: it seems as if to attack that you'd
have to move from generating random collisions into preimage attacks.
It is, of course, quite possible that I'm tired and missing something
important.  :)

@_date: 2013-08-21 09:53:22
@_author: Robert J. Hansen 
@_subject: need help for GPG 1.2.1 binary for REHL 5.8 
Although I certainly understand the desire to minimize risk, the
possibility of being hit by one of the dozens of bugs that have been
found in 1.2.1 (and fixed since) needs to be considered as well.
GnuPG 1.4 has no trouble interoperating with 1.2.1.  The OpenPGP
specification (which GnuPG implements) includes the ability to discover
what features the other party/parties support and to automatically use
compatible features.
If you are not able to, that would strike me as a very serious bug in
GnuPG and one that will be soon fixed.

@_date: 2013-08-22 09:56:51
@_author: Robert J. Hansen 
@_subject: Serpent? 
No.  SERPENT is not part of the standard OpenPGP cipher profile, and
GnuPG implements the OpenPGP specification quite closely.
GnuPG extends this with support for Camellia-128, Camellia-192 and
Camellia-256.  I don't know the reasoning for introducing Camellia, but
I'm sure there's a solid basis for it.
The best way to get GnuPG to support SERPENT is to convince the IETF
OpenPGP Working Group to add SERPENT to the symmetric cipher profiles.

@_date: 2013-08-22 13:51:38
@_author: Robert J. Hansen 
@_subject: Serpent? 
I agree, it is inappropriate.  On the other hand, I was not aware of the
RFC.  Thank you for telling me about it!  :)

@_date: 2013-08-23 13:24:46
@_author: Robert J. Hansen 
@_subject: Why trust gpg4win? 
It seems disingenuous to say, "well, GnuPG says they have no connections
to the BSI but if you're concerned about that then try my crypto product
because I have no connections to the BSI!"  If there's enough cause to
doubt GnuPG, there's enough cause to doubt you.

@_date: 2013-08-25 00:04:33
@_author: Robert J. Hansen 
@_subject: Why trust gpg4win? 
In a lot of ways, Windows 7 and beyond are much harder targets to crack
than Linux is -- Microsoft's implementation of ASLR is much stronger
than Linux's, for instance, to name just one technology that makes
Windows 7 a harder target than Linux.
*No* operating system deserves the label "secure."  *All* operating
systems are vulnerable to more or less equal degrees.  The number one
factor in the security of a system is the diligence and attentiveness of
the system administrator.  Someone who keeps a Windows box fully
patched, checks links to make sure they're not being spearphished, who
only runs apps from trusted partners, etc., is going to have a much more
secure operating system than someone running an OpenBSD box but who
clicks on everything they come across.
No, not until/unless people are willing to pay the price for secure
communication.  It doesn't come for free.
Give people the choice between insecure but convenient and secure but a
difficult learning curve, and people will overwhelmingly choose the former.
We cannot make people care.  That's one of the hardest truths I've had
to accept.
Very serious.  USB tokens are great tools for propagating malware.
Compromise the box that's connected to the net, and as soon as someone
plugs a flash drive into it, compromise the flash drive.  Bring it over
to the new computer, plug in there, and bang, you've spanned the air
gap.  This is not a new attack: it's been known about for many years and
has been demonstrated in real-world environments.

@_date: 2013-08-29 20:07:59
@_author: Robert J. Hansen 
@_subject: GNUPG and Cast6 
In addition to the other (correct) answers you've received, this one
also applies: "Because nobody else is using CAST6."
(Also, CAST6 is a different algorithm than CAST5.  It's not really a
"variant".  The algorithms are similar, yes, but then again so are
Blowfish and CAST5-128, and nobody calls Blowfish and CAST5 variants of
one another.)

@_date: 2013-12-03 13:02:06
@_author: Robert J. Hansen 
@_subject: Renewing expiring key - done correctly? 
The first question I have is, "How did you attempt to 'expire' it?"
Unfortunately, no.
There will certainly be well-meaning people who will speak up with  their own idea of what the best practices for such a thing are.  I  encourage skepticism.  Key management is at least 95% policy, and  policy will vary from person to person and place to place based on  each individual's perceptions of risks and risk mitigation strategies.
By all means listen to these opinions, but please be skeptical of  thinking they are correct.  What makes sense for one person's risk  profile may not make sense for yours.  There are very few universal  truths here, and that makes attempts at compiling best practices  extremely difficult.

@_date: 2013-12-03 13:04:43
@_author: Robert J. Hansen 
@_subject: Windows command line to decrypt multiple files 
Quoting bj :
What operating system are you using?  This is the sort of thing that's  more appropriate for a Windows service as opposed to a batchfile.  I  may have something around here that is useful for your niche, but I've  only tested it on a Windows 7/64 box.

@_date: 2013-12-03 19:03:13
@_author: Robert J. Hansen 
@_subject: Renewing expiring key - done correctly? 
1.  The attacker can just extend the validity himself.  He's
    successfully compromised the key, after all.
2.  As a consequence of  no one will notice.
There are certainly reasons to limit certificate and/or subkey
lifetimes, but these reasons are principally to comply with regulations,
policies and/or laws -- not so much because doing so is a security

@_date: 2013-12-03 19:26:09
@_author: Robert J. Hansen 
@_subject: Renewing expiring key - done correctly? 
Could you please share a realistic scenario by which an attacker could
compromise a subkey without also having the ability to compromise the
primary signing key?  I've been trying to come up with one and I just can't.
I'm sorry, but this entire argument is just too glib to be taken seriously.
Of course you can.  Reset their computer's clock.  You don't even have
to compromise their computer in order to do it: compromising whatever
NTP server they're contacting is enough.

@_date: 2013-12-03 20:10:32
@_author: Robert J. Hansen 
@_subject: Renewing expiring key - done correctly? 
Why do you think it's hard to compromise your boot medium?  Your boot
medium isn't a CD or DVD: your boot medium is the UEFI firmware that
gives you the choice of where to boot from next.
UEFI is a surprisingly capable operating environment.  If I can
compromise your machine, then I put down my own code in the UEFI loader
and wait for you to reboot your machine.
Hauke, you don't get to define what other people's models are, or even
what they should be.  Neither do I, for that matter.  Those models are
incompatible with what *you perceive* to be the requirements of crypto
usage in a business environment, but I promise you there are people
using crypto in a business environment who perceive things much differently.

@_date: 2013-12-03 20:20:07
@_author: Robert J. Hansen 
@_subject: Renewing expiring key - done correctly? 
By introducing offline primary key storage on an air-gapped system, your
policy has become so complicated that no one, yourself included, is
capable of always following it to the letter.
A system so complex it cannot be used correctly, won't be used
correctly.  This is why avoiding expiration dates, offline key storage,
etc., often results in a stronger system: because by making it easier to
use correctly you increase both the likelihood it will be used at all,
and the likelihood it will be used correctly.

@_date: 2013-12-04 22:04:44
@_author: Robert J. Hansen 
@_subject: Renewing expiring key - done correctly? 
Sure.  I can think of three ways to leverage a 15-minute maximum shift
into dialing the clock back to whenever I want.  I'm sure if I were to
spend more time thinking I could find more ways.  Spend some time
considering the problem: it's a fun thought experiment and will help
sharpen your skill at thinking like an attacker.
NTP is not, and was never meant to be, secure against a malicious
adversary.  It's resistant against random failures, but an attacker is
going to induce conditions that are very far from random.

@_date: 2013-12-06 23:16:57
@_author: Robert J. Hansen 
@_subject: Holiday giving 
For some years now I've done a little bit of fundraising for GnuPG, in
the form of reminding people that the holiday season is a great time to
show our thanks and appreciation for the important things in life.
Privacy is important to me, and I'd like to say thank-you to Werner and
to the rest of the GnuPG crew for all their work in providing
high-quality tools with which we may assert our right to privacy.
To show this, I'm going to be making a contribution to GnuPG.  And to
encourage you to make your own contribution, I will match any
contribution you make between now and January 1, 2014.  If you donate
ten euros, I'll pitch in another ten euros.  If you donate a hundred
euros, I'll pitch in another hundred euros.  It couldn't be simpler.[1]
Merry Christmas to everyone, and I hope you are all having the good
fortune to spend it with your loved ones.  :)
[1] My generosity has no limits, but my paycheck does: my offer
    caps out after 250 euros.

@_date: 2013-12-08 10:48:19
@_author: Robert J. Hansen 
@_subject: UK Guardian newspaper publishes USA NSA papers 
And, of course, the distance to felons is far less.  There isn't a
single person on this list whose distance to a pedophile is more than
two hops, for instance...
The hop counts of modern social networks are flat-out *scary*.

@_date: 2013-12-16 11:57:52
@_author: Robert J. Hansen 
@_subject: please give us safer defaults for gnupg 
If you're writing on behalf of a group, I would love to know the name  of the group and the names of its members.  Otherwise, I can only  assume you are suffering a mental illness and are speaking for the  multiple voices in your head -- either that or else perhaps you're  fighting off a parasitic infestation and are speaking on behalf of  your guests.  :)
It is definitely not the most-used, and it is likely not the  most-important.  OpenSSL is free software, and is used orders of  magnitude more often than GnuPG.  I routinely go days without using  GnuPG, but I rarely go even a few hours without accessing an  OpenSSL-secured webpage.
GnuPG is great, don't get me wrong -- but let's keep the hype in  perspective.  :)
Although you chose this metaphor, I'm not sure that it's a metaphor  you really want to use.
I am an amateur racer.  (My suicide ride of choice is my Mustang GT.)   This is exactly the behavior I want in a race car and exactly what I  *don't* want a novice driver to do.  A novice driver should be put  behind the wheel of a limited vehicle, and those limitations should  not be removed until such time as the driver demonstrates his or her  skill behind the wheel.  I will not share a track with you at 225kph  without first seeing you demonstrate your skills at 150kph.
The idea of giving a powerful and non-limited tool to a new user is  sort of like putting a new driver behind the wheel of a Jaguar XJ220.   Within an hour you'll have a dead driver and a smoking wreck that used  to be worth half a million quid.  What you call "limits" are, in  reality, carefully chosen behaviors meant to keep new users safe from  their own mistakes.  I do not believe it is wise or ethical to tell  new users they need to erase their margin for error.
If GnuPG's defaults lead it to being subverted, then I agree it is a  serious problem that will need remedy.  However, as near as I can tell  that is not the situation.
For as long as GnuPG has existed people have been saying "use this  gpg.conf file that I wrote in order to get the most security."  Very  often these 'recommended' gpg.conf files are in conflict with someone  else's 'recommended' gpg.conf file.
Interoperability.  SHA-1's long-term prospects are not particularly  good, but for now it is the only MUST digest algorithm in RFC4880.   The people developing RFC4880 are well aware of this problem and the  choice of digest algorithms will be addressed in the next revision of  the standard.  Until that new revision is published, GnuPG is choosing  to maximize interoperability.
Convenience.  You should always use a long key ID to retrieve a key,  but there's nothing wrong with using a short ID to refer to an  already-validated key.  The main risk of short ID collisions comes  from people pulling the wrong certificate off the keyservers and  mistakenly using that one; but when it comes to using keys you have  already downloaded and validated the risk is minimal.
Convenience.  See above.
NIST's recommendation is that a 2048-bit key will be sufficient for  the next 30 years.  ENISA concurs in this judgment (although they  recommend 3072-bit keys for reasons that are not particularly relevant  here).  RSA Data Security also concurs.  Given the vast majority of  cryptologic think-tanks in the world believe 2048-bit RSA will be  secure for the next 30 years, GnuPG has taken the reasonable position  of defaulting to 2048-bit RSA.
With respect to "if creating 4096-bit keys just takes a few seconds  longer and virtually make no difference when using these keys," as  several people here have attested to in the past it makes a big  difference for many users.  Mobile devices... embedded systems...  sites that do bulk encryption... mailing lists... the list goes on.
It is not necessary to take it for the sake of argument.  Compelling  thermodynamic arguments exist that say we will not break 2048-bit RSA  until we've had truly science-fiction level breakthroughs in computing  This would be a science-fiction level breakthrough in mathematics.  If  we can imagine a 1024-bit breakthrough, why not a 2048-bit, or a  3072-bit, or a 4096-bit, or a 16384-bit?  The problem with assuming  the existence of science-fiction level attacks is that once you start  there's no reason to stop.
I'm reminded of a _Simpsons_ episode where Lisa gives Homer a  tiger-proof rock.  She points out to him that he's not being attacked  by tigers, therefore the tiger-proof rock works.  Homer, being  foolish, believes Lisa and asks to buy the rock from her.
I do not believe it is ethical for us to be in the business of giving  people tiger-proof rocks.  Even if it "reduces anxiety," as you put  it, it's unethical.
McAfee has an offering, so does Symantec.  I know that at least one  major telecommunications firm is using the most brain-damaged and  minimalistic RFC2440 implementation on the planet.  There's  BouncyCastle, there's Peter Gutmann's cryptlib, there's...
I'm part of the Enigmail team, and I field a fair number of help  requests from users who are having trouble.
I'm not sure this is the most common help request I see, but it's  close: "I used this gpg.conf a friend of mine told me would give me  the most security..."  Almost always, it uses cert-digest-algo,  digest-algo or cipher-algo in a way that is seriously affecting

@_date: 2013-12-16 13:30:01
@_author: Robert J. Hansen 
@_subject: X.509 certificates for https://gnupg.org [was: Re: Another step 
Although I support each person's right to believe what they want with  respect to Israeli domestic policy, and to act on those beliefs in  whatever lawful manner they feel is appropriate, I don't think we want  to encourage GnuPG to take a political position on this issue.  I  think getting tangled up in politics -- especially politics that has  nothing to do with privacy rights -- would ultimately be a bad thing  for GnuPG.

@_date: 2013-12-16 20:34:31
@_author: Robert J. Hansen 
@_subject: please give us safer defaults for gnupg 
Perhaps not, but you *did* find them.  Your original email referenced,
for instance, the Debian GnuPG migration guide, which makes its own
recommendations for what one's gpg.conf file should contain.  Websites
with their own recommendations for "how to *really* make GnuPG secure"
are a dime a dozen; most of them are put up by people who deeply
misunderstand GnuPG.  (The Debian guide is, fortunately, among the
better ones.)
Then you need to use some other tool.  Alternately, you could create
your own GnuPG distribution which installs a gpg.conf file tweaked the
way you want it -- but I personally find it unlikely that the changes
you seek will be incorporated into GnuPG's master branch.
After Richard Nixon was re-elected President in 1972, the _New York
Times_ film critic Pauline Kael exploded.  "Nixon?  Re-elected?  That's
impossible!  Nobody I know voted for Nixon!"
Nothing is less trustworthy than our supposition about the feeling of a
community far, far larger than we are.
This is not a vulnerability.
Assume, for sake of argument, that my friend has a long key ID of
0xDECAFBADDEADBEEF.  I verify the fingerprint, sign the certificate, and
thus validate it.  Someone else tries to trick me into a collision by
sending me a certificate signed with 0xBADD00D5DEADBEEF.  My email
client automatically downloads the certificate from the server.  I now
have two certificates with the shortID of 0xDEADBEEF...
... and absolutely zero risk.
My email client tells me whether a message is signed by a validated key
or an invalid key, so no one can use the (invalid) 0xBADD00D5DEADBEEF
key to trick me into believing it comes from the (valid)
0xDECAFBADDEADBEEF key.  And when encrypting a message for my friend,
GnuPG won't let me encrypt to 0xBADD00D5DEADBEEF because it's an invalid
When certificates are properly verified and validated, the risk from
shortID (or even longID) collisions is effectively zero.  It's only when
one disables key validation checking, or improperly validates
certificates, that an attack surface becomes manifest.
Then use something other than GnuPG.
PGP was originally "Pretty Good Privacy."  Phil Zimmerman named it that
for a reason: it's pretty good.  It's not perfect and it won't be secure
forever.  GnuPG is built in that mold.
If you need perfect privacy, or forever privacy, you need to look
elsewhere.  GnuPG offers neither.
I imagine it's something like, "If enough people complain to Werner
about how GnuPG is no longer usable on their system, Werner will know
the system requirements should be lowered."
At some point they're the same thing.  The point remains, though, that
we can't defend against science-fiction level attacks, nor is it
productive for us to try.  Because once you start imagining
science-fiction level attacks, where does it stop?
A 2-bit reduction is not a science-fiction breakthrough.  A 1024-bit
reduction would be.
In 2000 I was a young software engineer living in San Francisco.  I was
considering applying for a job at a major, internationally-recognized
bank.  Before I sent in my resume, though, I talked to a friend who
worked there to ask about what kind of work I'd be doing.  My friend
told me the bank was undertaking a massive clean-slate project to get
rid of all their legacy COBOL code and replace it with modern,
well-designed, object-oriented Java.
I passed on the job.  To the managers at that bank, starting over from a
clean piece of paper sounded like the sort of thing that really should
be done.  To a software engineer, it sounds suicidal.  Those ancient
COBOL applications have been running with near-100% uptime for 50+ years
and last had a bug 20 years ago.  Getting rid of that is not the sort of
thing one does lightly, and never just because it seems like a good time
to do a clean-slate rewrite.
I think that if you consider this story, you will come up with what I
think of the idea of discarding RFC4880 and starting over from a clean
slate.  :)
My father is a federal judge who was asked to join FISA.  (He declined.)
I believe that, given my close association with the United States
government, a lot of people would stop trusting GnuPG if I were to ever
take a leadership or development role in GnuPG.  For that reason "what
kind of argument I would accept" is really kind of irrelevant -- you're
trying to convince Werner, not me.  All I do is answer questions, dude.  :)
(Also, it should follow that I am not speaking for Werner, nor for
GnuPG!  This email contains nothing except my own rambling opinions.)

@_date: 2013-12-17 08:31:43
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
It depends a lot on how you have GnuPG configured and how your  recipient's certificate is configured.
For asymmetric encryption, either RSA or Elgamal will be used.
For symmetric encryption, one of Twofish, AES256, AES192, AES128,  Camellia256, Camellia192, Camellia128, CAST5-128, Blowfish, IDEA or  3DES will be used.

@_date: 2013-12-17 09:02:00
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
"More secure" is sort of ... missing the point.  It's sort of like  arguing over whether King Kong or Godzilla is better at urban  destruction.  We choose between ciphers principally based on features  other than some nebulous concept of 'security', at which we can say  that all the ciphers are more or less equally secure.
Insofar as why one might be chosen over another, a big reason is  regulatory compliance.  For instance, a business might be constrained  by laws or regulations that require 128-bit crypto.  Some regulations  may require national standards to be used; in this case, a Japanese  business may be required to use Camellia, while a U.S. business would  be required to use AES or 3DES.
The other big reason to prefer one over another is comfort.  I've  audited GnuPG's 3DES code and I'm satisfied that it's correct; I  haven't audited the other algorithms.  That means I feel more  comfortable using 3DES.

@_date: 2013-12-17 10:22:33
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
I have to let my cynicism shine through, unfortunately.
For the vast majority of the population, cryptographic technologies  are a giant black box.  The popular view is that it's something only  accessible to really blindingly smart people, and that these people  know better than you.  As a result, there is never a shortage of  people who read a few web pages, come to a vague understanding of  things, declare themselves to be experts, and then preach doom and  gloom if you ever even think of violating their recommendations --  because, after all, they're *experts*.
Charlatanry is so commonplace in the crypto world there's even a FAQ  entry for it.
With respect to 2048-bit crypto, don't believe the hype.  Most users  and most purposes will still be well-served with even a 1024-bit key.   No one with half a brain is going to bother trying to break RSA-1024;  they will instead come up with more effective ways of recovering your  But there are some people and some users who have a true need for  long-term security in their messages.  The current recommendations of  NIST, ENISA, RSADSI and others is that RSA-2048 will be safe for the  next thirty years.  This is long-term security; as such, 2048-bit  crypto is generally a good recommendation.  Further, 2048-bit keys are  small enough that they may be used in smart cards, mobile devices and  embedded markets.  Basically, RSA-2048 hits the sweet spot.
But don't believe people who preach doom and gloom if you use  RSA-1024.  Although it's not sufficient for long-term security, it's  plenty sufficient to dissuade anyone who doesn't have the resources of  a First World government behind them.  If you're worried about someone  at your ISP reading your email to your girlfriend, RSA-1024 will do  the job just fine.  If you're worried about the Russian FSB reading  your Vladimir Putin slashfiction that you're sending to people in  Russia, you might want to use RSA-2048.  :)
Werner has already given you the default list.  It starts with AES-256.

@_date: 2013-12-17 11:28:58
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Well, yes and no.
When you encrypt an email for someone else, two *different* preference  lists are consulted.  The first is found in gpg.conf (or, if it's not  there, it uses default values).  The second is found on your  recipient's certificate.  So if you're looking at the preference list  on your own certificate, that doesn't tell you what algorithm you'll  be using -- it only tells you what algorithms other people may use in  their traffic to you.
With respect to "all the complaining about the defaults": excellent  damn question, and I wish I had the answer.

@_date: 2013-12-17 12:34:10
@_author: Robert J. Hansen 
@_subject: please give us safer defaults for gnupg 
Looking over it, my impression is that his principal criticism is, "It  is not all things to all people."
To which my response is -- nothing in this world is, so why should  OpenPGP be any different?  OpenPGP provides a useful set of  capabilities and tools, but if you need it to do something that it  clearly doesn't then you need to look elsewhere.
To return to the racing metaphor -- my Mustang GT is a hardtop.  If I  feel like putting the top down and enjoying the wind through my hair,  I need to get a different car.  This doesn't make my Mustang GT  inferior or inadequate, nor does it mean I shouldn't drive my Mustang  GT.  It just means I need to acknowledge the fact my car is a hardtop.

@_date: 2013-12-17 13:54:00
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Not this again.  I get very tired of answering this question.
The Second Law of Thermodynamics puts a minimum energy requirement on  how much energy it takes to change the state of a bit.  That's given  by kT ln 2, or on the order of 10**-23 joules.
You want to exhaust keys in random order, because otherwise it would  give the defender an easy way to make things hard for you: just use a  key that's close to the end of your search order.  By exhausting  random keys you foil that defense.  Between setting and clearing  registers on the CPU, loading instructions into memory and so on,  let's say that each rekeying operation takes 10,000,000 bits (10**7)  being changed.  (That's a wildly optimistic number, incidentally.)
Finally, 2**255 (the average number of keys you'll have to exhaust) is  about 10**77.
10**77 keys * 10**7 bitflips per rekeying * 10**-23 joules per bitflip  equals... 10**61 joules of energy.
A supernova releases 10**44 joules of energy.  You'll need 10**17 of  them just to power the computer to brute-force a 256-bit cipher.  The  Milky Way has about 10**11 stars; you'll need about 60 galaxies to go  supernova all at once.  This turns out to be about the same size as  the Virgo Supercluster, which is the region of the universe the Milky  Way is in.
The amount of energy we're talking about here is so large there is a  non-zero chance it would disturb the false vacuum of spacetime and  annihilate the cosmos.
People always seem to ask me if I'm making these numbers up.  No, I am  not, nor am I joking.
No one will ever.  Ever.  Brute-force a 256-bit cipher.

@_date: 2013-12-17 14:04:08
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Yes, which is why RSA-2048 is recommended.
I don't understand the reasoning by which you have concluded that I am  advocating RSA-1024.  I'm not.  I think the default of RSA-2048 is a  good one.  I'm only saying that for most users and most purposes,  RSA-1024 is sufficient; to reach "virtually all users" and "virtually  all purposes" we have to move to RSA-2048.
Simple: I'm human and I misremembered NIST's "secure until 2030" as  "secure for 30 years".  :)
NIST's guidance says 2048-bit RSA is equivalent to 112 bits of  symmetric cipher, as does ENISA and RSADSI.  ECRYPT is certainly free  to come up with their own metric; they're a competent outfit.  But  let's acknowledge that ECRYPT's opinion is a minority one, rather than  cherry-pick an outlier opinion and declare it to be authoritative.
NIST puts it in at 80 bits.  Let's not forget how long it took the  RC5-64 project to exhaust a 64-bit key.
Can it be broken?  Sure.  Easily?  No.  If you're worried about Google  being able to mine your message for targeted ads, that's plenty  enough.  If you're worried about your local sysadmin reading your  personal mail, that's plenty enough.  If you're sending Vladimir Putin  slashfic to a Russian publisher, maybe you should rethink using such a  short key.
Yes.  You've made this opinion abundantly clear many times.

@_date: 2013-12-17 14:08:38
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Quoting Hauke Laging :
This is almost certainly true.  A couple of years ago Vint Cerf  estimated that somewhere between a sixth and a quarter of all desktop  PCs were infected with remote-root malware.  The odds are quite high  that your desktop PC running GnuPG provides *zero* bits of security.
Sobering thought.
Really, all the obsession over key lengths does is distract us.  Pick  a keylength, be done with it, and then start paying attention to more  important things...

@_date: 2013-12-17 14:31:52
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Nope!  That thermodynamic analysis is how much heat you have to dump  in the universe.  (Well, entropy, actually, but to a first  approximation that's the same thing.)  For more details, check  Wikipedia's writeup on the Landauer bound:
So, yeah, it really is as catastrophic as I make it out to be.  :)

@_date: 2013-12-17 20:07:21
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Search the list archives, please -- this question has been asked and
answered a great number of times.

@_date: 2013-12-17 20:27:13
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Perhaps: but that's not what I was responding to.  The original poster
was asking why "people" (unspecified people) said to never use anything
less than 2048-bit asymmetric crypto.  My answer was that "people" were
wrong, and that what is needed for a particular environment needs to be
evaluated on a case-by-case basis.
I agree that RSA-2048 is a sensible default, but I don't see how that's
relevant to the thing I was discussing.  Did I miss a topic shift somewhere?
As do NIST, RSADSI, ENISA and others.  I agree they are a highly
professional outfit, but this makes them just one of many.
I have mixed feelings on this.  On the one hand, I fully concur that
there are some troubling possibilities there; on the other hand, it's
too easy to fall down the hole of paranoia and wind up mistrusting
everything and completely wreck your life.  For myself (and this is
purely my opinion), I believe NIST is still reliable.  If there's
evidence of tampering with a particular standard I think that standard
should be revisited and distrusted, but I think it's a stretch to say we
should distrust all things NIST for no other reason than it's
conceptually possible that a given specification, recommendation, etc.,
has been tampered with.
Yes -- but no one is claiming that 112-bit keyspaces are vulnerable
today, or at any time within the near future.  Further, moving to a
128-bit keyspace is not, IMO, any sort of a real win: you're only
gaining 16 bits of keyspace.  At most you're pushing things back for a
few years; it is not any kind of a long-term solution.
Still a 112-bit keyspace, assuming the attacker has effectively
unlimited computational resources.
Whoa there a second!  You might want to backspace and overstrike that,
because you just shifted to arguing that "since GnuPG defaults to
AES-256, we need to use RSA-15000 by default otherwise the asymmetric
portion will clearly be weaker to attack than the others."
We don't want to even out the cryptosystem.  We want to ensure that each
component of the cryptosystem meets or exceeds our minimum standards for
cryptanalytic resistance -- but the notion of "evening out" the system
is, as near as I can tell, fashionable nonsense.
So, RSA-30000, then?
A good bit prior to his death, I asked Len Sassaman why he had a
4096-bit RSA key when he privately mocked them as being key-length
fetishism.  "Because it isn't just about what I think of them," he told
me: "it's because of what *other people* think of them.  There are a lot
of people in the world who mistakenly think anything less is insecure.
They might have something to say which I'd like to hear, and I can't if
I only have a 2048-bit key."
Or something like that, something similar -- it's been a few years.
I understand Len's point of view.  I just think it's bad policy.  I
think we should not cater to key-length fetishism.
Unless we move to RSA-15000, it will be.
So far in this thread I have not been giving my own opinion on things:
I've been trying to explain the reasoning that has gone into the current
state of things.  Permit me to share my own opinion for a moment.  :)
I agree that a stronger asymmetric component would be nice, but I don't
believe RSA is the way to go.  We're already on the brink of introducing
ECC support into GnuPG.  I think that once ECC support is introduced in
the mainline, it will then be an appropriate time to revisit the
question.  I would support shifting to stronger asymmetric component(s)
at that time, but I don't think it's worth the headache of changing the
defaults if we're just going to change them *again* in under a year.

@_date: 2013-12-17 20:53:12
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Sorry for the double response -- I thought I'd included this in my
previous mail, but I didn't.
I am not in favor of covering more than 'virtually all users' and
'virtually all purposes.'  The difference between 99% of GnuPG's users
and 100% of GnuPG's users is, first of all, impossible to close, and
second of all, requires ever-increasing expense just to approximate it.
Phil Z. designed PGP to be Pretty Good Privacy.  Not perfect... just
pretty good.  GnuPG is quite clearly built in the same vein.
"Virtually all" is the right way to select defaults.  The next step
beyond "virtually all" is "all."  We can't achieve that and it's foolish
to try.

@_date: 2013-12-17 22:28:43
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
I don't understand your position.  First you're saying, "we currently
have 112 bits of keyspace, we need at least 128," and then you're saying
that you want to see the system evened out -- but the difference between
a 128-bit keyspace and a 256-bit keyspace is so enormous that you might
as well be talking about a 112-bit keyspace and a 256-bit keyspace.
If a 3072-bit key makes you happy and makes you feel it's "evened out,"
well, my question is -- why?  256 bit keyspace versus 112 is not much
different from 256 bit versus 128.
No.  My argument is that your reasoning is incoherent.  If you want to
even out the system -- or, as you advocated later, make the asymmetric
component stronger than the symmetric component -- the *only possible*
interpretation is that you're advocating for at least RSA-15000.  If you
truly believe the asymmetric component should be stronger, you're
advocating for RSA-30000.
I don't think that's what you want.  (And I note that you have
explicitly repudiated that notion.)  And since I think that's not what
you want, that means I have to conclude your reasoning is faulty.
At least 128 bits of keyspace less, obviously.  And when weighed in that
respect, whether we're talking about 128 bits or 140 bits is really
quite irrelevant.
That's why we need to focus on keeping each component at or greater than
our minimum specification.  112 bits of keyspace is a reasonable minimum
for the time being; therefore, I'm happy with the current defaults.  I
don't want to see them used for the next ten years, mind you, but I
absolutely reject the fierce moral urgency of immediate change that you
seem to be subscribing to.
That's a naked slander against NIST.  You're better than that, Daniel.
No one, and I emphasize *no one*, has presented any evidence that NIST
issued a deliberately bad PRNG, or for that matter whether Dual_EC_DRBG
is even backdoored.  _Wired_ magazine wrote of it,
(Link:  )
I emphatically agree there's a lot of uncertainty around Dual_EC_DRBG.
It is possible it was subverted -- but it's also possible it wasn't.
It's possible it was subverted, NIST knew of the subversion, and
approved the standard anyway -- but it's also possible NIST was caught
unawares.  It's possible that... etc.
Claiming that they offered a *deliberately bad* PRNG is, quite frankly,
a slander.  There is no certainty there.  There isn't even much in the
way of evidence.  There is a possibility.  Let's not go about declaring
NIST guilty based on nothing more than the possibility of wrongdoing.
Sure.  That's because we can't retroactively change keys that have
already been made.  Even if we adopt your recommendation of moving to
RSA-3072 immediately, RSA-2048 will still be the dominant key type for
I think it's a great one.  One of the best things about GnuPG has been
its stability.  Changing the defaults is not something to be done
lightly.  Doing so invalidates FAQs and tutorials, it forces people to
edit their scripts, it causes uncertainty and doubt and "why did you
change...?" on the mailing lists.  Changing to RSA-3072 now, and then to
ECC in nine months or a year, is (IMO) unwise.  "Why are you changing
the defaults again?  Did you make a mistake the last time?"
Etc., etc.  Better to wait until ECC is ready, make a single change to
the defaults, and keep the transition crisp and clean.
I think GnuPG has already clearly established its reputation in that field.
Yes -- and part of that is recognizing when the additional expense to
mitigate a risk is greater than the risk itself.  I'm sure we could
reduce airplane crashes by 90% if we were to overengineer airplanes so
much that a ticket cost a million dollars, but we don't do that.
You want perfection.  You're not going to get it.  It's like trying to
build a bridge that simply will not collapse, period, no matter how
large a weight is moved over it.
What I want instead is a quality bridge, one that's well-inspected, and
has a big sign a half-kilometer out reading, "Maximum Load 10,000kg".
That, we can do pretty easily.

@_date: 2013-12-17 22:33:35
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Too many to list.  Depends largely on your attacker's budget and the
constraints of their operation.  For instance, if I don't care if you
know I've compromised your traffic, I'll tie you to a chair and start
swinging a pipe wrench at your kneecaps.  Cheap and effective.
Or I can target your machine for compromise.  If I can trick you into
visiting a particular URL I might be able to plant a remote-root on your
desktop and gain control over it.  At that point it's easy to run a
keylogger to intercept your passphrase, and easy to copy your private
key off your desktop.
Or I can hire a $5,000-a-night hooker.  I'm pretty sure that inside of a
week you'd be willing to tell your new charming companion pretty much
anything.  The KGB employed this against United States cipher clerks
with amazing success.
Or... etc.  The list goes on and on and on.  In fact, there are so many
ways to gain access to your traffic that I think obsessing over whether
the default should be 2048-bits or 3072-bits is ... it's like arguing
over whether your security fence should be 100 feet high or 120 feet
high.  Either way you need to pay more attention to the guy who's
digging a tunnel underneath it.

@_date: 2013-12-17 23:02:41
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Beating your kneecaps into pulp, hiring a hooker to persuade the secret
out of you, beating your recipient's kneecaps into pulp, hiring a hooker
to persuade the secret out of your correspondent, Van Eycking your
terminal, Van Eycking your recipient's terminal, figuring out a way to
plant an exploit on your USB stick... I could go on for quite some time,
but you get the idea.  The best ways to recover the message do not
involve cryptanalysis, and the non-cryptanalytic means are devastatingly

@_date: 2013-12-18 00:05:47
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
How would I know?  Ask a government genius with a rack of computers.
I don't know the extent of the government's capabilities, nor do I want
to.  That's the kind of knowledge that normally comes with some really
strict rules on what you're allowed to say.

@_date: 2013-12-18 00:29:47
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Then why did you use it as a "I'm glad you can still trust them even
after they released a deliberately bad RNG?"
Good people and good institutions release bad things all the time.  Bad
things escape committees.  A lot of cryppies cringed when WEP was
announced because it used RC4 and RC4 is so difficult to use correctly.
(And true to form, WEP used it badly.) Does that mean we shouldn't
trust IEEE?
IPv4 is another great example: Vint Cerf has gone on the record saying
that he's a little ashamed of its success, since only having a 32-bit
address space has been sort of an ongoing professional embarrassment to
him, and he knew it all the while he was working for widespread IPv4
deployment.  Should we not trust Vint?
A flawed standard is just that, a flawed standard.  It's not a cause for
a crisis of trust in an outfit that has enjoyed the community's trust
for many decades.
I don't understand.  If your argument against switching to ECC is "we
won't get rid of RSA-2048 for a long time anyway," then how can you use
the same logic to argue for switching to RSA-3072 right now, since
presumably we still won't get rid of RSA-2048 for a long time anyway?
Doesn't address the issues of forcing people to rewrite tutorials and
manuals, rewrite standard operating procedures for their businesses,
rewrite scripts to accommodate the new defaults... etc.  I think you are
vastly underestimating the infrastructure here.
Only Werner knows his timetable.
And you're not making a compelling argument that 112 bits, as it
currently stands, is inadequate.
Further, there's nothing preventing you from packaging your own GnuPG
build that has 3072-bit RSA as a default.  Speaking just for myself, I'd
welcome that -- I wouldn't use it, but I'm completely in favor of there
being a competitive marketplace of ideas and letting the users sort it out.
The point of the metaphor was to show that moving from "adequate for 99%
of the population" to "adequate for 100% of the population" has some
extreme costs involved.
And your belief is that 112 bits of keyspace is not a strong set of
defaults with a reasonable security margin based on current knowledge?
For crypto that's currently projected to be secure out until 2030?
There's nothing more to say except, I disagree.  At this point in time
112-bit keyspaces are reasonable defaults.  We should be looking towards
shifting towards larger keyspaces, but there's no immediately pressing
urgency.  Let's wait for ECC.

@_date: 2013-12-18 08:23:46
@_author: Robert J. Hansen 
@_subject: encryption algorithm 
Perhaps: but *not over the PRNG they published*.  Please stay on point.
You are demonstrating a tendency here to stake out a position ("NIST is
untrustworthy") and argue towards it; and as soon as an argument is
refuted, you do a weak backtrack of that argument and stake out a new
one in the same direction.
Your argument for moving towards RSA-3072 was that you wanted the system
to be "more even."  When pointed out that we could not make the
asymmetric component "more even" with AES-256, you quickly said "well,
I'm not advocating RSA-15000" and have since pretended you never made
that argument.  When you made a smear against NIST on the basis of a
flawed PRNG algorithm -- and in context of what you were responding to,
it's hard for me to believe you were saying anything other than it was a
deliberate backdoor introduced with NIST's knowledge -- you backtracked
to "well, I never said it was witting/willing, and anyway, just putting
out a single bad spec is enough to damage trust in them."
There's no point in having a discussion about a subject if it starts
from a position and seeks arguments to support that position, rather
than starting from arguments and hoping it will lead to a position.  I
firmly believe in the latter.  The former is the specialty of bad cable
news channels where talking heads scream past each other -- which is the
state I fear this discussion has devolved into.
I'm going to make one last brief summation of my position.  Past that, I
am done with this thread.  It's not going anywhere useful.
1.  112 bits of keyspace is generally acknowledged to be the minimum
    level that current applications should support.  New crypto code
    should aim for at least 128 bits; 256 bits is better.
2.  The reason for the discrepancy is that when deploying a new system
    it's far easier to overdesign it.  When changing an existing
    system, one has to deal with a large installed codebase.
3.  GnuPG's asymmetric default meets the standard in   There is no
    imminent and pressing need to change.
4.  GnuPG's asymmetric default is believed to be secure for about the
    next 15 years.  That meets GnuPG's goal of providing pretty good
    privacy.
5.  When GnuPG introduces ECC support it will be a fine opportunity to
    deploy new certificates, whereupon the default can be changed to
    256 bits of keyspace with minimal disruption to people above and
    beyond the disruption shifting to ECC will do.
6.  No one has presented any reason to shift to 128-bit keyspaces
    right this very instant, especially when ECC is on the horizon and
    approaching fast.  Since the asymmetric component is expected to
    be safe for 15 years, we're not in an exposure window.
7.  If you seriously believe that a 112-bit keyspace is inadequate,
    then you need to stop using computers.  Pretty much every
    Authenticode-signed Windows application uses RSA-2048 at maximum.
    ATMs use 3DES, with a 112-bit keyspace.  The HTTPS infrastructure
    tends to max out at RSA-2048.  112-bit keyspaces are endemic.  It
    would be nice if they'd all move to ECC, and hopefully they will,
    but we are not facing an imminent Cryptoageddon because society's
    computing infrastructure uses 112-bit keyspaces.
8.  I would like to see GnuPG migrate to 256-bit keyspaces.  I'd like
    to see this migration done in a calm, orderly fashion.  Given the
    total lack of risk presently associated with RSA-2048 -- or for the
    next 15 years or so -- I'm just fine with waiting a year to make a
    single cutover to minimize disruption to end-users.
You may disagree with these; I imagine you will disagree vigorously.
That's fine.  But now I trust my position is clear, and we can put this
to rest.

@_date: 2013-12-18 14:26:45
@_author: Robert J. Hansen 
@_subject: Sharing/Storing a private key 
Hey, I was being *nice*.  I wasn't even pointing out that 3DES only has
112 bits of keyspace... ;)

@_date: 2013-12-18 21:44:48
@_author: Robert J. Hansen 
@_subject: How much load are keyservers willing to handle? 
The question I have is, "What problem are you trying to solve?"  I am
certain that Debian Security already has a protocol in place for how to
handle compromised certificates.  Is this protocol flawed or lacking?
What problem does it not address which this idea will solve?
The next question is, "Why is it important the certificate be retrieved
from the keyserver network?"  When talking about the global apt
repositories, it's likely they have access to multiple of orders of
magnitude more bandwidth than the keyserver network.  Why not host the
signing key on the apt repo server?
Good question.  Probably, but some keyserver operators might view it as
rude.  Best to ask on sks-devel at nongnu.org.

@_date: 2013-12-19 09:07:57
@_author: Robert J. Hansen 
@_subject: What is the latest version 
The latest Enigmail is 1.6.  1.5.2 is not tremendously old, but it's not
the latest-and-greatest, either.
Given that you got GnuPG and Enigmail from GPGtools, your best bet is to
ask the GPGtools maintainers (politely!) to update the version of
Enigmail they include with GPGtools.

@_date: 2013-12-19 10:09:22
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG launches crowdfunding campaign 
They omitted the word "new".  "Spanking new" is an English idiom for  something that's brand-new; it comes from the tradition of spanking a  newborn child in order to spur the child into taking its first breath.    Something that's "spanking new" is supposed to be as new as a  newborn child.

@_date: 2013-12-19 10:12:08
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG launches crowdfunding campaign 
It's in common usage in the U.S., although I more often hear it  without the "brand" prefix.  That said, "brand spanking new" is not  unusual usage over here.

@_date: 2013-12-19 14:37:24
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG launches crowdfunding campaign 
A district court judge found the program unconstitutional, but his  decision is *extremely* controversial right now.  I would happily bet  cash money on even odds that this decision will be overturned on appeal.
I normally don't like to go into detail about legal cases, but what  the hell -- given the general interest in this matter, I hope people  will forgive me for going off-topic.
The problem comes from a 1979 Supreme Court decision, _Smith v  Maryland_ (often just called _Smith_).
A woman was receiving harassing phone calls, so the police asked the  phone company for records about who was calling her.  The phone  company turned these records over without a warrant.  The harasser was  arrested and convicted.  He appealed his sentence, claiming that the  police should have received a warrant.  The Supreme Court refused Mr.  Smith's petition using logic sort of like the following:
     1. If you're asking the phone company to connect you to another
        phone number, the phone company knows at least your number
        and the number you're calling
     2. This isn't different from asking a friend to drive you to a
        place: your friend knows where he picked you up and where he
        dropped you off
     3. In  the police don't need a search warrant to get that
        information from your friend -- they just need a subpoena
     4. So in  the police shouldn't need a search warrant to get
        that information from the phone company -- they just need a
        subpoena
I personally find this logic simple, elegant and compelling.  That  doesn't mean I think it's right: it only means I think it's a very  serious opinion that is extremely difficult to refute.
The government has used this decision ("telephone metadata requires no  warrant, only a subpoena") on an extremely large scale... such a large  scale that it has created a very serious counterargument.  If the  police are investigating a crime that happened Thursday night, asking  your friends where they picked you up and dropped you off Thursday  night is not an infringement of your privacy -- but asking your  friends for *all* the times they've picked you up and *all* the times  they've dropped you off over the last five years would certainly be  seen as overreaching and as a gross privacy violation.  At least, such  is the counterargument.
Judge Leon -- appointed by George W. Bush, a fact that will no doubt  stun some people here -- was asked to choose between these two  opinions.  Interestingly, he really didn't choose.  Instead he said,
     "... I cannot possibly navigate these uncharted Fourth
     Amendment waters using as my north star a case that predates
     the use of cell phones."
He didn't so much agree with the plaintiffs as he found that the  _Smith_ decision was no longer relevant to modern life... and that's  where the controversy occurs.  He's a district judge.  Most judicial  ethicists would say that where SCOTUS has given clear and unambiguous  guidance on an issue, as _Smith_ appears to, a district court has no  business overturning SCOTUS's precedent.  (To which the immediate  rejoinder is, "Yeah, because it would've been such a bad thing for  some district judge to decide _Dred Scott_ was a stupid decision.")
This case is already being appealed.  At the appellate level judges no  longer look at the facts of the case: they assume the trial court  brought all the relevant facts to light.  Instead, the judges look at  a much narrower set of questions: (a) was the trial fair?, (b) were  the laws correctly applied?, and (c) were precedents correctly cited  and followed?  No one is arguing that Judge Leon was unfair or that  the law is being unfairly applied: the entire appeal will revolve  around whether _Smith_ still governs.
My feeling is that the appellate court will decide _Smith_ still  governs, reversing Judge Leon and approving the metadata program.  But  I also feel it's very likely SCOTUS will grant cert and agree to hear  the case, at which point SCOTUS will be revisiting their _Smith_  decision and potentially giving new guidance for how to apply  _Smith's_ reasoning to the modern day.

@_date: 2013-12-19 15:07:50
@_author: Robert J. Hansen 
@_subject: Holiday giving 
On January 6 (the Feast of the Epiphany, the traditional end of the  Christmas season) I'll ask Werner how many euros were raised between  the time I posted my original message and 11:59pm January 5.  Normal  donations and crowdfunding will both be matched.  Once I get a sum  from Werner I will be remitting two separate donations to g10 Code:  one will be the matching funds, and the other will be my Christmas  Werner is free to tell the list how many funds were raised, how many I  matched, and whether I lived up to my word.  However, I'm going to  request he keep my (private) Christmas contribution quiet: that's  between me and my conscience, not between me and the list.  :)

@_date: 2013-12-20 07:03:54
@_author: Robert J. Hansen 
@_subject: The Presidential Commission 
There has been a major development in the U.S. regarding government  surveillance.  Y'all might enjoy reading the following link.
Notably for us (but not mentioned in the news article), the commission  recommended intelligence agencies not be allowed to weaken encryption

@_date: 2013-12-20 07:10:27
@_author: Robert J. Hansen 
@_subject: What is the latest version 
User-Agent strings lie.  :)
Take a look at the original message.  In the OpenPGP signature there  was a comment block identifying it as having been generated with  GPGtools, which is an OS X port of GnuPG.
Please don't, actually.  Enigmail's rule of thumb is that you should  only upgrade from the Enigmail master site if you're running a  plain-Jane stock Thunderbird.  We don't know what specific  customizations GPGtools has made to Thunderbird and we can't guarantee  that our Enigmail 1.6 will work with GPGtools' version of Thunderbird.
Instead, please ask GPGtools -- *politely*, because it's important to  be nice! -- to release a new version of GPGtools which incorporates  the latest Thunderbird and Enigmail.  :)

@_date: 2013-12-20 15:51:09
@_author: Robert J. Hansen 
@_subject: Matching campaign over 
Given that we've already reached my maximum matching, I'm closing things
out a little early.  Thanks to everyone who contributed and forced me to
open my wallet.  :)
Should anyone have any doubts, please contact Werner off-list; he'll be
able to confirm receipt of this donation.

@_date: 2013-12-20 20:43:18
@_author: Robert J. Hansen 
@_subject: The Presidential Commission 
The President's commission on the NSA was expected to give a whitewash
of the program.  They definitely didn't.  When the recently-retired at the CIA tells the President, "you're screwing up and reforms need to
be made immediately over at NSA," that's pretty big news.

@_date: 2013-12-25 12:50:50
@_author: Robert J. Hansen 
@_subject: New GUI frontend for windows 
(a) If you're asking people to provide feedback and bug reports for
closed-source software, you're asking people to help you make a buck
without giving them much of anything in return.  I find that unethical.
 I don't find closed-source software unethical, mind you, but if you're
going to write closed-source software then, IMO, you need to take
responsibility for doing SQA without community assistance.
(b) Without source, there's no way I will trust it.
(c) The web page asks, "Can I trust you?", and you answer it with
"YES!".  Sorry, but no.  The only correct answer to "Can I trust you?"
is, "You need to figure that out for yourself."  In my experience,
people who answer that question "yes" are usually deeply untrustworthy.
(d) As a closed-source product, this should not be advocated on
GnuPG-Users.  GnuPG is a GNU project, and they have some quite serious
philosophical beliefs about the moral evils of closed-source software.
Let's respect the GNU position by not advocating closed-source software
on this list.

@_date: 2013-12-26 08:51:00
@_author: Robert J. Hansen 
@_subject: The Presidential Commission 
I'm not going to dignify that last one with an answer.
As to your first question, no changes have been made yet.  It's only
been a couple of days.  Give it time: let's see what shakes out of this.
 The committee just released its report a little bit ago, and between
that and the Christmas holidays it's unsurprising there's been no
further development on it.

@_date: 2013-12-26 08:55:26
@_author: Robert J. Hansen 
@_subject: New GUI frontend for windows 
I really wish people would read my emails before responding to them.
I'm not, as I said in that message -- a part which you quoted, even:
I also (correctly) attributed the anti-proprietary mindset to GNU, not
to me:
GnuPG is not my product.  I am not a GnuPG developer.  I am not a GnuPG
maintainer.  I have never contributed one line of code to GnuPG.

@_date: 2013-12-26 09:34:08
@_author: Robert J. Hansen 
@_subject: Rosetta CryptoPad released 
So what?  How is GoldBug relevant to GnuPG?  As near as I can tell it  has no relevance, which causes me to wonder why the author(s) of it  keep on introducing messages that refer to it.  It has about as much  relevance to GnuPG as does my bizarre obsession with prehistoric fish.
(Speaking of which,   has a great article on coelacanths.  If you get the dead-tree edition of _The Economist_ from late November it has the first photograph on that webpage in full 16x11 glory.   And if you're talking about Rosetta CryptoPad... the list moderators  have *specifically* *asked* that non-Free Software not be advocated on  this list.  The big exception to that rule is in the context of  discussing whether GnuPG can/should support features found in non-Free  Given the list moderators have asked that non-Free Software not be  advocated on this list, that's all the reason I need to not talk about  the Rosetta CryptoPad.  Between the closed source and the complete  lack of trust, let's consign discussion about it to the dustbin and  move on.

@_date: 2013-12-26 11:46:26
@_author: Robert J. Hansen 
@_subject: Rosetta CryptoPad released 
Because I had it conflated with Encreep, a similar tool that was also  recently posted here.  That's the closed-source one.  My apologies to  those who feel I've misled them.
Again: so what?
The GnuPG-Users community has always been structured around GnuPG,  OpenPGP, how to keep endpoints secure, and (to a lesser extent)  privacy rights.  GoldBug does not touch on any of those except insofar  as it borrows some code from GnuPG.
I have no personal animosity with GoldBug, except insofar as people  associated with it continue to post identical (or near-identical)  messages to many different mailing lists in an apparent marketing  attempt.  For instance, what possible relevance could it have to  OpenSSL?  Yet a very familiar-looking message was posted to  Given that these messages appear to be a marketing attempt, *and*  given that they're off-topic, I personally would appreciate it if they  could be taken somewhere else.  Others may disagree with me, of course.

@_date: 2013-02-04 22:15:05
@_author: Robert J. Hansen 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
No.  There are none, nor will there be.  You absolutely must retain
control of the processing hardware GnuPG runs upon.  If you don't have
that control, there is literally no device -- hardware or software --
that can help you.
You can't.
This doesn't make sense to me.  You don't trust your PC running GnuPG,
so you want to verify your mail on a PC running GnuPG, just one that
happens to be 'trusted'?
(Also, you seem to be using the word 'trusted' in a way opposite from
its real meaning.  A system is trusted if it has the ability to break
your security policy.  It doesn't mean the system is actually
trustworthy.  It's a statement that you're *forced* to trust it, not
that you think it's *deserving* of trust.  See, e.g.:
... bottom of page 2, if you want to see an academic reference to this
definition of 'trusted'.)

@_date: 2013-02-05 20:49:39
@_author: Robert J. Hansen 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
If you don't trust the PC that GnuPG is running on, don't run GnuPG on
that system.  (Or anything else that requires trust, for that matter.)
It makes no sense to me to believe that it's somehow possible to have a
dongle that you can plug into a compromised PC to make it safe (or
safer) to sign with.  If you believe the PC is compromised, cut it out
of your process completely.  There is no other realistic option here
that I can see.

@_date: 2013-02-06 17:51:00
@_author: Robert J. Hansen 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
I have an OpenPGP smartcard and an SCM card reader.  I installed it
under Fedora 16 and it worked beautifully.  Under Fedora 17 it's broken.
 After a few rounds of unfruitful debugging I gave Werner an account on
an F17 box with this hardware plugged in, and even then we were unable
to figure out what was wrong.  So, since this device clearly doesn't
work under F17 (or F18, now, for that matter), I've elected to stop
using it in favor of using my desktop PC.  Just makes sense.  Damned
thing doesn't work.

@_date: 2013-02-07 09:49:32
@_author: Robert J. Hansen 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
Yes, I did.  A good compromise is one that leaves the victim unaware the
machine has been compromised.  If you-the-user see evidence that makes
you think you've lost control, the compromise author has failed.  (Note
that this isn't true for a lot of malware nowadays, where the hijacker
literally doesn't care if you notice and instead trusts in your
inability to do anything about it: but that's not the kind of malware
we're talking about here, where we're assuming someone who has
compromised your system explicitly for purposes of hijacking your GnuPG
Then I re-compromise your box and start over.  I also plant a couple of
messages on message boards you frequent talking about how my dongle, of
the same model number as yours, doesn't work with my Linux distro, of
the same kind as yours, since a recent kernel upgrade.  Since I have
your machine compromised I know what sources you check for these things,
and the dark side of crowdsourcing is how easy it is to give strategic
misinformation to people.
At some point you're going to believe the problem is the device doesn't
work.  I might also deliver to you a high-priority message, something
that needs a signed response urgently, in order to give you another
reason to disregard the device for "just this once."
No, quite the opposite.  Vint Cerf estimated a few years ago that one in
five desktop PCs was rooted and the owners didn't know it.  One in five.
That's a really scary number.
Anyone on this list who thinks they couldn't possibly be part of that
one in five is living in a fantasy world.  Any of us could be.
Now, I haven't seen evidence to suggest that my machine is compromised.
But that doesn't mean I have limitless confidence in my hardware.  My
desktop PC is trusted hardware in the most classic definition of
trusted: I trust it because I have to, not because I believe it's
deserving of trust.
And that's the entire methodology I'd use to exploit your perfect
dongle.  Those who view things only academically tend to fall down and
go boom when confronted with real-world attacks on the human side of the
system.  Those who view things only as human interactions tend to fall
down and go boom when the math works against them.  This is the sort of
thing that must be looked at from both directions simultaneously.
Sure.  Because if I give you any clue that the machine is compromised,
I've failed to write a good compromise.  I'm assuming for sake of
argument that I'm competent at skulduggery.
Which is why I would seed the forums you use with reports of these
devices not working.

@_date: 2013-02-07 10:02:41
@_author: Robert J. Hansen 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
Yes -- I'm a fair bit more knowledgeable about these things than most,
and as my story of the smartcard reader shows, I may have *already
fallen victim* to this sort of thing.  (Or the reader could just be
buggy.  Or maybe I'm trying to exploit someone using an SCM card reader
on a Fedora 18 box and I'm planting seeds to make them think their
system is buggy and their reader won't work, so go ahead and fall back
to cardless usage.  Who knows?  It could be any of those.  I suspect
it's just buggy.)
Admittedly, in the case of a buggy-or-compromised smartcard reader the
attacker isn't looking to compromise the private key on the smartcard:
the attacker is trying to get me to fall back to my alternate keys which
are on my desktop.  The principle still stands, though.  Cards and
pinpads are great at protecting private keys from being exported off the
smartcard, but that's not the same as preventing exploits.

@_date: 2013-02-07 19:17:05
@_author: Robert J. Hansen 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
No.  I am arguing that if you do not/cannot trust the machine you're
running GnuPG on, *there is no dongle you can add to your system to
restore your trust in that machine*.  You want a system in which, even
if GnuPG is compromised, you can't be tricked into signing something
other than what you intend to sign -- where, even if GnuPG is
compromised, you can trust the signatures you make.  Good luck.  It
can't be done.
You need to be able to trust your hardware.  If you don't, then no
matter what dongle you use, the door is open for an enterprising
malcontent to exploit you in any of hundreds of ways.
Because I trust my hardware.  If you can trust your hardware, then
there's a lot of stuff you can do.  If you can't trust your hardware,
then the only thing you should be doing is figuring out a way to restore
that trust.
Sure.  That's theoretically possible.  I don't believe it to be true,
though.  My machine is trusted not because I'm certain that it's immune
to being pwn3d, but because I acknowledge that it can break my local
security policy and I'm willing to accept what I perceive as the risks.
If you don't trust your hardware, then that means you're not willing to
accept the risks you perceive.  And that's a really big problem.  If
you're not willing to accept the risks you perceive as associated with
your hardware, then why are you using your hardware?
The smartcard solves a completely different problem than what you're
talking about.  This is why there's a differential answer.

@_date: 2013-02-07 22:14:17
@_author: Robert J. Hansen 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
Sure.  There are always situations where a particular attack won't work.
 For instance, if there's an ironclad no-exceptions policy that you may
never, ever, fall back to using GnuPG on the PC, then this attack
wouldn't work.  But that quickly reduces to a game of whack-a-mole -- a
game you're not going to win.  The attacker gets to tailor his attack to
your defenses; you don't get to tailor your defense to the attacker.
If you don't trust your hardware, get new hardware that you do trust.

@_date: 2013-02-07 22:16:23
@_author: Robert J. Hansen 
@_subject: GnuPG in the media 
GnuPG was mentioned (somewhat inaccurately, but still mentioned) in the
_Daily Mail_.  It's not exactly 'respectable journalism', but it's still
very high-visibility.

@_date: 2013-02-20 18:48:17
@_author: Robert J. Hansen 
@_subject: Documentation on symmetric key options for GPGME 
It is possible to force the use of AES-256 whenever possible: add
"--cipher-algo aes256" to the GnuPG command line.  However, this is
thoroughly not advised.  It's possible to create traffic your recipient
will not be able to decrypt, for instance (not every OpenPGP
implementation supports AES).  There are also other edge cases in which
using cipher-algo can get you in trouble.
OpenPGP specifies its own block mode, which is basically CFB64 with some
special sauce added -- it's a hack which dates back many years.  Every
now and again there's some talk about replacing it with something more
modern, like Galois counter mode or somesuch, but so far nothing's come
of it.  So the answer to this one is no, you really can't specify a
block mode.

@_date: 2013-02-20 20:23:52
@_author: Robert J. Hansen 
@_subject: Patch add support for different algorithms in the agent private 
The current best attack on AES-256 maxes out at 11 rounds; the full
AES-256 has 14 rounds.  Nobody's ever demonstrated that full AES-256 is
easier to break than AES-192; and even if they had, it would still be a
nonissue.  "Theoretically, a reduced-round AES-256 is less secure than a
reduced-round AES-192" would be more accurate, and as the sentence gets
more accurate it seems to become less relevant.
Besides, cryptosystems very rarely fail as the result of cryptologic
flaws.  It's so rare I'm having a hard time thinking of any off the top
of my head; WEP fell to an implementation defect in RC4, SSL had
problems with side channels, there are a lot of systems that have fallen
to timing attacks, and so on.  But I'm scratching my head here trying to
think of the last time a system fell to cryptanalysis.  The DVD Content
Scrambling System, maybe?

@_date: 2013-02-20 20:39:18
@_author: Robert J. Hansen 
@_subject: Patch add support for different algorithms in the agent private 
Doing a little more research, I found a theoretical attack on the full
-256 and -192; I was wrong to say the current best attack only worked on
a reduced-round variant.  The new hotness is a related-key attack,
wherein the attacker chooses two keys and a relationship between them
and uses that to attack the full cipher.  It's definitely an exotic:
that sort of condition is unlikely to occur in the real world,
especially in GnuPG where AES is used for randomly-generated session
keys -- there's no relationship between them to be exploited.
Still, I was incorrect to say the best attack is on a reduced-round
variant.  Mea culpa.  :)

@_date: 2013-02-22 20:55:57
@_author: Robert J. Hansen 
@_subject: US banks that can send PGP/MIME e-mail 
OpenPGP, no, because there's no business case for them to do so.
OpenPGP users represent a phenomenally small fraction of their userbase
(probably <1%) and would account for a large fraction of their tech
support questions.
S/MIME, yes, some banks have discovered the benefit.  However that's
still mostly a business-to-bank thing as opposed to consumer-to-bank,
since S/MIME is a technology that's not exactly ready for consumers.

@_date: 2013-02-24 14:35:00
@_author: Robert J. Hansen 
@_subject: US banks that can send PGP/MIME e-mail 
Oh, please.  This is pure projection.
It doesn't.  It works for one particular bank.  It doesn't work for
Germany as a whole.  Different banks have different clienteles and
different incentives for how they deal with their clientele.
And as soon as a customer is on the phone with tech support for two
hours trying to get GnuPG to work on their system, that's about $100 the
bank has now spent trying to retain this customer.  That's a lot.  The
only way to make the user profitable in such a case is to raise service
fees, in which case that bank will hemorrhage business to their competitors.
If I were a banker and I had a choice between SSL-secured HTTPS that 99%
of my internet banking customers would approve of, which requires no
special training or experience on their part, which requires no
additional special training on the part of my tech support staff, or
adding OpenPGP-secured statement delivery that would appeal to 1% of my
userbase and each one of those users would have tech support costs
orders of magnitude greater than the users as a whole, the presence of
that 1% would require expensive training and retraining on the part of
my tech support staff...
Honestly, if I was advising a consumer bank about this, I'd tell them to
avoid OpenPGP.  I don't see the business case for it.  And until you can
show me either (a) radical improvements in ease-of-use, (b) radical
reductions in technical support costs, or (c) explosive demand from the
users, you really can't show me the business case for it, either.

@_date: 2013-02-24 16:24:54
@_author: Robert J. Hansen 
@_subject: US banks that can send PGP/MIME e-mail 
Meaning what, exactly?  At first blush you seem to be trading one
problem for another: people don't know how to use GnuPG, so ship a
device and now they don't know how to use the device.
Cheaper, not superior.
To a first approximation, MBAs and bean-counters divide a business's
operations into revenue and overhead.  They'll go to great lengths to
maximize revenue, and they'll go to great lengths to minimize expenses.
 Security doesn't directly generate revenue -- at best it indirectly
facilitates it, but that's difficult to quantify and plug into a
spreadsheet.  That means security gets viewed as an overhead expense:
something to be minimized at all costs.
People keep on thinking in terms of "wouldn't it be nice if," but that's
not how business thinks.  Business thinks in terms of, "what will
maximize revenue and minimize overhead?"
OpenPGP users account for probably less than a thousandth of all
computer users.  99.9% of all banking users have no real desire to see
OpenPGP used for their statement delivery.  If the 0.1% of customers who
want OpenPGP produce so much revenue for a bank that they cannot be
ignored, and are willing to leave their current bank for one that will
provide OpenPGP, then we can expect to see banks deploying OpenPGP-based
But until then, no.
This is not a technological problem.  It's a business problem.  To think
otherwise is to commit serious category error.

@_date: 2013-02-25 19:26:56
@_author: Robert J. Hansen 
@_subject: US banks that can send PGP/MIME e-mail 
No one, but your statement seemed to be a severe overgeneralization.
Declaring that something works "in Germany" has a strong implication of
it working throughout *the whole of* Germany.  If your intent was
instead to say, "Why does it work for these specific banks?", then I
have no objection to that and I think it's a very reasonable question.
Like perpetual motion machines, business cases are judged by how well
they work in the real world.
The discussion is about banks that *send statements via encrypted
email*.  If the bank is doing this then it's officially supporting it.
No, I'm not.  At some point any business will declare a customer to be
too much trouble for the amount of profit made from that person and will
seek to alter or terminate the business relationship.  This does not
change the fact that people will still seek technical support, and that
technical support costs money.
And if the bank is officially supporting sending customers bank
statements via encrypted email, then yes, the bank does need to offer
technical support or else the bank will soon be losing customers.
Having seen the balance sheets for tech support costs for a couple of
Fortune 50 firms, I can tell you that you're off by an order of
magnitude.  Unfortunately, I'm bound by nondisclosure agreements and
can't really say more than that.  $100 for an hourlong session is in the
right ballpark for the firms I have firsthand experience with.
To give you an idea of how the accounting is done, though, labor costs
are the least of the concern.  Another major concern is, "What if the
customer gets so frustrated with the problem that the customer stops
doing business with us?"  If 1% of tech support calls result in losing a
customer, and the average lost customer would've resulted in $10,000 of
profit over the course of that customer's relationship with the
business, then the amortized cost of a tech support call just jumped to
$100... right there... based on nothing more than the cost of the
customer's frustration.
You cannot measure the cost of a tech support call solely by the cost of
the labor involved.  The labor involved is insignificant: it's so minute
it's practically considered accounting error.  The real costs come
elsewhere, and they accrue the instant the tech support call is placed.
This assumes the 0.1% that uses OpenPGP provides per-customer revenue
comparable to that of the 99.9%.  This is probably not true: you're
talking about such a small selection of users that their profile will
probably be quite idiosyncratic compared to the community at large.
So your "solution" involves telling customers, "we will support your
request to use OpenPGP for sending encrypted bank statements, but only
if you agree to use Hushmail for a mail provider, even though they have
a track record of turning cleartext copies of email over to legal
authorities"? [1]
[1] You seem to think the problem is unlimited support.  It's not.  The
problem is the instant *any* support is offered it's a minimum $100
charge (under the model I presented above, where each call has a 1%
chance of terminating a business relationship that would've been worth
$10,000 over its lifetime).
You can reduce the price of offering technical support or reduce the
rate at which technical support is needed.  Capping support will do
nothing to mitigate the problem, because labor costs -- the thing you're
proposing to cap -- are not the problem.
Nobody ever made a fortune by catering to a small and stagnant market.
OpenPGP adoption has, on the whole, badly stagnated.  (Email itself is
also stagnating, which is far worse.)
In the quite-excellent film _Other People's Money_, an entrepreneur has
this to say on the subject:
Email is already stagnating -- the next generation of customers
(teenagers and college students) associate email as a decrepit
technology that was cool back in their parents' day.  The next
generation of customers wants HTML5 and smartphone apps.
The number of people who want balances emailed to them is not growing,
it's *shrinking*.  The number of people who want those statements
encrypted with OpenPGP is, at best, stagnating.
If you like, I encourage you to supply that demand.  I think you'll
quickly discover you're the buggy whip manufacturer in the
entrepreneur's story.
A business case which has already shown itself to work *for one bank*.
Without knowing details of this bank's economic niche, its customer
demographics, its technological infrastructure, the choices it made
which led it to its current point, it is impossible to make any kind of
pronouncements about whether that same plan would work in the United
States.  You can't say it would.  You can't say it wouldn't.  You simply
don't have the data to make any argument one way or another.

@_date: 2013-02-26 08:36:18
@_author: Robert J. Hansen 
@_subject: US banks that can send PGP/MIME e-mail 
Figuring out how to install an app is not the problem.  Figuring out how
to *use OpenPGP* is the problem.  The app is not the same as the amount
of specialized knowledge required to use the app successfully.
OpenPGP has a learning curve like the Matterhorn.  This is a long-known
and long-lamented fact.  If you can fix that, then maybe things will
change.  As things stand, though, I doubt they will change.
Then why bother at all with email and OpenPGP?
On the contrary, many of them are phenomenally good at it.  Operations
Research is part of the business school in most universities, and the OR
geeks tend to be astonishingly good at what they do -- which is maximize
efficiencies and cut inefficiencies.
(ObDisclosure: I'm a contributor to COIN-OR, the Computational
Infrastructure for Operations Research, and have assisted with a couple
of papers in the field.  I have been deeply, thoroughly impressed by
virtually everyone I've met in OR.)
OR nerds -- who are the B-schoolers who focus most heavily on
efficiencies -- are serious math and CS nerds.  Look up George Danzig
I understand that many geeks like to look down our noses at people in
the B-schools, but really, that's a shallow prejudice that we as a
community need to get over.  There are some alarmingly sharp people over
I'm going to have to ask to see the business study you're using to back
this up.  This is your prejudice, nothing more.  It's just as credible
to claim that a bank probably wouldn't want to cater to seriously
tech-savvy people because of the risk of bad apples.
If 0.01% of your customers have the capability to defraud your bank,
that's a much different situation from 1% having that same capability.
It affects the business logic considerably.  They might wind up spending
the *most*.
Which is why I didn't make that claim.  I said that probably <1% (and my
suspicion is <0.1%) of all users would want OpenPGP to be used to secure
For example, I'm in the ranks of people who don't care.  I genuinely
don't.  I want some sensible technology to be used, but I have zero
interest in specifying which technology should be used.

@_date: 2013-01-03 20:59:27
@_author: Robert J. Hansen 
@_subject: Is a document signed with hellosign legally binding? 
There is usually a world of difference between what cryppies consider a
"legally binding signature" and what is really a legally binding
signature.  The law has many ways for a signature to be deemed binding:
the law has many ways for a binding signature to be repudiated.  Whether
a signature is really binding in your specific case is a legal question
for which you'll need to consult with a lawyer licensed to practice in
your area.

@_date: 2013-01-04 08:34:40
@_author: Robert J. Hansen 
@_subject: gnupg not working with RHEL 4 
The fix is easy: upgrade GnuPG.
Version 1.2.6 is old, really old.  The certificate you're trying to
import uses an algorithm (DSA2) which is relatively new.  GnuPG is
trying to treat this as a DSA certificate and is complaining that it
uses the wrong parameters.
Download and install the GnuPG 1.4.13 source code from:
... and this problem will go away.

@_date: 2013-01-04 22:23:53
@_author: Robert J. Hansen 
@_subject: paperkey //  recommended OCR font ? 
My experiences are similar.  One additional thing: the larger the font
the easier it is for OCR to recognize it (up to a point: I doubt there's
much difference between 48- and 72-point recognition).  So try using 12-
or 14-point if possible.

@_date: 2013-01-28 00:56:25
@_author: Robert J. Hansen 
@_subject: Fedora 18: still broken for OpenPGP cards 
My prior bug report detailing Fedora 17's problems with OpenPGP cards is
still current for Fedora 18.  Would it be possible for one of the GnuPG
maintainers to shake the tree of the gnupg2-smime maintainer (the RPM
just lists the Fedora Project as the maintainer) and ask why in God's
name they insist on releasing a gnupg2-smime package that does not work,
clearly hasn't been checked against the most common smartcard hardware
in use for GnuPG, and which has been broken for two major releases?
The original thread, BTW:

@_date: 2013-01-28 01:07:48
@_author: Robert J. Hansen 
@_subject: Fedora 18: still broken for OpenPGP cards 
Addendum: GnuPG 1.4.13 works fine with smart cards.  It's only GnuPG
2.0.19 that's screwed up.
[rjh at localhost ~]$ gpg --version
gpg (GnuPG) 1.4.13
... snip ...
[rjh at localhost ~]$ gpg2 --version
gpg (GnuPG) 2.0.19
libgcrypt 1.5.0
... snip ...
[rjh at localhost ~]$ gpg2 --card-status
gpg: selecting openpgp failed: Unsupported certificate
gpg: OpenPGP card not available: Unsupported certificate
[rjh at localhost ~]$ gpg --card-status
gpg: detected reader `SCM Microsystems Inc. SCR 3310 [CCID Interface] 00 00'
Application ID ...: D276000124010200000500000D180000
Version ..........: 2.0
Manufacturer .....: ZeitControl
Serial number ....: 00000D18
Name of cardholder: Robert Hansen
... snip...

@_date: 2013-07-07 06:04:07
@_author: Robert J. Hansen 
@_subject: GPG keys for multiple email accounts 
Not hardly.  Theoretically speaking [*], AES-256 will fall to brute
force after 2^255 attempts.  A keyspace of 2^124 is nowhere near half of
2^255; it's not even particularly close to the square root of 2^255.
Assuming you meant AES-128 instead of AES-256, it's still not very
close.  A 128-bit keyspace will (again theoretically) fall after 2^127
attempts.  A keyspace of 2^124 is a factor of 8 less than this -- not
"nearly half."
[*] All this handwaves, of course, the fact that breaking AES-256 by
brute force is impossible given the physical constraints of the
universe, and breaking AES-128 by brute force is impossible given the
fact we'd like the Earth to remain a habitable planet.  People who
obsess over the amount of entropy in their passphrases are living in
sin.  Spend more time worrying about how to keep your passphrase secure,
and less time worrying about whether it has 128 bits of entropy or
instead "only" 80.

@_date: 2013-07-07 11:43:17
@_author: Robert J. Hansen 
@_subject: GPG keys for multiple email accounts 
Nobody with two brain cells to rub together is going to try
brute-forcing either the crypto or your passphrase.  Nobody.  Let me
make it really clear: anyone who would try to do this would be such a
blistering moron that I don't feel the need to waste any time
considering how to defend against him.
Further, who cares if the number of bits in different parts of the
system aren't balanced?  If I want 112 bits of effective protection, and
I use a passphrase with 128 bits of entropy to decrypt key material
shielded with AES-256, then I haven't "wasted" anything at all, nor is
my system "imbalanced."  Instead, my system has a minimum of 16 bits of
safety at each step.

@_date: 2013-07-07 17:19:02
@_author: Robert J. Hansen 
@_subject: GPG keys for multiple email accounts 
Find me some verifiable instance of OpenPGP passphrases being
brute-forced and I'll take this seriously.  Until then, I will continue
to treat brute-forcing as the myth I'm almost certain it is.  I like to
assume an attacker is at least as smart as I am.  If I'm smart enough to
see that brute-forcing has really bad odds of success, why would I waste
time when there are so many better avenues of attack available?
I need your secret key and passphrase I'd start by hiring a
thousand-dollar-a-night hooker for a week and point her in your
direction, with a $5,000 bonus if she's able to get your key and
passphrase without you noticing.  Simple, cheap and effective.  I might
have her plant a keylogger while she's in your bedroom.  Or I might try
and nab you via a carefully-prepared spearphish, or get you on a
drive-by as you surf the web, or... etc., etc.
It makes absolutely no sense to brute-force a passphrase when it's so
easy to compromise the communication endpoint.  That's where the real
work lies -- not in talk about making something resistant to brute-forcing.
This is irrelevant to the discussion.  If a cipher isn't fast enough for
your purposes then don't choose it.  It has nothing to do with whether
the entropy in a system is "balanced".

@_date: 2013-07-24 18:06:50
@_author: Robert J. Hansen 
@_subject: Multiple email addresses - any alternative to ask everyone to 
(My original reply went just to Philipp.  My apologies.)
Unfortunately, this is not casting very much light on things.  The use
of phrases like CONFIDENTIAL, SECRET and TOP SECRET have very specific
meanings in NATO countries, and you're using them here in ways that are
at odds with their NATO meanings.
Let me try this rephrasing:
You have three machines: Fry, Leela and Bender.  Fry is your smartphone,
Leela is your desktop and Bender is your "secure" desktop.  Email to
you at fry.yourdomain goes to ... what, all three of them?  Email to
you at leela.yourdomain goes to Leela and Bender, and you at bender.yourdomain
goes only to Bender.
Further, each piece of traffic can receive any of three classifications:
C, S or TS.  You can send C traffic to Bender: the necessary keys to
decrypt it are held there.  However, although you can technically send
TS traffic to Fry, Fry can't decrypt it: the keys aren't there.
If I have this right, then you've walked straight into the Bell-LaPadula
security model.  You'll be well-served by reading up on it: a good
academic reference will answer many of your questions.
The short answer is, "OpenPGP by itself will not be sufficient for your
purposes.  It might be able to provide a couple of tools, but what you
want to achieve is far beyond the scope of OpenPGP."

@_date: 2013-07-25 18:20:27
@_author: Robert J. Hansen 
@_subject: GPG weakness 
It is not very important, to be honest, but we still thank you for
bringing it here.  :)
The overwhelming majority of technology journalism is somewhere between
wildly uninformed and complete bollocks.  This article is one of them.
The first rule of using GnuPG -- and this is something that the GnuPG
developers strongly endorse -- is that *you must control the physical
hardware GnuPG is running on*.  If you don't, then there is literally no
end to the malfeasance an attacker can perpetrate.  If you don't have
physical control over the hardware, don't run GnuPG on it!
So, in light of this first rule, is it really all that surprising that
GnuPG should have security problems when it's run "in the cloud" --
which means running it on hardware you don't physically control?
Rule One exists for a reason.  Violate Rule One and it becomes pretty
easy to play hob with GnuPG.  This article is all about some researchers
who violated Rule One and discovered a new way to play hob.  It's
interesting research, but completely irrelevant to GnuPG users who are
wise enough to obey Rule One.  :)
Beware of all experts.  An ex is a has-been, and a spurt is a drip under
For what it does -- securing communications in transit -- GnuPG is a
well-regarded piece of software which is widely used in some extremely
demanding fields.  I have personally seen it used by international
telecommunications companies to secure tens of millions of dollars of
transactions, for instance.
And this is why you should beware of all tech journalism.  The
overwhelming majority of it is simply awful and uninformed.

@_date: 2013-07-25 18:31:17
@_author: Robert J. Hansen 
@_subject: Why trust gpg4win? 
It's been years -- 25 years or more -- since I've read Victor Milan's
"The Cybernetic Samurai."  I only remember one scene from the novel, but
it's a scene of such vividness that it's been permanently burned into my
The short version of it is, someone who is scared, in fear for her life,
and really needs a friend, asks a mercenary if she can trust him.
"I'm not going to answer that," he tells her.  "Deciding who to trust
and why is on you, not me.  A word of advice, sister... when you meet a
guy who says you can trust him?  Don't.  It never ends well."
Why should you trust GPG4WIN?  Beats me.  That's on you.  All that we
can do is answer questions.  If you have specific questions that can be
factually answered, I'd love to help you with them.  But I'm not going
to tell you that you should trust GPG4WIN, and I don't think you should
believe anyone who tells you otherwise.

@_date: 2013-07-25 21:46:05
@_author: Robert J. Hansen 
@_subject: Why trust gpg4win? 
Some thoughts --
First, if you're concerned about the involvement of government
intelligence agencies then you're on the wrong mailing list.  They're
already here, and for the most part they're quite helpful individuals.
Consider In-Q-Tel.  In-Q-Tel is a nonprofit venture capital firm that
invests in technology companies for the purpose of keeping the United
States intelligence community ahead of the curve.  If there's going to
be some big sweeping change rocking through the tech world in the next
few years, it's In-Q-Tel's job to know about it, potentially to invest
in it, and to keep the U.S. intelligence community abreast of it.
(In-Q-Tel is *not* a government agency: it just has deep ties to the
intelligence community.)
Now, if you were to go over a list of In-Q-Tel personnel, you'd find
that a very senior person within In-Q-Tel has posted to this list in
recent memory, reads this list regularly, and when he speaks generally
gives very good advice.  (I'm not publicizing this person's name because
I don't want him to get deluged in mail.  However, he is public about
his association with In-Q-Tel, so I don't feel there's a problem with
saying this person exists.)
Should we shun this person from the community?  Would telling this
person "hit the road, Jack, we don't want you around here any more" make
any of us safer?  Or would we instead lose the contributions of someone
who has a unique and useful perspective, and who has always given sage
John W. Moore, who hasn't been seen on these lists in a long time, was
always quite open about his past as a United States Marine and his time
spent working for the NSA while in uniform.  John was always patient and
helpful with newbies.  He was an important part of Enigmail.  Should we
stop using Enigmail because John W. Moore once worked for Fort Meade?
I live in the Washington D.C. metro area and attend a handful of
computer forensics conferences around here.  A couple of years ago I
wound up sitting in an auditorium at the NSA, because they were willing
to host one of the conferences.  Should I be shunned because I've been
inside an NSA auditorium?  When I was in graduate school and working in
electronic voting, my advisor and I wound up having a couple of
conversations with CIA personnel who wanted our opinions on the
trustworthiness of foreign elections -- "can the results from this
country be trusted?" sort of thing.  Should I be shunned because I've
briefed a couple of people about the electoral conditions in remote,
far-off places?  My father is a federal judge: does that make me any
more suspect?  One of my friends is an FBI agent: maybe that ought
disqualify me?
... It is completely natural to have concerns about the trustworthiness
of GnuPG and to wonder whether it has ties to the BSI and/or BND.  But I
respectfully suggest that if you're going to worry about that, you
should first worry about the GnuPG community as a whole.  Within this
community there exist an awful lot of people who have ties to the
government, to law-enforcement, to intelligence agencies, and more.
But that doesn't mean we're the bad guys, and it doesn't mean the
community is endangered because we're present.  I believe it's quite the
opposite.  The In-Q-Tel executive has an incredible perspective on
developing technologies, and we all benefit from that.  John Moore's
firsthand knowledge of history was very useful to us.  For me, growing
up around government and law-enforcement taught me a lot about how they
think and see the world, and I can impart some of that.
The moral of the story, I think, is that you shouldn't be worried about
the BSI or the BND.  Worry about people instead.  Ask yourself this
question: do you really believe Werner would deliberately compromise
GnuPG in order to satisfy a demand from the BND?
If your answer is "yes," then you probably shouldn't use GnuPG at all.
If your answer is "no," then it doesn't matter if Werner is working for
the BND himself.  (He's not, by the way.)  If you don't believe Werner
would do that to you, then there's no problem.
In the end, it's all a question of trust... and that means it's
something that *only you* can answer.

@_date: 2013-07-27 04:25:26
@_author: Robert J. Hansen 
@_subject: Fwd: Goldbug.sf.net - Secure Multi-Crypto-Messenger v0.1 released 
Based only on their press release, this seems like a completely
unscalable bucket of failure.
And this, right here, is why it's such a colossal disaster.  It cannot
Let's say that you're connected with 1,000 other users, and each of
those users is connected with another 1,000.  Someone sends you an echo
packet that you can't decrypt.  You then send it to 1,000 others.  999
can't read it and the last one can.  Each of these 999 users then sends
it on to *their* 1,000 contacts...
Remember, this is delivery to a user *adjacent to you in the graph*.  It
doesn't get better or easier than that.  And for a delivery this simple,
we're still talking about spamming the network with a million packets
(your original 1,000, plus 999,000 others) just to deliver a single packet.
This is not a communications protocol.  This is a denial of service
attack against a network.
Now, maybe the people behind the "echo network" are world-class network
engineers who have already accounted for this, and the person writing
the marketing copy is a brain-dead marketroid who started sniffing glue
at a tender age.  That's possible.  But, based on the marketing copy,
the entire idea looks bogus to me.

@_date: 2013-07-27 06:02:52
@_author: Robert J. Hansen 
@_subject: Fwd: Goldbug.sf.net - Secure Multi-Crypto-Messenger v0.1 released 
Anything's possible, but there's no evidence to support either of your
This is also getting increasingly off-topic for GnuPG-Users, since
GoldBug has virtually nothing in common with GnuPG (save for using
libgcrypt in some fashion).

@_date: 2013-07-27 06:17:05
@_author: Robert J. Hansen 
@_subject: Fwd: Goldbug.sf.net - Secure Multi-Crypto-Messenger v0.1 released 
Then it's even a less competent design.  A single server is a single
point of failure -- also a single point to issue subpoenas, a single
point to compromise, a single point to monitor or subvert.  Compare to,
say, GnuPG (he said, in a desperate attempt to make this on-topic),
where it's decentralized.  I don't have to trust any machine except my
desktop PC.  There's no single point of failure.
The comparison to IRC is ... weird.  Think about it: IRC never claimed
to be privacy-protecting software and the IRC design is in many ways
deeply at odds with privacy.  Using it as the basis for
privacy-protecting software is kind of surreal.
... I also note that about 30 minutes ago, a representative of the Chaos
Computer Club (CCC) posted a one-star review of GoldBug in which he said
that CCC had never heard of GoldBug, despite GoldBug claiming to be
associated with CCC.
About five minutes ago the GoldBug project admin disabled reviews and
the one-star review is no longer visible.
This kind of behavior on the part of the GoldBug project leaders is
deeply irresponsible.  This, by itself, should persuade people to not
use it.  Responsible programmers *welcome* criticism -- we don't
suppress it.

@_date: 2013-07-27 06:36:03
@_author: Robert J. Hansen 
@_subject: License violation: GoldBug 
Product: GoldBug Instant Messenger (
Version: 0.1.1567RC
Platform: Win32
GoldBug Instant Messenger distributes portions of libgcrypt as part of
its package, under the name "libspoton".  However, it claims to be fully
BSD licensed, which means it has relicensed libgcrypt in violation of
the original license agreement.
Further, although it distributes large portions of libgcrypt and
libgpg-error, there is no COPYING file associated with them, nor any
indication of what the end-user rights are with respect to these pieces
of software.
To be honest the whole thing looks like a nest of license conflicts from
a bunch of different people and groups: Qt, GnuPG and more.  I don't
know what the GnuPG developers want to do about this, but I figure y'all
deserve to know about it.

@_date: 2013-07-27 06:56:51
@_author: Robert J. Hansen 
@_subject: License violation: GoldBug 
I am helping people.  I am helping innocent people by telling them that,
in my experience as a professional software engineer with many years of
experience with security engineering, I believe GoldBug to be a
dangerous bit of charlatanry.
I really don't care if that opinion upsets you or anyone else associated
with GoldBug.

@_date: 2013-07-27 07:42:37
@_author: Robert J. Hansen 
@_subject: License violation: GoldBug 
The issue isn't "consideration".  The issue is that the libraries you
use in a program may influence how you can choose to license and/or
distribute the program.
After about ten minutes of looking through your code I've come to the
conclusion that your code cannot be legally distributed.  You distribute
both the OpenSSL libraries and the Qt libraries, but the OpenSSL
libraries are distributed under the OpenSSL license and the Qt libraries
are distributed under the GPL.  Those two licenses are incompatible: the
OpenSSL license has special requirements that the GPL expressly forbids.
See, e.g.,

@_date: 2013-07-27 13:22:42
@_author: Robert J. Hansen 
@_subject: License Comparison: Qt and OpenSSL 
So it is: the Qt license has changed since I last looked at it.  Good
for them!  The OpenSSL/GPL conflict is real and has prevented software
from being legally distributed in the past; I'm pleased to see that this
is OpenSSL/LGPL and there's no conflict.

@_date: 2013-06-03 01:26:22
@_author: Robert J. Hansen 
@_subject: certificat for a key pair 
Hash: SHA256
Speaking as another one of those people who took part in that
discussion: although the move to a pure-Javascript implementation has
done a lot to minimize this rule, I think John's "the 'same place' rule
is pretty much gone" needs a little explanation.
The number of different Linux distros, the number of different
customized Windows builds of Thunderbird, the number of different
customized OS X builds of Thunderbird... if you add up all these
variations you'll probably hit triple digits.  On top of that, each
distro may support several different versions of Thunderbird, and do
different optimizations to each.  We don't have the resources to test
Enigmail against every custom version of Thunderbird, and so we can't
make guarantees.  Moving to all-Javascript has made it far more likely
that Enigmail will work without a problem, but you're still taking
As John said, the 'same place' rule is pretty much gone.  But make sure
to remember the rest of what he said, which was that it's still a strong

@_date: 2013-06-08 20:40:07
@_author: Robert J. Hansen 
@_subject: Recommendations for handling (multiple) user IDs - personal and 
I entirely believe *you* might not be comfortable, but I think it's
already well-established that you're an edge case.  :)
People are free to be uncomfortable certifying user IDs that end in 'n',
in which case I'm completely out of luck.  People are free to be
uncomfortable signing user IDs for any old reason.  Unless there's
either a usability study that shows a particular pattern of behavior, or
widespread agreement that such a behavior is common in the field, I
think we ought be skeptical.
Nonsense.  They should be used where it makes sense to use them.  If it
doesn't make sense, they shouldn't be used.  We need no default
encouragement or discouragement policy, just a "please think about
whether it serves your needs" policy.

@_date: 2013-06-09 23:52:32
@_author: Robert J. Hansen 
@_subject: Recommendations for handling (multiple) user IDs - personal and 
Yes, I will repeat my mantra: unless you're looking at peer-reviewed
usability studies you don't really know anything -- you're going off
your accumulated anecdotal experience.  That's not to say you're wrong:
you might be completely correct.  It just means I can't take the claim
For what it's worth, the usability study I keep going back to agrees
with you.  The number one factor inhibiting adoption of encrypted email
is fear of public scorn, whether being seen as one of "those paranoid
people" or "I don't want people to wonder what I have to hide" or
what-have-you.  Inconvenience runs a close second.
That's why I'm so skeptical of all claims that if we just fix the UI
we'll solve the adoption problem.  The problem isn't UI.
This is not supported by the studies.  Many people who do not use crypto
openly acknowledge that maybe they "should", in a vague "I really should
eat more salads and less meat" sense.  However, they see the risks to
themselves as diffuse and distant, and the consequences mild.  If you're
a political campaign worker and you send an unencrypted email of your
contact list, and it gets intercepted by the other side, your screw-up
has done enormous damage to your candidate... but you, yourself, will
likely never face any real punishment for it.
Bruce Schneier has gone on the record as saying something to the effect
of, "Whenever I hear a business exec tell me they have mandatory
security training, I ask how many people they fired in the last year for
violating security policies.  If it's zero then they don't have
training, they have an hourlong all-hands meeting that no one will pay
attention to.  And really, why should they?"  (I'm paraphrasing him
quite loosely: I'm certain I've got the gist and spirit right, but I'm
certain the words are horribly wrong.)

@_date: 2013-06-10 21:05:56
@_author: Robert J. Hansen 
@_subject: Recommendations for handling (multiple) user IDs - personal and 
Interesting you should say that.  Apple's Certificate Manager
application (on Mac OS X) is an adventure in confusion: full-screen the
window and you'll easily get spammed with over two hundred different
widgets which can react to mouse clicks and menu presses.
Sure, but that's not the question.  The question is whether OpenPGP's
model could be, and whether such a simplification would improve
OpenPGP's adoption.  I think the answers are "no" and "not significantly."

@_date: 2013-06-11 00:23:20
@_author: Robert J. Hansen 
@_subject: Why OpenPGP is not wanted - stupid is in vogue right now 
I drive a Mustang GT with enough engine work to make it genuinely
dangerous to unprepared drivers.  When I was taking a couple of advanced
driving classes (because I don't want to be a hazard on the road behind
such a vehicle), one of my instructors -- a police driving instructor --
told me about a collision he recently saw with a tricked-out Mustang GT
like mine.
17-year-old drives an econobox to high school.  One day he gets to
borrow somebody else's tricked-out Mustang GT, and in order to impress
his friends with the noise of the engine, briefly floors the pedal.
He's expecting the engine to make a howling noise but of course he'll
take his foot off the pedal before the car goes out of control.
Except the car doesn't make a howling noise.  It howls *and lunges*, and
the G-forces were something this young man had never before experienced.
 The new experience left him cognitively paralyzed for a good part of a
second... with his foot still on the gas pedal.  At the last moment he
snapped out of it.  He thought he didn't have enough room to
successfully brake, so instead he whipped the wheel around --

@_date: 2013-06-15 23:46:00
@_author: Robert J. Hansen 
@_subject: Clarifying the GnuPG License 
I can confirm this.  According to my recollection, the argument was "all
right, so what *shouldn't* we bundle, then?"  Once you bundle GnuPG with
Enigmail you have to take responsibility for both packages.  And then
people will ask, "well, why don't you release your own Thunderbird for
[insert my OS here] that has Enigmail and GnuPG preconfigured?"
Some projects (GPGTools) pride themselves on doing just this, on
creating a single installer that drops everything onto your system in a
preconfigured state.  It works for them and we're happy it works for
them.  But given the perpetual shortage of developer time on Enigmail,
and the limited support staff... it doesn't make sense for us.
What a lot of people don't recognize: Enigmail is written by only one
guy -- Patrick Brunschwig.  He has a full-time job and hacks on Enigmail
in his spare time.  That places some severe constraints on the size of
the engineering we can do.

@_date: 2013-03-02 11:27:02
@_author: Robert J. Hansen 
@_subject: US banks that can send PGP/MIME e-mail 
At this point I'm giving up on this conversation.  It's pretty clear to
me that the thread is going nowhere.

@_date: 2013-03-30 23:08:04
@_author: Robert J. Hansen 
@_subject: How insecure is using /dev/random for entropy generation? 
By default, GnuPG uses RNGs that are as high-quality as the operating
system provides.  However, since there's no standard RNG across
operating systems, GnuPG has no standard RNG, either.  On Win32 GnuPG
uses the Win32 API and CryptGenRandom; on many UNIXes it uses
it's either /dev/random or CryptGenRandom.  :)
The best advice I can give you is "use whatever GnuPG uses by default
for your operating system."  It's the default for a reason: namely, it's
safe and known to work well.  :)

@_date: 2013-03-31 12:32:13
@_author: Robert J. Hansen 
@_subject: feedback on a gpg encryption/signing GUI frontend 
You might be surprised.  Although flash drives are getting larger and
larger, a 100MB set of dependencies is still going to have some
astonishing bits of fragility -- especially when running in a portable
environment, or on a non-UNIX OS.
Small is beautiful.

@_date: 2013-05-02 00:03:53
@_author: Robert J. Hansen 
@_subject: Confusion with signature digest type. 
First, thank you for a thorough reply.  I appreciate it a great deal.  I
think we may be using two different definitions of collision attack.
In the absence of a trusted timestamp, yes.  (Of course, then this
becomes a question of whether the trusted timestamp is susceptible to
attack.  I concede that this isn't a solution but just a reification one
level deeper.)
Are you sure that this is a collision attack?  It seems to me you've
created a preimage scenario here.  And if so, I stand by my statement of
"then I'm completely screwed on a dozen different fronts simultaneously
and my certificate is the least of my worries."  :)
(For those confused by the difference -- I'm certain Daniel isn't -- all
preimage attacks are collision attacks, but relatively few collision
attacks are preimage attacks.  Wikipedia defines a collision attack as
being able to "find two arbitrary different messages m1 and m2 such that
hash(m1) = hash(m2)."  The 'arbitrary' is important: you only care about
finding a collision, but you don't care one whit what that collision is
over.  By comparison, a preimage attack means finding a specific message
that hashes out to a specific value.  By manipulating the data I'm
signing, Eve is finding a specific message: by specifying "it must hash
out to the same as a signature he made in the past", Eve is specifying a
particular hash value.  This is why his scenario seems to me to be a
preimage attack in disguise, rather than a collision attack.)
(However, it is certainly possible that I've misunderstood his scenario.)
I continue to think that you're worrying about how you're going to turn
the coffeepot off as you're fleeing a house fire.  :)

@_date: 2013-05-02 00:48:44
@_author: Robert J. Hansen 
@_subject: Confusion with signature digest type. 
I think I can make a compelling argument this is a preimage attack and
not a collision attack, and I think I can sum it up in one sentence:
She cares what the collision is: it has to be a valid OpenPGP signature
I concur that this scenario is deeply troubling.  However, I think the
scenario as you've described it depends on a preimage attack and at that
point, as we've agreed, we're all screwed.
(As a comment for people who may be thinking Daniel and I are vehemently
disagreeing: sure, we don't agree, but I think we're far, far closer to
agreement than discord.)
Oh, please don't misunderstand me, I'm not encouraging the continued use
of SHA-1.  I'm simply not encouraging the wholesale migration to SHA256,
not at this point in time.  (Encouraging people to have a plan, though,
As a general rule, I've found the GnuPG developers to be quite capable
of coding sensible default behaviors.  I expect that Werner has been
thinking of these problems, and if-and-when Werner and g10 Code decide
to shift the default behaviors I'm certain it will be towards a stronger
hash algorithm.
In my experience, there is no such thing as a painless tradeoff.  The
instant you encourage someone to deviate from the defaults you open the
door to a flood of questions.  Some of them are quite reasonable ("why
should I use SHA256 when SHA512 is available?") and some show their
authors started sniffing glue at a tender age.  The only constant is
that the instant you tell someone to mess with the defaults, any and all
future problems they have are suddenly your fault and your
responsibility to solve.
I don't see the situation with SHA-1 is so dire that we need to jump the
gun on GnuPG's natural migration towards stronger hash algorithms.
Given that, and given that I don't want to field a ton of "I changed my
.gnupg file just the way you said and it doesn't work" type of
questions, well --
I concur that moving to better hash algorithms is the way to go.  I'm
unconvinced that the situation right now is so dire that we need to
leapfrog GnuPG's development process.

@_date: 2013-05-02 00:51:58
@_author: Robert J. Hansen 
@_subject: Confusion with signature digest type. 
Erf, did I really write that?
s/signature/User ID
The point being the User ID isn't allowed to be completely arbitrary:
there's a lot of structure to it.  I think that's what kicks this into a

@_date: 2013-05-22 08:06:41
@_author: Robert J. Hansen 
@_subject: [PATCH] Allow the user to specify AES256 as well as AES128. 
It isn't that we can't memorize passphrases with 128 bits of entropy:
it's that doing so is hard.  I have five separate passphrases with 128
bits of entropy (16 bytes from /dev/urandom piped through a Base64
encoder) which I'm required to use for various reasons.  Keeping track
of them all is difficult and the every-six-months password change policy
is enough to make me fume with anger, but... it's certainly *possible*.
Frustrating, though, definitely.

@_date: 2013-05-23 17:24:56
@_author: Robert J. Hansen 
@_subject: [OT] Why are you using the GPG / PGP keys? 
Rubber-hose cryptanalysis tips your target off to the fact their
communications have been cracked.  If I beat your passphrase out of you,
thirty seconds after I let you go you'll have alerted your friends and
generated a new keypair.
If I were breaking crypto, I would do everything I could to keep you
from discovering I was reading your traffic.  This would preclude such
Not even then.  "Plausible deniability" is a myth, an ephemera.  One
person may believe your denials; another may not.  Whether they believe
you will have much more to do with how honest you've been the rest of
the time than with the particulars of cryptography you're using.  The
jury isn't going to be technically skilled.  Rather than evaluate
technology in a dry and strictly logical sense, they're going to look at
your performance on the witness stand and, from that, decide whether to
believe your denials.
I'm not, save for package authentication on Linux-based systems.
This is something I wrote for PGP-Basics a few weeks ago.  It's bleak
and depressing, but I believe it's an accurate picture of where things
currently stand:
Email is dying and has been for years.  Ask a college student today what
he or she thinks of email and you'll get told it's an antiquated
technology that their parents insist on still using.  The mean age of
habitual users of email keeps rising.  When it comes to technology and
demographics, a shrinking userbase that keeps rising in mean age is
about as bad as it gets.
So, why is it shrinking?
The first generation of internet protocols -- email being one of them,
since email is considerably older than TCP/IP -- were devoted to
creating commodity infrastructure.  Everyone was connected to everyone
else, information would flow like a mighty river, the huddled masses
would be freed from the chains of corporate control of data, and so on.
It was a great dream.  The only problem was it was horrifically naive.
The exact same things led to the internet turning into an open sewer.  A
lot of people, when looking at the anarchic free-for-all of the internet
and what's come as a result of it, are of the opinion that if this is
progress they'd like to go back.  (I don't have any children, but if I
did I might be one of these techno-Luddites.  Reading the comments on
any YouTube video will likely convince you of the truth of John
Gabriel's Greater Internet F*ckwad Theory [1].)
I maintain that people are not flocking to walled gardens because
they're dumb, or ill-informed, or anything else like that.  They're
flocking to walled gardens because the garden-keepers are promising "we
will have none of that here."  Those who keep the garden can see you and
what you're doing, they can kick you out of the garden if you misbehave,
and it comes at the low, low price of ceding a great deal of social
control to them.
Some years ago someone asked me why I hated Apple so much.  I told them
it was because I couldn't get _Playboy_ on my iPhone.  It's not that I
subscribe to _Playboy_ or even want to subscribe to it, but I want to be
in control of what I read -- I don't want Apple to decide for me what
I'm allowed to read.
My friend was confused.  "So.  Between an unfiltered internet -- which
I've often heard you call an open and festering sewer -- and a highly
filtered internet that leaves a nice environment everyone can play in,
you're going to blame Apple's filters /not letting in crap you don't
even like in the first place?/"
Uh... hrm... I gotta go think about that, y'know.
The moral of the story: maybe the reason why so many people are
embracing privacy-destroying walled gardens isn't because they're
ignorant, but because they have made a rational choice based on what
they see as the downsides of privacy when applied to large groups of
people who all serve as each others' audiences.
Or, less literally but more poetically:
[1]

@_date: 2013-05-24 18:07:49
@_author: Robert J. Hansen 
@_subject: [OT] Why are you using the GPG / PGP keys? 
And at this point, you just became nasty enough to no longer be worth my
time.  I'll forgive a lot but I do draw a line.  That line gets drawn
where people accuse me of active malfeasance without a shred of
evidence.  That's the lowest form of ad hominem and I will not abide it.

@_date: 2013-05-26 12:37:42
@_author: Robert J. Hansen 
@_subject: [OT] Why are you using the GPG / PGP keys? 
In related news, you can still buy buggy whips:
Nobody is saying email will go away.  I've only said that email is seen
by the upcoming generation as an ancient technology that their parents
use, that the upcoming generation does not use email as a preferred
method of communication, and that this does not make me bullish on the
long-term prospects of email.
Will it still be around in ten years?  Sure.  But so will buggy whips.

@_date: 2013-05-27 11:32:37
@_author: Robert J. Hansen 
@_subject: [OT] Why are you using the GPG / PGP keys? 
Currently, one of the hot and trending ideas is to contract with
Facebook to provide corporate enclaves for such things.
Look at git as an example.  Ever since GitHub went up, a lot of
businesses have outsourced that service to them.  You think you're
accessing the company's git server, but in reality you're talking to a
particular walled-off portion of GitHub.
The same is being talked about for Facebook, Google+, and many other
social media platforms.  The idea is to provide a corporate enclave for
communication and forbid access to things like games, personal accounts,
and whatnot.
Businesses don't generally like email.  Between spam and security
issues, email has never really lived up to the utopian vision we had for
it in the Seventies.  It used to be that businesses ran their own email
services, but now many outsource it to Google or Microsoft in order to
enjoy lower operational costs.  If they can get lower operational costs
by moving to a Facebook-like platform, they'll do it in a heartbeat.

@_date: 2013-11-01 00:21:10
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
Huh -- fascinating!  Thank you for this new data point, dkg!

@_date: 2013-11-01 11:47:56
@_author: Robert J. Hansen 
@_subject: gpgsm and expired certificates 
This is why grown-ups don't believe in guilt by association.
To take an example: the graduate students at the University of Iowa  who teach undergraduate courses on classical French literature are  University employees. (Unionized ones at that: United  Electicalworkers/Committee to Organize Graduate Students, *represent*!  [1])  As University employees, they are officially also government  employees, since the University is funded by the State.
Do you really think a bunch of graduate students obsessing over _La  Chanson du Roland_ are "just as nefarious as the NSA"?
If you do, then I think your paranoia is so out of hand you really  ought consider seeking professional help.  And no, I'm not kidding.
If you don't, then let's dial back the rhetoric.  Governments are  *big* *big* things with lots of employees, and they deserve better  treatment than this.
[1] Yes, I was a card-carrying union man and served as a union  officer.  Try not to keel over from the shock.  ;)

@_date: 2013-11-01 12:25:30
@_author: Robert J. Hansen 
@_subject: gpgsm and expired certificates 
My previous email was pretty dry and impersonal.  This one is very personal.
My current job is in software forensics -- discovering new ways to  pull information off electronic media.  Most of the people funding  research in this area are connected to the government somehow.  I  would describe what a typical week for me entails but I'm pretty sure  I would terrify and traumatize a good portion of the list.  (A great  week for me is one in which I don't have to see, hear, or even think  about, the three words, "Daddy, no, stop!")  But since some of my R&D  funding comes from the government, I'm just as nefarious as the NSA.
John Moore III, who hasn't been seen on this list in ages, was always  quite open about the fact he served in the Marine Corps attached to a  signals intelligence unit at Fort Meade.  I'll let you do the math and  figure out what three letter agency at Fort Meade does signals  intelligence.  Apparently John's contributions to the GnuPG community  mean nothing, because he's just as nefarious as the NSA.
Werner has taken money from the German government to do crypto-related  software development.  Apparently Werner is just as nefarious as the  There are a lot of people on this list who have some kind of  connection to the government.  Many of them -- us -- are deeply  concerned about civil liberties, surveillance, and the future of  liberty.  We are not your enemies and we do not deserve to be tarred  with that brush.
You owe all of us an apology.

@_date: 2013-11-02 10:36:27
@_author: Robert J. Hansen 
@_subject: gpgsm and expired certificates 
Thank you for this.  (Seriously.)
There's an American movie that probably hasn't been seen much in Europe.
 _High Noon_, starring Gary Cooper, which may be the finest Western ever
made.  In a nutshell, the Frank Miller Gang comes to town intent on
bloodshed and violence, and to protect the town the retired police
officer, Marshal Will Kane, puts on the tin star once more.  The Frank
Miller Gang does something violent and Kane gets in the way -- the gang
retaliates and does something else violent, and Kane gets in the way and
stops that, too.
After a while the townsfolk, who were begging Marshal Kane to come out
of retirement at the beginning of the movie, are screaming their outrage
at him.  "If you'd just quit, the Frank Miller Gang would leave us
alone!  Can't you see that your meddling is just making them angry and
making the problems worse?"
In a climactic showdown Marshal Kane shatters the Miller Gang.  All the
townsfolk, who had begged him to save them and then screamed at him that
he was the problem, come around to praise him for his courage and valor.
 Marshal Kane looks them over in disgust, then tears off his badge,
throws it in the dirt, and rides off into the sunset with his
girlfriend.  The townspeople have finally done what the Frank Miller
Gang couldn't do: they've made a good and decent policeman stop caring
about his town.
I can't help but think, as I see the tenor of the discussion about the
NSA, that there are probably thousands of good and decent people in that
agency who are concerned with following the law and respecting civil
liberties -- and they probably feel an awful lot like Marshal Kane right
now, wondering whether it's even worth it.
They are not practicing guilt by suspicion.  They are practicing, "hey,
let's collect as much information as possible on this crime so that we
can find the truly guilty person."
Police do not determine guilt.  Courts determine guilt.  Police are in
the business of collecting information.  In a very real sense, police
are a domestic intelligence agency.

@_date: 2013-11-04 14:35:41
@_author: Robert J. Hansen 
@_subject: UK Guardian newspaper publishes USA NSA papers 
That's more urban myth than reality.  Reality is hard to model.  An  isolated village in a remote area of Africa might have a very hard  time connecting to London in six hops, but the instant one villager  gets a cell phone suddenly they're on the phone jawing with 10 Downing  Street.  It's hard to give simple "six hops is about it, yes" answers:  what we have to talk about instead is the degree of connectivity  within a network.  Given a network with a certain set of nodes and a  certain set of connections between nodes, how many hops will it take  to traverse the network?  This is a function of both how many nodes  there are, and the particular connections they have.
When the network forms a bunch of neighborhoods and there are few if  any long-distance connections, the hop count quickly goes out of  control.  As a historical example, look at the Black Death.  Despite  the worldwide conditions being virtually ideal for the various forms  of plague (principally bubonic), it still took many years for the  Black Death to spread from China to Europe.  At that time in history  the overwhelming majority of people not only had never traveled more  than 30km from their homes, they didn't even know someone who had  traveled more than 30km from their homes.  The Black Death was  condemned to spread 30km at a time -- ravaging a 'neighborhood' of the  network and then moving on.
Today, though, many of us have traveled internationally and virtually  all of us are connected to someone who has traveled  intercontinentally.  (Including all of you.  I've traveled to Europe  multiple times and you know me, so even if you've never left your  small rural village you're still connected to someone who has traveled  a long distance.)  It turns out that if you have even a small number  of long-distance connections, neighborhoods get bridged *very* quickly.
Let's connect me to Vladimir Putin as an example.  I'm looking for a  good long-distance hop that will get me most of the way to Russia.  I  attended undergrad with a Russian woman named Yelena (last name  omitted for her privacy), whose great-uncle sat on Gorbachev's  Politburo (his name omitted again for her privacy).  He, in turn, is  *scary*-well connected among the political elite.  If he doesn't have  a certain former KGB counterintelligence agent on speed-dial, I'll eat  my hat.  So:
     Rob --> Yelena --> Y's Great-Uncle --> Vladimir Putin
Three hops.  It's worth asking: if I didn't have that long-distance  hop, could I still make it to Putin?
Sure.  I just need a different hop.  It turns out my co-worker Greg,  who was born and raised in Moscow, knew Yelena's great-uncle (and  hated him something fierce, but that's beside the point).  So now it's:
     Rob --> Greg --> Y's Great-Uncle --> Vladimir Putin
Okay, so the real 'focus' node is Yelena's great-uncle.  Let's get rid  of that.  And let's do something weird, like require that the  connection be made through official government contacts and  coordinated through the Department of State.  Well, my father is a  federal judge who has professional and personal connections with  Senator Tom Harkin (D-IA).  Senator Harkin happens to be a close  friend of John Kerry, the United States Secretary of State.  Secretary  Kerry in turn has Vladimir Putin on speed-dial.  So there's...
     Rob --> Rob's dad --> Harkin --> Kerry --> Putin
It's not hard to come up with ways I'm connected to Vladimir Putin.   Try to connect yourself to Putin: seriously, it's a fun game.  :)
Hop counts will be lowest where each node in the network is connected  to a modestly-large neighborhood, and where each of those neighbors  has a good chance of having one or more long-distance connections.  It  used to be that a neighborhood consisted of no more than a couple of  hundred people, none of whom had long-distance connections of their  own.  This would be the case for a medieval village, for instance.   Nowadays we may have *thousands* of connections, and each connection  has an extremely good chance of having one or more long-distance  The combination of large neighborhoods and long-distance connections  is called the "Small World Effect," and it has a lot of academic  literature backing it.  You may want to check out the Wikipedia page  for more information:

@_date: 2013-11-04 14:40:06
@_author: Robert J. Hansen 
@_subject: UK Guardian newspaper publishes USA NSA papers 
Sure, but then again you're trying to hit people with *extremely*  large networks, and whose first-order networks are themselves  *extremely* well-connected.  Even the exotic ones like Ronald Coase --  he co-authored a ton of papers and attended a lot of conferences and  advised a lot of Ph.D. candidates and taught a lot of courses.
If you can map out a line to my great-uncle Ormo Rasmussen in three  hops without using me as a link, I'll be impressed.  ;)

@_date: 2013-11-06 14:17:49
@_author: Robert J. Hansen 
@_subject: BitMail.sf.net v 0.6 - Secure Encrypting Email Client 
I would suggest figuring out very precisely what you intend by  "secure."  Once you have that definition, look at the BitMail project  and see if their notion of "secure" has a lot in common with your  notion.  If they do, then it's time to take a look at the design of  BitMail and its implementation.  Look for areas where they do not  closely follow their definition of 'security'.  Every nontrivial  program has some of these areas.
Once you have a good idea of how BitMail works, then it will be time  to learn from their mistakes.  In the process you will undoubtedly  make mistakes of your own.  Don't be disheartened: the only hackers  who have not made completely humiliating errors are ones who have not  been programming long.  The trick is to never make the same one twice.    :)

@_date: 2013-11-08 11:09:10
@_author: Robert J. Hansen 
@_subject: gpgsm and expired certificates 
(Before I begin I should say I agree with Mark -- this is commentary,  not disagreement.)
A detail oft-overlooked is that the question isn't whether the  *sender* is part of the 0.1%; the question is whether the *recipient*  is part of the 0.1%.  If I use a self-signed S/MIME cert, will my  recipient be savvy enough to understand the risks and take appropriate  I think 0.1% is a reasonable approximation: of all Thunderbird users,  maybe one in a thousand has the skill necessary to safely and  responsibly use a self-signed S/MIME cert, or to safely and  responsibly check someone else's usage of a self-signed S/MIME cert.   So one in a thousand senders, multiplied by one in a thousand  What I'm getting at here is that this isn't just a case of "99.9% of  users will just hit 'yes', which is arguably a Bad Thing."  It's also  a case of the user base for this being so small as to be  indistinguishable from statistical noise.
Well, 'should' is a pretty strong word.  So long as someone  understands the risks involved in letting Mozilla define your list of  trusted CAs rather than taking individual responsibility yourself,  that's really all we can ask for.  I do agree, though, that the  default list of trusted CAs is eye-poppingly large.

@_date: 2013-11-09 20:46:23
@_author: Robert J. Hansen 
@_subject: Threema. 
Looking over their site briefly I was unable to find a link for source code. As a result, I think very little of it. I don't think it's wise to trust unknown third-party binaries that don't provide source.

@_date: 2013-11-15 08:53:07
@_author: Robert J. Hansen 
@_subject: [tor-talk] BitMail.sf.net v 0.6 - Secure Encrypting Email Client 
FBI, actually, in counterintelligence.  No, wait, whoops, wrong Robert  Hanssen.  Sorry, I get confused about myself sometimes.
All kidding aside, we don't need to cast aspersions on the motives of  people who post here.  It is far, far more likely that someone is  innocently unwise about something than that someone is being  deliberately malicious.
And this is, frankly, just paranoia.  New and unknown yet seemingly  polished tools have *always* been dropped on the computing community.   Always.  I remember a really neatly polished Mac OS file encryption  program that conveniently put the decryption key as plaintext in the  first few bytes of the output.
Making a beautiful-looking user interface is easy.  Making rock-solid  crypto is hard.  Those two facts by themselves mean there will always  be an abundance of beautiful-looking bad systems, and always a  shortage of primitive-looking solid systems.
Let's remember that this list is a community.  Let's not malign other  people's motives, and let's keep a sense of perspective about things,  okay?  :)

@_date: 2013-11-15 09:06:22
@_author: Robert J. Hansen 
@_subject: [tor-talk] BitMail.sf.net v 0.6 - Secure Encrypting Email Client 
For a service that's "out of vogue" they still host an awful lot of  Free Software, and for that I think perhaps we should be a bit  thankful.  Their bundling is distasteful, yes, but it's hardly the end  of the world given they've only done it with the explicit permission  of the projects involved.  Let's keep a sense of perspective and  remember this is GnuPG-Users, not a Sourceforge list.
Whenever I hear someone say what another developer 'should' do, I  always mentally substitute 'I want this developer to...' instead.   That seems quite a lot more honest.
That said, there are two major problems with this demand:
     * The 'Robert' who asked about BitMail never
       claimed to be the author and may not have
       the legal right to host the binaries
     * GitHub hasn't allowed projects to host
       binary files in well over a year.
So yes, there are good legal and technical reasons why your demand  cannot be complied with.
Goes against current US-CERT guidance, which deprecates MD5 for all  purposes.  The newer SHAs are the way to go.  Further, getting two  computers to generate the exact same binary code from the exact same  source code is a surprisingly difficult challenge.  It requires a  perfect match of everything from compiler versions to C library  versions right down to identical *clocks* -- because often, compilers  will incorporate timestamps into the output.
Doing checksum validation of source code is feasible.  Of binary code,  not really.

@_date: 2013-11-18 00:21:14
@_author: Robert J. Hansen 
@_subject: [tor-talk] BitMail.sf.net v 0.6 - Secure Encrypting Email Client 
In fact, it goes even deeper than that: many architectures allow their
processor to dynamically reorganize and/or modify the code being
executed.  (Out-of-order execution is one example of this.)  So even if
you're running two binaries that are completely identical, the CPU may
process them quite differently depending on the state of the system.
This has some extraordinary implications for those who are trying to
guarantee their CPU is operating exactly the same as another CPU!
Every couple of years I look at this problem, read a couple of papers,
and walk away muttering about now is a great time to start drinking

@_date: 2013-11-18 06:30:47
@_author: Robert J. Hansen 
@_subject: [tor-talk] BitMail.sf.net v 0.6 - Secure Encrypting Email Client 
Well, yes and no.  Provably-correct software is still a very hot thing
in engineering, particularly in life-critical applications like avionics
or nuclear reactor control software.  The Ada programming language has a
couple of variants -- SPARK and its descendants -- that support provable
The problem with provably correct code is that it only proves the code
correctly implements the specification.  It doesn't prove the
specification completely encapsulates the problem...

@_date: 2013-11-18 10:53:18
@_author: Robert J. Hansen 
@_subject: AES attack calculations (money and time) 
No, people ask how difficult it is to brute-force crypto.  That's a  very narrow question and can be answered with great precision.  When  it comes to the fuzzier question of how secure crypto is, I, like most  people, hem and haw and start things off by saying, "Well, it really  kinda depends, you know?"
Why?  There's no real contradiction here.
The theoretical lower limit for brute-forcing a 128-bit cipher  involves on the order of 10**17 joules of energy (100 megatons).   That's not particularly high, although if you were to do it enough  times you would significantly accelerate global climate change.
His back-of-the-envelope calculation for cryptanalysis (not  brute-forcing!) says a sustained 4 terawatts (10**12 joules per  second, sustained for a long period) is enough.  If you sustain  terawatts for a long period you're going to significantly accelerate  global climate change.  (Note: one terawatt held for 30 seconds = 100  Either way, the power requirements become absurd.  As he says, "Energy  seems to be the main bottleneck."  I haven't phrased it that way:  usually I phrase things more like, "Extremely large amounts of energy  are required, but those extremely large amounts of energy have side  effects we really don't want to experience."
What do you mean by 'correct'?  As far as a back of the envelope  calculation goes it seems reasonable enough, but I'm not sure I'd like  to wager money on it being correct in each detail.
4 terawatts multiplied by one year equals 35 billion megawatt-hours.   Per Wikipedia  ( nuclear  power costs $60 per megawatt-hour.  That's $2.1 trillion just to run  the nuclear power plants to power this hypothetical computer.  That's  a jaw-dropping number.
They're talking about doing sophisticated mathematical analysis of the  system in order to recover the key.  This isn't a brute-force setup.

@_date: 2013-11-18 12:35:24
@_author: Robert J. Hansen 
@_subject: article about Air Gapped OpenPGP Key 
The airgap networks I've seen have run in separate rooms from the  regular network and use a different kind of networking hardware in  order to make cross-contamination impossible.  For instance, if the  network uses gigabit Ethernet then the airgap will use 10base2 coaxial  cable, or some other incompatible networking system.  (This may be the  only remaining legitimate use for 10base2...)
If your airgap system is network-compatible with the regular system,  then you don't have an airgap.  What you have instead is something  that looks like an airgap until somebody has a five-second braino  while hooking up network cables, and you don't discover for two weeks  afterwards that your airgap was breached.

@_date: 2013-11-19 01:07:17
@_author: Robert J. Hansen 
@_subject: article about Air Gapped OpenPGP Key 
It comes into play more when entrusting others.  If I give my lawyer a
copy of my certificate and passphrase with instructions of "revoke these
when I die," I'm giving my lawyer the power to impersonate me should my
lawyer suddenly go rogue.  If I give my lawyer a revocation certificate,
I'm exposed to far less risk.
This can't be answered without knowing about a specific threat that the
person is trying to mitigate.  I think that most models will find this
to be a negligible risk.
(This next quote belongs to adrelanos, not Hauke.)
First, using the royal "we" is... well, royal.  "We" is appropriate when
writing a committee report or if the speaker is a sitting monarch.
Otherwise, "I" should be used.
Second, why is a secure wipe necessary?  The only information that's
recoverable is public metadata.  The key material itself is encrypted.
If people doubt me on this, I am quite happy to post my private key to
the list.  So long as you've got a good passphrase on your certificate,
you can post your private key in the _New York Times_.  I'm unaware of
any model in which a private key needs to be securely scrubbed, unless
you're not putting a strong passphrase on the certificate.
Even then, scrubbing data is usually a sign you've misunderstood the
problem you're trying to solve.  If you're concerned about sensitive
data lurking on your hard drive the solution isn't to scrub the drive,
it's to use an encrypted filesystem.

@_date: 2013-11-19 14:50:20
@_author: Robert J. Hansen 
@_subject: article about Air Gapped OpenPGP Key 
Most encrypted drive software doesn't actually work the way people  seem to think they work.  The drive is encrypted with a random nonce.   This nonce is written to disk in an encrypted format.  When you enter  a passphrase to unlock the drive, the encrypted random nonce is read  in and decrypted using the passphrase.  The newly-recovered random  nonce is then used to do all further crypto operations.  To put the  data forever beyond recovery, you generate a new nonce, encrypt it  with the same passphrase, and write it over the old nonce.  If someone  demands your cryptographic key you can honestly and genuinely give it  up without any fear of your old data being compromised.  The  investigator will be able to verify that you've complied with the  court's order, and the investigator will also be able to verify that  you never knew the original nonce.
"This drive was originally encrypted with a random nonce which the  defendant never knew.  The defendant cannot be compelled to produce  information the defendant never possessed.  This random nonce is  irretrievably gone.  The defendant *can* be compelled to produce the  key used to encrypt that random nonce, and the defendant seems to have  complied with that order -- but the random nonce itself is gone, and  with it, any hope of recovering the data on the encrypted drive."
I cannot think of a single use case for scrubbing plaintext storage  devices.  In every use case I can come up with, the user would be  better served by using an encrypted storage device.  That doesn't mean  no such use case exists, mind you -- just that I can't think of one.

@_date: 2013-11-19 19:31:02
@_author: Robert J. Hansen 
@_subject: article about Air Gapped OpenPGP Key 
Depends on when you did it and why.  Many businesses have document
retention policies (crafted with the assistance of counsel) that specify
old documents are to be put beyond recovery, and scrapping a crypto key
is generally seen as more cost-effective than shipping the drive off to
be shredded.  IronMountain charges $X per drive, but wiping a crypto key
is effectively free.
If you do this in response to an investigation then yes, you're likely
going to make the judge very unhappy.  If you do this as part of normal
business practices that were devised with the assistance of counsel,
you're likely to fare much better.

@_date: 2013-11-20 13:55:18
@_author: Robert J. Hansen 
@_subject: Theoretical and maybe stupid questions about security 
No one with two brain cells to rub together will try brute-forcing a  strong passphrase.  No one.  Assuming your passphrase is strong you  could publish your secret key in the _New York Times_ and still be  completely confident in the security of your communications.
The passphrase isn't stored as a hash, so much as the passphrase is  hashed (many, many times -- with salt) and the output is used to  attempt to decrypt the secret key.  The passphrase is never stored,  though, either in plaintext or in hashed form.

@_date: 2013-11-21 20:20:10
@_author: Robert J. Hansen 
@_subject: article about Air Gapped OpenPGP Key 
Depends on the meaning of "contempt of court" in your jurisdiction and
what your local rules are with respect to document discovery.
We're getting pretty far afield of email crypto.  Let's try and bring it
back on topic.  :)

@_date: 2013-10-10 21:35:49
@_author: Robert J. Hansen 
@_subject: First steps with GPG, am I off to a good start? 
Leave off the 'expert' flag and just use the defaults.  Seriously, the
defaults are reasonable and don't need tweaking.  :)

@_date: 2013-10-10 23:32:20
@_author: Robert J. Hansen 
@_subject: First steps with GPG, am I off to a good start? 
... Or, you know, you could just stick with the defaults.  :)
IMO, new users should be encouraged to use the defaults.  This gets them
using GnuPG and developing their skills with it.  If, once they develop
their skills, they decide that their needs are not well-met by the
defaults they can always create a new certificate that's fine-tuned how
they like.
GnuPG already has a learning curve like the Matterhorn.  Let's give some
thought to that before we start advising new users to tweak every knob
and dial on GnuPG's controls.  :)

@_date: 2013-10-11 23:59:55
@_author: Robert J. Hansen 
@_subject: First steps with GPG, am I off to a good start? 
(Please don't read this as disagreement with Doug.  Rather violent
agreement, in fact...)
I have told this story several times on-list: apparently it's time to
tell it again.
Some years ago during grad school, my colleague Peter Likarish came up
with an interesting phishing-detection technology.  He turned it into a
Firefox plugin.  Whenever the engine thought you were on a phishing site
it would put a small red banner over the top of the page with text
reading, "This may be a phishing site."
During human trials he got a number of "real users" to experiment with
his plugin in a controlled laboratory environment.  Amazingly, despite
his detection engine working perfectly not one single user managed to
avoid giving data to a (simulated) phishing site.
Peter figured the problem was the banner was too unobtrusive.  In
version 2 the banner would start off as a thin ribbon over the top of
the page and would gradually grow until it took up about a third of the
page.  If the user clicked a "Dismiss" button the ribbon would vanish.
In the next round of human trials the clear majority of users clicked
"Dismiss", and yet not one single user managed to avoid giving data to a
simulated phishing site.
Finally, Peter did one-on-one guided walkthroughs of the plugin.  He
would sit there beside a user, watch, and ask questions directly as the
user was doing actions.  The first time someone clicked "Dismiss," he
asked, "So what did that banner say?"
"I dunno," the user answered with a shrug.  "I don't read Flash ads."
There are two types of people on this list: the ones who know that on
some level they're Real Users just like everyone else, and the ones who
believe they're part of some anointed geek elite that's immune to such
pedestrian mistakes and thereby have just made a Real User mistake.
We literally cannot make GnuPG simple enough.  The more we use
agreed-upon default behavior, the fewer opportunities there are for us
to go all Real User on ourselves.
My only objection here is the use of the word 'average'.
More than that: if the enforcement of *your* security model ("I've got
an expiration date in order to...") depends on *other people*
cooperating with it, then you don't have a security mechanism at all.
I have a security model: my email should not be read in transit.  I'm
cheerfully depending on all parties interested in my email to understand
this and to respect my policy and help me enforce it by cooperating and
voluntarily choosing to not read my email.
Sounds kind of silly, no?
My key expirations should be respected.  I'm cheerfully depending on all
parties who use my keys to understand this and to respect my policy and
help me enforce it by cooperating and voluntarily choosing to refresh my
key at periodic intervals.
It's the same thing, and the same level of silliness.
And I am enough of an egotistical S.O.B. to love hearing this.  :)

@_date: 2013-10-12 00:04:28
@_author: Robert J. Hansen 
@_subject: First steps with GPG, am I off to a good start? 
I've been refreshing my keyrings via cronjobs since 1996.  One single
shellcode statement and bang, at 0400 each morning my keyring gets
updated, and...
... well, wait.  Hmm.  Guess since it uses a shell statement I can't
call it 'straightforward,' since it requires a level of skill beyond
that possessed by the vast majority of the populace.
Just like using Debian, period, requires a level of skill beyond that
possessed by the vast majority of the populace.
I'm glad you love parcimonie and I'm glad that it fits your needs, but
let's not confuse "it is aimed at my skill level and I do not find it
challenging to use" with "it is a straightforward tool for everyday
users".  :)

@_date: 2013-10-16 11:10:51
@_author: Robert J. Hansen 
@_subject: trust your corporation for keyowner identification? 
This is the wrong question, really.
HR is pretty good about verifying identity documents.  HR gets  specialized training in what proper identity documents look like and  HR typically has ways to check those documents with the government.   Even small firms do a lot of identity verification -- in the United  States you can't legally work without presenting your employer with a  passport (or, alternately, a driver's license and Social Security  card).  Not even a McDonald's or a 7-11 will let you work there  without providing them with those documents.
But HR is probably really bad about understanding the nuances of the  Web of Trust, what it means to make a certification, whether a  certification should be made at all, what level of certification  should be made, and so forth.  The limiting factor here is  technological skill, not document verification.
That said, I've worked for two companies that did this and did it  quite competently.
I haven't kept up with PGP since they got bought out by Symantec, but  I know that from at least '95 to '05 they would issue corporate  signatures to employee certificates, if the employee requested it.   They did this so that other users could be confident in who was really  an employee of PGP Security and who wasn't.

@_date: 2013-10-17 12:26:46
@_author: Robert J. Hansen 
@_subject: Differences in --list-packets between 1.4 and 2.0 
Under GnuPG 2.0, calling --list-packets on a GnuPG keyring file will  list key IDs as part of the public key packets.
Under GnuPG 1.4, the key ID information is suppressed.
Is there any way to make GnuPG 1.4 behave like 2.0 in this regard?

@_date: 2013-10-17 13:54:54
@_author: Robert J. Hansen 
@_subject: trust your corporation for keyowner identification? 
Under this scenario, the entire thing is dangerously bogus.
When I sign a certificate, I am sending a message: "I am vouching for  the identity of X."  Under your scenario, I'm no longer vouching for  the identity of X.  I would instead be saying, "Someone else who is  not listed on this signature has vouched for the identity of X.  I am  signing this without any direct personal knowledge of X's identity."
If you're vouching for X's identity, you need to take positive steps  to verify X's identity.  If someone else is vouching for X's identity,  then let them sign X's certificate.  Why should you get involved  without doing your own positive verification?

@_date: 2013-10-18 08:54:03
@_author: Robert J. Hansen 
@_subject: trust your corporation for keyowner identification? 
Forgive a nonanswer here, but this isn't a question.  You're positing a
particular set of facts to be in existence.  Okay, fine, let's assume
those facts.  What's the question?

@_date: 2013-10-22 18:01:46
@_author: Robert J. Hansen 
@_subject: trust your corporation for keyowner identification? 
Last time I walked into a courthouse to speak with a judge the marshal
asked for my driver's license -- he checked the photograph to make sure
it was me, held it up to the light to check for a hologram, then checked
the logbook to see if I was an expected visitor.  Once he saw my name
listed in the logbook he gave my driver's license back and buzzed me in.
 As far as the U.S. Marshal was concerned, my identity had been proven
to a sufficient degree.  He certainly didn't conduct a background check
on me.
(My father and cousin are both judges, if you're wondering why I visit
courthouses so often.)
That phrase, "to a sufficient degree," is important.  You cannot ever
verify someone's identity 100%, not even with DNA testing -- it's always
possible they have an identical twin, always possible the lab work was
sloppy and done in error, etc.  What you want to do instead is have a
certain level of confidence in someone's identity.
For some people, that level of confidence is "this person says they are
so-and-so."  For other people, that level of confidence is "this person
has a passport saying they are so-and-so."
OpenPGP is completely silent about what level of confidence you should
have for a certification.  It only says that when you sign a
certificate, you are making an assertion about identity: that, to a
level exceeding your threshold of certainty, such-and-such an identifier
is an accurate descriptor for the individual or agency who controls the
private part of a certificate.

@_date: 2013-10-24 19:46:20
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
Mostly zealotry.  According to NIST, RSA-2048 is expected to be secure
for about the next 25 years.

@_date: 2013-10-26 10:30:22
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
*To you* they're severely reduced.  Please don't presume to make ex
cathedra statements for the rest of the world.  While I agree that NIST
is certainly not looking good, I'm not going to go so far as to say
their authority or credibility is "severely reduced."
Further, this statement of NIST's is backed by RSA Data Security, which
has issued recommendations that are in much the same line, and various
other consortiums as well.
Not even intelligence agencies expect to keep things secret past 25
years.  If you're doing something that must remain secret for more than
25 years, I would recommend thinking about whether you should be doing
those things in the first place.

@_date: 2013-10-26 10:36:14
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
CAC is used for encrypted email, at least according to Wikipedia.  Not
having a CAC myself, I'm not in a position to know further.  If people
are interested, I'll ask a couple of CAC-carrying friends and see what
they say.

@_date: 2013-10-26 18:29:26
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian [doc patch] 
Hi!  I'm the quasi-official FAQ maintainer.  You can read the current
text of the FAQ at:
Excerpting from it:
Although we appreciate your patch for the FAQ, it would probably be
better to submit a patch against the in-development FAQ as opposed to
the old one, which is no longer being maintained.  :)

@_date: 2013-10-26 19:09:08
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
The name of the game is economics.  How much is the secret worth?  If
it's worth $50,000 of computer equipment and cryptanalysis, then it's
also worth a $50,000 bribe, a $50,000 payment to a professional thief to
break in and plant keyloggers, $50,000 in hookers and blow, $50,000 of...
Note that I'm not disagreeing with Christoph.  I'm only pointing out the
world is a big place and there are a *lot* of ways to acquire secrets,
not just "break the crypto" and "break the kneecap".

@_date: 2013-10-27 02:42:31
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
Hard to say.  Quite possibly, yes, they'd tell the entire world.  Take
AES as an example: if AES had a serious flaw that could be exploited to
recover ciphertext, it's quite possible the people who discovered it
would decide the risk to the world's financial systems from keeping it
secret far outweighed any benefit that might be had.
As a real-world example, look at the history of SHA.  The original SHA
(just called SHA, although sometimes [inaccurately] called SHA-0) was
designed by the NSA and published as a government standard in 1993.  In
1995 the NSA announced there were flaws in SHA and issued a new
standard, SHA-1, that addressed these problems.  The NSA never went
public with the precise vulnerability in SHA that caused them to develop
and release SHA-1, but they were quite open and public about SHA being
insecure and needing to be replaced as soon as possible.

@_date: 2013-10-27 13:13:29
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
It's simpler to implement.  That's a nontrivial benefit.

@_date: 2013-10-27 13:17:18
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
If you can compute discrete logs in a finite field, then you can factor,
yes, and the reverse is not guaranteed to be true.
However, Elgamal is not necessarily the same as the discrete log
problem, much in the same way that RSA is probably not the same as the
integer factorization problem.

@_date: 2013-10-27 13:21:12
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
It's amazing what you can discover by checking Wikipedia.
SHA was deeply flawed.  The civilian cryptanalytic community broke SHA
wide open.  We don't know if the flaws the civilian cryptanalytic
community discovered are the same ones as what the NSA discovered that
caused them to urge SHA be replaced with SHA-1; however, SHA being a
flawed algorithm is beyond question.
In the future, let's please not engage in paranoid speculation without
doing a little research first.  There is already plenty enough fear,
uncertainty and doubt in the air regarding the NSA without us
contributing needlessly to it.

@_date: 2013-10-27 13:27:26
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
Yes and no.  The mistake people make when discussing digital signatures
is to treat them as a purely mathematical exercise rather than as
something that exists within a legal framework.
Let's say that tomorrow I lose my passphrase and make a new keypair.
Then in 25 years someone approaches me with a signed OpenPGP message
dated Christmas 2013, saying "I agree to pay you one million dollars at
Christmas 2038."  I scream it's a forgery, they scream it's valid, we go
to trial.
Who do you think the judge will believe -- that this message, which
nobody can produce any evidence existed prior to 2038, is real?  Or that
it's some clever shenanigans made possible by newly-developed technology
which made my old keypair vulnerable?
Just because a digital signature can be forged *mathematically* is no
guarantee the signature can be forged *in actuality*.

@_date: 2013-10-27 13:36:25
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
In the embedded space it's still quite common to see 8-bit processors
used as PICs.  We're just beginning to make the migration to 32-bit
processors, but it's going to be a long, long transition: there's a huge
installed base that will only get replaced when old chips fry and burn out.
Consumer-grade hardware is a decadent Garden of Eden.  However, the tiny
little processor that monitors chemical levels at your local water
treatment plant is going to be embarrassingly low-powered.
Given GnuPG aims to support even some of those bits of hardware (and I'm
glad of it -- some of those installations need confidentiality,
integrity and assurance even more than I do!), I'm happy the GnuPG
defaults are the way they are.
Just once, I'd love to hear someone say "Kelsey advises" or "Boneh
thinks" or "Ferguson has opined that..."
The world of computer security is a lot larger than Bruce Schneier.
He's good, absolutely, but really.  Open your eyes a little and read
more of the literature.  There's a ton of good stuff out there, and a
lot of it disagrees with Bruce.

@_date: 2013-10-27 18:00:00
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
Yes; because past 3072 bits it's time to go to something other than RSA.
Several respectable organizations (not only NIST) have done their best
to come up with equivalencies between symmetric keys and asymmetric
keys.  They all seem to converge on the following:
A 1024-bit RSA key is equivalent to an 80-bit symmetric key
A 2048-bit RSA key is equivalent to a 112-bit symmetric key
A 3072-bit RSA key is equivalent to a 128-bit symmetric key
A 15,000-bit RSA key is equivalent to a 256-bit symmetric key
Each additional bit in an RSA key yields less resistance to
cryptanalysis than the one before it.  Moving from 1024 bits to 2048
bits gives you an additional 32 bits of entropy; moving from 2048 to
3072 only gives 16 bits of entropy.
If someone is able to successfully factor a 3072-bit key, they're quite
probably also going to be able to successfully factor a 4096-bit key.
PGP 5.0, way back in the day, introduced 4096 bits as the cap on RSA key
lengths.  This was before we'd put asymmetric and symmetric key lengths
on a firm mathematical basis.  Nowadays, there's really no reason to go
past RSA-3072 (and me, I think there's no reason to go past RSA-2048).
If you need more than that, you should be looking into elliptical curve
cryptography rather than a longer RSA key.

@_date: 2013-10-30 10:39:07
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
If you first encrypt with ROT10 and then with ROT16, the final  strength is not the maximum of (ROT10, ROT16).  You may think that's a  silly example, and I grant that it is, but it illuminates the point  pretty well and avoids a lot of difficult math.
Cryptographic algorithms are extremely subtle and interact with each  other in subtle ways.  As a general rule they should not be stacked  unless there is (a) a clear necessity and (b) the particular stacking  has been formally proven to not diminish the overall security of the  system.  Otherwise, much as how ROT10+ROT16 has really awful security  characteristics, your stacking may be similarly awful.

@_date: 2013-10-30 11:45:31
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
Quoting Philipp Klaus Krause :
Arguing that "but that's not a real example!" is a nonstarter.  It  wasn't presented as a real example.  It was presented as a way to  illuminate the principle involved -- that algorithms can interact with  each other in ways that diminish the security of both -- without  needing to break out graduate-level mathematics.

@_date: 2013-10-30 13:31:46
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
Dangerously naive.  Meet-in-the-middle and/or miss-in-the-middle  attacks could be devastating.

@_date: 2013-10-30 19:15:28
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
Or you could just use 3DES.
Reposted from the last time was wondering if anything had been broken in
the OpenPGP suite:
I have said this many times in the past; apparently I need to say it again.
"3DES has been turning brilliant cryptanalysts into burned-out alcoholic
wrecks for over thirty years."
Nothing in the OpenPGP suite comes anywhere near to the safety provided
by 3DES.  Nothing even comes *close*.  Assuming your adversary has
access to more computing power than exists in the entire world, 3DES
offers "only" 112 bits of security; for realistic assumptions about
computing power, 3DES offers the full 168 bits.
3DES is ugly, awkward, ungainly, slow, and it has all the aesthetic
appeal of the Socialist Realism school of art.  It is *awful*.  And yet,
it keeps on going, completely impervious to the last three decades of
It reminds me quite a lot of the coelacanth -- a fish that was found in
the fossil record 400 million years ago, and still can be found swimming
in the oceans today.  If you look at a coelacanth it just looks
primitive, unevolved, and strangely frightening.  It has survived the
last 400 million years of Nature's attempts at killing it.  It commands
respect and admiration, even while at the same time giving vague
feelings of revulsion.
3DES is our coelacanth.

@_date: 2013-10-30 23:52:32
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
Yes, but good luck answering the inevitable next two questions: "what's
a group?" and "how do we know if something's a group?"  You very quickly
run into some complicated higher-level maths, and that's something best
There is no single answer to this.  The "other symmetric ciphers" need
to be evaluated combinatorically: for instance, are AES128, 3DES and
Camellia a group?  That answer may be different from AES192, 3DES and
Given there are 11 different symmetric algorithms as of 2.0.22, figuring
out all known-safe 3-cipher selections would require us to investigate
165 different combinations.  Frankly, I don't feel like doing that much
No.  I'm quite happy with my blanket statement: cryptographic algorithms
are subtle and should be left alone.  If you're Don Coppersmith then I
think you should feel free to get down with your bad self, but otherwise
this entire line of inquiry is one that I think goes nowhere good.

@_date: 2013-10-31 14:36:08
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
Excellent!  Let's play more.
What's this "\forall" and "\in"?  I don't understand.  Are those HTML  entity codes that my email client isn't presenting properly?
... Or, in other words, your very first line assumes a level of  mathematical knowledge that the overwhelming majority of people lack:  namely, the abilities of understanding mathematical notion and TeX.   Likewise with your answer about how it must uphold the associative  property: a lot of people are going to conflate associativity with  Abstract mathematics is the sort of thing that needs to be avoided at  all costs when giving explanations to non-specialists.  It just  doesn't work.
Quite possibly not, as whether AES is a group has absolutely no  bearing on how easy it is to break AES -- only on whether AES can be  used in composition, which is not particularly high priority.
The reason why the cryptanalytic community looked into whether DES  forms a group is because the 56-bit keyspace was too short and we  critically needed a way to compose DES into a stronger algorithm.   That's not the case with AES.
A quick search of Google Scholar does not turn up any articles about  whether AES forms a group.  I don't know one way or another.  My  suspicion is that it does not, but I'm not willing to trust that  Not to my knowledge.
Beware of saying "can't" unless you've got a formal mathematical proof  in your hands.  Even then, salt your pronouncements with "at our  present level of ignorance."
It is true that one of AES's design goals was exactly as you say  above.  However, there is no proof that they succeeded.  A lot of  eminent mathematicians think it's overwhelmingly probable they  succeeded, but I'm unaware of anyone who believes this has been proven.

@_date: 2013-10-31 14:38:37
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
No one will ever be able to brute-force a 128-bit key until such time  as we have quantum computers with 256-bit ensembles running at 3.2  kelvins and powered by stars.
Consequentially, I don't think this is any advantage at all.

@_date: 2013-10-31 14:42:57
@_author: Robert J. Hansen 
@_subject: 2048 or 4096 for new keys? aka defaults vs. Debian 
If memory serves that's a related-key attack.
(Hmm.  When you've gotten to the point where you can recognize  academic papers by their URLs, maybe that's a sign you need to get a  hobby... sigh.  Time to take up needlepoint, I guess.)
Anyway.  Although there's some really neat theoretical cryptanalysis  against AES-256, in reality AES-256 is as solid as the Rock of

@_date: 2013-10-31 15:16:07
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
============================== START ==============================
Yes.  But please remember how this entire subthread started.  Someone  proposed stacking ciphers.  I answered that was not guaranteed to  work, and used ROT as an example.
You responded that the only reason it fails with ROT is because ROT  forms a group.  To which I responded with: so what?  To my knowledge  nobody's proven AES does not form a group, either, and incidentally,  let's avoid talk about abstract mathematics because it's unnecessary  to the discussion and only serves to make our conversation opaque to  people who are not mathematicians.
Yes.  And I repeat: you cannot blithely stack ciphers together because  doing so may be harmful to the overall security of the system.  And  that's all that most people on the list need to know, really, without  a side discussion about group theory.
Yes, I know.  Even if I didn't, you explained it quite well in your  message and I would've learned.
I don't disagree with your conclusion.  I disagree with your *certainty*.

@_date: 2013-08-31 20:43:15
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
It shouldn't; NIST recommends 2048 bits for 20 years of security.
NIST notably makes no recommendations past 20 years, as they are deeply
skeptical of their ability to forecast out that far.  I suspect your
ability is no greater than theirs is, so I'd be very careful about
declaring a 10K key to be greater than your natural lifespan.
Per NIST, a 2048-bit key is of comparable difficulty to breaking 3DES.
Given the tremendous level of confidence people have in the long-term
suitability of 3DES, I am convinced a 2048-bit key will outlast my
ability to remember the passphrase to it.

@_date: 2013-09-02 21:51:01
@_author: Robert J. Hansen 
@_subject: AES256 & AES192. (Was: Can I revitalise an old key-pair?) 
I don't know why I need to speak up.  I haven't done any serious crypto
work in almost a decade now.  I am not an authority on these matters.
At best, I can give a semi-informed perspective on things -- but that's
about it.
You're misquoting him.
"For new applications I suggest that people don't use AES-256.  AES-128
provides more than enough security margin for the forseeable future.
But if you're already using AES-256, there's no reason to change."
So, my response to this is a shrug.  If you're already using AES-256, go
on and keep using it: there's no reason to change.

@_date: 2013-09-03 16:47:47
@_author: Robert J. Hansen 
@_subject: Security of 3DES 
I have said this many times in the past; apparently I need to say it again.
"3DES has been turning brilliant cryptanalysts into burned-out alcoholic
wrecks for over thirty years."
Nothing in the OpenPGP suite comes anywhere near to the safety provided
by 3DES.  Nothing even comes *close*.  Assuming your adversary has
access to more computing power than exists in the entire world, 3DES
offers "only" 112 bits of security; for realistic assumptions about
computing power, 3DES offers the full 168 bits.
3DES is ugly, awkward, ungainly, slow, and it has all the aesthetic
appeal of the Socialist Realism school of art.  It is *awful*.  And yet,
it keeps on going, completely impervious to the last three decades of
It reminds me quite a lot of the coelacanth -- a fish that was found in
the fossil record 400 million years ago, and still can be found swimming
in the oceans today.  If you look at a coelacanth it just looks
primitive, unevolved, and strangely frightening.  It has survived the
last 400 million years of Nature's attempts at killing it.  It commands
respect and admiration, even while at the same time giving vague
feelings of revulsion.
3DES is our coelacanth.

@_date: 2013-09-07 19:38:16
@_author: Robert J. Hansen 
@_subject: NSA backdoors and Set Preferred Cipher 
Why?  Your preference list makes no sense.
GnuPG and PGP will stop as soon as they hit 3DES.  They won't even look
at the rest of the ciphers in your preference list.  "Okay, Mike likes
Twofish, but the recipient doesn't support it... then CAST5, but that's
not supported... then Blowfish, again not supported... hey, 3DES.  3DES
is *guaranteed* to be supported.  The recipient has to speak 3DES.
Cool.  We'll choose 3DES and not even bother with the rest of the list."
Which means what, exactly?  3DES came out of IBM in the 1970s, but it's
not a "commercial product" in any sense I can imagine.  CAMELLIA came
out of a Japanese telecommunications firm, but it's likewise not a
"commercial product."
There are no "commercially offered ciphers" in GnuPG.

@_date: 2013-09-07 19:45:50
@_author: Robert J. Hansen 
@_subject: NSA backdoors and Set Preferred Cipher 
NIST couldn't consider it for an AES candidate because it hadn't been
invented yet.
A brief timeline:
1997: NIST begins the AES selection process
1998: Rijndael is published
2000: Camellia is published too late to be considered for AES
2000: NESSIE begins evaluating new algorithms
2000: CRYPTREC begins evaluating new algorithms
2001: Rijndael is selected to become the Advanced Encryption Standard
2003: CRYPTREC and NESSIE each select Camellia

@_date: 2013-09-07 19:53:51
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
The good news is that you are not your ideas.  Whether your ideas are
good or bad has nothing to do with your worth as a person.  A great
paper won't make you a good human being -- I've known some true geniuses
who are terrible people -- and a bad paper doesn't make you stupid,
inferior, or bad.
Now for the bad news: it's rubbish.
NIST, RSA Data Security, Lenstra and Schneier (just to name four) have
been extraordinarily careful about their long-term recommendations.
None of them have been willing to project beyond about 25 years in the
future.  They have all shared their reasoning for their circumspection
and detailed the factors that make long-term prediction difficult.
You're projecting 87 years into the future.  Why should we have any
confidence in your analysis?
In my opinion, you very much need to address two questions right off:
Without those two questions being raised directly and immediately, there
is no reason for a reader to have any confidence in what you've written.
 It is far more likely that you are limited by the same factors that
have limited NIST, RSA Data Security, Lenstra, Schneier, et al., and are
simply not aware of how those factors are confounding your analysis.
There are a large number of other errors in your write-up, but those two
questions above are the most critical shortcomings.  Without answers to
those two questions I can see no reason for anyone to take your writeup

@_date: 2013-09-08 11:07:21
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
I do, actually.  If I see that a major part of your write-up is
seriously lacking in rigor, that causes me to suspect the rest of your
write-up is similarly lacking.
We can't be sure 2048-bit keys will be broken by 2100.  Likewise, it's
within the realm of possibility 4096-bit keys will be broken tomorrow.
Factoring/discrete-log technology has stalled out for the last 20-odd
years after some very promising periods in the late-80s and early-90s.
The dominant technology used today is the General Number Field Sieve,
which was first developed around 1993.
This shouldn't really surprise us.  Factoring is *hard*.  It's provably
an NP problem, which means that (assuming P!=NP) there will never, ever,
ever, be an efficient algorithm for it [1].  We've been looking for
efficient ways to factor ever since Eratosthenes; it is quite likely
there simply isn't one.
So on the one hand, focusing on advances in factoring technology is
suspect.  And on the other hand, you're completely ignoring the
possibility of vast advances in other areas of number theory.  A couple
of years ago Dan Boneh published a paper that rocked a lot of people's
worlds to the core: he proved that *breaking RSA is not equivalent to
factoring* [2].  The RSA Conjecture ("breaking RSA is equivalent to
factoring") is *false*.  Wow.  And since the long-term security of RSA
is predicated on the RSA Conjecture, and the idea there's no other way
to attack RSA than by factoring... along comes Dan Boneh and opens the
door to the possibility of there existing many other mathematical ways
to attack RSA.  Some of them will undoubtedly be worse than factoring.
Some of them may be better.  It's possible one of them might even be in
P.  And how do we project for the future when we cannot predict if,
when, one of these Boneh approaches will be developed?
I am not even scratching the surface of the difficulties involved in
long-term prediction.  I know exactly where my limitations lie in making
long-term predictions.  I doubt you have a better look on the future
than I do -- and given your write-up doesn't even address the factors
that make long-term prediction difficult, I have no confidence
whatsoever in your 87-year projection.
[1] An efficient *classical* algorithm for it.  Although factoring is in
NP, it's also in BQP, which means efficient quantum algorithms exist.
[2] By 2100, I expect some kind of quantum computation to exist.  87 years
is a long time for technology: it took us fewer than seventy years to go
from the first airplane flight to Armstrong's first steps on the Moon.
It took fewer than thirty-five years to go from ENIAC to the Apple II.
Quantum computing, if-and-when it appears in a large scale (hundreds or
more of qubits in an ensemble), will transform our society in ways that
are hard to imagine.  It is literally science fiction technology.  Right
now, two of the few things we know for a fact is that quantum computers
will be able to efficiently factor large composites and compute discrete
logarithms in finite fields.  That means RSA and Elgamal are both out
the window the instant quantum computing becomes a possibility.
Your write-up barely mentions the possibility of quantum computing, and
says nothing of the consequences should it come to pass.  Even just an
"I arbitrarily project that quantum computing will become possible in
2050 and mainstream by 2060" would be better, because at least you've
drawn a line on the map and said "beyond 2060 there be dragons, and the
world will be radically unpredictable."
What do I mean by "radically unpredictable"?
Imagine that you're an academic in the early 1930s, and you're working
on an estimate of how much computation humanity has done.  You bury
yourself in studies of how many computers (remember, in the 1930s,
"computer" was an occupation) there are today, how much growth there has
been for the field, how many there were in the past, and you project
dramatic exponential growth for the profession of computing.  Then along
comes ENIAC which, in the first fifteen minutes of its operation, did
more computing than had been performed in the whole of human history up
to that point.  All of your estimates are immediately null and void
because the future has bushwhacked you.
*The very first quantum computer with more than two hundred qubits will,
in its very first calculation, do more computation than has been done by
all the world's computers from 1945 to the present.*
Anyone who attempts to predict the future of computing past the
introduction of quantum elements is either (a) a science fiction author
or (b) living in sin.
Your write-up also doesn't mention thermodynamic limits on computing.
The Landauer bound and the Margolus-Levitin limit are well-known
physical constraints on how much energy is used to flip a bit and how
much time it takes, at a given energy level, to flip a bit.  Past
RSA-3072 (which, per NIST, is conjectured to have a 128-bit keyspace),
these physical limits require you to release a level of heat comparable
to a nuclear blast.  The only way to get around these limits is to
reduce the effective keyspace of factoring the composite (which, as
mentioned above, we might never be able to do due to factoring being
solidly in NP) or to find completely new mathematical ways of attacking
the RSA Problem (which, although Boneh demonstrated probably existed, we
have no idea how to do, and if/when we do will possibly completely
invalidate RSA as an algorithm).
Then you're putting the cart before the horse.  If you're basing that on
a *guess*, then my guess is for RSA-16k and Werner's guess is for RSA-8k
and Phil Stracchino's guess is for RSA-4k and... [3]
You first need to provide evidence that your RSA-10k projection has a
good chance of being correct in 87 years.  Once you do that, *then* it
will be time to start looking at timing data and thinking about how best
to adopt RSA-10k today.  But before you do that, your guess is no more
valid than mine, Werner's, or Phil Stracchino's.  And we could all come
up with our own timing data and talk about the need to adopt our
guesses, and the ultimate result would be an awful lot of confusion.  A
great deal of heat and very little light.
[3] These guesses are completely made up, and I'm just using the names
of random people within the community.
That is a necessary precondition to taking the rest of your document
seriously.  Otherwise you're left with just a table of, "hi, I did some
timings on RSA-10k and here's what I found."  It's not very useful.
You have not addressed those two questions.

@_date: 2013-09-08 18:29:01
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
cannot be equivalent to factoring integers ... an oracle for breaking
RSA does not help in factoring integers."
The title involves the word 'may' out of an abundance of caution and a
decent respect for the opinions of the mathematical community.  Whether
he's proven it or not is not really for him to claim, but for the
mathematical community.  He's provided a conjecture and strong evidence
to support it, and I feel his conjecture is well-proven.  Your mileage
may vary.  :)
A factor of 125 is so small as to be irrelevant.
The real obstacle is that Shor's algorithm requires 2n qubits to be
formed in an ensemble, so you'd be going from requiring a 4k quantum
computer to a 20k quantum computer.  Given decoherence, that might
amount to a much more insurmountable obstacle.  Still, my money is on QC.
The problem is the exact same thing can be said for RSA-2048.  RSA-2048
is expected to last at least the next 25 years; it may last for the next
century.  Hard to say.  Depends a lot on the progression of science
fiction level technologies, like quantum computation.  And again, anyone
trying to predict out past about 25 years needs to explain why they are
able to do this where NIST, RSA Data Security, and so many others have
failed to be able to do this.

@_date: 2013-09-08 22:04:07
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
Or you wait three years and let technological progression reduce the
work factor for you.  Or you throw 125 machines at it instead of one.
Or... etc.  If something is unsafe at work level X, it won't be safe at
work level 125X.
There's a big difference between physics and engineering.  For an
example, look at the history of aviation.  During the era of
propeller-driven aircraft we were limited by the engineering constraints
of piston-driven propellers.  People said, "ah, but if we could only
perfect jet propulsion we could accelerate as fast as we wanted!"
Well-respected engineers like Buckminster Fuller talked about doing
space launches with jet aircraft -- accelerating up to orbital velocity,
releasing the satellite, and landing the delivery aircraft again.
Once we invented jet engines we discovered those were pipe dreams.
There was a new limitation that no one had considered prior to the
perfection of jet engines: since the air in the engine must be slowed to
subsonic velocities, that sharply limits just how far supersonic a jet
engine can go.  There was a new speed limit to replace the old speed
limit -- and a speed limit we didn't foresee until we actually had the
new technology to play with.
Nowadays people are talking about developing scramjets to overcome the
limitations of jet engines -- supersonic combustion within the engine.
And the old ideas from the 1920s are coming back around again, of using
scramjets to deliver satellites (or bombs, if you're working on defense
contracts).  And I have no doubt that if/when we perfect scramjet
technology we'll discover a new limitation, one we couldn't have
foreseen before we had working scramjets to play with.
So, yeah.  A 4k ensemble would mean we'd overcome the decoherence
problem, but really, so would a 200-qubit ensemble, or even a 50-bit
ensemble.  I'm not skeptical about our ability to overcome decoherence;
Bill Unruh tells me that we know how to do it in a physics level and
it's only a matter of time until engineering catches up.  I'm skeptical
about our ability to overcome the new limits which will arise, limits we
are at present unaware of.
Nor am I, but Bill Unruh is.  :)  I also attended grad school with Ben
Moehlmann, who has since received his Ph.D. in quantum computation.
Ben's been a great resource over the years for this stuff.  I never have
a conversation with him without walking away staggering under the weight
of the new knowledge.
I am not a quantum computation expert, but I hang out with some really
cool nerds.  :)

@_date: 2013-09-09 03:42:16
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
As a data point on that one: the 80386 production line shut down in 2007
after 22 years of production.  It ran at a top speed of 25MHz, but was
more frequently undervolted to enhance lifetime at the cost of reducing
it to 16MHz.  Today it's still a commonly embedded processor.
For those who wonder why the 386 has survived even into the present day,
it mostly has to do with legacy support and recertification costs.  If
you have a piece of Assembly from '86 that works just fine and which you
paid a lot of money to develop and get certified for use in a certain
environment running on x86 hardware, you will probably be very reluctant
to hire the developers, pay for the re-engineering expense, and pay for
the recertification expense, in order to get your application to run on
a modern-day StrongARM.  The embedded 80386 may be slow and antiquated,
but it's *cheap*, and lets you leverage your existing resources.

@_date: 2013-09-09 03:49:08
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
Nitpick: I think what he's trying to do (make credible, accurate
long-term projections) is a good idea.  I just think he's going about it
in a way that will not give credible or accurate answers, and that as a
result his write-up is rubbish.

@_date: 2013-09-09 05:39:46
@_author: Robert J. Hansen 
@_subject: RSA Conjectures 
tl;dr version -- RSA has not been damaged.  RSA is still believed to be
a safe algorithm.  The world is not ending.  Do not panic.  Anyone who
tries to use what I've written here to fearmonger about the future will
make me Distinctly Displeased.
Some people have been asking me to explain what the significance of
Boneh's paper is -- "he only proved that breaking low-exponent RSA may
not be equivalent to factoring and he explicitly says it doesn't affect
the security of RSA; why does this make you so concerned?"
First, "concerned" is the wrong word to use.  "Excited" is the right
word to use.  Why am I so excited?
RSA is built on several different ideas.  Let's enumerate them:
The RSA Conjecture: "Breaking the RSA algorithm is equivalent to
The IFP Conjecture: "Barring quantum computation, it will never be
The RSA Conclusion: "Barring quantum computation, it will never be
The Ole Conjecture: "The sufficiently-large point is RSA-10k."
Boneh's Commentary: "Y'all know the RSA Conjecture is false, right?"
Dan Boneh's paper establishes -- IMO, pretty solidly -- that the RSA
Conjecture is false, which means the RSA Conclusion is no longer
logically sound.  *That doesn't mean it's wrong*.
If you think that things fall to the earth because invisible pixies seek
to pull everything Underhill, proving that there are no invisible pixies
doesn't mean you've taken gravity offline.  If you make an arithmetic
error while deriving Einstein's Theory of General Relativity, it doesn't
follow that you can now drive to the grocery store at Warp 3.  Proving
the RSA Conclusion is no longer logically sound doesn't mean that it's
false -- it only means we can't be sure it's true.
RSA is still a strong, well-regarded cipher.  Dan Boneh didn't damage
RSA; he just revealed there was a great mystery here waiting to be
solved.  "There are ways to attack RSA that don't involve factoring.
What are they, and are any of them easier than factoring?"
The relevance of Boneh's work to long-term predictions about RSA should
now be clear.  In order to predict how long RSA will last, you have to
come up with some guesses about what research will develop.  If you
guess that "no efficient non-factoring approaches will be discovered in
the next 100 years," you might be able to have long-term confidence in
even small (3072-bit) RSA keys.  If you guess that "efficient
non-factoring approaches to RSA will be discovered within 25 years," you
might not be so sanguine.
It is a *fascinating* time to be a crypto nerd.  There are such amazing,
intriguing, and -- yes, I'm nerdy enough to say it -- such drop dead
*sexy* problems out there just waiting to be solved.  This is just one
of many!

@_date: 2013-09-09 05:44:15
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
Heh.  I always heard that as the "beard paradox."  Same basic idea,
except the example given involves beards instead of full heads of hair.  :)
At age thirty-eight, I'm beginning to develop a bit of gray in my facial
hair.  I guess that I can now legitimately call myself a graybeard...

@_date: 2013-09-09 05:55:28
@_author: Robert J. Hansen 
@_subject: Recommended key size for life long key 
More like, "it is good that key lengths and their expected lifetimes be
subjected to rigorous study," with a soupcon of "but that write-up is
very much lacking in rigor."
I personally don't like phrasing things in terms of "knowledgeable
people".  There's a joke I like to tell --
A mathematician, an economist and a physicist are traveling through
Great Britain via rail.  The physicist looks out the window and sees an
animal grazing in a meadow.  "Look!" the physicist exclaims.  "In
Scotland, sheep are brown!"
The economist pooh-poohs this.  "You're generalizing.  All you've proven
is that in Scotland there exists at least one brown sheep."
The mathematician rolls his eyes.  "Not even that.  All he's proven is
that in Scotland there exists at least one sheep that has at least one
brown side."
A fellow passenger on the train looks quizzically at the three, then
shares: "We're in Wales, and around here we call them 'cattle'."
Knowledgeable people get things wrong all the time, and especially when
they say "trust me, I'm knowledgeable."  I trust in process instead -- I
trust in rigor and logical development of thoughts and ideas to reach a
conclusion.  If I review the process and feel that it's valid, then it
doesn't matter if the person presenting the idea is a Ph.D. or is in the
eighth grade.  :)
I suspect, though, that we are overall in violent agreement.  :)

@_date: 2013-09-09 17:39:06
@_author: Robert J. Hansen 
@_subject: Why trust gpg4win? 
USB is a peer protocol.  There's an astonishing amount of computational
power on both sides of that USB cable.  Protocol negotiation is complex.
 Put it all together and you get a peer-to-peer protocol which you
*cannot* secure because (a) there are too many computational resources
available to an attacker and (b) the protocol itself is too complicated
and there are many ways a malicious token could compromise the remote
system even without autoplay installed.
Don't get me started on Firewire, which is even worse.  Oh, yeah, I just
love the idea of random dongles I can plug into my machine which get
root-level read-write access to RAM *as part of normal operations*.

@_date: 2013-09-10 09:30:14
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
No.  This idea gets floated every few years and the answers never
change.  It's not a good idea.  If you look in the list archives you can
find some pretty long, detailed writeups on why.
Basically, though, it's "this is a naive and unfounded assumption."

@_date: 2013-09-10 15:28:36
@_author: Robert J. Hansen 
@_subject: The symmetric ciphers 
I repeat my earlier message:
It takes you about thirty seconds to type a message.  To fully answer
your question would require me to spend about an hour crafting an
answer.  Since your question has been answered *at length* in the
archives, I'm not going to answer your question.  I'm going to refer you
to the archives and save myself an hour.

@_date: 2013-09-13 20:17:11
@_author: Robert J. Hansen 
@_subject: Where is ECC in gpg2 (specifically gnupg-2.0.21 
Although it hasn't hit the IETF WG mailing list, I know that some list
participants have had intermittent off-list conversations about lattice
cryptography and other QC-resistant crypto.  I wouldn't say that it's a
subject of active discussion within the WG, but some individual WG
members are definitely keeping an eye on it.
And let me give a big "d'accord!" to Werner's "we don't need to rush."

@_date: 2013-09-15 17:08:20
@_author: Robert J. Hansen 
@_subject: Preferred block cipher 
Although Schneier is definitely one of the authors, he has in the past
expressed a desire to see the other people of his research team
credited.  Twofish was designed by Schneier, John Kelsey, Doug Whiting,
David Wagner, Chris Hall and Niels Ferguson, all of whom are big names
in the development of cryptographic algorithms.
Although Schneier offers *an* implementation of Twofish, there is not a
single canonical source representation.  Twofish is an algorithm and
there are many ways it can be implemented.
Similarly, GnuPG only uses publicly-available algorithms.
There are no proprietary algorithms in GnuPG.

@_date: 2013-09-15 17:09:50
@_author: Robert J. Hansen 
@_subject: Setting Preference for Block Cipher 
That's not how cipher-preference works.  You are conflating the
preferences listed *on the certificate* with the preferences listed in
the gpg.conf file.

@_date: 2013-09-16 09:17:23
@_author: Robert J. Hansen 
@_subject: Preferred block cipher 
... which I interpreted to be his personal-cipher-preferences, not the
preference set that's attached to a key.  If my interpretation was in
error, my apologies.

@_date: 2013-09-22 13:41:23
@_author: Robert J. Hansen 
@_subject: gpg: Go ahead and type your message 
The normal way to use GnuPG is to first compose your document (using
whatever application you wish -- a word processor, a text editor,
whatever) and save it as you normally would.  Then, at the command line,
you would type something like:
gpg --local-user [keyID] --recipient [keyID] --sign --encrypt [filename]
This would tell GnuPG to encrypt the file for a specified person (given
by the --recipient flag), and to sign the file using a specified
certificate (given by the --local-user flag).

@_date: 2013-09-23 21:49:04
@_author: Robert J. Hansen 
@_subject: PGP/GPG confusing PGPDisk? 
You have the most probable cause of the problem right there.  The
problem happened after a security update to Lion.  Look there.
Nope.  PGP is smart enough to use its own keyrings, not GnuPG's.
Whether your certificate is on the keyserver network also has nothing to
do with it.
I'm sorry about your problem, but really, it sounds as if it's either
Apple's fault or Symantec's -- depending on whether Apple informed
developers about the change which ultimately broke PGPDisk.  If they did
then it's Symantec's problem, if they didn't then it's Apple's problem.

@_date: 2013-09-25 09:18:23
@_author: Robert J. Hansen 
@_subject: Magic numbers for keyring files? 
I'm working on adding support for GnuPG keyrings to a file carver (a
forensic tool that recovers data from damaged filesystems, or recovers
things that have been deleted but not overwritten).  Detecting an
ASCII-armored keyblock is pretty easy: look for the "BEGIN PGP PUBLIC"
header.  Binary, though, is still an unsolved question.
Before I start diving into code to find out if the keyring has a
specific binary header I can detect, I figured I'd ask on-list.  :)
Does anyone know of any magic numbers for GnuPG keyring files?

@_date: 2013-09-27 09:27:31
@_author: Robert J. Hansen 
@_subject: Use of two private/public key pairs, Sign only and Encrypt only 
That depends on which context you're looking for.  In terms of
cryptographic articles about using separate keys, that one goes back to
the early '80s; I think Dorothy Denning had one in _Communications of
the ACM_.  (Five minutes with Google Scholar revealed "Digital
Signatures with RSA and other public-key cryptosystems," April 1984.)
In terms of legal articles about the consequences of using separate
keys, that one is currently badly unaddressed.
This has happened in the United Kingdom.  To my knowledge it has not
happened in the United States.  However, as this is a legal question,
you will be best served by asking a lawyer.  :(

@_date: 2013-09-27 09:56:03
@_author: Robert J. Hansen 
@_subject: Use of two private/public key pairs, Sign only and Encrypt only 
Arguably, the United Kingdom.  The Regulation of Investigatory Powers
Act of 2000 (RIPA) can be used to compel you to turn over the encryption
key used for a message.  Normally the police are satisfied with getting
the symmetric key used to encrypt the message, but there's nothing in
RIPA that requires them to limit themselves to that.  They could instead
require the RSA key involved, and odds are fairly good a judge would
uphold this demand.
If you have an RSA sign-and-encrypt key, then by doing so you've just
enabled the police to forge your signature.  What's worse is that
revoking your key could be seen as tipping off your correspondents to
the police's activities, and that's a serious offense under RIPA.

@_date: 2013-09-27 14:39:59
@_author: Robert J. Hansen 
@_subject: Use of two private/public key pairs, Sign only and Encrypt only 
Nothing is official until the jury comes back.
RIPA prohibits someone who is under a key-divulging order from telling
other people about the order.  That much is official.  It's within the
realm of possibility that a prosecutor would tell the Court, "Milord,
Mr. Laging revoked his certificate immediately after divulging to us the
passphrase.  This had the effect of tipping off his correspondents that
the certificate was compromised.  We ask that you deem this to be a
violation of RIPA's provisions prohibiting affected persons from telling
others about the forced disclosure of their key."
A lot of armchair lawyers (on this list and others) will say that this
argument would never fly.  I'm not so certain.  I'm not saying it would
certainly work; I'm also not saying it certainly wouldn't.  It would
depend a lot on the judge hearing the case.
Notice how I said "revoking your key *could* be seen as".  :)
These are legal questions.  Ask a lawyer.  (Or, given that it's a matter
of United Kingdom law, ask a solicitor.)

@_date: 2013-09-27 14:44:17
@_author: Robert J. Hansen 
@_subject: GPG Private Key Export Question 
For the last week I've been writing a parser suitable for filesystem
forensics.  All I can say is, "preach it, brother."  I printed out
hardcopy of the whole of RFC4880 and have pages from it pinned up to my
cubicle walls.
There is also a sheet of paper pinned up there that has a red circle
about six inches across and a caption beneath of, "BEAT HEAD HERE."  I
find myself referring to that almost as much as I do to RFC4880.
(Speaking of that project: thank you, Peter and David, for pointing me
towards the file(1) magic numbers library.  It works well enough for my

@_date: 2013-09-27 19:32:03
@_author: Robert J. Hansen 
@_subject: GnuPG encryption using command line 
Best solution: write JNI bindings for gpgme.  There are already some
bindings in varying stages of completion: you may want to use one of
these as a bootstrap.  Good luck!

@_date: 2014-04-01 19:43:09
@_author: Robert J. Hansen 
@_subject: post-quantum computing in GnuPG 
I am not a GnuPG developer: they will have the official word.
Unofficially, no.  GnuPG tracks the RFCs published by the IETF Working
Group.  If you want to see this, make a case for it to the WG and get
algorithm numbers, etc., assigned.  Then implement it as a patch to a
GnuPG tree and let people beat on it for a while.  If it survives,
you've got an excellent chance of getting it adopted into GnuPG.
I know, I know -- "I didn't mean 'how do *I* implement it,' I meant 'are
*you* going to implement it.'"  And the answer there is probably not,
not unless someone like you gets the ball rolling in the above fashion.

@_date: 2014-04-02 02:50:19
@_author: Robert J. Hansen 
@_subject: post-quantum computing in GnuPG 
Well, you'd need 4096 qubits in the ensemble, representing a state space
of something like 10^1233 (not a typo).
At that point I'm going to just give up and offer my services to our new
Space Overlords from Zarbnulax Prime.  Maybe if I help round up pesky
humans they'll give me a ride in their FTL spaceships!

@_date: 2014-04-04 02:04:14
@_author: Robert J. Hansen 
@_subject: Length for AES256 symmetric encryption passphrase? 
English has about 1.5 bits of entropy per symbol.  A 32-character
passphrase could thus be any of about a trillion different things.
That's a 1 followed by 12 zeroes.
A 256-bit keyspace is so huge English can't describe it.  It's a 1
followed by 77 zeroes.  The difference between the two is sort of like
comparing a lit match to Supernova 1987A.  The difference is on that
level of mind-boggling vastness.
Using plain English for the passphrase, a 170-character passphrase is
necessary to provide a full 256 bits of entropy.

@_date: 2014-04-04 02:06:02
@_author: Robert J. Hansen 
@_subject: Length for AES256 symmetric encryption passphrase? 
Depends on how you generate it and how much entropy you want.
For my high-security passphrases I grab 16 bytes (128 bits) from
excellent security margin.

@_date: 2014-04-04 10:10:55
@_author: Robert J. Hansen 
@_subject: Length for AES256 symmetric encryption passphrase? 
Your questions are not clear enough to be answered.
"What would the recommended length for completely random characters  generated, for example, by a password manager such as keepassx?  If  one were using the password as the symmetric key in libgcrypt?  Or  perhaps even just using openssl tools?"
1.  Well, which password managers?  Just because a character is  completely random tells me nothing about how much entropy is contained  in each symbol.  "TTHTHHTTH" is a completely random sequence  (generated it just now by flipping a fair coin), but it only has one  bit of entropy per symbol.  "fBTvC" is a completely non-random  sequence, but it has a lot more entropy per symbol.  Without knowing  how a random password is generated I can't answer this.
2.  Recommended for what purpose?  256 bits of entropy is wild  overkill for almost all purposes.  128 bits of entropy is generally  speaking plenty.
3.  Which toolkit?  libgcrypt and openssl are two completely different  toolkits that work in completely different ways, and an answer  appropriate for one might not be appropriate for the other.
4.  What is it you really want to know?  You already know: AES depends  on having a 32-bit key which can support up to 256 bits of entropy.   You've been told two good metrics for estimating entropy in a  passphrase: 1.5 bits per glyph of English text, 5 bits per glyph of  base-64ed random data.

@_date: 2014-04-04 13:04:26
@_author: Robert J. Hansen 
@_subject: Length for AES256 symmetric encryption passphrase? 
Looks good to me.  My only correction is a notational one.  Keyspaces  are normally expressed in bits of entropy, not in 2^N bits of entropy.    I'd suggest:
L = (3N) / (10 * log S)
... where 'L' is the length of the string in terms of its base  component, N is the desired entropy in bits, and S is the keyspace of  the string's base component.  This avoids having to compute logarithms  base-2, since 3/10 is an astonishingly good approximation of two in  Plugging in the numbers for Diceware and a 256-bit key:
L = (3 * 256) / (10 * log 7776)
L = 768 / (10 * 3.89)
L = 768 / 38.9
L = 19.74
Round it up to 20 words and call it done.
This is simple enough that you can turn it into a snippet of  Javascript, a Python applet, or anything.  It's not much work at all.   If anyone wants, I'd be happy to put up a passphrase length calculator.
And let me repeat, Ren?, you got the math absolutely right.  All I did  was clean it up a little bit to remove an obnoxious 2^godawful  calculation.  :)

@_date: 2014-04-04 13:14:09
@_author: Robert J. Hansen 
@_subject: Length for AES256 symmetric encryption passphrase? 
Again, correct!
Then this becomes pretty straightforward.  :)  Let's say you use the  upper- and lower-case letters, the digits 0 through 9, as well as the  '+' and '/' marks.  This character set is commonly called 'base64',  since there are 64 symbols in the set.
Using the equation Ren? provided and I polished a bit, you have:
       3 * 256    <-- 256: size of the key in bits
L = -----------
     10 * log 64  <--  64: how many letters are in your set
... 43 characters.
A quick back-of-the-envelope calculation confirms this to be the case.    base64 is known to have six bits of entropy per character.  6 * 43 =  258 bits.  At 43 characters you're providing GnuPG with 258 bits of  entropy to use in creating a 256-bit symmetric key.

@_date: 2014-04-09 12:51:20
@_author: Robert J. Hansen 
@_subject: Heartbleed attack on Openssl 
That right there should be your first hint.  :)
This is a great email list to get informed opinions on GnuPG and the
OpenPGP RFCs, but this may not be a great place to get informed
commentary on OpenSSL.  It's a completely different software package run
by a completely different outfit.
You may get better answers if you ask on the OpenSSL mailing lists.  :)

@_date: 2014-04-09 13:58:40
@_author: Robert J. Hansen 
@_subject: It's 2014. Are we there yet? 
Every year or so this subject comes up, and my answers are unchanged
from last time: start by reading up on academic papers studying this
exact problem.  For a while John Clizbe and I kept a list of good
papers, but I have to confess I haven't been keeping up on the latest
literature.  Still, our last list is pretty good reading.
(These selections come from both John and me, but John is the one who
assembled them into proper cite format -- thanks, John.  For the
original message, see "Re: what is killing PKI?" on this mailing list,
posted on 24 Aug 2012.)
Gaw, S., Felten, E. W., and Fernandez-Kelly, P. 2006.
Secrecy, flagging, and paranoia: adoption criteria in encrypted email.
In Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems (Montreal, Quebec, Canada, April 22 - 27, 2006).
R. Grinter, T. Rodden, P. Aoki, E. Cutrell, R. Jeffries, and
G. Olson, Eds. CHI '06. ACM, New York, NY, 591-600.
DOI= Garfinkel, S. L., Margrave, D., Schiller, J. I., Nordlander, E.,
and Miller, R. C. 2005. How to make secure email easier to use.
In _Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems_ (Portland, Oregon, USA, April 02 - 07, 2005).
CHI '05. ACM, New York, NY, 701-710.
DOI= Alma Whitten and J.D. Tygar. Why Johnny Can?t Encrypt: A Usability
Evaluation of PGP 5.0. In Proceedings of the 8th USENIX Security
Symposium, Washington, DC, August 1999. Steve Sheng, Levi Broderick, Colleen Alison Koranda, and Jeremy J.
Hyland. Why Johnny Still Can?t Encrypt: Evaluating the Usability of
Email Encryption Software. Poster session, 2006 Symposium On Usable
Privacy and Security, Pittsburgh, PA, July 2006.

@_date: 2014-04-09 19:20:09
@_author: Robert J. Hansen 
@_subject: Heartbleed attack on Openssl 
None.  The ordinary user is such an easy target that as bad as this
attack is, I don't see it as making things any worse.
Not yet.  Give it a few days: news reports will develop, Wikipedia will
be updated, and so on.
No, it does not.  Nor does Chrome.
Usually not.  Repositories are normally accessed via HTTP, not HTTPS.

@_date: 2014-04-09 19:42:24
@_author: Robert J. Hansen 
@_subject: Heartbleed attack on Openssl 
I have heard that Chrome is migrating to OpenSSL instead of Mozilla's
NSS libraries; it's possible Chromium is a testbed.  Speculation on my
part, though.

@_date: 2014-04-09 23:13:56
@_author: Robert J. Hansen 
@_subject: Heartbleed attack on Openssl 
Again, you will have better luck asking on an OpenSSL mailing list.
There is no guarantee that anyone on this mailing list is an expert in
Someone else could connect to X and use Heartbleed to scan the contents
of X's memory.  Anything sent to X could be considered compromisable for
so long as it's stored in X's RAM.

@_date: 2014-04-10 00:35:52
@_author: Robert J. Hansen 
@_subject: Heartbleed attack on Openssl 
I am flattered that you think I am a mind reader, but I assure you, I am
not able to use the Heartbleed attack to pull important information out
of your frontal cortex -- like what operating system you're using, what
browser you're using, and so on and so on.
At any rate, these are questions for your browser vendor.

@_date: 2014-04-10 12:33:07
@_author: Robert J. Hansen 
@_subject: It's 2014. Are we there yet? 
I prefer an analogy of a mailbox.
Anyone can drop a letter in my mailbox.  You walk up to it, slip the  letter through the mail slot, and you're done.  However, only I have  the key to my mailbox: once you've dropped it in my mail slot, you can  no longer read your own message.  After all, you don't have the key to  my mailbox.  And my mailbox doesn't have to be secret: it's public  knowledge where it is.  Anyone can drop a letter through the mail  slot, and it doesn't affect the secrecy of the messages.  Knowing how  to leave a message for me doesn't help you read messages that other  people leave for me, but if I lose the keys to my mailbox then I'm in  a lot of trouble.
Most of the people I deal with have used mailboxes and mail slots  before.  The analogy seems to work well with them.  YMMV, of course.  :)

@_date: 2014-04-11 14:47:03
@_author: Robert J. Hansen 
@_subject: It's 2014. Are we there yet? 
In 2007-8 (the last time I taught undergrad Computer Literacy), over a
third of my students only used email for university business (like
submitting papers to me) and talking to their older relatives.  Among
their own age bracket, most communication was done through Facebook.
(Today it's more Instagram and Snapchat and the percentage is
approaching 50%, according to my friends who are still teaching.)
But yes, email really is on the way out as a communications medium.  The
younger generation sees it as an antiquated technology.  I suspect in
another 20 years it'll be used about as much as Gopher is today.

@_date: 2014-04-11 15:35:20
@_author: Robert J. Hansen 
@_subject: It's 2014. Are we there yet? 
Right now, Microsoft Sharepoint is in use at 80% of Fortune 500 firms.
Normally it's used to set up internal social networking for the company.
 Some firms are adopting it halfheartedly, and other firms are seeing it
significantly cut into email usage.  The trend is upwards.
Whether I think this is wise makes no difference to whether I see this
happening.  I think it's unwise, and I see it happening in droves.
I find it to be an overwhelming one.  The future has spoken, and it
thinks email is for old folks and fuddy-duddies.  No technology can be
said to be ascendant, or even keeping its market share, if future
generations are not signing on to use it.
Will email still be around in twenty years?  Sure.  But we still have
Gopher servers today, too.

@_date: 2014-04-11 16:08:36
@_author: Robert J. Hansen 
@_subject: It's 2014. Are we there yet? 
You might want to think long and hard about that.
College campuses are filled with politically active young people who
have just received the right to vote and are consumed with passionate
intensity about their rights -- including their right to privacy.
They're young, politically active, mostly left-wing, and more
technologically adept than their parents.  They also shape future trends
and future political debates.
If they're not your target audience, then you're doing it wrong.

@_date: 2014-04-14 11:43:45
@_author: Robert J. Hansen 
@_subject: Am I being blocked from posting on this list? 
Heartbleed!  Heartbleed!  Heartbleed!
Nope, no Great Old Ones have risen from the depths and begun to expose  humanity to unimaginable horrors.  Maybe if I try again with the word  "Hastur"... [*]
Heartbleed was bad, yes.  However, it's hard for me to believe it's  "far more severe than most people think."  Being able to read 64k  chunks out of server memory at-will and on-demand by exploiting  commonly-used software is already a Chernobyl-level disaster.  Really,  how's it going to get worse?
If it starts replacing my Glenmorangie Quinta Ruban with Black Velvet,  okay, then it'll be time to scream, wail and grieve.  But until then,  let's keep our heads, let's face the future with a smile, let's not  panic, and let's not think the GnuPG list is censoring anything that  contains the word 'Heartbleed'.
Now, if you'll forgive me, there's a Great Old One I've been trying to awaken.
Hastur!  Hastur!  Hast--*urgkl* *thud*
[*] if this makes no sense to you, go read some H.P. Lovecraft's _The  Whisperer in Darkness_.  :)

@_date: 2014-04-14 12:27:13
@_author: Robert J. Hansen 
@_subject: The bug... More info. 
Given the bug was introduced in March of 2012, that would mean the bug  would have had to been discovered, an exploit tested, a product  weaponized, a product distributed to end-users, and deployed by  end-users against targets, all in under a month from the moment the  bug was introduced.  I'm not saying it can't happen, but a healthy  distrust would seem appropriate here.  Further, the use of "at least"  two years is meant to imply it could have been substantially longer --  but it could not have been more than two years and a month.  Between  that and the journo's mishandling of anonymous sources, I am not  confident the Bloomberg journo did his homework.
With respect to anonymous sources, the standard is generally --
     1.  You give their background, broadly speaking
     2.  You say something about where they got the information
     3.  You specify they asked for anonymity -- it wasn't your idea
     4.  You explain why you're granting anonymity
If you can't meet those four requirements, you don't use the source.   If you can't give the public information about their background and  the source of their information, then you can't give the public enough  information to decide whether your source is credible.  And if you  can't give the public enough information to decide whether your source  is credible, why should the public believe you?
(ObDisclosure: I used to work as a tech journo.  My four-point outline  there was the standard we used, and my editor was fastidious about  enforcement -- whether it was as small as "one space after a colon and  the word is capitalized" or "four-point process for anonymous  sources," Terry was on top of things.  I never used an anonymous

@_date: 2014-04-14 12:42:58
@_author: Robert J. Hansen 
@_subject: Am I being blocked from posting on this list? 
There have been several posts on this list saying, "you know, you will  probably get better discussion and better answers on an OpenSSL  mailing list."  I understand you believe the Heartbleed bug needs more  visibility.  I respectfully suggest that pretty much everyone on this  list knows about Heartbleed, and talking about it here will not  increase the visibility of this issue one bit.
I mean this with sincerity, caution, and respect.
Go watch the cherry blossoms.
In the current climate it's easy to think there's shadowy, nefarious  things going on in the darkness.  There's terrorism all over the  Middle East, there's a 777 that's gone completely missing in the South  Pacific, civilians getting nerve-gassed in Syria, Russians in the  Crimea and possibly agitating Eastern Ukraine, the Snowden  revelations, the Manning revelations, the controversy over domestic  and international surveillance, will the Iranians get the bomb, is  Pakistan an ally or an enemy, the Baltic States worried about an  invasion from the east, North Korean missile and nuclear tests... the  list goes on and on and on.
It's easy to think that life has turned into a remake of _Three Days  of the Condor_.  It is.  I've been there and I've had those thoughts.
But it's not about you, man.  Any more than it's about me.  And your  messages are not getting censored because they reference the  Heartbleed bug.
If you're in the Northern Hemisphere, then you're in the middle of  spring.  Around here in northern Virginia it's absolutely beautiful.   The cherry blossoms have come to Washington.  Life is beautiful.  Go  out and enjoy it for a while, and enjoy the fact that as bad as the  international news is nowadays ... it's not about you.
And that's good advice for the rest of us, too.  If you ever get  overwhelmed by all the bad news, go watch the cherry blossoms for a  It's cheaper than therapy, and in my personal experience it's far more  effective.  :)

@_date: 2014-04-14 13:47:46
@_author: Robert J. Hansen 
@_subject: The bug... More info. 
The government had a seat that needed filling, they couldn't get the  seat filled at the paycheck they're legally allowed to offer to a  direct employee, so they hired a private contractor to fill the role.   Pretty simple, really.
The government pay rate for someone with a Master's degree and ten  years of experience hovers around $60,000 per year, incidentally.   It's shockingly low by the standards of the tech sector.

@_date: 2014-04-14 18:51:44
@_author: Robert J. Hansen 
@_subject: The bug... More info. 
I was about to not respond, but -- I have this thing about errors of
fact: I want to see them corrected.  So yes, this is off-topic, and I
plan on letting this end here.
The USG still does a lot of these, and there are several companies
providing these background check services.  USIS, one of the largest
providers, is under investigation for misconduct -- but let's not go
about thinking the entire system has collapsed, or that the USG doesn't
do any of the work itself any more.  Neither is true.

@_date: 2014-04-19 12:02:26
@_author: Robert J. Hansen 
@_subject: It's 2014. Are we there yet? 
Given that this only affects PGP 2.6 certificates, and GnuPG users
overwhelmingly use modern v4 certificates, this is not a major problem
for GnuPG users.

@_date: 2014-04-19 17:14:47
@_author: Robert J. Hansen 
@_subject: It's 2014. Are we there yet? 
Version 3.  PGP 2.6 used version 3 certificates.  PGP 5 and beyond, and
all versions of GnuPG, have always used version 4 certificates natively;
support for version 3 certificates is done only for backwards compatibility.
If you don't want to trust GnuPG, don't look to me to talk you out of
it.  Life's too short.  If you have questions I'll happily answer them,
but I have zero interest in persuading you that GnuPG should be used or

@_date: 2014-04-22 18:56:58
@_author: Robert J. Hansen 
@_subject: UI terminology for calculated validities 
I can see it, actually.  Let's say that I have a certificate for
personal use, and a separate one for corporate use where the private
part is escrowed with the firm.  You might trust signatures from my
personal cert but not from the corporate cert, due to your concerns over
my corporate masters being able to impersonate me at-will.

@_date: 2014-04-24 20:51:23
@_author: Robert J. Hansen 
@_subject: C# .dll availability? 
Yes; gpgme-sharp.  However, since it P/Invokes out to native code it's
limited to 32-bit only.  This may be a problem if your code has to run
in a 64-bit .NET environment.

@_date: 2014-04-26 21:36:26
@_author: Robert J. Hansen 
@_subject: A few newbie Qs 
It's kind of like asking whether King Kong or Godzilla is the best at
urban demolition.  There are no clear answers here, and all rankings
will be hotly contentious.  Just discussing the different facets of the
problem requires college-level math: one might be slightly superior in
its resistance to differential cryptanalysis, another in
impossible-differentials, and so on.
The good news: all the ciphers in GnuPG are believed strong even in the
face of well-funded and highly-skilled adversaries.
These are called "known-plaintext attacks."
All the ciphers in GnuPG are believed to provide strong protection
against known-plaintext attacks.
Really, really hard.  Like, "it would make the earth uninhabitable."
Depends a lot on the mailing list.  I wish I could give clearer advice
than that.
Sure.  --personal-cipher-preferences will do this.  That said, you read
wrong: AES is considered one of the gold standards of strong
cryptography.  It's fast and believed highly resistant against
So long as you're confident your passphrase is still a secret, yes.
English has about 1.5 bits of entropy per glyph.  Past about 384 letters
you're not making things any harder to guess.  Long passphrases also
silently encourage users to do risky things like cut-and-paste them.
(It's very easy for malware to look at the contents of your clipboard
No.  That's a 1995-2000 model of how spammers work.  Email address
harvesting got replaced by Markov models about 15 years ago.
GnuPG will do it automatically.  Just import the certs.

@_date: 2014-04-26 22:02:11
@_author: Robert J. Hansen 
@_subject: Fwd: Re: Re: A few newbie Qs 
Is anyone else getting spam like this the instant they post to the list?
 It seems as if one listmember might have a compromised PC which is
sending out spam in response to anything that comes in.
(The full message headers have been trimmed, as they're not particularly
useful.  If a list maintainer wants, though, I'll be happy to send the
full headers.)
-------- Original Message --------
Reply-To: 	brighteyes26 at mailingbuddies.com
Hey cool you wrote back :) Wasn't sure if you were real or not it's hard
to tell sometimes lol. Can you send me a recent pic to this email? Also
you are looking for something really casual right? You need to know I'm
not looking for a boyfriend I just got out of a relationship. I need
some fun and a one night stand or whatever the heck its called. I
suppose if you were good enough we could meet again it depends how it
feels lol. See how it goes? I'll send you my pic now, yours is already
good enough for me. Maybe send one more. Did you wanna make a plan or
[[ attachment of type image/jpeg removed ]]

@_date: 2014-04-27 20:34:07
@_author: Robert J. Hansen 
@_subject: A few newbie Qs 
I think so, but I'm well-known for being barking mad.  Hornswoop me
bungo pony, dogsled on ice (red and black, it's their color scheme).  By
the silverfish imperetrix whose incorrupted eye sees through the charms
of doctors and their wives...
(At some point it's really hard to distinguish random Blue Oyster Cult
lyrics from a full-on psychotic episode.)
C&P is a time machine.
If I enter a passphrase normally on Monday and my machine is compromised
on a Tuesday, I can be confident my certificate is still secure because
I never entered my passphrase on a compromised machine.  If I enter a
passphrase via C&P on Monday and my machine is compromised on a Tuesday,
I suddenly have to worry: was my passphrase still in my C&P buffer?  Did
I remember to wipe the C&P buffer?  Did the C&P buffer get wiped
securely?  Did I...
Generally speaking, it is suboptimal to enter passphrases via C&P.  It
makes it possible for a compromise tomorrow to discover the passphrase
you entered today.
I don't doubt there are situations where it makes sense to use C&P.
I've yet to find one, though.

@_date: 2014-08-11 02:49:32
@_author: Robert J. Hansen 
@_subject: =?windows-1252?Q?Re=3A_=5Bopenpgp=5D_SHA-2_support_shoul?= 
(Since this has taken a turn for the GnuPG-specific, I have migrated
this thread to GnuPG-Users.  It was originally found on the IETF OpenPGP
working group page.)
The man page is correct.  Please don't use these options.  Please don't
encourage people to use these options.  It's very easy to misuse these
options in ways that will destroy interoperability with other OpenPGP
I would be happy to look at your suggestions for inclusion in the FAQ;
however, I'll tell you in advance the FAQ will not recommend using
digest-algo or cipher-algo.
Given the OpenPGP mailing list is comprised mostly of people who
implement OpenPGP for a living, it is unlikely there will be many people
there who use old versions of software.
Try looking here on GnuPG-Users.  You'll have to hunt a little bit, but
it's pretty easy to find people seeking help with GnuPG 1.2, which is
well over a decade old.  On Enigmail, I recently had a frustrating
experience helping a user who was trying to use GnuPG to exchange
traffic with a PGP *2.6* user... a codebase which is about 20 years old now.
So, short answer: yes, there are implementations that do not support
SHA-2 and/or AES.  Yes, they are still in use.  Yes, we really wish
they'd all just vanish or else upgrade to the latest, but no, they have
no plans of doing that.

@_date: 2014-08-11 13:18:33
@_author: Robert J. Hansen 
@_subject: FAQ change, final draft 
A few weeks ago on -devel I made a proposal for a FAQ change.  So far I've received feedback from three people, all of it fairly positive, all suggesting mild changes.  The following represents a final draft, which I'm now presenting on -users to get the most visibility/feedback.  If the community approves, I'll be submitting this to Werner for inclusion into the FAQ.
Q: Why does GnuPG default to 2048-bit RSA?
A: At the time the decision was made, 2048-bit RSA was thought to
    provide reasonable security for the next decade or more while still
    being compatible with the overwhelming majority of the OpenPGP
    ecosystem.
Q: Is that still the case?
A: Largely, yes.  According to NIST Special Publication 800-57,
    published in July 2012, 2048-bit RSA is believed safe until 2030.
    At present, no reputable cryptographer or research group has cast
    doubt on the safety of RSA-2048.  That said, many are suggesting
    shifting to larger keys, and GnuPG will be making such a shift in
    the near future.
Q: What do other groups have to say about 2048-bit RSA?
A: In 2014, the German Bundesnetzagentur fuer Elektrizitaet, Gas,
    Telekommunikation, Post und Eisenbahnen recommended using RSA-2048
    for long-term security in electronic signatures.
    In 2012, ECRYPT-II published their "Yearly Report on Algorithms
    and Keysizes" wherein they expressed their belief RSA-1776 will
    suffice until at least 2020, and RSA-2432 until 2030.
    In 2010, France's Agence Nationale de la Securite des Systems
    d'Information stated they had confidence in RSA-2048 until at
    least 2020.
Q: Is there a general recommendation that 3072-bit keys be used for
    new applications?
A: No, although some respected people and groups within the
    cryptographic community have made such recommendations.  Some
    even recommend 4096-bit keys.
Q: Will GnuPG ever support RSA-3072 or RSA-4096 by default?
A: Probably not.  The future is elliptical-curve cryptography,
    which will bring a level of safety comparable to RSA-16384.
    Every minute we spend arguing about whether we should change
    the defaults to RSA-3072 or more is one minute the shift to
    ECC is delayed.  Frankly, we think ECC is a really good idea
    and we'd like to see it deployed as soon as humanly possible.
Q: I think I need larger key sizes.
A: By all means, feel free to generate certificates with larger keys.
    GnuPG supports up to 4096-bit keys.

@_date: 2014-08-11 15:05:40
@_author: Robert J. Hansen 
@_subject: gnupg-2.1 Install 
The latest GnuPG is in the Ubuntu repositories, last I checked.
Ubuntu's normally pretty good about keeping current.
With respect to GnuPG 2.1, it's still in progress and hasn't yet been
released.  As such, that means it's really not in a state where users
are expected to be able to compile it from scratch.  Once we get close
to an official 2.1 release I'm pretty sure the compilation process will
get easier.  :)
Have you considered turning this into a bash or Perl script?  Some
people on the list might find that very useful.

@_date: 2014-08-12 15:58:03
@_author: Robert J. Hansen 
@_subject: FAQ change, final draft 
The guidance from NIST is:
[1] shannons of entropy needed
[2] bits of symmetric key
[3] bits of RSA/DSA/ELG
[4] bits of ECDSA/ECetc.
[1]     [2]     [3]     [4]
80      80      1024    160
112     112     2048    224
128     128     3072    256
256     256     ~15k    512
The entropy of symmetric and ECDSA/ECetc. keys scales linearly with key length; the entropy of RSA/DSA/ELG keys scales logarithmically with key

@_date: 2014-08-12 16:02:21
@_author: Robert J. Hansen 
@_subject: FAQ change, final draft 
Yes.  The general consensus is that the discrete logarithm problem is harder than integer factorization, so ELG/DSA will provide more strength than RSA for a given length.
However, I've also been cautioned by some big names in crypto that I shouldn't put too much stock in this: we know DLP must be at least as hard as integer factorization, but we don't have precise numbers for how much harder it has to be, and the tendency over the years has been for the two to slowly converge in difficulty.
As of now the best guidance is to think DLP is at least as hard as IFP, but to be skeptical about how much harder.

@_date: 2014-08-12 16:42:48
@_author: Robert J. Hansen 
@_subject: [Announce] [security fix] Libgcrypt and GnuPG 
I would also add the Qt pinentry plugin to this.  The native Win32 one
looks completely awful.  If someone could point me at an API, I'd give
serious thought to doing a modern one with WPF to replace the existing
native Win32.

@_date: 2014-08-13 00:29:03
@_author: Robert J. Hansen 
@_subject: Different signing & encryption keys 
gpg --edit-key [keyID]
Look at the right hand side.  For each subkey (including the main
signing key) there will be an entry for "usage".  This field can contain
the letters S, C, A, or E.
S = Sign
C = Certify
A = Authenticate
E = Encrypt

@_date: 2014-08-13 09:07:36
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 131, Issue 15 
Fort Meade is actually closer to Laurel than it is to Baltimore.
Which shouldn't be any surprise, since NIST collaborates with them on
determining these numbers.  You'll notice that they exactly match NIST's
recommendations, except that NIST doesn't list a 192-bit entry.  Also, I
think your 521 is actually 512.  :)
Nope.  That's the computational complexity in a computational-theory
sense, not the complexity in a cryptanalytic sense.  Be real careful
about thinking the two of them are connected; they're probably not.  If
it scaled with bit length to the 1/3 power, and if a 3072-bit RSA key
corresponds to 128 shannons of entropy, a 15360-bit RSA key would only
have 211 shannons -- not 256.
Coming up with these tables is black magic at the best of times.  For
that reason, I hope you'll understand if I choose to rely on NIST rather
than your numbers.  :)

@_date: 2014-08-13 11:05:19
@_author: Robert J. Hansen 
@_subject: James Mickens on security 
Microsoft Research's James Mickens wrote several humorous columns for USENIX in which he interspersed brilliant insights with side-splitting humor.  I just found his "This World We Live In," which has a good bit about PGP in it.  You can find his original at:
"[C]onstructing a public-key infrastructure is incredibly difficult in practice.  When someone says 'assume that a public-key cryptosystem exists,' this is roughly equivalent to saying 'assume that you could clone dinosaurs, and that you could fill a park with these dinosaurs, and that you could get a ticket to this "Jurassic Park," and that you could stroll throughout this park without getting eaten, clawed, or otherwise quantum entangled with a macroscopic dinosaur particle.'  With public-key cryptography there's a horrible, fundamental challenge of finding somebody, *anybody*, to establish and maintain the infrastructure.  For example, you could enlist a well-known technology company to do it, but this would offend the refined aesthetics of the vaguely Marxist but comfortably bourgeoisie hacker community who wants everything to be decentralized and who non-ironically believes that Tor is used for things besides drug deals and kidnapping plots. Alternatively, the public-key infrastructure could use a decentralized 'web of trust' model; in this architecture, individuals make their own keys and certify the keys of trusted associated, creating chains of attestation.  'Chains of Attestation' is a great name for a heavy metal band, but it is less practical in the real, non-Ozzy Osbourne-based world, since I don't just need a chain of attestation between me and some unknown, filthy stranger -- I also need a chain of attestation *for each link in that chain*.  This recursive attestation eventually leads to fractals and H.P. Lovecraft-style madness.  Web-of-trust cryptosystems also result in the generation of emails with incredibly short bodies (e.g., 'R U gonna be at the gym 2nite?!?!?!?') and multi-kilobyte PGP key attachments, leading to a packet framing overhead of 98.5%.  PGP enthusiasts are like your friend with the ethno-literature degree whose multi-paragraph email signature has fourteen Buddhist quotes about wisdom and mankind's relationship to trees.  It's like, I GET IT.  You care deeply about the things that you care about.  Please leave me alone so that I can ponder the inevitability of death."

@_date: 2014-08-13 14:43:32
@_author: Robert J. Hansen 
@_subject: FAQ change, final draft 
No, because that's the first time anyone's asked that question on the list -- so it's not a frequently asked question.  :)
Beats me, you'd have to ask Werner, I have no involvement with the code, and I can't even tell you which curves I'd personally recommend.
Due to my father being a U.S. federal judge, I think a lot of the GnuPG community would react very badly to me ever touching the GnuPG code.  In deference to their wishes, I limit myself to maintaining the FAQ and answering routine questions.  "Which curves will we use and why?" is not within my remit.  :)

@_date: 2014-08-13 22:32:05
@_author: Robert J. Hansen 
@_subject: FAQ change, final draft 
The questions experts think will be frequently asked are usually rarely
asked.  :)

@_date: 2014-08-14 09:50:33
@_author: Robert J. Hansen 
@_subject: FAQ change, final draft 
So far nobody's asked that question, either on the mailing list or to me personally, so ...
Weird as this may be to hear, I actually want to keep the FAQ small. The point of a FAQ is not to be a comprehensive resource: it's to answer *frequently* *asked* *questions*.  For comprehensive resources, people should read the manual...

@_date: 2014-08-14 09:59:02
@_author: Robert J. Hansen 
@_subject: FAQ change, final draft 
I haven't heard any big objections, so I think it's good for inclusion, yes.  I'd suggest removing 11.1 and replacing it with that content.

@_date: 2014-08-15 12:54:29
@_author: Robert J. Hansen 
@_subject: ICMP 
Whether it's a misconfiguration depends entirely on whether the
administrator intends this behavior.
It *is*, however, non-RFC-compliant.  Not that I think this matters much.

@_date: 2014-08-15 13:27:29
@_author: Robert J. Hansen 
@_subject: ICMP 
I agree with everything Doug wrote except this.  I may be insisting on usual semantics for "misconfiguration," though.  I am generally of the opinion that when someone deliberately configures something in a foolish way, well -- that's folly, not a misconfiguration.

@_date: 2014-08-15 16:33:47
@_author: Robert J. Hansen 
@_subject: (OT) Re: ICMP 
You'll notice I'm not disagreeing with you on anything.  :)

@_date: 2014-08-15 16:35:51
@_author: Robert J. Hansen 
@_subject: ICMP 
Yow, did I actually write that?  Time to go drink coffee directly from the pot.

@_date: 2014-08-16 19:08:29
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
Meh.  Color me unimpressed.
* "PGP keys suck."  No, asymmetric key infrastructure sucks in general.
 OpenPGP provides no infrastructure, only tools with which to build
infrastructure.  If your organization doesn't build its infrastructure,
that's not OpenPGP's fault.
* "PGP key management sucks."  Sigh.  Ditto.
* "No forward secrecy."  Not everyone needs PFS, and frankly, obsession
with PFS is one of those things I really wish people would grow out of.
 Before complaining about what OpenPGP needs or where it's lacking, try
looking at where OpenPGP has been broken in the real world.  Hint: PFS
ain't a panacea.
* "The OpenPGP format and defaults suck."
Good Lord, no.  As Jon Callas pointed out recently on the OpenPGP
working group list, there's a big difference between what the standard
*requires* and what implementations are encouraged to *use*.  Most
implementations have moved far beyond minimal conformance with the
standard.  The standard exists so that there is a common minimal core
that all clients can conform to: the reality is the two biggest players
(PGP and GnuPG) both go *far* beyond the defaults.
* "Terrible mail client implementations."
Again, unimpressed.  Consider his criticism that most OpenPGP-enabled
mail clients store passphrases in memory for longer than he'd like.
Well, one, this is easily configurable via gpg-agent, and two, *so
what*?  If an attacker is in a position where he or she can read
arbitrary memory locations on your PC, you're completely screwed anyway
and there's nothing OpenPGP can do to help you.
* "So what should we be doing?"
I'd start by ignoring the recommendations.  Do your own homework on
where OpenPGP fails and how, and start thinking about how to fix those.
 The author falls into the trap of knowing how to fix A, B, and C, and
so he wants to fix A, B, and C, without realizing the real problems are
X, Y and Z.
OpenPGP's biggest problem, BTW, which goes *completely unmentioned* in
this blogpost: OpenPGP can't protect your metadata, and that turns out
to often be higher-value content than your emails themselves are.
Further, exposed metadata is inherent to SMTP, which means this problem
is going to be absolutely devilish to fix.

@_date: 2014-08-17 01:05:52
@_author: Robert J. Hansen 
@_subject: Fwd: It's time for PGP to die. 
More or less, yeah.  Someday I'm going to wind up getting frustrated to
the point where I write an angry, bitter, ranty screed on how the
biggest headache with OpenPGP is unrealistic expectations and demands on
the part of people who claim to know better, but obviously don't...

@_date: 2014-08-17 16:42:52
@_author: Robert J. Hansen 
@_subject: Fwd: It's time for PGP to die. 
Speaking only for the U.S., this is not the case.
The United States Constitution protects an individual's right not to
testify against themselves.  If the production of a passphrase would
have any kind of testimonial value, then such production cannot be
ordered.  The only time production of a passphrase is permitted is when
it lacks any testimonial value.
Many people look at one particular case and say, "hey, production was
required in that case, clearly the U.S. can compel you to produce!", or
"production wasn't required in that case, clearly the U.S. can't compel
you to produce!"  The reality is different.  You need to look at the
role the production serves.  Testimonial in nature?  Nope, forbidden.
Non-testimonial?  Yep, permitted.

@_date: 2014-08-17 17:14:51
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
"Completely ignorant" is an overstatement.  Few people today are
completely ignorant about software and hardware.  Most people do not
have the sort of knowledge about computers that I'd like, but... you
know what I realized a few weeks ago?
I was watching a janitor mop a floor... without leaving footprints in
anything.  It struck me because I mopped my kitchen floor recently and
wound up with soapy water all over my shoes and tracked it through some
of my apartment before I realized what I was doing.  I mean to go back
to that janitor sometime soon and ask him, "hey, man, you look like you
know how to mop a floor correctly: what am I doing wrong?"
The janitor probably doesn't know the minimum voltage to flip a
transistor (200mV, usually) and couldn't build an adder out of NAND
gates if his life depended on it.  I can't mop a floor without tracking
soapy water throughout my place.  Kind of puts in perspective which one
of us is the ignorant one, you know?
Saying "most people today know very little about computers" is true, and
it deserves to be said.  But let's be real careful about thinking we are
in any way better than other people.  We're not.
Microsoft has a *ton* of security features built into their operating
systems.  Post-XP, Microsoft radically overhauled their kernel and
started enabling a ton of useful features.  DEP, ASLR, enabling some of
the cool security features of the x64 architecture...
In the XP and Win2K days, yes, Microsoft's security was a joke and it
deserved to be mocked.  It has not been that way for several years now.
Considered reading any of the available peer-reviewed papers that have
explored why this is the case?
No, Microsoft doesn't.  Walk into a Best Buy, a Fry's Electronics, or
whatever store you choose, and it's *easy* to find hard drives that
aren't pre-loaded with Windows.
Then fork the source code and code up your own vision.
So what?
If a new email cryptography standard comes out that's significantly
better than GnuPG, do you think Werner is going to sit around drinking
Tanqueray straight out of the bottle because nobody's using GnuPG
anymore?  I don't.  I think he'll cheerfully send GnuPG off into
maintenance, applaud the new standard, and volunteer to help with a free
implementation of the new standard.
If GnuPG dies out because nobody cares about privacy, I'm not going to
mourn the loss of GnuPG.  I'm going to mourn how nobody cares about
privacy any more.
GnuPG is useful and good only to the extent that it is a useful and good
thing for human beings.  *People* are the important thing.  The authors
hope GnuPG will help people.  But, by itself, GnuPG is ... really rather
When (not if) GnuPG dies out, the only question will be, "is this on
balance good for people?"  If so, then let's be thankful GnuPG existed,
celebrate its passing, and cheerfully move on.
The good ideas in computer science are overwhelmingly rejected.  The
ones that endure are usually really bad ones.  Compare the Intel 80x86
architecture against *any* of its competitors, for instance.  x86
Assembler makes me bleed through my eyeballs and beg for the sweet sweet
release of death.  It isn't MIPS or PA-RISC or PowerPC or any of the
literally *dozens* of superior architectures I've worked with over the
years.  And yet, x86 won in the marketplace.
I think everyone on this list who has more than ten or so years of
experience in the industry will have their own tales of technological
woe.  Good technologies get rejected, and then ten years later they get
rediscovered and renewed.
Look at VMS and UNIX.  UNIX won the server wars of the '80s and early
'90s and completely crushed VMS... up until VMS came back as Windows NT.
 Now, VMS has won the desktop, where UNIX is completely dead... except
for how UNIX got re-resurrected a few years ago as OS X, and as the Mac
desktop it's making a strong showing.  Good technologies rarely win, but
they almost always get re-adopted later.  It's a cycle.  :)
(No, I'm not kidding regarding Windows NT/VMS.  The parallels between
them are *profound*.  The same guy, Cutler, designed both, and the
Windows desktops that most people use nowadays are direct descendants of

@_date: 2014-08-17 17:55:13
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
Yes.  And somehow, I keep on getting soapy water on my shoes.

@_date: 2014-08-18 08:25:41
@_author: Robert J. Hansen 
@_subject: Fwd: It's time for PGP to die. 
That's one of the exceptions, yes.
Basically, if the fact you know something would tend to implicate you in
the commission of a crime, then you can't be compelled to reveal that
you know it.  Whether it's a passphrase or a safe combination makes no
There are a lot of nuances and exceptions here.  This isn't legal
advice.  If you need legal advice, ask a real lawyer, not an internet
mailing list...

@_date: 2014-08-18 08:31:40
@_author: Robert J. Hansen 
@_subject: Fwd: It's time for PGP to die. 
Johan, we're entering paranoid fantasy here.  If you truly believe the
whole of the USG is corrupt, and that our independent judiciary is in
cahoots with a corrupt Executive and Legislature in order to
systematically violate people's rights, well... then I think I'm going
to need to stop talking with you, which I regret.  :(

@_date: 2014-08-18 09:51:40
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
Nobody really cares what prosecutors view it as: the question is what they can get a judge to rule it as.
That said, the analogy is pretty much exact.  If the documents in the safe would incriminate you, and the government knows they exist and roughly what their contents are, then yes, you can be subpoenaed to provide them.  (If the government doesn't know they exist or generally what their contents are, the subpoena gets rejected as an illegal fishing expedition.)
If knowing the combination *by itself* would incriminate you, then you can't be compelled to provide.
For instance, let's say that a safe has been robbed.  There's no signs of forced entry or safecracking.  The government demands you cough up the combination, in order to prove that you had the means to commit the crime.  You object on grounds that proving you had the means to commit the crime would tend to implicate you in the crime.  The judge refuses the government's motion to compel you to produce the combination in court.

@_date: 2014-08-18 14:11:57
@_author: Robert J. Hansen 
@_subject: Fwd: It's time for PGP to die. 
Err -- *what* right to remain silent?  No country has a universal right
to remain silent.  If you're a witness to a crime, you can be compelled
to testify about what you see.  If you're in possession of documents
that are relevant to a police investigation, you can be ordered to
produce them, and so on and so on.  That's the subpoena duces tecum in a
nutshell, right there.
Keep in mind that the idea of a subpoena duces tecum is so
uncontroversial that it's been formalized in *two* separate Hague
conventions: the Hague Service Convention and the Hague Evidence
Convention.  If you don't have trust in U.S. law because we have the
subpoena duces tecum, you should have no more faith in Dutch law...
Been nice talking to you, Johan.

@_date: 2014-08-18 14:55:49
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
(Long anecdote, but I promise, it's relevant.)
I live maybe ten miles away from the world's largest firearms museum.
When I first moved to this area a couple of years ago I figured I'd take
a look around and see what it was like.  While there, I got the chance
to see an original M-16 rifle from *1959* -- before it had even been
accepted for military service.
The museum curator explained to me that the original rifle from 1959 was
the product of extremely strict requirements.  The strictest was, it
couldn't mass more than 2.7 kilograms.  The rifle was built to meet this
seemingly-impossible weight target, and many of the worst defects of the
rifle were in reality triumphs of engineering that let them reach this goal.
For instance: the M-16 feeds hot gases directly from the barrel back
into the action in order to tap some of that energy to cycle the action
and chamber a new round.  The AK-47 has the hot gases operate on a
piston, and the piston in turn works the action.  This has the effect of
the AK-47 being much more reliable than the M-16, since it isn't
channeling hot gas and gunpowder residue directly back into the weapon.
For the last 50-odd years, people have called the M16's direct gas
impingement operation "Eugene Stoner's biggest blunder."  The reality
was, the AK-47's piston-style arrangement is *heavy*, and they had a
2.7-kg weight limit... so by doing it this way, they saved about 200
grams of weight.  That's a big deal when your total allowed mass is 2.7
kilos.  That it had an unpleasant effect on the reliability, everyone
knew... but everyone also knew that if they hadn't done it, there's no
way they would've hit 2.7kg.
Today, when the basic M-16 model weighs in at 3.8kg (they waived the
2.7kg limit in the 1980s), it's easy to look at the defects and start
criticizing Eugene Stoner's biggest mistake.  When you've got a 3.8kg
rifle there's no excuse for direct gas impingement.  When your rifle is
3.8kg, the direct gas impingement can only be thought of as a terrible
But it didn't start out that way.
There's a big difference between saying, "this needs to die," and
"something better needs to live," I agree.
I find myself wishing, though, that before people said either of them
they would give more thought to why *this particular thing* came to live
in the first place.  Because I keep on thinking about that walk through
the National Firearms Museum, and seeing that old M-16, and hearing the
curator explain that everything people hated about it were actually
features demanded by the government, and it would have never been
adopted -- much less been so successful -- without those defects.

@_date: 2014-08-18 15:03:39
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
A U.S. appellate court recently ruled that inspections of laptop
contents at border crossings violated the Fourth Amendment.  It's
currently being appealed, but so far the tea leaves are the Supreme
Court won't touch it and will instead simply let the appellate decision
stand.  Just FYI.  :)

@_date: 2014-08-18 15:21:06
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
No, the Fourth Amendment protects all people within U.S. borders
equally.  Americans get no special protections over visitors to the country.

@_date: 2014-08-18 22:43:49
@_author: Robert J. Hansen 
@_subject: Fwd: It's time for PGP to die. 
Your examples which involve coercion are illegal, and the ones that are
legal do not involve coercion.
Not coercion.
Prosecutor: "We know you have an encrypted drive partition with a lot of
child porn on it.  Give up your passphrase and we'll reduce it to ten
counts of possession and drop the intent to distribute, and we won't
object to sentences running concurrently."
Defendant: "... that sounds really good."
Or, alternately, imagine the defendant is innocent of the charge:
Defendant: "I can't accept that deal.  I'm innocent of that."  (True: if
you're innocent of the charge, you're not allowed to plead guilty to it.
 You might be able to talk the judge into accepting an Alford, but it'd
be an uphill battle.)
Or, alternately, imagine the defendant is guilty, but only of eight
counts of possession:
Defendant: "No deal.  I'll take my risks in court.  Good luck producing
these 'thousands of images' you're talking about."
Grossly illegal, in violation of the canons of legal ethics, and will
get an attorney disbarred.  Don't confuse "Law & Order" re-runs with
real life.  The DA is allowed to threaten prosecution of only those
crimes the DA reasonably believes a person violated, and the DA is
expressly forbidden from using the threat of the death penalty to
persuade someone to taking a lesser sentence.
In your first example yes, in your second example no.
Don't get me wrong: prosecutors have a lot of power, and I personally
believe they have too much power with too little accountability.
However, it's not a de-facto state of tyranny, either.
As always, my best advice for people facing legal problems is "shut up
and get a lawyer."

@_date: 2014-08-19 09:48:01
@_author: Robert J. Hansen 
@_subject: So on & so forth 
They emphatically disagree with some of the key size limits.
To be blunt, it's made me lose a lot of faith in the developers.  In the grand scheme of things, it's hard to find *anything* less significant than whether someone uses RSA-2048 or RSA-8192.

@_date: 2014-08-19 14:49:37
@_author: Robert J. Hansen 
@_subject: So on & so forth 
Use of cert-digest-algo isn't really a problem unless you're needing
people running old PGP or GnuPG to be able to verify your signatures.
That's less of a problem than using digest-algo, which can easily
produce message traffic your correspondents can't read.

@_date: 2014-08-19 16:49:42
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
This is the last I will be contributing to this misbegotten thread.
The Supreme Court gets involved only rarely, but when they do, they
settle the argument with the finality of a nuclear strike.
Consider the Detainee Treatment Act of 2005, which Congress passed with
enthusiastic support from the Bush Administration.  This law claimed
that it had the right to strip the Supreme Court of jurisdiction to hear
any challenges to the Act.  The Court was not amused and in a 5-3
decision threw the entire Guantanamo Bay military commissions structure
out on its ear -- to hell with what Congress and the President wanted!
I could literally list *dozens* of cases where the Supreme Court told
Congress and the President "no" on subjects where Congress and the
President insisted they would only take "yes" for an answer.  In each
case that I'm aware of, the Supreme Court won the argument handily.

@_date: 2014-08-19 17:05:23
@_author: Robert J. Hansen 
@_subject: Fwd: It's time for PGP to die. 
Nope.  That's a trade.
Passphrase coercion is like so: "you will produce the passphrase, or you
will sit in jail until you decide to produce the passphrase, and we're
just fine if you sit in there the rest of your natural life, and once we
get the passphrase then we'll decide whether we want to prosecute you
further, and if we do then your time sitting in jail while deciding to
cough up the passphrase won't count against whatever prison term you
ultimately get."
What the prosecutor is offering there is, "you will plead guilty to
lesser charges, but I'm only willing to do this if you're willing to
show me the full extent of your illegal activities, so cough up the
passphrase so I can verify it for myself."
When you're facing coercion, you're not getting anything out of the
trade.  When you agree to something as part of a plea agreement, you do.
Or maybe you think that you should be allowed to get a plea deal just
by showing up, without cooperating with the State in any way?
The vast majority of prosecutors would not.  Some would, and in such
cases I think the doctrine of prosecutorial immunity should be waived.
Snark is not serious argument.
So what?  There are a bunch of prosecutors.  If even 1% of prosecutors
are corrupt -- which would make them on balance a bunch of saints by the
standards of the rest of society -- that's still a large number.  The
fact there are a large number of abuses is kind of unsurprising given a
country with over 300 million people.  It's the law of large numbers:
one-in-a-million events literally happen thousands of times a day.
You're the one who didn't know what an Alford plea was.  Just sayin'.
Please note: I'm not saying prosecutorial abuse doesn't happen, that
it's not a problem, or that we haven't vastly overcriminalized our civil
life.  But this paranoid fantasy some people have going, where they
believe *every* prosecutor is corrupt... that's just childish.

@_date: 2014-08-19 18:48:29
@_author: Robert J. Hansen 
@_subject: Fwd: It's time for PGP to die. 
In other news, water is wet, bricks are heavy, and politicians lie.
Yes, it's pure semantics.  It's *law*.  What, were you expecting
something else?  Wake up and realize the essential nature of what you're
talking about: law is *all about* formalism, syntax, semantics.  If you
think law is other than this, then -- well -- this conversation just
ceased being worth my time.  Discussing law with people who complain
about "semantics" is like discussing biology with Creationists.
The great thing about liberty is everyone has the right to an opinion.

@_date: 2014-08-20 08:53:50
@_author: Robert J. Hansen 
@_subject: It's time for PGP to die. 
Yes, as you could discover by checking interviews with their lawyers.
Of course, checking interviews with their lawyers might disturb your

@_date: 2014-08-21 09:54:17
@_author: Robert J. Hansen 
@_subject: Fwd: GNU hackers discover HACIENDA government surveillance and 
A little late to the party.  This sort of thing's gone on in the private
sector for at least six years -- that's when I first encountered a
business that continually portscanned the entire IPv4 address space,
service identification, and identification of known vulnerabilities
against those services.
Last I checked there were at least four businesses doing this, and
selling their results to anyone who could cough up $10K a year for a
Also note that, contrary to the FSF's press release, this isn't
government surveillance.  It isn't even surveillance in the usual sense
of the word.  If you run a public service like HTTP, how is it
"surveillance" for someone, anyone, to say "the server sixdemonbag.org,
located at IP address 111.222.333.444, is running FooHTTPD 3.17"?
That's like driving down the street and reporting on what colors
people's houses are and whether they have their garage door open.
Distasteful, sure.  But "surveillance" seems to mean something more:
someone listening in on things that you have good reason to believe are

@_date: 2014-08-21 11:41:40
@_author: Robert J. Hansen 
@_subject: Fwd: GNU hackers discover HACIENDA government surveillance and 
If it escalates to an intrusion, then yes, that's definitely surveillance in my book.  Compiling a collection of publicly available information is not.

@_date: 2014-08-21 11:43:26
@_author: Robert J. Hansen 
@_subject: [Announce] Libgcrypt 1.6.2 released 
Sure.  Read any of the emails that get posted to this list. Particularly, please note:
Go to that URL, scroll down to the bottom where you'll see "To unsubscribe from GnuPG-Users...", enter your email address, click "Unsubscribe," and you're done.  It's not hard.

@_date: 2014-08-21 19:16:15
@_author: Robert J. Hansen 
@_subject: Fwd: GNU hackers discover HACIENDA government 
So does the phone book, Wikipedia, and IMDB.  We don't call them
Name me any piece of non-trivial information which doesn't have the
potential to be used against someone.

@_date: 2014-08-21 22:17:30
@_author: Robert J. Hansen 
@_subject: Fwd: GNU hackers discover HACIENDA government surveillance and 
First, thank you for citing a definition rather than using a loose
handle on a notion.  I genuinely appreciate it!
It also means that a newspaper reporting on the outcome of a soccer
match is a surveillance program, since it influences the outcome of
gamblers who have twenty euros on the game.
I respectfully submit that once the definition is broadened that far,
the word ceases to have probative value.  But if that's the definition
people want to use, then I'll just shrug, register my objection, and
move on.  :)

@_date: 2014-08-22 14:03:04
@_author: Robert J. Hansen 
@_subject: email verification as casual checking? 
I think the first people to do this were at PGP Security (pre-PGP
Corporation; this was when PGP Security was owned by Network
Associates).  The PGP Global Directory worked basically this way.
Not necessarily so.  The RFCs define syntax for signatures, but not
semantics.  The semantics are left up to each individual user to determine.
Not only was it discussed, it was implemented and ran for years.  The
Global Directory may still be running, for all I know.
However, the Global Directory didn't really solve any of PGP's usability
problems.  Was it worth doing?  Yes.  Did it live up to the hopes people
had for it?  Not really.

@_date: 2014-08-27 12:15:09
@_author: Robert J. Hansen 
@_subject: Fwd: GNU hackers discover HACIENDA government surveillance and 
I see a couple, but much like Dan, I'm not optimistic about them.
The first is this: *stop talking about privacy*.  What people are
calling 'privacy' is really a large number of concepts which are all
being glommed together under the umbrella of 'privacy', but these
concepts may not all belong together at all.  Figure out what
*precisely* you're concerned with, and start talking about that -- but
"privacy" as a word has become so vague it's almost useless.  If we
can't describe precisely what we're afraid of losing, we're going to
lose it and we won't even be able to accurately tell people what we've lost.
The second is a more general observation: authority tends to behave best
when it's forced to submit to oversight.  Corporations behave best when
they're forced to answer to public shareholder meetings where anyone
with a single share to their name can demand answers -- and if they
don't get them, there's hell to pay.  Politicians behave best when
there's a free press following them around and asking them rude
questions.  Terrorists wear masks not to hide from the authorities, but
to hide from their own communities -- social oversight would make their
job impossible.  Unfortunately, oversight only works when those in
charge take it seriously.  We as a society would rather watch reality
television than television about reality: we'd rather watch _Big
Brother_ than C-SPAN hearings about whether government has become Big
The third is that those who *do* care, tend to care in deeply broken
ways.  I can't tell you how many times I've run into self-styled privacy
advocates here in the U.S. who are furious over how the U.S. has been
reading their email.  The only problem is there's very little evidence
of that occurring.  Reading email metadata, maybe, but not email
content.  When I try to explain that to them I usually find myself
wondering inside of two minutes why I ever bothered trying to bring fact
and reason to what is fundamentally an argument from passion and
emotion.  I have had people literally yell in my face over the
metadata-versus-content distinction.  When the front line of advocacy
appears to be detached from reality in one way, and the body politic is
detached from reality in another (reality television), well... how does
one fix this?
My reading of what Dan's said (I apologize, Dan, if I'm getting you
wrong) is that he sees no way to stop the technological assault.  I
don't think that's quite true, though.  If we were as a society to
suddenly say, "stop this, right now, let's establish some laws to
protect the essential core of privacy," we'd do it.
The problem I see is the old one of the Eloi and the Morlocks... and I
feel like an Eloi who fell down into the Morlock tunnels and spent just
barely enough time down there to get a sense of just how bad it's going
to be.  Now I'm waving my arms and screaming at the other Eloi that they
aren't going to like what happens when the Morlocks come, but nobody's
listening to me.  I'm getting in the way of the latest special about the
Kardashians, you see...

@_date: 2014-08-27 15:37:10
@_author: Robert J. Hansen 
@_subject: Fwd: GNU hackers discover HACIENDA government surveillance and 
Yes, absolutely.  If the problem is X and your advocacy loudly insists
that Y is happening, then you're (a) not solving X (although Y might
need fixing anyway), and (b) all the people you've persuaded to join
your cause will desert you as soon as they discover you were totally
As an example: malaria kills millions of children worldwide.  Imagine an
advocate telling people, "we must end malaria, and we can start by
getting these villages clean drinking water!", and getting tens of
thousands of people to donate money to the cause of drilling safe water
wells in the developing world.  Yes, preventable diseases caused by
unclean drinking water is a *very* serious problem, and yes, those wells
will almost certainly ameliorate some problems... but it will do
absolutely nothing to stop the spread of malaria.
How do you think people who bought into the advocacy, who believed they
were saving the world from malaria, will react when someone comes along
and tells them, "uh, the advocate was completely wrong, and although you
may have done some good for the eradication of, I don't know, cholera or
something, you've had zero effect on malaria"?
I'll tell you what happens -- an epidemic of cynicism.  And that hurts
us all.

@_date: 2014-08-27 21:52:08
@_author: Robert J. Hansen 
@_subject: Fwd: GNU hackers discover HACIENDA government 
For some individuals, yes.  For others, not so much.  While traffic
analysis is a tremendously powerful tool it does not apply to all
parties to equal degrees.
It was also part of why I used the metaphor that I did.  Malaria and
cholera are two different diseases that often are found in the same
populations and some of their symptoms mimic each other.  One is a
mosquito-borne parasitic disease, and the other is caused by unsafe
drinking water.  :)

@_date: 2014-08-30 15:06:21
@_author: Robert J. Hansen 
@_subject: default user and recipient 
Yes.  You may find the FAQ to be useful:
When using -e ("encrypt to"), you must also use -r ("recipient"), and -r
must come first.  You may also wish to use -s ("sign").  Personally, I
like to use the long form of the options, as I think it makes things
easier to read.  For instance, to encrypt a message for me you would type:
gpg --recipient 0xD6B98E10 --sign --encrypt filename.txt

@_date: 2014-12-01 10:16:36
@_author: Robert J. Hansen 
@_subject: Order/changing of subkeys derogates compatibility!? 
Then ensure you're testing it correctly by adding "pgp6" to your
gpg.conf file, or "--pgp6" to the command line, whenever doing anything
that involves PGP 6.5.8 interoperability.  :)

@_date: 2014-12-01 18:03:50
@_author: Robert J. Hansen 
@_subject: Order/changing of subkeys derogates compatibility!? 
I think that's a bit harsh: he was asking about interoperability, not
reporting a bug.
That said, in the main I agree with you.  If someone has a real need for
2.6 or 6.5.8 interoperability and upgrading isn't an option, then sure,
ask around.  But otherwise, I'd prefer it if anything pre-PGP 9 or
pre-GnuPG 1.2 could just be left on the ash-heap of history.

@_date: 2014-12-15 13:40:22
@_author: Robert J. Hansen 
@_subject: Thoughts on Keybase 
Keybase ( is trying to solve the Web of Trust problem in a new way.  They're currently in beta, but I was able to snag an invitation.  (I have no invites to give out, unfortunately.)  The following is just a write-up on how it works and what my impressions of it are.  You may find it interesting.  You may not.  :)
1.  SO WHAT'S THE PROBLEM WITH THE WoT?
In a nutshell, "everything."  In my own experience, the Web of Trust goes pretty much completely unused.  There are several reasons for this.   The first is that trust is intransitive: if Alice trusts Bob and Bob trusts Charlene, it doesn't necessarily follow that Alice trusts Charlene.  (I like to imagine that Alice and Charlene were competing for Bob's affections once upon a time, and that Alice still wishes Bob wouldn't trust that hussy.[1])
The dream of the Web of Trust is that trust chains would form and Alice would be able to trust Charlene's certificate as well as Doug's and Elaine's and all the way on through to Xavier, Yvonne and Zenobia. Unfortunately, it doesn't work that way.  If Alice trusts Bob, that means Alice has to trust all those people trusted by Bob... or even all those people trusted by all those people trusted by Bob... or even all those people trusted by all those people trusted by all those people trusted by Bob.  It gets impractical really fast.
In twenty years of using PGP and GnuPG, I've relied on the Web of Trust a total of something like six times.  It was a neat idea, but as far as general rollout goes it's been a dismal failure.
2.  OKAY, SO YOU CONFIRM EVERYTHING VIA VOICE.
Voice doesn't give us much confidence in identity.  Voice allows us to do out-of-band verification [2], but it doesn't let us confirm identity.   Most people think identity is something that gets proven by documents, but identity is actually a lot more nebulous than that.  I normally require two forms of government-issued identity documents before I'll sign a certificate, but I haven't seen two government-issued identity documents from my own mother.  That doesn't mean I think she's not my mother.  It means I've somewhere along the line done an identity verification that has nothing to do with documents.
3.  SO WHAT'S IDENTITY, ANYWAY?
In a phrase, identity is the name we give to continuity of agency over time.  Knowing who's responsible for something right here, now, in this moment, is all well-and-good, but it's also kind of trivial: "the person standing there with a smoking gun is the one who's responsible for the body on the floor."  Doesn't tell you very much, really.  But knowing that person is also "the person who bought a bagel at a delicatessen yesterday" and "the person who's driven a Peugeot to work every day for the last three years" and "the person who for the last several years has lived at this address" all builds up to give us a sense of *what choices this person has made* (agency) and *over what time frame these choices have been made* (time).
Once we have a concept of agency over time, that by itself is an identity.  A legal name specifies an agent, but not an identity. Identity requires history.  A track record.  A paper trail, as it were.
4.  SO WHAT'S THE RELEVANCE TO KEYBASE?
Keybase has given up on the Web of Trust and on using official government records to prove who people are.  Instead, proofs are established by *what you've done* (agency) and *for how long you've been able to do it* (time).
For instance, visit this website:
You'll see a list of several "what I can do"s.  Key 0xD6B98E10 has been used to sign a tweet containing an assertion of identity: "I am Rob Hansen, robertjhansen on Twitter."  Thereby, key 0xD6B98E10 has been bound to my Twitter social-media identity [3].  You can pull this tweet down from Twitter's own servers and verify the statement yourself; you don't have to take keybase's word for it.  (In fact, you probably *should* verify it for yourself.)
Likewise, I've made similar statements of identity for my GitHub account and for a couple of web pages I run.  These disparate activities comprise a record of things I have done (agency) over a time period (time), which is ... identity.
5.  BUT YOU'RE NOT REALLY PROVING ANYTHING!
It would be pretty foolish to think my legal name was Rob Hansen based solely on keybase, yes.  Keybase makes no assertion that someone is correctly representing their legal name.  But how many of us really care about that?  The more common use case seems to be that we want to know we're not being catfished [4].  I could be named Maurice Micklewhite and it wouldn't change the fact that I control that Twitter account, that GitHub account, or those webpages.  If the fraction of my identity that you care about maps well to that realm, then keybase is a pretty effective way to verify that fraction.
6.  FRACTIONS OF AN IDENTITY?
Sure.  People on this list know a completely different me than my parents do.  You're the only one who knows the fullness of the choices you've made over the course of your life: you're the only one who knows who you truly are when the chips are down.  The rest of us only ever get to see a fraction of the true identity.
7.  SO DO YOU SEE KEYBASE MAKING A BIG DIFFERENCE?
Given how miserable the WoT's adoption rate is, any improvement will be a big difference.  In its present form I don't see it as making a big difference to the world at large, though.  Right now keybase allows you to certify your Twitter, GitHub, Reddit, CoinBase, and Hacker News identities, as well as BitCoin addresses and any web pages you control.   For the geek cognoscenti that's great, but for the world at large it's not going to matter half a damn until and unless keybase gets either Google+ or Facebook on board.
8.  CLOSING THOUGHTS
It's a cool idea and worth looking into.    :)
[1] Americanism: "an impudent or immoral woman."  Generally considered rude, but not profane.
[2] Kind-of sort-of: most phone traffic nowadays flows over the network, so it's actually in-band.
[3] I rarely if ever use Twitter.  If you're a Twitter fiend feel free to follow me, but don't expect much.
[4] Americanism: "identity deception."

@_date: 2014-12-15 13:57:50
@_author: Robert J. Hansen 
@_subject: Holidays 
Just like in past years, I'm going to celebrate Christmas by making a donation to g10 Code for continued maintenance and support of GnuPG. Not only that, but from now until January 6 I'll match any contributions that *you* make, dollar for dollar and euro for euro, up to $500.  You can donate at the web site, you can hand the money to Werner in person, I don't care.
Merry Christmas to everyone, and a giant thank-you to all the contributors for putting together software worth supporting.  :)
(Why January 6?  Because that's the end of the Christmas season. Twelfth Night is the evening of January 5.)

@_date: 2014-12-15 14:40:40
@_author: Robert J. Hansen 
@_subject: Holidays 
That's an "ask my bank" issue.  On January 6 I'll ask Werner for how much I owe him, which I imagine he'll quote to me in euros.  I'll call up my bank, get that number converted to USD, and make an appropriate-sized donation.
Today the exchange rate is $1.25 USD = 1 EUR.  I don't imagine that rate will fluctuate wildly by January 6, but it'll probably vary some.
I don't.  This is a sum total.  If individual donations amount to $400 USD, then I pay out $400 USD, regardless of whether it's one person donating $400, four people donating $100, one person donating $100 four times, or whatever.
(And as a special bonus, if the space aliens from Zarbnulax are reading this, I'll match you guys two-for-one, but only if you let me play with your quantum computers that can brute-force RSA in realtime.)

@_date: 2014-12-18 10:24:34
@_author: Robert J. Hansen 
@_subject: Refreshing private key 
> My current key is 2048 bits in length and I would like to have
 > something that is closer to 8192 bits in length. Is there a way that
 > I can accomplish this...
Definitely not from GnuPG, and probably not from without it, either.
GnuPG is capped at 4096 bits (for good reasons).
Further, you cannot change the length of the primary subkey on a

@_date: 2014-12-18 14:30:34
@_author: Robert J. Hansen 
@_subject: Refreshing private key 
Sorry, a little bit of inside baseball there [1].
tl;dr version -- Daniel's right.  Longer version follows.
At work I'm twiddling about with an OpenPGP parser and for various
reasons you really don't want me to get into, the class that defines
primary keys is a subclass of the class that defines subkeys.  It seems
backwards, but needs to be that way to preserve Liskov substitutability.
As a result, I wind up talking about "primary subkeys" because in my
head I'm talking about the PrimarySubkey class.  :)
[1]

@_date: 2014-12-19 12:19:02
@_author: Robert J. Hansen 
@_subject: Securing the future of GnuPG with BitCoin 
I suspect it's the opposite: it's not missing at all so much as it's
been considered and rejected.
BitCoin is more of a currency speculation scheme than it is a serious
currency.  Further, governments haven't quite figured out how to
regulate it yet -- what it should be taxed as, how it can be taxed, and
so on.
That large companies like Microsoft are beginning to accept BitCoin is
promising, but Microsoft has a large team of lawyers to navigate these
sorts of things.  GnuPG doesn't.

@_date: 2014-12-19 12:22:45
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG 2.1.1 released 
While we're on the subject -- it might be nice for GnuPG to be able to
issue proper Authenticode-signed Windows binaries.  Code signing
certificates are fairly affordable although the paperwork is a headache.
"It might be nice" doesn't mean "we should do this," of course.  :)
Just it might be nice, and maybe we ought think about it some.

@_date: 2014-12-20 19:32:19
@_author: Robert J. Hansen 
@_subject: File Encryption 
Have you considered either encrypting your /home directory (with
dm-crypt, LUKS, pick your poison) and/or using an encrypted folder
(TrueCrypt, etc.)?  Either of those would possibly be a much more
user-friendly experience.

@_date: 2014-12-26 22:28:42
@_author: Robert J. Hansen 
@_subject: File Encryption 
First, please don't respect my opinion on it -- I don't think I know
enough to have an opinion on it!
TrueCrypt has published source and a lot of people looking at it.  Prior
versions of TrueCrypt sometimes had appalling failures (what was it, in
5.3 it actually stored passphrases in RAM in cleartext), but current
versions seem credible.  I'm unaware of any published attacks on the
latest TrueCrypt, nor am I aware of any research indicating there are
numerous problems.  The code is a mess, yes -- but that's not by itself
evidence of a major problem.
Please don't read this as a recommendation.  It's more of a, "if you
need free software disk encryption for Windows then it's your only real
choice, and it doesn't appear to be an obviously stupid one."

@_date: 2014-12-27 14:26:31
@_author: Robert J. Hansen 
@_subject: File Encryption 
I do not personally find Gibson to be a credible commentator.  He's made
a lot of really embarrassing brainos over the years -- like when he
predicted that TCP raw sockets would be the coming of the Information
Apocalypse.  There have been lots of other examples.  Check out his
Wikipedia page under "Controversies"; these have all been errors of such
magnitude that I'd be wearing a paper bag over my head.
I know a lot of people listen to him, but ... frankly, I do not have a
high opinion of his skills and commentary.

@_date: 2014-12-31 09:31:31
@_author: Robert J. Hansen 
@_subject: photo-ID 
The major problem is there is very little good advice about this, and what there is keeps changing.  For a long time the PGP Desktop product used 120x144 as a picture size.  Back when a high-resolution display was 800x600 it made a lot of sense; now, when my laptop has a 2880x1800 display, a 120x144 image is literally smaller than a postage stamp.
GnuPG adopted the photo-ID feature a few years later and technology had already progressed to the point where the GnuPG advice was 240x288.  That advice hasn?t changed in over ten years; it?s probably out of date by now.
With respect to what format should be used, the de-facto standard seems to be JPEG.
I personally don?t find photo ID to be a useful feature.  They?re too static.  The photo ID on my certificate, for instance, is almost ten years old.  If you need photo ID, a better route would appear to be something like keybase.io, which offers some neat tools for binding a certificate to photographs, social media accounts, and whatnot.

@_date: 2014-02-06 09:26:33
@_author: Robert J. Hansen 
@_subject: making the X.509 infrastructure available for OpenPGP 
Quite the contrary.  If there are no CAs, then no certificate possesses
any validity.
Don't confuse "OpenPGP doesn't need *external* CAs" with "OpenPGP
doesn't need CAs."  You are your own certificate authority in OpenPGP;
remove yourself as a certificate authority and no certificate will
possess any validity.

@_date: 2014-02-06 10:29:35
@_author: Robert J. Hansen 
@_subject: making the X.509 infrastructure available for OpenPGP 
You are free to redefine black as white while you're at it.
When you decide which certificates to accept, you are serving as your  own CA.  When you outsource this to someone else, that other person or  agency is serving as your CA.  But no matter how you slice it, there's  still a CA in the picture.

@_date: 2014-02-06 14:18:37
@_author: Robert J. Hansen 
@_subject: making the X.509 infrastructure available for OpenPGP 
You don't have a false statement so much as a logical paradox: when a  trader has no accountant, he is his own accountant -- structurally,  it's similar to 'the village barber shaves only those men who do not  shave themselves'; the statement nullifies its own truth.
Add the word 'external' before the first instance of 'accountant' and  you'll have a true statement.
Arguably, sure.  I'm not sure I'd go for that, but it has the virtue  of being a creative interpretation of commonly-accepted terms rather  than something completely heterodox.

@_date: 2014-02-27 22:23:42
@_author: Robert J. Hansen 
@_subject: key generation: paranoia mode - explicit random input 
You don't.
At some point you have to choose to trust something.  This is usually
your operating system provider.  If you can't trust your operating
system provider, then you're completely screwed and there's nothing
anyone can do to change this.
The question is not, "has GnuPG in distro XY been compromised?"
The question is, "should I trust distro XY?"

@_date: 2014-02-27 22:30:01
@_author: Robert J. Hansen 
@_subject: key generation: paranoia mode - explicit random input 
There are literally thousands of vectors.  Defending against *all* of
them is a deeply nontrivial task.  Sometime take a look at the
requirements for a SCIF: they're eye-opening.
It was always impossible.
If you really want a known non-compromised system, you have to set up
your own chip fab plant churning out low-transistor-count, hand-verified
IC designs made from six-nines silicon you personally smelted from sand
you personally mined off a beach.  It has always been this way.  It will
always be this way.

@_date: 2014-02-28 16:09:21
@_author: Robert J. Hansen 
@_subject: key generation: paranoia mode - explicit random input 
============================== START ==============================
It means that when people ask questions like, "But how do we know the
GnuPG in distro XY has not been compromised?", we give them clear,
matter-of-fact answers: you don't, but if you're serious about this
question you clearly need to use a different distro because the distro
has literally millions of ways to screw you over surreptitiously.
Your proposal tries to answer that question with, "well, use this
technique."  I've read your proposal and it doesn't seem like it solves
anything -- which I regret: I really wish it did.
Introducing stronger hash algorithms is easy to justify.  Introducing
new technologies that don't mitigate the problems they exist to solve...
not so much.

@_date: 2014-01-03 04:28:38
@_author: Robert J. Hansen 
@_subject: sign encrypted emails 
I'm going to cautiously disagree.  What we call "very naive users"
account for the vast majority of GnuPG users.
Unfortunately, that's as far as my disagreement goes.  I see what
Hauke's getting at, but I disagree that it really amounts to much of a
problem, or that his proposed fix would work.
The real problem Hauke's discovered is, "people generally don't have the
educational background to think formally and critically about trust."
Which is, well, true -- but that one's a hell of a hard problem to
solve.  Everything else (including "sign-encrypt-sign" schemes) amounts
to just ways to try to dodge the real issue.

@_date: 2014-01-03 06:21:05
@_author: Robert J. Hansen 
@_subject: sign encrypted emails 
I already did, in quite clear language.
You are trying to solve a social problem ("people don't have the
background to think formally about trust issues") via technological
means ("if we just change the way we sign...").

@_date: 2014-01-05 10:15:51
@_author: Robert J. Hansen 
@_subject: sign encrypted emails 
More to the point, he's solving the wrong problem and conflating policy
with mechanism.
GnuPG does not provide policy.  Policy is the responsibility of the
people using GnuPG.  All GnuPG provides is mechanism.
Your problem can be solved trivially by establishing a policy of,
"Encrypted messages must contain a notification within the signed
message body of who the message is encrypted for."
For many users this sort of policy is a good idea.  For the majority of
users it's overkill.  Why do you want a policy decision to be
permanently enshrined in GnuPG's mechanism?

@_date: 2014-01-05 10:27:12
@_author: Robert J. Hansen 
@_subject: sign encrypted emails 
There also seems to be something else at work here: an allergy to rigor.
GnuPG is most often used in a slipshod, half-thought-through manner.
People don't articulate a security model, much less establish a plan to
mitigate those threats, much less negotiate a policy with their
correspondents to mitigate threats held in common.
Sometime watch the movie _Crimson Tide_.  It's a good action film and
the central premise revolves around a message that violates policy.  A
nuclear ballistic missile submarine is given a legitimate order to
launch missiles at a Russian city.  While preparing to launch, the
submarine receives a second message telling them to abort the launch --
but due to forces beyond their control that message is received only as
a fragment.
The captain refers to the policy: "Any message that does not fully
conform to the policy must be completely disregarded."  The captain
insists on launching, since the last policy-conformant message was a
launch order.
The executive officer insists, "We received an abort signal; at the very
least we need to delay the launch until we can confirm it."  The
executive officer insists on deviating from policy.
I cannot think of the last time I saw a Hollywood blockbuster that was
built around what is, at its heart, a very technical question about how
high-security communications operate.  It's worth viewing.
The short version is -- if you don't have a policy established, you're
not going to be using GnuPG to provide its fullest amount of
communications security.  That policy also needs to tell people how to
handle messages that don't conform to policy.

@_date: 2014-01-05 11:45:25
@_author: Robert J. Hansen 
@_subject: sign encrypted emails 
It is a trivial fix; whether it is reliable depends on how committed
participants are towards enforcing policy.
Then why are we talking about this?
You are receiving useful comments.  You are choosing to disregard them.  :)

@_date: 2014-01-05 20:26:16
@_author: Robert J. Hansen 
@_subject: sign encrypted emails 
Hauke, at this point you've advocated your idea -- strongly -- and
you've received a general response that is not favorable.  Now, no one
is saying you need to give up on this idea: but if you want to pursue
this idea, you're going to need to implement it yourself.
The best way to prove us wrong is to write a patch that will implement
your idea.  Reality is the ultimate test of all new ideas; make it real,
put it out there, and let the marketplace of ideas choose.
But for now, I don't think you're persuading anyone into implementing
this for you.

@_date: 2014-01-23 10:20:32
@_author: Robert J. Hansen 
@_subject: time delay unlock private key. 
GnuPG doesn't make a brute force attack possible.
You make a brute-force attack possible by choosing a weak passphrase.   Choose a strong one.  It's really that simple.
Not really, although DKG gave you a good heads-up about the number of  iterations in s2k.

@_date: 2014-01-23 13:27:58
@_author: Robert J. Hansen 
@_subject: Revocation certificates [was: time delay unlock private key.] 
A "safe place" for a revocation certificate may be vastly different  from a "safe place" for a backup of your certificate.  For instance,  if you're married you may be completely comfortable storing a  revocation certificate in a locked desk drawer to which your spouse  also has a key, but you may not wish to leave a backup of your  certificate there.  In the event of divorce proceedings the worst your  now-aggrieved spouse can do is revoke your certificate; your spouse  won't have access to your private key as well.
And yes, a strong passphrase is still the strongest bar against these  backups being misused -- but unless you've got an eye-poppingly strong  passphrase, your best bet is to rely on denying attackers access to  the data as well as the passphrase.
(I've often told people I'd be happy to post my private key to this  mailing list in order to prove my claim that with a strong passphrase  you have nothing to fear -- I never said I wouldn't grab 32 bytes from  counts as eye-poppingly strong, I think...)

@_date: 2014-01-23 15:08:40
@_author: Robert J. Hansen 
@_subject: Revocation certificates [was: time delay unlock private key.] 
It is.  That's why that's not the threat being defended against.
The threat is against your spouse seeing you enter your passphrase.   It's very easy for roommates to discover each other's passwords and  passphrases; sometimes it happens by accident.  Everyone knows not to  enter a passphrase with a shoulder surfer around, but if you and your  spouse are sitting on the couch with your laptops open and you receive  an encrypted email, are you really going to tell her, "Sorry, honey, I  have to take this into the other room so I can enter my passphrase  without worrying about you spotting it"?
So long as there's marital bliss, you're perfectly safe.  You just  can't rely on that lasting forever.

@_date: 2014-01-23 16:38:19
@_author: Robert J. Hansen 
@_subject: Revocation certificates [was: time delay unlock private key.] 
With a nine-volt battery, a paperclip, and a USB cable that has only  one end -- the other is bare wires.  You wouldn't believe how  difficult it is to do the initial handshake, but once you've got it  down you can easily tap out oh, three or four words a minute.  For  speed, nothing else comes close.
My father gets on my case for using the nine-volt battery.  In his  day, they had a potato and a couple of wire leads plunged into it.   But really, technology marches on and we should all embrace battery  You are not the typical use case.  No one person is a typical use case.

@_date: 2014-01-24 09:09:13
@_author: Robert J. Hansen 
@_subject: his public key is 5 monitors high, and her same key is 1 ? 
Don't forget photo IDs, which can massively expand the size of a

@_date: 2014-01-29 10:52:26
@_author: Robert J. Hansen 
@_subject: MUA "automatically signs keys"? 
I suspect the majority of GnuPG and PGP users could not tell you what  a persona-level verification means.  Saying they appear to be  understood as X appears to me to be a dangerous bit of conjecture.

@_date: 2014-07-01 17:28:36
@_author: Robert J. Hansen 
@_subject: Calculating the Private Key 
Assuming you mean "RSA as used in GnuPG", it is not feasible with the
kinds of computers we know how to build.  It will take science-fiction
level breakthroughs in either engineering, mathematics, or both, to do this.
Same answer as above.
Nobody else does, either.  If you can prove that it's not possible to
solve the integer factorization problem in a reasonable time period,
then you'll have just proven P != NP and will be eligible for a cash
prize of a cool million dollars.  No, I'm not kidding.
The integer factorization problem (the math RSA is built upon) is
conjectured to be infeasible to break.  There is no formal proof of it,

@_date: 2014-07-01 17:42:33
@_author: Robert J. Hansen 
@_subject: Calculating the Private Key 
Dan Boneh has a really interesting paper showing that RSAP may not be
the same as IFP, yes.  But that paper exists on a very abstract plane:
my math is enough that I can read it and get the rough outlines and
understand the broad strokes, but I wouldn't want to make anyone think I
was any kind of an expert on it.

@_date: 2014-07-01 23:17:51
@_author: Robert J. Hansen 
@_subject: RSA or DSA keylength as an anti-spam feature 
Not really.  If you've got a hijacked botnet of 50,000 machines, what do
you care if the CPU gets pegged?  You're not the machine's owner.

@_date: 2014-07-03 23:54:39
@_author: Robert J. Hansen 
@_subject: Key distribution via NFC 
A good friend just gave me a handful of NFC tags that are capable of
storing about 400 bytes.  It's a convenient form factor: a cardboard
disk with an adherent backing, perhaps 2.5cm across.  Bring it close to
a mobile phone and presto, bang, it can access the 400 bytes.
This is too large to store an RSA or DSA2 certificate, unfortunately.
But it got me thinking that with the move to elliptical-curve crypto in
GnuPG 2.1, it might be interesting to think about the possibility of
using NFC tags for certificate distribution.  Keep an NFC tag on your
keychain.  If someone asks you for your certificate, you don't have to
trade a SHA-1 fingerprint -- just put down your keychain and let the
person wave a cell phone over it.
Obviously there are risks associated with NFC, and I haven't done any
real looking at the security model of NFC -- it's very likely there are
big things I'm overlooking.  But the ability to store 400 bytes, to
access it quickly and easily, and all in a tag that costs less than a
dollar and can be read with almost any modern smartphone, is kind of cool.
It might be worth thinking how this can be used.  :)

@_date: 2014-07-04 00:08:04
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
Sure, but it wouldn't take unless Bob had IDEA in his preference list.
If Bob's preference list is AES256 CAMELLIA256 3DES, then if Alice's
choice of IDEA will be ignored.  The choice of 3DES won't be, which is
why 3DES is relevant here.
I'm saying only that she puts 3DES ahead of Bob's preferred 256-bit
ciphers in her personal-cipher-preferences.
Bob is all about "I must have at least 256 bits of keyspace in all my
email!"  But Bob can't do that, because Alice can *always* degrade him
to 112 bits by choosing 3DES.  And since Bob is the target, and since
we're assuming the enemy is well-financed and professional and capable
of tricking people, Bob needs to stop thinking he can somehow guarantee
256 bits of keyspace in his emails.
Bob can guarantee 256 bits of keyspace in *what he generates*.
Bob cannot guarantee 256 bits of keyspace in *what he receives*.
Telling people to use extremely large keys because "then your
correspondents will be using RSA-ungodly, which has an effective
something-ridiculous keyspace" sounds nice, but it's not true.  Bob can
only guarantee up to 112 bits of keyspace in the traffic that gets sent
to him, because Bob can't prohibit his correspondents from using 3DES.
Anyone who simply, glibly, says "use long certificates because they give
a larger effective keyspace," is committing fraud, IMO.  You're making
promises that aren't true and which you can't back up.
"Using long certificates *may* give a larger effective keyspace, but
really, you can only ever be certain of 112 bits of keyspace, so you
should design your security model such that it only relies on 112 bits
of keyspace" is accurate.  But I think if long certificates were to be
marketed that way, a lot of people would blink a few times and ask,
"well, what's the point, then?"

@_date: 2014-07-04 00:15:16
@_author: Robert J. Hansen 
@_subject: Key distribution via NFC 
Too *small*.  Sorry.  Time for me to go drink coffee straight from the pot.
Also, for Americans, happy Fourth of July.  :)

@_date: 2014-07-04 00:18:56
@_author: Robert J. Hansen 
@_subject: Key distribution via NFC 
Probably, but once you've got a dozen of these things they sort of stop
being a convenient form factor.  :)
Yes, but...
Remember why the keyservers exist: because when a key is several
thousand bytes it's pretty inconvenient to keep it with you.  Only
keeping a 40-hexit SHA-1 hash is much more convenient: give the
recipient that and let them look it up on the keyservers.
But what if giving them your key was as simple as putting down a
read-only NFC token and telling people, "there, scan that"?
It might be popular with the crowd that shuns keyservers, for whatever
reason.  ("I don't like spammers," "I think they're probably monitored,"
"I don't know the keyserver operators so how can I trust them," etc. --
many of these reasons are ridiculous, but that doesn't mean there aren't
a lot of people who hold those beliefs.)

@_date: 2014-07-04 01:19:42
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
It means Bob should have a line item for that in his security model.
"Alice may send me cleartext."
It also means Bob should have a line in his security model, "Even if
Alice correctly uses OpenPGP to encrypt her email to me, I can only rely
on 112 bits of keyspace."
I love this idea: "permits."  Who permits it?  When designing a system,
you must assume that anything that's not a game-over is under the
enemy's control.  You're relying on *the enemy permitting it*.
If I'm trying to break your traffic, Daniel, the last thing I'll do is
tackle even 80-bit crypto.  Seriously.  Life's too short.  But if I have
to, the very first thing I'll do is find a way to degrade you into using
an inferior level than your model expects.  I'll go after Alice.  I'll
find some way to convince her to shift to 3DES.  And just like that, I,
the enemy, will revoke your permission to have 256-bit crypto on the
Alice->you link.  You'll have 112, because that's what I'll allow.
According to one group; according to NIST, it's 112.  That's quibbling,
though: a factor of 2**9 is irrelevant.
Sure, but this requires me to compromise Alice's box and violates the
game-over assumption that the endpoints are secure.
Because (a) according to NIST they're equivalent, (b) nine bits is
irrelevant, and (c) if you check the archives you'll discover I've been
rather kind to RSA-3072; it's beyond that where I've always said "oh,
give me a break already."

@_date: 2014-07-04 01:24:53
@_author: Robert J. Hansen 
@_subject: Key distribution via NFC 
*Almost*.  NFC is significantly more convenient than fumbling with your
phone's camera app, taking a snapshot, etc.  Wave it and it's done.  NFC
has some interesting human interface engineering behind it.

@_date: 2014-07-04 02:49:37
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
This will be my last on the thread.
You've said several times that your interest is in making sure crypto
isn't the weak link in the chain.
Well, it's not.  We know it's not.  (And not just because of XKCD,
either.[*]).  Roughly one in four desktop PCs is already exploited.
Applications are a seething morass of Metasploit targets.  Physical
access trumps all and that the government is skilled at using Van Eyck
devices, black bag teams, subpoenas, national security letters, and more
to get what they want.  Organized crime has even fewer scruples and
nothing's off the table for them, including field expedient dentistry.
Given what a target-rich environment the net is, the difference between
a 3DES level of keyspace and an AES256 level of keyspace does not matter
a tinker's damn to whether your communications are safe.  I want to
emphasize this: the changes that you are passionately arguing about *do*
*not* *matter*.  And passionate argument about things that don't matter
is... bikeshedding.
No more bikeshedding.  My final statements about this thread:
* I've seen very little support from the list for your proposed
  best practices document,
* I conclude the community's sentiment is that the defaults are
  good,
* The FAQ will continue to recommend people use the defaults. [**]
[*] [**] as always, Werner gets final say!

@_date: 2014-07-04 02:51:10
@_author: Robert J. Hansen 
@_subject: Key distribution via NFC 
Given I've only been playing around with these things for the last few
hours, you'll have to forgive the occasional newbie mistake.  :)  But
damn, they're *neat*!

@_date: 2014-07-04 14:02:06
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
Excited, maybe.  Not worried.
I had an aunt that I was really close to.  She was diagnosed with
terminal, inoperable cancer in 1980 and given no more than three to five
years to live.  Two years later new oncological medicine dialed the
clock back and gave her another three to five years.  A few years after
that, it repeated.  Ultimately she died in 2005, twenty-five years after
her initial three-to-five prognosis, after outliving two of her oncologists.
She was a tough old bird.  But cancer still got her, and I'm still angry
at cancer over that.
So what you're saying is ... if huge quantum computers come to pass,
what you're worried about is your personal emails being readable by
someone who's spent the last fifty years laboriously archiving everything?
Man, I'm *welcoming* the future.  The possibility of using really large
quantum computers to efficiently do simulation of large, complex
phenomena -- like drug interactions with cancer! -- is so cool that if I
could, if I could wave a magic wand and drop computing technology from
100 years in the future on us right now, I'd do it in a heartbeat and
have a big smile on my face as I caused everyone's secrets to be exposed.
Because it would also mean we'd be a hundred years closer to curing
cancer.  A hundred years closer to curing HIV.  A hundred years closer
to being able to efficiently and quickly discover new classes of
antibiotics to fight the current drug-resistant regimes.  A hundred
years closer to...
Am I worried about the future?  Oh, heavens, no.  I'm greeting it with
my arms wide open and screaming at it, "Faster, please!"  And I think
you should, too.  I think all of us should.  Oh, yes, there will be
drawbacks to progress -- there always are -- but that cannot be a reason
for us to look at progress with anything less than awe and joyful
If you're using OpenPGP to secure things for 50+ years, you're using the
wrong tool.
PGP stands for Pretty Good Privacy.  Not perfect, and not 50+ years.
Just Pretty Good.

@_date: 2014-07-04 14:29:48
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
(For the record: at 39 I am close to outside of David's target audience,
but I'm still within it.  :) )

@_date: 2014-07-06 12:21:13
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
In point of fact, we don't know this.
Theoretically, science-fiction level breakthroughs in quantum
computation would break RSA.  But the problem with theory is some of the
things that theory permits turn out to be impossible in reality.  For
instance, there's nothing in the laws of physics that prohibit things
from having negative mass, but we've never encountered negative-mass
material anywhere: not in the lab, not in the world, not in deep space,
not anywhere.
It's good to be skeptical of quantum computation.  It's interesting to
read up on, but be immensely skeptical of all predictions.

@_date: 2014-07-07 18:11:36
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
It's been done a few times but without results, which is unsurprising:
on an atomic level gravity is ridiculously weak.  It's still being
researched.  Smart money is that antimatter has a gravitic attraction
just like regular matter: if it doesn't, a whole lot of our commonsense
notions of reality have to get thrown out.
Yes, but there's a big difference between saying "it is possible that
RSA will be susceptible to quantum computation in the near future, so
let's account for that in our threat model," and saying, "RSA is
susceptible to quantum attacks."
Reality should always be described as accurately as possible.  Threat
models should be constructed under a pessimistic interpretation of that
accurately-stated reality.  :)

@_date: 2014-07-08 00:31:54
@_author: Robert J. Hansen 
@_subject: Greetings everybody, new user here 
Welcome to the community!  We're a pretty friendly bunch here.  Hasn't
been any blood drawn in quite a while, honestly.  :)
With respect to delays in the keyserver network, the major address that
people tend to use (pool.sks-keyservers.net) is not a single box but a
confederation of them.  It's sort of like how when you visit google.com
you're visiting one of thousands of boxes configured to respond to that
address.  If by some chance you and your correspondent happen to hit the
exact same keyserver the propagation delay will be measured in
milliseconds.  Otherwise the certificate has to be propagated from one
machine's database to another.  This process, while normally very quick
(sub-minute), sometimes has problems.
Imagine there's Box A and Box B and then the Big Cloud of Boxes that
represents the keyserver network.  A gets all its updates from B, and B
gets its updates from the Big Cloud of Boxes.  If for some reason the
network link from A to B goes down, A will fall behind B (and the rest
of the Big Cloud of Boxes) in synchronization.
The good news is that most of the time propagation speed is extremely
fast.  Network problems do occur, but generally they're not significant
enough to be a major worry.

@_date: 2014-07-08 02:40:06
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
Nonsense.  What, you don't find quantum mechanics to be common-sense and
wholly intuitive?  ;)

@_date: 2014-07-17 21:02:06
@_author: Robert J. Hansen 
@_subject: symmetric email encryption 
But given the overwhelming majority of GnuPG users have an asymmetric
key, this is ... kind of pointless.
Besides, "if you already have a secure channel over which you can send a
key, why not just use that channel for your communications"?

@_date: 2014-07-18 13:49:54
@_author: Robert J. Hansen 
@_subject: symmetric email encryption 
Whoa, let's back that up a moment.
Fingerprints and symmetric keys need to be exchanged *as often as they
change*.  Which, in the case of symmetric keys, is quite frequently.
If/when a key is compromised, all traffic that has been generated or
will be generated with that key gets compromised, and there's no
guarantee about whether you'll know the key is compromised -- so it's
only sane to have an agreed-upon rekeying policy.  "Keys will be used
for three days tops", for instance, limits your exposure to a three-day
window, but it requires you to rekey every few days.
Key management is a killer problem.  If you don't take it dead seriously
it'll hug you and love you and name you George[*].
[*]

@_date: 2014-07-18 16:47:53
@_author: Robert J. Hansen 
@_subject: symmetric email encryption 
Same issue, although now you're sharing the seed to a random number
generator for which you want the seed to expire very quickly.  You can
mitigate this somewhat using gating and some other RNG tricks, but
fundamentally it's the same problem: once the passphrase goes, the
security of the entire system goes, so therefore change the passphrase

@_date: 2014-07-18 22:51:13
@_author: Robert J. Hansen 
@_subject: symmetric email encryption 
Immensely.  An asymmetric key is a secret held by one person; a
symmetric key is a secret shared by two or more.
If you're not interested in providing real solutions, then I'm not
interested in having this conversation.

@_date: 2014-07-19 13:55:45
@_author: Robert J. Hansen 
@_subject: symmetric email encryption 
Yes.  A secret that only I know I can keep; a secret known to two people
can only be kept for a while.  Yes, that's an immense difference.

@_date: 2014-07-19 20:08:22
@_author: Robert J. Hansen 
@_subject: symmetric email encryption 
When technically savvy people make guesses about the "typical use case,"
we are usually wrong on levels we don't even imagine.  This is why real
usability studies with real users are essential.
At any rate, no one is telling you that you can't do this.  All you've
heard is that you've not convinced other people to implement it for you.
 The GnuPG and Enigmail sources are both freely available: start
hacking.  If you're right and people start using this in droves, I'll
cheerfully be the first one to admit I was wrong.
With this, I'm out of this thread.  :)

@_date: 2014-06-01 21:10:38
@_author: Robert J. Hansen 
@_subject: import from decimal 
Usually when people ask "is there some way," they really mean "is there
some easy way which a non-programmer can do."
Is there some way?  Yes.
Is there some easy way which a non-programmer can do?  No.
Sorry.  :(

@_date: 2014-06-02 11:40:25
@_author: Robert J. Hansen 
@_subject: Why create offline main key without encryption capabilities 
The government wants you to do X; you're apparently not complying;  you're now before the judge who has to decide whether the government  has the power to make you do X.  The judge doesn't care about the  third way you're proposing: the judge is only concerned with whether  the government has the legal power to make you do X.  That's it.   Nothing else.
If you want to negotiate with the government then you can do that  outside the courtroom.  Within it, all you are allowed to do is argue  your case ("the government does not have the authority to make me do  My standard ten-part advice for court appearances still holds true.   One, hire a lawyer to speak for you.  Two, shut up.  Three through  ten, see rule

@_date: 2014-06-05 06:42:43
@_author: Robert J. Hansen 
@_subject: New user needs some help 
This is overwhelming overkill for most users.  Most users will be
best-served by typing "gpg --gen-key" and using the defaults provided.
Likewise with the gpg.conf file.

@_date: 2014-06-11 09:03:03
@_author: Robert J. Hansen 
@_subject: adele 
I believe John Clizbe has a copy of the Adele source code.

@_date: 2014-06-13 02:13:45
@_author: Robert J. Hansen 
@_subject: adele 
Stacy Andrews, used to be an offensive lineman for the Cincinnati
Bengals.  Stacy Peralta, an actor from one of my all-time favorite
movies (_Real Genius_).  Stacy Compton, owner of Turn One Racing and a
former highly-ranked race driver.
I agree it's a rare name, but it's not unheard-of.
In the U.S., it's almost always Leslie.  The only Lesley I've ever met
was an Australian.
I drive a charcoal-black Mustang GT, and much like the Biblical Delilah,
oh brother, does she ever tempt me into doing things I know I shouldn't.
 The name makes *exquisite* sense to me...
[*] The song's probably older than that, but Blind Willie Johnson had
the first recording of it in 1927.  In the '70s it became a staple of
Grateful Dead concerts, and then Springsteen started to include it in
his concerts.  Recently, Shirley Manson made a heavy metal version of it
that's musically excellent, but it's theologically incoherent -- it does
no justice to the story of Samson and Delilah.

@_date: 2014-06-15 17:27:39
@_author: Robert J. Hansen 
@_subject: Docs central, with 'Email Self-Defence' 
Impractical, perhaps.  Good tech writers are rare; good tech writers who
understand the intricacies of crypto and communications security are
moreso; good tech writers who understand the intricacies and who are
willing to keep everything up-to-date while not getting paid a dime for
it are so rare as to be virtually nonexistent.

@_date: 2014-06-15 17:45:42
@_author: Robert J. Hansen 
@_subject: Docs central, with 'Email Self-Defence' 
Definitely.  Keeping up-to-date with the most recent versions, with new
features, with security advisories, etc.
Imagine if someone were to have written comprehensive and detailed
documentation for GnuPG 2.0, and how much of it would need to be
rewritten for the introduction of ECC into GnuPG 2.1.

@_date: 2014-06-16 20:36:01
@_author: Robert J. Hansen 
@_subject: Fwd: Using gpg to sign database information, 
Please don't do this.  Use gpgme-sharp instead.  (It will require
compiling your assembly as a 32-bit app, but this is normally not a big

@_date: 2014-06-17 08:20:01
@_author: Robert J. Hansen 
@_subject: mascot_p 
I'd go for Terry, the Tinfoil-Hatted Terrapin, myself.  :)

@_date: 2014-06-17 09:45:03
@_author: Robert J. Hansen 
@_subject: mascot_p 
First -- yes, I would love to see Terry the Tinfoil-Hatted Terrapin
become our mascot.  We've got a very businesslike logo; a mascot is an
opportunity for playfulness.  And what better way to poke a little
good-natured fun at ourselves?
Second -- okay, if the Tinfoil-Hatted Terrapin strikes a little close to
home (maybe some of us *are* terrapins: certainly, though, no one on
this list could ever be accused of wearing a tinfoil hat), I'd propose
something else entirely: the coelacanth.  Why?  Well, because I've got
this really weird and inexplicable fondness for them.  They're a fish
that's been around for 400 million years or more, has basically given
evolution the middle finger and dared Darwin to kill it off more times
than a Bruce Willis action movie, and ... well ... it has *style*.
The coelacanth also suggests Time, big-T Time.  (Like 400 million years'
worth.)  Given how often we wind up talking about brute-force analysis
and the megayears and megatons required and how much of an
extinction-level event it would be, a fish that's survived four hundred
megayears and several mass extinctions would be ironically appropriate.
Here, have a cool photo of a coelacanth:

@_date: 2014-06-17 15:14:53
@_author: Robert J. Hansen 
@_subject: mascot_p 
The Algonquin tribe of Native Americans, originally living in Virginia,
had a word for turtle: "torope".  American settlers adopted this word
and over the last 400 years it's been corrupted into "terrapin."  As a
result, "terrapin" has become a common American synonym for "turtle,"
but the word's rarely used in the rest of the world.

@_date: 2014-06-17 16:22:11
@_author: Robert J. Hansen 
@_subject: mascot_p 
Huh!  Learn something new every day.  If you have a source for that, you
may wish to edit the Wikipedia page for turtles, which does not make
that distinction.  (Wikipedia, wrong about something?  Imagine that...)

@_date: 2014-06-21 17:57:41
@_author: Robert J. Hansen 
@_subject: Compiling GnuPG for Windows 
I'm not aware of one.  There are a few that are somewhat to completely
out-of-date, but nothing that's current.  The official way to compile a
Windows version of GnuPG is to cross-compile from a Debian system.

@_date: 2014-06-23 13:30:07
@_author: Robert J. Hansen 
@_subject: Compiling GnuPG for Windows 
We would appreciate it if you would list the bugs, annoyances,
documentation errors, and incompatibilities you found.  Or even just
some of them.  We'd like to fix them.
I've seen PGP 10.x running on 64-bit Windows in WOW64 mode.  You may
want to consider going that route.

@_date: 2014-06-24 11:39:00
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
I'll go one step further: I think the article is going to do more harm
than good.
When young people ask me where to begin programming, I tell them to just
begin.  Don't worry about whether Javascript is better than Python or C
or anything else: just find something they think is neat and start.  The
most important thing for them is to begin, and the second-most important
thing is for them to finish what they begin.  Only later, once they're
well and truly on their way, should they start worrying about technical
The same applies here.  The most important thing in using GnuPG is that
people begin using it; the second-most important thing is that they keep
on using it.  Guides such as these may ultimately do more harm than
good, in that they tend to lead new users into thinking they *have* to
do all these things, daunting and maybe even scary things (and let's be
clear: there's a lot of opaque terminology and technical jargon there!),
in order to effectively use GnuPG.
Which just isn't true.
The best practice for GnuPG: --gen-key and find a plugin for your email
client.  Everything after that needs to be relegated to an advanced
class.  There's nothing wrong with advanced material: advanced material
is great.  But let's not go about scaring newcomers by making them think
they need to do and understand all of that.

@_date: 2014-06-24 13:52:25
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
This depends on what you mean by recommended, and why.  The last time I
checked it wasn't possible to use DSA2 keys to sign a Linux RPM file,
for instance.  Likewise, there are smartcards that don't support DSA2,
and so on.
But if you're not using one of those niche applications then there's
really not much difference worth mentioning between RSA2048 and DSA2048.  :)

@_date: 2014-06-25 16:58:16
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
Yes.  We are world champions at beating dead horses.  To interrogate a
horse, first simply shoot it in the head, and then we can leverage our
dead-horse-beating skills in order to do enhanced equine interrogation.

@_date: 2014-06-26 10:26:43
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
Although I'm going to be (almost wholly) agreeing with John here, I'm
speaking just for myself.  If anyone wants to chime in with a
"d'accord," that's on them.  :)
What gets me about the RSA-2048/-3072/-4096 debate is how (largely)
pointless it is.  Per NIST, RSA-2048 has about a 112-bit effective
keyspace and -3072 has about a 128-bit effective keyspace.  There is no
official NIST recommendation for RSA-4096, but the cryppies I've spoken
with at conferences ballpark it at somewhere around 140 bits of
effective keyspace.
Now for the kicker: *no one* is guaranteed more than 112 bits of
effective keyspace in the emails they receive.  No one.  Even if you use
a hacked-up GnuPG and RSA-16384, you're deluding yourself if you think
you're guaranteed your emails will have an effective keyspace of 256 bits.
The reason why is four letters long: 3DES.  3DES, which is an
always-accept algorithm, has a keyspace of 112 bits[*].  Someone can use
your RSA-16384 key with 3DES and bam, the effective protection of your
email is down to 112 bits.
So in a very real sense, anything past RSA-2048 is at best a "you
*might* get some additional security, depending on what symmetric
algorithm your correspondent uses.  Oh, and you can't forbid your
correspondent from using 3DES, either."
I think it's funny how the people who advocate moving to RSA-4096 by
default generally don't talk much about how it is impossible to
guarantee more than 112 bits of effective encryption keyspace for an
email message.  Will it give you a stronger signature?  Maybe.  But it
very possibly won't give you any stronger encryption.
Now, this isn't to say there's no purpose in RSA-3072 or -4096.  Some
organizations have requirements that say "any encryption key we use must
provide 128 effective bits of keyspace."  In that case, if them's the
rules, then sure, use RSA-3072, it meets your requirements.
But for the people who advocate "let's shift to RSA-4096, it gives us
about an effective 32 bits more than RSA-2048!", well... I really wish
they'd talk about the drawbacks (can't use on a smartcard, may cause
problems for mobile devices, etc.) and the inherent limitations of
OpenPGP (can't guarantee more than 112 effective bits of encryption
So, in summation: I think the RSA-2048/-3072/-4096 debate is utterly
pointless.  To the extent I have any strong feelings on it at all, it is
this: you are less likely to delude yourself about the strength of the
system if you use RSA-2048.
[*] ... against an adversary with access to more computing power than is
likely to ever exist in the world, true; but 112 bits nevertheless.

@_date: 2014-06-26 11:18:24
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
This is, IMHO, a complete nonissue.
If your adversary has the ability to brute-force a 112-bit keyspace,
then you are now living in a world where crypto cannot protect you.

@_date: 2014-06-26 11:39:13
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
If that's your criteria, RSA-1024 is sufficient.  Real systems are so
exploitable that crypto is never the weak point.
I have.
It must be nice to live in a world where you have unlimited resources to
direct to such efforts.
Pick and choose your battles.  At even RSA-1024, crypto is not going to
be the weak link in your system.  If your criteria is truly, "make sure
that crypto is not the weak link," then this entire discussion is moot:
any certificate GnuPG creates will do.

@_date: 2014-06-26 16:06:25
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
I've been writing and rewriting this several times now: I'm not sure if
I've found diplomacy here, but there comes a point where you have to say
"screw it" and hit send.
Four of the best guiding principles I've found are:
One of the justifications you give for your faith in increased key
lengths is "[RFC4880] also encourages people to advertise preferences
for stronger ciphers, so correspondents using tools which respect those
advertised preferences (like GnuPG) *will* get the increase in strength
But see  above, though.  The bad guys will degrade your system in the
most damaging ways possible, subject to the assumptions we make in Since it's possible to degrade the cipher preference to 3DES, we need to
assume that's exactly what will happen.  (Your next objection is "How?".
 That's a non-sequitur right now.  I believe serious adversaries can do
this because (a) there's no mechanism to prevent them from doing it, and
(b) system degradation is such a bog-standard attack vector that I can't
believe they haven't already thought up ways.  Whether *I* have thought
up ways is irrelevant.)
People should feel free to use cipher preferences, but they shouldn't
have any expectation that it matters a damn.  The most you can guarantee
out of it is 3DES with 112 bits of keyspace: everything beyond that is a
gift from your enemy.  If your security model depends on using
Camellia256, then you need to use something other than OpenPGP, because

@_date: 2014-06-26 17:36:45
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
Nope.  :)  I meant what I said.
The preference list on the key is advisory, not binding.  There's
nothing requiring an implementation to even look at the preference list
on the key.  For any OpenPGP certificate, you can send it 3DES-encrypted
traffic and be in complete accordance with the spec and the recipient's
A conformant implementation MUST choose a cipher that is listed in the
certificate preferences, but (a) the spec is completely silent about
*which* preferred cipher should be used, and (b) the spec guarantees
3DES will always be a preferred cipher.
This is why I've always pushed to call them capability sets, instead of
preference lists.  The spec doesn't guarantee they'll be treated as
preference lists.  The spec only guarantees they'll be treated as a
capability set.

@_date: 2014-06-26 17:45:01
@_author: Robert J. Hansen 
@_subject: On the advisability of stronger digests than SHA-1 in OpenPGP 
PGP 8.x, which is still in use today by a surprising number of people,
has limited support for SHA-256 and none at all for SHA-512.

@_date: 2014-06-26 18:07:18
@_author: Robert J. Hansen 
@_subject: On the advisability of stronger digests than SHA-1 in OpenPGP 
And yet, it still conforms (largely) to RFC4880.  Methinks you're
objecting because it's a largely-conforming implementation that doesn't
have good support for SHA256.  ;)
If I recall correctly, it can understand SHA-256 but not generate
SHA-256.  SHA-256 generation support was added late in the 8.x series,
but earlier 8.x releases could understand it.
It's not as if there are Nielsen ratings for these things.  All I can do
is say that I still regularly encounter it when I talk to people about
PGP.  For instance, I know of one law firm that purchased a site license
for 8.x and refuses to upgrade, since the more recent editions cost a
fortune in per-seat licenses and have very little in the way of new
Because there are still people using it.
Remember, GnuPG also supports most of RFC1991 because we've got a large
base of PGP 2.6 users who are refusing to upgrade...

@_date: 2014-06-27 17:02:01
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
It took me about fifteen seconds to come up with a way to do this with
acceptable (if not-100%) probability of success and acceptable (but
extremely low) probability of intercept.
Tomorrow I'll post my method to the list.
If I can come up with a method to degrade things to 3DES in fifteen
seconds, then I believe the people who do this stuff professionally have
spent at least a few weeks inventing and perfecting other methods.

@_date: 2014-06-27 19:35:12
@_author: Robert J. Hansen 
@_subject: On the advisability of stronger digests than SHA-1 in OpenPGP 
Be careful about that phrase "legacy."  Too often it's used as a slur.
It's more accurate to say, "PGP installations in corporate
environments."  There's no reason to think these installations are
closed, or that the IT departments are being unreasonable.
Just because they're not doing what you think they should doesn't mean
they're not playing with a full deck.
The "since" is probably inaccurate.  Group 1 can afford to keep using
PGP 8.x because it meets their needs.  They don't upgrade because it
doesn't make business sense to do so.
You may not exchange emails with corporations; many other people do.
That's a subtle rephrasing of the position -- and an inaccurate one.
SHA-x should not be used *by default in places where it would break the
spec*.  But no one is saying that SHA-x should not be used, period, nor
is anyone saying that if after careful deliberation you decide that
breaking the spec is appropriate, that you shouldn't do so.

@_date: 2014-06-28 00:09:40
@_author: Robert J. Hansen 
@_subject: riseup.net OpenPGP Best Practices article 
Since it looks as if I'm going to be out of contact for the next few
days (traveling), I figured I'd share the degradation a little early --
Alice and Bob are communicating.  Bob insists on using extremely large
keyspaces: his certificate is RSA-16384 and his preference list is
AES256 CAMELLIA256.  Alice does not.  She's not naive or clueless: she's
a competent user who understands that Bob insists everything be
encrypted with an RSA-16384 certificate.
Charlene wants to degrade Bob to 112 bits of effective keyspace.  (Why?
 Beats me.  Let's say she's working for the Zarbnulaxian Intelligence
Service, and ZIS has tasked her with preparing the Earth for its
eventual domination.  To further this goal, ZIS has given her a quantum
computer one of them got from their kid's breakfast cereal box.  It
doesn't provide enough qubits to break RSA, but can attack 3DES.)
Charlene can't do anything to Bob.  She *can* do something to Alice.
The next conference Alice goes to, the next OpenPGP Birds of a Feather,
Charlene makes sure people there are talking about how 3DES is "really
the most-trusted cipher in all of OpenPGP."[*]  Charlene makes sure a
few well-written webpages get put up talking about how 3DES is really a
superior choice to AES256 because Cortois[**].  Ultimately, Charlene
arranges for Alice to meet someone else who's privacy-paranoid and
insists that Alice only use 3DES to communicate, because "that's the
only MUST algorithm in OpenPGP, it's the most interoperable, and because
it's been turning brilliant young cryptanalysts into burned-out
alcoholic wrecks for 30 years" [***].
When faced with that, it's only a matter of time until Alice decides to
put 3DES first in her own preference list.  And then all her
communications to Bob have 112 bits of keyspace, not the 256 Bob
demands.  And unless Bob is paranoid enough to check the symmetric
algorithm used on every single encrypted message, Bob will never know
that Alice's communications to him have been degraded.
Werner and others are absolutely right: there is no *technical* way to
degrade things to 3DES.  But given that cipher preference lists are
fundamentally a *human* decision, well... the human being is always
[*]   ... which is probably true.
[**]  ... of which I've seen several.
[***] ... okay, yes, Charlene paid me to hook up with Alice.  YOU
      DON'T UNDERSTAND HOW CRUSHING GRADUATE STUDENT DEBT IS, OKAY?

@_date: 2014-03-02 22:55:42
@_author: Robert J. Hansen 
@_subject: key generation: paranoia mode - explicit random input 
That, by itself, is a compelling reason not to do it.
A feature that will be used by under 0.1% of the userbase is a feature
not worth introducing.  The likelihood of introducing a bug which may
affect everyone is orders of magnitude greater than the limited benefit
that will be enjoyed by one user in a thousand.

@_date: 2014-03-13 12:22:03
@_author: Robert J. Hansen 
@_subject: Multiple Subkey Pairs 
Your proposed solution won't work.  Sorry to be so blunt, but that's  the state of things.
So far there's no credible reporting that any government is doing mass  surveillance of email content.  Instead, mass surveillance focuses on  metadata: who's talking to whom, when, with what for a subject line,  routed through which mail servers, and so on.  GnuPG does not and  cannot protect against that.
If your concern is mass surveillance -- which is to say, metadata --  you need to look at other technologies.  GnuPG will not protect your

@_date: 2014-03-14 09:06:40
@_author: Robert J. Hansen 
@_subject: Multiple Subkey Pairs 
They also deny being able to violate the Second Law of Thermodynamics:  is it thus perfectly reasonable to assume they can violate the other  "Just because they deny X means it's reasonable to believe Y" is logic  that will get you in a whole lot of trouble.  If you have evidence to  support your assertion I'm sure we'd all love to hear it -- but as I  don't believe such evidence exists, the most we can reasonably say is  "we don't know."
Let me tell you a story about Allan.  Allan was a great guy, one of  the true heroes of American government.  He never got the recognition  he deserved.  Allan was a veteran FBI agent with a Ph.D. in criminal  justice, with a thesis that focused on police corruption.  His life  goal was to someday get appointed as a federal judge.  He authored  part of the FISA Act.  Later in his life he was appointed by the  Attorney General to become the Department of Justice's gatekeeper to  the FISA Court.  All warrant applications had to go through him.
He thus had two compelling reasons to be strict about the warrants he  presented to FISA.  The first was that he hated corruption in a  deep-in-his-bones way.  The second was he knew that if he allowed any  inadequate warrants to be presented to the FISA Court, those  inadequate warrants would come up in Senate confirmation hearings for  the federal judgeship he wanted.  As a result, he had a reputation for  being harder to convince of a warrant than the FISA Court itself was!

@_date: 2014-03-14 10:28:55
@_author: Robert J. Hansen 
@_subject: Multiple Subkey Pairs 
Sure, just like someone being German would make them pretty biased  against Jews.
What I just said was insensitive, offensive, and completely  inappropriate.  So, too, was what you just said.  Grow up.

@_date: 2014-03-14 14:34:54
@_author: Robert J. Hansen 
@_subject: Multiple Subkey Pairs 
You are missing the point.
It is contemptible to believe that just because someone is descended  from X, they must therefore possess trait Y.  This is not how  civilized people behave.  We judge people on their own choices -- not  their parentage.  To do otherwise is the act of a barbarian.
Quoting you: "That your father was a highly positioned judge, would  make you rather biased," to be specific.  You didn't say that my  information would be biased: you said that *I* am biased based on my  father's job.  And that's simply beyond the pale.

@_date: 2014-03-15 12:59:28
@_author: Robert J. Hansen 
@_subject: Regarding Allan 
Some people have expressed interest in redistributing my remarks about
Allan.  Please don't.  I sent my remarks to his family for review and
they found a couple of minor factual errors in what I wrote -- nothing
serious, but -- well -- Allan would insist on total accuracy, so a
writeup about him should, too.
I have a fixed version that has been approved by his family.  Email me
off-list and I'll happily send it to you.  It's in the public domain:
please feel free to share it.

@_date: 2014-03-17 06:34:21
@_author: Robert J. Hansen 
@_subject: Multiple Subkey Pairs 
This is not a reasonable inference.
I deny being able to violate the Second Law of Thermodynamics.  Is it
perfectly reasonable to assume I can violate the First or the Third?
No, clearly not: the inference is not logically sound.  Neither is your
original inference.
See my previous post.
I cannot accept this assertion, as it is offered without either direct
evidence or logically sound inferences.

@_date: 2014-03-17 12:54:39
@_author: Robert J. Hansen 
@_subject: Multiple Subkey Pairs 
Try some variations.
I deny that I've ever been to Vienna; is it logical to believe, based on
that, that I've traveled extensively in Europe?
I deny that I've ever seen _Star Wars Episode III_.  Is it logical to
believe, based only on that, that I've seen every other installment?
I deny that I've ever read the second stanza of Coleridge's 'Kubla
Khan'.  Is it logical to believe, based only on that, that I've read the
This is all rather irrelevant, though, since it's clear you _a priori_
believe nothing claimed by that outfit.  (Which may be justified, mind
you.  Saying "I do not trust them and I consider all of their statements
a nullity: I will only trust what I can independently verify" is a
perfectly logical position.)
There are two options here: either I confess my ignorance, in which case
you'll claim to be more knowledgeable and thus right, or I claim my
knowledge, in which case you'll think I'm clearly "too close to them to
be trusted."
At this point, I don't care what you think.  My original statement -- "I
have seen no credible claims that anyone anywhere in the world is doing
bulk surveillance of email content on an internet-wide scale" -- stands.
I stand by that.  No more and no less than that.

@_date: 2014-03-18 10:01:10
@_author: Robert J. Hansen 
@_subject: Multiple Subkey Pairs 
I am not in a position to know whether it is for a fact, but that agrees
with my understanding.
My other position is that we have to be careful what we believe.  In
these times it's tempting to see shadows and jump at them, believing
that we're seeing the bogeyman.  We have to resist this temptation.  In
frightening times, we must pay special attention to logic and reason.

@_date: 2014-03-18 11:34:20
@_author: Robert J. Hansen 
@_subject: Multiple Subkey Pairs 
Quoting Martin Behrendt :
Strange: when my nephews were young they would also pass on messages  from the Thing That Lived In The Closet.  (They never called it the  bogeyman.  Just "That Thing That Lives In The Closet.")  Despite all  the times I opened the closet to look for it, I was never able to find  Let's look at some of the problems here.
(1) Given how many flat wrong things get printed in the newspaper,  believing this reporting may not be wise.
(2) Let's assume it's true.  The story only says it can record 100% of  a foreign country's telephone calls for up to a month, not that it can  store *all* telephone calls for an indefinite period of time.  There's  still a lot of targeting that has to go on here.  Claims of worldwide  surveillance are still overblown.
(3) The capability may exist, but the story never claims the system  has been used.  We've had nuclear weapons sitting idle in their silos  for decades: this capability may be the information equivalent of a  nuke in a silo.
(4) Your "yes, they used that system," I simply can't believe, not  without seeing supporting evidence.
My uncle, a Korean War veteran, tells me that at one point during the  war U.S. troops reported they were witnessing tactical nuclear  strikes.  It turned out this was just the 16-inch guns of the _U.S.S.  Iowa_ battleship.  Apparently, it's pretty easy to mistake a 16-inch  shelling for a tactical nuclear strike.  The relevance to our present  situation is this: just as it was very easy for troops to see  mind-blowingly huge explosions and to conclude the war had just gone  nuclear, it is very easy for us to look at fragmentary and  often-inaccurate news media reports and leap to conclusions about  "that system must exist and it must be in use!"
Be careful.  Carefully separate out what you see from what cause  you're ascribing to it.  If you see X, I'm willing to accept that you  see X.  But so far you seem to be leaping towards "... therefore Y!",  and there I think you're on much weaker ground.
I never said we should not be aware of the possibility, nor have I  ever said that such a thing cannot happen.
I said that we should not treat it as fact, because facts are things  which can be proven, and so far there's no proof here.
Anyway.  I've said my peace.  I'm done here.

@_date: 2014-03-24 09:46:21
@_author: Robert J. Hansen 
@_subject: OpenPGP smartcard and RSA 8192 bit 
The limits on key size were chosen with great deliberation and for  good reasons.  Although you are certainly free to change these limits,  it would be unwise to do so lightly.  Most users who create extremely  large certificates will immediately encounter three major problems:
* It won't work with smartcards
* Other GnuPG users can't verify signatures it makes
* Other GnuPG users can't encrypt to it
If you need a longer key, then wait for elliptical-curve cryptography  to be added to GnuPG.  (It should be coming along fairly soon.)

@_date: 2014-05-01 23:09:04
@_author: Robert J. Hansen 
@_subject: Access to www.gnupg.org only via TLS 
Sure it can.
It's pretty foolish to expense something only by its opening cost.
Instead, good practice is to amortize the expenses of opening, closing
and maintenance over the expected life of the resource.  Free to open,
*possibly* free to close (if the cert expires) and $24.99 otherwise, and
no maintenance costs, is pretty easy to expense.
What's the probability you'll need to revoke a cert?  Call it one in
five each year and you'll be probably overshooting.
Opening costs:                     $0.00
Maintenance costs:                 $0.00
Probabilistic closing costs:       $5.00
Total operating costs:             $5.00 per year
$5 per year for an SSL cert is pretty hard to beat.  Yes, *this* year
it'll cost you $25, but that's because of an event already baked into
your risk model.

@_date: 2014-05-03 11:24:55
@_author: Robert J. Hansen 
@_subject: Access to www.gnupg.org only via TLS 
I find it unlikely someone who has the financial means to keep a server
provisioned will be left unable to eat for two or three days over a
$25.90 fee.  Inconvenienced, sure, but that inconvenience is the result
of improper planning on their part.
Further, you are not asking StartSSL to "cancel the free service."  This
isn't about asking StartSSL to stop doing something: this is about
asking them to *do something new* -- generate a revocation certificate
and ensure it gets propagated to all the certificate revocation lists.
That's nontrivial.

@_date: 2014-05-03 11:32:34
@_author: Robert J. Hansen 
@_subject: Managing Subkeys for Professional and Personal UIDs 
Imagine this: you're a purchasing agent at Yoyodyne.  You've established
WoT connections with all your providers using a certificate whose only
UID is:
Now you go out on vacation for three weeks and on day four a sudden
business need arises in which a sales order must be filed.
Seems perfectly reasonable for me for the company to issue a signature
on a purchase order using your *corporate-owned*, *corporate-controlled*
certificate, which was always issued for the needs of the corporation.
Just because a certificate has your name on it doesn't make it yours and
doesn't mean you have a legal or moral right to control how it's used.
Personally, I would prefer not to have my name on such a certificate,
for reasons that have already been expressed on the list.  But if
there's a corporate policy that says each cert must have the name of
someone authorized to use it, then that's the way you play the game.

@_date: 2014-05-03 13:01:05
@_author: Robert J. Hansen 
@_subject: Managing Subkeys for Professional and Personal UIDs 
Unfortunately, the world doesn't much care what we think of as good
business practices.  And why should they?  We're nerds -- we understand
technology, perhaps, but odds are good few if any of us have ever sat at
the CIO/CTO/CSO level.  On what expertise do we declare it to be "not
good business practice"?
I agree that this is not the sort of business practice I would like to
see, but I'm not willing to go out on the limb with you and to declare
it a bad business practice.
And regardless of whether it's a good practice or a bad one, I've worked
in businesses that have done exactly this -- so it's a real-world
example that demonstrates the occasional need for a third party to
possess signing keys.

@_date: 2014-05-03 21:35:14
@_author: Robert J. Hansen 
@_subject: Managing Subkeys for Professional and Personal UIDs 
In which case, the proper response is to say "I quit."  That's a simple
moral issue: the company policy is for something I find morally
reprehensible, and so I quit.
Morally reprehensible policies, though, are not the same as *foolish*
policies.  In which case yes, by all means, bring the foolishness to the
attention of those who have the ability to change it... but so long as
you wish to be employed, make sure to comply with the foolish policy.
Speaking just for myself, if my employer were to slam a business-class
plane ticket in my hand and tell me "you're flying to Indore and hopping
a bus to Ranapur and we want you to have your face painted blue for the
entire journey," well, I might ask a few questions.  But it's hardly
offensive and I have a rent check to pay, and I've done many things in
my life more foolish than painting my face blue before hopping on a
business-class to Indore.
This is done.  But, you know what?  *We're not going to change it*.  So,
since this is done, let's accept reality and work with what is, rather
than talk about what a tremendous injustice it is that the world has
stupid people in it who will not listen to our wisdom about the way
things ought to be.
The world is full of stupid people and stupid policies.  Change what you
can; encourage others to change what they can; and when 99% of the world
around you is still as stupid as it was yesterday, roll up your
shirtsleeves and start engaging with what's left.

@_date: 2014-05-04 18:30:23
@_author: Robert J. Hansen 
@_subject: Managing Subkeys for Professional and Personal UIDs 
The better comparison is to the autopen.  And if that's good enough for
President Obama...
The autopen is a machine that replicates a physical signature.  That's
pretty much a perfect analogue to what we're talking about here: should
it be possible for a third party to recreate your digital signature?
Should it be possible for a third party to recreate your *physical*
signature?  That one has been conclusively answered 'depending on the
circunstances, yes!' time and time again.  Consider the President as an
example: he may wish to sign a piece of legislation but he's
unfortunately unavailable for signatures.  Instead, he contacts a
trusted secretary and orders the secretary to autopen his signature on a
document -- said signature, since it is made on his behalf (even if it's
physically made by a machine operated by a third person), being just as
legally binding as if he himself had written his signature.
Are there good business reasons for third party escrow of signing keys?
 Quite probably.  If you can think of a situation where an autopen is
appropriate, whether in business or in government, that's also a
situation where third-party escrow of signing keys would also likely be

@_date: 2014-05-04 20:52:36
@_author: Robert J. Hansen 
@_subject: Managing Subkeys for Professional and Personal UIDs 
If that's an axiom in your system, then so be it.  But let's not go
about thinking that's something you've deduced from principles.
It's not about technical problems.  In the case of the President and his
autopen, it's about legal problems.  Under United States law, for a
piece of legislation to take effect the President must affix his
signature to the *exact same piece of paper* that the House and Senate
affixed their marks to.  He's not allowed to sign a copy.
When the Affordable Care Act passed Congress, the President was off in
France.  He wanted to sign it immediately, but couldn't.  The piece of
paper approved by Congress was in Washington D.C., he was in France, and
time was of the essence.  One option would be to put the bill in an F-18
and fly it to France for the President's signature, but even then it
would be a five or six hour delay.  The President instead chose to have
a third party issue his signature on his behalf using an autopen.
You are certainly free to think this is a broken system.  (Thinking the
American political system is broken is the favorite pastime of many
Americans.)  But you have to admit this is a real-life example taken
from the highest corridors of power in an environment where there are
some extreme security implications of allowing third parties to execute
the President's signature...
... /and yet they choose to do it./
That's the world we live in.  You are, of course, free to scream that
they are all idiots and fools and morons who are not listening to your
divinely-inspired wisdom.  Me, I'm going to grit my teeth, say, "well,
let me see if I can help them not make a complete hash of things," and
engage the world as it is.
Did you read the part about the ex-CEO breaking into my apartment and
accessing my PC?  Come on, man.  My *personally owned* certificates were
compromised.  How much worse could it really have been if he'd chosen to
improperly use my *corporately owned* certificate?
If you haven't been seeing arguments, then I respectfully suggest
reading closer.

@_date: 2014-05-04 22:28:24
@_author: Robert J. Hansen 
@_subject: Managing Subkeys for Professional and Personal UIDs 
Welcome to government, where "pretty crazy" is about the best you can
hope for.  :)
The laws specifying the President's signature must be on the same
physical document the House and Senate approved predates the widespread
use of electronic documents.  Someday they'll get around to updating it,
and when they do they'll probably do it badly...

@_date: 2014-05-04 22:43:14
@_author: Robert J. Hansen 
@_subject: Managing Subkeys for Professional and Personal UIDs 
Because the law says the document must bear the President's signature,
not that of a functionary acting on the President's direction.
Deception?  In politics?  Surely you jest.  That could /never/ happen...
This original thread started off with Daniel Kahn Gillmor saying there
were no use cases for a third party holding signing keys.
Well, there *are* use cases, as evidenced by the President's signing of
the Affordable Care Act.
And every time someone says "well, he really shouldn't," I don't know
how to read that except as an admission of "yes, there is a use case,
but no, I don't like it."  In which case you're in full agreement with
me and you're just in denial about it.  Yes, there is a use case, and
no, I don't like it, either... but that doesn't change the fact there's
a use case!

@_date: 2014-05-05 20:55:21
@_author: Robert J. Hansen 
@_subject: Managing Subkeys for Professional and Personal UIDs 
Feel free to push for it.  Optimistically, you might be able to get it
done in five years.  And in the interim time, you need to have a method
to deal with the world as it is, because the world doesn't care what you
think it should be.
I don't think you'll have much luck changing the President's priorities.
As I explained, you are choosing not to recognize the argument.
Point blank: /the world does not care what you think./  Nor what I
think, for that matter.  The world cares about its established
procedures and The Way Things Have Always Been Done.  If you try very
hard, you may be able to make small amounts of headway in changing small
things.  I encourage this: choose wisely where you will expend your
efforts.  But that will still leave vast parts of the world that will
not be changed, and you have to have some plan for dealing with those
parts other than to tsk-tsk and say, "well, they shouldn't be doing that."
By all means, pick an important part of the world that needs changing
and work on it.  But the rest of the world will keep on going about its
merry way, not giving a damn what you -- or I -- think of it.
Should third-party signatures on behalf of another exist?  That's an
irrelevant question.  What's relevant is they *do* exist.  If you want
to commit your life to changing this, feel free: go with God and I wish
you luck.  But otherwise, deal with the world as it is, because the
world genuinely does not care what you think of it.  Or what I think of
it, for that matter.
This is the last I'm going to say on the matter: if I'm not abundantly
clear by this point, I doubt I'll be any more clear in the future.

@_date: 2014-05-12 10:21:04
@_author: Robert J. Hansen 
@_subject: Best practices for securely creating master RSA key 
I feel as if I should apologize in advance here, because this is going  to be a little bit ranty -- Daniel is making a good point, though, and  any incoherent fist-shaking at the universe that I may do is  definitely not directed at him.
The GnuPG community is prone to bikeshedding on a truly mind-blowing  scale.  It often seems to me that although there's general consensus  on 90% of a subject, nobody can quite agree on what that 90% is.  If I  present a ten-step process as being a good practice, I can rely on the  vast majority of opinions being "this seems pretty good on these nine  points, but this tenth one absolutely has to go because it's wrong  wrong wrong" -- and no agreement whatsoever on which nine points are  good and which tenth one must go.
Further, there is an unfortunate subset of the community that believes  it has a monopoly on truth and that any disagreement is Jeoparding The  Security Of The Entire Internet -- I capitalize that phrase because  their emails to me often have that sense to them, as if every word was  being emphasized just to make sure that I "got it".
For that reason I'm generally not all that fond of weighing in on  certain subjects, because they are so phenomenally divisive and  generate so much more heat than light.  (Case in point: PGP/MIME,  which resulted in *so* much flamefesting in my inbox that rather than  give a single answer on the subject I threw up my hands, said "to hell  with it," and the FAQ entry basically says "whatever you think, half  the community will say you're wrong.")
Anyway: yes, this probably does warrant a FAQ entry, and I'll do my  best to make changes and send Werner a revised version.  Look for it  by the end of the week.  It may take a bit longer, depending on how  quickly Amazon is able to ship me a new pair of asbestos longjohns...

@_date: 2014-05-13 11:00:34
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
Bluntly, my thoughts are that 99% of the people who talk about quantum  computation couldn't identify a Hadamard transformation if they  tripped over its brakets.
Shor's Algorithm requires 2N qubits, where N is the size in bits of  the composite you wish to factor.  So for a 2048-bit certificate that  requires 4096 qubits, representing a state space of over 10^1100.   That's a quantum computer so ludicrously powerful that if one were to  exist it would transform the world in ways we literally cannot  imagine.  This is a quantum computer so powerful that it defies even  the dreams of science fiction authors.
I literally lack the skill in the English language to describe just  how eye-popping this thing is.  The best analogy I can think of is  that we're a bunch of primitive hominids just beginning to learn how  to knap obsidian into knife blades, and you're saying "What are your  thoughts on how obsolete these knives will be once we develop  thermonuclear bombs?  I mean, they're going to make these knife blades  just ... *obsolete*."
If that happens, I'll have much bigger things to worry about.  I'll  let you worry about the thermonuclear age: for now, I'd rather focus  on the advent of the Bronze Age.

@_date: 2014-05-13 11:53:02
@_author: Robert J. Hansen 
@_subject: Result of the crowdfounding 
Goteo charges an amount proportional to the funds that are raised.   2939 euros on 37270 is about an eight percent overhead.  Seems  reasonable to me.
It would be better if it worked.  It doesn't, so the GnuPG folks tried  something different, which turned out to work better despite the  increased overheads.  If funding increases by a factor of ten, then  even if overhead eats up half that funding is still increased by a  factor of five.
Donating to GnuPG is already quick and easy.  Yet despite this, people  overwhelmingly tend not to do it.

@_date: 2014-05-14 11:26:16
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
Rather, as evidenced by my willingness to try and tackle this one.
To a first approximation, trust is confidence in the future's  predictability.  My friends who grew up in dictatorships tell me the  uncertainty was far worse than the oppression -- or, more to the  point, that pervasive uncertainty is its own unique form of  oppression.  They didn't know which of their loved ones were reporting  on them to the state security forces.  They didn't know if the police  officer they saw on the street was going to obey the dictator's law or  decide his truncheon and gun gave him the right to enact his own law.   They didn't... etc., etc.
To defend against this, they smiled and moved forwards.  Some turned  to religion: "God will provide.  God will keep me safe."  Some turned  to optimism: "Tomorrow will be better.  I won't get shaken down by the  authorities tomorrow."  But they all worked to create their own  confidence in the predictability of the future, and in so doing  managed to keep their psychological health intact.  That health helped  them prevail against their situation.
So, my answer to whether "some things are suspect" or "all things are  suspect" is the true state of affairs is this: does it really matter?   Regardless of whether "some" or "all" are suspect, a smile and faith  in tomorrow seem to be much more important.  Don't despair.   Tomorrow's looking good.  Embrace that, and then you might find the  answers to other questions come more easily.  :)

@_date: 2014-05-14 13:15:40
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force [WAS: Re: GPG's 
No.  But since I'm going to be giving a lot of explanation here about  how you're misusing the Landauer Bound, I'm going to leave how you're  misusing the Margolus-Levitin Limit as a homework exercise.  :)
It's not.  You have to rekey the cipher.  This multiplies the energy  by about a large factor.  To make the math easier, let's call it a  If you want to run the temperature lower than the ambient temperature  of the cosmos (3.2K), you have to add energy to run the heat pump --  and the amount of energy required to run that heat pump will bring  your energy usage *above* that which you would've had if you'd just  run it in deep space at 3.2K.
So multiply your previous estimate by a factor of ten billion, in  order to reflect running it at ambient temperature.
10^10 * 10^6 = 10^16.  So far your estimate is off by a factor of a  thousand trillion.
Assuming you could do AES in a single bitflip, it would require  liberating as heat as a strategic nuclear warhead.  Every additional  bitflip adds another strategic nuclear warhead.  By the time you're  flipping 1000 bits for each rekeying, you're basically inflicting  World War Three on the earth just to brute-force a cipher.
I stand by my predictions of ecological catastrophe if anyone ever  brute-forces a 128-bit cipher.

@_date: 2014-05-14 13:36:33
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force [WAS: Re: GPG's 
*Ten* thousand trillion.  Sorry, that one's entirely my error.

@_date: 2014-05-14 19:31:26
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force [WAS: Re: GPG's vulnerability 
That's why it's a homework problem.
$dS = \frac{\delta Q}{T}$
The Second Law of Thermodynamics says there ain't no such thing as a
free lunch.  You want to lower the heat (entropy) in one place, you have
to (a) move that entropy elsewhere and (b) pay an entropic price on top
of it.  If you're moving a million units of entropy from A to B, you're
going to be be paying at least a million and one units of energy.
That's a gross simplification, but close enough for government work.
You want to lower the temperature (heat, entropy, whatever) to 10^-10 K?
 Okay, fine: pay the price.  But you will *always* be paying more than
if you were to just run the machine at 3.2K, and that's a consequence of
$dS = \frac{\delta Q}{T}$.
To put it in terms that we all can understand -- your air conditioner
runs on electricity.  Moving heat from inside your house to outside
requires energy be added to the overall system.  The hotter the day, the
more energy your air conditioner needs to move the heat around.
A one-megaton nuke releases a *petajoule* of energy.  That's a lot.
When people start using the phrase "peta-" to describe things, I
suddenly become very interested in their Health & Safety compliance.
This is a petawatt laser.  This is a petawatt reactor.  This is a
petajoule of energy.  This is Peta Wilson.[1]
(I trust that Ms. Wilson will forgive my asking, "uh, do we have someone
certified for operating her, and where's the nearest Health & Safety
card?" without getting too, well, petulant.[2] )
[1] [2] You're beginning to make me a little irate here: the Wikipedia page
answers this in the second sentence of its first paragraph.  "Any
logically irreversible manipulation of information ... must be
accompanied by a corresponding entropy increase."
Key phrase: Entropy increase.
Layman's translation: Heat increase.
The Landauer Bound gives not just a minimum amount of energy necessary
to change a bit of information, but how much heat must be liberated by
that computation.  And I repeat, this is in the second sentence of the
first paragraph of the Wikipedia article...
Yeah, adiabatic computing.  Give me a call as soon as we have an
adiabatic computer: I'll be deeply fascinated.  Right now that's even
more theoretical than quantum computing -- we've actually observed
quantum computation in the lab on a small scale, while adiabatic
computing is so far a complete no-go, AFAIK.
(Then again, it's been a few years since I've dived into the literature
on it -- if you can find a paper demonstrating real-world adiabatic,
energy- and entropy-free computing, I will be deeply fascinated.  I
wasn't kidding about that.)
Look!  A bit of information:  ___
That's what it was before.  Of course, it's now carrying the value '1'.
So, tell me: you say bit flips are reversible, so what was the value
before it was 1?  I promise, I generated these two bits with a fair coin
(heads = 0, tails = 1).
"Reversible" means "we can recover previous state without guessing."
Current computing systems are not reversible.

@_date: 2014-05-15 09:14:55
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force [WAS: Re: GPG's vulnerability 
Huh: neat!  It doesn't surprise me that there are interesting ways to
tweak the numbers: my calculation is something that would have to assume
vast pretensions of standing just to be considered worthy to go on the
back of a bar napkin.  :)
Point.  If/when I make a revision of it I'll review it.  :)

@_date: 2014-05-15 09:23:10
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force [WAS: Re: GPG's 
At the level we're talking about, the distinction between  thermodynamics and computational theory gets a little hazy.  Seriously

@_date: 2014-05-15 09:25:40
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force 
So, I can put you down as solidly in the eco-catastrophe camp, then?  :)

@_date: 2014-05-16 09:56:55
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
$dS = \frac{\delta Q}{T}$
Second Law of Thermodynamics, which you just broke.  Have a nice day.
And no, I am not going to explain this further.  My reason for this is
simple: you need to take college-level courses in differential and
integral calculus, partial differential equations, statistics, and
statistical physics in order to get in-depth here.  This is a mailing
list, not the first two years of university.
But, just so you don't think I'm pulling this out of nowhere:
Look at bullet point two.
You're entitled to your opinion, but not your own facts.  You are
claiming you can violate the Second Law.  My response: prove it.

@_date: 2014-05-16 10:07:25
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
Forgot one more reference -- look at Schneier's _Applied Cryptography_,
where he talks about the physical limits of the cosmos.  He has a
physicist's error in his presentation (he's off by a factor of ln 2),
but he confirms the Second Law necessity of a heat pump that would
offset any benefit from running at a lower temperature.
(By "a physicist's error", physicists think of hypothetical computers
that run in base e [2.71828], while computer scientists think of real
ones that run in base 2.  A physicist's hypothetical computer needs kT
joules to clear a nat, while a real computer uses kT ln 2 to clear a
bit.  Schneier's text talks in terms of bits, but he does the math in
terms of nats ... which makes a kind of sense, given he has a graduate
degree in physics.)
Now, can we put this ridiculous talk of "of course we can break the
Second Law!" to rest?
"If someone points out to you that your pet theory of the universe is in
disagreement with Maxwell's equations -- then so much the worse for
Maxwell's equations.  If it is found to be contradicted by observation

@_date: 2014-05-16 08:24:54
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
Peter is correct, but a little clarification may be in order.   Grover's is not a brute-forcing algorithm: it's a search algorithm.   To turn Grover's into a brute-forcer you treat the entire keyspace as  an extremely large database and you're searching through it to find  one particular entry -- the key.  If you get into more depth in  quantum computation you'll see Grover's appear in lots of different  contexts.  It's an important and fundamental algorithm that has  applicability far beyond crypto.
Let me repeat: Peter is completely correct.  I just want to make sure  people understand that although Grover's can be used to help  brute-force a cipher, it is not itself a cryptographic algorithm.  :)

@_date: 2014-05-16 20:05:40
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force [WAS: Re: GPG's vulnerability 
This is the last I will be saying on the subject.  I am not interested
in teaching a course on thermodynamics.
But what?  This in the same ballpark as you'd get from releasing a
half-kilogram of antimatter on the world.  It's big.  There are no
"but..."s about it.
There are two equivalent ways to define entropy, one using
thermodynamics and one using statistical mechanics.  When using the
statistical mechanics definition it's easy to forget you're talking
about the real world instead of just juggling around a lot of numbers
and probabilities.  When using the thermodynamic definition you get your
fingers burned and that reminds you you're talking about
*thermodynamics* -- how heat moves around in a system.
It was actually a 1.  The two bits were 1 and 1.  Knowing the second
value was a 1 is of no help whatsoever in recovering the previous state.
The previous state could have been anything.  The bit has no memory of
what it was before: that information is lost to the universe, and there
is a corresponding increase in entropy (heat) associated with it.

@_date: 2014-05-17 09:28:33
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force 
Another way of looking at it: RAM is normally implemented as a flipflop.
 (The EEs insist on calling them "bi-stable multivibrators," [1] but I
think that's just too kinky for a family-friendly mailing list.)  The
way a flipflop works, the contents are refreshed and/or changed with
each clock cycle.  Each and every clock, the former contents are
replaced with whatever the current state should be.  If a bit held 1
before and it holds 1 now, that still counts as a bit erasure for
thermodynamic purposes.
[1] No, I'm not kidding.  See, e.g.,
    *Very* unintuitive, yeah.  You flat-out can't trust your intuition: you
have to take refuge in math and physics.
To really understand computation at the limits of physics requires
general relativity (Riemann geometries, tensors, really high-end
calculus), quantum mechanics (matrices, Dirac brakets, eigenvalues,
probabilities), computational theory (discrete math, state transforms,
etc), statistical entropy, thermodynamic entropy, Shannon entropy, and
more.  It's hard.  I wasn't kidding about this field making me feel like
a dog sitting at a table with Ed Witten and David Deutsch.  Woof woof.
Niels Bohr is supposed to have said anyone who is not shocked by quantum
mechanics clearly has not understood it.  The same can be said about
computational limits.

@_date: 2014-05-17 13:52:07
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to brute force 
Point, but I think it's equivalent: whether it's a flipflop getting a
signal or a microcapacitor that's charging/discharging, in both cases
previous state is getting obliterated and the entropic cost accrues.  :)
Thank you for the correction, though!

@_date: 2014-05-17 13:53:18
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 128, Issue 24 
Go build this system, demonstrate you can break Landauer, and collect
your Nobel.  Seriously.

@_date: 2014-05-19 13:16:38
@_author: Robert J. Hansen 
@_subject: GPG's vulnerability to quantum cryptography 
tl;dr summary of the rest of this email -- don't focus on  factorization, and be careful of thinking about a post-RSA future.
I can't comment on this (for the most pedestrian of reasons: I can't  predict the future, and if anyone currently knows how to do it they  sure haven't told me), but a little commentary might be appropriate:
1.  We would like integer factorization to belong to complexity class  NP-Complete, but there are good reasons to think it's not.  If its  NP-Completeness could be proven, then so much of mathematics would be  transformed that I'm not sure continued confidence in *anything*  involving computers would be warranted.
2.  If someone could prove IFP was in P, that would be ...  breathtaking, to say the least.  Same thing: if it could be proven,  that would be such a seismic shift -- and would foment such  revolutions in mathematics -- as to jeopardize confidence for years  until the repercussions of it were fully understood.
3.  If IFP is NP-intermediate, as it's currently conjectured to be,  then nothing short of quantum computation will endanger it.
4.  But RSA is not the same as the IFP, and Dan Boneh has written a  great paper showing that it may be possible to break RSA without  needing to factor anything.  We don't know how to do it, we don't even  have *hints* about how to do it, just a good paper from Dan Boneh  showing that it may in fact be possible to do it.  But this, too,  would be such a breakthrough as to jeopardize confidence, etc., etc.
5.  If and when RSA gets broken, all bets are off.

@_date: 2014-05-25 04:06:12
@_author: Robert J. Hansen 
@_subject: Hotplate 
Over this Memorial Day weekend I've got two major priorities -- one is
to add something to the FAQ regarding certificate generation, and the
other is to force myself to learn JavaFX [1].
Anyway.  I figured to use recent heated -- pardon the pun -- discussions
on this list as fodder for a small excursion into JavaFX, and Hotplate
is the result.  It's a small app that will let you toy around with
different numbers and see how they, the Landauer bound, and the
Margolus-Levitin limit, affect the time and heat required to brute-force
a 128-bit cipher.
If you're interested in looking at it, the very first thing you should
do is visit  to get the latest version of the Java
virtual machine.  Once that's taken care of, you have two choices:
1.  Hit  and launch the application
through Java Web Start. [2]
2.  Download it from  and
double-click to execute.
The application is signed in accordance with Java's normal practices.
If you get a warning about an invalid signature, don't run it.  If you
don't trust Java's signing process, you can download a GnuPG-generated
clearsig from  .
Full source code is included inside the jarfile, and the entire thing is
contributed to the public domain.  Enjoy.
[1] Not that I'm particularly keen on it, mind you, but the first
question hiring managers ask in the DC metro area is, "Are you up with
the latest Java technologies?"  It pays to learn it just so you can get
hired for a job where you'll never use it.
[2] Probably the simplest, but not exactly recommended.  Java Web Start
is a pretty effective malware vector.  But if you've got it installed
already, well...

@_date: 2014-05-27 19:07:30
@_author: Robert J. Hansen 
@_subject: GnuPG class throwing null pointer exception 
First, that code is kind of ... ouch.  "Bug-ridden" may be an
understatement.  Take a look at, e.g., how it reads data from GnuPG:
class ProcessStreamReader extends Thread {
    StringBuffer stream;
    InputStreamReader in;
    final static int BUFFER_SIZE = 1024;
    ProcessStreamReader(InputStream in) {
        super();
        this.in = new InputStreamReader(in);
        this.stream = new StringBuffer();
    }
    public void run() {
        try {
            int read;
            char[] c = new char[BUFFER_SIZE];
            while ((read = in.read(c, 0, BUFFER_SIZE - 1)) > 0)
                stream.append(c, 0, read);
                if (read < BUFFER_SIZE - 1) break;
            }
        }
        catch (IOException io) {
        }
    }
    String getString() {
        return stream.toString();
    }
So let's say you've got this thread running, and it's cheerfully
spinning along adding data to stream.  While it's doing this, you call
its getString() method... and bam, immediate race condition, because the
call to stream.append() is neither atomic nor locked by a mutex, and
there's no guarantee that when you read the stream's contents the stream
will be in a consistent state!
On top of that, getString() really should clear the contents of stream
prior to return.  Otherwise if you get "abc" the first time you call
getString(), the second time you won't get "def" -- you'll get "abcdef".
On top of *that*, this thread will quite possibly bail out before it's
finished reading data.  It loops *fast* -- there's not a single sleep()
call in there -- and as soon as it receives less than a full buffer of
data, it assumes there's no more and bails out, rather than thinking,
"gee, maybe the other end of this communication channel is delayed for
disk I/O or somesuch."
So, yeah.  I would be wary of using this code in a production
environment.  It does not appear to be ready.
Happy to help.  The first question is, what OS are you running it on,
and where is GnuPG located on your machine?

@_date: 2014-05-27 20:15:29
@_author: Robert J. Hansen 
@_subject: GnuPG class throwing null pointer exception 
Mea culpa: someone just pointed out to me that as of Java 7,
StringBuffer is innately threadsafe and all the accessors/modifiers are
locked in synchronized blocks.  However, since this code dates back to
the Java 1.4 error, it would be an error under the JVM spec that existed
My error -- thanks to the (wishing-anonymity) person who corrected me!

@_date: 2014-05-29 18:21:04
@_author: Robert J. Hansen 
@_subject: Getting Passphrase From Encrypted and Unencrypted Secret Key 
This is considered "computationally infeasible."  That phrase means, "it
would require science-fiction technologies to do it."

@_date: 2014-11-05 10:56:24
@_author: Robert J. Hansen 
@_subject: Help needed to setup Passphrase with GNUPG 2.0.26 on Solaris 10 
Not to harp, but it bears repeating: use GnuPG 1.4 and this entire
problem goes away.  Given all the emails that have gone back and forth
on this subject, I think it's probably time to make the switch to 1.4.  :)

@_date: 2014-11-06 10:58:31
@_author: Robert J. Hansen 
@_subject: GPG 2.1.0/Win32: keyserver lookup problems 
There's an odd problem with 2.1.0 on Win32.  Steps:
1.  Uninstall existing gpg4win.
2.  Install the new experimental 2.1.0 Windows installer.
3.  Try to pull a key from a keyserver such as:
C:\utils>gpg --keyserver pool.sks-keyservers.net --recv-key d5078b4f
gpg: keyserver receive failed: Input/output error
I made no changes to my gpg.conf file nor to my keyring.  I've confirmed that I have network connectivity and I can hit

@_date: 2014-11-06 11:12:04
@_author: Robert J. Hansen 
@_subject: GPG 2.1.0/Win32: keyserver lookup problems 
Next round of problems: doing a --list-secret-keys takes considerable time -- approximately 28 seconds on a fairly modern desktop. --list-keys, though, is pretty snappy.

@_date: 2014-11-06 11:44:43
@_author: Robert J. Hansen 
@_subject: With the release of modern, is there intent to support ECC in 
The last this was discussed the answer was "no".  It's been some months
since then, but I haven't seen anything to make me think the answer has
changed.  Sorry.  :(

@_date: 2014-11-06 11:49:17
@_author: Robert J. Hansen 
@_subject: GPG 2.1.0/Win32: keyserver lookup problems 
I started from a brand new install, right down to emptying out my old %APPDATA%\Roaming\GnuPG directory.  I reloaded keys the "hard" way, by --import \path\to\old\pubring.gpg and --import \path\to\old\secring.gpg.
As near as I can tell I'm doing things correctly.  However, honesty compels me to say that I'm running into a *lot* of problems with the Windows build.  It does not appear to me to be ready for prime time.
Yes, which is why I reported it again: because I was under the impression that bug had been *fixed*.

@_date: 2014-11-06 14:09:15
@_author: Robert J. Hansen 
@_subject: GPG 2.1.0/Win32: keyserver lookup problems 
Sure, but even then -- this is a really shaky build, Werner.  I'm getting all different kinds of weird errors, from the keyserver helper not being able to communicate with the outside world, to GnuPG swearing it's created output but no output file being created (!!), to GnuPG 2.1.0 + Enigmail inserting additional newlines after every line of text, to GnuPG 2.1.0 + Enigmail telling me it's successfully decrypted a message but presenting me with a blank screen, to...
Some of this is probably on Enigmail; some of it is probably on Win32.
My own recommendation, for whatever it's worth, is that normal Win32 users should *not* upgrade.  Not yet, at least.  There's a lot of stuff here that needs shaking out.
(The "GnuPG insists it's created output, but none exists" -- this one was so surreal that I was seriously considering whether I was hallucinating from caffeine withdrawal, as I'd skipped my morning cup. I cd'ed into the C:\Program Files (x86)\Gnu\GnuPG\bin directory, so as to avoid having to type "gpg.exe" each time.  I wanted to test encrypting a file on my desktop, and I could've sworn I set the output to C:\Users\rjh\Desktop.  I didn't, though, and GnuPG dumped the output into the C:\Program Files (x86)\GNU\GnuPG\bin directory...
... or at least, it claimed to.  When I did a dir on the directory, the output didn't exist.
"Hmm," I thought, "that's weird.  Did it not have permissions to write to the dir?  If so, shouldn't it have given an error?"
So I repeated the same command line.  This time, GnuPG told me the file foo.asc already existed, and did I want to overwrite it?
I Ctrl-Ced out.  Intrigued, I combed through the directory looking for foo.asc.  It wasn't there.  So what the heck was GnuPG warning me about At some point I had to seriously consider the possibility I was hallucinating it.  I'm pretty sure I wasn't.  But I can't explain for the life of me what happened there.)

@_date: 2014-11-06 14:58:45
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG 2.1.0 "modern" released 
Is there any guidance as to how to install this on Fedora 20?  gnupg2 is
a protected package there: it literally cannot be removed without
completely breaking the system.  (The cause of the total-breakage: yum,
the Fedora package manager, has gnupg2 as a dependency.)
The timing of GnuPG 2.1 is a little unfortunate: we're already past the
beta freeze and final freeze is coming up in just a few days.  It's
unlikely GnuPG 2.1 will make it into Fedora 21, and I doubt Fedora will
shift from 2.0 to 2.1 outside of a major release, meaning Fedora users
will be left using 2.0 for six months or so.
In the grand scheme of things this is an annoyance more than anything
else... but still, an annoyance.  :)

@_date: 2014-11-06 15:39:14
@_author: Robert J. Hansen 
@_subject: GPG 2.1.0/Win32: keyserver lookup problems 
Ack -- I meant some of it is probably on GnuPG/Win32.  :)

@_date: 2014-11-07 13:53:35
@_author: Robert J. Hansen 
@_subject: Clang with GnuPG 2.1.0 
A great way to find hidden GNUisms is to use a non-GNU compiler, which is why I generally prefer to compile things with Clang -- it's a nice sanity check on code.  GnuPG 2.1.0 is refusing to build on a freshly-updated Fedora 20 box using Clang 3.4.
(It compiles just fine with GCC, incidentally.)
make[3]: Entering directory `/home/rjh/gnupg-2.1.0/common'
clang -DHAVE_CONFIG_H -I. -I..  -I../gl -I../intl -DLOCALEDIR=\"/home/rjh/share/locale\" -DGNUPG_BINDIR="\"/home/rjh/bin\"" -DGNUPG_LIBEXECDIR="\"/home/rjh/libexec\"" -DGNUPG_LIBDIR="\"/home/rjh/lib/gnupg\"" -DGNUPG_DATADIR="\"/home/rjh/share/gnupg\"" -DGNUPG_SYSCONFDIR="\"/home/rjh/etc/gnupg\"" -DGNUPG_LOCALSTATEDIR="\"/home/rjh/var\""        -I/home/rjh/include -I/home/rjh/include -I/home/rjh/include -I/home/rjh/include -DWITHOUT_NPTH=1 -g -O2 -Wall -Wno-pointer-sign -Wpointer-arith -MT libcommon_a-logging.o -MD -MP -MF .deps/libcommon_a-logging.Tpo -c -o libcommon_a-logging.o `test -f 'logging.c' || echo './'`logging.c
In file included from logging.c:51:
In file included from /usr/include/netinet/in.h:22:
In file included from ../gl/stdint.h:83:
extern intmax_t imaxabs (intmax_t __n) __THROW __attribute__ ((__const__));
        ^
extern intmax_t imaxabs (intmax_t __n) __THROW __attribute__ ((__const__));
                          ^
extern imaxdiv_t imaxdiv (intmax_t __numer, intmax_t __denom)
                           ^
extern imaxdiv_t imaxdiv (intmax_t __numer, intmax_t __denom)
                                             ^
extern intmax_t strtoimax (const char *__restrict __nptr,
        ^
extern uintmax_t strtoumax (const char *__restrict __nptr,
        ^
extern intmax_t wcstoimax (const __gwchar_t *__restrict __nptr,
        ^
extern uintmax_t wcstoumax (const __gwchar_t *__restrict __nptr,
        ^
__extern_inline intmax_t
                 ^
__NTH (strtoimax (const char *__restrict nptr, char **__restrict endptr,
#  define __NTH(fct)    __attribute__ ((__nothrow__ __LEAF)) fct
                         ^
In file included from logging.c:51:
In file included from /usr/include/netinet/in.h:22:
In file included from ../gl/stdint.h:83:
__extern_inline uintmax_t
                 ^
__NTH (strtoumax (const char *__restrict nptr, char **__restrict endptr,
#  define __NTH(fct)    __attribute__ ((__nothrow__ __LEAF)) fct
                         ^
In file included from logging.c:51:
In file included from /usr/include/netinet/in.h:22:
In file included from ../gl/stdint.h:83:
__extern_inline intmax_t
                 ^
__NTH (wcstoimax (const __gwchar_t *__restrict nptr,
#  define __NTH(fct)    __attribute__ ((__nothrow__ __LEAF)) fct
                         ^
In file included from logging.c:51:
In file included from /usr/include/netinet/in.h:22:
In file included from ../gl/stdint.h:83:
__extern_inline uintmax_t
                 ^
__NTH (wcstoumax (const __gwchar_t *__restrict nptr,
#  define __NTH(fct)    __attribute__ ((__nothrow__ __LEAF)) fct
                         ^
In file included from logging.c:54:
       declaration specifier
typedef __intptr_t intptr_t;
                    ^
../gl/stdint.h:229:23: note: expanded from macro 'intptr_t'
 intptr_t long int
                       ^
In file included from logging.c:54:
../gl/stdint.h:229:18: note: expanded from macro 'intptr_t'
 intptr_t long int
                  ^
18 errors generated.

@_date: 2014-11-08 20:49:24
@_author: Robert J. Hansen 
@_subject: some -- are broken in the HTML FAQ 
(On from my tablet)
What you're looking at is called an em dash (or an en; the FAQ uses both) and is typographically correct. Two hyphens are how people used to simulate an em dash in the ASCII days. Unicode offers proper hyphens, en dashes and em dashes, though, so the FAQ uses them.
The remark about imminent heat death is also correct.

@_date: 2014-11-08 22:42:27
@_author: Robert J. Hansen 
@_subject: some -- are broken in the HTML FAQ 
Ah ha.  IIRC, those were entered as double hyphens in the source text.
I'll double check.

@_date: 2014-11-09 00:46:31
@_author: Robert J. Hansen 
@_subject: [Announce] GnuPG 2.1.0 "modern" released 
Not really; every time I do some operation requiring a passphrase, GnuPG
2.1 aborts because it can't find a pinentry.

@_date: 2014-11-10 08:52:08
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
"11.10 Why is my DSA key limited to 3072 bits?
The United States? National Institute of Standards and Technology (NIST)
is responsible for the DSA specification. NIST has not published a
4096-bit DSA variant, and thus GnuPG doesn?t offer it."

@_date: 2014-11-10 08:56:36
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
Five, but nobody uses DSA-512 and I think it's been formally obsoleted.
 But yes, DSA-512 is a real thing, although GnuPG never supported it
(for good reasons -- it was seen as marginal even when it first came out!).

@_date: 2014-11-10 09:48:16
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
After going back to my sources to double-check this, it turns out to be a lot more than 5.  DSA was defined in DSA-512 to DSA-1024 at 64-bit steps -- so weird ones like DSA-576 exist, too.

@_date: 2014-11-10 11:01:12
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
Yeah, I was misled by the reference to 186-3 and misread it as "the family of 186 documents."
(For those of you who don't follow government specs as a hobby: FIPS 186, first released in 1994, has been revised several times over the years.  We're now up to the fifth revision, FIPS 186-4, which was published in July of 2013.)
I don't have a copy of FIPS 186-3, but my copy of 186-4 has a chapter 4 titled "The Digital Signature Algorithm."  The document *itself* is called the Digital Signature Standard, but there's nothing in the text that says "this particular algorithm with these particular parameters represents DSS".
(This is a break of sorts from FIPS 186, where "DSS" was used in the text a couple of times in an algorithmic context.  I don't know when the language shift happened, but clearly somewhere between 186 and 186-4.)
Huh: interesting.

@_date: 2014-11-10 13:31:04
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
This is news to the cryptographic community.  Cite, please?  I want to know who these "some people" are, and a list of their major academic If Dan Boneh says DSA is compromised, I'll have a coronary and I'll rush to read the paper proving it.  If Joe Bob's Web Page Of Crypto says DSA is compromised, I'm going to yawn and click "Back".
NIST's DSA standard has never been compromised, nor did Snowden release any proof of a backdoor in a NIST DSA standard.  (I know, I know, Nan is just saying "elliptic curve spec".  Given the sentence is embedded in some talk about DSA, I think it's reasonable to think Nan's talking about ECDSA.)
What Nan means to be talking about is the Dual Elliptical Curve Deterministic Random Bit Generator (Dual_EC_DRBG) specification -- a way of generating random numbers, but *not* a signature algorithm.  It was released in 2004 to a great yawn: it was inefficient, slow, and the parameters gave some people the heebie-jeebies.  In 2007, Shumow and Ferguson presented at CRYPTO some results that made this design look like it might be backdoored.
An algorithm that nobody used in the first place ... remained an algorithm that nobody used in the first place.
Six years later the _New York Times_, reporting on alleged internal NSA memos provided by _l'affaire Snowden_, accused the NSA of inserting a back door into the Dual_EC_DRBG standard.  But _l'affaire Snowden_ did not reveal the problems in Dual_EC_DRBG.  They were already quite well known about in the crypto community.
This is a flat lie.  NIST's official statement can be found at:
"NIST strongly recommends that, pending the resolution of the security concerns and the re-issuance of SP 800-90A, the Dual_EC_DRBG, as specified in the January 2012 version of SP 800-90A, no longer be used.   Effective immediately, NIST Special Publication 800-90A is being re-issued as a draft for public comment for a period ending November 6, 2013.  Any concerns or recommendations for improvement regarding the Recommendation for Random Number Generation Using Deterministic Random Bit Generators are solicited."
Then, on April 21, 2014, they announced their final decision with respect to Dual_EC_DRBG:
"Following a public comment period and review, the National Institute of Standards and Technology (NIST) has removed a cryptographic algorithm from its draft guidance on random number generators."
Dual_EC_DRBG wasn't "adjusted as little as possible".  It was outright *removed*.  And given how easy this is to find -- seriously, NIST *wants people to know this* -- I find this error of fact pretty much inexcusable.
Who is the "us" that you're referring to?
 From that webpage:
"DSA has been compromised."  No, it hasn't.  So far no one has shown any ability to break even DSA-1024.  I'm not optimistic about the long-term health of DSA-1024 (see the archives), but it's flat *wrong* to say that we know DSA-1024 to be compromised.
"The SSH spec says 'exactly 1024 bits', not '1024 bits or less.'  Why?"   Because FIPS 186-2, which OpenSSH wants to track, requires 1024-bit DSA.  FIPS 186-3 and 186-4, successors, permit up to 3072-bit DSA.
Why isn't OpenSSH tracking FIPS 186-3 and -4?  Good question.  Probably because the handwriting is on the wall and ECDSA is the future, and limited manpower can be better devoted to getting ECDSA working correctly rather than continuing to track obsolescent DSA standards.
It's not.  However, there are a *lot* of businesses that do trade with the United States government, and these businesses are required to comply with federal information processing standards.  If your software doesn't conform to the appropriate FIPS, you won't get the government's It's like objecting to the Russian cipher GOST.  GOST is a Russian governmental standard.  If you want to do business with the Russian government, you need to support GOST.  That doesn't mean you're "restricted" to supporting GOST; that means supporting GOST is a good idea for anyone who wants to do business with the Kremlin.
This is factually incoherent.  Rainbow tables attack hash functions: they don't attack signature algorithms.  If someone was interested in using rainbow tables against a signature algorithm they'd make sure to carefully specify what hash algorithm was used, because rainbow tables have to be made specifically for a hash algorithm.  But we don't see that in the DSA spec, so the conclusion I draw is that what you're saying here is flat wrong.

@_date: 2014-11-10 13:46:55
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
The USG does not advocate any particular key size.  They've made DSA
available in three sizes (as of FIPS 180-something) to support a variety
of different needs.
I don't want to sound blunt, but I respectfully suggest you don't
understand how rainbow tables work.
They aren't used against signature algorithms.  They're used against
*hash algorithms*.  Huge difference.  If you have a rainbow table that
can break SHA-1 (not that I think one exists today), then it's
completely useless against RIPEMD-160 or truncated SHA-256.
If anyone wanted to use rainbow tables against DSA-1024, they would need
some way to ensure that only one particular hash algorithm could be used
with DSA-1024.  Instead, DSA-1024 just requires 160 bits of hash.
SHA-1, RIPEMD-160, Tiger-192, WHIRLPOOL, SHA-224/160, SHA-256/160,
SHA-384/160, SHA-512/160...
Or, if you already believe some shadowy and nefarious organization has
rainbow tables for SHA-1, then I guess you could just say "I believe the
shadowy and nefarious conspiracy has at least eight times the resources
it did before, and it has rainbow tables for *everything*."
But at that point you've got a problem: if you're positing that your
opponent has such unlimited computational resources that they're in
effect God, well ... you don't win against God.  You've just defined the
opposition as having such unlimited computational resources that nothing
you do will matter and nothing you do can possibly save you.
That's MD5.  We knew all the way back in 1997 that MD5 could be broken
on a Pentium-90 (that's a 90MHz Pentium, kids: a full tenth of a
gigahertz) in under an hour.  We knew it because Hans Dobbertin *did
it*.  (The MD5 attacks have all been attacks on the MD5 compression
function, extended out to attacks on the full MD5 hash.  In 1997, Hans
Dobbertin proved the MD5 compression function was quite a lot weaker
than anyone expected and produced collisions in the compression function.)
SHA-1 has been shown to have a much weaker compression function than the
designers intended.
No one has shown any such weaknesses in RIPEMD-160, SHA-224, SHA-256,
SHA-384, SHA-512, Tiger192, or WHIRLPOOL.

@_date: 2014-11-10 13:51:29
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
ObDisclosure: I work with NIST maintaining some software connected to
the National Software Reference Library.  I am not a NIST employee; I've
never taken a paycheck from NIST; I just work on an open-source project
to help people use the NSRL.

@_date: 2014-11-10 14:08:41
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
Last addendum, I promise:
A question got raised: "Wouldn't this give you a random message that the
signature would also work for? Could it even be used to forge a useful
First question: yes.  Second question: probably not.  Maybe, depending
on how the signature was being used.  There are good reasons why nobody
attacks signatures with rainbow tables.
I apologize for not making this clear in my earlier email -- I thought
it went without saying, but maybe the clarification is useful.

@_date: 2014-11-10 14:10:13
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
(a) that's not a rainbow table
(b) that's a table about a hellabyte in size
One hellabyte is about 50,000 times the total informational content
generated by the entire human race over the whole of our existence, by
the way.

@_date: 2014-11-10 14:36:01
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
"in the first place" meaning "since it was proposed in 2004".
Yes, but strangely, despite the fact OpenSSL's Dual_EC_DRBG support
never worked outside of the test harness, nobody ever filed a ticket
against OpenSSL demanding Dual_EC_DRBG be fixed.
BSAFE may have used it by default (much to RSA's shame, and they deserve
to spend a long, long time living it down), but BSAFE isn't anywhere
near as big of a player in the market as OpenSSL is.  The two biggest
players in that area are Microsoft, which supported it but not by
default, and OpenSSL.
But I agree, saying that "nobody used it" was going a little far.  I
think it's accurate to say very few people used it.

@_date: 2014-11-10 14:41:19
@_author: Robert J. Hansen 
@_subject: DSA key sizes 
Whoops, my bad.  Sorry.  That table would have more entries than there are atoms in the universe -- by an extremely large margin.

@_date: 2014-11-12 10:42:55
@_author: Robert J. Hansen 
@_subject: GPG 2.1.0/Win32: keyserver lookup problems 
This turned out to be exactly it.  Thank you, Michael: this was driving me up the wall and making me wonder if I'd been hallucinating.  :)

@_date: 2014-11-12 11:02:31
@_author: Robert J. Hansen 
@_subject: ECDSA vs EDDSA 
Everybody makes a braino sooner or later.  God knows I have my own litany of them.  :)

@_date: 2014-11-13 10:02:59
@_author: Robert J. Hansen 
@_subject: GnuPG 2.1 and Mailpile (LWN comments) about GPGME 
Not to beat a broken drum, but making it easier to use GPGME from a
Microsoft environment would also be nice.  MSVC++ needs a .lib file for
each DLL you're going to link against, and GPGME/Win32 doesn't ship with
one.  Although workarounds exist (making your own .lib file, dynamically
opening the DLL, etc.), it would be nice if GPGME could be released with
a .lib file.
I'm not particularly keen on Microsoft environments for a lot of
reasons.  However, they do have 85%-90% marketshare.  If our goal is
ideological purity, MS should be avoided; if our goal is to provide
privacy tools to the most people possible, we need to consider MS
environments to be a high priority.
Given the announcement yesterday from MS about how they're opening up
the .NET server stack, I think we might see a resurgence of C# in the
UNIX space.  I have to say, it'd be really nice to see C# bindings for
GPGME.  There's already one set of them, gpgme-sharp, but I believe
they're unmaintained.

@_date: 2014-11-13 17:23:39
@_author: Robert J. Hansen 
@_subject: gpg4usb: Portable GUI for GnuPG 
I mean no offense, but this seems like a really bad idea.  Putting it on CD-ROM might be a pretty cool idea, but USB is just ... scary.
According to Vint Cerf, roughly one in five desktop PCs is already pwned by malware.  Plug your USB token into three different computers and you've got 50/50 odds of your crypto hardware being plugged into a machine that's under the control of a malicious adversary who wants to use your USB token as an infection vector.
It's a great goal, but the way you're going about it makes me shiver.

@_date: 2014-11-13 19:41:39
@_author: Robert J. Hansen 
@_subject: GnuPG 2.1 and Mailpile (LWN comments) about GPGME 
Sure, I'm up for that.
Can't.  I'm a forensics researcher who's received some USG funding; in
the eyes of a lot of people, especially post-Dual_EC_DRBG, I'd be
suspect.  It's best for the overall trustworthiness of GnuPG if I stay
away from development tasks.
I wish it was otherwise, but ... there you have it.

@_date: 2014-11-13 21:15:17
@_author: Robert J. Hansen 
@_subject: Fermi estimates 
A while ago Hauke asked if the statement in the FAQ about a brute-forcer
leaving the Earth uninhabitable was correct.  I said it was, but I
didn't break out the math.  Now that I have a few minutes to breathe,
here's the full answer.  It's a Fermi estimate, which means it's not
going to be perfectly accurate.  It's going to be in the ballpark, but
more than that isn't guaranteed.
The Landauer bound: you can't flip a bit using less than 10**-29 joules
of energy.
The Margolus-Levitin theorem: at 10**-29 joules of energy, you can't
make it flip faster than 10**-5 seconds.
Let's estimate the bitflips needed to check a key at a cool one million.
 That covers loading the new key, populating key schedules, doing a
trial decryption, the whole nine yards.  10**6 operations per key.
Let's also say your computer can flip 100 bits at a time (10**2).
10**6 bits per key, processed 10**2 at a time, means a total elapsed
time of (10**6 / 10 **2 = 10**4 bitflips per thread, multiplied by
10**-5 seconds per bitflip, equals 10**-1 seconds) a tenth of a second
per key.  Now, before you say "but my computer's much faster than
that!", your computer also isn't running on less power than you generate
by scuffing your feet on the carpet.  We'll be exploring faster
computers in a bit.
Breaking a 128-bit cipher by brute force requires about 10**38 key
attempts.  10**38 attempts times 10**-1 seconds per attempt equals ...
uh ... a lot of seconds.  10**37.  A year is more or less 10**7 seconds,
so 10**30 years.  The universe is about 10 billion years old, or 10**13
years, so ... our brute-force key cracker takes 10**17 times longer than
the age of the universe in order to brute-force a 128-bit key.
Clearly, we need to speed things up a bit.  We need to upgrade from a
carpet-scuffing system to two hamsters running on a treadmill.
Unfortunately, that's only a few thousandfold power improvement, so
we're going to have to give the hamsters amphetamines to get them the
rest of the way.  Now, with 10**30 times the power input (these are some
*good* amphetamines), our brute-forcer will be finished in a single year.
10**38 attempts at 10**6 bitflips per attempt equals 10**44 bitflips
total.  At carpet-scuffing power, that's about 10**15 joules of energy,
or about a single one-megaton nuclear bomb.  Admittedly, that energy
gets released over 10**13 times the age of the universe, so that's not a
big problem.  But to make our brute-forcer 10**30 times faster (so it
can run in one year), our brute-forcer also has to release 10**30 times
as much heat.
I'm not an astrophysicist, but that's the kind of energy levels one
normally associates with phrases like "perturb the false vacuum" and
"unmake the universe at the speed of light."  Look at the time, I must
be going.
Also: I'm hiring for a minion.  (Lackey, lickspittle, graduate student.
 Call it what you like.)  The pay is almost nothing, but somebody's got
to clean the hamster cage while I'm gone.  I'm moving to the nearest
convenient parallel dimension.  It's getting weird and dangerous around

@_date: 2014-11-13 21:36:34
@_author: Robert J. Hansen 
@_subject: Fermi estimates 
10 billion is 10**10, so it takes 10**20 times the age of the universe.
But at some point, who's counting?

@_date: 2014-11-14 10:22:14
@_author: Robert J. Hansen 
@_subject: Fermi estimates 
The real purpose of a Fermi estimate isn't to give you solid answers:
it's to give you an appreciation of the problem.  If it does that, it's
done its job.
(Also, a listmember named Ineiev points out that I *may* be misapplying
the Margolus-Levitin theorem.  It's ... interesting.  I need to think on
it for a while.  The objection is basically, "that much energy has to be
present, but not necessarily released as heat: Landauer still applies.
You need something really energetic, but that energy might not be
world-ending."  I don't know: I need to think about that.  :) )
Nope.  The odds are considerably worse than the lottery, though.
The assumption is the key is broken after exhausting 50% of the keyspace.
We're assuming the cracker has a crib -- a known message header or
something similar.  This is usually a safe assumption to make.
Checking takes time, yes.

@_date: 2014-11-14 10:32:51
@_author: Robert J. Hansen 
@_subject: Why the software is crap 
(a) delete random_seed
(b) copy your .gnupg directory over
I don't see the problem.  I've done this at least fifty different times
in the last year as I've stood up virtual machines.  If you'd like a
copy of the Python script I use to do this quickly, say the word.  It
probably won't be useful for you unless you stand up a lot of virtual
machines, but...
These are not facts.
Take a deep breath.  There are people here who want to help you, people who have successfully done what you want to do.  Keep a cool head and work the problem.  Let's not make matters worse with harsh words, okay?

@_date: 2014-11-15 21:28:39
@_author: Robert J. Hansen 
@_subject: GnuPG Migration Assistant 
Over the last few days there's been a lot of angry and hurtful words
thrown about surrounding the subject of trying to migrate a GnuPG 2.0
keyring.  I'm not going to weigh in on who's got the right of things or
who's being unreasonable.  I think we've all had the experience of being
deeply frustrated with things not working the way we think they should,
and as always I think a little sympathy for the frustrated is appropriate.
Don't get angry.  Do something productive instead.
So, in a spare hour I put together a quick and dirty tool to help Mac OS
X, Windows and UNIX users migrate their keyrings.  It's such a quick and
dirty tool that I don't have a fancy name for it, just "gpgma".
If you want to take a look at it, download it from
I've tested this out on both Windows 7 and on Fedora 20 using Mono 3.10.
It's primitive but it works and it might help you.  If there's interest
from the list, I'll see about turning it into a real application.
How does it work?
1.  Uncompress the zipfile to a directory and cd into it.
2.  (Windows) Double-click "gpgma.exe"
    (UNIX/Mac OS X) From a terminal, "mono ./gpgma.exe"
3.  You'll have a bouncing baby zipfile on your desktop.
Q0.  Didn't Hauke suggest something like this?
A0.  About a month ago or more, yes.  Nothing came of it, so I decided
to run with it.
Q1.  I don't trust it!  I don't trust you!
A1.  Great!  That's why you have source code.
Q2.  What's it licensed under?
A2.  This is so simple that I haven't even bothered to put an ISC
license at the top.  If it becomes important to you to have an official
free license for it, I'll post a revision with the ISC license at the top.
Q3.  Why C
A3.  Because it works across Mac OS X, Windows, and the free UNIX community.
Q4.  How does it work?
A4.  As simply as possible.  It figures out what OS it's running on and
looks for the appropriate GnuPG data directory (%APPDATA%\GnuPG on
Windows, $HOME/.gnupg for the others).  It then walks through that
directory looking for certain files, which it adds to a zipfile it
writes to your desktop.  (And yes, it handles the various Mac OS X,
Windows and UNIX desktop directories correctly.)
Q5.  Where can I find a signature for it?  I don't want to run a binary
without having a signature.
A5.  The binary is signed with the Authenticode key I use for my
professional work.  There is no detached signature for the binary.
Q6.  What about a signature for the source code?
A6.  Why?  It's like 100 lines.  Read it yourself and figure out if
there are any problems with it.
Q7.  It doesn't run on my [insert type of OS].
A7.  You need either Microsoft's .NET runtime (4.0 or later), or Mono
3.2 or later.  A lot of Linux distros still ship with Mono 2.10.
Q8.  It would be nice if...
A8.  I'm listening.  Talk to me.
Q9.  Are you going to put this on Github?
A9.  At only 100 lines of code, it's kind of embarrassingly small to put
on Github.  If there's interest, though, I'll put it up.
Q10. Is this an official GNU project?
A10. No.
Q11. Is this connected with GnuPG in any way?
A11. No.
Q12. I have Mono 3.10 on UNIX/Mac OS X.  How do I compile it?
A13. mcs -pkg:dotnet -r:System.IO.Compression -o:gpgma.exe gpgma.cs

@_date: 2014-11-17 12:02:07
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
This would have the ultimate effect of destroying email as a platform. Email works as well as it does -- as well as fails so miserably in other ways -- largely *because* it's open to inspection.
As an example, pervasive end-to-end encryption would require antispam defenses to move to the client rather than being deployed at the mailserver or relay.  This would essentially be tantamount to giving up, since there are no really effective client-side antispam measures.
Similarly, it would assist in the spread of malware and viruses and for the same reasons.  If a mailserver can't inspect the email, it can't recognize malware and quarantine it for the health of the internet.
Etc., etc.  I am fanatically in favor of people's right to protect the privacy of their communications, but there's a flipside to it: we also need to be responsible and prudent with how we do it.  Simple, naive solutions like "encrypt everything!" aren't a fix: at best, they'll trade our current set of problems for a new set of problems which we'll have even less knowledge of how to handle.

@_date: 2014-11-17 13:49:01
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
It also means there's pretty much no point in keeping archives, because it's inevitable that the keys will become separated from the archives. And if the key is part of the archive, then what's the purpose of the crypto in the first place?
Once, for my job, I had to look into the way the Roman Senate conducted its elections.  I was able to find ballots that were over 1500 years old.  It was pretty neat, and it changed my perspective on things like The crypto dream is that the confidentiality of our messages will be preserved for centuries after our death, which sounds really great up until you consider what an archaeologist circa 4000 AD is going to be thinking.  "I have a stack of records here that could shed light on the way people lived in a long-dead civilization, but I can't read them. Why?  What were these people doing that they thought their email to their Aunt Edna needed to remain secret for all time?  Why is it that, millennia after they're gone, Aunt Edna's recipe for potato salad has to be gone with them?"
Or think about your own kids, circa 2040 AD.  "I'd love to read these emails between Mom and Dad when they were courting, but ... they were afraid of Somebody-with-an-S reading their emails.  I wonder if they ever thought that the Somebody might be their son, who wanted to understand after their deaths how it was these two people came to meet and fall in love."
Historians called the early medieval period "the Dark Ages" not because the era was full of villainy and evil, but because record-keeping became so austere that we really don't know much of what happened for that period.  Much like dark matter (matter, but we don't know anything about it, hence it's dark), dark energy (energy, but we don't know anything about it, hence it's dark), the Dark Ages are an era we know little about.
We're living in a new Dark Age right now.  Historians of the future are going to see human record-keeping basically end around 1960.  Fewer records were printed out and more were put on digital media -- media that deteriorates much more quickly than paper, and depends on technology to read it, technologies which become obsolete and are discarded even faster than the media degrades.
So when you hear people advocate "crypto everywhere, always, for everything," ask yourself this: if they get what they want, what will it do to future generations' ability to make sense of our time?

@_date: 2014-11-17 15:21:13
@_author: Robert J. Hansen 
@_subject: Update 
>
 > [a lot of stuff with no quote-editing]
 >
Please, guys. Werner has asked for us to trim our quotes, not to just quote the other person's email in full.  Let's do that, okay?

@_date: 2014-11-17 17:38:15
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
Given that I've seen PGP-signed spam mails, no, I think you're being naive.
Then I don't want it.  If you're running the mailserver and you can decrypt my secured messages, then there's nothing preventing the federal government from serving you with a subpoena saying, "please hand over the encryption keys."
The only person who can be trusted to do the decryption is the end user, running on hardware the end user directly controls.
I care very little about what happens to corporations.  You're still talking about destroying the antispam experience of end-users.  That's what I have the biggest problem with.

@_date: 2014-11-17 18:11:39
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
Oh, please.
If I take you seriously then I'm only concerned about people with power
who wish to exert power over me.  Nonsense.  I'm concerned about *it's
nobody's business but mine*.  I don't need to subscribe to
power-relations theory in order to believe privacy is a good idea; I
just need to believe some things are nobody's business but mine.
I don't know what you're trying to say here.
We also know, quite precisely, the thermodynamic limits of computation.
  Power evolves, but is easy to account for.  Mathematical understanding
is harder to predict.
No, the printing press didn't solve the problem.  Gutenberg invented the
printing press in the 15th century, but we've got *great* records going
back to the 11th century.  And we've also got great records going back
to ancient Egypt.  It's only a few centuries after the collapse of Rome
that are lost to history.  They weren't lost for technological reasons:
they were lost for human ones.
Many magnetic tapes from the Viking program (a 1976 effort to put a
probe on Mars) were put in storage for later processing.  Around 2010,
NASA finally got around to processing these tapes... only to discover
the machines to read it no longer existed, no one knew what data format
it was written in, and not one single person associated with the Viking
program was still at NASA.  Many of them were dead.  It took an enormous
amount of resources to reverse-engineer the format, rebuild/rehabilitate
old tape machines, and pull the data off.  If the data had been less
important than "this is stuff we pulled from *MARS*", the entire thing
would've been written off as a sad case of knowledge being lost to the ages.
In 1086, William the Conqueror ordered the whole of England be surveyed
and every plot of land described.  That text, the Domesday Book, is
still around today.  In 1986, to celebrate the 900th anniversary of the
Domesday Book, the BBC put together a neat little computer package that
was a modern updating of Domesday.  Good luck finding it today, though.
  The UK National Museum of Computing in Milton Keynes is the only place
I know of that still has working BBC-Domesday hardware.  There have been
a couple of attempts to take this project and salvage the data and
programs, but so far it's been a big case of not enough money and not
enough skilled volunteers.  Some of it has been salvaged, but as a
whole... no, and it's probably going to be lost to us.
Every MLS/MLIS I know is having anxiety attacks over the subject of
digital decay.  This is a *huge* problem, and it's only getting worse.
Walk into your local library sometime and ask to see their newspaper
collection.  You might be surprised.  My local library has newspapers
going back over a century.
This is just the fallacy of the zero-sum game, so I'm not even going to
bother with it.
I did not say, "we should not ensure the privacy of our records."
I said, "we should consider what we are giving up when we demand eternal

@_date: 2014-11-18 10:11:41
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
A third party -- your mailserver administrator -- should never handle
the decryption or signing.  (There may be a couple of use cases where it
makes sense, but they're few and far between.)  All it takes is a
subpoena, and any citizen can file one of those.
It appears that you're selling a "solution" that involves giving a third
party access to your plaintext, all the while telling people that your
product will keep their communications secure.  I don't see how that can
be called anything other than snake oil.
So far you've --
* Made false claims that DSA is compromised
* Made false claims that NIST only minimally changed a compromised
   standard
* Advocated giving third-parties regular and routine access to
   plaintext
None of this is compatible with your claim that you're concerned about
human rights groups and stopping mass surveillance.
Please stop hyping snake oil.

@_date: 2014-11-18 11:09:05
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
Sure, but that also destroys the email ecosystem.  One of email's
strongest points has been that no introduction is necessary to begin a
conversation.  This year I found myself re-engaging with a friend I lost
touch with a decade ago, who found me on a mailing list and figured to
drop an email and see if maybe I was the same Rob Hansen she knew from
back when.  If my MUA/MTA had hidden it from me just because there was
no introduction, or urged me to delete it without reading...
Could email as a platform survive the shift to introduction-based
systems?  Sure.  But it would totally transform the email experience,
and maybe in ways we wouldn't like.  That's why I'm so skeptical of
proposals to fix email in this way: we might fix email, but we might
also kill it at the same time.
It already is.  Double-click on an executable attachment and a window
will pop up with a warning about how you should only run code from
people you know and trust, click "OK" to cancel running this, click "I
know the risks" to run it, etc.
An awful lot of people click "I know the risks."
I've told this story before, but it bears repeating --
During my grad school days I had a colleague named Peter Likarish.
Peter did some great work in using Bayesian statistics to detect
phishing sites.  Ultimately, he had an algorithm that could look at
webpage content and decide with 95% accuracy whether it was real or
phish-phood.  He packaged this up inside a Firefox extension: when you
browsed to a site and the plugin detected a phishing attempt, it would
put a narrow red stripe over the top of the screen saying, "Warning:
this may be a phishing attempt!"
He put it into human trials using the University's HCI (Human-Computer
Interactions) lab.  The results were dismal.  Post-experience interviews
revealed that people weren't looking at the top of the web page.  They
genuinely didn't notice a red stripe across the top of the screen.
So Peter went back to the drawing board and made a new interface.  Now,
the banner started off small, but there was a "Click to dismiss" button
on it.  Further, the banner would grow larger over time.  Peter knew
that the human eye is sensitive to motion: our eyes naturally are drawn
to things that change.  By making the banner grow larger, he figured he
could increase its visibility.
Back to the lab, and ... still dismal, soul-crushing results.  This
time, the overwhelming majority of the users confirmed they saw the
warning.  When Peter asked them why they chose to ignore it, the
majority said they thought it was just another Flash ad that was hyping
some "fix your PC fast, now!" solution.
I ran into Peter shortly after he finished his final day of human
trials.  He was normally a very cheerful guy, but this day he just
looked shattered.  I suggested we walk down to the nearest watering hole
and grab a beer, but he was too dejected.  He said that of all the
outcomes he imagined for his Ph.D., he never dreamed that it would be
that his research could be accurately summed up as, "the technology
works fine, it's *people* who are completely broken."
Shortly after I left grad school Peter found a warning mechanism that
worked, incidentally.  It's a cute technology and one I really wish more
browsers would incorporate.  I don't have a URL for a PDF of the paper
handy, but the poster he presented at SOUPS 2009 is available online at:

@_date: 2014-11-18 14:34:57
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
You're introducing a single point of failure -- and a SPOF that's highly susceptible to coercion, at that.
You say you're opposed to widespread surveillance: this does *nothing* to address that.  The only people it will stop are the people who aren't smart enough to realize, "You know, I could just get a subpoena."  Or the ones who think, "You know, I could just plant malware on the sysadmin's computer and gain access to all their encrypted communications at once."  Or the ones who think...
I think that's exceptionally foolish.  Build systems that provide a measure of security against smart, dedicated attackers -- don't build systems that only provide it against childish ones.
This is not a solution.  This is a surrender.
You have not presented *any* evidence that 1024-bit keys are compromised.
For that matter, you haven't presented any evidence that you understand what a FIPS is.  A FIPS is a *Federal* Information Processing Standard.   It's not binding on private citizens.  All FIPS 186-x says is, "if you want to use digital signatures with the United States Government, here is the digital signature scheme that we use."  FIPS specifies a standard for the USG to use, not one for private citizens to use.  Is it really so strange that a standards document would specify parameters for an For that matter, DSA has never been limited to any keysize, not even under the FIPS 186-2 regime.  DSA is the Elgamal signature scheme with a very slight algorithmic tweak to reduce one avenue of attack on it.  If a private citizen likes DSA but thinks it would be better with a 8192-bit key, they're free to go for it.  It's just Elgamal, after all.   We know how to extend DSA arbitrarily.  We just don't, because there's really no point in it.
FIPS 186-2, which you're obsessing about, was released in January of 2000.  In January of 2000, 1024-bit keys were expected to be safe for the next 20 years.  There has never been *any* credible hint that, in January of 2000, the belief was that Elgamal signature schemes of length 1024 bits were suspect.  It was the standard signature scheme in use in GnuPG 1.0 and PGP 6.5.8, both of which date back to that era.
Find me a single peer-reviewed paper published in a reputable journal that says DSA-1024 is compromised.  (Joe Bob's Web Page of Crypto doesn't count.  Something like EUROCRYPT or Financial Cryptography does.)
Just *one*.
Do that and I'll happily eat a whole steaming plate of crow, feathers and all.  But until then, I believe you're a dangerous charlatan.
False.  See, e.g.:
Browse around there and you'll find Suite B is certified for TS/SCI information.  Again: this is publicly available information that the authors want to be shared as broadly as possible.
False.  Let's quote the exact page, shall we?
"[Suite B] serves as an interoperable cryptographic base for both unclassified information and most classified information."
It never says it's only good enough for most classified information.  It says it's used as an interoperable cryptographic base for most classified information.  Given the size of the USG, it wouldn't surprise me if there was a rotor machine still in use somewhere.  There's a lot of inertia there: bureaucracies don't change overnight, and the entire USG didn't switch to Suite B the moment the spec was published.
With respect to DES, false.  DES was proposed to the National Bureau of Standards (NIST's predecessor) in 1976; it was published as a FIPS in 1977, and was subjected to periodic five-year reviews in '83, '88, '93 and '99.  No compromise has ever been discovered in DES; as of today, the best known method for breaking DES is brute force.
You have not presented evidence for a single compromise against DSA. You point to a FIPS parameter specification and say "the only reason this would happen is if it was compromised!", yet the civilian cryptographic community -- which has looked at DSA *very* closely -- disagrees emphatically.
Dual_EC_DRBG was handled in an appropriate manner: NIST advised against its usage and then completely withdrew it from the standard.
I've been quite careful, and I believe you're hawking snake oil.

@_date: 2014-11-18 19:31:55
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
No.  Client-side, you get to inspect (fully) only your data, and you
have to develop a statistical model of spam based on only your data.
When Gmail filters, it inspects (fully) traffic to *millions* of users,
and uses that to create a model no individual user can hope to match.
Encrypting everything, even Aunt Edna's recipe for potato salad, means a
significant step backwards in the spam fight.  I love decentralized
algorithms, but there's something to be said for a God's-eye perspective
on the problem -- look at decentralized route discovery protocols versus
Dijkstra's algorithm as an example.
Maybe one user in ten thousand has the skill to audit a nontrivial
codebase.  Free software is a good idea, but let's not pretend that
normal users will realize a real benefit from being able to check their
source code.

@_date: 2014-11-19 12:08:42
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
From Google: "A product, policy, etc. of little real worth or value that
is promoted as the solution to a problem."
So let me say it clearly: your product is of little real worth or value.
It's snake oil.  It doesn't appear to bring anything to the table that
SMTP+TLS+DNSSEC doesn't already (as M. Garreau already observed before me).
Except the people you want to sell this service to at $5,000 a year.
You want them to believe you are a knowledgeable expert about
communications and computer security issues.  As near as I can tell, you
are not, nor do you recognize that you are not.
I don't think you're malicious.  I think you're foolish and are trying
to sell your foolishness to the scared and the desperate at a high
price.  I am urging, begging, you to stop.  It's socially irresponsible.
There is no design document referenced from your technical FAQ.  There's
an entry, "What is GoodCrypto's design?", that says nothing of your
design.  It's a marketing document, not something that an engineer can
use to get a grip on how the application stack is architected.
For that matter, even as marketing material it's rife with errors.
"Just reboot to remove Advanced Persistent Threats."
If getting rid of it is that simple, it's neither persistent nor advanced.
"To avoid forensics, most malware is volatile."
Malware, especially poorly-written malware, writes to disk frequently
and leaves behind many traces.  This is the _raison d'etre_ of the
antivirus industry: that's why periodically your AV software scans your
hard disk looking for signatures.
"Elliptic curve [cryptography] is known [to be] compromised."
I would love to see references for this.  Again, peer-reviewed papers in
reputable journals, please.
"Virtual machine attacks are not yet well known."
In fact, they're so well known they've broken out of the high-end
forensics world and into DEFCON.  (Seriously.  At DEFCON 20 Alex
Minozhenko gave a talk on "How To Hack VMWare In 60 Seconds.")
I could go on, but ... I trust my point is made clear.
I've asked for your "clear evidence" several times and the only thing
you've got is, "in 2000, NIST specified using 1024-bit keys for DSA.
Obviously DSA is compromised."  And you haven't even offered that much
for your claim that elliptical curve cryptography is compromised.
It's important to me because I despise snake oil, especially when it's
sold to desperate and scared people.
I am not associated with NIST in any respect other than "I wrote a piece
of software for the forensics community which helps facilitate hash
lookups against a NIST dataset."
Anyway.  I'm finished here.  I think there's now enough of a record
associated with this that when people thinking of dropping $5K on
GoodCrypto do a Google search for it, they'll find my objections.

@_date: 2014-11-19 12:17:26
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
I don't mean to sound like I'm dismissing your experience, because -- well -- your experience shouldn't be dismissed.  (Nobody's should.)  But I do think you might be overlooking something: you already experience a significant benefit from the aggressive, God's-eye-view anti-spam efforts of Google, Yahoo!, Microsoft, and more.  The things they do for their users have a ripple effect in making your own anti-spam fight a little easier.
A couple of months ago Mike Hearn wrote a brilliant treatise on end-to-end cryptography and anti-spam technologies, with a long digression on how anti-spam technologies work at Google.  It's worth every second it takes to read.

@_date: 2014-11-19 15:15:34
@_author: Robert J. Hansen 
@_subject: Encryption on Mailing lists sensless? 
And the point I'm making is this: this setup, which works, is what we will have to discard and replace if we move to E2E crypto.
I'm not saying decentralized systems can't work.  I'm saying that before we throw out our current system, we need to look long and hard at what it does, why it does it, and how effective it is -- because as soon as we adopt E2E crypto this thing goes completely away and we're going to need to rebuild it in a quite different way.
No, you don't always end up finding it (where 'it' is 'a decentralized algorithm that offers efficiency equivalent to a centralized algorithm').  There are many algorithms that have no known equivalently-performing decentralized alternative, algorithms where global knowledge is strictly necessary.
Decentralized algorithms also have really interesting failure modes. Back in 2008, a one-bit error in Amazon's S3 cloud propagated from one node to the next and ultimately brought the entire thing down for several hours.  It was a brilliant example of both error propagation and the limits of Byzantine fault tolerance.[1]
I'm a firm believer that decentralized algorithms are a good thing, but let's keep our sense of perspective, all right?  They're not magic and they don't always beat centralized algorithms.
[1]  -- a really fascinating read if you love decentralized algorithms.

@_date: 2014-11-20 11:27:50
@_author: Robert J. Hansen 
@_subject: Backup of encrypted private key on uncontrolled disks 
If you are completely confident that no one will ever get your passphrase from you, this is safe.  Otherwise, it's not.
It may be appropriate to have a little caution with respect to whether you believe anyone will ever get your passphrase from you.

@_date: 2014-11-20 13:53:18
@_author: Robert J. Hansen 
@_subject: Backup of encrypted private key on uncontrolled disks 
The people fooled by Robin Sage were all intelligence professionals of
one stripe or another.  These are people who have been vetted for their
reliability and discretion, and who regularly get briefed about efforts
by foreign powers to get information out of them.  They were all aware
of the risks.  Despite this, they were fooled.
It's really easy to point fingers at them and say, "man, what chumps."
But the reality is none of us on this list are different than they are.
We're human, with the same foibles and weaknesses, and I'm pretty sure
Robin Sage would rip through this mailing list like a chainsaw.
(For that matter, I have no reason to think one isn't doing so right
now.  It's worth thinking about.)

@_date: 2014-11-21 09:47:35
@_author: Robert J. Hansen 
@_subject: How much information can be gleaned about a gpg key by possessing 
Virtually none.
Enough to make it far, *far* more cost-effective to resort to other
methods to recover your key.  Just buying the hard drives alone would
exhaust the budgets of large corporations.

@_date: 2014-11-21 11:31:46
@_author: Robert J. Hansen 
@_subject: Backup of encrypted private key on uncontrolled disks 
For that matter, Eliezer Yudkowski's "AI in a Box" experiment shows just
how prone people are to being gamed.  (And yes, I was reminded of
Yudkowski's work by seeing today's XKCD.)

@_date: 2014-11-21 13:24:02
@_author: Robert J. Hansen 
@_subject: Symmetrical encryption or ... 
Not really.  Sym would appear to be ideal for your use case.

@_date: 2014-11-23 10:09:30
@_author: Robert J. Hansen 
@_subject: Pros and cons of PGP/MIME for outgoing e-mail? 
This subject tends to get a lot of very passionate opinions on both
sides.  The FAQ covers both:
(ObDisclosure: I wrote this entry.)
Until such time as the SMTP ecosystem improves and no longer mangles a
significant fraction of PGP/MIME traffic, I think inline should be
preferred where feasible.  That's just my own opinion, though: take it
for what it's worth.

@_date: 2014-11-25 09:53:52
@_author: Robert J. Hansen 
@_subject: Setpref is not working or is it a bug or something? 
The preferences list in gpg.conf are your preferences for what you use for the mail you compose to others; the preferences list on your key are your preferences for what you'd like other people to use for the mail they compose to you.
They represent two different things, which you seem to have conflated together.  I think this will resolve a good half of your questions.
The other half can be resolved by asking this question: "When I changed my key preferences, then deleted the key, and restored it from a backup I made before I changed my key preferences, how could the backup know about the changes I made *after* I made the backup?"

@_date: 2014-11-25 13:45:28
@_author: Robert J. Hansen 
@_subject: Gpgma 
In some spare minutes while waiting for an airplane to arrive and my
vacation to begin, I did a little more work on the key backup and
migration tool that I mentioned on-list a while ago.  It's still fairly
simple, but there's a good side to simplicity: that also makes it hard
to screw up.
Major changes:
1.  Switched over to Java, mostly for access to a good GUI toolkit[*]
2.  Now there's a proper GUI on it
3.  Better sanity-checking and error handling
4.  Now on Github at If you've wanted to contribute some code to GnuPG but feel a little
intimidated by the size of the codebase and the occasional hairiness of
C, I hope you'll take a look at gpgma.  It works, but there's a lot of
stuff that could be done as well -- things from simple to complicated, like:
* Adding a menu bar to make it look like a normal application (simple)
* Improving error handling and error reporting (simple)
* Making it able to recognize when it's given a corrupted/incomplete
   backup file (moderate)
* Making it back up everything but random_seed, not just the absolutely
   necessary files (simple to moderate)
* Use Eclipse/SWT to make it look native on all platforms (moderate)
If you're interested I hope you'll check it out.

@_date: 2014-11-28 22:27:49
@_author: Robert J. Hansen 
@_subject: Setpref is not working or is it a bug or something? 
This isn't quite true.  personal-*-preferences won't affect s2k
preferences or cert-digest-algo.  However, you're absolutely correct to
advise against using cipher-algo or digest-algo.
(I *think* I'm right on this, but I can't promise I am, nor have I done
a quick empirical test to check.  Take the preceding with a grain of salt.)
Some of them are serious problems (digest-algo and cipher-algo).  The
others are mostly safe.  s2k is only used by the user on their own
machine, so there isn't much concern about interoperability with other
OpenPGP clients.
Those who are concerned about OpenPGP conformance should add "openpgp"
to the end of their gpg.conf file.  :)
Nope!  The preference list you gave will not cause troubles with any
OpenPGP application, not even old PGP 5.x.  If there's no preference
list on your recipient's public key (which does happen, from time to
time), OpenPGP will gracefully degrade to use SHA-1 and 3DES.  SHA-1 is
getting pretty long in the tooth, but 3DES is still solid as a rock.
My usual joke about 3DES -- which, like most of my jokes, is a way of
telling truth with a laugh -- is that 3DES has all the beauty of a
Soviet workers' housing bloc, all the aesthetics of the Socialist
Realism school of art, and yet has been turning brilliant young
cryptanalysts into burned-out alcoholic wrecks for the last 35 years.  :)

@_date: 2014-11-30 15:07:09
@_author: Robert J. Hansen 
@_subject: Order/changing of subkeys derogates compatibility!? 
6.5.8 is about sixteen years old now and has many known security
problems.  Please stop using it.

@_date: 2014-11-30 17:49:32
@_author: Robert J. Hansen 
@_subject: Difference Kleopatra vs WinPT 
============================== START ==============================
WinPT only works with the 1.4 branch of GnuPG and hasn't had a new
release in the last five years.  I'm under the impression Timo (the
author) has stopped working on it or supporting it.  Given that, I'd
have to recommend not using WinPT.

@_date: 2014-10-01 22:34:57
@_author: Robert J. Hansen 
@_subject: NSA, PGP and RSA 
No cryptographer of note has made these claims, and the algorithm has
been continuously studied by the world's cryptographic community for
more than three decades.  So -- anything is possible, sure.  But I think
if you think on it some you'll realize some things are more probable
than others.  :)

@_date: 2014-10-02 10:04:22
@_author: Robert J. Hansen 
@_subject: RSA in theory (was: Re: NSA, PGP and RSA) 
There are some hints the theoretical underpinnings of RSA aren't quite
what we've always believed them to be.  These hints don't point at a
weakness -- just some weirdness that we don't fully understand.  My
reading of the tea leaves says this weirdness will not result in a
serious attack, but I don't recommend people stake much money on my
hunches.  :)
The security of RSA is predicated on three major conjectures:
1.  P != NP
2.  Integer factorization is really hard
3.  Breaking RSA is equivalent to integer factorization
 is strongly believed to be true (but so far there's no proof).   is
strongly believed to be true (and there are good lines of math to
suggest it's so).   is ... now believed to be *false*, [1] which opens
all kinds of doors for cryptographers to study.
Don't panic.  Some top-drawer cryppies are looking at this closely and
so far they keep on using phrases like "Our results do not expose any
weakness in the RSA system" when talking about their findings.  This is
a fascinating area of ongoing research, *not* any indication of weakness
in the overall system.
But yeah, we've got some tantalizing hints that the theoretical
underpinnings of RSA aren't quite what we've always believed them to be.
 It's a fascinating time to be alive!
[1]

@_date: 2014-10-02 14:45:52
@_author: Robert J. Hansen 
@_subject: producing GnuPG keys as proof of work 
Depends.  Expert users, sure; new users, or people who aren't that
interested in GnuPG but just want to get access to a website, not so much.
I have to ask -- why?  What particular use case is this?  Why use GnuPG
as a proof-of-work as opposed to giving someone six bytes and saying,
"find me a SHA256 hash that starts with this, and provide me with it"?

@_date: 2014-10-02 16:58:42
@_author: Robert J. Hansen 
@_subject: producing GnuPG keys as proof of work 
How?  What is there about the proof of work that can somehow
authenticate a GnuPG certificate?

@_date: 2014-10-03 13:15:54
@_author: Robert J. Hansen 
@_subject: [Announce] The maybe final Beta for GnuPG 2.1 
Indeed.  Today's also Tag der Deutschen Einheit ("German Unity Day"),
which celebrates the end of the GDR -- whose secret police service, the
Ministerium fuer Staatsicherheit[*], commonly known as Stasi, practiced
surveillance of its own citizens on a scale that's hard to imagine.  So,
celebrate your privacy by donating to GnuPG and sitting down with the
movie _Das Leben der Anderen_, released in English-speaking countries as
_The Lives of Others_.  It's a remarkable film and worth seeing.
[*] Werner, Wikipedia lists it as Staatssicherheit, but for some reason
that just doesn't look right to me.  Is it?

@_date: 2014-10-03 14:16:04
@_author: Robert J. Hansen 
@_subject: [Announce] The maybe final Beta for GnuPG 2.1 
These are forgivable character flaws.  :)
Ah, that explains my difficulty.  My usual grammatical rule of thumb for
German is "imagine 18th-century English," which works fine most of the
time but breaks for the genitive case (on account of English not having
one -- the way we structure possessives is a remnant of the Saxon
genitive, but it does not represent an actual grammatical case).
Thanks.  :)

@_date: 2014-10-09 02:20:37
@_author: Robert J. Hansen 
@_subject: How do I see what algorithm is used for a signature 
gpg2 --fixed-list-mode --with-colons --list-key [keyID]
Once you learn how to read that output, you get a *ton* of information.
 It's kind of overkill for most tasks, but it's kind of like learning
how to use flex and bison: once you get the knowledge, you wind up using
it in places you never thought you would before.
Look for lines that look roughly like:
The number in the fourth field (third, if you're zero-indexing), which
here is 17, is the algorithm descriptor.
1: RSA (encrypt or sign)
2: RSA (encrypt-only -- if you see a sig with this, something's wrong)
3: RSA (sign-only)
16: Elgamal (encrypt-only -- ditto)
17: DSA
19: Reserved for ECDSA

@_date: 2014-10-09 20:48:59
@_author: Robert J. Hansen 
@_subject: How do I see what algorithm is used for a signature 
... which is exactly what my method does, so I don't understand what
you're saying here.

@_date: 2014-10-16 14:58:31
@_author: Robert J. Hansen 
@_subject: Libcrypt examples? 
Please don't take this the wrong way, but -- please don't.  Libgcrypt is
not particularly friendly to novices.  It exposes a *lot* of dials and
switches in the interests of letting experts do weird and useful things.
 Novices will be better-suited with something like Peter Gutmann's
cryptlib, which is high-quality and well-regarded and is probably more
I believe on FreeBSD this is just bog-standard DES, but I could be
mistaken.  DES is not a strong cipher.
To help foil brute-force attacks.  crypt(3) is normally used with really
short pieces of text -- passwords.  As such, one way to attack passwords
is to get a large dictionary of words and run each word through crypt(3)
and store the result.  If you want to break a password, look at its
crypt(3)ed value and compare it to your database of computed values.  If
you get a hit, then look back at what the original word was.
To foil these sorts of attacks ("dictionary attacks"), crypt(3) has been
built to be very, very slow.

@_date: 2014-10-16 15:15:55
@_author: Robert J. Hansen 
@_subject: Libcrypt examples? 
The question then becomes, "who are you securing this data against?"  If
your goal is to keep data on someone else's computer in a form that they
can't read, you should be advised going in that it's a fool's errand.
Can't be done.
As an example of how it can be foiled: while your program is running,
tell the computer to hibernate.  It writes a memory image to disk.  Load
the memory image into a tool like Volatility and start searching through
memory looking for AES key schedules.  There won't be more than a
handful of them.  Recreate the key from the key schedules and bam,
you've got the original key and can read/write this data stream at-will.
This is not an abstract or theoretical thing.  This is real.  I've done
it.  If you're interested in reading more, check out "The Persistence of
Memory: Forensic Identification and Extraction of Cryptographic Keys."
It was presented at DFRWS back in '09, and is available online at:
It's a good read, including a footnote where they talk about how they
managed to break PGP 8 this way.
If you're doing what I suspect you're doing, there really aren't any.
There are a lot of techniques that don't work at all, and of those some
are simple, and a lot of people use them without knowing that they don't
work, instead believing that everything's going swimmingly because they
don't, themselves, know how to break it.
The manual is sufficient for its intended audience.  Crypto has a steep
learning curve and no one manual can reach all audiences.  Some crypto
libraries are meant for people who don't care about the difference
between CBC mode and Galois Counter Mode; others are meant for people
who care quite a lot.  Libgcrypt is in the latter category.
I'm sorry if you find the libgcrypt manual to be of no use, but if it's
of no use, please consider the possibility that you are not libgcrypt's
intended audience.  That's no slight on you, on your coding ability, or
your professionalism.  I'm a highly-skilled data forensics nerd, but
when I have to do digital signal processing my eyes glaze over when the
A/V nerds start talking about how the butterfly interleave of the fast
Fourier transform is fundamentally and deeply connected to the roots of
unity.  There's no shame in not knowing everything, because really, how
could anyone be expected to?

@_date: 2014-10-17 00:00:41
@_author: Robert J. Hansen 
@_subject: Libcrypt examples? 
Crypto comes in only two varieties: the kinds that will keep secrets
safe against a motivated thirteen-year-old, and the kinds that will keep
secrets safe against space aliens from Zarbnulax.[*]
It's kind of the nature of this list to believe there's no point in the
former and to obsess over the latter -- when neither dismissal nor
obsession is actually a very good policy.  I'm not going to dismiss the
former kind of crypto: my only lookout is making sure that you're fully
appraised of the risks.  Which it seems like you are, so go with God and
happy hacking.  :)
[*] "the space aliens from Zarbnulax" is my usual shorthand for "an
adversary with knowledge of mathematics and science far beyond ours, and
computers that operate at the outer edge of what the universe will
bear".  Most of the regulars on the list have heard me talk about the
Zarbnulaxians before, but I figure a heads-up for the newcomer might be
Excellent!  I'm glad we could point you in a useful direction.
Incidentally, the author of cryptlib is a pretty reasonable guy.  If you
have questions shout out to him and I suspect you'll get reasonable
answers.  :)

@_date: 2014-10-17 14:23:25
@_author: Robert J. Hansen 
@_subject: The return of the crypto wars ? 
Warning: I am not a lawyer.  But that's okay, because this law firm
doesn't appear to have any lawyers, either.
In 1995, Dan Bernstein wanted to electronically publish an academic
paper and supporting source code which implemented a cryptosystem.
Under the regulations in place in '95, this was a violation of ITAR and
EAR, the two comprehensive set of rules that govern how munitions and
sensitive information may be exported.  Bernstein filed a lawsuit
claiming this was a violation of his First Amendment right to speak freely.
The trial court, administered by Judge Marilyn Patel, agreed with
Bernstein.  So did the appellate court (Judges Bright, Fletcher and
Nelson).  The government asked for a third level of appeal, the
so-called "en banc review." [1]  The appellate court withdrew their
decision pending the en banc review -- but at the last minute the
government changed the ITAR and EAR regulations in ways that would let
Bernstein post his source code, so the entire case became moot.
There's another case that's on-point here -- _Junger v Daley_, coming
out of the Sixth Circuit in ... uh ... I don't know: '96?  The decision
came down in 2000, at any rate.  The Sixth Circuit held that source code
is protected by the First Amendment.  The government has no more
authority to prevent a U.S. person from publishing source code
internationally than it would have authority to prevent a U.S. person
from sending a painting to the Louvre, or a copy of a book to a friend
So, yeah.  I am not in any way worried.  The U.S. government has argued
*five times* in federal court that libre hackers may be prohibited from
sharing our source code internationally... and *five times* the federal
courts have smacked it down as unconstitutional.  There's a lot of
precedent protecting libre hackers.  For once, the system worked the way
it's supposed to.
[1] The United States federal judicial system is broken up into what are
called "circuits".  California, Hawai'i, Alaska, Oregon, Washington and
some other states comprise the Ninth Circuit.  In every circuit but the
Ninth, en banc review means *every* appeals judge on the circuit is
asked to weigh in on a decision.  The Ninth Circuit is so large, though,
that polling every appellate judge is considered impractical.  Instead,
in the Ninth Circuit an en banc hearing means the case is heard before
11 different appellate judges.
If you get the idea en banc review is a big deal, you're right.  Very
few cases receive en banc review, and those are usually ones that the
appellate court believes are making a beeline for SCOTUS.
The reason why I called it the "so-called 'en banc review'" is because
it's a misnomer.  In the Ninth Circuit, an en banc review isn't really
an en banc review -- it's just 11 judges, not all 45.

@_date: 2014-10-17 14:29:20
@_author: Robert J. Hansen 
@_subject: The return of the crypto wars ? 
Err, sorry.  Argued five times in federal court, been smacked down four
times.  They would've been smacked down a fifth, but the government
mooted the case by capitulating to Bernstein.
I apologize for the error.  Still, it doesn't change the bottom line:

@_date: 2014-10-17 16:04:28
@_author: Robert J. Hansen 
@_subject: The return of the crypto wars ? 
Commercial speech receives fewer legal protections than political,
artistic, or scientific speech, but it's not unprotected.  Basically,
corporations can be required to file paperwork before exporting crypto.
 It's not much paperwork, either: I think it's only a couple of pages'
worth that have to be faxed over to the Department of State.
In the case you're talking about, Wind River wasn't punished for
exporting crypto -- they were punished for not filing two pages of
information with the Department of State.  If they had they would've
been just fine.

@_date: 2014-10-17 16:12:46
@_author: Robert J. Hansen 
@_subject: Libcrypt examples? 
No.  Quantum computers still obey the mathematical laws of computation
as formulated by Turing and Church and others, and obey physical
constraints like the Landauer bound, the Margolus-Levitin limit,
Bremermann's limit, the Jarzynski equality, and more.  If you take all
of these principles and plug them together, you get what's called
"quantum information theory" -- a framework that lets you put limits on
how fast computers can operate and what minimum energy is required to
run them.
It's pretty easy to show, for instance, that breaking a 256-bit cipher
with a Zarbnulaxian quantum computer would release so much heat the
earth would be uninhabitable.  That's why I'm pretty sure no one on
earth is anywhere near close to being able to break it: because if they
were, none of us would be alive to talk about it.  :)
The coolest thing about quantum information theory, though?  You can
sing it to the Teenage Mutant Ninja Turtles theme song.  "Quantum
information theory!  Shannon is my homeboy!  QUANTUM POWER!"
I changed  for you.  :)
The reason why I never talk about "the [insert-three-letters-here]" is
because those conversations deteriorate very quickly.  Once you invoke
those three letters, many otherwise-rational people turn into unhinged
conspiracy theorists who buy even the most absurd claims.  As an
example, over on the Enigmail list there was someone who sincerely
believed that a site parodying the [insert-three-letters-here], which
*explicitly said it was a parody*, was in reality the real deal and
everything it said should be believed.
Once you start using those letters the overall quality of the
conversation gets degraded.  I prefer to avoid that.

@_date: 2014-10-17 16:15:36
@_author: Robert J. Hansen 
@_subject: Encrypt folders which include audio video and text files 
On Windows I use BitLocker; on Mac OS X I use FileVault; on Linux I use
an encrypted loopback filesystem.  Folders are a property of the
filesystem, and it's usually best to solve filesystem issues at the
filesystem level.

@_date: 2014-10-18 21:08:30
@_author: Robert J. Hansen 
@_subject: new helper program for configuration import / export 
It sounds reasonable.  Why not write it yourself?
It's not hard to make highly portable Perl or Python scripts.  I think
you're overestimating the difficulty here.

@_date: 2014-10-19 16:34:50
@_author: Robert J. Hansen 
@_subject: Wind River 
It was brought up and discussed at length less than two days ago.  Check
the archives.

@_date: 2014-10-21 10:49:51
@_author: Robert J. Hansen 
@_subject: Wind river 
Makes perfect sense to me, once you understand three things:
(a) at one point all the good crypto came out of either the US, UK,
    or France,
(b) nuclear weapons are scary, and
(c) laws and regulations change so slowly they make glaciers look swift.
A lot of WW2 historians believe the Allies' ability to read Purple and
Enigma traffic at-will resulted in the war being shortened by a few
years and saved millions of lives.  The lesson politicians learned was,
"we must protect our communications and exploit those of other nations."
 Prior to the advent of the civilian cryptographic community, it was
perfectly rational to restrict the export of strong cryptography in
order to help keep the nation secure.
The dawn of the nuclear age happened to occur at the same time.  The
importance there is that it's really, really hard to validate a nuclear
weapon design without computers.  It can be done -- the U.S. did it,
twice -- but it's really hard.  With computers, machining and building a
nuclear weapon is mostly pretty easy.  (Enriching U-235 and/or creating
Pu-239 is still really hard, but it's the only really hard step.)  So,
for a long time, it was perfectly rational to restrict the export of
high-powered computers in order to limit nuclear proliferation.
The world has moved on, though, and Congress has shown itself mostly
either unable or unwilling to recognize this.  When the PlayStation 2
was coming to market Sony discovered that it couldn't be exported out of
the U.S. without an arms control export license -- the laws hadn't kept
pace with technology, and by the (outdated) standards in the laws the
PlayStation 2 was a supercomputer.  Oops.  Sony pushed for changes in
the definition of 'supercomputer', and the PS2 suddenly could be
exported worldwide.  (Mostly due to the console gaming market, the
definition of 'supercomputer' keeps on creeping upwards.  Sony and
Microsoft really, really want to be able to export their consoles
worldwide without worrying about ITAR compliance.)
The internet is a fascinating place, but it's also a world completely
unlike the one that existed when Congress drafted its laws.  As libre
hackers who like crypto, we run smack into ITAR and EAR on two fronts.
Our computers keep getting more and more powerful, which runs afoul of
the regulations originally designed to counter nuclear proliferation,
and our crypto keeps getting better and better, which runs afoul of the
regulations originally designed to make sure only the good guys had
strong crypto.
All this being said, the laws aren't *wholly* stupid.  ITAR has a couple
of nice commonsense exceptions.  (See, e.g., ITAR 120.10 (5): ITAR "does
not include information concerning general scientific, mathematical, or
engineering principles commonly taught in schools, colleges, and
universities or information in the public domain.")
Unfortunately, those exceptions aren't enough to save you from really
expensive legal bills.
When I was assisting in the teaching of a a graduate-level computer
security course at the University of Iowa back in 2007, we had to get
briefed by the University's lawyers about the foreign students in our
class and what we were and were not allowed to say in front of them
about computer security subjects (!!).  The University's concern wasn't
that we could be successfully prosecuted for violating ITAR -- the First
Amendment and the ITAR's own provisions for education provided safe
harbors.  It was that we could be prosecuted *at all*, and forced to
spend money we didn't have resolving a legal headache.  Better by far,
in the University's view, to be very careful what information we taught
to foreign graduate students and avoid any possible legal headache.
These regulations make sense when you consider the historical context in
which they were created, and consider just how hard it is to get old and
outdated laws changed.  Are they stupid in the present day?  Yeah.  But
they're also still the law, and Wind River was *freaking* *stupid* to
knowingly, willfully violate ITAR/EAR some 50-odd times.
Now, before armchair lawyers leap up to say, "$750,000?  For that money,
I'd take the case to court and see if I could get the court to agree
that ITAR doesn't apply to what I was exporting!"... Wind River has
lawyers, too, and the lawyers signed off on this.  For whatever reason,
Wind River's lawyers thought this was a good plan.  Maybe they were
worried about what other violations the USG might find and they were
able to fold an amnesty into the deal.  Maybe they were concerned about
the hit in the court of public opinion.  Maybe... etc.  We don't know
why Wind River chose to pay the fine instead of challenge it in court.
We just know they decided that paying this fine was in their company's
best interests.
Wait, you mean like the U.K. did after WW2 when it sold Enigma machines
to half the world and told them that it was a strong, unbreakable
system?  Color me shocked.
(Yes, the U.K. was selling Enigma machines as late as the 1970s.  That's
why ULTRA remained so secret for so long: revealing ULTRA would have
told all these Enigma customers that the U.K. was able to read their
traffic at-will.)

@_date: 2014-10-22 11:19:18
@_author: Robert J. Hansen 
@_subject: Wind river 
That dates from April 1, 2013, and apparently has been updated since
then -- but yes, I was quoting from an official ITAR issuance.  :)

@_date: 2014-10-23 14:02:36
@_author: Robert J. Hansen 
@_subject: Wind river 
It's a popular opinion.
In the immediate postwar period up until, oh, maybe 1980, most of the
good civilian cryptographic work came out of the United States.  But
since then, it's very much been a collaboration from around the world.
AES was developed by a pair of Belgians, for instance.
That wasn't my intent.  I think ITAR and EAR are remarkably silly
regulations when it comes to crypto.  However, it's a good idea to learn
about the historical forces that shaped ITAR and EAR.  :)

@_date: 2014-10-27 14:20:36
@_author: Robert J. Hansen 
@_subject: Update on USG, Software, and the First Amendment 
Just received word back from a friend of mine who's a law professor
focusing in electronic civil liberties, and is a former Commissioner of
the FCC to boot.  He's skeptical that ITAR/EAR enforcement will affect
U.S. hackers participating in libre software development.  More than
that I can't/shouldn't say, since he was writing off-the-cuff in a
personal email rather than carefully drafting remarks for public
He rather likes writing short essays on law.  If there's interest, I'll
try and talk him into writing something layman-friendly about ITAR/EAR,
cryptography, and the First Amendment.

@_date: 2014-10-27 15:51:04
@_author: Robert J. Hansen 
@_subject: Update on USG, Software, and the First Amendment 
I just don't want to ask my friend to put together something on the
subject and then discover there's no interest in it -- it seems
disrespectful to Professor Johnson.  :)

@_date: 2014-10-29 14:00:39
@_author: Robert J. Hansen 
@_subject: key length/size RSA discussion/recommendations in the wiki 
I thought we largely addressed this in the FAQ, sections 11.1, 11.2,
11.3, 11.4 and 11.5.
Do we need to address it in more depth?  If so I'm happy to write an
extension to the FAQ.

@_date: 2014-10-29 14:44:59
@_author: Robert J. Hansen 
@_subject: key length/size RSA discussion/recommendations in the wiki 
Sure you can.  To brute-force a 128-bit RSA key would require you to
check every prime number between two and 10**19.  There are in the
neighborhood of ten quadrillion of them.  You could break a 128-bit RSA
key for under $100 of computation on an Amazon cloud instance.

@_date: 2014-10-29 17:23:51
@_author: Robert J. Hansen 
@_subject: key length/size RSA discussion/recommendations in the wiki 
Either-or.  RSA-1024's dangerously close to being brute-forceable, too.
We've already brute-forced RSA-768 and we're closing in on RSA-890.  I
haven't looked into how well the general number field sieve
parallelizes, but I wouldn't want to take bets on how long RSA-1024
could stand up to a massive Amazon Cloud instance.

@_date: 2014-10-29 17:30:56
@_author: Robert J. Hansen 
@_subject: key length/size RSA discussion/recommendations in the wiki 
Technically, brute force is testing every *possible* value... not values
that you know aren't going to work.  Why test those?
If you're trying to factorize 2701, for instance, you can feel free to
skip dividing by 2 (doesn't end in an even number), 3 (sum of the digits
isn't divisible modulo three), 4 (already know it's not divisible by 2),
5 (doesn't end in a 5 or a 0), 6 (not divisible by 3 or by 2), etc.
If your brute-forcer is testing values that cannot possibly be correct,
then you're using an inefficient brute-forcer.  Get a better one.  :)
Depends.  I think so.  But if you're taking an exam sometime in the near
future, I think you should answer this however your professor wants.  :)

@_date: 2014-10-31 13:29:21
@_author: Robert J. Hansen 
@_subject: key length/size RSA discussion/recommendations in the wiki 
The FAQ is discussed in public and changes are submitted to the
community for comment and review before I make any changes.  So far, no
one on the list has raised a serious objection to the content -- some
have said, "I don't agree but I'm in the minority," but no one has said,
"I don't think the community is behind this."
The people who are most up in arms over this aren't going to be
convinced by a chain of arguments.  Holy wars are driven by articles of
faith ("vi is superior to emacs!"), not by reason. [*]
I agree that the FAQ is a bad place to present a chain of arguments and
the wiki is the natural spot for it.  My concern is that the FAQ and the
wiki need to be kept in sync somehow, and I'm not going to be watching
the wiki constantly to make sure we're giving consistent advice.
My other concern is the false air of authority that wikis tend to get.
When anyone can edit, wikis periodically wind up saying ... anything.
If people are looking for a curated line of reasoning from
cryptographers and/or cryptographic engineers, that may not be a good
candidate for a wiki.
All this said, though: how can I help?
[*] emacs is *so* superior to vi, incidentally.  I don't know how any
right-thinking person could think otherwise.  Heathens.  They probably
eat pork, too.

@_date: 2014-10-31 17:28:26
@_author: Robert J. Hansen 
@_subject: Help needed to setup Passphrase with GNUPG 2.0.26 
One option would be to install GnuPG 1.4 on the host machine -- headless
servers are some of the few uses I can still see for it.

@_date: 2014-09-01 15:42:40
@_author: Robert J. Hansen 
@_subject: Hal Finney 
Hal Finney, one of the original PGP hackers and a pivotal figure in
twenty-plus years of PGP development and evolution of the OpenPGP spec,
died this past weekend of complications from amyotrophic lateral
sclerosis (ALS, or "Lou Gehrig's Disease").
Although he had minimal involvement in the Free Software community, he
was a pivotal figure within the larger PGP community.
I knew Hal, though not well.  In my brief experiences with him he was
witty, funny, and unfailingly kind.
My thoughts are with his family.  The world is diminished with his absence.

@_date: 2014-09-02 15:10:17
@_author: Robert J. Hansen 
@_subject: default user and recipient 
If you're absolutely certain you want to disable that warning (and
please think twice about it before you do, as it's there for a reason),
then you may add:
trust-model always
... to your gpg.conf file.  Please take note of what it says in the
manpage about this option, though: "You generally won't use this unless
you are using some external validation scheme."

@_date: 2014-09-15 12:38:37
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Wasn't me: I think a statement like that is arrogant even by my
standards.  It implies the speaker can accomplish this task, and if the
history of communications security tells us anything it's to be deeply
skeptical of anyone making such a claim.
For that matter, what does "secure" mean, anyway?  Most people would say
it means "an adversary can't intercept the communication or modify it."
Fine.  Who's the adversary?  If your adversary is a smart 12-year-old,
a good way to establish secure communication is to walk into your
nearest bar and tell the bouncers to be on the lookout for 12-year-olds
trying to get inside.  If the adversary is an outfit with a lot of
professional experience at intercepting communications, then you're
completely screwed and there's nothing you can do about it.
I really wish we could get over our obsession with the word "secure".
In twenty years of talking about PGP/GnuPG, I have yet to see it add one
iota of meaning to any conversation.

@_date: 2014-09-15 13:19:10
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
If by "too liberal" you mean "it's possible to do it," then I don't see
how to avoid it.  You'd need a trusted timestamp on the certificate and
a trusted timestamp on the machine using the certificates, and trusted
timestamps are a hard, *hard* problem.
Yes, OpenPGP is quite permissive about letting people encrypt to expired
certificates, but I think that's more a factor of it being incredibly
hard to prevent it than it is any neglect on the part of the OpenPGP

@_date: 2014-09-15 14:17:53
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Well, I still respectfully disagree, because -- oh, that's a rant.
Then again, when has something being a rant ever stopped me?
Okay: hang tight for some heresy.
I've been using PGP and GnuPG for over twenty years now, and in those
twenty years I've reached only a handful of beliefs.  I love the math
because you don't need to believe math: the theorem either works or it
doesn't.  Belief is a harder thing, and because of that it's wise to be
very careful before forming beliefs.
Here's my belief: anyone who advocates PGP/GnuPG, with or without
supporting tools like Enigmail, to average end-users is committing
professional malpractice.  If they don't recognize they're doing it,
they should take that as a sign they don't understand GnuPG/OpenPGP
anywhere near as well as they think they do.
GnuPG is not a communications security solution.  It is a communications
security *toolbox*, and an incomplete toolbox at that.  GnuPG provides
mechanism and only mechanism.  GnuPG does not provide policy, and
precious few of the tools supporting GnuPG fill in that gap.  Enigmail
doesn't.  GPA doesn't.  Pretty much nothing does.  For that reason,
recommending these tools to end-users is professional malpractice
because end-users do not have the skills or experience to wisely
determine policy.  (I don't, either.  If I were drafting policy I would
need, at the least, assistance from HR [to tell me about human-factor
concerns], Legal [to tell me about regulatory concerns], and IT [because
they'd be the ones supporting the thing].  I doubt that anyone on this
list, up to and including Werner, is capable of drafting a competent and
effective policy for an entire organization on their own)
Whew.  That was a good beginning to a rant.  Let me take a deep breath
Policy -- who signs what, whose certificates are trusted and why,
whether persona certifications should carry different semantic meaning
than generic certifications, whether signatures should carry expiration
dates, whether those expiration dates should be respected -- is, in a
word, *IMPORTANT*.
Further, policy will vary from person to person to person and
organization to organization.  This is one of the reasons why the
"should we use inline or PGP/MIME?" question will never be conclusively
answered.  That's not a technical question, it's a policy question that
people insist on treating like a technical question.  Technical
questions have only one answer: policy questions can only truly be
answered with a, "well, it depends..."
Here's something else about policy: putting together good policy is
*HARD*.  I've sat in on policy meetings before to provide technical
advice, and let me tell you, I'd much rather be debugging Win32 binaries
using gdb and a broken keyboard.  Policy is driven by human factors as
much as, or more than, by technical factors and that means your average
geek is completely adrift in this space.
Once you've got a usage policy, your next three questions become
monitoring, remediation, and enforcement.  How do you monitor usage to
ensure it complies with policy?  When something falls out of spec,
what's the process to bring it back into spec?  When you find who's
responsible for it falling out of spec, what happens to them?  These
questions, too, get discussed and resolved in policy meetings.
So, put it all together and here's what you need, at a minimum, to
effectively use GnuPG:
1.  Cryptographic tools.  GnuPG provides these.
2.  Usage policy.  You're on your own.
3.  Monitoring policy.  You're on your own.
4.  Remediation policy.  You're on your own.
5.  Enforcement policy.  You're on your own.
... So, yeah.  Whenever I see someone talk about how "we need to improve
GnuPG's adoption numbers!", I roll my eyes.  Invariably they talk about
how we need to make GnuPG "easier to use".  But that's not the problem
and it's never been the problem.
The problem is *policy*.
Werner has, IMO wisely, decided that GnuPG will not make policy for the
user.  I think that's the absolutely correct decision to make.  GnuPG
should not be telling me what my usage, monitoring, remediation or
enforcement policies should be.  But the total absence of policy has led
to the vast majority of GnuPG users *not even knowing that it's absent*.
As a result, we as a community drastically understate (or in many cases
don't even state!) the difficulty, expense, and necessity of policy.
So, to tie all this back to your original remarks, Nicholas, I disagree
that we need to do something about making it harder to encrypt to
expired certificates.  That's a policy decision, and as such it's
outside the scope of GnuPG.
But if you want to start waving the banner of, "POLICY!  GET SOME!",
well, the line starts behind me.  :)

@_date: 2014-09-15 15:30:23
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Okay, I apparently misread.  I'm sorry about that.  It really annoys me
when people misread me, and I suspect you feel likewise.
There's an old saw about a drunken man who's leaning up against a
streetlamp while looking around for his keys.  A passer-by halfway down
the block finds the keys and takes them to the drunk.
"Why were you looking for them under the streetlamp if you lost them
down the block?" the passer-by asks.
The drunk answers, "I may have lost 'em down the block, but the
streetlamp I need to lean against is right here!"
I often think that's how many of us treat GnuPG.  Securing
communications is *hard*.  Tool development, which is only one part of
the equation, is easily-definable and quite tractable.  And rather than
say, "okay, the easily-definable and quite tractable part is done to an
acceptable level, now let's tackle the hard stuff," we instead have a
tendency to shout "No!  3DES shouldn't be a mandatory cipher!  It's
weak!  And oh God we're using 2048-bit keys by default and that's a
disaster!  And we don't support larger than 4096-bit keys!  And..."
Rather than tackle the Herculean problem of pulling the weeds from the
garden, we insist on gilding all the lilies... and then gilding them
again and again and again, because "there's still so much work to do."
All the while, the weeds keep growing.
So, yeah.  Violent agreement here.  I see a community that's obsessed
with gilding the lily again and again, and that has been very resistant
to suggestions that we need to broaden our perspective.

@_date: 2014-09-15 15:56:04
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
There's a half-finished liter of milk in my fridge that's now a week
past its expiration date.  (Yes, yes, I'm going to throw it out once I
get home...)
If you want, feel free to come by.  I'll pour you a glass of milk.
After all, an expiration date doesn't mean "don't use this," right?
It's only a number that's to be interpreted according to however someone
As has already been explained elsewhere, this cannot be enforced.
It is not GnuPG's job to set policy: if you really need the ability to
encrypt to expired certificates, go right ahead and do it.  However,
there is something to be said for making people go through an additional
couple of hoops before shooting themselves in the foot.
In the cases you made, I think GnuPG would be improved by removing those
options.  This argument really isn't a winner.

@_date: 2014-09-15 16:23:08
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Sorry, that's idiomatic English.
For the non-English speakers: "gilding the lily" means to foolishly try
to improve on something that's already magnificent.  "Gilding" means to
paint something with gold.  A lily is already a beautiful flower:
gilding the lily will not make it more beautiful -- it will only waste
your time and your labor.
Not to be confused with gelding the filly, which, if you're doing, well,
as I said, you're probably quite confused...

@_date: 2014-09-15 18:05:34
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Yes.  Hence my choosing of the term "OpenPGP", as opposed to GnuPG.
Within the OpenPGP spec, there's nothing preventing you.

@_date: 2014-09-15 18:10:25
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Minor nit: it is not that we know Hauke's correspondent is not in
control of her key -- it is that we do not know if she is.

@_date: 2014-09-15 18:45:00
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Loss of control breaks continuity of control, and CoC is the sine qua
non of certificate management.
"She lost control of the cert" ==> CoC is broken, do not use again
even if control is re-established
"I do not know if she has control of the cert" ==> CoC may be broken, do
not use until CoC can be established.

@_date: 2014-09-15 20:12:51
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Hauke, this entire argument is what I meant when I talked about gilding
the lily repeatedly.  If you can find half a dozen *real users* who are
being *really impacted* by this, I'd love to hear about them.  But so
far, all the discussion is so hypothetical that it's hard for me to take
it seriously.
I get that you view the current situation as in need of changing.  I
don't agree, and I won't agree until I see six real life users whose
usage of GnuPG would be made significantly better by making this change.
Until then, all I can do about this 'problem' is yawn.

@_date: 2014-09-16 10:16:29
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Yes, and this is reasonable.  My example was against what I saw as
Hauke's overly broad "expiration dates don't mean anything except what
you project onto them."  No, expiration dates *do* mean something, and
you've agreed with me here.  :)
As a farm kid, the answer is a resounding "yes, and you should be
thanking me."  We raise cattle on my family farm (as well as soybeans,
corn, and the like).  We've never had a case of Mad Cow, but my family
has decided what we'll do if we get such a steer: we'll take the
financial hit involved in putting the entire herd down.  Sure, 99% of
the cattle would be healthy... but we're not willing to take that risk
with the food supply.  And I think you should be thanking your food
providers that we are willing to throw out perfectly good food, simply
because we cannot *prove* that it is perfectly good food.
American, European and Australian food supplies are the safest in the
world precisely because we throw away so much good food.  Can we prove
that the food is safe?  No?  Then we get rid of it.
There's a subtlety there that I think you're missing.  Just because
something is good doesn't necessarily mean you can prove that it's
good... but knowing you *can't* prove that it's good is still enough to
tell you what to do.
It doesn't to me.  You're only looking at half the risk-versus-reward
equation -- more accurately, you're only looking at the reward half.
Reward: "A small number of users who currently have to jump through
         hoops to use expired certificates will be able to do so more
         easily."
Risk:   "A large number of users may wind up, through accident, error,
         or misadventure, disabling expiration checks on certificates."
If you truly need to do this, then I'm just fine with making you jump
through hoops if it means not providing casual users with a pistol
that's conveniently pre-loaded and pre-aimed at their head.
Correct, but this is sort of quibbling.  The most accurate would be,
"There is no assurance this certificate is valid, since we are past X in
time.  Therefore, I will treat it as invalid until the certificate owner
makes a new assurance."
While I agree that "I will treat this certificate as invalid" is a
different thing from "this certificate is invalid," in practice there's
not much difference.
True but irrelevant.
I have a smoke detector that uses alien technology to tell me if my
house is on fire.  My Zarbnulaxian smoke detector (which I picked up at
a Zarbnulaxian Best Buy the last time they kidnapped me; next time I'm
on Zarbnulax I'm going to grab one of their quantum computers!) doesn't
detect smoke -- it determines the truth or falsity of statements,
subject to a certain low .01% error rate.  It will sometimes certify a
true statement as being false, but it will never certify a false
statement as being true.
I started off by programming it to test the truth of the statement, "My
apartment is on fire."  As long as it tells me "The statement 'my
apartment is on fire' is false", then I can be confident my house isn't
on fire.  Unfortunately, one night my apartment caught fire.  That made
the statement true, and my smoke detector sometimes certifies true
statements as false... so it continued to tell me, "The statement 'my
apartment is on fire' is false."  I barely got out with my life (and my
Zarbnulaxian technology).
So in my new apartment, I set up my Zarbnulaxian smoke detector to test
the truth of the statement, "My apartment is not on fire."  This
statement is usually true, and that means sometimes it tells me
(incorrectly), "The statement 'my apartment is not on fire' is false."
These false alarms are really annoying, but I also know my Zarbnulaxian
smoke detector will *never* fail to detect a fire.  After all, if the
statement 'my apartment is not on fire' is false, the Zarbnulaxian smoke
detector is incapable of erroneously reporting it as true.
The same logic applies to certificates.  You think that "the expiration
date means the certificate is valid to a given point, not that it is
invalid after."  Which is true, but misses the point.  The point is that
the absence of a certification is, itself, enough reason to avoid using
a certificate.
So would you be fine with a restaurant serving you expired milk, if the
proprietor says "oh, hey, I used my nose and common sense, and it's okay"?
When you are the only one bearing the consequences of your decisions, a
lot more can be justified than when you are asking *other people* to
bear the consequences of your decisions.  And when you send email
encrypted to an expired certificate, you are asking *your recipient* to
put the confidentiality of your communication with them entirely in the
hands of your judgment about whether their "I no longer certify this for
use" statement should be respected.

@_date: 2014-09-16 10:31:23
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
And how much impact did this really have on you?  What was to prevent
you from using symmetric encryption?  It's not as if you don't have a
secure communication channel with yourself over which a symmetric key
can be negotiated.
I've had the exact same situation before.  My solution was to use
symmetric encryption using a strong passphrase -- a few lines of "The
God Forsakes Antony" by Cavafy, if memory serves.[1]
We have one person who has had minimal impact and for whom an easy
workaround exists, and we have Hauke's case.
I'm not asking to see six real users who are really impacted for no
reason, Peter.  I'm asking because this dramatically cuts down on
bikeshedding and lets us prioritize things.  If encryption with Elgamal
keys suddenly breaks, okay, thousands of users are affected in a
critical way for which no easy mitigation exists: that's something that
should be fixed immediately.
But the lack of a flag to allow people to ignore the expiration date?
I'm not seeing a large number of users who are facing serious impacts
because of this.
And I am overwhelmingly against those feature requests, too.
Sure I can.  You weren't really impacted by it.  You had easy
mitigations available to you.
[1] A particularly beautiful poem by the Greek poet Constantin Cavafy,
inspired by the legend of Mark Antony realizing he was destined to lose
the city of Alexandria when he saw Bacchus and his entourage depart the
city.  It's not particularly germane to this discussion, but -- well.
It is beautiful, and what the hell: beauty ought be shared.  :)
If unexpectedly, in middle night,
an unseen company be heard to pass,
with music and with voices exquisite --
turn not away and uselessly lament
your fortune that is giving in, your work
that came to nothing, the projects of your life
that proved illusory from first to last.
As one prepared long since, as fits the brave,
bid now farewell to the departing city,
farewell to the Alexandria you love.
And above all, do not deceive yourself:
say not that your impression was a dream,
that, it may be, your hearing played you false:
to futile hopes like these never descend.
As one prepared long since, as fits the brave,
as most fits you who gained so great a city,
approach the open window steadily,
and with emotion, but without the plaints
and supplications of the timorous,
listen -- knowing it to be your last delight --
listen to the Elysian sounds, the exquisite
instruments of the mystic company;
and bid farewell to the city you are losing,
farewell to the Alexandria you love.

@_date: 2014-09-16 14:41:09
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
No, I'm using the same verbiage I did before.  Quoting myself:
"Hauke, this entire argument is what I meant when I talked about gilding
the lily repeatedly.  If you can find half a dozen *real users* who are
being *really impacted* by this, I'd love to hear about them."
A "real user" is not a user that technically exists but has only ever
used GnuPG once and is unlikely to do so again; a real user is one who
has a significant need for GnuPG and uses it to address these needs.
"Really impacted" doesn't mean an impact barely greater than epsilon; it
means significant impact.
My usage is consistent.  If you've chosen to reinterpret my words as
"existence" rather than "significance," that's on you; you've dropped my
threshold from significance to "it's okay if the user and the impact are
completely insignificant, just so long as they exist," which is clearly
not what I meant at all.

@_date: 2014-09-16 15:11:14
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Or, perhaps, many people are seeing that you do not understand the
meaning of, "don't use this key past this date."  You look into the
abyss, the abyss looks into you, and all that.
In deference to Peter's hot-button issue of food expiration, I'll use a
couple of other examples:
* A police officer pulls me over for speeding.  I give him my driver's
  license.  "Sir," he tells me, "this expired last month."  Yes,
  officer, but it's okay, I've actually got a current driver's license
  at home -- just because *that particular* expiration date has passed
  by doesn't mean my driving privileges have expired.  Result: I still
  get a ticket for driving with an expired license.
* My paycheck is stamped, "Expires after 90 days."  On day 91 I take
  it to the bank to get it cashed.  The bank refuses.  "But there's
  plenty of money in my company's account," I tell them, "and my
  company agrees that I'm owed this money.  Nothing bad will happen
  if you cash this check.  Look, I've brought an HR representative with
  me: he will attest that you can cash this check."  Result: the bank
  refuses and I have to convince my company to draft me a new,
  non-expired check.
* My hunting license expires on a certain day.  The day after the deer
  season ends, a game warden spots me over a freshly-killed deer.
  "Look," I tell the warden, "there are still plenty of deer and it's
  not as if there's any harm done."  Result: I get a citation for
  poaching.
* I take a prescription to the pharmacist's.  "Sorry," the pharmacist
  says, "this says 'expires after 30 days'.  I can't fill your meds."
  But I'm still sick and I still need them.  Result: I get sent back
  to the doctor to get a new, non-expired prescription.
... I have to confess, I don't understand how people can reach these
highly tenuous meanings of "expire" which don't actually mean "expire".

@_date: 2014-09-16 15:15:04
@_author: Robert J. Hansen 
@_subject: encrypting to expired certificates 
Telling me that "[I] can't argue that it's not a real impact", when the
meaning of "real" that I've been using has been significance, and I
clearly *can* argue that it's not a real/significant impact, is an
invitation for me to do just that.  Your examples are not real impacts.
Not really.  This 'problem' is so hypothetical it's hard to take
seriously.  I'm still waiting to see one single real user who has had
real impact from this, and that means the problem is still hypothetical.
[shrug]  As soon as I let the opinions of other people I've never met
start weighing heavily on my self-esteem, I'll let you know.  Until
then, I really don't care.

@_date: 2014-09-16 16:36:26
@_author: Robert J. Hansen 
@_subject: (Really OT!) encrypting to expired certificates 
I did not dismiss your beliefs, nor did I mock them.  When I said "in
deference to Peter's hot-button issue of food expiration," there was no
perjoration or sarcasm attached to that.  I said precisely, exactly,
what I meant: in order to avoid tromping on something that is a
sensitive subject for you, I elected to use other examples.  You may
wish to rethink whether that amounts to a dismissal of your beliefs or
consideration of them.
We are not our ideas.  Our ideas are separate things from us, and one
can be a virtuous and commendable soul even if one's notions are
nonsense.  A Young-Earth Creationist who volunteers to feed the hungry
is still showing great personal virtue.  Their idea may be flamingly
wrong, but only a heartless fool would think that fact should somehow
diminish their worth or value.
We live in a society that encourages us to wear labels.  Atheist.
Agnostic.  Buddhist.  European.  American.  Black.  White.  Arab.
There's nothing wrong with those labels, really -- but there's something
wrong with letting ourselves *be defined by* our labels.  And in the
end, the ideas you hold are just another label.  Don't let your labels
define you.  Especially don't let them define your self-worth.  You are
more, and richer, than that.  We all are.  Not just everyone on this
mailing list, but every human being throughout the world.  (Even the
ones currently kidnapped on Zarbnulax.)
I'm sending this to the entire list because it's something I'd like to
tell the entire list.  None of us are our ideas.  It is normal and
natural for ideas to come into violent collision.  If your idea
prevails, congratulations, but that doesn't make you a better human
being.  If your idea doesn't, I wouldn't lose any sleep over it: no one
worth knowing would think that having an incorrect idea was any kind of
reflection on you as a person.
You certainly don't have to agree with any of this.  They're just ideas,
after all...

@_date: 2014-09-18 10:00:10
@_author: Robert J. Hansen 
@_subject: (OT) encrypting to expired certificates 
To clarify:
I think that the body politic should thank producers of food for being
willing to throw away food (and thus, profit) in the interests of
preserving the safety of the public's food supply.  That's all.
The reason why I find the metaphor appropriate for GnuPG is because it
highlights the different responsibilities producers have versus
consumers.  A producer is expected to provide product (food, encrypted
communications, whatever) that exceeds the standard of the consumer.
Similarly, the use case of "I forgot to add a new expiration date on my
own key" is different from the use case of "my correspondent forgot to
add a new expiration date on his key".  These two use cases revolve
around policy, not mechanism.  In the former, whether you want to hack
up the system time to get around the expiration issue is wholly your
lookout -- whatever policy one decides, I neither get to judge it nor
comment on it.  In the latter, I get to say, "I cannot imagine a world
where this makes sense.  The certificate has expired; don't use it."
Again, producers are -- must be -- held to a higher standard than consumers.
Peter, I hope this makes my feelings on the matter clear.  It was not my
intent to tell you how to run your refrigerator, or that you are somehow
doing it incorrectly.

@_date: 2014-09-18 10:04:13
@_author: Robert J. Hansen 
@_subject: Keeping .gnupg folder in cloud 
Potentially foolish, but not for the reason you might expect.
I've often said I'm willing to publish my keyrings in the _New York
Times_.  I'm not being facetious.  My passphrase is 128 random bits from
published in the newspaper I have nothing to fear (except, perhaps,
someone deciding to torture me to get my passphrase: an event that I
find unlikely).
But the .gnupg folder contains a few sensitive files, such as
random_seed.  If you publish your random seed, it's theoretically
possible for someone to determine the internal state of your random
number generator, and at that point you've got a serious risk to the
confidentiality and integrity of your communications.
If I recall correctly, not all platforms use random_seed.  The basic
lesson remains the same, though.  There are files in .gnupg which
probably should not be stored in the cloud.  :)

@_date: 2014-09-18 12:04:37
@_author: Robert J. Hansen 
@_subject: Keeping .gnupg folder in cloud 
The biggest risk is the gpg.conf file, actually.  If the admin silently
adds another "encrypt-to" and you don't notice it, then you're totally
Like I have said -- there are a lot of files in .gnupg that probably
should not be hosted in the cloud.

@_date: 2014-09-18 12:36:41
@_author: Robert J. Hansen 
@_subject: Keeping .gnupg folder in cloud 
Oh, good point.  I missed that.  My apologies to the original poster!

@_date: 2014-09-19 14:14:44
@_author: Robert J. Hansen 
@_subject: New beta 
Unfortunately, this is not something I'd recommend for anyone except a
handful of MinGW experts.  It's technically possible, but daunting.
The approved way of building Win32 executables of GnuPG is to
cross-compile from Linux.

@_date: 2014-09-19 16:15:15
@_author: Robert J. Hansen 
@_subject: New beta 
It would be nice if it could also be checked with Fedora.  CentOS/RHEL
is really big in the business world, and I know a couple of shops that
would like to be able to cross-compile their Windows GnuPG builds from
their CentOS/RHEL boxen.
However, I'm unaware of anyone who's calling this a blocker, so it's a
pretty low priority.  (See, folks?  I apply the
six-real-users-with-real-problems test even to my own requests.  ;) )

@_date: 2014-09-26 00:38:47
@_author: Robert J. Hansen 
@_subject: Keybase 
The sender is making a rather blue joke.  Normally, we talk about key
SIGNING parties.  A "key party" is ... rather a lot different, at least
in the United States.
The presence of a blue joke in their outreach materials to new users
causes me to have serious doubts as to their professionalism.

@_date: 2015-04-21 14:34:56
@_author: Robert J. Hansen 
@_subject: Unsubscribe 
It's located right at the end of each message:
Visit that web page.  At the bottom you'll see, "To unsubscribe from
GnuPG-users, get a password reminder, or change your subscription
options...".  That's what you want to use.

@_date: 2015-04-28 10:26:05
@_author: Robert J. Hansen 
@_subject: Notes from the first OpenPGP Summit 
This doesn't seem like a good reason.  It never has.  If I configure
gpg-agent to cache for 20 minutes, but forget to configure
gnome-keyring-daemon, then it's possible that 25 minutes later I'll do
something requiring a passphrase, gpg-agent will ask me for my
passphrase, but gnome-keyring-daemon will silently intercept it and use
the cached value, etc., etc., leaving me wondering why gpg-agent isn't
respecting the timeout I've given it.
This also means passphrases are cached in two places, not one -- in
gpg-agent and in gnome-keyring-daemon.  In my day job I work in digital
forensics, with a good bit of memory forensics work in my past.
Speaking as a forensicist, if you keep two copies of a sensitive
passphrase in memory you're making things much easier for me.
I don't understand GKD's choices here.  I never have.  They've always
seemed foolish.  If GKD wants to implement gpg-agent's protocol and run
as a replacement gpg-agent, that's one thing... but the current setup
just does not strike me as wise.
I'm sorry, but I don't think this is a good solution.  GNOME is asking
for privileges other desktop environments haven't asked for and don't
get. KDE doesn't get KDE-specific functionality added to pinentry.  Nor
does XFCE, nor does Enlightenment.  If GNOME gets to have GNOME-specific
enhancements folded into GnuPG, then what's to prevent KDE, XFCE,
Enlightenment, Windows, OS X, and all other desktop environments from
demanding the same?

@_date: 2015-04-28 11:36:34
@_author: Robert J. Hansen 
@_subject: Notes from the first OpenPGP Summit 
I'm not objecting to the idea of GKD providing its own pinentry:
creating a gkd-pinentry sounds like a good idea.
I'm objecting to what I read (and possibly misread) as placing GKD hooks
into the *GnuPG-distributed* pinentry.
I would suggest that in the future we talk about "pinentry" only for
GnuPG's pinentry, and "foo-pinentry" to denote a pinentry provided by
foo, so as to prevent future misunderstandings.  :)

@_date: 2015-04-28 12:42:48
@_author: Robert J. Hansen 
@_subject: Notes from the first OpenPGP Summit 
Point.  I still think if GKD wants to hook into a pinentry, they need to
distribute their own pinentry instead of modifying one that GnuPG maintains.
Given pinentry-gtk2 is FOSS, it shouldn't be too hard for them to fork
it, make their changes, and distribute it.  I just don't want to see
GNOME 3-specific code in a pinentry for GTK+2, as that seems pretty far
out of scope.

@_date: 2015-08-16 16:41:14
@_author: Robert J. Hansen 
@_subject: protecting pub-keys from unwanted signatures 
No?  So you'd be fine if someone generated a fake certificate belonging
to "White Power Action Network " and added a
signature to your certificate from it?
There are definitely such things as unwanted signatures.
No.  This isn't even in the same postal code as reality.  More
signatures from *real people* may result in a better WoT; more
signatures, period, or signatures from fake identities, really don't add

@_date: 2015-08-16 17:26:15
@_author: Robert J. Hansen 
@_subject: protecting pub-keys from unwanted signatures 
Except that 99% of people who see that signature will think you have an
association with white supremacists.
Should they?  No.
Will they?  Yes.
The average person doesn't have a formal/mathematical model of trust and
what it means.  They have a loose, poorly-specified understanding, like
"only sign certificates of people you know well."  This leads them to
thinking, "well, this white supremacist group must know Chris well".
That's a false inference, but it's one a *large* number of people draw.
So you're now changing your statement: signatures *don't* always
strengthen the WoT -- a large number of them are irrelevant.  This is
much closer to reality.

@_date: 2015-08-22 07:55:15
@_author: Robert J. Hansen 
@_subject: PGP Global Directory does not send verification email 
It's long-standing list policy that we avoid talking about non-libre
software, except in the sense of interoperability concerns.  If you have
concerns with how the PGP Global Keyserver is working, I'd suggest
bringing that up to Symantec's technical support, or a mailing list like
PGP-Basics which explicitly supports PGP and their products.
This is a complete nonissue.  Search the list archives and you'll find
this discussion has been done to death many, many times.  The takeaway:
1.  Spammers don't work by harvesting email addresses.
2.  Honeytrapped email addresses on the global keyserver have not
    been harvested to any significant extent.  (I think the record
    is something like four spam emails over a year-long period.)
3.  Keeping your email address private is the wrong way to address
    the spam problem, anyway.

@_date: 2015-08-27 14:41:37
@_author: Robert J. Hansen 
@_subject: FAQ: drop mention of 1.4? 
After much delay, I've started work on overhauling the FAQ and making
the changes I've been threatening for some time.  So far the only
commits have been minor things not worthy of mention, but I'm about to
make a significant content change and I'd like to get the community's
feedback on it.
Namely, I plan on dropping (most) mention of 1.4.  1.4 will get
mentioned as an older branch of GnuPG meant for system administrators,
but for the rest of the FAQ I plan on focusing entirely on GnuPG 2.0 and
My rationale for this is simple: we don't want to encourage new users to
use 1.4.  We want to encourage new users to use 2.0 and/or 2.1.
Some tools (e.g., Enigmail) now require 2.0 or later.
I, personally, don't think it's a big deal to drop mention of 1.4 except
to talk about "it's for system administrators, not regular users".
However, I'd really like to hear your feedback on this.  Should we make
this change?  Yes or no?

@_date: 2015-08-27 17:11:13
@_author: Robert J. Hansen 
@_subject: The FAQ's 4GiB recommendation 
I had someone wonder why the FAQ recommends avoiding CAST, BLOWFISH,
IDEA, or 3DES for bulk encryption.  It occurs to me that this is a
pretty reasonable question and probably should get placed in the FAQ.
So, here's proposed new content -- please feel free to chime in with
thoughts or criticism.
For the technically inclined, yes, this explanation simplifies things an
awful lot -- maybe too far, I don't know.  If you can come up with
better phrasings *that are still understandable to non-technical users*,
I'd love to hear them.  :)
Q:  Why should some ciphers be avoided for bulk encryption?
A:  Ciphers are deterministic.  This means that for the same inputs, you
get the same outputs.
The OpenPGP standard requires that ciphers run in what's called a
"feedback mode," where the ciphertext of one block becomes an input to
the next block.
But what happens if two identical ciphertext blocks are found?  Since
the cipher is deterministic, the cipher will begin repeating its output.
This creates a distinctive pattern which a cryptanalyst can exploit.
For a 64-bit cipher, you'll probably wind up repeating a block after
about 32 gigabytes.  In order to reduce the risk of this happening, we
recommend that if you use a 64-bit cipher  you don't use it to encrypt
more than a single DVD's worth of data -- about four gigabytes.
A 128-bit cipher will begin to repeat after about 100 exabytes.  This is
a number so mind-bogglingly large it's unlikely to ever become a problem
for even the most demanding of users.

@_date: 2015-08-27 17:37:22
@_author: Robert J. Hansen 
@_subject: FAQ: drop mention of 1.4? 
The 2.x branch is the future of GnuPG development, has been for some
years now, and is what the GnuPG developers recommend for new users.
Further, a good part of the GnuPG ecosystem is moving to 2.0-only (e.g.,
Given this, it would only make sense to tell new users about the 1.4
branch if the 1.4 branch offered the average user something that 2.x
doesn't or couldn't.  As near as I can tell, it doesn't.
PGP 2.6 has been obsolete since before I could legally drink, and now
I'm on the wrong side of forty.  You have to draw the line somewhere.
With respect to the FAQ, I'm drawing it here.
I applaud the decision to drop V3 support and MD5, and I don't plan on
making mention of a PGP version that's been obsolete for longer than a
lot of our users have been alive.

@_date: 2015-08-28 12:52:16
@_author: Robert J. Hansen 
@_subject: FAQ: drop mention of 1.4? 
PGP 2.6 *is* obsolete.  There's no point in using quotation marks.  Read
this URL: "Software developers, Certification Authorities, website owners, and
users should avoid using the MD5 algorithm in any capacity. As previous
research has demonstrated, it should be considered cryptographically
broken and unsuitable for further use."
You don't get clearer than that.  PGP 2.6 is a dead letter.  Obsolete.
And with PGP 2.6 being obsolete, so are V3 keys.
You seem to believe PGP 2.6 (and V3 keys) are still in fine health.
They're not.  They need to be abandoned.  The fire alarm went off 17
years ago, people have had plenty of time to move to the exits, the
thing to do now is watch the thing burn down, share stories about how
well it served us, roast some s'mores, and maybe sing a round of
"Kumbaya, My Lord".
(For non-Americans: s'mores are a dessert involving marshmallows and
chocolate, normally eaten around a campfire.  "Kumbaya, My Lord" is a
well-known campfire song.)

@_date: 2015-08-28 13:36:24
@_author: Robert J. Hansen 
@_subject: FAQ: drop mention of 1.4? 
Then keep a copy of PGP 2.6 around.
But don't expect GnuPG, which exists to provide a libre implementation
of OpenPGP and S/MIME, to support ClassicPGP.

@_date: 2015-11-30 19:37:30
@_author: Robert J. Hansen 
@_subject: problems decrypting ASCII-armored file 
It's a UTF-16BE BOM, you mean.  The UTF-8 BOM is 0xEF 0xBB 0xBF.
It's a little weird.  You don't see much UTF-16BE out there.

@_date: 2015-12-01 08:54:44
@_author: Robert J. Hansen 
@_subject: problems decrypting ASCII-armored file 
Ah, I read it as being straight-up hex, not a code point.  Thank you.  :)

@_date: 2015-12-01 15:47:32
@_author: Robert J. Hansen 
@_subject: New FAQ items 
1.  A new user contacted me via email to point out there was no FAQ
    entry about whether there's anything to be done about a lost
    passphrase.  I added a FAQ entry for this, with text that basically
    amounted to "if you truly can't remember your passphrase then we
    can't help you, revoke your certificate with a pre-made revocation
    certificate and start anew."  If anyone has better suggestions (that
    don't amount to "well, have you tried all permutations of what you
    think the passphrase was?"), please let me know.  :)
2.  GNU contacted me via email asking for a FAQ entry about how to use
    GnuPG to verify downloaded software.  This was present in a prior
    iteration of the FAQ but not this re-written one, so I figured it
    was an unobjectionable addition.
I would normally present things on the list before pushing to Git, but
GNU's keen on a fast turnaround on   If you're interested in the FAQ,
give it a day or so for the HTML version of it to get generated and
check out the new entries.

@_date: 2015-12-01 15:52:41
@_author: Robert J. Hansen 
@_subject: Insecure memory message on PC-BSD 
Hey, Anthony.  Sorry for the long-delayed response: I'm just now
crawling out from beneath my backlog.
Some operating systems allow GnuPG more low-level control over memory.
Others don't, and these other systems get the insecure memory warning.
However, it's  pretty hard  to exploit
insecure memory without root privileges -- and if your attacker has root
privileges on your machine then it's all over anyway.
In my own environment, I don't care about this.  It's a nonissue.  You
can disable the warning by putting no-secmem-warning in your gpg.conf file.

@_date: 2015-12-01 15:55:21
@_author: Robert J. Hansen 
@_subject: Malware detected 
I'd be happy to look into this for you, but I'm going to need to know
specifically which version of GnuPG for Windows you downloaded and where
you downloaded it from (a link would be best).

@_date: 2015-12-01 16:01:42
@_author: Robert J. Hansen 
@_subject: New FAQ items 
I thought about it but decided against it.  I've never heard of someone
successfully using nasty to recover their passphrase.  I hate to
recommend a tool where I can't point to a single user who's had a good
experience with it.
I'm not saying they don't exist.  Just that if they do exist, I don't
know about them, and for that reason I feel I can't recommend the tool.

@_date: 2015-12-01 16:08:18
@_author: Robert J. Hansen 
@_subject: New FAQ items 
Good enough for me.  I'll adjust the language and submit a revision to
the list for review.

@_date: 2015-12-09 18:29:34
@_author: Robert J. Hansen 
@_subject: Please consider joining Bountysource Salt to collect recurring 
Is there some problem with the existing donation system?  If there's a
problem then let's fix it, but I'm not sure it's a good idea to change
something that works.

@_date: 2015-12-10 11:33:44
@_author: Robert J. Hansen 
@_subject: Please consider joining Bountysource Salt to collect recurring 
Then that's a problem we should look into, and thanks for telling us
about it.  :)
Recurring donations would be a nice feature.  We should look into this.
See my next remark.
You just said it's a place where people eager to give go to find whom to
give... but now you're saying that it's new.  If it's new, that means
they're still beginning to attract users and build their own reputation.
 So which is it?  Is it a place with a lot of users and a reputation for
being a place where people looking to give can find worthy projects, or
is it just starting out and needs to gain popularity?

@_date: 2015-12-10 11:49:09
@_author: Robert J. Hansen 
@_subject: Please consider joining Bountysource Salt to collect recurring 
On a lark, I checked out Bountysource Salt.
Here's their C++ projects you can support:
Checking their Python project offerings:
Checking their GTK+ project offerings:
... So, yeah.  I'm thinking this is not a credible source for
fundraising.  Arduino and GNOME, projects with *far* greater visibility,
get $0 a month from Bountysource.  I find it hard to believe we'd do
much better.
I think this is something best avoided.

@_date: 2015-12-16 17:21:21
@_author: Robert J. Hansen 
@_subject: QC resistant algorithms? 
The one-time pad is proven QC resistant.
With respect to hypothesis, remember that *none* of the ciphers in
OpenPGP are proven to be resistant against even classical computers, and
we won't until there's a solid proof that P != NP.  QC-resistant
algorithms are in much the same state: a formal proof that an algorithm
was QC-resistant would be breathtaking and shocking, and possibly on the
level of a P != NP proof.
Some.  Others look quite solid -- e.g., Lamport signatures.

@_date: 2015-12-16 17:25:26
@_author: Robert J. Hansen 
@_subject: QC resistant algorithms? 
If I remember correctly, we definitely already have -- a while ago I saw
some paper claiming to be a proof that McEliece was NP-HARD.  If that's
true, I'm willing to say McEliece is QC-immune, because a QC attack on
an NP-HARD problem is currently pretty much unimaginable.

@_date: 2015-12-17 15:29:22
@_author: Robert J. Hansen 
@_subject: MIT Tech Review on user error 
MIT's Technology Review has a good article on how user error tends to
subvert communications security.  It's probably not news to people here,
but it might be worth sharing with your less-technical friends.

@_date: 2015-12-27 04:19:13
@_author: Robert J. Hansen 
@_subject: advice please 
Welcome to the world of free software. :)
This is in the FAQ:
Good luck!

@_date: 2015-02-11 10:20:37
@_author: Robert J. Hansen 
@_subject: moving up from 2.0.26 to 2.1.1 
If your goal is to enjoy tinkering with technology, by all means, do
what you're doing.  Can't fault you for it in the least; I love doing it
If your goal is just to make sure you have the latest and greatest
security updates, you should probably stick with your distro's packages.
The distro package may *say* 2.0.22, but any security fixes released
after 2.0.22 will quickly be backported into your distro's 2.0.22 package.

@_date: 2015-02-11 14:58:15
@_author: Robert J. Hansen 
@_subject: moving up from 2.0.26 to 2.1.1 
Yep, but as I'm not much of an Ubuntu guy I'll let one of them give you
specific instructions -- I just know Ubuntu, like Debian (which it's
built on), is very good about making that information available.
As a first try I'd suggest looking at:

@_date: 2015-02-12 22:18:25
@_author: Robert J. Hansen 
@_subject: MIME or inline signature ? 
It's still true for PGP-Basics; Enigmail's been bit by it within the
last year, if memory serves, but it's been generally accepted; GnuPG's
been AFAIK stable for it.  I've got a few hours free tomorrow; I'll see
about fixing this verbiage.
I should also add that PGP/MIME *may* give protection to metadata (see
Patrick's decision to use the creative header protection scheme you
mentioned), with some verbiage about how only Enigmail has promised to
implement it.  But over the last 18 months or so the metadata issue has
become important to a lot of people, so that should also be mentioned.
As is my usual, once I draft something I'll post an easily
human-readable diff to the mailing list and give people a chance to
raise objections and concerns.  I'm more the FAQ custodian than the FAQ
maintainer -- I want everything in it to reflect community consensus,
not just my own opinion.  :)
And the MIME attachment being mangled by the mailing list, yes, I agree.
 It's almost a bizarre endorsement of the attachment fragility idea...

@_date: 2015-02-13 14:41:14
@_author: Robert J. Hansen 
@_subject: MIME or inline signature ? 
It's worth noting that Postel (the guy who first formulated it) was very
dissatisfied with how people tended to interpret Postel's Law.  Per him,
he felt most people who quoted Postel's Law were confused on the
difference between 'liberal' and 'foolish', and tried to justify foolish
engineering decisions on the basis of a liberal acceptance policy.
Postel's sentiments were more, "Reject traffic that does not conform to
the spec, even if it's in common use; accept traffic that conforms to
the protocol spec, even if it's exotic; and only generate traffic that
conforms to both spec and common use."  Unfortunately, that loses much
of the poetry of the original phrasing.
This has long been one of my complaints about the way GnuPG gets used.
GnuPG will accept and generate some pretty darn exotic traffic ("let's
use SHA-224 with ECDSA and Camellia-256!"), which is good: that's
exactly what you want in a toolkit.  But just because we can do things
like this doesn't mean we actually should...

@_date: 2015-02-13 21:49:24
@_author: Robert J. Hansen 
@_subject: Sign key with externalized master key 
NTFS also works.  Linux can read/write NTFS through NTFS-3G and FUSE,
and a port exists for OS X as well.  And yes, the stack is 100% libre.  :)

@_date: 2015-02-14 11:13:29
@_author: Robert J. Hansen 
@_subject: MIME or inline signature ? 
To you, perhaps, sure -- to me, no.  Either way it doesn't matter; the
guidance is what it is, and many counterintuitive things turn out to be
Security and reliability.

@_date: 2015-02-15 18:07:25
@_author: Robert J. Hansen 
@_subject: MIME or inline signature ? 
It doesn't even show that.
The modification can be in the signature, not the message -- meaning
it's possible to have an entirely unchanged message, but still have a
bad signature.
A good signature verifies message integrity.  A bad signature does not
confirm tampering: it only states the integrity is not assured.

@_date: 2015-02-16 20:21:00
@_author: Robert J. Hansen 
@_subject: 2.1.2: keyserver route failure 
Is there any explanation for this behavior, or is this a 2.1.2 bug?
(This is using Patrick's OS X package, if that matters.  It also affects
all keyservers I tested, not just the round-robin front-end.)
quorra:~ rjh$ gpg -vvvv --keyserver x-hkp://pool.sks-keyservers.net
                  --recv-key 0xD6B98E10
gpg: using character set 'utf-8'
gpg: keyserver receive failed: No route to host
quorra:~ rjh$ ping pool.sks-keyservers.net
PING pool.sks-keyservers.net (140.211.169.202): 56 data bytes
64 bytes from 140.211.169.202: icmp_seq=0 ttl=55 time=102.879 ms

@_date: 2015-02-17 08:39:18
@_author: Robert J. Hansen 
@_subject: 2.1.2: keyserver route failure 
I know, which is why I said:
I tried several different non-round-robin servers.  Same thing.

@_date: 2015-02-17 14:23:43
@_author: Robert J. Hansen 
@_subject: 2.1.2: keyserver route failure 
Okay.  I have no idea what I'm looking for, but here goes.
quorra:~ rjh$ gpg-connect-agent --dirmngr 'keyserver --hosttable' /bye
S # hosttable (idx, ipv6, ipv4, dead, name, time):
S #   0       pool.sks-keyservers.net
S #   .       pool.sks-keyservers.net
S #   .   --> 6 8 1 13 20 4 10 11 7 2 15 5 12 17 9 19* 14 3 16 18
S #   1   4   c-75-75-183-132.hsd1.pa.comcast.net v4=75.75.183.132
S #   2   4   keys.exosphere.de v4=81.7.19.101
S #   3   4   tarquin.bootc.eu v4=81.187.55.68
S #   4   4   gozer.rediris.es v4=130.206.1.8
S #   5   4   keys02.fedoraproject.org v4=140.211.169.202
S #   6   4   176.31.199.172
S #   7   4   key.ip6.li v4=193.17.17.6
S #   8   4   198.128.3.63
S #   9   4   pgpkeys.eu v4=37.59.144.15
S #  10   4   host-37-191-220-247.lynet.no v4=37.191.220.247
S #  11 6     hufu.ki.iif.hu v6=[2001:738::600:216:3eff:fe02:42]
S #  12 6     keyserver.mattrude.com
S #  13 6     cl-1291.qas-01.us.sixxs.net v6=[2001:4830:1600:50a::2]
S #  14 6     svcs4.riverwillow.net.au v6=[2405:1000:10:309::5004]
S #  15 6     keys.jhcloos.com v6=[2602:ffea:1:ea::1]
S #  16 6     [2610:81:3001:53::231]
S #  17 6     keyserver.synack.com v6=[2a00:d880:3:2::4f76:8c5c]
S #  18 6     [2a02:180:a:65:2456:6542:1101:1010]
S #  19 6     sks.spodhuis.org v6=[2a02:898:31::48:4558:73:6b73]
S #  20 6     francis.connectical.com v6=[2001:41d0:1:bc3e::1]

@_date: 2015-02-18 00:24:51
@_author: Robert J. Hansen 
@_subject: 2.1.2: keyserver route failure 
I don't have IPv6 routing, period.  This raises the question of why
GnuPG is trying to reach an IPv6 address at all.
Worked fine under 2.0.x; under 2.1, this behavior manifested.

@_date: 2015-02-18 11:56:43
@_author: Robert J. Hansen 
@_subject: Please remove MacGPG from gnupg.org due to serious security 
That's not what the GPGTools folks did.  Your caricature of their
response is unfair and ungentlemanly.

@_date: 2015-02-18 21:30:31
@_author: Robert J. Hansen 
@_subject: 2.1.2: keyserver route failure 
It already *is* widespread.  China and Japan have signed onto it in a
big way.  In the US, the largest wireless carrier -- Verizon -- has
migrated over a third of its smartphones to IPv6, and plans to migrate
the rest in the next few years.
The largest Aussie telecom firm, Telstra, is 100% dual-stacked.
22% of Deutsche Telekom DSL customers are on IPv6 and they're migrating
mobile devices to IPv6 this summer.
IPv6 adoption is largely invisible, but it's picking up worldwide.

@_date: 2015-02-19 00:07:55
@_author: Robert J. Hansen 
@_subject: 2.1.2: keyserver route failure 
Nor am I, but the world has never much cared whether something was my
job: it concerns itself more with ensuring there are consequences for
the job going undone.
At the very least, if we're not going to address the problem we should
(a) reach out to Apple about the problem and (b) document for OS X users
that GnuPG's keyserver functionality may be broken on that platform.

@_date: 2015-02-19 02:28:14
@_author: Robert J. Hansen 
@_subject: Help need to use truecryt + openpgp applet. 
Unfortunately, we really can't.  GnuPG is written in C, not Java, so
it's unlikely your OpenPGP applet uses GnuPG.  You might have better
luck on a mailing list for the applet you're using.

@_date: 2015-02-19 21:41:58
@_author: Robert J. Hansen 
@_subject: Please remove MacGPG from gnupg.org due to serious security 
There are at least four guys in the security world named Robert Hansen;
to make matters worse, some of us have spoken at the same conferences.
My middle initial is only to distinguish me from the others; my friends
just call me Rob.  :)

@_date: 2015-02-20 10:45:06
@_author: Robert J. Hansen 
@_subject: Help need to use truecryt + openpgp applet. 
People put a lot more faith in encrypted filesystems than perhaps they
should.  They're a great way to protect data against casual theft, but
their track records against well-funded opponents are badly mixed.

@_date: 2015-02-27 10:56:33
@_author: Robert J. Hansen 
@_subject: German ct magazine postulates death of pgp encryption 
Ah, yes, back when men were men and sheep were scared.  :)
(It's an old American joke about the Old West: "when men were men and
sheep were scared," mostly due to a shortage of women.  I imagine the
Australians probably have their own version of it.)
With great respect, Werner, one thing twenty years of watching Classic
PGP and OpenPGP not succeed has taught me is that there is nothing
simple about increasing our user numbers.
In some sense I see GnuPG as a quite successful failure.  For the
original purpose of PGP -- email security -- OpenPGP has turned out to
be a dismal failure.  When used correctly by knowledgeable people it
offers a remarkable degree of protection, but it's condemned to forever
be a niche player.  Yet, in places where PGP was never imagined (signing
operating system packages, for instance), OpenPGP has turned out to be
incredibly important.

@_date: 2014-12-31 21:30:05
@_author: Robert J. Hansen 
@_subject: photo-ID 
With what?
I never said it wasn?t.
I said the photo ID feature, *as used within OpenPGP certificates*, isn?t.  There?s a big difference there.
Frankly, the possibility of allowing arbitrarily-sized binary blobs to be attached to OpenPGP certificates scares the ever-living bloody f*ck out of me.  (I try to avoid vulgarity, but I?m using it here to underline just how critical this problem is.)  The keyserver network, as currently configured, is susceptible to a total worldwide denial-of-service attack that can be conducted by just one malicious individual who figures out how to turn the photo ID feature into an attack vector.
I?ve discussed this attack vector on the keyserver mailing list.  The general consensus is that the attack that I?m concerned about is real, and would result in serious disruption to the global keyserver network for an extended period until we developed countermeasures ? but those countermeasures would fundamentally transform the keyserver network and force us to radically redefine our expectations of service.
So, yeah.  Photo IDs on OpenPGP certificates is really another way of saying ?OpenPGP supports putting arbitrarily-sized binary blobs on certificates that will be replicated worldwide and, depending on local jurisdictions, will immediately convert keyserver operators into felons.?  That?s enough for me to declare the entire OpenPGP implementation of photo IDs a staggering clusterf*ck of failure, and something that I really wish would get dropped from the OpenPGP spec.
(I?m not going into specifics about the attack because I don?t want to give anyone ideas, not in any expectation that it really matters a damn.  My write-up is available, but I?m not going to help you find it.)
Sure, but it would be nice if it didn?t expose people to phenomenal risk while we?re at it.
We have better ways of doing photo IDs ? e.g., keybase.io.  I think we should use them.
You?re arguing against something I never said and don?t believe.

@_date: 2014-12-31 21:40:01
@_author: Robert J. Hansen 
@_subject: The praise of GnuPG @31C3 
Not a reference, but some history ?
Microsoft?s point-to-point tunneling protocol version 1.0 was a miserable failure.  Version 2.0 closed up many of those holes and was widely regarded as secure, except for a configuration option which was on by default: ?Enable backwards compatibility.?  So to exploit a PPTP 2.0 connection, you just had to connect and give it a 1.0 handshake, at which point it would fall back into an insecure mode.
The protocol was secure: you just had to configure it correctly.  The server was correctly implemented.  It?s just that it was shipped in a completely broken state, most system administrators didn?t know it and/or didn?t check it, and as a result it was pretty much useless.
A secure protocol must be used correctly in order to provide communications security.  Too often people completely lose sight of that and don?t even introduce it into their discussions.  So ? discuss.  If you use ssh and trust it, how do you know that you?re using it correctly?  How do you know the people who connect to your system are?  Etc.

@_date: 2014-12-31 21:46:53
@_author: Robert J. Hansen 
@_subject: The praise of GnuPG @31C3 
Check section 5.1, ?Version rollback attacks?.  Full details there.

@_date: 2014-12-31 21:58:59
@_author: Robert J. Hansen 
@_subject: photo-ID 
Before people think I?m overreacting ?
A few years ago we lost an Austrian keyserver to, of all things, EU data privacy laws.  Think about the irony of that: a tool meant to help safeguard individual privacy got shut down by a single individual who invoked EU data privacy laws to get rid of a tool that helps data privacy.
A user uploaded their certificate to a keyserver, and that certificate soon propagated around the net.  The user then decided they didn?t want their email address published like that, and invoked a right under EU law to require the keyserver operator to delete his email address.  The keyserver operator was unable to do this due to the way the keyserver network works ? if he?d complied, the certificate just would have resynced a minute later.  The only way to support this EU data privacy provision was to allow the global network to drop certificates, and the global network has as a design goal that certificates *cannot* be dropped, in order to protect the integrity of the database against deliberate attack.
The keyserver operator received legal advice saying that continuing to operate his keyserver exposed him to significant legal risk.  So, without any real other alternatives, he did the only thing he could under the EU data privacy law and took his keyserver offline.
It is cheap and easy to take down any keyserver in the EU; just do what this user did.
The keyserver network is an important part of the OpenPGP ecosystem, and it?s nowhere near as robust as we like to imagine.

@_date: 2015-01-01 18:38:42
@_author: Robert J. Hansen 
@_subject: photo-ID 
It *is* allowed by the spec, and it?s the spec that?s the problem here.
This is sort of what keybase.io does; it lets you post cryptographically-signed statements like ?this is my Twitter account? to let other people have confidence that a given social media account really does belong to you.

@_date: 2015-01-01 19:31:51
@_author: Robert J. Hansen 
@_subject: The praise of GnuPG @31C3 
First, my usual reminder: don?t focus on the three-letter Voldemort.  The world is a bigger place than that and there are lots of threats, including many non-government actors.
Second ? I suspect those who know won?t tell, and those who claim to know will steadfastly refuse to demonstrate it.  Which tells you nothing you didn?t already know, I?m sorry.  :(

@_date: 2015-01-04 22:22:19
@_author: Robert J. Hansen 
@_subject: Thoughts on Keybase 
In context, the person had just committed a murder (see my remark about standing over a dead body holding a smoking pistol).
I?m just fine with invasive identity establishment for murder suspects.  :)

@_date: 2015-01-05 20:22:47
@_author: Robert J. Hansen 
@_subject: Thoughts on Keybase 
Yes, which is plenty sufficient to soothe my conscience about invasive
measures.  If there's a homicide, ought it go uninvestigated and the
shooter undiscovered just because we're concerned we might be invading
the privacy of a possibly-innocent person?  I would suspect I was
grossly misunderstanding you were it not for what you said below:
"Until you prove guilt I won't approve of any serious investigation into
who did it or how.  And if somehow you prove guilt anyway then you don't
need to ask these questions any more, so I still won't approve."
Okay.  Thanks.  I'm really glad you're in the minority: if I were to
wind up murdered on a city street, I'd really hope the police would care
enough to find out who did it and how it was done and why -- even if
those questions might offend people's sensibilities.

@_date: 2015-01-06 22:27:10
@_author: Robert J. Hansen 
@_subject: Thoughts on Keybase 
Unfortunately, unless you?re psychic this is impossible.  You don?t know what information will be relevant.  You?ll never discover ?the dead guy spilled a hot coffee all over the other guy yesterday, and they had an argument, and the guy said he was going to kill him for spilling coffee? unless you interview the barista where the shooter had a cup of coffee yesterday.
The police?s job isn?t just to see whether a person fired the gun; it?s also to determine why, and whether more crimes are likely connected. If the dead guy is named McCoy and the living one is named Hatfield, that?s a strong hint the death is connected to a blood feud and the police need to be on the lookout for revenge killings.
Yes.  But some would likely be.  You don?t know what information will be relevant.
Only true in certain countries.
Not a privacy invasion, since that?s a public record.

@_date: 2015-01-06 23:30:45
@_author: Robert J. Hansen 
@_subject: Thoughts on Keybase 
Sure it does ? premeditation.  Murder committed with premeditation and malice aforethought is punished much more severely (in most places) than a heat-of-the-moment killing.  Knowing the offender?s state of mind is thus a perfectly legitimate avenue of inquiry, and requires investigation into background.
Or just Google ?hatfield mccoy?.
I understand you believe there is a right to be forgotten; I hope you will understand I consider that to be Pollyannic fantasy.

@_date: 2015-01-07 11:14:53
@_author: Robert J. Hansen 
@_subject: Thoughts on Keybase 
One more thing ? remember that probabilities are tricksy things.  They vary wildly depending on how one looks at the problem.
Let?s say there are 10,000 threats of murder that are made, and only 10 murders.  If we assume that only ten of those 10,000 threats was connected to a murder, the probability of any given threat being connected to a murder is vanishingly small ? one in a thousand, or 0.1%.  Starting from the fact there was a threat, it would be foolish to conclude the speaker intended on murdering someone.
However, if we look at the murders, we discover that 100% of them are connected to threats.  If you start from a murder, it would be pretty wise to start looking into who threatened the person.
If the only fact you have is ?Alice threatened Bob?s life,? then yes, that?s pretty poor evidence on which to investigate Alice for Bob?s death.  But if the facts you have are ?Alice threatened Bob?s life and Bob was killed under suspicious circumstances,? then yes, that?s actually pretty good evidence on which to investigate her.
ObComputerSecurityStuff: this turns out to be a recurring mathematical pattern that pops up all over in computer security.  If you have 10,000 IDS red-flags warning of catastrophe and catastrophe never happens, that?s a pretty bad system? but if in post-incident analysis you discover, ?hey, IDS correctly reported this when it was happening,? Management will ask you some really harsh questions about why you didn?t pay attention to the warnings.  I think this is how IDSes manage to get sold: too often we look at them from a postmortem, rather than premortem, perspective.

@_date: 2015-01-12 13:46:42
@_author: Robert J. Hansen 
@_subject: Bug with GnuPG 2.1.1 on Windows 7 x64 
On a Fedora 20 box running GnuPG 2.0.20-something (.25?), I made a backup of several sensitive files -- including my keyrings -- and used GnuPG to symmetrically encrypt the archive.  I can decrypt this archive on every 2.0.whatever installation I have, but my one GnuPG 2.1.1 installation, on a Windows 7 x64 box, can't decrypt it.
C:\Users\rjh\Desktop>gpg -vvvv backup.tar.xz.gpg
gpg: using character set 'CP437'
# off=0 ctb=85 tag=1 hlen=3 plen=526
:pubkey enc packet: version 3, algo 16, keyid B8A6B74C001892C2
         data: [2044 bits]
         data: [2047 bits]
gpg: public key is 001892C2
# off=529 ctb=85 tag=1 hlen=3 plen=268
:pubkey enc packet: version 3, algo 1, keyid E5B12DCFA1AC6FC0
         data: [2047 bits]
gpg: public key is A1AC6FC0
# off=800 ctb=8c tag=3 hlen=2 plen=46
:symkey enc packet: version 4, cipher 2, s2k 3, hash 2, seskey 256 bits
         salt 018490B8887579F9, count 65536 (96)
gpg: 3DES encrypted session key
# off=848 ctb=d2 tag=18 hlen=2 plen=0 partial new-ctb
:encrypted data packet:
         length: unknown
         mdc_method: 2
gpg: encrypted with 1 passphrase
gpg: encrypted with RSA key, ID A1AC6FC0
gpg: encrypted with ELG key, ID 001892C2
gpg: encrypted with unknown algorithm 64
gpg: decryption failed: Invalid cipher algorithm
... What's going on here?  It seems like an alarming regression if GnuPG 2.1.1 is unable to decrypt symmetrically-encrypted files made with GnuPG

@_date: 2015-01-12 14:14:36
@_author: Robert J. Hansen 
@_subject: How to sign the name of the name as well, not just the file? 
Drop version 1.7 of your 'foo' program into a directory called
'foo-1.7'.  Now:
tar cf foo-1.7 foo-1.7.tar && gpg --sign foo-1.7.tar
Congratulations.  Even if someone changes "foo-1.7.tar.xz" to
"foo-1.6.tar.xz", you can trivially look inside the archive and see it's
foo-1.7.  The contents are signed and you have some way of being able to
verify the file version hasn't been tampered with by comparing the
version number inside the signed tarfile with the version number on the
What you're talking about is called 'signing a manifest' and it's pretty
much the only game in town.  That technique is in use in a lot of
different places and it's a standard tool.  Done right, it's simple and
easy -- I use a Python script to do this task automagically.

@_date: 2015-01-12 15:50:42
@_author: Robert J. Hansen 
@_subject: A passphrase for all keyrings 
Sure, just use the same passphrase for each certificate.  There's some
risk here, in that if one passphrase gets compromised all your
certificates get jeopardized, but if you're comfortable accepting that
risk then go for it.

@_date: 2015-01-12 16:51:57
@_author: Robert J. Hansen 
@_subject: Bug with GnuPG 2.1.1 on Windows 7 x64 
Update: 2.1.1 on OS X (using Patrick Brunschwig's build) works fine.
The major difference between the two installations is (a) one is a
Windows box and one is an OS X box, and (b) OS X has my private keys on
it, and on Windows I was relying on using the symmetric passphrase to
decrypt it.

@_date: 2015-01-12 16:58:55
@_author: Robert J. Hansen 
@_subject: How to sign the name of the name as well, not just the file? 
Yeah, except that I think I screwed up the order of arguments to tar.
Been using UNIX for over 20 years and I still do that from time to time.
"tar cf foo-1.7 foo-1.7.tar" should be "tar cf foo-1.7.tar foo-1.7".

@_date: 2015-01-13 03:14:51
@_author: Robert J. Hansen 
@_subject: Bug with GnuPG 2.1.1 on Windows 7 x64 
Same results as on Win7/x64.  *However*... I have some useful
information.  Namely, I mistyped the passphrase and got the output below:
quorra:~ rjh$ gpg -vvvv backup.tar.xz.gpg
gpg: using character set 'utf-8'
# off=0 ctb=85 tag=1 hlen=3 plen=526
:pubkey enc packet: version 3, algo 16, keyid B8A6B74C001892C2
gpg: public key is 001892C2
gpg: no running gpg-agent - starting '/usr/local/gnupg-2.1/bin/gpg-agent'
gpg: waiting for the agent to come up ... (5s)
gpg: connection to agent established
# off=529 ctb=85 tag=1 hlen=3 plen=268
:pubkey enc packet: version 3, algo 1, keyid E5B12DCFA1AC6FC0
gpg: public key is A1AC6FC0
# off=800 ctb=8c tag=3 hlen=2 plen=46
:symkey enc packet: version 4, cipher 2, s2k 3, hash 2, seskey 256 bits
gpg: 3DES encrypted session key
# off=848 ctb=d2 tag=18 hlen=2 plen=0 partial new-ctb
:encrypted data packet:
gpg: encrypted with 1 passphrase
gpg: using subkey A1AC6FC0 instead of primary key 2B89BD45
gpg: encrypted with 2048-bit RSA key, ID A1AC6FC0, created 2011-07-28
      "Robert J. Hansen "
gpg: using subkey 001892C2 instead of primary key D6B98E10
gpg: encrypted with 2048-bit ELG key, ID 001892C2, created 2008-07-30
      "Robert J. Hansen "
gpg: encrypted with unknown algorithm 64
gpg: decryption failed: Invalid cipher algorithm
... but when I entered the passphrase correctly, it decrypted correctly.
 I suspect I mistyped the passphrase on Win 7/x64; I'll check that in
the morning.
Still, GnuPG reporting an invalid cipher algorithm when the real problem
is a bad passphrase should still be a bug worth fixing.

@_date: 2015-01-13 11:29:58
@_author: Robert J. Hansen 
@_subject: More strangeness. 
Starting from an empty GnuPG 2.1.1 Win 7/x64 installation, I imported my
existing secret certificate for 0xD6B98E10 and set it to ultimate trust.
  The result was a little ... weird.
C:\Users\rhansen>gpg --edit-key d6b98e10
Secret key is available.
pub  dsa2048/D6B98E10
      created: 2008-07-30  expires: never       usage: SC
      trust: ultimate      validity: ultimate
sub  elg2048/001892C2
      created: 2008-07-30  expires: never       usage: E
sub  rsa2048/810DB5D0
      created: 2013-03-14  expires: never       usage: S
[  undef ] (1). Robert J. Hansen [  undef ] (2)  Robert J. Hansen [  undef ] (3)  Robert J. Hansen [  undef ] (4)  Robert J. Hansen [ revoked] (5)  Robert J. Hansen [  undef ] (6)  [jpeg image of size 14285]
... Now, maybe I'm missing something completely obvious here (and if so,
it wouldn't be the first time), but if I have the secret part of a
certificate, and that certificate is marked as ultimately trusted, isn't
it a bit odd that the user IDs would possess undefined validity?

@_date: 2015-01-16 23:10:37
@_author: Robert J. Hansen 
@_subject: Blackhat 
Today a new movie came out, _Blackhat_, directed by Michael Mann.  Being
a huge Mann fan -- I've seen every movie he ever directed, yes, even
_The Keep_ -- I saw it tonight.
The good news: GnuPG gets namedropped in it.  Twice.  :)
The bad news: it's Mann's worst film, yes, even worse than _The Keep_.
No matter what you do, do not try and think logically during this film.
 Logic will only betray you.

@_date: 2015-01-17 17:48:29
@_author: Robert J. Hansen 
@_subject: Hash selection failure on 2.1.1 
After having tea with a friend, I sent her an email telling her to feel
free to mention it to others if she was so inclined -- and GnuPG seems
to have selected the wrong algorithm.  I'm including the email and
relevant data here.
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
If you feel like mentioning our tea on LJ, please, feel free.  Use your
own best judgment as to what things you relate to others.  :)
Note the SHA-1 hash selection.  This seems ... very odd.  Checking her
key I see:
quorra:~ rjh$ gpg --edit-key Raven
pub  dsa1024/3D7489C0
     created: 2002-02-21  expires: never       usage: SC
     trust: unknown       validity: unknown
sub  elg2048/5DD7F638
     created: 2002-02-21  expires: never       usage: E
[ unknown] (1). Raven Alder [ unknown] (2)  Raven (Key  [ unknown] (3)  Raven Alder gpg> showpref
[ unknown] (1). Raven Alder      Cipher: AES256, AES192, AES, CAST5, 3DES
     Digest: SHA1, RIPEMD160
     Compression: ZLIB, ZIP, Uncompressed
     Features: MDC, Keyserver no-modify
[ unknown] (2)  Raven (Key       Cipher: AES, TWOFISH, CAST5, BLOWFISH, 3DES
     Digest: RIPEMD160, SHA1
     Compression: ZLIB, ZIP, Uncompressed
     Features: Keyserver no-modify
[ unknown] (3)  Raven Alder      Cipher: AES256, AES192, AES, CAST5, 3DES
     Digest: SHA1, RIPEMD160
     Compression: ZLIB, ZIP, Uncompressed
     Features: MDC, Keyserver no-modify
... okay, so each and every user ID lists RIPEMD160 as a hash algorithm;
that's good.  Now let's look at my preferred algorithms.
quorra:~ rjh$ grep default-pref .gnupg/gpg.conf
default-preference-list SHA256 RIPEMD160 AES256 CAMELLIA256 TWOFISH 3DES
... As I understand the way algorithms are selected, GnuPG uses the
most-preferred algorithm in my list that is also present in the
recipient's capability set.  Since SHA-1 implicitly follows after SHA256
and RIPEMD160, it has the lowest priority.
By my understanding, GnuPG should start by trying SHA256 and discovering
Raven doesn't advertise that as a capability.  It should then try
RIPEMD160 and see Raven advertises that, and thus it should use RIPEMD160.
Instead, it went to SHA-1.
This seems like a bug in the algorithm selection code.
Note: my certificate's primary signing key is DSA2048, which would seem
to require SHA224 or longer.  However, in order to be able to sign
messages for people who don't support anything other than SHA-1 or
RIPEMD160 I added an RSA2048 signing subkey a couple of years ago.  It
only gets used when DSA2048 is unavailable, such as here.  So please,
don't panic when you notice it was signed with a key other than my
primary.  :)

@_date: 2015-01-17 21:27:47
@_author: Robert J. Hansen 
@_subject: Hash selection failure on 2.1.1 
[puts on the brown paper bag]
I did until early this afternoon, when while editing my gpg.conf I
foolishly decided to consolidate the personal-*-preferences into
My braino, guys.  Oh man.  :)

@_date: 2015-01-22 13:44:12
@_author: Robert J. Hansen 
@_subject: Crypto device where I need to confirm every operation? 
This attack can't be prevented.
Once the attacker has control over your hardware, you're done.  Game
over.  People keep on trying to invent ways to do crypto even on
compromised hardware, but it's a completely lost cause.  The attacker
has too many options at that point for you to make any sort of effective
If I were Eve and I wanted to defeat your pushbutton setup, here's what
I'd do:
1.  Figure out exactly your operating system
2.  Figure out which forums you look for help on
3.  Start posting messages on forums for your operating system, saying I
was having problems with your specific card reader and how it wasn't
responding to a pushbutton
4.  Post answers, under a different name, saying this was a known
problem with your model of card reader under the most recent USB driver
update, and that unplugging and replugging the device was usually enough
to reboot the card reader and make it work
5.  Under yet more fake account names, upvote the answer and talk about
how it works for me
6.  Repeat  3-5 over several different web forums
7.  A couple of weeks later, subvert your machine
8.  Replace your copy of GnuPG with one that caches the PIN.  When you
enter your PIN and push the button, it silently substitutes my message
for yours.  You sign it, and this compromised GnuPG deposits the signed
message in some hidden file/directory somewhere awaiting my later collection
9.  You'd be understandably concerned.  You'd check web forums and see,
"ah, this bug has been reported by five different people, and a lot of
people are confirming that unplugging and replugging the USB device
solves the problem."
10. You unplug and replug the card reader.  My malware detects the
unplug/replug and uses that as its "clean up and get out of there"
trigger.  It erases itself and leaves behind a clean GnuPG in its wake.
11. You re-try signing your message.  It works correctly.  However,
you've already signed a message of my choosing, and I can pick it up off
your machine at my leisure.
... I understand the wish to make a system that's secure even if the
underlying hardware is compromised.  I really do.  But it's a fantasy.
Can't be done.  Once you lose control over the hardware the attacker has
a near-limitless number of possible attacks, and there's absolutely no
way for you to defend against all of them, or even to effectively
anticipate what it will be.
Please don't tell me how, "well, to defend against your attack I'd
just..."; that misses the point.  The point is there are literally
*hundreds*, if not *thousands*, of attacks like this that could be
levied against you, and there is absolutely no way for you to anticipate
or defend against even a significant fraction of them.
Once you lose control of the hardware, you're done.

@_date: 2015-01-22 18:37:30
@_author: Robert J. Hansen 
@_subject: Crypto device where I need to confirm every operation? 
That's not what the original poster was positing, though: the original
poster was positing *someone else* had complete control -- and trying to
make a system that works in that environment is a fool's errand.
Excellent question.  Vint Cerf has said that in his estimate one of five
desktop PCs is completely pwn3d by malware.  We don't pay enough
attention to that.  We tend to assume the security of the endpoints, and
that's simply not a supportable assumption nowadays.

@_date: 2015-01-22 18:43:08
@_author: Robert J. Hansen 
@_subject: Crypto device where I need to confirm every operation? 
Right: that's because the original poster outlined an attack which was,
in my opinion, naive.
If Eve can read arbitrary memory locations on your desktop PC without
your knowledge, then Eve's got root access.  At that point you need to
start thinking like a clever person with root access.
The alternative is to say, "well, assume Eve's got some exotic side
channel that only allows her a limited ability to monitor..."  Okay,
great: what's the side channel?  Defending against a side channel that
you don't know exists is pretty suboptimal, too, since you can always
imagine another hypothetical side channel.
This isn't about not trusting the endpoint: this is about a security
system built on the assumption the endpoint is already compromised.
There is no "in the long run" here.  If your endpoint is compromised and
you're using it to do crypto operations, you're living in sin.
Smartcards exist to keep private keys safe(r) from being stolen.  They
do a pretty good job of that.  But when we expect smartcards to be able
to somehow make a compromised environment safe to operate in, then we've
crossed the line and turned them into magic crypto fairy dust.

@_date: 2015-01-22 22:15:11
@_author: Robert J. Hansen 
@_subject: Crypto device where I need to confirm every operation? 
There aren't.  It's like saying someone's a "little bit pregnant".  You
have complete control, or you have less-than-complete control.  There
are degrees of less-than-complete, but not complete.
The name of the game is prevention, detection, and recovery: prevent
compromises from occurring, detect them when prevention fails, and
recovery to a known-good state.  In electronic voting we liked to have
multiple orthogonal PDR; the idea of somehow persisting in operations
after complete compromise was always seen as a fool's errand.

@_date: 2015-01-22 22:29:46
@_author: Robert J. Hansen 
@_subject: Crypto device where I need to confirm every operation? 
You're changing the subject slightly.  :)  The thread is about letting a
legitimate user continue to safely use the system; you're talking about
limiting the damage an attacker can do.  The two are related but different.
The idea might be good for damage mitigation; but for permitting
continued normal operation, it's IMO a non-starter on every level.

@_date: 2015-07-07 13:18:25
@_author: Robert J. Hansen 
@_subject: Question about FAQ maintenance 
First, the good news: yes, I did receive your emails about the FAQ.
Second, the bad news: I'm on vacation and won't be responding to them
for another couple of days.  I haven't vanished, I'm just on holiday.  :)

@_date: 2015-07-08 11:45:55
@_author: Robert J. Hansen 
@_subject: Question about FAQ maintenance 
I have a small update to the FAQ that's ready to be pushed, but I'm held
back slightly by my lack of comfort with org-mode (the format used for
the FAQ).
The FAQ hasn't changed in a few years.  Probably 95% of the text is
still correct.  However, there are some changes that need to be made
(e.g., we now give a cautious recommendation for PGP/MIME, and the
defaults have changed slightly, etc.).
The GitHub repo should probably be closed: it's been completely
superseded by the main GnuPG repo.

@_date: 2015-07-17 19:36:01
@_author: Robert J. Hansen 
@_subject: Problems with key available in v1.4.19 but not v2.1.5 
You're using a key generated with PGP 2, which conforms to RFC1991.
This is an *old* *old* standard, and has been pretty much completely
replaced by RFC4880.
Older versions of GnuPG supported RFC1991.  Current versions of GnuPG
have much less in the way of support for RFC1991.
I'd suggest generating a new certificate -- after 20 years you're due
for one.  :)
RFC4880 keys are interoperable between versions.  RFC1991 keys *aren't*.
RFC1991 has an unfortunate dependency on the MD5 hash algorithm, and MD5
is pretty much completely broken for cryptographic purposes.  Since MD5
is broken, current versions of GnuPG refuse to process MD5 data... which
means RFC1991 support is severely curtailed.

@_date: 2015-07-19 14:28:52
@_author: Robert J. Hansen 
@_subject: High resource usage when verifying a signature 
If you visit the website listed at the bottom of each email, you'll be
able to unsubscribe yourself.
Otherwise, you'll have to wait until a list moderator gets back.

@_date: 2015-07-20 12:32:50
@_author: Robert J. Hansen 
@_subject: gpa and gpgex in gpg 2.1.x releases for windows. 
MS has committed to opening up C# and placing it entirely under a libre
license, and Mono is beginning to incorporate some of MS's libre code in
order to improve Mono's ability to run .NET apps.  (Mono doesn't support
WPF, WCF, and some other important .NET technologies.)
Once Mono is able to host/run WiX, which is also libre, then there'll be
a fully libre ecosystem for creating MSIs.
If your objection to MSI is on purely libre grounds, this may change
things.  If your objection is that it's an awful packaging standard, well...

@_date: 2015-07-20 13:01:15
@_author: Robert J. Hansen 
@_subject: Peculiar behavior of --list-secret-keys 
My newly-generated secret key is demonstrating some "first it's there,
then it's not" behavior.  Behold, it's there:
[rjh at localhost ~]$ gpg --list-secret-key b44427c7
sec   3072R/1DCBDC01B44427C7 2015-07-16
uid                          Robert J. Hansen uid                          Robert J. Hansen ssb   3072R/DC0F82625FA6AADE 2015-07-16
Behold, it's not:
[rjh at localhost ~]$ gpg2 --list-secret-keys
sec   rsa2048/B700F482FEAF8109 2005-02-22 [revoked: 2009-03-17]
uid               [ revoked] Robert J. Hansen
uid               [ revoked] Robert J. Hansen sec   dsa2048/23806BE5D6B98E10 2008-07-30
uid               [ unknown] Robert J. Hansen uid               [ unknown] Robert J. Hansen uid               [ unknown] Robert J. Hansen uid               [ unknown] Robert J. Hansen uid               [ unknown] [jpeg image of size 14285]
ssb   elg2048/B8A6B74C001892C2 2008-07-30
ssb   rsa2048/446A446F810DB5D0 2013-03-14
Also, GnuPG seems to have lost track of the fact that D6B98E10 is an
ultimately-trusted key.

@_date: 2015-07-20 13:02:46
@_author: Robert J. Hansen 
@_subject: Peculiar behavior of --list-secret-keys 
Also, why is it trying to read secret keys from my public keybox?  See

@_date: 2015-07-20 13:33:55
@_author: Robert J. Hansen 
@_subject: Really weird behavior with fresh install 
So, in the interests of further checking this out, I figured I'd start
from a fresh slate:
    [rjh at localhost ~]$ rm -rf .gnupg
    [rjh at localhost ~]$ gpg
    gpg: directory `/home/rjh/.gnupg' created
    gpg: new configuration file `/home/rjh/.gnupg/gpg.conf' created
    gpg: WARNING: options in `/home/rjh/.gnupg/gpg.conf' are not ...
    gpg: keyring `/home/rjh/.gnupg/secring.gpg' created
    gpg: keyring `/home/rjh/.gnupg/pubring.gpg' created
    gpg: Go ahead and type your message ...
    ^C
    gpg: Interrupt caught ... exiting
I verified the directory was clean:
    [rjh at localhost ~]$ ls -l .gnupg/
    total 12
    -rw-------. 1 rjh rjh 9188 Jul 20 13:18 gpg.conf
    -rw-------. 1 rjh rjh    0 Jul 20 13:18 pubring.gpg
    -rw-------. 1 rjh rjh    0 Jul 20 13:18 secring.gpg
Let's verify gpg-agent is gone:
    [rjh at localhost ~]$ killall gpg-agent
    gpg-agent: no process found
    [rjh at localhost ~]$ ps ax|grep gpg
    45613 pts/0    S+     0:00 grep --color=auto gpg
Then, when Enigmail tried to get a key list, this happened:
    enigmail> /usr/bin/gpg2 --charset utf-8 --display-charset utf-8
              --batch --no-tty --status-fd 2 --fixed-list-mode
              --with-colons --list-keys
    gpg: error reading key: Invalid user ID
Let's verify there are no user IDs, so ergo there can't be an error
related to an invalid key ID:
    [rjh at localhost ~]$ ls -l .gnupg/
    total 16
    -rw-------. 1 rjh rjh 9188 Jul 20 13:25 gpg.conf
    -rw-------. 1 rjh rjh    0 Jul 20 13:25 pubring.gpg
    -rw-------. 1 rjh rjh    0 Jul 20 13:25 secring.gpg
    -rw-------. 1 rjh rjh   40 Jul 20 13:30 trustdb.gpg
And finally, let's run Enigmail's same command line:
    [rjh at localhost ~]$ /usr/bin/gpg2 --charset utf-8
                       --display-charset utf-8 --batch --no-tty
                       --status-fd 2 --fixed-list-mode --with-colons
                       --list-keys
    tru::1:1437413421:0:3:1:5
... No error.
This is very, very weird.  Does anyone have any thoughts?

@_date: 2015-07-20 14:32:00
@_author: Robert J. Hansen 
@_subject: Peculiar behavior of --list-secret-keys 
Yeah, that was my bad; I forgot Fedora ships with both 2.1 and 1.4.
However, weirdness persists.

@_date: 2015-07-21 13:31:09
@_author: Robert J. Hansen 
@_subject: GnuPG 2.1 
Nonsense: good questions deserve good answers.  :)
It's a little of both, actually.  You may want to ask again on Enigmail,
although you'll likely get a lot of the same answers from a lot of the
same people (myself included).
Right now, I wouldn't recommend ECC for production use.  We're still
getting the kinks worked out of it, and it isn't beyond the realm of
possibility to think we might see significant changes by GnuPG 2.2.
That said, if your purpose is edification and education, go for it! :)
The easy answer is also the wrong one.  This appears to be a serious
usability bug, and we very much want to fix those!
Could you please do the following?
I'll take a look at it.  If I can't see the problem, I'll kick it over
to Patrick and Nicolai for some in-depth debugging.
This is a known issue.  Enigmail expects GnuPG to behave in a certain
way, and since 2.1 GnuPG acts just slightly different than what we
expect.  Getting this fixed is on our to-do list.  :)

@_date: 2015-07-23 17:13:49
@_author: Robert J. Hansen 
@_subject: Archaic PGP usage 
Old versions of PGP were at least FOSS-friendly, if not FOSS themselves,
so it's probably safe to discuss it here.  :)
You'd have to ask them.  There are some reasons to keep using ancient
versions of PGP, but why these specific people keep using ancient PGP is
really a question for them and not this list.
That said:
1.  PGP 2.6 is *small*.  The original PGP specification (RFC1991) is a
small fraction of the size of the modern OpenPGP specification
(RFC4880).  When it comes to trustworthy code, small is beautiful.
2.  PGP 2.6 is extremely well-audited.  GnuPG and Symantec's PGP are
both moving targets, but PGP 2.6 really hasn't changed in about 20
years.  That gives a lot of confidence that its major bugs have been
3.  PGP 2.6 is "good enough crypto".  Modern OpenPGP adds a ton more
capabilities, but for many users PGP 2.6 offers them just enough to do
what they need.  The small-is-beautiful camp tends to have a lot of
overlap with the good-enough-crypto camp.
... All this being said, do I recommend PGP 2.6?  Absolutely not: its
dependency on MD5 alone should disqualify it.  But that doesn't mean I
don't understand some of the motivations of the people who keep using it.

@_date: 2015-07-27 17:31:45
@_author: Robert J. Hansen 
@_subject: Next Big Future on quantum computation 
Some people have been all abuzz over this article lately:
Rather than go through it point by point I'm just going to talk about
the author's closing paragraph, which one would expect to have been
pretty closely checked prior to publication.
The first "wait, what did you just say?" was his assertion that it's
possible to get a 1.4 millionfold speedup over a single CPU with the
money it would take to build a Google data center.  If it was possible,
don't you think Google, Microsoft, Apple, and Facebook would *already be
building them*?  Entrepreneurs who can afford to do this are
overwhelmingly choosing not to do this.  When the people who should be
doing it aren't, think hard and think twice.
His next claim is just ... it makes no sense to me.  "If that rack of
[quantum] computers could not solve your NP-hard problem..."
Point blank: quantum computers cannot solve NP-Hard problems.  Period,
end of sentence.  NP-Hard is where the ridiculously difficult problems
live.  If you had a computer that could break NP-Hard problems, you
could literally crack one-time pads, predict the future, solve the
Halting Problem, reverse entropy, and essentially become a god.
Okay, so maybe the author had a goof.  Maybe he meant NP-Complete.
That's better, right?  If that rack of computers couldn't solve your
NP-Complete problem you could use it for many other revenue generating
and useful applications.
Except that, by definition, if you're unable to solve *one* NP-Complete
problem, you're unable to solve *any* NP-Complete problem.  It's an
all-or-nothing deal.  You can either solve everything in NP-Complete, or
nothing.  No in-betweens.  So reading his sentence as "couldn't solve
your NP-Complete problem" doesn't improve it.  Can't solve one, can't
solve any.
Let's scale it back some more.  Maybe he meant "If that rack of
computers couldn't solve your NP problem you could...".  Okay.  Now
we're getting kind of close to reality, except that NP is a *big* class
of algorithms -- this is like asking someone to find your lost dog and
saying you're pretty sure you left him in Australia.  It's too vague to
really be meaningful.  NP is like that, but its Outback is bigger.
Take it back a step further: "If that rack of computers could not solve
your BQP problem you could..."  BQP is the set of all algorithms that
can be efficiently solved with a quantum computer.  If that rack of
computers can't solve a BQP problem, then maybe you should consider
whether you've been defrauded.
So that sentence there --
... I'm a thesis shy of a Ph.D. in computer science and I've got
absolutely no idea what the author meant by what he said in that
paragraph.  None.  Zero.  It sounds nice but I'm at a loss to explain
what it means.
I'm not an expert on rocketry, so I won't comment on those parts of the
essay.  But the computer science parts of the essay are all like this:
they're superficially glib but they're just plain *bad*.
Also, check out the author's bio/resume:

@_date: 2015-07-27 18:01:26
@_author: Robert J. Hansen 
@_subject: Next Big Future on quantum computation 
For those who like pedantry: NP-Hard is the name given to any problem
that is as hard, or harder, than any problem in NP.  The Traveling
Salesman Problem is NP, and is known to be as hard as any problem in NP,
therefore it's NP-Hard.
But it's also the *easiest* NP-Hard.
Because remember, NP-Hard is anything as hard *or harder* than anything
in NP.  Playing a perfect game of Go isn't in NP, ergo playing a perfect
game of Go is NP-Hard.  NP-Hard is a collective term that covers a truly
staggering amount of terrain, going from the "easy" problems like
traveling salesman all the way up to the "are you kidding me?" like
reversing entropy.
Few computer scientists like talking about NP-Hard.  It's simply too big
of a space.  And if anyone seriously talks about a general technique
that works on NP-Hard problems, they get laughed at.  Lots.  Because
there isn't one, and we've formally proven there isn't one.  This was
the proof that made Alan Turing famous.

@_date: 2015-06-01 10:30:59
@_author: Robert J. Hansen 
@_subject: Facebook and OpenPGP 
Facebook has just this morning announced limited support for OpenPGP.
At present, it's limited to allowing users to upload an OpenPGP
certificate, and Facebook using that certificate to encrypt all email
communications between Facebook and the user.
It's a small step forwards, but an exceptionally welcome one.
Also, thanks to the individual in Facebook's security team[*] who tipped
me off to this minutes after the release was official.  I had no advance
notice of it, but the very instant it got rolled out FB made contact --
with the expectation, I think, that I would spread the word, although no
one asked me to do anything.
Thanks, Facebook.  We really appreciate not just the new feature, but
your reaching out to make sure the people who would most love this new
feature know about it.  :)
[*] This individual has requested his affiliation with Facebook not be
published, lest he start getting 50,000 emails a day from people asking
him to reset their passwords.  If you know or have figured out who he
is, please honor his request.  They've done us a favor: the least we can
do is return it.

@_date: 2015-06-01 12:18:46
@_author: Robert J. Hansen 
@_subject: Facebook and OpenPGP 
Apparently, some people are having trouble finding Facebook's public
announcement.  See the following:

@_date: 2015-06-02 12:41:40
@_author: Robert J. Hansen 
@_subject: s2k-cipher-mode default 
At present I'm against it, but my mind's not made up.
Right now pretty much everyone is content with RSA-3072, which has an
estimated work factor comparable to AES-128.  So if 128-bit crypto is
enough, I don't understand the motivation behind jumping to AES-256.
There needs to be something motivating this besides "bigger is better".
Let me turn the question around, dkg.  (Completely serious here, not
snark.)  What problem do we have with AES-128 that switching to AES-256
will solve?

@_date: 2015-06-02 14:26:39
@_author: Robert J. Hansen 
@_subject: s2k-cipher-mode default 
I think this is a pretty unrealistic thought experiment.  It requires
two conditions to be met:
We don't have  but in the (oft-forlorn) hope we'll see more OpenPGP
adoption I'll give it to you.  But  isn't the description of any
real-world organization I've ever heard of.  Honestly, it sounds more
like a James Bond-style evil organization like SPECTRE or QUANTUM than
like anything that exists in the world.
(Quoting you quoting djb)
In other words, the likelihood of choosing one of the weak set by random
is 10**-53.  That's a one-in-
I'll take those odds.  Happily.  Twice on a Sunday.
(Still quoting you quoting djb)
So there's a 10**-88 chance that one of my keys can be broken in 10**53
computations?  Sign me up.
I have a lot of respect for djb, but on this one he's just way off in
left field.
(Meant as humor, not snark:)
I am much more concerned with the possibility of landing a hot date with
Claudia Schiffer[*], which is rudely interrupted by the eruption of the
Yellowstone Caldera that wipes out all life in North America, than I am
with any AES-128 weakness.  Landing a hot date with Claudia Schiffer and
the end of the world happening before I pick her up for our night out is
considerably more likely to happen.  It would also probably make me
considerably unhappier than a random AES key, somewhere, being broken.
Given I've spent about half an hour of my time calmly considering the
possibilities of your hypothetical, perhaps I might trouble you to spend
a minute or two coming up with a plan for how I might enjoy an evening
with Claudia even as the world ends?  I will understand if your reaction
is hysterical laughter.  :)
[*] You youngsters who have no idea who Claudia Schiffer is... when I
was your age, she was The Awesomeness.  Had a soft spot for her in my
heart for about the last twenty-five years.

@_date: 2015-06-02 15:46:18
@_author: Robert J. Hansen 
@_subject: s2k-cipher-mode default 
Yes, I understood that.  I think maybe you're misunderstanding: if it
was a case of my asymmetric key being compromised, I'd take it more
seriously.  (Not much more seriously: it's still far out there.)
If an asymmetric key is compromised then past and future traffic gets
revealed, people can forge new signatures, the WoT can be abused and
misused... it gets very nasty very quickly.  But looking through my
sent-mail folder, the last encrypted email I sent was to a friend
offering to buy him a drink when we met up at a science fiction
convention in Baltimore.
The likelihood of a compromised asymmetric key leading to terrible
consequences is high.  The likelihood of a compromised symmetric key
leading to terrible consequences... not so much.  If someone breaks my
RSA key I'm going to be extraordinarily upset.  If someone learns I
offered to buy a friend a drink in Baltimore, I'm going to be annoyed.
I'm just fine with the per-message risk.
Daniel, seriously: sit down and run the math.  If you don't have a copy
of Mathematica handy, Wolfram Alpha can do the arbitrary-precision math
needed so you can be sure I'm not misleading you.
Each message has a 10**-53 chance of being part of the weak set.  The
likelihood of a message being part of the strong set is (1 - 10**-53).
Raise that to a power N and you get the probability of *all* keys being
part of the strong set.
Here's the takeaway: after 10^50 keys there's still a 99.9% chance all
the keys are strong.
[Note for UK/European readers: 'million' here denotes an American
million: 1,000,000.]
Do you think GnuPG will ever generate 10^50 keys?  I certainly don't.
Assuming there are a million GnuPG installations generating a million
AES-128 keys a second, running continuously, that's only about 10^19
keys per year.  You'd have to run these million machines for
substantially longer than the lifetime of the universe to even have a
statistically significant chance of generating a weak key.
At this point the conversation is bikeshedding.  IMO, there's absolutely
no reason to think your scenario is likely, and many reasons to think
it's not.
djb is a smart guy and I have no doubt that what he's talking about is
real.  It's also such an incredibly theoretical attack that it really
doesn't deserve to be brought up in a conversation about real-world
Given this, I would feel much better if Werner were to spend his time
reviewing the code for exploitable bugs than spending even five minutes
changing the s2k default from AES-128 to AES-256.  The five minutes
spent reviewing code stand a very small chance of discovering something
exploitable -- call it one in a billion -- but that's still so much more
productive a use of time than using those same five minutes to defend
against an attack of such vanishing small probability that we have to
break out Mathematica to talk about it.
I suggest you worry about the Yellowstone Caldera while you're at it.
That has a far greater likelihood of taking out your entire baseball
stadium.  :)

@_date: 2015-06-03 08:58:00
@_author: Robert J. Hansen 
@_subject: s2k-cipher-mode default 
Not 10**50 messages worth, we're not.
Maybe 10**9.  *Maybe*.  Multiply that by a factor of
100,000,000,000,000,000,000,000,000,000,000,000,000,000 and we'll talk.
No, I'm not kidding.  Do the math yourself.

@_date: 2015-06-03 11:37:41
@_author: Robert J. Hansen 
@_subject: s2k-cipher-mode default 
Time for me to put out a big "I screwed up" message.  I screwed up: my
math is, in fact, wrong.  I was in a boring meeting today and was
mentally reviewing my math and realized, "wait, there's no way a 2**-78
chance of picking a weak key by accident corresponds to a 10**-53 chance."
I was right.
There are a few different ways you can convert between log bases, but
like many mathematically-inclined people I have an affinity for base e.
 Conversions into and out of base e are really simple.  To convert a
logarithm in base N into base e, multiply by ln(N).  To convert a
logarithm in base e into base N, divide by ln(N).  And so on.
The binary logarithm of 2**-78 is -78.  Multiply that by ln 2 and you
get -53.  2**-78 is e**-53.
You guys see the problem, right?  I converted it into base e, but
neglected to convert it into base 10.  ln(10) is about 2.3.
So 2**-78 = e**-53 = 10**-23.
Yowch.  It's not every day you create an error of thirty orders of
magnitude, but ... there you have it.  (I'm still an amateur, though.
The physics community has an error of 120 orders of magnitude in their
computed value for the cosmological constant, and they still have no
idea where they're screwing up.)
This changes the math slightly.  You now need about 10^20 messages to
have a very small chance of one message being encrypted with a weak key,
not 10^50.  That's still a *huge* number, though, and is greater than
the number of GnuPG messages I expect to ever be encrypted.
I'm still not worried, the conclusion is still sound.  Still, an error
of thirty orders of magnitude should be noted -- and if anyone wants to
point at me and laugh, I definitely deserve it.  :)

@_date: 2015-06-16 19:45:57
@_author: Robert J. Hansen 
@_subject: General brute force attack question 
Pretty close.
Not quite.  If you're doing a brute-force attack it's easy to figure out
what fraction of the possible number of keys you've tried, and to
present that as a progress bar -- when the progress bar is half done,
you've searched half the possible keys, and thus there's a 50% chance of
finding the key by then.  So yes, it's possible to come up with a pretty
good estimate of how long it'll take to brute-force a cipher, and that
lets you do things like status bars... it's just that the amount of time
is, for any good system, ludicrously big.
Called "cribs", yes.  Even then, this is rarely used in the key itself.
 Usually it's used as the input to a key derivation function, which
accepts something nice and English-like as input and yields a garbled
mess for output.
Add *many* more zeroes on to this.  :)
Without getting into high levels of detail, all I can say is "it will
vary from system to system."

@_date: 2015-06-17 10:02:35
@_author: Robert J. Hansen 
@_subject: General brute force attack question 
Yes.  And that's what lets you make a statistical model: "there's a 25%
chance it'll take this long, a 50% chance it'll take this long," etc.,
etc.  You're confusing a lack of certainty with a lack of accuracy.  :)
Yes, Hollywood is awful about progress bars.  But that doesn't mean you
couldn't do one in an intelligent manner -- it just means Hollywood
doesn't do them intelligently.

@_date: 2015-06-17 10:15:07
@_author: Robert J. Hansen 
@_subject: Teaching GnuPG to noobs 
Varies between extremely good and extremely bad with very little
in-between.  When addressing people who have the motivation to learn and
the ability to think analytically, it's been great.  When addressing
people who lack one or the other it's frustrating, and when addressing
people who lack both it makes me prefer dental surgery.
The most common one I've found is not understanding the material as well
as they think.  This tends to come through most in the metaphors an
instructor uses.  For instance, I frequently encounter instructors who
tell the class to imagine a lock with two keys, one that locks it and
one that unlocks it, and they proceed to use that lock metaphor to
explain crypto.
It's absurd.  Who in the class has ever seen a lock with two keys, one
that locks it and one that unlocks?  The metaphor's ridiculous: the
locks the students are familiar with require *no* keys to lock and only
one key to unlock.
When I see an instructor use inappropriate metaphors, who doesn't
understand that these metaphors are inappropriate, it makes me think the
instructor has a superficial and fragile understanding of the material.
 And frankly, there are a lot of those people out there.
(One metaphor I've been playing with lately, but haven't decided yet
whether it's a good one, involves magical sealing wax.  This magical
sealing wax can only be cut or shaped by one person -- the person who
owns it.  If you seal a message with this person's magical sealing wax,
only that message recipient can open it.  And if you see that someone
has pressed a signet ring into it, you know the person who owns the wax
did it, since only they could shape it.  So if Alice were to affix her
magical sealing wax to a message and press her signet ring into it, and
then fold the letter and seal it with Bob's magical sealing wax, only
Bob could cut the magical sealing wax to read the message and he would
know that only Alice could have put her signet on the blob of wax at the
end of the letter.
Is magical sealing wax a better metaphor than a lock with two keys?
Yes.  Is it better *enough*?  I don't know yet.)
Anything that gets explained with a poorly chosen metaphor.

@_date: 2015-03-03 12:51:52
@_author: Robert J. Hansen 
@_subject: Circumvention Tech Summit in Valencia 
Daniel Kahn Gillmor and I are both here.  (And in fact, we met briefly,
and much to the surprise of many people here but not to either dkg or
myself, there was mutual respect, goodwill, and a stunning lack of
bloodshed.)  :)
Admittedly, "the GnuPG dev people" is really a one-element list
containing Werner.  But there are certainly people active in the GnuPG
community here.

@_date: 2015-03-03 15:49:41
@_author: Robert J. Hansen 
@_subject: Circumvention Tech Summit in Valencia 
And happy to buy people beer.  Thanks again, Samir.  :)

@_date: 2015-03-03 16:15:45
@_author: Robert J. Hansen 
@_subject: Circumvention Tech Summit in Valencia 
I'm glad I contribute code to a couple of small FOSS digital forensics
projects, then.  Because I've never contributed a single line of code to
GnuPG or Enigmail.  :)

@_date: 2015-03-03 16:53:14
@_author: Robert J. Hansen 
@_subject: German ct magazine postulates death of pgp encryption 
I fully agree with Kristian.
I further don't see how keybase.io amounts to "poor security practice".
 The Web of Trust is, itself, a poor practice because it's
rarely-if-ever used in practice; even something like TOFU is far
superior to the Web of Trust in most real-world environments.

@_date: 2015-03-03 17:01:34
@_author: Robert J. Hansen 
@_subject: Thoughts on GnuPG and automation 
Hans, please trim your quoted material.
Unless you've got a desk somewhere deep inside Fort Meade and you're
sitting in on briefings the rest of us aren't, you don't know this.
There's a lot of panic and paranoia in the air already without people
making it worse by treating what they *think* is true as if they *know*
it's true.
(I don't know if what he's claiming is true or false... but I *do* know
that I don't believe his certainty, and I wouldn't believe anyone else
who claimed to be certain, either!)
keybase doesn't expect users to upload the private key.  It works just
fine if you don't, and in fact you have to go through an extra couple of
steps to put the private key on the keybase servers.
For some use cases this is a good practice.  For many more it's a bad
practice.  But it's way too facile to simply say,

@_date: 2015-03-03 17:49:42
@_author: Robert J. Hansen 
@_subject: Thoughts on GnuPG and automation 
Eh.  Different operating systems, sure: that's the nature of kernels.
They provide different syscalls, and that's at root how you launch an
external process -- by making syscalls.
But different programming languages can have very different ways of
launching and handling external processes?  I've never seen that to be
true.  C Process, C's fork/exec, Python's subprocess, Go's
syscall.StartProcess()... it's all pretty much identical.  There are a
couple of exotics, but they're exotic.
It *can* make for complicated and weird software.  I don't doubt that
GnuPG doesn't fit well into the Android model, but this isn't a reason
to do GPGME differently.
If I'm Count Rugen, I'm not going to complain that glovemakers need to
change the way they do things to accommodate my six fingers.  I'm going
to acknowledge that my hands are quite a lot different from the
glovemakers' models, and rather than tell the glovemakers how
five-fingered gloves are a mistake because they don't account for the
possibility of six, I'm just going to hire a tailor to make my gloves.
(Count Rugen: the six-fingered villain from _The Princess Bride_.)

@_date: 2015-03-03 19:31:14
@_author: Robert J. Hansen 
@_subject: Thoughts on GnuPG and automation 
If all encrypted traffic is deemed suspicious, then 99.9999999% of the
suspicious set -- Amazon transactions, Google searches, SMTP transfers,
instant messaging, OkCupid profiles, iTunes purchases, and more -- is
totally clean.  You'd have statistically better odds by arresting random
people on suspicion of murder.  The policy would be completely
pants-on-head absurd.
This leads to a different question: "Is it more likely that this is the
real pants-on-head absurd policy, or that the _Forbes_ journo has
profoundly misunderstood the subject?"
Just because something's been published doesn't mean it should be
trusted.  Bring your brain -- and when someone tells you something that
supports your worldview, look at that thing hard and twice.

@_date: 2015-03-03 19:35:40
@_author: Robert J. Hansen 
@_subject: Thoughts on GnuPG and automation 
GnuPG and GPGME are products of their birth, just like anything else.
It was built for desktop operating systems.  If you want to make it live
in the mobile space, go with God and I wish you all the luck in the
world -- but if GPGME isn't working well for you, the burden is on you
to do something better.  The burden isn't on GPGME to totally change how
it does things.
I really don't understand what you're getting at here.

@_date: 2015-03-04 01:40:52
@_author: Robert J. Hansen 
@_subject: Thoughts on GnuPG and automation 
Did.  Have.
In other words, "you're wrong, but I'm not going to present any evidence
or reasoning, I'm just going to make vague statements about how you're
missing details which I am privy to."
At this point, you saying that you believe something -- without
supporting evidence -- no longer carries any weight with me.  If you're
going to present this without evidence, I'm going to reject it without

@_date: 2015-03-04 01:45:12
@_author: Robert J. Hansen 
@_subject: Thoughts on GnuPG and automation 
Maybe I'm a little irritable here, but -- pretty much everyone who's
ever hacked on GnuPG has found situations where GPGME isn't a good
solution, sometimes for architectural reasons and sometimes for API
reasons and sometimes for language binding reasons and sometimes for
licensing reasons and... etc.
No one has ever said GPGME is the all-purpose, all-in-one solution.  No
one.  So why are we having this discussion?  What was the point in even
bringing it up?

@_date: 2015-03-04 10:50:53
@_author: Robert J. Hansen 
@_subject: Thoughts on GnuPG and automation 
Perhaps.  Plausible, even, given storage requirements for connection
information.  But storing traffic, when 99.999999% of it is good --
that's ridiculous.
The reason why I'm so fervent about stomping down on fashionable
misinformation, by the way, is because the people propagating these
things are *hurting* *people*.
Security is as much a state of mind as it is a state of reality.  Here
in the United States, violent crime is down 50% since the 1990s, and
crimes against children are down even more than that.  Yet, due to a
steady stream of awful news stories, most people feel they're in more
danger than ever before, and parents are genuinely afraid to let their
kids play outdoors.  The last time we've been this safe in our
communities was the early 1970s, and we feel like we're under siege.
That's no way to live.  When people feel like they're under siege they
act like they're under siege.  Personal relationships fray.  People stop
trusting each other.  Happiness plummets.  Suffering increases.
We face a lot of threats on the electronic front, yes.  We absolutely
need to face these threats squarely.  If we pretend a real threat
doesn't exist, that's terrible for our overall health as a society.
But if we pretend a false threat *does* exist... that's just as bad.
The possibility of widespread metadata collection is real, troubling,
and the free countries of the world need to engage in some spirited
discussion about it.
The possibility of *every encrypted communication* being intercepted and
stored for later exploitation ... is not real, and we need to stop
treating it as such.

@_date: 2015-03-04 10:57:57
@_author: Robert J. Hansen 
@_subject: Thoughts on GnuPG and automation 
You're looking at FOSS projects that have successfully used GPGME, but
that doesn't tell you about proprietary projects that have chosen not to
use GPGME.  I've had clients refuse to use GPGME because of the
licensing, even under the LGPLv2.1.  (Foolish, I know.)  Other times
I've discovered GPGME doesn't support a particular feature I need, like
discovering the default preference lists that are currently in use.  Etc.
This doesn't impact my opinion of GPGME as a tool.  It just means that,
like all tools, there are environments where other tools are better ideas.

@_date: 2015-03-06 17:45:46
@_author: Robert J. Hansen 
@_subject: where can one find an official gnupg project statement on the 
I think this is a bad idea.
Third-party software repositories are beyond the capabilities of many
users, particularly casual ones.  Their distro came with certain
repositories pre-configured.  So for us to say, "oh, and by the way, you
need to add this new third-party distro, and then do these steps to
replace your old distro-provided package with a new one," runs smack in
the face of
We're not going to make things better by demanding casual users develop
even more skills.

@_date: 2015-03-11 13:10:08
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
At the Circumvention Tech Festival there was an event called
speed-geeking, where the people responsible for a tool would speak for a
few minutes on something related to the tool and field a few minutes of
Q&A from the audience about the tool.  I received a number of requests
afterwards to reprise my Enigmail speed-geeking presentation, so I wrote
it up and put it online.
"Things you're doing wrong with Enigmail" is a short (500-word) essay on
four mistakes I repeatedly see Enigmail users making.  However, it's not
limited to Enigmail: most of the content is broadly applicable to any

@_date: 2015-03-11 14:13:47
@_author: Robert J. Hansen 
@_subject: AES-NI, symmetric key generation 
It's also way overkill.  :)
"gpg --armor --gen-rand 1 16" will produce a (relatively) short
passphrase suitable for pretty much any imaginable usage.  128 shannons
of entropy's nothing to sneeze at.

@_date: 2015-03-12 11:51:15
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
For many users, smart cards are a good idea.  (I've got one myself.)
But for just as many users, smart cards are inconvenient and overkill.
Frankly, they have awful usability, just terrible.  When I receive an
email message encrypted to my smart card key, finding the smart card is
easy -- it's in my wallet -- but finding the smart card *reader* is the
sort of thing that leads me to crazed conspiracy theories.  Is the
reader attached to my laptop?  Did I leave it at the office?  Did I kick
it under the sofa?  Did the space aliens from Zarbnulax take it?
The upshot of it is that whenever I want to decrypt messages sent to my
smart card, in the best case scenario (I remember where the reader is
and it's within a few meters of my desk) it takes me 30-45 seconds to
read the message.  In the worst-case scenario, I'm in Valencia, Spain,
and my reader is in Washington, D.C., and there's no way I'm reading
this traffic until I get home.  (And in case you're wondering, yes, that
really happened to me.)
If email crypto makes it hard to read email, few people will adopt the
technology.  We want technologies that make our lives easier, not
harder.  Smart cards, although a really good idea in certain
environments, make crypto harder in a lot of environments.  I'm not sure
the (marginal) additional security from using a smart card is worth the
(very real) usability expense.
Is it unsafe to keep your keys on your hard disk?  Dunno.  Depends a lot
on your situation.
Is using a smart card a must?  Dunno.  Depends a lot on your situation.
Hope this helps.  :)

@_date: 2015-03-12 12:25:27
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
Yeah -- back in 2000 I used a Rainbow iKey, which was one of the first
USB tokens.  Then I discovered the downside of USB tokens: they don't
take well to going through the wash.  (You know how when you pull
clothes out of the dryer they've got all kinds of static electricity on
them?  USB tokens don't take kindly to that.)
I dunno, maybe today we've got USB tokens that can survive the wash.
Wouldn't surprise me.  Unfortunately, I don't have the money to make a
good empirical test.

@_date: 2015-03-12 13:21:56
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
Sure!  And I even said that.  "For many users, smart cards are a good
idea.  (I've got one myself.)  But for just as many users, smart cards
are inconvenient and overkill."  Your use case isn't my use case.
That said, I've heard from enough people over the years sharing the "I
can never find a reader when I need one" problem for me to think I'm not
Depends on the user.  I personally have three different 128-bit
passphrases memorized (sixteen random bytes base-64 encoded).  Other
people have trouble remembering their four-digit ATM PIN code.
Will I get additional security from using a smart card?  Depends on my
specific usage and my goals, but in most of my cases, no.  Enough to
justify the usability expense?  Again: it depends on my specific usage
and my goals, but in most of my cases, no.
But that doesn't mean I don't use my smart card.  I do.  I just use it
in use cases where it makes sense to do it.
Probably not, but in my defense, Apple didn't put a hole in my laptop
and give me a glossy brochure showing a MacBook Pro hanging off my
keychain, either.  Rainbow Technologies did, and what happened to the
token after that was predictable.  It went where my car keys did.
Namely, the wash.
Not "completely unusable".  In the best case, a smart card adds 30-45
seconds to my operation time.  That's a price I'm willing to pay for
certain operations.  For others, it's not.
If you think I'm portraying them as "completely unusable," then I think
you didn't bother to read my message very closely.  Their usability and
appropriateness is *intensely* dependent on the user and the operating
environment.  For some users they make a lot of sense.  For others, they
The number of environments, number of users, and number of use cases, is
way too vast to be able to make a glib statement like this.  You're just
wrong.  :)
The answer is, "it depends."

@_date: 2015-03-12 14:52:36
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
In response to someone who was thinking that storing keys on your hard
drive was categorically unsafe, and that smart cards were categorically
necessary, yes.  If you want to illustrate that smart cards are not
categorically necessary, you don't highlight instances where they're
useful and/or necessary: you highlight instances where they're not.  Had
the original poster said, "Is it correct to say there's no real use case
for smart cards?", I would have talked about situations where they're a
real benefit.
No.  You said they add security, period, and that they either
inconvenience minutely or add convenience.  That's not an "it depends"
answer.  That's a "this is true in all times and situations" answer, and
that's exactly wrong.  They do *not* add security in all times and
situations, and they do *not* only ever cause minute inconvenience.

@_date: 2015-03-12 15:04:26
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
Yep!  And just as importantly: it may require it.  It depends on your
threat model and what you need to defend against.  Ultimately, it's a
judgment call.
This, too!  If you want to play around with them and have fun, don't let
me stop you.  :)

@_date: 2015-03-12 15:44:31
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
I dunno.  I think there are some good arguments for regular users
employing them; I just don't think those arguments are all that compelling.
For instance, I have my smartcard cross-signed with my usual certificate
(0xD6B98E10).  If you trust 0xD6B98E10, you'll probably also trust my
smartcard certificate -- and vice-versa.  Now let's say that in a couple
of years 0xD6B98E10 gets compromised.  I revoke the certificate,
propagate the revocation, and generate a new cert (0xBADD00D5).  I sign
0xBADD00D5 with the smartcard cert and put it up on the servers.  Etc.
People can see 0xBADD00D5 is signed by my smartcard and can have
confidence this is my new certificate.
This is basically the idea of the "offline master signing key" that a
lot of people talk about, but a lot more convenient due to the smartcard
form-factor.  I don't have to worry about air-gapping the signing
system, I just have to worry about finding the card reader when it comes
time to generate a new cert.
Yep.  Don't lose 'em.

@_date: 2015-03-13 10:08:46
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
This is not true.  There are a lot of use cases where "there are no
backups of this smart-card key" are baked into the security model.
That's why we can create keys on the card directly: that way they never
need to exist outside of the card.
Yes, and in some security models that's preferable to having a backup
copy somewhere.

@_date: 2015-03-13 14:23:35
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
Let's calm things down, folks.  :)
We're communicating in a text medium.  Sometimes, things we think are
obvious aren't obvious to others.  Let's take a deep breath and remember
that everyone's discussing things in good faith, okay?  :)
Nothing but peace here, guys.

@_date: 2015-03-13 17:20:39
@_author: Robert J. Hansen 
@_subject: Making the case for smart cards for the average user 
(ObWarning: no facts, just opinions.)
I think the biggest problem we face, to be honest, is our conviction
that there's an answer out there and we just have to find it.  It seems
to me far more likely that it's like curing cancer -- if/when we finally
cure cancer, we won't cure cancer, because there is no single thing,
"cancer".  Cancer is a name we give to literally thousands of distinct
different diseases which have exactly one thing in common: uncontrolled
cell growth.  Leukemia isn't glioblastoma, and my wanting to keep my
email safe against sneaking sysadmins isn't the same as a human rights
worker in Syria who's living under persistent surveillance.
In a similar vein, I don't think we will ever reach "the answer" for
email crypto.  There are too many people with too many different use
cases, skill levels, threat models, needs, and so on.  Our obsession
with finding "the answer" seems to blind us to the possibilities of
making small positive changes in small communities, with the idea that
if we do this enough times, for enough small communities, we might be
able to make a difference overall.
So -- no, I actually don't hold out much hope for your project.  Smart
cards are not part of the answer, because I don't think there's an
answer to be had.
But smart cards could definitely be a part of many small answers.  :)

@_date: 2015-03-13 17:33:05
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
Be careful.  When was the last time you checked the GnuPG code?  And
when was the last time you checked the options your distro maintainer
used to build your GnuPG?  :)
GnuPG doesn't have one RNG.  It has *many* RNGs.  Some of them are
really just thin wrappers over lower-level OS facilities.  And if you
don't trust /dev/urandom, I'd suggest using a different operating
system, because that's a game-over compromise.  It's like not trusting
CryptGenRand on Win32.

@_date: 2015-03-15 08:57:21
@_author: Robert J. Hansen 
@_subject: Making the case for smart cards for the average user 
I disagree: I don't believe there is an "average person" or an "average
use case".
But please, don't mistake this for discouragement!  I just want to
caution you against judging your efforts by an impossible standard.
Your efforts are very unlikely to be "the solution", because (IMO) there
is no single solution.  But that does not invalidate the benefit some
will receive from what you do.
Really, please read this as strong encouragement.  But please don't
judge your success by an unachievable goal.  You deserve better
treatment than that.  :)

@_date: 2015-03-15 08:59:42
@_author: Robert J. Hansen 
@_subject: Enigmail speed geeking 
No idea -- I haven't looked at haveged.  Sorry.  :(

@_date: 2015-03-17 15:44:47
@_author: Robert J. Hansen 
@_subject: Defaults 
Given that 2.1 introduces a lot of new capabilities (mostly with respect
to ECC), I think now, early on in the 2.1 series, would be a good time
to discuss changing the defaults for newly-generated certificates.
In a nutshell:
[*] As I read the tea leaves, I'm more convinced of AES256's long-term
strength than I am of AES128's.  However, the idea that either one of
them is somehow 'weak' is just ludicrous.  If you use AES128, don't
panic.  :)
[**] Don't believe me, though.  I haven't done any serious crypto work
in years and my memory could be off.  I vividly recall this warning in
both _Applied Cryptography_ and the _Handbook of Applied Cryptography_,
and I think it was also given in _Practical Cryptography_ and maybe
_Security Engineering_.  Check this before you believe it!

@_date: 2015-03-17 17:33:48
@_author: Robert J. Hansen 
@_subject: Defaults 
That one's a related-key attack, which requires the attacker to have a
significant number of keys that have some mathematical relationship to
each other.
OpenPGP uses random nonces for symmetric keys (or iterated hashing,
which does a pretty good job of destroying mathematical relationships),
so this attack is a complete nonissue for OpenPGP.  :)
The biggest reason, IMO, to move to 256-bit ciphers is because it will
hopefully quell the voices who are screaming that 128-bit crypto is
somehow insufficient.  It's not, and no one has ever presented any
serious evidence that it is, but these arguments crop up with great
regularity nevertheless.

@_date: 2015-03-17 18:25:12
@_author: Robert J. Hansen 
@_subject: Defaults 
I have reasons to prefer RSA, yes, but whether they'll convince you is a
different matter.  :)
Where signature size matters most is in email.  An RSA-3072 signature's
size is significant (says the sophist, surreptitiously suggesting
alliteration on several syllables) on a 512-byte message; there, the
overhead is huge.  On a 5MiB file, the signature's insignificant.
In email, the way of the future is PGP/MIME.  For years I've advocated
inline PGP and said PGP/MIME wasn't ready for prime time, but I'm now at
the point where I believe PGP/MIME is ready to be the default.  And in
PGP/MIME messages, the end-user never sees the signature block, so
there's very little for users to get upset over.  The size difference
between a DSA-3072 signature and an RSA-3072 signature is unlikely to
make a dent in anyone's mobile data plan, either.
So the main advantage DSA has over RSA -- smaller signature size -- is
And although it genuinely pains me to say this, I can understand why
some OpenPGP users mistrust DSA.  I don't mistrust it and I think people
who do mistrust it are doing so erroneously, but I understand.  NIST's
reputation has taken a pounding in the last few years.
Frankly, people trust RSA more.  I personally think that's foolish:
they're both rock-solid algorithms.  But I understand it, at the same
time, and a decent respect for the concerns of others causes me to
recommend RSA.  I frankly have no preference between RSA and DSA; some
other people in the community trust RSA more; so, okay, let's go for RSA.
Because at present GnuPG supports the following curves:
I cannot in good conscience recommend changing the defaults to an
algorithm not yet supported by GnuPG.  :)
Looking over it again, it turns out the Canadians are distrustful of
128-bit crypto *in general*.  None of them are approved for periods
longer than seven days.
About fifteen years ago I learned about a miss-in-the-middle attack on
IDEA that broke 4.5 of 8.5 rounds (by ... Biham, I think).  That made my
eyebrows go up.  It wasn't a full break, but it sure as hell was
interesting, and attacks only ever get better over time.  That was when
IDEA started giving me the heebie-jeebies.
Khovratovich presented a break against full (8.5-round) IDEA in 2012.
This attack isn't huge -- it reduces 128 shannons of uncertainty to 126,
more or less -- but, at the same time, it's freaking enormous.  From
here on out, every improvement is going to reduce the effective strength
of IDEA.  We're no longer playing games of trying to extend things to
the full cipher: for the last three years we've been watching the full
IDEA be subjected to real attacks.
So far those attacks haven't been successful.  Like I said, a
two-shannon reduction isn't much.
But imagine what it's going to be like in another five years.

@_date: 2015-03-17 18:27:56
@_author: Robert J. Hansen 
@_subject: Defaults 
D'oh!  Forgot to mention an important one --
RSA-3072 keys can be moved to smart cards, and/or generated on the same.
Very few smart cards support DSA.  :)

@_date: 2015-03-17 18:37:40
@_author: Robert J. Hansen 
@_subject: Defaults 
I think it's best to minimize the number of times we change the
defaults.  If we change them too often it causes users to wonder if
there's some weakness in OpenPGP -- after all, why else would we need to
constantly play catch-up?  (Note that I don't agree with this; I just
understand it.)
So if we're looking at a situation where we think that within the next
five years we'll want to make ECC the default, I think it would be best
to get that option out in front of users now.  Default to RSA-3072,
sure, but let's get users accustomed to seeing ECC as an option so that
when we migrate fully to ECC-by-default nobody gets surprised.
I freely admit this is a human-factors argument and not a technical
argument, though.  :)

@_date: 2015-03-17 18:58:23
@_author: Robert J. Hansen 
@_subject: Defaults 
You're absolutely right, I should have.  :)  I took my eye off the ball
and didn't notice we were changing defaults, otherwise I would've argued
then for RSA-3072.
Point, point.  The ECC ecosystem isn't mature enough to encourage users
to migrate to it.
Okay, so drop the ECC recommendations from my suggestions.
RSA-3072/SHA-256 + one of the modern 128-bit block ciphers, plus strong
recommendations against CAST5, IDEA, or using 64-bit block ciphers to do
bulk encryption.  So far that all seems pretty uncontroversial.  :)

@_date: 2015-03-17 19:09:44
@_author: Robert J. Hansen 
@_subject: Defaults 
Point: this is probably not indicative of Canadian distrust in AES-128,
CAST5, or 3DES, so much as it is the Canadians codifying an existing
best practice.
However, using the same symmetric key for long periods isn't at all
uncommon.  I last changed the passphrase on my key a little over a year
ago, for instance, so I'm empirical evidence of at least one person
who's been using a symmetric key for over a year.  :)

@_date: 2015-03-17 20:34:42
@_author: Robert J. Hansen 
@_subject: Defaults 
Yes.  My list was comprehensive ("what the new set should be"), not
differential ("what needs changing").  :)
Your key pref isn't what matters: it's your default-cipher-prefs.  :)
CAST5 may not be the default choice anymore, but it can still be
selected (I believe) if the recipient's key prefs list it.  I think this
shouldn't be supported; CAST5 should only be used if (a) it's in the
recipient's key prefs and (b) it's explicitly listed in
The former, although I think setting cert-digest-algo SHA256 by default
may be worth discussing.

@_date: 2015-03-26 00:22:38
@_author: Robert J. Hansen 
@_subject: upgrading v1 to v2 
Open up a terminal window.
"sudo apt-get install gnupg2"
Bang, done.  Ubuntu isn't lying to you -- you have the most recent
version of GnuPG *1*.  GnuPG version *2* is a separate package.

@_date: 2015-03-26 00:26:48
@_author: Robert J. Hansen 
@_subject: upgrading v1 to v2 
Ubuntu does provide them, and has for several years.

@_date: 2015-05-02 01:54:48
@_author: Robert J. Hansen 
@_subject: excessive usage of /dev/random? 
And unreasonable, too.  I specifically said that I couldn't use it to
argue one side or another, but rather it illuminated the uncertainty of
both sides.  A capsule summary is below.
I concur with Peter's assessment that it's numerology.  :)
A 2048-bit number as used in RSA has ~2028 shannons of uncertainty (due
to not every number being prime).  To sort through 2028 shannons of
uncertainty using the general number field sieve requires approximately
2^112 work.  (*Approximately*.)  So I see an enormous disconnect between
the uncertainty of the prime and the work factor that goes into breaking
the key.
We talk about how a key has so many shannons of entropy, but the reality
is different: it has so much equivalent work factor.  If we reduce the
uncertainty of the prime to a "mere" 112 shannons, will that affect the
work factor for the GNFS?
I don't know, and I don't trust my sense of large number theory enough
to even have a good guess.

@_date: 2015-05-15 15:26:20
@_author: Robert J. Hansen 
@_subject: Removing hkp from server 
Once uploaded to a keyserver, a certificate can't be removed.  Once it's
there, it's there for good.

@_date: 2015-05-20 20:13:32
@_author: Robert J. Hansen 
@_subject: Popescu and keys 
In the last couple of days a few different people have pointed me to
Mircea Popescu's blog, where he's claimed he's broken ~150 keys that are
in common circulation among the keyservers.  Unfortunately, his blog
post is rather difficult to read: it's full of rude political asides
that have no bearing on anything cryptological.  I regret that, because
it obscures what I think is a fascinating question: has he actually
managed to recover private keys given just the public key?
He claims to already have broken my key.  If so, proving it is
straightforward: sign a 256-bit value with my private key and upload it
somewhere the world can see it.
I'm going to be fascinated by the results, one way or another.  If he
can successfully do this it's going to lead to a lot of very interesting
For those people who are concerned about this, relax and remember to
breathe.  :)
The 256-bit value, in base64 encoding:

@_date: 2015-05-21 12:45:33
@_author: Robert J. Hansen 
@_subject: [Enigmail] Popescu and keys 
He didn't say.  You're correct in that I made an unfounded assumption;
thank you for the correction.  :)
I'm not worried about this, and I hope no one else on these lists is,

@_date: 2015-05-21 15:55:41
@_author: Robert J. Hansen 
@_subject: OPENPGP URI PROPOSAL 
The format of a URI is, generally, "mechanism:address for that
mechanism".  For instance, email has a URI scheme:
FTP has one, too:
HTTP has them:
Filesystems have them:
There's an ISO standard for serial numbers:
Heck, there's even a URI scheme for Gopher.
You'll notice that for each of them, the first element in the URI is the
protocol by which a network resource should be obtained.  Web resources
start with "http:" to let people know to use HTTP to obtain them.  Mail
links start with "mailto:" to let people know they need an email client
to obtain the resource (or, in that case, deliver to that resource).  Etc.
It seems to me that you're confused as to what a URI is.  Your proposal
actually *delivers content*, as opposed to telling people where they can
find/deliver content and what protocol they should use to access it.
There may be some good ideas in this proposal, but there seems to be
such a misunderstanding of URIs and how they work that I'm not inclined
to delve too deeply.

@_date: 2015-05-21 20:18:47
@_author: Robert J. Hansen 
@_subject: OPENPGP URI PROPOSAL 
Something that's mostly limited to web browsers and a couple of email
clients.  It's meant for including data in-line in web pages, not as
separate documents, and has pretty close to nil adoption in the rest of
the ecosystem.
Adopting a special OpenPGP data URI scheme just for web browsers seems
pretty weird to me.  Especially given how difficult it would be to get
the browser community to adopt it -- as a general rule, no standard can
take off unless Internet Explorer supports it.  (XHTML 1.0 and 1.1, may
you rest in peace.)
If you can get Microsoft to support this, or someone to produce an IE
plugin to handle it, then maybe.  But otherwise, I think a web-specific
data URI for OpenPGP data is DOA.

@_date: 2015-05-23 20:03:22
@_author: Robert J. Hansen 
@_subject: Prime distribution 
A couple of days ago dkg posted a back of the envelope calculation about
the number of 2048-bit primes out there.  (Anybody who thinks that's
perjorative is crazy.  His answer was both quick and pretty accurate.  I
think he'd agree it was a good BOTEC.)
Anyway.  The use of pure integer arithmetic gave my inner mathematician
the heebie-jeebies, and I had some time while waiting on the car repair
shop to give me some news about my rear differential, so... I figured to
do it the right way, with logarithms.  :)  I used the same prime
distribution formula dkg did (Euler's n/ln n estimate).
Note: due to vagaries of floating-point behavior, this table is not
perfectly accurate.  And Euler's estimate is just an estimate, anyway.
              +-------+------------------+------------------+
 Bits  |    In base-10    |    # of primes   |
              +-------+------------------+------------------+
 512   | 1.341 * 10**154  | 3.778 * 10**151  |
 768   | 1.553 * 10**231  | 2.916 * 10**228  |
 1024  | 1.798 * 10**308  | 2.533 * 10**305  |
 1280  | 2.082 * 10**385  | 2.346 * 10**382  |
 1536  | 2.41  * 10**462  | 2.264 * 10**459  |
 1792  | 2.791 * 10**539  | 2.247 * 10**536  |
 2048  | 3.232 * 10**616  | 2.277 * 10**613  |
 2304  | 3.742 * 10**693  | 2.343 * 10**690  |
 2560  | 4.333 * 10**770  | 2.442 * 10**767  |
 2816  | 5.017 * 10**847  | 2.57  * 10**844  |
 3072  | 5.81  * 10**924  | 2.728 * 10**921  |
 3328  | 6.727 * 10**1001 | 2.916 * 10**998  |
 3584  | 7.789 * 10**1078 | 3.136 * 10**1075 |
 3840  | 9.02  * 10**1155 | 3.389 * 10**1152 |
 4096  | 1.044 * 10**1233 | 3.679 * 10**1229 |
              +-------+------------------+------------------+
This will hopefully shed some light on what I've always found to be a
fascinating question, which is the unreasonable efficiency of the
general number field sieve.
NIST estimates that a 1024-bit key is about as hard to break as an
80-bit symmetric key, and a 2048-bit key is about as hard to break as a
112-bit key.  So going from 1024-bit to 2048-bit makes it about a
billion times harder to break by brute force.
But when we go from 1024-bit keys to 2048-bit keys, we go from 10**305
possible primes[*] to 10**613 possible primes[**].  There are literally
  000,000,000,000,000,000,000,000,000,000,
  000,000,000,000,000,000,000,000,000,000,
  000,000,000,000,000,000,000,000,000,000,
  000,000,000,000,000,000,000,000,000,000,
  000,000,000,000,000,000,000,000,000,000,
  000,000,000,000,000,000,000,000,000,000,
  000,000,000,000,000,000,000,000,000,000,
  000,000,000,000,000,000,000,000,000,000,
  000,000,000,000,000,000,000,000,000,000,
  000,000 more potential primes.  Something like that.  I might be off
by a couple orders of magnitude.  The point is, it's *huge*.
And yet despite that, it's only a billion times harder to break.
You could easily do a Ph.D. in large number theory just looking into why
the GNFS is as curiously effective as it is.  I don't have the math to
give this problem a serious look.  I'm happy just having enough math to
be able to appreciate the magnitude of the problem.  :)
If you want to see the Python code that generated this table, just ask.
[*] Kinda-sorta.  Technically we should subtract out the number of all
1023-bit primes, but honestly, that's almost a rounding error.  Think
about it in base-10.  If I ask you how many 3-digit numbers there are,
you might say 1000.  "No," I'd say, "you have to exclude 2-digit and
1-digit numbers.  There are 100 of those.  There are only 900 3-digit
numbers."  And then you'd slap me upside the head and tell me to stop
being a pedant.  100 is insignificant compared to 1000.  Likewise, the
number of 1023-bit primes can pretty much be ignored when looking for
the number of 1024-bit primes.
[**] Kinda-sorta.  Kind of odd that when we doubled the number we *more
than* doubled the number of primes.  Aren't they supposed to get spread
out more as the numbers get bigger?  This would seem to suggest they got
clustered closer.  This is one of the reasons why I think I got bit by
floating-point error.  Or maybe there's a bug in my code.  Dunno.  Take
your pick.

@_date: 2015-05-27 10:29:01
@_author: Robert J. Hansen 
@_subject: Random Seed for Generating PGP Keys 
This is not true.  A flipped coin has a very slight bias for the side
that was up when it was flipped.  Dice have subtle irregularities that
predispose them towards certain numbers and away from others.  Not even
quantum effects are truly random -- although the underlying effect may
be, the measuring apparatus by which we monitor the event will always
introduce hidden bias.  People have even managed to show bias in Geiger
counters (!!).
Software has problems, yes.  So too do manual processes.  And generally
speaking, competently-designed hardware or software solutions beat the
living daylights out of manual processes.  You can demonstrate the bias
of a flipped coin with nothing more than a couple of very boring days
spent flipping coins and some pen-and-paper work; demonstrating bias in,
say, an ANSIX9.17 RNG takes quite a lot more.
Not really, no.
Sure.  Most CSPRNGs permit you to specify the initial seed.
Not unless you hack the source.
Can't be answered.  Whenever talking about cryptographically secure
PRNGs, you have to specify the operating assumptions.  Even something
with a proof of security attached (like Blum Blum Shub) you have to
specify the assumptions involved.  For instance, with Blum Blum Shub the
assumption is "the Integer Factorization Problem is intractable."

@_date: 2015-05-27 10:30:38
@_author: Robert J. Hansen 
@_subject: Random Seed for Generating PGP Keys 
It's an unfortunate ambiguity, yes.
"Cryptographically secure" is a misnomer at best: it tends to lead
people into thinking it means the RNG cannot be broken, when in reality
it just means we don't know how to do it yet.

@_date: 2015-11-17 10:45:07
@_author: Robert J. Hansen 
@_subject: best practices for creating keys 
Not really, no.
One of the weirdest things about OpenPGP (and, by extension, GnuPG) is
that it provides a great deal of mechanism and very little in the way of
policy.  As a result, it's incredibly difficult to speak about best
practices in specific terms.  What's good practice for one person isn't
so for another.
The phrase 'perfect' in that link is a warning.  There is no such thing
as a perfect keypair.  Everything will always involve tradeoffs.  Those
who claim otherwise are usually charlatans.
It's worth noting, BTW, that the official guidance of the GnuPG project
is, "unless you know what you're doing and why you're doing it, stick
with the defaults."
8.1: Q.  Does GnuPG need to be 'tuned' before use?
     A.  No.  GnuPG has sensible defaults right out of the box.  You
         don't need to tune GnuPG before you can use it.
Don't.  Stick with the defaults.  You'll be happier, the learning curve
(which is already steep!) will be easier, and you'll enjoy wildly more
safe communications with people.  Once you've used GnuPG for a while,
have become familiar with how it does things and why, learned what
tradeoffs go into different decisions, and so on... at that point you
can generate a new keypair that's made just perfectly, exactly, the way
you like it.  :)
It depends.  For some people in particularly high-security applications,
yes, it's necessary.  For instance, the website kernel.org was
compromised a few years ago.  The prospect of an attacker being able to
insert a backdoor into the Linux kernel was so dramatic that a lot of
the kernel developers decided taking extreme steps was appropriate.
Can't fault them for it a bit.
On the other hand, if you're trading fantasy football picks with your
friends, those extreme steps would just be overkill.
Keyloggers are a possibility.  So are $10,000-a-night hookers.  It all
depends on your enemy and how much in the way of resources they're
willing to throw at the task of acquiring your passphrase.
Everyone always thinks I'm joking about $10,000-a-night hookers,
incidentally.  I'm not.  If someone were to give me a $100,000 budget to
acquire a secret worth $1,000,000, hiring a high-class call girl for two
weeks would be a *damned* tempting attack vector.  People spend so much
time obsessing over technical minutiae of crypto, and so little time
realizing the weakest part of the system is always the human being... so
why not hire an expert in manipulating human beings?
This said, brute force isn't something you need to worry about.  A
strong passphrase will resist brute force for, quite possibly, longer
than the earth will exist.
That's the idea.  That said, this is just one way to solve the problem
of how to recover from a key compromise event.  There are many others.
You can use it to decrypt the data.

@_date: 2015-11-17 11:00:20
@_author: Robert J. Hansen 
@_subject: backing up keys 
Honest questions get honest and accurate answers.  Can't beat that for
customer service, can you?  :)
Not really, although a fair number of people have written scripts and
tools to help automate the process.  If you were to ask (and tell people
what operating system you're running), you might get some responses.
You don't technically need to back up your public key, but it's a good
idea to back up your public keyring.  As you communicate more you'll
discover some of your correspondents don't have publicly-available keys
and they want to keep it that way.  If you lose their public key you'll
have to go back to acquiring their public key however you first got it,
which may be anywhere between an annoyance to an impossibility.
It depends.  If the bad guys get your encrypted private key they only
need one additional piece of data -- your passphrase -- to
catastrophically wreck your security posture.  If you're completely
confident the bad guys will never get your passphrase, then sure, post
your private key in the _New York Times_.
But maybe you shouldn't be completely confident.  Never underestimate
how foolish you can be when you've had a few glasses of wine and are
chatting up a pretty member-of-the-appropriate-sex.  :)
paperkey saves you a lot of paper by stripping out everything from the
key except what's absolutely necessary.  This also has the effect of
making the backup more reliable.  If you were to print out a full dump
of my entire private key, for instance, it would be hundreds of pages
long -- there are a couple of JPEG images attached to it.  An error on
page  could have catastrophic consequences for restoring from backup.
With paperkey, it gets reduced down to one single page of 8x11 paper.
It's easier to store, easier to handle, and easier to restore from backup.

@_date: 2015-11-23 10:52:02
@_author: Robert J. Hansen 
@_subject: best practices for creating keys 
For the same reason it doesn't default to RSA-4096: because the authors
are unconvinced there's a need.  Longer is not the same as better.  At
some point there's such a thing as enough.
SHA-256 is (a) safe enough for essentially all purposes, (b) more
interoperable with other OpenPGP implementations, and (c) better for
human readability.
I'm going to repeat my earlier advice: learn to walk before you run.
The defaults are safe.  Use them.  We can have this conversation at
great length, but I don't want to encourage you to start doing this.
Quite the opposite.  Please don't.
The last word in your sentence is the answer.
It's not safer.  You're talking about making a bank vault door "safer"
by adding a single millimeter of armor plate.  Your attention is better
spent elsewhere, especially right now when you're just starting out.
Focusing on the technical components of the system is ... I hate to say
"you're doing it wrong," but IMO, you are.  The stuff you're paying
attention to right now is pretty much irrelevant and unimportant.  The
stuff you're ignoring is relevant and important.  Start focusing on
that.  I'd start with:
* Do you have a revocation certificate generated?
* Is it stored safely?
* Who has access to your revocation certificate and/or private key?
* How would you know if someone else had access?
* How strong is your passphrase?
* How do you know how strong it is?
* What will you do if you forget your passphrase -- what's your
  fallback?
* If you revoke your certificate, how will you rebuild your personal
  web of trust?
* Is GnuPG integrated into your email workflow?  If not, how can it
  be integrated?
* Have you considered storing your certificate on a smartcard?
These are the places where GnuPG fails in the real world.  In 20+ years
of using PGP 2.6+ and GnuPG 1.0+, I've never -- not once, not ever --
encountered anyone who has said, "man, I really wish I'd stripped my
certificate, that would've saved me no end of grief," and a lot of
people who have said, "man, I really wish I'd safely stored a revocation
certificate, that would've saved me no end of grief."

@_date: 2015-11-23 12:05:22
@_author: Robert J. Hansen 
@_subject: best practices for creating keys 
Absolutely.  Please don't misinterpret what I said as trying to dissuade
you from curiosity.  I'm just urging you to not let your curiosity lead
you into making poor decisions from the get-go.
The following anecdote is meandering, but if you'll bear with me for two
paragraphs it'll make sense:
I live in the United States, in a state which allows private citizens,
under incredibly close regulation, to own military firearms.  When I
visit the rifle range, sometimes I'll spend some time with a suppressed
German-made MP5SD3 submachinegun.  (It's not mine: a friend owns one and
we sometimes hit the range together.)  It's a nice piece of kit; I like
it.  And quite often, other people who are at the range want to talk
shop about it.  We get into discussions about roller-locked firearms
like the Cz52 and MG42 versus roller-delayed firearms like the MP5, how
annoying it is when people get the terminology wrong, whether it's a
good thing or a bad thing the MP5 uses a fluted chamber, how anyone who
thinks it's okay to fire subsonic 9mm from the MP5 needs their head
examined, and so on and so on.  And it's fun, as far as it goes, and
it's often educational for the people who've never seen an MP5 before
and are fascinated to learn more about its inner workings.
It's great -- up until they think they know enough to use an MP5 on the
range, despite the fact they've never fired a weapon before.  At that
point we have to explain to them that look, yes, they know a lot more
about the MP5 than most people do, but really, they need to start off
with something small, like a nice .22 Ruger Mk II, develop the basic
skills, learn trigger discipline and proper usage of safeties, learn how
the range operates and what the various calls by the Range Safety
Officers mean, etcetera.  There's a huge amount to learn: they don't
need to make things worse by leaping straight over this stuff straight
to firing fully-automatic military hardware.  That's just imprudent, and
we'd be awful human beings if we permitted them to do that.
That's what we're talking about here.  The knobs and dials on GnuPG are
great fun to learn about: you're in good company!  But there's a big
reason why we're urging you to not do what you want to do, and that's
because you're not yet competent to do what you want to do.  We'd rather
see you start off with small steps, and from there move on to the big
ones, than have you start off big.
Admittedly, it's highly unlikely that screwing up with GnuPG will lead
to a magazine of 9mm being sprayed around the room.  But it's the
principle of the thing.  :)
So: for now, please stick with the defaults.
Not really.  It's probably not worth worrying about.
One of the important skills to learn early on is about how to migrate a
certificate.  You're going to make mistakes.  You'll forget passphrases,
you'll compromise your keys, you'll realize you made a hash of it and
need to start over again.  How do you recover from this?  How do you
communicate a change-of-certificate with your correspondents?  Etc.
The only reason to think "it's a bit too late" is if
There are almost certainly people and groups for whom (a) applies.  If
you're one of them, please let me know.  But if (b) applies, then I
suggest learning the skill, because it's important.  :)
That wiki page is guidance *for Debian*.  Debian has some very specific
operating restrictions which are unlikely to apply to you.  The
guidelines Debian put together apply to them, in their environment,
facing their threat model, which they defend with their particular set
of resources.
It is not guidance for you, unless you're part of Debian.
By all means, study it!  It's a well-written policy.  Learn what goes
into their policy and why they make the decisions they do.  But don't
think that what they recommend will automatically apply to you.  Some of
it will be applicable; a lot of it won't be.
Yes.  And, as several people here have told you, you correctly create it
by running "gpg --gen-key" and accepting the defaults.

@_date: 2015-10-01 13:05:28
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
Yes.  No.  Somewhere in between.
Some years ago a user on PGP-Basics was irate over how I refused to sign
my messages.  My argument was basically the one you were using: that
nobody on the list had verified my identity and that made my signatures
of marginal use.  This fellow insisted, and insisted rudely, so John
Clizbe, John W. Moore, and I all conspired together to make a point: we
created a keypair, shared it amongst us, and all three of us used the
exact same certificate to sign our emails.
It took a few months for anyone to notice.
So sure, yes, without identity verification it's hard to have confidence
in someone's legal identity, absolutely.  But even with identity
verification, most people don't even bother to check to see that the
signing certificate's email address matches the one on the email.
Identity verification is a useful step: it's not a sufficient one by itself.
Pointless in the sense of *legal* identity.  But there are many
identities other than the legal.
One of my favorite books, _Shibumi_, was written by an author named
Trevanian.  Trevanian was infamously private and withdrawn: there are
only a few interviews with him and they were all conducted via letter or
email.  Trevanian wrote books, had some amazing ideas and insights, and
was even responsible for a great Clint Eastwood movie (_The Eiger
Sanction_).  Trevanian was a real identity, as real as you could hope for.
And then there was Rodney William Whitaker, a professor at a small
American university who never amounted to very much.  Except that,
unbeknownst to the world at large, he was Trevanian.
So let's imagine, for sake of argument, that Trevanian had an OpenPGP
certificate which he used to sign all of his books, plays, and
screenplays, so that people could be confident they were reading an
authentic Trevanian work.  If I just read _The Eiger Sanction_, okay,
fine, that signature has little merit for me.  But then would come
_Shibumi_ and _The Summer of Katya_ and by the time _The Crazyladies of
Pearl Street_ came out I could be confident that if I saw Trevanian's
signature on an ebook, that ebook would be worth my hard-earned money.
Trevanian is an identity every bit as real as Rodney William Whitaker.
Trevanian can amass reputation, engage in interviews and communication,
opine on things, have fans and foes, the whole nine yards.  The only
thing Trevanian can't do is get a driver's license, because Trevanian
isn't a *legal* identity.
No.  Absolutely not.  This is flat wrong.
You don't get to control what somebody else's signing policy is.  They
get to decide that on their own.  Neither you nor I nor anyone else gets
a vote in it.  We don't get to say what they should or should not do.
I have determined what *my own* signing policy is, and yes, it depends
on face to face meetings and identity documents.  That's because it
makes sense for my needs to do this.  But other people will have
different needs, and I've got no business telling them what their
signing policy should be.  Neither do you.

@_date: 2015-10-01 15:57:36
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
(This came just to me, not to the mailing list.  I'm assuming Bob
intended to reply-all and just hit the wrong button.  If I'm in error,
Bob, please forgive me.)
This depends on what a certification means.
You have a belief that a certification must, _a priori_, be connected to
a legal identity.  This isn't necessarily true.  Imagine there are
thousands, millions, of self-styled prophets who announce tomorrow's
lottery numbers.  They sign each pronouncement.  One particular lottery
prophet has always been right.  Someone then asks you, "So this lottery
prophet, 0xBADD00D5F00DBAD, is he for-real?"
And you could say, "All I know is, the person who uses that certificate
has always been right so far."
And that would be a certification, and that would be a perfectly
appropriate usage of certification.  If other people want to project
onto your certification that the prophet's name is Maurice Micklewhite,
or whatever -- that's their projection and their folly, not yours.  Your
certification was accurate and appropriate.
Neither does "Bob Henson".  The collection of bits that represent the
glyphs that make up "Bob Henson" has no more connection to you than the
word "gift" does to a ... well, to something.  In German it's poison, in
English it's a present.  Neither one is right or wrong.  What matters is
whether we can use a pseudonym to identify a figure, not whether that
actually happens to be the person's given name.
Look at how many people have read the teachings of Jesus Christ.  Are
his teachings any different just because his name was actually Isho?
Err -- well -- maybe it was Isho.  Probably.  But it was also probably
Yeshua ben Yosef.  Christ grew up speaking Aramaic in conversation and
Hebrew in the temple.  He had two names: in Aramaic he was Isho, in
Hebrew he was Yeshua, and after his death accidents of transliteration
into Greek turned Yeshua into Iesous, which then turned into Latin as
Iesus, and then when Latin invented the J- letter he became Jesus.  Look
at how many names that guy's had over the years, and during his life *no
two groups could agree on his legal name*.
Look at William Shakespeare.  We've got six of his signatures, and they
all have different spellings of his name:
... and these were all recognized as his legal name.  (All six
signatures are on legal documents.)
Names are tremendously fluid instruments.  Charles Martel, the hero of
France, didn't actually have a last name.  "Martel" is an appellation he
picked up on the battlefield: it means "hammer".  Chuck the Hammer was
so named because of how he beat the Moors at the Battle of Poitiers in
732.  Within a few years, the "pseudonym" of Martel became his very real
last name just by dint of how many Frenchmen would look at you funny if
you suggested his name was something *other* than Martel.
If you think pseudonyms don't exist, well--there are two possibilities I
can see.  If you're saying that "all names are really pseudonymous to
one degree or another, so it doesn't make sense to call some names true
names and some other ones fake", then I agree with you.  If you're
saying that "only true names exist and I insist on calling Jesus 'Isho',
Charles Martel 'Charles', William Shakespeare 'Wm Shakspe', and so on,"
then I think you're quite wrong.  :)
I dunno.  If any observant Jews want to argue with me that the
Tetragrammaton is the original true name and that everything else is
pseudonymous, I think that would be a fascinating theological argument
we should have off-list.  :)
There have been a large number of well-meaning, well-intentioned people
who have wanted there to be one--but there isn't one and never has been.
Nobody has.  They've laid down *guidelines*.  "We think this is a pretty
good procedure to follow, and here's why.  Ultimately, though, it's up
to you."
Last year I was sitting in the audience at a keysigning event emceed by
Samir Nassar.  Samir was absolutely fastidious about how he did things,
but at the same time, he wasn't walking through the aisles of chairs
making sure that everybody was double-checking two forms of government
ID.  How could he?  Crazy to even suggest it.  He did what he could,
accepted there was a lot he couldn't do, and did his best to keep people
informed of the process and why it was the way it was.  Couldn't ask for
better than that.
It isn't that you're obliged.  It's that *you can't stop them*.
If you want to be King Canute, well--the ocean's that way.  Enjoy the
tides.  As for me, I have learned the wisdom in accepting that some
people will just be foolish and there's nothing I can do to stop them.
The best I can do is to keep my wits about me and learn who acts
foolishly and who acts wisely.  :)

@_date: 2015-10-01 16:01:19
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
Probably not "all", but a lot, yes.
The problem comes from you can't force a user to pay attention to a
warning.  Some years ago a friend of mine, Peter Likarish, invented a
browser plugin that would detect phishing sites.  When you hit a
suspected phishing site it would display a big red banner across the top
of the screen.  In controlled usability trials (he was a university
researcher), not a single person noticed the big red banner across the
top of the screen.  In exit interviews those who did notice it said they
assumed it was a banner ad and they just ignored it.
Users have become so accustomed to advertisements trying to attract
their attention that it's actually become difficult for apps to warn
people of real dangers.  This is a real concern in the usability field.
 It's a hard problem.

@_date: 2015-10-01 16:17:06
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
Oh, man -- I completely forgot the great one from modernity.  You can be
elected President under a pseudonym.  Not only that: *it's already
happened*.  President Ulysses Simpson Grant.
His real name was Hiram Ulysses Grant.  That's what's on his birth
certificate.  When he was seventeen he asked Congressman Thomas Hamer to
nominate him for West Point (the American Army's military college).
Hamer got the name wrong and wrote it down as "Ulysses Simpson Grant".
Grant refused to correct Hamer's error, though, as he thought that "U.S.
Grant" was a much better set of initials for a military officer than "HUG".
So if a pseudonym's good enough to get elected President of the United
States... is it a pseudonym at all?  Would you refuse to sign Ulysses S.
Grant's certificate on the grounds that "well, that isn't your *real* name"?

@_date: 2015-10-03 14:19:30
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
A digital signature means surprisingly little.  These are the conditions
that must be met for a signature to be meaningful: it must be correct,
issued from a validated[*] certificate, and belong to a trusted person.
If you've got all those, then yes, a digital signature can be very
meaningful.  If you don't, they mean very little.
Maybe I should add this to the FAQ, along with an explanation of why.
[*] Insert word-of-choice here.  Trusted, validated, whatever.

@_date: 2015-10-03 16:15:04
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
You have been told how to unsubscribe.  Perhaps try following those
To recap: visit this URL.
At the bottom you'll see text of, "To unsubscribe from Gnupg-users, get
a password reminder, or change your subscription options enter your
subscription email address:".  Enter your email address there and click
"Unsubscribe or edit options".

@_date: 2015-10-03 18:53:26
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
Probably not.  But if so, I'm fine with that: John and John are good
people.  And the point we were making -- which was that people invest
way too much trust into unvalidated keys and/or possibly untrustworthy
people -- was important and worth making.
If I commit a crime and it gets traced back to the certificate we
shared, then the authorities would have to figure out which of us was
using the certificate.
The idea that OpenPGP signatures are non-repudiable is a fashionable bit
of nonsense: I am aware of no court, anywhere in the world, which has
recognized OpenPGP signatures as being non-repudiable.

@_date: 2015-10-04 09:48:55
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
Yes, many!  Digital signatures are enforceable in U.S. courts.
Non-repudiability, though, as far as I know has never been successfully
argued.  More to the point, I don't think it could be.

@_date: 2015-10-04 19:43:48
@_author: Robert J. Hansen 
@_subject: OpenPGP Signatures (was Re: How to get your first key signed) 
Peter's right, and you're moving the goalposts.  Please stop.
To repeat my answer: yes.  Because it's a digital signature and courts
have repeatedly found them enforceable.  Courts have *not* found them
non-repudiable, though: you repudiate a digital signature in more or
less the exact same way you repudiate a real one.  You say "that wasn't
me, Your Honor" and you show the judge why he or she should believe it
wasn't you.
Werner and I (and maybe others) have seen PGP-signed spam.  Someone was
using Symantec's signing proxy, had it configured to sign all outgoing
mail, had no passphrase on the certificate, and then got hit by a botnet
that used their PC to send out Viagra spam.  Did it have a valid
signature?  Yes.  Was the signature repudiable?  Yes.  "Your Honor,
forensic analysis shows my PC was compromised by malware.  I didn't
authorize those spams to be sent out and I didn't authorize their
Non-repudiability is a big myth when it comes to OpenPGP.  In this era
where, per Vint Cerf, one in five desktop PCs is pwn3ed, repudiability
is cheap and easy.  "Malware, Your Honor..."

@_date: 2015-10-05 10:20:12
@_author: Robert J. Hansen 
@_subject: How can it be made even easier!? 
If you're serious about "no background," I'd suggest by enrolling them
in a good preschool.  Everyone else will have a background: they might
be lawyers, doctors, teachers, carpenters, or what-have-you.  You can
assume basic fluency in English and a certain amount of formal
education.  They might be at a sixth-grade level in math or they might
all have graduate degrees, but there will be *some* background.
Find out what the common background is.  Then try asking your question
again.  Because, honestly, believing that people have *no* background is
a gross disrespect to them.  Learn their capabilities, and structure
your materials appropriately.

@_date: 2015-10-06 10:07:07
@_author: Robert J. Hansen 
@_subject: First quantum gates in silicon 
Australian researchers have figured out how to make a quantum gate on a
silicon chip.  This is interesting work, because we've spent a *lot* of
money learning how to etch silicon.  Being able to build quantum gates
on the same material that our current systems use is really important
from an engineering perspective.
So far they've only been able to build a two-qubit chip.  This means
there's absolutely nothing to panic over.  Still, it's fascinating news.
 We live in interesting times.  :)

@_date: 2015-10-19 20:13:24
@_author: Robert J. Hansen 
@_subject: Importing and using non-self-signed PGP keys 
Then they issued you a malformed certificate which cannot and must not
be used.  The self-sig is an essential part of every correctly-formed
OpenPGP certificate.  If you were issued a certificate lacking a
self-sig, then your issuer has a problem that needs to be corrected.
I wish I had better news for you, but a missing self-sig is pretty much
a big red stop sign.

@_date: 2015-10-23 09:27:43
@_author: Robert J. Hansen 
@_subject: First quantum gates in silicon 
Interesting.  It's worth remembering, though, that users who have a
50-year writ-in-stone absolute need for security are, by their very
nature, going to be paranoid gits.  :)
Imagine that you lived in 1965 and were responsible for composing
communications security standards that had to keep secrets safe until
2015.  How paranoid would you be?  It's easy to not be paranoid enough
(in the '80s, Ron Rivest doubted a 512-bit composite would ever be
factored; today, RSA-512 is a sad joke) and easy to be too paranoid ("we
must consider the possibility space aliens will appear with technology
beyond mortal ken").  Hitting the sweet spot is pretty hard.
If I was writing a 50-year standard today, I'd probably be concerned
about modest-sized quantum computers.  ECC is vulnerable to these; RSA,
DSA and Elgamal really aren't.  To efficiently solve discrete logs with
Shor's algorithm requires twice as many qubits as there are bits in the
number.  A 256-bit ECC key, providing ~128 shannons of uncertainty,
could be efficiently broken by a 512-qubit computer.  An RSA-3072 key,
providing ~128 shannons of uncertainty, would require a 6144-qubit
This is all off the top of my head: it's been a long time since I've
looked at Shor's.  I may be off on my numbers.

@_date: 2015-10-24 04:52:46
@_author: Robert J. Hansen 
@_subject: absolutely nothing to panic over 
Never heard of McEliece, have you?  Quantum-resistant public key crypto.
 It's pretty cool stuff.
I know it's popular to say the sky is falling, but it isn't, and this
kind of scaremongering doesn't help anyone.

@_date: 2015-10-26 23:55:12
@_author: Robert J. Hansen 
@_subject: absolutely nothing to panic over 
At first blush this seems nice and formal, but it's pretty much incoherent.
"There is no secure communication over an insecure channel" is a
tautology.  An insecure channel is one which *by definition* cannot
support secure communication.  This statement is trivially true.
It gets worse if we go on.
"There is no secure communication over an insecure channel without
out-of-channel bootstrap."  Now you've gone from tautology to paradox:
you've defined the channel as insecure, except that with some magic
pixie fairy dust you can communicate securely over it ... but that would
mean the channel was secure, when you defined it as insecure.  Paradox.
You start from tautology and conclude at paradox.  This doesn't appear
to be something to be taken seriously.

@_date: 2015-09-01 09:15:09
@_author: Robert J. Hansen 
@_subject: GNUPG symmetric encryption compatibility question 
Most likely.  The spec is well-known and unlikely to change in ways that
break backwards compatibility.  Over the next, say, ten years I'd expect
you to have no trouble at all.

@_date: 2015-09-03 18:46:00
@_author: Robert J. Hansen 
@_subject: FAQ: drop mention of 1.4? 
Here's the question I really want people to answer: "At what point do we
tell people, 'no, that data format has been obsolete for twenty years,
we're not going to support it any more, it's not even close to
conforming to the RFCs we implement'?"
If you say "for as long as people have that traffic," then you've just
given GnuPG an open-ended commitment to supporting PGP 2.6 *forever*.
There are still people using Apple IIes and Appleworks to manage their
business spreadsheets.
I don't think we should support PGP 2.6 forever.  I don't think most
people on this list do, either.  So to me, the interesting question is
where we draw the line.  Where do we say, "no more, we're not supporting
PGP 2.6 any further"?
For me, the answer is -- "Today.  We've supported it for sixteen years.
 That's long enough."

@_date: 2015-09-06 13:39:17
@_author: Robert J. Hansen 
@_subject: GnuPG modern can't genereate keys on my Windows 
Potentially.  It allows the compiler to use x64 features such as W^X,
which relies on there being an NX bit in the page table entry.  This
wasn't part of the x86 design, but was added by AMD for the x64.  Then
Intel backported it to the Prescott architecture for the Pentium-4.  But
unless you can guarantee you'll never run on pre-Prescott chips, you
can't rely on W^X.
True, W^X is an OS-level feature and not a GnuPG feature.  But it should
work as an example of how the two instruction sets could be different in
ways important for computer security.

@_date: 2015-09-06 14:25:49
@_author: Robert J. Hansen 
@_subject: Krebs on Security: SCI 
Brian Krebs has a great case study of a shady snake-oil seller.  Worth
Also, the Robert Hansen mentioned in it is not me.  :)

@_date: 2015-09-08 17:29:48
@_author: Robert J. Hansen 
@_subject: gnupg-for-java 
A while ago, the fellows at the Guardian Project released Java bindings
for GnuPG.  A project's come along where I could make use of them, and
thought I'd give them a spin.  I was quite surprised to discover that,
as of this writing, they don't even build.
The offender seems to be jUnit.  The gnupg-for-java code uses a lot of
imports like "junit.framework", and the current jUnit drops everything
in the org.junit namespace.  On top of that, old test methods like
TestSuite from jUnit 3.8 have been deprecated in favor of Suite, from
more modern jUnits.
This doesn't appear to be hard work.  The test suite is about 250 lines
of code, most of it fairly clear.  If you know Java and would like to
contribute to GnuPG but don't quite know where, this would seem to be an
excellent "bite-sized" project to take on.
(If anyone's wondering why I'm not doing it: following my long-standing
rule, I don't contribute code patches for either GnuPG or Enigmail.
Although I'm not an employee of the U.S. government, I have a lot of
friends and family who are.  If I contributed code, some people would
make a ruckus about how GnuPG was now 'tainted'.  To prevent this, and
to maintain the community's trust in GnuPG, I don't touch the code.)

@_date: 2015-09-09 10:10:47
@_author: Robert J. Hansen 
@_subject: gnupg-for-java 
Excellent!  Now send that off to hans at guardianproject.info (I *think*
that's his address) as a diff, and you'll be well on your way to
completing a contribution to a FOSS project.  :)
Other stuff that needs to be done: verify it works on Java 1.8, clean up
the OS X build (which is really hackish), and consider distributing
pre-built jarfiles containing the binaries and the source code, so that
people don't have to rebuild from scratch on each platform they want to
work on.
I'm certainly not saying you need to do these things, Antony.  I'm just
saying that if other people are looking for bite-sized chunks, there are
several of them waiting to be bitten.  :)

@_date: 2015-09-10 18:05:35
@_author: Robert J. Hansen 
@_subject: plaintext non-ssl distribution - who things this is a good idea? 
There are many better ways for Werner to spend his time and money.
(Getting an Authenticode certificate, for instance.)

@_date: 2015-09-11 10:19:15
@_author: Robert J. Hansen 
@_subject: Please remove MacGPG from gnupg.org due to serious security 
Given we've already had this conversation (about the inappropriateness
of binary blobs in what should be FOSS software) once, I feel the need
to say that the more times this happens the less trust people will have
in GnuPG and the GnuPG ecosystem.
It's *really* *important* that the major tools surrounding GnuPG be
FOSS, and can be built entirely without depending on closed-source blobs.

@_date: 2015-09-11 20:46:00
@_author: Robert J. Hansen 
@_subject: OpenPGP smartcard reader 
GNOME implements its own gpg-agent... badly... in ways that break
smartcards.  I've heard they've recently fixed it, but as of 14.04 the
broken GNOME behavior was still in place.  Search for GNOME and
gpg-agent in these archives and you should find a solution.

@_date: 2015-09-11 21:08:45
@_author: Robert J. Hansen 
@_subject: OpenPGP smartcard reader 
And there's a wiki page for it, too:
Also see Simon Josefsson's writeup:
This misbehavior has been reported to Debian and Ubuntu:
... Hope these links help!

@_date: 2015-09-19 06:15:03
@_author: Robert J. Hansen 
@_subject: gnupg-for-java 
To repeat: I work in digital forensics.  That means I come into contact
with law-enforcement and intelligence agencies on a semi-regular basis.
I'm not going to say which agencies, but I will say that I have friends
at most of them -- people I genuinely like, whom I'll have a beer with
after work.  I don't see anything shameful or dubious about this, and
I'm sure 95% of the GnuPG userbase shares in this.  But 5% do not, would
consider it to be a sign of governmental subversion of GnuPG, and they'd
make a whole lot of fuss and scream and rant a lot.
Look at the guy who keeps re-opening "bug"  on the tracker
(  This guy devotes that much
time, effort, and anger, just to how he thinks Werner is going to get
people killed for not distributing GnuPG over a TLS connection.  Imagine
if he were to find out I had a beer a while ago with an Air Force Office
of Special Investigations nerd.
Look at the guy who threatened me with axe-murder if it turned out I had
any FBI involvement.   -- given I
have friends in the FBI, oh yes, I took that one seriously, especially
after he dug up my (old, no longer current) address from WHOIS records.
That was the first death threat I've received.  There have been more
since -- I just don't publish them.
There's a significant fraction of people within this community who are
deeply unhinged.  Most of the GnuPG userbase is composed of solid,
reasonable people who are concerned about electronic privacy in the
Golden Age of Surveillance -- but some are really out there.
I don't want to deal with people who say, "you were a groomsman at an
NSA agent's wedding" (true) "and therefore you're a Fort Meade stooge"
(false) "and I'm going to scream about how the NSA has obviously
subverted GnuPG" (oh, man) "AND THEN I'M GOING TO MURDER YOU WITH AN AXE
AND YES I KNOW WHERE YOU LIVE" (why did I get out of bed this morning?).
This is why I don't touch code.
Please respect my decision.  It's the best decision for GnuPG, and it's
the best decision for me.

@_date: 2015-09-22 17:38:05
@_author: Robert J. Hansen 
@_subject: Keyserver lookup failure, redux 
Back in February I reported a bug that was preventing GnuPG 2.1.2 from
being able to look up certificates on the keyservers:
I just looked at it again.  2.1.8 still has the same bug.  Is there an
idea for how to fix this?

@_date: 2015-09-23 04:25:02
@_author: Robert J. Hansen 
@_subject: Keyserver lookup failure, redux 
quorra:~ rjh$ gpg -v --keyserver hkp://pool.sks-keyservers.net
--recv-key 0xD6B98E10
gpg: keyserver receive failed: No route to host
quorra:~ rjh$ gpg-connect-agent --dirmngr 'keyserver --hosttable' /bye
S # hosttable (idx, ipv6, ipv4, dead, name, time):
S #   0       pool.sks-keyservers.net
S #   .       pool.sks-keyservers.net
S #   .   --> 2 3 13 7 20 10 9 5 1 4 19 12 6 11 17 8 15 16 18* 14
S #   1   4   host-550b4a17.sileman.net.pl v4=85.11.74.23
S #   2   4   85.93.216.115
S #   3   4   91-143-92-136.blue.kundencontroller.de v4=91.143.92.136
S #   4   4   ip5f590cb8.dynamic.kabel-deutschland.de v4=95.89.12.184
S #   5   4   gozer.rediris.es v4=130.206.1.8
S #   6   4   obelix.hetzner.computer42.org v4=144.76.43.40
S #   7   4   app.aaiedu.hr v4=161.53.2.219
S #   8   4   sks.es.net v4=198.128.3.63
S #   9   4   euler.nerds.lu v4=62.210.74.32
S #  10   4   c-75-75-183-132.hsd1.pa.comcast.net v4=75.75.183.132
S #  11 6     openpgp.us v6=[2604:a880:800:10::60d:b001]
S #  12 6     keys.alderwick.co.uk v6=[2a01:4f8:131:149::f2]
S #  13 6     alita.karotte.org v6=[2a01:4f8:150:7142::2]
S #  14 6     [2a01:4f8:192:f5::3]
S #  15 6     srv2.globale-gruppe.de v6=[2a01:4f8:200:6329::2]
S #  16 6     vod.ohai.su v6=[2a01:4f8:211:1623:a::1]
S #  17 6     s3.pkern.at v6=[2a03:4000:5:b3::1]
S #  18 6     [2001:67c:2050:1000::3:4]
S #  19 6     itunix.eu v6=[2001:41d0:2:4f0b::1]
S #  20 6     blazrsoft.com v6=[2605:6400:10:544b::1]
S #  21   4   keys02.fedoraproject.org v4=140.211.169.202

@_date: 2015-09-23 10:20:09
@_author: Robert J. Hansen 
@_subject: Keyserver lookup failure, redux 
How odd.  All right -- time for me to assume there's some problem with
how OS X has borked IPv6 configuration.  (I don't even have IPv6
connectivity; why OS X insists on giving me IPv6 addresses, I don't know.)
Thanks to everyone who helped out.  :)

@_date: 2015-09-24 11:05:03
@_author: Robert J. Hansen 
@_subject: Facebook and OpenPGP 
A friend at Facebook just clued me in to a story at The Register:
I know nothing more about this than what's in the page.  Figured some
people here might find it interesting, though.  :)

@_date: 2015-09-28 10:00:17
@_author: Robert J. Hansen 
@_subject: Should I be using gpg or gpg2? 
Mostly true.  Close enough for government work.  :)
Most of the GnuPG 1.4 documentation is still relevant for GnuPG 2.0 and 2.1.

@_date: 2015-09-28 12:08:13
@_author: Robert J. Hansen 
@_subject: Own Mail: PGP running on local server; Is it secure 
This has a critical chicken-and-egg problem.  Let's say I want to send
you an encrypted email.  I send it to the OwnMail box, and it in turn
sends to you, in cleartext, an HTTPS link to the OwnMail box.  But Eve,
who's listening in on communications between us, who is the adversary I
want to foil ... well, she gets the HTTPS link, too, and she's able to
use it to view my message to you.  End result: Eve is not foiled.
Okay, so let's say the HTTPS link goes to a page protected by some kind
of authentication, some kind of login method.  How do I communicate to
you the credentials to login?  Eve gets to eavesdrop on those, too.  End
result: Eve is not foiled.
So let's say that you create a username/pw on someone else's OwnMail box
early on, before Eve starts listening in.  Now you can go fetch those
HTTPS-secured pages securely.  Eve is foiled.  *But*, you have to set up
the username/PW ahead-of-time, before Eve comes into play.  And now you
have to keep track of yet another username/PW.  End result: Eve is
foiled but it's a usability nightmare because you're stuck tracking 25
different OwnMail username/PWs for 25 different OwnMail users.
Further, they're not doing *anything* that we haven't already been able
to do for 20+ years.  Seriously.  Every mail administrator on the planet
has been able to do this sort of thing for 20+ years.  They don't.  We
rarely if ever see OwnMail-like setups.  It's worth asking the question,
My initial thoughts after reviewing the page: I'm not optimistic.  I
might be wrong!  But I'm definitely not optimistic.

@_date: 2015-09-28 13:00:46
@_author: Robert J. Hansen 
@_subject: Own Mail: PGP running on local server; Is it secure 
Looking over their FAQ, I found this entry which makes me doubt them
even further.  It downright deserves a fisking, which I'll deliver inline.
"Q: Why shouldn't I trust any cloud email service with JavaScript
encryption on the client-side ?
A: These services cannot be trusted, because they still give power to
companies to spy on you.
Why is it not secure?
1-Encryption is done in JavaScript, and therefore relies on your
browser's JavaScript engines, which 80% of the time are proprietary
software coming from Google, Microsoft, Apple, and most eminent NSA
"It leaves 4% chances that both you and your correspondent don't use any
of them, (because even if you don't use them, your correspondent might,
and he would compromise your security). Using these browsers for
cryptography, even once, leaves these companies full power to forever
break your cryptography."
"By extension any cryptography done on a proprietary operating system
like Mac or Windows can be considered as doomed, since Microsoft and
Apple can then access your keys."
"2-The JavaScript code may be changed at any time by the email service
provider. So except if you check the JavaScript code sent to you each
time before entering your password (which is impracticable), you leave
the email service provider open to breaking your cryptography at any
time they want, without you even necessarily knowing it (since you don't
check it)."
"3-These services don't and cannot have a strong private key encryption.
They rely on a much weaker private password that can be remembered by a
human being. Therefore, they either use a much weaker algorithm than
openPGP, or they use openPGP but store YOUR private key on THEIR
servers, in clear form or encrypted with a simple password. In the movie
citizenfour, Edward Snowden quoted saying "A 10 character password can
be broken by the NSA in few days". So in practice, using a simple
password for encryption make those services easily breakable. In
comparison GPG was initially designed to work with 2048 or 4096 bits
long private keys. GPG and SSL use this kind of strong private key
encryption, as simple passwords are too weak and can be easily broken."
"4-If you want to access your emails on computers that are not yours (at
the library, at work, at a printing store), you have to do cryptography
on their computer, and therefore you're never really sure that you don't
compromise your whole cryptographic system, you are effectively giving
the power to the computer's owner to break it."
"5- It is controversial whether JavaScript as a language, is actually
able to perform good quality encryption at all."
"This is not only theoritical. The company hushmail, providing an email
service with java/javascript client-side encryption, has allready spied
on its users. [3]. If they could do it and did it, how do you know other
companies won't?"
"To conclude, it should be said that a broken cryptography implies not
only that your future emails can be watched, but also that all your past
emails can also retroactively be read by spies."
"Also you should not forget how aggressive the attempts are to break
cryptography. There have been several attempts from the US government in
the past to add flaws in the Linux kernel, in order to break
cryptography [4]. So it is very dangerous to leave that many security
holes opened, which are easy ways for NSA and other organizations to
break in."

@_date: 2015-09-28 14:12:03
@_author: Robert J. Hansen 
@_subject: Own Mail: PGP running on local server; Is it secure 
First, I love the Thorn Letter Agency: I'm going to have to steal it.  I
don't know whether it should be used sincerely as an "insert agency
here", or snarkily as a "oh, right, *?ey* are out to get you".  Maybe
both.  :)
Second, I dunno, man.  I read that paragraph a few times just trying to
understand what they meant before I tore into them, and I came up with
realizing that not only didn't I know what they meant, but I doubted
they knew either.
The troubling line for me was, "Using these browsers for
cryptography, even once, leaves these companies full power to forever
break your cryptography."
So if I use Google Chrome, and it's not compromised, and I use it only
once, after that I switch to Firefox and use that for all my web
needs... and then, later on, Google decides to toggle the evil bit...
suddenly Google Chrome is going to jump in the TARDIS, travel back to
when it was trustworthy, and become evil then, and send my key material
forwards in time?
I mean, taken at their word, that's what they seem to be saying, right?
You could be right.  Absolutely you could be.  But their language is so
weird that I don't think I'm willing to give them the benefit of the doubt.

@_date: 2015-09-28 16:26:35
@_author: Robert J. Hansen 
@_subject: Should I be using gpg or gpg2? 
Per NIST, RSA-2048 is believed safe until 2030.  That means that if you
need to keep secrets longer than fifteen years, you need to move away
from RSA completely.  RSA-3072 is not all that much stronger than
RSA-2048, and RSA-4096 adds even less.
The future is clear: 512-bit ECC, which is about as resistant to
brute-forcing as AES256.
GnuPG 2.1 has it.  GnuPG 1.4 *will never get it*.  That means each day
that moves forward is one day closer to GnuPG 1.4's obsolescence.
Other major improvements: the codebase is cleaner.  There's more
separation of code.  Most crypto operations are now handled by
libgcrypt, which is a great move.  The more libgcrypt gets used by
outside people, the better a chance we have of spotting bugs before they
become problems.
There are a lot of important improvements in 2.0.  I'm not saying I'm a
fan of all the decisions the development team made, but on balance I
think it's a much better product than 1.4 ever was.
If your name were Vint Cerf, Admiral Mike Rogers, Whit Diffie, or
someone of that caliber -- then yes, I might be able to look at who you
are, your professional history, your accomplishments, and come to a
reasoned evaluation of how much credence I should lend to your honest
estimates.  But I don't know you.  I don't know your reputation, I don't
know who's worked with you that will vouch for you... nothing.  Without
that, why should I consider your estimates to be any more reliable than
a Ouija board?

@_date: 2015-09-28 16:29:47
@_author: Robert J. Hansen 
@_subject: Own Mail: PGP running on local server; Is it secure 
I've run into some of the Mailpile people at various conferences and on
various mailing lists.  I've yet to hear anything unusually foolish from
them.[1]  I can't recommend them because I haven't looked at their
product very much, but so far I've yet to find anything to make me
suspect them, either.
[1] Usual foolishness is, of course, expected.  We're all human.  I'm as
usually foolish as the next person.  It's only unusual degrees of
foolishness that are cause for concern.

@_date: 2015-09-28 17:36:19
@_author: Robert J. Hansen 
@_subject: Should I be using gpg or gpg2? 
Without knowing the basis for this claim, I have to reject it.
To paraphrase the movie _A Few Good Men_, it doesn't matter what you
know, it only matters what you can prove.  You could tell us all what
the winning lottery numbers would be, but unless you had some way to
prove your accuracy ahead of the drawing your prediction would mean little.
You may very well have excellent insights to share, but without having
any way to evaluate their likelihood of correctness how can we have any
confidence in them?  This week's lucky numbers may very well be 7, 8,
24, 29 and 31, but how can we know?  How can we have confidence?  Why
should we listen?

@_date: 2015-09-29 12:04:59
@_author: Robert J. Hansen 
@_subject: Should I be using gpg or gpg2? 
No: they're comparable to AES-128 *at our present level of mathematical
knowledge*.  That's a very important qualifier.
Back in the mid-to-late '80s, Ron Rivest declared that 1024-bit RSA keys
would be unbreakable for at least the next century.  The initial
releases of PGP 2.6 offered 512-bit, 768-bit, and 1024-bit keys, and
people recommended against using 1024-bit keys the same way we recommend
against 16384-bit keys today.  And, at the time these predictions were
made, there was every reason to think they were accurate.  They just all
made the same error, which was thinking the quadratic field sieve
couldn't be improved upon.  That was a conjecture.  It turned out to be
When the general number field sieve was invented, almost immediately
afterwards factoring records began to fall.  Today, 512- and 768-bit
keys are considered grossly inadequate, and a 1024-bit key is on the
razor's edge of adequacy.
I don't know when the next mathematical revolution (something like the
general number field sieve) will come along.  But when it does, it's
going to really upend the apple cart and our RSA-3072 keys aren't going
to be equivalent to AES-128 any more.
No, they're vulnerable to some graduate student slurping up a bowl of
ramen who looks at something on the blackboard and says, "hey, that's
weird."  It's happened before: look into George Dantzig.
Dan Boneh has already published an awe-inspiring paper showing that RSA
isn't anywhere near as safe as we think it is:
Breaking RSA is not equivalent to factoring; it's possible to break RSA
without needing to factor large numbers.  We just don't know how and
we've made precisely zero headway on that question.
But you never know when a George Dantzig will appear.  And that means I
think your long-term confidence in RSA is misplaced.

@_date: 2015-09-29 12:18:47
@_author: Robert J. Hansen 
@_subject: Should I be using gpg or gpg2? 
Eh.  Correction: *may* not be anywhere near as safe it is.  Definitely
shows that our confidence in RSA probably isn't as well-founded as we'd
I did a pretty long writeup of the implications of the paper a couple of
years ago.  Read:

@_date: 2015-09-29 13:37:56
@_author: Robert J. Hansen 
@_subject: Should I be using gpg or gpg2? 
I don't know.  Sorry.  :(
What I do know is that, judging from past experience, our projections on
key lengths need to take into account the possibility of radical
improvements in mathematics that make our original projections optimistic.
ECC-256 is probably good enough for any imaginable purpose for the
foreseeable future, at least up until quantum computers come along.
That's why I favor using ECC-512 instead.  :)
Different, but I'm not sure I'd say stronger.  And yes, it's still
susceptible to mathematical breakthroughs.

@_date: 2015-09-30 15:58:51
@_author: Robert J. Hansen 
@_subject: How to get your first key signed 
More important than whether your certificate gets signed is who signs
the certificate, who they are connected to, and so on.
Some people will sign almost anything.  People who get a reputation for
signing anything develop a reputation for their signatures being
meaningless.  Some people have very strong requirements before they'll
sign.  Their signatures are often worth quite a lot of credibility, but
good luck getting them.
The good news is this *can be done*.  I promise.
The best thing you can do right now is to get involved in the community.
 Get engaged in the mailing lists (here, PGP-Basics, Enigmail-Users are
three good ones).  And when you post, sign your messages.  Over time
people will come to trust that your signature connects to the real you,
even if they can't promise that your name really is David Niklas, or
can't say what you look like.
Once you've got a couple of years' track record of consistently using
the same certificate, consistently contributing to mailing lists and
FOSS projects, consistently being part of the solution and not part of
the problem ... I promise, you'll find people who are willing to vouch
for you.
There is no quick way, no shortcut.  But I think you'll find that
although it takes a while, it isn't hard, either.  :)
I grew up on a farm in the middle of nowhere.  I know *exactly* what
that's like.
So, first, host your software publicly, somewhere that it's easy to
find.  GitHub works great, but there are a lot of options.  On whatever
page you use for your FOSS work, put a notice that says "My GnuPG
certificate is 0xDEADBEEFDECAFBAD, and you can download signatures for
all the tarballs over here."
It works.  Seriously.  :)
Welcome to the community!

@_date: 2016-04-01 18:36:39
@_author: Robert J. Hansen 
@_subject: Translate to dutch 
Eva --
We have a Russian translation for the GnuPG FAQ, but not a Dutch.  If
you'd care to contribute one, I'd love to link to it from the main FAQ.  :)

@_date: 2016-04-04 08:15:05
@_author: Robert J. Hansen 
@_subject: Procedure of deriving a pruivate key from the password 
Private keys aren't derived from passphrases.
The result is used as an AES256 key and used to decrypt the private key

@_date: 2016-04-20 02:09:48
@_author: Robert J. Hansen 
@_subject: Using a passphrase FD from variable and piped data for encryption 
You're asking people to sign on for a literally never-ending process.
(Peer review never ends, after all.  Ask the OpenBSD guys.)  There's
nothing wrong with that.  You should always feel free to ask other
people to help.  But in order to get the best-qualified people on board,
your project should offer something new: a new capability, a new
security guarantee, a new resistance to attacks, a new *something*.
Because without some new improvement, what motivation is there for
anyone to switch?
It's good to scratch your own itch.  If you want to use this tool you've
built, more power to you.  But other people probably won't unless you
can give them specific reasons to care.

@_date: 2016-04-20 19:45:34
@_author: Robert J. Hansen 
@_subject: gpgme-sharp API missing 
On  , gpgme-sharp is listed as being in alpha
status for .NET.  Unfortunately, the link is dead and there's no sign of
where it's moved to.  For a while it was hosted on GitHub, but
apparently no more.
If anyone has a copy of the gpgme-sharp source code I'd be happy to host
it on my own GitHub account.  But either way, the link on the wiki needs
to be either updated or removed.

@_date: 2016-04-21 10:05:18
@_author: Robert J. Hansen 
@_subject: gpgme-sharp API missing 
I haven't looked at it in a few years.  My recollection is that it was a
barely-working GPGME binding.

@_date: 2016-04-25 10:01:40
@_author: Robert J. Hansen 
@_subject: Paper backup 
Why not use Paperkey and QR-encode that instead?
It depends.  For some users, sure.  For other users, no.

@_date: 2016-04-25 10:08:30
@_author: Robert J. Hansen 
@_subject: Paper backup 
It annoys me when I hear people talk about this.  :)  IMO, it's the sort
of thing that tends to get parroted by people who haven't thought things
When people talk about key length and say "so I'm good for twenty
years," I wince.  Because they also need to be talking about the rather
extreme measures they'll also need to take to ensure their private key
is never compromised, they're able to read their data, the data is
preserved, the certificate is preserved, etcetera, for a 20-year period.
When talking about anything past about a five-year window, you really
need to spend more time thinking about the data archiving problem than
you do about cryptography.
Preaching to the choir, Peter, I know...

@_date: 2016-04-26 09:11:29
@_author: Robert J. Hansen 
@_subject: making a Debian Live CD for managing GnuPG master key and 
I'd like to make it clear that I'm not talking about Dashamir here.
What I'm saying here applies more broadly to libre software in general.
The libre community is a reputation culture.  People keep track of how
much others give (and how valuable it is) and use that to determine how
much to give back (and how valuable it'll be).  Well-managed projects
(GitHub pages, build environments, bug trackers, etc.) enjoy more
reputation than poorly-managed projects, and benevolent dictators for
life enjoy more reputation than tyrannical martinets.
When asking other people to do things for you, it pays to keep in mind
how valuable the community has deemed your contributions.  If you
haven't earned much reputation, you might want to do that before you go
about asking people to do things for you.
Just my two cents' worth.  :)

@_date: 2016-04-26 09:37:49
@_author: Robert J. Hansen 
@_subject: making a Debian Live CD for managing GnuPG master key and 
He can't do that, shouldn't do that, shouldn't even want to do that.
You're a human being, not a machine.  You deserve to be treated as a
person, not as a system of inputs and outputs.  Ideas should be
criticized or praised purely on a technical basis, but people should be
criticized or praised purely on a *human* basis.
I've looked over your egpg code.  My bloodless technical evaluation is
simple: "it is nowhere near ready for production environments."  And I
think if you read over the other technical criticisms you've received,
you'll see this is pretty much a consensus opinion.  By your own
admission, it has not received any kind of peer review or independent
code audit.  And yet, you feel it's appropriate to recommend to the
Debian folks they put this code on a live CD image they intend for use
in high-risk environments, *and* you think they should put together a
.deb package for you.
That you believe your project is ready for inclusion into a live CD
image meant for hostile environments is, I think, enough to make me
question your wisdom.  And that *is* a personal judgment, and I make no
apologies for that.

@_date: 2016-04-26 12:44:44
@_author: Robert J. Hansen 
@_subject: Is there a foolproof tutorial to start with gpgme? 
A while ago I wrote a brief GPGME application to iterate over keys on a
keyring -- I used it to benchmark whether GPGME or piping GnuPG output
to a Perl script would be faster for processing large keyrings.  I've
cleaned up the code, put a proper CMake build environment on it, and you
can download it at:
Please note: since CMake doesn't have a plugin (yet) to automatically
detect GPGME, and since Homebrew's gpgme-config application is
completely broken (seriously, it refers to paths that don't even exist
on my system), certain paths are hardcoded.  Open src/CMakeLists.txt and
look at lines 2-7.  You'll need to edit those to reflect your own
system.  Beyond that, it should work for you.  If it doesn't, let me know!

@_date: 2016-04-26 13:31:15
@_author: Robert J. Hansen 
@_subject: Req: 64-bit GnuPG/GPGME for Windows 
How difficult would it be to get a 64-bit GnuPG and GPGME binary package
built for Windows?  The existing one appears to be 32-bit only, and my
development environment is 64-bit only.
(This is not a high-priority item.  Please, no one go to any special

@_date: 2016-04-26 16:51:37
@_author: Robert J. Hansen 
@_subject: making a Debian Live CD for managing GnuPG master key and 
Well, yeah, but let's keep in mind the GnuPG community
endorses/recommends very little.  Not even something like Enigmail gets
an endorsement or recommendation from GnuPG.  By and large, GnuPG just
focuses on GnuPG, and I think that's a good policy that's served
everyone well.  :)
Well, there's a little bit of a chicken-and-the-egg problem here.  If
new projects are told "don't evangelize here", how will they let users
who might be interested in their project know it exists?  Evangelization
is important.  I don't think we want to adopt a no-evangelization rule,
but at the same time, we want to keep it within limits, too.
We don't have a rule on this subject.  I don't think we need one,
either.  But speaking just for myself, I'd advise people not promote
their projects more than every other month.  Six announcements a year
ought to be plenty to let people know about a new project.

@_date: 2016-04-27 11:41:37
@_author: Robert J. Hansen 
@_subject: Req: 64-bit GnuPG/GPGME for Windows 
Besides my contract requiring 64-bit deliverables?  :)  A 32-bit GnuPG
standalone executable is okay, but my code needs to be 64-bit, which
means a 64-bit GPGME DLL.

@_date: 2016-04-27 11:48:23
@_author: Robert J. Hansen 
@_subject: Top-posting (was: Re: making a Debian...) 
A: Yes.  Just not top-posting.
Q: Are both allowed here?
A: Quote a few lines, write your response to those few lines, quote a
few lines, write your response, and so on. This is called inline-posting.
Q: What if it's a long message?
A: Quote as much of the material as you need for context, place it at
the top of the message, and write your response beneath it. This is
called bottom-posting.
Q: So what should I do instead?
A: Normally the stuff preceding text is relevant to what comes after it.
When you top-post, the following text is relevant to what precedes it.
It's reversed.
Q: What do you mean?
A: It reverses the usual flow of reading.
Q: What's the problem with top-posting?

@_date: 2016-04-27 19:50:42
@_author: Robert J. Hansen 
@_subject: Top-posting 
I hereby contribute it to the public domain.  Share and enjoy.

@_date: 2016-08-11 10:20:38
@_author: Robert J. Hansen 
@_subject: Standard gnupg folder created despite --homedir parameter 
In fact, an excellent rule of thumb for this list is there are no
experts -- just idiots who have carefully kept track of their mistakes.  :)
Watch your back, Jack.  A lot of people who are affiliated with GnuPG started out with the "it's just a hobby!" line.  :)

@_date: 2016-08-16 09:00:47
@_author: Robert J. Hansen 
@_subject: 2 Q's 
This depends on what version of GnuPG you're using.  The mechanism
changed between GnuPG 1.4 and 2.0.  Look for a configuration file called
"gpg-agent.conf" (normally found in ~/.gnupg; dunno where it would be
stored on iOS).  Open it up with your favorite text editor and look for
the line:
default-cache-ttl That's the duration, in seconds, your passphrase will be retained.  3600
seconds is one hour, and 86400 seconds is one day.
Don't.  Public keys are big and a little obnoxious.  Send your public
certificate to a keyserver.  In your email signature, you can say
something like "OpenPGP Certificate ID: 1DCBDC01B44427C7".  Anyone can
then retrieve your public certificate by typing something like:
$ gpg --keyserver pool.sks-keyservers.net --recv-key 1DCBDC01B44427C7
... and presto, they get it and import it into GnuPG, all in one statement.

@_date: 2016-08-16 09:48:25
@_author: Robert J. Hansen 
@_subject: gpg.conf recommendations (FAQ improvement) was: GnuPG 1.4.19 - 
[puts on official FAQ maintainer hat]
I'm weakly against this.  If we want to recommend people put something
in gpg.conf, what we should be doing is changing the default behavior to
be that, rather than expecting people to set an option.
I agree that long keyids are preferable for the future, but I think the
proper fix here is to make them the default behavior.
As always, though, if the list consensus is to do it in gpg.conf, I'll
amend the FAQ to recommend such.  Does anyone have any strong opinions
on the matter?

@_date: 2016-08-17 09:21:32
@_author: Robert J. Hansen 
@_subject: 2 Q's 
You're assuming people refresh their keyrings.  Although that's a
recommended practice, it appears to be the opinion of the minority.  My
certificate 0x23806BE5D6B98E10 has been revoked for seven months now,
and yet people continue to use it instead of 0x1DCBDC01B44427C7.  If
they had refreshed their keyrings even once in that time period, they
would no longer be able to encrypt to 0x23806BE5D6B98E10.
Before people ask:
(P.S.: if I bcc'd you on this, please type "gpg --refresh" now... :) )

@_date: 2016-08-17 09:52:59
@_author: Robert J. Hansen 
@_subject: 2 Q's 
That suggestion fills me with horror.  Key management is *already* a
nightmare without adding this to it.
Better by far to provide a cronjob that can do the refreshing
automatically -- or, on Windows, to write a service to do it.

@_date: 2016-08-17 14:15:31
@_author: Robert J. Hansen 
@_subject: 2 Q's 
A poorly-thought-out answer to a problem that doesn't exist.
Parcimonie is a key refreshing daemon.  (So far, cool!  It's a real
problem.  Solving this problem is cool.)  In order to defend against
completely hypothetical movie plot attacks, it insists on refreshing the
keys spread out over a long period of time and routing everything
through Tor.
The developers of Parcimonie claim that if you refresh your keyring all
at once, you're giving someone monitoring keyservers information about
your social graph and that could be useful in defeating your privacy.
That's true, but it's also missing the point.  There are literally
*thousands* of things people could hypothetically be doing to defeat
your privacy: should we have thousands of tools to defend against these
thousands of hypotheticals, or should we instead ask that we focus our
efforts on the very real risks we face?
Solving real problems is good.  "Solving" hypothetical ones, I'm not
fond of...

@_date: 2016-08-23 22:26:17
@_author: Robert J. Hansen 
@_subject: Attacks on encrypted communicxatiopn rising in Europe 
I've got to ask a question.
What would you have us do instead?
For the last eight years I've worked in digital forensics.  That's put
me in a position to see the works of psychopaths up close and personal.
They tend to love photographing or recording their exploits, and their
"art" winds up crossing my desk.  Evil exists and the worst thing I've
ever heard is a wailed, "Daddy, no, please stop!"
I believe that privacy is on balance a good thing and we need good tools
to preserve it.  But I've also seen enough victims and crimes to believe
that we also need ways to detect, apprehend, and prosecute offenders, too.
So long as you're a privacy absolutist -- which it appears you are --
then you're going to be on the losing side of your nation's privacy
debate.  As soon as people hear that your preferred answer to, "So how
should investigators and forensics geeks deal with this Tor, GnuPG, and
cgiproxy-using fiend?" is, "well, he shouldn't, because privacy!",
they're going to write you off as not having anything useful to bring to
the discussion.
Some serious questions --

@_date: 2016-08-24 04:42:34
@_author: Robert J. Hansen 
@_subject: Attacks on encrypted communicxatiopn rising in Europe 
I'd shrug and point to my many public statements where I've supported
strong, non-backdoored privacy tools.  If someone wants to accuse me of
being a government absolutist, that's on them.
Once it becomes such it'll be time to stop.  Until then, the discussion
can be quite useful.

@_date: 2016-08-24 09:11:23
@_author: Robert J. Hansen 
@_subject: Attacks on encrypted communicxatiopn rising in Europe 
Simple: I wasn't presenting my own views, I was asking Johan for his.
Where's the contradiction?

@_date: 2016-08-24 09:17:19
@_author: Robert J. Hansen 
@_subject: Attacks on encrypted communicxatiopn rising in Europe 
Thank you for being clear on that.
But this doesn't answer my question.
Why should we listen to a privacy absolutist?
Wait, wait, wait.
You're opposed to *any* kind of privacy circumvention... but you're okay
with torture?  You're seriously advocating "swing a wrench at this guy's
knees and make him talk" as an alternative to any kind of circumvention
of a privacy technology?
Johan, your position is morally incoherent.

@_date: 2016-08-24 10:23:43
@_author: Robert J. Hansen 
@_subject: Attacks on encrypted communicxatiopn rising in Europe 
My question was, "How should we permit privacy tools to be
circumvented?"  His answer was, "You can try - someone might have used a
weak password, wrote it down somewhere or made another mistake. Or can
be pressured into telling it (the famous $5 wrench comes to mind here)."
If I ask "how should we permit privacy tools to be circumvented?" and
someone's answer is "Pressure them.  A wrench comes to mind," well...
I've received an answer to how the person believes governments should be
permitted to obtain secrets.  It's not a very good one.
Consider me what you will.  Couldn't care less, myself.

@_date: 2016-08-24 10:27:58
@_author: Robert J. Hansen 
@_subject: Attacks on encrypted communicxatiopn rising in Europe 
Ideally, because they present options that may work better than what we
currently have.  Privacy absolutism -- the position that there is *no*
justification for infringing on individual privacy, even in the case of
serious crimes -- doesn't offer anything better than what we currently
have.  In fact, many people would think it was a lot worse.
Okay, I can understand speaking glibly: thank you for clarifying you're
opposed to that.
But if you're okay with technical attacks, you're not a privacy
absolutist, either.  If your solution is targeted malware, remote
exploits, Trojans, and the like, then you're permitting the government
to do an awful lot to subvert privacy.

@_date: 2016-08-24 10:37:35
@_author: Robert J. Hansen 
@_subject: Attacks on encrypted communicxatiopn rising in Europe 
Yeah, which is why I find both sides of the privacy absolutist debate to
be ... pretty much comically missing the point.
Tor, cgiproxy, GnuPG, Signal, and other such tools are out there and
aren't going to go away.  All proposals to require backdoors are silly,
because so long as just one nation has no such requirement those tools
will continue to exist and development will continue pretty much without
interruption.  So the "backdoor everything!" crowd is completely barmy.
But so too are the privacy absolutists who believe that law-enforcement
is doing something morally wrong when they try to break Tor's anonymity
in the pursuit of awful people.
I find the current state of detente to be pretty good, actually.  We're
allowed to design the best systems we can, and governments are allowed
to discover where we're not as clever as we think we are.  If there's a
flaw in Tor and the FBI uses it to pierce anonymity and go after a bad
guy, I can get behind that.  Way to go, FBI, you did it right, now
please hold on while we figure out how you did this and write a patch to
keep you from doing it again.
I guess you could say my preferred solution to the crypto wars is to
encourage an ongoing escalating crypto arms race.  It's crazy, but it
seems to work.

@_date: 2016-08-24 13:57:49
@_author: Robert J. Hansen 
@_subject: Attacks on encrypted communicxatiopn rising in Europe 
I never said I believed backdoors were an appropriate way to circumvent
privacy tools.  I think backdoors are a terrible and inappropriate way
to do it.
I completely agree that backdoors are a lousy idea.

@_date: 2016-08-26 10:12:53
@_author: Robert J. Hansen 
@_subject: Please unsubscribe me form your mailing list. Thank you. 
The world is a better place for it neither banning, nor trying to ban,
such things.
First, how do you ban signatures without banning people?  Many people
work in businesses which mandate signatures.  If we attempted to ban
signatures we'd be telling people, "unless you have a personal email
account, you don't deserve to talk to people."
Second, how do you ban signatures?  That would be an interesting problem
in AI, and would lead to false positives.  Again, this would have the
effect of barring some people from communicating.
Third, define "non pure-text".  If you're requiring 7-bit ASCII then
you're telling people from non-English-speaking countries that they
can't communicate.  And once you open it up to Unicode, you've
introduced a huge amount of attack surface -- I can't think of a
coherent argument that says "we'll support arbitrary character sets
including Unicode, but HTML is evil because of the attack surface it
Fourth, why is *forbidding a capability* considered a feature?
Forbidding the misuse of a capability, sure, I can see that as a
feature.  But every now and again I try to present math in this mailing
list, and I have two choices:
We shouldn't be angry about capabilities -- we should be angry about
people using them inappropriately.

@_date: 2016-08-30 14:12:15
@_author: Robert J. Hansen 
@_subject: Key Discovery Made Simple 
I hate to be the one to rain on this parade, but this seems like a mistake.
Most of our users don't run their own domains, don't have full authority over the mail server, and don't have webservers that can deliver static pages over TLS.  A solution that depends on this trifecta of capabilities should not be called "simple".  Just getting TLS running on a webserver can be a frustrating ordeal.
IMO, GnuPG development should be guided by a concern for regular users, not power users.  I'd like it if we could aim new features at regular users.

@_date: 2016-08-31 09:32:30
@_author: Robert J. Hansen 
@_subject: Key Discovery Made Simple 
I want to be careful about my criticism here, because it's really easy to
sound like I'm telling someone else what they should have volunteered to
work on for free instead.  That annoys me when other people do it to me, and
I want to be careful I'm not doing it to you.
I'm having a hard time imagining why a mail provider would adopt WKD when
probably less than 1% of their userbase uses OpenPGP in the first place.
Sure, I can see it for the geek elite who run their own domains,
mailservers, and webservers with TLS.  I can imagine a couple of fringe
players in the mail space might adopt it.  But I can't imagine adoption
beyond a small niche of the GnuPG community, which is *already* a really
small niche.  Carving out niches of niches does not strike me as a
productive way to expand the userbase.
The big players have already chimed in on OpenPGP.  Last year there was talk
from Google and Yahoo on the IETF WG list about how they were going to
introduce OpenPGP support to their mail clients, but they've been
conspicuously silent lately.  I know Cistercians who make more noise.  Does
Gmail even have one project member subscribed to this list and following the

@_date: 2016-08-31 13:05:44
@_author: Robert J. Hansen 
@_subject: Key Discovery Made Simple 
I hope they accelerate their movement.  :)
I've never learned how to politely say, "all right, then I think this wraps
up the conversation" without sounding rude.  I promise, it's not my intent.
I've spoken my thoughts on the matter, they've been heard and responded to,
and I don't think anyone's entitled to more than that.  Thanks for
answering, even if we see this differently.  I appreciate it, and all the
work you do on GnuPG, an awful lot.

@_date: 2016-08-31 13:34:02
@_author: Robert J. Hansen 
@_subject: Decryption Key Compatibility between GNUPG V 2.030 and GnUPG 
============================== START ==============================
Unlikely.  It's much more likely that you only imported the public key on the Production box.  On the Production box, try this:
C:\> \path\to\gpg.exe --list-secret-keys
If the key isn't listed there, then you forgot to import the private key.  If that's the case, give a smile and move on -- it's a common mistake, and one pretty much everyone here has made at least once.  :)

@_date: 2016-11-30 21:54:06
@_author: Robert J. Hansen 
@_subject: libgpgme-11.dll 
For long and boring reasons I need to be able to call GPGME from
Microsoft Visual C++.  The MSVC linker requires .lib files, which are
not shipped with GnuPG.  That's okay: the procedure to make them is
pretty straightforward.
For each of libgpgme-11.dll, libgpg-error-0.dll, and libassuan-0.dll, I:
1.  ran dumpbin /exports on it, to recover the function names
2.  put these function names in a text file with "EXPORTS" at the top
3.  ran lib /def:somefile.def /out:somefile.lib to create the .libs
(Insert appropriate filenames for "somefile", of course.)
A really basic test of GPGME passes: I can link against
gpgme_check_version and confirm the correct version of GPGME.  However,
I can't actually *do* anything with it: gpgme_engine_check_version
continually throws an invalid engine error, and gpgme_get_dirinfo keeps
on returning nulls.
So, if I had to wager a guess, GPGME isn't able to find GnuPG.
My sample code runs just fine on OS X and Linux, incidentally, so I
doubt the problem is with it.  (If people want to see it just to make
sure, I'm happy to provide it.)
Anyone have any ideas?

@_date: 2016-12-01 06:51:27
@_author: Robert J. Hansen 
@_subject: libgpgme-11.dll 
I did not, and this was the problem.  Thank you, Werner.  :)

@_date: 2016-12-02 01:05:44
@_author: Robert J. Hansen 
@_subject: gpgme 1.8 build failure (again) 
Last month I had a build failure for GPGME 1.8 on macOS.  I reported it
to the list and received a useful answer about a custom preprocessor
define that should've been, but was apparently was not, used.
Unfortunately I didn't write this down, and the email thread is not in
the archive.  (Only one message seems to be:
 )
Can anyone give me once again the magic invocation needed?  Thanks.  :)

@_date: 2016-12-02 09:20:50
@_author: Robert J. Hansen 
@_subject: GnuPG version info from GPGME? 
I'm working on a command-line application to migrate profiles not just
between machines, but versions of GnuPG.  E.g., 1.4 on machine A -> 2.1
on machine B, or vice-versa.  For this, I need a way to discover which
version of GnuPG is currently installed.  A quick look through the GPGME
manual doesn't reveal anything.
Have I just overlooked it, or do I really need to launch gpg --version
and parse the output?

@_date: 2016-12-02 09:22:05
@_author: Robert J. Hansen 
@_subject: GnuPG version info from GPGME? 
And literally two seconds after clicking "Send", I found the answer.
Never mind.  :)

@_date: 2016-12-03 10:16:14
@_author: Robert J. Hansen 
@_subject: gpgme 1.8 build failure (again) 
That was the one I needed.  :)  For some reason, something in the GPGME
build requires _DARWIN_C_SOURCE to be set.

@_date: 2016-12-07 14:22:46
@_author: Robert J. Hansen 
@_subject: RFC on issue 2701, default expiration time for new keys 
I'd go one step further: this is not even a best-practices document.  Any
document which claims to be a best-practices document which does not have,
as a high-priority item, "Figure out your threat model," is frankly just
somebody pretending to be competent.
[puts on FAQ maintainer hat]
Every now and again I get someone asking me why there aren't best practices
listed in the FAQ.  The answer is always the same: because GnuPG doesn't
really have them.  GnuPG is a toolkit you use to implement part of your
custom solution to address your particular threat model.  As such, the idea
of "best practices" that are one-size-fits-all is really kind of silly.
There might be some merit in a "Things To Think About" document, but the
idea of a single best-practices document that applies to everyone everywhere
borders on the absurd.
[takes off hat]
It also recommends ignoring things like the keyserver-url field on a
certificate.  Which is ... interesting.  If Alice works for a company that's
rolled out GnuPG, the company may have its own LDAP server with
up-to-the-minute revocations.  And the company may wish you to fetch Alice's
certificate from it, in order to get up-to-the-minute details, as opposed to
getting it from the keyserver network, which the company doesn't sync with.
So if you follow these "best practices", you'll actually never get to update
Alice's certificate, even when it's revoked after she leaves the company...
Also, don't get me started on "Primary keys should be DSA2 or RSA (RSA
preferred)".  Right, like there's some inherent problem with DSA2 that makes
RSA such a superior choice...

@_date: 2016-12-11 15:37:19
@_author: Robert J. Hansen 
@_subject: Hybrid keysigning party, your opinion? 
I'm glad you made the correction: that error was sooooo profound.  :)
(For those not up on their large-number theory: the difference is
insignificant.  Peter's correction was made in a spirit of utterly
pedantic attention to detail [a spirit I share!], not because it mattered.)

@_date: 2016-12-14 22:59:39
@_author: Robert J. Hansen 
@_subject: Ubuntu Version, Desktop Interface, and GUI Question(s) 
The latest version.
Whatever the default for your Ubuntu version is.
GPA or the Enigmail key manager come to mind.
Probably wise.  ;)

@_date: 2016-12-15 11:39:16
@_author: Robert J. Hansen 
@_subject: Upgrade to gpg2 
Most older configuration files will work just fine with GnuPG 2.0 and 2.1.
It'll install GnuPG 2.0 (2.1 in Sarah) and you'll be ready to go.

@_date: 2016-12-16 20:16:13
@_author: Robert J. Hansen 
@_subject: Common directory for different installs of GnuPG 
Unlikely.  It's technically possible to have configuration files that
don't work with 1.4 and 2.0/2.1, but it involves options you likely
shouldn't have set in the first place.

@_date: 2016-12-17 19:56:43
@_author: Robert J. Hansen 
@_subject: Smartcards and tokens 
Nope.  OpenPGP requires each RSA encryption add at least eight random
bytes to the data pre-encryption in order to make even identical
messages encrypt to different ciphertexts.  Search RFC4880 for a
reference to RFC3447 7.2.1, then look up RFC3447 7.2.1 and see how
EME-PKCS1-v1_5 encoding is defined.

@_date: 2016-12-20 05:32:21
@_author: Robert J. Hansen 
@_subject: File perms for conf files 
So, as some of you may remember, I've been working on something to help
users back up their user directories and migrate them to new machines.
We really have no good tools at present to do this, so I'm putting
together a small Qt application to make this easier.
(Note: it is not complete and not ready for user testing.)
It *almost* works on macOS and Linux; it's a little further from
finished on Windows.  I'm now at the point where I need to restore files
from a zip archive, and part of that means ensuring I have the correct
POSIX permissions on each file.
The files which, if present, are backed up:
So, two questions:
(a) Is this list missing anything important?
(b) What's the official, GnuPG-approved permission for each?
(Oh, sure, I could just assume my GnuPG installation had correct perms
and use those.  But for something like this, I'd like to be sure.)

@_date: 2016-12-25 15:22:09
@_author: Robert J. Hansen 
@_subject: Unable to import Private Key 
Try verbose mode.
gpg -v --import keyfile.asc
If that doesn't give you enough information, try ultra-verbose mode:
gpg -vv --import keyfile.asc

@_date: 2016-12-27 17:06:11
@_author: Robert J. Hansen 
@_subject: ? Comments re key servers? re gpg-encrypted mail? re key servers 
Completely orthodox.  Certificates retrieved through the keyserver network
should not be trusted until/unless verified.
Some people are moving to embrace TOFU, which changes these rules somewhat.
For my money, though, I don't (and won't) use TOFU.

@_date: 2016-12-28 16:40:18
@_author: Robert J. Hansen 
@_subject: Gpg key lost in self update 
For a strong passphrase, there is no effective way to crack it.  Sorry,
you're SOL.

@_date: 2016-12-30 10:07:01
@_author: Robert J. Hansen 
@_subject: ubuntu installation failure. 
Why are you installing 2.0.30 from source?  GnuPG 2 is already available in
the package repositories.
Current Ubuntu stable, Yakkety Yak, ships with 2.1.15, I think, so it's even
considerably newer than 2.0.30.

@_date: 2016-12-31 14:59:48
@_author: Robert J. Hansen 
@_subject: File perms for conf files 
============================== START ==============================
The last time I asked this I received no response, so I've been moving
forward a bit in the dark here --
Yep, still underway.
I'm going with 0x0644 (-rw-r--r--) on the .conf files, 0x0755
(-rwxr-xr-x) on the directories, and 0x0600 (-rw-------) on all files
other than .confs.
I need to add a (c):
(c) What should the perms be on Windows?
Right now I'm just uncompressing files directly into the GnuPG data
directory on Win32.  For all I know that's sufficient; for all I know
it's wrong.

@_date: 2016-02-03 15:12:59
@_author: Robert J. Hansen 
@_subject: FAQ maintenance 
Time for my semi-regular FAQ perusing and updating.  I plan on updating
the FAQ to include a link to the FSF's email security guide, but that
seems like such an unobjectionable change I'm not going to kick it
around the list for pre-approval.  Beyond that, if there's anything
you've always thought the FAQ should mention, now's a great time to
suggest it.  :)

@_date: 2016-02-04 03:56:47
@_author: Robert J. Hansen 
@_subject: FAQ maintenance 
As near as I can tell, this question isn't asked very frequently.  If
the opinion of the list is that it is, though, I'll certainly add it.
What say y'all?

@_date: 2016-02-04 04:29:17
@_author: Robert J. Hansen 
@_subject: FAQ maintenance 
The FSF asked Patrick Brunschwig and me to review it prior to
publication.  I don't know if Patrick turned in criticisms; I gave a
couple of pages' worth.  I'm pleased with the end result.

@_date: 2016-02-05 05:55:25
@_author: Robert J. Hansen 
@_subject: FAQ maintenance 
Let me put on the maintainer hat and speak ex cathedra a moment: The FAQ
is aimed at Qs that are F Aed.  The answers it provides are aimed at new
and/or casual users, not tinkerers, and this focus will not change.
Once a FAQ becomes a tinkering manual, the content explodes and so does
the size of the maintainer's job.  For my own sanity, I won't let it
become a tinkering guide.
I suspect the FAQ is appropriate.  If we're going to present information
to new users, we should anticipate them having questions about it.
It's not, as near as I can tell.  Some of their GnuPG examples are from
version 0.9.4, which is 17 years old.  One would think periodic
maintenance would have led to these examples being updated.  For that
reason, my suspicion is it's unmaintained.
Further, I can't recall the last time I saw the maintainer (Mike Ashley)
post here.

@_date: 2016-02-05 06:01:38
@_author: Robert J. Hansen 
@_subject: GNU Privacy Handbook 
Looking over the GNU Privacy Handbook, it's clear it hasn't received any
maintenance in a decade or more.  According to it, DSA is limited to
1024-bit keys, RSA gets almost no mention, SKS gets no mention, and
users are led to use the (closed-source, non-synchronizing) PGP
Corporation keyserver.
IMO, the GPH needs to be taken down.  Documentation that badly out of
date does no one any good.  At the very least it needs top-to-bottom
If Mike Ashley is no longer maintaining the GNU Privacy Handbook, I'm
willing to take on the job.

@_date: 2016-02-05 07:06:07
@_author: Robert J. Hansen 
@_subject: FAQ maintenance 
I confess to some slight misdirection here.  Is that a valid gpg.conf
file?  Sure.  Will it get someone in trouble?  Probably not.  But is it
needed?  Not really.  :)
What's the justification?

@_date: 2016-02-05 07:34:42
@_author: Robert J. Hansen 
@_subject: FAQ maintenance 
That seems to be a big 'if' right now.  Short collisions are easy; long
ones are nontrivial.  Or did I miss something?

@_date: 2016-02-06 06:51:35
@_author: Robert J. Hansen 
@_subject: Minor FAQ updates 
Ineiev of the Free Software Foundation sent me some typos she noticed
while composing a Russian translation.  I incorporated these typo fixes
and introduced a link to her Russian translation.  Thank you, Ineiev!  :)
There are no other changes to speak of.  The FAQ is current, the
contents are accurate.  This weekend I'll be drafting comments on the
SCEA capabilities; once I have language I'll bring it to the list for
final review before I incorporate it into the FAQ.
Also, please think about what we want to do with the GNU Privacy
Handbook.  Peter and I both think it's badly out of date.  I think it
either needs to be taken down or else completely rewritten.  If the list
consensus is to keep it around but rewrite it, I'll volunteer to
coordinate that task.  (Samir Nassar contacted me to express his
interest in helping with a rewrite, which I really appreciate; thanks,

@_date: 2016-02-06 07:08:50
@_author: Robert J. Hansen 
@_subject: Documentation format 
Since I seem to have become the doyen of documentation, I figure I
should ask: what markup language and/or output formats should we be
pursuing for future documentation work?
The FAQ is currently written up in orgmode, which Werner is fond of.
What you see on the web is orgmode-text put through an HTML translator.
 But, it also produces lousy print output.
The FSF is really fond of their own standard, texinfo, which they prefer
to be used for hardcopy and online documentation.  I personally don't
like texinfo; some people really like it.  In its favor, it produces
high-quality print output.  It actually looks like a book when you print
it off.
I'm a big fan of LaTeX and PDF output.  With a good layout package (like
Tufte-Latex) you can get astonishing print quality and
professional-looking layout.  However, this comes at the expense of good
HTML support.  You'd have a hard time reading these docs on mobile
devices, or at a text-only terminal that had no PDF reader.
Another option: Open Document.  For obvious reasons we can't choose
Microsoft Word, but there are no liberty-related reasons to avoid Open
Does anyone have any particular preferences?

@_date: 2016-02-06 09:17:07
@_author: Robert J. Hansen 
@_subject: Usage text 
Proposed FAQ language -- feel free to criticize, to suggest alternate
phrasings, or anything else.  :)
Q: When I view my certificate I see letters like S, C, E, and A.  What
do they mean?
A: Your certificate contains two or more cryptographic keys.  When
attached to a certificate, we call them ?subkeys?.  Different subkeys
get used for different sorts of tasks.
There are four different tasks a subkey can perform.  It can
          can see you vouching for it
For instance, looking at my own certificate, we see:
    laptop:~ rjh$ gpg --edit-key rob at enigmail.net
    Secret key is available.
    sec  rsa3072/1DCBDC01B44427C7
         created: 2015-07-16  expires: never       usage: SC
         card-no: 0005 00000D18
         trust: ultimate      validity: ultimate
    ssb  rsa3072/DC0F82625FA6AADE
         created: 2015-07-16  expires: never       usage: E
         card-no: 0005 00000D18
    [ultimate] (1). Robert J. Hansen     [ultimate] (2)  Robert J. Hansen Subkey 1DCBDC01B44427C7 can be used to sign data or certify other
people's certificates; subkey DC0F82625FA6AADE can only be used to
encrypt data.
You don't need to keep track of subkeys.  GnuPG will never ask you for a
specific subkey.  Instead, GnuPG will ask you for a certificate ID.
GnuPG will then use whichever subkey is appropriate for the task it's
performing.  If two or more subkeys are appropriate, it will use the
newer one.
Q: None of my subkeys are marked ?A?.  Is this a problem?
A: No.  Using GnuPG to authenticate yourself to a computer system is an
advanced topic and only a few users will ever need it.  For that reason,
by default GnuPG does not mark subkeys as usable for authentication.

@_date: 2016-02-06 09:44:53
@_author: Robert J. Hansen 
@_subject: Minor FAQ updates 
I agree, but this will be a substantive change.  For that reason I'm
folding it into the substantive edits I'm making over the weekend, as
opposed to the review-and-typo-hunt of this morning.  :)

@_date: 2016-02-06 16:11:24
@_author: Robert J. Hansen 
@_subject: Documentation format 
I should preface this by saying that I'm not advocating we move away
from org-mode.  I don't have any aims in that direction.  I really
dislike org-mode's print output, but that's (IMO) insufficient reason to
throw the entire thing out.
I *do* think, though, that exploring other options is a good idea.  :)
My big annoyance comes from how org-mode silently mangles i18n.  The FAQ
uses UTF-8 encoding so that we can do the Right Thing with respect to
languages.  Right now we only rely on it in two places (presenting the
Greek roots of the word 'cryptography'), but I can easily imagine it in
more; for instance, if I have to credit a GnuPG-Users contributor named
A?man, or talk about Merkle-Damg?rd hash functions, or Vigen?re ciphers,
or... etc.  Crypto is a truly international field, and so we need to
expect/prepare for internationalized text.
When org-mode exports to LaTeX, most internationalized text falls out
and goes boom.  The Greek that's currently in the FAQ gets silently
dropped, for instance.  This *really really annoys me*, because it means
that after I've done a detail read of the HTML version of the FAQ
looking for errors I now have to do a detail read of the print version
looking for errors introduced by org-mode's export filter.
(For the record: yes, I know why org-mode has trouble with i18n export
to LaTeX.  Yes, it's a hard problem.  Yes, fixing it might not be worth
the effort.  All of this is true.  None of it changes how annoyed I am
by the bug, though.)
I don't like the way Texinfo looks on the page.  It has a very 1970s
textbook feel to it.  It's also deeply married to very specific font
families, and I think we can do a lot better.  The world has mostly
abandoned Computer Modern Roman, even Knuth -- he's moved on to his
Concrete font family, for the most part.
Open Document is just XML, so it meets your requirement of a
human-readable plain text file.  Or do you really mean, "I don't like
XML, so please don't use an XML-based standard"?  :)

@_date: 2016-02-06 23:59:23
@_author: Robert J. Hansen 
@_subject: Documentation format 
I don't; for all I know nobody's reported it yet.  (If that's the case,
I should.)  The problem stems from how orgmode assumes that downstream
tools can parse UTF-8.  LaTeX way predates UTF-8 and requires that
foreign symbols be composed using TeX escape sequences.  For orgmode to
translate UTF-8 to LaTeX reliably would require it to keep track of an
impractically large translation table: Greek characters, French,
Cyrillic, grave and acute accents, circumflex composition, and more.
LaTeX is unique among document processing systems in that it can
effortlessly represent the correct orthography for the rock group Spinal
Tap (which uses a Turkish dotless lowercase i and a Jacaltec umlauted
n), but that comes with a steep price: namely, its near complete
inability to handle Unicode like the rest of the world.
I tried pandoc, but without good effect.  I haven't explored it further.
Sure!  I also think Marisa Berenson is the most fashionable woman in the
world... for 1967.  Look at photographs of Marisa Berenson from the '60s
and you'll be stunned at the fashion ensembles she wore: beautiful,
striking, and memorable.  But if you were to see someone walking down
the street dressed like that, you'd think they came to the party about
forty years late.  :)
Typography is the fashion of literature.  If you want to look good, you
need to balance the timeless with the temporal.  Texinfo looks really
good for the 1970s, but by current standards it's pretty antiquated.
Typography and layout are, believe it or not, user interface issues.  If
the user's response on seeing the printed documentation is "did this
just fall out of the '70s?", they're probably going to start off with a
negative impression of the work.  To make documentation approachable and
something that people actually want to read, you need to make it look
like something current.
... Incidentally, Marisa Berenson on the cover of _Vogue_ in the '60s.
Safe for work.
The old saw is "you can't judge a book by its cover".  The old saw is
wrong.  Book publishers spend enormous amounts crafting their books so
that you have a positive experience with it from the moment your eye
lands on the cover in the bookstore.
Typography and layout matter.

@_date: 2016-02-17 20:21:36
@_author: Robert J. Hansen 
@_subject: NYT on surveillance 
The NYT is now saying it appears the scope of U.S. surveillance is less
than previously suspected.  I have no idea if it's right; take with a
grain of salt.

@_date: 2016-02-21 01:32:00
@_author: Robert J. Hansen 
@_subject: What is an appropriate link for IceDove?... 
Mozilla's Thunderbird email client is free and open-source software.
However, Debian requires that software also be free of trademarks, and
Mozilla and Thunderbird are both trademarks.  So they take Thunderbird,
remove the trademarks, and rebrand it as Icedove.

@_date: 2016-02-22 20:38:29
@_author: Robert J. Hansen 
@_subject: Migration assistant 
I'm dusting off an old set of scripts that I used to use for migrating
GnuPG instances from one machine to another.  I have to revisit some of
the logic to update it for GnuPG 2.1.  I know roughly what should be
here, but before I update the code and share it with the world I'd like
to have it *precisely* correct.
In GNUPG_HOME ($HOME/.gnupg, or %APPDIR%/GnuPG):
Iterate over all files in this directory
  If the filename could be a SHA-1 hexadecimal hash:
    If the filename ends in ".rev":
      If the file contents contains a line with ":-----BEGIN
      PGP PUBLIC KEY BLOCK-----":
        Flag this file for inclusion in the archive
Iterate over all files in this directory
  If the filename could be a SHA-1 hexadecimal hash:
    If the filename ends in ".key":
      Flag this file for inclusion in the archive
Do I have this correct?  Are there any files that I'm missing?  Is there
any better logic I can use for the contents of the crls.d/ subdirectory
except "better grab everything, I guess"?

@_date: 2016-02-23 04:09:30
@_author: Robert J. Hansen 
@_subject: Can the NSA Crack GnuPG 
One might suspect this question had been asked so frequently there was a
FAQ entry devoted to it.  ;)

@_date: 2016-02-23 05:16:24
@_author: Robert J. Hansen 
@_subject: Can the NSA Crack GnuPG 
And what the heck, I can't sleep, so I'll give longer answers:
Why would they tell you?  And if you're the sort of person they'd tell,
why would you tell us?
No, it really doesn't.
There are about n/ln n primes less than n.
2**4096 = e**2839.
  e**2839       e**2839
----------- =  ---------
ln(e**2839)      2839
ln 2839 is approximately 8.
------- = e**(2839 - 8) = e**2831.
 e**8
e**2831 / log(2) = 2**4084 = 10**1229.
There are about 10**1229 primes less than 4096 bits.
If you repeat this exercise again for how many primes there are less
than 4095 bits, then subtract one from the other, you'll get a solid
approximation for how many 4096-bit primes there are.  I'll leave that
as your homework and just tell you the answer: it still comes out to
pretty much the same number.
10**1229 is unimaginably huge.  By comparison, there are about 10**90
neutrinos in the universe.
Where do you plan on storing this chart?
You literally need to store it in a bigger universe than our current
one.  Our universe doesn't have enough matter or energy to make this chart.
People say lots of things.  And some people are cruel enough to
deliberately mislead people they feel will believe their nonsense.  I'm
not saying you're one of these cruel people; I'm saying he probably was.
Miller-Rabin is a really nice primality checking algorithm.  AKS is
an even better one.  Factoring composite numbers is really hard;
figuring out if a number is composite is really easy.

@_date: 2016-02-23 08:04:38
@_author: Robert J. Hansen 
@_subject: Can the NSA Crack GnuPG 
Pfeh.  Haven't you heard of Grover's algorithm?  Come on, man, get with
the program.  Assuming you've got a Zarbnulaxian quantum computer with
an arbitrary number of qubits, an epsilon error rate, effectively zero
decoherence, and protons that are stable over considerably longer than
the currently expected lifetime, you could reduce this down to about
10**550 times longer than the known age of the universe.

@_date: 2016-02-23 08:23:08
@_author: Robert J. Hansen 
@_subject: Can the NSA Crack GnuPG 
That noise you just heard was my train of thought going off the rails,
catching on fire, and hurtling like a fiery missile of kinetic death
into a nearby station.  I'm sorry, *what*?
If we're able to transmit information FTL then relativity is wrong wrong
*wrong*.  Are you sure that you're not reporting on the Bell inequality
experiments, where they were able to demonstrate instantaneous action
but in a way that was unable to be used for a communications channel?
Either way, you have my full attention.  :)

@_date: 2016-02-23 09:04:04
@_author: Robert J. Hansen 
@_subject: Can the NSA Crack GnuPG 
Whew.  Okay, that's a relief: that's on experimental confirmation of
Bell's theorem.  Yes, the speed of entanglement is instantaneous, but
there's some additional weirdness involved that makes it impossible to
use as an instantaneous communications channel.  :)

@_date: 2016-02-24 20:52:09
@_author: Robert J. Hansen 
@_subject: Profile Backup Tool 
Well, it's done (enough) for a 1.0 release:
Supported OSes:

@_date: 2016-02-25 13:11:55
@_author: Robert J. Hansen 
@_subject: FAQ maintenance 
If an attacker can control your gpg.conf file, there are so many worse
things to do that it's hard for me to take this seriously.

@_date: 2016-02-26 10:29:53
@_author: Robert J. Hansen 
@_subject: FAQ maintenance 
It's far more intensive of a much more limited resource: user happiness.
 Normal users tend to find hexadecimal frustrating:
"It's a *number*?  But it uses A through F."
"I don't understand.  Why do I need the long ID?"
"Wait, now I need to use the *entire* fingerprint?"
"You can't be serious: I need to give a 40-character serial number
whenever I need to identify a key?"
"What do you *mean*, future keys will be expanding to 64 characters?!"
... In all this discussion about what's mathematically optimal, I'm
dejected to see how little we're talking about human factors.

@_date: 2016-01-14 11:27:40
@_author: Robert J. Hansen 
@_subject: Key selection order 
First, recognize that this has likely already happened, and the world
hasn't ended.  :)  Look at how many certificates there are for
president at whitehouse.gov, for instance.
Fingerprint verification.  An attacker can create a fraudulent
certificate, but an attacker cannot (to the best of our knowledge)
create a certificate that has an identical fingerprint to the real one.
And if you're concerned about this, then retrieve certificates based on
fingerprints, not on email addresses.

@_date: 2016-01-14 13:09:20
@_author: Robert J. Hansen 
@_subject: Key selection order 
Tell them to look you up by fingerprint.  Problem solved.
No, it breaks up the "grab a random certificate that claims to be mine
and just use it" workflow, which is stupid, and isn't even what the TOFU
advocates suggest.
TOFU is built on trusting certificates that are used in received mail.
If you receive a mail signed by 0xB44427C7, TOFU says "you should
probably trust this is from rjh at sixdemonbag.org."
But if you don't already have the certificate, and you're looking for it
on a keyserver, TOFU says "you should really pull it down by long key ID
or fingerprint."

@_date: 2016-01-14 14:37:47
@_author: Robert J. Hansen 
@_subject: Key selection order 
That's when you ask your correspondent, "I need your certificate
fingerprint, please."  I don't see what the problem is.
And you've been told!  If you know you're being targeted by a malicious
actor, stop using TOFU and fall back to fingerprint verification.
Why are we still talking about this?

@_date: 2016-01-14 17:36:00
@_author: Robert J. Hansen 
@_subject: Key selection order 
Beware all absolutes.  There are lots of situations in which TOFU works
*just fine* as a long-term solution.  Remember, the truest answer in
cryptography is, "It depends a lot on the situation."
I've known vedaal for what, coming up on 20 years now, vedaal?  I've
never used any verification for him besides TOFU.  Works just fine for
us.  There's a decent chance it's been working for us longer than you've
been alive.  :)
I think people have a vast misunderstanding about the TOFU threat model.
 If you are already under active attack by a well-funded adversary, then
yes, you're screwed: don't use TOFU.  But if you're not, then TOFU
allows you a much easier way to build and develop your own personal Web
of Trust in ways that make it much harder for an active attacker to
later on subvert your communications.
Neither does the WoT.  What does, for that matter?

@_date: 2016-01-18 09:17:31
@_author: Robert J. Hansen 
@_subject: Key selection order 
This is because in the absence of trust, signatures are meaningless.
Who on this list has verified my certificate to any real degree?  Samir
Nassar, Patrick Brunschwig, maybe one or two others.  Who on this list
would invest my messages with a degree of trust they shouldn't?  Many
many more.
For that reason, I show some caution with what messages I sign.  I
suspect many others are likewise.

@_date: 2016-01-26 05:43:46
@_author: Robert J. Hansen 
@_subject: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
Welcome!  You're in the right place, and we'll be happy to help you out.
 You may wish to switch from HTML email to plain-text; that's the
standard for this list.
If it's taking your GnuPG setup ~15 minutes to generate a new
certificate, that indicates to me your GnuPG installation has a problem.
Let's tackle that one first before we start looking at your code.
Are you getting periodic messages about "Not enough random bytes
available.  Please do some other work to give the OS a chance to
collect more entropy! (Need 167 more bytes)" or something like that?

@_date: 2016-01-26 18:41:21
@_author: Robert J. Hansen 
@_subject: NSA Civil Liberties & Privacy Report 
The United States National Security Agency was required by Congress to
assemble a report on how they conduct electronic surveillance and the
measures taken to preserve the privacy of U.S. citizens.  It was
released last Friday, but I've yet to see it in the press.  It's very
dry reading, but there are some interesting nuggets within.

@_date: 2016-01-27 05:06:09
@_author: Robert J. Hansen 
@_subject: AW: AW: Key generation with GPGME and GnuPG hangs at 
For the record -- I used the code you provided with three minor changes:
(a) in lieu of CONFIG_DIR, I used nullptr, (b) I released the context at
the end of the code, and (c) I used C++14isms like nullptr, auto, and so
It compiled and ran just fine.  This makes me think the problem is in
GnuPG's entropy collection and/or key generation -- not your code.

@_date: 2016-01-27 08:25:59
@_author: Robert J. Hansen 
@_subject: AW: AW: AW: Key generation with GPGME and GnuPG hangs at 
I don't have a solution for you, but --
Use std::getline(), not >>.  >> terminates at the first whitespace
character; you want to read in a full line.
Don't do this.  C-style memory allocation is technically legal in C++,
but *strongly* advised against.  For that matter, you don't need to do
it at all: you can rely on the fact the string address-of-element
operator returns a char*.
Consider the following trivial C++14 program:
  int main()
    std::string foo { "Zaphod Beeblebrox for President\n" };
    char* bar { &foo[0] };
    for (size_t index = 0 ; index < foo.size() ; index += 1)
    {
        std::cout << *(bar + index);
    }
    return 0;

@_date: 2016-01-27 09:42:54
@_author: Robert J. Hansen 
@_subject: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
I cleaned your code up a bit and it works fine.
Compile with:
$ g++ foo.cc -O2 -o foo -std=c++11 `gpgme-config --cflags --libs`
$ clang++ foo.cc -O2 -o foo -std=c++11 `gpgme-config --cflags --libs`
    using std::string;
using std::cin;
using std::cout;
using std::cerr;
using std::getline;
static gpgme_error_t passphrase_cb(void *hook,
                                   const char *uid_hint,
                                   const char *passphrase_info,
                                   int prev_was_bad,
                                   int fd)
    string passphrase { "" };
    size_t written { 0 };
    cout << "Enter your passphrase: ";
    getline(cin, passphrase);
    if (passphrase.empty())
        return GPG_ERR_CANCELED;
    while (written < passphrase.size())
    {
        ssize_t bytesWritten = gpgme_io_write(fd,
            &passphrase[0] + written,
            passphrase.size() - written);
        if (bytesWritten == 0)
            break;
        written += bytesWritten;
    }
    gpgme_io_write(fd, "\n", 1);
    return GPG_ERR_NO_ERROR;
int main()
    int rv = -1;
    gpgme_ctx_t mContext;
    gpgme_engine_info_t info;
    gpgme_error_t error;
    bool contextInitialized { false };
    const char* def = " \n"
        " Key-Type: default \n"
        " Subkey-Type: default \n"
        " Name-Real: Joe Tester3 \n"
        " Name-Comment: with stupid passphrase \n"
        " Name-Email: joe3 at foo.bar \n"
        " Expire-Date: 0 \n"
        " Passphrase: abc \n"
        "  \n";
    gpgme_check_version(nullptr);
    error = gpgme_new(&mContext);
    if (GPG_ERR_NO_ERROR != gpgme_err_code(error))
    {
        cerr << "Couldn't create new context.\n";
        goto BAIL_OUT;
    }
    contextInitialized = true;
    error = gpgme_engine_check_version(GPGME_PROTOCOL_OpenPGP);
    if (GPG_ERR_NO_ERROR != gpgme_err_code(error))
    {
        cerr << "GPGME doesn't support OpenPGP.\n";
        goto BAIL_OUT;
    }
    error = gpgme_get_engine_info(&info);
    if (GPG_ERR_NO_ERROR != gpgme_err_code(error))
    {
        cerr << "Couldn't get engine information.\n";
        goto BAIL_OUT;
    }
    error = gpgme_ctx_set_engine_info(mContext,
                                      GPGME_PROTOCOL_OpenPGP,
                                      nullptr,
                                      nullptr);
    if (GPG_ERR_NO_ERROR != gpgme_err_code(error))
    {
        cerr << "Couldn't set engine to OpenPGP.\n";
        goto BAIL_OUT;
    }
    gpgme_set_passphrase_cb(mContext, passphrase_cb, nullptr);
    error = gpgme_op_genkey(mContext, def, nullptr, nullptr);
    if (GPG_ERR_INV_VALUE  == gpgme_err_code(error))
        cerr << "Value error\n";
    else if (GPG_ERR_NOT_SUPPORTED == gpgme_err_code(error))
        cerr << "Not supported error\n";
    else if (GPG_ERR_GENERAL  ==  gpgme_err_code(error))
        cerr << "general error\n";
    else if (GPG_ERR_NO_ERROR == gpgme_err_code(error))
    {
        gpgme_genkey_result_t res = gpgme_op_genkey_result(mContext);
        if (res->primary && res->sub)
        {
            rv = 0;
        }
    }
    if (contextInitialized) gpgme_release(mContext);
    return rv;

@_date: 2016-01-27 15:12:38
@_author: Robert J. Hansen 
@_subject: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
Without exception, *every* good programmer I know feels this way on a
regular basis.  Writing good software is hard and frustrating.  I've
been writing C++ since 1989, and I still frequently feel like an idiot.
 And I'm not one, and neither are you.
Don't give up!
So far we've cleared two major problems: the first was GnuPG taking ~15
minutes to generate a certificate, and the second was GPGME not working
with your callback.  Two major problems solved in two days.  Imagine
what we can get solved by the end of the week.
Programming is hard, but you're not stupid, and you're in a place where
you can get help.  Stick with it.  Things will be okay.

@_date: 2016-01-28 00:56:31
@_author: Robert J. Hansen 
@_subject: BAD signatures for GnuPG Stable 
MitM is theoretically possible, but unlikely: an attacker would have to
be both technically sophisticated and profoundly stupid.  It's far more
likely there's an innocuous explanation.
The MD5 and SHA256 digests of it are:
I just downloaded it and was able to verify Werner's signature.

@_date: 2016-01-28 03:45:00
@_author: Robert J. Hansen 
@_subject: AW: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
This is actually expected behavior.  See:
gpg-]agent is a hard requirement.  The only reason for keeping the
passphrase callback is for symmetric encryption."
Since you're not using symmetric encryption -- you're generating a
certificate -- your callback never gets called.

@_date: 2016-01-28 04:32:03
@_author: Robert J. Hansen 
@_subject: AW: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
Maybe less than you think!
Already been done for you.  The guys at the Guardian Project maintain
the official Java-GPGME bindings, *and* they're in production use on
There was some talk on this list a few months ago about getting some
important patches in there, but looking over the Git log they seem to
have not yet been applied.
Antony Prince was the guy updating Guardian Project's code.  See the
thread at:
According to Antony, you can grab his updates from:
It wasn't responding for me just now, though.  Antony, are you still
maintaining this?

@_date: 2016-01-28 04:34:09
@_author: Robert J. Hansen 
@_subject: AW: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
His webserver, though, is still going strong.  Try:

@_date: 2016-01-28 05:54:59
@_author: Robert J. Hansen 
@_subject: AW: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
The GnuPG developers have historically been unwilling to provide GPGME
under any terms except the GPL.  If you need an LGPLed GPGME, you're out
of luck.
If you can't/won't use GPLed code, we insist you not use GPGME.  If you
can, we're happy to continue helping you address your problems with it.

@_date: 2016-01-28 14:15:27
@_author: Robert J. Hansen 
@_subject: AW: Key generation with GPGME and GnuPG hangs at gpgme_op_genkey 
Really?  I thought GPGME had a dependency on libgpg-error, and the
COPYING file for that is clearly GPLv2.

@_date: 2016-01-30 05:27:48
@_author: Robert J. Hansen 
@_subject: Default configuration of GnuPG preferred chiphers and 
Let's tackle this.
So far so good.
Shouldn't CONFIG_DIR be dir?  I'm guessing you have CONFIG_DIR defined
somewhere else in your project and it's sending you off-course.  If
you've already tried gpgme_set_engine_info(GPGME_PROTOCOL_OpenPGP,
nullptr, dir) though, ignore me.  :)
Also, a C++ tip: never use NULL.  NULL is defined to be 0.  If you need
the numeric value zero, use 0; if you need a pointer to null, use
nullptr.  Wikibooks has a good article on this:
You don't need a gpg.conf file, but if you want one, check the GnuPG
FAQ.  There's a sample gpg.conf file in there that sets default cipher
preferences.  The lines you'll want to change/modify are

@_date: 2016-07-01 14:33:32
@_author: Robert J. Hansen 
@_subject: Accidentally used SHA1 
Definitely no to the first, and probably not to the second.  SHA-1 is
weak in a theoretical sense, but we're nowhere near seeing preimage
attacks on it, which is what would have to happen for your message to be
susceptible to forgery.
We advise against SHA-1 out of an abundance of caution, not because it's
broken.  The current attacks against SHA-1 are troubling but not
applicable to OpenPGP... *yet*.  It's that "yet" which causes us to
advise using better hash algorithms.  :)

@_date: 2016-07-15 16:52:57
@_author: Robert J. Hansen 
@_subject: Threefish cipher in GnuPG? 
RFC4880 has identifiers for the following symmetric ciphers:
Unencrypted, IDEA, 3DES, CAST5-128, Blowfish-128, AES in three key
sizes, and Twofish-256.  Supplemental RFCs (5581) have added identifiers
for Camellia in three key sizes.
If you can get the IETF to release an RFC for Threefish in OpenPGP, it's
very likely GnuPG will include Threefish support.  But without that,
it's very unlikely.

@_date: 2016-07-18 17:02:32
@_author: Robert J. Hansen 
@_subject: How to encrypt and sign with different keys 
ID-A is the certificate ID for A, ID-B is the certificate ID for B.
gpg --recipient ID-A --local-user B --encrypt --sign filename.txt
Please don't.  Doing things this way sort of destroys the purpose of a
passphrase.  Remove the passphrase from the certificate instead.

@_date: 2016-07-18 19:08:42
@_author: Robert J. Hansen 
@_subject: How to encrypt and sign with different keys 
Grr.  Typoed it.
gpg --recipient ID-A --local-user ID-B --encrypt --sign filename.txt

@_date: 2016-06-02 04:54:28
@_author: Robert J. Hansen 
@_subject: [Announcement] EasyGnuPG 2.1-0.9 
... which apparently has not fixed the "it will nuke your hard drive if
you have a certain environment variable set" problem I pointed out a
month ago.
I am not kidding.  Use at your own risk.

@_date: 2016-06-06 22:17:15
@_author: Robert J. Hansen 
@_subject: Older gpg version does not ask for passphrase 
This is howlingly bad advice.
If you don't trust your computer, do not use it for sensitive
communications.  It's that simple.

@_date: 2016-06-09 11:11:13
@_author: Robert J. Hansen 
@_subject: Installing gnupg 
GPGOSX provides a newer version of GnuPG than GPGTools does:

@_date: 2016-03-01 08:42:13
@_author: Robert J. Hansen 
@_subject: Retrieval of passphrase 
They're stored in two files: pubring.pkr and secring.skr.  Look for
those files.  Then import them into GnuPG.  :)

@_date: 2016-03-02 08:12:15
@_author: Robert J. Hansen 
@_subject: Question about getting started with PGP and smart cards 
Please, *don't* do this.  This is genuinely bad advice for someone who's
just getting started.
If you're just getting started, then use the defaults.  The defaults are
good ones; they were chosen for a reason.  You don't need to go through
this much more complicated key generation scheme.
Start using GnuPG and your smartcard with the defaults.  If, later on,
you decide that your specific needs require more extreme steps, you can
always take those steps then.

@_date: 2016-03-08 09:06:08
@_author: Robert J. Hansen 
@_subject: Remove photos from OpenPGP key in the keyservers 
You'll get the same answer here you got on Enigmail's list.  Photographs
on certificates are there for the long haul once they're uploaded to the
keyservers.  There is no practical way to remove them.

@_date: 2016-03-08 12:37:12
@_author: Robert J. Hansen 
@_subject: Remove photos from OpenPGP key in the keyservers 
They go down.
A few years ago Peter Pramberger, a keyserver operator in Austria, had a
request from someone who had uploaded a certificate but was now
asserting their right under EU data privacy directives to have their
personal information removed.  After consulting with legal counsel,
Peter realized the only step he could take would be to shut down his
keyserver.  Otherwise, he'd be hit with large per-day fines for failure
to comply with the user's demand.

@_date: 2016-03-21 18:39:33
@_author: Robert J. Hansen 
@_subject: Where is /usr/local/gnupg-2.1? 
Edgar reached out to me earlier, and I directed him here to this list in
the hopes that someone with more clue than me would be able to help.
Edgar, I'm not particularly up on GPG for OS X.  However:
GnuPG doesn't host an OS X build.  These are provided by either the
GPGTools group (providing GnuPG 2.0) or Patrick Brunschwig (providing
GnuPG 2.1).  I don't know which version of GnuPG you installed, but if
you got it from the GnuPG site then I'm pretty sure it wasn't what you
think it is.
Try downloading GnuPG 2.1 for OS X from Sourceforge instead:
Install that version of GnuPG.  Then open up a Terminal window (it's in
your Applications folder, in the Utilities subfolder, called Terminal).
 At a command prompt type:
ls /usr/local/gnupg-2.1
If you get back a listing of files in that directory, congratulations,
things are installed.  Try Enigmail again.  If that doesn't work, ask us
again and we'll keep on working the problem until it gets solved.  :)

@_date: 2016-03-21 23:31:56
@_author: Robert J. Hansen 
@_subject: Where is /usr/local/gnupg-2.1? 
And Fink, and... etc.  However, I'm omitting the ... let's call them
"comprehensive" solutions that allow you to install all manner of
things.  For standalone packages, it's either GPGTools or GPGOSX.

@_date: 2016-03-22 05:46:25
@_author: Robert J. Hansen 
@_subject: EasyGnuPG 
I think it's rather a bit more extreme than that.  I think if a user has
to fire GnuPG up from the command line *for anything*, something's gone
terribly wrong and we're in danger of losing a user.
No, no, I'm not saying GnuPG is bad for being a command-line
application.  But ask yourself how many users even know how to launch a
terminal, much less interact with one.  The number is shockingly low.
If you want to improve GnuPG's adoption rate, the best path forward
appears to be to target users who only know how to navigate GUI interfaces.
I don't think the EasyGnuPG authors have thought through their target
market.  It targets users who are comfortable enough to say "oh, I
should use the terminal for this!", but not comfortable enough to read a
manpage.  It's targeting a small subset of a small subset.

@_date: 2016-03-22 06:35:47
@_author: Robert J. Hansen 
@_subject: EasyGnuPG 
Oh, it's *hard*.  Look at how long it took Enigmail to get into a state
where it wasn't painful to use -- and there are still, today, parts
about it that give me the heebie-jeebies.  (Admittedly, I don't have a
good fix for it, but...)
User interface design is a hard subject.  It requires a much different
set of skills than software development, particularly cognitive
psychology.  Look at how much money Apple spends making user interfaces;
they're not throwing that much money at the problem because it's easy.  ;)

@_date: 2016-03-22 06:50:09
@_author: Robert J. Hansen 
@_subject: EasyGnuPG 
GnuPG is, believe it or not, a lot more like Apache than it is like
grep, cat, or wc.  When I start an Apache server it always asks me for
an SSL certificate password, it opens network connections, it spawns
daemons, it awaits connections... etc.
When I run "gpg2 --card-status", GnuPG has to spawn at least two
daemons: gpg-agent and scdaemon.  When I do a "--recv-key" I'm opening
HTTPS connections with the outside world.  When I do a signing
operation, gpg-agent has to connect with gpg2 and do complex handoffs
between them.
GnuPG isn't a single tool.  GnuPG is a complete platform, a whole
system, the same way that Apache or MySQL are.
Thinking that the gpg command-line tool is GnuPG is sort of like
thinking apachectl is Apache.  In both cases they're just tools that you
use to manipulate a far larger software ecosystem.

@_date: 2016-03-25 04:37:59
@_author: Robert J. Hansen 
@_subject: EasyGnuPG 
Preach it, Brother Ben.  And it's not just about formats, it's also
about targets, because each of these formats works best with different
targets.  Do we want to optimize for reading in a browser on a desktop?
 Read in a mobile browser on a smartphone?  What about reading on a
tablet or e-reader?  What about dead-tree editions?  How will we make it
accessible to the blind?  How...
And no matter which you choose there's always a sea of people eager to
tell you that you're doing it wrong.
It's very frustrating.

@_date: 2016-03-30 07:28:06
@_author: Robert J. Hansen 
@_subject: How do you think the FBI managed to get the clear text of the 
It's also worth noting that we'll likely discover what the exploit was
in the next few weeks.

@_date: 2016-03-30 09:41:47
@_author: Robert J. Hansen 
@_subject: What am I missing? 
As I might someday want to work in the field of digital forensics again,
I'm going to keep my mouth shut about this specific case.  But speaking
generally ...
Bruce Schneier is fond of saying that experience in breaking ciphers is
necessary before someone can write a good cipher.  The same applies to
forensics: without a background in how forensicists actually work, you
don't have good odds of figuring out how forensicists have recovered data.

@_date: 2016-03-30 09:46:12
@_author: Robert J. Hansen 
@_subject: What am I missing? 
I try not to get involved in conspiracy theories, but this one's just...
So, let's assume the FBI wanted a court ruling to force other companies
into compliance.  Which makes more sense?  To take on a
multibillion-dollar and much-beloved company like Apple and fight their
entire legal department to get a court precedent it can then use to
force smaller guys into compliance...
... or would they take on a small company that can't put up as much of a
legal fight and wouldn't get as much publicity?  And then, having won
that, go to Apple and say "we have precedent on our side"?
Your idea works only if you assume the FBI is pathologically stupid.

@_date: 2016-03-30 12:03:46
@_author: Robert J. Hansen 
@_subject: What am I missing? 
Because it assumes the FBI is stupid.  Conspiracy theories which require
the conspirators are morons are very rarely correct.
So they find one that's large enough to put up a fight but not large
enough to win.
Your conspiracy theory founders on the fact that Apple is *the largest*
and *most formidable* player in this space.  (Maybe Alphabet can compete
with them for that title.)  If they can win against Apple, they don't
need precedents to pull on others.  If they need precedents, they would
be for use against Apple.
Put this in terms of a computer RPG.  You take on the smallest monsters,
get level-ups and better weapons, take out the mini-boss, get equipment
from that fight, and ultimately use everything you acquired along the
way to fight the boss monster and win.
But if you're strong enough to take on the boss monster without any of
that stuff, why would you need it to take on the small guys?

@_date: 2016-03-30 14:08:18
@_author: Robert J. Hansen 
@_subject: What am I missing? 
Yes.  You and Johann seem to be of the opinion the FBI's petition was
unusual.  It wasn't, really, except in the fact that they were going
after someone who had the resources to fight it, and they were asking
for just a little bit more than Apple was willing to go along with.  But
the general idea, "use the All Writs Act to compel a company to bypass
security measures"?  Already been done.  The precedent already exists.
See, e.g.:
Johann's position: "The FBI wanted to get precedent on their side so
they could use it as a club against other smaller companies."
My position: "The FBI already had precedent on their side from clubbing
other smaller companies, and they decided they finally had enough legal
support to go after the big fish: Apple."
If you believe Johann's position, it requires you to believe two things:
Do I think the FBI had plans for how to capitalize on a court victory?
Sure.  But this particular idea, that the FBI wanted to get precedent on
their side to go after smaller players next, is ... it's crazy talk.
The Middle East in particular is full of small, weird mobile phone
manufacturers.  Looking over my notes of mobile manufacturers I've
worked with and starting at the top, there's Alcatel.  Lot of Motorola,
lot of Samsung, and at the end there's ZTE.
It is *not* hard to find atrocities on mobiles by small manufacturers.
And in the interests of not going into detail on the stuff of my
nightmares, I'm going to leave it at that.

@_date: 2016-03-30 14:59:29
@_author: Robert J. Hansen 
@_subject: What am I missing? 
iPhones put memory in tamper-resistant hardware.  I'll note that
tamper-resistant isn't tamper-proof.

@_date: 2016-03-30 15:57:02
@_author: Robert J. Hansen 
@_subject: What am I missing? 
That's the core point you're making, and I have no opinion on it.
The latter.  They believed they already had the precedents they needed;
otherwise they would've never brought the lawsuit.
How would I know?  What's public record is this: they hire a *lot* of
forensics nerds from the private sector and have long-standing
relationships with major forensics firms like Kyrus, Cellebrite, and
others.  I suspect it's fair to conclude they need support from the
private sector for a lot of their operations.
My apologies to Johan.  :)  Many years ago I was an exchange student in
Hildesheim, Germany.  My knowledge of German has atrophied considerably
in the last twenty years, but I suspect some lingering instinct there
compelled me to add the second 'n'.

@_date: 2016-03-30 16:04:28
@_author: Robert J. Hansen 
@_subject: What am I missing? 
I apologize; I meant no disrespect.
The particular case I cited was just one of many times the government
used the All Writs Act to compel a manufacturer to bypass security.  The
FBI's petition with respect to Apple attempted to use the All Writs Act
in a similar way.  I don't know if they used the specific case I cited
as precedent; they had many options to choose from.

@_date: 2016-05-04 18:09:07
@_author: Robert J. Hansen 
@_subject: Hundreds of RSA keys factored 
Not scary.  Not all that interesting, either.  It's also been discussed
on this list before.  This group claims to have access to my secret key.
 I posted a 256-bit random sequence and asked them to sign it with my
key.  Daniel Kahn Gillmor realized I'd made an oversight: it could be my
encryption key they'd broken.  He posted an encrypted message and
suggested they reveal the random string contained therein.
We have not heard back from them.
See, e.g.:
Until such time as they're able to verify that yes, they can forge
signatures or decrypt traffic, I think we should be suspicious of their

@_date: 2016-05-04 18:14:01
@_author: Robert J. Hansen 
@_subject: managing OpenPGP cards in batch mode? 
Dashamir, this list has very few rules.  I'm grateful for that, really.
One of the few rules that must be obeyed, though, is "we will not
advocate non-libre software or products here".
If you want to host your project on GitHub, go for it!  Nobody will
condemn you for it.  But describing GitHub as a superior product,
*without constructive criticism as to how to improve libre products*, is
against the rules.
"GitHub is so much better than the libre alternatives because it
supports two-factor authentication via Yubikey" is okay.  You're talking
about how a proprietary product is better, but you're also showing how
libre products can be improved.
"GitHub is better" is not okay.  You're just talking about how a
proprietary product is better.

@_date: 2016-05-04 20:09:42
@_author: Robert J. Hansen 
@_subject: Attempted extortion of Enigmail 
I just received this at my Enigmail address.  I'm posting this publicly
    "And that is called paying the Dane-geld;
       But we've proved it again and again,
     That if once you have paid him the Dane-geld
       You never get rid of the Dane!"
There's a 99% chance this threat is empty.  If a miracle happens and
these people are actually capable of making good on their threat, the
Enigmail web site/mailing lists may see some disruption -- but even if
so, we'll be back afterwards.  Don't fear.  :)
-------- Forwarded Message --------
FORWARD THIS MAIL TO WHOEVER IS IMPORTANT IN YOUR COMPANY AND CAN MAKE
We are Armada Collective.
Your network will be DDoS-ed starting 12:00 UTC on 08 May 2016 if you
don't pay protection fee - 10 Bitcoins @ [omitted]
If you don't pay by 12:00 UTC on 08 May 2016, attack will start, yours
service going down permanently price to stop will increase to 20 BTC and
will go up 10 BTC for every day of attack.
This is not a joke.
Our attacks are extremely powerful - sometimes over 1 Tbps per second.
And we pass CloudFlare and others remote protections! So, no cheap
protection will help.
Prevent it all with just 10 BTC @ [omitted]
Do not reply, we will not read. Pay and we will know its you. AND YOU
WILL NEVER AGAIN HEAR FROM US!
Bitcoin is anonymous, nobody will ever know you cooperated.

@_date: 2016-05-04 20:32:53
@_author: Robert J. Hansen 
@_subject: Attempted extortion of Enigmail 
Paul Applegate was kind enough to point me at:
TL;DR version: there's no evidence these people can back up their threat
with action, but they've still been making a ton of money from their
victims.  There are a lot of people who have paid out.

@_date: 2016-05-05 02:11:51
@_author: Robert J. Hansen 
@_subject: managing OpenPGP cards in batch mode? 
The Free Software Foundation requires them for all FSF-sponsored mailing
lists.  Thou Shalt Not Advocate Proprietary Software.  I wish I had a
link but I don't -- I was told about this Thou Shalt Not Advocate
Proprietary Software rule by a member of FSF, it wasn't something I saw
on a webpage.
I disagree with the FSF's rules, but so long as I'm on an FSF list I
abide by them.

@_date: 2016-05-06 17:13:30
@_author: Robert J. Hansen 
@_subject: GNUPG Issues. 
Probably not.  You're using a version of GnuPG that's 14 years old with
many known bugs.  Please upgrade to at least GnuPG 1.4.  If the problem
persists, we can probably help track down what's happening -- but our
ability to help with GnuPG 1.2.1 is pretty minimal.

@_date: 2016-05-08 00:53:42
@_author: Robert J. Hansen 
@_subject: Help needed - again 
I've been hoping someone else would tackle this, since I'm not
particularly well-versed in PGP for OS X.  I do run GnuPG on OS X,
though, so maybe I can be of some assistance.
I'm going to be posing a lot of questions here, but they're all
rhetorical -- they're meant to illuminate some of the open questions,
not things to respond to right away.  At the end of this message I'll
repeat these questions, and give steps that you can follow which will
help reach answers.
My laptop's 10.11 as well, so my experience should be applicable to yours.
Symantec sells a 10.x version which worked with OS X -- at least, a
previous version of OS X (I haven't checked past 10.8).  If GnuPG fails
to work out for you, you may want to consider that.  I don't advocate it
as a first option, though: let's see if we can resolve your problem.  :)
Which suite?  Several different groups package GnuPG for OS X.
Without knowing precisely what package you installed, my advice here
will have to be general.
PGP stores its public and secret keys in two files called "pubring.pkr"
and "secring.skr".  These are not stored on the Apple Keychain.  Did you
migrate the pubring.pkr and secring.skr files, or did you migrate the
Apple Keychain?
Do you recognize the certificate ID associated with this set?
Which certificate did you use to encrypt to yourself?  The one you found
which you believe was mistakenly created, or your certificate from 2003?
How do you know that he used your certificate to encrypt the message?
Oftentimes, when we can't decrypt traffic sent to us, it's because the
person sending us email used the wrong certificate.
How are you trying to import them?  And are you importing two files
named "pubring.pkr" and "secring.skr", or something else?
It's hard to say right now.  Let's try to get a firm handle on exactly
what's going on before we take any drastic steps.  :)
* Which GnuPG suite did you install?
This one should be fairly straightforward.  If you don't remember
offhand, look through your browser history.  :)
* Did you migrate an Apple Keychain, or a pubring.pkr/secring.skr file set?
Open a Terminal window (Applications/Utilities/Terminal.app).  At the
prompt, which I'm going to assume is "$" (although it probably won't
be), type:
$ find ~ -name "*ring.?kr"
When you respond to this email, include the output of this command,
please.  (You should, of course, first check to make sure you're not
revealing any confidential information.  This command is perfectly safe,
but you shouldn't take my word for it.)
* Is the certificate ID of the mystery certificate the same as that of
your normal certificate?
If you don't know your normal certificate's ID, then just answer "I
don't know".  It's okay.  :)
* Which certificate did you use to encrypt to yourself?
Take the email that you could read and save it (in encrypted form) to
your Desktop as "my_message.eml".  From Terminal.app, run this:
$ gpg -vvvv $HOME/Desktop/my_message.eml
You'll get a ton of output.  Copy-and-paste it into your response (after
checking to make sure there's nothing confidential in there).
* Which certificate did he use to encrypt his message to you?
Take the email that you couldn't read and save it to your Desktop as
"his_message.eml".  From Terminal.app, run this:
$ gpg -vvvv $HOME/Desktop/his_message.eml
Copy-and-paste that into your response.
... Do all this, and we should be much better able to help you figure
this thing out.  :)

@_date: 2016-05-08 03:56:56
@_author: Robert J. Hansen 
@_subject: OT egpg evaluation 
I think this code, in its current form, is genuinely dangerous, and
should not be recommended to anyone.
I didn't test it.  What I saw while reading your code gave me such the
heebie-jeebies I *won't* test it -- that's how big some of the bugs are.
Let's start with the very first function I inspected.  I chose this
function because it's short, simple, and hard to screw up:
gpg_send_keys() {
    is_true $SHARE || return
    gnupghome_setup
    gpg --keyserver "$KEYSERVER" --send-keys "$
    gnupghome_reset
Okay, so to know if we can send keys successfully we have to know how
gnupghome_setup works.  Let's look at that (in auxiliary.sh).  The first
few lines are:
gnupghome_setup() {
    # ...
    workdir_make
    # ...
So now we need to know if workdir_make (in platform.sh) can fail.
I found workdir_make in platform.sh.  Let's look at that one.
workdir_make() {
    [[ -z "$WORKDIR" ]] || return
    # ...
    trap workdir_clear INT TERM EXIT
Whereupon my brow began to arch and I began to get a bad, bad feeling.
You test if WORKDIR is set, but what if the user has already set WORKDIR
for something else?  What if the user has specified "export
WORKDIR=/path/to/my/doctoral/thesis" in their startup file?
This is not auspicious, but it might be understandable.  Does the
manpage warn the user about this?  Searching through the manpage, there
is no mention of WORKDIR.
Moving on: the trap line means that when the script receives INT, TERM,
or EXIT, workdir_clear gets called.  So let's look at that.
workdir_clear() {
    [[ -n "$WORKDIR" ]] || return
    [[ -d "$WORKDIR" ]] && find "$WORKDIR" -type f -exec shred {} +
    [[ -d "$WORKDIR" ]] && rm -rf "$WORKDIR"
    unset WORKDIR
And at that point I decided that I *will not* test this code.  If
WORKDIR is set in the user's environment before they start egpg, egpg
will shred and rm -rf $WORKDIR.  This could have terrifying consequences
for my doctoral thesis, and even worse if someone has WORKDIR set to
something like /.
I found a potentially *system-destroying bug* in literally the *very
first function I inspected*.  I've been very circumspect in my
criticisms until now, Dashamir, because I really want to encourage
people to hack on things.  But it took me under seven minutes to
discover a bug that will destroy a user's hard drive, and that is not
the sort of thing which inspires trust in your code.
Now do you understand why so many people here are getting upset about
you recommending this package for inclusion in live Debian images,
recommending it to new users, etc.?

@_date: 2016-05-08 04:48:27
@_author: Robert J. Hansen 
@_subject: OT egpg evaluation 
I have tried very hard to be polite in my criticisms, but you seem to be
under the unreasonable belief that politeness means I am amenable to
working with you on it.
I do not want to be involved with this in any way, except as someone who
has spoken out clearly about its flaws and your inability to write good
I believe that anyone who gets involved in this is taking terrible
chances with their reputation.
And this is the last I will say on the matter.

@_date: 2016-05-08 22:12:11
@_author: Robert J. Hansen 
@_subject: how to configure default sign key for particular user? 
It is wrong.  You should file a bug with the software package which is
mistakenly using UIDs as unique identifiers, as they are not.
Probably not.  The bug is in the software package you're using, not
GnuPG.  Adding new features to a package to remedy the brokenness of
another package is usually counterproductive.

@_date: 2016-05-11 22:12:57
@_author: Robert J. Hansen 
@_subject: Documentation on --with-colons output? 
Use --fixed-list-mode and look at the DETAILS file.

@_date: 2016-05-23 14:19:51
@_author: Robert J. Hansen 
@_subject: Encoding of user ID strings 
Is there any way to determine the encoding for a user ID string?
At first blush it appears the answer is "no, but most people use UTF-8."
 If so that's fine, but I'll have to silently discard a number of user
IDs that appear to be in foreign encodings or are garbled UTF-8.  I'd
prefer not to do this, so if there's some magic way of discovering the
intended encoding, I'd love to know about it.  :)

@_date: 2016-05-23 17:24:08
@_author: Robert J. Hansen 
@_subject: Encoding of user ID strings 
Or KOI-8R/Windows-1251.
Yeah, that's what I'm afraid of.  It's not valid UTF-8 encodings that
trouble me: it's having to deal with unknown encodings.

@_date: 2016-11-07 19:49:31
@_author: Robert J. Hansen 
@_subject: [admin] postings from non-subscribers 
Or when the list owners have specifically requested it be done, as is
the case here.
(Although my comment is first in that thread, I'm not the list owner.
wk chimes in a few comments into the thread: his opinion is the
authoritative one.)

@_date: 2016-11-17 16:28:28
@_author: Robert J. Hansen 
@_subject: Fresh OS installation 
Good question: there really isn't a good, standardized way to do this.
There are three different branches of GnuPG that are in common use (1.4,
2.0, 2.1), and it's possible that your old keys were set up on 1.4, your new
machine will be a 2.1 install, and so on.
The easiest way will not necessarily be the best way.  It will probably be
good enough for your purposes.
On your old machine:
Copy the tarfile to your new installation.  Place it in your home directory.
Then, on your new machine:
If you can list your secret keys and public keys OK, then you're probably
good to go.  Let us know if you have any problems.

@_date: 2016-11-18 14:24:20
@_author: Robert J. Hansen 
@_subject: gpgme 1.8 build failure 
It is, but it's in an  guard.  A small test program is able to use
quorra:~ rjh$ more test.cxx
 int main()
  const char* foo = "Foo";
  const char* bar = strdup(foo);
  return 0;
quorra:~ rjh$ clang++ -W -Wextra -std=c++11 test.cxx -o t
So given that a dummy program can see strdup, but a default ./configure
gpgme-1.8.0 can't, I suspect somewhere the configure script is setting a
custom  which is causing the build to fail.

@_date: 2016-11-22 14:52:04
@_author: Robert J. Hansen 
@_subject: Implications of a common private keys directory in 2.1 
architecture if
I concur.  This post is agreement, not dissent.
A user ID on a key makes an assertion: "The person named X is in control of
this certificate."  But in this architecture the end-user *isn't* in
control.  You remain in complete control of the private certificate.  You
have the power to completely undermine the system.  So for that reason, it
seems strange to me that your users would have their own private
certificates -- what, precisely, *could* they certify?
Likewise, a signature on a message makes an assertion: "This message went
through the hands of the person who controlled this certificate, and has not
been altered since then."  (Signatures do not prove authorship: that's a
common misconception.  If Alice sends Bob a signed message saying "I love
you", and Bob strips off the signature, places his own on it, and sends it
on to Charlene, Charlene will have a message Alice authored but which Bob
signed.  Charlene can prove the message went through Bob's hands, but she
cannot prove who wrote it.)
But if I'm on your system, and you're the one doing signatures for me, then
what does a signature which claims to be from me really attest?
Your scheme appears to deeply subvert the meaning of signatures and
certificate ownership.  This is crazy.  Maybe it's crazy enough to be a
breakthrough, but so far I'm not seeing it.

@_date: 2016-11-30 16:04:26
@_author: Robert J. Hansen 
@_subject: =?us-ascii?Q?RE:_Is_there_a_=22ground-up=22_explanation_of_PGP/GnuPG=3F?= 
============================== START ==============================
Yes: RFC 4880.  It's a highly technical guide to the entire OpenPGP
standard.  Once you have a basic understanding of what OpenPGP is and what
it provides as far as capabilities go, the next step is to learn about
packets, identifiers, octets, and more.

@_date: 2016-10-07 11:52:09
@_author: Robert J. Hansen 
@_subject: gnupg-for-java 
A while ago someone was trying to update gnupg-for-java to work with a more
modern environment.  Does anyone remember who did that work, or where I
could find it?  The version of gnupg-for-java I'm downloading from Guardian
Project's github account has dependencies on a lot of old stuff and I'm
having the devil's own time getting it built on macOS Sierra (Java 1.8,
GPGME 1.7).  Before I dig deeper into this to fix my problems and bring it
up to date, I thought I'd check and see if someone had already done so and
saved me the effort.  :)

@_date: 2016-10-17 09:48:13
@_author: Robert J. Hansen 
@_subject: regular update of all keys from a keyserver 
Not that I know of.  Some people will tell you that "an attacker listening
in on your network connection could discover your social graph!", but
honestly, if people are eavesdropping on my network connection they already
have so many ways to discover my social graph that one more just doesn't
matter.  This 'problem' has always struck me as much ado about nothing much.

@_date: 2016-09-03 21:05:28
@_author: Robert J. Hansen 
@_subject: I think that's a false dichotomy 
What does it mean for something to be a "fundamental" human right?  If
the question is meaningful, then there must be human rights that are
*not* fundamental.  So, what's a fundamental human right, and how is it
different from a normal human right?
Of course I believe privacy is a human right -- but I have no idea what
a "fundamental" human right is.
That was not a discussion I participated in, and not one I'm interested
in commenting on.
All rights exist in a constant balancing act with the equal rights of
others.  The question of, "so where do we strike the balance, and why?"
is one of the central animating questions of democracy.  There is
nothing unconditional in that balancing act.  It's highly conditional.
I own a rifle.  With that rifle, I can deprive you of your right to
live.  But so long as I keep the rifle in the closet and use it
according to law, you haven't been deprived of anything.  Likewise,
you're conflating the possibility of the authorities having ways to
subvert the privacy of innocent people with them actually doing so.
Now, of course I don't want the civil authorities to have
legislatively-mandated back doors into every system.  I don't think
that's an appropriate solution.  But I do believe the civil authorities
need appropriate mechanisms to pursue their lawful ends (and effective
oversight systems to ensure they're being used lawfully).
I'm transitioning out of my job, where for the last eight years I've
been doing research and development into digital forensics, mostly for
government customers.  After eight years I reached the point where I
began to think that every adult male should just have his clothes
surgically attached, and at that point it's time to move on to the next
I wish you were right.  I really, honestly, truly do.  But you're not.
Quite often, we're stuck literally *watching kids get exploited* and
there's nothing we can do about it except wait for the exploiter to make
a mistake.
The amateurs are easy to catch.  But there are some genuinely crafty
people in this world, and they practice astonishingly good operational
"Crack the hard drive in a clean room and go over it with an atomic
force microscope" is the kind of glib nonsense that gets bandied about
by people who have never struggled to get into a bunny suit (they never
have one in my size) or freaked out upon seeing the chemicals that get
used in the process (when you notice you're in the same room as a tank
of chlorine trifluoride, you begin thinking about a new career).

@_date: 2016-09-04 10:35:19
@_author: Robert J. Hansen 
@_subject: I think that's a false dichotomy 
There are two ways to interpret this, Peter, one which I think you
intended and one which people might infer you meant.  So I both don't
disagree, and I vehemently disagree.  :)
Yes, it would be a mistake for policy to be determined by those who've
been down in the mud with this crap.  It would be deeply antidemocratic,
in fact.  This decision belongs to the people, not to an extremely small
subset of the people with a (perhaps-understandably) skewed worldview.
But that doesn't mean policy shouldn't be *informed* by our experiences.
 Laws that are made without consultation with the people who ultimately
have to live under those laws (whether being subjected to them, or being
made to enforce them) tend to be either ineffective, draconian, or both.
True and false.  It's not necessarily a zero-sum game.  There are some
enhancements in liberty that also lead to enhancements in safety.  I
personally think we do ourselves a disservice when we think of it as a
zero-sum game.  I think we should be working as hard as we can to
enhance both simultaneously.

@_date: 2016-09-04 13:58:53
@_author: Robert J. Hansen 
@_subject: I think that's a false dichotomy 
Yes, democracy is a mess.  But "it belongs to the people" is a lot more
convenient than listing the complex, convoluted, and sometimes corrupt
machinery of government.  :)
I'd take this as evidence to support a claim that policy should also be
informed by the reasonable fears of privacy activists.  :)

@_date: 2016-09-04 18:45:39
@_author: Robert J. Hansen 
@_subject: I think that's a false dichotomy 
The Stockholm syndrome is half-pop science and half-real.  It stems from
a hostage situation in Stockholm where many of the hostages emotionally
bonded with their captors, and vice-versa, to the point where they
sympathized with each other.  Many of the hostages visited their captors
in prison in later years.
We see it in abused children, too -- kids have been known to commit
perjury in court in order to protect the parent they love, the parent
who has been abusing them.  It's incredibly sad when that happens: not
only is the kid a victim of abuse, but now the kid feels guilty for not
being able to protect Mom or Dad.
Colloquially, it means sympathy for the devil.  It means you're
empathizing with the people you're opposed to.  So what you've just done
is accused me of emotionally bonding with some of the worst evil in
Maybe you meant exactly what you said.  Maybe it was just an
extraordinary act of foolishness.  I don't much care.  Goodbye.  You've
been added to my killfile.  We won't be speaking again.

@_date: 2016-09-08 16:06:44
@_author: Robert J. Hansen 
@_subject: smart card no longer works 
The last I checked, Ubuntu's stock install did not include smartcard
drivers.  The good news is these can be easily installed via apt-get.  The
bad news is I don't remember what the package name is.  :(
Although I understand your frustration, it would be best to aim that
frustration at Ubuntu -- they're the ones who elected to not make smartcard
drivers part of the base OS image.

@_date: 2016-09-08 16:21:25
@_author: Robert J. Hansen 
@_subject: smart card no longer works 
is I
A little searching suggests that "sudo apt-get install gnupg-pkcs11-scd" is
the magic you need.  Hope this helps!

@_date: 2016-09-09 16:46:59
@_author: Robert J. Hansen 
@_subject: Keybase integration with GnuPG? 
(ObWarning: I am not a GnuPG developer.)
I think this is unlikely to occur.  Werner's spoken out pretty strongly
against the keybase.io model, which relies heavily on social media outlets
like Facebook to provide confidence in an identity.  However, few people in
the privacy community like or trust Facebook, which makes relying on
something like keybase.io problematic -- it looks too much like GnuPG is
encouraging the use of a platform (FB) that it's philosophically opposed to.
The counterargument is that keybase.io works just fine with several other
back-ends which are more respecting of privacy -- and if a user wishes to
trust FB, why should GnuPG refuse to honor that user's choice?

@_date: 2016-09-10 13:30:34
@_author: Robert J. Hansen 
@_subject: Excessive quoting (was: smart card no longer works) 
You quoted 34 lines there and added 5 lines -- meaning your total
message was about 13% content.  I hate acting line a netiquette cop, but
could you please reduce the amount of unnecessary quoting you do in the
future?  Thanks.  :)

@_date: 2016-09-10 14:45:00
@_author: Robert J. Hansen 
@_subject: Keybase integration with GnuPG? 
Ack, you're right -- I apologize to the keybase.io crowd.  Apparently I
got my wires crossed with "Facebook supports hosting your public key" to
"Facebook integrates with keybase.io".
Thank you for the correction!

@_date: 2016-09-10 17:00:40
@_author: Robert J. Hansen 
@_subject: Confusion about a statement in the FAQ 
It means there's a way to cryptographically protect most (but not all)
email headers, which foils many kinds of metadata analysis.
At present I don't think any email client supports this capability.
However, it's planned for Enigmail and other clients, and it's a good
reason to use PGP/MIME instead of inline.

@_date: 2016-09-10 17:20:39
@_author: Robert J. Hansen 
@_subject: Confusion about a statement in the FAQ 
Without knowing who you mean by "they", no, I can't.  Daiki Ueno is
planning on implementing it in Gnus.  Patrick Brunschwig has already
implemented limited support for it in Enigmail.  You'd have to ask them
how they plan to implement it.
If you mean "do I have a link to how the headers can be encrypted",
check ModernPGP:

@_date: 2016-09-10 19:36:27
@_author: Robert J. Hansen 
@_subject: Confusion about a statement in the FAQ 
Headers that are strictly required to process email are not armored.

@_date: 2016-09-10 21:13:23
@_author: Robert J. Hansen 
@_subject: Confusion about a statement in the FAQ 
I said "Enigmail and other clients" -- if you don't specify which
precise implementation you're interested in, I don't know which one you
want to know about.
There's limited support for it.  I wouldn't say it's ready for prime
time, but if you feel like living on the bleeding edge, go for it!  :)

@_date: 2016-09-12 00:49:43
@_author: Robert J. Hansen 
@_subject: Javascript and smartcard 
OpenPGP.js is not a GPGME binding.  It doesn't use GnuPG at all.

@_date: 2016-09-12 15:10:24
@_author: Robert J. Hansen 
@_subject: Why would I want S/MIME? 
There's a subtle point here.  The question isn't whether you're comfortable with GnuPG; the question is whether the people you want to send email to are comfortable with GnuPG.
I use S/MIME literally daily at work.  My co-workers like S/MIME because it's close to an "it just works" solution.  Few of my co-workers have been willing to learn GnuPG.

@_date: 2016-09-12 16:58:47
@_author: Robert J. Hansen 
@_subject: Why would I want S/MIME? 
Regulatory compliance.  For instance, if you were in the banking industry you'd be using S/MIME even if everyone preferred GnuPG -- S/MIME is part of several important banking standards, whereas GnuPG isn't.
That's the only compelling reason I can think of.

@_date: 2016-09-13 09:12:36
@_author: Robert J. Hansen 
@_subject: Why would I want S/MIME? 
No, they refuse to learn GnuPG.  If S/MIME was provided by GPGSM they'd
refuse to use S/MIME -- they want something that "just works," not
something they have to install and fiddle with.

@_date: 2016-09-14 15:01:47
@_author: Robert J. Hansen 
@_subject: What is a reliable way to backup/restore my keys and test? 
Welcome!  And your question is not trivial.
The following is the procedure I use on UNIX systems:
First, export all public certificates into a public keyring:
Second, export all secret certificates into a secret keyring:
Third, export ownertrust values and save those:
Fourth, copy all the *.conf files in ~/.gnupg into your current directory:
Fifth,  put these, and all your GnuPG .conf files, all into a single
Copy gpg-backup.txz to the new machine.  Once you've done that, uncompress
it on the new machine:
Import your secret certificates:
Import your public certificates:
Import your ownertrust values:
Make sure your ~/.gnupg directory exists.  If it doesn't, run gpg with no
arguments and hit Ctrl-C to break out of it.
Copy your .conf files into ~/.gnupg:
... And at that point you should be done.  This technique should work
regardless of whether you're migrating from 1.4 to 2.0, 1.4 to 2.1, 2.0 to
1.4, 2.0 to 2.1, 2.1 to 2.0, or 2.1 to 1.4.  No matter which you're doing,
you're covered.
It's a good idea to not copy the random_seed file.  PRNG states should not
be shared between computers.
Follow the above process and they will be.  Your private certificates were
exported, as were the trust assignments.
See the above process.

@_date: 2016-09-15 10:32:22
@_author: Robert J. Hansen 
@_subject: What is a reliable way to backup/restore my keys and test? 
I don't use local signatures myself, which is why my process skips those.
But I agree with Daniel that it's important to include those options if you
have local signatures on your keyring.

@_date: 2016-09-17 17:57:15
@_author: Robert J. Hansen 
@_subject: About encrypting files 
The data is encrypted with a symmetric cipher, then the symmetric key is
encrypted with the recipient's public key.
It's possible to do purely symmetric encryption, but this isn't the default.

@_date: 2016-09-29 08:52:40
@_author: Robert J. Hansen 
@_subject: Terminology - certificate or key ? 
"Certificate" is the correct word, but "key" has historically also been
used and has a tremendous amount of inertia behind it.
A certificate contains one or more keys as well as supporting metadata,
like user IDs, signatures, and so on.

@_date: 2016-09-29 11:17:55
@_author: Robert J. Hansen 
@_subject: Terminology - certificate or key ? 
For related reasons, GnuPG and PGP have different names for some of the same algorithms.  What GnuPG calls Elgamal, PGP calls Diffie-Hellman.  The correct name is Elgamal, but waybackwhen PGP had a licensing agreement with ... blanking on the company ... which offered them a reduction in licensing fees if they'd call it Diffie-Hellman instead.  PGP wanted the reduced licensing fees so they went along with the misnaming, and now the misnaming is so entrenched in the PGP community that it would be impractical for them to change the name, even though there's no longer a business case for calling it Diffie-Hellman.
Likewise with SHA-x.  The family of modern SHAs is called SHA-2, and specific hashes within SHA-2 are called SHA-224, SHA-256, SHA-384, SHA-512, SHA-512/224, and SHA-512/256.  (GnuPG implements -224, -256, -384, and -512; it does not implement -512/224 or -512/256.)  GnuPG calls these hashes by their correct NIST nomenclature.  PGP insists on calling them "SHA-2-256", "SHA-2-512", and so on.
I have to admit to being extremely annoyed with the state of the language we use.  OpenPGP is hard enough to learn without having to be confused by multiple names for the same algorithms, confusing usage of "certificate", "key", and "Key", and every other bit of linguistic tomfoolery we seem to have accumulated.

@_date: 2016-09-30 08:46:11
@_author: Robert J. Hansen 
@_subject: Terminology - certificate or key ? 
Where can I find this usage documented?  In almost 25 years in the PGP
community I've heard the word "key" used >95% of the time, "certificate"
<5% of the time, and this is literally the first time I've heard the
word "keyblock".
Also see:
All of these are well-respected authorities (Gnutls, GnuPG, PGP
Corporation, and the IETF) using the certificate terminology.
I have been unable to find reputable uses of "keyblock" in a five-minute
Google search.  If this is the officially approved language, could you
please point me to where it's documented?

@_date: 2016-09-30 10:24:55
@_author: Robert J. Hansen 
@_subject: Terminology - certificate or key ? 
You are technically correct (the best kind of correct!) [1] -- no, wait!  That's "key block", not "keyblock"!
I'm more technically correct!  I win!  :)
In all seriousness, the only context in which I've seen "key block" has been the beginning of an armored certificate, and I've literally never seen "keyblock", nor have I ever heard anyone call their certificate a "keyblock" or "key block" outside of the narrow context of "look for -----BEGIN PGP PUBLIC KEY BLOCK-----".
[1]

@_date: 2017-04-01 04:57:04
@_author: Robert J. Hansen 
@_subject: Unicode and --with-colons 
C:\Users\Robert J. Hansen\Desktop> gpg --fixed-list-mode --with-colons
--list-key 0x3ADBFA6D00A1E6FE
[... trimmed ...]
H??gelsch??fer :
"That's an odd encoding," I said to myself.  "It must be UTF-8 presented
as ASCII or Windows-1252.  Let's look, shall we?"
C:\Users\Robert J. Hansen\Desktop> gpg --fixed-list-mode --with-colons
--list-key 0x3ADBFA6D00A1E6FE > ludwig.asc
C:\Users\Robert J. Hansen\Desktop> python
Python 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 08:06:12) [MSC v.1900 64
bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
...     bytes = fh.read()
Weirder and weirder.  GnuPG is outputting data in UTF-16LE, complete
with a correct byte-order mark... but is first taking what is
(apparently) the UTF-8 of Ludwig's name, giving each byte a null pair
byte, and calling it UTF-16.
Looking at the output from just a plain --list-key, it appears correct:
So -- what's the canonically approved way to convert this mangled form
back into Unicode?  Is this mangled form a deliberate design choice, or
is this a bug?

@_date: 2017-04-01 16:08:13
@_author: Robert J. Hansen 
@_subject: some beginner questions 
Move on.  It's okay, everybody makes this mistake in the beginning.  :)
(My opinion on this used to be 100% orthodox; in the last few years I've
seen it become heterodox.  The cool kids are all about TOFU today; I
think TOFU borders on crazy.  So be warned, this opinion is ... stodgy,
by present standards.)
If I'm corresponding with someone, I ask if they use OpenPGP; if they
do, I arrange for an out-of-band key verification.  I also have my
fingerprint on my business card, so that if I meet someone face-to-face
it makes it easy as can be to do a key verification: here's my driver's
license, here's my business card, you get to verify I'm really Rob
Hansen and you have my fingerprint given to you directly by me.
Please read the FAQ.  Question 8.1 is directly applicable.
The internet is full of people who will tell you "the true secret" to
"creating the perfect key".  The reality is, unless you know exactly
what changes you're making and why you need to make them, you will be
far better served with the defaults.

@_date: 2017-04-02 19:12:38
@_author: Robert J. Hansen 
@_subject: Complexities on faking one signature 
The difficulty of this is dependent on the length of the asymmetric key.
 NIST's guidance is that cracking a 1024-bit key is about 2**80 work, a
2048-bit key is about 2**112 work, and a 3072-bit key is about 2**128 work.
I'm not sure what you mean here; that's not how signatures work.
Signatures work by computing a digest over data and encrypting that with
the private key.  Since you lack the private key, you can't generate
What you could do instead is look at an earlier message your target
signed, get the digest of that, and generate new messages until you
created one with an identical digest.  The difficulty of this will
depend on your target's signature:
DSA-1024: 2**159 work
DSA-2048: 2**223 work
DSA-3072: 2**255 work
RSA: varies by user prefs, but unlikely to be under 2**159
You'll notice the work to break the hash is almost exactly the square of
the work to break the key.  This is not an accident.  :)

@_date: 2017-04-03 21:32:59
@_author: Robert J. Hansen 
@_subject: Complexities on faking one signature 
Unimaginably harder to brute-force a sig.
Since RSA is deterministic (at least, na?ve RSA is), a sig is done on a
digest (of let's say size 256 bits) and there are 2**256 different valid
outputs.  But the signature length itself is thousands of bits, for
2**thousands of possibilities.  So the per-attempt likelihood of finding
one of the 2**256 valid signatures out of a signature of 2**thousands of
bits is likelihood is 2**(256 - thousands).
2**-2000 is so close to zero as makes no difference whatsoever.

@_date: 2017-04-03 21:37:56
@_author: Robert J. Hansen 
@_subject: Smart card 
Smartcards are not out of vogue for people who need them.  Those who
don't will be better served by avoiding them.  Do you have a need for
one?  If so, the kernelconcepts card works well, as do Yubikeys.

@_date: 2017-04-03 22:27:12
@_author: Robert J. Hansen 
@_subject: Smart card 
Imagine we're in a restaurant and you ask me, "Should I order the
pizza?"  Well, beats heck out of me.  I don't know you from Adam, I
don't know your personal tastes, I don't even know if you're hungry.  So
I shrug and say, "Sure, if you like pizza."  You may think that's a
useless answer, but the question was no champ, either.
Should you get a smartcard?  Sure, if you need one.  But I don't know
how you expect me, or anyone else here, to be able to give a more
precise answer than that.  Only you can make those decisions about your
local security policy.
Smartcards haven't fallen out of vogue, but they're also not useful to
everyone.  Examine your needs, see if a smartcard can help satisfy those
needs, and then make your decision.  If you decide to go that route
there are plenty of people here who can help.

@_date: 2017-04-04 08:37:16
@_author: Robert J. Hansen 
@_subject: Smart card 
Completely non-snarky: this is an important realization to make and
we're happy to help with this.  Getting this answered will go a long way
towards answering your "should I get a smartcard?" question.
Again, completely non-snarky: this is the most common newbie mistake
there is.  The name of the game is not risk minimization -- it's risk
They can be.  They can also be right royal pains in the ass, too.  I
have a kernelconcepts card and use it to store my secret key, since my
laptop is a theft target.  Whenever I receive an encrypted email I have
to rummage in my laptop bag for my card reader, find it, plug it in, get
my wallet, rifle through it for the card, plug it into the reader,
discover gpg-agent got wedged, kill gpg-agent, try to decrypt the
message, enter my PIN, and finally get my message.
It's annoying as hell.  OTOH, I deal with some high-value secrets.  If I
was dealing with lower-value secrets I probably wouldn't bother.
I used to work in computer forensics.  GnuPG's symmetric encryption is
probably not working as well for you as you think, since it doesn't
remove traces of plaintext from the hard drive.  (In its defense, it
really can't.)
Use an encrypted file system instead.
As in most of life, this is the big trick.  :)

@_date: 2017-04-08 04:29:58
@_author: Robert J. Hansen 
@_subject: Smart card 
A funny but completely accurate way to put it:
When your private key is on your laptop, you never put it through the
wash by accident.
(I can tell you from personal experience most smartcards handle being
washed just fine, but the static charges they're exposed to in the dryer
will often fry them.)
Once you make a smartcard into a credit card, or a dongle you hang off
your keychain, you open yourself up to some very interesting failure
modes -- many of which you won't see coming.  For instance, I once tried
to pay for a hotel with my kernelconcepts card, because it was located
adjacent to my credit card and I pulled it out by accident.

@_date: 2017-04-08 22:20:47
@_author: Robert J. Hansen 
@_subject: Smart card 
This is not true, not for any sensible definition of 'secure'.
My passphrase is literally 16 random bytes read from /dev/random, base64
encoded, to produce a passphrase of 128 bits strength.  If you'll pay to
run the ad, I'll happily publish my private key in the newspaper of your
choice.  Yes, I'm serious.
If your private key is at risk of being seen by your adversaries then
it's extremely important to have a good passphrase.  But so long as you
do, your private key is safe.

@_date: 2017-04-09 07:51:09
@_author: Robert J. Hansen 
@_subject: Smart card 
Jim Mickens' essay, "This World Of Ours", ought be required reading for
anyone talking seriously about scraping memory pages:
"My point is that security people need to get their priorities straight.
The 'threat model' section of a security paper resembles the script for
a telenovela that was written by a paranoid schizophrenic: there are
elaborate narratives and grand conspiracy theories, and there are heroes
and villains with fantastic (yet oddly constrained) powers that
necessitate a grinding battle of emotional and technical attrition. In
the real world, threat models are much simpler. Basically, you're either
dealing with Mossad or not-Mossad. If your adversary is not-Mossad, then
you?ll probably be fine if you pick a good password and don?t respond to
emails from ChEaPestPAiNPi11s at virus-basket.biz.ru. If your adversary is
the Mossad, YOU'RE GONNA DIE AND THERE?S NOTHING THAT YOU CAN DO ABOUT
IT. The Mossad is not intimidated by the fact that you employ If the Mossad wants your data, they?re going to use a drone to replace
your cellphone with a piece of uranium that's shaped like a cellphone,
and when you die of tumors filled with tumors, they?re going to hold a
press conference and say 'It wasn't us' as they wear t-shirts that say
'IT WAS DEFINITELY US,' and then they?re going to buy all of your stuff
at your estate sale so that they can directly look at the photos of your
vacation instead of reading your insipid emails about them. In summary,
https:// and two dollars will get you a bus ticket to nowhere."
Once you assume that your opponent is specifically targeting you with
malware capable of sophisticated memory forensics, you're screwed.
Pinning your hopes on a smartcard is the worst kind of crypto-fetishism.
 You can't proudly hold it up and say "ah ha, but *now* I am safe from
Tier-1 actors!"  It doesn't work that way.
Smartcards are a great technology for a certain part of the problem
domain, but they aren't magical crypto fairy dust.
Mickens' full essay, BTW:

@_date: 2017-04-09 11:26:39
@_author: Robert J. Hansen 
@_subject: Smart card 
It never was true -- for decades the French DGSE surveilled on Airbus's
competitors, for instance.
But the point still stands.  The attacks you're talking about are not
automated.  They require significant per-target involvement from
highly-skilled technical talent, and once you posit you're being
targeted by people who have both technical talent and a budget you're
far outside the realm where a smartcard can save you.
There are definitely domains where smartcards make sense.  I use a
smartcard not just because of high-value secrets, but because I use
several different computers.  A smartcard means I have one copy of my
private key that I can safely share between rigs, without the risks that
come from each machine having a copy, putting my private key on an NFS
share, storing it on a USB drive, or any of the other ways to tackle it.

@_date: 2017-04-09 13:02:39
@_author: Robert J. Hansen 
@_subject: Smart card 
I've seen some truly scary malware, and I'm not seeing the level of
sophistication you're talking about except from nation-state actors.
GnuPG certificates aren't targeted by mass-market malware because there
aren't enough GnuPG users to be worth targeting.  Malware that targets
online banking, though ... that's worth constructing specialized malware
to target.
It is.  Those aren't the risks I'm talking about.
Why don't I want to store the private key on multiple computers?
Because a good rule of thumb in a forensics lab is "store the minimum
personal data possible on your systems".
Why don't I want an NFS mount?  Because these computers need to be isolated.
Why don't I want to use a USB drive?  Because USB is a critical vector
for malware, and as such USB devices are closely controlled and monitored.
Etc., etc.  Standard fare for a forensics lab.

@_date: 2017-04-08 04:36:57
@_author: Robert J. Hansen 
@_subject: GPA bug report 
(Apologies for the HTML mail; it seems to be the best way to submit a
screenshot, though.)
The last two subkeys on this list are elliptical curves, not RSA.  GPA
is mis-reporting them.

@_date: 2017-04-09 16:16:54
@_author: Robert J. Hansen 
@_subject: Smart card 
I've been in the PGP community for 25 years.  I've been the official
GnuPG FAQ maintainer for a few years, which has led to me getting a
steady stream of questions from people who mistakenly (though
understandably) think I'm GnuPG's helpdesk.  I've been part of
Enigmail's official help team for about a decade.  For almost fifteen
years I've been involved in training people in how to practice good
communications security in hostile environments: journalists, NGO
workers, and even union organizers.  That's my background which is
informing my answer.  I'm not presenting it to argue that I'm right, but
so you may have an estimate of how I may be biased.
The average GnuPG user is not a technical expert.  They come to GnuPG
from somewhere else as the result of an awareness of how their
communications may be at risk.  When I addressed a crowd of United
Electricalworkers employees, for instance, they were concerned employers
might be snooping on private union communications.
The average GnuPG user runs Windows.
The average GnuPG user neither knows nor cares what MIME is.
The average GnuPG user has a specific threat model in mind--"I'm worried
my employer might be reading my union-related email which gets sent to
my corporate account"--not diffuse, unfocused ideas about hypothetical
malware that might be targeting certificates.
The average GnuPG user understands the threat actor ("my employer", "the
secret police", "a competing political party"), but has a poor
understanding of the actor's capabilities or how to defend against them.
The average GnuPG user uses GnuPG as a last, desperate, final resort.
If they had a better avenue, they'd take it.  (E.g., I pointed out to
United Electricalworkers they could sign up for free webmail accounts
and their union emails would no longer be on their employers' email
The average GnuPG user is scared, and rightly so.  This system is so
eye-poppingly user-unfriendly that the userbase largely consists of two
groups: people who have threats serious enough to warrant dealing with
such a tool, and people who are paranoid and think they do.
The average GnuPG user finds the system to be at the outer limit of
their technical skill.
The average GnuPG user is deeply interested in doing things right, but
has no idea how to evaluate what's right.  As a result they often get
tied up in cryptographic technofetishism fed to them by others, and
getting them to drop this technofetishism is *really really hard*.
After all, their commitment to 16384-bit RSA keys has kept them safe, right?
Two years ago there was a Spanish digital civil liberties convention
called Circumvention.  (They've since changed their name to the Internet
Freedom Festival.)  They thought I'd be a good resource for them, so
they flew me to Valencia for a week.  During that week I met up with
literally dozens of technical trainers -- people who after the
convention were going home to places like Syria, Iran, and Zimbabwe,
where they'd be meeting with local journalists and teaching them how to
safely communicate with the West.
I had heartbreaking conversations with them.  Without exception, every
one of the trainers had firsthand knowledge of people who critically
needed communications security, but who found GnuPG (and Enigmail) to be
too difficult to use.  Without exception, every one of the trainers
wanted GnuPG (and Enigmail) to be made simpler.
Simplicity is literally a matter of life and death.
So when someone asks about smartcards, please, let's keep the discussion
focused on whether they need a smartcard.  Because the instant people
think smartcards are universally necessary, we lose.

@_date: 2017-04-09 16:44:03
@_author: Robert J. Hansen 
@_subject: Smart card 
I thoroughly disagree.  This is not an article filled with actual
security advice.  It was published in USENIX's humor column, after all.
It is straight-up satire of tendencies that need satirizing.  Satire
deeply grounded in truth, yes, but I shudder to think of the foolishness
required to mistake this satire for actual security advice.
Satire is an excellent weapon against folly, and the idea that everyone
should use smartcards is exactly the kind of folly Mickens is railing
No, realistic.  At that point you've got an attacker who is highly
motivated against you specifically, who has access to technical experts,
who has a significant operating budget.
"You're screwed" might be understating things.
You're making my case for me.
I've always been amused by how often people think that if their keys are
safe, their communications are, too.
"I'm worried a well-funded attacker might root my laptop, plant a
keylogger, and get my passphrase and my secret key, and then be able to
read my email.  I use smartcards to prevent this attack."
Apparently, the prospect of a well-funded attacker rooting your laptop,
planting a trojaned GnuPG with a compromised PRNG, and being able to
read all your traffic at their leisure, though, you're just fine with that.
Once you assume the attacker can root your machine, *you* *are*
*screwed*.  There is no way around it.  The universe of malfeasance the
attacker can throw at you is effectively unlimited.  And you're
seriously saying, "but at least my keys are safe!"?
Give me a break.

@_date: 2017-04-09 18:27:52
@_author: Robert J. Hansen 
@_subject: Smart card 
There's a great quote from _Zero Effect_ that springs to mind.  "There
aren't any good guys!  You realize that, don't you?  I mean, there
aren't evil guys, and innocent guys, and -- it's just -- it's just a
bunch of guys!"
There are very few good practices in communications security, and very
few bad practices.  Mostly, you have to pick from a very mixed bag of
That it is, and so long as it's fun I advise you to knock yourself out!
Suggest questions to be addressed in the FAQ and I'll take a stab.  Our
FAQ needs reorganization -- badly -- but the answers are pretty good, I
think.  Wikipedia actually cites us in a couple of crypto articles.
So you want someone who isn't just a whiz in cryptogeekery, but has a
detailed knowledge of the OpenPGP spec and how GnuPG implements it,
*and* is a skilled technical writer, *and* has the free time to commit
(conservatively speaking) hundreds of hours of free labor?
You're looking for a unicorn -- but I encourage you to keep looking.  :)

@_date: 2017-04-09 23:25:06
@_author: Robert J. Hansen 
@_subject: Smart card 
If you send or receive sensitive communications from a compromised
endpoint, you're screwed.  The smartcard will not save you.  It can't.
When I hear people talk about how the smartcard will keep their keys
safe even after a system compromise, I hear that as being like a
survivalist talking about how great it is his tiny bomb shelter will
keep his seeds safe after a direct hit from a nuclear bomb.  Great, I'm
very happy for you, but you're giving *terrible* advice to people who
are worried about the bomb dropping.  Even encouraging them to move
somewhere that's not a high-priority target for a nuclear strike, as
impractical as that advice is, is better.
If your threat model includes Tier-1 actors, you're gonna get Mossaded.
You.  Cannot.  Win.
Therefore, any threat model that assumes you're the target of Tier-1
interest is inherently -- I'll say it again -- screwed.  Once you become
a target of Tier-1 interest it's all over.
Don't come to their attention.  And don't mislead newbies by making them
think they can win against Tier-1s, either.
You seem to think that your bomb shelter surrounded by five hundred
meters of radioactive fused glass is somehow a win.  After all, your
keys are safe, right?
Preserve the security of your endpoint system.  Nothing else will do.

@_date: 2017-04-09 23:33:59
@_author: Robert J. Hansen 
@_subject: What could make GnuPG + Enigmail "easier"? 
Better grab your reading glasses.  :)  Academic computer science
literature is full of papers researching this subject.  John Clizbe and
I (speaking of, John's been gone for some time; I hope he returns soon)
keep a curated list of some good ones.
Gaw, S., Felten, E. W., and Fernandez-Kelly, P. 2006.  Secrecy,
flagging, and paranoia: adoption criteria in encrypted email.  In
_Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems_ (Montreal, Quebec, Canada, April 22 - 27, 2006).  R. Grinter,
T. Rodden, P. Aoki, E. Cutrell, R. Jeffries, and G. Olson, Eds. CHI '06.
ACM, New York, NY, 591-600. DOI=
  Available at:
Garfinkel, S. L., Margrave, D., Schiller, J. I., Nordlander, E., and
Miller, R. C. 2005. How to make secure email easier to use. In
_Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems_ (Portland, Oregon, USA, April 02 - 07, 2005).  CHI '05. ACM,
New York, NY, 701-710.  DOI= Available at: Steve Sheng, Levi Broderick, Colleen Alison Koranda, and Jeremy J.
Hyland.  Why Johnny Still Can?t Encrypt: Evaluating the Usability of
Email Encryption Software. Poster session, 2006 _Symposium On Usable
Privacy and Security_, Pittsburgh, PA, July 2006.
Alma Whitten and J.D. Tygar. Why Johnny Can?t Encrypt: A Usability
Evaluation of PGP 5.0. In _Proceedings of the 8th USENIX Security
Symposium_, Washington, DC, August 1999. Views, reactions and impact of digitally-signed mail in e-commerce.
Garfinkel, Schiller, Nordlander, Margrave and Miller.  Originally
published somewhere in _Lecture Notes in Computer Science_, but I got
mine from:
Usability of Security: A Case Study. Alma Whitten and J. D. Tygar.
Carnegie Mellon University Computer Science technical report
CMU-CS-98-155, December 1998.

@_date: 2017-04-10 03:11:14
@_author: Robert J. Hansen 
@_subject: What could make GnuPG + Enigmail "easier"? 
[good points snipped]
Shirley Gaw's 2006 paper addresses these factors dead-on.
It's worth reading.  A major additional factor Gaw found inhibiting
adoption was the fear of being seen as paranoid.  The following excerpt
talks about various employees (all under pseudonyms) at an
environmental-action NGO which participated in a variety of illegal
direct action campaigns.  You'd think these people would view paranoia
as a good thing, but the reality was quite different.
A couple of passages are _underlined_ to reflect italics in the original
"Many of the employees interviewed at [this NGO] had limits to their
willingness to be more secure. In fact, moving beyond that limit was
seen as abnormal or paranoid. While Woodward was especially vigilant,
even the technical support staff admitted he might be excessively
protective. Was the effort justified? Was it reasonable precaution?
Abe explained how someone could 'go overboard' when he described how a
representative of the PGP Corporation visited [the NGO]. Instead of a
typical password authentication, the representative took off his
necklace and used a removable flash drive that held his private key. The
demonstration discouraged Abe:
'It was too over-the-top and definitely too complicated... it was like a
He saw the presenter as paranoid. He went on to say:
'Yeah, I admire him because he comes in and puts his passphrase ...
every single day, three times a day, so that's very dedicated to his
stuff. He must either be very scared or very motivated.'
He was not sure whether this vigilance was justified. In fact, he
associated it with being fearful, perhaps irrationally fearful.
Abe reiterated this when asked to speculate on why a colleague sent
every e-mail message encrypted. He figured this man has an automated
system for encrypting e-mail 'or he's nuts.'
When Sandra was asked why she said her e-mail communications were not
anything people were 'dying to get their hands on,' she explained:
'I'm not paranoid enough to think the CIA is monitoring my emails or
anything to that effect.'
Not only was encrypting messages excessive for someone who had no
secrets, it was _paranoid_ _behavior_ to assume anyone would be
interested in eavesdropping on her communications.
Jenny also thought it was abnormal to encrypt non-secret information.
When the interviewer abstractly explained that people in security
suggest all users encrypt all messages, Jenny was baffled:
'So you're saying that ... people should just--even _normal_ people?
That you're sending e-mail to ... your mom, like "hey, things are going
...", that you should encrypt your e-mail?  That people should do all
Jenny emphasizes 'normal people.' _Normal_ _people_ wouldn't encrypt
normal messages."

@_date: 2017-04-10 19:22:56
@_author: Robert J. Hansen 
@_subject: I never quite got my answer, 
Add these two lines to your gpg.conf file:
cert-digest SHA512
default-preference-list AES256 SHA512 SHA256 BZIP2 ZIP ZLIB
Then generate your new ECC certificate.

@_date: 2017-04-10 21:54:23
@_author: Robert J. Hansen 
@_subject: where do you find gpg.conf on debian 8 or 9? 
It's not an error if it doesn't exist.  A lot of people get by just fine
without one.  But yes, $HOME/.gnupg is the customary location.
If you don't have one, create a new text file in that directory.

@_date: 2017-04-11 07:21:59
@_author: Robert J. Hansen 
@_subject: Smart card 
I'm going to give two answers here, one human-readable and one which
will require a fairly high level of technical knowledge.
You haven't heard me talk about intelligence agencies for a simple
reason: the capabilities of private sector groups match or exceed those
of nation-states.  For instance, Google's been defending their networks
against sophisticated Chinese attacks for so long that it wouldn't
surprise me one bit if Google had an in-house team capable of playing
the game with anyone.
That said: effective defense is built upon knowledge.  Knowledge informs
your threat model and helps guide your responses.  Extremely serious
attackers will be single-mindedly obsessed with denying you this
knowledge.  That's part of what makes defending against them so
difficult: if you don't know you're under attack, you're extremely
ill-equipped to defend.
I am not especially worried about so-called "advanced persistent
threats".  When I hear someone say their IDS is going off hundreds of
times a day with IP addresses resolving to China, I yawn.  That's not an
advanced threat.  (Persistent, maybe.  Not advanced.)  An advanced
threat is one that doesn't set off the IDS, one you don't see coming,
one you don't get the opportunity to stage active measures against.
Now for the technically challenging stuff: Lockheed Martin wrote a
*fantastic* whitepaper on defending against advanced threats.
"Intelligence-Driven Computer Network Defense Informed by Analysis of
Adversary Campaigns and Intrusion Kill Chains".  Read it.
  My explicit assumptions for such a

@_date: 2017-04-18 14:46:26
@_author: Robert J. Hansen 
@_subject: Registry entries 
(Default), (value not set)
Install directory, [whatever dir you installed it to]
Both are REG_SZs.  If you're installing it on x64, you can expect to see
this in HKLM\SOFTWARE\WOW6432Node\GnuPG, just as any other 32-bit code

@_date: 2017-04-22 13:01:12
@_author: Robert J. Hansen 
@_subject: "general purpose OS is fundamentally inadequate for trusted 
Not really.  What's the trusted device in the system?  It's still the
desktop PC.  A compromise there leads to so many different and
catastrophic attacks that it needs to be called a game-over.
No.  The game-over condition without a smartcard is, "my computer gets
compromised by an attacker."  The game-over condition with a smartcard
is, "my computer gets compromised by an attacker."
There are *some* use cases where smart cards lead to better risk
mitigation.  But as a general rule, no, smart cards are not ready for
prime time.

@_date: 2017-04-22 13:06:02
@_author: Robert J. Hansen 
@_subject: "general purpose OS is fundamentally inadequate for trusted 
[lots of good stuff I completely agree with snipped]
I only use my full name and middle initial to prevent confusion with
Robert "rsnake" Hansen.  He and I both spoke at Black Hat a few years
ago, we're both in the computer security field, and so on.  "Robert J.
Hansen" is pretty unambiguously me; "Robert Hansen" is usually him.
But in person or outside of professional contexts, it's just Rob.  :)

@_date: 2017-04-23 07:25:56
@_author: Robert J. Hansen 
@_subject: yes, Virginia... 
This is the kind of "advice" we can do without.  Whether encrypted email
is of use to someone depends entirely on their threat model.
Years ago, my best friend was engaged to be married.  He and his fianc?e
(now wife) were discussing wedding and honeymoon plans via email, up
until she walked into the IT department at work and found the sysadmin
reading her email aloud to someone else for purposes of gossip and
entertainment.  Emily was horrified; Doug was red with rage.
Do you mean to tell me OpenPGP on internet-connected computers wouldn't
have been useful to them?
Some people have major nation-state agencies, multinational
corporations, or organized crime syndicates as enemies.  These people
have extreme needs and need to take extreme measures.  But most people
have much different needs.
There are very few one-size-fits-all answers in communications security.
 There are slightly more, but still few, one-size-fits-most.  What you
are doing is peddling a one-size-fits-some as a universal
recommendation.   What I'm worried about is that people whose security
could be vastly improved by simple and painless measures will listen to
this gospel you're preaching, decide clearly there's too much work
involved, and give up altogether!

@_date: 2017-04-23 20:42:45
@_author: Robert J. Hansen 
@_subject: "general purpose OS is fundamentally inadequate for trusted 
[a lot of stuff I agree with snipped]
Please re-read the thread.  You'll see you're agreeing with Peter
Lebbing and me.  We've consistently maintained smart cards are useful in
a number of use cases and threat models -- but they do not rise to the
level listo is ascribing to them.
No.  It's more secure *only if those attacks are within your threat
Wearing a parachute gives me additional security against, say, aircraft
disasters.  But if I don't fly anywhere, it's just an inconvenience
which offers me no additional security.

@_date: 2017-04-24 07:23:23
@_author: Robert J. Hansen 
@_subject: "general purpose OS is fundamentally inadequate for trusted 
The overwhelming majority of GnuPG users do not know enough about
information security to have an opinion worth listening to.
More than that, they shouldn't need to.  GnuPG is meant to be a tool for
regular users.  It fails at this pretty badly for a variety of reasons,
not all of which are within its control, but that's always been the
goal.  If we expect GnuPG users to be experts in information security,
then we've utterly and completely failed.
A consequence of this is there will always be fads and fashions running
through the community, things that many users embrace because "it's more
secure" when the reality is it's nothing of the sort.  Look at how many
people think 3DES is obsolete, for instance, or that anything less than
AES256 is risky.
One fad in particular -- using symmetric algorithms of comparable
strength to your asymmetric key -- has been going on for more than 25
years.  Phil Z made this recommendation back in the days when he thought
Bass-o-Matic was secure, and it was bogus even then, too.  No, this
won't give you a "balanced system".  (Phil Z was apparently badly
misunderstanding a "balanced network" -- a property of Feistel ciphers.)
Smartcards are that same thing today.  They can be, *in some
situations*, a good tool.  They are not a *generally recommended* tool.
This is exactly what we've been doing.  Except "the problem" was not, in
Mr. Senn's case, so much "how do I use a smartcard with GnuPG?" as it
was showing him the real question was, "will using a smartcard with
GnuPG help me?"
And that's a hard question, and an interesting one, and it deserves to
be seriously addressed.  Ultimately he decided he'd like to learn more
about them just because, and that's a perfectly valid use case!

@_date: 2017-04-24 07:33:58
@_author: Robert J. Hansen 
@_subject: "general purpose OS is fundamentally inadequate for trusted 
My bad: I used "obsolete" when I should've said "insecure".  I fully
agree 3DES is obsolete; it's the "3DES is insecure" which is,
IMO, unsupported and faddish.
(The best attack on 3DES requires more RAM than exists in the entire
world, by several orders of magnitude.)

@_date: 2017-04-24 17:49:00
@_author: Robert J. Hansen 
@_subject: "general purpose OS is fundamentally inadequate for trusted 
No.  Security is inherently subjective.  A risk that one person is
willing to bear, another is not; a risk one person deems catastrophic,
another deems insignificant.

@_date: 2017-08-01 14:17:37
@_author: Robert J. Hansen 
@_subject: GnuPG and standard output 
GnuPG seems to insist on writing to a console, even where it's
unnecessary and counterproductive.  Consider the following Python code:
 python3
args = ["/usr/local/bin/gpg",
        "--edit-key",
        "0xb44427c7",
        "showpref",
        "quit"]
result = subprocess.run(args, stdout=subprocess.PIPE)
print("Got {} bytes output".format(len(result.stdout)))
(If you're wondering why I'd do this, GPGME does not yet have a way to
query key prefs, and I need them for a project.)
There's no security reason to dump this to the console.  It's just
publicly-available information about the certificate.  And yet, it
consistently puts zero bytes in result.stdout, while displaying data to
the console.
What's the best way to get past this behavior?

@_date: 2017-08-01 21:05:04
@_author: Robert J. Hansen 
@_subject: GPGme operations with subkeys 
This isn't really well-supported, and for good reason: which subkey to
choose is normally viewed as a decision of the OpenPGP engine, not so
much of the user.  If you have a set of keys, all of which provide the
correct capability, GnuPG will use the most recent one under the logic
that the most recently added subkey is the one the user prefers.
At the command line a subkey can be specifically selected by appending
an exclamation mark to the *subkey* key ID, but I don't believe GPGME
supports this behavior.

@_date: 2017-08-05 14:07:09
@_author: Robert J. Hansen 
@_subject: Posting short GnuPG clear signed messages on social media sites 
Some years ago while teaching computer literacy at a university, some of
my students told me they'd been at a nearby restaurant complaining with
each other about how stupid the class was (we were covering privacy in
the information age), while they were filling out credit card
applications to get a free sandwich.  I asked them what they did when
they realized the privacy implications.  "We got our free stuff and
started talking about girls."

@_date: 2017-08-17 00:17:33
@_author: Robert J. Hansen 
@_subject: Is it possible to certify (sign) a key using a subkey? 
Does the subkey have the certify capability on it?  If the subkey isn't
marked for certifying, it can't be used to certify.

@_date: 2017-08-27 10:29:39
@_author: Robert J. Hansen 
@_subject: Newbie Question: Creating a Key Server using GNUPG tools 
This doesn't sound like any keyserver I've heard of.  Normally
keyservers only store copies of keys people give them, not create
keypairs themselves.  (Or perhaps you meant "that will generate public
and private key pairs" to attach to the clause "the network", not "the
Key Server"?)
Not as you intend, no.

@_date: 2017-08-28 19:05:23
@_author: Robert J. Hansen 
@_subject: Questions about particular use cases (integrity verification w/o 
No.  You can check the format of the message and ensure it's not
mangled, but that's about it.  A loose proof of this follows:
GnuPG only uses asymmetric crypto to encrypt the session key(s) for a
message.  The message itself is encrypted with a symmetric cipher using
a randomly-generated key.  A key principle of symmetric ciphers is the
output of that cipher should be indistinguishable from random noise.
So you have a message you're couriering.  To you, it appears to be
random noise.  How do you do message integrity on random noise?  If you
can distinguish correct from incorrect encrypted data, then clearly
you're able to discern information about the underlying message, which
contradicts the given that the data you're looking at is
indistinguishable from random noise.
You might be able to attach a SHA256 of the encrypted data packet, but
that only tells you if you're carrying the encrypted data packet the
sender intended -- it doesn't tell you a thing about whether the
*decrypted* message will be sensible to Bob.
So no.  Can't do this, sorry.  You can check the message format to make
sure all the packets are well-formed and make sense, but you can't do
more than that.  Only the message recipient can.
Kind of, by checking the message format.
Yes, but this is usually spectacularly unwise.

@_date: 2017-08-28 19:47:49
@_author: Robert J. Hansen 
@_subject: Questions about particular use cases (integrity verification w/o 
Sure, but this is a heuristic, not a formal verification.  A useful
heuristic, absolutely, but this is still at the level of "let's look at
the packets to glean publicly available data" -- whereas message
sanitization and verification would require access to the content of the
Part of this is, I think, the OP is being a little handwavy with the
idea of verification/sanitization.  If what you're checking is dependent
in any way on the cleartext, then you're screwed.  And if what you're
checking is dependent on the ciphertext, you're not really dealing with
the message at all, but the container it's packaged into.

@_date: 2017-08-28 19:51:40
@_author: Robert J. Hansen 
@_subject: Questions about particular use cases (integrity verification w/o 
--expert --full-generate-key
Options 8 or 11 should work for you.  Haven't verified it.

@_date: 2017-08-28 20:21:41
@_author: Robert J. Hansen 
@_subject: Questions about particular use cases (integrity verification w/o 
*shrugs* Do better.  Seriously, if you literally choose option 8 and
just go through the defaults you'll get a single primary key with an
encrypt capability.
quorra:~ rjh$ gpg --expert --full-generate-key
Please select what kind of key you want:
   (1) RSA and RSA (default)
   (2) DSA and Elgamal
   (3) DSA (sign only)
   (4) RSA (sign only)
   (7) DSA (set your own capabilities)
   (8) RSA (set your own capabilities)
   (9) ECC and ECC
  (10) ECC (sign only)
  (11) ECC (set your own capabilities)
  (13) Existing key
Your selection? 8
Possible actions for a RSA key: Sign Certify Encrypt Authenticate
Current allowed actions: Sign Certify Encrypt
   (S) Toggle the sign capability
   (E) Toggle the encrypt capability
   (A) Toggle the authenticate capability
   (Q) Finished
Your selection? q
RSA keys may be between 1024 and 4096 bits long.
What keysize do you want? (2048)
Requested keysize is 2048 bits
Please specify how long the key should be valid.
         0 = key does not expire
        = key expires in n days
      w = key expires in n weeks
      m = key expires in n months
      y = key expires in n years
Key is valid for? (0)
Key does not expire at all
Is this correct? (y/N) y
GnuPG needs to construct a user ID to identify your key.
Real name: Delete Me
Email address: delete.me at example.com
You selected this USER-ID:
    "Delete Me "
Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? o
We need to generate a lot of random bytes. It is a good idea to perform
some other action (type on the keyboard, move the mouse, utilize the
disks) during the prime generation; this gives the random number
generator a better chance to gain enough entropy.
gpg: key FD87EA81A2F00BA1 marked as ultimately trusted
gpg: revocation certificate stored as
public and secret key created and signed.
pub   rsa2048/FD87EA81A2F00BA1 2017-08-29 [SCE]
      6DBE635236A542524E7D950FFD87EA81A2F00BA1
uid                            Delete Me

@_date: 2017-08-28 20:42:26
@_author: Robert J. Hansen 
@_subject: Questions about particular use cases (integrity verification w/o 
I apologize for sounding like I'm condescending here: it's not my
intent.  However, there are very important things you are apparently not
quite understanding, so I'm going to be excruciatingly clear.
A primary key must have the Certify capability -- it's used to certify
the subkeys, after all.
This means algorithms which can only encrypt cannot serve as a primary key.
ECC algorithms come in two varieties: ones that can sign (EdDSA, ECDSA)
and ones that can encrypt (the rest).
So if you insist on using ECC, you must use EdDSA or ECDSA as the
primary key.
Which means your primary key cannot encrypt.
RSA does not have this limitation.  RSA can be used for signing and
This is why my example used RSA.
Use RSA.

@_date: 2017-08-28 23:27:11
@_author: Robert J. Hansen 
@_subject: Questions about particular use cases (integrity verification w/o 
You're confusing the field of numbers in which an algorithm operates
with the algorithm itself.  It's like confusing a sports car with a tour
bus, thinking that since they run on the same roads they're interchangeable.
secp256k1 is a certain field of numbers in which elliptical curve
operations may be defined.  It is not an algorithm.  You do not have a
secp256k1 key.  You have an ECDSA key which operates in the curve
defined by secp256k1.
When you "create a subkey with E capability", you're creating an ECDH
subkey operating in secp256k1.  It's a completely different algorithm
that happens to operate in the same numerical space.  Different cars,
different capabilities, same roads; different keys, different
capabilities, same curve.
ECDSA/EdDSA cannot encrypt.  ECDH cannot sign or certify.
Your primary key must be able to make certifications.  So that means if
you want to use ECC, your primary key must be ECDSA/EdDSA, and you will
never be able to make it into an encryption-capable primary key.

@_date: 2017-08-29 09:19:59
@_author: Robert J. Hansen 
@_subject: Questions about particular use cases (integrity verification w/o 
Please re-read my message:
What you want to do is like saying, "RSA and DSA each use prime numbers,
so can't I use the same prime numbers for each?"  And the answer is no,
not really, because RSA and DSA are different algorithms that work in
different ways.  Even if you were to use the same prime numbers for
both, your RSA keypair would be distinctly different from your DSA
keypair.  They are not interchangeable.
Please stop talking about "secp256k1 keys".  You do not have secp256k1
keys.  You have ExDSA or ECDH keys which are not interchangeable with
each other.

@_date: 2017-08-29 14:33:46
@_author: Robert J. Hansen 
@_subject: E-mail with deniable authentication 
This is not true except in a theoretical mathematical sense.
For instance, several people in the community (I know I have, and I
recall Werner saying he as well) have seen PGP-signed spam mails that
are the result of a home user using Symantec's PGP mail proxy, then
getting infested by malware which sends out spam.  Since all mail goes
through the proxy and the credentials are cached, the spam mails were
You can prove origination *only if* you can prove the originating PC was
not compromised.  Given how common compromise is today -- a few years
ago Vint Cerf estimated one in four desktop PCs was compromised -- this
is a very high threshold to clear.
In a theoretical sense, OpenPGP is a nonrepudiable protocol.  But in a
practical sense, it is not.

@_date: 2017-08-31 11:04:11
@_author: Robert J. Hansen 
@_subject: please help "No pinentry" 
I'm not a creator (just a FAQ maintainer), but maybe I can shed some
light on your troubles.
I think I might know the problem.  If I recall correctly, GPGTools ships
with its own custom pinentry dialog.  When you installed GPGTools, it
added a line in a configuration file telling GnuPG to use its custom
pinentry dialog; when you uninstalled GPGTools, that custom pinentry
dialog went away but the configuration file is still changed.  So GnuPG
is trying to use a pinentry dialog that doesn't exist.
choice.  Look for a line called "pinentry-program" and place a hashmark
(" in front of that line.  This will cause gpg-agent to skip that
line when reading the configuration file.
Then, from a Terminal window:
$ killall gpg-agent
... and try again to decrypt a message.

@_date: 2017-08-31 16:33:09
@_author: Robert J. Hansen 
@_subject: please help "No pinentry" 
That shouldn't have worked.  You're on a Mac, and apt is used by
derivatives of Debian GNU/Linux.
(Well, wait, I guess Fink uses apt, doesn't it?)
That doesn't look like a valid path.  On a Mac, it would be
path actually exists?
Hey, if a miracle happened and your problem got solved, then ... your
problem got solved, and we're happy for you.  :)

@_date: 2017-02-14 12:35:36
@_author: Robert J. Hansen 
@_subject: Questions about --throw-keyids 
Some years ago I had the wild urge to set up Prolog code that would
determine the necessary command-line flags to sustain certain operations,
and which ones could be mixed-and-matched without affecting each other.
After a few days of work I gave up on it: even after reading the source
code, the multitude of operations seemed to be a hall of mirrors.
If I could wave a magic wand, I'd make a huge number of those options just
simply go away.

@_date: 2017-02-16 17:27:25
@_author: Robert J. Hansen 
@_subject: Upgrade instructions required from GnuPG v2.0.14 to 2.1.18 
This is a system administration question.  You will have better luck
asking on a mailing list devoted to your specific operating system.

@_date: 2017-02-22 08:25:08
@_author: Robert J. Hansen 
@_subject: Announcing paperbackup.py to backup keys as QR codes on paper 
I'll chime in with another recommendation for Paperkey.  I'm a little
surprised that your code is as large as it is, too: using an alternate
pipeline you might be able to significantly reduce code size.
(a) use Python 3's gpg module to export the secret key
(b) paperkey --output-type raw --secret-key key.gpg --output key.raw
(c) use Python 3's QR library to create a series of PNGs
(d) use Wand or PythonMagick to convert the PNGs to PDF
(e) save the PDF and you're done

@_date: 2017-02-23 13:58:06
@_author: Robert J. Hansen 
@_subject: SHA1 collision found 
SHA-1 is broken *for some purposes*.  That's scary enough, trust me.  Let's
not overstate things.
For the last ten years I've been saying, "The smoke alarm has gone off and
we think there's a fire.  There's no danger to anyone right now, but we need
to move to the exits in an orderly fashion.  Start migrating away from SHA-1
right now, so that when the collisions happen you've already been using
SHA256 for years."
Today we've seen the fire.  It's not surprising.  We knew this was coming,
we just didn't know when.  If you're still using SHA-1, you probably need to
begin migrating *right now* before the fire gets worse.  If you don't know
how, ask on this list and we'll help you.  But don't panic: we can help.
A question for the list: should we put a "Migrating to SHA256" section in
the FAQ?

@_date: 2017-02-23 15:00:05
@_author: Robert J. Hansen 
@_subject: SHA1 collision found 
(I originally sent this off-list by mistake.  Peter was kind enough to respond off-list and to suggest we take it back on-list.  This email is a distillation of three different emails: my original, Peter's response, and a response to Peter.)
To which I said, "Create two keys with the same fingerprint.  Sign a contract with one, then renege on the deal.  When you get called into court, say "I never signed that, Your Honor!" and present the second key.  This collision pretty much shatters the nonrepudiability of SHA-1 signatures."
To which Peter quite reasonably answered that the other person has a copy of the public key which was used to sign the document originally.  Why should the fraudster's denial be believed?
The answer is that to enforce a contract (at least here in the United States) you must be able to prove, based on a preponderance of the evidence, that the other person entered into a contract with you.  So imagine this conversation:
PLAINTIFF: "Your Honor, the defendant reneged on a $10,000 contract.  Make him pay up."
DEFENDANT: "I never signed anything, Your Honor."
PLAINTIFF: "I have his key, it's right here."
DEFENDANT: "That's not my key.  This is my key."
PLAINTIFF: "Of course that's what he claims!  They have the same SHA-1 fingerprint!  He did that in order to deny his signature!"
JUDGE: "So these keys are uniquely identified by the fingerprint?"
(both parties agree)
JUDGE: "And you have two keys that are identified by the same fingerprint?"
(both parties agree)
JUDGE: "And there's no way to tell which key is real?"
(both parties agree)
JUDGE: "Then we're stuck.  There's no reason to prefer one key over another.  Plaintiff, you have failed your burden of proof in establishing the defendant signed the contract."
Now, you could establish proof some other way: let's say you made a videotape of the defendant signing the document.  If you could introduce other supporting evidence (which might include other signatures on keys) you might be able to convince the judge the signature is enforceable.  But there's nothing intrinsic to the signature itself which could convince the judge.
So Peter is completely right to say "but there's no reason to believe one person over the other."  Completely, absolutely right.  But the person asking the court to enforce a contract must present a reason to believe them over the defendant.
I hope this clarifies my answer!
(Peter also rightly remarked that he thought nonrepudiability in OpenPGP was kind of iffy anyway.  He and I are in complete agreement on this.  OpenPGP has always had very iffy nonrepudiability.  With this SHA-1 attack, I feel the threshold has been crossed and we need to consider it repudiable.)

@_date: 2017-02-23 21:49:46
@_author: Robert J. Hansen 
@_subject: SHA1 collision found 
You kidding me?  MD5 hashes are still the standard tool of computer
forensics.  It's appalling.  The reasons why are fascinating, though:
it's largely for judicial reasons, not technical ones.
It took a lot of work to get courts to accept MD5 as a hash algorithm,
but now it's the judicially-approved standard.  So if you're a forensics
nerd who talks about how we need to migrate to SHA256, you can expect
every prosecutor to roll their eyes and say, "not this thing again!"
If you say that MD5 is no longer trusted as a hash, suddenly they get
downright panicked.  "Hush!  Do you want every previous case in which we
used MD5 to certify evidence hadn't been tampered with to come into

@_date: 2017-02-26 20:56:55
@_author: Robert J. Hansen 
@_subject: gpg2 on a Windows 10 Pro 64 bit machine 
Kinda-sorta, but yes!
WARNING: this works on my laptop for both GnuPG 2.0 and 2.1.  It may not
work on yours.
Save everything between the "=====" marks to a file named "gpgclean.ps1".
# gpgclean.ps1 -- cleans expired/revoked keys from GnuPG
# Requires GnuPG 2.0 or later.
# Copyright 2017, Rob Hansen
# Permission to use, copy, modify, and/or distribute this
# software for any purpose with or without fee is hereby
# granted, provided that the above copyright notice and
# this permission notice appear in all copies.
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS
# ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO
# EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
# INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER
# TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE
# USE OR PERFORMANCE OF THIS SOFTWARE.
# Use the Windows Registry to find GnuPG's location
 Start by looking for GnuPG 2.1.  If we can't find
 it, fall back to looking for 2.0.
If (Test-Path "HKLM:\Software\WOW6432Node\GnuPG") {
ElseIf (Test-Path "HKLM:\Software\WOW6432Node\GNU\GnuPG") {
# Create the two Lists we're going to use to store the
# revoked/expired private keys and the revoked/expired
# public keys
$private_keys = New-Object `
$public_keys = New-Object `
# Many of our "expired" keys will have new, duration-
# extending signatures.  We do a keyring refresh from the
# keyservers to ensure we don't delete anything we don't
# have to.
&$gpg --keyserver pool.sks-keyservers.net `
# Get the expired/revoked private and public keys
(&$gpg --keyid-format long `
    $keyid = $match.Groups[1].Value
 In GnuPG 2.0, you can't figure out whether a private
 key is expired except by looking at its corresponding
 public key.  In GnuPG 2.1, you can, but the old way
 still works.  This code will therefore work with both.
If ($public_keys.Count -gt 0) {
# If we have revoked/expired private keys, get rid
# of them first.
if ($private_keys.Count -gt 0) {
# Follow up with revoked/expired public keys
if ($public_keys.Count -gt 0) {
Save that.  Then, in the "Ask me anything" box, type "Windows
PowerShell".  Launch the program that comes up.  You'll see a prompt like:
    PS C:\Users\rjh>
Then just type the path to gpgclean.ps1 and hit RETURN.
    PS C:\Users\rjh> .\Documents\gpgclean.ps1
It will likely appear to hang for a few minutes.  That's normal.  It's
refreshing your keyring in order to see if any certs have revised
expiration dates.  Once it finishes that, the rest goes quickly.
If there's interest, I'll put a good-looking GUI on this.

@_date: 2017-01-15 19:12:03
@_author: Robert J. Hansen 
@_subject: Sherpa 0.3.0 
Sherpa, a tool I've been working on off-and-on, now only blows up
infrequently.  That means I need brave, intrepid souls who aren't afraid
to frag their hard drives.  Bwahahahahahaha!
Windows users are preferred right now (since most GnuPG users are on
Windows).  A signed Windows installer package is available.  I also have
a Fedora 25 RPM, if any F25 users would like to try.
If it works correctly you'll think it's a tiny little app that does one
thing well and is thoroughly unremarkable.  If that's your experience
I'll sing hallelujah.  If it's not, I'll forgive you for cursing my name
as your hard drive catches fire.
        (Note: not kidding -- this is not ready for production systems!)

@_date: 2017-01-16 14:28:19
@_author: Robert J. Hansen 
@_subject: gpgme: error in OS X app bundle 
I've packaged Sherpa up into an OS X application.  It works when opened
at the command line with "open sherpa.app"; it fails when double-clicked
from Finder.  The offender seems to be:
GPGME 2017-01-16 14:14:55 <0x0d3f>  gpgme-walk_path: 'gpgconf' not found
in '/usr/bin:/bin:/usr/sbin:/sbin'
When launched from the command line, the child process inherits my PATH
and thus GnuPG can find gpgconf; when double-clicked in Finder, PATH
isn't inherited and thus gpgconf can't be found.
Now, I could blunder my way to a solution but I thought I'd ask here
first.  Has anyone else encountered this problem?  How did you solve it
in your own code?
I can think of a few ways to approach this, but they all seem inelegant.
 Looking for a .profile in $HOME, parsing it for PATH information, and
looking for gpgconf in those dirs?  Or should I just raise a, "Please
navigate to your gpgconf executable" file-chooser, which would likely be
too complicated for many novice users?  Etc.

@_date: 2017-01-17 08:52:00
@_author: Robert J. Hansen 
@_subject: gpgme: error in OS X app bundle 
Well, the problem we run into is there's so many different places people
install GnuPG on OS X.
Homebrew uses /usr/local, GPGTools uses /usr/local, GPGOSX uses
use /opt, and so on.
I have a hack around it, but it's kind of gross, and I'm really hoping
there's a better way.

@_date: 2017-01-19 08:27:06
@_author: Robert J. Hansen 
@_subject: Counterarguments Supporting GnuPG over Off The Record (OTR) 
Maybe.  So what?  15-20 years from now many of us will have expired and
only be of interest to our families.
Everything dies.  That doesn't make things less valuable.

@_date: 2017-01-25 08:41:10
@_author: Robert J. Hansen 
@_subject: gnupg website 
For that matter, I'm still in the dark as to what the big problem with
three-key 3DES is.  The best attack against it requires more RAM than
exists in the entire world and only reduces it to 112 bits.
3DES is slow, ungainly, and has been largely replaced by better
ciphers... but *unsafe*?

@_date: 2017-01-25 17:00:18
@_author: Robert J. Hansen 
@_subject: gnupg website 
Quoting from the abstract:  "In our proof-of-concept demos, the attacker needs to capture about 785GB of data."  I question the wisdom of any system which sends 785Gb of data without ever rekeying.
This attack seems to fall into the realm of "stupid SSL mistakes lead to exploitation. "

@_date: 2017-01-25 17:33:01
@_author: Robert J. Hansen 
@_subject: gnupg website 
Sure, but those proofs-of-concept require *hundreds of GB of traffic*.
That's the sort of thing that causes a lot of crypto nerds to twitch and
mutter "rekey, rekey".

@_date: 2017-01-26 13:48:34
@_author: Robert J. Hansen 
@_subject: gnupg website 
The 256GiB limitation (2**32 blocks of 2**6 bytes = 2**38 bytes; 2**30 is a
gibibyte, 2**8 is 256, hence, 256 GiB) is so well-known that it appears
multiple times in the GnuPG FAQ, even.  All the 64-bit-block ciphers have
notations of "don't encrypt more than about 4GiB of data".
(If people are wondering why we advise 4GiB when the birthday bound is
256GiB, it's because we want a large safety margin.)

@_date: 2017-07-13 10:48:32
@_author: Robert J. Hansen 
@_subject: use policy of the GnuPG-card 
You just lost.  Everything after this sentence is irrelevant.  Once an
attacker has privileged access to your machine it's all over.
It can't be.  GnuPG is only for use in environments where you trust the
admins.  GnuPG cannot protect you from a rogue admin.  Do not fall into
the trap of thinking you can manage this: you cannot.

@_date: 2017-07-17 09:54:56
@_author: Robert J. Hansen 
@_subject: A Quick Supplement 
The step-by-step process I posted last year didn't, because I don't use
them in my own local policy and thus didn't think about them (oops).
Sherpa doesn't, because GPGME doesn't support the exporting of local
It is infuriatingly difficult to come up with a backup method that
applies across GnuPG 1.4 - 2.1, is crossplatform, is safe (doesn't copy
random_seed, etc.), and so on.  Ease of backing up has never been a high
priority for the GnuPG devs, and it shows.

@_date: 2017-07-17 09:59:42
@_author: Robert J. Hansen 
@_subject: A Quick Supplement 
At risk of sounding arch and caustic -- which I'm not; it's just that
reality is going to sound arch and caustic -- go for it: just remember
that it's a long complex that requires some command-line juggling that's
beyond the skills of the majority of users, and this is something you
really don't want to get wrong.
If you feel you have the necessary skills to safely do it at the command
line, knock yourself out.  But if you don't, please use the tool.  It
will save you a lot of frustration.

@_date: 2017-07-18 09:36:39
@_author: Robert J. Hansen 
@_subject: A Quick Supplement 
I have made these observations before, yes.
This *is* a security issue.
Some versions of GnuPG use a file called "random_seed", for instance.
This file contains material for seeding a random number generator, and
for that reason it must not be backed up or shared between computers: if
the file doesn't exist it'll be recreated, but if it does... then you've
just reused RNG seeds on two different computers, which has the
potential to dramatically reduce the cryptographic security of the code.
If you don't make it easy to back up keys, people won't back up their
keys.  Then, any minor disaster has the possibility of irreparably
wrecking their keys and the Web of Trust connections they've carefully
created.  Disaster recovery is an important part of security, too.
Click Enigmail -> About and see if you spot any familiar names there.
Maybe Enigmail's usability guy, who's had to wrestle with the problems
of importing and exporting keyrings, will have some interesting
thoughts.  :)
So?  He could've been the first man to walk on Mars: it would have no
bearing on whether the difficulty of backing up keyrings is a problem
that needs to be addressed.
Yep.  Sections 3.8, 3.9, and 3.10 of the FAQ mention this.  You might
also want to check out section 1.2.  It's a pretty good FAQ; someone
clearly put a lot of work into it.  :)
I do not contribute code to GnuPG -- I could: I'm a fairly good C
cryptographic engineer with a strong security background.  However, once
upon a time I worked on U.S. government contracts, so it's best for the
GnuPG project if I don't contribute code.  I still find other ways to
contribute, whether that means non-core code contributions (Sherpa),
documentation (the FAQ), usability issues (Enigmail), etc.

@_date: 2017-07-18 16:49:38
@_author: Robert J. Hansen 
@_subject: A Quick Supplement 
Not a dumb question.
There are a number of lockfiles, sockets, etc., that live in the
~/.gnupg directory which shouldn't be copied.
No, because GnuPG has a ton of different pseudorandom number generators
that it can use.  An in-depth explanation would require knowing specific
versions of your operating system, possibly even which chipsets you're
using (hardware accelerators, etc.) -- and at that point I'm going to
start charging you my consulting rates.  :)
In a nutshell, though: a pseudorandom number generator has some internal
data that it uses to generate the sequences.  If you restore the PRNG to
an earlier state, it'll generate the same numbers over again... at which
point, they're really not random any more.
random_seed is internal data belonging to the PRNG.
Don't share it.  :)

@_date: 2017-07-18 20:58:33
@_author: Robert J. Hansen 
@_subject: A Quick Supplement 
In my day job I'm a developer, among other things.  However, due to my
taking research funding from the U.S. government in the past, I do not
contribute code to either GnuPG or Enigmail.  I find other, non-code,
ways to help the GnuPG and Enigmail teams.
You're quite welcome.  :)

@_date: 2017-07-19 11:08:20
@_author: Robert J. Hansen 
@_subject: GPG Installation on AIX 6.1 & RedHat Linux 6.8 & RedHat 5.11 
The Linux machines should be easy, if you'll tell us what distro you're
I'll give someone else the chance to answer your AIX question, as I
haven't used it in many years.

@_date: 2017-07-25 14:34:10
@_author: Robert J. Hansen 
@_subject: How to use a the same generated keypair on enigmail/thunderbird 
This is correct.
I've often volunteered to publish my private key in the _New York
Times_, if someone will just pay for the listing.  With a strong
passphrase, private keys are pretty darn safe against casual snooping.

@_date: 2017-07-28 02:44:55
@_author: Robert J. Hansen 
@_subject: Invalid Crypto Error 
Where are you getting libgpgme-glib-11.dll?  My copy of GnuPG provides
these libraries and executable for using GPGME.  Note that all of them
must be present in the same directory as your executable.
* gpgme-w32spawn.exe
* libassuan-0.dll
* libgpg-error-0.dll
* libgpgme-11.dll
Check that you have all the DLLs, and the supporting gpgme-w32spawn.exe

@_date: 2017-07-30 18:46:54
@_author: Robert J. Hansen 
@_subject: 'sign (and cert)' or just 'cert' on a master key with subkeus 
The standard advice applies: stick with the defaults.

@_date: 2017-07-31 11:41:58
@_author: Robert J. Hansen 
@_subject: 'sign (and cert)' or just 'cert' on a master key with subkeus 
I hate to say something bad about a tutorial someone put so much obvious
love into, but most of these tutorials are _just plain bad_.  And even
the good ones, I don't recommend.
A newcomer to GnuPG needs to be told the defaults are safe for the vast
majority of users, that GnuPG does not require any special tuning before
use, and that the developers chose the defaults very carefully to be
applicable to the vast majority of users.
Debian may have specific needs which GnuPG does not meet in its default
configuration.  So if Debian wants to put together a tutorial teaching
people how to configure GnuPG in a way that meets the Debian developer
needs, I'm all in favor of that -- but I wince every time I see a
newcomer to GnuPG think that process is somehow necessary for them to
follow.  It's not.  Use the defaults until and unless you can articulate
a specific and compelling reason to deviate from them.

@_date: 2017-07-31 12:52:58
@_author: Robert J. Hansen 
@_subject: 3DES deprecated by NIST 
For many years I've been saying that 3DES is a much stronger algorithm
than its detractors think, subject to some massive concerns about its
64-bit block size and the near-certainty of a block repeating after
about 32Gb of traffic (2**32 blocks, 8 bytes per block).  This isn't to
say I've been advocating 3DES: we certainly should be moving to AES, but
the fearmongering over 3DES has been -- IMO -- counterproductive.
Well, NIST has recently lowered its estimate of 3DES's safety.  Their
guidance now says a single 3DES key shouldn't be used for more than 8Mb
of traffic.  If previously we were moving to AES and away from 3DES
because the fire alarm went off, this would be the smell of smoke in the
If you're still using 3DES, please migrate to AES immediately.  Until
you do, make sure to follow NIST's guidance.

@_date: 2017-06-04 06:50:12
@_author: Robert J. Hansen 
@_subject: Question for app developers, like Enigmail etc. - Identicons 
The question then becomes how hard it would be to forge a qidenticon.
There's not a whole lot of entropy there.

@_date: 2017-06-12 11:19:03
@_author: Robert J. Hansen 
@_subject: Fwd: Re: Fwd: Re: Question for app developers, like Enigmail etc. 
If Mallory can tamper with your keyrings, that's a total game-over
condition.  At that point there are dozens of attacks open to her.  Once
you lose control of your computer, it's all over.

@_date: 2017-06-12 11:28:47
@_author: Robert J. Hansen 
@_subject: Question for app developers, like Enigmail etc. - Identicons 
It cannot be the job of the GnuPG team to teach people how to safely
administer their operating system.  There are too many operating
systems, too many different threat models, too many different use cases,
for anyone to go down that rabbit-hole.
Some generally good advice might include:
- Keep your operating system up to date
- Disable Flash in your browser
- Disable Java Web Start in your browser
- Install ad blocking and tracker blocking plugins into your browser
- Only run software from trusted sources
- Only use USB thumb drives with machines you trust
- Only use USB thumb drives that came from trusted sources

@_date: 2017-06-12 16:10:38
@_author: Robert J. Hansen 
@_subject: Fwd: Re: Fwd: Re: Question for app developers, like Enigmail etc. 
If you think your online computer may be compromised, then you have no
business sharing USB devices between it and your believed-safe computer.

@_date: 2017-06-12 16:35:06
@_author: Robert J. Hansen 
@_subject: Fwd: Re: Fwd: Re: Question for app developers, like Enigmail etc. 
No.  More to the point, there can't be.  Each user faces threats
specific to that user; each user is responsible for their own threat
But follow the steps I outlined before and you'll significantly improve
your online security.  You won't be perfect -- there is no such thing as
perfection.  You won't be a hardened target -- that takes a lot of work.
 But follow those steps and you'll have taken care of the easy ways that
your machine can be compromised.

@_date: 2017-06-29 17:31:35
@_author: Robert J. Hansen 
@_subject: SHA1 depreciation ?? 
(a) Not for OpenPGP's uses.  For our uses it's still safe, although we
recommend moving to other, better, hashes as soon as possible.
(b) It's pretty easy to avoid using SHA-1.  There are still a small
number of places where it's mandatory, and this will not change until
the IETF OpenPGP Working Group publishes the v5 key specification.
(c) The IETF OpenPGP WG is working on a new key specification ("v5")
which completely gets rid of SHA-1.
You found out it's *impossible*.  SHA-1 is a MUST algorithm according to
the RFC.  You cannot get rid of SHA-1 from your key preferences.  Even
if you were to do it, every RFC-conformant OpenPGP application on the
planet would say, "that's odd: let me just append SHA-1 to that", as
they are required to do by the RFC.
You didn't read the manual.  The preferences attached to your key tell
the world what algorithms you're capable of interoperating with.  GnuPG
never uses them to decide which algorithms to apply to your own traffic.
Enigmail doesn't sign anything.  GnuPG is what signs things.  Enigmail
just hands your documents to GnuPG for processing.
Check what digest was used to sign this message.  Hint: I'm using Enigmail.
Try adding this lines to your gpg.conf file:
personal-digest-preferences SHA512 SHA384 SHA256 SHA224 RIPEMD160

@_date: 2017-06-29 23:26:06
@_author: Robert J. Hansen 
@_subject: SHA1 depreciation ?? 
Yes.  Search the RFC for the term "SHA-1" and you'll find them.  It's
hardwired into several of the packet formats, for instance.
No.  The WG is being annoyingly slow.

@_date: 2017-03-03 12:09:33
@_author: Robert J. Hansen 
@_subject: Verify with missing public key: unexpected returncode 
Because there were no bad signatures.  A signature which cannot be
verified is neither good nor bad, it just is.
The alternative would be for GnuPG to return a bad signature literally
*whenever* it had no public key with which to verify the signature,
meaning that 99% of signatures on a mailing list would be reported as
bad.  Can you imagine the bug reports we'd get from people if that were
the case?  "Your software package is listing every single signed message
I've received as being bad!"

@_date: 2017-03-07 09:08:39
@_author: Robert J. Hansen 
@_subject: From Masterkey to subkey 
Whoever told you this was badly misinformed.  While you *can* do this,
it is by no means a general recommendation.  The only general
recommendation we give is "unless you know what you're doing and why,
stick with the defaults."
You didn't make a mistake.  If you have a need for an offline master key
(if not having one will cause your local security policy to fail), then
by all means do it.  But otherwise, think twice: you're introducing a
lot of additional complexity for not very much benefit.

@_date: 2017-03-12 12:36:17
@_author: Robert J. Hansen 
@_subject: Interleaving issue 
This is a bit odd:
quorra:~ rjh$ gpg --check-sig b44427c7
pub   rsa3072/1DCBDC01B44427C7 2015-07-16 [SC]
      CC11BE7CBBED77B120F37B011DCBDC01B44427C7
uid                 [ultimate] Robert J. Hansen sig!3        1DCBDC01B44427C7 2016-07-02  Robert J. Hansen
sig!         23806BE5D6B98E10 2015-07-16  Robert J. Hansen
sig!3        D037CE8EEFA13249 2015-07-17  Phil Stracchino
sig!3        DB1187B9DD5F693B 2015-07-18  Patrick Brunschwig
sig!3        1DCBDC01B44427C7 2015-07-16  Robert J. Hansen
sig!3        4D1E900E14C1CC04 2017-02-18  Phil Pennock
uid                 [ultimate] Robert J. Hansen sig!3        1DCBDC01B44427C7 2016-07-02  Robert J. Hansen
sig!3        4D1E900E14C1CC04 2017-02-18  Phil Pennock
uid                 [ultimate] Robert J. Hansen sig!3        1DCBDC01B44427C7 2015-07-16  Robert J. Hansen sig!         23806BE5D6B98E10 2015-07-16  Robert J. Hansen
sig!3        D037CE8EEFA13249 2015-07-17  Phil Stracchino
sig!3        DB1187B9DD5F693B 2015-07-18  Patrick Brunschwig
sig!3        4D1E900E14C1CC04 2017-02-18  Phil Pennock
sub   rsa3072/DC0F82625FA6AADE 2015-07-16 [E]
sig!         1DCBDC01B44427C7 2015-07-16  Robert J. Hansen
Let me draw attention to:
quorra:~ rjh$ gpg --check-sig b44427c7
sig!3        1DCBDC01B44427C7 2015-07-16  Robert J. Hansen It would appear GnuPG is interleaving outputs.  This is on a macOS
Sierra system with GnuPG 2.1.19.  It's reproducible, too.

@_date: 2017-03-13 11:17:07
@_author: Robert J. Hansen 
@_subject: Security doubts on 3DES default 
This is required behavior per RFC4880.  Your concern should be addressed to
the IETF OpenPGP working group, not to GnuPG.
There is no security risk with 3DES unless you (foolishly) choose to encrypt
vast quantities of data (multiple gigabytes) with the same key.
RFC4880 requires 3DES be used with three independent subkeys, giving it a
technical keyspace of 192 bits, the same as AES192.  However, 24 of those
bits are used for parity and contribute nothing to the security of the
system, meaning it comes in at 168 bits of effective key.  This is a
keyspace about a trillion times larger than AES128's.
There are a couple of *theoretical* attacks on 3DES that reduce it to about
a "mere" 112 bits (still unassailable, but less strong than we'd like).  The
best known attack requires a billion known plaintexts and
100,000,000,000,000,000 gigabytes of RAM.
3DES is even somewhat resistant to quantum computation, as a 168-bit
keyspace is still an 84-bit keyspace even after hitting it with Grover's
algorithm and a large quantum computer.  An 84-bit keyspace can be
brute-forced by people willing to throw huge amounts of resources at the
problem, but it'd be tremendously annoying.  A few years ago when
distributed.net tackled RC5-64 (with a keyspace a millionth the size of a
quantum-attacked 3DES) it took them a large distributed cracking effort and
eighteen months of time.
I don't know who told you that 3DES was insecure.  They misled you.  It is
not insecure.  It is slow, it is ungainly, it has all the aesthetics of a
Soviet worker's housing bloc, and we have better ciphers available to us.
But 3DES has also been turning brilliant cryptanalysts into burned-out
alcoholic wrecks for 40 years.
Again, required per the spec, and this can be prevented by having one person
on the list use a DSA-2048/-3072 key, which forbids SHA-1 usage.
You're missing the boat on the security of 3DES.  You're correct that SHA-1
is unsuitable for use as a hashing algorithm and that usage of it may be
mandated in certain situations.
Take it up with the IETF OpenPGP working group, not GnuPG.  Get them to
change the RFC.
The current opinion in the IETF OpenPGP working group is the next iteration
of the standard will probably settle on AES256 and SHA256 as replacement
MUSTs for the current 3DES/SHA-1.  (Other hashes, such as BLAKE2, SHA512,
and SHA-3/Keccak, are also being discussed as optionals.)
However, when this next iteration will be released is anyone's guess.  The
group works painfully slowly.

@_date: 2017-03-13 19:02:48
@_author: Robert J. Hansen 
@_subject: Security doubts on 3DES default 
I was speaking a bit too glibly; I'm sorry about that.
If I'm sending to 30 people it's quite likely I'll wind up using CAST or
3DES, since that's the lowest common denominator.  Cipher preferences
have a complex find-the-best-option algorithm that finds what all
recipients can use, then chooses one from among them -- so finding a
"common denominator" of algorithms is important.
But lowest common denominator for signatures is ... it's uncommon to
encounter such a situation; in fact, in 25 years of using PGP I don't
think I've ever encountered it.  If I sign a message with TIGER192 and
you can't verify it, tough luck.  Given this, I don't know how you'd
come up with a real-world case where you'd need a common hash algorithm
set for signing purposes.
But if there were such a case where there was a lowest common
denominator hash algorithm, DSA-2048 requires a 224-bit hash (and -3072
requires 256), so inclusion of either of those would preclude any
160-bit hash being used; they could not appear in a common algorithm set.

@_date: 2017-03-14 16:54:52
@_author: Robert J. Hansen 
@_subject: Security doubts on 3DES default 
So long as you understand GnuPG will not make any changes that break RFC
conformance... and dropping SHA1/3DES breaks RFC conformance.
Everyone agrees.  GnuPG for many years has defaulted to AES.  3DES
exists for RFC conformance.  We've migrated away from 3DES as far as we
can; any further requires a change to the RFC.
This opinion is not shared by the cryptanalytic community as a whole.
We are nowhere near a break in 3DES.
We're already in the working group trying to push this forward.
The WG has a mailing list where these things are discussed.  Also, many
WG members have private asides with other WG members.

@_date: 2017-03-15 20:44:41
@_author: Robert J. Hansen 
@_subject: Security doubts on 3DES default 
Yeah, but that's ... *bad*.  Breaks most of the Web of Trust, makes most
cert sigs meaningless, removes the fallback cipher ... I think this is a
great example of a cure worse than the disease.  :)
Phil Pennock made a post a bit ago detailing his experiment with
disabling SHA1.  It was informative, to say the least.

@_date: 2017-03-16 10:21:57
@_author: Robert J. Hansen 
@_subject: Security doubts on 3DES default 
protecting its
In my defense, I never said GnuPG wasn't going to try to protect users from
dangerous things.  I said that until the RFC changes, 3DES and SHA1 will
remain in the codebase -- which is, I think, the correct position to take.
Why?  What's the reasoning for refusing to encrypt using 3DES?
I can see "we should refuse to put 3DES in any non-final position in key or
cipher preferences" -- that would make sense: it's the cipher of last
resort, and putting it in non-final position kind of breaks that guideline

@_date: 2017-03-16 11:13:14
@_author: Robert J. Hansen 
@_subject: Security doubts on 3DES default 
In the next draft of the RFC, I'd like to see 64-bit-block ciphers go the way of the dodo.

@_date: 2017-03-19 17:01:13
@_author: Robert J. Hansen 
@_subject: help 
To your gpg.conf file add the line,
personal-cipher-preferences AES256 CAMELLIA256 TWOFISH
... and you'll generate 256-bit encrypted traffic whenever possible.

@_date: 2017-03-20 01:29:30
@_author: Robert J. Hansen 
@_subject: I figured out how to change the algorithms, 
No, you didn't figure out how to change the algorithms.
Key preferences are the capabilities you advertise to the world.  What
you've done is told the world, "I only understand AES256, 3DES, SHA512,
and SHA1."  Which is great if the entire world understands AES256 and
SHA512 -- but the moment you have a correspondent who doesn't (or who
refuses to use it) you'll silently degrade to 3DES or SHA1.
Imagine you're corresponding with someone who doesn't trust AES256,
thinking it's tainted by association with NIST.  (This is crazy talk,
but unfortunately common.)  They've configured GnuPG to never use
AES256, but to prefer TWOFISH and CAMELLIA256 instead.  Despite the fact
your GnuPG is plenty capable of CAMELLIA256 and TWOFISH, since you're
not advertising that capability your correspondent's GnuPG will silently
drop to 3DES.
Notably, GnuPG never looks at your own key preferences.  That's what you
advertise to the world as your capabilities.  GnuPG looks to
personal-cipher-preferences, et al, to determine which algos to use when
creating traffic, which is why you were advised to set
personal-cipher-preferences, etc., in your gpg.conf.
If you want to generate 256-bit traffic, put AES256, TWOFISH, and
CAMELLIA256 in your personal-cipher-preferences.  Which is exactly what
you were advised to do earlier.

@_date: 2017-05-02 15:10:18
@_author: Robert J. Hansen 
@_subject: What is an RSA subkey? [eom] 
We're going to need a lot more info than this.
"What is an RSA subkey?"  Well, it's a part of a certificate which
provides the capability to do some or all of signing, certifying,
authenticating, and/or encryption, using the RSA algorithm to provide
its cryptographic needs.
If that answer is helpful to you, you're quite welcome.  :)  But if it's
not, you really need to drill down and tell us what precisely you're
looking to learn.

@_date: 2017-05-29 19:49:09
@_author: Robert J. Hansen 
@_subject: Don't send encrypted messages to random users 
All presence on the keyservers says is, "if you have something to send
me, you may send it securely".  It is not a permission to send someone
email they'd prefer to avoid.
Further, the conduct the OP is talking about amounts to dragooning
someone into helping you without first asking them whether they're
willing to help you.

@_date: 2017-11-10 01:42:31
@_author: Robert J. Hansen 
@_subject: a bunch of questions 
No.  There's no expiration date on your certificate, and it's a 4096-bit
RSA keypair.
I personally think it's unlikely 4096-bit RSA keys will be broken in the
next twenty years.  Over that timeframe, RSA-4096 is probably stronger
than elliptical curve cryptography: we might (*might*) have quantum
computers large enough to tackle ECC by 2040, but RSA-4096 would require
a far larger quantum computer.
quorra:~ rjh$ gpg --edit-key "Charlie Derr"
pub  rsa4096/BB8B3D7331A9367F
     created: 2010-12-16  expires: never       usage: SCA
     trust: unknown       validity: unknown
sub  rsa4096/F44E4BC7C1F121DD
     created: 2010-12-16  expires: never       usage: E
[ unknown] (1). Charlie Derr I don't use Claws, so I can't answer that; but Thunderbird+Enigmail
allows you to use whichever key you wish -- just set it up according to
the instructions on the Enigmail webpage.  If the instructions there are
unclear or confusing, I'm happy to help you with it further.

@_date: 2017-11-14 17:54:00
@_author: Robert J. Hansen 
@_subject: question about determining the key length 
There seems to be a misunderstanding here.  A keyring is just a
collection of certificates (which used to be called "keys").  Each
individual certificate will have various subkeys of different
algorithms, but the keyring *as a whole* has no algorithm nor bit length.
To get a detailed look at an individual key, try --list-key.  (Which
should really be "--list-certificate".  We're changing our language very
quorra:~ rjh$ gpg --list-key b44427c7
pub   rsa3072/1DCBDC01B44427C7 2015-07-16 [SC]
      CC11BE7CBBED77B120F37B011DCBDC01B44427C7
uid                 [ultimate] Robert J. Hansen uid                 [ultimate] Robert J. Hansen uid                 [ultimate] Robert J. Hansen sub   rsa3072/DC0F82625FA6AADE 2015-07-16 [E]
sub   ed25519/A83CAE94D3DC3873 2017-04-05 [S]
sub   cv25519/AA24CC81B8AED08B 2017-04-05 [E]
The primary subkey is RSA-3072, made on July 16, 2015.  There are three
other subkeys: an RSA-3072 useful for encryption (same date), an
Edwards-25519 key useful for signing (dating April 5, 2017); and an
ECC-25519 key useful for encryption (April 5, 2017).

@_date: 2017-11-22 02:54:36
@_author: Robert J. Hansen 
@_subject: Complete Ubuntu compile of GnuPG 
Pass --enable-g13 --enable-wks-tools to your make invocation.
make -f build-aux/speedo.mk INSTALL_PREFIX=/usr/local \
  speedo_pkg_gnupg_configure='--enable-g13 --enable-wks-tools' \
  native
Also see  .
Hope this helps!

@_date: 2017-10-01 20:44:15
@_author: Robert J. Hansen 
@_subject: 1024 key with large sub key 
You'd have to ask the owner.  If he used GnuPG to generate this key he'd
have to hack on the source code, because out of the box GnuPG only
generates up to 4096-bit keys.

@_date: 2017-10-02 10:46:48
@_author: Robert J. Hansen 
@_subject: 1024 key with large sub key 
I was about to disagree with you when I discovered the
--enable-large-rsa flag.
When did this get introduced?  Why?  What possible use case is there for

@_date: 2017-10-02 15:04:07
@_author: Robert J. Hansen 
@_subject: 1024 key with large sub key 
Thank you for digging this up.
I'd like to open a discussion about removing this option.
First, I think it was a misfeature from conception.  The justification
was, "Some older implementations built and used [large] RSA keys" --
which is absolutely true -- but there was no justification given to
allowing RSA keys *generated today* to be of that size.  Allowing GnuPG
to import keys of that size might be necessary to give users an upgrade
path; allowing GnuPG to *generate* keys of that size seems unjustified.
Since we are no longer concerned with "older implementations" (which I'm
assuming means "PGP 2.6 and its derivatives"), the original
justification is gone.  And on the downside, keeping this option in
place encourages a kind of cryptofetishism where all that matters is key
Anyone want to point out what I'm missing?  I don't want to sound as if
my mind is made up, but right now it truly seems to me the
--enable-large-rsa option is a misfeature.

@_date: 2017-10-02 17:38:36
@_author: Robert J. Hansen 
@_subject: 1024 key with large sub key 
It's fine if it's not at the top of the list; but is there any
compelling reason to not put it on the list?

@_date: 2017-10-03 03:12:12
@_author: Robert J. Hansen 
@_subject: Redundant certificate in keyring 
I don't know how this came to pass, but:
PS C:\Users\Robert J. Hansen\Documents> gpg --list-keys 12d9199d7b3b7495
pub   dsa2048/12D9199D7B3B7495 2017-07-26 [SCA]
      1BE9AAB825A55E48195F1A0312D9199D7B3B7495
uid                 [ unknown] Tobias Schultz sub   elg2048/B57E2F27C75F8668 2017-07-26 [E]
pub   dsa2048/12D9199D7B3B7495 2017-07-26 [SCA]
      1BE9AAB825A55E48195F1A0312D9199D7B3B7495
uid                 [ unknown] Tobias Schultz sub   elg2048/B57E2F27C75F8668 2017-07-26 [E]
(Windows 10, GnuPG 2.2.0.)
Somehow, this cert got introduced into my keyring twice.  I don't know
how and I don't really know when; I only found out about it after a
script I run every month broke horribly, since it expects a given cert
to only appear once in the keyring.
I don't ever edit my keybox file directly.
Deleting that cert deleted only one of the two certs, too.
There appears to be a bug in the keybox code; unfortunately, I'm not
able to give much in the way of details.  :(

@_date: 2017-10-03 09:56:11
@_author: Robert J. Hansen 
@_subject: 1024 key with large sub key 
As always, the needs of real users are paramount.  If there are real
users who will be impacted, that's all the justification needed.
Consider my request withdrawn.  :)

@_date: 2017-10-04 16:29:41
@_author: Robert J. Hansen 
@_subject: 1024 key with large sub key 
I know this wasn't addressed to me, but what the heck.  I won't share my
preferences, but this is some modestly-accurate history.
Way back when, DSA and Elgamal had to be the defaults in OpenPGP because
RSA Data Security held the patent on the RSA algorithm, whereas DSA and
Elgamal were patent-free.  That patent was relinquished in September of
Twofish became part of the suite of ciphers with PGP 7, and GnuPG had to
support it because PGP 7 made it their default.  In PGP 7.1 they
switched to AES (which had just been released) but left Twofish in
because Twofish had Schneier cachet.  This is also probably why Blowfish
is still an approved algorithm.  IDEA continued to be supported almost
entirely for backwards compatibility with PGP 2.6; it has not held up at
all well, and is probably the weakest cipher in the suite.
(I have heard it said Blowfish was introduced to the spec as a fallback
in case CAST5 turned out to have flaws.  Given how similar CAST5 and
Blowfish are, design-wise, if this is true I think it was terrible
So right there, you can see that DSA, Elgamal, Twofish, and Blowfish,
all exist in the spec for non-engineering reasons: patent infringement,
fame of designer, backwards compatibility, etc.
I won't bore you with my list of preferred algos, though.  :)

@_date: 2017-10-05 12:39:44
@_author: Robert J. Hansen 
@_subject: 1024 key with large sub key 
I was unaware GnuPG had a role in this decision: thank you for the
clarification.  :)
... wait, 3DES was patent-encumbered?

@_date: 2017-10-09 21:57:37
@_author: Robert J. Hansen 
@_subject: Working with an Online and Offline Computer when using GnuPG - 
In '07, my research group developed some really low-tech data transfer
with admirable characteristics: it was provably one-way data transfer.
Get a serial cable and cut it in half.  On one end attach a laser; on
the other end attach a photoreceptor.  Mount the two.  You now have a
data diode -- a "cable" over which data can only flow in one direction.
We had to write custom drivers for it, but it wasn't hard.
If memory serves we weren't able to go over about 300 baud.  This was by
design: our photoreceptor was ***old*** (like 1960s tech) and had a
relatively long cycling period after each pulse.  The point of using the
old photoreceptor was that way we were dead certain there was no
exploitable integrated circuit in the photoreceptor...
Yep, they are.  Seen them myself in the malware lab.  No further comment
available, as I'm bound by NDA-of-doom.  But yes, SD cards have been
known to be infection vectors.  If you think about it for a while I'm
pretty sure you'll figure out how, but I unfortunately cannot connect
the dots for you.
Yep!  Been done.  SATA firmware has been exploited via the JTAG
interface, new firmware loaded onto it, and been used as a vector.

@_date: 2017-10-09 22:06:17
@_author: Robert J. Hansen 
@_subject: FAQ and GNU 
A request has been made that each instance of "Linux" in the FAQ be
replaced with "GNU/Linux".
I'm not inclined to make this change.  However, in order to make sure
that the FAQ reflects the community's wishes, I'm submitting the
proposal here for community feedback.
If anyone has strong feelings on it one way or another, chime in.

@_date: 2017-10-10 02:46:05
@_author: Robert J. Hansen 
@_subject: FAQ and GNU 
I disagree.  It's a more political term.
With respect to specific distros, we ought use the name the distro
prefers.  The Fedora Project releases Fedora, not Fedora GNU/Linux.  The
Debian guys release Debian GNU/Linux, not Debian Linux.  The people who
set up these distros have given their distros names, and it seems
appropriate to use the names properly.  It is as inappropriate to refer
to Debian Linux as it is to refer to Fedora GNU/Linux: in both cases
that's rejecting the community's right to name their distro what they wish.
When speaking generically about operating systems using the Linux
kernel, there it seems GNU is also inappropriate.  GNU is not an
inseparable part of Linux; we should not promulgate the myth they are.
In the FAQ, wherever "Linux" is used as a generic descriptor it is in a
context where the presence of GNU utilities is irrelevant.  Example:
"there is no single, consistent way to install GnuPG on Linux systems."
The truth/validity of that statement is in no way dependent on whether
one's talking about a system that uses the GNU userland or the BSD userland.
In those cases where "Linux" is used to open a segment detailing how
GnuPG works on different distros, I use the distro's preferred full name
or shortened name:
Yes, but they aren't mentioned in the FAQ.

@_date: 2017-10-10 22:49:57
@_author: Robert J. Hansen 
@_subject: Working with an Online and Offline Computer when using GnuPG - 
Supply chain security.  The more complicated the hardware, the harder it
is to prove the ICs and firmware haven't been exploited.  If you're
using hardware you scavenged from a ham radio swap meet, you can be
pretty sure there's nothing malicious in the hardware.
Our use case was a vote tabulating system communicating realtime updates
with a publicly-facing web server.  The assumption was the web server
was compromised: given that, how can you be absolutely sure there's no
communication channel back to the trusted tabulator?
Answer: a 1960s photoreceptor.
We didn't need a fast link from the tabulator to the web server: we
needed a slow and absolutely, positively, definitively one-way link.

@_date: 2017-10-10 23:55:32
@_author: Robert J. Hansen 
@_subject: FAQ and GNU 
I agree.  Bikeshedding frustrates me: I'll leave it at that.
Reviewing the last forty-odd emails on the subject, there are a small
number of regular contributors to the community who are in favor, a
small number opposed, and a smaller number of mostly-lurkers who have
exceptionally strong feelings.
I do not see a community consensus one way or another.  I'll continue
with my original plan.
Should any of the people with exceptionally strong feelings on the
subject want to fork the FAQ, well, it's under a permissive license for
a reason -- just please don't claim that it's the official FAQ.  :)

@_date: 2017-10-11 08:04:34
@_author: Robert J. Hansen 
@_subject: Working with an Online and Offline Computer when using GnuPG - 
Right.  Our assumption was that the web server would be compromised
within moments of bringing up the external-facing network.  Permitting
trusted machines to communicate in a *provably* one-way manner with
systems outside the DMZ is an important problem -- not just being able
to do it, but coming up with a way simple enough that non-technical
users can understand.
That's why the vote tabulating office is guarded by people with guns.  :)

@_date: 2017-10-12 14:56:57
@_author: Robert J. Hansen 
@_subject: OT: FAQ and GNU 
It's tempting, but unfair, to call these people a bunch of ideologues.
Most of us on this mailing list are ideologues, after all.  Human
rights, privacy, software freedom -- these are all pretty good ideas,
and I think we're right to be motivated by them.  They seem to be
logologues instead: it isn't enough to have the right ideas and be
working to put them into action, but we need to only use the right
language about it, as if the words were more important than the deeds.
One of my closest friends is a staunch atheist, the kind who thinks
Richard Dawkins is too conciliatory towards people of faith.  Recently
he suffered a stroke.  At the first sign he told one of his friends,
"I'm stroking out: help me."  He then sat there, cool as a cucumber with
a Zen smile on his face, as everyone jumped into action around him.  It
unnerved the paramedics, who thought his utter calm was a sign he didn't
understand what was happening.  Quite the opposite: as he explained to
the doctors, he understood what was happening perfectly well and that's
why he was so calm.  What was happening was he'd asked his friends to
save him, and so he was going to get saved: why should he worry?
Whenever he tells that story I laugh.  A man who claims to have no faith
demonstrates the power of it.  The way he *lives* faith, keeping
cheerful in the face of imminent death just on the strength of his
conviction that his friends would save him, is awe-inspiring.  I have
better sense than to tell him this, though: he'd get grouchy and accuse
me of being really annoying -- and he'd be right.  We can both enjoy the
benefits of faith in our lives, even if only one of us believes in God.
Ideologues: good.  Logologues: really annoying.
I will leave any application of this to the GNU/Linux-vs-Linux, or Free
Software-vs-Open Source, arguments to the reader.  I will, however, ask
that we remember we're ideologues of deeply compatible stripes.  :)

@_date: 2017-10-12 18:50:55
@_author: Robert J. Hansen 
@_subject: OT: FAQ and GNU 
It quite definitely does.  Unlike, say, French or Icelandic, where
there's an actual institution charged with the development of the
language, the *only* definition of correctness in English is found in
whether it conforms to everyday usage in the community in question.
You can insist all you want that a cheater is someone appointed by the
Crown to look after royal escheats, but (a) nobody cares that's what the
word originally meant and (b) you'll be using the language incorrectly.
(How did cheater get associated with dishonest people?  Let's say the
Crown's cheaters had a certain reputation...)

@_date: 2017-10-12 22:54:45
@_author: Robert J. Hansen 
@_subject: OT: FAQ and GNU 
Great: you learned something today!  Read up on linguistic
prescriptivism and descriptivism; you'll find it rewarding.
Style guides, dictionaries, and grammatical references are useful tools
in that they write down the tacit and informal agreements the world has
made about how to use language.  However, they're always behind the
times because the language is in constant flux.  To understand English,
one must look at how it is actually spoken.
What, that I'm a linguistic descriptivist?  Dude, I also use words like
"cromulent"[1], enjoy a good split infinitive[2], use "they" as a
singular epicene[3], and when I'm really feeling naughty I'll drink wine
straight from the bottle and read James Joyce[4].
... And why, yes, my mother *is* an English teacher, and I *do* have a
liberal arts degree.  :)
[1] Recently added to dictionaries, despite it being an utterly made-up
word, due to how often it was being used in language
[2] "To boldly go where no one has gone before!"
[3] ... along with the Bront? sisters, Thackeray, and Shakespeare
[4] "I was a Flower of the mountain yes when I put the rose in my hair
like the Andalusian girls used or shall I wear a red yes and how he
kissed me under the Moorish Wall and I thought well as well him as
another and then I asked him with my eyes to ask again yes and then he
asked me would I yes to say yes my mountain flower and first I put my
arms around him yes and drew him down to me so he could feel my breasts
all perfume yes and his heart was going like mad and yes I said yes I
will Yes."

@_date: 2017-10-13 09:46:04
@_author: Robert J. Hansen 
@_subject: OT: FAQ and GNU 
By writing and maintaining the FAQ.  With the exception of some light
edits by Werner and about three sentences from A.M. Kuchling, the entire
thing is my work.
I'm not the manual maintainer; perhaps ask that person first.

@_date: 2017-10-13 11:12:10
@_author: Robert J. Hansen 
@_subject: OT: FAQ and GNU 
Sure it does.  Chaucer, Joyce, Shakespeare.  We even have special
grammatical terms for when the author decided to say "to hell with it".
English is a strict subject-verb-object (SVO) language: screw that up
and you sound like Yoda... or Shakespeare.  "Bloody thou art; bloody
will be thy end." (_Richard III_)  Inverting word order is called
Sentence fragments are bad, right?  Meet anapodoton.
Repetition is bad.  Well, except if you're Churchill, in which case
epizeuxis is your friend.  "Never give in -- never, never, never, never,
in nothing great or small, large or petty, never give in except to
convictions of honour and good sense.  Never yield to force; never yield
to the apparently overwhelming might of the enemy."
English is chock full of special rules that tells speakers how we ought
break the rules.  It's beautiful.  :)
Perfectly valid depending on the community and the dialect.  When I go
visit my Southern relatives I don't talk about dragonflies, I talk about
snake doctors.  I don't say "the sun went down," I say "the sun's gone
done."  It's called code-switching, the ability to shift between
different dialects, vocabularies, and grammatical rules.
I get that you're a linguistic prescriptivist.  But English --
especially American English -- isn't.
Sure.  And "cheater" was originally introduced to refer to an employee
of the Crown charged with administering real estate.  But that's not
what it means any more, and that's not what Linux means any more, either.
Sure.  English is a sloppy language; that's what makes it so awesome.
Embrace the mutability.  Set yourself free.  :)
I continue to be amused by your tendency to think the English language
has to respect the fragility of your linguistic beliefs.  :)

@_date: 2017-10-13 11:26:07
@_author: Robert J. Hansen 
@_subject: FAQ and GNU 
I consider the current amusement I'm receiving small payment for my
having to read every last %$^$ message in the bikeshedding.
But, as it's been requested to take it off-list -- and it *is* pretty
off-topic -- I think it's only genteel to do so.  And what a shame: I
was looking forward to showing examples of iambic pentameter that were
neither iambic, nor pentameter.  :)

@_date: 2017-10-26 22:06:49
@_author: Robert J. Hansen 
@_subject: Verify that the file is from who I expect it to be from 
Look for output like:
Signature made 10/26/17 22:01:37 Eastern Daylight Time
               using RSA key CC11BE7CBBED77B120F37B011DCBDC01B44427C7
Good signature from "Robert J. Hansen " [ultimate]
                aka "Robert J. Hansen " [ultimate]
                aka "Robert J. Hansen "
See that line reading "Good signature"?  That's what you're looking for.
 Hope this helps.  :)

@_date: 2017-09-02 10:58:50
@_author: Robert J. Hansen 
@_subject: Questions about particular use cases (integrity verification w/o 
Nope.  You can tell how many subkeys it was encrypted for, but not how
many distinct certificates those represent.  If one recipient has 10
subkeys and you encrypt to all 10, there will be 10 packets awaiting
you... but there's no way to determine these all correspond to one

@_date: 2017-09-12 15:07:57
@_author: Robert J. Hansen 
@_subject: [Feature Request] Multiple level subkey 
Until and unless you present a usability study involving 100+ people
composing a representative sample of an identifiable community, you
don't know a thing.
Over the last 25 years I cannot count the number of people who were sure
their use case was common, or their pet idea would result in widespread
GnuPG usage, or what-have-you.  And without exception, not one has been
I understand you have a belief that your use case is common.  Until and
unless you present a study showing that it actually *is* common, I will
not share in your belief.  I suspect many people here share in this
Househusband.  English has used this word since 1858.
Either way, please don't use housewives or househusbands as examples of
"clueless users".  They are far from it.  They may lack sophisticated
technical skills, but that's not the same as being foolish or clueless.
If you want people to use your product, you need to start by respecting
your users.
No.  Big, emphatic, *NO*.
There is no average user.  Please repeat that sentence until it sticks.
There is no average user.  Average users don't exist.  They're myths.
Unicorns.  And if you design for an average user, you're going to make
it a poor experience for essentially everyone.
During WW2, the United States government spent a lot of money doing
measurements of fighter pilots.  Height, weight, build, length of arms,
length of legs, size of their hands, and more.  With all this data they
built cockpits that would be comfortable for 90% of pilots.  Pilots
hated their cockpits because they were terribly uncomfortable.  Real
people fell outside of the 90% mark in at least a few categories.  In
the course of making a cockpit that would fit almost everyone
comfortably, it fit almost no one comfortably.
Modern fighter jets have instead embraced customizability.  The American
F-15E fighter can accommodate pilots from 5'4" to 6'6" (1.62m to 1.98m),
a variety of builds, reaches, and more.  By recognizing there was no
such thing as an average pilot, the designers opened the door to make a
cockpit that was comfortable for the vast majority of users.
Your "average internet user" is a 1940s-style way of thinking.  We need
to do better than that.

@_date: 2017-09-13 22:57:58
@_author: Robert J. Hansen 
@_subject: [Feature Request] Multiple level subkey 
They all provide intensely personalized experiences.  Just because they
don't expose the dials and switches to you doesn't mean they don't exist.
As an example: Google Chrome scans the content of webpages you visit,
and uses that to guide autocomplete in the search bar.  Your
autocomplete settings are automatically personalized based on your
browsing history with no user intervention needed.
Automatic personalization of user experience based on the software
learning the user's behavior is pretty much the gold standard in UX
design nowadays.  It's a commendable goal and worth pursuing.

@_date: 2017-09-14 17:58:30
@_author: Robert J. Hansen 
@_subject: [Feature Request] Multiple level subkey 
Create a GitHub repo and start committing code.
What you want to do is not something that's within the scope of the
OpenPGP RFC.  It's close, but it's not quite there.  If you do this,
you'll have to go beyond the RFC.  So go off, start with a clean sheet
of paper, design a system, and start hacking.  Probably 95% of the
crypto code is already written for you.  All you need to do is design a
protocol, implement it, and give it to the world.
You've already heard a lot of good advice from people here.  Now's the
time to go off and start committing code.

@_date: 2017-09-15 04:52:32
@_author: Robert J. Hansen 
@_subject: [Feature Request] Multiple level subkey 
Nope.  Not kidding.
The first version of your product will be awful.  That's to be expected.
 Look into PGP 1.0 sometime: it was so terrible PRZ had to basically
burn it down and start over.  And, you know, *that's okay*.
Often, the best way to begin learning how to do something is to go out
and do it.  Linus Torvalds was a mediocre C programmer who barely
understood Minix when he first started working on Linux.  PRZ's initial
PGP 1.0 was a joke.  Pretty much every successful software project you
see today started from a bungled beginning, but the people working on
the project learned from their mistakes and slowly things became very,
very good.
The best way to discover what problems you'll have to solve is to go out
and encounter them.  Once you do that, *then* build solutions.

@_date: 2017-09-21 10:55:26
@_author: Robert J. Hansen 
@_subject: Houston, we have a problem 
By remembering that anyone can create a key claiming to be anyone, and
that seeing a signature allegedly from Werner (or anyone) means
absolutely nothing until and unless you've verified the signing
certificate actually belongs to him.
Key validation -- ensuring a key really belongs to who it says -- is an
important step.  It cannot be skipped.  It is not optional.

@_date: 2017-09-21 16:13:56
@_author: Robert J. Hansen 
@_subject: Houston, we have a problem 
About 25 years ago I first saw the suggestion that signatures from
unvalidated certificates should simply not be visible to the end-user,
as a signature from an unvalidated certificate is meaningless and the
risk of people believing "oh, Frank (or whoever) signed this!" is so high.
(A command of --list-all-sigs would need to be added, to force display
of signatures from unvalidated certificates.)
I've thought it was a good idea ever since I first saw it.  I have
always been in a distinct minority, though...

@_date: 2017-09-21 16:16:12
@_author: Robert J. Hansen 
@_subject: Houston, we have a problem 
By validating Governikus's certificate.
You seem to be asking the same question (and getting the same answer)
over and over again.  Perhaps try a different phrasing?  Or is it that
the answer isn't clear?

@_date: 2017-09-21 17:06:18
@_author: Robert J. Hansen 
@_subject: Houston, we have a problem 
No.  When you see something claiming to be Werner's sig on Erika's
certificate, ask yourself:
If you can positively answer all three questions 'yes', then you should
trust it.  Otherwise, you shouldn't.

@_date: 2017-09-22 01:22:13
@_author: Robert J. Hansen 
@_subject: Prince Jones v US 
Good news for US citizens: _Prince Jones v US_ was decided Thursday.
The important text from the opinion is recreated here, and the
implications for encrypted email follow.
* * * * *
But in addition to the fact that people reasonably value and hope to
protect the privacy of their location information, what necessitates our
conclusion is the _method_ by which the government obtained the location
information in this case. Unlike in a situation in which the government
determines a person's location through visual surveillance or by
employing the older generation of tracking devices, it cannot be argued
that "the information obtained by [the government] in this case was ...
readily available and in the public view". The cell-site simulator
employed in this case gave the government a powerful person-locating
capability that private actors do not have and that, as explained above,
the government itself had previously lacked -- a capability only
superficially analogous to the visual tracking of a suspect. And the
simulator's operation involved exploitation of a security flaw in a
device that most people now feel obligated to carry with them at all
times. Allowing the government to deploy such a powerful tool without
judicial oversight would surely "shrink the realm of guaranteed privacy"
far below that which "existed when the Fourth Amendment was adopted". It
would also place an individual in the difficult position either of
accepting the risk that at any moment his or her cellphone could be
converted into tracking device or of forgoing "necessary use of" the
cellphone. We thus conclude that under ordinary circumstances, the use
of a cell-site simulator to locate a person through his or her cellphone
invades the person's actual, legitimate, and reasonable expectation of
privacy in his or her location information and is a search.
* * * * *
The above is taken from the opinion -- citations omitted.  But it
appears to me this logic is immediately applicable to many different
kinds of surveillance: namely, if it involves security flaws in common
everyday technologies which millions of Americans entrust with their
secrets and who really cannot reasonably avoid using... then it needs a
The implications for electronic privacy in the United States should be
clear.  This is a really good development.  :)

@_date: 2017-09-22 10:18:51
@_author: Robert J. Hansen 
@_subject: Prince Jones v US 
It was a DC Court of Appeals decision, not SCOTUS.  It appears unlikely
to hit SCOTUS.

@_date: 2017-09-26 11:37:53
@_author: Robert J. Hansen 
@_subject: Houston, we have a problem 
As the guy who was largely pushing that on Enigmail ... although I
strongly sympathize, there's a rock here and a hard place there.
UX is not driven by the users we *might* have: it's driven by the users
we *do* have.  The users we do have *do not want to switch*.  I think
that after investing so much in learning the current system, users tend
to develop powerful opinions the UX should just be left alone please
don't fix a thing.
Imagine you have this certificate:
+ Kate 0xDECAFBAD
+-- Kathryn Carver 0xDECAFBAD
(That is to say, a primary userID of Kate, and one other UIDs using her
full name.)
Now throw that into a whole bunch of other certificates and render them
in a GUI toolkit.  All rows are collapsed by default.  Now ask a user to
find the certificate associated with Kathryn Carver.
90% of users will click on the "Name" column header to sort by name,
will survey the Ks, and then say "she's not in the system."  (And yes, I
found this in a usability study I did in '07 with Tristan Thiede and
Juan-Pablo Hourcade.)
Clearly there's a problem here.  Obviously the way we present
certificates to users is broken and wrong.  But God help you if you
change the way you present certificates: some people will complain
loudly and the vast majority of users just won't consider switching.
Change is hard, and I have no good answer for that.

@_date: 2018-02-04 05:43:46
@_author: Robert J. Hansen 
@_subject: Can't import public key 
Please don't.  GnuPG 1.2.1 dates back to *October 2002*.  It's fifteen
years old and was EOLed ages ago.  There are many known problems with
it.  Please upgrade.
You'll find few people here will be able to help you, I'm afraid.  :(

@_date: 2018-02-15 10:56:53
@_author: Robert J. Hansen 
@_subject: Huawei manual about Gnupg 
The documentation we create is free for the world to use for any
purpose.  If Huawei wants to use it, they can, so long as they respect
the license.  But so long as Huawei is selling proprietary stuff, why
should we volunteer our time and labor to help them sell more
proprietary stuff?

@_date: 2018-01-07 10:39:39
@_author: Robert J. Hansen 
@_subject: Import keys from .gnupg folder 
Obligatory drum beating: I wrote a tool, Sherpa, to help ease migration
between different GnuPG versions.

@_date: 2018-01-08 10:11:24
@_author: Robert J. Hansen 
@_subject: Tool: Sherpa: (Re: Import keys from .gnupg folder) 
Inadequate testing.  It's in a "it works for the core dev and two other
people" stage, which to me screams not ready for the real world.

@_date: 2018-01-15 02:13:50
@_author: Robert J. Hansen 
@_subject: Hide UID From Public Key Server By Poison Your Key? 
Uh -- how?
There is no mechanism in the keyserver to do this.  That's why you have
to validate certificates you receive from the keyserver.  The fact
there's a UID named "Robert J. Hansen " on key
0xB44427C7 provides you with precisely *zero* evidence that I'm Rob
Hansen or that Rob Hansen even exists.  For all you know my name is
Maurice Micklethorpe.
I rarely use language like this, but this time I think it's warranted:
This is a total dick move.  Don't do this.  You'll make yourself a lot
of enemies, and if you pick the wrong real names and emails, some of
those people are pretty damn good at figuring out what's going on.
Don't put real names and emails belonging to other people on your cert.
It's *rude*.  If someone goes looking for "Robert J. Hansen
" I want them to see one cert is newest and I want
them to use that one.  If you go about putting my name and email address
on your cert, I'm going to get cross.
Again: this is a total dick move.  Don't do this.

@_date: 2018-01-15 14:39:56
@_author: Robert J. Hansen 
@_subject: Remove public key from keyserver 
Nope.  SKS has no cryptographic code in it.  It does no evaluation of
certificates or signatures.
Adding this feature would require a vast amount of effort to add RFC4880
signature verification into the core of SKS.  And it would also destroy
one of the design goals of SKS, which is "the keyserver never discards
To implement this would require a completely new keyserver
implementation, one with considerably more code, which would *by design*
drop certificates.  I'd say it would take about five years for such a
re-work to come to maturity and be trusted.  So yes, it can be done, but
it's not something to be done lightly, nor without a ton of buy-in from
the existing keyserver community.
Many times.  There appears to be no easy fix.

@_date: 2018-01-15 15:00:34
@_author: Robert J. Hansen 
@_subject: Remove public key from keyserver 
SKS came out in 2003.  It largely replaced PKS, which was widely
considered old and broken.  SKS was Yaron Minsky's Ph.D thesis, wherein
he developed some really cutting-edge math to make key sync fast and
"Old-fashioned" is not the phrase I'd use to describe something
considerably newer than GnuPG.
It's from 2003.  It doesn't need modernization.
Keyservers are designed the way they are for a reason.  If keyservers
*never ever discard or modify existing data*, then you can easily
identify any code which theoretically might be able to discard data as a
bug, a vulnerability, or tampering with it by a malicious actor.  It
makes code review easier and it makes it difficult for repressive
regimes to surreptitiously take down certificates belonging to dissidents.
This "we never discard or modify existing data, we only ever add new
data" rule has some *really really nice* properties for information
security.  However, it also comes with a downside: we can't discard or
modify existing data.
It's a package deal.  When SKS was being built in the early 2000s there
were vigorous discussions about what properties we wanted in a
keyserver.  We knew exactly what we were getting into.
Please, learn why it was built before you go about saying it was built
I worked at PGP Security during that time period.  It really didn't.  If
we'd received a court order compelling us to remove a cert from the
keyserver and not tell anyone, we could have complied.  That gave the
flaming heebie-jeebies to at least three engineers on the floor,
including the keyserver admin, a guy named Randy Harmon.
Whether you embrace a "our keyserver can delete things" or "our
keyserver is delete-free" model, that decision has immediate
consequences you will not like.

@_date: 2018-01-15 15:09:52
@_author: Robert J. Hansen 
@_subject: Remove public key from keyserver 
I personally know Syrians and Iranians who have given me bear hugs at
conferences when they hear I'm involved with GnuPG, Enigmail, and am on
the periphery of SKS.  A common theme with these people is they believe,
on the basis of reasonable evidence, that their governments are involved
in active campaigns to intercept and/or degrade communications,
including by CNO means.
I have been asked probably ten times in the past five years by
dissidents, "Can I trust the keyservers?  Is there any way to tamper
with the data on them?"
I have always told them the keyservers are trustworthy, and that they
are designed to never delete or modify existing data.  This seems to be
a great relief to those dissidents.  If the keyserver network were to go
away tomorrow, it would definitely impact people in repressive regimes.

@_date: 2018-01-15 17:45:49
@_author: Robert J. Hansen 
@_subject: a step in the right direction 
... shutting down a keyserver network relied on by literally tens of
thousands of people, to say nothing about OS distributions, is a "step
in the right direction"?
Okay.  Fine.  Let's say you wave a magic wand and you're able to make
the keyserver network go away.  What are the immediate, *predictable*,
First, people in bad places like Syria and Iran lose the ability to
easily get public keys for journalists in free countries.  The neat
thing about the pool is nobody knows exactly who all is in it.  Years
ago for some months I ran a covert keyserver to see how practical it
would be for people in hostile regimes: my keyserver was not part of the
public pool, but synced with it.  That's useful because a regime might
firewall off the entire pool, but so long as covert nodes exist the
whole of the network is still accessible even in information-controlling
Second, your operating system -- if you're running something like a
Linux distro, or macOS using Homebrew, or heck, even Windows with
msys2/mingw -- *BREAKS*.  You can't get updates any more.  Let's look at
why, using the package manager in msys2/mingw/Arch Linux.  It's called
In pacman, each package is signed by the package maintainer.  The
package maintainer's certificate is in turn signed by at least three
other pacman maintainer certs.  E.g., if you manage a package called
"fooblitzsky", you sign the fooblitzsky packages with your cert, and
three msys2 maintainers sign your cert.  This way, end users can be
confident that you, the maintainer, personally authorized this release,
and that you're trusted by the msys2 team.
Now that you've taken down the keyserver network, you go to install
fooblitzsky, and ... uh ... wait.  You can get the package, but you have
no way of getting the maintainer's cert to verify the package.
_Literally every major FOSS package manager breaks.  Updates become
Let that sink in for a moment.
I don't think you understand anything about the ecosystem here.  You're
advocating burning down a _critically important part of the entire FOSS

@_date: 2018-01-15 18:32:07
@_author: Robert J. Hansen 
@_subject: Remove public key from keyserver 
(Responding here because Stefan's message hasn't hit my mail server yet)
Which is not a modernization issue.  It's a feature request, and the
feature you're asking for is DRM.  Literally.  You're asking that the
keyserver network be rewritten to give you the ability to manage how
information, which you think belongs to you, gets shared: that's DRM.
DRM schemes are awful and they don't work.

@_date: 2018-01-15 19:01:52
@_author: Robert J. Hansen 
@_subject: Hide UID From Public Key Server By Poison Your Key? 
I should also add: in addition to being a dick move, this approach
doesn't work.  It's genuinely counterproductive.
If I were to see a certificate with a hundred different UIDs, I'd
immediately start digging around.  This is not what you want: in the
course of poisoning your cert you've made it odd, unusual, and interesting.
Next thing I'd do would be to start scouring the internet for these
usernames.  Most would simply not have any trail associated with them
whatsoever: I'd email them and get bounce messages to confirm it.  I've
now largely cured your attempt at poisoning your cert.  I'm down to a
handful of user IDs.
One of them will have a very carefully-curated digital trail.  The
others will not.  Congratulations: I've just found the identity you want
to keep secret.  Now I know there's some connection between this
identity and the small number of user IDs that are left after depoisoning.
Now it's just a matter of time until I figure out who you are and what
fake identity you're using... and here's the rub: until I saw over 100
UIDs on your cert, I wouldn't have given a damn and wouldn't have bothered.
The worst thing you can do in your situation is to draw attention to
your mistake.  Your poisoning attempt is genuinely counterproductive.
You're making yourself visible.
I cannot advise against this course of action strongly enough.  Burning
your current fake identity is probably far safer and more effective.

@_date: 2018-01-15 20:17:01
@_author: Robert J. Hansen 
@_subject: a step in the right direction 
I think you'll have a hard time convincing people that when speaking
about human rights activists in North Korea, it's somehow inappropriate
to say they're living in a bad place.  Repressive governments are real
threats to human rights, and it doesn't do anyone any good to pretend
No, you're not.
Evacuation and replacement requires a replacement exists.  The moment
you present an alternative that's running and working and stable, *then*
we can have a discussion about moving to the exits.
US keyservers are.  The only thing EU regulations will do is end
keyservers in the EU.
The SKS community has been discussing a considerably worse nightmare
scenario for the past seven years.  There have been a number of flawed
proposals made in that time period.  Your time might be better spent
perusing the last seven years of sks-devel to learn what has already
been proposed and the flaws in each of them.

@_date: 2018-01-16 03:20:54
@_author: Robert J. Hansen 
@_subject: a step in the right direction 
(I originally composed this on a mobile device and it was held for
moderation.  Re-sending it from my laptop.)
(Apologies for the terseness: on a mobile device)
I am darkly amused at someone who has not done the research into what
the nightmare scenario *is* telling me that it's not a nightmare scenario.
The nightmare scenario is malcontents realize the keyserver network is a
multijurisdictional, redundant, distributed database from which data
cannot be deleted... and decide this makes it an ideal way to distribute
child porn.  The moment that happens, the keyserver network goes down
hard as every keyserver operator everywhere gets exposed to massive
criminal liability.
We've known about it for several years.  We've been thinking about how
to counter it for several years.  It turns out that countering it is a
*really hard job*.  If you make it possible to delete records from a
keyserver, you open the door to all kinds of shenanigans that
governments could force keyserver operators to do on their behalf.
How do you make it possible to delete records from a keyserver, while at
the same time keeping the keyserver resistant to malicious tampering
from adversaries?
This is an incredibly hard question to address.  And frankly, you're not
adding a single iota to the discussion.  But if you want to continue it,
I'd suggest speaking up over at sks-devel at gnu.org, where people have
been having this discussion off and on for years.

@_date: 2018-01-16 09:54:37
@_author: Robert J. Hansen 
@_subject: a step in the right direction 
I was the one who brought up DRM.
What Stefan and Listo want is some mechanism by which, if I have a copy
of their public key, I can be prohibited from sharing that with a
keyserver.  How I get to use data in my possession is controlled by a
third party -- that's DRM.  In this case it's a voluntary, half-assed
DRM scheme, but it's still in the family of DRM schemes.

@_date: 2018-01-16 10:35:09
@_author: Robert J. Hansen 
@_subject: Remove public key from keyserver 
That's because you think information *does* belong to you.  But
information doesn't belong to anyone: the nature of information is that
it has no owners.  You can place restrictions on what people do with
information -- maybe -- but you can't make information into a possession
any more than you can declare you own mathematics.
The fact an EU committee has declared otherwise strikes me as like the
legend of King Canute.  When his advisers told him his power was without
limit, Canute took them to the ocean and let them watch as he ordered
the tide to not come in.  The tide came in anyway, thus proving Canute's
point to his advisers -- just because they say it's so doesn't mean it's so.
None of this is to say you have no privacy interest in your data, nor
that our laws shouldn't facilitate you having some control over your
private data.  But our laws also shouldn't be written in such a way as
to lead people to think they can *own* information.
You seem to be under the belief I don't see this as a problem.  As a
quick check in the archives will show you, I've been talking about this
problem for at least eight years.  And I know Werner's been dealing with
this problem for even longer.
Just because I think you understand neither the problem nor the deeply
problematic aspects of your proposed fixes, does not mean I disagree
there's a problem.
I already know exactly what you're concerned about.  I share in those
concerns.  I do not believe you're contributing to finding an answer to
these problems.

@_date: 2018-01-16 10:56:39
@_author: Robert J. Hansen 
@_subject: Remove public key from keyserver 
The pgp.com keyserver had some serious problems.  When I was at PGP
Security there were at least three engineers on the floor -- myself, Len
Sassaman, and Randy Harmon (the keyserver admin!) -- who thought the
keyserver was a pretty marginal idea specifically because we could be
compelled by governments to do unpleasant things.  None of us used that
keyserver in our own personal lives.
The pgp.com keyserver is also a *standalone* server.  It does not sync
with the keyserver network.  (Search for 0xB44427C7, for instance.  My
cert has been in the SKS network for years, but as of this writing isn't
in the pgp.com keyserver.)  That's important for several reasons.  It
means it's very easy for governments to blackhole, for instance.  And it
also means it's possible to drop certificates.
One of the other reasons SKS doesn't allow dropping information is
because it lets two disagreeing keyservers figure out very easily what
the canonical and correct data is: it is the union of the disparate
data.  As soon as you change this to allow for discarding data, suddenly
each certificate needs to bear with it some way to prove to other
keyservers that it's the most recent record and thus correct.  Now you
get into needing trusted timestamps, certifications of changes, adding
crypto code into SKS, and ... things get out of hand quickly.
If you like the PGP Global Directory, go for it.  Use it!  It still exists.
But please, understand why SKS works the way it does before telling
people to change it.

@_date: 2018-01-16 11:05:03
@_author: Robert J. Hansen 
@_subject: a step in the right direction 
I welcome the correction, but I stand by my statement.  Many users,
particularly in corporate environments, roll their own packages and rely
on the keyservers to propagate those signing keys worldwide.  I know
I've seen RHEL corporate networks doing this; I _believe_ I've seen
Ubuntu-based corporate networks doing this.  (Back in 2016 I wound up
doing just this task for an RHEL network, while my officemate handled
the Ubuntu machines -- I have no hands-on experience with the Ubuntu
side of things, just recollections of hearing my officemate talk about
It is correct, though, to say official Debian packages would have
minimal disruption.  Thank you.  :)

@_date: 2018-01-16 11:42:29
@_author: Robert J. Hansen 
@_subject: DRM? 
It is theoretically and practically possible to have a keyserver that
honors such requests, but what many people want is *enforcement*.  Not
merely a voluntary system that's trivially circumventable, but some
mechanism by which their public keys can be actively kept out of

@_date: 2018-01-16 15:38:20
@_author: Robert J. Hansen 
@_subject: DRM? 
Public: it may be shared freely with the world.
Private: it must not be shared freely with the world.
(Fundamentally you're right, in that what Stefan et. al. are asking for
is for public certificates to become private certificates.)

@_date: 2018-01-16 21:52:11
@_author: Robert J. Hansen 
@_subject: Will gpg 1.x remain supported for the foreseeable future? 
The game plan has always been to retire 1.4 as soon as practical.  Do
not rely on it existing in the future.

@_date: 2018-01-16 22:37:52
@_author: Robert J. Hansen 
@_subject: Will gpg 1.x remain supported for the foreseeable future? 
I should also say some more things about it, like --
* it's not going away in the near future
* we know people like to use it for servers
* it's a lot of work to keep two codebases going
* new crypto, like ECC, will not be backported to 1.4
* new features will probably not be backported
* if you need 1.4 support, contact g10 Code GmbH

@_date: 2018-01-23 16:55:20
@_author: Robert J. Hansen 
@_subject: Keys clean of all signatures except those made by others I trust 
Note that this can be done in a bash one-liner:
$ for x in `gpg --list-keys|grep "[A-F0-9]\{40\}"|sed 's/ //g'` ; do gpg
--edit-key $x clean save ; done
Or in Windows Powershell:
"[A-F0-9]{40}") { &gpg --edit-key $keymatch.ToString().Trim() clean save;}
... There are undoubtedly half a dozen ways to do this quickly.  But if
you're looking for one, these will do.

@_date: 2018-01-24 18:01:25
@_author: Robert J. Hansen 
@_subject: Keys clean of all signatures except those made by others I trust 
Correction noted, thank you.  Have one in return.  :)
"fpr" should be $fpr, I think.

@_date: 2018-01-30 00:36:09
@_author: Robert J. Hansen 
@_subject: Key Length Issue on Mac OS X 
I don't see any issue there.  Two certificates may be of vastly
different lengths for many different reasons.  So far there's no reason
to believe they contain different lengths of asymmetric keys.
A 4096-bit key takes up about 12 lines of text in a certificate.  The
rest is other, non-key-related stuff.
Instead of posting a link to an image of two certificates, please share
the two certificates themselves -- for instance, via Dropbox or
Pastebin.  Once we can see the actual certificates we'll be able to more
fully explain what's going on.

@_date: 2018-06-08 04:15:08
@_author: Robert J. Hansen 
@_subject: EFAIL countermeasure recommendations on your site 
This is the sort of thing better addressed to email plugin authors. Efail had very limited applicability to GnuPG itself.

@_date: 2018-06-27 00:55:50
@_author: Robert J. Hansen 
@_subject: gpg2 
Try "gpg2 --version" and look for a line like:
Compression: Uncompressed, ZIP, ZLIB, BZIP2
... I suspect you'll discover whoever compiled your GnuPG 2 neglected to
include support for the BZIP2 algorithm.

@_date: 2018-06-27 02:58:58
@_author: Robert J. Hansen 
@_subject: gpg2 
Please *don't* do this.  BZIP2 compression is common enough that if a
GnuPG build doesn't have it, the best course of action is to get a
properly-done build.
Removing BZIP2 from the preference list will hide the problem (no
support for BZIP2), not address it!

@_date: 2018-03-02 23:43:26
@_author: Robert J. Hansen 
@_subject: New employment 
I'm taking a new job with IronNet Cybersecurity, which is run by former
Director of the National Security Agency Keith Alexander.  My work will
not overlap with GnuPG in any way.
I'm presenting this in a spirit of full disclosure, so that if and when
it comes out later that "the guy who maintains the FAQ was spotted in a
bar with Keith Alexander last December!", people here can say "yeah, it
was a corporate Christmas party, big deal".

@_date: 2018-05-14 03:27:42
@_author: Robert J. Hansen 
@_subject: Don't Panic. 
[taps the mike]
Hi.  I maintain the official GnuPG FAQ.  So let me start off by
answering a question that is certainly about to be asked a lot: "Should
we be worried about OpenPGP, GnuPG, or Enigmail?  The EFF's advising us
to uninstall it!"
Werner saw a preprint of this paper some time ago.  I saw it recently.
Patrick Brunschwig of Enigmail saw it.  None of us are worried.  Out of
respect for the paper authors I will skip further comment until such
time as the paper is published.
It would've been nice if EFF had reached out to us for comment, rather
than apparently only talking to the paper authors.  We hope they'll
reach out next time.

@_date: 2018-05-14 04:27:35
@_author: Robert J. Hansen 
@_subject: Efail or OpenPGP is safer than S/MIME 
The following is what I wrote to a journalist covering the story:
We've known about problems in OpenPGP's feedback mode for at least
thirteen years.  (See  for an
example.)  The OpenPGP working group resolved these problems by adopting
modification detection codes (MDCs).  GnuPG properly implements MDCs and
gives clear and unambiguous warnings if a message lacks an MDC.  The
paper authors acknowledge that if an email client handles these warnings
sensibly, their attack fails.
In other words, their attack is completely dependent on email clients
handling our warnings in a broken way.  Great: that they've found bugs
in major email clients is a good thing, but where's the flaw in the
OpenPGP protocol or GnuPG's implementation of it?  And does this really
deserve the hype-tastic title "Breaking S/MIME and OpenPGP Email
Encryption" when it really doesn't do that?
In grad school my adviser told me to follow Napoleon's Rule in paper
titles.  "If you tell the world you're going to conquer Russia, you'd
better conquer Russia."  This paper doesn't deliver on what its title

@_date: 2018-05-14 05:15:42
@_author: Robert J. Hansen 
@_subject: Efail or OpenPGP is safer than S/MIME 
By default, GnuPG will scream bloody murder if a message lacks an MDC or
if the MDC is invalid.  At that point it's up to your email client to
pay attention to the warning and do the right thing.  Enigmail 2.0 and
later are fine, but I can't speak for other systems.
Of course, if you're crazy enough to disable the MDC check
("--no-mdc-warning") then all bets are off, but really, you'll get what
you deserve.
MDC is an attribute of the packet, not the cipher.  By default, all
ciphers in the GnuPG suite use MDC.
Hope this puts your mind at ease.  :)

@_date: 2018-05-14 05:42:19
@_author: Robert J. Hansen 
@_subject: Efail or OpenPGP is safer than S/MIME 
Let's try it and find out.  :)
PS C:\Users\rjh> gpg --recipient 0xB44427C7 --cipher-algo 3DES
--disable-mdc --encrypt --sign foo.cc
gpg: 0xB44427C7: skipped: public key already present
gpg: WARNING: encrypting without integrity protection is dangerous
PS C:\Users\rjh> gpg foo.cc.gpg
gpg: WARNING: no command supplied.  Trying to guess what you mean ...
gpg: encrypted with 256-bit ECDH key, ID AA24CC81B8AED08B, created
      "Robert J. Hansen "
File 'foo.cc' exists. Overwrite? (y/N) y
gpg: Signature made 05/14/18 05:40:46 Eastern Daylight Time
gpg:                using EDDSA key 4BF2042AE28F62B81736E8CBA83CAE94D3DC3873
gpg: Good signature from "Robert J. Hansen " [ultimate]
gpg:                 aka "Robert J. Hansen " [ultimate]
gpg:                 aka "Robert J. Hansen "
gpg: WARNING: message was not integrity protected
... Yep, GnuPG will warn you the message was not integrity protected.
Your email client should see this warning and refuse to render the message.

@_date: 2018-05-14 07:18:29
@_author: Robert J. Hansen 
@_subject: Efail or OpenPGP is safer than S/MIME 
Fascinating.  I've thrown it over to Patrick: we'll look into it and get
back in touch soon.

@_date: 2018-05-14 07:23:25
@_author: Robert J. Hansen 
@_subject: Efail or OpenPGP is safer than S/MIME 
It's worth noting, incidentally, the  attack flat-out requires
MIME.  So inline PGP messages are not vulnerable, as there's no MIME
parsing pass which can be exploited.  So you're *still* safe, although
this is still a bug that should be fixed.  ;)
I can recreate the bug; I'll be bringing it up to Patrick soon.

@_date: 2018-05-14 07:25:09
@_author: Robert J. Hansen 
@_subject: Efail or OpenPGP is safer than S/MIME 
... and Patrick, moving faster than the speed of light, already has the
bug triaged and bounced back.  This is actually a GnuPG bug, not an
Enigmail bug.  From Patrick:
The problem is that gpg doesn't say anything. I would expect a
DECRYPTION_FAILED message here:
[GNUPG:] ENC_TO 5F5FDF400616A9CF 1 0
[GNUPG:] KEY_CONSIDERED 4F9F89F5505AC1D1A260631CDB1187B9DD5F693B 0
[GNUPG:] KEY_CONSIDERED 4F9F89F5505AC1D1A260631CDB1187B9DD5F693B 0
gpg: WARNING: cipher algorithm CAST5 not found in recipient preferences
[GNUPG:] DECRYPTION_KEY 530187ED159A04E6F53ED1385F5FDF400616A9CF
4F9F89F5505AC1D1A260631CDB1187B9DD5F693B u
[GNUPG:] KEY_CONSIDERED 4F9F89F5505AC1D1A260631CDB1187B9DD5F693B 0
gpg: encrypted with 4096-bit RSA key, ID 5F5FDF400616A9CF, created
      "Patrick Brunschwig "
[GNUPG:] BEGIN_DECRYPTION
[GNUPG:] DECRYPTION_INFO 0 3
[GNUPG:] PLAINTEXT 62 1526296937
[GNUPG:] PLAINTEXT_LENGTH 4
[GNUPG:] NEWSIG
gpg: Signature made Mon May 14 13:22:17 2018 CEST
gpg:                using RSA key 4F9F89F5505AC1D1A260631CDB1187B9DD5F693B
[GNUPG:] KEY_CONSIDERED 4F9F89F5505AC1D1A260631CDB1187B9DD5F693B 0
[GNUPG:] SIG_ID Rh02jRM7bb5K0OOXQaEgmdJF+Bo 2018-05-14 1526296937
[GNUPG:] KEY_CONSIDERED 4F9F89F5505AC1D1A260631CDB1187B9DD5F693B 0
[GNUPG:] GOODSIG DB1187B9DD5F693B Patrick Brunschwig gpg: Good signature from "Patrick Brunschwig "
gpg:                 aka "Patrick Brunschwig "
gpg:                 aka "[jpeg image of size 13251]" [ultimate]
[GNUPG:] VALIDSIG 4F9F89F5505AC1D1A260631CDB1187B9DD5F693B 2018-05-14
1526296937 0 4 0 1 10 00 4F9F89F5505AC1D1A260631CDB1187B9DD5F693B
[GNUPG:] TRUST_ULTIMATE 0 direct
[GNUPG:] VERIFICATION_COMPLIANCE_MODE 23
[GNUPG:] DECRYPTION_OKAY
gpg: WARNING: message was not integrity protected
[GNUPG:] END_DECRYPTION

@_date: 2018-05-14 07:47:12
@_author: Robert J. Hansen 
@_subject: Mailpile on Efail 
Short version: Mailpile isn't impressed, either, and is a little annoyed
they were mistakenly listed as being vulnerable.

@_date: 2018-05-14 08:27:44
@_author: Robert J. Hansen 
@_subject: Efail press release 
Over the last few hours, Werner, Andre, and I have been working on an
official statement about the Efail paper.  Without further ado, here it is.
An Official Statement on New Claimed Vulnerabilities
== ======== ========= == === ======= ===============
by the GnuPG and Gpg4Win teams
(This statement is only about the susceptibility of OpenPGP, GnuPG, and
Gpg4Win.  It does not cover S/MIME.)
Recently some security researchers published a paper named "Efail:
Breaking S/MIME and OpenPGP Encryption using Exfiltration Channels".
The EFF has gone so far as to recommend immediately uninstalling
Enigmail.  We have three things to say, and then we're going to show you
why we're right.
1. This paper is misnamed.
2. This attack targets buggy email clients.
3. The authors made a list of buggy email clients.
In 1999 we realized OpenPGP's symmetric cipher mode (a variant of cipher
feedback) had a weakness: in some cases an attacker could modify text.
As Werner Koch, the founder of GnuPG, put it: "[Phil Zimmermann] and Jon
Callas asked me to attend the AES conference in Rome to discuss problems
with the CFB mode which were on the horizon.  That discussion was in
March 1999 and PGP and GnuPG implemented a first version [of our
countermeasure] about a month later.  According to GnuPG's NEWS file,
[our countermeasure] went live in Summer 2000."
The countermeasure Werner mentions is called a Modification Detection
Code, or MDC.  It's been a standard part of GnuPG for almost eighteen
years.  For almost all that time, any message which does not have an MDC
attached has caused GnuPG to throw up big, clear, and obvious warning
messages.  They look something like this:
    gpg: encrypted with 256-bit ECDH key, ID 7F3B7ED4319BCCA8, created
          "Werner Koch "
    [GNUPG:] BEGIN_DECRYPTION
    [GNUPG:] DECRYPTION_INFO 0 7
    [GNUPG:] PLAINTEXT 62 1526109594
    [GNUPG:] PLAINTEXT_LENGTH 69
    There is more to life than increasing its speed.
                    -- Mahatma Gandhi
    gpg: WARNING: message was not integrity protected
    [GNUPG:] DECRYPTION_FAILED
    [GNUPG:] END_DECRYPTION
GnuPG also throws large warning messages if an MDC indicates a message
has been modified.  In both cases, if your email client respects this
warning and does the right thing -- namely, not showing you the email --
then you are completely protected from the Efail attack, as it's just a
modern spin on something we started defending against almost twenty
years ago.
If you're worried about the Efail attack, upgrade to the latest version
of GnuPG and check with your email plugin vendor to see if they handle
MDC errors correctly.  Most do.
You might be vulnerable if you're running an ancient version of GnuPG
(the 1.0 series; the current is 2.2), or if your email plugin doesn't
handle GnuPG's warning correctly.  You might also have had some exposure
in the past if back then you used a pre-2000 version of GnuPG, and/or an
email plugin which didn't handle the warning correctly.
We made three statements about the Efail attack at the beginning.  We're
going to repeat them here and give a little explanation.  Now that we've
explained the situation, we're confident you'll concur in our judgment.
1.  This paper is misnamed.  It's not an attack on OpenPGP.  It's an
attack on broken email clients that ignore GnuPG's warnings and do silly
things after being warned.
2.  This attack targets buggy email clients.  Correct use of the MDC
completely prevents this attack.  GnuPG has had MDC support since the
summer of 2000.
3.  The authors made a list of buggy email clients.  It's worth looking
over their list of email clients (found at the very end) to see if yours
is vulnerable.  But be careful, because it may not be accurate -- for
example, Mailpile says they're not vulnerable, but the paper indicates
Mailpile has some susceptibility.
The authors have done the community a good service by cataloguing buggy
email email clients.  We're grateful to them for that.  We do wish,
though, this thing had been handled with a little less hype.  A whole
lot of people got scared, and over very little.

@_date: 2018-05-14 08:42:35
@_author: Robert J. Hansen 
@_subject: Efail or OpenPGP is safer than S/MIME 
MDCs stop it dead.  If a message has no MDC or an invalid MDC, GnuPG
_will_ warn you about it.  Now, whether your email client does the right
thing upon being warned, that's between you and your email client...

@_date: 2018-05-16 19:48:21
@_author: Robert J. Hansen 
@_subject: Breaking MIME concatenation 
While y'all are having this discussion, remember that GnuPG's 95% use
case is verifying Linux packages, and that number isn't expected to
change a whole lot.
Email users are important, but are also a very very small part of the
ecosystem.  Under 5% of the use, definitely; probably under 1%; I
wouldn't be surprised if it was under 0.1%.

@_date: 2018-05-17 16:42:52
@_author: Robert J. Hansen 
@_subject: Breaking MIME concatenation 
dkg got it in one.  Especially with the advent of cloud computing and one-click deployments of whole OSes, the package verification space is bigger than ever before.
I don't have concrete numbers here, but my suspicion is that GnuPG is a package verification system that's useful for email... and most of the problems people have with it as a package verification system stem from the fact it was originally an email privacy system.
This isn't a mark against it.  Any good software package will soon get used for things far beyond the authors' original intent.

@_date: 2018-05-18 14:10:25
@_author: Robert J. Hansen 
@_subject: =?UTF-8?Q?Re:_Kommentar:_Efail_ist_ein_Megafail_f=c3=bcr_E-Mail-Ver?= 
He's also not exactly wrong.  The continuing support for SE packets is
an embarrassment to us.  In our defense, though, the GnuPG userbase
revolts whenever Werner mentions something as mild as dropping PGP 2.6
support.  When Patrick changed Enigmail to consider lack of MDC a fatal
error, he had five complaints overnight.
It's very easy for pundits to say "your backwards compatibility is a
real problem, you need to break it and move forwards."  But I don't see
any of them volunteering to answer all of the support requests that
would flood in if we were to do that.

@_date: 2018-05-20 02:26:47
@_author: Robert J. Hansen 
@_subject: A postmortem on Efail 
Writing just for myself -- not for GnuPG and not for Enigmail and
definitely not for my employer -- I put together a postmortem on Efail.
You may find it worth reading.  You may also not.  Your mileage will
probably vary.  :)

@_date: 2018-05-21 01:20:33
@_author: Robert J. Hansen 
@_subject: Breaking changes 
Here's my own set of suggestions for breaking changes to GnuPG:
1.  End-of-life 1.4 already.
Yes, it's the only option for PGP 2.6.  Yes, it's the only option for
old and out-of-date stuff.  Yes, there will be people who need to
decrypt this stuff.  All of that is true, but *we* don't need to be the
people who cater to their needs.  At this point if you need pre-Web
crypto (which, I remind people, is pretty much what PGP 2.6 is), you
have a specialized need and you need to talk to someone about a custom
solution.  There are companies that specialize in this sort of thing
(like, say, g10 Code).
We should keep the 1.4 source code available, but wash our hands of it
and say it will receive *no* future fixes, not even for security issues

@_date: 2018-05-21 08:51:17
@_author: Robert J. Hansen 
@_subject: A postmortem on Efail 
I blame the EFF for that more than I blame the Efail developers.  I
expect the people who develop new attacks to overstate their importance:
it's not out of any intent to deceive, it's just that they're too close
to the problem to have a clear perspective on the user impact.  The EFF,
But even then, I have some sympathy for their position.  The EFF works
with many different activists in many different countries running many
different setups.  They were in a difficult situation of needing to put
out a press release that had useful recommendations for everyone, left
no one out in the cold, while still not raising a panic.
Let me be clear: I think the EFF behaved irresponsibly.  But I can be
sympathetic to their situation, too.  It's not a one-or-the-other thing.
 And I'm going to remain quiet on this further until I have time to see
the EFF's postmortem.
If I can help in any way, please let me know.
I entirely agree.

@_date: 2018-05-21 13:11:16
@_author: Robert J. Hansen 
@_subject: efail is imho only a html rendering bug 
Efail is not just an HTML rendering bug.  It includes very real attacks against S/MIME as it's used by thousands of corporations.
It's true that the cryptanalytic attack on OpenPGP is pretty much nothing.  But even then, there's room to argue whether GnuPG has made it too easy for email clients to do the wrong thing.
Efail is not just an HTML rendering bug.  The hype around it is awful, but there are good things in the paper and we should be careful not to wash our hands of it and say "nope, not our problem..."

@_date: 2018-05-22 05:35:38
@_author: Robert J. Hansen 
@_subject: =?UTF-8?Q?Re:_Break_backwards_compatibility_already:_it=e2=80=99s_t?= 
Guys, especially in the wake of Efail, *please* stop sending HTML mail
to the list.

@_date: 2018-05-22 05:47:43
@_author: Robert J. Hansen 
@_subject: Breaking changes 
1.4 was deprecated the instant 2.0 was released.  After much pushback it
was agreed to continue supporting 1.4.  But after fourteen years it's
time to end it so that Werner's limited time can be fully devoted to the
2.3 branch.
Yes.  And the code will still be around.  It will just no longer be
maintained.  If it's that important to you, you should consider
maintaining it yourself or paying someone to maintain it.
Why do you feel you have the right to make Werner work for you for free?
That's what you're saying here.  "I'm not paying a dime and I insist on
my legacy package getting highly professional work done on it for free."
Well... no.  It doesn't work that way.  Werner gets to work on what he
wants to work on, and I think the best bang for the buck,
community-wise, is 2.3.
But if Werner were to say tomorrow, "I'm done, guys, I'm going to go
sell ice cream on the beach," I'd just say thank you, wish him well, and
wonder where the beaches were in Germany.
Nope.  1.4 will still be out there, just unsupported.
No.  I'm well past the point where I care about how vocal a fringe
minority is.  It's unwise to make engineering decisions based on the
volume made by a small number of people.

@_date: 2018-05-22 20:21:54
@_author: Robert J. Hansen 
@_subject: Breaking changes 
You're an optimist.  For any EOL date, a vast number of users will
simply *not migrate* until they stop getting updates.  The reason why is
they're not subscribed to mailing lists.  We could announce tomorrow's
lottery numbers and they wouldn't notice.
I'm fine with a 12-month EOL date.  It's more important that an EOL date
be made and enforced than it be any particular date.  Whether it's three
months, six months, twelve, I don't care, *so long as it gets done*.

@_date: 2018-05-23 10:04:36
@_author: Robert J. Hansen 
@_subject: Breaking changes 
First, I am in *no way* important to GnuPG's future.  I maintain a FAQ,
field questions, and for the last couple of weeks have been a PR flack.
Many other people do more for GnuPG than I do, and Werner does the most.
 Please, keep that in mind.  :)
Second, 1.4 isn't requiring huge resources to maintain -- it's a fairly
small drain.  But when problems occur, suddenly we have to track them
down, fix them, test them, and release them in two branches, not one.
So it's when dev time is most important -- security problems -- that the
continued existence of 1.4 is most taxing.  Just a thought to consider.

@_date: 2018-05-28 18:39:18
@_author: Robert J. Hansen 
@_subject: A Solution for Sending Messages Safely from EFAIL-safe Senders to 
Or, better, use a system of random nonsense phrases.  Let's say you have
seven different subjects that you regularly correspond about via private
emails -- corresponding to seven different business customers, whatever.
 For each customer you've got sales, marketing, provisioning, support, R&D.
Seven customers.  You need a group that has seven elements.  Colors:
red, orange, yellow, green, blue, indigo, violet.  Five different types
of subjects: five permanent members of the U.N. Security Council (the
U.S., Britain, France, Russia, China).  You can now map a phrase like
INDIGO FRANCE to a customer and a task type.  Different threads get -A,
-B, -C, -D suffixes: some random word beginning with that letter will
suffice.  INDIGO FRANCE DERELICT would refer to "the IBM contract, R&D
work, the fourth thread."
Sure, this only obscures the subject.  It exposes the metadata and
allows an attacker to monitor what the communication patterns are like.
But honestly, that's plenty good enough for the vast majority of
confidential emails...

@_date: 2018-11-07 15:50:58
@_author: Robert J. Hansen 
@_subject: Most secure GPG combination for Mac OSX 
None of the MacOS builds have received a formal audit.  None.
The GnuPG codebase as a whole has received audits, but usually in a Linux environment.  I'm unaware of any MacOS-specific audits.
Plus Fink, MacPorts, Homebrew, and GPGOSX.
Not really.  They're all reasonably responsive.  You are almost certainly *not* better off building your own.
Possibly.  GPGTools has some problems in that they can't see the source for Mail.app, and as a result they've sometimes been slower to patch things than Enigmail.  Enigmail has excellent relations with Thunderbird, which really helps when there's a serious bug which needs addressing.

@_date: 2018-11-17 10:01:11
@_author: Robert J. Hansen 
@_subject: WoT question - policy 
That codebase is old and no longer maintained.  There are no well-maintained Java bindings for GPGME.
You will almost certainly have an easier time using BouncyCastle, which is a Java library implementing the OpenPGP protocol.

@_date: 2018-09-12 19:25:30
@_author: Robert J. Hansen 
@_subject: aes-mode, RSA 
No.  GnuPG uses a version of CFB mode.  CBC mode is not part of the spec.
If your recipient's primary encryption subkey is RSA-2056 or higher,
congratulations, you're done.

@_date: 2018-09-13 15:41:58
@_author: Robert J. Hansen 
@_subject: aes-mode, RSA 
Wayne asked me off-list how to ensure RSA-2056 or greater was being used.
First, it's a little weird: normally we talk of RSA-2048, not -2056.
But never mind, the answer is the same each way.
When sending email to another person, you use their public key for the
encryption.  Your own key isn't used at all for encryption (unless you
include yourself on the recipients list).
To check a certificate, use --list-key and the ID of the certificate you
want to check.  For instance, my certificate is
rjh at pop-os:~$ gpg --list-key 1DCBDC01B44427C7
pub   rsa3072/1DCBDC01B44427C7 2015-07-16 [SC]
      CC11BE7CBBED77B120F37B011DCBDC01B44427C7
uid                 [ultimate] Robert J. Hansen uid                 [ultimate] Robert J. Hansen uid                 [ultimate] Robert J. Hansen sub   rsa3072/DC0F82625FA6AADE 2015-07-16 [E]
sub   ed25519/A83CAE94D3DC3873 2017-04-05 [S]
sub   cv25519/AA24CC81B8AED08B 2017-04-05 [E]
Cut-and-paste that into a text document (Notepad, Atom, whatever).
Remove any line that doesn't start with "pub" or "sub".
pub   rsa3072/1DCBDC01B44427C7 2015-07-16 [SC]
sub   rsa3072/DC0F82625FA6AADE 2015-07-16 [E]
sub   ed25519/A83CAE94D3DC3873 2017-04-05 [S]
sub   cv25519/AA24CC81B8AED08B 2017-04-05 [E]
Now remove anything that doesn't end with the letter "E" somewhere in
brackets.  "[SCE]" is okay, but "[SC]" isn't.
sub   rsa3072/DC0F82625FA6AADE 2015-07-16 [E]
sub   cv25519/AA24CC81B8AED08B 2017-04-05 [E]
Presto.  I have two encryption subkeys.  Now look at the second column:
one starts with "rsa3072", denoting a 3072-bit RSA key.  The other,
cv25519, is an elliptical curve key -- not what you want.
By default, GnuPG will use the newest encryption subkey.  That means if
you were to type in this:
rjh at pop-os:~$ gpg --recipient 1DCBDC01B44427C7 --encrypt foo.txt
... GnuPG would use my cv25519 subkey, since it's the newest.  You can
override this.  To the right-hand side of my RSA key you'll see an
identifier for it, "DC0F82625FA6AADE".  To override GnuPG's choice of
subkeys, specify the specific subkey's identifier and add an exclamation
point to the end ("!").  This is how you tell GnuPG "no, really, use
this one".
rjh at pop-os:~$ gpg --recipient DC0F82625FA6AADE! --encrypt foo.txt
Hope this helps!

@_date: 2018-09-17 17:24:48
@_author: Robert J. Hansen 
@_subject: Washington State Electronic Notary Public endorsements 
Each state will go on a case by case basis, _but_, states are required
to give full faith and credit to the proceedings of other states.

@_date: 2019-08-12 23:35:15
@_author: Robert J. Hansen 
@_subject: PGP Key Poisoner 
I did.  Much closer to two decades than one.  I remember talking about
it with Randy Harmon of PGP Security in 2000.
Re-read my Gist, please.  It's all in there.

@_date: 2019-08-13 10:54:24
@_author: Robert J. Hansen 
@_subject: Difficulty of fixing reconciliation 
I didn't say this.
I said they handle up to about that, *because we've seen keys with that
many*.  So clearly, obviously, they handle that many.
A great many people have assumed I intended to say "and it won't handle
more than 150,000".  Which I didn't say and don't intend.  It very well
could handle more.

@_date: 2019-08-13 11:11:36
@_author: Robert J. Hansen 
@_subject: PGP Key Poisoner 
In my defense, I wrote that front-to-back in under an hour.  My goal was
to quickly release a useful pr?cis, not to slowly write a definitive
reference on the problem.  :)
That said, this particular thing I stand behind.  The number of people
in the SKS community who grok OCaml is pretty close to zero.
I agree.

@_date: 2019-08-14 15:45:19
@_author: Robert J. Hansen 
@_subject: Difficulty of fixing reconciliation 
Sure, if you can give me a valid reason why I *should* give you a valid
I'm not a GnuPG developer.  I don't run an SKS keyserver.  I know a good
bit about the internals of both, but I wasn't involved in the decisions
and I'm getting really annoyed at people who expect me to be an
apologist just because they mistakenly think I'm more involved than I am.
Now that I've got that out of the way, welcome to the Zero-One-N rule.
It's a rule of thumb in software engineering that says to either allow
none of something, only one of something, or an arbitrary number of
somethings.  Either support no third-party signatures, one third-party
signature, or arbitrary numbers of them.  When the OpenPGP spec was
developed *more than twenty years ago* it was decided to support
arbitrary numbers of third-party signatures.  GnuPG faithfully
implements this spec, even though this policy has turned out to not be a
good idea.
If you want to be *productive*, get over on the IETF Working Group
mailing list and start asking how the next draft of the spec is going to
resolve this problem.  That's where the problem began.  That's where you
need to solve it.

@_date: 2019-08-14 15:49:31
@_author: Robert J. Hansen 
@_subject: was Re: PGP Key Poisoner // now "Binding one person's subkey to 
Not enough OCaml programmers, mostly.
Strange but true: SKS has no crypto code in it anywhere.  So the moment
you say "I wonder why SKS doesn't do this thing that involves crypto,"
well, that's the answer: because it involves crypto and nobody has ever
added that capability to SKS.

@_date: 2019-08-15 02:50:14
@_author: Robert J. Hansen 
@_subject: Key poisoning 
Someone already chimed in about how this is "enumerating badness", which
runs counter to best practices in security.
Additionally, the bad guys can create new malicious certificates faster
than the keyserver network can blacklist.

@_date: 2019-12-14 11:51:02
@_author: Robert J. Hansen 
@_subject: gnupg private-keys encryption 
Change the passphrase.  Just changing configuration file preferences
doesn't change the way the key is stored on disk.  It only says "the
next time you have to alter the way the key is stored on disk, use these
new parameters".
Changing the passphrase on the key will force GnuPG to write it out to
disk again, at which point your new preferences will take effect.
Warning: this information was correct for GnuPG 1.4 and 2.0.  I'm not
sure about 2.2, as I've never needed to do it on 2.2.

@_date: 2019-12-14 19:31:55
@_author: Robert J. Hansen 
@_subject: Modern gnupg.conf setup 
The standard advice still applies: unless you know what you're doing and
why it's necessary, just stick with the defaults.  :)  GnuPG 2.2 runs
quite well with a minimal config.  That said, I'll try to answer your
All still valid, all still useful.
Valid.  Whether they're useful depends a lot on your personal needs.  I
don't have much use for them, but your needs might be different from mine.
Please don't: you're possibly harming interoperability.  Although AES256
is a strong and well-supported cipher, you'll find other people who
don't have it listed on their key preferences.  In that case, you will
silently degrade to 3DES, which is widely considered the worst cipher in
OpenPGP.  It's slow, it's inefficient, and it has inherent risks when
encrypting large files due to its 64-bit block size.
(It is also overengineered like a Soviet workers' housing bloc.  No one
is aware of any cryptographic attacks on it, other than when used with
very large files.  Still: slow and inefficient.)
Likewise, if you encounter someone who for whatever reason can't use
SHA512 (like if they're using the old, but still encountered, PGP 8.1),
you will silently degrade to using SHA-1, which I don't think you want
to do.
Instead, try this:
personal-cipher-preferences AES256 CAMELLIA256 TWOFISH AES192
CAMELLIA192 AES CAMELLIA128
personal-digest-preferences SHA512 SHA384 SHA256 SHA224 RIPEMD160
This way, if your correspondent can't use AES256 GnuPG will degrade to
the (strong, modern, fast) CAMELLIA algorithm.  If that's a no-go,
degrade to the (strong, modern, fast) 256-bit TWOFISH algorithm.  If the
256-bit ciphers are all a no-go, it degrades to 192-bit AES and
CAMELLIA, then the 128-bit variants.  Only if *no* modern cipher is
available will it then degrade to 3DES.
The same logic applies to SHA512.  It will exhaust all the modern hashes
before degrading to the (old, probably not very reliable any more, but
still better than SHA-1) RIPEMD160 algorithm, and only if all of them
are a no-go will it fall to SHA-1.
Why do you prefer 128-bit AES over 256-bit TWOFISH?
*These are probably bad ideas.*  These say "screw what I just said about
my preference lists, ONLY use AES256 and SHA512" -- which can make your
message traffic non-interoperable with people who, for whatever reason,
cannot use AES256 or SHA512.
Still valid, still useful.
Scratch this for the same reasons as scratching "cipher-algo" and
"digest-algo".  Let GnuPG use a compression algorithm your correspondent
can actually use: don't force GnuPG to use one your correspondent can't use.
20 years ago it was widely believed compression before encryption was a
good idea.  Today that belief is pretty much shot, given how most file
formats already incorporate compression.
You can remove this line entirely.
3DES is a MUST algorithm, according to the spec.  If you want to disable
the others that's your business -- but it's already implicit by not
including them in your personal-cipher-preferences.  This line can be
removed entirely.
Again, SHA-1 is a MUST.
These are implicit given your personal-cipher-preferences and
personal-digest-preferences, and can be removed.
This is the default, and as such it can be removed.
I have never found any use for cranking s2k-count this high.  I'd
suggest removing this line and using the defaults unless you have a
specific need for such a high count.

@_date: 2019-12-15 13:32:39
@_author: Robert J. Hansen 
@_subject: Modern gnupg.conf setup 
That presumes they were ever accurate in the first place.  Many of them
were not.
Not necessarily.  Personal-cipher-preferences is the list of ciphers
you're willing to use, but the list of ciphers on your key (what's put
there via setpref) is the list of ciphers you ask *other people* to use.
Will they often be the same?  Yes.  But not always, and there's a
subtlety there that's often overlooked.  You might be willing to
generate traffic using ciphers you're not willing to accept.
Probably not.
The reason why cipher-algo and digest-algo are recommended against is
because GnuPG already has a robust mechanism for choosing a strong
cipher that you're willing to generate (via personal-cipher-preferences)
and the recipient is willing to receive (via prefs on the key).
There is no such mechanism for certificate signatures.  That's entirely
generated by you.  You have zero knowledge of what algorithm other
people will use.  If you want maximum interoperability, you have to use
SHA-1; everyone can read SHA-1 signatures.
But that's SHA-1, and SHA-1 isn't exactly a highly recommended digest
any more.
Use something better and stronger.  SHA512 is probably the best option
right now.  If someone can't read your certificate signatures, well --
that's on them: they should be moving away from SHA-1.
I question the credentials of anyone calling 3DES "weak".  It has one
and only one serious cryptographic weakness: due to its 64-bit block
size, it should not be used to encrypt more than about 4Gb of data with
the same session key.
40 years after it was first released, the best attack on it is a
meet-in-the-middle that requires -- hand to God, I am not making this up

@_date: 2019-12-17 09:43:55
@_author: Robert J. Hansen 
@_subject: GnuPG v2.2.17.22805 with StarksoftCryptographyOpenPGP 
The good news is there's a good chance this is an easy fix.
Sure do.
What this means is really simple: GnuPG can't find the recipient's public key.
GnuPG stores keys on a per-user basis, not systemwide.  So if you imported the recipient's public key to your local keyring, but this code is running as a different user, GnuPG will look in that different user's keyring for the public key -- not yours.
You can test this out by switching over to whatever user account this is running as and running "gpg --list-key XXXXXXXX".  I strongly suspect you'll get no output, thus showing that when running as this user GnuPG has no access to the public key that's on your own user keyring.
While still logged into the different user account this is running as, import the public key into GnuPG.  Your problems should vanish.
If this still doesn't work you'll need to dive into Starksoft, as it's possible they're switching users and not telling you.

@_date: 2019-12-17 09:55:21
@_author: Robert J. Hansen 
@_subject: Usability of OpenSSL vs GNUPG 
One of my repeated complaints about GnuPG is that nobody can agree on what it is.  Is it a toolkit for building bespoke cryptographic solutions?  Is it an RFC4880 implementation meant for end-users?  Is it an RFC4880 implementation meant for MUAs?  Is it...
A lot of the things you're (rightly, I think) criticizing are the result of this clouded vision of what GnuPG is meant to do.  In the course of trying to be all things to all people it's occasionally being very You're using it as a toolkit for bespoke solutions.  You want your tools to work consistently across versions.
Other people are using it as an end-user tool.  They want the end-user experience to be continuously refined.
This leads to things like gpg-agent ignoring s2k iteration counts in order to give a positive end-user experience, at the risk of frustrating people who are wondering why their bespoke solutions with custom s2k iteration counts no longer work.

@_date: 2019-12-17 10:31:16
@_author: Robert J. Hansen 
@_subject: GnuPG v2.2.17.22805 with StarksoftCryptographyOpenPGP 
We try to be helpful.  We sometimes fail, but we try.  :)
Yep.  Use both "--no-default-keyring" and "--keyring".  For instance:
$ gpg --no-default-keyring --keyring \path\to\pubring.kbx --list-keys
However, as of GnuPG 2.2 you can no longer specify private keys this way.  There used to be an option, "--secret-keyring", which was used just like "--keyring", but it's obsolete and now does nothing.
Yeah, that's expected and doesn't shed much light on the matter.

@_date: 2019-12-17 11:41:14
@_author: Robert J. Hansen 
@_subject: GPGME frustrations (was OpenSSL/GnuPG usability) 
It's reduced *twice*.  Once by GPGME directly, and then once by whatever language binding to GPGME you're using.  Not all language bindings are made equal.  The C++ one is reasonably good; the Python one, likewise.  But the C# one is alpha-quality only, the Java ones don't even compile any more, and so on.

@_date: 2019-12-17 11:53:20
@_author: Robert J. Hansen 
@_subject: GnuPG v2.2.17.22805 with StarksoftCryptographyOpenPGP 
We're definitely closer.  Remember what Thomas Edison said when someone accused him of having failed 10,000 times in his pursuit of the light bulb.  "I have not failed, I have only found 10,000 ways that don't work!"  Churning through failures quickly is an essential part of success.  A frustrating part, to be sure -- but essential.
So, next up.
Open a command window and use that exact same command line.  Does it work correctly?

@_date: 2019-02-03 04:14:06
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 184, Issue 22 
It's a serious question.  What exact feature set was there present in
PGPfone which you believe is not easily available with out-of-the-box
software solutions?

@_date: 2019-02-03 11:48:28
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 184, Issue 22 
In the era before NAT, this may have made sense.  In today's
NAT-pervasive era, not so much.
Under NAT, your IP address is hidden from the rest of the internet.  The
address my router gives me is not one the outside world can use to route
information to me; and if I go to a website that lists my IP, that's
actually my router's IP, not mine.
I won't go into how NAT works except to say that under NAT, connections
cannot[1] be made from one peer to another.  You need a server that's
not NATted in order to facilitate connections between peers.
So -- I hate to be the one to tell you this, but the architecture of the
internet has changed dramatically since PGPfone was released in ... what
was it, '94?  Today, one of the major purposes of these servers is to
facilitate traversing NATs.
[1] It's technically possible to do peer to peer behind NAT, but beyond
the technical capabilities of the vast majority of users.

@_date: 2019-02-03 23:38:35
@_author: Robert J. Hansen 
@_subject: Gnupg-users Digest, Vol 184, Issue 22 
"All you had to do" was:
(a) understand computer networking well enough to understand what you
needed to do,
(b) know your router could be used to do port forwarding,
(c) log into your router, navigate bad UX,
(d) probably switch your DHCP allocation to a static one, so you
wouldn't have to do this again every time you acquired a new DHCP lease,
(e) and on and on and on.
No, PGPfone was not "easier to use".  The skills required to use it were
far in excess of what most users possessed.
I get that you liked PGPfone.  Nothing wrong with that.  But there are
good reasons it failed to get traction in the privacy community, most of
them revolving around user-unfriendliness and inconvenience.

@_date: 2019-02-23 08:55:02
@_author: Robert J. Hansen 
@_subject: user id question 
There's nothing forbidding it.  Whether it's a good idea depends on your
own particular use case.
I'd recommend thinking long and hard before doing this, as it's possible
you'll confuse some badly-written workflows somewhere.  But if after
thinking long and hard you decide to go for it, knock yourself out: it's
allowed.  :)

@_date: 2019-01-06 05:23:17
@_author: Robert J. Hansen 
@_subject: Removing expired keys 
Before anyone accuses me of being less than helpful: Jerry asked this
same question two years ago, got an answer on-list, verified that it
solved his problem, and then just now asked the same question, got an
answer from the same person, and was referred to the earlier thread.  A
touch of mild ribbing seems to be in order.  :)

@_date: 2019-06-30 18:57:11
@_author: Robert J. Hansen 
@_subject: Your Thoughts 
We're living in it.  OpenPGP is used on a scale the protocol designers
never dreamed, mostly for verifying operating system packages.
Peak _email_ adoption rate?  It's never been any kind of serious player
in that space.  I've seen it used productively in nonpermissive
environments where other tools simply could not suffice.  I do not
recommend it as a casual tool: but when nothing else will do, well...
nothing else will do.

@_date: 2019-06-30 19:36:41
@_author: Robert J. Hansen 
@_subject: Your Thoughts 
I think Matthew Green is a very sharp fellow and his criticisms are
thoroughly on-point.  My biggest complaint about that article is that he
doesn't draw a clean distinction among the OpenPGP specification, how
software packages like GnuPG choose to implement the specification, and
the supporting ecosystem that is neither OpenPGP nor implementation.
The OpenPGP spec says surprisingly little about what the format of a key
should be, for instance.  If you look at GnuPG's key export format, it
was chosen in the late '90s to be interoperable with PGP Security's PGP
5.0 offering (which was, at the time, pretty much cutting-edge).
Well -- nowadays GnuPG is the big mover in that space.  There's a strong
argument to be made that GnuPG should be more of an innovator.  There's
no reason anymore to retain the old and inefficient PGP 5 format.  We
can change it and still be compliant with the spec: maybe we should.  I
think we should.
And hey, if we fix the key exchange format, that's one massive section
of his objections gone.  That set of objections isn't to OpenPGP, it's
purely about how we implement it.
Another major complaint of his is the keyserver network, which we've
known for years was inadequate.  It was also the only game in town and
there was neither the money nor the manpower to do a better job.  Now
we've got Autocrypt, WKD, and Hagrid: of these Autocrypt is probably the
most mature and the easiest for email users.  We've got three at least
arguably better ways of distributing certificates: if we can actually
persuade people to start using them, we can fix this and wipe another
set of complaints off his list.  His set of objections here is not to
either OpenPGP or an implementation of it, but rather the support ecosystem.
(Note to anyone who thinks I'm saying "it's kinda good that this Great
Unpleasantness is happening because it's making people migrate": no.
Absolutely not.  The people behind this deserve to be shunned by our
community and exiled from our mailing lists.  They are not our friends.)
About the only actual protocol-level complaints Professor Green has are:
1.  OpenPGP has no forward secrecy.  (Correct!  I'd love to see the
OpenPGP Working Group tackle this.  I'm not sure it can be done for
offline asynchronous communications, but it would be good to at least
investigate the possibilities.)
2.  OpenPGP has no AE/AEAD mode.  (Incorrect!  The MDC is a form of
authenticated encryption.  It predates modern AE/AEAD and looks kind of
baroque to modern eyes, but it's AE.  The fact some mail clients
*ignore* the AE is a different [and very serious!] matter.  Further, the
latest RFC4880bis spec -- which was written after Professor Green's
blogpost -- explicitly incorporates modern AE/AEAD.)
My complaint about Professor Green's blogpost is that he treats PGP as a
single monolithic block, instead of as different plants in a garden that
all grow interdependently.  The OpenPGP protocol is solid.  But we can,
and I think we need to, do a serious modernization pass on how we choose
to *implement* that protocol.
If I were to set priorities for GnuPG?
1.  Set a flag day.  Past a certain date, old-and-busted certificates
and data formats will simply not be supported.  They won't be written,
they won't be read, they won't be processed, GnuPG will simply say
"nope, that might be legit old-school RFC4880 traffic but I'm not going
to play that game."
2.  Overhaul the key format.
3.  Do away with user IDs.  Only use key IDs.  If a user wants to
associate a key with an email address, let them: but user IDs originally
existed *mostly* to support the email use case, and with the advent of
Autocrypt that's not such an issue any more.  (Note that a lot of thorny
problems suddenly just *go away* if you stop using userIDs.)
4.  Require a limited subset of the RFC4880bis standard to be used.
Keep support for adding ciphers to the spec -- algorithm agility is a
wonderful thing -- but by default only use one specific ECC algorithm in
one specific key length, with AES256 as a symmetric cipher, and SHA512
for a hash.  GnuPG's ability to support arbitrary preferences and
algorithms is neat technically but I have literally *never* seen it be
necessary in field usage, and I have seen people accidentally degrade
their security literally *hundreds* of times.  (If your cipher
preferences are 3DES AES128 AES256, for instance?  Say hello to 3DES:
you will literally never use AES256.)
5.  If we're going to continue to have a keyserver network the only way
forward is to burn it down and build something newer and better.  There
are no other realistic options.
6.  Develop a well-defined output format.  Werner & co. like to say the
output of --with-colons is well-defined.  It's not.  Unless there's
something like a DTD or a BNF specification and the output can be
formally verified against the specification, what you have is ad hoc.
The processing bugs the Efail paper exploited were overwhelmingly caused
by MUA authors misunderstanding or misinterpreting the output GnuPG was
giving it.
... Would this be painful?  Sure.  But it doesn't involve throwing out
the OpenPGP spec, just overhauling how we implement it and the
supporting software ecosystem.  That would be *hard*, don't get me
wrong, and I am *in no way* saying this would be easy.
But worth it?  I dunno.  Maybe.  Yeah.  Let's throw it out there, let's
talk about it.
But that's just me.  :)

@_date: 2019-06-30 21:52:45
@_author: Robert J. Hansen 
@_subject: Your Thoughts 
Yes.  And frankly, it's a bigger subject than just GnuPG: to be
effective we'd need to get buy-in from OpenPGP.js and Sequoia, for starters.
Optimistically, we'd be looking at two years of work, maybe more.
One of the things I'm beginning to consider, though, is that it might be
a good idea to make the Implementation-Future group invitation-only.
Over the last few years I have *really* lost faith in the idea of open
and unmoderated groups.  The gist I posted where I outlined the
poisoned-certificates attack took all of three messages before someone
started accusing me of being a bigot on account of my belief that child
pornography is a moral evil...

@_date: 2019-06-30 22:48:01
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
Eh.  Yes.  No.  Hard to say.  The problem is that many of these distros
allow third parties to run their own repositories under more permissive
rules, and some of these third parties are extremely popular.  Plus,
often sysadmins will roll their own RPMs of packages: in such cases you
quickly lose the ability to say definitively what will or will not happen.
If the major distros update their distro signing certificates through
signed packages, great: that's good.  But don't go thinking that means
you're out of the woods.
Whenever anyone gives you concrete yes-or-no, this will-or-won't happen
answers about a complicated ecosystem that has a ton of hidden bits that
can't be seen, that person most likely has misunderstood the problem.

@_date: 2019-07-01 05:54:26
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
Thankfully we live in free societies where dissent is allowed: on good
days, even tolerated and encouraged.  You're wrong, of course, but
please understand I encourage you to be wrong.  :)
Also, if it isn't clear: although I emphatically disagree with you, this
is not a personal dispute.  I plan on turning your idea into a pinata,
but on a personal level as far as I'm concerned there's nothing but
peace between us.
No.  No.  No.  I have not said that.  In the last ten years the
sks-devel at nongnu.org community has explored pretty thoroughly the
problem space and concluded it cannot be solved at the SKS level, given
the community's level of manpower and funding.
That's not "nothing".  That's a very important result and it is
literally the most the sks-devel community can be asked or expected to
do, given their critical shortages of money and manpower.
In a very real sense, WKD, Autocrypt, Hagrid, dkg's work in
abuse-resistant keyservers, and so forth, all sprang from the sks-devel
community's recognition of the problem and the inability of SKS to
effectively fix it.  If SKS were in better shape it's likely none of
those projects would have ever started.
There is a line of thinking which I find to be morally appalling, and
you describe it quite clearly in your footnote:
If the sks-devel community has repeatedly made it clear over the course
of a decade that "we lack both the manpower and the financial resources
to fix this problem", never receives manpower or financial resources,
and then ten years later this happens... our reward is to be
victim-blamed?  "If you were really serious you would've done something
by now"?
It's like telling a doctor in the developing world who has for ten years
been screaming that she needs polio vaccine, after a polio epidemic
starts in her neighborhood, "the poverty is in effect a societal excuse,
not a legitimate reason for lack of action"?
It takes stuff to do stuff, and it's really rude to blame the victims
for problems they inherited but did not create.
Three now, since apparently Kristian has been hit.
At a tremendous price.  A price that I, and many others, think is
morally appalling.  These people are not our friends and have done us no
I seem to recall people saying the same after 9/11: that yes it was a
horrific thing, but that "good can come of this tragedy".
I seem to recall people saying the same after my best friend's suicide:
that yes it was a horrific thing, but that "good can come of this tragedy".
It is the nature of goodness that, like hope, it springs eternal and in
the most unlikely of places.  But it is also barbarous to claim the good
that may come out of a horror should be counted to the horror's credit.

@_date: 2019-07-01 09:26:38
@_author: Robert J. Hansen 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
A thought that would unfortunately require an adjustment to the OpenPGP
spec itself: why do we put certification signatures on the target's
certificate, anyway?
If Alice 0xDEADBEEF certifies Bob 0xDECAFBAD, 0xDECAFBAD bears a
certification from 0xDEADBEEF.  Why not reverse it?  Why not, when
looking at a certificate 0xDEADBEEF that says "Hi, I'm Alice!", do we
not see "And I certify that 0xDECAFBAD is really Bob"?
In some respects it would permit us to preserve an append-only signature
model.  Only the certificate owner would be allowed to append a cert
signature to their cert.
The current debacle is completely the result of allowing *anyone* to
append a cert signature to *anyone else's* cert.
I am certain there's some subtle problem here I'm not seeing.  But it's
worth a thought.
Note that this amounts to "SKS must die".  SKS does no cryptographic
verification of material.

@_date: 2019-07-01 23:47:56
@_author: Robert J. Hansen 
@_subject: Your Thoughts 
Eh.  Yes, no.  I agree with the claim that GnuPG's "we-do-it-all"
approach is overall a net negative for security: but there's a strong
argument to be made that if GnuPG didn't do it all, it wouldn't get done
at all.
Remember that for about fifteen years GnuPG received basically nil for
funding.  For a long while each Christmas I'd run a fundraiser match for
GnuPG, where I'd match dollar-for-dollar every dollar donated to GnuPG
for development.  My donation capped at $500.  For several of those
years, I was one of the largest individual contributors to GnuPG.
During that long period when GnuPG was short of funds and developers, it
could have focused on just one part of the crypto puzzle.  "This will
verify operating system packages with OpenPGP" or "this will verify
emails with OpenPGP", to use one simple distinction.  But doing that
would've left the other, just as important, need unaddressed: so the
developers did their best to make one package be useful to as many
OpenPGP users as possible.
This approach created some problems.  Some of the Efail bugs were
created when GnuPG generates output data even though the file fails
integrity checks.  This is not behavior you want in an email crypto
engine: if the email fails, you want to just bomb out and create no
data.  But this *is* behavior you want in a bulk crypto engine, where
there is no reasonable way to store petabytes of encrypted data in RAM
to check for consistency before writing to disk.

@_date: 2019-07-02 07:55:28
@_author: Robert J. Hansen 
@_subject: Some thoughts on the future of OpenPGP and GnuPG 
I could not agree more.
Stefan, that was out of bounds, inaccurate, and easy to refute.  If
you'd just done a Google search before you hit 'Send' you would've
discovered the truth.
I think you owe Werner an apology.

@_date: 2019-07-02 08:18:29
@_author: Robert J. Hansen 
@_subject: Your Thoughts 
I think this is a misunderstanding of Signal.
OpenPGP is, by its very nature, agnostic to ... well, just about
everything.  It was originally intended for email but spread to become
just about everywhere.  It's used for package verification mostly
nowadays.  That is the genuine 99% use case, and that's where our
attention really should be focused on.  Email is a niche, and even
moreso nowadays as email _itself_ is becoming a niche.  OpenPGP in email
is a niche within a niche.
Signal is, by its very nature, tightly tied to one specific
communications platform -- that of the smartphone.  It's not likely to
break out of its home.
It's true that Signal has had more impact than OpenPGP in email -- but I
think that's an unfair statement to make, as you're cherrypicking the
one niche where OpenPGP has had the *least* adoption.  Anything looks
like a failure if you only look at where it's failed.

@_date: 2019-07-02 15:29:26
@_author: Robert J. Hansen 
@_subject: Some thoughts on the future of OpenPGP and GnuPG 
Oh yes, absolutely so.
Facebook makes good money off your personal data.  If they allow other
people to obtain it, that's money they're losing.
You can rely on Facebook to zealously protect their bottom line.

@_date: 2019-07-03 05:06:13
@_author: Robert J. Hansen 
@_subject: SKS and GnuPG related issues and possible workarounds 
This is reasonably correct.  You'll get well-intentioned pedants
screaming at you that you've got things exactly wrong (as I have
discovered in recent days), but ignore them.
As I understand it the current list of targeted keys is myself, dkg,
Werner, Patrick, and Kristian.  It is clear the attacker's goal is to
wedge as many GnuPG installations as possible.
Yes.  A warning is in order: few distributions use the keyserver network
to distribute signing certificates directly.  However, given the
behavior of --refresh-keys, one could always upload a poisoned signing
certificate to the keyserver network, wait for sysadmins to do a
--refresh-keys on the entire keyring, and blammo.
Or switch to Autocrypt, WKD, or Hagrid.  All three options are worth
considering, although none of them are (or could be) drop-in replacements.
This would only shift the problem, not cure it.  Once you poison a
certificate until it's a few gigabytes in size, you can easily kill the
entire SKS network by forcing it to reconcile that certificate over and
I am *cautiously* optimistic.
As an emergency mitigation, I think distributions should consider
issuing a system update that blackholes *.sks-keyservers.net, with a big
warning to people about what's happening and why.
Enigmail users are, at present, getting hit left and right due to (a)
how many of them have an affected certificate in their keyrings and (b)
Enigmail's habit of automatically refreshing keyrings.  Patrick has
already sent an emergency message to the Enigmail mailing list, and an
emergency update will be released imminently shifting to keys.openpgp.net.
Werner will no doubt be updating GpgOL as well.
Those two account for literally 99% of all use cases.  The vast majority
of OpenPGP is to verify package signatures; for the small fraction that
use it for email, Enigmail is the most dominant choice, with GpgOL a
close second.
The one small bit of silver lining to this stormcloud is we only need to
figure out how to fix three separate things.
The real damage is going to be to people's workflows.  A whole lot of
people are going to be impacted by these fixes and we can expect to need
to help an awful lot of them.

@_date: 2019-07-17 00:05:01
@_author: Robert J. Hansen 
@_subject: Essay on PGP as it is used today 
Although I largely share in the criticisms, I think the author made a
couple of serious mistakes.
First, RFC4880bis06 (the latest version) does a pretty good job of
bringing the crypto angle to a more modern level.  There's a massive
installed base of clients that aren't aware of bis06, and if you have to
interoperate with them you're kind of screwed: but there's also
absolutely nothing prohibiting you from saying "I'm going to only
implement a subset of bis06, the good modern subset, and if you need
older stuff then I'm just not going to comply."  Sequoia is more or less
taking this route -- more power to them.
Second, the author makes a couple of mistakes about the default ciphers.
 GnuPG has defaulted to AES for many years now: CAST5 is supported for
legacy reasons (and I'd like to see it dropped entirely: see above, etc.).
Third, a couple of times the author conflates what the OpenPGP spec
requires with what it permits, and with how GnuPG implements it.
Cleaner delineation would've made the criticisms better, I think.
But all in all?  It's a good criticism.

@_date: 2019-07-22 07:07:32
@_author: Robert J. Hansen 
@_subject: Essay on PGP as it is used today 
Yeah, these conspiracy theorists always show up.
You're in the right place.
Mathematicians have come up with different ways to estimate how many
primes there were under a certain value -- what we call the prime
counting function, or "?(x)" in mathematicalese.  There are lots of ways
to do it, but they all give answers very close to each other: these are
estimates, not precise numbers.
The first estimate for ?(x) was "x divided by the natural logarithm of x".
Let x be 100.  The natural log of 100 is about 4.6.  100 divided by 4.6
is about 22.  Thus, we expect there to be about 22 primes under 100.
There are in fact 25 -- so while this method isn't perfect it's
definitely enough to get us in the neighborhood.
If we do that same equation for a 2048-bit key, it turns out there are
10 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000
000 000 000 000 000 000 000 different prime numbers that could go into it.
Google's total data storage is about 10 exabytes.  In 10 exabytes you
could store about 40 000 000 000 000 000 prime numbers.
There's just no way anyone on earth has a list of prime numbers that
they're trying one after another.  Not only isn't there enough hard
drive space, but the hard drives required would literally be bigger than
the entire Milky Way galaxy!

@_date: 2019-07-22 22:57:16
@_author: Robert J. Hansen 
@_subject: Essay on PGP as it is used today 
This is true, but it's not because OpenPGP is uniquely difficult.  It's
because it's uniquely flexible.  Signal is intimately tied to the cell
platform and cell signaling.  Even when using the desktop client, it's
using your cell phone as a proxy.  The more choices you take away from
the user, the easier the remaining experience tends to become.
(Which is not the same as saying the remaining experience is a *good*
one, just an *easy* one.  Go ahead, try using Signal to do a third party
noninteractive introduction.  Can't do it!  That choice is taken away
from you.  Which means if you don't need third party introductions, the
experience is good and easy... and if you do, it's bad and easy: bad, in
that you can't do what you need, but easy, in that at least it's very
honest about not being able to do what you need.)
Given the government uses email to transfer national security secrets, I
question this assumption.  Email can definitely be made safe enough: the
question is whether individual users can be expected to have the
training and experience and resources to do so on their own.  (I
personally think the answer is 'no'.)
I generally agree.  I recommend WhatsApp as a communications client of
first recourse for people in non-permissive environments.
Number one, it's easy to convince other people you meet to use it.  "You
can reach me on WhatsApp at..." tends to get reactions of, "oh, yeah, I
have it installed" or "I guess I should install that".  You don't need
to talk about security or code audits or E2E or anything else: just show
them it's fun.
Number two, switching from SMS to WhatsApp is a *huge* increase in
security for the average smartphone user.
Number three, the cops don't look at you funny if you've got it on your
phone.  Especially if you've got some nieces and nephews you can trade
funny memes with.  Purge the important stuff before you go through a
border crossing and if you're asked about WhatsApp just say "my nieces
and nephews made me install it so they could share funny stuff with me".
Signal fails on  ("This is supposed to be a ... a secure
communications tool?  Why do I need that?  I don't want to get in
trouble with the cops.") and on  ("Why do you need this, citizen?").

@_date: 2019-07-25 15:22:46
@_author: Robert J. Hansen 
@_subject: Need to implement a gpg/gpg2-compatible tool to encrypt millions 
For a straightforward purely-symmetric use case, consider using OpenSSL.
 Just use it wisely: specify your own key and initialization vector,
rather than trust OpenSSL's weak password derivation function.
$ tar -cJf - mydir | openssl aes-128-cbc -out foo.txz -K
DEADBEEFDEADBEEFDEADBEEFDEADBEEF -iv DEADBEEFDEADBEEFDEADBEEFDEADBEEF
-out mydir.txz.aes
Don't get me wrong: GnuPG can definitely do the job you want.  But
consider whether you really need RFC4880's baroque packet format, weird
CFB mode, and everything else.  Sometimes there's a lot to be said for
OpenSSL meets your requirement.

@_date: 2019-07-25 17:26:28
@_author: Robert J. Hansen 
@_subject: Need to implement a gpg/gpg2-compatible tool to encrypt millions 
An AES256 key is only 32 bytes long; an IV, only 16.  Keeping track of
48 bytes to decrypt your files isn't exactly a lot.  You can fit this on
the back of a business card with room left over.  I've done it before.
Passphrase-based crypto works by converting a passphrase into a
(seemingly) random series of bytes.  The problem is OpenSSL's
passphrase-to-bytes routine is pretty badly substandard.  Specify your
own key and IV.
Which language are you looking to use?  C Java, and Python all include
AES256 in the standard library and have excellent long-term support.
Many other languages offer it as well.  Python has some excellent PyPI
packages like passlib and Crypto which can make your task much simpler.
OpenSSL.  Look at the command line I gave you: it's used as part of a
pipeline that creates a tar archive and encrypted output all in one go.
We're getting pretty far afield from GnuPG here: please feel free to
follow up off-list.  Thank you!  :)

@_date: 2019-07-30 22:40:40
@_author: Robert J. Hansen 
@_subject: Enigmail 
This is simply not possible, as Enigmail didn't exist until 2001.  (It
took until about 2003 before it became really usable.)

@_date: 2019-05-31 23:53:13
@_author: Robert J. Hansen 
@_subject: Encryption Algorithm for GnuPG? 
Please don't send HTML email to this list.
As soon as you get ChaCha20 added to the OpenPGP spec, I'll start
participating in discussions on this mailing list about its merits.  :)
Although djb definitely has cryptographer cred, you're doing yourself no
favors by not noting the pedigree of AES.  Vincent Rijmen is one of the
sharpest cryptographers in the world today, and Joan Daemen is also
better known as the guy who invented Keccak.  Their errors are literally
more interesting than most other people's successes.
djb is definitely a smart guy.  But there are lots of smart people
bouncing around the crypto field -- and we are all so lucky that's the case!

@_date: 2019-06-03 13:22:17
@_author: Robert J. Hansen 
@_subject: [gpg4win-3.1.7] Automated Import of Public Key between programs 
Please don't send HTML email to this list.
Enigmail doesn't.  Enigmail uses GnuPG behind-the-scenes, so any key
GnuPG knows about, Enigmail knows about.  Enigmail has precisely zero
crypto code itself (although that's slowly changing as we give more
thought to OpenPGP.js).

@_date: 2019-06-30 02:26:55
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
I stand by what I wrote.
As usual, don't read the comments unless you want to despair for humanity.

@_date: 2019-06-30 04:19:19
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
(I am sputteringly angry over this entire thing: please understand this
and give a charitable read to what I write.  I appreciate it.)
Hard to say.
One of the big problems we have is the size of the existing codebase.
Once people have GnuPG installed people overwhelmingly like to leave it
alone.  We still get people coming onto this list asking for support
with GnuPG *1.2*.  So for these installations, these "we're going to
install it and forget it"s?
They're screwed.  Sooner or later they'll import a poisoned certificate,
GnuPG will get wedged, and it will appear as if GnuPG just stopped
working.  It might happen tomorrow or it might happen in five years.  We
don't know, but it will happen.
There are other groups that run human networks in dangerous places.
(There are many of them: Medicins Sans Frontiers, Reuters, and more.)
The people who are running around Syria treating casualties or doing
political news reporting from Gaza are overwhelmingly not computer
nerds.  They know they're supposed to run "gpg --refresh-keys" from time
to time to get the latest revocations.  They do it this time, and GnuPG
breaks horribly.  Odds are good they'll say "sod this, I can't trust
this crap" and throw it away.
There are a ton of tiny little poorly-maintained systems in
out-of-the-way places that get completely overlooked until things break.
 Those, too, have good odds of getting wedged the first time they
encounter a poisoned certificate.
The next version of Enigmail will no longer use the SKS network by
default.  Great!  But what about existing Enigmail users?  They'll see a
signature, click "Import Key", and ... bam.  They're likely not going to
think that someone's performing a malicious attack by poisoning
certificates: they're going to think "this is crap" and walk away.
Right now only three certificates are known to be affected: mine, dkg's,
and Kristian's.  I expect that number to rise, either due to the
original jerk figuring this is fun, or due to copycats getting in on the

@_date: 2019-06-30 04:37:14
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
(I am certain Andrew has already considered this: I am making explicit
what I think Andrew considered to be implicit.)
The obvious choice there is hkps://keys.openpgp.org.  The problem there
is keys.openpgp.org is not a drop-in replacement for SKS, and there's a
tremendous chance of breaking workflows in unpredictable places.

@_date: 2019-06-30 05:37:02
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
It's pretty unreasonable to think a piece of software from 2003, meant
as a drop-in replacement for software written in 1993, would implement a
feature that first appeared in GnuPG around 2013.[1]
If your next question is, "well, why doesn't SKS get modernized?", the
answer is "with what personnel and what budget?"  SKS doesn't even have
a maintainer, for God's sake.
[1] That "around 2013" is a guess: I don't know off the top of my head
when that was first added to GnuPG.

@_date: 2019-06-30 06:10:07
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
There's an important c):
c) what happens when they go after more certificates?
If you're willing to blackhole two certs, great.  Where does it stop?
How many certs can the strong set stand to lose?

@_date: 2019-06-30 08:44:43
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
A nation-state with a professional intelligence service probably isn't
very interested in taking down the keyserver network.  Why should they
take down something that's not a big priority for them, especially if
it'll cost them a lot of international goodwill if it gets attributed to
This has all the hallmarks of a child playing with matches and clapping
with glee as the house catches fire.

@_date: 2019-06-30 09:50:09
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
I feel like I am screaming into the void here.  I'm going to be quite
blunt because the message is just not getting through:
I don't get to decide these things.  Stop implying that I do.  Stop
blaming me for other people's decisions.  And stop thinking that I have
*anything whatsoever to do with the keyservers*.  I don't.  I understand
them but I am not a developer on them.  I don't even run a keyserver.
And if you knew the first thing about the keyservers you would know this
without needing me to tell you.
So please forgive me for not wanting to have a conversation with you.  I
am getting very tired of people confusing "Rob understands the current
mess" with "so I'm going to impugn his competence".

@_date: 2019-06-30 10:33:15
@_author: Robert J. Hansen 
@_subject: SKS Keyserver Network Under Attack 
For whatever it's worth, as soon as I heard word there were poisoned
certificates in the strong set I spoke to a friend who's well-connected
in the kernel community and made sure to pass on the warning and the
I am not worried about the kernel hackers being hit.  They're
technically savvy, close-knit, and largely self-sufficient technologically.
I'm very worried about people who lack technical skills (for many
people, just editing a config file is beyond them), who are in loose
contact with the GnuPG/keyserver community (people who might check in
once a year to see if there's any major updates), who are dependent on
others for their communications ("I don't know how this works, my IT
department sets it up for me").
Those people are -very- vulnerable to this.  They're going to get hit hard.
Please show me how we can prevent certs from being poisoned.  This is a
phenomenally hard problem.  You are handwaving away a huge amount of
What you are saying here is, "it would never end."
"Look, this one guy who just got mugged?  Clearly the street gang
doesn't like him.  So if we just, you know, don't help him, then the
gang won't also go after us.  We're not 'punishing the victim'.  We're
just saying, the needs of the many outweigh the needs of the few.  I
mean, it's too bad, what's happening to him.  And it's too bad the gang
is making us turn our backs and walk away.
I bet that once we're a block away we're not going to be able to hear
him screaming.
Come on, let's walk faster."

@_date: 2019-05-31 11:58:48
@_author: Robert J. Hansen 
@_subject: Encryption Algorithm for GnuPG? 
By default, AES.  Other algorithms are possible but not recommended.
The only other algorithms I'd recommend are Twofish and Camellia.
It can be used.  You'd be insane to actually use it, but that doesn't
change the fact it can be used.
IDEA was broken in 2011-2012 using meet-in-the-middle attacks and a
bicliques attack.  These aren't attacks on reduced-round variants of
IDEA.  This is the full-strength algorithm has been found vulnerable to
at least two different methods of cryptanalysis.  Right now those
attacks aren't terribly significant -- they shave a few bits off the
strength of the cipher -- but those attacks will only get better over time.
I'm unaware of any cryptographer who's still seriously studying IDEA.
It's considered to have taken a hit below the waterline.  Please do not
use IDEA for generating new traffic.  Please only use IDEA to read
existing traffic.
No.  It's a Belgian-designed algorithm with no connection to the United
States government.  This algorithm, called "Rijndael", works with a
variety of block sizes and key sizes.
All the United States government did was say "Rijndael with a 128-bit
block size will be our new Advanced Encryption Standard, and AES will
support key sizes of 128, 192, and 256 bits."
That's it.
No.  An excellent reason to believe there is no back door comes from the
fact the United States government uses AES to secure its most
confidential information -- it's one of the few algorithms that's
certified for use at the Top Secret level.

@_date: 2019-11-04 11:40:45
@_author: Robert J. Hansen 
@_subject: BSI withdraws approval of GnuPG (revisited after 3 month) 
Whoa there, chief.  You're taking some *wild* leaps.  There is
absolutely no indication BSI believes OpenPGP is insecure.  It's just
that BSI believes OpenPGP doesn't meet their particular application
requirements.  This could be as simple as, "we prohibit the use of 3DES,
but OpenPGP lists it as a MUST algorithm".

@_date: 2019-10-05 10:00:53
@_author: Robert J. Hansen 
@_subject: We have GOT TO make things simpler 
S/MIME adoption has far exceeded OpenPGP's in the world of email for a
simple reason:
You can make a whole ton of money as an S/MIME CA.
OpenPGP was designed such as to, as far as possible, cut centralized
trusted introducers out of the equation.  Of course, those centralized
trusted introducers are also the groups with the greatest ability to
influence market decisions.  ("While you're buying new SSL certs for
your business, have you thought about email security?  We offer S/MIME
certs for affordable prices...")
S/MIME prevailed over OpenPGP not for technical decisions, but economic
ones.  Given this is a technical mailing list, we should probably just
give a grudging nod in the direction of Adam Smith and his Invisible
Hand and move on to more technically-oriented lines of discussion.

@_date: 2019-10-05 10:06:41
@_author: Robert J. Hansen 
@_subject: We have GOT TO make things simpler 
OpenPGP was never meant to be about email.  It was never meant to be
about instant messaging.  It was never meant to be about any of that.
It was meant to be a toolbox people could use to help solve a wide
variety of communications security problems, and in that respect it's
been astonishingly successful.
For example, pretty much every Linux installation on the planet uses
GnuPG to verify downloaded packages.  Every single time you update your
Linux box, you're calling GnuPG to verify your supply chain.
If you want to say "OpenPGP hasn't been successful in this specific
niche," well, that may or may not be true, dunno, but we can at least
discuss it.  But if you say "OpenPGP hasn't been successfully adopted,"
there you're just wrong: there are lots of niches it's been successfully
adopted.  They're just ones you're either unaware of or deem unimportant.

@_date: 2019-10-05 10:10:06
@_author: Robert J. Hansen 
@_subject: We have GOT TO make things simpler 
It was not to be an email encryption tool.  It was to be a *file*
encryption tool.
This is all that RFC1991 has to say about email:
"This radix-64 conversion ... is used to protect binary messages during
transmission over non-binary channels, such as Internet Email."
That's it.  The only other mention of "email" in the entire document is
to list email addresses for Derek Atkins, Bill Stallings, and Phil

@_date: 2019-10-05 12:30:09
@_author: Robert J. Hansen 
@_subject: We have GOT TO make things simpler 
No, they were using it for file encryption.  They were using email as a
file transport protocol.  That's what inline PGP is: you take a blob of
data, do crypto, base64 it, drop it in email.  At the other end you pull
it out and undo the process.  But the inline PGP payload is in
*absolutely no way* integrated into the email message.  That had to wait
until the PGP/MIME RFCs -- that was when OpenPGP became an email protocol.
See above.  Email was used as a way to transfer files.  But there was
nothing special about using email to transfer files.  You could just as
easily replace the Alice, Bob, and Eve stories by saying "Alice is
delivering a 5.25-inch floppy to Bob, but is afraid Eve might get her
hands on it while Alice is distracted at the coffeeshop."

@_date: 2019-10-09 00:28:31
@_author: Robert J. Hansen 
@_subject: gpg.conf for use with gpg-1.4x and -2.2x... 
Not really.  Name them gpg.conf-1 and gpg.conf-2.  GnuPG 2 will use the
-2 file, GnuPG 1.4 will use the -1 file.

@_date: 2019-10-12 02:23:48
@_author: Robert J. Hansen 
@_subject: Future OpenPGP Support in Thunderbird 
Three major reasons:
1.  License incompatibility.  GnuPG is GPLv3, and Mozilla uses the
Mozilla Public License.  They're not compatible.  Arguably (and I
believe _correctly_) distributing GnuPG with Moz wouldn't be a
dealbreaker, as mere aggregation is different from actually linking, but
lawyers are by nature conservative.  Moz has already said their lawyers
won't let them do this.
2.  Dependencies.  Mozilla will not accept responsibility for users
doing foolish things with their gpg.conf files, because those users will
expect Mozilla to fix it for them.  It's a dealbreaker.  This is also
why Mozilla has declared they won't even support using GnuPG keyrings --
they're going to insist on running their own keyring internal to
Thunderbird which isn't shared with anything else.  (I imagine
*importing* from a GnuPG keyring will be supported, but *sharing* a
keyring is right out.)
3.  Enigmail has shown them the limitations of GnuPG.  The Efail attack
on Enigmail was very real.  It was created by an ambiguity in how GnuPG
returns error states: just because GnuPG says "decryption OK" doesn't
mean it was decrypted okay.  (Whether Enigmail should've understood
this, or whether GnuPG should have not returned such an ambiguous
message, is an open question and not one I'm interested in discussing.)
 Rather than repeat Enigmail's interface, which historically had its
fair share of security problems, Mozilla has decided to go a different
More power to 'em.  I love Enigmail, but it's the nature of all software
that at some point we learn how to do things better.  When we learn how
to do things better, we should elect to do them better rather than stay
mired in the past.
(... and that principle, applied to OpenPGP, suggests throwing out a
whole lot of cruft.  Which is another open question I'm not interested
in discussing, except to throw it out there for people to think about.)

@_date: 2019-10-12 05:19:33
@_author: Robert J. Hansen 
@_subject: Future OpenPGP Support in Thunderbird 
A few years ago at Circumvention (the first Internet Freedom Festival),
I was asked to give an impromptu talk on Things You're Doing Wrong With
The first thing on my list was certificate lifetime.  We teach people
the importance of maintaining their certificate for the long haul, but
we also know very few people are capable of doing that.  What we *don't*
teach them is how to rebuild their trust network after a
loss-of-certificate event.  So when someone loses their cert, or has a
system compromise, or their YubiKey goes through the laundry, or
what-have-you, they get a double whammy of failure: they feel like a
failure because they didn't do this thing that was expected of them
(keep the cert for 20+ years, never mind how unreasonable that it), and
they feel like a failure for not knowing how to recover from it.
So instead: teach people that it's okay to lose a cert, so long as you
have a plan to come back from it.  Then if their Yubi goes through the
laundry they (a) don't feel like a failure and (b) already have a plan
for how to move forward.
Seriously, ending the Cult of the Long-Term Certificate is one of the
simple but good things I think we should be embracing for the sake of users.

@_date: 2019-10-15 01:00:40
@_author: Robert J. Hansen 
@_subject: Configuration Failure Gnugp 
You will almost certainly be better off grabbing a pre-built MacOS
binary from GPGTools.  Building from source is regrettably complicated
due to all the prerequisites that need to be installed first.  If you
absolutely must have your own build we'll help you through the process,
but GPGTools and/or Homebrew will give you a much easier way to get up
and running with GnuPG.

@_date: 2019-10-15 01:13:01
@_author: Robert J. Hansen 
@_subject: Future OpenPGP Support in Thunderbird 
It does not.
There's excellent academic research into why.  I heartily recommend
reading this paper: "Secrecy, Flagging, and Paranoia: Adoption Criteria
in Encrypted Email".  Shirley Gaw, Ed Felten, and Patricia
Fernandez-Kelly, out of Princeton University.

@_date: 2019-10-15 15:09:40
@_author: Robert J. Hansen 
@_subject: Future OpenPGP Support in Thunderbird 
I'd suggest reading the Efail paper.  The vast majority of the news
coverage was shoddy.  Efail included two *completely separate* attacks
in their paper, which the news media overwhelmingly conflated into a
single attack.
I'll call them Efail-1 and Efail-2 here.
Efail-1 was what Werner is talking about here.  It was a pretty bad blow
to S/MIME, but far less so to OpenPGP, since OpenPGP has had
countermeasures in place for almost twenty years.  Efail-1's impact on
OpenPGP was, is, minimal.
Efail-2 wasn't an attack on OpenPGP at all, but instead showed how
poorly email clients and/or email plugins communicated with GnuPG.  It
was possible for GnuPG to give a correct warning that someone was
playing games with the message, and for the email client to disregard
this warning and present it to the user as authentic.
Efail-1 had minimal applicability to GnuPG; Efail-2 had none whatsoever
(except, arguably, some of the messages GnuPG gave were ambiguous: I
think they were, but Werner disagrees).

@_date: 2019-10-15 15:17:58
@_author: Robert J. Hansen 
@_subject: FAQ October 2019 update 
The last time I gave the FAQ a thorough read-and-review was in October
2017, so it was time for a review.  I fought off the urge to rewrite the
thing entirely -- I really don't like how it flows, but I view my job as
maintainer is more about making minor incremental changes than total
rewrites whenever the whim seizes me.
Anyway, the major changes:
* Every reference to the SKS keyserver network now points to
keys.openpgp.org.  Reason: the SKS attacks a few months ago.
* All references to 2048-bit crypto are updated to refer to 3072-bit
crypto.  Reason: GnuPG now defaults to 3072-bit RSA.
* PGPNET's email address has changed.
... Those were the high-priority changes that needed to be made.  If
anyone has other suggestions, speak up: I'm listening.  :)
(Note: I just committed the FAQ changes.  It may take a couple of days
for the documentation on the website to be regenerated.)

@_date: 2019-10-15 16:59:23
@_author: Robert J. Hansen 
@_subject: FAQ October 2019 update 
Let's start with the most important thing:
I didn't find your comments harsh, but thank you for being considerate.  :)
I can't agree with this.  SKS is effectively dead.  Older GnuPG
installations can still get utterly wedged if they pull down a poisoned
certificate from SKS.  There are a *lot* of these older installations
out there in the wild, and what we suggest to them should not lead them
into wedging their system.
Should they update?  Yes.  Is the problem mitigated by an update?  Yes.
 But will they?  Probably not before wedging their keyring.  Given that
high-profile people in the community have had our certificates defaced,
it's possible someone will say "I want to ask dkg a question," pull down
his cert, get wedged, and... etc.
I think it's dangerous to our users to continue to recommend SKS in the
face of a well-known poisoning problem.
I'm fine with this.  My major concern is removing SKS recommendations.
I agree there is no immediate rush: the US guidance says they're safe
until 2030.  But for many years we advised people to use 2048-bit keys,
now we're generating 3072-bit keys by default.  At the very least the
old guidance on 2048-bit keys needs to be dropped.  Whether we explain
it away as "we're now using 3072-bit keys by default, in order to get a
long head start on 2048's obsolescence" or "we're going to be moving to
ECC in the near future" matters little to me, but we need to explain the
shift away from 2048.
Because it raises an immediate question of, "then why does GnuPG default
to RSA-3072, if the FAQ's guidance is past -2048 to use ECC?"  The FAQ's
statement collides with what GnuPG actually does.
There were three major changes: keyservers, key lengths, and an email
address.  All three existed in prior iterations of the FAQ.  If you
think they should be dropped, I'm all for that conversation, but please
keep in mind that I'm not adding new subjects to the FAQ: in this pass I
was updating existing content.

@_date: 2019-10-17 15:18:07
@_author: Robert J. Hansen 
@_subject: FAQ: seeking consensus 
Unless there's no objection, I'll be making the edit to PGPNET's mailing
list address, as that seems uncontroversial.
I'd like to get a sense of the community on the other two changes I
made.  Werner and I disagree on certain things (which is understandable
and okay!), and I'd really like to get a sense of where the community lies.
Obviously, Werner gets the final decision.  But I do think community
feedback is essential, so please speak up!
1.  How should we handle the SKS keyserver attacks?
One school of thought says "SKS is tremendously diminished as a
resource, because using it can wedge older GnuPG installations and we
can't make people upgrade.  We should recommend people use other methods
than SKS."  If you think this is correct, please let me know what you
think the alternate method should be.
Another says, "with a recent GnuPG release SKS may be used productively
and we should keep the current advice."
Is there another solution I'm overlooking?  Please don't think I'm
limiting the discussion to just those two.  If you've got a third way
(or a fourth, or a fifth) I'd love to hear them.
2.  What should be done about the FAQ's guidance to use RSA-2048?
First, I think everyone agrees it should be removed, as it's just not
accurate any more; we've defaulted to RSA-3072 for some time.
One option is, "remove it and update the text to refer to RSA-3072, our
current default."
Another is, "remove it and update the text to refer to ECC, which will
be our next default."  (If so: which curve and which lengths do you
think should be the default?)
(Again, third, fourth, and fifth ways are welcomed.)
3.  What should we advise people about their existing RSA-2048 keys?
"There's no rush, but migrating them to [whatever our new guidance is]
at a deliberate pace is advised, since RSA-2048 isn't expected to be
generally safe past 2030"
"Your existing RSA-2048 keys are fine, you don't need to take any action"
(Again, third, fourth, and fifth ways are welcomed.)

@_date: 2019-10-21 01:09:17
@_author: Robert J. Hansen 
@_subject: FAQ change 
Due to Yahoo! Groups closing, the PGPNET mailing list has moved to
groups.io; the FAQ has been updated with the change.  Nobody objected to
this, so it seems like a safe change.
Due to a lack of any consensus for how the existing text should change,
I've made no other edits at this time.  This is a problem for us,
because we need to figure out whether we wish to continue advocating SKS
and how we ought adjust the RSA-2K language in the FAQ in light of the
fact we currently default to -3K and will soon move to ECC.

@_date: 2019-10-21 05:57:54
@_author: Robert J. Hansen 
@_subject: Future OpenPGP Support in Thunderbird 
And at the same time, less.  Remember what Efail showed us: that the
interface between GnuPG and clients calling it is remarkably subtle and
prone to misinterpretation.  It isn't just Enigmail which got bit by
this, either: a *lot* of email clients got hit.
GnuPG has steadfastly refused to create an OpenPGP library programmers
can use directly, on the grounds that security is improved by adding
process separation between the application process and the GnuPG
process.  There's a lot to be said for this argument.  There's a lot to
be said for the counterargument: that the additional complexity involved
in communicating across a process boundary turns it into a false savings.
I'm not sure which one I believe, myself.

@_date: 2019-10-21 15:11:50
@_author: Robert J. Hansen 
@_subject: Future OpenPGP Support in Thunderbird 
It is not.  Under the hood, GPGME works by launching an entirely new
process and directing it via interprocess communication.
Hopefully this puts the rest of my paragraph in perspective:
"... on the grounds that security is improved by adding
process separation between the application process and the GnuPG
process.  There's a lot to be said for this argument.  There's a lot to
be said for the counterargument: that the additional complexity involved
in communicating across a process boundary turns it into a false savings."
Regardless of whether you interface with GnuPG directly (as Enigmail
does) or through a library (as GPGME-using applications do), you're
still running GnuPG in a separate process and communicating across a
process boundary.

@_date: 2019-10-21 21:21:42
@_author: Robert J. Hansen 
@_subject: FAQ change 
What I know is this: I was asked by a PGPNET member to change the
address, and the cause for the change was the imminent closure of the
Yahoo! Groups version of PGPNET.  That's all.  Beyond that, discuss it
on PGPNET, please.  :)

@_date: 2019-10-24 09:19:14
@_author: Robert J. Hansen 
@_subject: a new free smime service, but... 
Because it's outside the scope of what Let's Encrypt exists to do, which
is make it easy to provide HTTPS support to small websites.
SMTP is *totally* outside of Let's Encrypt's mission.  If you've got a
problem with that, take it up with Let's Encrypt.  They're pretty
responsive on Twitter at Because CACert hasn't been able to comply with Mozilla's Root Store
Policy.  Chrome has its own root store policy, as does Internet
Explorer.  CACert hasn't been able to dot the is and cross the ts for
any of them, AFAIK.

@_date: 2019-10-26 09:36:06
@_author: Robert J. Hansen 
@_subject: Help needed - for a binary to words encoder/decoder for GnuPG 
You can do a *lot* better than that.  This is a solved problem.

@_date: 2019-10-26 10:11:42
@_author: Robert J. Hansen 
@_subject: Help needed - for a binary to words encoder/decoder for GnuPG 
It was designed by a computational linguist specifically to be resistant
to these concerns.  There's an academic paper written about it.  You
should read it.

@_date: 2019-10-26 11:34:37
@_author: Robert J. Hansen 
@_subject: Help needed - for a binary to words encoder/decoder for GnuPG 
Let's not assume anything.  You either have users in such conditions or
you don't.  Design for the users you do have, not the hypothetical users
you imagine having.  I can tell you from bitter experience, hypothetical
users virtually never appear in real life.  The users who *do* appear
normally have use cases you've never even imagined.

@_date: 2019-09-23 21:54:37
@_author: Robert J. Hansen 
@_subject: Upgrade query 
Please send your email as plain text, not HTML.
Migrating from 1.4 to 2.2 is not quite *that* simple, but it isn't hard.
 A while ago I put together some detailed how-to notes: let me dig them
up and I'll get back to you.
Some people will tell you that yes, you can just install-and-go.  It's
certainly possible to *for some users*, but there are corner cases that
can complicate things -- which is why a checklist is useful.

@_date: 2019-09-23 22:53:31
@_author: Robert J. Hansen 
@_subject: Upgrade query 
Can't immediately find them, but here goes.  This is a bit of a process
but it will leave you with a fresh, clean GnuPG 2.2 directory with all
of your GnuPG 1.4 data intact.  And it should also cover the vast
majority of the odd corner cases, too.
1.  Start by backing up your ~/.gnupg directory.  We're going to be
nuking, paving, and rebuilding.  Don't skip this, as there will be files
in here you'll definitely need.
2.  Get a list of every ultimately-trusted key on your keyring.  I do
this with standard command-line tools:
$ gpg --fixed-list-mode --with-colons --list-keys | \
  grep "^pub:u:" | cut -d ":" -f 5 > ~/trusted_keys.txt
3.  Export your entire public and private keyrings.
$ gpg --export-options export-local-sigs,export-sensitive-revkeys \
      --export > ~/pubkeys.gpg
$ gpg --export-secret-keys > ~/privkeys.gpg
4.  Kill gpg-agent.
$ killall gpg-agent
4.  Empty the ~/.gnupg dir.
$ rm -rf ~/.gnupg/*
5.  From the backup you made in step 1, restore the following files.
(You may not have all of them.  If you're missing some, or even most,
that's okay.)
    dirmngr.conf
    dirmngr.conf-1
    dirmngr.conf-1.4
    gpa.conf (no -1, -1.4 variants exist)
    gpg.conf
    gpg.conf-1
    gpg.conf-1.4
    gpg-agent.conf
    gpg-agent.conf-1
    gpg-agent.conf-1.4
    gpgsm.conf
    gpgsm.conf-1
    gpgsm.conf-1.4
    policies.txt
    scdaemon.conf
    scdaemon.conf-1
    scdaemon.conf-1.4
    scd-event
    sshcontrol
    trustlist.txt
6.  Look in your new ~/.gnupg dir for GnuPG 1.4-specific configuration
$ ls ~/.gnupg/*.conf-1*
Then look for unversioned configuration files:
$ ls ~/.gnupg/*.conf
If you have, e.g., a gpg.conf-1 file but not a gpg.conf file, make a new
unversioned file out of the old one.  E.g.,
$ cp ~/.gnupg/gpg.conf-1 ~/.gnupg/gpg.conf
7.  Import your secret keys into gpg2:
$ gpg2 --import ~/sec.gpg
$ gpg2 --import-options import-local-sigs,import-clean \
       --import ~/pub.gpg
8.  Mark your previously ultimate-trusted keys as ultimate-trusted
again.  For each key in your ~/trusted_keys.txt file,
$ gpg2 --edit-key [insert key ID here] trust
Set each trust to ultimate by typing '5'.
... You should be done!

@_date: 2019-09-25 16:35:50
@_author: Robert J. Hansen 
@_subject: ed25519 and sha256 
Wikipedia is not a very good reference for low-level technical details.
 Ed25519 is shorthand for "EdDSA on a specific curve": it is silent on
the subject of hash algorithms, although you can specify one as
"Ed25519-SHA-512" or what-have-you.
Many other applications, such as DNSSEC, call for SHA-256 to be used
with Ed25519.
"Our recommended curve for EdDSA is a twisted Edwards curve birationally
equivalent to the curve Curve25519 from [12]. ... We use the name
Ed25519 for EdDSA with this particular choice of curve.
Specifically, Ed25519-SHA-512 is EdDSA with ... SHA-512."

@_date: 2020-04-20 23:15:24
@_author: Robert J. Hansen 
@_subject: Restoring keyring from backup fails 
GnuPG 2.2 changed the way it stores public and private keys.  If your
old installation was GnuPG 2.0 and the new one is 2.2, that might
explain things.  The fix is pretty easy, though.  Check your versions
and let us know what's up.  :)

@_date: 2020-04-27 00:48:43
@_author: Robert J. Hansen 
@_subject: Passphrase window freezes my DE's panel - is this a bug? 
How would it do so?
Nonsense.  A prior job literally *required* that I not only use
completely random passwords, but 128 bits of them, and completely change
them every six months, for four different networks.  It was incredibly
annoying but possible.
If I can remember "ZECY17pJQo9PoeVqJ4S/lA==" and three others like it,
and change them twice a year, then it's simply untrue that "one HAS to
use a clipboard to get them from where they are stored into where they
are needed".
Convenient, absolutely.  Good UI design, also.  But not *required*.
Further, I don't know who told you that your passphrase must be long,
complicated, difficult to remember and difficult to type.  The
passphrase exists as a defense in the event someone's able to steal your
private key: but if you think you've already defended against theft
adequately, use a short passphrase or none at all.  Like so many things,
it all depends on your own risk model.
Perhaps I missed something, but did the GnuPG team write your pinentry?
 If not, they're really not in a good position to offer help.

@_date: 2020-08-19 14:10:29
@_author: Robert J. Hansen 
@_subject: In case you use OpenPGP on a smartphone ... 
Stefan, I'm not a list moderator and I have absolutely zero authority to
say this, but I'm going to say it anyway:
Please take this stuff elsewhere.
You're linking to a conspiracy theory video alleging a... look, I'm not
going to give these people credibility even by *summarizing* it.  It
should be enough to say that InfoWars is backing it.
It has no connection to fact or even reality, and even less than no
connection to GnuPG or communications security.
Please, I'm begging you: take it elsewhere.  It doesn't belong here.

@_date: 2020-08-20 14:50:36
@_author: Robert J. Hansen 
@_subject: In case you use OpenPGP on a smartphone ... 
Yes.  Obviously.  As everyone has known since the day the CIA was
established.  There's even a website for contractors with security
clearances:   This nonsense video of
conspiracy delusions revealed nothing factual.
Please, I'm begging you: stop hyping this madness.  At the very least,
do it elsewhere.

@_date: 2020-11-30 19:25:45
@_author: Robert J. Hansen 
@_subject: Christmas giving 
In years past I'd run a Christmas fundraiser for GnuPG.  I haven't done that recently after GnuPG received some large contributions from corporate sponsors: but 2020 being what it is, I kind of suspect GnuPG can use a fundraiser, so... let's go back to the classics.
WHAT: For every euro you donate to GnuPG, I donate one euro, up to five hundred euros.
WHEN: From December 10 to January 6.  This should cover the vast majority of seasonal religious holidays.
HOW: All you have to do is donate.  At the end of it I'll ask Werner how big of a donation I'm making, and once it arrives he'll confirm to the list I've upheld my end of the deal.
WHY: Because a great way to say "thank you for all your work, guys!" is to donate to the GnuPG project.
LINK: Merry Christmas, Happy Hanukkah, Blessed Yule and/or Solstice, Season's Greetings, and just have yourself a nice day.  :)

@_date: 2020-12-10 11:58:50
@_author: Robert J. Hansen 
@_subject: Christmas giving 
It very likely was not.
These "Elon Musk is giving away bitcoin!" scams have been going on for Stefan, think about it for a second.
Start with one bitcoin, trade it, get two back... transfer those two BTC to another account... have that account send two BTC to Musk, get four back... transfer those four to another account... send four BTC to Musk, get eight back... transfer those eight to another account, get sixteen back... cash out six BTC ( ** $111,000 USD ** ) and send ten to Musk, get twenty back... cash out ten BTC ( ** 180,000 USD **), send ten to another account, send them to Musk, get twenty back ...
But wait!  Once you have 10 BTC, it parallelizes.  So instead of cashing out 10 BTC, you start an *entirely new* set of BTC trades.  Your first 10 BTC transfer yields 20 BTC, which you then split into two 10 BTC transfers each yielding 20 BTC giving you 40.  You split those into four 10-BTC transfers and...
Musk, with all his billions, would literally be bankrupted in single-digit hours.
Think about this stuff, Stefan.  Type in "Elon Musk bitcoin" into Google before you share things like this.  Don't spread scams on this mailing list.

@_date: 2020-12-10 12:33:03
@_author: Robert J. Hansen 
@_subject: Christmas giving 
I have great sympathy and compassion for people snookered in by such scams, but not when they claim to be part of the information security These BTC scams are obvious nonsense to anyone with a glimmer of security awareness.  "If it were true he would already be bankrupt, he is not bankrupt, therefore it is not true" ain't hard logic to work through.

@_date: 2020-12-11 06:57:03
@_author: Robert J. Hansen 
@_subject: No v3 keys allowed 
v3 keys are the kind generated by PGP 2.6.2, dating from the early
1990s.  You certainly created a v4 key.  Another strong hint comes from
your key fingerprint, which is a v4-style 160-bit hash.  v3 keys
overwhelmingly used 128-bit hashes.
My suspicion is that keyserver.pgp.com doesn't support elliptical curve
keys, and when it throws an error it has half-assed error handling that
assumes "if I couldn't import the key it must've been a v3 key."

@_date: 2020-12-13 23:15:33
@_author: Robert J. Hansen 
@_subject: Protecting your private key - passphrase 
This is snake oil.  Please do not use it.  Stefan's claims are not
rooted in mathematics.  Ingo's criticism is bang-on accurate.
Digest algorithms do not produce random output.
They do not even produce cryptographically secure pseudorandom output.
A digest algorithm is not a CSPRNG.  The construction Stefan is using
here is known to fail many important tests of a CSPRNG.
Don't do this.  The entire step is unnecessary and adds literally zero
security to GnuPG.
Nor is he a cryptographic engineer.
Please do not use this, or if you do, use it at your own risk.

@_date: 2020-12-13 23:35:15
@_author: Robert J. Hansen 
@_subject: Protecting your private key - passphrase 
Stefan, I read your original posting and I completely concur with Ingo.
Please explain to me who might benefit from this.
Seriously.  If people want CSPRNG output, this is not CSPRNG output. If people want a key derivation function, this is a *really bad* key
derivation function: you should've used PBKDF2 or Argon2.
What's your use case?  Who might benefit?
No, Stefan, that's not how it works.  It is flat impossible to, by any
deterministic means, increase the entropy of a function's output over
the function of the input.  Deterministic functions only ever reduce
entropy: there exist no deterministic functions that increase it.
Imagine I have a 'Gender' field on a driver's license, and it can take
three values: 'Male', 'Female', and 'Nonbinary'.  There are three
states there, meaning there are (log-2 of 3 = ) 1.58 shannons of
entropy present.  If I feed one of those three fields into SHA256 and
get 'fceea935c627080824b44df8f222631d39e6f705b307be1fc80f36769ade230c'
I'm not increasing the entropy, I'm only spreading 1.58 shannons out
over a larger region of text.
"But if I feed this into an entropy estimator it comes back high!" Yes, because entropy estimators are like any other tool: they need to
be used with insight.  If the entropy estimator knew the universe of
possibilities was only 'Male', 'Female', and 'Nonbinary', and the
algorithm used was SHA256, it could then say "oh yeah, 1.58 shannons of
entropy, boss."
But when you na?vely run an entropy estimator and *deny it information
about the possibility set or algorithms used*, you're violating
Kerckhoff's Principle and of course you're going to get wildly
incorrect results.
Then I invite them to come here and explain to me where I'm wrong.
So far in the last week you've advocated Bitcoin scams on this list and
hyped your own snake oil.
In just the last week.
Please stop.

@_date: 2020-12-14 06:26:42
@_author: Robert J. Hansen 
@_subject: Protecting your private key - passphrase 
Then why aren't you using PBKDF2 or Argon2?
If you're writing a key derivation app -- use a key derivation function.
What are you talking about?  Here's the signature for PBKDF2 in Golang's crypto library:
func Key(password []byte,
          salt []byte,
          iterations int,
          keyLength int,
          hashFunction func() hash.Hash) []byte
If you need to generate the same key again later, just feed in the same inputs.  You have nothing to keep track of so long as you remember the I'd advise people to use Firefox's password safe and ability to generate pseudorandom keys for each site you visit.  KeePassX is a good open-source alternative for people who want to keep passwords on their desktop machine instead of encrypted in the cloud.

@_date: 2020-12-14 06:37:35
@_author: Robert J. Hansen 
@_subject: Protecting your private key - passphrase 
I'm not going to discuss this with you further.  It's clear you don't know what you're doing, and I trust that's been made clear to the mailing list.

@_date: 2020-02-24 12:01:42
@_author: Robert J. Hansen 
@_subject: Bulk removal of expired keys 
gpgclean.ps1.  "PGP" is a registered trademark of Symantec.  The free software version is GPG.
No, but if you give me until tonight there can be.

@_date: 2020-01-04 04:10:13
@_author: Robert J. Hansen 
@_subject: Different key pare for e-mail and signing code 
It should be noted that Enigmail hasn't changed how it does anything.
We don't know, either.  It's going to depend on your own personal risk
If you want to segregate your code signing from your email, the best way
to do that is with a second certificate -- not adding subkeys to your
current one.
Ask yourself this: how often have you noticed that my signed messages
bear *two* signatures from *two* subkeys belonging to the same
certificate?  I've been doing this for years and nobody's ever noticed.
 (Or at least, nobody's ever mentioned it to me to ask why I'm doing
something so weird.)
So if you're depending on people ascribing special semantic value to
which subkey is used -- honestly, I doubt people will ever even notice
which subkey you're using.  It's simply not a use case that comes up
very often, if ever.

@_date: 2020-01-07 02:37:30
@_author: Robert J. Hansen 
@_subject: Changes in GnuPG 
The names are actually keygrips, not fingerprints.
They didn't.  RFC4880 doesn't define how to store certificates.
Way back when, PGP Corporation stored its two keyrings as "pubring.pkr"
and "secring.skr".  These two files were incredibly simple: each was
effectively an OpenPGP message containing nothing but a long sequence of
certificates.  When PGP started it read each file into RAM, populated a
master keyring, and that was that.
When GnuPG came along they decided to use the exact same format so that
people could migrate just by renaming their .pkr and .skr files to have
.gpg extensions.  And this was likely a good decision, in that it made
it easy for people to switch from PGP.
PGP is no longer a serious player in the OpenPGP space.  Symantec bought
PGP years ago and seem to have been neglecting it ever since.
Consequentially, we no longer *need* to use old PGP formats to encourage
people to cross over.  And at the same time, keyrings are getting a lot
bigger -- back in 2000 few people had more than a couple of dozen
certificates; twenty years later it's easy to have a few *hundred*
certificates.  And the old, inefficient PGP keyring format doesn't work
very well any more.
We don't need the PGP compatibility any more and it's holding us back.
That's the root reason for the changes.

@_date: 2020-01-07 09:53:33
@_author: Robert J. Hansen 
@_subject: What are some threats against which OpenPGP smartcards are 
Hint: because the phrase "forensics lab" is extremely important in what I wrote.
I used to (don't any more) work in a forensics lab doing R&D into recovering data from memory, SSD, and spinning-platter media.  While I was doing this my colleagues were reverse-engineering malware.  Our network was airgapped from the rest of the network, but we were still paranoid about data getting out -- including information about our identities.  When you're doing reverse engineering on a botnet belonging to an organized crime syndicate, you really don't want the organized crime syndicate to discover your name.
I was also using OpenPGP to help move data into and out of our airgapped network.  When a CD came into our lab containing data to be loaded onto machines, we used OpenPGP to verify its provenance.  When we burned a CD containing data to be removed from the lab, we'd put a signature on it so the system administrators in the lab outside could be certain that a specific human being was taking responsibility for the contents of that Problem: I didn't want there to be any certificate stored on the lab machines... because any user ID that identified me would be personal information of the kind I didn't want to be stored.
Solution: use a smartcard.  A smartcard allowed me to make these signatures while leaving minimal forensic traces.
But, outside of that laboratory environment, I didn't -- still don't -- need to use a smartcard.  Usually I just keep the key on the hard drive of whatever machine I'm using.

@_date: 2020-01-07 09:57:46
@_author: Robert J. Hansen 
@_subject: What are some threats against which OpenPGP smartcards are 
Dude, the lab I worked in *required* me to use 128-bit secure passphrases.  It was *awful*.  And a 180-day change policy.  But the good news is that once you prove to yourself you can do that, the idea of keeping a 128-bit passphrase on your certificate no longer seems so To quote the movie _Men in Black_, "Give it a few months.  You'll get used to it, or you'll have a psychotic episode."

@_date: 2020-01-09 19:13:27
@_author: Robert J. Hansen 
@_subject: Changes in GnuPG 
Growing up in a family of hunters, I learned at an early age that even
if someone tells you a firearm is unloaded you should still clear the
chamber and store it pointed in a safe direction... especially if
someone tells you "no, really, it's perfectly safe, I just checked it".
I apply the same to any file claiming to be a random seed.  No matter
who tells me it's safe to copy it I'm not going to copy it, and I think
other people would be best served to adopt the same rule.  :)

@_date: 2020-07-13 23:02:55
@_author: Robert J. Hansen 
@_subject: Multiple UIDs or multiple master keys? 
Let's hop in the Wayback Machine and look at the old specification for
OpenPGP, called RFC2440.
5.2.3.22. Reason for Revocation
   (1 octet of revocation code, N octets of reason string)
   This subpacket is used only in key revocation and certification
   revocation signatures. It describes the reason why the key or
   certificate was revoked.
   The first octet contains a machine-readable code that denotes the
   reason for the revocation:
       0x00 - No reason specified (key revocations or cert revocations)
       0x01 - Key is superceded (key revocations)
       0x02 - Key material has been compromised (key revocations)
       0x03 - Key is no longer used (key revocations)
       0x20 - User id information is no longer valid (cert revocations)
   Following the revocation code is a string of octets which gives
   information about the reason for revocation in human-readable form
   (UTF-8). The string may be null, that is, of zero length. The length
   of the subpacket is the length of the reason string plus one.
Reasons 1, 2, and 3 are simply not used by UID revocations.
To answer your next question of "why is 'User ID information is no
longer valid' number 4, instead of 32 (hexadecimal 20) like it is in the
spec?", I'm guessing to prevent people from wondering what happened to
the other 30-odd (nonexistent) options.  :)

@_date: 2020-07-26 15:01:43
@_author: Robert J. Hansen 
@_subject: Newbie question. 
I am very pessimistic about the idea of collective effort.  What
experience has taught me from working on the FAQ is that a small number
of people with extreme ideas speak up the loudest, and the vast majority
of users who are calm and reasonable speak up barely at all.

@_date: 2020-07-28 01:39:21
@_author: Robert J. Hansen 
@_subject: Non printable ASCII characters in pass phrase. 
GnuPG doesn't care, but your password manager might have problems or
your third-party pinentry or...
Best advice is to use printable UTF-8.

@_date: 2020-07-28 08:12:19
@_author: Robert J. Hansen 
@_subject: Protecting encryption server 
You can't.  There is little to no defense possible against a trusted
insider that's gone rogue.  The best you can do is to vet your people
carefully and, in the event of treachery, to use whatever legal means
are available to dissuade future treachery.
Kim Philby, Aldrich Ames, John Walker, Robert Hanssen, Reality Winner,
Chelsea Manning, Ed Snowden...

@_date: 2020-07-28 15:58:45
@_author: Robert J. Hansen 
@_subject: Protecting encryption server 
Strange but true: although I can't claim to have been on the research
team that invented the data diode, I *was* on the research team that
invented the first cheap optical data diode.  We packaged it up into an
Altoids tin.  Total materials cost was under $100, and most of that was
spent on the custom PCB.
Oh, quite the contrary.  It just forces the attacker to get clever.
Our paper from 2006:

@_date: 2020-07-28 16:38:25
@_author: Robert J. Hansen 
@_subject: Protecting encryption server 
The data diode is a one-way link, yes.  But there are so many ways to
gain access to machines that putting too much faith in a data diode to
protect your systems is deeply foolish.  A data diode can make *one
particular link* a one-way data link.  That's genuinely useful in the
context of a complete security solution that looks holistically at the
But no, they don't make a system unhackable.
Lateral movement through networks is a thing.  Look into it.  :)

@_date: 2020-07-29 05:53:53
@_author: Robert J. Hansen 
@_subject: Protecting encryption server 
Our research was done as part of an electronic voting security group at
the University of Iowa.  The particular use case we had was, "how do you
communicate realtime election results to a public webserver in a way
that even if attackers compromise the webserver they cannot access the
tallying system?"
And for that, the tickertape model works pretty well.  We had a proof of
concept running in Python at a very low baud rate: it was transmitting
at a speed slightly slower than an old Telex teleprinter.  This had the
additional side effect of making it easier to audit (you could
physically see the LED flip on and off), easier to sync, and more
resistant to transmission errors.
For election results, Telex speeds are just fine.  If you need more
bandwidth than that, the next best bet is to just burn a DVD and
hand-deliver that.
... which, not to put too fine a point on it, is where the potential to
exploit the system comes from.

@_date: 2020-06-28 16:24:43
@_author: Robert J. Hansen 
@_subject: decrypt aes256 encrypted file without gpg-agent 
It's also responsible for calling pinentry, which is how GnuPG receives
passphrases.  It's a pluggable component: on Windows you get a Windows
pinentry that uses a Windows look and feel, on KDE you get a Qt one that
looks like a KDE app, on GNOME you get a GTK one that looks like a GNOME
app, and so on.
GnuPG sees the symmetrically encrypted message and knows it needs to
recover/derive a key.  It calls gpg-agent, which in turn calls pinentry.
Let's be clear: you're passing judgment on a design without first
learning what the design is.
GnuPG adopted gpg-agent in large part to clean up GnuPG's design.  GnuPG
was introduced in GnuPG 1.9.0, released in August *2003*.
You've ignored GnuPG development for so long you're surprised by a
change introduced seventeen years ago.  That's on you.

@_date: 2020-06-29 02:31:24
@_author: Robert J. Hansen 
@_subject: decrypt aes256 encrypted file without gpg-agent 
If you were using GnuPG 1.4, yes.  GnuPG 2.0 and later have always used
If you want a gpg-agent free version of GnuPG, use version 1.4.

@_date: 2020-06-30 02:37:22
@_author: Robert J. Hansen 
@_subject: decrypt aes256 encrypted file without gpg-agent 
Again, you're criticizing a design before learning why that design is
the way it is.
You don't understand the design, which means you don't know what the
system needs and/or doesn't need.  You're not displaying judgment here,
you're displaying prejudice.
You are of course welcome to give what feedback you like.  I
respectfully suggest that if you start by learning why these various
tradeoffs were made, it will allow you to make better criticisms that
will be taken more seriously by the development team.

@_date: 2020-06-30 10:50:59
@_author: Robert J. Hansen 
@_subject: decrypt aes256 encrypted file without gpg-agent 
============================== START ==============================
There is no such universal playbook.  It simply does not exist.
In his book _Lila_ the philosopher Robert M. Pirsig wrote that morality
is not a set of universal principles, so much as it is what emerges from
the interplay of conflicting principles that are at odds with each other.
You can say the same about software engineering.  There are no universal
principles, only rules of thumb that are often at odds with each other.
Learn about GnuPG's design and why it is the way it is, _then_ judge it.
 To loftily decree there exist universal principles and thus you don't
need to learn the specifics before judging is little different from the
judge who decrees that murder is illegal and so doesn't need to learn
whether the accused was acting in self-defense.
I'm an amateur auto racer, and this sounds like an *awesome* idea.  In
virtually all races pit crews are required to not touch the car until
it's stopped moving, entirely for safety reasons: when there's a
thousand-kilo piece of metal in motion, it's wise to require people to
stay clear of it.  If you could figure out a way to make it safe to make
changes to a car in motion, you'd have every NASCAR and SCCA team
beating a path to your door.
Your "universal principles", well -- aren't.

@_date: 2020-03-11 15:49:12
@_author: Robert J. Hansen 
@_subject: ed448 support in =?UTF-8?Q?gpg=3F?= 
Why is it so important your keypair be as long-lived as possible, when there's very little likelihood of you going for that long a period without a key compromise event?
Think about key compromise events as you would a building fire.  We don't make our buildings fireproof: instead, we clearly mark fire exits, hold drills, make backups, and write continuity-of-operations plans.  The fire *will* happen, but how quickly we recover from it is up to us.
Murphy *will* find us, Murphy *will* beat us, Murphy *will* take our lunch money.  When making a new keypair, I think people are well-served to remember the key lifetime is fundamentally in Murphy's hands -- not

@_date: 2020-05-11 18:11:27
@_author: Robert J. Hansen 
@_subject: Fwd: The GnuPR FAQ 
This arrived in my inbox: I'm presenting it here without comment.  My
response will be following in a moment.
-------- Forwarded Message --------
I'm just getting?started on a write-up with instructions explaining?how
to use all of the new options in GnuPG to set it up in the various email
clients and browsers.
I noticed on this page:
You've advised people to use a HORRIBLE practice of using dictionary
words solely for their password. I tested this theory myself back in the
day, so I can 100% guaranty you of this fact: A brute force dictionary
based attack can crack a password like that in LESS THAN 5 minutes!! I
once stretched that out to 20 minutes by cleverly picking words that I
already knew were at the opposite ends of the dictionary.
This was back in the Pentium II days!! Processors these days could
likely crack a dictionary based password in a matter of seconds.?
I'm sorry, but that particular bit of advise is terrible and needs to be
changed. If you guys accept public assistance, I could go through the
instruction / FAQ pages for you, update them, then submit them to you
for approval.
Since I'm already writing updated instructions anyway. ;)?
?- James T. Long
There are 10 kinds of people in the world - those who understand binary,
and those who don't.

@_date: 2020-05-11 18:13:11
@_author: Robert J. Hansen 
@_subject: The GnuPR FAQ 
Tell you what: try it.  :)
If you choose only from the thousand most-common English words (a
keyspace of about 2^10), a six-word passphrase gives a work factor of
2^60.  The key derivation function means you're spending at least 2^-10
seconds for each attempt, which means you've got 50/50 odds of breaking
the passphrase after 2^49 seconds -- or about 18 million years.
A four-word passphrase could be broken after 2^29 seconds, or about 17
It's parallelizable, of course, if you want to rent out 18 million AWS
instances.  But at present, the sense of the community is that the FAQ
advice, which gives people between 17 years and 18 million years of
resistance to a brute-force attack, is sufficient.
I have forwarded your criticism on to the community and invited them to
give their own feedback.  The FAQ is the collective opinion of the
community, not just myself -- all I do is write the thing.  If the
community concurs with your sentiments, I'll change the text.
We welcome any useful contributions.  :)

@_date: 2020-05-12 10:41:09
@_author: Robert J. Hansen 
@_subject: Fwd: The GnuPR FAQ 
This is probably not the best metric.  The length of the word is
irrelevant: if one of your words is "zoo", that's no easier or harder to
guess than "prolix" or "antediluvian".  The words are all equally random.
Much more important than length is memorability.  "Coulrophobia" is a
great word but I'd be looking up how to spell it all the time.
You can get by just fine in most everyday English with a vocabulary of
5,000 words.  Stick to those words and you'll have an easy-to-remember
Or, you know, learn coulrophobia, enhance your vocabulary, and get down
with your clown-fearing self.  It's up to you.  :)

@_date: 2020-05-12 16:29:28
@_author: Robert J. Hansen 
@_subject: Comparison of RSA vs elliptical keys 
"Yes".  :)
Back when we got these questions -- Elgamal?  RSA?  DSA?  Help? -- we
used to tell people what mattered far, far more than which algorithm
they used was how much care they gave to their system.  Keep your system
malware-free.  Don't sign things willy-nilly without reading them first.
 Be careful who you share your system with.  Etcetera.
I have never ever heard of a cryptographic break against OpenPGP.  I've
seen people be careless many times.  I'm far more worried about that
than I am which algorithm you use.

@_date: 2020-05-13 06:18:36
@_author: Robert J. Hansen 
@_subject: Comparison of RSA vs elliptical keys 
rjh at maggie:~$ gpg --gen-key
gpg: WARNING: using experimental features from RFC4880bis!
Note: Use "gpg --full-generate-key" for a full featured key generation
GnuPG needs to construct a user ID to identify your key.
Real name: Delete Me
Email address: delete at example.org
You selected this USER-ID:
    "Delete Me "
Change (N)ame, (E)mail, or (O)kay/(Q)uit? o
We need to generate a lot of random bytes. It is a good idea...
Where in there was I ever asked to choose an algorithm?
"Unless you know what you're doing and why, use the defaults."  I've
been saying that for twenty years now.  I keep thinking that someday
someone will actually take it seriously...

@_date: 2020-05-14 17:23:00
@_author: Robert J. Hansen 
@_subject: Comparison of RSA vs elliptical keys 
Speaking for myself, I have "rfc4880" in my gpg.conf for damned good
I *do not* want GnuPG to generate UID-less certificates in strict
compliance mode, I *do not* want GnuPG to use them in strict compliance
I have no opinion on "--allow-broken-certificates" and only allowing
them to be generated in expert mode after a clear warning about it being
I also think this is the wrong place to talk about how the RFC should be
changed.  Take it to the WG, please.

@_date: 2020-05-14 21:56:32
@_author: Robert J. Hansen 
@_subject: Comparison of RSA vs elliptical keys 
Sure.  And if they're important enough for me to justify breaking
compliance, I am perfectly capable of removing the "rfc4880" flag from
my gpg.conf file.
There is no excuse for willfully breaking RFC4880 compliance *when the
user has explicitly requested strict compliance*.

@_date: 2020-05-15 09:21:47
@_author: Robert J. Hansen 
@_subject: Comparison of RSA vs elliptical keys 
Yes.  If you want to talk about changing the standard please bring it up
to the proper mailing list.  Here is not the place for it.  If you can
persuade people to change the standard I'll be wildly in favor of GnuPG
implementing the standard.
This is irrelevant.
We're talking about what GnuPG should do if someone specifies strict RFC
conformance.  The answer to that question is simple: it should strictly
conform to the RFC and treat UID-free certificates as the malformed
entities they are.

@_date: 2020-05-15 09:32:34
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
It is not the job of the command-line interface to teach users the
subtleties and nuances of OpenPGP.  If users want to know the many
different ways GnuPG can be used they need to read the documentation.
If you think this use-case is important enough it should go in the
manpage or FAQ, let's discuss that.  But the command-line user interface
is the wrong place to be teaching people about unusual use cases.

@_date: 2020-05-15 12:30:57
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
They are free to use whatever identifier they like for a UID, even just
the key ID.  A UID-free certificate is in no way required for user privacy.
You're being dishonest.  I hate to say that, but I believe it's true.
You insist on pretending that you're the only one concerned about
privacy and that UID-free certificates are necessary for privacy of
personally identifying information.  The reality is the UID system in no
way requires personally identifying information and everyone you're
accusing of not caring about privacy cares a great deal about it.
You're being dishonest.  Please stop.
If you want the documentation to reflect PII-free UIDs, please say that.
This could be a useful discussion.  If the community believes PII-free
UIDs should be in the FAQ I will happily write up an entry for it.

@_date: 2020-05-16 11:56:47
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
I tell them, "I will not be able to use OpenPGP with you until such time
as you UID conforms to the standard.  Would you like help in making your
user ID standards-conformant in a way that reveals nothing about your
real-world identity?"
This is, in fact, the preferred GNU way.  "I'd love to be able to work
with you on this document, but you're using a proprietary format I can't
read.  There's an open format we can both use, though, and I'd be happy
to help you get started with it."
The RFC is maintained under auspices of the Internet Engineering Task
Force (IETF), just like every other RFC.  The IETF's motto is "rough
consensus and running code".
Werner sits as secretary of the (largely dormant) group that guides
OpenPGP development, but there are a lot of non-GnuPG people who are
deeply involved in giving feedback on proposed changes.  He's the
secretary, not the dictator.

@_date: 2020-05-16 12:04:07
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
Please, just "Rob".  :)
I share a name with Robert "rsnake" Hansen of SecTheory.  He and I have
both spoken at Black Hat and DEF CON (which has sometimes led to
hilarious results when journalists have tried to track us down to talk
about our research).
In order to reduce confusion I always use my middle initial
professionally.  But I go by Rob.  :)

@_date: 2020-05-16 16:28:58
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
GnuPG had a bug in the key importation code which made it run in time
proportional to the square of the number of signatures.  Importing a
certificate with 100,000 signatures was literally a hundred million
times slower than importing a certificate with 10.
That bug has since been fixed.  With judicious use of the various -clean
options, the key spamming bug is effectively dead... on the GnuPG side:
on the SKS side, people are still filling up SKS keyservers with spam.
SKS is a completely separate project from GnuPG, and has no RFC guiding
it.  So the "bureaucratic" project has it resolved, and the "free to
innovate" project has been unable to innovate.
(Note: I'm not blaming SKS.  This is a hard problem.  I personally don't
think SKS can be saved.)

@_date: 2020-05-17 20:23:23
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
GNU is a project by the Free Software Foundation.  They're very focused
on what they call "free software", where freedom is about liberty and
not price.  (Most people call it "open source software" instead, but FSF
and GNU are very particular about the language they use.)
FSF and GNU are both very concerned about the spread of proprietary
formats.  For instance, for many years only Microsoft Word could read
.doc files.  This was a problem for people who wished to only use free
So the FSF/GNU way was, whenever someone tried to send them a document
in a proprietary format, was to tell the sender
GnuPG is part of the GNU project.  I think we should use the standard
GNU response when people want us to use certificate formats that don't
comply with the OpenPGP standard.
You can learn more about the FSF at:
You can learn more about GNU at:
Hope this helps.

@_date: 2020-05-18 12:16:58
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
I think that's a little excessive, Werner.  OpenPGP was always intended
to be flexible on the subject of certificate distribution, and there are
many use cases where a single authoritative keyserver is preferred over
a distributed federation.
In 2001 I was the chief system administrator for a law firm which used
OpenPGP to secure client communications.  (It didn't require clients to
use OpenPGP but provided it as an option for clients who were concerned
about email privacy.)  The procedure was simple: when you opted into
OpenPGP you showed up at your attorney's office in person with your
certificate burned on a CD.  Your attorney then called in a member of
the sysadmin staff (usually me) who would check fingerprints with you,
before signing it with the firm's trusted-introducer key and uploading
it to the firm's own keyserver.
Doing it this way meant we could skip long conversations about, "but
can't anybody get my certificate if it's on the internet?"  Instead of
spending 30 minutes talking about why it's okay if public certificates
are shared, we could instead just say "we're not going to share your
public key with anyone without your written consent" and spend those 30
minutes talking abut more productive things.
Centralized key management schemes are sometimes very useful.

@_date: 2020-05-19 10:29:26
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
Sets up a named group, which is similar to aliases in email pro?
        grams.  Any time the group name is a recipient (-r or  --recipi?
        ent),  it  will  be  expanded  to the values specified. Multiple
        groups with the same name are automatically merged into a single
        group.
        The  values are key IDs or fingerprints, but any key description
        is accepted. Note that a value with spaces in it will be treated
        as  two  different  values. Note also there is only one level of
        expansion --- you cannot make an group that  points  to  another
        group.  When  used from the command line, it may be necessary to
        quote the argument to this option  to  prevent  the  shell  from
        treating it as multiple arguments.
The feature you want, GnuPG already has.  If my certificate had no email
address listed, you could put
... and then whenever you asked GnuPG to encrypt something for
rjh at sixdemonbag.org, GnuPG would silently substitute my certificate.
So let's recap:
* PII-free UIDs are possible today
* Nobody is forced to put PII in a UID
* Certificates can be relabeled with the 'group' option
It really seems like after all this discussion the only thing left is
you think GnuPG ought do a better job documenting how to create a
PII-free UID.  And if you can get the community to back you on that I'll
draft it myself.

@_date: 2020-05-21 12:48:01
@_author: Robert J. Hansen 
@_subject: "just invent something..." 
Only if your sigs are exportable.  Local sigs are a perfectly legitimate
way to use the WoT.  If Alice locally signs Bob's certificate and sets
Bob up as a trusted introducer, Alice can benefit from Bob vouching for
Charlotte's certificate without revealing her identity to Charlotte --
or even the fact that she (Alice) even exists.
The question is irrelevant.  OpenPGP allows you to use true identity
information, false information, or true information about a persona, or
false information about a persona, or a recipe for a nice habanero
salsa.  Do what's right for you, and understand that what's right for
you may well be different from what's right for others.
(Saute two thinly-sliced cloves of garlic in a little oil for a few
minutes until they start releasing the garlicky goodness.  Add a pinch
of ground cumin; saute another minute.  Add 500g finely-diced tomatoes
and their juices, one habanero finely-diced, cook over low heat for ten
minutes stirring constantly.  Once the tomatoes and peppers are
well-cooked, pour into a blender or food processor.  Add cilantro and
the juice of one lime, puree the mixture, pour into a bowl.  Decorate
with lime slices.  And here you thought this mailing list was only good
for nerd stuff...)
It already is.
But they can.

@_date: 2020-05-22 07:50:21
@_author: Robert J. Hansen 
@_subject: keys require a user-id 
He would prefer you refer to Debian as the GNU/Linux Debian OS.  :)
dkg is also a genuinely pleasant person.  I've met him a couple of times
at conferences.  He's very nice.  We need more kind people in the
community.  :)

@_date: 2020-05-23 12:30:30
@_author: Robert J. Hansen 
@_subject: "just invent something..." 
Okay, but this seems largely redundant with section 8.12 of the FAQ,
which, uh ... does exactly this.  What exactly are you objecting to?
8.12 How do I use another person?s certificate?
In order to send an encrypted message or verify a signature, you must
obtain the certificate for the recipient?s/signer?s public key.
Occasionally you might obtain the certificate physically, by meeting the
certificate holder face-to-face and exchanging the certificate on some
storage medium such as a USB stick, memory card, or portable disk. Or
you might download a copy of the certificate from the holder?s web site.
Once obtained in one of these ways, you can add the certificate to your
collection of public keys by doing:
gpg --import certificate.txt
More commonly, you?ll download a correspondent?s certificate from a
[snip keyserver instructions]
*Why do I need to validate certificates?*
If you were to receive a letter in the mail that claimed to be from the
President of the United States, would you believe it? Probably not,
because anyone can put together official-looking letterhead: you?d
insist on doing some kind of checking to make sure that no one was
fooling with you.
The same applies to email. A certificate can claim to be from anyone.
You have to make sure that the certificate really belongs to whom it
claims it belongs to. That process of making sure is called ?validation?.
*How do I validate certificates?*
This advice is controversial.
It?s controversial for a simple reason: every Tom, Dick and Harry has
their own idea about the ?right way? to validate certificates. Some of
these people are well-informed and some of them are just plain unhinged.
In the end, you are responsible for making your own decisions. That
said, the following is generally agreed upon as being a reasonable
    1. Meet the certificate holder face-to-face.
    2. Ask to see two forms of government-issued identification.
    3. Upon verifying the person really is who they claim to be, ask
this person to provide their certificate?s fingerprint, their email
address, and where you can obtain a copy of their certificate. (Example:
?My fingerprint is 4541 BB01 8EA4 8F99 19CA 3701 2380 6BE5 D6B9 8E10,
and you can find it on pool.sks-keyservers.net.?)
    4. On your own computer, retrieve the person?s certificate from the
specified location. Check to make sure the email address they gave you
is one that?s also listed on the certificate. Check to make sure the
fingerprint of the certificate you?ve downloaded matches the fingerprint
the person gave you.
    5. gpg --edit-key [their certificate ID] sign
    6. Once signed, gpg --armor --output signed_cert.asc --export [their
certificate ID]
    7. Send the file signed_cert.asc to the address they gave you
By following this process you first ensure that you?re speaking to the
right person. By comparing the fingerprints of the certificate you have
against the fingerprint they specified, you?re ensuring that you have
the right certificate. Checking to make sure the email address they gave
you is also listed on the certificate is one more check to make sure.
Once that?s done, presto, Bob?s your uncle: there?s nothing left to do
except sign it and return the newly-signed certificate to the other person.
I mean, this seems like 95% of what you want.  You just want the
reference to an email address in step 4 removed?
If you can get the community to agree, I'm all in favor.
The FAQ covers both online and offline use.

@_date: 2020-05-24 00:14:20
@_author: Robert J. Hansen 
@_subject: "just invent something..." 
Correct, and that's by design.
There is no -- *NO* -- generally understood meaning for user IDs beyond
"the name here is a meaningful term of address for an individual or
individuals who control this email address".
Many years ago I was in Germany and tried to persuade a friend of mine
to do the hard right thing as opposed to the easy wrong thing.  She
rolled her eyes at me and declared "du bist Rob, der Ritter".  ("You're
Rob, the knight.")  She was attempting to be sarcastic.  Bystanders
misheard her as "du bist ein Raubritter" and a new nickname for me was
So let's say I give you my ID and you're one of these people who knows
me as Raubritter.  Would you sign raubritter at sixdemonbag.org?  Probably.
 Should you?  Sure, why not?  You know there's a specific person, me,
who answers that email address and you know exactly who I am in the eyes
of the law, thanks to seeing my ID.
So why shouldn't you sign a pseudonym, if you know the pseudonym maps to
an individual person?  And if you're going to sign a pseudonym, why not
sign donald_trump at sixdemonbag.org if you happen to know there's a person
or persons at that domain which answer to that name?
[1] This was thirty years ago.  Words tend to change their cultural and
slang meanings over the years.  I don't know what the current
implications of "Raubritter" are, and for that reason I don't use it or
advertise it to others... but yeah, there are people who have known me
for thirty years who still call me that.

@_date: 2020-05-24 12:18:51
@_author: Robert J. Hansen 
@_subject: Backup of Keys 
Good Lord, it's been a while since I wrote that.  The Windows MSI
installer should still work, though.  If there's interest in other
formats, I'll see about updating it.

@_date: 2020-05-24 15:57:17
@_author: Robert J. Hansen 
@_subject: Backup of Keys 
Don't.  GnuPG puts things in that directory that are specific to your
particular machine.  Most of these are harmless (lockfiles, etc.) but
some are potentially harmful to share between installations.
For instance, there's one file, "random_seed".  Werner says it's not a
major concern, but I and many others have a flaming heebie-jeebies
reaction to the idea of sharing a random number generator's seed file
between two machines -- copying RNG state information is how *many,
many, many* cryptosystems in history have been broken.
Don't just back up the directory.  Only copy the files that are strictly
necessary for operation.  Sherpa can help you with this.

@_date: 2020-05-25 03:06:09
@_author: Robert J. Hansen 
@_subject: Public Keyring Security 
The OpenPGP standard dates back to the mid-1990s, when PGP 3 was first
being considered.  (It was never released: the next version of PGP was
actually PGP 5.)  Our understanding of the risks of metadata have
evolved significantly since then: it's possible that if OpenPGP were
being designed fresh today on a clean sheet of paper there would be some
mechanism in place to obscure or conceal metadata.
Which is, of course, another way of saying that at present OpenPGP is
completely silent on this subject.  If you want your public keyring to
be a confidential secret, the way to do that is to store it on an
encrypted file system.

@_date: 2020-05-25 03:13:28
@_author: Robert J. Hansen 
@_subject: "just invent something..." 
I refer you back to the part of the FAQ which says the certificate
signing process is controversial because every Tom, Dick, and Harry has
their own idea on how to do it.
If you can convince the list that the FAQ needs updating, I'll update
it.  But otherwise, I'm going to consider this yet another opinion on
what the right thing to do is, and although I certainly think it's on
topic for the list, I'm not going to consider changing the FAQ until and
unless there's buy-in from others.  :)
Nabokov once said that translations were like women: the beautiful ones
weren't faithful, and the faithful ones weren't beautiful.
Literally, "raubritter" means "robber-knight" and historically refers to
minor nobility in the medieval period who extorted money out of anyone
they could.  In English literature, these figures are normally called
"black knights".
Use whichever meaning you want.  :)

@_date: 2020-05-25 03:17:02
@_author: Robert J. Hansen 
@_subject: "just invent something..." 
By all means, go for it!  And if you can get the community to say "yeah,
that's a good idea" I'll happily merge 'em in.
I know I keep on saying "if the community wants it...".  That's the hard
and fast rule for the FAQ: it represents the consensus of the community.
 I'm the FAQ custodian more than I am the FAQ author.

@_date: 2020-05-25 17:49:47
@_author: Robert J. Hansen 
@_subject: Backup of Keys 
The word of caution is because I'm not actively maintaining it: the lack
of commit history is because it's literally a project I threw together
over a single long evening fueled by two beers and a Red Bull.
The code isn't bad.  However, in the four years since I wrote it QMake
has changed its .pro files just barely enough that they need to be updated.
If there's interest, I'll take a look at updating this for the most
recent version of Qt.

@_date: 2020-05-29 16:32:34
@_author: Robert J. Hansen 
@_subject: Certified OpenPGP-encryption after release of Thunderbird 78 
Over the last fifteen years of providing email support to Enigmail
users, I can say 95% of the Enigmail problems were caused by needing to
call out to GnuPG.  The pipeline was (still is) fragile and the source
of many errors.  Distributing GnuPG separately from Enigmail was also a
headache and a half.
You may think Enigmail is a proven working solution because it works for
you and the people you know.  I'm very happy it works so well for you!
But from my perspective, with literally almost two thousand emails over
the last fifteen years from people asking for help, I'm reluctant to
call it that.
It works well for many people and I'm really glad it exists.  But
there's still an unfortunate amount of work involved in getting it set
up and working.

@_date: 2020-05-29 17:34:52
@_author: Robert J. Hansen 
@_subject: Certified OpenPGP-encryption after release of Thunderbird 78 
Enigmail development has ended.  The upcoming 2.2 is the final release
and introduces no new features.  It exists only to help people migrate
to TB78's OpenPGP support.
TB68 is being EOLed this fall.  We've promised to continue to support
users for six months after that, including giving emergency security
fixes to Enigmail if they become necessary: but at six months and one
day we're going to mop the floor, tally up the cash register, shut off
the lights, and lock up as we leave.
(The only exception is a commercial email company that has a signed
support contract with Patrick -- their contract will be fulfilled.)

@_date: 2020-05-29 19:07:03
@_author: Robert J. Hansen 
@_subject: Certified OpenPGP-encryption after release of Thunderbird 78 
You're missing the gotcha of "as of -Beta3, the new Thunderbird *cannot
even import a key*."
I'm not kidding.  It is so far from complete that Kai Englert, who leads
the TB78 OpenPGP effort, recently proposed postponing OpenPGP support in
TB until version 78.2, or about a three-month delay.
At present, as of -Beta3, TB78's OpenPGP support is badly broken.

@_date: 2020-05-29 19:26:02
@_author: Robert J. Hansen 
@_subject: Certified OpenPGP-encryption after release of Thunderbird 78 
It should be an easy learning curve for Enigmail users.  That isn't the
same as finding it acceptable, though.
Back in the mid-'90s PGP came out with a GUI for PGP 5, and it's
universally agreed at user interface was horrific.  (See "Why Johnny
Can't Encrypt" for a detailed teardown.)  The problem was that this
horrific user interface became the standard user interface, and most
OpenPGP key managers ever since have adopted it.  Those that haven't
adopted it, nobody uses, because their UI is so different than
everything else.
No.  There's some talk about supporting it, but as far as I know there's
no plan to do it.  It's still at the "you know, it'd be kind of nice
if..." stage, not the "we really should do this" stage.

@_date: 2020-05-29 19:51:17
@_author: Robert J. Hansen 
@_subject: Certified OpenPGP-encryption after release of Thunderbird 78 
Oh!  When you said "process", I read that as "workflow".  My apologies.
 Yes, it's all part of the main family of processes.  There's no
spawning off of a GnuPG instance and setting up a communications channel
to it.

@_date: 2020-05-30 18:05:38
@_author: Robert J. Hansen 
@_subject: Certified OpenPGP-encryption after release of Thunderbird 78 
I have yet to talk to anyone who's been able to import their keyring,
which is the absolute minimum use case.  When it fails it does so
silently.  If the minimum use case of "average users should be able to
import their keyrings" leads to RNP crashing, no keys being imported,
and no error message being generated, I have no problem calling key
importation broken.
According to Kai's post on one of the TB mailing lists, he wants the
version in 78 to be a technology preview, hidden from the user, and only
accessible to power users.  I don't consider that to be shipping it for 78.

@_date: 2020-11-30 04:16:56
@_author: Robert J. Hansen 
@_subject: Odd error 
This should not be happening, but is.  From a completely clean installation, importation of legitimate OpenPGP keys results in strange general failures.  The system is an x64 Fedora 33 box running GnuPG 2.2.24 on libgcrypt 1.8.6.
I'm happy to provide the keys.asc file to any GnuPG dev who needs it to look into this problem.
[rjh at localhost ~]$ gpgconf --kill gpg-agent
[rjh at localhost ~]$ rm -rf .gnupg
[rjh at localhost ~]$ gpg --import Downloads/keys.asc
gpg: directory '/home/rjh/.gnupg' created
gpg: keybox '/home/rjh/.gnupg/pubring.kbx' created
gpg: /home/rjh/.gnupg/trustdb.gpg: trustdb created
gpg: key 1DCBDC01B44427C7: public key "Robert J. Hansen " imported
gpg: kbx: error computing keygrip
gpg: error writing keyring '/home/rjh/.gnupg/pubring.kbx': General error
gpg: error reading 'Downloads/keys.asc': General error
gpg: no valid OpenPGP data found.
gpg: import from 'Downloads/keys.asc' failed: General error
gpg: Total number processed: 5
gpg:               imported: 5
gpg: no ultimately trusted keys found
Let's try again on a higher verbosity level.  (I have to say I saw nothing of use here.)
[rjh at localhost ~]$ gpgconf --kill gpg-agent
[rjh at localhost ~]$ rm -rf .gnupg
[rjh at localhost ~]$ gpg -vvv --import Downloads/keys.asc
gpg: using character set 'utf-8'
gpg: directory '/home/rjh/.gnupg' created
gpg: keybox '/home/rjh/.gnupg/pubring.kbx' created
gpg: armor: BEGIN PGP PUBLIC KEY BLOCK
# off=0 ctb=99 tag=6 hlen=3 plen=269
[snipping successfully imported public keys]
[leaving in debugging lines from other GnuPG components]
[some data anonymized, because it's not mine]
gpg: pub  rsa2048/XXXXXXXXXXXXXXXX 2010-10-18  XXXXXXXX
gpg: writing to '/home/rjh/.gnupg/pubring.kbx'
gpg: /home/rjh/.gnupg/trustdb.gpg: trustdb created
gpg: using pgp trust model
gpg: key XXXXXXXXXXXXXXXX: public key "XXXXXXXX" imported
gpg: no running gpg-agent - starting '/usr/bin/gpg-agent'
gpg: waiting for the agent to come up ... (5s)
gpg: connection to agent established
gpg: pub  rsa2048/XXXXXXXXXXXXXXXX 2012-05-24  XXXXXXXX
gpg: writing to '/home/rjh/.gnupg/pubring.kbx'
gpg: key XXXXXXXXXXXXXXXX: public key "XXXXXXXX" imported
gpg: pub  rsa4096/XXXXXXXXXXXXXXXX 2013-09-13  XXXXXXXX
gpg: writing to '/home/rjh/.gnupg/pubring.kbx'
gpg: key XXXXXXXXXXXXXXXX: public key "XXXXXXXX" imported
gpg: pub  rsa4096/XXXXXXXXXXXXXXXX 2016-10-04  XXXXXXXX
gpg: writing to '/home/rjh/.gnupg/pubring.kbx'
# off=10553 ctb=99 tag=6 hlen=3 plen=397
:public key packet:
gpg: key XXXXXXXXXXXXXXXX: public key "XXXXXXXX" imported
# off=10953 ctb=b4 tag=13 hlen=2 plen=35
:user ID packet: "Robert J. Hansen "
# off=10990 ctb=89 tag=2 hlen=3 plen=446
:signature packet: algo 1, keyid 1DCBDC01B44427C7
# off=11439 ctb=89 tag=2 hlen=3 plen=540
:signature packet: algo 1, keyid DB1187B9DD5F693B
# off=11982 ctb=b4 tag=13 hlen=2 plen=38
:user ID packet: "Robert J. Hansen "
# off=12022 ctb=89 tag=2 hlen=3 plen=449
:signature packet: algo 1, keyid 1DCBDC01B44427C7
# off=12474 ctb=89 tag=2 hlen=3 plen=540
:signature packet: algo 1, keyid DB1187B9DD5F693B
# off=13017 ctb=b4 tag=13 hlen=2 plen=41
:user ID packet: "Robert J. Hansen "
# off=13060 ctb=89 tag=2 hlen=3 plen=446
:signature packet: algo 1, keyid 1DCBDC01B44427C7
# off=13509 ctb=b9 tag=14 hlen=3 plen=397
:public sub key packet:
# off=13909 ctb=89 tag=2 hlen=3 plen=415
:signature packet: algo 1, keyid 1DCBDC01B44427C7
# off=14327 ctb=b8 tag=14 hlen=2 plen=51
:public sub key packet:
# off=14380 ctb=89 tag=2 hlen=3 plen=511
:signature packet: algo 1, keyid 1DCBDC01B44427C7
# off=14894 ctb=b8 tag=14 hlen=2 plen=56
:public sub key packet:
# off=14952 ctb=89 tag=2 hlen=3 plen=415
:signature packet: algo 1, keyid 1DCBDC01B44427C7
# off=15370 ctb=99 tag=6 hlen=3 plen=525
[resuming omission of other people's keys]
gpg: pub  rsa3072/1DCBDC01B44427C7 2015-07-16  Robert J. Hansen gpg: key 1DCBDC01B44427C7: 2 signatures not checked due to missing keys
gpg: writing to '/home/rjh/.gnupg/pubring.kbx'
gpg: key 1DCBDC01B44427C7: public key "Robert J. Hansen " imported
gpg: pub  rsa4096/XXXXXXXXXXXXXXXX 2017-03-18  XXXXXXXX
gpg: writing to '/home/rjh/.gnupg/pubring.kbx'
gpg: kbx: error computing keygrip
gpg: error writing keyring '/home/rjh/.gnupg/pubring.kbx': General error
gpg: error reading 'Downloads/keys.asc': General error
gpg: no valid OpenPGP data found.
gpg: import from 'Downloads/keys.asc' failed: General error
gpg: Total number processed: 5
gpg:               imported: 5
gpg: 0 keys processed (0 validity counts cleared)
gpg: no ultimately trusted keys found

@_date: 2020-11-30 09:25:26
@_author: Robert J. Hansen 
@_subject: Odd error 
It's a standard Fedora GnuPG, so although I'm sure a source RPM is available I'm not enough of an RPM surgeon to know how to modify the .rpmspec to apply the patch.
I'll send the keyring onto you privately.
* GnuPG 2.2.25 (40f75823d)
* Libgcrypt 1.8.7 ()
* GpgRT 1.37-unknown (0000000)
* Libassuan 2.5.3 (4de3154)
* KSBA 1.3.5 (?)
* GNUTLS 3.6.15

@_date: 2020-10-08 12:00:37
@_author: Robert J. Hansen 
@_subject: Five volunteers needed (EU .... Are you sure that this is really 
Here in the United States, it is generally quite difficult for consumers
to get -anything- except the bog-standard that their ISP offers.
Doesn't matter what it is: if it's not part of the bog-standard
consumer-grade package your only recourse is to upgrade to a
commercial-grade package.
There are some exceptions to this rule, but by and large it holds true.

@_date: 2020-10-10 05:42:17
@_author: Robert J. Hansen 
@_subject: Why is Blowfish's key size limited to 128 bits in RFC 4880? 
Age.  At the time Blowfish was adopted there were literally no 256-bit
ciphers in the RFC2440 suite.  Symmetric ciphers were all 128-bit
(except arguably for 3DES, where the size is wonky[*]).  The first
256-bit cipher to be added was Twofish in mid-2000 in PGP 7, followed
soon by AES in PGP 7.1.
[*] 3DES can credibly be claimed to have a 192-bit key, a 168-bit key, or a 112-bit key, depending on how the speaker defines "key".

@_date: 2020-10-14 03:20:56
@_author: Robert J. Hansen 
@_subject: Why is Blowfish's key size limited to 128 bits in RFC 4880? 
Then you really ought be using 3DES, which is the most heavily
scrutinized symmetric algorithm in OpenPGP.  AES is a close second.
Which situations are those?
In a word, 'no'.  In three, 'oh *hell* no'.
The best attack on 3DES, after more than 40 years of academic research,
requires ~10^17 bytes of RAM and ~10^34 encryptions.  That's 100
petabytes of RAM, which is silly enough already.  10^34 encryptions,
each of which requires a minimum of erasing ~10^3 bits of data during
its evolution through S- and P-boxes, and the laws of physics flat
*require* losing about 10**-22 joules per erasure... you're talking
about liberating 10**15 joules as heat.  That's about what a nuclear
bomb puts out.
And that's for 3DES, which is generally believed to be by far the
*worst* cipher in OpenPGP.
Why would anybody break ciphers the hard way with cryptanalysis, when
real-world systems are so easily exploitable and the human beings behind
them even moreso?

@_date: 2020-10-17 12:36:49
@_author: Robert J. Hansen 
@_subject: Why is Blowfish's key size limited to 128 bits in RFC 4880? 
It absolutely *has* survived scrutiny.  I don't know where you're getting your information.  3DES is being phased out because its 64-bit block size makes it dicey for modern bulk encryption, and because its spectacular overdesign makes it very slow.
That's it.  Nobody has come up with any kind of meaningful cryptanalytic attack against it.  It simply doesn't exist.
Very practical.  You could practically use 3DES on these files.  60MB is nothing: you're going to experience more slowdown writing to disk.
In that case, why not also work on defending against time travel, psychic phenomena, or aliens from Zarbnulax?
The moment you say "it doesn't matter what the science says," you open the door to some very reasonable questions about why you're defending against one not-rooted-in-science attack and not others.
No, that's not how cryptanalysis works, either.  Cryptanalysis works by reducing the amount of work to be done: only in rare cases will it totally erase the work factor.  A massively profound cryptanalytic attack on AES128 would reduce the work factor to, oh, call it 2**80; that result would be *seismic*.
But 2**80 ain't easy, either.  You still have to do an awful lot of hard work and pay a really huge utility bill.
Why do it this way?  Why not go after the data in a non-cryptanalytic way, where the work factor is so much less?

@_date: 2020-09-08 12:47:30
@_author: Robert J. Hansen 
@_subject: On Becky! Internet Mail's GnuPG Plugin 
As I have told several people, the moment your threat model is "I am of
interest to a major nation-state intelligence agency" your response
needs to be either "call my lawyer and sit down for a long talk with
them" or else "withdraw all my savings as cash and go on the run
refusing to use any technology more complicated than a frying pan".
There are no realistic in-betweens.
Bin Laden went for option  and was able to survive for almost ten
years while being of interest to every world intelligence agency.  It's
good advice, it seriously is.  But I'm not kidding about refusing to use
any technology more complicated than a frying pan.
A frying pan might be useful should one elect to go this route!

@_date: 2020-09-08 13:55:30
@_author: Robert J. Hansen 
@_subject: On Becky! Internet Mail's GnuPG Plugin 
I have already begged you once, Stefan, to stop hyping this disinformation.

@_date: 2020-09-19 07:42:06
@_author: Robert J. Hansen 
@_subject: Which keyserver 
I'm not sure that's true.
The keyserver poisoning attack was demonstrated first by EFF's Micah
Lee.  When he published his findings, he also published the Python
scripts necessary to execute the attack.
I don't know who the poisoner was.  However, if I were to do the
poisoning attack I certainly would've begun by downloading Micah's code
and adapting it to the task.  And for that reason I think it's entirely
reasonable to believe the keyserver poisoning attack was bootstrapped by
an EFF-funded research project which inappropriately released attack tools.
