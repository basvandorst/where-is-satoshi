
@_date: 2017-04-08 12:23:01
@_author: Mike Gerwitz 
@_subject: Smart card 
Not that I'd recommend anyone else test this, but my Nitrokey survived a
wash and the majority of a dry cycle unscathed.  I've never run into the
basement so quickly in my life when I realized what I had done.

@_date: 2017-04-08 12:26:18
@_author: Mike Gerwitz 
@_subject: Smart card 
I use a Nitrokey, which itself is a reader.  I keep it in the small
pocket of my pants (if it has it), and I'll even keep it on the side of
my ankle in my sock if I'm wearing longer socks for work (interesting
idea from a co-worker when it fell out of my pocket).
I find it to be very convenient, and it cannot be stolen without me
realizing, since it's stored in one of two locations that cannot be
accessed without being seen and felt.

@_date: 2017-04-09 14:01:02
@_author: Mike Gerwitz 
@_subject: Smart card 
(Don't get me wrong---I like James Mickens; I watched an MIT course he
partially taught, and I was rather fond of him.  But this is a dangerous
article, and hard to distinguish between satire and actual security
advice.  And there's both.)
This type of defeatism is just as absurd as putting your faith in snake
oil or failing to even contemplate a threat model before blindly
following others' advice.  In fact, the latter is precisely what this
is---not from the author's standpoint, but from the reader's.
Security is not binary (or ternary, in that article).  You're not just
dealing with "Mossad or not-Mossad".  You're dealing with a wide range
of adversaries from your grandmother who gets on your computer when
you're still logged into your dating website, to script kiddies who
discovered intro to Metasploit articles, to script kiddies at the CIA
and NSA, to actual targeted attacks/surveillance by a State, to the guy
who's going to break and then re-break your knee caps until you give him
what he wants.
If I know a threat exists, I'm going to evaluate my threat model and
decide whether or not it is worth my time to mitigate it; whether I can
hope to mitigate it; and whether attempting to do so is going to put me
at even more risk for some other threat.
I just gave a talk at LP2017 about "The Surreptitious Assault On
Privacy, Security, and Freedom".  The talk was focused on some threats
that might actually be applicable to the audience.  There weren't
discussions about drone targeting or kneecap breaking or NSA
interception of packages.  There wasn't discussion about tapping
underseas cables.  And yet, the sophistication of the threats in the
presentation were such that I didn't get to a fraction of what I wanted
to discuss.
Most people aren't going to have to worry about the CIA taking control
of their stupid 4G-enabled, always-connected vehicle to assassinate them
or abduct their children.  But the attacks and surveillance methods the
CIA and NSA use on these types of things---as revealed by Vault 7,
Shadow Brokers, Snowden, Klein, and others---can be discovered or
performed by other bad actors.  And they are.  So defeatist attitudes
toward State actors make you immediately vulnerable to less skilled,
less resourceful attackers.  Using HTTPS doesn't protect me against a
lot of things.  But it does protect me from many things.
Again, defeatist.
For your average user, yeah, they're screwed just by using technology in
the first place---if not by crackers, then by adversaries like the
companies they're feeding data to.  But _I_ could target someone with
memory forensics "malware", and I'm not a cracker!  If not through an
exploit for the slew of vulnerable systems users use, then through
physical compromise of their computer.  Maybe pay out an evil
maid.  I've never tried a cold boot attack, but maybe I'd have some luck
with that.  We're not talking about State-level knowledge here---we're
talking about using existing tools; we're talking about a privilege
escalation vulnerability; we're talking about data swapping to disk;
we're talking about Heartbleed, and Cloudbleed, and many other such
bugs; ...and so on!
Nor should anyone think they are.  But it's sure as hell a smaller
attack surface than the, uh, near-unlimited attack surface of an
Internet-connected computer (or mobile device!) that most people store
their private keys on.  I use a Smartcard because the attack surface is
otherwise enormous---I cannot audit whether my key has been
compromised.  I don't have the time or resources.  I like to believe my
key was reasonably secure.  But I generated a new one about a year ago,
got me a Smartcard, stored the master key offline, and access it using
an airgapped computer.  Does that prevent me from being pwned by a
committed adversary?  No, not even close.  But I can enumerate many such
attacks against my current setup.  And they're far fewer than the near
innumerable number against my previous situation.  If someone's setting
up a GPG key, am I going to suggest to them that they use a Smarcard?
_Of course_ I am!  I'd rather do that then spend the next few months
educating them on portions of a relevant threat model and do-this but no
don't-do-that but oh that means you can't use the Internet at all,
sorry!  And by the time I'm done explaining that, there's be another
catchily-named vulnerability out there peeking out from the stockpile of
CVEs that have made their way into pentesting frameworks with a
click-to-pwn usability level.
Do I think Mickens is going to stand there and tell Karen Sandler that
she shouldn't give a care about the security of her pacemaker because
someone can season her cup of noodles with uranium?  No, I don't.

@_date: 2017-04-09 22:32:23
@_author: Mike Gerwitz 
@_subject: Smart card 
The number of times I have seen this article to rationalize
black-and-white threat models and dismiss threats is concerning---its
grounding in truth is what makes it good satire, and it's not hard to
distill security "advice" from it.
I think this is being confounded by adjoining two conversations---that
smartcards provide additional security given a compromised system, and
the satirical quote your provided.  I was referring in this case to the
My point is that if you base your entire threat model and practices on
the fact that some attacker somewhere is going to succeed in a targeted
attack against you, then you may as well give up on security period.
And my point was further that memory forensics is a pretty poor baseline
for "screwed".  That's the default category for any user of a
surveillance operating system like Windows 10.  Is the decision there to
not attempt to address the problem at all?
I'm not sure if you're adding that to the discussion or saying that I
implied that; I certainly didn't.
This is the other conversation, which I didn't comment on; I should have
made that more clear.
You seem to be suggesting that key safety isn't even a concern if you're
compromised---that nothing else matters, and the distinction between a
compromise as you described with or without access to the key(s) is
This doesn't have to start with a compromise from Day 1.  If you are
using a compromised system for generating your GPG key, sure, a
smartcard isn't going to help you at all.  But note that you can also
generate the keys on the smart card itself rather than the host
system, which would circumvent a compromised PRNG.  Of course that's not
much of an option if you need a long-term identity, but for someone
looking to use GPG for other purposes, that's certainly an option.
Let's say you're not compromised Day 1, and you don't have a
smartcard.  Your key can be copied by malware at any point in time.  The
password can be brute-forced offline or can be gathered through some
other method at a later date.
Let's say Eve has access to system memory, and a keylogger, and can view
communications before they are even encrypted.  Fair enough, a smart
card won't help you if crypto is circumvented entirely.  That's the case
with or without it.  But GPG keys are seldom rotated.  If you do happen
to use it for encrypting sensitive communications, the compromise of
your encryption key at any point means the compromise of possibly years
(or a lifetime's worth) of data.  With a smartcard, a passive
eavesdropper can't do anything---Mallory would be forced to either steal
it from you, or issue commands to decrypt when it's connected to the
system, which would prompt for the PIN at least once, would be slow, and
would hopefully trigger an indicator on the smartcard.
Let's say I receive encrypted correspondence from someone.  If Mallory
has access to my communications/mailbox, he could grab the message,
decrypt it, and be done.  He could then write a reply, sign it as me,
and have a full-on conversation, without me knowing.  With a smartcard,
I'm still needed---he'll have to find a way to sneak in those crypo
operations on the card without me noticing.
The primary purpose of my key is signing.  If Mallory wanted me to sign
something unwittingly, and I used an external reader, he would have to
intercept a legitimate operation and replace it with his own.  But then
I wouldn't have the signature that I requested.  If I noticed (I
personally would, I don't know that everyone would; maybe a recipient),
Mallory would be at risk of being
My Nitrokey locks the user PIN after three invalid attempts and bricks
itself after three admin PIN attempts.  If my smartcard is stolen, brute
force isn't possible---they will have had to have gathered my PIN in
some other manner.  Since I use a Nitrokey, I'd be owned by a
keylogger.  But if you use an external card reader with a PIN pad, then
Mallory might have a harder time, especially if he is a remote attacker.
I use GPG as an SSH agent---I can use SSH on any system that will
recognize my card.  Otherwise, you'd generate a key per host, any of
which could be compromised at some point in the past or future.
For users that need their GPG key on multiple boxes, I consider a
smartcard to be essential.  Otherwise, the user is just furthering her
risk of compromise.
Key safety is still important.
But again, that's assuming that Eve/Mallory _exist_.  With my original
argument: they may not.  The average user is far more likely to get some
random malware and get added to a botnet than they are to be a specific
target, and in those cases especially, their key won't be grabbed with
all the other data on their disk.

@_date: 2017-04-09 22:52:59
@_author: Mike Gerwitz 
@_subject: Smart card 
Sure: the sensitivity of the data determines the threat model.  If I'm
just protecting the password to my bank account, then law enforcement
isn't part of my threat model, because they wouldn't need it to access
my account.
My advice isn't useful to those people (unless they find it cool),
you're right; but they aren't my audience, generally speaking.  With
that said, everyone can benefit from strong crypto to some degree to
protect their privacy.  Whether or not they care, and whether or not GPG
is the solution to any sort of problem they're having, is another story.
I agree.  I don't mean to give the impression that I convey that it is
required.  When introducing users to the concept of PGP, smartcards are
always mentioned as an extra step that might help with certain concerns
they have (e.g. sharing the key on multiple devices).  I don't invent
reasons, unless someone's asking from a crypto perspective and wants
that level of detail.  Sometimes smartcards don't come up at all.
With that said, my use of my smartcard sometimes initiates discussion.
And sometimes people use GPG simply because they want to be able to use
a smartcard for something like SSH.

@_date: 2017-04-10 12:59:27
@_author: Mike Gerwitz 
@_subject: Smart card 
Yes, exactly---if.
I'm not arguing against that.  It's the "if" part.  The article left no
space inbetween for a threat model between "organized criminals, don't
click on herbal Viagra ads" and "Mossad, magical amulets".  The original
conversation into which you pasted that quote wasn't talking about
Mossad (unless I missed something).

@_date: 2017-04-10 23:20:43
@_author: Mike Gerwitz 
@_subject: Smart card 
It's not that it's impossible to do.  But in most cases, because of all
of the software, hardware, and wetware used, the attack surface is
If an organization did all of its sensitive computation in a Faraday
cage in an underground bunker under constant surveillance, where any
operation on any sensitive data requires N people present through a
secret sharing scheme, are you going to be better off?  Sure.  But still
not immune to various types of espionage.  And there are limits to what
is practical.
But that's different than the security of an individual, which is what
we've been talking about.  Corporations can afford to build secure rooms;
hire ex-government security officials and other security/crypto experts;
build their own hardware; etc.
But the more people you involve, the more people you have to trust too.
I do not believe that being the target of Mossad or the NSA or GHCQ or
other intelligence agency means that a sufficiently well-funded and
well-researched corporation is doomed to total compromise.  I haven't
been given reason to believe that through all the leaks we've
seen.  These intelligence agencies have immense resources, but certain
practices and procedures introduce bottlenecks that increase the
cost/risk of an attack possibly to the point that it's not worth
carrying out.  That's also a driver behind a lot of the legislation/laws
we see under the guise of protection against terrorism and "going
dark"---if you can't beat 'em, make them let you in.

@_date: 2017-10-10 09:13:11
@_author: Mike Gerwitz 
@_subject: FAQ and GNU 
GnuPG is part of the GNU operating system.  Anywhere "Linux" is used to
describe the GNU/Linux operating system, "GNU/Linux" should be used.
Please see:

@_date: 2017-10-10 12:33:26
@_author: Mike Gerwitz 
@_subject: FAQ and GNU 
Of course it does.  GnuPG is _part of_ the GNU Project.  Not promoting
its own ideals is working contrary to its goals.
The link I provided is GNU policy.

@_date: 2017-10-10 12:43:26
@_author: Mike Gerwitz 
@_subject: FAQ and GNU 
I haven't looked over the FAQ personally; I was just providing GNU's
stance on the issue.
But thank you for outlining it.
Yes, that shouldn't be GNU/Linux.
If the intent is really to convey any distribution using the kernel
Linux, then it could say any "distros based on the kernel Linux", or
more weakly "Linux-based".
I don't think that's what it means.
"Linux system" is explicitly mentioned as something to avoid in the
maintainers document I referenced.
Same as above.
In any case, GNU packages have a bias toward GNU.  Emphasizing
"Linux-based" systems instead of GNU isn't much different than Apple
advertising BSD-based systems instead of Mac.

@_date: 2017-10-10 13:09:46
@_author: Mike Gerwitz 
@_subject: FAQ and GNU 
There may be a misunderstanding.
GnuPG is a package that is a part of the GNU operating system.  The list
of all such packages can be found here:
  GNU is usually used with the kernel Linux.  GNU doesn't require that
packages support any other kernel (e.g. Hurd).  But the operating system
is GNU.  GnuPG works on other operating systems, but GNU only requires
that it work best on GNU, or at least as well as other operating
The GPL is unrelated to this discussion.

@_date: 2019-05-03 22:24:54
@_author: Mike Gerwitz 
@_subject: Enforcing password complexity for private keys 
FWIW I use a 4096 bit RSA key on a Nitrokey Pro (a model that's a couple
years old) and the total time of PIN entry + signing averages
~5s.  While it is certainly a noticeable delay, I don't find it
burdensome for operations like signing mail and commits, and I'll sign
sometimes dozens of times per day, with forced pinentry.
I'm not suggesting that RSA be used instead of ECC; my token just
doesn't support it.  But newer Nitrokeys do.  I'll likely switch

@_date: 2020-01-07 22:18:47
@_author: Mike Gerwitz 
@_subject: What are some threats against which OpenPGP smartcards are useful? 
PINs can also be changed confidently.
The passphrase of the _copy_ of a key on disk can be changed, but you
can't necessarily be confident that it's the only copy.  It could have
been copied with or without your knowledge, by you or an adversary.
If you enter your passphrase somewhere and realize after the fact that
someone may have been standing over your shoulder, or there's a security
camera in the distance, an audio recording of your keypresses, or
_anything_ that reduces the keyspace of your passphrase, then an
attacker can brute force the rest offline forever using an old copy of
your key, and there's nothing you can do about it.

@_date: 2020-01-07 22:54:59
@_author: Mike Gerwitz 
@_subject: What are some threats against which OpenPGP smartcards are useful? 
I don't have time to read what I already wrote in that thread, so I'm
sorry if I repeated myself here.
That's too coarse of a conclusion.
Let's say I decided to plug my Nitrokey into some adversary's computer,
willingly, and enter my PIN.  The attacker can make use of the card
while it's plugged in.  But operations using the card are very slow, and
I'll notice the light going on more than once.  I'll unplug it.  Attack
mitigated.  The only thing lost is whatever the attacker managed to do
within that time period---decrypt files, sign documents, SSH into remote
machines, etc.  (Don't get me wrong: all those are really bad.)
Then I go to a safe location and change my PIN.
Or maybe I'm punched out and my smartcard stolen.  I go home, revoke my
subkeys, and have to pay for a new smartcard.  And let some people know
that I was beat up and you shouldn't trust anything that was signed in
that time period.
But consider the alternative: if you weren't using a smartcard, and your
key were on disk, all of that still would have happened.  But in
addition, your private key has been compromised.  You now have to revoke
your entire key.  If you've built a web of trust, you have to start
Smart cards _are_ useful even if your system is compromised, because it
still protects your key from offline use.  It gives me peace of mind
when it's capped and stored in a safe location.
If you just leave your smart card plugged into your computer 24/7 and
leave your computer on while you're sleeping, that's a problem.  It
won't protect you from bad practices.
You can get some of those benefits by e.g. using a laptop as a thin
client and forwarding the GPG agent to a remote box over SSH, and store
the private key on the laptop.  The risk is still higher than a
smartcard though.
It all depends on your threat model.
I use my Nitrokey for SSH as well.  Prior to having it, I would store an
SSH key to personal accounts on e.g. my work computer.  I cannot fully
trust that system.  But today I don't need to do that: I insert the
Nitrokey only when prompted by GPG, immediately remove it, and change my
PIN when I get home.  While there's still the risk that the card may be
used for other things by a malicious process, it's pretty well
mitigated.  I know how long the light on the smartcard should be on for
and watch it the entire time.  I never allow the card to be out of my
view when connected to a system.
Of course, there's also the risk that someone has physically tampered
with the smartcard to suppress the LED under certain
circumstances.  This isn't foolproof.  But it's better than SSH keys on
my work system.
