
@_date: 2008-03-19 08:45:13
@_author: khurram.humayun 
@_subject: urgent gpg help needed with regards to file size. 
Hey guys,
   the problem i am having is that i have been using a script for the
longest time to encrypt via this vendors public key. however after they did
some maintenance the last 2 week, they are not able to decrypt most of the
files i am sending them. i have a large file 10232593860 or 9.5gigs. i then split this file into
chunks of 6000000
-rw-rw-r--   1 khumayun dev      2460000000 Mar 11 16:41 fds_20080226_txt_aa
-rw-rw-r--   1 khumayun dev      2460000000 Mar 11 16:41 fds_20080226_txt_ab
-rw-rw-r--   1 khumayun dev      2460000000 Mar 11 17:10 fds_20080226_txt_ac
-rw-rw-r--   1 khumayun dev      2460000000 Mar 11 17:40 fds_20080226_txt_ad
-rw-rw-r--   1 khumayun dev      392593860 Mar 11 17:42 fds_20080226_txt_ae
now if i use the my script which has always been working it generates the
pgp files jsut fine. but, the vendor reports a rc=32 error. meaning they now
cannot decrypt it. ofcouse when i ftp the files its in bin and everything
matches. but the only thing i noticed is that when i run each file through a
script vs when i run it manually the pgp files created file sizes are
different. i am not sure why that is? any help regarding that would be
when i use the script one of the pgp files generated is  cksum fds_20080226_txt_aa.pgp 2992943044      500154558       fds_20080226_txt_aa.pgp
when i do the same thing on the command line
 cksum fds_20080226_txt_aa.pgp 780762217       500154561       fds_20080226_txt_aa.pgp
i also know i am using the correct public key because they are in each case
are able to decrypt the last file (the smallest size. of course they used to
be able to decrypt all the other large size files as well till now)
in addition when i run my script 2 times each time it gives different
results except for the last file generated in each case. run 1 using script
-rw-rw-r--   1 khumayun dev      500154558 Mar 18 21:32
-rw-rw-r--   1 khumayun dev      500156606 Mar 18 21:42
-rw-rw-r--   1 khumayun dev      499769818 Mar 18 21:52
-rw-rw-r--   1 khumayun dev      500190233 Mar 18 22:02
-rw-rw-r--   1 khumayun dev      79674234 Mar 18 22:04
run 2 using script
-rw-rw-r--   1 khumayun dev      500154562 Mar 11 18:07
-rw-rw-r--   1 khumayun dev      500156608 Mar 11 18:21
-rw-rw-r--   1 khumayun dev      499769824 Mar 11 18:36
-rw-rw-r--   1 khumayun dev      500190236 Mar 11 18:51
-rw-rw-r--   1 khumayun dev      79674234 Mar 11 18:56
notice how the last file is the same in each case and is successfully
decrypted. but the other 4 all fail according to the client. your help regarding this matter would be greatly appreciate.
thanks guys

@_date: 2008-03-20 07:35:35
@_author: khurram.humayun 
@_subject: urgent gpg help needed with regards to file size. 
ok here is the script i am using... to encrypt. it just simply splits my
large file into 6Million records each and then ecrypts it using the clients
public key. its a really small script.
cd /load01/infutor/$1/output/
split -l 6000000 fds_$1_txt fds_$1_txt_
for file in $(ls fds_$1_txt_??); do
 gpg --always-trust -o $file.pgp -e -r FDSolutions $file
done

@_date: 2008-03-20 11:34:36
@_author: khurram.humayun 
@_subject: urgent gpg help needed with regards to file size. 
1. i always use binary format when transfering via ftp. but in this case i
can safely say that is not what is causing the issue.
2. now i nkow that the encryption process inherently compresses the data. i
am just wierded out but the fact that the same public key and file always
compress to some different file size each time? i am using the solaris 5.8 and gpg 1.4.7. i am not sure if this os would
have those issues with truncating the data? On Behalf Of khurram.humayun
case are able to decrypt the last file (the smallest size. of course they
used to be >able to decrypt all the other large size files as well till now)
results except for the last file generated in each case.
