
@_date: 2011-08-14 13:41:24
@_author: Hubert Kario 
@_subject: Extract numbers from a key 
If your "prime" is composite, it is at most half as long as a real prime would So, instead of a ~1024 bit prime you have a ~512 bit prime, which are tryvial to crack.
Mind that I learned RSA 5 years ago during 2 hours of a 20 hours course on cryptography, so it may be even easier to crack encryption using composite

@_date: 2011-08-14 16:39:10
@_author: Hubert Kario 
@_subject: Extract numbers from a key 
looking through full 512bit space will take 8192 less time than checking all numbers between 2^525 and 2^526.
as we're talking about 512 and 1024, it will be "few" orders of magnitude Checking "just in case" for such situation in the grand scheme of things will make your cracking algorihm only marginally slower.
Ah, the EMACS Ctrl+Alt+Meta+Top+P 1024 command! ;)
algorithms than finding primes and then checking them.
Prime numbers are quite common, testing for primality is expensive, prime number distribution is non deterministic.
I keep forgeting that people still use 1024bit RSA keys ;)
but, yes, I meant 1024 bit and 512 bit keys, which consist of two ~512 bit and ~256 bit primes

@_date: 2011-12-20 16:49:09
@_author: Hubert Kario 
@_subject: keyserver spam 
At least we're getting there. Don't know about the EU Data Protection directive, but the Polish one says specifically, that login reuse is Yeah, the kind of "protections" banks use is funny. But then, what can they do when people forget their passwords 5 minutes after they set them or use the same password on facebook and their bank...
If only the "horse battery staple correct" method was taught as *the* method for creating and remembering passwords...

@_date: 2011-12-20 19:11:42
@_author: Hubert Kario 
@_subject: keyserver spam 
I didn't mean the login to a web service. This is, in all cases I saw, always two-factor. I meant the phone service or all the credit card transactions.

@_date: 2011-07-20 18:57:09
@_author: Hubert Kario 
@_subject: gpgsm and OCSP problems 
Hi all!
I'm not sure if I configure the gnupg package correctly, but when I enable OCSP I'm unable to validate certificates (gpgsm --with-validation -k)
When I add "enable-ocsp" to gpgsm.conf and "allow-ocsp" to dirmngr.conf I get
either "Unknown system error" or an "End of file error".
Even when the only other configuration variable is "honor-http-proxy" in I tried adding CA certificates to ".gnugp/trusted-certs/" and intermediate certificates together with OCSP responder server to ".gnupg/extra-certs/".
I verified that certificates are loaded by dirmngr, contain OCSP server addresses and that the servers are queried.
I'm using gpgsm (GnuPG) 2.0.17
libgcrypt 1.4.6
libksba 1.0.8
Log follows:
gpgsm[23389]: chan_9 -> [ 44 20 30 82 06 34 30 82 04 1c a0 03 02 01 02 02 ...
    (982 byte(s) skipped) ]
gpgsm[23389]: chan_9 -> [ 44 20 05 07 02 01 16 22 68 74 74 70 3a 2f 2f 77 ...
    (630 byte(s) skipped) ]
gpgsm[23389]: chan_9 -> END
dirmngr[23390]: chan_6 <- [ 44 20 30 82 06 34 30 82 04 1c a0 03 02 01 02 02
    ...(982 byte(s) skipped) ]
dirmngr[23390]: chan_6 <- [ 44 20 05 07 02 01 16 22 68 74 74 70 3a 2f 2f 77
    ...(630 byte(s) skipped) ]
dirmngr[23390]: chan_6 <- END
dirmngr[23390.0]: using OCSP responder
    `
dirmngr[23390.0]: OCSP responder at
    ` status: success
dirmngr[23390]: chan_6 -> S ONLY_VALID_IF_CERT_VALID
     D9DF4E2507CB1A4E76DF761CB5505625E5E23B67
dirmngr[23390.0]: certificate status is: good  (this=20110720T120126      next=20110721T123920)
gpgsm[23389]: chan_9 <- S ONLY_VALID_IF_CERT_VALID
     D9DF4E2507CB1A4E76DF761CB5505625E5E23B67
dirmngr[23390]: chan_6 -> OK
gpgsm[23389]: chan_9 <- OK
gpgsm[23389]: unable to find the certificate used by the dirmngr: Unknown
     system error

@_date: 2011-07-24 23:37:07
@_author: Hubert Kario 
@_subject: How secure are smartcards? 
It probably depends on the card's chipset. On the other hand, to connect to chipset memory bus to read it you'd need diamond saws, very good microscopes, lots of cards for trying out the methodology and lots of time to do it. The hardware alone is in the realm of tens of thousand of dollars. Not to mention that you have only one try at It's at the point that any real attacker would perform rubber hose cryptanalysis. Even before trying to break the card.

@_date: 2011-07-26 14:41:26
@_author: Hubert Kario 
@_subject: How secure are smartcards? 
The key is also useful for decrypting past communication...

@_date: 2011-11-19 10:50:33
@_author: Hubert Kario 
@_subject: Which ExpressCard/54? 
The gemalto reader is actually a USB card reader, so any experience with USB readers should also apply.

@_date: 2011-10-19 23:06:44
@_author: Hubert Kario 
@_subject: STEED - Usable end-to-end encryption 
since when key servers are hard to use? the short PGP fingerprints can easily be told on the phone (so you have a voice verification of the key if you know the person) and the full can be verified just as easily.
The problem is that people don't feel the need for authentication and privacy in e-mail. They feel that e-mail is secure (after all I use encryption to my e-mail server).

@_date: 2011-10-22 12:36:02
@_author: Hubert Kario 
@_subject: Win7: Kleopatra does not open 
Kleopatra is part of KDE, so you may have more luck with asking on the KDE

@_date: 2012-04-25 11:52:10
@_author: Hubert Kario 
@_subject: [off topic] 
It's not a real solution, but Works For Me?: fdm.sf.net

@_date: 2012-08-02 12:34:00
@_author: Hubert Kario 
@_subject: learning curve like Monte Cervino 
Is it really so hard to demand from users to 1. understand that private key is sensitive, so is password protecting it
2. that you need to validate certificates/public keys from other parties
3. the only hardware that does crypo you can trust is your own hardware
You can be a secure user of GPG (or any other crypto suite) without understanding block chaining modes or why ECC is better than RSA.
As a hammer user you must learn not to use it to drive screws in to wood, even if it appears to work. You *need* to have basic understaing of tools you use.

@_date: 2012-08-13 15:48:35
@_author: Hubert Kario 
@_subject: Elliptic Curve Cryptography 
Please, don't top post.
Yes, you could, but virtually nobody would be able to validate your ECC signature as support in clients is non-existing. The only widely used one is newest Outlook on Vista and 7, but no public CA is giving out ECC certificates so they won't be verifable anyway.

@_date: 2012-08-28 14:31:28
@_author: Hubert Kario 
@_subject: what is killing PKI? 
The fact that you've just showed up on The list makes this e-mail and pseudonym disposable, not the fact you're using a pseudonym or gmail.
Besides, gmail is very much disposable. It's not like you have to provide your name, surname and ID document scan to get a gmail account...

@_date: 2012-08-28 16:01:05
@_author: Hubert Kario 
@_subject: what is killing PKI? 
Yes, but if the content is controversive and with debatable argumentation then only your credentials remain -- the recognition of your name. Which you have none at the moment.
Don't take it personally though. We've got plenty of tinfoil hatted individuals, shills or plain misinformers on this list in the past. *Because* it's a cryptography list. Whatever your ID looks like a real name or not has nothing to do for it.
Over and out.

@_date: 2012-12-04 13:19:11
@_author: Hubert Kario 
@_subject: Seperate RSA subkeys for decryption and signing or one for both? 
Keys can become "used up" so it entirely depends on how often you use it.
What I mean by that, is that any signing operation leaks some information about the key used for signing (generally far less than few tens of a bit).
If you have signed tens of thousands of documents with it, an attacker can recover substantial portion of the key and speed up the key recovery.

@_date: 2012-12-04 14:48:53
@_author: Hubert Kario 
@_subject: Seperate RSA subkeys for decryption and signing or one for both? 
Leaking is caused by signing, if your using the same key for signing and encryption, then you can use the signatures to speed up the attack on If you're encrypting with one key and signing with other then the encryption key doesn't need to be changed, as the encryption is done with public part anyway -- you don't leak any information that's not already avaiable to the Signature keys should be changed regularly, every few hundred thousand signatures or so.
In typical business deployments you don't have users that send over three hundred signed e-mails a day, every day (including holidays), and the certificates are valid only for a year. So you don't go over the "few hundred thousand signatures" limit. It is something you should keep in mind when you're using GPG and send lot of e-mails, though -- it is easy to use the same key for many years...

@_date: 2012-12-04 18:20:41
@_author: Hubert Kario 
@_subject: Seperate RSA subkeys for decryption and signing or one for both? 
I don't have one at hand and can't find one through quick googling. I'm not sure where I've got this info from, it may have been in Applied Cryptography.
Basically anything I have to back this is the general recommendation for TSA used in SignServer:
but unfortunately they don't provide any rationale for this either.
Logically though, if you have a known function that takes two parameters, A and B. You know B, function's output and size of A, then provided enough pairs of B and output you theoretically can say something about A (as A is constant). Of course, this works only because RSA is reversible and you know A' -- the public part of key.
The problem is defining "enough pairs", probably the 100000 I mentioned is quite conservative. On one hand, such a limit is hardly a problem for anybody but automatic systems (which can be easily configured to rotate keys), on the other hand, this attack was described as purely theoretical AFAICR.
How do you propose an attacker could force me to sign data I already In both cases (encryption, signature) I don't process the data itself but either its hash or random data used as key for symmetric cipher. I may be wrong here, but I'm quite sure such situation is simply impossible to happen with GPG or other standard protocols (S/MIME, PKCS)
See CodesInChaos comment

@_date: 2012-01-23 17:34:46
@_author: Hubert Kario 
@_subject: Creating a key bearing no user ID 
And there's a very good reson why you shouldn't be a fan of such comparisions:
Unlike physical security, properly implemented cryptography is unbreakable at this time.
All key types in wide use are completely broken: tumbler locks, Gerdas, etc. they can be made useless with only a little bit of know-how and few simple The only known working attacks on cryptography use brute force: similar to going through the wall, when the doors with a lock are too big of an

@_date: 2012-01-23 18:52:20
@_author: Hubert Kario 
@_subject: Creating a key bearing no user ID 
I didn't claim that any crypto is properly implemented.
I did claim it is far easier to find unbreakable crypto than it is to create unbreakable physical security. If TLAs are involved, then still the first is only questionable while the second is simply imposible.
Also, your example is flawed: any security scheme can be only as good as the

@_date: 2012-07-27 14:44:59
@_author: Hubert Kario 
@_subject: [OT] Multi-user hierarchical password management via pki 
I know about no such FLOSS system.
passpack.com is good at sharing passwords, but it is very rudimentary in comparision to your requironments.
I know that Hitachi makes "Identity Manger" that claims similar functionality to what you want, but I've not seen it, let alone use.

@_date: 2012-07-27 14:50:40
@_author: Hubert Kario 
@_subject: [OT] Multi-user hierarchical password management via pki 
If you have PKI it's easy.
All people that have access to an entry have this entry symmetric key encrypted using their public key.
To change the symmetric key, you decrypt, select new key, encrypt key with public keys of all people that had access to the entry in the first place. It is no different than changing the data inside the entry...
It requires usage of cryptographic primitives, not simple wrapers aroung gpg but it's completely doable.

@_date: 2012-06-06 16:33:53
@_author: Hubert Kario 
@_subject: can someone verify the gnupg Fingerprint for pubkey? 
In other words, as long as the fingerprint matches the certificate, it doesn't matter where you get the certificate from. But this only holds true if you trust the validity of fingerprint.
Regards, Hubert Kario

@_date: 2012-05-04 00:27:10
@_author: Hubert Kario 
@_subject: SSH Agent keys >4096 bit? 
It all depends on who you're talking to. French[1] suggest 4k for AES128.
But if you've got data that needs to be protected for 30-40 years, using AES256 is basically a no-brainer. Using just 4k RSA with that is not a smart decision, and that's agreed by basically anybody (NIST, ECRYPT II). Especially when the cost of establishing the link with 8k RSA is insignificant for any session over 5min in length (as is common in SSH).
Besides that, Schneier and Ferguson[2] say that basically any RSA based crypto system should support 8k keys. Switching to ECC is not easy, you need to change your whole infrastructure, protocols, management systems, etc. to allow this. Generating extemely large keys is very easy in comparision.
Using large keys would be stupid only if you need low latency/high IOPS system that can't use long lasting secure channels: web servers. But that's not our use case.
Hubert Kario
[1]: [2]: Practical Cryptography, Chapter: RSA Defined, section "The size of n",

@_date: 2012-05-04 12:07:25
@_author: Hubert Kario 
@_subject: SSH Agent keys >4096 bit? 
OK, so the use of 8k RSA keys won't work with low power embedded devices.
It still doesn't change the overall picture:
1. migrating to ECC is hard and complicated
2. using 8k RSA is easy
Quote from the book:
"The absolute minimum size for n is 2048 bits or so if you want to protect your data for 20 years. This minimum slowly increases as compiters get faster. If you can afford it in your application, let n be 4096 bit long or as close to this size as you can get it. Furthermore, make sure that your software supports values of n up to 8192 bits long."
That was written in 2003, nearly 10 years ago. They suggested using current day minimums when GPGPU didn't even exist and FPGAs with large memories were just surfacing.
possibly, still I'd guess that most of them are active, online attacks
but now we're in the hypothetical realm of vague possibility, such discussion is useless and suggest more that we "just have to throw away cryto as it's useless anyway" than anything else. Which, frankly, is bollocks.
What has online/offline net connection anything to do with that? Storing acquired information for 20 years is nothing extraordinary as far as intelligence agencies and highly motivated individuals are concerned.
Hell, I've got files on my hard drive that are around 15 years old.
Computing in 20 years may be very different than it is today.
Current practice is for data that hardly never has to deal with secrets that have to be kept for 40 years (like I noted before). As regularly the most valuable information being passed over secure links are passwords and http cookies. Which basically never have validity of over 10 years and 1 year Thing is, that is not the only use-case of crypto systems.

@_date: 2012-05-05 15:49:56
@_author: Hubert Kario 
@_subject: SSH Agent keys >4096 bit? 
As far as I know, OpenSSH uses DH parameters of the same size as the RSA keys: for 8k DH you need 8k RSA or (which is unmaintainable) manually force use of 8k DH.

@_date: 2012-05-05 16:13:08
@_author: Hubert Kario 
@_subject: SSH Agent keys >4096 bit? 
Reading about cryptography history I noticed one thing, when NSA said "don't do something" it meant that this thing did break the crypto entirely or allowed for far easier attacks.
Considering that they tell us "don't use RSA" (in Crypto suite B), would suggest that they have an attack on RSA that considerably limits its security.
So whatever 4k RSA really does have a large margin of security is We've already established that telling everybody to use 8k or greater keys is infeasible because of computational problems (in phones and web servers, let alone smartchips). The only solution for that problem is to tell everybody to use ECC (which has lower computational requirements). This does not mean that long RSA keys are useless for all use cases. SSH certainly isn't one of them.

@_date: 2012-05-06 01:42:13
@_author: Hubert Kario 
@_subject: SSH Agent keys >4096 bit? 
The secret being exchanged is, of course, the random session key. Its size is related to size of subgroup in DH. But it's the size of prime used that sets the security level, which just happens to share security evaluation with RSA as far as number of bits is concerned (IOW: n-bit DH is considered to be as hard to attack as n-bit RSA).
DH without authentication is useless (trivial to MITM). You need to authenticate the DH params you recieve from the other party before you do anything with them.

@_date: 2012-05-22 19:18:12
@_author: Hubert Kario 
@_subject: Some people say longer keys are silly. I think they should be 
Since when the security of encryption is dependant on the carrier/communication channel?
Did I miss some memo?

@_date: 2012-05-22 19:23:28
@_author: Hubert Kario 
@_subject: Some people say longer keys are silly. I think they should be 
"everything that could be invented has been invented"
"640k ought to be enough for anybody"
Do we really have to repeat the history?

@_date: 2012-05-23 15:51:47
@_author: Hubert Kario 
@_subject: There may be more to security than password length, 
How putting passwords to public WiFi on a wall undermines security?
If you depend on PSK WiFi for security then you've already failed...

@_date: 2012-05-25 15:10:37
@_author: Hubert Kario 
@_subject: PGP interoperability 
Considering that Suite B uses ECC only for asymetric crypto, I'd say you're probably right.
But that's just speculation, we will know in 30 - 40 years... :)

@_date: 2012-05-29 18:06:29
@_author: Hubert Kario 
@_subject: getting an encrypted file to show what public key was used 
No, thank you. Getting people to use any form of crypto is hard enough. We don't need to show them that it doesn't fix all problems...

@_date: 2012-05-31 02:33:33
@_author: Hubert Kario 
@_subject: Some people say longer keys are silly. I think they should be 
Ahh, the Memoirs Found in a Bathtub! Well written book, quite captivating.

@_date: 2012-10-04 22:09:27
@_author: Hubert Kario 
@_subject: collision vs. preimage attacks: policy for signing data created 
won't the answer to that depend on the hash in question?
The hash output depends on internal state of the hash function.
If the output depends on all bits of internal state then yes, appending new data should give the same output.
If the output depends only on some bits of internal state (we have 512 bits of internal state and the output is only 256bit) then appending new data may or may not give the same output. If the collision was found randomly I'd say the latter has more chance of happening.
Or am I missing something?

@_date: 2012-10-05 10:28:42
@_author: Hubert Kario 
@_subject: collision vs. preimage attacks: policy for signing data created 
the only collisions I saw were for MD5 and SHA-0
I don't think there are any collisions for SHA-1 published

@_date: 2012-10-06 17:52:46
@_author: Hubert Kario 
@_subject: Is it possible to construct a GPG Certificate from an existing 
There is some support for PGP in Bouncy Castle, so if is possible you should look at their API.

@_date: 2012-10-30 10:45:12
@_author: Hubert Kario 
@_subject: new release of GPA 
Just shut it and stop making a fool out of yourself.

@_date: 2012-09-03 15:39:00
@_author: Hubert Kario 
@_subject: gpg clear signed message on website 
do a binary diff (in linux: diff <(hexdump -C original.txt) <(hexdump -C copy-from-website.txt)
I'd guess have a problem with line endings

@_date: 2012-09-25 17:24:43
@_author: Hubert Kario 
@_subject: use of multiple keys 
I'd guess so. My experience is restricted to S/MIME part of GPG used through kmail, but when a person has two valid certificates I'm presented with a dialog asking me which cert to use for encryption.
Small note though: I can save my choice and I won't be asked again about this e-mail. I'd say that other MUAs have similar abilities.
So, it's not foolproof, but should be usable as long as the user knows what he's doing.

@_date: 2013-02-04 12:47:59
@_author: Hubert Kario 
@_subject: air gap private key? 
You need to airgap only your main key, the key used for signing can be stored on your Internet-connected machine.
if it's compromised, you can just revoke it and issue another key for signing This way all the traffic from the offline machine can be one-way

@_date: 2013-02-06 19:11:31
@_author: Hubert Kario 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
Don't extended (-T, -X, -A form) PAdES signatures add new hash values?! I'm quite sure not only they do, but that it's mandatory. So, new hashes can be used when ones used in file are beginning to weaken (e.g. SHA1 now).
I'd suggest to make a habit of not trusting PDF files with currently invalid timestamps... Or files without cryptographic timestamps with currently invalid

@_date: 2013-02-07 15:26:56
@_author: Hubert Kario 
@_subject: More secure than smartcard or cryptostick against remote attacks? 
In a world where software and hardware usually *has* bugs it's more likely that the dongle stopped working because of bugs, not because I'm under attack.
Especially if we're talking about the "usual use case", I doubt even bigger companies that use GPG review all the patches and test them individially, let alone individuals.
The usual response in this kind of situation is "let me do my damn work already" not "hmm, interesting, let's diagnose the issue, other projects be damned". Honestly, I'd probably fall victim to such an attack, and IMNSHO I'm a bit more knowledgable about crypto and security that regular users of GPG. I'm afraid that this kind of attack would be only unsuccessful against GPG developers or developers close to the GPG project (basically only the people that would have the means, knowledge and time to bisect the issue).

@_date: 2013-01-04 00:33:53
@_author: Hubert Kario 
@_subject: Is a document signed with hellosign legally binding? 
Hi Morten,
As always on the Internet, IANAL. Even if I were, this wouldn't be a legal advice, not legally binding, yada yada. What's more, I have no knowledge how exactly their system works so below is just my opinion and bits of knowlege about how digital signatures work in EU.
Now, back to the issue in question.
In one sentence: this looks very fishy to me.
First: basically only Qualified Electronic Signatures are unquestionably legally binding.
Second: Qualified Electronic Signature can only be created using a Secure Signature Creation Device (a.k.a. cryptographic token).
Third: to get a Qualified Certificate you need to personally visit (this may be more relaxed in some countries) one of certification authorities and present some kind of state issued ID
Considering that the biggest problem (as far as proving its origin, creation date, etc.) with electronic data is that it is very easy to copy, the whole goal of digital signatures was directed to make it impossible to copy a signature (in a way for it to still be valid) without copying verbatim the file/data that was signed. They are doing exact opposite. The only thing agains that is the audit trial. If it doesn't use third party provided time stamps in one way or another I'd bluntly call it useless.
They perform no detailed verification of the person's identity (I can submit scan of Steve Jobs signature and his photo, doesn't make me Steve Jobs).
As such, I'd say it's very unlikely for the scheme described to be regarded as trustworthy (and admissible before court without question), let alone usable for Qualified Electronic Signing.
The only stuff they can reasonably prove, is that a document was created before such and such time and uploaded at such and such time to their service. gmail can do just as much. I'd say if the other person signing a contract is also using gmail it's just as secure and trustworthy.
But maybe it's just my bias against crypto that doesn't use DSA/RSA/ECC...

@_date: 2013-03-25 23:14:40
@_author: Hubert Kario 
@_subject: IDEA License 
that's usually a sign that the package from testing, or in this case, wheezy, will work fine.
