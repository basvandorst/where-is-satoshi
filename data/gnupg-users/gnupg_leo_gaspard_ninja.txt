
@_date: 2018-01-16 09:48:20
@_author: Leo Gaspard 
@_subject: a step in the right direction 
>> should not be viewed
as "discussing a [...] nightmare scenario",
I think this may be the reason why others than you are much more
optimistic than you about all this: I don't think we are considering
this scenario, only the much more restricted case of ?I want to remove
information associated with my private key?. In which case there is no
need of trusted introducers who would be allowed to moderate data, or
anything like this: the owner of the key could just sign the deletion
token with the said key.
Handling network-wide censorship of information published is a much
harder scenario, as the network was designed to be censorship-resistent.
And it looks like a nice property we would want to keep at network-level
in my opinion, though in order to accomodate local jurisdictions
keyserver operators could maybe want not to store eg. photo IDs or the
like -- just like if I understand correctly the case of someone sueing
to get his key removed from keyservers lead to the addition of an option
for keyserver operators to refuse syncing certain keys.
That said, I did read your ?To implement this would require a completely
new keyserver implementation, [?]? ; this message was just to maybe cast
some light on why some people look much more optimistic about this than
you are.

@_date: 2018-01-16 18:19:56
@_author: Leo Gaspard 
@_subject: DRM? 
Well, if such requests were honored, this would fix the OP's answer (ie.
?how do I hide the fact I mistakenly associated two unrelated UIDs on my
key?, if I understood correctly), as well as requests pertaining to the
EU's ?right to be forgotten? (modulo people who would have lost their
private key and still claim this right, but I guess the extraordinary
measures taken for the last time it was invoked would still be possible).
So that's at least a good part of the current problem solved, I think --
though obviously nothing close to the nightmare scenario or people
wanting to DRM their keys.
Also, there are flaws with this approach (like after a private key
compromise, it would allow to prevent dissemination of the revocation
certificate) [1], but fixes like allowing the statement to be ?on
2018-04-01, please expose only the master key and its revocation
certificate(s) to clients? would likely handle this particular issue.
All I'm saying is that a system like this one is not a silver bullet
solution, but may handle a few of the current complaints against the SKS
[1] It looks like Kristian has written more about it during my typing
this mail if I can guess from Peter's answer, though Kristian's mail
didn't land in my mailbox yet.

@_date: 2018-01-16 19:17:58
@_author: Leo Gaspard 
@_subject: DRM? 
Hmm, I was thinking only about de-listing information someone
inadvertently made public, not about having the keyservers become CAs
(which I don't think should happen, even though from a UI perspective
it's easier when things are centralized). I must say I basically took
only the ?please delist me? signature packet into account in my answer,
not the ?please list me?, as I don't think it would bring large
That said, thanks for the link! Just curious, I never saw information
about this in enigmail, do you know whether it has been implemented yet?

@_date: 2018-01-16 23:26:57
@_author: Leo Gaspard 
@_subject: key distribution/verification/update mechanisms other than 
I guess one argument could be ?when lazy people use the keyserver
network, they likely get not-too-bad data?.
I seem to remember that when a keyserver returned multiple keys to
GnuPG, GnuPG imported both, even when searching for a fingerprint and
the fingerprint didn't match, at some point in the last few years? If
even GnuPG can fail at properly sanitizing the data received by
keyservers (and I hope I'm not mistaken in this memory), I guess having
such keyservers only serve curated data when used in their ?nominal? use
could help a bit.
It could also help limit the impact of the nightmare scenario RJH has
described, by making sure all the data is ?cryptographically valid and
matching?, thus making it harder to just propagate arbitrary data down
the network. Then I don't have the structure of an OpenPGP key in mind,
so maybe this would not work due to fields in the key that could be set
to arbitrary data anyways

@_date: 2018-06-07 02:01:34
@_author: Leo Gaspard 
@_subject: [NIIBE Yutaka] STM32F103 flash ROM read-out service 
Some people do reverse-engineering based on photons emitted by
transistors switching. These would get through this shielding.
Unfortunately, I can't find again the link to the conference talk where
I heard people explaining they did that? sorry.
Another kind of attack would be EM pulses / lasers for error-ing a
crypto computation, that would get through this shielding too.
There are defenses against these attacks (well, for the
transistors-emitting-photons attack I'm not really sure), that are
deployed in secure elements. Attacks like this are tested by CC/EAL
evaluation laboratories.
All that to say: hardware security, to me, is a way to increase the cost
of the attacker to perform an attack. All devices are eventually
vulnerable, given the right price, the point is to make attack more
costly than the benefit from breaking the card and/or than finding a way
around the card. (I'm not going to extend this point to software
security, but I'd think it most likely holds there too)
Oh, and also to say: choosing between a non-secure-element open-source
token and a secure-element NDA-ed-and-thus-non-open-source token is not
an obvious choice.

@_date: 2018-05-14 12:55:13
@_author: Leo Gaspard 
@_subject: Efail or OpenPGP is safer than S/MIME 
> The topic of that paper is
that HTML is used as a back channel to create
The full details appear to be out [1].
If I read it correctly, it also has another attack, no longer based on
user agents concatenating HTML mime parts, but also based on CFB
gadgets. Which, here, looks like a flaw in the OpenPGP specification
indeed (and thus GnuPG's implementation of it), and not in MUAs?
[1]

@_date: 2018-05-23 01:22:41
@_author: Leo Gaspard 
@_subject: Breaking changes 
If the announced end-of-life is 12 months, then people will complain for
9 months, and maybe start working on migrating during the last 3 months.
I mean, I'm still seeing people actively developing python2 code bases
without even thinking of migrating to python3 *now*, and retirement was
initially announced for 2015?
The longer you leave people with maintenance, the longer they will want
maintenance past the deadline.
I think 3-6 months is more than enough, and if people can't manage to
update their production code in this time frame they can live with an
un-maintained GnuPG until they finish migrating (unless they want to pay
for paid support for continued 1.4 maintenance, that is).
I don't have a personal opinion, but dropping 1.4 appears to have two
advantages to me: first, it reduces the voluntary maintenance burden,
and second, it may help gather funding for work on 2.3, if people choose
to contract with g10code for continued maintenance.
GunPG 1.4 has been out for way longer than necessary, and people are
never going to migrate out of it unless they are forced to.

@_date: 2018-05-23 02:17:03
@_author: Leo Gaspard 
@_subject: Breaking changes 
>> The longer you leave
people with maintenance, the longer they will want
This service org already exists, is named in the message you replied to,
and is called g10code.
I think I do. Such large production environments can afford paying for
maintenance of what is currently GnuPG 1.4 until they complete migration.

@_date: 2019-07-01 14:08:24
@_author: Leo Gaspard 
@_subject: SKS Keyserver Network Under Attack 
I think we can't rely on humans actually reading the output, even if
GnuPG was able to display the output on eg. `--refresh-keys` in a way
understandable by a human.
Also, the aim of my suggestion was to actually *not* block the
keys. This second point of part 1 is there to just filter some hardcoded
list of packets, thus making key updates still propagate.
The first point was there to prevent additional keys from being
poisoned, and the second to limit the damage caused by already-existing
keys -- the first one is unfortunately quite necessary, as
sks-keyservers can't reasonably be coordinating changes on the ~220
keyservers every time a new key gets poisoned (or even twice, for that
matter, one flag day is already bad enough)
Well, nowadays ?fixing SKS? means ?making hagrid able to synchronize its
cryptographic-only content and propagate third-party signatures under
some circumstances?, as far as I understand.

@_date: 2019-07-03 21:14:00
@_author: Leo Gaspard 
@_subject: Your Thoughts 
Well, that's also an ecosystem issue, and if I'm not mistaken this
thread (or was it another one?) was going quite far in the ?let's fix
the ecosystem and keep the standard? direction.
?weak? *could* be used for verification. For instance, if I were to
write an OpenPGP client, I'd likely make it so that:
* Trust (which is 0-255 in the standard) is a slider with marks like ?I
  trust not at all|a bit|a lot| completely? (with a proper sentence so
  that people understand, not like what I'm putting here)
* Signature level (4 levels in the standard) is a similar slider
* Both trust and signature level are mapped to a [0, 1] value, and
  multiplied to get the amount of confidence we have thanks to this
  particular signature that the key is correct
* All such amounts of confidence get added, and the ?3-marginals or
  1-full? rule becomes a simple number that needs to be passed with this
  addition (also configured as a slider with some ?normal user / ? /
  parano?d user? landmarks)
(for trust signatures, in such a scheme they'd first be cut off to
follow the OpenPGP certification, and then get multiplied by the length
of the path, to account for decreasing trust along longer paths)
This is compatible with RFC4880 (well, except it doesn't respect the
?SHOULD? that full trust is 120 and marginal 60, because it actually
uses the whole range).
So ask-cert-level might make sense as a default. Just not as GnuPG's
default, as GnuPG doesn't have such a behavior (and no client that I
know of currently do). But someday, maybe.

@_date: 2019-06-30 19:37:56
@_author: Leo Gaspard 
@_subject: SKS Keyserver Network Under Attack 
One way to do that, though it would mean officially sunsetting SKS,
might be to:
1. Publish an update to SKS that:
   - Blocks all uploads of any packet that is not a revocation signature
     packet (maybe also having to check the revocation is actually
     correctly signed, to avoid flooding of revocation packets to become
     the new flaw)
   - Embeds a hardcoded list of already-disrupted keys for which packets
     should be filtered-out when serving them
2. Pressure keyserver operators into updating
3. Kick all not-up-to-date keyservers from the pool after some delay
   deemed acceptable (shorter means less broken GnuPG, longer means less
   keyservers kicked out)
   Note: I do not know how the pool is handled. Maybe this would mean
   that the new update to SKS would need to stop synchronizing with
   earlier versions, and that the hkps pool should be turned off until
   enough keyservers are updated to handle the load?
Do you think such a plan might be reasonably done, to at least keep the
most basic functionality of not breaking existing installations and
allow them to keep revocations flowing? The biggest issue I can see is
it requires a quite big amount of development work.
Hope that helps,
  Leo
