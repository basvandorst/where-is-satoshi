
@_date: 2002-12-05 11:16:01
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
Looking through Google, I found a thread here from a few months back that
mentions the concept of a "Robot CA".  It's basically certificate authority
that verifies only the email address on a key.
I've created such a beast.  There's information on it here:
Perl source is available.  I also wrote a more descriptive article for
kuro5hin.org, which you can find here:
I'm interested to hear opinions on this.  In particular, my robot does not
do a challenge/response the way it's usually assumed.  It just signs the
key and sends it to the address in the key ID.  I rely on delivery failure
to eliminate the bad signatures.

@_date: 2002-12-05 15:59:01
@_author: kyle@toehold.com 
@_subject: Robot CA at toehold.com 
Hash: SHA1
The postmaster case is something I hadn't thought of.  I think the earlier
suggestion of encrypting the response would take care of that.  Am I
missing something?
The benefit is in automation.
Once you have a robot CA, you can make an email client that looks for
recipient keys and automatically encrypts for them if they have the robot's
signature.  (More generally, it encrypts to any key that's considered
valid, and you make the robot's key a trusted signer.)
Once you have that, you can make the same client automatically generate a
key on installation and get it signed.  Then people are using encryption
The "robot only" users won't know what's going on, but they get extra
security anyway.  Further, they're able to "graduate" to "real" GnuPG usage
once they learn.  They already have a key, and they can get a real
signature on it at any time.
The educated users can encrypt to people who don't know what's going on,
and get encrypted mail from them.  If they don't want those automated
encrypted mails, they just don't get their key signed by the robot.  If
they don't trust the robot's signatures, they just mark the key untrusted.
At the point that we have automatic encryption in the mail client, you need
something to validate keys, or you get the attack where Eve makes a key
with Alice's email address and publishes it.  Then Alice gets encrypted
mails she can't read.  If Bob (the sender) can't figure out his mail
client, he can't stop sending them.
Thanks for reading this far.  I think the robot is a first step on the way
to transparent/zero-UI crypto.  That's the point.

@_date: 2002-12-05 18:23:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
I agree, it's a safer design.  Its only downside is that it's more complex.
I'm not very interested in signing sign-only keys; the whole point is to
sign keys that will be used for encryption.  At this point, though, it
doesn't make the distinction, so this is a problem.
The ultimate goal is to bring encryption to people who wouldn't have it
otherwise.  The benefit it brings is some extra security where there would
be none otherwise.  The users of this mailing list (who already know how to
use GnuPG, and do so) are not the "target audience."  The target is the
granny who won't put up with a passphrase in a million years.
With tools yet to be created, people could get the benefits of encryption
without having to understand it.  The robot CA will make those tools work
I've heard before the objection that this produces a false sense of
security.  I don't deny it.  What I think, though, is that the false sense
of security will always be a problem.  I've talked to users who are
astonished to learn that their sysadmin can read their email on the mail
server.  I want those who don't understand security, who think they have
some, to actually have more than they do now, even if it's not the most
that's possible.

@_date: 2002-12-05 18:29:01
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
I wanted to make signatures that expire, but I didn't see an obvious way to
do it with GnuPG.  If the key itself expires, it gives you the option of
expiring your signature at the same time (and the robot does that), but I
didn't see a way to set an arbitrary expiration date for a signature.
I considered having the robot's key expire periodically, but I decided
against it.
I made this an option in the robot's config file.  Mine makes normal
signatures right now only because I couldn't decide on 1 or 2.  I agree
that this would be a good way to flag it as an unusual signature.

@_date: 2002-12-05 18:42:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
It's true that anyone who can intercept your email can generate a
bogus-but-signed key.  Challenge/response systems have the same problem,
however.  In a sense, if the attacker can intercept the victim's email, the
verification is working--the attacker DOES have access to that email
address, and that's all the robot is trying to find out.  From the robot's
point of view, there's no difference between this and two (or more) people
who legitimately and knowingly share an email address.
Yes.  I didn't do it because I was put off by GnuPG's "I have done no
verification" description.  It does SOME verification, just not a lot.
Since I'm seeing multiple people suggest this, I'll probably do it this way
in the near future.

@_date: 2002-12-05 21:59:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
I prefer  myself, maybe   If the robot's key expires, suddenly all
its users want to get resigned on the same day.  I'd rather they get their
new sigs over a longer time period (i.e., the time it took them all to get
them in the first place).  The robot's load continually increases as it
handles old users as well as new, but it won't have a big "flag day" spike
where the one key expired.
If I were doing  I'd make the robot's key expire after a longer time.
That is, sigs expire every four months (say), but the main key doesn't
expire for two years.
Perhaps I'll implement the --ask-cert-expire thing below, make a new key
without such a long life, and revoke the old one.
Clearly I should have read more documentation.  Thank you!

@_date: 2002-12-05 22:34:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
This question is harder than I thought.  Perhaps I don't actually
understand it.
All this gives us is a binding between a key and an email address.  It
makes it safer to use that key when sending mail to that address.  It's
better than using an untrusted key because you can be more sure it will
work and not require the user to backtrack somehow.
If Alice doesn't have a key at all, Granny's software hasn't defeated the
attack.  It's also not defeated if Granny has a bogus key but not the real
one (though this seems less likely).
I guess that's it.

@_date: 2002-12-05 23:02:01
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
That situation is made no worse by having non-working encryption.
Hopefully the user gets a key working BEFORE people start sniffing.  When a
doppleganger shows up, hopefully people will notice.  There's some optimism
there, I know.
Do you not bother to lock your bicycle when you know there are people with
bolt cutters?  Envelopes can be steamed open, but I still use them.  What
I'm proposing is "better than nothing".  It is NOT absolute security.  It's
merely better than the (terrible) security that's there now.  Knowing this,
you're welcome not to use it.  People who are none-the-wiser will get some
benefit, perhaps without knowing it.  If not, they're no worse off.
I don't think I can prevent unsophisticated users from falling victim to
sophisticated attackers.  It's just a given.  The determined attacker will
get through this simple security.
What I can do is stop the more casual attackers.  If it's harder to get the
opportunity to violate someone's privacy, it won't happen as often.

@_date: 2002-12-05 23:22:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
I'm willing to yell from the hilltops how secure this idea is not.  I
haven't plastered it all over the web site yet, but it'll be a big part of
the FAQ when I make one.
I agree with you in principle that security is hard, and that people should
understand the risks involved.  However, the reality is that people don't
understand security, and I, for one, think the majority of them never
will.  I'd like to give them some better security in spite of their own
They're already astonished that a From: line can be forged--not just by
their sysadmin, but by anyone.

@_date: 2002-12-06 00:16:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
If I have a key with no signatures, I don't use it.  If all of this
software worked today, I'd have mine configured to ignore any key that is
not signed by the robot (or someone I trust).
Perhaps that's why I think this is useful.
I could be wrong in doing this, though.  Since I'm so used to sending mail
in the clear, I'd rather do that than have to resend something when my
recipient squawks "can't decrypt with this bogus key" (or merely "this
isn't important enough to make me type my passphrase").
If Alice doesn't have a key at all, and I refuse to use Mallory's
(unverified) key, then everything works fine (or as well as it did without
the attacking key).  That scheme "fails" if Alice has a key that's not
verified.  In that case, Alice just needs to get verified to get her mail
I consider having a key that's not verified to mean that Alice can get
encrypted mail if she has to, but she doesn't want to get it all the time
from everyone.  This makes sense to me since I know people who can do
encryption for something "sensitive" but don't want to do it routinely.
Having the robot's signature is a flag for strangers to tell them that
routine encryption is encouraged.

@_date: 2002-12-06 17:20:05
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
There are lots of ways email can go wrong.  If postmaster forwards the
signed key, maybe my encrypted messages will go through too.  I have the
same problem if someone's email is broken so that every tenth message gets
through.  Not only that, your working email address could go away the day
after I sign the key.  Since all I verify is email addresses, the
signatures are no more reliable than email itself.
I do that (if I understand you correctly).  If an email comes in with two
UIDs, then I sign them individually and email them to their respective
addresses.  When the two emails arrive, it's up to the user to merge all
the signatures together.  If one doesn't get through, they don't get that
What's funny is I thought this would be a rare special case when I decided
to handle it.  It turns out, almost everyone who's used the robot has three
UIDs or more.

@_date: 2002-12-06 17:36:02
@_author: Kyle Hasselbacher 
@_subject: AW: Robot CA at toehold.com 
Hash: SHA1
If I never sign a UID with a real name or comment (only email address),
then I don't need to yell so loud (or at all) that that's all I'm
checking--that's all there is to check.
The down side to doing that is, there aren't so many keys that have just
that.  People have to make a special UID to get signed.  I'd rather work
with what's there now.  That having been said, I certainly see the security
advantage to doing it your way.
Ultimately I'd like to be merely the first of many robot CAs that run.  If
others want to have a different (better?) policy on what they sign, I'd
encourage that.
[periodic challenges]
If I keep a list of UIDs that I've signed, I'd have to check the key
servers to see which actually have my signature before I start challenging
them.  Just a detail.

@_date: 2002-12-06 18:00:03
@_author: Kyle Hasselbacher 
@_subject: AW: Robot CA at toehold.com 
Hash: SHA1
On second thought, I'd rather expire signatures and make people get new
ones.  If your service goes away and stops challenging the users, then the
signatures hang around forever.  I'd rather they all expire forever.

@_date: 2002-12-06 18:18:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
The suggestion made here is to encrypt the response with the key I'm
The idea eventually is that the client would do a lot of this
automatically.  Behiind the scenes, it generates a key, submits it to a
robot, receives the signed key, and publishes it to a key server.  Then
when it's sending mail, it checks the key server for keys belonging to the
If I encrypt the responses, I see no harm (besides you getting unwanted
email).  With the responses unencrypted, you only have to worry about the
user taking the bogus key and publishing it.  That could be done with some
social engineering.
Well, this attack works just fine without the robot.  The attacker
convinces your contacts to use the wrong email address.  Your contacts
already have to check your email account by phone (or some other way).  The
robot doesn't change this.
My employer could verify that my work email address belongs to me.  They've
already checked my ID and such when they hired me.  If they're going to do
that, they could just sign my key whole.  If you would be satisfied looking
up my employer's phone number, calling, and verifying with someone that I
do work here, and this is my email address, you could maybe connect the
email address (and key) to me.
I think connecting a person to an email address is not much easier than
connecting a person to a key.
That's true.

@_date: 2002-12-06 18:38:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
I guess I'd rather have my message go through on the first try.  I only
want to use encryption when I'm sure it's welcome.  Maybe I'm more social
than secure.
I have a key, and it's published, but I still don't get much encrypted
email because my friends don't use it.  Right now if someone made a
duplicate key for me, it wouldn't make much difference.  The attacker's key
would be used as rarely as mine is.
When things get automated (and most people are encrypting to whatever key
they can find that matches the recipient), the duplicate key attack gets
easier.  If Alice doesn't have a key, she gets DoSed massively and easily.
She has to tell all her contacts to stop encrypting, and they have to
figure out how to do that (many of them may not have known they were doing
it in the first place).  And she'll have the same problem with every new
person who tries to contact her.  She has no way to stop it other than to
make her own key, get it certified, and publish it next to the bogus one.
I don't want the automation to make such a big headache for people who
haven't yet caught on.
Is there a way to do that?  I hope I haven't reinvented the wheel.
End users aren't meant to think about that question.  I'd answer it "yes."
If I were writing the software, I'd want to make it an option either way.

@_date: 2002-12-06 20:21:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
If I see a key that's not mine that IS signed by the robot, then I know
that someone else has access to my email.  That's a big improvement over
them reading my mail without me knowing.  The action I can take when I find
out is the same--get another email address.  Without knowing, I take no
action, and the snooping continues.
It brings a benefit to those who use it.  The ones who get their keys
signed by the robot and use the robot's signatures ARE the "closed
community".  People without the robot's signature or who don't trust it do
not get the benefit--just like the people who don't use GnuPG now.
This is just like GnuPG itself--it brings a benefit only to those who use
it.  People with keys are a closed community within the larger set of
people who have email access.
It seems, however, that you would not be a user.  If I've understood you
correctly, your decision is to encrypt to every candidate key you can find
regardless of whether it has been validated.  If you find two keys for an
email address, you prefer ones with more validation (such as the robot's),
but otherwise, you don't care.  Do I have that right?

@_date: 2002-12-07 05:17:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
Replying once here to multiple messages...
I hadn't considered that people would have multiple legitimately signed
keys.  The problem will be mitigated by expiring signatures (this makes me
want to expire them faster), but it'll probably still happen a lot (with
people installing multiple email clients and whatnot).
You could automate the check for multiple signed keys.  When it turns up,
explain to the user what it means, and what it MAY mean.  If they choose
"ignore it", then remember the extra key you saw, and pop the dialog again
only if ANOTHER key shows up.  We can have as many dead keys as we want on
the "don't care" list.
People who ignore real attacks are (again) no worse off than if they had no
crypto, except maybe that they're annoyed by perplexing questions.  What
bothers me is people who take action against a false positive.  They
generated two keys without knowing it, but they think the big bad
postmaster is out to get them.
That's a tough one.
I've already seen people send in two real keys with the same email
address, so I don't think I'll do that.
I think as long as there are some cases where we encrypt productively when
we would not have before, it's victory.  If I fail totally to encrypt when
there are multiple signed keys, or when there's a legitimate key that's not
signed, that won't bother me.  These are users who previously would have
never encrypted anyway.
Say there are 1000 people who aren't encrypting now.  Say 100 of them try
this thing.  Say 10 of them have it work (the other 90 fall victim to the
evil postmaster, or duplicate key creation, or whatever).  That's still 10
more people using encryption that wouldn't have it at all otherwise.
That having been said, in my mind, when there's some doubt, I don't
encrypt.  If I ever get a chance to write the software I'm talking about,
I'll make that the default (unless someone convinces me otherwise).  I'll
also give the user check boxes to change the behavior, if they ever feel
advanced enough to have their own opinion.
Yes.  I've had keys for seven years without being connected to the strong
set.  Most of my online time is not spent on crypto mailing lists, so most
of the other keys I see are of the "self-signed only" variety.  Most of the
people I communicate with online are ones I've never met, and may never
meet.  Authenticating their real names is not very important, but being
able to communicate with them privately would be welcome.
This is the situation that I think the robot can help, and I think it's
more common than your situation.  I know it isn't a perfect solution, but
that doesn't bother me.  As has already been pointed out, the perfect
solution requires user education.  I won't hold my breath until that
happens.  I'll go for the less-than-perfect solution in the meantime.
Yes, postmaster is still a vulnerability.  I'm frankly not very worried
about postmaster, though.  Having been a postmaster, I've seen others'
email during maintenance in various unintentional ways.  I'd never have
gone out of my way to read Alice's mail, though.  I certainly wouldn't have
gone through a procedure that leaves a trail like this one.
I'm sure there really are evil postmasters that will foil this little
scheme, but they're in the minority.  Most don't care.
As I said somewhere else, I can't stop the determined attacker.  My goal is
to stop the casual ones.
Very nice.  Thanks for the pointer.
It was just an idea.  Clearly I hadn't thought it through much.  8-)
I think most users feel safe already, but I see what you're saying.  NOT
using email addresses in place of fingerprints doesn't change this attack,
however.  This is another attack that I think the robot makes no worse.
You can, right now, make a key for your unwitting customers.  You can forge
mail from them asking their contacts to use it.  Etc.  The existence of the
robot just means you go through another step along the way.
OK, yes, you're right.  OTOH, if I didn't think you were right, you could
just not trust my signatures, knowing what my policy is.  Reading a little
further down, you already know this.
No, I was just brainstorming.  I'm actually kind of embarrassed.
FYI, I've only signed keys of people I know personally.

@_date: 2002-12-07 23:52:02
@_author: Kyle Hasselbacher 
@_subject: AW: Robot CA at toehold.com 
Hash: SHA1
I may be off my rocker, but I've been thinking "3 months" for expiration.
I wonder if I'm crazy since every other suggestion I hear is longer.  Does
anyone have evidence beyond the personal anecdotal about the lifetime of
the average email address?

@_date: 2002-12-08 07:49:01
@_author: Kyle Hasselbacher 
@_subject: Robot CA -- thanks for the suggestions. 
Hash: SHA1
I won't make a habit of announcing changes here, since I don't think it's
the place for it, but all the changes I made tonight are a result of
suggestions made on this mailing list.  I thought folks might be
interested.  The web page reflects these changes already:
- - The robot's responses are encrypted with the key it's signing.
- - The robot's signatures are "persona" signatures.
- - The robot's signatures include a policy URL.
- - The robot's signatures expire after three months.
- - It's under RCS, so you have revision numbers.
- - I signed the code, so you can verify it when you get it.
- - There's an option in the code (that I'm not using) to ignore a UID if it
  contains more than just an email address (so the robot doesn't appear to
  verify anything it isn't verifying).
I didn't really get to test that last one much.  When I make a key with
GnuPG, it wants my real name to be at least five characters.  I didn't
spend much time looking for a way to generate an email-only UID.
I'm thinking about revoking the current robot key (that doesn't expire) and
creating a new one that expires in a few years.
Thank you all for the suggestions.  I've gotten a lot out of the discussion

@_date: 2002-12-08 18:11:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA -- thanks for the suggestions. 
Hash: SHA1
It doesn't send the resulting signed key to a key server, and it never
did.  Doing so would break the design since email delivery to the user is
what verifies that the signature is good.  I rely on delivery failure to
eliminate the signatures I shouldn't have made.
I'll put that in when I make some of the other changes I have planned.
Thanks for the suggestion!

@_date: 2002-12-08 20:23:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
That is interesting.  Still, I fall back to "Granny would have NO
encryption otherwise."
I think including more people in the web of trust is a good thing.  Part of
my motivation for creating this is that I saw so many keys which I thought
were good but which had no solid trustworthy connection to anything.  The
reason they had no connection is that making the connection is hard.  I
WANT to lower the barrier of entry.
I agree that it's sort of a "back door" into the web, and the unwary may
place too much faith in a path that is really weak, but the path is clearly
marked.  I think part of the problem is that WoT implementations treat all
classes of signatures the same--that is, the robot's lame "persona"
signature is just as strong as signatures made with a personal meeting.
Everyone is either in the web or out.  It doesn't allow for the "half-way
in" kind of trust the robot provides.
It's easy in this case simply not to trust the robot's signatures.
However, what if a person starts giving out signatures of different types
(this already happens)?  I can understand not wanting to trust the persona
signatures, but they're also producing sigs made with real verification.
If you cut out ALL of that person's signatures, you're eliminating people
from the web unnecessarily.  There needs to be a way to say that "Alice's
signatures are good unless they're personas."
Given that kind of functionality, you can have a web of trust that includes
practically everyone (but the blatantly bad), and still limit your trust

@_date: 2002-12-08 20:35:01
@_author: Kyle Hasselbacher 
@_subject: AW: Robot CA at toehold.com 
Hash: SHA1
Tangent:  why don't OpenPGP implementations discard expired data?  I can
understand holding a revoked key so you don't reimport it as unrevoked, but
stuff that's expired is just useless, useless, useless.  Or am I missing
something?  Are we worried that my clock is wrong?
Wow, I'm surprised that anyone bothered to find that out.  Of course, a
customer relations group would be interested.  If I've read this right,
this means that 69% of email addresses last longer than a year.  That makes
a one year expiration sound better.
The idea, eventually, is for it all to be automated.

@_date: 2002-12-08 22:50:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
I think the only keys that should not be in the web of trust are the ones
that are totally bogus, through and through.  Being able to express weak
connections expresses the truth--that I have a little trust, but not
absolute trust, that I know something, but not everything.  If Alice gets
in, but I can see that no one is REALLY sure about it, that still tells me
more than if she doesn't get in at all.
I think they're details.  They express a truth that was not expressable
before.  It's not noise; it's just not as good as other signals.
Clearly, I don't believe it will be ruined that way.  8-)  Of course, I
don't want to make the WoT worthless.  I think getting more people in it
makes it more valuable.
That's fine.  There may be a little chaos in the meantime.  The existence
of persona signatures (and people who make them) is an incentive for people
to upgrade.  I'd say since GnuPG already supports making persona
signatures, distinguishing them from harder signatures is a feature that
needs to come next anyway.
Adoption of a validating key server may be faster than adoption of OpenPGP
implementations that recognize persona sigs for what they are.  I don't
mind if that's the right way to go, but, well, I went this other way
already.  8-)
Besides, I think GnuPG needs to understand persona sigs anyway.
It might be almost as easy to make a key server that accepts only keys
signed by the robot, and strips those signatures when exporting them to the
world.  I'm not sure that's an improvement.
So, if I get a key through another route, I have to check to see if it's on
the validating key server to know if the email address is valid.  If I'm
offline, I'm just blind.  Not that that will happen much, but it's not a
problem with a robot's signature floating along with the key.
I've never thought of the WoT that way.  Fact is, there are jokers out
there who will sign a key at the drop of a hat.  If they've been validated
(no reason not to if they're using their real name), then they're bringing
in people who wouldn't get in otherwise.  It's up to the users to discover
who those jokers are and to distrust their signatures.  The nice thing
about the robot is, it MARKS its signatures as being "a joke."

@_date: 2002-12-09 04:51:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
I've seen lots of talk about whether my Robot CA should be part of the web
of trust, and about weak signatures in the web of trust.  I'm writing one
post rather than follow up to everything.
David Shaw is correct in pointing out that getting the Robot CA in the WoT
does not improve its functionality.  The problem I see is how someone would
verify the integrity of the robot's key.  They could verify it with me the
same way they'd verify my key.  Given a verified key, it could be put on
read-only media distributed with the user's mail client or other
out-of-band means.  It seems far easier just to use the WoT (I sign the
robot, and they verify my key the usual way).
Concerns about polluting the WoT aside, it seems proper for me to sign my
robot's key and vice versa.  Assuming I am who I say I am (I feel
comfortable making that assumption), I could get into the WoT legitimately
myself.  At that point, the robot is in too, and everyone it signed.
I agree with Richard Laager when he says that the "over trust" of 0x11
signatures is an issue with the user agent.  The fact that it's an issue
with ALL of them doesn't make this less true.  When everyone on the road is
speeding, it doesn't mean they're not breaking the law.
Ultimately there's the same solution that was there three days ago when I
first posted about this: just don't trust the robot's signatures.  That
seems like a good interim solution until the user agent can figure out what
to do with weak signatures.  Since all the robot's signatures are weak by
definition, GnuPG's blindness to them isn't important.
The way GnuPG deals with weak signatures is a bigger problem for a real
person who chooses to use them along side strong signatures.  People
assigning trust to Jason Harris have a choice: (1) distrust some strong
signatures, or (2) trust some weak signatures.  I think that's the real
motivation to make GnuPG use them better.
As for "chaos in the meantime", that was a dumb remark.  I think that GnuPG
should deal with weak signatures for reasons above.  I'd like it all to
work as smoothly as possible, but I don't believe in giving up the feature
because other implementations don't have it.

@_date: 2002-12-10 08:31:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
This is all true, but I was thinking not of Granny verifying the Robot CA
but rather Granny's software's programmer.  Granny will have a trusted-key
line in a config somewhere, sure enough, but it'll be her software that
puts it there, not her.  Since she won't be verifying any keys by hand, she
has no way into the web of trust.  It doesn't help her to have that web
It DOES help Alice the Programmer when she writes Granny's software.
Alice, being a crypto enthusiast, DOES have a way into the web of trust.
She might even be close enough to me in the web (or more accurately,
someone who signs me) that she feels comfortable trusting my signature on
the robot's key.  If she's not that close, she knows how to verify a key on
her own, and add her signature, which might help the next Bob the
Programmer do the same thing.

@_date: 2002-12-10 18:39:01
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
Is that really better?  I see very similar attacks.
- - Break into the robot box, steal the secret key, use it to sign bogus keys
until someone notices and revokes it.
- - Break into the robot box, insert bogus keys into the "OK to sign" list,
get them signed until someone notices.
Not knowing the details of your setup, I don't know if this is a valid
attack.  I think as long as you trust the computer to do the validation
correctly, you might as well trust it to do the signing too.
You do get a little more security because it's harder to keep an open door
to a broken machine than to simply get in once and steal the goods.  It's
also nice that there's a possibility of reviewing what's signed before
signing (wither this is actually done or not).
Still, it seems like a lot more pain for the operator for only a little
gain in security.  I guess it's just a matter of what you're willing to
trade off.

@_date: 2002-12-10 19:53:02
@_author: Kyle Hasselbacher 
@_subject: Robot CA at toehold.com 
Hash: SHA1
Well, there's the Super Signer idea.  Granny would have a key that's
trusted to sign robot keys.  Right now that's just me, but it could be a
more formal non-human key.  I think it might as well be a list of trusted
operators, or perhaps the author of Granny's software.  In any case, it
could/should be something more secure than the robot itself.  A non-human
off in a safe somewhere is better than just my key, but I'll keep talking
about it as if it's just me for now.
When the robot is compromised, I revoke it.
Automated-like Granny's software notices the revocation.  It resubmits her
key to the robot to get a new signature.  It finds the new key that signed
Granny, and checks to see if it's signed by me (the Super Signer).  If so,
it can start trusting that key the way it trusted the old one.  If not,
she's stuck for the moment.  The software can try to resubmit again later.
Granny's contacts all go through the same procedure.  They look on their
favorite key server periodically for that revocation (daily?  hourly?).
When it happens, hopefully the operator already has a new key in place, and
everyone picks it up as they notice it.  As they all get resigned, they can
start encrypting again (or maybe they keep encrypting but with a gentle
The attacker has a window while the compromise is undiscovered.  After
that, there's a window for each user until the software catches up with the
new situation.
If the Super Signer is compromised, then it's the apocalypse.  But, that's
the nature of a CA.  If there's more than one Super Signer (the programmer
plus the operators) and more than one Robot CA, this gets easier.  If one
Super Signer gets revoked, Granny can still rely on the others (until she
gets a new list by upgrading her software (in 10 years)).
If there's more than one Robot CA, people get signed by two or three so
that when one gets compromised, their multiply-signed keys are still
"trusted" as far as Granny's software is concerned.  They still should get
a new signature when there's a compromise, but there's no rush to do it,
and no window where Granny has no way to trust their keys.
I'd really like to be just one of many Robot CA operators.  I think the
software could use a few more months of shakedown before it goes into
common usage, but ultimately it's an idea that works better if it's spread
Considering the variety of opinions about how the robot should or should
not work, there could be robots with different policies.  Users can then
decide which policies they like best and trust those robots but not the
others.  (And by "users" I mean people writing Granny's software or real
GnuPG users capable of making those decisions.)

@_date: 2003-02-05 17:43:07
@_author: Kyle Hasselbacher 
@_subject: mutt question 
Hash: SHA1
I have this in my .muttrc, and it works for me.  I'm using Mutt 1.4.0 on
Debian GNU/Linux.
set pgp_create_traditional
set pgp_outlook_compat
If you have the first without the second, it will make messages that are
not text/plain (application-pgp/signed?  I don't remember) and some people
will still see them as attachments.  With both options, it works for most
people, but I've still heard from the random Aunt that my messages show as
an attachment and nothing more.  I think it's producing a MIME header that
is "inline" but also has a filename, and some mailer got confused by that.
Hope this helps.

@_date: 2003-01-16 04:43:02
@_author: Kyle Hasselbacher 
@_subject: Prefered decryption key? 
Hash: SHA1
I have a couple of secret keys, one I use a lot, and one I don't use as
much.  I sometimes have files encrypted with both of them.  When I go to
decrypt one, GnuPG usually asks me for the passphrase of the key I DON'T
use as much.  I'd like to tell it that, given a choice, it should decrypt
with my more commonly used key (because that passphrase is "worn in" on my
fingers much more).  Is there a way to do this?

@_date: 2003-01-16 17:45:02
@_author: Kyle Hasselbacher 
@_subject: Prefered decryption key? 
Hash: SHA1
Aha!  Thank you!  That works well enough for me.

@_date: 2004-08-12 17:08:58
@_author: Kyle Hasselbacher 
@_subject: delete key from batch mode problem 
Hash: SHA1
Under "How to specify a user ID".
Basically, you take the key fingerprint:
2909 A7B5 0EB4 734C 2898  8D63 D74B 287E 2A94 C484
...and give it without any spaces:
...so you get a command line like this:
gpg --list-key 2909A7B50EB4734C28988D63D74B287E2A94C484
Hope this helps.

@_date: 2004-12-30 21:01:40
@_author: Kyle Hasselbacher 
@_subject: signing a robot's key - was: Re: Global Directory signatures 
Hash: SHA1
Some folks signed the Robot CA key (C521097E) to show that they believed that
it is what it says it is:  a gravel-dumb key verifier.
In some cases, a user might have wanted to use it as a trusted introducer.
To assign owner trust, it has to be valid.  To be valid, they have to sign
it.  Perhaps some of them knew that this is better done with a local
signature and fat fingered the signing, but it's a little hard to believe
someone understood the web of trust well enough to want to sign but not well
enough to know a local sig was better.
Some people may have seen it as a back door into the global strong set.  The
Robot CA is in the strong set, and it gives out signatures easily.  Give a
signature back, and you're in the strong set too.
I signed it because I wrote it and run it.
Are folks signing the Global Directory key for the same reasons?  I don't
know, but it's possible.

@_date: 2004-12-30 21:40:16
@_author: Kyle Hasselbacher 
@_subject: signing a robot's key - was: Re: Global Directory signatures 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
No, sorry, I was talking about the Robot CA key (C521097E).  It and I have
certainly exchanged signatures.  I'm on the GD, so I have its signature (if
you ask the GD for it), but I haven't signed the GD key.  If I ever do, it
will be to certify that it is what it says it is (a dumb key signer).  Like
my other signatures, that's not an endorsement of its key signing policy,
just certification of identity.
Fine with me; it's your list.  8-)

@_date: 2004-12-30 22:32:10
@_author: Kyle Hasselbacher 
@_subject: signing a robot's key - was: Re: Global Directory signatures 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Yes, it would be.  All I could do is verify that it APPEARS to work as
advertised.  Its functionality IS its identity, in my opinion, but I can see
there are dueling interpretations here:
* I made it and called it "Robot CA".  Therefore, it is "Robot CA".  Only I,
its mighty creator, can verify its identity.  The rest of you have to take my
word for it.
* It is called "Robot CA" and it performs within the definition of "Robot CA"
that I agree with.  Anyone satisfied with the performance can verify its
identity.  Satisfaction comes through software testing instead of "testing"
an official document of some kind.
I take the latter interpretation.  It's fuzzier, but I think it conforms
better to how I already think of signatures.  As such, even my own signature
on my own Robot CA is a matter of some faith (that it's bug-free, nyuck nyuck
nyuck).  I can't test the GD as a user the same way I tested RCA as an
operator, so there would be more faith involved in that signature, if I ever
made one.  I consider that similar to the extra faith involved in signing a
key named "Fred" when the state-issued ID says "Frederick".

@_date: 2004-07-14 18:15:19
@_author: Kyle Hasselbacher 
@_subject: Wraparound with --enable-progress-filter 
An embedded and charset-unspecified text was scrubbed...
Name: msg.pgp
Url: /pipermail/attachments/20040708/d0da64e2/msg.txt

@_date: 2004-06-15 19:03:12
@_author: Kyle Hasselbacher 
@_subject: Secure deletion of files in a directory 
An embedded and charset-unspecified text was scrubbed...
Name: msg.pgp
Url: /pipermail/attachments/20040615/22b17892/msg.txt

@_date: 2004-05-06 17:56:07
@_author: Kyle Hasselbacher 
@_subject: OT: Revoking Old Keys... my problem 
Hash: SHA1
The '-c' in Greg's suggestion indicates symetric encryption.  The
certificate will be encrypted with a passphrase (perhaps the same one you
use on the secret key, to make it easier to remember).  As long as you
remember the passphrase, you're set.  Attackers who don't know the
passphrase can't decrypt (and (ab)use) the certificate.

@_date: 2004-05-15 14:47:23
@_author: Kyle Hasselbacher 
@_subject: key-signing for pseudonyms 
Hash: SHA1
Pseudonym != anonymity.  Say I use a pseudonym online for some time, and I
gain a (good) reputation with that name.  I decide to "come out" and
associate myself with the pseudonym I use.
In answer to the original question, I'd verify just the email address and
give a weak (persona) signature.  The easiest way to do this is to sign the
key, encrypt the signed key WITH that key, and email it to the address on
the key.  Delete your local copy.  If it doesn't arrive, or the address
holder doesn't have the secret key, the signature never appears.
Ultimately how you "verify" such an identity is entirely up to the signer.

@_date: 2004-05-17 15:14:14
@_author: Kyle Hasselbacher 
@_subject: key-signing for pseudonyms 
An embedded and charset-unspecified text was scrubbed...
Name: msg.pgp
Url: /pipermail/attachments/20040517/99351593/msg.txt
