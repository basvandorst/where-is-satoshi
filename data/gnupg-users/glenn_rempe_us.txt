
@_date: 2016-12-02 08:36:25
@_author: Glenn Rempe 
@_subject: Proof for a creation date 
Tierion creates a Merkle tree of incoming hashes and puts the root of the Merkle tree on the Bitcoin blockchain which proves that the hash was placed there prior to the time embedded in the BTC transaction. You want to use their HashAPI.
Other similar services are:
These services don't need GnuPG, but nothing to stop you from hashing a signed document.

@_date: 2016-12-02 10:24:09
@_author: Glenn Rempe 
@_subject: Proof for a creation date [GishPuppy] 
Unfortunately, I think the public key from that service is no longer importable in modern GnuPG.
Trying to import the public key on this page results in no public key being imported. Without this the service cannot be used to verify the signature on a timestamp report (I reported this to them several years ago. No changes were made). ?Also, this service is not a very secure source of time. They use their own clock. They claim some security by using an incrementing counter and publishing signed snapshots to a usenet group. ?Bottom line though is this service is pretty ancient and requires a lot of trust on your part of the administrator.
$ gpg2 --verbose --import stamper.asc
gpg: armor header: Version: 2.6.3i
gpg: Total number processed: 3
gpg: ? ? skipped PGP-2 keys: 3
$ gpg2 --version
gpg (GnuPG) 2.1.16

@_date: 2016-12-05 12:03:49
@_author: Glenn Rempe 
@_subject: Proof for a creation date 
Posting on a forum or github issue does not provide immutable and
cryptographically verifiable proof that a digest existed at a specific
point in time. It is very weak from that standpoint.
If you use one of the services that implants your digest on the
blockchain it is guaranteed to be immutable once transactions are
layered on top of it (within minutes to hours).
This approach does NOT require the service that originally posted this
digest to continue to exist past that point in time as you can
independently verify either the digest or the merkle tree root digest
that you posted using open source software.
As an example, I wrote a Ruby wrapper for the Tierion API and this Ruby
code does not require Tierion to continue to exist past the point when
you retrieve a receipt (which are the merkle tree root verification
instructions that the code can follow). You can verify that a hash
exists in the merkle tree independently and for as long as the
blockchain exists (or as long as you keep your own independent copy of
it). This also provides consensus from thousands of miner machines as to
the rough time when a transaction containing your digest was submitted
since all transactions contain the hash of the prior transactions.
Changing and earlier hash would also require rebuilding all hashes on
top of it which is considered computationally infeasible. This is
similar to how a chain of git commits work, but distributed with real
monetary value on the line. It usually takes about 10-30 minutes from
when you submit the hash to when it is permanently and immutably
embedded in the blockchain.
Tierion is free to use, but requires you to calculate the merkle tree
proof to verify it later (not hard with open source software that is
available).  directly submits your digest on the
blockchain (no merkle tree, your transaction is not shared with other
digests), so it is a bit easier to prove later, but you need to pay them
in BTC to cover the transaction costs and their costs at the time you
make the API call. I think its a couple of dollars worth of BTC.
Not only does itconult.co.uk provide signatures from a key that is no
longer importable in modern GnuPG, you are also relying on the fact that
their system clock is accurate and can never be changed maliciously or
through error. This is not an assumption you can make. There is also no
immutable storage of the hash only a signature that was claimed to be
made at a certain time. A claim that cannot be verified later since it
is lacking context.

@_date: 2016-01-15 00:08:04
@_author: Glenn Rempe 
@_subject: Yubikey, GnuPG 2.1 Modern, and SSH on OS X 
I recently setup my own Mac w/ gnupg 2.1.10, and I am using a Yubikey to
manage my gpg private keys and I am using that key for SSH auth.  I have it
all up and running but I ran into some issues as well so I wrote up a blog
post.  I'd appreciate any suggestions for improvement and especially for
any ideas for a better fix for the workaround I had to do that I documented
at the end of the post.  Maybe this will be of some use to those wanting to
use the latest gpg for SSH auth on a Mac with a Yubikey.
Here is a discussion thread that describes *exactly* the issue I am still
having (if I don't use my workaround to kill and restart gpg-agent on every
yubikey insertion and deletion):

@_date: 2016-01-15 12:17:13
@_author: Glenn Rempe 
@_subject: Yubikey, GnuPG 2.1 Modern, and SSH on OS X 
I am on OS X, and just so you know I have turned off the OS X system
scdaemon per this blog post (I did this before upgrading to GnuPG 2.1):
So I am using just the scdaemon embedded with GPG I believe.
I just tried your suggestion to reload the internal scdaemon with
'gpgconf --reload scdaemon' and that also worked just as well as killing
gpg-agent, and probably without some side effects, none of which I've
noticed yet. So that is a step in the right direction, but I still have to
run it every time I remove/reinsert the card and SSH to a remote host
or it fails with a 'Permission denied (publickey)' error. So this seems
like a step in the right direction, but I still have to use ControlPlane
to restart scdaemon on insert/remove events.
I do have a revoked Authentication sub-key on my primary key, but I
no longer use it and that is also not why I added the keygrip entry to
sshcontrol file.  I added it at the suggestion of Werner in this post:
And these blog posts:
Is this suggestion outdated?

@_date: 2016-01-15 21:29:55
@_author: Glenn Rempe 
@_subject: Yubikey, GnuPG 2.1 Modern, and SSH on OS X 
I'm not sure when the use of sshcontrol emerged. My impression was that it
is only used as part of GnuPG 'Modern' 2.1.x versions. That being said, If
I remove the keygrip entry from the sshcontrol file it appears to work
fine.  The only difference I've just noticed is in the output of 'ssh-add
with keygrip in sshcontrol:
~/.gnupg$ ssh-add -l
error fetching identities for protocol 1: agent refused operation
2048 SHA256:X3YiWulZ1xJlqGRFqeaQOmLuZvyfJV/r7Qwo/kmUgCg cardio:000MYCARDNUM
2048 SHA256:X3YiWulZ1xJlqGRFqeaQOmLuZvyfJV/r7Qwo/kmUgCg (none) (RSA)
without key grip in sshcontrol:
~/.gnupg$ ssh-add -l
error fetching identities for protocol 1: agent refused operation
2048 SHA256:X3YiWulZ1xJlqGRFqeaQOmLuZvyfJV/r7Qwo/kmUgCg cardno:000MYCARDNUM
Any ideas for also eliminating that error message, or understanding why its
there are appreciated.
As for the suggestion by the2nd at otpme.org regarding the scdaemon bug.
This sounded promising, but when I investigated a bit it seems that the
commit in that thread that indicated this issue might be fixed on master
(f42c50dbf00c2e6298ca6830cbe6d36805fa54a3) was committed on Dec 2, 2015,
and gnupg version 2.1.10 was tagged on Dec 4, 2015.  So that fix should
already be in the version of GnuPG I am using (2.1.10) and yet I am still
seeing a problem.
commit f42c50dbf00c2e6298ca6830cbe6d36805fa54a3
Author: NIIBE Yutaka     scd: Fix "Conflicting usage" bug.
    * scd/apdu.c (apdu_close_reader): Call CLOSE_READER method even if we
      got an error from apdu_disconnect.
    * scd/app-common.h (no_reuse): Remove.
    * scd/app.c (application_notify_card_reset): Deallocate APP here.
    (select_application, release_application): Don't use NO_REUSE.
    --
    Reproducible scenario: Invoke gpg --card-edit session from a terminal.
    Invoke another gpg --card-edit session from another.  Remove a token.
    Insert a token again.  Type RET on both terminals.  One of terminal
    answers "Conflicting usage".
    Perhaps, having NO_REUSE field was to avoid race conditions.  Now,
    APP can be safely deallocated by application_notify_card_reset.
    Thanks to the2nd.
I installed 2.1.10 from this homebrew recipe:
My SSH client is the one that comes with OS X 'El Capitan':
OpenSSH_6.9p1, LibreSSL 2.1.8
On Fri, Jan 15, 2016 at 12:31 PM Simon Josefsson

@_date: 2016-01-15 23:47:07
@_author: Glenn Rempe 
@_subject: Yubikey, GnuPG 2.1 Modern, and SSH on OS X 
Thanks Peter, I was not aware of that (and it certainly explains the double
entry in ssh-add -l.
btw, Werner was not writing that response to me. It was just pointed out to
me, so yes it was
probably not smart card specific I would guess. I'll update the blog post
to reflect that we
probably do not need to modify sshcontrol for use with Yubikey.
Back to the main issue I am having. I followed the instructions to output a
verbose scdaemon log
which I was exercising this issue.  Here is a gist with the commands I was
running and the resulting
Perhaps NIIBE Yutaka or someone else more knowledgable than I can take a
look and
get us closer to resolution. :-)
Thanks for everyone who is helping.
On Fri, Jan 15, 2016 at 3:08 PM Peter Lebbing

@_date: 2016-11-10 20:06:56
@_author: Glenn Rempe 
@_subject: PCI DSS compliance 
I think this is where you want to look into a Hardware Security Module
(HSM) or a solution like Hashicorp's Vault server. The split secret would
be used to initialize either of those solutions (Vault uses split keys to
unseal the server out of the box, and can even encrypt those shares to
several different GPG keys when the root key is created, this way the
shares are never exposed in plaintext form to anyone, not even the original
admin that creates the key)
I don't know if any HSM's support hardware based protected GnuPG encryption
or not.
If you want to experiment with a Shamir Secret Sharing key split you can
look at an implementation in Ruby that I have created which also has a
simple command line interface for splitting and recombining secrets.
In any case I think you would have those trusted admins, with shares of a
private key passphrase, unlock the key in memory at boot time of your
application and this server would be the only one that is capable of
automated decryption using that unlocked private key. They would need to
repeat this process at each reboot or if the process that contains the key
I am not aware of GnuPG ever supporting Shamir Secret Sharing style
encryption key splitting. They may exist, I just don't know.

@_date: 2016-09-10 18:30:31
@_author: Glenn Rempe 
@_subject: Keybase integration with GnuPG? 
I think you are operating under some assumptions about Keybase that are not
entirely accurate. Contrary to what you state, Keybase.io does not support
Facebook as a proof destination.
I have a pretty complete Keybase profile if you are interested to see the
services they *do* currently support.  Please note that many of these are
not social networking platforms but also domains, DNS records, and Bitcoin
accounts that I control.
True. Keybase supports a number of ways to hosts proofs currently. I
imagine they will add more as they mature for those sites that can meet the
requirements for hosting a proof that is public and can only be controlled
by a single user. This not only allows you to find public keys for a
person, but to authenticate that a person who claims to control the account
on site A is provably the same person who claims to control an account on
site B or a certain GPG key.
You can also host proofs on your own domain as a static signed file or as a
DNS record. Here is an example where I demonstrate that I control my
personal website:
You can learn a bit more about this here:
Please also note that for most of the last year Keybase is in the midst of
a transition away from using GPG keys as the primary identifier and the
primary way of signing proofs. They have already moved to a model where
NaCl keypairs are used to identify various devices the user controls, and
then the user can sign proofs on various services with those NaCl keys. You
can still add one, or more, GPG keys into this mix.
Keybase is creating a form of the Web of Trust, but it does not rely on, or
even require at all, GPG keys or the use of social networking services.
Facebook is not supported at all.

@_date: 2017-02-24 10:26:14
@_author: Glenn Rempe 
@_subject: SHA1 collision found 
If you read the announcement Google never uses the words "completely broken" that you attribute to them. I believe that was someone else's characterization.
Mis-attribution and name calling can also be unhelpful.
Google's security team has been the driving force behind two major security issues this week alone (SHA1 and Cloudflare) and with SHA1 they made concrete something that was only theoretical before. Let's give credit where credit is due.

@_date: 2017-02-27 16:28:25
@_author: Glenn Rempe 
@_subject: How U2F works 
Just chiming in here with some comments below. I am an active U2F user
and have played around with the server API's and read some of the
specs. Just to be clear, not an expert on U2F.
Well, the attestation key would be checked by the server side process
right? And that is optional to check (but perhaps not optional to
send). So you probably would need to ask those that are integrating
U2F as a server auth method. Sending this seems to be a requirement
based on the spec link you sent. Couldn't you get a vendor specific
attestation key in any case for GnuK and use the same key across all
Yubico describes something about the attestation metadata they use here:
I believe that at this point almost all use of U2F is through web
browsers that support talking to the U2F hardware API's directly. Only
Chrome has full support now, and Firefox and Opera are working on it
but are not yet generally available. The web Javascript API's are just
for requesting registration of a token or authentication. So you can't
use U2F in a browser that does not have support for it no matter what
JS you load in your page.
Browser support:
Yubico Demo Code and JS API
JS Polyfill
FIDO U2F is based on an openly published standard but only for you to
'read and analyze'. Seems like you have to become a member of the FIDO
alliance to be protected. Its not an Internet RFC.
"FIDO's specifications are public and available for anyone to read and
analyze. But only FIDO Alliance Members benefit from ?the promise? to
not assert patent rights against other members? implementations (see
the FIDO Alliance Membership Agreement for details). Anyone may join
the FIDO Alliance; we encourage even very small companies with a very
low cost to join at the entry level. Members at all levels not only
benefit from the mutual non-assert protection, but also participate
with FIDO Alliance members, activities and developments; Associates
have more limited participation benefits. All are invited to join the
FIDO Alliance and participate."
Wouldn't making this work require the browser vendors to support some
kind of 'pluggable local auth' that gnupg would emulate, and not only
support for hardware tokens like Yubikey? I don't know if they support
this broader concept or not.
What though is the benefit of using gnupg key as the crypto behind the
client auth? Seems like you are more exposed by having a portable gpg
key as opposed to a hardware embedded key. U2F makes it so easy to add
a backup key, and most implementations let you drop and add keys
pretty easily. Just trying to figure out if backing U2F with gpg, if
that is what you are proposing, is worth it?

@_date: 2017-01-25 17:16:36
@_author: Glenn Rempe 
@_subject: gnupg website 
Hash: SHA512
I would also like to note that gnupg.org does not appear to work on
the latest versions of Apple iOS or macOS  Safari due to TLS cert
issues. It fails to load in Safari on either platform (but Chrome and
Firefox do work on macOS, Safari is the only browser on iOS).
I believe this may be due to Apple's App Transport Security (ATS)
rules. You can find an overview of those rules and a link to more
details here:
It seems that iOS/macOS cannot negotiate a strong connection with TLS
1.2 and one of the allowed cipher suites using forward secrecy when
talking to gnupg.org.
The accepted TLS 1.2 ciphers for Apple ATS are:
And gnupg.org only provides:
TLS_DHE_RSA_WITH_AES_128_CBC_SHA (0x33)   DH 2048 bits   FS	128
TLS_DHE_RSA_WITH_AES_256_CBC_SHA (0x39)   DH 2048 bits   FS	256
TLS_RSA_WITH_3DES_EDE_CBC_SHA (0xa)	112
As you can see, there appears to be no overlap with the suites that
ATS expects for a strong connection and those that gnupg.org offers.
For comparison sake, here are the cipher suites that cloudflare
advertises with its CDN services:
Preferred TLSv1.2  128 bits  ECDHE-ECDSA-AES128-GCM-SHA256 Curve P-256
DHE 256
Accepted  TLSv1.2  128 bits  ECDHE-ECDSA-AES128-SHA256     Curve P-256
DHE 256
Accepted  TLSv1.2  128 bits  ECDHE-ECDSA-AES128-SHA        Curve P-256
DHE 256
Accepted  TLSv1.2  256 bits  ECDHE-ECDSA-AES256-GCM-SHA384 Curve P-256
DHE 256
Accepted  TLSv1.2  256 bits  ECDHE-ECDSA-AES256-SHA384     Curve P-256
DHE 256
Accepted  TLSv1.2  256 bits  ECDHE-ECDSA-AES256-SHA        Curve P-256
DHE 256
Here is the full list of TLS suites that I used to compare:
- -parameters-4
SSLlabs tests for gnupg.org seem to show that it cannot negotiate a
connection with forward security with gnupg.org which is a requirement
for ATS.
Every load of gnupg.org in Safari results in a total failure to load
anything. Running one of the suggested diagnostics shows the following
$ nscurl --ats-diagnostics Starting ATS Diagnostics
Default ATS Secure Connection

@_date: 2017-01-26 10:48:28
@_author: Glenn Rempe 
@_subject: gnupg website 
Hash: SHA512
Werner, you (or anyone setting up a web server themselves really)
might also find this config generator from Mozilla helpful as a
shortcut in creating what is considered a modern web server config for
This config may not apply to gnupg.org directly since its not clear
what web server you are running. In any case it will tell you which
suites you are recommended to support for modern(ish) browsers.
I would also note that there is room for improvement regarding the
security headers the gnupg.org sends with its content.
You are using HSTS, which is generally very good, but in this case it
forcibly breaks users experience since it requires me to connect with
TLS but that is not possible since you are not advertising a TLS suite
that shares common ground with my browser (or millions of other
potential visitors).

@_date: 2017-01-29 22:54:27
@_author: Glenn Rempe 
@_subject: gnupg website 
Hash: SHA512
Is there a plan to take action on this TLS issue the Julien and I have
written about? I believe all Safari and iOS users are excluded from
gnupg.org without action on the TLS setup.

@_date: 2017-01-30 11:13:15
@_author: Glenn Rempe 
@_subject: gnupg website 
Hash: SHA512
Awesome! Works perfectly now. Tested on macOS (Sierra) Safari and
current iOS Safari.
Congrats on your A+ at SSLlabs
I would suggest you also look at doing HSTS browser preload now that
you have long duration HSTS and a good modern TLS suite. It would
require being applied to sub-domains as well I think which you may or
may not be able to do. You can test (and register for it) here:
Thanks for fixing this issue. Its been bugging me for months. :-)
