
@_date: 2015-08-28 20:41:31
@_author: listo factor 
@_subject: FAQ: drop mention of 1.4? 
Those that use GPG as a matter of principle or because of "geek appeal"
have no problem with TSR ("terminate-but-stay-resident" :) components and the fallacy of "always on-line and trusted" computer. Those that
use GPG because they need to, depend on 1.4.

@_date: 2015-07-31 07:15:23
@_author: listo factor 
@_subject: Proposal of OpenPGP Email Validation 
The problem with most "e-mail reform" proposals (this one included)
is that they don't address what is the primary problem of essential
users of the encrypted communication: that to their attackers the
knowledge of who communicates with whom is of greater value than
the content of the message. Without solving that primary problem,
the motivation for the adoption of any new scheme is either low
or non-existent.
Listo Factor

@_date: 2015-06-18 18:21:33
@_author: listo factor 
@_subject: two-lock mailbox analogy 
FWIW, I use the following analogy:
I have a secure steel mailbox, located on a street corner - just
like the Post Office does - that I visit occasionally to collect
the mail that my correspondents have deposited there. The only
difference between my box and those owned and operated by the
Post Office is that on my box, there is a second lock and key,
one that is required to open the slot by which the letters are
deposited into the mailbox. Copies of that key I give freely to
all that want to securely send me a message. This is the public
key: it is useless for retrieving the messages from the box, it
can be used only to deposit them.
Just like the Post Office, I have another, private key, which is in
my possession only, and which I must keep protected. This one opens
the back cover of the steel box, one through which I, just like the
post office collection truck operator, retrieve all the letters
from the mailbox.
The set of two keys, private and public, are mathematically related
in a unique way. The public key is thus also useful to confirm
that the message is deposited in my box, as opposed to somebody
else's box that happens to be located on the same street corner.
I advise those that I teach how to use GPG to completely ignore
WOT and key-signing, and to rely on rigorous out-of-channel key
fingerprint verification. If they don't, they could be depositing
their messages into an imposter's box, who could read them, and
(since he, like everybody else, is likely to be in the possession
of my public key) afterward deposit them in my mailbox. Neither
I, nor the message sender would know that such message has been
read by the imposter.
Teaching those that don't have a very concrete idea of the cost to
themselves and/or to their correspondents in case the content of
their communication is compromised is a waste of time: they lack
the motivation to put in the considerable effort that is necessary
to effectively use (as opposed to just "go through the motions")
of something as complex as GPG.
Advocating for the adoption of encrypted communication as a matter
of personal policy or principle, in conjunction with teaching the
use of a complex software system necessary to do it is, IMHO,
a big mistake.
Listo Factor

@_date: 2015-10-12 20:32:52
@_author: listo factor 
@_subject: How can it be made even easier!? 
Unfortunately, this approach has been subverted by several
decades of "computer security" doctrine, which held that
encryption must "just work", without any need on the part
of the user to understand the fundamentals. Which is why
doctors and lawyers expect the communications security to
be available as a product, just as the car they drive, and
not as a professional service, such as their bookkeeping.

@_date: 2015-10-13 06:49:30
@_author: listo factor 
@_subject: How can it be made even easier!? 
The assignment of the units on abscissa and the ordinate is completely arbitrary. If the abscissa is the amount of knowledge, and the ordinate is the effort put in to gain it, the curve reflects the popular usage
of the phrase quite well. To me, "knowledge" as a unit makes more sense that "learning", and "effort" more than "time".
It is quite comical to see an article advising on measures against
"bulk surveillance" urging participation in the "web of trust" and
uploading one's key to a keyserver.

@_date: 2015-10-24 03:37:36
@_author: listo factor 
@_subject: absolutely nothing to panic over 
Yup, instead of panicking, we should simply acknowledge the fact
that secret communication is not possible without out-of-channel
key exchange. The dream of circumventing this fact of life with
the alchemy called "public key cryptography" is quickly coming
to its end. It was nice while it lasted, but now is the time to
move on. Like every change of massive technical infrastructure
built on weak foundations this will be difficult and there
will be casualties, but mostly among those that refuse to
abandon public key cryptography as soon as they possibly can.

@_date: 2015-10-25 07:40:37
@_author: listo factor 
@_subject: absolutely nothing to panic over 
I agree that the sky is not falling, at least not for everybody.
I do however believe that we must face the future without the
hocus-pocus of "public key cryptography". *There is no secure
communication over an insecure channel without out-of-channel
bootstrap*. For a while, we thought that we can cheat the laws
of nature with smoke and mirrors: either "trusted third parties"
(a contradiction in term), or public key verification using
devices such as "web of trust" (a Rube Goldberg-esque contraption
if there ever was one in widespread use) or party-to-party key
verification that depended on authentication and information
exchange integrity over an insecure channel. As if that was not
enough, we now see the cracks in the basement: advances in
computing technology are corroding the fundamental algorithms,
one by one...
Fortunately, this process is slow, and there is ample time to
transit. If the sky is falling, it is falling only for those that
deal with the reality by burying their heads in the sand.

@_date: 2015-10-27 07:25:24
@_author: listo factor 
@_subject: absolutely nothing to panic over 
Allow me to try again:
*There is no secure communication over an insecure channel
without out-of-channel bootstrap*.
I believe the above can be re-phrased as follows, with no change
in meaning:
Cryptography is an art of turning large secrets into small secrets. [1]
We need a secure channel to transfer small secrets (typically
the cryptographic device and the key), so that we can communicate
large secrets over an insecure channel. [2]
[1] The definition is of course not mine.
[2] It is often forgotten that it is not ~only~ the key
that comprises the "bootstrap". The cryptographic device does not
need to be secret, but it must be authenticated, which can not be
done over an insecure channel. Same holds for the "public" key in
asymmetric systems.

@_date: 2015-09-28 11:23:32
@_author: listo factor 
@_subject: Should I be using gpg or gpg2? 
Unless you have specific reasons for transitioning to gpg2, stick
with gpg (GnuPG) 1.4.16. It is just as secure, and much easier
to use.

@_date: 2015-09-28 20:00:14
@_author: listo factor 
@_subject: Should I be using gpg or gpg2? 
> On Mon, 28 Sep 2015 13:23, listofactor at mail.ru said:
 >
 >> Unless you have specific reasons for transitioning to gpg2, stick
 >> with gpg (GnuPG) 1.4.16. It is just as secure, and much easier
 >                                       ^^^^^^^^^^
 >
 > That is definitely not the case.  All improvements go into 2.1
 > and some are backported to 2.0.  We only add necessary
 > fixes to 1.4.
Most od 2.x "improvements" have little to do with security.
I can't offer any conclusive evidence for this, but it is my
honest estimate that more real-world sensitive traffic volume
is generated by 1.4.x than 2.x. Consequently, if 1.4.x is in any
was insecure, this would be of significantly greater benefit to
a whole class of large institutional web-traffic attackers than
if 2.x was insecure. So, if 1.4.x is indeed in any way insecure,
that should merit more serious and immediate attention that if
2.x was insecure.

@_date: 2015-09-28 20:52:44
@_author: listo factor 
@_subject: Should I be using gpg or gpg2? 
Most of those that use gpg because they really, really need to keep
their secrets from their adversaries are concerned with this year
and next, not about A.D. 2030. Their enemy is mistakes caused by
overly complex interfaces, much more than residual differences
in the cryptographic primitives. (Kind of AK-47 vs M16 thing).
I'm obviously not one of those gentlemen; my "caliber" is that of a
half-educated practitioner toiling in the trenches. But sometimes
those can offer observations that escape the admirals and generals...

@_date: 2015-09-29 03:55:48
@_author: listo factor 
@_subject: Should I be using gpg or gpg2? 
I'm not here to prove anything.
An Internet mailing list is not about proving things. It lacks
both the procedural rigour and an impartial umpire; two things that
are sine qua non for the concept of "proving". The observations I'm
offering here are simply that; observations of a user of the product.
The only reason they might be worth reader's time is that they come
from someone familiar with the world of end-users with limited
resources combined with a real need for the facilities this product
has to offer.

@_date: 2016-08-27 07:30:45
@_author: listo factor 
@_subject: Torture and rights to privacy 
It would help if in similar discussions participants first find
out what are the ethical fundamentals that they agree on. May I
suggest the following:
1) Torture is absolutely unacceptable. It includes not only
physical harm to the individual's body, bit also actions that
instill pain or fear without leaving permanent marks on the body
(water-boarding, mock executions...), mind-altering pharmaceuticals
or keeping one locked up for refusing either a confession or
self-incriminatory evidence.
2) No one can prevent an individual to keep his journals or ledgers
in a language that only he understands, or any two individuals to
communicate in such language. The fact that such language happens
to be a stream of ones and zeros changes nothing, as does not the
fact that a mechanical or electronic device - instead of pen and
paper - may be used for reading and writing this language. Mere
possession and use of such device can not be considered a
transgression, any more than a possession of pen and paper.
These two principles seem to me to be universal. After that, it
becomes the matter of an individual jurisdiction law and the
majority rule.
Personally, I would not be much thrilled to live under a government
that restricts the trade in the aforementioned devices, or worse,
punishes someone for constructing them and making them available.
I have lived long enough too see many different governments
manipulate the public, typically using a mixture of fear-mongering
and ideology, to accept various laws that are quite unpalatable to
me. However, the discussion of one particular government's behavior
is best left to it's citizens.

@_date: 2016-08-29 19:42:29
@_author: listo factor 
@_subject: Servant of Two Masters 
How about we stop considering 'the government' to be an adversary
in a class by itself? From a technical cryptographers' point of
view, there is a user that wants to keep his stored or communicated
data secret, and the adversary that wants to break the secrecy.
It is perfectly normal for a technical professional to offer his
or her services to one or the other, depending on either monetary
consideration or on some ethical, political, or philosophical
criteria. But attempts to be a servant of two masters have resulted
in either catastrophe or a farce so often that not much can be
said about that has been said or written already.

@_date: 2016-02-19 18:54:38
@_author: listo factor 
@_subject: Documentation format 
Whatever you decide to use, I suggest to consider the likely split
between the frequency of electronic vs. paper reading. If I was
doing it, my primary concern would be the ability of the chosen
format to support flexible, "read-time" formating for electronic
displays of both 'pad and desktop monitor size. I also believe
colour has no place in such publications. All just IMHO, and from
someone who does not even remember when he last printed a
computer manual...

@_date: 2016-03-25 20:50:25
@_author: listo factor 
@_subject: EasyGnuPG 
It ~is~ hard, but only when the documentation is written ~after~
the software has been built, based on the functionality definitions
derived from the program itself; instead of being based on a-priory
functionality specifications, that both the program and the
documentation must equally conform to.
But even when that is the case, the documentation is hard to
understand for the user if there is no separate "Concepts and
Facilities" document, one that does not address or even mention
any interface or procedure detail, and unless the user understands
that a firm grasp  of its content is an absolute requirement before
he or she can get to the interface and procedures documentation
(i.e., the "User Manual").
To perform tasks that GPG is designed to accomplish in a safe manner
is *very, very hard*, and even the best documentation could not change that fact. The efforts which concentrate on making it easy might
indeed increase the number of people that use it, but at the expense
of their safety. That, to me, appears to be behind a lot of projects
similar to the one discussed here.

@_date: 2016-03-26 06:51:34
@_author: listo factor 
@_subject: EasyGnuPG 
>> ... The efforts which concentrate on making it easy might
 >> indeed increase the number of people that use it, but at the
 >> expense...
That is, essentially, correct.
Allow me to expand. There are three groups of people whose
interests overlap only partially:
[A] GPG developers
[B] GPG users that "have nothing to hide"
[C] GPG users with secrets that must be protected from active
     and capable adversaries
This mailing list (and specifically, the project that is the subject
of this thread), appears to be dedicated to increasing the size of
[B] for the benefit of [A]. I wish both [A] and [B] well, but I am
concerned here with [C], who would indeed be much better off by not
using GPG at all, than by using it with insufficient understanding,
competence and prudence.

@_date: 2016-03-30 12:16:11
@_author: listo factor 
@_subject: What am I missing? 
I do not use this device, so I am wondering if those that are
familiar with it may be kind enough to confirm my understanding
of its security architecture:
The device uses a protected hardware module, which does several
1) It uses it's own secret, etched in silicone, in combination
with a user-supplied secret to generate symmetric encryption key.
2) It never exports either it's own secret or the generated key,
instead it performs all encryption/decryption operations on the
blocks that the general-purpose processor provides to it and
receives from it.
3) It only executes the code signed by a private key for which
it holds a corresponding public key.
4) In order to make brute-forcing of user secret impractical,
it delays successive key-generation requests and erases it's
own secret after a small number of unsuccessful attempts.
All of this is done in order to make it possible for the
majority of device users to opt for the convenience of an
extremely low-entropy user secret (only 4 digits?). However,
there is nothing to prevent the user to opt for a pass-phrase
of such length that brute-forcing it would be impossible, even
on hardware that has no restrictions built into it.
If this is all essentially correct, someone who knows that
the content of his device-at-rest is extremely valuable to an
attacker would surely use a pass-phrase of adequate length, and
thus make a potential cooperation from the device builder to
his adversary inconsequential.
What am I missing in this whole case?

@_date: 2016-03-31 01:41:06
@_author: listo factor 
@_subject: What am I missing? (Again) 
> I do not use this device, so I am wondering...
There was a quite a few posts following my question, but
unfortunately those quickly drifted off to the aspects of this
case (good/bad government(s), compelling rich/poor vendor(s)...)
that are of no interest to me, and also clearly OT for this list,
and none provided the answer.
Let me condense and try again:
1) Is it correct that this particular device maker designed a
sophisticated hardware-based system with the specific purpose of
thwarting the brute-forcing of ridiculously low-entropy user's
2) Is it possible for the user to circumvent the potential problem
of the device maker cooperating with his adversary to by-pass this
protection, simply by using a pass-phrase of an appropriate length?
Is anybody on this list user/owner of this device? (as I am not).
Can anybody answer (1) and/or (2) with "yes" or "no"? I really
would like to know the answer...

@_date: 2016-11-13 08:30:24
@_author: listo factor 
@_subject: No "evidence" is possible 
It can not.
Even if it was possible to obtain conclusive evidence that
currently installed OS components on some computer do not send
some particular segment of user's data back to the OS vendor,
any new update of the operating system, done automatically,
without continued exhaustive examination of its internals
by the user, could change things and invalidate the "evidence".
Even on Linux systems, there is not much security that can
be guaranteed by any program running on a network-connected
Even if GnuPG encryption and decryption is performed on a
stand-alone computer and transfered for communication to a
networked computer via a memory device, only the content of
the message would be protected. All other data, specifically
a complete network of who communicates with whom, when and
where, is completely open to an adversary. In almost all
real-life threat models, this data is just as sensitive as
is the content of the message.
All of the above is not explained sufficiently well to a
non-technical users. This hardly matters to those that use
GnuPG simply because they believe all e-mail should be
encrypted for philosophical reasons, but can have dire
consequences for those that use the program when they have
a real need for robust protection of their communication.

@_date: 2016-10-28 11:50:48
@_author: listo factor 
@_subject: self-decrypting message 
An e-mail message is just a piece of data; it is always a
computer program (i.e., a piece of software, not data) that
performs either encryption or decryption. It is therefore
not possible to construct a message that would somehow
"decrypt itself" upon arrival on ~any~ computer, but it is
possible to set up a program on a specific recipient's
computer to do that. Details would depend on the nature
of recipient's computer and software - specifically the
e-mail client program - used on it. This would of course
only make sense if the attacker has absolutely no access
to recipient's computer, not even via the network.

@_date: 2017-04-22 07:34:53
@_author: listo factor 
@_subject: "general purpose OS is fundamentally inadequate for trusted 
The year is 2017 and this is simply no longer a practical strategy:
"...Our position is that the general purpose operating system is fundamentally inadequate for trusted operations. One can have a
general purpose system or a trusted system, but one can't get both
in a single package. So one needs two..."
Quoted from an almost 10 year old paper "Choose the Red Pill and
the Blue Pill" by Ben Laurie and Abe Singer. Full paper pdf can
be found on the 'net. It's more than worth reading the whole text.
Smart card is not the device authors discuss in that paper, but
it is a small, evolutionary step toward it. It is the best that
many users who agree with the quoted sentence have at their
disposal at the moment. It might not prevent all imaginable
attacks, but it could prevent enough of those to make it worth
Use of smart card is an operational complication, and it does
present a "barrier to entry". Consequently, the promotion of it's
use is frowned upon primarily by those that are more interested
in spreading the use of gpg for philosophical and political
reasons among those that don't have any real adversaries, rather
than in the protection - however imperfect - of those that have
real need for communication security.

@_date: 2017-04-23 08:32:14
@_author: listo factor 
@_subject: yes, Virginia... 
No, this is not what I'm saying...
When asked, I simply repeat that I completely agree with the above
quoted "Laurie/Singer proposition". For those that agree, the
practical (but not effortless) options are:
a) Simulate their "Nebuchadnezzar device" on an air-gapped general
purpose computer with a general-purpose OS, equipped with crypto software, that never connects to the Internet.
b) Set up their primary general purpose computer as a dual boot
machine, with the trusted OS that does not include access to the
network hardware, that can read the data extents of the connected OS,
and that is regularly refreshed from a verified static system image.
c) Smart card can be, in some marginal instances, only "better than
nothing". Tea-spoon better.
I also tell them that using encrypted mail on an Internet connected
general purpose OS computer is good for practice and "fun factor",
but not much else.
Finally, I completely agree that it would be irresponsible to say
to those with real need for communication security, that simply using
a Smartcard will increase their general security level. However,
vague statements to the effect that "yes, Virginia, you can preserve
the security of your endpoint system" are not any better.

@_date: 2017-04-24 07:50:15
@_author: listo factor 
@_subject: "general purpose OS is fundamentally inadequate for trusted 
> ascribing to them...
The central argument I've been making in this thread is not the
promotion of smartcards, it is something best summarized by
the quote from the Laurie-Singer paper: "...the general purpose
operating system is fundamentally inadequate for trusted
operations." The problem has grown immensely since that paper
was written, so that today *it affects the average gpg user*.
The use of smartcards is to me only a welcome sign that a
growing segment of gpg users appears to agree with that
proposition. They should be helped and advised how to better
tackle the problem, instead of being told that the problem
exists only for those that face some arcane class of
adversaries with mythical powers.

@_date: 2017-06-16 06:17:06
@_author: listo factor 
@_subject: Key expiration question 
There is nothing ~in the key itself~ that prevents any key
from being used to create signatures, it is only a feature of
the software used to create the signature to compare a date in
the key with some arbitrary external information (computer
system date) that may or may not observe such limitation.
The key expiration date should therefore be considered a only
~suggestion~, and not a ~limitation~ for creating or not
creating signatures.

@_date: 2017-05-29 18:58:11
@_author: listo factor 
@_subject: Don't send encrypted messages to random users 
This I find surprising: if one does not want receiving
encrypted messages from those that he does not have
existing relationship with, why does he publish his
public key on public keyservers?

@_date: 2017-05-30 15:53:44
@_author: listo factor 
@_subject: Don't send encrypted messages to random users 
Keservers have every characteristic of a public directory.
What possible reason there could be for placing one's
e-mail in the public key if not to make it possible
for anyone to send an e-mail to the owner. To make
a piece of information publicly available on the net
and then depend on "netiquette" for that piece of
information not be used in a manner the owner finds
objectionable strikes me as a rather outdated notion.

@_date: 2017-11-07 14:58:49
@_author: listo factor 
@_subject: New smart card / token alternative 
>
This is a mantra from another, more gentle time.
Today, there is a whole class of real-world use cases where the
protection of the user demands that it not be known to the adversary
he or she is communicating with someone, as much - or even more -
than it is required that the content of the communication is kept
confidential. If the connection between the user and the computer
is transient, there may well be many instances where the adversary
will not be able to identify the user, even if he manages to learn
the content, and where the content, without the identity of the
communicator, is of very limited value to the adversary.
It therefore appears to me this is a worthwhile project, provided,
like always, *and for any crypto*, the user understands his or her
threat model.

@_date: 2017-11-08 23:39:06
@_author: listo factor 
@_subject: New smart card / token alternative 
there are many real-world use cases where the recipient does not mind
that an adversary knows he is receiving encrypted communication, as
long as the content is secure, but where the sender can be exposed
to various levels of unpleasantness if the adversary can find out
he is communicating with a specific recipient, using encryption.
The ownership of a device such as one discussed in this thread is
trivial to conceal, especially when compared to a computer equipped
to participate in encrypted communications.
Real-life threat-models are much more varied than what Alice, Bob
and Eve would have us believe.

@_date: 2017-10-09 18:05:20
@_author: listo factor 
@_subject: Safe transfer via USB devices 
Use a USB floppy disk reader/writer and shred the floppies with cleartext after the use. Writing sensitive cleartext to USB flash "drives" that could potentially fall into the adversary's hands should be avoided.

@_date: 2017-10-10 06:41:08
@_author: listo factor 
@_subject: Attack costs 
Well, here goes:
A competent adversary can spend $100K to develop and deploy a software tool that will compromise computers of one thousand of its opponents. Thus the cost per compromised computer is $100.- If it costs $1000.- per opponent to send an operative (or, more likely, a team of operatives) to physically enter the computer location in order to compromise it, the total cost to the attacker is one million.
The numbers are, obviously, for illustrative purposes only. But my thoughts is this: when it comes to mass surveillance, over-the-net attacks may indeed be of significantly greater concern than physical (Another, perhaps tangential, thought: in the era of mass surveillance, money is the principal limiting factor for a whole class of large institutional attackers - both ethical and legal limitations are long gone).

@_date: 2017-10-16 06:09:59
@_author: listo factor 
@_subject: Key Storage Abstraction? 
> ...I'd like to actually access GPG*as*  a library, but all the tools I see seem to invoke GPG as a program and then operate on its standard What you need is GPG as a pure crypto-engine; completely divorced from all key management and user interface functionality, so that both of these tasks can be performed by applications that are tailored to meet specific user population operational requirements.
This ("GPG crypto-engine" ?) would be a software package of significant general utility.
In addition to the requirements you outlined, I would add one more: it should abandon all attempts to protect the secrets (private key or plaintext) from other users and processes running on the computer on which it is running, and it should sacrifice the execution efficiency whenever it significantly impacts the code. This would reduce the complexity of the code, so that it could be more easily audited and made platform independent. Ideally, it would be a BSD or similarly licensed, so that it could be included in source form into applications such as yours.

@_date: 2018-01-15 20:25:22
@_author: listo factor 
@_subject: a step in the right direction 
Which would be step in the right direction when compared
with the current situation.

@_date: 2018-01-16 01:02:11
@_author: listo factor 
@_subject: a step in the right direction 
..> First, people in bad places like Syria and Iran lose the ability to...
I would never allow my opinion of what are the "good places" and what
are the "bad places" to enter into a technical discussion.
(On immigration, or on security engineering).
Burning it down is not what I was advocating. I am advocating orderly
evacuation and replacement of a system that has clearly outlived its
usefulnesses. If it is not replaced in time, it will, at some point,
burn ignited by forces we have no control over. ~Then~ it will have
to be abandoned in rather more painful manner - just as you are
alluding to.
EU legislation, among other things, will see to that. The times are changing, and nobody is free to keep serving publicly someone else's
private information over the objections of the owner. "This is the
way we always did it" is a poor response and it will not be a valid
one forever.

@_date: 2018-01-16 03:24:33
@_author: listo factor 
@_subject: a step in the right direction 
Considering the possibility that this particular system will
be forced to conform to a more contemporary (and I would argue
more enlightened) legislative framework in respect to the right to
privacy (cf., should not be viewed as "discussing a [...] nightmare scenario",
it should be considered as planning for demands that will be placed
on the system by developments outside of it, i.e., by developments
of the society that the system is supposed to serve.
If there is merit to the principle that an Internet server operator
can not keep publicly serving private data over the objections of
the owner (the same as today, after many battles, he can no longer
publicly serve data of commercial value over the objections of its
owner), then it is not unreasonable to assume that most enlightened
jurisdictions will sooner or later enact such legislation. Yes, it
is DRM, but in my view ethically much more justifiable than DRM over
the data of commercial value.
The fact that one large jurisdiction is well on its way with
enacting this, while another is not there yet, should be viewed
as a fortunate circumstance, one that buys us time to do what needs
to be done, not as an excuse to bury our heads in the sand.

@_date: 2018-01-17 02:47:16
@_author: listo factor 
@_subject: Privacy vs. security 
Somewhat of a generalization, but essentially correct. More
precisely - if I may - it's point of balance between the privacy
and security represents our thinking about the relative importance
of these two categories at the time the system was conceived,
decades ago.
Since that time, our view about the importance of security has
changed very little. Our view about the importance and desirability
of privacy has changed a whole lot.
Consequently, it is time to re-examine the point of balance
between the two.

@_date: 2019-07-06 12:06:35
@_author: Listo Factor 
@_subject: robots.txt and archiveteam.org... 
On 7/5/19 10:13 AM, Wiktor Kwapisiewicz via Gnupg-users - Thanks for posting the link. To quote from the text there:
 > What this situation does, in fact, is cause many more problems than it solves - catastrophic failures on a website are ensured total destruction with the addition of ROBOTS.TXT. Modifications, poor choices in URL transition, and all other sorts of management work can lead to a loss of historically important and relevant data. Unchecked, and left alone, the ROBOTS.TXT file ensures no mirroring or reference for items that may have general use and meaning beyond the website's context.
  This is both stupid and arrogant. It is precisely the owner of the
website and data contain therein to decide what is and what isn't of
"general use and meaning beyond the website's context", not of some aggregator/archiver's management.
GDPR has indeed changed the nature of Internet forever, and it is for
the better. If Google was put in its place (well, at least first steps
have been made..) by the EU, surely it will be possible to force other,
lesser operators of "archived information" to toe the line. Among other,
to respect the straight and simple Robot Exclusion Protocol. It is not
at all something difficult to do.

@_date: 2019-07-07 12:31:32
@_author: Listo Factor 
@_subject: robots.txt and archiveteam.org... 
As any law or regulation, it has undeniable and numerous detrimental
side effects, which I fully acknowledge. But it establishes an
important principle, completely new to the Internet (and thus often
very irritating to those that are forced to change their MO):
*An individual has the right* to demand that his personally
identifiable information be removed from some specific public
information source, *even if*, at some previous time, in his
ignorance or naivete, he himself made that information publicly
The GDPR as a solution is neither perfect nor without warts, but
our agreement or disagreement with this principle - in my humble
observation - determines how harsh we judge its warts.

@_date: 2020-05-10 03:35:10
@_author: LisToFacTor 
@_subject: Maximum keypair length... 
It is actually an interesting contemporary phenomenon: there
are quite a few instances I've encountered, where the threat
model is never properly defined, and therefore the cryptography
system architecture is not what fits any particular threat
model, and where public key crypto is used where the "common",
symmetrical crypto would do the trick quite nicely.
It is my theory that this is happening with such surprising
regularity because too many system architects view GPG as a
"magic box", without even understanding that in reality it
is only a public key crypto "wrapper" around the conventional,
symmetric crypto hiding inside. In other words, symmetric
crypto is *always used* by their system, if the wrapper
around it is used in addition, there better be a justifiable
reason for it.

@_date: 2020-05-12 09:46:13
@_author: LisToFacTor 
@_subject: Fwd: The GnuPR FAQ 
In order to discuss the feasibility of brute forcing a set of a few random dictionary words, we would have to agree on a few numbers:
1) how many words in the passphrase
2) how many words in a dictionary
3) how many dictionaries
4) how many slightly different forms can average word of the
    dictionary take due to the declension, conjugation and
    noun/adjective gender matching.
This happens to be an English-only language mailing list, but very few
users of this program speak (only) English. It always surprises me how
contributors native-language-centric some Internet discussions on a
technical subject that transgresses language borders are.
Overall, the original suggestion in the FAQ is perfectly valid, and all
I would add is point out the benefit of (3) and (4) above.

@_date: 2020-05-20 16:03:53
@_author: LisToFacTor 
@_subject: "just invent something..." 
Demanding a piece of information from someone who would prefer not
to give it is equally user-hostile, especially so if he who demands
it does so only because it is required by some internal mechanics
of the system he constructed. Answering user's objection to such
request by telling him: "well, if you don't want to give me this
information, just invent something..." is wrong on so many levels
that I feel no need to get into.

@_date: 2020-05-20 22:14:40
@_author: LisToFacTor 
@_subject: "just invent something..." 
English is not my native tongue, and the word I've chosen is based
on my interpretation of the dialog presented by the program when
generating the key:
used the term in one of the previous posts) just can't even
upon entering an empty string, the response is:
(and the program quits with no further explanation)
To me, this appears to qualify as a demand for user's "Real name".
It is not up to a program designer to decide that it is mandatory for
a user to provide a piece of personally identifiable information
because "this is for the benefit of your correspondents, since using different IDs will likely cause confusion."  User is the one to decide what personally identifiable information to provide, when and to whom.
And if the is demand for such information is refused, and the service
is summarily denied, (as outlined above) then it is not okay for the
program designer to wash his hands with "...so why didn't you just
invent something...".
Of course, it would be a one-minute job to change the prompt to
"enter a ?real name? of some kind..." (or something to that effect,
better formulated). But with that, the whole "Web of Trust" structure
would collapse, and that is something to horrible to even

@_date: 2020-05-21 13:34:48
@_author: LisToFacTor 
@_subject: "just invent something..." 
You are correct, the e-mail address was likewise an empty string.
First, let me mention that Web of Trust is to me not a useful public
key verification mechanism, as it is compromises my privacy. I use
other methods to make it possible for my correspondents to verify
the key.
I do not have a/one e-mail address either. At any point in time,
I might be using any number of addresses, depending on who I'm
communicating with, and none of those addresses is likely to
remain in use as long as the key I am generating. None of such
e-mail correspondents would have any idea whatsoever what to do
with a gpg-encrypted message received from me anyways. On the
other hand, for the exchange of personal and confidential messages,
I do not use the "conventional" e-mail at all - the encrypted
text is exchanged by other means, of which there are myriad.
I do know I could have given my name as "Peter P. Pumpkineater"
and the e-mail address as "peter.p.pumpkineater at example.com"
and the program would generate the key-pair for me. But the
question begs: is inventing false information the proper way
of preventing the leakage of personally identifiable information,
completely unnecessarily, via programs constructed by system
architects whose thinking about the privacy is stuck in the time
long behind us?
The proper thing for gpg program to do would be to allow the
personally identifiable information in the key to be optional,
and to warn the user generating such key that he will not be able
to participate in the Web of Trust. Wouldn't that be a better
system design than demanding the user to provide the false
information and treating such information as valid? Especially
as one would not be able to participate in the Web of Trust as
"Peter P. Pumpkineater", but there is no way for a program to
issue any warning for that?

@_date: 2020-05-22 22:18:10
@_author: LisToFacTor 
@_subject: "just invent something..." 
Hi and thanks for the reply. Salsa is cooking. And since you
are so kind:
It would help a whole lot if GPG included some authoritative
documentation on how to use the program in the following scenario:
- The trust in the correspondent's public key is established only
by comparing the key fingerprint derived programmatically from the
locally stored key-file and a copy independently obtained from
the owner. The only identification of a public key is its fingerprint.
Since the public key is either known to an adversary, or it is very
hard to guard against such eventuality, the public key itself should
not provide the adversary with any useful information.
- All gpg operations (key generation, encryption, decryption) are
carried out on a device not connected to the Internet.
- There is no e-mail. (It's not just "resting", it is DEAD).
It would really, really help.
Out-of-channel fingerprint dissemination and exchange of ciphertext
without the benefit of the e-mail system has been dealt with, so
there is no need at all to address that.

@_date: 2020-05-24 15:26:11
@_author: LisToFacTor 
@_subject: "just invent something..." 
I maintain two short internal documents on "WOT-less" and
"e-mail-less" off-line gpg use: one can be thought as "tutorial"
the other as "reference". When I get some free time I'll merge
them, remove group-specific stuff and post in a new thread.
Would that be okay?
Would that be worthwhile?

@_date: 2020-05-29 15:39:50
@_author: LisToFacTor 
@_subject: gpgAnon, draft 20150 
The setup described in this "how-to" was originally put together
and used (and possibly still is) quite a while ago, using
Disastry's  PGP 2.6.3ia-multi06 as the crypto back end.
This guide has been composed from bits and pieces of the original
user documentation, scissoring out the content that it refers to
vaguely as "group policies". Other than that, the only substantial
change is the replacement of pgp 2.6.3ia-multi06 with gpg 1.4.10
(or later).
Technical testing of the described setup with the new crypto back
end is underway.
Any comments and criticism, of whatever kind, is welcome, if it
implies the permission to incorporate it into the final version
of the document.
Available to first one hundred downloads at:

@_date: 2020-05-29 18:12:47
@_author: LisToFacTor 
@_subject: gpgAnon, draft 20150 
Live-CD is a "public resource", available from multiple locations on
the 'net and off, simply discarded when not practical to protect.
Anybody can download, burn and give her a copy. On first use, checked
sudo cat /dev/cdrom | shasum -
While noting on the CD is a secret, it is quite unlikely an adversary
can modify it without being detected.
USB hygiene is always a problem. Small devices and frequent hardware cycling on the trusted device with two USB ports is helpful:
dd if=/dev/sdb of=/dev/sdc bs=10M
(with subsequent cat ... | shasum - thrown in for good measure)
