
@_date: 2010-03-04 18:48:46
@_author: erythrocyte 
@_subject: Changing & verifying the --max-cert-depth in Windows 
I have installed the CLI version of GPG.
I understand that GPG options have to be set in a configuration file.
The configuration file can be created if it doesn't exist as per a
previous thread here
         I added the following line in my gpg.conf :
        max-cert-depth 3
And then ran:
        gpg --update-trustdb
And then:
       gpg --check-trustdb
And here's the output of the last command:
      gpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model
      gpg: depth: 0  valid:   1  signed:   0  trust: 0-, 0q, 0n, 0m, 0f, 1u
      gpg: next trustdb check due at 2011-03-03
It mentions that the --marginals-needed option is set to 3. And
--completes-needed option is set to 1. Which I think I'm okay with.
But the depth mentioned is 0!
Why hasn't it changed? And how do I verify my current --max-cert-depth value?

@_date: 2010-03-04 23:44:36
@_author: erythrocyte 
@_subject: Changing & verifying the --max-cert-depth in Windows 
Thanks! That makes perfect sense :) .
Thanks for the explanation. I think some bits of this can to be added to
the GnuPG Handbook. The section on web of trusts lacks some much needed
Going over what you said, I think I'll be happy with a --max-cert-depth
of 2 :) .

@_date: 2010-03-11 13:59:15
@_author: erythrocyte 
@_subject: Off-The-Record Email 
I'm a user of Pidgin with the off-the-record plugin:
      Is there a way to be able to have off-the-record email conversations
with GPG technology? It would definitely be a terrific thing. Email is
traditionally supposed to mirror paper mail and paper mail is usually
not thought of as being off-the-record, so I guess that's probably why
no one really thinks about it.
But if the technology exists, it would be fantastic to have OTR email
conversations every now and then.
I came across some interesting articles and papers worth checking
    but nothing out there for users to be able to use.

@_date: 2010-03-11 14:09:33
@_author: erythrocyte 
@_subject: Implications Of The Recent RSA Vulnerability 
With the recent news of researchers being able to crack 1024-bit RSA
keys using power fluctuations, I was wondering if it would be a good
idea to switch the RSA keys I have to some other algorithm. Both my
signing and encryption keys are 4096-bit keys. Am I vulnerable to this
security hole?
Is it possible to generate a new keypair and retain/transfer the old
signatures from my email buddies?

@_date: 2010-03-11 13:50:08
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
I'm a user of Pidgin with the off-the-record plugin:
      In order to use GPG based email encryption properly, it's important for
users to authenticate with each other and verify that the public keys
downloaded from the keyservers have fingerprints that match the ones on
their respective computers. Typically the securest way to crosscheck
fingerprints is via a secure channel such as an in-person meeting. But a
phone call comes pretty close too (assuming the fact that it would be
difficult to mount a voice man-in-the-middle attack).
But what if there was no way to meet in person, make a phone call or a
VoIP call. I was wondering if using Pidgin with the OTR plugin (and
authenticating the OTR session using the Q&A method; see above link)
could be considered a secure channel to exchange and crosscheck GPG key
fingerprints in such a case.
Any thoughts?

@_date: 2010-03-11 21:03:37
@_author: erythrocyte 
@_subject: Implications Of The Recent RSA Vulnerability 
Alrighty. But doesn't this compromise the layer of security offered by
the passphrase? What's the point having a passphrase at all, if it's so
easy to compromise a private key?

@_date: 2010-03-11 21:21:05
@_author: erythrocyte 
@_subject: Implications Of The Recent RSA Vulnerability 
How very eloquently put :-) . Makes sense. Thanks :-) .

@_date: 2010-03-11 21:22:21
@_author: erythrocyte 
@_subject: Implications Of The Recent RSA Vulnerability 
ith an error. Thanks for the explanation. Makes sense :-) .

@_date: 2010-03-12 13:06:46
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
Hmmm...if I understand it correctly, if and when the OTR session is
fully verified/authenticated it doesn't matter what the content of the
data you transmit is. It could be any of the above - fruit cake recipes,
financial data, et al.
I don't think OTR technology can claim to solve the gun-to-the-head
scenario. Although it claims to give users the benefit of
perfect-forward-secrecy and repudiation, I think such things matter
little in a court of law. People get convicted either wrongly or
rightly, based on spoofed emails and plain-text emails all the time.
I think the same goes for GPG based email encryption as well.
GPG-encryption doesn't protect end-points. It only protects the channel
between them. The more end-points there are, the more vulnerable such
encrypted emails become.
The only scenario I see that minimizes end-point vulnerability is to
encrypt data to oneself. One end-point, one source of potential
compromise. Even that is susceptible to a rubber hose attack. In some
countries people are required to decrypt data if asked by law
enforcement and refusal to comply means jail time.
Bottom-line IMHO, you can't let out your inner demons just because
there's encryption technology. That isn't what it was built for afaik.
The safest possible place for data to reside in is within the confines
of one's own brain.
So I envision myself using OTR-based-IM and GPG-based-email-encryption
only with a prior understanding of these deficiencies. If I'm confident
enough that the end-points are secure during an OTR-IM session that has
then been authenticated, can I use such an IM session to exchange and
crosscheck my friend's GPG public key fingerprint that I've downloaded
from a keyserver for email encryption purposes?
PS: Despite the much hyped security behind SSL based websites such as
online banking, if you care to look around you'll soon realize that even
that isn't as bullet-proof as one would like to think. There have been
instances where unscrupulous people have gotten digitally signed
certificates from TTPs/CAs (reputed ones I might add) for businesses
that don't exist, etc. And with companies like Thawte that besides their
traditional for-profit CA business model, also provide individual users
free SSL certificates using email-based authentication, a lay person who
doesn't recognize the different kinds of Thawte certificates could as
well trust that a given bank website is genuine when in fact it might be
a fraud.
All in all, encryption isn't the panacea that we'd like it to be. At
least not yet. There are multiple attack vectors that crop up all the
time - from social engineering to mathematical/technological.

@_date: 2010-03-12 18:16:28
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
Umm I'm not an expert or anything but I think it really depends on where
you live. If you belong to a minority people susceptible to persecution
by a state agency, then yea sure there are many records of wrongful
detention and arbitrary human rights abuses based on false pretenses.
Even if those pretenses are 'cooked up', or 'spoofed'. Amnesty
International and Human Rights Watch are sites worth checking out for
information on this. It's difficult to achieve immunity from a rogue
state agency. Technology and encryption isn't the way to stop these
kinds of things. In some cases it might help, but only up to a point. I
think Bruce Schneier is right when he says that what are needed instead
are laws and legal mechanisms for protection of human rights and civil
liberties. See Schneier's talk, "Future of Privacy":
Interesting question. I think OTR is a great theoretical concept. I just
ignore the PFS/R part when using it. PFS/R might be effective if you're
potentially up against a rogue employer, etc. but it's got its
limitations when it comes to dealing with agencies of the State IMHO.
Same goes for Plausible Deniability, etc. This is what Bruce Schneier
noted in an article from 2008 on PD BTW:
    "*So we cannot break the deniability feature in TrueCrypt 6.0. But*,
    *honestly, I wouldn't trust it* ".
     If you really think about it, when you look at people who've gotten
convicted and/or framed based on plain text unsigned email, then it goes
to show that there's no point in inventing a technology that
specifically provides PD from a cryptographic perspective, because
unsigned email is already plausibly deniable. Yet juries & courts
regularly convict people despite their best efforts to claim innocence,
Who's to say what a regular Joe jury would think of about such things.
The fact is that we're living in an era when the vast majority of people
use technology without really understanding the nuances that underlie it.
Second, even with PD encryption technologies such as Truecrypt, it's
easy to look at the problem from a law enforcement officer's
perspective. Compel the individual to lie to a question. Compel him to
take a polygraph on his statement. And then convict him based on a
polygraph. Add in rubber hose attack techniques to the mix and it could
get worse...
Thanks :-) . I'll try and take a look.
PS: On that last point on SSL pitfalls I mentioned in my earlier email a
couple of additional points that I thought would be good to understand.
All it takes is for one CA to be compromised (a rogue element within the
CA perhaps, etc. ) and the entire system comes crumbling down. Also, a
typical browser such as
Firefox will have almost 200 root certificates from various CAs. Each of
these adds a given amount of risk, that really should be made
transparent to end-users IMHO. Some belong to well known CAs, while
others belong to less reputable ones. Plus some CAs will still use
outdated hash algorithms to sign certificates. This has allowed people
in some cases to generate fake certificates and spoof well known
websites. I learned about this last point from a Security Now episode.
BTW Schneier did a nice interview discussing some SSL pitfalls here
 .

@_date: 2010-03-13 03:34:59
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
Sure, that is such a valid point. I'm a completely new user to GPG, so
do pardon some of my ruminations :-) . I realize they might not be
completely correct.
I guess what I'm trying to say here is that because regular people don't
understand what spoofing actually is, that by itself is a security hole.
The only way to correct something like that is to educate people and to
educate oneself. I also think the word 'spoofing' could apply not just
to emails, but to other things such as forging real-life identities such
as passports, etc as well. There's no way I could be trained enough to
recognize spoofing of the latter kind even at a keysigning party. So as
I begin to use GPG, I'm becoming more and more aware of the limitations
that one has to come across - be they technological or social.
I actually use Pidgin OTR because
    a. it gives me the PFS/R option if and when I do think that might
       help (realizing its limitations nevertheless).
    b. I just think the ease with which users can authenticate makes it
       a good choice. The secret answer method of authenticating is
       easy for most of my friends to understand.
Well, I do think that's such a relative thing. Just because you don't
notice these kinds of things going on in the place where you live
doesn't mean they don't happen. How many people actually bother to look?
I guess what I'm saying here is that human rights abuses can occur
anywhere and everywhere.
I think that that makes perfect sense. :-)

@_date: 2010-03-13 03:48:44
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
I guess you could think of it that way. I guess what I'm trying to say
is that there might be instances where your security requirements aren't
in line with what your browser already trusts. And there has to be a
method to improve that and make it more "clear" / "transparent" / etc.
Again 'repute' in this context is relative. People's gold-standards can
vary. I might be comfortable in trusting CA-A because they've actually
never ever screwed up in the past, while I wouldn't feel the same way
with CA-B because they actually have. It all goes back to how you define
your security requirements. Steve Gibson on his podcast, Security Now,
once talked about how a certificate from a well known CA was spoofed
because of a weak hash algorithm that was used in signing.

@_date: 2010-03-13 03:38:10
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key 
That actually got me thinking. Aren't keysigning parties based on that
model anyway?
You have an existing credential - a passport.
You then use that credential to verify another - a PGP key.

@_date: 2010-03-13 12:36:47
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key  
I'm a little confused as to how does that make it any different from using
the Pidgin OTR method.
I simply open up an OTR session, ask my friend a question the answer to
which is secret (only known to him) and thereby authenticate that it is in
fact him that I'm talking to. Next, over this secure connection, we exchange
our email-encryption key fingerprints and verify them and then sign them, in
effect stating like you mentioned: "Yes, I believe this person is associated
with this OpenPGP key."

@_date: 2010-03-13 12:44:59
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key  
The reason I think that it's still difficult is because even immigration
officials get duped all the time.
Okay. What weakness(es) do I need to be wary of?
Pardon me for being skeptical about all of that. I realize that this is a
controversial issue and I'm respectful of what you believe.

@_date: 2010-03-13 16:36:52
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key  
Thanks for the explanation.  Makes sense :-) . I think I understand the
pitfalls much better now.

@_date: 2010-03-13 17:38:30
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key  
It really depends on how you're calculating combined probability. If you
take an example of 4 individuals at a keysigning party,
The combined probability that all individuals would accept a fake ID would
be 1/4 * 1/4 * 1/4 * 1/4 = 0.00390625 .
However, the combined probability that at least one of the encounters would
result in accepting a fake ID would be 1/4 + 1/4 + 1/4 + 1/4  = 1 .
Please do correct me if I've made a mistake. I'm not a math guru by any
But all that aside, I'm pretty sure news reports, etc. of human traffickers,
smugglers, spies, etc. all confirm the fact that national IDs such as
passports can be forged and do in fact slip by immigration authorities
pretty commonly.
I think I've gotten the answer to the question in thread. Thanks.

@_date: 2010-03-13 18:31:39
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key  
2010/3/13 Ingo Kl?cker Ah yes. That makes sense :-) . Thank you.

@_date: 2010-03-14 06:36:04
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key  
Alrighty... :-) . So the combined probability that there would be >= 1
failures would be 68.4% .
Umm.. if I understand the nature of the probability tests or
calculations just mentioned above, the results have to be accepted as
they are. They either got it wrong or right. Those individuals who got
it wrong might have actually had that thought, "hey, that's weird",
but eventually they did go ahead and make that wrong decision. I'm
just recollecting some probability concepts and hypothesis testing
concepts I learned a long time ago.
And besides, even if the above weren't true, how do I know that
someone who does have that thought will make sure to check with others
at the keysigning party?
I guess depending on one's security policy or requirements that's a
pretty weighty assumption to make.
Also, there's a difference between deciding a stranger's identity
solely based on a passport/national ID versus checking his/her ID
_and_ getting to know them a little better. And that decision lies in
the hands of the user. It's a more social issue I guess.
Anyhow, I've learned so much from this great discussion over the past
few days. Let me thank all who've cared to enlighten a new user such
as me about these things. This is definitely a great community! :-)

@_date: 2010-03-14 12:22:23
@_author: erythrocyte 
@_subject: Using the OTR plugin with Pidgin for verifying GPG public key  
Hmmm...I know this is already getting off-topic. But let me qualify
that by saying that it really depends on what error you're calculating
here. From my understanding, the probabilities calculated give you
random error. That is "given a population of 4 people, there is a
68.4% chance that there would >=1 failures purely by random effects
regardless of what actions they may or may not take to influence their
chances of making a mistake" .
These calculations do not give you the effects of systematic error or
bias. Systematic error would be what you're referring to. That can be
The sum error would be a combination of random and systematic error.
Of course, all of this gives us a picture of the average chances of
error. When it comes to individual people, like you and I, we are not
averages. Some of us will be more adept than others at not making
mistakes and that in turn will depend on a whole slew of other
factors. Now all of that should be taken into account when thinking
about one's security policy.
And I might add that all of this also depends on what your perspective
is. I for one did not envision a scenario where Alan and Bill from
your example, would discuss their ruminations with each other. Of
course that might happen. But not necessarily always. That's just
human behavior perhaps.
Or *incompetent*, *stupid*, *lazy*, *not learned*, *unsure*,
*unaware*, etc. It could be any combination of the above :-) .
