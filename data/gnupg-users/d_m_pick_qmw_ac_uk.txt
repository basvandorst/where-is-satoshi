
@_date: 1999-12-01 18:31:41
@_author: David Pick 
@_subject: New UK crypto law and an idea on how to defeat it 
Several comments more-or-less at random:
1) The last time I saw these proposals there were several elements to them:
   1.1) The police would have to obtain a warrent from a magistrate to
        demand these keys; this would be similar to a search warrent.
   1.2) Something not many people know is that any search warrent must
        state the type of crime the police suspect has taken place and
        what section of the appropriate Act of Parliament authorizes the
        granting of the warrent.
   1.3) Someone would only be required under such a warrent to reveal
        keys necessary to enable data to be decrypted; keys used only
        for signatures could not be obtained.
   1.4) The Police and Criminal Evidence Act, 1984 (PACE) already states
        in section 19 subsection 4 that "The constable may require any
        information which is contained in a computer and is accessible
        from the premises (to be searched) to be produced in a form in
        which it can be taken away and in which it is visible and legible
        if he has reasonable grounds for believing--
         (a) that--
              (i)  it is evidence in relation to an offence which he is
                   investigation or any other offence ; or
              (ii) it has been obtained in consequence of the commision
                   of an offence ; and
         (b) that it is necessary to do so in order to prevent it being
             concealed, lost, tampered with or destroyed."
2) The provisions in PACE are getting decidedly impractical given the
   rise in capacities of hard discs since 1984.
3) I think the *intent* of the proposed law is to keep similar levels
   of search available to the Police in environments where data volumes
   and encryption make the existing provisions impractical. Of course,
   we need to keep an eye on things to try and ensure that the proposed
   Act doesn't go too far. But I'm no more paranoid about this proposal
   than I am about the rest of UK law (consider that a classic British
   understatement). I do consider British law a bit intrusive, but don't
   consider the proposals out-of-step with the general tone of UK law.
4) When I first heard of these proposals (10 Nov 1998) I wrote requesting
   thet GPG had the ability to use different passphrases for keys and
   subkeys, so that it would be possible to reveal one without the other.
   This was turned down with the following comment "But please don't ask
   me to do this because I do not want to support such laws even by
   considering how to limit the damage of the secret keys."
5) In the scenario discussed, the imfamous Police Chief would be laying
   himself open to serious complaints if he obtained a warrent by lying
   about his grounds (on oath!) and Bob (once the "evidence" of the love
   letters had been revealed) used the facts to support a complaint that
   the warrent had been obtained illegally.
6) The police do have experts available to them. These exports will
   almost certainly be aware of the characteristics of any released
   software products. This means they will be able to examine an
   encrypted file and the derived cleartext and (knowing the software
   used to produce the file) will be able to measure the proportion
   of the encrypted file used to encode the clear text. This should
   give them a very good clue about the existance of other text(s).
7) The proposal is really an example of steanography; and it would
   probably be better to hide the "love letters", encrypted or
   otherwise, using standard steanographic techniques; the *existance*
   of the hidden text is far less obvious that the technique proposed
   by Adam Lock. All the forensic searches of which I'm aware will
   fail to find them even *without* encryption.

@_date: 1999-12-22 11:01:57
@_author: David Pick 
@_subject: Palmtop crypto 
Depending on what you mean by a "palmtop"...
...there is now a beta release of PGP 2.6.3ia for the Psion Series 5
(and I assume other EPOC32 machines); see:

@_date: 1999-12-01 18:31:41
@_author: David Pick 
@_subject: New UK crypto law and an idea on how to defeat it 
Several comments more-or-less at random:
1) The last time I saw these proposals there were several elements to them:
   1.1) The police would have to obtain a warrent from a magistrate to
        demand these keys; this would be similar to a search warrent.
   1.2) Something not many people know is that any search warrent must
        state the type of crime the police suspect has taken place and
        what section of the appropriate Act of Parliament authorizes the
        granting of the warrent.
   1.3) Someone would only be required under such a warrent to reveal
        keys necessary to enable data to be decrypted; keys used only
        for signatures could not be obtained.
   1.4) The Police and Criminal Evidence Act, 1984 (PACE) already states
        in section 19 subsection 4 that "The constable may require any
        information which is contained in a computer and is accessible
        from the premises (to be searched) to be produced in a form in
        which it can be taken away and in which it is visible and legible
        if he has reasonable grounds for believing--
         (a) that--
              (i)  it is evidence in relation to an offence which he is
                   investigation or any other offence ; or
              (ii) it has been obtained in consequence of the commision
                   of an offence ; and
         (b) that it is necessary to do so in order to prevent it being
             concealed, lost, tampered with or destroyed."
2) The provisions in PACE are getting decidedly impractical given the
   rise in capacities of hard discs since 1984.
3) I think the *intent* of the proposed law is to keep similar levels
   of search available to the Police in environments where data volumes
   and encryption make the existing provisions impractical. Of course,
   we need to keep an eye on things to try and ensure that the proposed
   Act doesn't go too far. But I'm no more paranoid about this proposal
   than I am about the rest of UK law (consider that a classic British
   understatement). I do consider British law a bit intrusive, but don't
   consider the proposals out-of-step with the general tone of UK law.
4) When I first heard of these proposals (10 Nov 1998) I wrote requesting
   thet GPG had the ability to use different passphrases for keys and
   subkeys, so that it would be possible to reveal one without the other.
   This was turned down with the following comment "But please don't ask
   me to do this because I do not want to support such laws even by
   considering how to limit the damage of the secret keys."
5) In the scenario discussed, the imfamous Police Chief would be laying
   himself open to serious complaints if he obtained a warrent by lying
   about his grounds (on oath!) and Bob (once the "evidence" of the love
   letters had been revealed) used the facts to support a complaint that
   the warrent had been obtained illegally.
6) The police do have experts available to them. These exports will
   almost certainly be aware of the characteristics of any released
   software products. This means they will be able to examine an
   encrypted file and the derived cleartext and (knowing the software
   used to produce the file) will be able to measure the proportion
   of the encrypted file used to encode the clear text. This should
   give them a very good clue about the existance of other text(s).
7) The proposal is really an example of steanography; and it would
   probably be better to hide the "love letters", encrypted or
   otherwise, using standard steanographic techniques; the *existance*
   of the hidden text is far less obvious that the technique proposed
   by Adam Lock. All the forensic searches of which I'm aware will
   fail to find them even *without* encryption.

@_date: 1999-12-22 11:01:57
@_author: David Pick 
@_subject: Palmtop crypto 
Depending on what you mean by a "palmtop"...
...there is now a beta release of PGP 2.6.3ia for the Psion Series 5
(and I assume other EPOC32 machines); see:

@_date: 1999-07-28 19:06:22
@_author: David Pick 
@_subject: large pub key import 
*almost* always ;-)
But if a "proper" "port" is made for FreeBSD one of the "standard" options
for such a port is the choice of "make" or "gmake". That might help...

@_date: 1999-07-28 19:06:22
@_author: David Pick 
@_subject: large pub key import 
*almost* always ;-)
But if a "proper" "port" is made for FreeBSD one of the "standard" options
for such a port is the choice of "make" or "gmake". That might help...

@_date: 1999-06-16 18:09:28
@_author: David Pick 
@_subject: How to authenticate permissions of a local user? 
Passphrases are really intended to certify the identity of the user running
the command - and need to be interactive. There *is* an option "--passphrase-fd"
which allows you to specify that the passphrase should be read from that
(numeric) FD, but the documentation *also* says "Don't use this option if
you can avoid it". Since you say you'd put the passphrase in a file only
readably by the SUID script, an alternative would be to use a key *without*
a passphrase stored in a keyring only readable by the SUID script. This is
equivalent in terms of the protection it gives.

@_date: 1999-06-16 18:09:28
@_author: David Pick 
@_subject: How to authenticate permissions of a local user? 
Passphrases are really intended to certify the identity of the user running
the command - and need to be interactive. There *is* an option "--passphrase-fd"
which allows you to specify that the passphrase should be read from that
(numeric) FD, but the documentation *also* says "Don't use this option if
you can avoid it". Since you say you'd put the passphrase in a file only
readably by the SUID script, an alternative would be to use a key *without*
a passphrase stored in a keyring only readable by the SUID script. This is
equivalent in terms of the protection it gives.

@_date: 1999-09-17 11:23:29
@_author: David Pick 
@_subject: trusted keyring storage 
I run FreeBSD on a laptop and just store the secret keys as normal in
the filestore, with no other special precautions. Just the same as my
SSH keys, SSL Certificate Authority keys, &c, &c.
OTOH I *do* take all sorts of precautions over the laptop itself. It's
single-boot into FreeBSD (unless you have a PCCard floppy drive).
There's a BIOS password in use. FreeBSD has the "console" marked as
"insecure" so it won't boot into single-user mode without the "root"
password. *Nobody* else gets to use it. It runs with the bare minimum
of "listening" processes (syslog and SMTP) and these ports are blocked
by kernel packet filters. All other incoming calls are blocked as well
just-in-case. I *never* leave the machine switched on unattended.
No. You can never be too paranoid. I don't consider myself absolutely
safe - it's a matter of risk assessment and balancing the time-and-
effort of increased security against the threat assessment and cost
of damage from a compromise. BTW: that laptop is not running at the
moment - it only gets run when it needs to!

@_date: 1999-09-17 11:23:29
@_author: David Pick 
@_subject: trusted keyring storage 
I run FreeBSD on a laptop and just store the secret keys as normal in
the filestore, with no other special precautions. Just the same as my
SSH keys, SSL Certificate Authority keys, &c, &c.
OTOH I *do* take all sorts of precautions over the laptop itself. It's
single-boot into FreeBSD (unless you have a PCCard floppy drive).
There's a BIOS password in use. FreeBSD has the "console" marked as
"insecure" so it won't boot into single-user mode without the "root"
password. *Nobody* else gets to use it. It runs with the bare minimum
of "listening" processes (syslog and SMTP) and these ports are blocked
by kernel packet filters. All other incoming calls are blocked as well
just-in-case. I *never* leave the machine switched on unattended.
No. You can never be too paranoid. I don't consider myself absolutely
safe - it's a matter of risk assessment and balancing the time-and-
effort of increased security against the threat assessment and cost
of damage from a compromise. BTW: that laptop is not running at the
moment - it only gets run when it needs to!

@_date: 2000-02-04 11:21:41
@_author: David Pick 
@_subject: Setting up gpg on an IRIX web server 
FreeBSD has the identical text in the mlock(3) man page.

@_date: 2000-02-04 17:48:17
@_author: David Pick 
@_subject: Setting up gpg on an IRIX web server 
The man page also stated that the mlock call was introduced in BSD 4.4,
so I guess all systems derived from it probably behave the same.

@_date: 2000-02-04 11:21:41
@_author: David Pick 
@_subject: Setting up gpg on an IRIX web server 
FreeBSD has the identical text in the mlock(3) man page.

@_date: 2000-02-04 17:48:17
@_author: David Pick 
@_subject: Setting up gpg on an IRIX web server 
The man page also stated that the mlock call was introduced in BSD 4.4,
so I guess all systems derived from it probably behave the same.

@_date: 2000-01-27 11:00:06
@_author: David Pick 
@_subject: GnuPG manual doubt 
The private keys are only stored encrypted. The (symmetric) algorithm used
needs (of course) a key. Using the passphrase directly as a key is not a good
idea because too many bits are related to each other other or by the fact
that the passphrase is encoded in ASCII. Therefore a cryptographic "hash"
of the passphrase is used instead to "mix up" the bits in the passphrase
and generate a good key for the actual encryption. The parameter concerned
gives the user a choice of which cryptographic hash function is used for
this process. Another name for the cryptographic "hash" function is a
"message digest" function, especially when it is used in signatures.
This refers to the process of adding some random bits to a passphrase
before computing the cryptographic hash. These bits are stored with
the computed hash. This is done so that the same passphrase, when hashed
by different users, does not produce the same hash value - because the
"salt" is different. It's usually implemented by providing and initial
random value for some variable used iteratively during the computation;
I guess the use of the word "salt" is related to its use in the phrase
"salting a mine" for leaving a little gold behind in an otherwise empty
mine for your "sucker" to find so he thinks he's buying something
valuable from you when he's not.

@_date: 2000-01-27 11:00:06
@_author: David Pick 
@_subject: GnuPG manual doubt 
The private keys are only stored encrypted. The (symmetric) algorithm used
needs (of course) a key. Using the passphrase directly as a key is not a good
idea because too many bits are related to each other other or by the fact
that the passphrase is encoded in ASCII. Therefore a cryptographic "hash"
of the passphrase is used instead to "mix up" the bits in the passphrase
and generate a good key for the actual encryption. The parameter concerned
gives the user a choice of which cryptographic hash function is used for
this process. Another name for the cryptographic "hash" function is a
"message digest" function, especially when it is used in signatures.
This refers to the process of adding some random bits to a passphrase
before computing the cryptographic hash. These bits are stored with
the computed hash. This is done so that the same passphrase, when hashed
by different users, does not produce the same hash value - because the
"salt" is different. It's usually implemented by providing and initial
random value for some variable used iteratively during the computation;
I guess the use of the word "salt" is related to its use in the phrase
"salting a mine" for leaving a little gold behind in an otherwise empty
mine for your "sucker" to find so he thinks he's buying something
valuable from you when he's not.
