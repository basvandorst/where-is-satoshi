
@_date: 2011-10-20 22:25:58
@_author: Matthias-Christian Ott 
@_subject: STEED - Usable end-to-end encryption 
But who are the providers? Except for people who work in computer
science, physics or similar fields I don't know people who run their own
mail servers or are part of a cooperative. Most other people use a
handful of providers who often offer free service in exchange for the
loss of privacy or at least some form of semi-targeted advertisement. Do
you expect those providers to ruin their business models by implementing
this proposal? I wouldn't count on them.
Perhaps the providers could also be forced by law not to implement
this, because (if I remember correctly) come countries require that
they store at least the header information (including subject, which
should also be encryted by the system) for traffic analysis. So in
the worst case the providers couldn't implement this without breaking
the law (I doubt that citizens could use the system without breaking the
law in this situation either, but individuals are often more venturous
than organisations).
What about making everyone their own provider? The efforts in this
direction intiated by Eben Moglen that lead to the FreedomBox and other
projects seem to go in the right direction. It doesn't seem to me less
realistic than requiring cooperation from providers.

@_date: 2011-10-23 18:50:16
@_author: Matthias-Christian Ott 
@_subject: STEED - Usable end-to-end encryption 
I agree, there are other business models and perhaps there will be
demand for this, but I just summarised the service providers almost all
?non-technical? people I communicate with use.
I'm not aware of any overview of e-mail data rentention, so I don't
have complete picture, but a quick search on EU data retention laws
showed that only SMTP envelope data is officially stored, so at least
in these countries it's not a problem (though I think the subject
should be encrypted as well). Moreover, I agree that as long as the
body and thus the actual contents are not stored there is reason
why a provider could break the law by providing STEED services to
their costumers. Fortunately many countries have laws to garantuee
(at leas in theory) privacy of correspondance and these laws of a
long tradition, so it seems hard to abolish them. However, I see the
possibility that providers could be forced to cooperate with government
agencies, but this would have little impact and would require bigger
efforts to ?break? STEED this way (e.g. MITM attacks by publishing
false keys for new contacts).
I agree, but I also talked to people who don't care about privacy
(nothing to hide) and don't understand it. Therefore, it is important
not to rely on the market to provide the means for private e-mail
communication (do it yourself instead of relying on other people to do
Let's say you had the opportunity to convince a smaller independent
hosting provider that e.g. sells web hosting, e-mail and resells
internet connectivity, how would you do this? There had to be real
demand and easily installable and maintainable software to convince them
to implement STEED.
Recently I did some search and inquiries on DNSSEC, for which there is
argueably real demands from private and enterprise customers and there
is working software, but only relatively few companies worldwide offer
it and I don't expect it to be widely deployed within the next years.
However, people running their own server have it running or at leas
prepared (waiting for the registras to close the trust chain by
submitting their public key to the registry) for some time now.
I agree, but there is a lot to be done. If the technical specification
is done and there is working software, there really hard work just
begins as I tried to demonstrate by taking DNSSEC as an example.

@_date: 2015-02-04 21:44:56
@_author: Matthias-Christian Ott 
@_subject: Talking about Cryptodevices... which one? 
If I remember correctly, that statement refers to speculations about
backdoors that were speculated to be implanted or exploited by
intelligence agencies.
You speculated that Rainer SCT might cooperate with the German
intelligence agency BND. You gave the following reason for your
suspicion: "microcontrollers are smaller and writing malware for them is
harder". You know much better than me that just because a
microcontroller is smaller it doesn't mean that it is hard to exploit it
by uploading modified firmware. In fact the scenario you mentioned,
saving the PIN, could probably be implemented with just a few hundred
additional instructions. Moreover, Rainer SCT is not the only German
vendor that has firmware that can be updated: SCM PC-Card also allows
the firmware of its SPR532 card reader to be updated from the USB host.
You construct the same story for SCM PC-Card and more broadly any other
proprietary hardware or software. There are enough examples of vendors
that introduced government backdoors in their proprietary products to
come to the conclusion that it is probably not a good idea to use
proprietary software or hardware if your threat model includes
government backdoors and you want to defend against them (of course that
doesn't mean that it is impossible to verify that a proprietary product
does not contain a backdoor but it is unarguably a lot harder). So I
don't know how speculating that a particular vendor of proprietary
hardware and software implants backdoors in its products does move the
discussion forward.
I mostly agree with you here and I think what has been revealed over the
last years confirms your statement. But will a smartcard solve the
problem that the host computer might be infected with malware? I don't
think so but invite you to proof me wrong. I think that sandboxing
mechanisms like SELinux, AppArmor, grsecurity, seccomp etc. would help
more to not let the computer become infected in the first place. I would
like to give the following example to prove/illustrate this:
Suppose that your web browser has an exploitable security vulnerability,
you visit a website that manages to execute code on your computer and
that code wants to steal your OpenPGP key. If you would run SELinux and
properly label the .gnupg folder in your home directory and your
system's GnuPG binaries, you could have prevented this attack. Without
SELinux but with a smartcard the exploit code could have controlled the
smartcard even though it might not have the smartcard's PIN and the
attacker would probably be able to do something with the key on the card
next time you want to use it. Moreover, SELinux is just a piece of
software that costs nothing and could be rolled out to millions of
computers over night whereas the smartcard costs money and requires no
additional knowledge (see for example Fedora's default SELinux policy),
whereas equipping and educating millions of users with an OpenPGP
smartcard and a reader is not trivial and inexpensive.
There is probably a lot more to say and to consider about this whole
topic and this topic is most likely also beyond the scope of GnuPG but I
think one can look at the enterprise software market as a good example
that shows why adding hardware to an existing insecure system is not
really effective. At least as far as I know running software like IDS,
DPI firewalls, transparent/intercepting proxies, anti-virus software and
so on does not solve the problem of Microsoft Windows or application
software running on Microsoft Windows being insecure.

@_date: 2015-02-04 23:12:04
@_author: Matthias-Christian Ott 
@_subject: Talking about Cryptodevices... which one? 
You could protect against this scenario by signing the firmware. In some
countries "the government" can legally force the manufacturer to sign
"the government's" firmware.
I didn't make this argument.

@_date: 2015-02-06 01:21:28
@_author: Matthias-Christian Ott 
@_subject: Talking about Cryptodevices... which one? 
Do you have evidence for this? If they provably don't sign their
firmware or incorrectly check the signature and are not responsive,
perhaps it would be helpful to talk to them through third parties like
BSI or S-CERT (Deutscher Sparkassen Verlag exclusively sells Reiner SCT
readers for HBCI and I'm sure that it would be in their interest to only
allow firmware updates that are signed) with Reiner SCT instead of
speculating about backdoors.
Moreover, why should the readers accept unsigned firmware if "the
government" requested the ability to install "modified" firmware? The
manufacturer could simply handover the keys.
At least the cyberJack RFID komfort conforms to BSI-TR 03119 [1,2] and
is in the reader category that requires signed firmware updates (see
sections 3.1 and A.8) and the certification report also mentions this.
You can of course speculate what "authorised persons or systems" means.
However, I think it is safe to assume that the German government is not
outright crazy and does not try to undermine the security of their eID
cards because fake eID cards are not in their interest and they can
issue themselves fake eID cards without the need to compromise a
smartcard reader. So at least for this particular model your statement
seems wrong and the fact that Werner Koch claimed this doesn't make it
Of course without the source code it requires a major reverse
engineering effort to verify that the statements of the certification
companies are correct or that the code is bug-free. Moreover, the
certification report does not mention that the certification companies
verified the source code or even looked at it.
Only Werner Koch knows how this statement was meant. I read it the way I
described it and think that there is no contradiction between both aspects.
Werner Koch suggested it (<87y4oen5lx.fsf at vigenere.g10code.de>).
If I'm not mistaken the OpenPGP card is proprietary software and runs on
a proprietary operating system (BasicCard). If this is true, why should
you trust it and why does the FSFE distribute these cards even though
they conflict with their core values?
What is the threat model in which a smartcard is an effective defense
and what are attacks that smartcards protect against? How are smartcards
supposed to protect against malware on the host computer?
If somebody wants to discuss or answer these questions that I'm asking
myself for years, I will be happy to continue the discussion otherwise
I'm out of it.

@_date: 2015-02-06 15:06:04
@_author: Matthias-Christian Ott 
@_subject: Talking about Cryptodevices... which one? 
If you use Schneier's attack tree for PGP encryption [1] as the threat
model (for the lack of something better), a smartcard would protect
against 1.4.2 ("Get private key from recipient's key ring") and 1.4.3
("Monitor recipient's memory"). But if your goal is 1 ("Read a message
encrypted with PGP") and you have infected the host computer (as you
scenario says) you can't protect against 1.2.1 ("Fool sender into
encrypting message using public key whose private key is known"), 1.2.3
("Monitor sender's computer memory") and 1.2.4 ("Monitor receiver's
computer memory"), any of which suffices to achieve the goal. A similar
argument can be made for digital signatures.
Maybe smartcards can increase the costs of an attack but security
economics are a really dangerous field that equates people to money and
works by the "garbage in garbage out" principle which is also dangerous
if you are non-critical. Peter Gutmann reports in the draft of his book
"Engineering Security" [2] that there is in fact malware that steals
keys and certificates. Perhaps a smartcard could have prevented some
current malware from stealing your keys from the smartcard but stealing
the keys is just a means to an end and the ultimate goal is to either
break confidentiality (decrypt messages) or impersonation (sign messages
of the attackers choice).
Perhaps one can say that smartcards can improve the usability,
especially for average computer users who know how to protect bank cards
and want portable key storage. Perhaps this in itself improves security
because these users would better understand the system. I have setup
some users with smartcards for HBCI banking and noticed that they
applied more "security measures" and caution with the card than logging
into the website of their bank with username and password.
That is definitely a usability advantage, especially if you consider
ransomware that wants to get money from the user for decrypting their
files. However, randsomware could also destroy your smartcard by
entering a wrong PIN and PUK (or whatever they are called) too many times.
I agree. But if your adversary is more powerful than an average
cybercriminal that won't help you either because such adversary could
intercept the communication between smartcard and host computer and
would trick you into performing a key rollover or decrypt or sign other
messages that you did not intend to decrypt or sign. Of course you would
notice this at some point and perhaps notice it more likely with a
smartcard (if you can trust it) than with a key file but if you notice
it, it might be already too late: Imagine for example a journalist
communicating with a source (just too use an example that has been used
too many times ;)) and an adversary who wants to find the source. The
adversary could feed the smartcard a different message that the
journalist wanted to sign and for example sign the message "meet me at t
at l". Instead of the journalist the adversary would wait at l at time t
to arrest the source. Another example would be malware that wants to get
another piece of malware signed (see Gutmann's book for examples) that
infects computer of a software developer or company and instead of
signing the new release of a software it signs a new release that also
contains malware because it is able to control the communication between
host computer and smartcard (this would also work with source code only
releases). You can also see this problem when you look at online
banking. When German banks employed indexed TAN lists there was malware
that simply substituted the recipient fields of wire transfer forms but
displayed the original recipient fields to the user. German banks had to
take the extreme measure of distributing air-gapped devices to their
customers that display the entire contents of the wire transfer form on
their tiny screen to prevent this attack (this doesn't help if the
attacker also manipulates the bill that you received via email and want
to pay). For OpenPGP this is simply infeasible to display the entire
message in hexdecimal on a tiny one line screen and a hash value won't
help either. For example the attack on the German eID card, where users
signed PDFs with embedded data that the eID PDF reader could not
display, demonstrated this. In all of these cases it does not matter for
the attacker whether the attacker is in possession of the private keys.
Moreover, sandboxing and update mechanisms like those employed by the
Google Chrome and Chromium web browsers have probably saved more average
users from malware than any smartcards combined (see more lengthy
description in previous emails). So from the perspective of security
economics (if you want to apply it and have given up absolute security)
such mechanisms are a cheaper and more effective countermeasure for the
average user.
[1] [2]

@_date: 2015-02-19 18:22:42
@_author: Matthias-Christian Ott 
@_subject: Help need to use truecryt + openpgp applet. 
Your Java Card does probably not support PKCS  An applet on the card
might implement it. To make it work, you need a PKCS  middleware and
tell TrueCrypt about it (Settings > Security Tokens... > PKCS Library Path). If you are using an applet that is supported by OpenSC,
you can use OpenSC. Otherwise you have to resort to the proprietary
middleware supplied by the vendor. OpenPGP cards should be supported by
OpenSC and should be usable with TrueCrypt [1]. There is also a
proprietary PKCS  library that should provide a PKCS  interface
for OpenPGP cards [2]. Otherwise you can try Scute [3].
That said, it is probably better to ask on the OpenSC mailing list [4]
about PKCS The Java Card OpenPGP applet seems to be maintained by Yubico at the
moment [5].
[1] [2] [3] [4] [5]

@_date: 2015-02-19 21:16:43
@_author: Matthias-Christian Ott 
@_subject: Help need to use truecryt + openpgp applet. 
You could store it in the private use data objects (0103, 0104). I look
at both TrueCrypt's and OpenSC's source code. TrueCrypt uses PKCS  to
find all private object with a matching label. OpenSC's PKCS implementation in turn uses its PKCS  implementation to store
objects. OpenSC's PKCS  driver for OpenPGP cards in turn does not
handle data objects even if the card could store them. It doesn't look
too difficult to implement this feature. Perhaps somebody will do it for
you if ask on the OpenSC mailing list.
Scute supports certificates only as well.
I think this is impossible TrueCrypt derives keys from the password and
then decrypts the header of the volume. There is no space to store
encrypted key material.

@_date: 2015-02-19 21:20:05
@_author: Matthias-Christian Ott 
@_subject: Help need to use truecryt + openpgp applet. 
I'm well aware of this. That why I wrote "middlware" instead of
"driver". SoftHSM is a good example of a PKCS  middleware that is not
a smartcard.

@_date: 2015-02-21 03:01:51
@_author: Matthias-Christian Ott 
@_subject: Help need to use truecryt + openpgp applet. 
As mentioned in my more detailed follow-up email on how TrueCrypt
accesses the "keyfile" on the smartcard, Scute is not able to do this.
GnuPG however can access the (optional) private data objects on the card
that could be used to store the "keyfile" on the card (as they are PIN
protected). If I'm not mistaken, you should be able to add this to Scute
through scdaemon and the GETATTR PRIVATE-DO-3 and SETATTR PRIVATE-DO-3
commands over scdaemon's Assuan protocol that you would have to map to
the appropriate PKCS  in Scute (see TrueCrypt's source code for how
it finds PKCS  objects on the card). That said, I doubt using the
private DOs for PKCS  objects and associated metadata will be
generally accepted (other people could be storing other data in these
data objects), so you would probably have to add a compile-time option
or maintain a fork.
If you are trying to implement this as part of job/on behalf of your
employer (guessing from your website and work email address that seems
to be the case), I would also advice you to subcontract somebody else to
implement this feature (see Werner Koch's email).

@_date: 2015-01-24 00:05:17
@_author: Matthias-Christian Ott 
@_subject: Talking about Cryptodevices... which one? 
The same is true for the OpenPGP smart card or for almost any other
smart card available on the market. They could all contain a secret key
escrow mechanism and some probably do. Proprietary smart cards are hard
to audit and verify and are easy targets for backdoors and bugdoors.
Moreover, I would like to see a realistic threat model under which
compromising the host system does not render the smart card useless
(that doesn't mean smart cards aren't useful from a usability
perspective for some types of users). From a security perspective it's
yet another mitigation technique to try to work around insecure
operating systems and applications.
There are some smart cards with PIC and AVR microcontroller available on
the market that seem to be used to decode scrambled/encrypted satellite
broadcasts (starting keyword: Funcard, Goldcard). They have limited
memory but there are models that should suffice for a minimal
implementation of the OpenPGP Card specification. There are also similar
microcontrollers of the size of a USB flash drive. Both have fuses to
prevent changing the bootloader which in turn could verify firmware
uploaded to the device.
As already mentioned in this discussion, there is also Gnuk which is a
USB device without proprietary firmware and there are USB connected
computers of the size of a USB flash drive that run GNU/Linux and could
be used as a HSM (there are several software based Free Software HSM
Moreover, you should be able to use any card supported by OpenSC
(including MuscleCard and derived Java Card applets) with gnupg-pkcs11.
As far as I know OpenSC does not support any hardware that is entirely
based on Free Software.
That being said, really think about your threat model and whether smart
cards would help you to prevent attacks in your threat model. If they
don't, save the money or give it to people in need.
- Matthias-Christian

@_date: 2015-01-24 00:27:06
@_author: Matthias-Christian Ott 
@_subject: Crypto device where I need to confirm every operation? 
Twice is enough: once to generate a revocation certificate and once to
sign a new key created by the attacker.
- Matthias-Christian

@_date: 2015-01-25 16:31:06
@_author: Matthias-Christian Ott 
@_subject: Talking about Cryptodevices... which one? 
This is just paranoia and pure speculation for which I have no evidence.
I just replied to an email that speculated that an intelligence agency
has an agreement with a card reader manufacturer to leave security
vulnerabilities unpatched. If you assume this, you also have to assume
that the proprietary OpenPGP card is also subject to such an agreement.
I also remarked that it would be technically feasible to deliberately
insert a key escrow mechanism or some other backdoor or bugdoor into a
smartcard. In the current global threat model we have to assume that
there are forces with enough power and resources to pursue anything that
is technically feasible. Whether you assume this threat model is up to
you and subject to your level of paranoia.
I don't think that such discussion belongs on this mailing list but I
felt that I had to intervene to stop portraying the OpenPGP card as a
secure solution. Any secure software has to be Free Software. Otherwise
it is very difficult to verify its security.
I think we could go on and on about threat models, security usability
and so on. Such a discussion would lead nowhere and is highly
speculative. In fact a smartcard with backdoor would probably be more
secure than the an average Windows computer or an unpatched Android
phone because it's more difficult to exploit. However, I think that it
is not healthy and dangerous to look at computer security from such
perspective and apply security economics and so on because it is
speculative and you compare people to money.
EJBCA is also Common Criteria EAL4+ certified but still has bugs so such
certification is not a guarantee but merely an indicator. In a public
presentation an EJBCA developer also mentioned that the certification
organization only looked at the software at a conceptual level and never
audited the source code. So such certification does not prevent
backdoors or bugdoors and is essentially worthless if you assume such
threat model. With your experience you probably know more about Common
Criteria certification. I just repeated what happened in the case of EJBCA.
I'm confident that it is very difficult if not impossible to develop a
secure implementation a specification of the complexity level of
GlobalPlatform or similar even if you use formal verification. There
will always be attacks that you did not anticipate. Without many eyes
looking at the source code you will never know if your software is secure.
So without repeating a discussion that is being repeating over and over
again about whether Free Software is more secure or applying a
perspective on security that only considers something to be secure or
insecure without somethin in between, I think it everyone on this
mailing list would agree that it is important for security that software
is Free Software and that proprietary smartcards are problematic.
I can imagine this. What do we do now? There is no mechanism to verify
this. If the smartcard manufacturer uses deterministic builds and
provided access to the source code, you could verify that to the extent
that you feel assured that the source code does not contain backdoors
and that the software on the smartcard is indeed the software that you
think it is.
A recent example would be the Taiwanese national ID cards. I could not
find the exact model and certificate for the card but I'm sure that they
were somehow certified and they are indeed used in "security sensitive
mass applications" without being "secure". I'm certain that the weak
random number generator would have been found if the source code had
been available and there had been a competition with reasonable prices
to comprise the cards before they were rolled out.
As already mentioned, under a certain threat model a successful attack
only needs two signatures: one for the revocation certificate and one to
sign the key of the attacker. And again I don't think we can discuss the
security or effectiveness of smartcards without a concrete thread model
because without that you can always argue that something is secure or
insecure if you assume X, Y and Z and the discussion leads nowhere. So
if you want to make this discussion fact-based and continue on, propose
a threat model that satisfies the needs of the person asking the
original question and we can carry on the discussion.
- Matthias-Christian
