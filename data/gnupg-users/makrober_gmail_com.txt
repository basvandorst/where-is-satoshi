
@_date: 2010-01-07 09:36:26
@_author: makrober 
@_subject: Web of Trust itself is the problem 
Well, here are some thoughts:
The presentations starts with:
"Why isn?t PGP widely used?"
The first point ("Designed around the E-mail") is absolutely correct.
E-mail is not the only communication channel that needs protection
now, and I strongly suggest that it will be less and less prominent
in the future. There is an awful lot of crud in g/pgp that complicates
the use in contexts other than e-mail.
But the rest of the "Why isn't [it] used" is plain wrong.
G/PGP isn't widely used because it does not address adequately the
real-life operational circumstances of the potential user, and
Web of Trust is the main culprit. It brings an enormous burden to
the development and - consequently - to the daily use of the system.
This burden is of such magnitude that it prevents all but technically
very competent computer users from adopting the system. Yet it
addresses the need that is present, I propose, only for a very minor
segment of users: those that would like to communicate in secrecy
but have not had a previous trusted relationship.
*Most individuals will rarely, if ever, be motivated to communicate
in secrecy with someone they don't already have a trusted
relationship with*.
This simple fact seems to me to be an issue that goes to the core
of the design synopsis of a system such as g/pgp. On the other hand,
the inverse of it has been built so deep into the system that
somehow it appears impossible to discuss it "sine ira et studio".
On the other hand, WoT brings with it an immense problem for a
large number of those that need to communicate in secrecy: it is
providing an adversary with a traffic analysis tool that he can
only wish for. To state - as those who promote the system in its
present shape do - that they should not worry about this fact is
naive. The current change of legal landscape is undeniable: not
only can various magistrates force the user to reveal his
cryptographic key, but it has become common that such keys must
be produced, often years after the fact, in civil litigations.
In this combination of technical characteristics of the product
and wider environment in which it is used, we simply must ask
Just who is left to use the system and why would he or she want
to do it?
Or - Web of Trust isn't the solution, Web of Trust is the problem.
Consequently, a WoT "improvement mechanism" such as outlined in
the presentation is, unfortunately, extremely unlikely to advance
the adoption of g/pgp.

@_date: 2010-01-07 12:35:47
@_author: makrober 
@_subject: Web of Trust itself is the problem 
Thanks for your comments Werner;
Correct, but still there is no doubt that only a very small fraction
of what I would call "qualified e-mail" is encrypted. (In this context,
let's agree that "qualified" is mail between two parties that have
a trust relationship and a real need for secrecy (from whatever
adversary!) as opposed to those that would just encrypt the mail out
of style or principle. We probably agree at least that that the adoption
of encryption in computer communication, both "general" and "qualified"
communication is surprisingly low, and that it is worth examining why
is this the case and what should or could be done to change that.
I offered one view of the reasons, but in the following I would also
suggest what would be worth undertaking:
Using the excellent crypto-code base of GnuPG, a derivative public
key encryption/decryption product with the following characteristics
should be created:
1) it should be communication channel and protocol agnostic.
2) its operational components should be self-contained; i.e., it should
assume it is running on a stand-alone computer. It should require no
tight integration with the operating system of the computer it is
running on.
4) until successfully decrypted, none of the data it operates on should
be distinguishable from a random stream.
5) it assumes that someone or something outside of the system guarantees
the authenticity of fingerprint of the public key of the corresponding
6) it can be both shell-driven and provide an API for the inclusion
into a variety of software products that manage the variety of
constantly evolving communication channels and protocols.

@_date: 2010-01-07 13:30:28
@_author: makrober 
@_subject: Web of Trust itself is the problem 
A public key communication system such as gnupg can have three,
somewhat related but to the user very distinct purposes:
1) secrecy of communication
2) authentication of the public key of message recipient.
3) non-repudiation of the content by it's sender.
To a cryptographer, all three may seem equally important. In practice,
they are not: the first one is of extreme importance and can not be
substituted by any means outside of the system. The second not only
can be achieved by methods that operate in addition to or outside of
the system, but it is, for varios reasons I outlined before, sometimes
(or perhaps even often?) desirable to do so. Finally, the third
(I believe this is what you refer to above?) is, in practical terms,
an extremely rare requirement when compared to the first one.
If the above is the case, making a system very hard to use because of
secondary objectives which are either hardly ever of real use
(non-repudiation) or likely/preferably achieved by other means better,
can't be conducive to the wide adoption of such system.

@_date: 2010-01-23 23:55:23
@_author: makrober 
@_subject: distributing ones public key (email) 
Unsolicited attachments are considered inappropriate by many.

@_date: 2011-04-27 20:19:45
@_author: M.R. 
@_subject: No, it is not. 
For most individuals who really *need* (as opposed to those
that do it as a matter of ideology or principle) to protect
their communication, the need to keep confidential who is
communicating with whom is as important as is the protection
of the content.
Current "secure computer communication systems" do nothing
for them. WoT is actually a complete antithesis of their
requirements. This is probably why, after all these years,
the fraction of encrypted e-mails remains so minuscule.
Encrypted e-mail between private individuals is today the
province of the enthusiasts instead of those who are in the
need of it.
Mark R.

@_date: 2011-04-28 16:03:02
@_author: M.R. 
@_subject: nothing so dramatic 
Quite probably, but I do not consider myself qualified to comment
on trials and tribulations of human rights activists in faraway lands,
or, for that matter, on this continent. My concern is the result of
a much more mundane set of circumstances.
When legal "pressure to decrypt" is discussed, almost universally
the issue becomes that of the right not to self-incriminate.
Implicitly, it is assumed that the proceedings are part of some
segment of the criminal law. However, it is not in the criminal
but in the civil litigation that the courts can (and nowadays
increasingly do) issue Subpoena Duces Tecum ("production of evidence")
for plain-text of one of the litigant's communications. No right not
to self-incriminate applies in such case. Where the record exists
(just for an-instance) in a monetary hefty divorce litigation that
there was encrypted communication with a third party, reasonably
suspected of interfering in the marriage, the request from the
opposing side for such duces tecum would not be hard to obtain.
But there has to be a "reasonable expectation of relevance"; i.e., encrypted communication with a specific and relevant individual.
Without it, request would likely be treated as nothing but a fishing
expedition and rejected. I can easily imagine similar cases where
the other communicating party is not Alice (36-29-38) but Bob, your
accountant or stockbroker.
Mark R.

@_date: 2011-02-25 04:15:05
@_author: M.R. 
@_subject: PGP/MIME considered harmful for mobile 
They might not be harmfull for ~your~ mobile...
Any mail with attachments is likely to be harmful for mobile.
You just don't know what device and what program will be used to
read your mail and most of those will have difficulty with
attachments. If you must use signatures, please make them in-line!
Mark R.

@_date: 2011-02-28 14:20:59
@_author: M.R. 
@_subject: Question regarding shared keys 
> managers has forgotten the key and therefore, they can't decrypt some
Do you know what program was used to encrypt the files?
Mark R.

@_date: 2011-05-05 02:24:19
@_author: M.R. 
@_subject: Storing secrets on other people's computers 
That article makes no sense at all.
a) Storing files containing your secret data on somebody else's
computer makes sense only if *you* encrypt the data beforehand,
completely independently from the person or organization that
you will give the files to store.
b) Your data can not be considered safely encrypted, unless encrypted
with a competently written program that had its source inspected by
you or someone you trust, on the computer that you control at the
time of encryption.
Once these two extremely straightforward principles are observed,
it is perfectly OK to give the files containing your secrets to
someone/anyone else for safekeeping, provided you have no problem
that it will be known to him, to all those that he cooperates with
and to all those that monitor the traffic between the two of you
that you have given *some* secrets away for safekeeping. To imply
that one such service is better or worse than another based on what
*they* do (or they say they do) in order to protect your secrets
is utter nonsense.
Marko R.

@_date: 2011-05-30 21:10:58
@_author: M.R. 
@_subject: GnuPG language setting 
I wish application developers would understand
a simple fact: language choice can't be computer-wide,
it must be *application specific*.
Mark R.

@_date: 2011-10-17 06:32:36
@_author: M.R. 
@_subject: no, you can't 
To me, it is perfectly obvious what the OP is trying to accomplish:
perform the encryption by supplying the cryptographic key itself,
instead of character string material, from which the key will be
derived by some in-program procedure.
Why does he want to do that makes no difference to the answer,
which is simply: no, unfortunately you can't.
Mark R.

@_date: 2011-10-20 05:39:28
@_author: M.R. 
@_subject: The problem is "motivational" 
> Over the last year Marcus and me discussed ideas on how to make
 > encryption easier for non-crypto geeks.
 > We prepared a short paper...
Interesting. However, the problem of widening email encryption
practice is not technical, it is motivational.
Broadly speaking, there are those that "have nothing to hide"
(i.e., those that completely lack the motivation - see above,
mid-way in the thread) and those that indeed do "have something
to hide".
Those that "have something to hide" would never, ever place an
ISP or webmail operator on their trust chain. After all, they must
assume that those that they must protect their communication from
can probably secure the cooperation of either or both those parties.
On the other hand, I keep wondering: why are we (and we obviously
are, witness this paper and the initiative behind it) so motivated
to spread the gospel of e-mail encryption among those that completely
lack the motivation for it?
(This *is not* a rhetorical question).
Mark R.

@_date: 2011-10-20 15:34:29
@_author: M.R. 
@_subject: The problem is "motivational" 
Thanks for the link, interesting reading. The quote from the paper that
follows demonstrates, I believe, that the authors follow the dogma of
"all mail should be encrypted, even if it is of no benefit to the
mail sender and reciever, because it is of benfit to others":
...but it was a huge cognitive leap to go from protecting secrets in
an individual message to obfuscating secrets using everyone else?s I also believe this dogma is behind Werner's first follow-up to my
 > Because we, who care about privacy, are affected by those who
don't care.
I propose this way of thinking is counterproductive. It will not
succeed in any meaningful way, because "encryption by default"
is a completely unrealistic goal in today's environment of
multiple mail end-user platforms, plethora of client applications,
uncooperative mail service operators and hostile universal surveillance
culture, and, last but not least, by the legions of users who resent
it because they "have nothing to hide". Any "solution" which marshals
mail service operators and ISP's into the trust chain is however
recklessly endangering those that might "have something to hide",
by giving them false sense of security.
I therefore propose that this dogma should be re-examined, and if and
when abandoned, released energy be directed towards addressing the
outstanding issues of those that know they need to protect their
communication and are motivated to do so.
Mark R.

@_date: 2011-09-17 04:00:42
@_author: M.R. 
@_subject: MS windows and gnupg 
How about a large user base that already has that tool set at
hand, and has a natural resistance to install another tool set
they are not familiar with and have no use for other than to
build one single application package? MS compilers give ~us~
(you and me, I guess) nothing, but we must not look at the
world through ~our~ keyhole.
I very much believe gnupg should be available to the users of
MS operating systems, and it is not this that our discussion
here is all about. Selection of an operating system is a complex
matter, often influenced by factors outside the user's control,
and it is naive of the application creator to assume that
someone's decision on what OS he chooses will be driven by his particular application.
It should also be a matter of craft pride on the part of a
programmer that his clean C shell program will build with
no errors in a simple shell script on all three major platforms
with the most common compiler and link-editor found on it.
Something like that should be especially important with
security applications, where it is advantageous - if not
mandatory - that the end user has the ability to crate his
the executable from the source code.
Mark R.

@_date: 2011-09-17 07:51:38
@_author: M.R. 
@_subject: MS windows and gnupg 
I agree with you to some extent. I also happen to believe there are
ways of tamper-resistant distribution of binaries that require the
trust in the application provider and no one else; at least not
someone else in the distribution channel. In addition, the ability
of an average end-user to inspect the source is long gone.
There is however one point on which I'd like to comment:
 > For a while I was stuck maintaining a codebase that was 100% ISO C++.
 > The codebase was clean as could be, and was quite a point of pride.
 > Then came the mission to "support MS," and the Autotools system
 > compiled
 > out-of-the-box on MinGW: it was beautiful.  Then came the mission to
 > "support MS under Visual Studio," we switched to CMake, and I
 > immediately spent more time maintaining our fragile build environment
 > than I spent maintaining the codebase.
Indeed, while code can be "standard" and "cross-platform", build
environments (i.e., innumerable variants of "make") are not. We
have no option of avoiding them in ~application development~ but
I firmly believe this is quite different cattle of fish from
~application distribution~.
In the hands of "end-user-source-recipient" *all* components are
compiled in a linear fashion, and any error is typically terminal.
This situation calls for simple shell scripts and not makefiles.
Even if we assume that end user has the ability to intervene in
a failed build process, he will much sooner be able to do so
with a native (i.e., to his run-time OS) shell script than an
arcane file he is probbaly totally unfamiliar with.
Mark R.

@_date: 2011-09-22 21:22:19
@_author: M.R. 
@_subject: windows binary for gnupg 1.4.11 
Yes, there are many threat models where operating from
a PC that is unknown to the attacker to be associated
with the particular target user will be easier to achieve
than preventing the attacker to subvert the PC that is
known to belong to him or her. Depending on circumstances,
this will mean either booting from static removable media,
or running the software without installation from a
portable medium or device.
Well designed security application should not ignore
this fact and the need for this "drive-by" M.O. I consider
the often heard argument "you must *never* run this software
on computer that you don't own and control" as a poor excuse
for inadequate design.
Mark R.
