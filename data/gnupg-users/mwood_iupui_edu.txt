
@_date: 1999-09-02 09:17:31
@_author: Mark H. Wood 
@_subject: Fetching keys from key servers? 
Hmmm...auto-fetching by key ID works just fine for me, with pine and
pgp4pine.  The only trouble I have is with the large number of people
whose keys use unfree encryption types. :-(
(That and being a newbie who hasn't actually made himself a node in the
web-of-trust yet, so valid keys are still unverifiable.  How does one find
already-trusted people with whom to exchange signatures, aside from just
asking all of one's acquaintances "are you one too?" :-)  Every
key-signing party I ever heard about seems to be in another state and
likely composed entirely of people I've never met.)

@_date: 1999-09-24 08:32:10
@_author: Mark H. Wood 
@_subject: PGP compatibility 
My interpretation:
If algorithm X requires that you pay for the right to use it, GPG doesn't
have it.  (These requirements are considered unenforceable in some parts
of the world, and people have built addons that can be used in such
places.  If you live elsewhere, I would advise against using the addons.)
If algorithm X requires that you not disclose source, GPG doesn't have it.
(Again there may be exceptions in some parts of the world.)
If an implementation of algorithm Y may be published in source and
distributed without fee, then it's either in GPG or someone is probably
working on it.
RSA is not free.  IDEA is not free.  There are addons for them but it is
arguably illegal to use them in many parts of the world.
Sorry -- that's the best I can do.  I think that R. Jackson wanted
something like:
RSA			X	X
IDEA			X	X
DSA			X	X	X
Twofish				X	X
 etc.
but I don't know enough to supply it.  (In fact the table above is
probably inaccurate.)  Could someone who *does* know the score work up a
compatibility table and insert it into the GPG documentation?
Personally, the bulk of the signed mail I get evokes one or more
"unsupported algorithm" complaints and winds up being unverifiable.  I'm
seeing an increase in verifiable signatures, but no decrease in
unverifiable ones.  So the news is good and bad. :-/
IANAL but I believe that U.S. patents may be extended (once) upon
application.  The extension grants an additional 17 years.  If RSADSI has
something waiting in the wings that will make more money than continuing
to sell RSA then they may allow the RSA patent to expire, but if not then
they may apply for an extension.  Don't get your hopes up too high.  (I
have no idea how this affects anyone in any other country -- I have
enough trouble understanding only U.S. laws.)

@_date: 1999-09-02 09:17:31
@_author: Mark H. Wood 
@_subject: Fetching keys from key servers? 
Hmmm...auto-fetching by key ID works just fine for me, with pine and
pgp4pine.  The only trouble I have is with the large number of people
whose keys use unfree encryption types. :-(
(That and being a newbie who hasn't actually made himself a node in the
web-of-trust yet, so valid keys are still unverifiable.  How does one find
already-trusted people with whom to exchange signatures, aside from just
asking all of one's acquaintances "are you one too?" :-)  Every
key-signing party I ever heard about seems to be in another state and
likely composed entirely of people I've never met.)

@_date: 1999-09-24 08:32:10
@_author: Mark H. Wood 
@_subject: PGP compatibility 
My interpretation:
If algorithm X requires that you pay for the right to use it, GPG doesn't
have it.  (These requirements are considered unenforceable in some parts
of the world, and people have built addons that can be used in such
places.  If you live elsewhere, I would advise against using the addons.)
If algorithm X requires that you not disclose source, GPG doesn't have it.
(Again there may be exceptions in some parts of the world.)
If an implementation of algorithm Y may be published in source and
distributed without fee, then it's either in GPG or someone is probably
working on it.
RSA is not free.  IDEA is not free.  There are addons for them but it is
arguably illegal to use them in many parts of the world.
Sorry -- that's the best I can do.  I think that R. Jackson wanted
something like:
RSA			X	X
IDEA			X	X
DSA			X	X	X
Twofish				X	X
 etc.
but I don't know enough to supply it.  (In fact the table above is
probably inaccurate.)  Could someone who *does* know the score work up a
compatibility table and insert it into the GPG documentation?
Personally, the bulk of the signed mail I get evokes one or more
"unsupported algorithm" complaints and winds up being unverifiable.  I'm
seeing an increase in verifiable signatures, but no decrease in
unverifiable ones.  So the news is good and bad. :-/
IANAL but I believe that U.S. patents may be extended (once) upon
application.  The extension grants an additional 17 years.  If RSADSI has
something waiting in the wings that will make more money than continuing
to sell RSA then they may allow the RSA patent to expire, but if not then
they may apply for an extension.  Don't get your hopes up too high.  (I
have no idea how this affects anyone in any other country -- I have
enough trouble understanding only U.S. laws.)

@_date: 2000-04-17 08:28:29
@_author: Mark H. Wood 
@_subject: Compatibility 
Wishing not to go to jail for using patented algorithms without a license
is a very good reason, IMHO.

@_date: 2000-04-17 08:28:29
@_author: Mark H. Wood 
@_subject: Compatibility 
Wishing not to go to jail for using patented algorithms without a license
is a very good reason, IMHO.

@_date: 2000-02-11 09:28:48
@_author: Mark H. Wood 
@_subject: subject line -- to hide or not to hide 
There you go!  Now instead of forcing MUA maintainers to accept a new
threading standard, the problem is reduced to forcing them to support the
one that's already out there.
This threading discussion should probably go elsewhere....

@_date: 2000-02-11 09:28:48
@_author: Mark H. Wood 
@_subject: subject line -- to hide or not to hide 
There you go!  Now instead of forcing MUA maintainers to accept a new
threading standard, the problem is reduced to forcing them to support the
one that's already out there.
This threading discussion should probably go elsewhere....

@_date: 2000-10-24 09:27:37
@_author: Mark H. Wood 
@_subject: understanding what gnugp can do 
If for some strange reason you don't like mutt, pine with pgpenvelope also
works pretty well.

@_date: 2000-10-30 08:24:07
@_author: Mark H. Wood 
@_subject: RSA support 
Hash: SHA1
The last time I looked at the IDEA license, Icouldn't think of any use I
might make of the algorithm that couldn't be construed as "commercial".  Have a lawyer look it over before assuming that you aren't required to
obey it.

@_date: 2000-10-24 09:27:37
@_author: Mark H. Wood 
@_subject: understanding what gnugp can do 
If for some strange reason you don't like mutt, pine with pgpenvelope also
works pretty well.

@_date: 2000-10-30 08:24:07
@_author: Mark H. Wood 
@_subject: RSA support 
Hash: SHA1
The last time I looked at the IDEA license, Icouldn't think of any use I
might make of the algorithm that couldn't be construed as "commercial".  Have a lawyer look it over before assuming that you aren't required to
obey it.

@_date: 2000-09-06 08:39:14
@_author: Mark H. Wood 
@_subject: Can't compile RSA / IDEA under Windows 
I think he's saying that forcing GPG users in many countries to choose
between breaking the law and waiting seven years for their next GPG
upgrade is of absolutely no interest.
This is true.  Sadly, many cling to versions of PGP that are now nearly
FIVE MAJOR RELEASES OUTDATED.  *Their* software is not RFC2440-compliant.
I took it seriously.  The source is in the celebrated book.  Go fix it.
[snip stuff on which I can't usefully comment]
It sounds reasonable to have collective switches which implement
commonly-used combinations of more specialized options.  This does nothing
about the legal issues, but it wouldn't hurt.
No, what makes the use of IDEA deprecated is this language in RFC2440:
[from section 3.6.2.2]
   PGP 2.X always used IDEA with Simple string-to-key conversion when
   encrypting a message with a symmetric algorithm. This is deprecated,
   but MAY be used for backward-compatibility.
If protocol specifications are not technical facts, then I wonder what
they are.
I can't argue with that.  However, only time or money will solve the
patent issues.

@_date: 2000-09-06 08:39:14
@_author: Mark H. Wood 
@_subject: Can't compile RSA / IDEA under Windows 
I think he's saying that forcing GPG users in many countries to choose
between breaking the law and waiting seven years for their next GPG
upgrade is of absolutely no interest.
This is true.  Sadly, many cling to versions of PGP that are now nearly
FIVE MAJOR RELEASES OUTDATED.  *Their* software is not RFC2440-compliant.
I took it seriously.  The source is in the celebrated book.  Go fix it.
[snip stuff on which I can't usefully comment]
It sounds reasonable to have collective switches which implement
commonly-used combinations of more specialized options.  This does nothing
about the legal issues, but it wouldn't hurt.
No, what makes the use of IDEA deprecated is this language in RFC2440:
[from section 3.6.2.2]
   PGP 2.X always used IDEA with Simple string-to-key conversion when
   encrypting a message with a symmetric algorithm. This is deprecated,
   but MAY be used for backward-compatibility.
If protocol specifications are not technical facts, then I wonder what
they are.
I can't argue with that.  However, only time or money will solve the
patent issues.

@_date: 2001-07-18 17:03:02
@_author: Mark H. Wood 
@_subject: Trusted Signatures on your Public key? 
That's basically it.  That person probably knows how to do so with the
software he uses.  The GNU Privacy Handbook discusses this rather
generally at:
The question I neve see properly addressed is:  how do I discover the
intersection between [people I trust] and [people who use compatible PKC]?
Do you just go around asking all of your friends and associates, "are you
one too?" until you find someone?

@_date: 2001-06-13 00:59:02
@_author: Mark H. Wood 
@_subject: Corporate use 
Do you mean:  how many people use GnuPG at work?  Or:  how many workers
can get official support from the IS department for the use of GnuPG at
their jobs, as opposed to a horrified look at the thought of the corporate
network being contaminated with "dangerous" free software? :-/
I'm in the first category, but probably not in the second.

@_date: 2001-05-17 15:31:01
@_author: Mark H. Wood 
@_subject: Using signing in a group environment 
Well, unless there is some compelling reason to share a single key, the
*best* way is to give each member a separate key.  If a member leaves, he
can continue to send signed email, but since you know it is from a
nonmember (the signature *proves* that) you can ignore it.  If this is not
sufficient, explaining your need more thoroughly may elicit a better

@_date: 2001-05-17 15:50:01
@_author: Mark H. Wood 
@_subject: secret key 
Others have addressed that which is probably your actual need.  However,
to address your question directly:  gpg will continue to absorb what you
type until it receives an end-of-file indication.  Usually the way to do
that in interactive input is to enter control-D (on Unix) or control-Z (on
MSDOS or Windows).
Once you've done that, gpg will tell you that it found no valid PGP data,
because the default is to decrypt its input.  Adding the options '-s -e'
will cause it to sign and encrypt its input.  Now the command will spew
out binary encrypted gunk on your terminal.  This is probably not what you
wanted.  Adding '-a' will change the binary gunk to printable ASCII gunk,
which is probably still not what you wanted.  If you want the output to go
to a file called NAME, your best bet is to add '-o NAME'.
NAME could then, for example, be used as the body of an email message.
However, if what you want to do is send signed and/or encrypted email,
there are layered products which will do this much more simply by
directing gpg for you.
You need to study the gpg man page if you want to understand what gpg is
doing.  There are many options.  gpg is like the proverbial Swiss Army
knife:  a broad array of tools all riveted to a single handle.  You need
to tell it what kind of tool you want it to be today.

@_date: 2001-09-19 16:23:01
@_author: Mark H. Wood 
@_subject: multipart/signed ? 
Would someone point me to discussion of how to conveniently verify a
multipart/signed message body.  If it helps, the UA is pine.

@_date: 2001-09-24 16:36:02
@_author: Mark H. Wood 
@_subject: Mutt/GnuPG doc initial release 
Second the motion.  I often see assertions that MIME is a deadly sin on
lists, but I've never received a credible explanation.
Oddly enough, Pine.  At least, if this were working, I should think that
*someone* would describe how it's done.

@_date: 2001-09-25 13:42:01
@_author: Mark H. Wood 
@_subject: Mutt/GnuPG doc initial release 
Not only is it not necessary, it is not sufficient.  You could walk up to
me face-to-face and claim to be, say, Bill Gates, and if you look enough
like him how would I know the difference?
All authentication is relative, really.  Who is that "known authority"?
How do you know?  A web of trust is based on judgments as to the
probability that any given link is not compromised (and so is a CA chain,
by the way).  Some relationships can be extraordinarily difficult to fake,
but I have thought of none for which it is impossible.

@_date: 2001-09-28 16:27:01
@_author: Mark H. Wood 
@_subject: Mutt/GnuPG doc initial release 
Although you have no other alternatives w.r.t. car horns, you do have
another alternative w.r.t. signatures:  it sounds like what you really
need is an MUA which can be set to check only signatures which interest
you and ignore others.  If there is no such MUA, you can add this feature
yourself (assuming you don't favor some closed-source abomination :-).
I believe that someone has already mentioned a way to make one MUA
sensitive to the distinction between list and private mail, requiring that
you have your listmail delivered to alternate folders.  But it shouldn't
be too hard to also make an MUA check the sender's address against a list
of senders whose signatures you are willing to endure.
That way others may choose to sign *and* you may choose not to care about,
or perhaps even see, the signature.  It seems to me that in this way
everybody wins.
Further discussion of this not-GPG-specific topic should probably take
place elsewhere.

@_date: 2001-09-28 16:35:01
@_author: Mark H. Wood 
@_subject: Die E-Mail von gnupg-users-admin@gnupg.org 
---
    ------------------
                                             ^
...on grounds of [safety|security]

@_date: 2002-08-16 15:47:04
@_author: Mark H. Wood 
@_subject: Detached signature on multiple files? 
FOR has been around in Microsoft OSes for a long time, but bear in mind
that COMMAND.COM (DOS, Win/DOS) and CMD.EXE (NT) are different command
interpreters.  There's a lot of stuff in CMD that's missing or different
in COMMAND.  So stuff that works on NT may not work on Win9x/ME.
NT had that Posix subsystem, ya know, so there was some incentive for the
NT team to make CMD behave as Posix fans would expect.  The Win/DOS team
had no such incentive and was probably much more concerned with lingering
codesize constraints.

@_date: 2002-08-28 15:59:01
@_author: Mark H. Wood 
@_subject: Security of message when private key is exposed but password 
[drifting offtopic]
There's a nice little gadget called 'apg' which will crank out FIPS-181
passwords up to 255 characters long.  FIPS-181 passwords are supposed to
be always pronounceable, which helps a lot in remembering them.  I'm told
that the OpenVMS command SET PASSWORD/GENERATE uses the same algorithm
(which is why I hunted down 'apg' -- that's one of the things I really
missed when they took my VMS away.)

@_date: 2002-10-28 16:20:01
@_author: Mark H. Wood 
@_subject: E-Mail Encryption: Why Isn't Everyone Doing It? 
A while back, when someone was sending anthrax spores through the mail
over here, I actually spent some time thinking about whether cryptographic
signatures could be adapted to verification of the return address on
physical mail.  I gave up when I realized that, not being trained in
cryptography, I didn't trust my own answers.
I'm going to teach my children such things, so maybe that's a start. :-/

@_date: 2002-10-28 16:43:02
@_author: Mark H. Wood 
@_subject: E-Mail Encryption: Why Isn't Everyone Doing It? 
[snip interior quote]
Sure there is.  You put all of the simple, popular stuff on the front of
the interface and provide more-advanced stuff on other tabs, "Advanced"
buttons, wizards, etc. according to the complexity of the material.
Why should GUI development have any effect on the answering of questions
about the commandline interface?  The GUI goop should just be a wrapper
around the commandline tool.
I must disagree.  EVERY feature should have a good user interface.  One of
the things which make a UI good is correctly identifying the "90%+ of
users will never want this" options and placing them on a portion of the
interface which the user must explicitly request.
I do, and I'm considering writing a comprehensive GUI for the openssl
command which will keep track of all 69,000 options for me so I won't have
to remember or relearn them on the 2-3 occasions every year when I want
them.  Yes, I know it'll be a big job, but I'd happily spend two hours
coding rather than one hour to do the same thing manually, even just to do
it once.
The way SSL is built into browsers is precisely what makes it not terribly
useful in that setting.  I would like a *lot* more control over this
aspect of my browser; I just don't want it to all spring out at me every
time I select a link.  And I want my email to work similarly.

@_date: 2002-09-06 16:04:02
@_author: Mark H. Wood 
@_subject: GnuPG and Windows Registry variables 
No, it's more complex than that.  User profiles may be located anywhere;
the form you give is only the default and may not be correct even then.
To form a path to the Application Data directory, you need to expand
%APPDATA% (if it exists on this platform).  Thus:
  %APPDATA%\GnuPG
Another approach is to ask the shell for the Application Data path and
append the product name.  Use:
  ShGetFolderPath(hwnd,CSIDL_APPDATA,NULL,SHGFP_TYPE_CURRENT,&pathbuffer)
to get the path to the Application Data directory.  The PSDK's Windows
Programming Guidelines recommend this method.  However, Application Data
was not in the original Win32 design (or they didn't get around to
implementing it for a while) so older platforms won't know what to do with
either %APPDATA% or CSIDL_APPDATA.  You need a fallback.
No, it won't.  The current PSDK documentation states that one must run
REG_EXPAND_SZ data through ExpandEnvironmentStrings() to get the proper
substitutions.  The difference between REG_SZ and REG_EXPAND_SZ appears to
be only that the latter may be expanded while the former should not.  I
believe that the Registry APIs themselves use the same code paths for both

@_date: 2003-04-29 15:31:04
@_author: Mark H. Wood 
@_subject: Subject tag in all list messages ? 
I'm curious:  what's wrong with this header:
  To: gnupg-users
or this one:
  Sender: gnupg-users-admin
or this one:
  X-BeenThere: gnupg-users
or this one:
  List-Id: Help and discussion among users of GnuPG in identifying the source of messages reflected by this list?

@_date: 2003-08-05 14:53:02
@_author: Mark H. Wood 
@_subject: Evolution signatures 
Hash: SHA1
[interior quote snipped]
Realizing that this is wandering offtopic, I can think of one way to beat
it.  Your addressbook should remember which kind of signature each person
prefers.  Say you're sending to Fred, Barney, and MrSlate.  Fred and
MrSlate can handle only inline sig.s, while Barney can take either kind,
and you prefer attached sig.s.  So Barney receives his copy with attached
sig., while Fred and MrSlate receive the same body with an inline sig.,
without you having to do anything special.  When replying to a signed
message, default to signing the reply the same way the original was
signed.  You should only have to choose when sending to someone whose
preference is not recorded and cannot be deduced.
When taking an address into the addressbook from a signed message, the
form of the message's signature should set the default value for
signature-type in the entry.

@_date: 2003-08-07 15:11:02
@_author: Mark H. Wood 
@_subject: Signed headers (was Re: Evolution signatures) 
Hash: SHA1
And when the sender is seated at one of the 200 public workstations that I
maintain, which host should his key be bound to?  He may not get that host
again for many days.

@_date: 2003-12-18 16:21:19
@_author: Mark H. Wood 
@_subject: gnupg feature request 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
This much is quite proper (and the path is *much* more proper than the
default C:\GnuPG).
I have wondered whether REG_EXPAND_SZs are automagically expanded by the
Registry access functions or just exist as a clue that the app. should
expand the strings, but was too lazy to do the experiment.  Thanks for
clearing that up!  However, the path to the user's keyrings should be a
per-user setting, so it belongs in HKCU.  The above works, but it is
common to every user so they all have to keep their keyrings in the same
place relative to their usernames.  In particular, I might prefer to keep
my keyrings on a central server and use them from there, instead of
leaving various stale copies all over the campus in roaming profile
images.  (IMNSHO about 98% of the stuff in a user's profile belongs

@_date: 2003-02-21 14:38:01
@_author: Mark H. Wood 
@_subject: Elgamal signatures (was Re: splitting keys) 
Indeed, I had thought that the keyserver was hanging on these messages,
and that I hadn't managed to track down the proper key manually.  I was
developing the habit of just skipping Sr. Alvarez' messages since
pgpenvelope wouldn't let me see them after I ^Ced what I thought was an
endless wait.  But I can wait if I know that my patience will be rewarded,
and it was.

@_date: 2003-01-06 17:16:01
@_author: Mark H. Wood 
@_subject: Cannot connect to Keyservers 
Um, RR stands for "Resource Record".  The DNS database is composed of 100%
RRs;  there is no other kind of information in it.  The person who brought
that notation into the thread didn't say what *kind* of RR it is.  He
probably meant that it's a CNAME RR, which points to some other name, but
perhaps he will clarify his remarks.  (Sorry, I deleted the earlier
message so I don't have the domain name in question or the poster's name.)

@_date: 2003-07-09 22:28:02
@_author: Mark H. Wood 
@_subject: Corporate public key? 
Hash: SHA1
I think the bank is going to need its own keyserver anyway.  People need
quick reliable access to those revocation signatures, you know.
And this leads to a problem I see with using GnuPG, which is a general
problem but more acute when using the product for business:  key updates.
I know I can refetch a key whenever I feel the need, but I don't recall
seeing any way to automagically check for revocations.  I would probably
refresh a key manually whenever I'm about to communicate something
critical, but in financial transactions that means "every time".
SSL has the same problem, but it also has a developing solution:  OCSP.
Does GnuPG have something like that and I just missed it?
As you say, policy takes care of this.  The bank's signatures mean what
the bank says they mean.  You get a copy of the then-current policy when
you sign up for the service, just as with any other financial service.
You can follow the policy URLs anytime you want to check for changes.
It's the standard chicken/egg problem faced by any new service.  It's
waiting for someone who smells enough money to stick his neck out by
providing an attractively packaged solution and waiting for customers to
show up.  Once a few customers start telling their friends, "oh, I use
this free encryption gadget to do my banking securely by mail, it's much
safer than the phone," word will spread and the service will take off.
And if it ramps up to just 10% of the customer base, it's probably well
worth the startup cost.
And once two or three "Internet banks" see significant use, the
brick&mortar banks with an Internet presence will *have* to follow suit,
or they'll be bleeding accounts even faster than before.
Moving up a layer, once we get the financial services industry sorted out,
maybe I can convince the medical and pharmacy professions to adopt secure
electronic communication instead of playing telephone tag or passing
handscribbled notes.

@_date: 2003-07-10 15:37:04
@_author: Mark H. Wood 
@_subject: Auto Key Refresh 
Hash: SHA1
[snip interior quote]
Yeah, my pubring.gpg is over a megabyte.  I don't want to refresh the
whole thing every time I do business with my bank.  (I know, I know, I
should weed out stuff I don't use....)
It sounds like key entries in keyrings need two more attributes:  a
"refresh before each use" bit, and a list of the best places from which to
refresh this entry.  If there's no server list, use the master list from
gpg.conf .
I forgot to mention the reason I think the bank will want its own
keyserver:  would *you* trust billions of dollars a day in transactions to
a server not under your control?  I don't think your banker will.

@_date: 2003-07-14 15:55:02
@_author: Mark H. Wood 
@_subject: newpg won't compile (RANT!) 
Hash: SHA1
Some things you did *not* do:
o  You didn't show us the error message.  Paraphrases often leave out
   critical information.
o  You didn't tell us whether you looked in config.log to see *why*
   libgcrypt-config couldn't be found, and if so, what you saw there.
o  You didn't tell us whether you looked in configure to see how it is
   searching for libgcrypt-config, and how you compared that to where you
   expect it to be found.
o  You didn't tell us where your libgcrypt-config originally was before
   you began copying it.  'locate libgcrypt-config' might help you here,
   if you haven't already done that.  'which -a libgcrypt-config' would be
   a good idea as well.
autoconf is nice when it succeeds, but the occasional failure can be quite
puzzling.  The more information, the quicker the cure.
BTW would someone please remind me what "newpg" is -- I can't find it

@_date: 2003-07-16 19:35:19
@_author: Mark H. Wood 
@_subject: signature as attachment? 
Hash: SHA1
Not just on MS Windows, either.  pine on Linux gives me this last case
quite often.  The message processing hooks in pine seem to be at the wrong
places for PGP/MIME since you need the text of all bodyparts plus some of
the metadata in order to process this kind of message correctly.
(To head off helpful suggestions:  I already have mutt and I don't like
it; I already have Mozilla Mail and don't like it either.  I liked VMSmail
and I liked PMDF MAIL even better, but hated DECwindows' GUI MUA.  I may
write myself Yet Another MUA if I ever get the time.)

@_date: 2003-06-10 16:22:03
@_author: Mark H. Wood 
@_subject: gpg usage w/ pine 
Hash: SHA1
Also note that "display-filters" has nothing to do with *sending* signed
or encrypted mail.  For that you want "sending-filters".  Here's mine:
# This defines a program that message text is piped into before MIME
# encoding, prior to sending
sending-filters=/usr/local/bin/pgpenvelope_encrypt _RECIPIENTS_

@_date: 2003-06-19 16:42:02
@_author: Mark H. Wood 
@_subject: Why CAs or public keysigning? 
Hash: SHA1
Yes, that's a problem for which the WoT doesn't give much help.  It's not
the right tool.  A nice large X.500 "white pages" directory in which you
can go fishing using multiple constraints would give much more confidence,
especially if one of the attributes was a link to a page with a
biographical sketch of the person to which the object refers.  (Maybe
there should even be a standard for machine-searchable biography, like the
emerging standards for document metadata.)  But since all of those
directory attributes are, of necessity, "personally identifying
information", in most countries we must wait for the individual to
volunteer them even if the public facilities for their advertisement are
available.  (If this is not true in country X today, it will be soon.)
I think this points to a chicken/egg problem.  If I'm going to *publish*
lots of personally identifying information, I want a strong authentication
infrastructure in place to prevent abuse.  But the authentication
infrastructure needs the prior availability of the information to make it
useful in the general case.
One way out of the dilemma would be a set of common, *enforceable* rules
for identifying people in different situations.  (That is, your banker
could *go to jail* if he accepts blind requests for access to your account
based solely on the requester's knowing your U.S. Social Security Number,
for example.  Or an overzealous prosecutor could lose his job for
malfeasance if he draws unwarranted conclusions from your personal data
and drags you into court without good reason.)  Right now there's great
potential for abuse, and very little one can do about it except to refuse
to participate in purported "progress".  But the expectation of harm from
abuse diminishes in proportion to one's ability to *punish* abuse, even
with no reduction in the potential for that abuse.
Hmm, I see I'm helping to carry this thread away from any focus on GnuPG.
Maybe wider discussions of what the WoT can and cannot do should move
elsewhere?  Where?

@_date: 2003-05-14 15:36:04
@_author: Mark H. Wood 
@_subject: Opportunistic Encryption [Was: Keys not trusted] 
Hear, hear.  I'm often surprised at the variety of things which get lumped
together these days under the heading "privacy", still more under
I need a little help here.  What, exactly, would an "anonymous" key
*mean*?  To what would a document signed by such a key be bound, and why
would I care?
(I'm always swimming against the current.  While it seems everyone else
wants to become invisible, I've been wondering how to go about getting
really high-quality identity documents, both paper and electronic.  I
*want* to be well-known, *on my terms*.)

@_date: 2003-05-21 14:30:02
@_author: Mark H. Wood 
@_subject: Encouraging email security. 
Well, over here in .us people are beginning to get upset about identity
theft.  Unsecured email certainly sounds like an easy target for identity
thieves, to me.  Anybody see how to link the two and get some press
That sounds a lot like what I'd like to see here.  I'd also like to see
the medical industry take up encrypted electronic comm.s.  I could email
notes to be dropped into my medical record for the doctor to review
*before* my next visit.  I could receive test results more conveniently
*and* more securely.  We could move away from this insecure and
error-prone system of ordering drugs via hand-scrawled notes on little
scraps of paper.
Want more?  How about setting your community's school up with secure,
authenticated access and transmission of grade reports, disciplinary
summaries, events, etc.  Lots of people get really worked up about the
privacy of educational records and notices, yet we hand these over to
children to carry home in their bookbags.  In our community we can email
our kids' teachers informally, but we could go a lot further with secure
Lately our utilities all want me to switch over to electronic monthly
statements.  I don't want to give up paper copy, though, until they will
provide me with *signed* statements that I can take to small-claims court
as proof of what they said, if need be.
I'd like to quash "slamming" by asking my phone company to accept change
orders for my service *only* on signed media.  Maybe they'd even sell
lists of accounts that *cannot* be accessed by telemarketers, so the
latter would know better than to waste their time by wasting mine.  It
could save the telco some money too, by avoiding the investigation and
reversal of unwanted changes.
There's no end to the things we could do more conveniently and more
reliably if we had a really pervasive PKI.

@_date: 2003-05-21 14:30:47
@_author: Mark H. Wood 
@_subject: Encouraging email security. 
Hash: SHA1
This points indirectly to part of the problem:  people tend to associate
cryptography with secrecy only.  But OpenPGP and S/MIME also do signing.
Maybe you don't send sensitive or embarrassing material, but what if
someone else sent embarrassing statements, and put your name at the bottom
and your address in the header?
I usually don't have any secrets to hide, but I don't want to be
misrepresented, and I'd sign everything I send if I wasn't embarrassed to
have you all find out that I haven't yet collected a single nonself
signature on my key -- oops! :-/
I'm not a crook either; I want to use encryption to give the crooks a hard

@_date: 2003-05-21 15:40:02
@_author: Mark H. Wood 
@_subject: Encouraging email security. 
Hash: SHA1
[snip good point about embracing the diversity of email clients]
And who needs mutt when we have pine? :-)  (See, I agree with you.)
BTW pine works just fine with gpg, thanks to pgpenvelope (or pgp4pine,
but I've switched).  Now if I could find a way to make pine handle S/MIME
as well, without giving up OpenPGP, I'd be all set.  (A brief look at the
gaggle of RFCs required to describe S/MIME suggests that it won't be quite
so easy.)

@_date: 2003-11-07 17:47:55
@_author: Mark H. Wood 
@_subject: gnupg for a multiuser system 
Hash: SHA1
There's nothing wrong with it.  It's just another namespace.  How would
you do this differently?  (Technically, yes, per-user data don't belong in
the SYSTEM hive; they belong in each user's hive.  Is that what you're
To do a proper job, the entire gpg.conf ought to move into
HKCU\Software\Gnu\GPG, and the underlying storage mechanism (Registry on
Win32, ~/.gnupg on Unix, etc.) be abstracted.
That would seem to be something we don't have now.  All I see on that
Windoze box over there is HomeDir, which contains the keyrings and

@_date: 2003-10-10 17:22:02
@_author: Mark H. Wood 
@_subject: Problems Installing GnuPG 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
An important point.
Yes, but there's also such a thing as observing established convention.
In the Win32 world, applications ought to default to installation into
%programfiles%\vendor\application (where %programfiles% is the localized
name of the Program Files directory, and should be obtained from the shell
using the function provided for that purpose) and should note its presence
by creating the key HKLM\Software\vendor\application in the Registry.
There's another key (I can look it up if you wish) which makes a file
"known" to Win32, so that you can just mention "gpg.exe" and Win32 will
know where to find it whether it is on the PATH or not.  You can even use
a value of that key to specify additions to PATH which apply only to that
program, which occasionally comes in handy.  Much neater than plunking
non-OS applications into %windir%.
All of this (and much more) is somewhere in the Logo Requirements
document, and I wish more developers (including a lot of billion-dollar
companies, *sigh*) would read it.  I've long since made a note to see what
I can contribute to the packaging and integration of GnuPG for MS Windows,
but since I never use it there I haven't done much yet.

@_date: 2003-10-10 23:52:46
@_author: Mark H. Wood 
@_subject: Windows multi-user installation? 
Hash: SHA1
I set it up that way to try it out with Thunderbird, but I recall having
to move stuff into place and tweak the Registry by hand.  It seems to work
once everything is set.
The one part that may be painful is getting the HomeDir value in
HKCU\Software\Gnu\GnuPG set properly for each user.  There may be a way to
cobble together a simple Windows Installer package that will set this up
on each user's first run, using the tools that come with WinInstall LE on
the Win2k Server kit or your favorite .MSI package builder.  Or you could
arrange for users to run gpg.cmd, gpg.vbs, or whatever to stuff the
Registry and then run the actual gpg.exe, which would likely be a lot
simpler, albeit messier.

@_date: 2004-04-07 19:07:28
@_author: Mark H. Wood 
@_subject: openPGP vs x509 
Hash: SHA1
You're asking the wrong list.  The necessary work is all in the browsers.
You need to add a different type of certificate evaluation to each
browser, together with a new user interface to control it, one which will
be somewhat more complex than the existing "I trust this certificate
implicitly to certify any web page from whatever domain it says it's for"
UI.  There's no way to express user-specified trust levels in existing
BTW, certificates can be had for free, but trust is *always* one of the
costliest things you can desire.

@_date: 2004-12-13 16:36:55
@_author: Mark H. Wood 
@_subject: Signature in Attachment 
Hash: SHA1
Our corporate email group runs Exchange.  My MUA is Pine.  Outlook is not
an absolute requirement to work with Exchange.
(Okay, because I'm a former Postmaster and refugee from the mainframe
world, my setup is a little more complicated.  Incoming mail is sucked out
of Exchange using fetchmail, injected into Exim, and delivered to a local
mailbox.  Outgoing mail goes through Exim to wherever Exim thinks it
should go, and it does the Right Thing for mail back to Exchange
accounts.  It all gives me something to tinker with over lunch.  But Pine
plus a PGP/MIME filter should suffice, so long as Exchange is set up to
offer IMAP.)

@_date: 2004-02-10 16:11:30
@_author: Mark H. Wood 
@_subject: Question about backdoors 
Hash: SHA1
I hope they are going to teach you all to ask better questions, somewhere
in that class.
Can a backdoor be put into GNUpg, or any open-source product?  Certainly.
Would its secrecy have a useful lifetime?  Almost certainly *not*.  Is
there, therefore, any point in trying?  Probably not enough to be worth
the effort.  How does this risk compare with that from some closed-source
product?  I will leave that as an exercise for the student. :-)

@_date: 2004-05-17 19:02:23
@_author: Mark H. Wood 
@_subject: key-signing for pseudonyms 
Hash: SHA1
Is there a book somewhere, where someone generally thought trustworthy (or
several someones) has worked out what it would mean to sign keys given
the possession of different kinds of knowledge about the person presenting
the key?  I find the subject too slippery as yet to completely trust my
own reasoning.

@_date: 2004-05-18 16:26:04
@_author: Mark H. Wood 
@_subject: key-signing for pseudonyms 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Exactly!  What does a given label *mean*, and does it help you establish
the relationship you consider to be "identity" for your particular
purpose?  I did a search a few years back and found three other guys in my
home town alone who are named Mark Wood.  One even has my middle initial.
Say someone is in the Witness Protection Program.  You've checked out his
name and other details, and it all matches his records.  Have you
identified him or not?  It depends on what you want to know.
I think that before we ask how we can identify someone, we need to ask
ourselves, "what do I mean by 'identify'?"

@_date: 2004-11-08 13:58:47
@_author: Mark H. Wood 
@_subject: Should I use S/MIME? 
Hash: SHA1
I'm not prepared to address the original question, but some of the
responses are dancing around an issue which, in my opinion, is too little
Whether that is a good idea or not depends on what you (as the sender,
*or* as the recipient) want an identity document to mean.  If it's good
enough to be able to strongly suggest that the sender of message A and the
sender of message B are the same (possibly unknown) person, then these
essentially anonymous certificates should suffice.  If, on the other hand,
someone wishes to identify the sender of a message with some entity or
event outside the realm of e-mail (and there are legitimate reasons to do
so) then more investigation is needed to bind the certificate to that
other identity.
I wouldn't give much weight to the word of a CA which depends on e.g. AOL
to supply real-world identity checking.  I don't know what the ISPs do to
identify people, beyond assuring themselves that the checks are bankable.
I'd accept such a certificate as usefully meaningful if I received it
physically from a known individual described by the certificate.
(Yes, I'm well aware that my own PGP key is as yet signed only by me.  I'm
still looking for a way to find someone *known to me* who also uses PGP,
and meanwhile it at least allows me to tell people personally that they
should discount messages appearing to emanate from me which are not

@_date: 2004-11-09 14:32:19
@_author: Mark H. Wood 
@_subject: OK, here goes trouble... re c:\gnupg 
Hash: SHA1
[snip some history]
The difficulty arises because some people want the MS Windows version to
work like every other MS Windows application, and some want it to work
like every Unix application.  Your proposed behavior is probably the best
compromise between these two irreconcilable desires.
The default user-settings directory can *and should* be dependent on the
OS, because the conventions are different.  On Unix-alikes it should be
$HOME/.gnupg, and on MS Windows it should be %ApplicationData%/gnupg/gnupg
(the first "gnupg" is the "vendor" and the second the product).
The product should not be installing itself directly off the root of the
file system.  A product using an active installer should ask the user
where to install itself, and the default should be
%ProgramFiles%\vendor\product .  Further, no per-user data should *ever*
be stored there, unless the user insists; user settings go in the profile,
as indicated above, unless the user says otherwise.  (OTOH I usually try
to keep layered products *off* of %SystemDrive% and complain bitterly when
the installer doesn't let me change the install path.)
(I've shown the environment variables ApplicationData and ProgramFiles,
but those paths should actually be fetched using the appropriate Shell
APIs.  Microsoft say that the variable names may be localized, but the API
argument constants won't change.)
On MS Windows an executable can discover the path from which it was run,
and that's probably the best way for the product to find its installed
location.  There's also a Registry key AppPaths somewhere in which the
path should be stored if other applications need to find yours.
I may be arguing for a lot of stuff that's already been done, because I
only use GnuPG on Linux and haven't seen the MS Windows deployment.  But I
do develop stuff for MS Windows [hangs head in shame] and the above is the
way that MS Windows fans will expect things to work.  People who want
things to work as in Unix should IMHO use Unix, but sometimes one can't,
so some *optional* accommodations for that situation would be a great

@_date: 2005-04-13 17:56:59
@_author: Mark H. Wood 
@_subject: OpenPGP Smartcard Advantages 
Hash: SHA1
That reminds me:  would someone please point me to a thorough discussion
of why I should be able to trust a smartcard, given that an untrusted
computer has complete control of the channel between me and my card.

@_date: 2005-08-01 16:51:09
@_author: Mark H. Wood 
@_subject: Entropy in ascii-armored output? 
Hash: SHA1
I find many FIPS-181 "words" to be significantly more memorable than
unconstrained strings of random printables and they should be reasonably
strong if they're not too short.  VMS' SET PASSWORD/GENERATE command
supposedly uses this method and has been in the field for many years.
If you need a really long secret you could always make up a "sentence" of
shorter FIPS-181 "words".  It might be easier to remember than one long

@_date: 2005-08-09 15:18:02
@_author: Mark H. Wood 
@_subject: validate_key_list failed 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Me, too. :-/ I completely emptied my public keyring, one key at a time,
looking for the damage and never found it.  Eventually I renamed the empty
file away and built a new one, and now I have no more trouble.
I don't know whether a keyring file is supposed to shrink when substantial
numbers of keys are removed, but it never did.

@_date: 2005-08-09 15:33:08
@_author: Mark H. Wood 
@_subject: Extra information in public key 
Hash: SHA1
I think this looks like a job for a directory service.  About half of
those attributes are already defined in some X.500 schema and could easily
be dished up via LDAP, which any recent MUA ought to understand already.
Using a directory service for directory service sounds better to me than
overloading key subpackets.  How about just one simple record (a URI?) to
provide the linkage from the key to the directory object?  (I'd be very
much surprised if there isn't an attribute ID allocated for PGP keys
already, which can effectively provide the reverse "link".)

@_date: 2005-08-12 15:56:47
@_author: Mark H. Wood 
@_subject: Access experimental subpackets of 'User Attribute Packet' 
Hash: SHA1
Better you should lobby the vCard maintainers to define "message integrity
suggestion" fields, so your vCard can include a key fingerprint and
preferred server.  The vCard is already attached to your message -- we
don't need another copy in the key.
Finding out more contact information for you is an identity question, not
an authentication question.  The key need contain only information which
helps us to bind it to its owner, such as an email address or a small
photo.  That some of the information on a vCard can be used for such
purposes is incidental; that's not what it's for, and what it's for is not
what keys are for.
Packing too many different kinds of information into a single service is a
kind of overoptimization.  Better to build several clean, simple,
well-defined services and let clever people figure out new combinations of
data as they have need.  Then they can just join records across the
services holding what they need for a custom view of the available data
which accomplishes their purposes.

@_date: 2005-02-28 15:51:11
@_author: Mark H. Wood 
@_subject: GnuPG and registry keys 
Hash: SHA1
If PortableThunderbird behaves undesirably in such circumstances, it is
improperly designed.  Tell them to read the Logo Requirements again.  User
settings go in HKCU, and systemwide settings go in HKLM, and if some
software is confused by the presence of both then it must be rewritten to
correctly implement this distinction, at which time the confusion will
This is definitely bad behavior.  Every "designed for Windows xxx" product
creates such a key for itself.  Only that product's uninstaller should
remove such keys.

@_date: 2005-01-01 17:36:57
@_author: Mark H. Wood 
@_subject: signing a robot's key - was: Re: Global Directory signatures 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
So, looking up PGP Corporation in the phone book, calling their corporate
headquarters, and verifying the fingerprint with a person wouldn't help?

@_date: 2005-01-02 19:02:10
@_author: Mark H. Wood 
@_subject: signing a robot's key - was: Re: Global Directory signatures 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
How is this different from trusting an unknown person I've never met
(before) on the basis of his being able to produce a couple of cards which
have his likeness (more or less) and the name he gave me?  One reason I
haven't been to any keysigning parties is that I wouldn't trust my ability
to verify someone's identity.
*All personal identification is role-based.*  It just depends on which
role is important to you.  Do you care that I'm the child of my parents?
employed by a certain employer? the author of a body of emails? the person
living at suchandso address? the person who bought the property at
suchandso address? the person who put money into your bank, or borrowed
money from your bank?  Those are all me.  It's reasonable for various
entities to care about some of those roles and not others, and to be
satisfied with any sufficiently trustworthy binding to the significant
role regardless of any bindings to any other roles.  My bank doesn't care
whose high-school grades those are.
"Who are you" is a devilish difficult question to answer, or even to
And no matter how you verify someone's identity, you're still playing
probabilities.  Someone could knife me in an alley, destroy the body,
submit to plastic surgery until he looks and sounds just like me, learn my
handwriting and my style and habits, and essentially become me in any way
you might test.  He's got my primary identity documents, after all.  How
likely is that, though?  Now how likely is it that someone marched into
PGP's HQ, shot the receptionist, and is calmly sitting by the phone while
guards are running to find out what the noise was, just when my call comes
in?  (How likely is it that the receptionist is allowed to verify the
company's key fingerprints anyway?)
Bad guys *could* do all kinds of sneaky things, but how likely is it,
what would it cost them, and would they be able to recover the cost
(including the cost of being found out)?  Is it worth the expectation of
trading a nice job for a cell to trick me (that is, nobody) into signing a
bogus key purporting to be from a low-security thing like this?
An artificial person is a lot easier to check out than a natural person.
Have *you* been eyeballed by SEC, D&B, the states of California and
(probably) Delaware, and a host of commercial banks?  I haven't.  Having
established that PGP is likely on the up and up, how likely is it that
they wouldn't take reasonable care with the security of one of their
services' keys, given that their entire income stream is based on a
reputation for reasonable security?
I'd be more likely to trust an unknown person bound to a large business by
a trusted introducer (the telco) than an unknown person with only his own
name for identification, when the former's job and freedom are on the
line and the latter's likely not.

@_date: 2005-05-20 16:17:32
@_author: Mark H. Wood 
@_subject: Keyservers and the future 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
I don't see any connection.  PGP is a sublayer of the application layer.
Transport-layer trust is a separate issue.  PGP takes no notice of
transport mechanisms.
If I receive a message with an invalid PGP signature, or an unsigned
message from someone who habitually signs messages, I don't care how many
MTAs swear that the address is trustworthy; the *message* still appears to
be a forgery.
Transport authentication and message authentication address different
problems.  The only effect of widespread transport authentication on PGP
ought to be a small decline in use of PGP by people who don't understand
the distinction and are enjoying a false sense of security.

@_date: 2005-05-26 16:29:59
@_author: Mark H. Wood 
@_subject: IBM to Provide Security w/o Sacrificing Privacy Using Hash   
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Organization A know a name and the hash they calculated from it.
Organization B know a name and the hash they calculated from it.  If the
hashes match, either A or B can request from B resp. A the plaintext
corresponding to the ordinal of the hash record that matched, to verify
the hit.  Now A and B share the plaintext.  The plaintext is not recovered
from the hash; it's requested from the entity which has it, using the hash
to find it.
The whole point of using a hash is to make it extremely unlikely that
either party could recover the plaintext unilaterally.  It's like having a
vault with two different locks, and giving the keys to two different
people, to make abuse more difficult by requiring collusion for a
successful penetration.
It's worse than that.  I don't know of anybody who spells his name
"Aleks", but both "Yuri" and "Yuriy" are in use, not to mention (usually
from another part of the world) "Uri".  Likewise both "Mark" and "Marc"
are common.  It doesn't have to be an error to be a false mismatch.
If I understand what e.g. Soundex does, it should be possible to compare
hashes of Soundex-coded strings in order to reduce the incidence of false

@_date: 2006-08-21 16:32:51
@_author: Mark H. Wood 
@_subject: GnuPG neophyte inquiries. 
Hash: SHA1
Assuming they spent the extra $100 for XP Professional rather than the XP Toy^wHome edition that comes with most PCs (which has only the protection-free VFAT).

@_date: 2006-10-03 17:21:29
@_author: Mark H. Wood 
@_subject: Logo suggestions 
Crossed spears on a recatngular field of 1s and 0s?

@_date: 2006-10-18 15:40:04
@_author: Mark H. Wood 
@_subject: RFCs, standards, pink bunnies and flower patterns 
Precisely.  Once MIME enters the picture, the user agent must be
looked at as a collection of subsystems driven by the MIME structure
of the message.  None of the subsystems (other than the MIME parser)
*ever* deals with a whole message; the user agent is presented with an
assembly of bodyparts and deals each part out to the subsystem best
equipped to interpret it.
There was a previous comment asserting that various applicable
standards require certain content-types in the *message header*.  Any
such standard is broken, because the thing with which it deals may be
nested within a hierarchy of other things (with other content-types)
of any depth.
What *should* happen is that a multipart/signed or multipart/encrypted
bodypart is detected *somewhere* within a message; it is given to
gnupg or pgp or 'openssl smime' or whatever to interpret; the
interpreted content is given back to the MIME interpreter; the content
is seen to be a multipart/alternative bodypart; the user agent (for
reasons I will never understand :-) selects the text/html bodypart;
that bodypart is given to an HTML interpreter, and as text/html is
terminal w.r.t. MIME the process is complete (up to the node at which
the multipart/whatever bodypart resides).
External references from text/html bodyparts are the concern of the
HTML interpreter; the OpenPGP interpreter has already done its job.
If they are to be secured, HTTP specifies mechanisms for doing that.
It sounds like some user agents are continuing the grand tradition of
implementing MIME poorly where they bother to do so at all.  I suspect
that the sign/encrypt community's role here will be limited to
repeating, "if you would follow the specifications then it would Just
Work" until the clue is accepted.

@_date: 2007-04-18 09:39:39
@_author: Mark H. Wood 
@_subject: Lost passphrase 
A good point.  But it applies equally to any other lifetime, including
the current default.  What this suggests to me is that the end user
drops out of the equation, because from the POV of the abstract
"typical user" no value that the developers choose is any more
supportable than any other.
This frees the developers to ask another question: "what value would
be good for the product's reputation?"  A moderate one (1-2 years)
seems like a reasonable answer, since it provides some protection to
the user who has no policy or omits to apply it, but isn't
tremendously burdensome.  Still, some thought and discussion would be
good.  Is there any science to support certain ranges of values in
certain applications?

@_date: 2007-04-26 08:43:33
@_author: Mark H. Wood 
@_subject: Generating and storeing keys on usb pen 
Yes, that's something important to remember about any removable
storage medium.  But the two situations are not equivalent.  Placing a
trojan on a storage volume for someone to choose to run is not at all
the same as breaking into the logic of a device controller to plant
autonomous malware.  What evidence do we have that USB controllers are
reprogrammable once they leave the factory?

@_date: 2007-12-21 13:26:40
@_author: Mark H. Wood 
@_subject: [Announce] GnuPG's 10th birthday 
Hear, hear.  Consider the asymmetric nature of the conflict.  A small,
loosely-knit organization with few, simple operations in the works is
much more likely to prefer the superior security of a handful of
arbitrary single-use codes agreed to in face-to-face meetings to the
use of algorithmic encryption.  PGP and the like are most useful to a
large, busy organization because the sheer volume of traffic makes
other types of secrecy impractical and relatively insecure.  If
terrorists are using PGP it is probably because they haven't thought
about it very much.
Any systematic method can be broken sooner or later.  But, if "how is
uncle George" means "attack at dawn", how could you possibly calculate
that if you weren't in on the secret already?  What good would it do
you to learn that after the fact, if that meaning is abandoned after a
single operation?
I use PGP because it provides more than enough protection for my
personal and professional business and allows me to easily communicate
in reasonable security with large numbers of people I've never
personally met.  I require a meager amount of secrecy and a good deal
of ease-of-use.  This is just about the opposite of the requirements
of a guerilla, who risks lives and The Cause on communicating
sparingly with a very few well-known partners who already know most of
the message.

@_date: 2007-05-16 10:06:55
@_author: Mark H. Wood 
@_subject: Printing Keys and using OCR. 
If you want reasonably accurate data from OCR of scans of fonts not
specifically designed for OCR then you need to proofread the output
and correct as necessary.  Outside of tightly controlled
circumstances, OCR is not going to be fully reliable without this
I keep a paper copy of my revocation key in locked storage, and if I
ever have to use it I figure I'll just type it by hand.  It's really
not very many characters.  It would be more trouble (though more fun)
to try to scan and OCR it than to just go the low-tech route.
The barcode ideas sound interesting, but letterforms were designed for
a system that has very different ways of processing information, and
very different strengths and weaknesses.

@_date: 2007-05-18 09:54:54
@_author: Mark H. Wood 
@_subject: Printing Keys and using OCR. 
Of course, paper can also be eaten by bugs or mildew, which wouldn't
be interested in polycarbonate or Mylar.
The lesson here is that, regardless what medium you choose, let the
rated lifetime guide you in developing maintenance procedures but DO
NOT depend on it; take each volume out of the vault every year or so
and check it.  The manufacturer will cheerfully refund your purchase
price if their product fails, but how will you get your information
Anything that absoultely MUST be readable after umpty-ump years should
be replicated, all replicas tested frequently for readability, and
recopied as needed.

@_date: 2007-10-19 09:11:19
@_author: Mark H. Wood 
@_subject: PGP messages getting flagged as spam 
Why?  I mean, what evidence is there that the owner of the key used to
sign the signed content had anything to do with the unsigned content?
Signed content in the interior of a message conveys no information
about the trust one might choose to assign to the rest of the message.
A properly written rule shouldn't care that there is signed content
inside an unsigned message.

@_date: 2008-04-15 09:37:45
@_author: Mark H. Wood 
@_subject: How trust works in gpg... 
What it is meant to do I can't say, but I hope that it does *not*
assign trust to others' keys automatically.
What I would expect is that what gpg does on its own is to
authenticate a use of a key:  does this crypto blob have the
properties necessary to be judged a valid use of key X?  But the
*meaning* of that validity *to me* is a judgment that no machine can
make.  I should have to grant trust myself, because gpg cannot know
enough about me to do it for me.
I may trust B's handling of his own keys, but not trust B's judgments
about F's handling of *his* keys.  The safest thing for gpg to assume
is that I assign no trust at all until I have instructed it
otherwise.  B's signature on F's key is information that I might take
into consideration, but I might (for example) decide merely to
remember that datum and observe F's behavior for a while before
trusting F's key.
As for whether you should do anything about your associate's
additional UID, you should consider the proposition that what you are
willing to say to the world about your associate as an individual, and
what you are willing to say about his persona as a representative of
his employers, may be two different things.  For one thing, the
handling of his "company" UID may be dictated by policy beyond his
control and not altogether in his hands.

@_date: 2008-04-21 09:30:34
@_author: Mark H. Wood 
@_subject: Naming of GnuPG 
So, GnuPG 1.4 implements OpenPGP.  GnuPG 2.0 implements OpenPGP and
So 2.0 is "better" than 1.4 if you need S/MIME, otherwise not.
So, perhaps 1.4 should be GnuPG and 2.0 should be GnuPG-Plus.
(Please, no "++"!)

@_date: 2008-04-24 09:22:40
@_author: Mark H. Wood 
@_subject: Miscellaneous questions 
Besides, as the Bard says, what's in a name?  Binding a key to a name
doesn't tell you much.  First consider what it is you want to prove,
and then you will know what bindings you require.
Consider also the distinction between the information required to
investigate an identity and the information required to use it.
Banks, insurers, employers, etc. want a great deal of information to
establish the identities of those with whom they do business, but they
don't write it all on the outsides of envelopes that they mail to
us.  Maybe you want to check my DNA before signing my key, but
should I make my genome part of my identifier?  Trust in a signature
derives from the signer, not from the subject.
The user ID really only needs to be a label with sufficient
information to decide:  "this seems to be the person I want, so I will
investigate further."  No matter what information is asserted in the
user ID, you would have to test the assertion by other means before
accepting the identity as meaning what you require.  *Once the
identity is authenticated* you can use the key binding as a shortcut,
assuming that you trust the key's holder to take proper care with it.
And then there's the question of roles.  "HRH Izzy IV, King of Upper
Loa, Duke of Absentia, Protector of the Faith" is a bit much when
exchanging mail with relatives, but a salesman might want to provide
quite a bit of detail when cultivating business relationships with
strangers all over the globe.  Generalizing, your business role ID might
need more information than your personal role ID, and details would be
different and different in nature when acting for your employer
vs. for your church or civic organization.

@_date: 2008-04-24 09:34:52
@_author: Mark H. Wood 
@_subject: Miscellaneous questions 
Well, if you want to be pedantic (and I think this is a good place for
it), no object can be an identity.  An identity is a testable
relationship among collections of objects, such as "(1+1) = 2".  A
given object may be part of many identities -- for example, (4/2) = 2.
A name or a key may *label* a particular identity.  So your question
perhaps should be:  which set of labels do you want to use?
This is why I keep banging on about what a binding *means*, or what
you want to prove.

@_date: 2008-08-13 09:39:06
@_author: Mark H. Wood 
@_subject: public newer than the signature 
Would that it were that simple.  The epoch (time 0) means different
times in different OSes.  Unix uses the above, Microsoft products use
another, VMS system time is the quadword number of nanoseconds since
some time on some date in (IIRC) November, 1858 (associated with some
astronomical catalog), etc.  SQL has its own ideas about how to
measure time regardless what your OS believes.  Even on the same OS
you may find different sets of functions that work with different
representations and may even use different epochs.
It's a valid point that how the machine counts time and how various
programs represent time as text are two different matters, and that
typically the OS presents time in a form that makes arithmetic easy
and the userspace program is responsible for making it comprehensible
to humans.
Time is a mess, dates doubly so.  That's why I usually write something
like either 13-Aug-2008 or 20080813T093730 even if it does make people
stop and think.

@_date: 2008-08-20 12:04:39
@_author: Mark H. Wood 
@_subject: Securely delete files... [going further off topic] 
Hmmm.  You'd have to ensure that every point within the coating on
every platter reaches the critical temperature (perhaps for a minimum
amount of time?).  That sounds too uncertain when certain destruction
is required.
The binder in the coating also has some critical temperatures and
might do Interesting Things before reaching the pigment's Curie
Point.  In a sealed box, no less.  I have no idea what will happen,
but maybe you should before trying the experiment.

@_date: 2008-08-20 16:18:47
@_author: Mark H. Wood 
@_subject: Securely delete files... 
Have they ever tried a disk that's had the coating polished off with a
wire-wheel chucked into a portable drill?  Dust is usually fairly
Or how about supposedly happened to the Purple cipher machine just
before Pearl was hit:  hammered to bits, dissolved in acid, poured in the
flower beds.

@_date: 2008-01-29 16:58:13
@_author: Mark H. Wood 
@_subject: IDEA 
That is not precisely correct.  A source kit for GnuPG can be found in e.g.
  /usr/portage/distfiles/gnupg-2.0.7.tar.bz2
while the IDEA patch is found in e.g.
  /usr/portage/app-crypt/gnupg/files/gnupg-2.0.4-idea.patch
It would be correct to say that Gentoo does not distribute GnuPG
binaries, with or without IDEA.  The package management system
(portage) gathers tarballs, patches, etc., constructs a source tree,
and compiles it on the target system.
The "instructions", to be clear, are the ebuild file that portage uses
to automagically build the software for you.
I can state that I have GnuPG built by portage on my Gentoo systems,
and it does not include IDEA.
  mwood at mhw ~ $ gpg --version
  gpg (GnuPG) 2.0.7
  Copyright (C) 2007 Free Software Foundation, Inc.
  License GPLv3+: GNU GPL version 3 or later
  This is free software: you are free to change and redistribute it.
  There is NO WARRANTY, to the extent permitted by law.
  Home: ~/.gnupg
  Supported algorithms:
  Pubkey: RSA, ELG, DSA, ELG
  Cipher: 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH
  Hash: MD5, SHA1, RIPEMD160, SHA256, SHA384, SHA512
  Compression: Uncompressed, ZIP, ZLIB, BZIP2
A quick look at the 2.0.7 ebuild suggests that portage will apply the
IDEA patch but not enable IDEA.  But I'm nothing like a portage
expert, so don't give my analysis of ebuilds too much weight.

@_date: 2008-05-02 11:54:20
@_author: Mark H. Wood 
@_subject: filtering signed email with thunderbird 
Better to ask on a Thunderbird list.  I think that the best way to
tackle this problem will be independent of GnuPG and specific email
formats.  Thunderbird "knows" quite a lot about a message by the time
it is ready to present it, and it is not unreasonable to ask that all
of this knowledge be made available to filters.  So rather than
constructing elaborate match expressions for, what is it? three very
different ways of signing mail, I'd suggest finding a way to just ask
the guts of Thunderbird whether a message was signed, whether the
signature was verified, what public key matched, and anything else
your filter needs to make a good decision.
If Thunderbird doesn't provide that kind of information to filters
then it sounds like a nice subject for an extension.
(Sorry, I only use Thunderbird when mutt isn't readily available, and
never very elaborately, so I can't be more specific about it.)

@_date: 2008-05-02 20:42:53
@_author: Mark H. Wood 
@_subject: playing with cryptography... 
"whether you do or not" is not strictly correct, I think.  It sure
looks to me like I could delete some or all of the root certificates
that my browser came with, and then keys from certificates which chain
back to those removed roots would no longer be implicitly trusted.
I've never yet heard of anyone who *did* that, mind you, so in
practice the system seems to work as you say.  But I don't see why it
has to.

@_date: 2008-05-22 14:37:28
@_author: Mark H. Wood 
@_subject: playing with cryptography... 
Aw, how hard is it to go to  look for the seal, and see
that an independent auditor (apparently KPMG) has examined their
practices and given an opinion on whether they follow their own
policies and procedures (which should be published, so you can inspect
them)?  If you think the seal is faked, ask the auditors.
Which evaluation is what Certification Practice Statements are for.
The CA's CPS should be one of the inputs to the audit.
This stuff all works.  It just works differently.

@_date: 2008-05-22 15:00:40
@_author: Mark H. Wood 
@_subject: how long should a password be? 
FWIW I usually use a gadget called 'apg' to generate random
passwords.  It has a mode in which it will only produce strings that
are pronounceable (sometimes just barely so), which I find a great aid
to memorability.  For example, I can recall my home WEP key easily
even though I almost never see it.  Usually setting a minimum of 8
characters produces a satisfactory result.
If I want something much longer than that, I make up a phrase or
sentence using one or two random strings from apg as "words".
I have not tested the strength of these choices, but I'm satisfied
that they produce something better than I would without mechanical

@_date: 2008-10-22 10:29:38
@_author: Mark H. Wood 
@_subject: There is no limit on the length of a passphrase, 
Nitpick:  a glyph is a specific drawn letterform.  There are many ways
to draw, for example, a "Roman capital A" (serif/sans, upright/slant/italic,
various degrees of boldness or extension, innumerable sizes and many artsy
styles) but they all map to one Unicode code point and one encoding in
e.g. ASCII.  A glyph is a representation of a language symbol, but not
the symbol itself.  All of those variants are members of the class "Roman
capital A".
A passphrase *could* be an image, but usually is a sequence of
character codes.  So, although most readers probably understood
"glyph" in the way I believe it was meant, I think we should be using
some other word.

@_date: 2008-09-18 14:30:29
@_author: Mark H. Wood 
@_subject: Changing preferences 
True, not true -- it's not *clear*.
It sounds like GPG will find the intersection of the sender's and
recipient's cipher lists and then take the sender's "preference" from
that list -- that is, the first member of his list which is in the
Good point.  If Alice sent the message then I would expect AES256 to
be selected; if Baker, then TWOFISH.  An exchange will alternate
ciphers.  Correct?
Who *should* win?  That question, if it must be answered, sounds like
it belongs to the OpenPGP WG.
But how much do we care?  Two parties who can communicate at all (that
is, have at least one "preferred" cipher in common) will always do so
using one of the ciphers they are both willing to use.  Is that good
There seems to be confusion over whether to treat cipher preferences
as lists or sets.

@_date: 2008-09-22 10:17:45
@_author: Mark H. Wood 
@_subject: Changing preferences 
There's the problem right there.  "Used" when?  When sending?
apparently not.  When others send to me? apparently so.  Somehow the
two cases (I send; I receive) should be disentangled.

@_date: 2008-09-23 08:58:10
@_author: Mark H. Wood 
@_subject: Changing preferences [again and again and again....] 
You are not alone; I've received dozens of copies.

@_date: 2008-09-23 09:53:40
@_author: Mark H. Wood 
@_subject: Changing preferences 
Sounds good to me.  It seems to cover what people mostly need to know,
and is compact enough for a man page.

@_date: 2009-02-24 10:55:31
@_author: Mark H. Wood 
@_subject: "Please select what kind of key you want" ~~ suggestion to 
Well, I would suggest that it goes deeper than that.  The world first
needs to learn to *want* literacy.  There is no demand for a thing, no
matter its excellence, until people see why they ought to want it.
We're at a disadvantage here, compared to the benefits of reading,
because successful use of crypto usually goes unnoticed.  The most one
can hope for is that an attacker will have more persistence than
sense, and become intrusive enough to be detected by the wary before
he succeeds.  The smart ones will either succeed quickly and quietly,
or walk away.  *Are* there any success stories more compelling than,
"no compromises that we know of so far"?

@_date: 2009-02-26 11:32:51
@_author: Mark H. Wood 
@_subject: future proof file encryption 
Staggering off-topic a bit, this also points out that, for a variety
of reasons, if you want to store data for the long term, you need to
establish a periodic review of every single item in your archive.
You need to be aware of obsolescent medium types and file formats and
suchlike, and recode at-risk items using then-current best practice.
You need to be aware of media volumes that are degrading, and copy
at-risk items to fresh volumes before they become unrecoverable.  You
should copy older volumes from time to time anyway, at intervals
appropriate to the medium, to evade trouble before it starts.  This is
a good opportunity to switch to a newer medium if there is one you like.
You also need to archive things you might need to recover your items.
File format documentation, useful software, and the like.
If you do all that, your archive should be usable in toto for hundreds
of years, which is probably longer than you need.  Much of it can be
automated, requiring your attention only briefly.
Or you can stash it all in an old shoebox, like the rest of us do. :-/

@_date: 2009-01-16 08:21:27
@_author: Mark H. Wood 
@_subject: Dan Brown - Digital Fortress book 
[Freon decomposition products include phosgene]
Well, it's a tangled mess.  There are many different chemicals which
have been sold under the Freon name.  Mr. Brown may have confused any
of these with Halon, another large family of fluorocarbons which
*have* been used for fire suppression, including data centers.  They
all seem to be on the way out, due to the ozone-depleting properties
of halogens in the upper atmosphere.  I haven't examined all of the
Halons, but I don't recall seeing any chlorinated ones, and without
chlorine you can't make phosgene.
I'd sometimes wondered about the phosgene link, and finally looked it
up.  Its name has got nothing to do with phosphorus (which isn't used
in any of these chemicals), but to the use of light to power the
reaction in which it was first synthesized.  So says Wikipedia, anyway.

@_date: 2009-03-02 09:19:13
@_author: Mark H. Wood 
@_subject: future proof file encryption 
Silver chemistry is (or, at least, it used to be) much more resistant
to decay than color dyes.  You still have to be sure that the print
has been archivally processed (mainly to wash out all traces of hypo,
which otherwise will continue doing the job it has in the process and
eat away at the silver grains).  You still need to keep it away from
atmospheric contaminants when not in use.  You can plate the grains
using a bath of gold chloride to protect them a little longer.  You
can use vesicular film rather than silver, if you can still find it,
for even longer storage.  (Huh, *silver* chemistry is getting harder
to find.)
Used to be that color photos which had to be preserved for a long time
were stored as separation sets:  three silver images were made to
capture the three primary colors from the image, to be reassembled
later and reconstitute the color image using the ordinary dye
process.  Dunno if it's still done.  I'd put my trust in a
well-maintained redundant set of digital scans, these days.
Most photos won't really need all this fancy treatment; you enjoy 'em
while they last, and keep making new ones.  The problem is, often we
don't understand which ones *should* have special preservation, until
it's too late.

@_date: 2009-03-04 09:02:42
@_author: Mark H. Wood 
@_subject: surrendering one's passphrase to authorities 
I don't quite grasp the nuances of whether entering a password is or
is not in itself testimony.  But one interesting aspect here is that,
until the drive is decrypted, its contents cannot become evidence, and
the government is left with only the testimony of the border control
officers as to what might be contained in the defendant's property.
If the drive cannot be examined by the court, the government's case is
somewhat weaker.  So that's one non-ulterior motive for wanting the
password entered.  It matters less, in court, what LE know, than what
they can demonstrate.
This of course does not dispose of other possible motives.

@_date: 2010-01-07 13:27:16
@_author: Mark H. Wood 
@_subject: Web of Trust itself is the problem 
I think this hits way below the level of technology.  We haven't been
taught useful ways of thinking about our security and identity
w.r.t. the world we now live in.  When concepts like "authentication"
and "trust" are seriously discussed in grade school (perhaps in
smaller words :-) then we'll begin to build a society (as opposed to a
few experts and enthusiasts) which is prepared to use these tools
effectively.  As it is, few know *how* to care about their privacy.

@_date: 2010-01-12 09:48:52
@_author: Mark H. Wood 
@_subject: Web of Trust itself is the problem 
[but test subjects didn't react to the warning]
Yes indeedy.  Those ad.s appear at the top of the page (and elsewhere,
but there's *always* one at the top).  We're rigorously trained every
day to ignore stuff at the top of the page that doesn't look like what
we expected.  Maybe he should try a bar across the *middle* of the
window, or a diagonal, or alpha-blend a red overcast onto the entire
Still, it's another technology-intractable problem.  If people cared,
they would train themselves to look for trouble indicators, like
scanning the dashboard from time to time for problems with speed,
fuel, temperature, etc.  We're trained to operate motor vehicles, but
not to operate browsers or MUAs.  ("It's intuitive!"  Not.)  And
meanwhile the world is training us that it is vitally important to our
sanity and the defense of our time to learn to detect and ignore
things that we don't care about.
I think that technology can't help this as much as would knowing why
we want some technology.  People who feel a need will look for tools
to deal with it; people who feel no need will ignore the finest tools.

@_date: 2010-01-22 11:17:24
@_author: Mark H. Wood 
@_subject: distributing ones public key (email) 
Oh, yes.  My tongue is nearly bitten through from suppressing the urge
to respond, "what did you think an 'application/pgp-signature'
attachment is?"  I too would like to find some way to get the word
out about what it is and why my correspondent might find it desirable.

@_date: 2010-06-11 09:34:44
@_author: Mark H. Wood 
@_subject: Keyserver spam example 
If there is such an RFC, it's rubbish; I run an MTA at home on my
dynamic address, and it works just fine, and is quite valid.

@_date: 2010-06-21 08:47:13
@_author: Mark H. Wood 
@_subject: AUTO: Richard Hamilton is out of the office (returning 06/24/2010) 
RFC2919, anyone?  This list uses the List-* headers.

@_date: 2010-03-03 10:53:51
@_author: Mark H. Wood 
@_subject: key question 
I'm just waiting for a few businesses to be sued for making decisions
based on failure to understand what we can actually know about someone
from e.g. the signatures that happen to appear on publicly served
copies of his certificate.  Maybe then they'll wise up.

@_date: 2010-03-03 11:16:21
@_author: Mark H. Wood 
@_subject: key question 
There are issues of tradecraft, then.  Using OpenPGP as a tool for
committing crimes is kind of stupid.  There are more secure methods
for a closed community to secure its lines of communication.  If one
chooses the wrong tool for a job, or chooses to use it incorrectly, no
blame attaches to others for the consequences of one's choice.
I feel there is a strong assumption among OpenPGP users that our
community is, *ahem*, open.

@_date: 2010-03-03 12:12:31
@_author: Mark H. Wood 
@_subject: David's findings 
I think this exercise says something about the relative value of
attempts to control the distribution of one's personal data, and of
power to effectively punish those who abuse one's personal data.

@_date: 2010-03-04 12:25:09
@_author: Mark H. Wood 
@_subject: key question 
Yes, I thought that was what you meant.  If the state in which one
communicates prohibits encrypted communication, and one communicates
over an encrypted channel, then one has already committed one crime
(in the eyes of that state), whatever the content or purpose of the
communication may have been.
Were I the individual, I would think long and hard about using a tool
which would require me to defeat its features that create identity
labels (however false or information-poor) and carry them along with
the message.  I would be drawn toward tools whose methods carry no
identity data themselves.  You can't accidentally misuse a feature
that isn't there.

@_date: 2010-10-08 10:16:13
@_author: Mark H. Wood 
@_subject: Seahorse 
If you ever decide to promote that alternate interface, the approach I
would try is to sneak it in by actually making it an alternative:  put
the traditional interface on one tab and the "simplified" interface on
another, and let users live with them for a while.  People may start
out conservative, but some of them will become curious and try the
Cost, from the user's point of view: a small dab of complexity (the
tab panel) and a small slice of screen real-estate (the tabs).

@_date: 2011-04-08 09:41:46
@_author: Mark H. Wood 
@_subject: Signing a key (meaning) 
Sounds like some people could use a signature type which means:  "I
disclaim all signatures made by ".

@_date: 2011-04-18 11:46:29
@_author: Mark H. Wood 
@_subject: A better way to think about passwords 
I think the author of the page was on his way to saying something
important but got sidetracked.  Whether his math works or not is
secondary to the bit I think is important.
It's easy to build gadgets which yield passwords that are
mathematically very strong.  The problem is that such passwords tend
to be psychologically and pragmatically weak:  you'll never remember
Instead you'll wind up writing it on a scrap of paper and carrying it
with you, and any pickpocket could take it.  The essence of a password
or passphrase is that it is something you just learn, so that it
cannot be taken from you without violence.
So an "all-around strong" key generation method must take into account
psychology as well as cryptology.  Its output must at the same time be
easy to learn, difficult to guess, and infeasible to calculate.  The
obscured point in the article is that insisting solely on
ever-increasing mathematical complexity is psychologically unsound.
It tends to make the system's users into another class of adversary
whose goal is to bypass the complexity rules so he can get logged on
and do work without first spending an hour trying to recall something
that looks like line noise.  A legitimate user should not have to
crack his own password more than three or four times in a decade.
Mark H. Wood, Lead System Programmer   mwood at IUPUI.Edu
Asking whether markets are efficient is like asking whether people are smart.

@_date: 2011-04-18 13:02:05
@_author: Mark H. Wood 
@_subject: A better way to think about passwords 
Oh, sure -- I do that too.  But the CC memorization problem seems a
lot easier.  First, it's all digits, not a typical Base64 mishmash.
Second, it's not a 23-digit number; it's a 16-digit number, a date,
and a 3-digit number.  The hardest part by far is the 16-digit number.
But since that number doesn't have any particular meaning to me *as a
number*, it can be further broken down to a sequence of four
four-digit sequences.  Four four-digit numbers, a date, and a
three-digit number doesn't sound difficult at all -- it's only six
symbols.  Chunking at useful level(s) can greatly assist learning.
OTOH if there are any useful groupings in "c2l4IHdvcmRzIGxvbmcuCg=="
they are not readily visible to me.  My eye tends to slide right past
it without taking anything in.
This is why I tend to use something like APG to generate strings of
nonsense *syllables*.  If I can pretend it's a word, it's a lot easier
for me to learn, because can I learn a handful of syllables instead of a
long patternless jumble of individual characters.  It engages auditory
memory and can expose verbal handles for association.

@_date: 2011-04-19 10:14:31
@_author: Mark H. Wood 
@_subject: A better way to think about passwords 
Well, memory seems to be a highly individual thing.  Mine is not so
good in some ways, and I've had to learn to search for the kinds of
patterns that I find memorable.
Frequent use helps too: I've learned to put repeating "touching base"
notes on my calendar to make me learn passwords to things which are
infrequently accessed but urgent when I do need them.  (I don't put
the passwords in the calendar, of course!)
Incidentally, I've sometimes substituted a mechanical nonsense word
into a phrase, mostly just to satisfy some nag about "you should
switch to a passphrase".  So I wound up with things like:
  Paul McCartney fakbetyest Abbey Road Studios
I don't expect it to be much stronger than the nonsense word alone,
but perhaps it will encourage a complex cracker to waste time on
clever shortcuts before falling back to brute force.  These I find
more or less equally memorable as the word alone.

@_date: 2011-04-27 10:25:38
@_author: Mark H. Wood 
@_subject: Passphrase 
Then it's useless.  Because brute force will *always* succeed.  It may
not succeed in your lifetime, however. :-/
To the OP: someone probably could suggest a brute-force tool, but if
your passphrase is strong enough to have been worth using then the
tool would likely run far longer than you care to spend.  That's the
point of having a passphrase.

@_date: 2011-04-27 10:31:38
@_author: Mark H. Wood 
@_subject: Passphrase 
Maybe he thinks that the key might be compromised in the future.  It's
still out there.  There is a lot of future left.  He has lost control
of the key.
(I know:  I'm arguing both sides.  I don't have a key guesser to share,
and we don't know enough about the problem as the OP sees it.)

@_date: 2011-04-27 11:09:00
@_author: Mark H. Wood 
@_subject: Is the OpenPGP model still useful? 
Some thoughts:
o  Agreed:  OpenPGP is difficult.
o  Media-hopping:  each segment can be treated separately.  The users
   know there is a thread of conversation but the technologies do
   not.  So, is this point relevant?
o  Who is the attacker?  A government with sufficient motivation and
   money should have little trouble getting carriers to inform them of
   who is involved in a given flow in near realtime (say, by forwarding
   the log streams out of their RADIUS servers), and matching that
   to a watch list is trivial.  These are exactly the people who would
   be doing large-scale collection.  A personal rival probably
   couldn't afford it.  (This is directed at the "distinguishment"
   factor.)
   Today the chief difficulty for a state really isn't technical or
   financial, but legal.
o  "Encrypt each communication (Facebook post, SMS, whatever) with a
   random 40-bit key.  Throw the key away.  Send it."  Isn't that what
   we do now?  Or do you mean:  encrypt *everything*; don't ask, just
   make encryption the default for all communication.  I could get
   behind that.  (I've argued for some time that we ought to do away
   with HTTP-not-S, not-S-SMTP, etc. and this just extends the
   argument to another layer.)
o  Agreed:  most people don't care about most of their messaging.
o  Just so long as those who *do* care can plug in or wrap on something
   stronger and more manageable if they wish.

@_date: 2011-02-16 09:54:39
@_author: Mark H. Wood 
@_subject: Help with OpenPGP plugin in Mozilla Thunderbird and Claws Mail 
I'm going to stick my non-expert neck out, because this seems to need
more than a brief answer.
No; the key ID *names* your keypair.  The public and private keys are
much larger objects.  The ID is related to them but doesn't contain
them.  The ID is used to identify particular pairs.
Ultimately, someone who wants to verify signatures from you or send
privacy-protected messages *to* you using GnuPG will need a copy of
your public key.  You can deliver the public key itself, or you can
publish your public key on a keyserver and give correspondents your
key ID, which is usually enough to identify your public key, and they
can use the ID to fetch a copy of the key from the server.
The advantage of sharing the ID is that it is short enough to just type
into an email or write by hand in a letter, while the keys themselves
are a few *hundred* characters long.  I could easily learn my key ID,
but the key itself (7122 characters!) is far beyond my power to
The advantage of delivering key copies directly is that you control
the distribution of your public key (assuming you can trust your
correspondents to honor your wishes).  A published key can be fetched,
signed, and resubmitted by *anyone*.  Some people have reason to desire
control over who signs their keys.  Their reasons have been discussed
on this list.  Keys can be exported to removable storage or attached
to a message.
The way I would proceed:
1.  Get a list of your secret keys and locate the one you want to work
    with.  You probably only have one so far, so this is pretty
    simple.
2.  Note the key ID.  It's an 8-character hexadecimal number.
3.  Locate the public key with the same ID.  That's the public key you
    are trying to distribute.
4a. If you intend to give copies of your public key to your
    correspondents, export that key to a file.  If you are offered the
    option of producing an "armored" key file, you probably want that
    -- the resulting file is all printable characters and travels well
    through email.  Unarmored files are binary and can be damaged by
    some methods of transmission, but have their uses too.
4b. If you intend to publish your public key to a keyserver, this is
    the key to publish.  Tell your correspondents the ID to fetch.  Or
    just start signing messages on the assumption that their message
    agents offer options to fetch and verify keys from keyservers.
Specifically how you do all that depends on which tool you are using.
The following use commandline tools because that's what I use.  If you
are using a GUI tool then it should offer similar operations.
You can get a list of your secret keys using "gpg
--list-secret-keys".  You'll see something like:
  /home/foobar/.gnupg/secring.gpg
  -------------------------------
  sec   1024D/12345678 1858-11-01
  uid                  A. User (an optional comment)   ssb   1024g/87654321 1858-11-01
The middle column of the "sec" line is the size, type, and ID of the
key.  The ID is the part after the slash.  You can double-check this
by then using "gpg --list-public-keys 12345678" (or whatever your key
ID is).  You should see a similar display except that it says "pub"
instead of "sec".
You probably have only one secret key so far, so figuring out which ID
to use is pretty easy.  If you ever have more than one, use the "uid"
lines to figure out which is which.
Now that you have your key ID, you can send your public key to a
keyserver if that is how you want to work.  "gpg --send-keys 12345678
--keyserver keybucket.example.com" will publish the key with id 12345678
to the server keybucket.example.com.  To fetch someone else's key, use
--recv-keys and the other person's ID instead of --send-keys and your
There are a number of public keyservers.  Their merits have been
discussed on this list.
If you'd rather deliver copies of your public key individually, you
can get it using "gpg --armor --export 12345678 > public-key.asc".
The new file public-key.asc will then contain an "ASCII-armored" copy
of your public key suitable for importation into someone else's
OpenPGP implementation.  You may be as open or secretive as you wish
with this file, as it doesn't contain your private key.
GnuPG has *many* other functions and options.  GUI tools in front of
it are similarly endowed.  You should look them over so that you know
what's available to you.  You don't have to understand every single
one of them right away, though you *do* need to thoroughly understand
the ones you use.
Just the use of personal cryptography is a large and complex topic.
I recommend you do some further reading before relying on your
understanding (or mine!) for the protection of sensitive matter.  It's
easy to do things that only make you *think* you are secure.

@_date: 2011-02-21 17:25:44
@_author: Mark H. Wood 
@_subject: Some SHA-2 news 
Hrm, well, the Second-System Effect refers to a problem with
designers, not releases.  As Brooks put it, "this second is the
most dangerous system a man ever designs." (1)  It refers to the
designer's typical advance from caution, to boldness, to mature
The accumulation of complexity over time probably belongs to the
Creeping Featurism family.
1  Brooks, Frederick P., jr.: _The Mythical Man-Month_, p. 55

@_date: 2011-01-13 10:23:01
@_author: Mark H. Wood 
@_subject: What is the benefit of signing an encrypted email 
Better not to send unconsidered emails at all.  One of the reasons I
often prefer email to a telephone conversation is the opportunity to
read what I have written, tighten up the language and logic, and do
research to support my claims or check my knowledge.  Even so, I
discard a lot of the emails that I write, having realized that they
aren't worth sending.  I try never to send a message I would dislike
to have signed.
Defaulting to an explicit choice to sign does however seem to be the
best design.  People who think about what they are doing can override
it, and people who don't think about what they are doing will at least
confront the opportunity to think before doing one thing they may rue.

@_date: 2011-01-13 10:06:47
@_author: Mark H. Wood 
@_subject: What is the benefit of signing an encrypted email 
Well, guarantees are worth more than suggestions, but suggestions can be
worth something too.  The problem comes from paying attention to
illusions rather than interpreting the evidence as it is.

@_date: 2011-07-20 09:33:58
@_author: Mark H. Wood 
@_subject: Yet Another Mail Encoding Thread 
[increasingly offtopic rant]
Well, a *proper* MUA would send both text/html and text/plain
bodyparts in a multipart/alternative container, so that a *proper* CUI
MUA could render the important part of the message without all the
markup.  But the evidence suggests that many maintainers of
HTML-possessed MUAs still do not read standards. :-P
Some character-cell MUAs will, in desperation, delegate HTML rendering
to a character-cell browser and then display the result.  I'm willing
to go the extra mile with messages that can be so treated, if the
actual text is intelligible.  Often I find that this yields something
more readable than what the sender thought I would see.  But some MUAs
do not even mark their HTML output as HTML, foiling this. :-{
When I open a message and see nothing but a farrago of markup, I
generally throw it away unread.  Unless it's an anticipated message
from a known sender, it's too much trouble even to type "v", "m" to
force it through lynx.
Sent from my big clunky desktop using Mutt.

@_date: 2011-03-16 08:53:49
@_author: Mark H. Wood 
@_subject: GPG and PGP 
On that day it would be well to already know what to do about it and
already have the tools in hand.  It would be best to have already done

@_date: 2011-03-23 15:06:41
@_author: Mark H. Wood 
@_subject: Deniability 
An interesting thought.  I'm going to keep this one.
My suspicion is that we never had anywhere near as much privacy as
many believe.  A hundred years ago, when nobody had computers or
databases or Internets, everyone in town knew your name, your address,
your occupation, your family, your approximate economic status, your
(ir)religion, your circle of friends, and many past deeds you'd rather
have forgotten.  We may actually have *more* privacy these days, when
so much can be done in secret and only the machines know until someone
thinks to ask the right one in the right way.
We can also raise the cost of improper use of information.  I don't
think there's been enough attention to this.  If Alice draws
insupportable or downright illogical conclusions about my character or
status from my online presence, and on the basis of those conclusions
makes decisions on my employment or my insurance premiums or whether I
ought to be prosecuted for something, can I punish her *enough to make
her stop*?  If she's following company policy, can I punish the
company *enough to make it stop*?  Enough power can make privacy

@_date: 2011-05-10 13:54:43
@_author: Mark H. Wood 
@_subject: PGP and "Smart" Cards 
Good luck.  The merchants don't seem to care, and the banks still
think that the name of my third-grade teacher is some kind of closely
guarded secret.  It's not going to happen unless required by law or in
response to some hugely expensive (and successful) class actions
against card issuers.  The customer is the only one with a compelling
incentive to change the system.

@_date: 2011-10-18 10:00:29
@_author: Mark H. Wood 
@_subject: STEED - Usable end-to-end encryption 
I don't see why the ISP has to be the entity providing DNS lookup.
The one I use won't even allocate me a static address, let alone
accept RRs from me to serve out to others.  I'm not sure I'd trust
them to get it right and *keep* it right anyway.
If the ISPs won't cooperate, maybe the antivirus vendors would.
They're already in the data security business, already have an
extensive network presence, and already get money from me to help me
secure my information assets.  Build enrollment into the AV product or
provide a separate setup tool.  It should be simple.
Likewise there are freestanding DNS providers out there who already
have the infrastructure and the experience, are already serving some
of us, already get money from some of us.  This could be a welcome
source of a little more income for very little more cost, or a freebie
to get you in the door like free DDNS does.
(I should read the paper; maybe this has been addressed.)

@_date: 2011-10-18 09:42:19
@_author: Mark H. Wood 
@_subject: STEED - Usable end-to-end encryption 
"Three can keep a secret, if two of them are dead."
If your computer holds the ultimate secret, anyone who can control the
computer can use that secret.  The user *must* be actively involved.
We can remove *needless* complexity, but security could be said to be
the art of *introducing* specific complexity that's a lot worse for
the attacker than it is for you.  It can't be automagical.
Anyway, key generation is already automated.  All you have to do is
(1) choose to employ crypto, and (2) supply a passphrase that you can
remember.  There are even methods and tools to help you do (2)!
To be secure without being involved in the process is an unreasonable
expectation which can never be met.  We need to teach our kids to
expect to protect themselves online the same way we teach them to look
both ways before crossing the street.  Probably at the same age.
Otherwise they'll grow up to believe the hype that you can buy
security the same as buying bread.

@_date: 2011-10-18 09:15:14
@_author: Mark H. Wood 
@_subject: private key protection 
Well, not quite.  Eventually you would get it.  The task of security
systems is to make "eventually" be longer than:
o  the payoff is worth; or
o  the time it takes to be discovered; or
o  the time it takes for the secured object to lose its value.
Statistically, that is.  You could get it right on the first try, but
you very probably won't.  You are guaranteed to get it right if you
try every possible value.

@_date: 2011-10-18 10:59:10
@_author: Mark H. Wood 
@_subject: private key protection 
I think we would be in error to think about "users" as a single class.
I usually try to educate lightly -- to make all users aware that there
is much more to learn, and to indicate how more learning might be to
their advantage.  Then provide sensible defaults, so that those who
choose to go no deeper will get some benefit, and in-depth
documentation for those who do choose to go deeper so that they can
reap the full benefit (or, at least, as much as each is willing to
work for).
I was pleased to see room for different classes of users in the STEED
paper.  When I encounter software that tries to be helpful, my own
first thought is:  how do I turn that off?  But I recognized long ago
that I was never a "typical" user and my own inclinations are no guide
to popularity. :-/

@_date: 2011-10-20 09:56:38
@_author: Mark H. Wood 
@_subject: STEED - Usable end-to-end encryption 
What proportion of consumer-grade ISPs have bothered to implement
DNSSEC for serving their customers?  I don't think mine does, and
they're a big outfit.  If I asked, I expect they'd think I was
speaking Aldebaranese or something.

@_date: 2011-10-20 10:17:59
@_author: Mark H. Wood 
@_subject: The problem is "motivational" 
o  Philosophical:  I just think that communication channels should be
   encrypted unless someone demonstrates a good reason not to.
   Perhaps it comes under the heading of not tempting others to sin. :-)
o  Protective coloration:  if email is normally encrypted, this further
   weakens the already-stupid argument that "if you want this much
   privacy then you must be up to no good."
o  Weariness of "duh moments":  some people throw their secrets around
   like confetti and then get all bent out of shape when this comes
   back to bite them.  Saying, "well, you could easily have protected
   yourself with X if you cared" is always unrewarding and always hard
   to eschew.  I'd rather not be tempted.
o  Taking unenthusiasm personally:  we obviously think this stuff is
   interesting and useful, and it can feel kind of insulting that
   others don't.
o  The telephone quandary:  if *I* want to communicate securely with
   you, then I need for *you* to have a compatible secure means of
   communication.  (If I'm the only person with a telephone, whom can
   I call?)
o  Cassandra complex:  the vague feeling that Something Bad Will
   Happen And I Didn't Warn Them.
That's all I can think of right now.

@_date: 2011-10-20 10:24:23
@_author: Mark H. Wood 
@_subject: The problem is "motivational" 
BTW I "have nothing to hide" but like my privacy anyway.  Privacy is
essential for maintaining personal boundaries, as well as security.
(That said, the vast majority of my use of crypto in email is to
establish identity, not to protect privacy.  I *want* to be positively
identifiable in most circumstances.)

@_date: 2011-10-20 10:37:00
@_author: Mark H. Wood 
@_subject: The problem is "motivational" 
I suspect that, for many, "too hard to do" is not as significant a
factor as "too hard to believe in".  Over here, doctors' offices have
at last been dragged, kicking and screaming, into the mid 20th century
and will at least use FAX to transmit prescriptions to the pharmacy,
but mention e-mail and they back away making the sign against the evil
eye, because they "know" it's not secure.
The office staff would all die of apoplexy if I told them how I *want*
it to work -- not because my notions are insecure, but because they
don't understand why those notions *are* secure.  (Assuming they are. :-)

@_date: 2011-10-24 11:15:16
@_author: Mark H. Wood 
@_subject: STEED - Usable end-to-end encryption 
I would suggest that, if you are trying to get people to think about
privacy, about the only thing worth saying to them (initially) is to
point out real-life examples of bad things happening to average people
who didn't think about privacy.
No one can desire salvation until he believes that he is in jeopardy.

@_date: 2011-10-24 12:02:07
@_author: Mark H. Wood 
@_subject: STEED - Usable end-to-end encryption 
And I agree with this.  The problem with applying the turn-or-burn
sermon to proselytization is that it requires that the audience
already believes in sin and hell, and that the problem is one of
raising awareness.  Unbelievers...don't believe.  It is fortunate to
such efforts that an argument couched in terms of benefit is available.
So, in the absence of any threat, what exactly *are* those benefits?
The cited passage asserts that the hearer is missing out -- he could
have more than he has now.  How much more can I get out of email by
using crypto?  What do I get, if I don't believe that my privacy is
threatened or I do not value privacy?

@_date: 2011-10-25 16:11:40
@_author: Mark H. Wood 
@_subject: STEED - Usable end-to-end encryption 
So, to summarize what I think I've been hearing: the problem which
remains to be solved (if it is a problem) is a nontechnical one, and
no amount of technical wizardry will solve it.  The most that can be
done now is to be ready to help someone who fears for his privacy and
asks, "what can I do?"
Maybe someday there will be a panic and everybody will be asking.
It's good to have an answer.

@_date: 2011-10-31 11:23:22
@_author: Mark H. Wood 
@_subject: digitally signing contracts 
I have no experience in this matter, but it's an interesting problem,
so here are my thoughts, whatever they are worth:
When contracting on paper, the signature is a personal characteristic
of the signer, so samples can be compared by an expert witness.
Unless there's some sort of biometric component to the creation of the
certificates, personal characteristics don't enter into crypto
signatures, so you need some other way to make it personal, such as a
face-to-face meeting at which certificates or at least key
fingerprints are exchanged by parties who can sense each other
directly, match photo IDs to faces, and the like.  You could consider
it a keysigning party for two and use published recommendations to
guide you in setting up the process.  Once personal control is
established, I suppose that no more meetings are required.  So this
would seem to work well for people who are able to meet once, and even
better for parties who then make contracts again and again from time
to time.
If trusted third parties are willing to attest to signatures then the
other parties only need to meet with the third parties, separately.  I
recall seeing notices by some notaries public that they also certify
PGP keys.
Another form of assurance might be the publication of key fingerprints
on the key owner's website.  (How much would you bet that your website
wasn't cached by Google or sampled by the Wayback Machine before you
changed the fingerprint?  A number of companies have found, to their
embarassment, that trying to "disappear" inconvenient pages is not
Still another form of assurance would be the publication of keys in
the keyserver network, since it's impossible to remove keys unless you
control all of the servers.  And again, someone may have a copy of
that certificate which is simply not remotely accessible but which
could conceivably turn up in court.
As with signatures on paper, you need to evaluate your risk and decide
whether it's acceptable.  Your insurance agent may be able to help.
If you read some of the laws governing admissibility of digital
signatures, you may find that your requirements are already laid out
for you, to some level of abstraction.  It's a possible starting
point, at any rate.  And your lawyer might be a good source of
pointers to procedural and technical recommendations, since that would
make his job easier.
I'll note that there are a number of companies in the business of
issuing durable digital identity tokens: X.509 certificates.  You
might want to insist on EV certificates, since EV has a documented
meaning and some CAs are not very energetic in identifying non-EV
customers.  In any case you probably ought to read the CA's
Certification Practice Statement and decide whether their procedures
are acceptable to you.  There may be sound ways to use X.509 material
to initialize OpenPGP exchanges if that's important to you, or you
could use PEM instead of PGP.

@_date: 2012-08-27 17:00:40
@_author: Mark H. Wood 
@_subject: Why "trouble"? 
Why is it a problem that most people don't see value in signing and
My answer is a selfish one:  because I do, and I want to be able to
have the benefit of those techniques in dealing with others.
I want to be able to (for example) exchange information with my doctor
by email.  He has to deal with privacy laws.  Theoretically, encrypted
email could satisfy that requirement (and mine too).  (No, I haven't
tried to apply HIPAA to OpenPGP.  But it's worth thinking about.)
I want to no longer have to fiddle with closed email systems that
require me to go to my bank's website to exchange written messages
with my banker.
I want to see those techniques replace the basketful of "enhanced"
authentication methods I have to deal with at various vendors' sites.
Anybody with a little time can look up my mother's maiden name, or any
of a dozen other things that some people think are soooo secret.  I
have little if any confidence in what they are doing; I'd rather
exchange certificates and keep my credentialling secrets entirely off
the 'net.
Like the guy with the first telephone, I need for lots of other people
to adopt the same technology in order to make it an everyday tool for
me rather than an expensive plaything.
I think that all this goes a lot deeper than technology.  I think that
we don't do enough to make thinking about trust and privacy part of
the normal way we interact.  Children are taught to use locks and
sealed envelopes, but they are not taught to generalize these acts.

@_date: 2012-08-28 11:32:26
@_author: Mark H. Wood 
@_subject: what is killing PKI? 
I was following along, nodding in general agreement, right up to
there.  I feel that a weapon, or encryption, is a tool.  Tools per se
have no social context; it is our actions, with or without tools,
which attach social context.  Using a weapon (whether it is a firearm,
a pillow, or a hunk of software) in a way not generally accepted is
(Aside: if you believe that lots of the people outside your home are
armed, and you go out anyway, that shows a lot of trust.  Almost
anyone could kill you, but they don't.  There's an agreement that
weapons be used only in certain contexts: see how riled up people get
when someone violates such an agreement.  The trust doesn't come from
the weapons; it is generated by the behavior of those who bear them,
and the penalties for violation of such trust are severe.)
I use encryption to enforce the privacy I already (should) have.  So,
yes, it's a weapon.  There are people who don't respect my privacy,
and if I don't defend it they may take it away.  Even if someone
penetrates my encryption, if I can show that he did so I may be able
to win a case against him in court, so it's (potentially) both a
passive and an active defense, a shield for my privacy and an
assertion that I will defend that privacy.
That said, most of the time I don't encrypt because what I say is not
something I consider private.  When I do consider something private,
I'd like to be able to communicate it electronically without fear that
someone I don't trust may be eavesdropping.
I could argue that it would be antisocial for someone to insist that
people not enforce their privacy.  We do not and should not trust all
equally in all situations.  Anyone may have lawful, moral business,
the disclosure of which would be so harmful (in his eyes) that he
might want assurance that only the intended recipient be party to the
discussion.  I doubt there ever was anyone who had *nothing* to hide.

@_date: 2012-08-29 10:18:14
@_author: Mark H. Wood 
@_subject: what is killing PKI? 
I'm not sure that the average person's current mode of living really
exposes him to a threat big enough to take seriously.  Rather than a
threat of actual loss, I feel that we face an opportunity cost: there
are things we could do differently, arguably better, if we could do
them securely via electronic media.
We simply wouldn't think of discussing possibly embarassing personal
matters with our doctors by email, even if the doctors would agree to,
so we don't ask.  We still carry around hand-scrawled prescriptions,
or cross our fingers and hope that the doctor's FAX calls to the
pharmacy are really secure, when we could (given the infrastructure)
get a (long!) number that can be verified as coming from the doctor,
verified to still say what he said, and unlocked only with our
personal smart card and PIN.  (Also it would have to be typewritten,
so it wouldn't be so hard to interpret. :-) We could do e-commerce
without worrying about our trading partners' losing a truckload of
backup tapes or being massively compromised from afar, because we
would never give them any secrets worth stealing.  We could manage a
handful of certificate passwords instead of a thousand website
passwords.  We could probably do a lot of other stuff that I haven't
thought of because, in our present nearly-naked condition, it's
Individuals wouldn't be the only beneficiaries.  The first bank in
town to offer free or discounted certificates *and* more-secure
e-banking would have a competitive advantage.  The first e-tailer to
offer security the others can't touch should win the business of
consumers who are worried by all the "'hackers' capture 200,000
passwords" stories in the papers.  The doctor or lawyer who adopts a
pervasive records security plan (of which customer communications
would be but a part) should be able to negotiate lower insurance
premiums.  It seems to me that people are leaving money on the table
all over.

@_date: 2012-08-30 10:20:10
@_author: Mark H. Wood 
@_subject: what is killing PKI? 
This is why jokes about anti-social networks are so much fun.
I would argue that this division cannot be done.  Associations always
include some and exclude others.
  ^ inclusive  ^                  ^ exclusive                            ^
           ^ inclusive                              ^ ^ exclusive
          ^
The NSDAP or the Ku Klux Klan were quite inclusive of anyone who
believed that certain racial and ethnic groups should be excluded from
society.  The difference (aside from methods of exclusion!) lies in
the nature of the discriminator function.
Indeed:  all purely exclusive clubs' memberships are identical to the
null set. :-)
Certain elitisms are usual, accepted, and beneficial.  I would not be
at all surprised to find that I am barred from membership in the
American College of Physicians and Surgeons, since I am not and never
have been either a physician or a surgeon.  I couldn't just walk into
the NSA, take a seat, and ask for some interesting crypto work to do;
there are qualities they would expect me to possess before I would be
accepted, and I would think they were doing a poor job if they did not
enforce those requirements.
No, it's only anti-social to exclude people for particular kinds of
reasons.  If someone joined your chess club, but never played chess
and always wanted to talk about nothing but soccer at the meetings,
sooner or later someone would ask him to leave.  Excluding someone
because he doesn't share the interest or aims of the group is
accepted; excluding someone because he doesn't share the race,
ethnicity, gender, etc. is (widely, but not universally) unaccepted.
Often it comes down to whether or not *anyone* could make himself
acceptable to the discriminator function if he wished.  Yes: function
is acceptable; no: function is not acceptable.  Within that there are
degrees of acceptability depending on the cost of the changes that
might be required, so requiring certain body piercings or religious
affiliations makes us more uneasy than requiring that someone show a
genuine interest in the topic of the group.  This is not a perfect
fit; the issue is quite complex.  But I think it's a usable first
To draw this back toward security and privacy through crypto: I think
it's natural and usual to want to exclude some from our
communications.  I want to exclude thieves from the set of people
having access to my banking credentials, for obvious reasons.  I want
to exclude just about everyone from my more intimate conversations
with my wife -- we feel comfortable being vulnerable in the presence
of those who love us, but uncomfortable showing that same
vulnerability to others.  In every society there are questions it
would be highly improper for a stranger to ask, often for good
reasons, and it is legitimate for us to employ appropriate tools to
protect our propriety.

@_date: 2012-08-30 10:33:32
@_author: Mark H. Wood 
@_subject: what is killing PKI? 
If I can prove that I possess my password without ever disclosing that
password to my correspondent, he never has my password and can't have
it lost or stolen.  "Three can keep a secret, if two of them are
It doesn't prevent backup loss; it eliminates the cost to me should
some vendor's backups go astray.  No one can learn my secrets from
people who never had them.  I only have to disclose my public key,
which is not secret, to my correspondents; my private key never leaves
my equipment unless someone penetrates *my* system or steals *my*

@_date: 2012-08-30 10:39:58
@_author: Mark H. Wood 
@_subject: what is killing PKI? 
More to the point:  my passphrase never leaves my equipment and isn't
recorded anywhere outside my brain.  You can only get it by getting
inside my computer.  That's not perfect but I like it a lot better
than the current setup.

@_date: 2012-08-31 09:40:53
@_author: Mark H. Wood 
@_subject: what is killing PKI? 
Actually that's quoting me.
True.  But it reduces the attack surface from "me + anybody in the IT
department at ${giant e-tailer} + anybody at the records management
service they use" to "me".  I think that's a significant reduction.

@_date: 2012-12-03 09:43:25
@_author: Mark H. Wood 
@_subject: OT: USB key with hardware encryption? 
Not to discount the value of media with built-in encryption hardware,
but...maybe you should also try the same methods as secure couriers in
the movies: attach the USB drive to a cord or chain clamped to your
wrist, so that it can't leave you without your knowledge.  You can
probably adapt a simple, cheap lanyard made for carrying thumb drives.
Losing control of your information is bad, but so is losing your work
and your valuable equipment.  Combining high- and low-tech measures
seems appropriate.
Of course there's also the lowest tech of all: designate a secure
place (a buttoned-flapped or zipped pocket, for example, or even a
money belt or a traveller's concealed document shoulder pouch) in which
you will carry the medium, and write out a checklist to make certain
that you've followed your procedure.

@_date: 2012-02-02 10:13:40
@_author: Mark H. Wood 
@_subject: On message signing and Enigmail... 
Well, no; what you know is that someone with access to the private key
and passphrase did it.  If someone steals your private key and
passphrase, they no longer uniquely identify you.  Signatures can't
protect against this form of imposture.
But they *can* protect against someone else simply creating another
key with the same name in it.  Not by themselves.  But the impostor,
in this case, cannot demonstrate control of your private key, and when
challenged, will be shown to be lying if he claims to be the person
who controls your key.
This still doesn't establish that the person named in the certificate
has control of the key, but use of the key to create a signature does
create evidence which can be investigated.  Someone could visit you in
person and ask you to create a recognizable signed object in his
presence using the same key.  If you can, then you are a person who
could have created the other signature.  If there is no evidence that
anyone else could have created the other signature, then there is good
reason to believe that you created it, though this is not proof.
Signatures also cannot establish *non*identity, since you could easily
have another key and pretend you don't.  If the key were somehow
produced, you could pretend you don't know the passphrase, and
demonstrate this any number of times by typing anything which is *not*
the passphrase.  This is roughly equivalent to claiming that unsigned
objects don't come from you.  The pattern that you establish is
evidence but not proof.
I would like to say that, while proof settles the matter, evidence
short of proof often has value.  I'm going to continue to sign every
email.  Besides, I'm too lazy to turn it on and off. :-)

@_date: 2012-01-23 09:24:03
@_author: Mark H. Wood 
@_subject: Using root CAs as a trusted 3rd party 
It seems to depend on the CA.  I know that one does a bit more
checking because, the first time I sent them a request, I got a call
from our corporate security officer to ask if I was really the one who
had sent that request, because the CA had asked him the same
question.  They had wanted some identifying information about us that
was not so easy for a mere computer wrangler like me to get, too.
That little bit of fussiness won my repeat business, BTW.  I figured
that being fussy is what we were paying for.  I wouldn't spend a dime
at one of those CC-clearance-is-good-enough-for-us outfits.
I guess that the lesson is:  don't assume.  Find out for yourself
whether a CA is worthy of your trust, before trusting.

@_date: 2012-01-27 09:20:23
@_author: Mark H. Wood 
@_subject: hashed user IDs redux [was: Re: Creating a key bearing no user ID] 
A difficulty here is that "spamming" is fairly specific, while
"privacy" (it seems to me) is huge, amorphous, and defined differently
by different people.

@_date: 2012-05-04 08:53:37
@_author: Mark H. Wood 
@_subject: SSH Agent keys >4096 bit? 
Let me turn things around.  Other than providing opportunities to
discuss the practicalities of large RSA keys, is there any reason why
the agent should care what size key it is storing?

@_date: 2012-05-24 08:55:54
@_author: Mark H. Wood 
@_subject: Testing GPG EMail encryption 
I have no idea how a debugger would know that you couldn't sign an email.
On my Gentoo system, there is no gpg v1 installed:
mwood at mhw ~ $ dir /usr/bin/gpg*
lrwxrwxrwx 1 root root      4 Sep 15  2011 /usr/bin/gpg -> gpg2
-rwxr-xr-x 1 root root 699072 Jun 29  2011 /usr/bin/gpg2
-rwxr-xr-x 1 root root 268352 Jun 29  2011 /usr/bin/gpg-agent
-rwxr-xr-x 1 root root 130720 Jun 29  2011 /usr/bin/gpgconf
-rwxr-xr-x 1 root root 142736 Jun 29  2011 /usr/bin/gpg-connect-agent
-rwxr-xr-x 1 root root  50627 Apr  2 15:28 /usr/bin/gpgdir
-rwxr-xr-x 1 root root    205 Jun 30  2011 /usr/bin/gpgen
-rwxr-xr-x 1 root root  18448 Sep 21  2011 /usr/bin/gpg-error
-rwxr-xr-x 1 root root   1804 Sep 21  2011 /usr/bin/gpg-error-config
-rwxr-xr-x 1 root root   8990 Apr  2 15:28 /usr/bin/gpg-key2ps
-rwxr-xr-x 1 root root  39320 Jun 29  2011 /usr/bin/gpgkey2ssh
-rwxr-xr-x 1 root root   4005 Apr  2 15:28 /usr/bin/gpglist
-rwxr-xr-x 1 root root   2750 Apr  2 15:28 /usr/bin/gpg-mailkeys
-rwxr-xr-x 1 root root   3521 Jan 11 09:14 /usr/bin/gpgme-config
-rwxr-xr-x 1 root root  26864 Jun 29  2011 /usr/bin/gpgparsemail
-rwxr-xr-x 1 root root   1708 Apr  2 15:28 /usr/bin/gpgparticipants
-rwxr-xr-x 1 root root  13830 Apr  2 15:28 /usr/bin/gpgsigs
-rwxr-xr-x 1 root root 382016 Jun 29  2011 /usr/bin/gpgsm
-rwxr-xr-x 1 root root   4635 Jun 29  2011 /usr/bin/gpgsm-gencert.sh
lrwxrwxrwx 1 root root      5 Sep 15  2011 /usr/bin/gpgv -> gpgv2
-rwxr-xr-x 1 root root 327504 Jun 29  2011 /usr/bin/gpgv2
-rwxr-xr-x 1 root root  22760 Apr  2 15:28 /usr/bin/gpgwrap
mwood at mhw ~ $ gpg --version
gpg (GnuPG) 2.0.17
libgcrypt 1.4.6
Copyright (C) 2011 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
As you can see, 'gpg' and 'gpgv' are symlinks to the v2 programs.
Nevertheless, I just sent a signed message to myself at another
address, from Thunderbird, using Enigmail.  It arrived signed, with a
valid signature.  Thunderbird + Enigmail + gpg2 works.  You should
consider the possibility that you have a different problem.

@_date: 2012-05-25 09:03:15
@_author: Mark H. Wood 
@_subject: Testing GPG EMail encryption 
However: because it works on my system, even though there is no GPG v1
installed on it anywhere, does demonstrate that gpg v1 is not required
and gpg v2 is not the problem.

@_date: 2012-05-25 09:06:26
@_author: Mark H. Wood 
@_subject: Testing GPG EMail encryption 
Sorry, that's lingering evidence of my VMS habits:
mwood at mhw ~ $ alias dir
alias dir='ls -l'

@_date: 2012-05-25 09:31:38
@_author: Mark H. Wood 
@_subject: Draft of nine new FAQ questions 
And life is too short to go trawling the Internet for X Compose
sequences.  If I could find a comprehensive table I'd probably use
them more.

@_date: 2012-05-30 08:57:11
@_author: Mark H. Wood 
@_subject: getting an encrypted file to show what public key was used 
Indeed.  The problem is much like a hash index.  And anyone who's used
hash indexing* should know that he must search the indicated "bucket"
for the record which actually matches the search key.  Hashing only
cuts the size of the search space; it doesn't guarantee reducing it to
a single-element space.
* And anyone who puts socks in one drawer and shirts in another has
  used hash indexing. :-)

@_date: 2012-05-30 09:40:35
@_author: Mark H. Wood 
@_subject: changing the default for --keyid-format 
Oh, how many times have I wondered why GPA has no search tool.
There's plenty of unused space to the right of "[bunch of keys] Key
manager".  To say nothing of the (perhaps peculiar) custom of placing
a "Find" operation on Edit menus.  The tabular display can stay where
it is.  Perhaps the search function (when there is one) could scroll
it, or sort all of the current hits to the top of the table widget's
I've been meaning to do something about that but, I'm ashamed to say,
I haven't gotten it done.

@_date: 2012-10-04 10:59:16
@_author: Mark H. Wood 
@_subject: what is killing PKI? 
I have anecdotal evidence that people *think* they can't.  Just this
week, my wife asked me how to change the passphrase on her PGP private
key.  Now, I would have expected this to be an easy, very visible
operation, and been thunderstruck if I should find it were not, but
whatever.  So I followed her to the computer and just sat there making
encouraging murmurs while she easily navigated Enigmail to the dialog
and did it.  If she had expected the software to be usable, she
wouldn't have needed me at all, because it is.
This isn't confined to crypto software.  A great many people have
acquired considerable skill with computers but little confidence
therein.  There seems to be a lingering expectation that you need a
team of experts to handle the unfamiliar.  Lots of people don't
realize that the experts have been and gone, that the result of good
engineering is that the engineer can go home and let you use the
machine without his oversight.
Oh, yes.  We have no choice.  See any number of articles about thieves
copying out tens of thousands of *plaintext* passwords from some
e-tailer's systems, or boxes of *unencrypted* backup tapes lost.
Those businesses still have customers.  I think that one hope of the
encrypt-by-default camp is that, when enough people see encryption as
normal, these execrable blunders won't happen anymore.  Another
anecdotal data point: I am still flabbergasted to hear that people
design their systems that way -- to me, it's just *not normal*.
Or look at the dozen messages I get every day purporting to be from
some bank or ISP, telling me that I must send them my password right
away or Bad Things will happen.  Someone must actually respond to
these, or the bad guys wouldn't keep at it.  Probably responsible
people, but they don't know *how* to behave responsibly in this
context.  I wish our trading partners would crypto-sign all of their
emails, so that it could be simple for people to spot scams, and those
scams at least would lose value and disappear.
This much I agree with.  But I wonder why they don't.  We don't
have to understand how locks are made, but we do have to understand
how to use them.  And the vast majority of Joe Average Citizens do.
Billions of people have learned to use banks and checkbooks at least
somewhat securely.  I think one difference here is that one is taught
from an early age and *expected* to learn their proper use.
Another is that financial institutions are in the business (when they
can remember it) of keeping things safe, and won't interact with you
unless you follow procedures designed to promote that safety.  Few
find this unreasonable.
Heh, of course I want people to make good practical use of crypto.
Not doing so is costing me time and money.  It's costing them, too,
because I will dump my cart and walk away from an e-store if I think
their processes are too loose -- and I won't be back.  Ceteris
paribus, I would choose a medical practice which has good secure and
convenient IRM over one that doesn't, and I'm learning how to find
that out.  I will write and mail a paper check if I don't trust the
look of your online payment system.
I'm not a security expert, but somehow I realized that I need security
in the virtual world as in the physical world and I had better
understand how to get it.  If more people would cross that bridge, I
wouldn't have to work so hard, because more of the burden would be

@_date: 2013-08-06 08:56:50
@_author: Mark H. Wood 
@_subject: Why trust any software? 
Heh, but then Gentoo Linux users will look at you strangely if you say
that you *don't* compile parts of your system. :-)
Sorry -- public key cryptography.
I don't see how this is different from a community building trust
relationships for email.
I suppose that you could rig a compiler to compute signatures over the
sources it reads and incorporate these signatures into the binary.
Likewise the linker.  The whole toolchain would have to be carefully
considered and modified to suit.  I haven't heard of anyone doing
that.  (Someone will now point out that we would be reposing even more
trust in the toolchain, making its verification more important.  Yes.)

@_date: 2013-08-14 10:50:35
@_author: Mark H. Wood 
@_subject: Can I create domain keys? 
How could you successfully pretend to be herrprofessor when your
signature (the only mechanically verifiable attribute of the message)
says hhhobbit?  The signature doesn't say anything about what the
message means or from where it was sent, only that someone controlling
a given key bound the text to himself.  Like those political ad.s
ending with "I'm John Q. Candidate and I approved this message," we
don't learn anything about the truth of the message, only that someone
recognizable is willing to stake his reputation on getting us to
believe it.
I would interpret the signature as an explicit denial that the sender
was someone other than the holder of that key.
Now, if I knew that herrprofessor and hhhobbit are the same person,
then I wouldn't think it very strange to see the two identities
mingled.  It would depend on how I have known him to use his
identities.  But if they are the same person, then what harm?  I try
to keep my personal and professional identities distinct, but some
people don't.

@_date: 2013-08-14 11:01:32
@_author: Mark H. Wood 
@_subject: Can I create domain keys? 
I see I am insufficiently devious.  I was assuming that the message
was signed with hhhobbit's key, not a forged key.
Now there are two possibilities.  If Herr Professor has no PGP key or
has never used it, then the signature has no reputation and should be
verified out-of-band.  Otherwise, there are now two keys asserting
that address and not linked by cross-signatures.  Suspicious, verify
It seems unduly risky.  Traditional methods of forgery try to bury one
identity under another, but forging PK certificates *asserts* a new
identity.  It feels to me like making too much noise -- it attracts
attention just when and where the forger wants to *deflect* attention.

@_date: 2013-12-03 09:30:28
@_author: Mark H. Wood 
@_subject: Any future for the Crypto Stick? 
I wonder how feasible that really is.  The system surrounding the card
is not under control of the card's manufacturer or anyone who might
have corrupted him.  All it takes is one knowledgable person watching
the data stream for interesting anomalies, and you have given the game
away.  The cost, as we've recently seen, could be considerable.

@_date: 2013-12-20 09:56:45
@_author: Mark H. Wood 
@_subject: [Announce] GnuPG launches crowdfunding campaign 
This is also common in USA, and seems to refer to the tradition of
giving a just-born infant a swat on the rump to encourage the
beginning of breathing (because the baby needs air to yell at you).
At any rate, it means as new as can be; freshly arrived, unpacked or

@_date: 2013-02-25 11:18:10
@_author: Mark H. Wood 
@_subject: US banks that can send PGP/MIME e-mail 
Well, there is a way to find out whether it works.  Those who care
deeply about this should get together, raise some capital, and open
NerdBank(tm) where they can do business their way, and see how it
goes.  There's plenty of room right now for people who want to
reimagine the retail banking business, so long as they still keep
depositors' money safe and deal it out as ordered.
I'm actually more interested in the local bank as portal to
certificate services.  Actually going physically to the issuer and
presenting, face-to-face, identifying documents that might actually be
slightly difficult to steal or forge, is not something that most
people can realistically do with the current crop of CAs.
Long-distance relationships in the security realm make trust
difficult, in both directions.
None of this has a great deal to do with OpenPGP or GnuPG as such.

@_date: 2013-02-26 09:29:43
@_author: Mark H. Wood 
@_subject: US banks that can send PGP/MIME e-mail 
Heh, exactly why I won't take those app.s.
I imagine that there is another class of security at work here which,
at some point, is still cheaper:  buy insurance and just pay off the
affected customers when something occasionally goes wrong.  I can't
point to any evidence, but it would seem to be the way that
businesspeople think about security.  Remember, from their viewpoint,
they are securing *their business*, not ours.
Careful:  "would like their statements delivered automatically" vs. "have
a desire to see OpenPGP used for statement delivery".
That sounds like human nature, but I would be interested to see
measurements if there are any.
As above.
We also have to consider the question of what the banks' lawyers will
let them do, once they pick their jaws up off the floor.  This is
probably the origin of the closed, private email system locked away
inside each bank's site.  That is, perhaps, where one should work on
acceptance of suitable encryption and signing.  ("Suitable" including
what will actually be used more or less correctly by a sufficient
percentage of customers.)

@_date: 2013-02-26 09:43:26
@_author: Mark H. Wood 
@_subject: Questions about OpenPGP best practices 
That service presents a self-signed certificate (I checked), which
means that if you do not already have a copy of that cert. installed in
your browser and marked trusted, then it cannot be verified.  You would
need to satisfy yourself that the certificate is genuine and the
service trustworthy, and then install the certificate in your browser,
in order to make the message go away.  (Well, at least one would have
to install the cert., whether one does any investigation or not. :-/ )
I have no idea about this one and I'm too lazy to go read the protocol
The site doesn't want unencrypted connections, and they way they
enforce this is by returning "no route" to requests for connection to
port 80.  I would have used "administratively prohibited", to give
real users a clue, but they may be trying to be less visible to 'bots.

@_date: 2013-01-04 08:50:56
@_author: Mark H. Wood 
@_subject: Is a document signed with hellosign legally binding? 
I don't know, but I must say that I'm wary of dealing with unknown
people who are collecting signature samples from all over Europe,
offering a service which seems to accomplish very little and making
disputed claims about its legal effect.

@_date: 2013-01-07 10:39:12
@_author: Mark H. Wood 
@_subject: Paperkey 1.3 
I'd suggest assuming some periodic read-only use, since we *should* be
testing our backups regularly to discover decay *before* it makes
something irretrievable.

@_date: 2013-01-08 10:25:39
@_author: Mark H. Wood 
@_subject: Paperkey 1.3 
[Hmmm, we are diverging a bit from Paperkey.]
This is why backup formats typically have internal redundancy.
(Printing the data as characters on paper adds a *lot* of redundancy.)
Depending on the medium, you might include error-correcting codes that
can recover from single-bit errors.  If you catch it at that stage,
you can copy it out and discard the failing medium.
Some codes will also detect errors that can't be corrected, so that
you know *now* to throw this medium away and make a new copy of your
other backup.  (You *do* have another backup?)  If you wait, they may
both turn out to be corrupt.
Every backup medium decays.  Long-term backups should be:
o  armored against bit-level decay;
o  tested regularly to detect degradation in progress;
o  replicated (and the replicas housed separately);
o  periodically refreshed or copied to new media.
I realize that most of us don't do any of that which didn't come with
the software, but we should. :-/
Of course, if an active device (like a flash stick) just stops working
and starts smoking, nothing can be recovered from it.  That's one of
the reasons you keep two of them.

@_date: 2013-07-24 08:51:53
@_author: Mark H. Wood 
@_subject: Multiple email addresses - any alternative to ask everyone to 
It's called compartmental design.  No one compromise destroys all your

@_date: 2013-07-24 09:15:16
@_author: Mark H. Wood 
@_subject: Multiple email addresses - any alternative to ask everyone to 
Absolute security isn't possible.  Any machine you are not shackled to
is sometimes out of your control.  The best one can do is make the
expectation of loss significantly more than the expectation of gain.
Smart attackers will go elsewhere and stupid ones can be caught.
Installing a keylogger represents a significant risk of detection.  If
"they" can do surreptitious monitoring, how do "they" know that I am
not doing surreptitious monitoring?  Remote log servers, firewall
logs, 'tripwire', cheap cameras the size of an aspirin tablet....

@_date: 2013-07-24 09:18:30
@_author: Mark H. Wood 
@_subject: Multiple email addresses - any alternative to ask everyone to 
Um, wait...what does other people signing your keys have to do with
you decrypting mail?  Authentication and privacy are two different
dimensions of communication security.

@_date: 2013-07-26 09:22:32
@_author: Mark H. Wood 
@_subject: Why trust gpg4win? 
But it takes only one person who can and does do this inspection, to
reveal the evil deed.  And that person could be anywhere.  He very
likely won't be identified until he announces his presence by
announcing his discovery of the attack.
Well, Windows users who aren't programmers, who switch to e.g. Linux,
will then be Linux users who aren't programmers, so this alone changes
little for the individual.  He is still dependent on others in the
community.  That is quite alright -- an important part of PKC is for
people to find out for themselves who is reliable and form open-eyed
trust relationships.
If one wishes to be more self-sufficient, one must learn a great deal
about work formerly left to others.

@_date: 2013-06-10 10:00:31
@_author: Mark H. Wood 
@_subject: Why OpenPGP is not wanted - stupid is in vogue right now 
Hmmm.  I begin to think that "privacy" is another one of those words
we should avoid because it is so vague.  Encryption is about secrecy,
which is a bit easier to define.  I could argue that someone
pretending to be me on email is an attack on my privacy and that
signing my emails thus increases my privacy (if my correspondents
accept my assertion that I don't send unsigned emails; if not, I might
argue that it at worst doesn't change anything).
Yes, let's get rid of "privacy" (the word).  We can have secrecy, we
can have verification of authorship, we can have several other
properties I've forgotten just now, and they are all aspects of this
misty thing called "privacy".  Privacy itself is a set of social
conventions:  there are aspects of my life which it is right and
proper for me to control, and it is wrong and improper for others to
attempt to control them, because my society generally agrees that
this is so and my government is (generally) willing to enforce laws
codifying these norms.

@_date: 2013-06-10 11:48:19
@_author: Mark H. Wood 
@_subject: Recommendations for handling (multiple) user IDs - personal and 
So, "think I need it" is a continuous variable.  Many people think
they need it, sort of, in a small way, but think they don't need it
enough to pay the cost of learning to use it.
Provided that potential user X understands his position, the threats
to it, and his values w.r.t. those, he may be drawing a reasonable
conclusion against which I would not argue.
People don't need to encrypt their grocery lists, except in the sense
that it's easier to always do something potentially useful than to
make a decision each time.  The CIA does not care that I send myself a
reminder to get a book on software testing; this is noise, for their
purpose, and they'd rather not handle it.  Identity thieves do not
care to know that I fed the dog this morning, though my wife does.
Occasions when I find myself thinking, "I'd better guard this
information" are exceedingly rare.
But that points at the real cost of crypto: you have to think about
it.  There is no escape; you have to think deeply about slippery
things like identity and trust and threat models, and then you have to
apply your resulting policies a hundred times a day.  Software can
relieve large parts of the latter burden; it can do nothing about the
former, which is the hardest part.

@_date: 2013-05-28 09:22:56
@_author: Mark H. Wood 
@_subject: [OT] Why are you using the GPG / PGP keys? 
Hmm.  Each upcoming generation declares many things to be ancient
practice that their parents use, no longer relevant.  A few years
later they have found out why their parents use it and are using a lot
of it themselves.  It might be useful to look at the just-got-here
generation to see what *they* use, now that they have so much more
official business than they had in school a few years ago.
It also might be interesting to break down interpersonal communication
by categories and see whether different material is migrating to new
media at different rates.  Are tired jokes we've all seen a million
times moving off of email to Twitter faster than detailed business or
technical discussion, for example?  Were we doing stuff by email five
years ago which really didn't fit the email model very well, which
stuff is today escaping to media better designed for it?  Are newer
channels swelling with content because nobody thought seriously of
sharing *that* when email (or a phone call, or a paper letter) was the
best available channel?
I'm not even sure who would study such things.  Anthropologists, I suppose.

@_date: 2013-05-28 16:05:39
@_author: Mark H. Wood 
@_subject: Relevance of e-mail (was [OT] Why are you using the GPG / PGP 
1.  Establish a pattern:  none genuine without this signature.  I
    understand it's not possible to prove that an unsigned message
    didn't come from me, but this couldn't hurt.
2.  OTOH I *can* show that a signed message must have been made with
    knowledge of a specific key, which I assert that I control.  When
    I do write something, I want my authorship to be believed.
3.  Habit.  The same reason I always automatically relock doors when I've
    entered:  if I have a policy then I don't have to make judgments
    in most cases.  (Yes, I *always* carry a house key.)  Considering
    all the gooey rubbish I *don't* send to my correspondents, I hold
    that the small cost of a signature is entirely negligible.
4.  Privacy.  While I prefer to hand-deliver things like new
    passwords, I'm willing to send them in encrypted emails if someone
    insists.  Or I might want to write to a family member something
    that's not super-secret but is nobody else's business.
5.  Cool factor. *blush*
6.  My signing habit is my tiny contribution toward a future in which
    any unsigned email is automatically suspect.  This would make it
    feasible, for example, to set up a rule sending all mail with
    no or unknown signature to a UCE folder (or the bitbucket).  I
    won't hold my breath while I wait, though.
I should distinguish signing and encryption.  I can count on my fingers
the number of encrypted emails I've sent, but I assert that I sign all
emails addressed to humans.  (Some mailing-list robots are fragile and
have trouble with signatures when directly addressed.  Boo.)

@_date: 2013-05-29 08:49:59
@_author: Mark H. Wood 
@_subject: Relevance of e-mail (was [OT] Why are you using the GPG / PGP 
Ha, that reminds me, when I submit artifacts to Maven Central (a
public code repository) I'm required to OpenPGP sign them.  Maven has
a very nice plugin which handles this automatically.

@_date: 2013-05-29 09:11:37
@_author: Mark H. Wood 
@_subject: [OT] Why are you using the GPG / PGP keys? 
The code is there.  The problem is that so few use it.  I always
enable STARTTLS but I see a lot of rejections.
I think that the problem that nobody wants to face is key management.
Vetting potential trusted introducers is *hard* and you have to keep
doing it periodically.  Maintaining trust stores is hard and tedious.
Most end users just don't do it.
To a certain extent the problem is fundamentally intractable.  Trust
is a complicated beast and depends on individual values and
judgments.  Automation can help but can't take it over.
I can't wait to see a serious legal or engineering discussion taking
place over Twitter.  No, on second thought I can....
Imagine if this thread were being carried on by us scribbling on each
other's Facebook walls.  *shudder*
Wow, *real* military use?  I want to see an iPhone after Raytheon has
had a go at it.

@_date: 2013-11-08 10:17:58
@_author: Mark H. Wood 
@_subject: gpgsm and expired certificates 
This bug seems to cry out for an add-on.  Then people who (think they)
know what they are doing can have the additional convenience, and the
rest can do whatever it is they do now.  I would guess there is
resistance to putting this into the base product on the theory that
99.9% of users will just hit "yes", meaning "get rid of this
unintelligible dialog and let me read the message", which is arguably
a Bad Thing.
Since we're getting offtopic anyway, I'll continue and opine that this
add-on would only be doing for self-signed cert.s and other unknown
CAs the same thing that the user *should* have done with those
commercial root cert.s: evaluate and install them individually.  (Of
course hardly any of us have done this.)

@_date: 2013-10-16 09:37:37
@_author: Mark H. Wood 
@_subject: trust your corporation for keyowner identification? 
Not without investigating their procedures.
Then let the corporation (i.e. HR) do the signing and you decide
whether to trust HR's signatures.
Really this should be designed into the corporation rather than pasted
on.  The chief security officer should somehow determine what would be
satisfactory procedures for verifying identity for the purpose of
issuing such signatures and get it accepted as a requirement for HR.
Probably this will be designed in consultation with HR so that it will
actually be implemented properly and not be a constant source of
pushback.  The meaning of such signatures should be documented and
published internally, so that relying parties know what they are
getting and can decide for what and how far they are willing to rely
on them.  Part of the determination should be the purpose and scope of
such signatures.
One factor in the steady drizzle of corporate security failures is
the notion that one can buy a box of security off the shelf and
thereafter be secure, without thinking about what one is doing.  It
seems to me that designing secure processes for your specific needs
should work better and be cheaper in the end.

@_date: 2013-10-31 09:36:12
@_author: Mark H. Wood 
@_subject: The symmetric ciphers 
I often worry about the assumption that there are no unfortunate
interactions between the structures of A and B such that the effort to
break A+B < min(a,b).  Consider a composition of *three* ciphers:
  A := ROT13
  B := ROT10
  C := ROT3
Each different from the others, though similar in operation.  But
(when the symbol set is the Roman alphabet) A(B(C(x))) = x.  Composing
these three ciphers produces a cipher worse than any of its
components.  Any order of composition will do the same.  Compose any
two of them and the result is no stronger than any single one.
Obviously this should not be assumed to hold true for all possible
functions, but it provides a counterexample: composing ciphers does
not necessarily produce a stronger cipher.

@_date: 2013-10-31 09:41:00
@_author: Mark H. Wood 
@_subject: The symmetric ciphers 
Having not read far enough down the thread, Mark H. Wood wishes to
recall a completely redundant message:

@_date: 2013-10-31 10:00:36
@_author: Mark H. Wood 
@_subject: The symmetric ciphers 
I sincerely doubt that there is, in the general case.  That's the
point: you have to analyze each combination as if it were a new,
untried cipher.  It seems useless to ask whether one can benefit from
composing multiple unspecified symmetric ciphers; much more useful to
ask whether e.g. AES+BLOWFISH is at least as strong as, or stronger
than, either AES or BLOWFISH alone.  Then ask the same question for
each composition you think promising.
You will wind up doing quite a LOT of math.  You could probably get a
book out of it, if you do a thorough job.

@_date: 2013-09-16 08:46:41
@_author: Mark H. Wood 
@_subject: Where is ECC in gpg2 (specifically gnupg-2.0.21 
On the one hand, we don't need to rush.  On the other, it is good to
see that people are thinking ahead, because I don't want to see
matters come to a state in which we *do* need to rush.

@_date: 2013-09-20 09:17:50
@_author: Mark H. Wood 
@_subject: Where is ECC in gpg2 (specifically gnupg-2.0.21 
If Alice does not trust the NIST curves, and Bob insists on using
them, this is a reason for Alice not to trust Bob because (in her
eyes) his security practice is lax.  Bob does not (in Alice's view)
take sufficient care to keep Alice's words confidential.  It is
reasonable for her then not to exchange confidences with Bob in this
A:  Can you keep a secret?
B:  No.
A:  Then I won't tell you any.

@_date: 2014-04-10 10:50:06
@_author: Mark H. Wood 
@_subject: It's 2014. Are we there yet? 
I think this one is easy.  The key pair is a mathematical analog of
the old spy trick (I'm sure it's in the movies somewhere) of tearing a
playing card in two, giving one piece to each of two people who do not
know each other but must be able to recognize one another.  No two
cards tear *exactly* the same way.  And the math does this *much*
I thought that the tradition of the mizpah coin would serve as well,
but I haven't found a good explanation, just advertising and Biblical
backgrounders.  As I recall, someone thought to break a soft metal
coin in two, so that the jagged edges would symbolize a unique
relationship, and somehow related it back to the story of the cairn of
stones that symbolized an agreement with God as witness.  Nowadays
they mint the things in two pieces, very stylized, and you buy them
already separated.  So maybe this is not so useful here.
Anyway, the point is the same:  a random process produces a unique
boundary between two complementary pieces, which the holders can use
to identify each other.  A computer does it with mathematics that you
don't have to fully understand, so long as you trust someone who
does.  If you need to see it in the physical world, just tear a piece
of paper, or break a cookie in two, and contemplate the result.
There are other things you can do with the jagged edges (so to speak)
of these keys, to scramble and unscramble a message, because the two
pieces are related, in a way too complex to easily guess if you don't
have one of them.  Go ahead:  pick up a pencil and paper, and try to
predict the EXACT shape of the torn edges of a card without seeing it.
One thing you must understand is that the keys are related
*mathematically*, not physically.  *Unlike* the card, knowing one shape
does not automatically give you the other.  This is useful:  it means
that you have a secret which you don't have to share to prove that you
know it.
After that, it's all just multiplying impossibly huge numbers.
That's dumbed down considerably, but I think it gets the basic idea
across simply.

@_date: 2014-04-16 13:28:02
@_author: Mark H. Wood 
@_subject: signatures for other people's emails 
I also thought it would be preferable just to pass the message through
the person whose prestige would, if lent, get you a reading.  The
problem with having the message come from an unknown is that it is
coming from an unknown.  If the message is not opened, it doesn't
matter whose signatures are on it, because they will not be seen.  So,
I don't think that multiple signatures addresses the original problem
at all.
However, there are uses for documents which must bear multiple
signatures from *known* individuals or roles, and being able to
present all of those signatures as a set, rather than having them
scattered through layers of MIME frosting, would be valuable to some.
OTOH some types of multiple signature may require "signature over
signature":  a signed document contained in another signed document,
so that the outer signature attests that at the time it was made, the
inner document bore a specific signature.  It may be possible to
compress the structure if there were defined signature types for these
uses, so that one knows (for example) to include all of the foregoing
signatures in the text to be validated.

@_date: 2014-04-25 09:12:00
@_author: Mark H. Wood 
@_subject: UI terminology for calculated validities 
German and English have been closely related for many centuries.  But
I've been trying to make sense of the terms using the *other* half of
English, since so many of these words seem to have Latin roots.
Valid: having value; acceptable for certain transactions.  A bank
draft is valid if it identifies an actual bank, identifies an actual
account at that bank, is signed in the appropriate place by an
appropriate person, is not too old, and has other correct
corroborating information.
Verified:  tested and found truthful.  A bank draft is verified if you
ask the purported issuer and he agrees that he issued it, or trusted
records show that he did, for that account and in that amount and to
that payee.
Authentic: properly associated with the entity which it claims;
genuine.  A bank draft is authentic if it was issued by the person
named in the signature and other marks.  It is typically authenticated
by comparing the signature sample on the draft to a trusted signature
sample, either already on file or executed by the named person in the
presence of the authenticator.  (Apparently Latin borrowed this one
from Greek.)
Is that of any help at all?

@_date: 2014-04-25 09:23:54
@_author: Mark H. Wood 
@_subject: UI terminology for calculated validities 
What about abandoning terms of art and just saying things more simply:
"This message was signed by key AAAAAAAA.  You have indicated that you
trust that key."

@_date: 2014-04-29 10:23:10
@_author: Mark H. Wood 
@_subject: hash email addresses / directory privacy enhancement 
Eh, I consider the possibility of address harvesting an opportunity
for a bit of sport.  I enjoy occasionally crafting a new regular
expression to make maildrop automatically toss a new strain of UCE.

@_date: 2014-08-18 09:59:33
@_author: Mark H. Wood 
@_subject: Fwd: It's time for PGP to die. 
Perhaps it would be a start if sites providing SMTP would turn on

@_date: 2014-08-18 12:24:43
@_author: Mark H. Wood 
@_subject: Fwd: It's time for PGP to die. 
Sure, it does encrypt mail.  My SMTP has mail from me to deliver.  It
contacts an SMTP that it thinks can get the mail closer to its
addressee.  My SMTP sends STARTTLS, the receiving SMTP agrees, they
handshake, and the rest of the session, including MAIL FROM, RCPT TO,
and my mailgram following the DATA, is encrypted over the wire.
As is often said here, "what's your threat model?"  Keeping
nonprivileged people out of the transaction is worthwhile, if I am
worried about mail being spied on in transit.  STARTTLS greatly
reduces the number of parties who could just read email metadata if
they have access to the wire.
Sysadmin.s take a risk if they are prying into the mail spool -- they
could be discovered.  Governments, too, may judge that the cost of
exposure of such activity is worth more than the advantage of doing
But I wouldn't depend solely on STARTTLS for securing email any more
than I am satisfied to depend solely on encrypting the message body
with OpenPGP or similar means.  I believe in making the bad guys take
as much time, create as much mess, and make as much noise as I can
compel.  It costs almost nothing to make as much trouble as possible
for snoopers, and it's interesting work, so why not do it?
You mean those webmail thingies that I never use?  There's so much we
don't know about their security practices that I wasn't even thinking
about such services.  My remark was focused on the scenario above:
there is a local MUA, a local MTA and a remote MTA.

@_date: 2014-08-18 12:34:06
@_author: Mark H. Wood 
@_subject: It's time for PGP to die. 
Yes.  I know what tools I used and how I used them.
No.  I have no idea what it actually did.
Same answer as (b).

@_date: 2014-08-27 09:32:50
@_author: Mark H. Wood 
@_subject: Fwd: GNU hackers discover HACIENDA government surveillance and 
It was never possible to live in perfect anonymity.  You can't
participate in society and be invisible to it at the same time.  One
has to accept being known, to some extent.
So, secrecy is only one part of privacy.  Another part is effectively
asserting what you believe is right.  Just because someone knows
something about you, doesn't mean he understands it or can argue
properly.  Challenge the idiots, the misinformed, the insufficiently
educated, the malicious, and make their misuse of your personal
information costly.  Without that, you will indeed live in a bubble of
privacy which steadily shrinks until it evaporates entirely.
Lies, rumors, and faulty logic readily die of exposure.  Expose them!
If someone attacks your secrets...attack his!  The falsity of a false
argument is one of your opponent's centers of gravity, so strike it
to keep him busy protecting it.
Secrecy alone is defensive.  The term for a purely defensive figher is

@_date: 2014-02-04 09:01:12
@_author: Mark H. Wood 
@_subject: making the X.509 infrastructure available for OpenPGP 
Assuming you trust those CAs.  All of them.
Having said that, you might look at how OpenSSH has included X.509
certificates in its operation.  There is precedent for something like
what you suggest.

@_date: 2014-02-06 10:42:23
@_author: Mark H. Wood 
@_subject: making the X.509 infrastructure available for OpenPGP 
It varies.
I've dealt with CAs who wanted a DUNS number and would call the
corporate security officer at a published number to find out whether I
am authorized to request certificates.  In other words, these CAs
actually do some investigation of the claims in the CSR.  That's
likely one reason why their certificaties cost $200/yr.  I'd trust
these cert.s for everyday uses (only because my everyday risk is small).
I'm aware that others require as little as responding to email at the
proffered address, and clearance of a small payment.  I repose very
little trust in such cert.s.  They're mainly useful for initializing a
privacy mechanism, and don't say much that I'd believe about the
identity of the other party.  They're useful if that's all you want,
and most small e-commerce sites don't need more, possibly because most
people are unaware that there could be more and haven't thought deeply
about why they might want more.
So:  what would one want from X.509 certificates used to initialize an
OpenPGP session?  What would it take to get that?

@_date: 2014-02-06 11:10:33
@_author: Mark H. Wood 
@_subject: making the X.509 infrastructure available for OpenPGP 
I think that the CA certifies whatever its Certification Practice
Statement says it certifies -- because that is a document you could
present to a court as evidence.  Commercial CAs typically are audited
periodically to determine that their operations conform to their CPS.
The problem is that a CPS can say *anything*.  Without reading it, you
have no way of knowing what you should expect that CA's certificates
to mean.

@_date: 2014-01-31 10:54:50
@_author: Mark H. Wood 
@_subject: cryptanalysis question: Does knowing some of the content of the 
Well...that depends on the value of the information, the assets of the
adversary, and the cost of failure.  Passively capturing and analyzing
your traffic from 1000km away offers little hope but also little risk.
Active measures like remotely installing a software keylogger can be
detected and resisted or undone.  Active measures like installing a
hardware keylogger can get the adversary shot dead in the act, or
result in exposure that would be far more costly to his employers than
the failure of his individual mission.
I would likely agree that nobody is going to attack the cipher to get
*my* secrets.  Most people haven't got anything worth that much time
and effort.  The greatest expectation of reward probably lies in
waiting for me to make a misteak.

@_date: 2014-07-04 17:05:52
@_author: Mark H. Wood 
@_subject: Key distribution via NFC 
First thought:  wow, someone came up with an NFC application that I
would actually accept as not obviously horrible security.
Second thought:  you could just keep your public key in a saved TXT
and just send it to the other's phone that way.  Even my unsmart phone
with the 4.5cm screen can do that.

@_date: 2014-07-21 09:32:57
@_author: Mark H. Wood 
@_subject: Automatic e-mail encryption 
Please remind me why we need an alternative to TLS.
I treat hop-by-hop encryption, not as an alternative to end-to-end,
but as defense in depth.

@_date: 2014-06-03 10:22:25
@_author: Mark H. Wood 
@_subject: Why create offline main key without encryption capabilities 
So, anyone who wants to offer to recover session keys rather than hand
over more-general keys should work on that *now*, when you can perhaps
get it into the law and common practice, rather than later, when you
cannot get it into court.  Right now might be a good time to be heard
on questions of narrowing the scope of search w.r.t. electronic

@_date: 2014-06-10 08:23:43
@_author: Mark H. Wood 
@_subject: Docs central, with 'Email Self-Defence' 
From time to time I will try to explain something, convinced that I am
*not* the best choice to explain it, in the hope that someone more
knowledgable will correct my errors.  I figure that, if I trot out my
limited knowledge, I may help someone to understand just a bit, and I
too may learn something in the process.
That is my suggestion as well.

@_date: 2014-06-12 09:06:05
@_author: Mark H. Wood 
@_subject: adele 
Copyright isn't used for names, but a name in association with a
business or service can, in some jurisdictions, be protected by
*trademark* or *service mark*.

@_date: 2014-06-17 09:00:52
@_author: Mark H. Wood 
@_subject: mascot_p 
We have one, but it's a secret. :-)
Alas, the octopus is already associated with GitHub:

@_date: 2014-06-18 08:45:26
@_author: Mark H. Wood 
@_subject: mascot_p 
Assuming that there *should * be a mascot, the discussion seems to
concentrate on the secrecy aspect of GnuPG.  But what about the
other aspect -- assertion of identity?  Does that spark any ideas?
What sort of mascot would combine the two aspects?

@_date: 2014-06-19 09:42:45
@_author: Mark H. Wood 
@_subject: mascot_p 
Yes, but that's the opposite of what I meant.  A digital signature
does not hide one's identity, but asserts it rather loudly and (we
hope) provably.

@_date: 2014-05-01 08:57:55
@_author: Mark H. Wood 
@_subject: Access to www.gnupg.org only via TLS 
So perhaps the problem is that the gratis certificate provision
business model only works when life is good; when bad things happen,
this imposes costs which require choosing between customer
dissatisfaction and stockholder dissatisfaction.
I think I would rather pay a reasonable amount up front for a
certificate *and the services necessary to maintain it*.  As someone
pointed out, this is a predictable and avoidable cost.  I do think
that a CA should not charge for revocation, but that implies that I
should have already paid for possible needs to which I'm committing

@_date: 2014-05-15 09:25:00
@_author: Mark H. Wood 
@_subject: GPG's vulnerability to brute force [WAS: Re: GPG's vulnerability 
I notice that the Wikipedia article refers here to "thermodynamically
reversible" which is perhaps not the same thing as computationally
reversible.  So I looked up "thermodynamically reversible" and found
  which gives the interesting summary: thermodynamically reversible
processes are theoretical and don't occur in the real world.  These
seem to live in the same realm with 100% frictionless surfaces and
insulation with infinite R-factor.
That article seems confused as to whether a reversible process must be
infinitely slow or infinitely fast, but Wikipedia says the former:
  But I'm way, way out of my depth here so I'll shut up.

@_date: 2014-11-18 10:14:29
@_author: Mark H. Wood 
@_subject: Encryption on Mailing lists sensless? 
It's time to expose my ignorance again, hopefully to cure some of it.
Would this not at the same time make it simple for MUAs to discover
that "this message is not from anyone you say you know.  Delete
without reading?"  Because to decrypt the SPAM, you need the public
key, which is identifiable.  Even if the spammers lie, well, it's from
no one you know, or it's verifiably *not* from who the sender claims
to be.
Again, if it's provably from no one you say that you trust, the MUA
could refuse to execute runnable content without explicit permission.
(Which I say should be the normal and only setting for all content,
but I know I'm a crank.)
I can also say that, so far as I know, the principal effect of
MTA-based antivirus in my life is to prevent me consciously emailing
known innocuous code that I wrote to people who ask for it.  So I for
one wouldn't miss it.  That's selfish of me, of course.

@_date: 2014-11-18 13:47:52
@_author: Mark H. Wood 
@_subject: Encryption on Mailing lists sensless? 
This raises an interesting point.  If I bequeath my collected letters
to someone, how do I arrange the transmission of the necessary
passphrases as well?  I wonder if the lawyer who draws up my will
would even understand the question.

@_date: 2014-10-02 09:11:19
@_author: Mark H. Wood 
@_subject: NSA, PGP and RSA 
How could anyone honestly answer that question, if the suspected
weakness has never been found?  We don't know that it exists, and if
it does exist we don't know its nature.

@_date: 2015-02-13 10:44:02
@_author: Mark H. Wood 
@_subject: MIME or inline signature ? 
There is.  In the words of the song:
  You can't please everyone, so
   you got to please yourself.
       -- Rick Nelson, "Garden Party"
Some people will complain if you use one format, and others will
complain if you use the other, so unless there's someone you
especially want to favor (or annoy) you may as well send what you
would most like to receive.  (Isn't there some sort of Golden Rule
about that?)

@_date: 2015-02-27 10:57:38
@_author: Mark H. Wood 
@_subject: German ct magazine postulates death of pgp encryption 
Whenever someone says that X is too complex for people to use, I
always remember something attributed to Albert Einstein:
       In physics, everything should be made as simple as possible.
       But not simpler.
I think it may be more widely applied.  Some problems are inherently
difficult.  Any successful attempt to remove *inherent* complexity
means that you are now solving a different problem which, while it may
be interesting, might not model reality in a particularly useful way.
It's always good to look for patterns that lead to useful
simplification.  But there comes a point at which no further
simplfication can be done without making the system less useful.
So: how well does PGP model the problems that people face in
communicating securely?  Does that model decompose neatly into
smaller, simpler models that fit well to distinct communities of
communicators?  *Are* there useful clusterings of communication needs,
w.r.t. security, within the community of communicators?

@_date: 2015-01-06 09:14:20
@_author: Mark H. Wood 
@_subject: Thoughts on Keybase 
True.  But we have established an identity between him and a person of
interest in the case.  Investigation of that interest is going to
require some more identities ("where were you on the night of the 13th?")
I suspect that imprecise language such as "who they are" lies at the
root of the disagreement here.  I think there may be some disagreement
about the meaning of "invasive" as well.
Well, if a person is suspected of a crime, many of his various
identities are irrelevant.  Others may be critical to establishing
guilt or innocence.  ("But this photo of me in the Boston Globe shows
that I was nowhere near the scene at the time you say the crime was
committed.  Look at that clock behind me.")
Now, if guilt is established, that new identity matters a great deal,
since it tells us who to discipline.  If guilt is disproven then that
should be made clear to anyone who might reasonably have learned of
the suspicion.  So:
o  if guilt is proven, that is the only identity we care about
   w.r.t. the crime;
o  if guilt is disproven, then the suspect's public identities are
   relevant to publishing his innocence.
Things get murky when you consider established procedures.  If the
suspect is released, but ordered to remain available ("don't leave
town") then the police need to record and distribute established
identities sufficient to detect whether the suspect is disobeying the
order.  Later there may be a need to identify a person who is no
longer to be especially watched.
(This is why I tend to think of identification as the establishment
and maintenance of sets of mappings or labels.  I have a lot of labels
("identities") stuck on me by family, friends, enemies, employers,
trading partners, etc., each of which is more or less independent.
Various sets of these labels make up how my associates retrieve their
concepts of me.)

@_date: 2015-03-13 09:04:30
@_author: Mark H. Wood 
@_subject: bugs.gnupg.org TLS certificate 
That is precisely the issue with free or even cheap certificates:
they are likely *not* of the same quality.
A few years ago, I ordered my first certificate from a well-known CA.
They charged us $159.00.  I *know* that they check up on new
applicants: our security officer got a phone call from them, asking if
I was legitimately representing the organization.  That certificate
certified more than just "probably the same host that presented this
certificate to you last time."
A CA that charges nothing cannot afford to do much (any?) checking of
the assertions in my CSR.  The resulting signature thus cannot have
some of the meaning that a more thoroughly investigated CSR can
A free cert. may have all of the qualities that you need, but I
recommend that you think as carefully about your choice of CA as you
do about who you would have sign a PGP key.  The more you depend on
a certificate for *establishing* trust, the more it's going to cost
you, because it's going to cost the issuer more to provide that
assurance while protecting his own reputation.

@_date: 2015-10-01 10:18:41
@_author: Mark H. Wood 
@_subject: How to get your first key signed 
There are two issues here.  One is what the O.P. asked:  how to get
useful signatures which bind a key to a specific physical-world
person.  Face-to-face meetings, photo ID, etc. are all part of that.
But the other is binding a key to a reputation.  And that can be done
at arms' length, simply by doing stuff in public and signing the stuff
with your perhaps-unsigned key.  If I've examined, tested, and used
stuff bound to key X, and learned to trust it, then when I meet some
other stuff bound to key X it is not unreasonable to trust it more
readily since, by means of key X, it is bound to stuff that I already
To put my point more plainly:  signatures on products and signatures
on keys mean different things, and to gain trust for them works in
different ways.

@_date: 2015-10-12 11:32:13
@_author: Mark H. Wood 
@_subject: How can it be made even easier!? 
Dare I suggest that people who need private and/or integrity-protected
email for professional use should hire a professional to interview
them, set up the software according to the client's standards for
professional practice, and explain its use?  (That would suppose that
one *can* find such people for hire.)
Doctors and lawyers shouldn't be doing such things for themselves --
they aren't trained for it, they don't have time for it, and much
rides on getting it right.  (I had added "and bankers", but banks have
whole departments devoted to securing records and communication, or
should.)  Doctors and lawyers hire accountants to set up their
financial subsystems, so why not hire experts to set up their
communication subsystems?
It probably comes down to getting the professions to squarely address
the problem of just what *are* their standards of professional
practice for secure electronic communication with their business
associates.  I get the sense that this is a problem which is being
studiously ignored because it is (a) hard and (b) deep in somebody
else's problem domain.
We should always be looking for ways to make things easier to use.
But there are limits to just how simple some processes can be made
before violence is done to the nature of the process and the utility
of its outcomes.  There *are* doctors and lawyers because medicine and
law are inherently hard problems requiring considerable expertise to
do well.  What is the limit of simplification of secure electronic
messaging imposed by its intrinsic difficulties?  We should be wary of
transgressing that limit in the name of further ease of use.  There
are already enough examples of systems which have been made so easy to
use that they should not be used at all.

@_date: 2016-08-18 15:55:33
@_author: Mark H. Wood 
@_subject: 2 Q's 
No need for yet another service; use Task Scheduler to run the refresh
command periodically.

@_date: 2016-01-06 10:20:11
@_author: Mark H. Wood 
@_subject: about cartoon in FAQ 10.1.  'Correct, horse! Battery staple!' 
For years I've used a gadget that generates random pronounceable
strings for creating passwords.  Eventually word came down from on
high:  "thou shalt use passphrases".  So now I generate one of those
random pronounceables and substitute it for a word in a sentence:
  "Never stop leyphohap number 3!"
I can learn that just about as quickly as "leyphohap" alone.

@_date: 2016-11-10 09:27:43
@_author: Mark H. Wood 
@_subject: PCI DSS compliance 
I would be interested to hear this auditor's explanation of how *any*
completely automated software system can protect private keys from a
human with access to the system.

@_date: 2016-09-13 07:32:33
@_author: Mark H. Wood 
@_subject: Why would I want S/MIME? 
Indeed, it's like telephones:  for communication to happen, both
parties must have them.
That echoes my experience.  At work we have a bulk-purchase
arrangement for certificates, so if I need one I just request one and
it magically appears.  OTOH most external correspondents have been
unwilling to pay the price of a certificate, so with those few who
*are* willing to pay the time to learn OpenPGP I use that.  At work,
Mutt (my MUA) is set up with keys for both and some rules to
automatically select the right one for each To: address.
In some workplaces, S/MIME is mandated.  That's another reason. :-)
With all the phishing going on these days, I foresee a wave of
companies issuing policies that unsigned mail seeming to come from a
fellow employee must be reported and then ignored.  Since it's already
easy to just buy certificates, they'll probably mostly go S/MIME.

@_date: 2018-05-15 11:06:26
@_author: Mark H. Wood 
@_subject: Don't Panic. 
Heh.  "We've discovered that locks can be picked, so you should remove
all the locks from your doors right now."

@_date: 2018-05-21 10:17:12
@_author: Mark H. Wood 
@_subject: A postmortem on Efail 
(I understand that that's a quote of a discussion-opener from the write-up.)
I'd like to first see how many haters can be won over by selling the
necessary changes.
By "selling" I mean addressing the concerns of those who aren't
convinced that they want something:
o  Why this is important *to you*, even though its importance was not
   immediately obvious.
o  What we have done, and are doing, to keep *your* cost down.
o  What else would we need to do, to make this something *you* want?

@_date: 2018-05-22 09:12:28
@_author: Mark H. Wood 
@_subject: A postmortem on Efail 
*sigh*  Imagine that I wore a wry expression as I wrote that.  I think
 we are mostly in violent agreement.  I tend to play off of the
 wording of a previous statement when replying, especially when I want
 to bend the discussion in a different direction.
Yes.  I, too, have encrypted stuff from way back that I would like to
be able to read.  Addressing such needs is part of selling the
selected way forward.
Another part of selling is dialogue.  I see lots of confident
assertions about what we should do.  Is anyone taking this back to the
affected users to see if any of it makes sense to them?
Yes, but don't just do it silently; tell people who need this that it
is being done, because of their concerns, and how it is being done.
Sell it.
I was hoping for practical ideas which show that the community
understands the needs of all its members and is working to minimize
the cost of necessary evolution.  I'd like to be one community, but
apparently at the moment we are two.

@_date: 2018-05-30 09:09:10
@_author: Mark H. Wood 
@_subject: A Solution for Sending Messages Safely from EFAIL-safe Senders 
I think that this points out something:  while integrity and
authenticity may be bolted on using third-party packages, secrecy must
be organic to an email agent.  If there is to be a "Real-Subject:"
header within the encrypted payload, then user agents must look for it
and handle it appropriately.  This probably includes extracting and
indexing suitable encrypted labels upon decryption.  But that then
means that the index records must be encrypted.
As is often the case with devising secure facilities, much of the
difficulty lies not in how to do things but in knowing where to look
for things to be done.  Each subset of the consumers of security
practice (email is only one) needs a few trusted sources of up-to-date
best practice which focus on the ways in which that subset may be
usefully attacked.  To do good, not only must such sources exist; they
must be widely known and valued, so that people who build software
will consult them regularly when planning new projects or overhauling
existing ones.
Hear, hear.

@_date: 2019-12-10 10:09:39
@_author: Mark H. Wood 
@_subject: gmail smime, sends two messages one is not encrypted. Experience? 
Here, the University has a deal with an academic consortium to provide
cert.s chained back, ultimately, to a well-known commercial provider.
I just submit a CSR to a website, a globally-valid cert. is issued to
me in a few hours, and my department is not billed for anything.  It's
probably cheaper than all the paperwork required to process a
requisition and chargeback.
We use this, not only for email, but for websites and other network
services, where there is no viable OpenPGP-based alternative.  The
ability to issue email certificates was actually added later, when the
Powers That Be became increasingly concerned about phishing.

@_date: 2019-12-10 10:50:08
@_author: Mark H. Wood 
@_subject: gmail smime, sends two messages one is not encrypted. Experience? 
Yes, if you trust that the page with the hash on it has not been
compromised.  Once the bad guy is inside the site, changing the hash
is just as easy as replacing the software.  Signatures depend on
material that is *not* in the same place with the signed object (if
we're doing it right) and thus can be verified from independent
Simple hashes can only detect simple failures.  They have no value
against a careful adversary.
PKC, used properly, can raise the cost of compromise, by increasing
the number of places that the bad guy must break into and get out of
undetected.  This is the electronic analog of a principle in physical
security:  require the bad guy to spend time, make noise, and create a
visible mess, to increase his fear of being discovered to the point
that the expectation of winning is not worth the expectation of

@_date: 2019-12-10 11:01:19
@_author: Mark H. Wood 
@_subject: gmail smime, sends two messages one is not encrypted. Experience? 
Oh, I hope not.  The point of asymmetric crypto is that you never,
ever, give your private key to anyone, even, *especially*, the CA.
The proper way to get an X.509 certificate is to generate a keypair,
keep the private key private, and send a CSR containing the public key
to the entity which will issue the certificate.

@_date: 2019-07-22 16:00:54
@_author: Mark H. Wood 
@_subject: Essay on PGP as it is used today 
Depends on your threat model.  For mine, reliably and easily
encrypting email is almost absurdly simple:
1) Use PGP
2) Don't send secrets to people I don't trust to keep them.
Anyway, 99% of my PGP use is for the opposite of secrecy: I sign my
emails so that (if you care enough to install PGP) you can be highly
assured that they're from me.

@_date: 2019-10-12 08:07:58
@_author: Mark H. Wood 
@_subject: Future OpenPGP Support in Thunderbird 
That would be one of the reasons why I tend to avoid "other software".
My primary use-case is identity, not secrecy.  I am not alone: quite a
few employers are at last discovering crypto signatures in their
efforts to combat spear-phishing, and spending quite a bit of money
and effort to deploy them.  (I accept that most of them are using
S/MIME rather than OpenPGP, but that's a detail; identity is important.)
Humph, I was already grumpy about Mozilla products' insistence on
having their own insular X.509 store, meaning that I have to install
certificates twice (once for Firefox, again for *everything else*.)
Maybe there will be an add-on, so that those who care can choose to
integrate Thunderbird into their systems rather than having it still
standing off to one side haughtily awaiting special treatment.

@_date: 2020-11-23 10:15:43
@_author: Mark H. Wood 
@_subject: Thunderbird / Enigmail / Autocrypt 
I consider that Mutt gives me the best of both, when I configure it:
  auto_view text/html
and in .mailcap:
  text/html; \
        lynx -dump -force_html %s; \
        copiousoutput
The text is flattened.  The result is sometimes ugly, but readable.
Attachments (such as images, or things purporting to be images) are
presented separately, and I can open them if I choose.  (Or I can copy
them out and inspect them in other ways, if I'm suspicious.  Examining
the un-rendered structure and content of some malicious messages can
be briefly entertaining.)
I would be mildly surprised to learn that my co-workers, outside of my
immediate workgroup, are even aware that I don't see their emails
rendered the way they do.  And nobody has ever told me, "your message
looks funny," except an occasional comment that someone couldn't open
the "attachment" (meaning the PGP/MIME signature).  Those stopped when
I got a corporate X.509 certificate and configured Mutt to use S/MIME
for internal mail.
Other console MUAs probably can do similar things when configured to
do so.
