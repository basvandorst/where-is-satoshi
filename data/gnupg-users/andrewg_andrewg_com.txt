
@_date: 2015-12-01 08:41:00
@_author: Andrew Gallagher 
@_subject: problems decrypting ASCII-armored file 
It's the same thing. One is just a different encoding of the other. The OP's software is obviously Unicode-capable as it displayed the unknown character as a U+xxxx code point. The underlying code point is identical no matter which encoding is being used. The only time you would see the raw utf-8 bytes would be if the software was Unicode-incapable or if the locale was set incorrectly, leading it to be interpreted as a sequence of bytes.

@_date: 2015-12-01 12:20:12
@_author: Andrew Gallagher 
@_subject: problems decrypting ASCII-armored file 
I think so. The use of BOM as a UTF-8 marker is not going to go away any
time soon...

@_date: 2015-12-15 23:07:04
@_author: Andrew Gallagher 
@_subject: Can I pass the password from the command line? 
I don't think there is a password parameter, and I'd strongly recommend not doing it even if there was. Many OSes make the command line parameters of processes available to any local user. Have you tried piping the password to stdin?

@_date: 2015-11-17 14:33:40
@_author: Andrew Gallagher 
@_subject: best practices for creating keys 
Pretty much. You also need your primary private key if you want to
update the details of your public key (as it needs a self-signature) and
for certifying other keys (web of trust).
This is a fairly good article - I've used it myself for reference in the
past. Also have a look at:
Nothing to forgive!
The two files are the public key (including all public subkeys) and the
private key (including all private subkeys).
Think of your keypair as a pair of matching tree structures:
PUBLIC  | (private)
PRIMARY | (primary)
--SUB-- | (--sub--)
--SUB-- | (--sub--)
--SUB-- | (--sub--)
Each "key" (singular) really consists of multiple keys (plural), a
primary and some number of subkeys that are signed by the primary. This
singular/plural inconsistency in terminology is probably the confusing
bit. ;-) You can create as many subkeys as you like, but they can all be
considered part of your "key" (singular).
GPG will by default create a subkey marked usable for encryption only
(as there are attacks against keys that are used for both encryption and
signing). The best practice method above creates a separate signing-only
subkey so that you don't need to use your primary key for signing messages.
Your "laptop key" is then just your private key-tree with the primary
private key safely deleted.
You just answered yourself below. ;-)
Keeping your primary private key offline does not help against brute
forcing, but it does protect against keyloggers, rootkits, physical
loss/theft etc. The only protection against brute force is key
complexity/length, but brute forcing a properly generated key is
vanishingly rare - you are much more likely to lose it by less glamorous
Correct. As you worked out yourself, it is of limited use in the case of
encryption subkeys (as anything encrypted against that key is now
exposed) but it is VERY useful for signing and authentication subkeys,
so long as you notice the loss and revoke them in a timely fashion.
You can continue to decrypt with a revoked encryption key. Revocation
does not make the private key unusable, it just marks the public key as
"do not use". Best practice is to regularly revoke your encryption
subkeys and regenerate them so that only a finite amount of data is
encrypted with each subkey, limiting the impact of a disclosure. How
often you want to do this is up to you - if you rarely get encrypted
emails it might not be worth your while, but if you are a heavy user
then I'd strongly recommend it.

@_date: 2015-11-17 14:53:01
@_author: Andrew Gallagher 
@_subject: backing up keys 
"Better" really depends on your use case. Are you likely to forget your
passphrase? Are you going to keep your USB backup drive in a floor safe?
Are you expecting your home to be searched by the feds (or the mob)? I
don't think there is One Correct Answer to that one...
No, there is no public key data embedded in the private key, but you can
regenerate the important mathematical bits of the public key from the
private key, and you can fill in your name, email etc. from memory. So
it's not absolutely necessary - but it is convenient.
Of course, the backup of your public key does not need to be secure.
Brute forcing a password is always easier than brute forcing the key
itself (otherwise you'd be typing in your entire private key by hand!),
so if (when) dropbox do leak the key data you've given the Bad People a
That's fine if your OCR is perfect and your paper never gets folded or
stained or torn, but ascii-armored data has no checksum or error
correction so you may suddenly discover your paper backup is unusable.
And such discoveries usually happen at the worst moment. ;-)

@_date: 2015-11-27 11:41:14
@_author: Andrew Gallagher 
@_subject: best practices for creating keys 
There's a post about how to do this in the list archives:
... but it's really not worth your while. So long as your primary key
doesn't have E usage set*, you can create new A and S subkeys and simply
refrain from using the primary key for those functions. The only problem
you might run into is if one of your correspondents is using broken
client software that doesn't check signatures against multiple subkeys.
I've no idea how likely this is though.
(*) HIGHLY unlikely unless you've done it on purpose, and in that case
you're probably best advised to revoke it and start over.

@_date: 2015-11-30 22:41:33
@_author: Andrew Gallagher 
@_subject: problems decrypting ASCII-armored file 
That's a Unicode byte order mark. Strictly, it should only be used in UTF-16 documents but in the real world it's commonly used to mark any Unicode file. I'm assuming this is a UTF-8 file? If so, you should just be able to delete the character using vim or similar and try again.

@_date: 2015-10-01 12:35:02
@_author: Andrew Gallagher 
@_subject: How to get your first key signed 
Yes, trust in the intent, or competency, of a particular person is
completely different to verification of the identity of that person
(which is why I think PGP's use of the word "trust" in this context is
dangerously misleading).
And if you want to create a localsig on that basis, fire away. But
publicly certifying someone else's key is a statement of identity
verification, not trust.

@_date: 2015-10-01 16:44:00
@_author: Andrew Gallagher 
@_subject: How to get your first key signed 
Another case where common PGP terminology is confusing. You don't really
"sign a key", you certify that a particular identity should be bound to
a key. This process uses the same algorithm as a signature, but the
semantics are different - as evidenced by the fact that [C]ertify and
[S]ign are distinct usages.

@_date: 2015-10-25 09:20:30
@_author: Andrew Gallagher 
@_subject: absolutely nothing to panic over 
By calling PKC "hocus pocus" and using "scare quotes" you won't convince us of your claims, just of your obsession. ;-)
Correct. And PKC has just such an out of band bootstrap - key verification.
There is nothing wrong in principle with any of these, so long as one understands and accepts the limitations. A trade off between security and practicality will always have to be made at some level.
Advances in computing technology have corroded every encryption algorithm ever made. This is not unique to PKC. Security is and always will be an arms race.
Well, no. If you believe that PKC is fundamentally flawed, it may look that way to you. But you haven't shown any evidence other than your gut instinct. You may be right, or you may not. But gut instinct isn't enough to give up PKC, which is the only PRACTICAL mass-cryptography paradigm we know of. Imagine having to exchange out of band and in advance symmetric keys with every person or company you will ever deal with. Imagine Microsoft, Google, etc having to keep on file AND SECRET a symmetric key for every person on the planet. The drawbacks of a non-PKC future should be blindingly obvious.
None of that is to say that some fundamental flaw in PKC won't be found. But all the signs point to the future being quantum-resistant PKC, and there is no point worrying about a future in which even that fails. If we are forced back to symmetric cryptography it will be a disaster, but we have the tools already. And who knows what other algorithms will arise in the meantime.

@_date: 2015-10-30 15:54:07
@_author: Andrew Gallagher 
@_subject: "invalid option: --agent-program" 
I'm using gnupg-agent 2.0.26-6 (jessie) and in the manual page for
gpg-connect-agent it says:
But when I try it:
Is this a documentation issue or an implementation issue? ;-)

@_date: 2015-09-22 13:08:35
@_author: Andrew Gallagher 
@_subject: Problem with unix socket forwarding 
Hi, all.
I've been trying to get gpg-agent forwarding working between my laptop
and a remote VM. Using the new unix socket forwarding in openssh 6.7, I
have defined the following script:
ssh -R /home/andrewg/.gnupg/S.gpg-agent:$( echo $GPG_AGENT_INFO | sed
's/:.*//g' ) -o "ControlMaster=no" -o "ControlPath=no" -o
"StreamLocalBindUnlink=yes" $*
gpg-agent on the VM indicates that the socket is live, but gpg2 reports
no private keys available. I have one local and one smartcard private
key working perfectly on the laptop (see below).
Anyone know where I'm going wrong?
On a side note, the option StreamLocalBindUnlink=yes appears to do
nothing, meaning I'm constantly having to rm .gnupg/S.gpg-agent - any
help with that would also be appreciated. ;-)
Thanks in advance,
agallagher at itchy:~$ gpg2 --list-secret-keys
sec   2048R/0xD5BF93B014A49700 2013-03-14 [expires: 2018-03-14]
      Key fingerprint = FB29 3A52 9FEB 41D7 B7C8  7B49 D5BF 93B0 14A4 9700
uid                            Andrew Gallagher ssb   2048R/0xACB387E2BD11B295 2013-03-14
ssb   2048R/0xDE32C1F5C819C504 2013-10-23
sec#  4096R/0xFB73E21AF1163937 2013-07-02 [expires: 2017-01-20]
      Key fingerprint = 00CC 54C6 A0C6 0169 1AF4  931F FB73 E21A F116 3937
uid                            Andrew Gallagher uid                            Andrew Gallagher uid                            Andrew Gallagher uid                            [jpeg image of size 18803]
ssb>  4096R/0x6B09069314549D4B 2013-07-02
ssb>  4096R/0x5C1EC404D5906629 2015-04-26
ssb>  4096R/0x85FDF561DA8C0C46 2015-04-26
agallagher at itchy:~$ gpgforward nex
No mail.
Last login: Mon Sep 21 15:16:26 2015 from itchy
andrewg at xen:~$ gpg-agent
gpg-agent: gpg-agent running and available
andrewg at xen:~$ gpg2 --list-secret-keys
andrewg at xen:~$

@_date: 2015-09-22 15:47:05
@_author: Andrew Gallagher 
@_subject: Enigmail and =?UTF-8?B?cOKJoXAgYXJlIHRvZ2V0aGVyIGZvciBkZXZlbA==?= 
So how do you perform out of band verification? Or is it just TOFU?

@_date: 2015-09-23 10:30:22
@_author: Andrew Gallagher 
@_subject: Problem with unix socket forwarding 
There is no gpg-agent running on the remote VM. GPG_AGENT_INFO is not
set, but even if I set it explicitly to point to the socket it doesn't
appear to attempt to contact it:
andrewg at xen:~$ GPG_AGENT_INFO=~/.gnupg/S.gpg-agent:1:1 gpg2
--debug-level 10 --list-secret-keys
gpg: enabled debug flags: packet mpi cipher filter iobuf memory cache
memstat trust extprog cardio assuan
gpg: DBG: fd_cache_open (/home/andrewg/.gnupg/secring.gpg) not cached
gpg: DBG: iobuf-1.0: open `/home/andrewg/.gnupg/secring.gpg' fd=4
gpg: DBG: iobuf-1.0: underflow: req=8192
gpg: DBG: iobuf-1.0: underflow: got=0 rc=-1
gpg: DBG: /home/andrewg/.gnupg/secring.gpg: close fd 4
gpg: DBG: fd_cache_close (/home/andrewg/.gnupg/secring.gpg) new slot created
gpg: DBG: iobuf-1.0: underflow: eof
gpg: DBG: iobuf-1.0: close `?'
random usage: poolsize=600 mixed=0 polls=0/0 added=0/0
              outmix=0 getlvl1=0/0 getlvl2=0/0
secmem usage: 0/65536 bytes in 0 blocks

@_date: 2015-09-23 11:54:42
@_author: Andrew Gallagher 
@_subject: Problem with unix socket forwarding 
That would explain it...! I'll just have to create a throwaway key on
the VM for the time being.

@_date: 2015-09-29 15:33:38
@_author: Andrew Gallagher 
@_subject: unlock keychain with pam authentication 
I was referring to mutt (allegedly) importing random secret keys that it
finds attached to arbitrary mails... but yes, a discussion for elsewhere.

@_date: 2016-04-06 13:08:37
@_author: Andrew Gallagher 
@_subject: Change the location of the gpg-agent socket? 
Would it not make more sense to add an exclusion for the socket in your backup config?

@_date: 2016-04-08 18:42:47
@_author: Andrew Gallagher 
@_subject: Perform only asymmetric encryption/decryption 
A bit more info about your use case might be helpful (and intriguing!).
If you're just trying to create a new asym-encrypted copy of an existing
GPG session key (or something similar) then there might be a way. If
you're thinking of encrypting large amounts of data directly with
asym-encryption, then I'll question your sanity. ;-)

@_date: 2016-08-04 08:33:00
@_author: Andrew Gallagher 
@_subject: Advice on key set-up for work at employer 
Yes, this is the textbook case for having a separate primary key for a particular identity. I have implemented this myself.

@_date: 2016-08-11 15:25:31
@_author: Andrew Gallagher 
@_subject: Standard gnupg folder created despite --homedir parameter 
The definition of "expert" is someone who's made all the same mistakes
as you, just earlier. ;-)

@_date: 2016-08-17 14:27:18
@_author: Andrew Gallagher 
@_subject: 2 Q's 
That sounds like an argument for marking downloaded local copies of
public keys stale after a certain period, similarly to DNS TTL...

@_date: 2016-08-17 15:36:05
@_author: Andrew Gallagher 
@_subject: 2 Q's 
;-) Key management is a nightmare whether you add tests or not. At
least with tests you *know* how bad it is...!
The above suggestion would only be workable in combination with
auto-key-locate, of course. A prompt to proceed with a stale key in the
case of limited network access might also be useful. But the
substantial point is that a) regular key refreshes should be default
behaviour and b) failure to refresh keys on time should be an error.
Parcimonie already exists. But it's an optional extra that most people
don't install (or even know of). People shouldn't be expected to
install or configure extras before they have a (safely) usable system.

@_date: 2016-08-17 16:07:34
@_author: Andrew Gallagher 
@_subject: 2 Q's 
"parcimonie is a daemon that slowly refreshes a gpg public keyring
from a keyserver."
(The original homepage isn't responding)

@_date: 2016-08-17 16:43:43
@_author: Andrew Gallagher 
@_subject: 2 Q's 
Computers were invented to liberate us from such drudgery.

@_date: 2016-08-17 16:52:28
@_author: Andrew Gallagher 
@_subject: 2 Q's 
The only thing that can't be worked around is out-of-band identity
verification - but better tools can make that process less painful.
Everything else is automatable in principle.

@_date: 2016-08-17 17:41:29
@_author: Andrew Gallagher 
@_subject: 2 Q's 
My only hope is that someday 1024-bit DSA keys will be generally
Yes, absolutely. And it should also be made much clearer that
expiration dates can be extended indefinitely. I threw away two
perfectly good primary keys before I learned this handy fact.
No, because you misplacing your private key and me failing to download
your revocation are different problems, with different burdens of
responsibility and different urgencies. A weekly or even daily keyring
refresh could be considered prudent - but weekly key expirations would
be extreme.
To use the DNS analogy again, "TTL" and "expiry" are different numbers.
One is a cache refresh schedule and one is a cache invalidation
schedule. Not the same thing at all.
The entire point of civilisation is that you don't need to know
everything. Sure, computer geeks should know these things. But your
granny should never need to know what goes on under the hood of her
software, any more than she needs to know how to refine diesel or bump
a yale lock. If you make the barriers to entry too high, people just
won't bother.

@_date: 2016-08-17 19:35:00
@_author: Andrew Gallagher 
@_subject: 2 Q's 
Public keys are low-latency things anyway, so it matters little if
parcimonie is being overly paranoid for the average user. The only
problem arises when $WORK decides to block tor - but you can fool
parcimonie into using plain https (just need to read between the lines
of the man page).
This is an excellent example of how software ecosystems take on lives
of their own. When the only people who are using your system in anger
are people with different political priorities to yours, don't be
surprised when they fix the problems that you haven't got round to
fixing yet in ways that you don't approve of. ;-)

@_date: 2016-08-26 15:56:05
@_author: Andrew Gallagher 
@_subject: Please unsubscribe me form your mailing list. Thank you. 
It's a sad day when pdf is considered preferable to html... ;-)

@_date: 2016-08-31 12:25:45
@_author: Andrew Gallagher 
@_subject: GPL license responsibility 
In this case you have no obligations. Fly, and be free. ;-)
The only time when the GPL becomes significant is when you are
distributing modified code to other people or companies. In that
instance, you usually(*) are required to make freely available any
modifications you have made to that code.
In this case you are neither distributing nor modifying the GnuPG code,
so the GPL is not applicable.
* If you don't change the source code, you don't have to do anything.
* If you change the source code, but only use it yourself, you don't
have to do anything.
* If you use an LGPL library in your own code, but don't change the
source code of the library itself, you don't have to do anything.
(*) Most of the complicated details of the GPL are concerned with
pinning down the exact scope of "usually".

@_date: 2016-12-02 17:21:12
@_author: Andrew Gallagher 
@_subject: How do you help someone to encrypted email (Re: How do you let 
Yes. Secret key generation, backups, and portability. Also, the fact
that so many people now use webmail rather than a local client.
Yep. I've been using a smart card reader for a while, and although I'm
comfortable with it now, initially it was daunting. I ended up writing
a tool to automate the key generation and backup process
( There is a similar project under
development in Debian
( I
wouldn't ask my mother to use either of them.
Enabling the smart card for use across multiple machines was a long,
trial and error process. Once it is working the convenience is great.
But I wouldn't expect anyone else to do it.
Arguing "personal responsibility" is too often a means of passing the
buck. If it is too difficult or time consuming to be a responsible
citizen, people won't. This applies across all walks of life, not just
computer security.
The best systems make Good Things easy, and Bad Things more trouble
than they're worth. Poor systems make Bad easier than Good and then
spend all their energy chasing up people who took the lazy way out -
which in extreme cases can mean literally everyone.
GPG's secret keyring is a password protected database, just like a
password manager. The main thing it does not do that many password
managers provide is automatically store the encrypted secret in the
cloud for easy synchronisation. This is a questionable practice
however. Much better to store your secret key material on a smart card.
Of course that buggers up mobile.

@_date: 2016-12-04 23:09:38
@_author: Andrew Gallagher 
@_subject: Toggle the authenticate capability 
Hi Roy,
You normally don't need to remove the A capability from a signing key. By default, gnupg will use the most recently created valid subkey with the appropriate capability, so all you need to do is create a new A subkey and it will be used in preference to the old one. Mathematically, authentication is just a special case of signing, so having both S and A on a subkey does not introduce extra vulnerabilities (that we know of). It is technically possible to change the capability flags on any key, but you can't do it with a vanilla version of the software. There is a patch somewhere in the archives of this list but I would recommend against it. The only use case where it would be necessary to remove a capability flag would be if you had created an encryption key that also had S or A capability - but it's almost impossible to do it by accident and in such cases it's safer to revoke the key and start again.
Andrew Gallagher

@_date: 2016-12-05 12:54:31
@_author: Andrew Gallagher 
@_subject: Toggle the authenticate capability 
You don't need A capability to perform this attack though - so long as
you can social-engineer your way to getting someone to sign a message
of your choice. This isn't a *mathematical* vulnerability but an
implementation/procedural one, and it's not technically "extra" -
although it could be viewed as widening an already existing hole. ;-)
OK, I'm clutching at straws. I'll bail out of this argument now. ;-)
Yes, from an implementation point of view an authentication challenge
and its response should be strictly formatted in a way that can't be
mistaken for another protocol. Your auth routine shouldn't be blindly
signing whatever plaintext the attacker suggests...
Sorry, yes expiry is as good as revocation, and this applies to both
primary keys and subkeys.
I think it was Enigmail on OSX. This was a few years back though, and
it may have changed since.

@_date: 2016-12-05 17:16:33
@_author: Andrew Gallagher 
@_subject: Implications of a common private keys directory in 2.1 
Hold on a sec.
Are you running a pseudonymity service on your personal desktop?

@_date: 2016-12-06 23:27:08
@_author: Andrew Gallagher 
@_subject: Proof for a creation date 
I don't see any reason why it couldn't be done in principle - anyone who wants could set up an "authority" that produces a regular, signed list of all the certificates it currently trusts at each point in time. The trick is a) making sure that revocations get submitted to the authority in a timely fashion and b) working out whether to trust the authority in the first place. But that's a problem in OCSP too. In general, anything you can do in the X509 trust model you can do in PGP - but with a little more effort and a lot fewer default assumptions. Andrew Gallagher

@_date: 2016-12-07 08:53:43
@_author: Andrew Gallagher 
@_subject: Proof for a creation date 
No signature can possibly attest that something is valid *forever*. You're right that stapling is absolutely required in a data at rest use case, because a real time service only makes sense for ephemeral comms. But it's just a form statement by the authority which the sender appends to their signed data.
Trying to protect against future compromise of a signature algorithm is really hard. And once you open that door, all data at rest signatures are questionable. Merkle trees protect against this though, as not only do you have to forge the signature, but also recreate the entire subsequent merkle tree, which should be infeasible. If you embed the OCSP response in the tree with the signed data, then it enjoys the same protection.

@_date: 2016-12-16 00:18:09
@_author: Andrew Gallagher 
@_subject: Smartcards and tokens 
The difference is that if you use a smart card in a compromised host, the plaintext of particular messages may be compromised but the key itself remains secure. It also helps in the case of hardware loss or theft, because an encrypted drive can be brute forced, but smartcards have retry limits that can't be worked around short of dissecting the silicon. That's assuming it has been sufficiently hardened against side channel attacks, of course. And if you leave the smart card in the machine with an insufficient pass phrase timeout, the attacker could feed an arbitrary number of messages through it without you knowing. So it's no panacea.

@_date: 2016-12-16 12:36:19
@_author: Andrew Gallagher 
@_subject: Smartcards and tokens 
Smartcards perform signing and DEcryption (which in the case of RSA are
mathematically identical).
That's true of DSA and ElGamal, but smartcards normally implement RSA.
Remember also that PGP uses a two-step encryption process. The random
symmetric session key is generated on the host rather than the
smartcard, and the secure hash used in signing is deterministic.
The smartcard itself only RSA-decrypts the session key (or hash), and
this doesn't require an RNG.

@_date: 2016-12-16 18:38:33
@_author: Andrew Gallagher 
@_subject: Smartcards and tokens 
Yes, but the key space of the smartcard is much larger than the key
space of a USB drive encrypted using a key derived from a
human-readable passphrase...

@_date: 2016-12-18 00:30:36
@_author: Andrew Gallagher 
@_subject: Smartcards and tokens 
No, because the plaintext is symmetric-encrypted with a random session key on the host. The smartcard just asymmetric-encrypts the session key. This two step process is used mainly because asymmetric encryption is comparatively slow, but it also means that two identical plain texts won't get encrypted to the same ciphertext, due to the random session key.

@_date: 2016-02-26 16:59:06
@_author: Andrew Gallagher 
@_subject: FAQ maintenance 
The fundamental problem here is that computers have become so powerful
that they can generate more data objects than human beings can ever give
distinct names(*) to. Hell, we can't even give *ourselves* unique names,
and there's a mere 7 billion of us.
(*) IDs, serial numbers, handles, identifiers...

@_date: 2016-02-29 16:52:27
@_author: Andrew Gallagher 
@_subject: Question about getting started with PGP and smart cards 
Unfortunately the developer of that pageant replacement distributes
unsigned binary blobs over plain HTTP. The Windows build of GnuPG 2.1 on
the other hand (linked from the official gnupg site) has a gpg-agent
that can run as a pageant replacement for putty (same idea as ssh-agent
replacement). You don't get all the graphical tools that come with
GPG4Win, but it's a safer (and more future-proof) solution IMO.

@_date: 2016-01-14 17:04:07
@_author: Andrew Gallagher 
@_subject: Key selection order 
... which is why you should never use ToFU. There is no known method of
secure communication that does not involve out of band verification.

@_date: 2016-01-14 20:06:38
@_author: Andrew Gallagher 
@_subject: Key selection order 
Granted. And it does provide a speed bump to a potential attacker, so is preferable to nothing. But it's not a long term solution.
Tofu does not guarantee identity persistence. Just because your correspondence hasn't been obviously tampered with (yet) does not mean that someone hasn't been MITMing you all along and biding their time.

@_date: 2016-01-14 23:12:32
@_author: Andrew Gallagher 
@_subject: Key selection order 
Fair enough, let me rephrase: I don't believe it's a long term solution, particularly as the capabilities of well-funded attackers to mitm multiple network paths simultaneously appear to be still growing. But yes, in many cases it is good enough to be getting on with.
No, because mitm doesn't mean one identity replaces another, but that the two identities become conflated. A signature that could have been created by one of two people does not identify either person. If I faithfully transcribe every email that I mitm apart from one, it does not make me the author of the faithful mails; only of the one that I alter.

@_date: 2016-01-14 23:15:15
@_author: Andrew Gallagher 
@_subject: Key selection order 
There's a decent chance it's been working for us longer than you've
I'm afraid I predate not just PGP but also RSA. Just about. ;-)

@_date: 2016-01-15 20:21:55
@_author: Andrew Gallagher 
@_subject: basic identity mgmt 
It's complicated, but not necessarily _pointlessly_ so. Depending on
circumstances it could be considered minimally prudent. I've worked on
several projects for more than one financial institution, and airgaps
like this are considered barely sufficient for some important keys. (Of
course in such projects the idea of a certification subkey not on the
airgapped machine would be completely unacceptable...)

@_date: 2016-01-15 21:37:38
@_author: Andrew Gallagher 
@_subject: basic identity mgmt 
Most relevant example, a system where users can register their
authorisation keys against a semi-automated authority which signs them
for trust by a third system. The root key that certifies the automated
authority keys is offline. Essentially a private root CA.
Now, this example is using x509 rather than pgp, but the threat model is
the same. Bad guys hack into the system, they can fake a trust
relationship, which in turn compromises a different system.
To put this into PGP terms, say Lachlann were Stallman (ok, I'm
stretching a bit!). Then say someone wants to impersonate Linus. If they
could root RMS's laptop they could certify a key in Linus's name and
many people would say "RMS is paranoid, so it really must be Linus!".
;-) But if RMS keeps his certification key offline, the best the hackers
can do is impersonate him - until he notices of course, at which point
he can roll his subkeys and draw a line under the incident.
Of course if a C-capable subkey were to exist, Linus would lose the
benefit of the airgap. RMS would still be able to roll his subkeys, but
that would also revoke all the trust relationships that depended on the
C-subkey. So both of them are worse off.

@_date: 2016-01-17 03:06:36
@_author: Andrew Gallagher 
@_subject: basic identity mgmt 
That may have been the initial motivation. But consider that the most common real world use of PGP today is verification of code signatures - many of which are generated semi-automatically by build infrastructures such as Debian and verified by install tools. The trust relationship here is between your client and a build server, not people.
Two factor ssh smart card auth? I use it nearly every day - much more often than encrypted mail. I don't think anyone has sent me an encrypted mail in over a year, and the last one was about signing a PGP key. ;-)

@_date: 2016-01-18 13:10:14
@_author: Andrew Gallagher 
@_subject: Key selection order 
I find it funny that on a gpg users mailing list, out of 80 emails since
new year, only 15 have signatures at all, and three of those are mine*.
Even Werner doesn't sign his mails.
I'm reminded of the story (possibly apocryphal) of a delegation of local
notables travelling up to Belfast in the 1960s to petition the transport
minister not to close their local railway line. The minister asked them
how they got to Belfast that morning and they all said "the motorway".
(*) Granted, I don't always sign mine but you can blame the iPhone for

@_date: 2016-01-21 13:23:38
@_author: Andrew Gallagher 
@_subject: problem signing with a smart card 
The main reason for using an encryption subkey is that there is a known
vulnerability where an attacker tricks a victim into signing a "message"
that is actually the encrypted payload that the attacker wants to
decrypt. This works a) because signing and decryption are equivalent
mathematically and b) iff the victim uses the same key to both decrypt
and sign. Using a separate subkey for encryption removes prerequisite b.
A secondary reason for using a subkey (and this applies to signing and
authentication subkeys also) is that if it gets compromised, you can
revoke just that one subkey, rather than your entire key. This means
that your trust relationships don't have to be rebuilt from scratch.
As Peter said earlier, a smartcard key without a backup is inadvisable
for most users. It's not so bad for a signing or authentication subkey,
but if you lose your encryption key you've lost access to historical
data. This is why I keep a copy of all my private key material on two
Tails* encrypted partitions, stored separately.
The easiest way to copy a key to a smartcard without losing the on-disk
copy is to create an on-disk subkey, save, use "keytocard" to transfer
it to the card and then quit without saving again.
(*)

@_date: 2016-01-21 14:47:27
@_author: Andrew Gallagher 
@_subject: problem signing with a smart card 
You shouldn't need to regenerate your master key, unless something else
is wrong with it ;-). Just revoke the subkey you created on the
smartcard, overwrite the smartcard key with a newly generated key
(making sure NOT to "save" afterwards, see previous email) and republish.
Maybe try the process out with a new temporary key to be sure you're
doing it right (don't publish it, of course).
Yes. In addition, if you want the ssh server to automatically update
your auth subkeys as you create and revoke them, you could try
installing monkeysphere.

@_date: 2016-01-21 15:15:16
@_author: Andrew Gallagher 
@_subject: problem signing with a smart card 
Good point! I understood that this was a fresh key. If it is not then
no, overwriting it is a bad idea.

@_date: 2016-01-21 15:24:12
@_author: Andrew Gallagher 
@_subject: problem signing with a smart card 
Yes to all the above. I'd just point out that the same considerations
apply to any lost vs. stolen authentication token (e.g. password).

@_date: 2016-01-25 13:55:26
@_author: Andrew Gallagher 
@_subject: Master Key Best Practice with SmartCard 
Once you've published a subkey it stays published. Deleting a previously
published subkey only removes it from your local machine. It won't stop
others from finding it on the keyservers and trying to use it.
If you want to explicitly mark a subkey as "do not use" (but you do not
believe that it has been compromised), then give it an expiration date
of yesterday and republish. There's no particular reason to delete your
local copy of the subkey (and there may be very good reasons not to,
e.g. old encrypted data).
NB expiration can be undone, but revocation cannot.
(Remembering our previous conversation, you may instead want to expire
your smartcard encryption subkey, and copy the other encryption subkey
to the smartcard - but only if you have made a decrypted copy of all
your sensitive data first.)
If there's nothing wrong with your primary key there's no need to make a
new one. I personally don't think having an extra usage flag counts as
sufficiently "wrong" (so long as it's not "E"!). It may not be neat and
tidy, but modern implementations should happily verify/auth against
multiple subkeys. My current primary key has S,C,A usage and the S,A
subkeys haven't caused me any issues so far.

@_date: 2016-01-25 15:15:19
@_author: Andrew Gallagher 
@_subject: Master Key Best Practice with SmartCard 
I'm really not. Just trying to be helpful. Don't trust me any more than any other random person on the Internet. I'm quite likely to make a mistake or leave out something important.
Just locally. You can't delete stuff from the keyservers, as they're a distributed database with no central control, and they have no method of confirming you are the key's owner. Even if you could get one server to delete your key, it would be resynchronised almost immediately from another server.
In general, you should assume that anything that goes on the Internet is there forever, as you have no way of knowing who has made a copy for their own use, let alone do much about it. ;-)

@_date: 2016-01-27 10:45:39
@_author: Andrew Gallagher 
@_subject: AW: AW: Key generation with GPGME and GnuPG hangs at 
If your problem is merely lack of entropy on a VM, then I'd recommend installing haveged, available in Jessie. It broadens the sources used by the kernel for the entropy pool.

@_date: 2016-01-27 14:20:37
@_author: Andrew Gallagher 
@_subject: Problems with 4096 keys on 2.1 card 
I fixed it by disabling gnome-keyring at system level. The following
works under Jessie:
echo "X-GNOME-Autostart-enabled=false" >>
echo "X-GNOME-Autostart-enabled=false" >>
NB this will affect all users.

@_date: 2016-01-31 17:40:32
@_author: Andrew Gallagher 
@_subject: GnuPG and the debian-archive-keyring 
Do you have the revoking keys in your keyring? It sounds as if there's a revocation sig attached to the public key but gpg has no way of determining its validity.
(Not at the computer right now so can't check myself)

@_date: 2016-07-01 19:40:48
@_author: Andrew Gallagher 
@_subject: Accidentally used SHA1 
If someone were able to generate a message which collided with the sha1 hash of this particular message then they could impersonate you to anyone who still regarded sha1 signatures as valid (this last point is an important caveat).
We must be careful to distinguish this from a collision attack though. A hash collision is where you generate lots of hashes and find any two that match. Sha1 is known to be vulnerable to this. But to fake your signature requires a preimage attack, which needs the fake hash to match *this particular* hash. That is a good deal more difficult, and sha1 is believed to be preimage-resistant for the moment.
At some point in the future of course, sha1 will fall. However, all is not lost. Your primary key is not compromised, just this particular signature packet made by this particular signing subkey. If you are sufficiently worried, you can revoke the subkey (thus revoking this signature) and generate a new one. All your previous signatures will be invalidated also, but you can regenerate them with your new subkey if that is an issue.

@_date: 2016-07-26 12:22:08
@_author: Andrew Gallagher 
@_subject: gpg: KEYTOCARD failed: Unusable secret key 
It copies, but if you then save the changes to your local disk, the
original copy on local disk is deleted - so calling it a "move"
operation is correct. If you want to keep a backup copy on local disk,
you need to quit *without saving* immediately after running 'keytocard'.
This behaviour is a well-known gotcha.
What does it say when you run "gpg --list-secret-keys" on your local
machine now?

@_date: 2016-07-26 14:54:04
@_author: Andrew Gallagher 
@_subject: gpg: KEYTOCARD failed: Unusable secret key 
It shouldn't matter whether you have the card reader connected or not.
To get the state of your card, use "gpg --card-status".
The ">" means that the substance of the secret key has been moved to a
card; a stub remains to indicate where it went.
That is probably just the stub that you've exported, not the actual key.
That would also explain why re-importing it doesn't help.

@_date: 2016-03-01 11:20:41
@_author: Andrew Gallagher 
@_subject: Question about getting started with PGP and smart cards 
Only the private keys go on the card. Public keys are intended to be
public. ;-)
A yubikey Neo will work in the same way as a PGP smartcard, the main
difference being that you can directly connect it to a USB port without
a smartcard reader.
If you have your private subkeys on a smartcard, you can sign and
decrypt in the normal fashion so long as the smartcard is plugged in.
You don't need the card for encryption or verification, as these are
done (by other people!) using your public key.
If you run "gpg2 --card-status" when you plug the card in for the first
time, gpg will remember to check the card for those subkeys in the
future. You will also need a copy of your public key on the same machine
- depending on where you generated your private key this may not be
automatic. You can fix this by running "gpg2 --card-edit fetch" with the
card plugged in.

@_date: 2016-03-08 17:24:10
@_author: Andrew Gallagher 
@_subject: Remove photos from OpenPGP key in the keyservers 
You shouldn't think of a PGP key as a single file that is overwritten -
it's more like a logbook that is progressively filled. Your primary key
is the first entry, and each "fact" that is associated with the primary
key (id, certification, subkey, photo) gets appended to the bottom. You
can upload a new fact to the keyservers, including a fact that
repudiates a previous fact, but it all just gets appended to the log and
it's the client's job to sort through it and decide what bits are still

@_date: 2016-03-09 19:30:11
@_author: Andrew Gallagher 
@_subject: Remove photos from OpenPGP key in the keyservers 
Not only do the servers still have your picture, but clients cannot know
to ignore it unless you explicitly revoke the picture and upload the
revocation. But all this does is mark the picture as invalid. Clients
have to download the picture before they find out it has been revoked -
so other people will still be able to see it.

@_date: 2016-03-14 20:47:04
@_author: Andrew Gallagher 
@_subject: gnupg doesn't create new keys 
VMs are notorious for having poor entropy gathering. You can mitigate this by installing haveged.

@_date: 2016-03-15 16:47:06
@_author: Andrew Gallagher 
@_subject: DNS record for finding a key from an e-mail address 
"Secondary zones"? If you mean secondary nameservers, you must enjoy
living on the edge if you don't have them set up already. Your hosting
provider will often give them to you for free. I have five.
DNS is a distributed cache, so it's much more difficult to DDOS your DNS
records than it is to DDOS your website. And if you're being DDOSed you
have bigger problems.
The advantage of putting a key in DNS is that it can make use of the
DNSSEC chain of trust. A user may wish to configure their client to
regard such keys as valid in the absence of a traditional PGP trust path
(yes, there are important caveats with the DNSSEC security model, but
it's nowhere near as broken as X509). This contrasts with the
keyservers, where the presence of a key implies no validation whatsoever.
But. DNS typically has a very high latency (often measured in hours), so
one should probably also check the keyservers for revocations before
placing any trust in a DNSSEC-validated key. So the keyservers and
DNSSEC each provide features that the other does not, and can be
regarded as complementary.

@_date: 2016-03-18 13:26:07
@_author: Andrew Gallagher 
@_subject: (OT) mathematicians-discover-prime-conspiracy 
The intuitive result (that all sequences of N random equally-probable
events must have the same probability of happening first) holds if one
fixes the groupings of events in advance so that all possible sequences
are independent of each other ("mutual independence" being the most
important statistical precondition!). In this case, if the pairing of
coin tosses is always the odd-numbered toss followed by the
even-numbered toss, e.g:
TH HT HH TT HT HH TH HT
then for any *given* pair of tosses, the probability that it contains a
particular sequence is independent of any other *non-overlapping* pair
of tosses.
However, if one looks for a sequence of N events in a string without
specifying in advance which window into the string we are matching
against, then sequences of identical events will generally be less
likely than mixed ones. This is because we can choose after the fact
whether to consider an event the beginning of a new sequence or a
continuation of the previous one, and overlapping sequences of events
are not mutually independent.
An extreme example is the case of the ten-event sequences HHHHHHHHHH and
THHHHHHHHHH. Unless the first sequence of ten heads occurs at the very
beginning of the string of events (which is highly unlikely!), then the
sequence beginning with a single tails must *always* occur one event
earlier than the first sequence of ten-heads. But it could also have
occurred much earlier than ten-heads, if it had been followed by another
Alternatively, we could consider how we treat the sequence history after
a "success". Do we wipe the slate clean once we get ten heads and start
over? Or if the eleventh toss was another head, do we consider that a
second sequence of ten heads? If we can choose part-way through an
experiment when to stop, then that skews not only the order in which
events are seen, but also the probability that they will be seen at all.
The moral of the story is: outside the comfortable walls of mutual
independence, there be dragons. ;-)

@_date: 2016-03-19 22:35:52
@_author: Andrew Gallagher 
@_subject: (OT) mathematicians-discover-prime-conspiracy 
You are correct, as this is implicit in the formulation of the problem: start flipping coins and see how long it takes for a particular pattern to turn up once. The implicit assumption is that you then stop, rather than continuing to accumulate data. And that's where the problems start. :-)

@_date: 2016-03-22 13:55:18
@_author: Andrew Gallagher 
@_subject: EasyGnuPG 
This is undeniably true. Unfortunately you first need to learn the API, which can be a barrier to someone who knows the command line interface and just wants to hack together a script to do a particular job. Cryptography is hard, and decades later we still aren't at the point where average computer users can take advantage of it without either first becoming experts or punching holes in the sides of the boat. For that we need to be encouraging hackers and tinkerers to experiment with novel interfaces; and this is best done by giving them the software equivalent of Lego rather than Meccano. This is not a gpg-specific issue. OpenSSL suffers the same problem of having to be both a comprehensive implementation and a user interface, and handles it pretty much the same way, by using a basic command prompt. Where is the gpg equivalent of easy-rsa though? This is a complaint about software tools in general, but for hackers and tinkerers inconsistency across UIs is a significant barrier to entry. If I can't take what I've learned from using the command line for years and apply it (safely) to writing a modest shell script, I'm going to think long and hard before taking the time to learn a Python API. At the very least, any feature accessible through an interactive interface should have an equivalent command line option, so that all interactive operations can trivially be automated. Thought should also be given to whether wrapping all functionality in a single binary with thousands of options is the best interface to present to even expert command line users (again, OpenSSL is another offender). I say this because I found myself in exactly the same boat as the OP. I wanted to write a small script for my technically-proficient but non-cryptography-expert users so that they could easily manage gpg private keys without me worrying that they'd screw it up; and I ended up with a fragile interface very similar to his that needed to be completely refactored using gpgme. Just interfacing with gpg was the most difficult part of the process; the logic that I built on top of it was easy by comparison. This is the wrong way around.

@_date: 2016-03-22 18:14:45
@_author: Andrew Gallagher 
@_subject: Verification via the web of trust 
All this is true. But this does not help *me* one iota.
While the usual formulation of the web of trust (or any PKI for that
matter) runs along the lines of "given that I trust this finite list of
people, can I verify this particular signature?", the question most
useful to a user is "given this particular signature, how much
confidence should I invest in it?".
They are not the same question.
Real world example. I wanted to install the latest copy of Apache for
windows. It is signed by one William A Rowe Jr. I do not know William A
Rowe Jr, nor do I know any of the people who have signed his key, nor am
I ever likely to meet them, let alone trust them enough to verify other
keys on my behalf. I'd never even heard of William A Rowe Jr before I
tried to download his software. And yet the PGP signature on that binary
must be worth something other than zero.
In my quest to verify the signature of William A Rowe Jr, I ended up
downloading over a thousand keys. Even importing the entire Debian
keyring and setting them all to marginal trust (I'm already trusting
them to write my OS, so why not?) wasn't enough. I did manage it in the
end by assigning full trust to a judicious selection of people that I
recognised by name and reputation, and a few that I didn't.
Sure, it probably wasn't worth the effort I spent on it. And of course,
I then ended up with a terrifyingly liberal trustdb - but which was
still not liberal enough to verify a significant fraction of posts to
debian-security despite me marginally trusting their entire keyring.
My point is, there are times when you want to be absolutely certain that
a particular key belongs to someone you know and trust. And there are
times when you are looking for whatever assurances you can get that some
random dude on the internet isn't about to pwn your server. I'd contend
that the second use case is far more common than the first.
If you can't ascribe at least *some* level of trust to multiple PGP
signatures in the WOT made by named individuals (even those not
personally known to you), then you certainly shouldn't be relying on
X509 certificates issued by a single one of hundreds of faceless CAs
through some automated process. But every day you do that, because the
alternative is not to use the internet at all.

@_date: 2016-03-22 18:43:20
@_author: Andrew Gallagher 
@_subject: Verification via the web of trust 
Only for a project with one developer! Otherwise, the person who signs
it could legitimately change between releases. Large projects often have
a separate release signing key, but not apache it seems...
And at the risk of getting shot down (again), TOFU doesn't work. Not
because TOFU is broken (it's a perfectly valid method), but because
*people* are broken. How many times have you blithely clicked through an
ssh "WARNING: the remote host key has changed!" prompt? ;-)

@_date: 2016-03-22 22:56:27
@_author: Andrew Gallagher 
@_subject: EasyGnuPG 
Please please for the love of all that is sweet and beautiful in the world don't make an encryption-usage primary key. If you ignore everything else Peter has said, please don't ignore this. There are no benefits whatsoever to making an E-usage primary key, and plenty of reasons not to. And unlike expiry dates which can be fixed later, once you have E enabled on a primary key you can't remove it without hacking the innards of the data structure.
IMHO the only thing to do with E-usage primary keys is revoke them and start again from scratch. The only reason they are even still allowed in GPG is for backwards compatibility, right...?

@_date: 2016-03-23 15:35:46
@_author: Andrew Gallagher 
@_subject: EasyGnuPG 
A signing primary key is fine. I prefer making single-use subkeys for each of A,E,S but only the E subkey is strictly necessary. You can always generate the A,S subkeys later if you find you need them (e.g. if you buy a smartcard), and since you can always enforce use of your A,S subkeys (unlike E, where it's out of your hands) this shouldn't cause you any issues if you change your mind. If you are aiming your tool at beginners then single-use subkeys are probably overkill, so the GPG defaults are fine. In general, you should stick to the default behaviour unless you can justify doing otherwise.

@_date: 2016-03-23 16:54:51
@_author: Andrew Gallagher 
@_subject: Verification via the web of trust 
PGP pathfinder will tell you what paths exist between any two specific
keys, so long as they are both in the strong set.

@_date: 2016-03-23 23:38:36
@_author: Andrew Gallagher 
@_subject: Verification via the web of trust 
You're contradicting something I didn't say.
"Very little" is still better than "nothing", which is the only alternative on offer. Unchanged compared to what? ;-)
All true. And all beside the point that I was making, which is that a validated signature may not be much, but it's a) all that we have, and b) better than nothing. Spending a lot of bandwidth refuting straw man points that I didn't actually make is also a fools' errand. ;-)

@_date: 2016-03-24 20:46:54
@_author: Andrew Gallagher 
@_subject: Verification via the web of trust 
I don't see anyone on this thread arguing otherwise. All that I've claimed is that *some* trust path is better than none, as it provides a speed bump against *some* attacks. All security is just speed bumps in the end - if the NSA really wants to get you, they probably will. Listing the attacks a particular measure *doesn't* cover (developer coercion!) doesn't tell us anything, particularly when a) nobody claimed that it did and b) no other practical measure covers them either.
Value is in the eye of the beholder. I did say that my effort was not worth the result. You said it was a fool's errand. I don't see how we are disagreeing on anything of substance.

@_date: 2016-05-05 12:01:45
@_author: Andrew Gallagher 
@_subject: Hundreds of RSA keys factored 
Hanno B?ck has a fairly comprehensive response here:
tl;dr: they're mangled, useless copies of real pubkeys, and mangled keys
will almost always be non-prime.

@_date: 2016-05-08 21:39:48
@_author: Andrew Gallagher 
@_subject: OT egpg evaluation 
By hand, yes. If you are constructing the algorithm yourself and have a reasonable expectation of the file names etc and are confident you won't hit any edge cases. If you're knocking something together for a particular purpose and don't mind picking up the pieces when it doesn't work exactly as you expected. But when you expect other people to use your code on machines you've never heard of and in contexts that you never anticipated, it's a whole order of magnitude more complicated. In particular, if your language of choice doesn't support an execve() equivalent (e.g. perl's open(,,,)), you're pretty much screwed before you start. Andrew Gallagher

@_date: 2016-05-23 23:03:06
@_author: Andrew Gallagher 
@_subject: Encoding of user ID strings 
You can tell fairly reliably if someone is using either vanilla ascii or UTF8, in the cases of "7-bit characters only" and "8 bit characters in strictly valid UTF8 order" respectively. An off the shelf UTF8 validator should be able to do that for you. In the case of "all 8-bit characters, no 7-bit" you're dealing with either a practical joker or EBCDIC. Same thing really...
After that you're into heuristics. There are quite a few programs out there that attempt to detect encodings statistically, but with such a short string of data you might as well pick a number. ;-)

@_date: 2016-05-23 23:54:47
@_author: Andrew Gallagher 
@_subject: Encoding of user ID strings 
I'd forgotten about that. Or any of the iso-8859 that encode non-Latin scripts. Or shift-jis. Or... Or... :-(
One of the little-appreciated advantages of UTF8 is that its horribly inefficient byte level encoding is so distinctive.
I'm afraid this is one more case where the only reasonable position to take is "speak UTF8 or the management cannot be held responsible"... ;-)

@_date: 2016-11-21 11:24:50
@_author: Andrew Gallagher 
@_subject: Primary and Signing Key on Different Smart Cards 
Have a look at the graphs on page 7 of this PDF:
tl;dr: Some smart cards have *shockingly* poor RNG implementations.

@_date: 2016-11-22 18:25:29
@_author: Andrew Gallagher 
@_subject: Implications of a common private keys directory in 2.1 
gpg is intended to run on the client, not the server. A mail service
operator should not hold the private keys of its users, never mind
perform encryption operations on their behalf. I would question the
design of your architecture if you feel this is necessary.

@_date: 2016-11-23 09:53:45
@_author: Andrew Gallagher 
@_subject: Implications of a common private keys directory in 2.1 
There is no problem having a server in control of a key. Just so long as we understand that the key is now the *server's* key, not the user's. And there's no point in the server having multiple keys when the same information can be conveyed using a standardised header that's signed by a shared key. All you're saying with the signature is "the sender of this email appears to have authenticated to this server using X credentials", where the credentials in this case are equivalent to username/password. It sounds to me like you're trying to reinvent DKIM. True. But this appears to be unrelated to your proposal. There are ways around this, such as attaching the real message as a PGP encrypted attachment to a generic form letter (as per Facebook), or alternatively encrypting the header values individually (as per memoryhole). But the received: headers of the message will leak this anyway. Unless you configure your mail queue to only run once a day. If you are worried about an attacker on the wire doing statistical analysis of your message sizes and patterns of use, you will probably have to go the whole hog and transport over Tor. And even that is no panacea. If the message is being automatically decrypted at the MTA then it provides no more security than TLS. And if we are only encrypting the content of the mail, then it provides less security than TLS, which encrypts everything from the handshake onwards. How does this provide the user with any more assurance than DKIM verification?
You have not described a transport security layer, but an MTA-to-MTA message encapsulation protocol. I don't see how this improves upon TLS+DKIM.

@_date: 2016-11-23 10:54:13
@_author: Andrew Gallagher 
@_subject: Implications of a common private keys directory in 2.1 
Absolutely. But if you're using a non-standard protocol, then you also
need to explicitly configure both sides. So in practical terms there is
little advantage.

@_date: 2016-11-23 18:51:25
@_author: Andrew Gallagher 
@_subject: Implications of a common private keys directory in 2.1 
Aha, this is the subtlety I was missing. Yes, this sounds like an
interesting project.
I still don't understand what you gain from per-user keys though.
But the SMTP envelope contains plaintext addressing info. TLS protects
this on the wire, while PGP encryption of the message (even the
headers) does not.
That wasn't my question. I was asking what advantage a per-user
signature gives you compared to a server signature over a custom header.
But if you have a per-user signature on the message content, surely the
sender can still be deduced? At least on the last hop...

@_date: 2016-11-25 13:18:19
@_author: Andrew Gallagher 
@_subject: Implications of a common private keys directory in 2.1 
In this case, you must have already created a separate PGP keypair on
your local machine for each nym username.
So the server can sign the WME encapsulation with it's own key. It
doesn't add anything for the server to use a per-userid key, because
the user must already have a per-userid key locally in order to use
nym, and so can sign the original message in the MUA.
The same applies at the receiving end. The recipient must have a
per-userid PGP key, and therefore can decrypt messages in their own
MUA. Encryption to the receiving nym server's common key is sufficient
for confidentiality as far as the mailbox - at which point it gets
converted back to a standard PGP message.
So I can see why you want per-userid PGP keys. And I can see why you
want an encryption/signing layer at the MTA. What I don't get is how
implementing per-userid keys *at the MTA* gives you anything but grief.
Sorry if I'm diverting the subject of the thread, but my initial
suspicion was that your scalability issues are the inescapable result
of an over-egged design, and I haven't read anything since to change my

@_date: 2016-11-28 15:00:22
@_author: Andrew Gallagher 
@_subject: Implications of a common private keys directory in 2.1 
I understand how this would be useful for people with limited clients,
but is it really worth it to worry about disclosing metadata at the
server when you're leaking plaintext at the client?
I was assuming that the end user would have a PGP-capable client. In
the case where the end user does not have PGP, would it not be safer to
use webmail over TLS? At least you won't leak plaintext...
Doesn't the return path leak this info anyway? Unless you're talking
about one-shot messages with no return path, in which case why sign at all?

@_date: 2016-10-14 22:01:49
@_author: Andrew Gallagher 
@_subject: Secret key Questions regarding expiration and backing up 
Secret keys don't have expiration dates, only public keys. Best practice is to set an expiration date of a year or two in the future on the primary key, and either the same or shorter on your subkeys (I use the same expiry myself, for simplicity). The reason for this is that you may lose your secret material or forget your password, and you don't want stale keys hanging around on the internet forever with no indication that they are no longer usable. Yes. Just edit the public key and republish. The expiration date only informs other people that their software should stop using the key - it doesn't prevent you from doing anything.

@_date: 2016-10-15 00:16:45
@_author: Andrew Gallagher 
@_subject: Secret key Questions regarding expiration and backing up 
The expiry date shown here is just a copy of the one on the public key. It is checked by gnupg to prevent it making signatures with a secret key that has an expired public key (and which are therefore unverifiable by others). I suppose you could think of this as being the expiry of the secret key, but it is always the same as that of the public key and the one on the public key is the important one.
I'll defer to someone more expert than me on the internals, but my understanding is that a copy of some public key information (such as expiry dates) is kept in the corresponding secret key store, and this will be updated when the public key is edited.

@_date: 2016-09-10 22:13:34
@_author: Andrew Gallagher 
@_subject: Confusion about a statement in the FAQ 
Do you have a link to how they plan to implement it?
Andrew Gallagher

@_date: 2016-09-11 01:00:35
@_author: Andrew Gallagher 
@_subject: Confusion about a statement in the FAQ 
Whichever "they" you had in mind when you brought it up...? ;-)
memoryhole's readme (thanks for the link!) states that it has been implemented in enigmail but is disabled by default. Which probably answers my question. :-)
Thanks.

@_date: 2016-09-13 12:07:46
@_author: Andrew Gallagher 
@_subject: Confusion about a statement in the FAQ 
Well, I sort of wanted to know about them all, i.e. if there was an
emerging consensus. Not much use if all the MUAs do it differently. ;-)
I've waited 20 years for it, no harm waiting a little longer for
stability... :-P
Thanks again.

@_date: 2016-09-13 13:02:22
@_author: Andrew Gallagher 
@_subject: Changing smartcard 
I recently decided to change my default smartcard on one machine
because it was easier to use and carry a flat card than one in a USB
reader, and that particular machine has a smartcard slot. I had two
smartcards anyway for testing purposes.
I thought it would be a simple matter of deleting the key stubs on the
machine in question and running gpg --card-status, but even after doing
this for both gpg and gpg2 (debian!) it still sometimes asked for the
old smartcard.
Things that worked: poldi (on login screen), enigmail
Things that didn't work: ssh, sudo/poldi (on command line)
The only thing that might explain why poldi works on the login screen
but not for sudo is the agent (which isn't running at login time, so
poldi must call scdaemon directly at that point).
Using gpg-connect-agent:
S KEYINFO xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxEDB763AD D - - - - - - -
S KEYINFO xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxCFEF4E2C T
D276000124010201000500003F990000 OPENPGP.1 - - - - -
S KEYINFO xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx0EFB3577 T
D276000124010201000500003F990000 OPENPGP.2 - - - - -
S KEYINFO xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxD39C4ACA D - - - - - - -
S KEYINFO xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx20FE2863 T
D276000124010201000500002ED90000 OPENPGP.3 - - - - -
This seems to indicate that the agent is still looking for the old card
(the one ending "2ED90000") for the slot 3 key (auth), but is correctly
configured for E and S (hence why enigmail works).
I found keystub entries that corresponded to these in
private-keys-v1.d. The offending keystub file had a modification date
earlier than the other two, so I deleted it and ran gpg --card-status
once more. The keystub file was regenerated and gpg-connect-agent now
reports the correct card ID. I didn't even have to log out and in.
So I'm happy now, but have two questions:
1. Why was the A keystub not deleted and regenerated when I did gpg
--delete-secret-keys; gpg --card-status, like the E and S ones
apparently were?
2. What do these fingerprint-like IDs in the agent and v1.d refer to?
They don't correspond to anything that --with-colons produces.

@_date: 2016-09-13 15:42:37
@_author: Andrew Gallagher 
@_subject: Changing smartcard 
I did get two slightly different terminal prompts along the lines of
"Do you really want to delete this secret key? [Y/N]". I replied Y to both.

@_date: 2016-09-28 14:25:14
@_author: Andrew Gallagher 
@_subject: recording and retrieving "secrets" into gpg files 
Seahorse stores passwords in the Gnome keyring, which is not related to
PGP -- it uses symmetric encryption based on an iterative password
hash. Try the docs for "gnome-keyring"?

@_date: 2016-09-30 17:50:01
@_author: Andrew Gallagher 
@_subject: Terminology - certificate or key ? 
The problems always start with the words "public key"...
"Lock and key" works for symmetric crypto, because you lock and unlock
with the same key. "Latch and key" is the best analogy I know of to
public key crypto, because anyone can pull a latch closed, but you need
the key to open it again.
It's true that the term "certificate" can imply an unwarranted level of
authority - but that's also true of most things in the real world that
we call "certificates", so I don't think the problem is entirely in the
terminology...! ;-)
Another problem with the signature analogy is that you don't sign with
a "key" in the real world -- but there are other physical objects that
you can "sign" with, such as a signet ring, which is a more intuitive
analogy than "private key". But then what is the "public key" in this
There just isn't anything in the physical world that works as a
watertight analogy for the underlying mathematics. The fact that the
same process can be used (with subtle differences) in *both directions*
is where all known analogies come completely unglued...

@_date: 2017-04-04 13:23:58
@_author: Andrew Gallagher 
@_subject: Smart card 
Depends whether by "smartcard" you mean the technology or the form
factor. The underlying protocol is here for the long term - it's the
same one banks use for credit cards so even if it's not fashionable, it
will still be supported by software for the foreseeable future.
But smart cards (the form factor) really only make practical sense if
your equipment has a built-in smart card reader - and that is highly
dependent on industry fashion. My current work laptop has an inbuilt
reader and that's why I chose a full format smartcard over a yubikey or
a clamshell reader - both of which are less physically portable but
more logically portable.
So while the smartcard protocol may be here to stay, the credit-card
form factor might not. But don't agonise over it. As long as you are
careful and keep an offline backup of your primary key and encryption
subkey, all you lose by picking an obsolete form factor is the money
you spent on the physical hardware.

@_date: 2017-04-04 13:53:06
@_author: Andrew Gallagher 
@_subject: Smart card 
I bought mine from cryptoshop.com and was satisfied with the experience.

@_date: 2017-08-04 15:07:22
@_author: Andrew Gallagher 
@_subject: Extraction of decryption session key without copying complete 
Yes, someone with root on the remote machine can do whatever they want
on that machine. The solution is not to perform *any* crypto on a
machine whose admins you do not trust. There's nothing that software can
do to protect you from rogue sysadmins.
If you don't want the sysadmins on the remote machine to abuse your
private key, then you have to download the data, perform your crypto
locally and then upload the data again. Once you allow any software on
the remote machine to access your local resources, the remote sysadmins
can access them too.
This applies to all sorts of other things BTW, such as client drives and
printers shared over RDP.

@_date: 2017-02-02 13:42:35
@_author: Andrew Gallagher 
@_subject: Estonian e-residency 
Which particular people? And a head start at doing what?
AIUI the e-residency signature is not PGP-compatible, so people will
need to verify it using a separate tool. And once I have verified your
e-residency signature, what does it mean to me? At best, it tells me
that you are one of possibly many people known to the Estonian
Government as "Richard Ulrich". Unless I have already dealt with you
elsewhere via your Estonian ID, how does this help me?
What particular problem are you trying to solve? It seems to me that
unless you are going to use your E-identity for some other purpose,
tying your GPG key to it adds little value. You say your sole reason
for applying for e-residency is to add "credibility" to your existing
key. But how is asking the Estonian government to verify your passport
more credible than producing your passport at a keysigning party? Or
better still, showing it to the actual person you want to talk to?

@_date: 2017-02-07 11:33:30
@_author: Andrew Gallagher 
@_subject: Estonian e-residency 
keybase.io is a great idea. But its main use is to tie a PGP key to a
social media account or accounts that act as a surrogate web of trust
(by being referenced in multiple independent places by hopefully
reputable third parties). But if your correspondent's social network
does not overlap with yours, again I'm not sure much value is added.
I'm not sure I would have the cojones to follow through with this deal,
signatures or no. ;-)
In a scenario where you do not know the intermediary, the only
meaningful validation is whether the vendor vouches for both the
intermediary's person and key. The fact that the intermediary
offers you *an* identity doesn't mean you are validating the correct
If for example he had given you a key signed by a Russian government
agency, would you have had more confidence? Granted, you like (and
obviously trust to some extent) the Estonian e-ID system. Others might
not have so much faith.
Sorry if I'm coming across as a little harsh, but you are proposing
spending hard cash and I'd hate to see you do so and not get your
money's worth. By all means, get an e-ID for the fun, for experiment,
or to start up a company. But signing PGP keys with it is non-standard,
and it's hard enough to convince most people to verify
keys via standard methods.
The problem with any PKI (which we still haven't cracked) is that the
motivation to get your key signed is "How do I prove my identity to
others", while the motivation of the person verifying the key is "To
what extent should I trust this person". And unfortunately, the two
questions are far from equivalent.

@_date: 2017-02-10 16:10:28
@_author: Andrew Gallagher 
@_subject: Keyring operations _very_ slow 
What version of gpg are you using, and how many keys do you have? I've
been suffering from similar problems for years.
One thing I found that did help somewhat was to export my public
keyring, delete it, and then reimport the dump. I found some keys were
un-importable and (subjectively) keyring operations seem to run a
little faster now. YMMV

@_date: 2017-02-17 14:11:56
@_author: Andrew Gallagher 
@_subject: GPG, subkeys smartcard and computer 
I meant to reply last night, but didn't fancy writing this out on a
phone keyboard. No need to resend questions - this tends to be a
high-latency list for people in odd time zones, working from home, on
the move etc.
NB all the below is IMHO, YMMV etc. :-D
Both of those are subjective criteria... ;-)
What you describe is a common scenario for those who want a little more
physical security than a standard online key. If you are not an
experienced gnupg user maybe you should try using the defaults for a
while until you are comfortable. If you make a mess of encryption you
run the risk of either a) losing access to your encrypted data or b)
leaving your encrypted data wide open. You can choose for yourself
which scenario is worse. ;-)
But if you know what you're doing, then:
Personally, if you have a smartcard I see no advantage in keeping the
subkeys on your laptop (so long as you have a backup). If you want to
take things one step at a time that's up to you - just understand that
keeping an online copy of your subkeys negates the security advantages
of having a smartcard, the point of which is that the key material
never gets stored in a format accessible by malware.
If you want to use your key on a friend's PC, just beware that if you
don't trust it enough to keep a copy of your actual key on, you may not
trust it enough to not alter your messages or keylog your PIN.
Compromising the key material is the sexy bit of cryptanalysis, but
it's usually much easier to work around security measures than break
through them.
Back up the entire .gnupg directory just to be sure. Technically, you
can make do with just a backup of the secret keyring, but it will make
your life a lot easier if you back up the public keyring and your
trustdb also.
Is it worth to use that approach or, as of today, the (i) is fine? I
The second is a "cleaner" solution, but makes no practical difference.
If you have S capability on your primary key but never use it, only
your subkey signatures will ever exist, and only the subkey will
therefore ever be checked. And if your primary is compromised you have
worse problems. ;-)
If you import your master to an online PC, you lose the advantages
of keeping it offline in the first place. See below.
If you are using a smartcard, it is normal practice to generate a
separate subkey for each usage. It is no harm, and has the advantage
that you can rotate them separately.
One thing that you should NEVER do is have E on a subkey that has any
other capability, as there are known methods of tricking a user into
decrypting data by getting them to sign a specially crafted plaintext.
This is difficult to achieve in PGP, but better to be safe than sorry.
You do not create a revocation for subkeys, only for the primary. If
you still have access to the primary you can revoke a subkey at any
time. Revocations are only for when you lose control of your primary.
I personally don't keep revocations, just multiple offline copies of
my primary. This only works because I consider it vanishingly unlikely
that I will forget my passphrase. YMMV.
Having more than one E subkey is a worthless exercise - most software
will encrypt to the most recently created E subkey, meaning that
whichever one you create first will never be used (and thus won't be
able to decrypt anything).
Having multiple S and A subkeys is doable, but this just means that
your correspondents will have to check against both. Some systems will
only authenticate against the most recently created A subkey. It may be
more trouble than it's worth to manage multiple current subkeys this
way. IMO, better stick to just one of each.
If you run "keytocard" and then save your changes, you will delete the
on-disk copy of those subkeys. They will only then exist on the
smartcard. I normally don't recommend this, as it means you have no way
to back up your E subkey, and if your smartcard breaks you then lose
access to all data encrypted to it. If you are keeping your master
offline, there is IMO little extra risk in also keeping an offline
copy of your E subkey. In order to do this, once you run "keytocard" on
all three subkeys you should immediately quit gnupg *without saving*.
This will ensure that the on-disk copy is not deleted.
If you need to keep a copy of your subkeys on a laptop or other device,
use --export-secret-subkeys and transfer just that file to the device.
Again, I don't see the point in doing this for a laptop if you have a
smartcard - the only use case I have found for it is if you have a
device such as a smartphone that can't read smartcards. This does of
course mean that your subkeys are now more vulnerable to malware than
they would be if they were stored only offline and on the smartcard.
This is a compromise that you will have to decide is worth the
convenience or not. On the other hand, not all software will import
bare subkeys, so again this may be of little actual use.
In general, any time you create, change the expiry on or revoke a
primary key, subkey or ID you should republish your public key.
If you want to keep an offline copy of your secret key material, I
recommend Tails ( There are some hoops to jump
through to get a persistent storage partition set up, but it is well
supported and designed for the use case of managing sensitive data
offline. It has the advantage that you don't need a separate offline
computer for your key storage, but can boot your normal PC from a USB
key and be reasonably confident that the secret key material will stay
on the USB key.
I have written a tool to (mostly) automate the above procedure, but it
is still not ready for production use. Contact me off-list if you'd
like to help test.

@_date: 2017-02-19 10:24:10
@_author: Andrew Gallagher 
@_subject: GPG, subkeys smartcard and computer 
You need the *exact* subkey. This is why I make such a big deal about backups! Subkeys are not "created from" the primary, but completely at random. If you create a new subkey it will be completely different from any previous ones. Attaching the subkey to a primary is just a statement saying "don't use the primary key, use this subkey instead". The keys are not mathematically related. This is a feature! ;-)
Easier to just back up the entire .gnupg directory. Why complicate the restore process?

@_date: 2017-02-19 12:45:08
@_author: Andrew Gallagher 
@_subject: GPG, subkeys smartcard and computer 
In my personal experience, monkeysphere has correctly added all valid A subkeys. But I have a niggling doubt that I once read complaints from somebody somewhere (not helpful, I know) that whatever system they were using had trouble with multiple valid A subkeys. The main reason I am wary of having multiple subkeys for the same usage is that it just adds more complexity to an already complex system. In the case of E, multiple subkeys cause utter chaos. And in the case of A and S, there next to no benefit - if one of your subkeys is lost you should revoke it immediately anyway, and you can generate a new subkey while you're at it. Having an extra subkey generated in advance only gives you a tiny window of extra utility. Andrew.

@_date: 2017-02-21 14:38:39
@_author: Andrew Gallagher 
@_subject: GPG, subkeys smartcard and computer 
I did. In my original scenario, since you have to load up your primary key in order to revoke the compromised subkey, there's little extra effort involved in creating a new subkey while you're at it. (Yes, you could have prepared offline subkey revocations, but as you say this is very poorly supported and I wouldn't recommend it to anyone)
I'm not convinced having different A subkeys for each client device is useful. If one of your A subkeys gets compromised, all your servers are vulnerable until such point as your revocation gets pushed, and after which point any new subkeys will also have been pushed. So rolling A subkeys is an atomic operation on the server no matter what way you go about it or whether you have subkeys created in advance. On the other hand, if you have separate A subkeys for each *server*, then why not make life easy for yourself and just use separate primaries? Distributing revocations is the Achilles heel of every PKI. I don't know of any that has definitively solved it.

@_date: 2017-02-21 15:19:34
@_author: Andrew Gallagher 
@_subject: GPG, subkeys smartcard and computer 
And this is the main reason I started running my own keyserver - by
refreshing your monkeysphere-host keyring, you are leaking to the
keyserver which user credentials have login access to your system. :-)

@_date: 2017-02-21 15:31:50
@_author: Andrew Gallagher 
@_subject: GPG, subkeys smartcard and computer 
Using your own keyserver(s) also helps with this, because you're not
relying on external internet connectivity to get your revocations. Now,
if your keyserver loses gossip with the pool you still may not get
revocations, but only if your users push them to the pool and not to
your keyserver, which is a question of defaults.
Absolutely! :-)

@_date: 2017-01-06 11:23:26
@_author: Andrew Gallagher 
@_subject: gpg-agent has to be restarted after GnuPG SmartCard pulled from 
I suspect you don't need to kill gpg-agent, just pcscd. I had to do the
same thing when I used an ACS USB reader on my work laptop, because it
already had a built in full-size reader that I couldn't use (I had
already punched out the SIM) but which would override the (removable)
USB reader because it was always found at startup.
Put the following in /etc/udev/rules.d/99-local.rules (one line) :
ACTION=="add", SUBSYSTEM=="usb", ATTR{idVendor}=="072f",
ATTR{idProduct}=="90cc", RUN+="/usr/sbin/service pcscd restart"
You will need to change the idVendor and idProduct to match your
hardware - these can be found using `lsusb` while the reader is plugged in.

@_date: 2017-01-22 23:11:31
@_author: Andrew Gallagher 
@_subject: Full Workflow with Smart Card(s) 
Working out what to do with your primary key is the big conundrum. I don't think there is a perfect solution. Yes, and there are some on this list (not me!) who have done so and can share their experiences.
I keep my primary keys on a Tails persistent volume, and use a smartcard for the subkeys. I find Tails an acceptable compromise between completely airgapped keys and convenience. YMMV. I've written utilities to simplify key management and persistent volume backups, but these should be considered experimental and beta (respectively). I've been meaning to polish them up but can't seem to find the time - they both need extensive refactoring. But if you feel like living on the bleeding edge, go for it. :-)

@_date: 2017-01-25 09:13:42
@_author: Andrew Gallagher 
@_subject: gnupg website 
Browsers are not deprecating HMAC-SHA-1, but the use of SHA-1 in certificate signature generation. These are not the same thing. gnupg.org's own cert uses SHA-256 and it's intermediate uses SHA-364. Nothing to see here, move along. :-)
Andrew.

@_date: 2017-01-25 18:10:56
@_author: Andrew Gallagher 
@_subject: Mail address to account conversion (keybase.io) 
If the ID still "belongs" to you (in some meaningful sense) then
there's no need to revoke it just because it is unusable for the
purposes of email. It is merely a convention that IDs correspond to
email addresses. If your keybase account still exists, has a 1-to-1
mapping with that ID, and is still under your control, then IMO it's
legitimate to keep the ID - particularly if it is used as a reference
point for other things. The presence of an ID on a public key makes no
claim as to whether the ID is usable for a particular purpose. True,
people might try to email you on that ID, but the worst that will
happen is they get a bounce (and you have other, usable IDs on the same
pubkey I assume).

@_date: 2017-01-26 00:16:42
@_author: Andrew Gallagher 
@_subject: gnupg website 
I've looked into this and I'm not sure why ssllabs is degrading from A-
to C. There is a link to the blog post in the results page, but the post
appears to say that the grade will *not* be reduced. I quote:
gnupg.org *does* keep 3DES at the end of the supported suites, so surely
it should not be affected. I'm tempted to write this off as a
mistake by ssllabs.

@_date: 2017-01-26 11:49:54
@_author: Andrew Gallagher 
@_subject: gnupg website 
I've spoken to ssllabs and it appears that this was an ambiguity in the
wording of their blog post. That means the downgrade to C next month is
legit - not because 3DES is present, but because 3DES is present *and*
GCM is absent.
What both this and Glenn's Apple issue have in common is the lack of
ECDHE+GCM suites in the cipher list. I generally use the following
config in Apache:
SSLCipherSuite \
  "EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 \
  EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 \
  EECDH EDH+AESGCM EDH+aRSA +3DES 3DES \
  !aNULL !eNULL !LOW !EXP !MD5 !KRB5 !PSK !SRP !DSS !SEED !RC4"
This uses all HIGH suites in a sensible order but still falls back to
3DES for XP compatibility. When retiring 3DES this simplifies to:
SSLCipherSuite \
  "EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 \
  EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 \
  EECDH EDH+AESGCM EDH+aRSA !MEDIUM !LOW !aNULL !eNULL !PSK"

@_date: 2017-01-29 14:18:08
@_author: Andrew Gallagher 
@_subject: Expired GPG key for ssh authentication 
It is still working because the remote ssh server has no concept of key expiry. When you converted your auth subkey to ssh format you stripped all the expiry info from it. (There is the related problem of your client offering the expired key to the server, but this is relatively harmless). If you want your ssh key to stop working when the auth subkey expires, you need to make sure to run monkeysphere on a regular basis (cron) on the remote server, to refresh the authorized_keys and thereby overwrite any ssh keys associated with expired pgp keys. Ssh keys themselves do not expire. See: Andrew.

@_date: 2017-07-13 12:44:42
@_author: Andrew Gallagher 
@_subject: use policy of the GnuPG-card 
*snipped evil plan*
Worse than that, they can keylog your PIN and use that to perform
unlimited crypto operations using your smartcard whenever they detect it
is plugged in. Or they can read decrypted passwords out of memory, or
replace gpg with a version that copies everything it touches to a
network connection. The possibilities are literally endless.
Don't plug your smartcard into a computer that someone else has root
access to. That's not flippant, that's the best you can do in principle.
Smartcards can protect you against disclosure of your secret key, but
not of data encrypted to that key. If you want to protect all the data
encrypted by that key, then you still need to take all the precautions
that you need to with any other method of secret key storage, and that
means (amongst other things) don't decrypt your data on an untrusted
Remember, if someone else has root on your computer then it isn't your
computer - it's theirs.

@_date: 2017-07-15 16:35:22
@_author: Andrew Gallagher 
@_subject: Changing PINs of German bank card 
No, the chip on the card is not involved. So no website should *ever* ask you for your PIN. Run away!
Andrew.

@_date: 2017-07-17 11:19:53
@_author: Andrew Gallagher 
@_subject: How to use a the same generated keypair on enigmail/thunderbird 
In the case of iPGMail, it can also use the "mail attachment" OS hook to
automatically populate a draft email. You still need to press "send" a
second time, but you don't have to mess around with clipboards.
The disadvantage is that sending encrypted messages as attachments is
not standards compliant, and enigmail for one has great trouble dealing
with them at the other end. Unfortunately there's no way for an iOS app
to implement PGP/MIME properly, given Apple's strict restrictions on
email apps.

@_date: 2017-07-30 23:37:05
@_author: Andrew Gallagher 
@_subject: 'sign (and cert)' or just 'cert' on a master key with subkeus 
I don't think it particularly matters if you have both an S primary and an S subkey. I can't think of any use case where it would be a problem (although I'm sure now I've said it someone will correct me). What I have found problematic myself is having an A primary and an A subkey. This is because my primary is offline and I use smartcards for my subkeys, and there exist some applications which only accept one auth key. There have been times when I have mixed up my online and offline A pubkeys, which is not a security issue, but is a usability one.
So I personally would not recommend having more than one valid A (sub)key at any one time - purely for your own sanity.

@_date: 2017-07-31 16:28:27
@_author: Andrew Gallagher 
@_subject: 'sign (and cert)' or just 'cert' on a master key with subkeus 
He does, but his argument is weak. The meat of it is:
There are two enormous holes in this argument:
1. If the people you communicate with regularly don't do "gpg
--refresh-keys" regularly they won't find out whether *anything* has
*ever* been revoked. So they will continue to trust your bad signature
regardless of whether you're using a subkey, a primary key, a wax seal,
thumbprints in blood, whatever. This is a completely separate argument.
2. He seems to be operating under the impression that encryption subkeys
can't be individually revoked, which is complete nonsense. And no matter
what you do after your encryption key is compromised, yes of course all
your past communications using that key are still readable by the
attacker. But again, that's the case with or without subkeys.
And of course he overlooks the strongest argument in favour of using
subkeys, and that's so you can put them on a hardware token and not have
to store them on your laptop at all.
The only bit where he has (half) a point is that it may be a good idea
to revoke your entire key because it is noisy, and therefore more likely
to be noticed (and your compromise paid due attention to) than if you
simply rolled your subkeys. But so long as your passphrase is good, it
shouldn't matter whether an attacker has a copy of your encrypted
privkey (see: RJH's NYT small ads offer) and rolling your subkeys is a
precaution against your passphrase having been keylogged at some point
prior to losing your laptop (remembering of course that if your laptop
had malware, it's Game Over anyway).

@_date: 2017-06-02 16:03:15
@_author: Andrew Gallagher 
@_subject: Certification-only key 
The main motivation for publishing a signing secret after use is
repudiability. But for that to work properly, your correspondents need
to know that you've published the secret, and you also need to have
confidence that they know. Synchronous protocols like OTR do this
well. PGP is highly asynchronous, with typically very infrequent key
refresh cycles, and intentionally publishing secret material - even for
revoked keys - runs the risk of your correspondents getting scammed
during the refresh interval.

@_date: 2017-06-06 14:14:49
@_author: Andrew Gallagher 
@_subject: Certification-only key 
To protect against this, one would use a timestamping service to sign
the secret key publication, thereby proving the publication was earlier
than the forgery.

@_date: 2017-06-06 15:38:46
@_author: Andrew Gallagher 
@_subject: Certification-only key 
Ah, yes. I was thinking of the case where the signature was forged, not
one where the signature was genuine.
Repudiable signatures, like ephemeral keys, only really work in a
synchronous environment such as chat or TLS. The signatures are checked
automatically and thrown away before being presented to the user, which
allows them to be valid for very short periods of time (on the order of
seconds). The secret keys are then published (within the secure channel)
immediately. In such an environment, any discrepancy found by referring
to a timestamping service can be explained away by clock drift.
This reminds me of the side discussion at openPGPconf re ephemeral keys
for email. At some point you have to admit that data-in-motion and
data-at-rest security are fundamentally different beasts.

@_date: 2017-06-07 07:50:28
@_author: Andrew Gallagher 
@_subject: Question for app developers, like Enigmail etc. - Identicons 
Everything *can* be faked, given enough time, effort and/or money. The correct question is *would* criminals etc go to the necessary lengths to fake this procedure, and the answer (as always) is: it depends on what it's worth to them. :-)

@_date: 2017-06-07 14:17:12
@_author: Andrew Gallagher 
@_subject: TOFU 
If I send an email to myself from my new work email, but sign it with my
old personal key (which doesn't have my new work email as a UID), it
still shows up as green in Enigmail. Now, that may be because I'm using
an ultimately trusted key - but it's still not what one might naively

@_date: 2017-06-23 10:49:38
@_author: Andrew Gallagher 
@_subject: Managing the WoT with GPG 
Yes, this is a limitation. I did say it was dirty. ;-)
Not the raw diff, no. But it might be possible to run a diff on the
ownertrusts, ignore any "normal" changes (e.g. where the old/local trust
state was "unknown") and present the user with a list of potentially
dangerous conflicts, such as your unlikely scenario above.
Trust signatures could trivially implement this, iff it were possible to
ltsign a key without also certifying it. (Feature request?)

@_date: 2017-06-23 11:33:21
@_author: Andrew Gallagher 
@_subject: Using gpg for ssh (Maximum Portability) 
For any linux distro that provides a recent gnupg 2.1, the easiest way
(not necessarily the Proper Way) is to put the following in your ~/.profile:
if [ -z "$SSH_CLIENT" ]; then
$XDG_RUNTIME_DIR normally expands to /run/user/. For v2.0, the
default socket location is under ~/.gnupg, but otherwise the trick is
the same. Note the vital  statement that prefers a forwarded
ssh-agent over a local gpg-agent.
This avoids having to mess around with distro/gui-specific session
configurations, and also has the advantage that you can cut and paste it
onto the command line of a logged-in system. There is no need to disable
the vanilla ssh-agent - just override $SSH_AUTH_SOCK and nothing will
talk to it.

@_date: 2017-06-30 21:29:21
@_author: Andrew Gallagher 
@_subject: TOFU 
Anybody who knows enough about computers to poison your local GPG
keyring already knows more than enough about computers to be able to
download H at ck0rT00l.exe from a website and install it on your machine.
In the scenario above, it is in fact *easier* to do this without getting
caught than it is to do it by hand - perhaps as easy as inserting a
flash drive when your computer is locked.
If you want to protect yourself against an Evil Maid (or an Evil
Coworker) then you are *way* outside the scope. Encrypt your drive, lock
your screen, disable your USB ports and store your laptop in a safe. If
you can't trust the data on your computer, you can't trust a single
thing it says.

@_date: 2017-03-07 14:29:40
@_author: Andrew Gallagher 
@_subject: From Masterkey to subkey 
I would strongly recommend against that. I would create completely new subkeys, including (especially!) an E subkey with no other capabilities, and expire that weird subkey ASAP. You'll still be able to decrypt any messages encrypted to it, but it won't be used for any new messages.

@_date: 2017-05-16 16:28:23
@_author: Andrew Gallagher 
@_subject: suspicious key found 
Yes, they did. Most of the strong set was duplicated by the Evil32
project in order to demonstrate the danger of relying on short key IDs
(because on modern hardware it takes mere seconds to generate a fake key
with the same short ID). Unfortunately the fake keys got uploaded to an
SKS server and polluted the database. The authors then mass-revoked all
the offending keys, but since SKS is append-only they still appear in
search results.
The fact that invalid (even suspicious) keys exist on the SKS servers
(or anywhere on the internet for that matter) is in itself not a problem
- any decent public-key infrastructure must be designed under the
assumption that forgeries are inevitable and use some other method
(signatures, out of band verification) to determine the validity of keys.
The moral of the story is: don't believe everything you see on the
internet. ;-)

@_date: 2017-10-10 16:06:37
@_author: Andrew Gallagher 
@_subject: FAQ and GNU 
This is a universal problem that is not understood well enough. If you
want to know what people actually think, you have to a) actively survey
them, and b) control for biases in the responses. This is a nontrivial
process. Anything else tells you at best what memes are trendy[1], and
at worst what factions are committed to entryism[2]. ;-)
[1]

@_date: 2017-10-10 17:56:05
@_author: Andrew Gallagher 
@_subject: FAQ and GNU 
There is nothing in the GPL that requires one to be an evangelist. If
the FAQ is incorrect or misleading, let's change it. But "insufficient
fervour" is not sufficient grounds.

@_date: 2017-10-29 21:48:59
@_author: Andrew Gallagher 
@_subject: Impact of ROCA (CVE-2017-15361) in subkey vs. private key? 
There should be no way for a compromised subkey to affect the security of its primary key. Creating a subkey does not alter the primary key in any way; all that happens is that an SBIND signature is created by the primary key for the subkey. This does not compromise the primary key material if done in a conformant way (if it did, your implementation would have *much* more serious problems).
Further, if the subkey is revoked, the overall effect should be as if the subkey did not exist. An application that complains about revoked subkeys is probably being overly paranoid. There may be a flimsy argument that doing so might protect those people whose clients do not handle revocations properly. But if a client were to ignore subkey revocations then again, it has bigger problems.

@_date: 2017-09-01 14:31:04
@_author: Andrew Gallagher 
@_subject: E-mail with deniable authentication 
This is the real trick though - the DH algorithm requires two-way
synchronisation in advance of sending the payload. This is easy enough
with a realtime connection, but much harder with email.
Most "modern" communication protocols can implement deniability and
forward secrecy relatively easily, because they assume a realtime (or
near realtime) connection that allows for cooperative algorithms like
DH. These protocols are a form of data-in-motion security, where the
sequencing of the data is significant, and the integrity of the data is
only valid for the duration of the session.
But emails are data-at-rest. Their integrity has to be mantained for an
indefinite time, since the correspondents may not be online at the same
instance. They are closer (conceptually) to a collection of tiny
encrypted disk volumes than to communication streams, even if those
volumes are then transferred over data-in-motion-secure channels such as
To take a concrete example, when you download a file over HTTPS, your
web browser decrypts the file immediately and throws away the
now-useless ciphertext. If you save that file, it's either saved in
plaintext, or encrypted again using a completely separate system. By
contrast, when your MTA receives a PGP email, it does no decryption on
it before saving it to disk (save for whatever the TLS connection
requires). If you come back to that mail a year later, you have to
decrypt it at the point of reading. In the intervening time, the email
has sat in the pristine encrypted form.
Real-time syncronisation such as required by DH can't happen when I'm
asleep and/or my mail client is turned off. It can't happen if I don't
read my emails for a month while I'm on holiday. Now, it is still
possible to implement DH over a high-latency connection such as email -
however this would either have to involve manual intervention at each
stage (e.g. opening an attachment for each step in the DH handshake), or
a mail client that was aware of the protocol and parsed the handshake
emails both automatically and transparently. Perhaps one could adapt the
signal/whisper protocol so that each encrypted message contained part of
the handshake for future messages - but you'd have to open your
encrypted emails in the correct order and maintain an ever-expanding
cryptographic state indefinitely, which itself opens a can of worms.
What happens if you read email using multiple clients? What if someone
roots your laptop?
And as others have pointed out, plausible deniability isn't a panacea.
It's only really useful in the case where your adversary must prove
their assertions to an independent fourth party beyond reasonable doubt.
It might keep you out of jail in a well-functioning democracy, but it
won't save you from the mafia, the CIA or Kim Jong Un.

@_date: 2017-09-10 17:34:35
@_author: Andrew Gallagher 
@_subject: [Feature Request] Multiple level subkey 
I think C subkeys are a *much* simpler solution for that use case. Better to treat this scenario as "solved in principle" and put it aside for the time being.

@_date: 2017-09-26 12:07:48
@_author: Andrew Gallagher 
@_subject: Houston, we have a problem 
Absolutely. But it can *appear* to be trustworthy, and this is a problem
in itself.
The issue is UX and user expectation. If I go to a server and ask for
some specific data, and the server gives me that data, then there is an
implied authority to that data. We can argue here until the heat death
that users *should not* read any sort of endorsement into a server
merely providing data. But that's not the way human beings think. And
trying to train human beings to constantly fight against their instincts
is like trying to train cats not to catch birds.
If we don't want people to read anything into unverified data, then we
should not display unverified data in a form where people may mistake it
for verified data. So in this case, the problem arises not because the
server has provided a signature on a key, but because it has naively
repeated the (unverified) claim that a particular signature was made by
a key that has a particular ID bound to it, in human readable form and
without a giant red flashing neon sign saying *THIS IS ALL LIES*.
As you say, we know nothing meaningful until the full signature chain
(including any SBINDs) has been validated. The problem comes when
software is "being helpful" and blindly regurgitates unverified
(therefore meaningless, therefore *misleading*) data. Average users
cannot be expected to remember when data has been verified and when it
has not. The only way to stop people making the same mistakes over and
over again is to stop facilitating those mistakes.
We can draw a parallel with fake news. No matter how many times you tell
people "Do not trust anything you read on the internet", the default
state of the human brain is to believe what it is told unless suspicion
is aroused. It can only be thus. If you doubted every single thing you
were presented with every day, you would never get out of bed.
So when SKS lists the signatures on a key, people believe it. When
Enigmail says "untrusted good signature", people read the "good" and
gloss over the "untrusted". The only way to stop people believing things
that may not be true is to stop telling them things that may not be true.
So SKS should just say "unverified signature from ". It
should not repeat the purported user ID, nor provide a search link that
returns completely unrelated keys that happen to have the same purported ID.
But user-facing software shouldn't be exposing unverified IDs *at all*.
Enigmail now sort-of does this - the latest versions won't even admit to
the existence of a signature by a key that's not in the keyring. It
could do even better - it should stop saying "untrusted good signature"
and just say "unknown signature". If people want the gory details, they
can click the details button.
The gpg command itself should cryptographically verify signatures when
performing --list-sigs, so that at least it can throw a warning when an
invalid signature packet is found. Ideally it should not display invalid
packets at all (by default). Displaying a genuine-looking signature on a
key that doesn't result in a valid chain of trust is a sure way to
encourage people to work around the safeties.
It is not enough that something bad is forbidden. You have to make it
obvious at all times *why* it's forbidden, otherwise people think the
system is broken and fight against it.
The fact that technically-proficient people have been coming in here for
twenty years with the same misconceptions about what is and isn't
verified and/or trustworthy is a sign that there's something
fundamentally broken with the ecosystem's UX.

@_date: 2017-09-26 13:15:58
@_author: Andrew Gallagher 
@_subject: Houston, we have a problem 
Um, did you reply to the wrong paragraph? I did mention disclaimers
elsewhere, but only in passing (and tongue in cheek). My argument is
that we shouldn't be displaying unverified information at all.
Absolutely. None of this is an argument against users having to do
things right. But the way to get users to do things right is to train
them to do things right from the start - and you do that by railroading
them down the straight and narrow and not even have the option to do it
any other way. That way, if the opportunity to do it wrong arises in the
future their first instinct will be "this isn't how it's supposed to
happen". If you can't train people personally, you have to write your
software so that the software trains them.
WhatsApp gets the UX *very nearly* right. And since everyone and his dog
now uses it that's the new baseline. If it's easier to do it wrong than
in WhatsApp, it's broken. If it's harder to understand than WhatsApp,
it's broken. If you have to read more instructions than WhatsApp, it's
It's no good implementing something correctly if it can be applied
incorrectly. Murphy's Law applies.
Indeed, but is it necessary to display the untrustworthy user-ID on
signatures? The fingerprint should be sufficient.

@_date: 2017-09-26 14:38:06
@_author: Andrew Gallagher 
@_subject: Houston, we have a problem 
Users shouldn't do it. And yet they still do it, precisely because it is
a convenience.
It's broken, but it's usable. They've prioritised usability over
security, absolutely. People don't care. They should, but they don't.
We're not going to get them to embrace something technically better if
it's harder to use.
Yes. Unfortunately it's tricky to implement that on a smartphone. We
don't have card+phone working in gnupg yet either. We *barely* have
gnupg working on phones at all. But that's for another day.
I wouldn't go that far. The signature itself is not a signature by "John
Doe " - it's a signature by some (sub)key "0x123456...".
The fact that it may or may not be a (sub)key bound to "John Doe" is
rightly stored elsewhere. My argument is that displaying an unverified
comment that *implies* there is a binding *somewhere else* identifying
this key with a particular ID may be a convenience, but is a)
unnecessary and b) a source of confusion. We can't perform any
verification without downloading the full key of the owner anyway, and
that's done with the fingerprint.

@_date: 2017-09-26 14:51:34
@_author: Andrew Gallagher 
@_subject: Houston, we have a problem 
Not getting into an OS flame war here, but not everyone uses Android. ;-)

@_date: 2017-09-26 16:52:04
@_author: Andrew Gallagher 
@_subject: Houston, we have a problem 
Yes, this is a universal problem. The people who are most invested in
Thing X are also the people who are most resistant to making Thing X
more attractive to new people. This applies to politics, culture,
engineering, you name it. It's also the main non-technical reason why we
keep reinventing things from scratch instead of building on what we
already have (the technical one being baked-in assumptions).
On the other hand, I am usually the first person to complain about
weakly justified UX changes. Gnome3 comes to mind... ;-)

@_date: 2017-09-27 10:10:54
@_author: Andrew Gallagher 
@_subject: Houston, we have a problem 
I've been using gpg for decades, and I was unaware of the distinction.
But a follow-on question arises: is Enigmail using --list-sigs rather
than --check-sigs? Its output appears to be derived from --list-sigs,
which undermines somewhat the rationale behind only displaying sigs from
known keys.
Or just describe --check-sigs and have --list-sigs tucked away in an
"experts only, beware" section.
This is the sort of thing I was thinking of when I talked about
"railroading the user" earlier. There are two ways of doing something,
one is more secure than the other but it's not immediately clear which,
and the casual user therefore has *too much* choice. This has two
effects: 1. the user may choose the less secure option by accident; 2.
the user is frightened of using the software for fear of choosing the
less secure option by accident.
And if you do choose the less secure option by accident, there's no
feedback to tell you that you're off the reservation. I've been using
--list-sigs forever and I thought I was getting --check-sigs. At no time
did gpg disabuse me of that. I hear the arguments about users becoming
reliant on warnings, but warnings in this case aren't about telling
people that something unexpected has happened - they're about telling
users that they're doing it wrong. Once they learn how to do things
right, they become *less* reliant on the warnings, not more.
Yes, but unless a collision is found (in which case we're all screwed),
a signature made by a fake key will have a distinct fingerprint, and
we've reduced the problem space back to fake keys, which at least have
the advantage of being well-known. An option such as Enigmail's "don't
display unknown sigs" can handle that. Furthermore, if "don't display
unknown sigs" was default behaviour everywhere, it would remove the
incentive to make wasteful vanity sigs in the first place.

@_date: 2017-09-28 12:30:11
@_author: Andrew Gallagher 
@_subject: preferring --check-sigs over --list-sigs [was: Re: Houston, we 
What specific error are you getting? I don't see any errors using
--check-sigs on that key, but then I don't trust Governikus so I'm not
performing the same test that you are.
BTW, your usage of key IDs to contain arbitrary text produces some weird
galactica:~ andrewg$ gpg --search-keys stefan.claas at posteo.de
gpg: searching for "stefan.claas at posteo.de" from hkps server
(1)	supersedes 0x981EB7C382EC52B4
(2)	Stefan Claas (ECC Test Key - do not use) (3)	Stefan Claas (4)	Stefan Claas
Keys 1-4 of 4 for "stefan.claas at posteo.de".  Enter number(s), N)ext, or
Q)uit > 1

@_date: 2017-09-28 14:43:54
@_author: Andrew Gallagher 
@_subject: preferring --check-sigs over --list-sigs [was: Re: Houston, we 
As I argued above, vanity signatures *shouldn't* be an issue - the
problem comes when client software blindly regurgitates vanity
signatures without any consideration of their usefulness.
But back to the point at hand. I wasn't referring to you putting
plaintext in your ID (lots of people do that), but because you split the
plaintext over multiple IDs it becomes scrambled because IDs don't have
an intrinsic order.

@_date: 2017-09-28 14:58:05
@_author: Andrew Gallagher 
@_subject: preferring --check-sigs over --list-sigs [was: Re: Houston, we 
Apologies, you are right. Importing the governikus key gives me the same

@_date: 2018-04-26 10:05:59
@_author: Andrew Gallagher 
@_subject: Quick commands documentation 
Hi, all.
There's a suspiciously empty documentation page on the main site:
Is this still WIP, or just an update/sync error?

@_date: 2018-02-06 10:16:07
@_author: Andrew Gallagher 
@_subject: OpenPGP card && exporting secret keys 
I recommend using an offline system to do this; then you don't need to
worry about leaving traces behind. Tails is a good solution, as it
provides an encrypted persistent partition and comes with a recent gnupg

@_date: 2018-02-28 17:57:36
@_author: Andrew Gallagher 
@_subject: gpgsm as a CA 
Hi, all.
Is there any support for using gpgsm as a certificate authority?

@_date: 2018-01-04 08:25:27
@_author: Andrew Gallagher 
@_subject: Modernizing Web-of-trust for Organizations 
This bit confuses me. If you already store a private key locally, why use it to download a second private key? If you?re using a key escrow system then surely you just need to upload the private key once and keep a local copy?

@_date: 2018-01-05 09:13:52
@_author: Andrew Gallagher 
@_subject: Modernizing Web-of-trust for Organizations 
The standard way of doing this without allowing for impersonation is escrow of the encryption subkey only. This can be done by encrypting the E subkey to the auditing key, the private key of which is presumably well controlled.

@_date: 2018-01-15 18:53:26
@_author: Andrew Gallagher 
@_subject: Remove public key from keyserver (was: Hide UID From Public Key 
You also need to prove that removal is technically possible. Otherwise all that such a court case will achieve is to shut down the keyservers.

@_date: 2018-01-15 23:19:02
@_author: Andrew Gallagher 
@_subject: Remove public key from keyserver 
So long as there is one keyserver somewhere in the ecosystem that fails to enforce this, I don?t see the point...

@_date: 2018-01-16 11:51:03
@_author: Andrew Gallagher 
@_subject: a step in the right direction 
This is an important distinction.
Ordinary users should not be browsing the raw data. They should be using
tools such as Enigmail that filter out unverified data from their
default views. Sure, if you want to go looking for all the junk
signatures on people's keys you can, but it shouldn't be displayed as a
matter of course.
Now, for various reasons a lot of us on this list have spent far too
much of our lives looking at the raw keyserver data. And similarly, I
have no doubt that a lot of early Bitcoin adopters have looked at the
raw blockchain data.
So we have to distinguish between what is available if one is
sufficiently motivated to go and look, and what is shown to the majority
of users. The vandalism problem is solved by clients not displaying
unverified content. Whereas the "nightmare scenario" happens entirely
out of view of the average user, but has more serious consequences.
Let's not mix them up.

@_date: 2018-01-16 18:05:49
@_author: Andrew Gallagher 
@_subject: DRM? 
The right to be forgotten is not absolute. For example, it does not
require that published news be unpublished, although it does sometimes
ask that published news not show up in search results. It also does not
require that search engine operators scrub their internal databases.
It is technically difficult to prevent keys from being propagated
because altering or deleting data packets breaks the assumptions upon
which the reconciliation algorithm is founded. But there is nothing to
stop individual servers from scrubbing search results of keys that have
a valid "nopublish cert" (however this may be technically implemented).
This would not affect SKS reconciliation and would reduce the
computational overhead.
IF something like this were to be implemented, then only searches for
IDs should be stripped. Searches on fingerprints should always return
data, in order to ensure that revocation certificates are still
distributed. "Nopublish" certs could also be used by well-behaved
clients as a guard against accidental disclosure, even if preventing
malicious disclosure is technically impossible.
If we were worried about the *legal* implications of right to be
forgotten, then this could be a defensible fallback position. But it is
not a solution to many of the *practical* problems in privacy protection.
Ultimately, the PGP ecosystem prioritises security over privacy. They
are not the same thing, and in some cases they are in conflict.

@_date: 2018-01-16 18:12:11
@_author: Andrew Gallagher 
@_subject: DRM? 
IF you wanted to go this route, it would be easier for keyservers to
only serve the master key + revocation cert for *all* cases where a
revocation cert exists. What does it matter who signed a key that has
been revoked, or what IDs it used to be tied to? It's dead, throw it away.

@_date: 2018-01-16 18:50:45
@_author: Andrew Gallagher 
@_subject: DRM? 
Yes, absolutely. This would be a presentational fix. It would also be a method of giving people a way around right to be forgotten - revoke your cert and your info becomes more or less unsearchable. Agreed. I was thinking more along the lines of having some method of causing signature vandalism to expire.

@_date: 2018-01-17 01:09:43
@_author: Andrew Gallagher 
@_subject: key distribution/verification/update mechanisms other than 
It would make it *very* slightly more computationally expensive to pull off, but would not limit the impact one bit.

@_date: 2018-01-17 15:51:07
@_author: Andrew Gallagher 
@_subject: key distribution/verification/update mechanisms other than 
The main technical question is where should this policy be applied?
1. At upload stage - easy to implement, but requires all keyservers to
cooperate. It also means starting from an empty set, effectively
building a parallel keyserver network from scratch.
2. At replication stage - this would be effective, but to the best of
our knowledge would cripple the algorithm.
3. At search/display stage - almost as easy as 1, although more
computationally intensive as it would need to be calculated per download
(caching may help). Can be retrofitted to existing keyservers.

@_date: 2018-07-16 11:57:37
@_author: Andrew Gallagher 
@_subject: key distribution/verification/update mechanisms other than 
As I see it, the keyservers perform two related but distinct functions -
finding unknown keys by UID, and finding updates to known keys by
All the current issues are related to the first function, but the first
function has several alternative solutions available (DNS, WKD, Keybase,
attaching pubkeys to every email...). If this first function were to
fail overnight, it would be an inconvenience but not a disaster.
But there is no known alternative to the second function, which is the
distribution of key updates, including revocations. Therefore I believe
the immediate priority should be to protect update distribution.
How to prevent abuse of a distributed, unauthenticated store of
arbitrary data remains an unsolved problem (see: usenet). If the
keyservers are to remain unauthenticated and distributed, then the only
option is to prohibit arbitrary data. That means no arbitrary data
fields (i.e. no UIDs) and no arbitrary data in structured data fields
(i.e. validity checks on self-sigs). This will shrink the size of the
database significantly, but impose some processing cost.
There are two ways forward: a new network of key-material-only servers,
or restricting the existing network to key material only. In the first
case, we would still need a means to propagate keys between the old and
new networks during the transition. And in the second case, we would
need to handle an intermediate state where only some servers have been
upgraded to the new version.
So no matter what we do, we will still need to have some method of doing
fake recon with legacy sks instances. The question is how to arrive at
this state most efficiently. I would suggest that since recon is at the
root of the problems, we should concentrate on the recon process itself.
If uploading a bad key takes down one server then fine, we can lose one
server. But the badness must not infect other servers automatically.

@_date: 2018-07-16 13:56:48
@_author: Andrew Gallagher 
@_subject: Forwarding both gpg and ssh agents 
Yes, but remember you have to enable ssh-agent support on your local
machine and forward both gpg and ssh agents separately down the full
chain of connections. You can't patch one into the other at some
intermediate stage, it has to be at your end.
So long as you have agent forwarding enabled at each step in the chain,
you should be able to forward it through an unlimited number of chained
I use this arrangement myself every day, and have written some (basic)
documentation for internal use in my company. Let me know if you need
any further help.

@_date: 2018-06-05 07:56:54
@_author: Andrew Gallagher 
@_subject: Forward gpg-agent to container 
This sounds overly complicated. Once you have the extra socket visible inside the container, it should be sufficient to set the environment variable GPG_AGENT_SOCK. You don?t need to start an extra agent inside the container.

@_date: 2018-03-15 17:11:15
@_author: Andrew Gallagher 
@_subject: Stupid Symantec 
The obvious approach would be to write a FUSE driver. It would be
mounted as an overlay filesystem, and this filesystem would decrypt the
encrypted files on demand into a ramfs, and then re-encrypt (and shred)
on file close.
I saw a commercial product here that might do what you want, but the
documentation is making my brain hurt:

@_date: 2018-03-16 09:04:24
@_author: Andrew Gallagher 
@_subject: Stupid Symantec 
If you mounted the remote filesystem using smbfs you should be able to mount an overlayfs over the top, just like any other mounted filesystem.

@_date: 2018-03-16 13:15:02
@_author: Andrew Gallagher 
@_subject: Stupid Symantec 
How does that work when the decryption key is on the client?

@_date: 2018-05-03 10:03:29
@_author: Andrew Gallagher 
@_subject: Quick commands documentation 
Aha, I was misreading that reference as one to "Programmatic use of GnuPG".
Perhaps it would be clearer if that section was refactored a little, from:
Recent versions of GnuPG have an interface to manipulate keys without
using the interactive command --edit-key. This interface was added
mainly for the benefit of GPGME (please consider using GPGME, see the
manual subsection ?Programmatic use of GnuPG?). This interface is
described in the subsection ?How to manage your keys?.
Recent versions of GnuPG have an interface to manipulate keys without
using the interactive command --edit-key. The non-interactive --quick-*
commands are described in the subsection ?How to manage your keys?.
The non-interactive interface was added mainly for the benefit of GPGME,
which is described in the manual subsection ?Programmatic use of GnuPG?.

@_date: 2018-05-14 10:03:48
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
This confirms that my forensic analysis of the wording of the
announcement was sound. ;-)
The good thing is that oracle attacks are *noisy*, so you'll notice when
it happens.
Unfortunately HTML mail is commonplace, so never reading an HTML mail
again may be too much to ask.
So how do we enforce MDC checking at the receiving end? I assume this is
something that has to be handled by the calling program at the moment. I
see that MDC is the default for all modern ciphers, but does that imply
that MDC *checking* is the default? If so, then all we would need to do
is disable non-modern ciphers.
Looks like S/MIME is pretty much buggered though...

@_date: 2018-05-14 10:30:18
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
OK, but from Werner's link earlier:
So if someone sends me a 3DES-encrypted mail it won't check the MDC?
Doesn't gpg still support reading 3DES?

@_date: 2018-05-14 11:56:00
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
Yes, but that's not as serious as the error thrown for an unprotected
AES message. Do mail clients treat such warnings as fatal? Should mail
clients *ever* treat mere warnings as fatal?
I can't test here because I'm suffering from  - guess that means I'm immune! ;-)

@_date: 2018-05-14 12:13:31
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
I tried again using CAST5 instead of MD5 to bypass the smartcard bug.
The news is not good.
andrewg at fred:~$ gpg --recipient 0xFB73E21AF1163937 --cipher-algo CAST5
--disable-mdc --encrypt --sign --armor reply.txt
gpg: using "00CC54C6A0C601691AF4931FFB73E21AF1163937" as default secret
key for signing
File 'reply.txt.asc' exists. Overwrite? (y/N) y
andrewg at fred:~$ gpg reply.txt.asc
gpg: WARNING: no command supplied.  Trying to guess what you mean ...
gpg: encrypted with 4096-bit RSA key, ID 0x6B09069314549D4B, created
      "Andrew Gallagher "
File 'reply.txt' exists. Overwrite? (y/N)
Enter new filename: foo
gpg: Signature made Mon 14 May 2018 11:57:17 IST
gpg:                using RSA key 291E79A1DC55AE27A52EEF835C1EC404D5906629
gpg: Good signature from "Andrew Gallagher " [ultimate]
gpg:                 aka "Andrew Gallagher " [ultimate]
gpg:                 aka "Andrew Gallagher "
gpg:                 aka "Andrew Gallagher
" [ultimate]
gpg:                 aka "[jpeg image of size 18803]" [ultimate]
gpg:                 aka "Andrew Gallagher "
Primary key fingerprint: 00CC 54C6 A0C6 0169 1AF4  931F FB73 E21A F116 3937
     Subkey fingerprint: 291E 79A1 DC55 AE27 A52E  EF83 5C1E C404 D590 6629
gpg: WARNING: message was not integrity protected
So far so good - gnupg correctly throws a warning. But:
andrewg at fred:~$ cat reply.txt.asc | mailx andrewg at andrewg.com -s "test
Now in Enigmail, I get a decrypted message with a green bar and no
warnings whatsoever:
Enigmail Security Info
Decrypted message
Good signature from Andrew Gallagher Key ID: 0xF1163937 / Signed on: 14/05/18, 11:57
Key fingerprint: 00CC 54C6 A0C6 0169 1AF4 931F FB73 E21A F116 3937
Used Algorithms: RSA and SHA512
Note: The message is encrypted for the following User ID's / Keys:
  0x6B09069314549D4B (Andrew Gallagher )
So it would appear that Enigmail IS VULNERABLE.
I have reproduced this on debian's 2:1.9.9-1~deb9u1 (v1.9.9) and 2.0.3
on Mac. By comparison, the default cipher (AES) correctly throws a
decryption error in enigmail using the same test systems.

@_date: 2018-05-14 12:20:00
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
Argh, I meant to say 3DES of course, not MD5. Sorry.

@_date: 2018-05-14 12:36:59
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
I wouldn't be that confident. I haven't tested PGP/MIME yet simply
because it's harder to construct the test message. The important point
is that we can't rely on gnupg's message integrity check to prevent
automatic decryption - so there's no good reason to believe that PGP
mail is any less vulnerable than S/MIME.
Note to anyone coming fresh to the conversation: disabling the display
of HTML email is *probably* a sufficient mitigation in either case.

@_date: 2018-05-14 12:49:57
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
So perhaps the solution is to throw a big warning and prompt when an
integrity check failure is thrown by gnupg? That would mitigate the
current issue, but allow for reading pre-MDC emails as per Werner's
earlier link.
The problem here is that an integrity failure is a serious error when it
occurs in a context where oracle behaviour is possible (such as email),
but it's much less serious when used outside that context. Just because
gnupg says it's only a warning-level offence doesn't mean enigmail
should agree...

@_date: 2018-05-14 14:44:31
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
This all exposes one of the difficulties with trying to manage security
software in a decentralised ecosystem. We end up in arguments over whose
responsibility it is when the joints come apart.
I would humbly suggest that we stop worrying about which side of the
GPG/MUA fence the ball is on, and fix it on *both* sides. That means:
1. change the default behaviour of GPG so that any integrity failure is
fatal by default, even for old ciphersuites (we could have a flag to
override for those that really need it). For belt and braces, disable
the obsolete ciphersuites by default (again, we can provide an
override). We have assumed that so long as you don't *generate* poor
crypto you're safe. That's just not true.
2. AND the MUAs need to make sure they fail hard on integrity warnings,
because old versions of GPG may hang around for a while. Also ensure
that links aren't followed by default, that the capabilities of
encrypted HTML mail are constrained, etc.
The PGP ecosystem will survive this, because the tech is in place. The
enforcement has just erred a little too far on the side of
compatibility. It's all fixable.

@_date: 2018-05-14 21:09:45
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
I?m sure it?s feasible, but it doesn?t address this issue or any other kind of oracle, replay or chosen-text attack. If today has taught us anything, surely it is that flaws in decryption are just as dangerous as flaws in encryption.

@_date: 2018-05-14 21:43:56
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
Indeed. This is why data must be treated as a living object. If tape drive technology moves on, the data must be moved on. Same with file formats, encryption systems and dying raid arrays. Librarians and archaeologists understand the process of care and feeding for physical artefacts. Digital artefacts are no exception. Yes, absolutely. I think this is the easiest and most effective technical mitigation available. If people have a problem with data archival, they should be pointed to a guide on how to re-encrypt their sensitive data in a modern format. Their data is probably horrendously insecure anyway, so we?re doing them a favour. :-)
If we believe that there will be more encrypted messages in the future than there have been in the past, then protecting those future messages takes priority, especially if an upgrade pathway exists. As an aside, I think we have to be careful about the meaning of ?use?. They are not used by default in encryption, but they are in decryption. I?ve had multiple conversations today over this ambiguity. Yes, nevertheless I don?t think it is good practice to rely on one single layer for security protection, because then we have a single point of failure. With two interacting systems, neither should assume that the other is behaving correctly. Trust but verify, belt and braces, measure twice cut once.
That means security policy should be enforced by both applications, so that a single failure doesn?t blow open the entire system. This is especially important when there are potentially unlimited kinds of systems, of varying compliance, that could be involved in any interaction. I think also that we should be mindful that ?be strict about what you send but liberal about what you receive? is great advice for interoperability, but absolutely disastrous advice for security. Another thing we need to learn from this is that HTML elements may be a privacy concern in plaintext mail, but they are a *security* concern in encrypted mail. The context changes the risk profile. So mail clients (tbird) that disable risky HTML (such as loading images) by default but provide user overrides are doing so justifiably from a privacy standpoint, where a warning about the privacy implications may be sufficient. But encryption has to change this risk analysis - in an encrypted mail there can?t be an easy override because the stakes are much higher and people are easily tempted. When we have a system like tbird+enigmail+gpg where there are *three* interacting components, this coordination becomes really difficult. At the very least, enigmail must be able to enforce a stricter content hygiene policy on encrypted HTML mail than tbird applies to plaintext HTML.
How *feasible* this might be is a question aimed at the enigmail devs in the list. :-)

@_date: 2018-05-14 21:49:32
@_author: Andrew Gallagher 
@_subject: Don't Panic. 
This may not be sufficient. It?s not just automatic decryption but any decryption at all in the client that can trigger a callback. In the PGP case the attack is noisy, so you *may* have a chance to protect yourself before the damage is done if manual decryption is required for each attempt. But that assumes that a human being can reliably distinguish the attempts, which assumes a high level of knowledge of the attack procedure.

@_date: 2018-05-15 09:29:45
@_author: Andrew Gallagher 
@_subject: efail -> improvements (was: Efail or OpenPGP is safer than S/MIME) 
I?m not saying that active elements should be banned outright, just that they should be handled more carefully in the encrypted case than they are in plaintext. So for example, I could change my thunderbird settings to display active content by default, or tbird could let me click on a handy button to load foreign images. This is reasonable UC behaviour if we are only concerned about the privacy implications. But I would argue that it may not be reasonable if we have serious security concerns, so we may want to suppress the handy ?load images? button or have a separate config setting for ?display remote content in encrypted messages by default?. The point being that the context determines the measures that we may want to take.

@_date: 2018-05-15 10:14:20
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
I have just opened tickets in both GnuPG and Enigmail for the respective
integrity check mitigations.
Please let's avoid a finger-pointing contest. Belt and braces. :-)

@_date: 2018-05-15 10:56:49
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
This is a very good point that I think has been overlooked in the chaos.
There are many different things going on here that overlap and interact.
The only emails that are in danger of being leaked *via the MDC issue*
are those that were originally encrypted using one of the obsolete
cipher suites. Anything encrypted with AES should be immune. This is
a) gnupg only falls back to compatibility mode for messages that use
obsolete ciphers, and
b) If you inject an AES cipherstream into a 3DES or CAST5 message (which
is how the CFB gadget trick works), you get garbage.
We should also be very careful to note that none of this discussion
thread applies to the MIME concatenation vulnerability, which is a
problem in Thunderbird and other mail clients, and which cannot be
solved by gnupg.

@_date: 2018-05-15 15:59:32
@_author: Andrew Gallagher 
@_subject: Breaking MIME concatenation 
It struck me at lunch that it might be possible for gnupg itself to
scupper the MIME concatenation (direct exfiltration) technique mentioned
in efail, and thereby plug the leaks in multiple vulnerable clients at
once. This would however require it to be naughty with its output.
MIME concatenation works because in many clients the individual MIME
parts of a message are not kept isolated from each other after they are
passed to the rendering engine. Instead, they are concatenated together
into a single document, perhaps with some separator such as an hline.
This is dangerous because an HTML parser will interpret that document as
a single unit, breaking all sorts of same-origin hygiene.
The primary technique for exfiltration is to wrap the target document in
an active HTML tag such as . But HTML requires the
quoted string to be safe, and there is no way for the efail attack to
perform input sanitation on the target document before the HTML parser
gets its hands on it.
Bear with me, because this is *not* a fully thought-out plan, merely an
idea. ;-)
So gnupg could (under circumstances likely to prevail inside a mail
client) prefix and/or suffix its output with an HTML content-injection
string specially designed to break out of whatever active element the
efail attack might be using. It could be as simple as prefacing the
output document with the perfectly valid HTML tag:
If this were parsed by an HTML display engine in the normal manner, it
would have negligible effect. But enclosed in a tag property, the first
set of quotes+angle would exit the tag safely, and then the would cause an early end to the document, with luck causing a fatal
validation error, or preventing any content that came after it from
being accessible via the DOM.
I see a couple of problems with this. Firstly, it may not be possible to
tailor a single content-injection tool that would be effective against
all attacks and in all HTML engines, although
And secondly, gnupg will probably not be able to tell on its own whether
it has been called from an MUA context. But setting an environment
variable such as GNUPG_HTML_COUNTERMEASURES=true would certainly be
sufficient, providing both users and MUA developers a convenient big red
switch that can just be enabled.

@_date: 2018-05-15 17:37:26
@_author: Andrew Gallagher 
@_subject: Breaking MIME concatenation 
OK, that particular trick won't work. But if content injection is
possible, then counter-injection should also be possible. How about:
We don't need to worry about what comes after the injected tag close
unless DOM scripting is enabled, and if it is enabled, we can abuse it
just as easily as the bad guys can. :-)
Of course that would be the most correct solution. I was trying to see
if I could think up the quickest solution. ;-)

@_date: 2018-05-16 08:08:05
@_author: Andrew Gallagher 
@_subject: Breaking MIME concatenation 
I like this. It handles the various quoting options, and does its best to display the cleartext safely. Tbird correctly disables JS, so we don?t need to worry about that.
Should there be some indication that mischief is afoot? Or is it more important not to unnecessarily frighten the user?

@_date: 2018-05-16 14:55:16
@_author: Andrew Gallagher 
@_subject: AW: AW: Efail or OpenPGP is safer than S/MIME 
Why do we need a plethora of configuration parameters to selectively turn off various parts of a security protocol? Why should we even encourage such a thing? With security, either everything seems to be ok, or it?s broken in such a way that it?s potentially an utter disaster. And quite probably both simultaneously. The only reasonable use case for selective disabling of security protocol features is for backwards compatibility. That doesn?t require fine grained control, just a version number. And even then, it opens up the possibility for user error. I?m going to preemptively quote RJH here before he gets around to it. Use the defaults! ;-)

@_date: 2018-05-17 09:20:51
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
Are we confident so far that this is limited to the expected breaking
cases (pre-MDC ciphers) and not some unexpected side effect?

@_date: 2018-05-17 10:20:30
@_author: Andrew Gallagher 
@_subject: Users GnuPG aims for? (Re: Breaking MIME concatenation) 
I think you're screaming into the wind there... ;-)
More seriously though, properly marked-up text is demonstrably easier to
read. That's why people submit academic papers in Latex instead of
courier monospace with hand-drawn equations. At Patrick's suggestion I
have moved to "Simple HTML" in my tbird, but even that requires
noticeably more effort to scan and parse compared with "Original HTML"
with disabled remote content.
Featurism is absolutely a problem. But not all features are featurism.
Simple markup (like the original markdown, not its increasingly
featureful descendants) does make an important difference.
The real trick is knowing where to draw the line. Turing-completeness in
a document format is a fundamentally bad idea, but things like CSS that
allow for hidden content can be problematic in certain contexts and not
others. Like most things in security, "it depends".
I completely understand where you're coming from, I'm a vim-loving unix
beardie at heart too. But I don't think an insistence on text/plain
asceticism is tenable in 2018. HTML mail is unfortunately going to be
around for a long time. So mail clients (no more or less than web
browsers) have a responsibility to sandbox untrusted content. Plaintext
is a workaround, not a solution.

@_date: 2018-05-17 11:32:10
@_author: Andrew Gallagher 
@_subject: Breaking MIME concatenation 
I know I did suggest this earlier as a thought experiment, but MIME
issues are obviously better implemented in the mail client itself, or in
extremis in the secure mail plugin(s). And since this has already been
implemented in at least one plugin (see Patrick's earlier messages) I
think it's best to leave it on that side of the fence.

@_date: 2018-05-17 12:15:35
@_author: Andrew Gallagher 
@_subject: Efail or OpenPGP is safer than S/MIME 
I agree, while it would be easy for the users to have a magic button in enigmail, this isn?t something we should be encouraging users to use on a regular basis. IMO a better solution would be a standalone tool that you could point at a local Maildir and tell it to clean and re-encrypt anything it finds that is bad (for a given value of ?bad?), and save it to a new Maildir, perhaps with an attachment explaining what was done. This would of course invalidate any signatures on the re-encrypted data, but that?s OK for the use case. It should not be an in-place update, nor should it work over e.g. IMAP because that would a) encourage people to run it in a cronjob and b) destroy the originals, which may be a deal breaker for archival purposes.

@_date: 2018-05-20 10:22:29
@_author: Andrew Gallagher 
@_subject: A postmortem on Efail 
I wouldn?t call myself a cryptography expert, although I do try my best to keep up. I speak as a tinkerer who wants to humanise cryptography, because it?s still too hard for ordinary people to understand, and you shouldn?t need to understand everything about a technology to be able to use it properly, because that defeats the purpose of technology. I find a lot of things about the whole PGP ecosystem interminably frustrating. But the worst thing is the inertia. We know there are things that need done, but getting them done often seems politically impossible. Not to mention the small number of people who are actually getting paid a salary to fix these things. TLS at least gets attention because the Googles, Apples and Facebooks of the internet are beating people over the head saying ?we need to push forward?. TLS breaks backwards compatibility regularly. That?s the price of improved security.
I said earlier that deprecation has to happen, but I?ll reiterate here. If doing the things that we know need to be done requires breaking backwards compatibility, then so be it.

@_date: 2018-05-22 10:55:36
@_author: Andrew Gallagher 
@_subject: =?UTF-8?Q?Re:_AW:_Break_backwards_compatibility_already:_it?= 
I don't think we should be encouraging the automated or transparent use
of legacy crypto upgrades, particularly in an online setting such as a
mail gateway. All this does is launder the obviously-dangerous bad
ciphertext into an apparently-safe new ciphertext.

@_date: 2018-05-22 12:41:01
@_author: Andrew Gallagher 
@_subject: I just got an odd message 
Without seeing the full email, it's hard to tell. They don't appear to
represent any well-known file type when run through a base64 decoder.
Most uses of such constructions are hacks to get emails to display
differently depending on the idiosyncracies of different readers, and I
see plenty of them. But the text-encoded data does look odd.
I grepped the last 500 days of my spam folder and found one instance
from a long time back that closely matches the pattern of yours. It is
missing the leading dashes and whitespace chunking but otherwise looks
almost the same. It includes the domain name "wei wei gift dot com".
I see nothing in my example that screams "efail", but even so I am
reluctant to open it in an HTML renderer to find out. ;-) It may simply
be garbage intended to confound bayesian analysis.

@_date: 2018-09-04 09:11:55
@_author: Andrew Gallagher 
@_subject: First smartcard operation always fails 
Hi, all.
I've had a pgp smartcard v2.1 for years now (two, actually), and I've
noticed that no matter what operation I perform, the first attempt after
inserting the card, or waking from sleep with the card inserted, fails.
andrewg at fred:~$ ssh my.server
sign_and_send_pubkey: signing failed: agent refused operation
andrewg at my.server's password: ^C
andrewg at fred:~$ ssh my.server
Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-92-lowlatency x86_64)
A similar thing happens with signing emails, and my signing and
authentication subkeys are distinct.
This has been bugging me for as long as I can remember, across different
machines, different software versions and OSes (Linux and Mac), and
using both smartcards.
Does anyone have any idea what's going on?

@_date: 2018-09-04 09:17:49
@_author: Andrew Gallagher 
@_subject: First smartcard operation always fails 
And I have just confirmed (by sending that mail) that both the first
auth operation AND the first signing operation fail, separately.

@_date: 2018-09-20 17:53:32
@_author: Andrew Gallagher 
@_subject: First smartcard operation always fails 
On further experimentation, it turns out it only happens with one of my
two cards, but does happen on multiple machines with multiple readers.
The signature counter increases every time. I can reproduce the sig
operation failure consistently, but not the auth operation.
Does this mean the card is unwittingly producing bad output on the first
attempt, and gpg (or scdaemon) is automatically retrying? Could this be
a manufacturing flaw in the card?

@_date: 2019-04-04 16:43:10
@_author: Andrew Gallagher 
@_subject: card-sized 4 Kbit RSA Smartcard recommendation with 3 slots 
On the v2.1 Zeitcontrol cards, 4096 bit RSA takes a couple of seconds
per operation. This is fine if you're just doing bits and pieces, but
when using it heavily, e.g. as an ssh auth method over ansible, it can
get *very* sluggish.

@_date: 2019-08-14 11:09:17
@_author: Andrew Gallagher 
@_subject: Difficulty of fixing reconciliation 
Indeed, but that condition is fundamentally incompatible with
decentralised reconciliation - because deletion without permissions
management is an open door, and permissions have to be enforced by an
There are three signatures. Which one is illegal? You can't base your
decision on the contents of any of the signatures, because they're
third-party and therefore untrustworthy. Timestamps can be backdated,
for example.
There's nothing intrinsically wrong with third-party signatures. The
problem is caused by keyservers allowing a global search on the target
id to include all the third party signatures on it, whether the target
consents or not. Unless you use a maximum trust path length of 1, you
must have some way of searching for intermediates.
A third-party signature is just a statement by someone saying "I know
this person". Sure, that may make you a suspect by association, but so
does mentioning your name in public, or sending you an unsolicited postcard.

@_date: 2019-08-15 07:07:34
@_author: Andrew Gallagher 
@_subject: Key poisoning 
This is known as ?enumerating badness? and it doesn?t scale. You would only be able to identify a bad actor after its actions are noticed - by a human being. Also, if thousands of separate keys have signed another key, making it unusable, how do we decide which of those thousands of keys are legit and which the bad actors? Generating lots of keys on modern hardware is not difficult.

@_date: 2019-08-26 18:37:46
@_author: Andrew Gallagher 
@_subject: Slightly OT - mobile OpenPGP usage 
It?s a nice idea in principle, but it?s a technical violation (sorry, nonstandard extension) of the standard to allow bare private subkeys, so many mobile clients (e.g. ipgmail) don?t support it. I used to do this on my laptops with gnupg (which does support it) but have since migrated to smartcards.
With the advent of NFC and lightning hardware tokens, it will make more sense to use them for all devices, removing the need for nonstandard extensions entirely. There is a non-negligible cost for the hardware, but it is *much* more convenient and secure to plug a card or dongle into a new device than it is to transfer subkey bundles (which are still sensitive data, even without the primary key).

@_date: 2019-08-27 17:07:34
@_author: Andrew Gallagher 
@_subject: Slightly OT - mobile OpenPGP usage 
If you think there's a keylogger on your machine, then don't type in a
password at all, ever. And if there's a keylogger then there's just as
likely to be a screen scraper, or all sorts of other nasty things.

@_date: 2019-08-31 12:44:09
@_author: Andrew Gallagher 
@_subject: Slightly OT - mobile OpenPGP usage 
I recently migrated from squirrelmail to roundcube on my own domain and I would recommend it. Mailvelope will support any roundcube installation if you add the appropriate domain to its whitelist.
I have found though that while Mailvelope works well with manually imported or generated private keys, its integration with gnupg for e.g. smart card support is very sketchy due to lack of gpgme-json packaging in the major distributions. DKG has been trying to push it in debian but afaict there isn?t a package available yet.

@_date: 2019-12-17 15:09:40
@_author: Andrew Gallagher 
@_subject: Usability of OpenSSL vs GNUPG 
One of my frustrations has long been that the design is inverted - the
core utility is the fully-featured CLI (gpg), and the wrapper interface
is the reduced-featureset API (gpgme). This is a reflection of its
history, especially PGP backwards-compatibility, but causes problems
when trying to use it as a component in a larger system. Unfortunately,
refactoring it to be a fully-featured API with a reduced-featureset
and/or backwards-compatible CLI is a project so overwhelming that I'm
sure nobody wants to take it on...

@_date: 2019-12-18 09:20:48
@_author: Andrew Gallagher 
@_subject: Best way to get fingerprint programatically 
Your awk looks awkward to me. What about this instead?

@_date: 2019-12-18 09:56:31
@_author: Andrew Gallagher 
@_subject: Best way to get fingerprint programatically 
Aha, I forgot about handling multiple results. Note that you don't need
head if you're already using awk:

@_date: 2019-02-17 09:26:03
@_author: Andrew Gallagher 
@_subject: Yubikey keytocard: "Bad secret key" 
But you?re trying to load an rsa1024 key onto it. Have you tried loading a 2048 bit key instead?

@_date: 2019-02-18 07:35:27
@_author: Andrew Gallagher 
@_subject: Using Yubikey only to encrypt/sign 
You need to download the public key of the secret keys you are about to use, and then run `gpg --card-status` again. After that it Should Just Work.

@_date: 2019-02-18 20:51:07
@_author: Andrew Gallagher 
@_subject: Using Yubikey only to encrypt/sign 
Would you mind posting the results of `gpg --list-secret-keys`? With the yubikey plugged in. It shouldn?t contain anything too sensitive. You may have the decryption key in the wrong slot.

@_date: 2019-02-26 14:03:21
@_author: Andrew Gallagher 
@_subject: Question about the security of the GnuPG Agent with regard to 
Indeed, but if you use one of the standard web browsers your session
tokens are also stored on disk, by default unencrypted, and in many
cases these are equivalent to passwords (depending on the website).
Password managers address the issue of a network attacker. They don't
directly solve the problem of an attacker who has physical access to
your device. An encrypted drive is a better way to prevent an attacker
getting access to sensitive material on disk (not only passwords).
So while the problem you identify is bad, it's not fatal.

@_date: 2019-07-01 00:53:41
@_author: Andrew Gallagher 
@_subject: Your Thoughts 
Is it worth drawing up a work program for the ecosystem, some sort of priority list of what needs fixed, how urgent each is, and what dependencies there are between different components? For example, say we want to make it possible to work without any IDs. How many things need changed? How urgent is it compared to, say, getting Hagrid up to spec as an sks replacement? Where should we concentrate our efforts?
This list will be long.

@_date: 2019-07-01 13:36:43
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
We start from hagrid or something like it, and carefully add the ability
to sync only the absolute minimum of data required to allow revocations
to propagate. This probably means primary keys, their self-sigs and
revocation sigs.
(*Maybe* subkeys also, but it's probably unnecessary since distributing
new key material is less urgent than revoking existing material.)
We could repurpose the existing SKS recon protocol, but introduce
breaking changes: a) the protocol is versioned so that implementations
can gracefully degrade, and b) only whitelisted packet types are synced.
Sure, but WKD and Autocrypt still don't collectively cover all the edge
cases, so some residual need for a keyserver-like system remains.
iOS's native Mail app cannot be replaced, and all third-party mail apps
must use its API which is less than fully-featured. Constructing a
PGP/MIME message requires access to the MIME headers that the Mail app
does not expose. All PGP apps under iOS must either cut and paste inline
PGP or encapsulate messages as attachments that Mail treats as black
boxes. PGP on iOS is therefore klunky as hell, and it's not going to
improve unless Apple makes a conscious decision to support it.
I am under no illusion that the keyservers are authoritative, don't worry.
A comparison with DNS may be useful. DNS is a distributed cached
database, but there is a distinction between primary, secondary,
recursive etc. Recursive resolvers make the system resilient, but the
primary is consulted regularly and the cache constantly invalidated.
(In DNS of course, the master is also considered authoritative, but this
does not automatically follow in a cryptographically validating system)
The keyservers make no distinction between primary and secondary - all
keyservers are equal, the provenance of data is thrown away, and the
cache can therefore never be invalidated. But provenance matters, and if
synchronising keyservers can't be primaries, something else should be.
That can be WKD, DANE, or just a plain URL on a server that I control.
Keyservers would then be mainly limited to caching information that was
obtained from some master keystore (with the exception of material
strictly required for revocations).
OpenPGP already has the "keyserver" field which is rarely used. It is
supposedly a hint to clients to tell them to prefer a particular
keyserver, but it could also be used as a hint to the keyservers
themselves, to tell them where the master copy of any public key can be
I'd suggest adding a "caching keystore", either after or as a subsection
of "updates-only keystore", with the following properties:
A caching keystore extends the concept of an updates-only keystore, by
supplying user IDs and third-party certifications on the condition that
they were recently available at an original location specified by the
key's owner. This mitigates key-flooding attacks by preventing arbitrary
submissions, and allows for the coordinated deletion of old or
problematic material by removing it from the original location.
* A caching keystore MUST accept submissions of primary keys as well as
cryptographically-valid self-certification and revocation sigs
(including third-party revocations) over those primary keys.
* It MAY synchronise the above key packets from other keystores. It MUST
NOT synchronise, or accept external submission of, any other packets.
* It SHOULD attempt to fetch and temporarily cache user IDs and incoming
third-party certifications over each primary key from the URL contained
in that primary key's "keyserver" field, if defined.
* If more than one "keyserver" definition is found for a given primary
key, then the most recent cryptographically-valid packet MUST take
* It MUST cryptographically verify all fetched material.
* It MUST discard any unexpected fetched packets, even if they are
cryptographically valid. In particular, it must discard any outgoing
third-party certifications *from* the fetched key, in case they flood
some other key.
* It MAY impose further restrictions on cached packets (e.g. it may
choose not to cache image IDs).
* It SHOULD delete cached packets after a reasonable period of time once
they can no longer be retrieved from the "keyserver" URL.

@_date: 2019-07-01 14:29:41
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
Or alternatively, we start with either hockeypuck or SKS (yes, I know) and carefully cripple them. Thinking about this a bit more, and with the DNS comparison in mind, it may be best if caching keyservers and validating keyservers were two entirely different things, to make sure we don?t accidentally open ourselves to a cache poisoning attack.

@_date: 2019-07-01 14:55:10
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
I think it's mostly to do with key size. This works fine either way when
it's among peers, but in large organisations you'll tend to get one key
that certifies a large number of others, while the median number of
certifications made by any of the other keys is zero. Better to
distribute lots of keys each with one signature, than lots of keys with
no signatures and one key with all the signatures.
Also, given that there tend to be a small number of super-certifiers, it
is easier to trace back the possible verification paths given a list of
certifiers on a newly-encountered key. The question is rarely "what is
the list of the keys that I can verify?", and almost always "how can I
verify this particular key?". X509 uses this model also, and for the
same reason.
Yes, which is why we've informally had "let the owner choose whether to
publish her incoming certifications" as best practice for a long time.
Cross-signing would enforce this, but the client-side tooling is lacking.
SKS as we know it must die, but I think that has been obvious for a
while. Its reconciliation algorithm can live on, however. The crypto
verification doesn't need to be performed in the synchroniser. It might
be best if it didn't so that we don't run into potential issues re some
systems being able to verify, a new algorithm and some not. Better to
let the synchroniser just do its job, and move all the verification and
caching stuff to a higher level. It need not be in the same binary.

@_date: 2019-07-01 15:38:22
@_author: Andrew Gallagher 
@_subject: Your Thoughts 
Golang? Not Rust? :-P
I do find it odd how many projects make such a big deal of what language
they're written in. It shouldn't matter what language you use so long as
it works (and is memory safe).
Who wants to copy and paste messages? That's soooo 1995.
You can't script a GUI, but you can GUI a CLI - and there is no shortage
of decent GUI interfaces for GnuPG.
Most of those are separate because of security concerns. Monolithic
systems may look simpler from the outside, but they're often a bucket of
bolts on the inside. Role separation is your friend.
Yes, it is possible to make very short public keys by stripping all
non-mathematical information and using ECC (SSH's ECC keys are similarly
terse). I'm skeptical of the long-term safety of ECC though (the NSA
appears to agree[1]) so while it may be worth using for session keys I'm
not going to trust it with my long-term identity. And the
non-mathematical information has its uses if you're maintaining any sort
of PKI.

@_date: 2019-07-01 16:11:31
@_author: Andrew Gallagher 
@_subject: Your Thoughts 
I think we're criticising the same thing. Yes, I'm calling Golang (and
Rust) "exotic". :-)
Interestingly, Rust was first implemented in OCaml... (!)

@_date: 2019-07-01 16:44:41
@_author: Andrew Gallagher 
@_subject: Your Thoughts 
That seems excessively baroque. What's your threat model? Is it really
so dire that Tails isn't sufficiently sandboxed for you?
I agree that's the way user interfaces should be, but now I'm unclear
what your complaint about GnuPG is, given that it's a CLI tool
optionally wrapped in a GUI interface.

@_date: 2019-07-02 10:44:12
@_author: Andrew Gallagher 
@_subject: Some thoughts on the future of OpenPGP and GnuPG 
The main problem with OpenPGP isn't that its guts are old and slightly
klunky. Many other things that the internet relies on are old and
slightly klunky, but they still do the job. Where it does fall down
often is in ease of use, both for end users and developers. And this is
where most mature software projects end up putting most of their time,
because "fit for use" is an order of magnitude more difficult than "fit
for purpose". [1]
The problem is that a) there's no revenue model for email security, so
the big companies are reluctant to work on it for profit, and b) it's
not sexy, so the talented youngsters aren't willing to work on it for
fun. That will be true of any replacement, which is why despite people
suggesting a modern replacement for over a decade, nobody has actually
made one. And while starting from scratch may look tempting because it
gets rid of all the technical debt, it also gets rid of all the
technical assets.
Yes, there are sexy new things like Signal, but they got to where they
are by doing one (relatively straightforward) thing and doing it well.
OpenPGP is a generalist tool, which explains both why it has ended up
quietly embedded in so many other things, and why it is so difficult to
upgrade or replace.
And this is the crux of the problem. If the big mail providers took
email security seriously, we would never have got here in the first
place. But the nature of email is that nobody owns it, therefore it is
nobody's job to fix it. And the people who care have real jobs and

@_date: 2019-07-02 14:02:55
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
It is convenient, but if it is covenient for you to attach one signature
to the keys of your developers and redistribute, then it is convenient
for an arbitrary person to attach a million sigs and gum up the system.
I think this is one case where convenience will have to be sacrificed no
matter what solution we adopt.
This could be a use case for the "preferred keyserver" extension. If you
ran your own keyserver and your developers set it as their preferred
keyserver, then they would be publicly stating "Allow Gentoo to attach
signatures without my explicit permisson, but distrust everyone else".
This would only have to be done once in advance, and it could be made
part of your new developer onboarding process.

@_date: 2019-07-02 15:27:37
@_author: Andrew Gallagher 
@_subject: Some thoughts on the future of OpenPGP and GnuPG 
Facebook are a *serious* user of OpenPGP. Every email they send me is
encrypted to my PGP key. In this respect they are decades ahead of 99.9%
of the other big IT companies.

@_date: 2019-07-03 09:17:51
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
OK, but what's the failure mode? If it's graceful, then we haven't lost
much. So long as key updates fall back to a keyserver somewhere it
should be transparent.
This does of course need thorough testing, as not all clients will have
the same failure modes.
Yes, from my reading this is expected behaviour. It would be relatively
straightforward to create a server-side alias for the HKP URL, depending
on what else is deployed at that location.
I didn't even know it supported finger URLs - handy to know! Opening a
finger port may be a step too far for the security-conscious though...

@_date: 2019-07-03 14:20:25
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
Any of those attack vectors applicable to keyservers attempting to
refresh from it?

@_date: 2019-07-03 14:33:46
@_author: Andrew Gallagher 
@_subject: No subject 
If your communication pathway is untrustworthy, it is more effective to
use multiple independent lines of communication than multiple messages
over the same channel. This is still not foolproof, but it significantly
increases the difficulties faced by an attacker. That said, if you've
already leaked your secrets over the insecure channel it may be too late
for you.
This is not quite true - if I am the recipient of a message, I must
explicitly assign "signing trust" to all the links in the signature
chain, in addition to assigning "identity verification" to the root of
that chain. I can also assign "marginal trust" so that more than one
verification pathway is required, to protect against duplicitous
But you're right, these subtleties are why WoT never took off. :-)

@_date: 2019-07-03 15:18:50
@_author: Andrew Gallagher 
@_subject: SKS and GnuPG related issues and possible workarounds 
Would you mind waiting for the replacement system to be fully tested and
migrated before setting fire to the old one?
There's a scene in the classic comedy Father Ted, where a visitor to the
parochial house starts complaining about the build quality of the
bookshelves, and to prove his point he pulls them to pieces. "Look at
that, it's falling apart!" [1]
Just because something is broken does not mean you are obliged to kick
it over to prove the point.
[1]

@_date: 2019-07-03 15:31:23
@_author: Andrew Gallagher 
@_subject: SKS and GnuPG related issues and possible workarounds 
It's the protocol that's broken, not the software. Migrating from SKS to
hockeypuck doesn't (in itself) fix the problems.

@_date: 2019-07-03 15:50:31
@_author: Andrew Gallagher 
@_subject: SKS and GnuPG related issues and possible workarounds 
Sure, but it doesn't help server operators until after those changes are
made. And because hockeypuck is currently ineligible to be a member of
any of the pools, operators migrating en masse to it will hasten the
pools' death. If you don't have one of the poisoned keys in your
keyring, there's nothing wrong with continuing to use the keyservers
(for now), so we shouldn't kill a service that's working just fine for
those people, not until we have a replacement.

@_date: 2019-07-03 16:17:31
@_author: Andrew Gallagher 
@_subject: SKS and GnuPG related issues and possible workarounds 
There are several interlocking issues here. Firstly, gnupg locks up when
importing outsized keys. There are things that can be done at the import
stage, and this is what you mention above, but all of them just move
around the consequences of abuse. That's because of the second issue,
which is that the keyservers are abusable. You can fix this by making
keyservers verify the identity of the uploader (as hagrid and keybase
do), but this then makes the SKS reconciliation protocol unviable - so
it is SKS the protocol that has to be changed, not SKS the software.

@_date: 2019-07-03 16:20:37
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
As in DoS amplification? I create a load of keys with a victim's URL in
the `keyserver` field and the pool does my dirty work? Interesting, but
so long as the keyservers' spiders are well behaved, it should be no
worse than being indexed by Google.

@_date: 2019-07-04 08:19:10
@_author: Andrew Gallagher 
@_subject: SKS Keyserver Network Under Attack 
Exactly. This is why I believe we need to separate the functions of ?master? keystores (such as hagrid, keybase, WKD) from ?caching? keystores such as SKS. The master (but not authoritative) keystores would provide IDs and third party sigs, at the cost of having to perform verification (email in the case of email IDs and domain in the case of server IDs). The caching keystores would synchronise, but only the primary keys. They would then spider the master keystores for the rest of the key info. There is no reason for the master keystores to publicly certify keys - their verification process is an antispam measure, not an attestation of identity. But we can?t do away with verifying entirely, because there is no other known way to prevent flooding.

@_date: 2019-07-04 09:37:56
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
Nice. I can't see corporate firewall admins buying it though. :-)

@_date: 2019-07-10 11:59:05
@_author: Andrew Gallagher 
@_subject: WKD: mutt integration status 
Well now, this email was interesting.
I can view it normally on my iphone, but in thunderbird+enigmail it
comes up as an empty message. It could be that this is one of the Efail
mitigations gone rogue, but there is another possibility.
Most email clients use MIME boundaries such as:
but Werner's email client uses a hot word dictionary, seemingly to mess
with the NSA's bulk monitoring. For example, in this particular mail it
In this instance, I wonder if the apostrophe hasn't screwed something up
- are apostrophes valid in the MIME boundary charset?

@_date: 2019-07-17 07:52:35
@_author: Andrew Gallagher 
@_subject: Essay on PGP as it is used today 
Indeed. Backwards compatibility with the 1990s is an albatross. Anyone still using obsolete ciphers is screwed anyway, so why encourage it?
Some nitpicking:
* Modern PGP does encrypt subjects (although not other metadata).
* Magic wormhole is an excellent toy, but it?s written in python, so literally the *first person* I tested it with got his dependency stack shredded. I think he?s forgiven me but he hasn?t used it since. The line about rewriting wormhole in a decent language may look throwaway but it?s not.
* Similarly, the alternative archiving software suggested is still a work in progress. It?s all very well criticising PGP for being a clumsy jack of all trades, but ?modern crypto? has had twenty years to replace it and still hasn?t fully succeeded. This isn?t just on PGP. * And finally: ?don?t encrypt email?? Yes, well. Email is not going away. Just like passwords, its death has been long anticipated, yet never arrives. So what do we do in the meantime?
But yes.

@_date: 2019-07-18 18:35:52
@_author: Andrew Gallagher 
@_subject: [Sks-devel] Fwd [from schleuder dev team]: Signature-flooded 
We can kill two birds with one stone here, using two simple extensions-by-convention of the protocol. A key owner can (preferably automatically) create a ?self-identity? on her primary key consisting of a well-known string that contains no personal information. To avoid breaking legacy search-by-id systems this string should be unique to the primary key. I suggest using ?fpr:00000000000000000000000000000000000?, where the zeros are replaced by the fingerprint of the key. The self-identity (and any revocations on it) can then be safely distributed by keystores that would otherwise refuse to distribute personal info. A recipient can then infer from revocation of the self-identity that the primary key itself has been revoked (and by extension all associated identities, whether published or not).

@_date: 2019-07-24 17:54:04
@_author: Andrew Gallagher 
@_subject: new to GPG: "gpg: Fatal: zlib inflate problem: invalid code 
Presuming that F742DB29 really is your key, then the message has been
correctly encrypted to you. I've sent a few test messages to adele, but
she doesn't seem to like the public key that I've sent her... :-/
It is possible that the message has been mangled in transit, or in the
process of copying and pasting it into a file. Did you cut and paste
from the raw email source, or from the formatted mail? Could it be that
there are invalid characters in the pasted ciphertext?
I'll send you a test message off-list. Let me know here if you get it,
and if you can decrypt it. Feel free to include it in any replies so
that we can see what format it gets to you in.

@_date: 2019-07-30 19:28:52
@_author: Andrew Gallagher 
@_subject: Enigmail 
That is simply not true. I used enigmail with multiple keys for years without any issues. If you?re having issues configuring it, perhaps ask on the enigmail list.

@_date: 2019-07-31 14:18:19
@_author: Andrew Gallagher 
@_subject: Enigmail 
Enigmail will default to the first set of keys in your keyring that
matches the selection criteria. Do you have more than one ID on each
key? Do you have more than one key for each ID? This could be causing
some confusion.

@_date: 2019-07-31 15:05:07
@_author: Andrew Gallagher 
@_subject: --lsign --add-me or the invisible WoT 
The keyservers (SKS at least) blacklist lsign packets already, so you're
not gaining anything here.

@_date: 2019-07-31 15:52:52
@_author: Andrew Gallagher 
@_subject: Forbes article: The Encryption Debate Is Over - Dead At The Hands 
Facebook are being expected to act as both poacher and gamekeeper
simultaneously. Cory Doctorow has an interesting viewpoint - we can
either regulate the internet giants and expect them to act as an arm of
the state, or we can break them up and expect them to act on behalf of
the customer. But we can't reasonably expect both.
There's a balance to be had between the needs of personal privacy and
public security, and the best way to ensure it's done honestly is for
different agents to take different sides and have it out in public. It's
conflicts of interest and the inevitable closed-door decision making
where the problems really start.

@_date: 2019-06-14 11:04:16
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
I think it's interesting, but it has a few shortcomings. For a start, it
only supports email userids - so it is incompatible with monkeysphere.
It's also a centralised resource, meaning it's not resilient enough for
distributing revocations, which is the main use case for SKS these days
(there are already several alternative systems for discovery).
So it's not an SKS-killer (yet).

@_date: 2019-06-16 13:49:30
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
I would recommend that if you want to go down the road of selectively allowing some third party sigs, that the only honest and transparent way is to allow the leaf certs to determine which sigs are allowed on themselves, via cross signing. If a CA wants to make this process cleaner for the end user, it can be done through tooling.

@_date: 2019-06-16 14:00:10
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
I will when I get back to a desktop, thanks. My first thought would be to use domain verification, as in ACME. No point reinventing the wheel.
I?m well aware of the limitations of SKS. I spammed the SKS list last year re modifying the reconciliation algorithm to prevent transmission of problematic key packets (tl;dr: it?s harder than it looks). My main concern has always been how to reliably distribute revocations; this is a Very Hard problem that other PKIs have also struggled with, and the ?optimum? solution is heavily dependent on your threat model. But even so, SKS worked really well up until relatively recently.

@_date: 2019-06-21 15:26:17
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
If hagrid supported an SKS-like reconciliation protocol, would that
mitigate your concerns?

@_date: 2019-06-30 00:33:22
@_author: Andrew Gallagher 
@_subject: New keyserver at keys.openpgp.org - what's your take? 
Indeed, c) was exactly the killer use case I had in mind.
On the other hand, b) is also quite useful in the short to medium term, until all mail providers decide to support WKD etc. And considering that some companies still don?t fully support PGP/MIME after nearly twenty years of being the preferred standard (I?m looking at you, Apple), ?short to medium? effectively means ?indefinitely?.
So maybe we shouldn?t think of keyservers as storage repositories, but rather as search engines. The keyservers should not be authoritative, but they should be a best effort directory of where the authoritative locations are, combined with a cache of the non-identity cryptographic material in case the authoritative locations get DOSed.
If the authoritative location is not on a keyserver, then we do not need to sync arbitrary data between keyservers, just a list of location hints. The keyservers would then fetch from the authoritative locations and decide for themselves how much of the content to cache.

@_date: 2019-06-30 09:34:52
@_author: Andrew Gallagher 
@_subject: SKS Keyserver Network Under Attack 
Thankfully there is a practical - if drastic - solution for all OpenPGP users everywhere. Point pool.sks-keyservers.net (and its various aliases) somewhere else. The question is where to and how soon.

@_date: 2019-06-30 09:50:18
@_author: Andrew Gallagher 
@_subject: SKS Keyserver Network Under Attack 
Yes, this is the ?how soon?. We are *nowhere near* prepared enough to take that step now. But a solution exists (at least in principle) that does not require end users to take any action. The big obstacles are:
1. scalability. A non-distributed key service could potentially collapse if global hkp(s) traffic was redirected to it. 2. reliability. There would need to be enough failover capacity in the new system to withstand individual server failure. 3. interoperability. The replacement service would need to be fully compatible with all existing clients. DKG?s internet draft shows how hard this will be to ensure in practice without simply replicating the problems of the existing network. We?ve known this day was coming for some time. We?ve just got a fire lit under our collective backsides.

@_date: 2019-06-30 11:03:06
@_author: Andrew Gallagher 
@_subject: SKS Keyserver Network Under Attack 
Because a) it?s enumerating badness [1] but more importantly b) it?s punishing the victim. Protecting the ecosystem by banning RJH and DKG?s keys from the keyservers entirely is doing the bad guys? work for them.
[1]

@_date: 2019-06-30 11:04:23
@_author: Andrew Gallagher 
@_subject: SKS Keyserver Network Under Attack 
Unfortunately even if that patch were merged it doesn?t solve the issue, which is compatibility with the existing client base.

@_date: 2019-06-30 15:00:21
@_author: Andrew Gallagher 
@_subject: SKS Keyserver Network Under Attack 
It prevents escalation, yes. But at the expense of exiling the targeted
people from the network - which may well be the attacker's real intent.
Any "solution" that turns a general problem into a problem for a small
number of *specific individuals* is not a solution, it's a lynching. I'm
sure those specific individuals will be thankful that they've been
thrown under the bus for the greater good. I'm sure nobody else will be
looking over their shoulder wondering whether they'll be next.
We solve this issue for *everyone*, or we all go home.

@_date: 2019-06-30 16:55:53
@_author: Andrew Gallagher 
@_subject: SKS Keyserver Network Under Attack 
Hm, that?s not how I read it, although I could be wrong. It is possible to prevent submission of bad keys, but this just leads to new problems:
1. We would have to ensure that all keyservers block the same uploads. One permissive keyserver is a backdoor into the entire system. We can?t block bad keys at reconciliation time for the same reasons that have been hashed to death already. 2. Although it may be possible to block an individual upload of tens of thousands of key packets, it will not in general be possible to prevent an attacker from incrementally increasing the number of packets attached to a key over time. If we impose a reasonable limit on the cumulative number of packets attached to a key, that key may never become undownloadable, but it will at some point become unmodifiable - so we have just transformed one DOS vector into a different one.
A

@_date: 2019-05-15 16:27:59
@_author: Andrew Gallagher 
@_subject: Johnny-You-Are-Fired 
Bluntly, because MUAs are designed to accept arbitrary data from random
strangers on the internet and display it to you without question. They
prioritise Getting It Done over Doing It Right, and it's hard to fight
against a baked-in paradigm.
It's like the old proverb about the tourist asking for directions in
Ireland and being told "If I was you, I wouldn't start from here" :-D

@_date: 2019-05-27 09:05:59
@_author: Andrew Gallagher 
@_subject: I've been hacked and now I only use a key pair on keybase. 
For the last four years or so, I have maintained my PGP primary key on a
Tails[0] thumb drive, and my subkeys on a redundant pair of OpenPGP
smartcards. This gives me:
a) offline storage of my master key
b) secure backup of all key material
c) convenient access using any of my existing machines
I started developing a tool[1] to simplify the management of the offline
primary key on the Tails drive, but development has stalled. If there is
genuine interest out there, I will dedicate some more time to it.
[0] [1]

@_date: 2019-11-03 12:45:37
@_author: Andrew Gallagher 
@_subject: How to decrypt a message while preserving the signature? [ 
Can one of the admins please unsubscribe or mute this recipient? It?s getting silly now. Thanks.
Andrew Gallagher

@_date: 2019-10-09 07:23:59
@_author: Andrew Gallagher 
@_subject: Future OpenPGP Support in Thunderbird 
Agreed. Such functionality is vital for those of us who use smartcards.

@_date: 2020-04-21 15:15:37
@_author: Andrew Gallagher 
@_subject: Making a subkey a standalone Master key 
This is a potentially interesting hack. I don't see any reason in
principle why you can't construct such a key, since the mathematics of
keys and subkeys is identical.
But there is a big wrinkle coming, and that is how such a mangled key
would be understood in practice. If someone were to send you a mail
encrypted to your "real" key, would Protonmail understand that it has
the correct key material available to decrypt it? After all, the "fake"
key that Protonmail knows would have a different (primary) fingerprint
from the one your correspondent used to encrypt. It might be possible
IFF protonmail tests only the fingerprint of the encryption subkey and
ignores that of the primary, but that would be an implementation detail.
If you do get it to work though, I would be very interested in your
method. :-)

@_date: 2020-04-26 14:32:37
@_author: Andrew Gallagher 
@_subject: Passphrase window freezes my DE's panel - is this a bug? 
To find out what process is controlling a window, you could use xwininfo and xprop as described in this SO answer:

@_date: 2020-04-27 07:58:37
@_author: Andrew Gallagher 
@_subject: Passphrase window freezes my DE's panel - is this a bug? 
This is definitely not pinentry then. It?s most likely a unified desktop passphrase manager such as gnome-keyring.

@_date: 2020-08-11 19:32:30
@_author: Andrew Gallagher 
@_subject: In case you use OpenPGP on a smartphone ... 
It matters little whether these statements were made by Snowden. Whether a particular piece of software exists or not, and whether it is owned by the Russians or the Israelis or the Americans, is beside the point. In principle, it can exist and similar pieces of software have existed in the past, so we can safely assume that something like it will always exist in some form or another.
If someone roots your phone, or your laptop, it is Game Over. It does not matter if you are using Signal, or WhatsApp, or PGP. If the Bad Guys have rooted your phone you are helpless against them. The solution is not to let them root your phone in the first place (i.e. update regularly and don?t click on anything unsolicited), and don?t use your phone for anything that would endanger your life if you were rooted.
Andrew Gallagher

@_date: 2020-08-12 10:42:47
@_author: Andrew Gallagher 
@_subject: In case you use OpenPGP on a smartphone ... 
The problem with best practices is that they are context-dependent. Any
FAQ that steps outside the purely technical domain into operational
security will be misleading at best, and outright dangerous at worst. I
am a Tails user, but I only use it for specific things - I don't boot it
up for my everyday work (that would be insane, given my job). But my
threat model is very different to that of others, so I would never
presume to tell them that my best practice should be theirs.
Hardware encryption devices are already plentiful. The problem is that
secure hardware comes at a huge cost in flexibility, meaning that only a
small part of our computing landscape will ever be "secure hardware".
That's why we have Yubikeys, smartcards, HSMs, Nitrokeys, etc. A small,
limited-functionality device is much more likely to be secure because it
is much easier to audit. Anything with the breadth of functionality of a
general-purpose computer will never be fully trustworthy. Your CPU is an
entire GP computer, buried in another computer. Same with your SSD
drive. A USB-C *cable* now has more computing power than the Apollo moon
mission. It's software all the way down.
No, you should not stop using encryption software on online devices.
That would be insane. We should be adding more encryption at multiple
levels, so that compromise of one layer of encryption does not mean a
compromise of the entire system. Defence in depth is the only long-term
sustainable strategy.

@_date: 2020-12-04 19:55:04
@_author: Andrew Gallagher 
@_subject: Add key to card without substituting stubs for actual private key? 
Yes, after you invoke the keytocard command(s) you have a choice to quit or save. If you save, you write the stubs to disk and overwrite the real key material. If you quit without saving, no disk write is performed, but your keys are already on the card so now you have both a card and a disk copy. Andrew.

@_date: 2020-12-10 19:59:46
@_author: Andrew Gallagher 
@_subject: [Keyserver] Hockeypuck 2.1.0 released 
How do you handle the gradual degradation of sync as different operators implement divergent blacklists?

@_date: 2020-12-11 07:52:12
@_author: Andrew Gallagher 
@_subject: [Keyserver] Hockeypuck 2.1.0 released (Andrew Gallagher) 
But the problem with divergence isn?t loss of efficiency - divergent servers don?t gracefully degrade. They work perfectly fine until they hit the polynomial limit, and then they just break. And they break in a way
that requires reloading the entire database from scratch.

@_date: 2020-12-13 21:22:44
@_author: Andrew Gallagher 
@_subject: Best practice to use several smartcards for a single key? 
How are you going to decrypt the old files if your old smartcard is already dead? If you don?t want to lose all access to your encrypted files, you *must* keep a backup of your encryption key material at the very least. There is no recovering from a deleted encryption private key.
I keep my key material on a Tails encrypted partition in a safe place. Alternatively you could keep a paper backup in a safe place. But there?s no getting around having some form of backup. What amounts to a ?safe place? depends on your threat model of course...

@_date: 2020-12-17 09:51:55
@_author: Andrew Gallagher 
@_subject: GPG Encryption on Raspberry Pi 4 using custom e-mail address 
It appears that you don't already have a copy of the public key for david.donnelly at daviddonnelly.com on that machine. Is this expected?
I can't find keys for any of your listed emails on the SKS pool, or on Hagrid (which appears to be down?), or via WKD. If you don't have the key locally either, then gpg won't be able to encrypt.

@_date: 2020-12-20 10:05:25
@_author: Andrew Gallagher 
@_subject: Split private key in order to share among users 
You?re referring to Shamir?s secret sharing scheme, for which several implementations exist. If you are using Linux, it should be as simple as installing the ?ssss? package.

@_date: 2020-12-22 16:55:33
@_author: Andrew Gallagher 
@_subject: How Do I Overwrite Files in GnuPG? 
This is one of gpg?s little UI idiosyncrasies. '?batch', '?yes' etc. must come before actions such as '?encrypt' on the command line.

@_date: 2020-02-27 10:31:35
@_author: Andrew Gallagher 
@_subject: GNUGP new key with old data under an old gnu version - how to fix 
Firstly, are you sure you have both the old and new keys in your private
keyring? If an encryption key expires, it just means that nothing should
be encrypted *to* it any more, but unless you believe that it has been
compromised it is still safe to use to process existing data. So don't
delete it. :-)
If you do have the old key but it isn't decrypting the old data, then it
may be because the old data is using an outdated format. Try passing the
option --ignore-mdc-error and see what happens. Are there any error
messages emitted? Can you export one of the encrypted blobs to local
disk and decrypt it on the command line?
Yes, but I would only recommend this as a last resort. Also note that if
you do this you will lose access to all your *new* data, which may be a
worse outcome for you, depending on your use case.
Yes, but it will depend on you being able to decrypt the old data so we
should fix that problem first...
Maybe, what *exactly* are you doing? Without divulging any secrets. :-)

@_date: 2020-01-07 14:25:22
@_author: Andrew Gallagher 
@_subject: What are some threats against which OpenPGP smartcards are useful? 
This is also a very good argument for smartcards - transferring a
private key between devices is error-prone and potentially catastrophic.
Yes, it can be done securely but for non-experts (and even experts!)
having a physical "key" is much more intuitive. How often have we heard
of people accidentally distributing their private key instead of their
public one? Few of them will have a 128-bit secure passphrase like RJH. :-)

@_date: 2020-01-07 14:39:34
@_author: Andrew Gallagher 
@_subject: Fwd: Re: What are some threats against which OpenPGP smartcards are 
Could one of the admins please twit this subscriber? Their autoreply has
been firing since November.

@_date: 2020-01-08 12:51:58
@_author: Andrew Gallagher 
@_subject: What are some threats against which OpenPGP smartcards are useful? 
That effectively uses the smartcard as a hardware security module, which
does have some advantages. The disadvantages are that if an attacker has
code execution access to your machine they still have full access to use
the key material. However, they cannot exfiltrate that key material, so
any malfeasance must be performed on your machine directly, which makes
it noisy. That may or may not be a deterrent, depending on your threat
model. It is more secure than having your private keys on disk, it just
may not be sufficiently secure.

@_date: 2020-01-08 17:35:20
@_author: Andrew Gallagher 
@_subject: What are some threats against which OpenPGP smartcards are useful? 
On my yubikey at least, the touch contact is only used for the FIDO 2FA
- the PGP smartcard feature is secured by PIN as per any other smartcard.

@_date: 2020-01-08 21:37:28
@_author: Andrew Gallagher 
@_subject: Re-sign subkey binding with changed digest? 
Have you tried changing the subkey expiry? Or does that reuse the same hash?

@_date: 2020-07-08 12:12:18
@_author: Andrew Gallagher 
@_subject: Traveling without a secret key 
Entropy checkers only provide an *estimate* of randomness, at best an upper bound. Once you know that someone has used a particular key expansion algorithm, the entropy estimate can go down dramatically. This is because randomness is a measure of ignorance, and new information changes the calculation (cf the Monty Hall problem).
Andrew Gallagher

@_date: 2020-07-08 20:38:14
@_author: Andrew Gallagher 
@_subject: Traveling without a secret key 
Multiple smart cards. If you quit rather than save after transferring your subkeys to smart card, they remain on disk and you can transfer them again. I recommend keeping a backup of your encryption key at least, on a safe offline medium such as a Tails persistent volume.

@_date: 2020-07-09 18:01:17
@_author: Andrew Gallagher 
@_subject: Traveling without a secret key 
The standard GPG4win package handles smartcards and PINs. I'm not an
Android user though, so can't help you there.

@_date: 2020-03-07 23:40:27
@_author: Andrew Gallagher 
@_subject: Sunset of a smartcard encryption key 
I generate my keys in a copy of Tails and then copy to smartcard without saving changes on disk; that way I have a backup of all key material. I?ve never lost a smartcard but last year I had to factory reset one and restore from the backup when it went a little haywire.
Andrew Gallagher

@_date: 2020-03-10 15:59:02
@_author: Andrew Gallagher 
@_subject: How to use reprepro (or anything really) over ssh? 
Hi, all.
I maintain a private debian repository using reprepro. This requires me
to sign updates using a code-signing key, which I keep on my home
machine. I am not always on my home machine of course, meaning I would
like to ssh into it and run reprepro remotely.
This does not work.
reprepro uses gpgme, so it doesn't support `pinentry-mode loopback` (it
crashes if I try). And since I am normally logged in to my home machine,
there is almost guaranteed to be a display active (localhost:0).
Even if I kill all instances of gpg-agent before running reprepro, the
pinentry comes up on :0. Running `ps ax` shows that the pinentry process
is being invoked using `pinentry --display localhost:10.0`, and yet
PINENTRY STILL COMES UP ON :0 WITHOUT FAIL.
Is pinentry ignoring its command line parameters? And how do I get it to
behave? I can only manage this repository when I'm sitting at my home
computer, which is not acceptable.

@_date: 2020-03-11 10:07:57
@_author: Andrew Gallagher 
@_subject: How to use reprepro (or anything really) over ssh? 
OK, apologies.
*reprepro* doesn't appear to support `pinentry-mode loopback`, for
whatever reason. But this is orthogonal to the substantial point...
I have tried this, and it makes no difference. I have also attempted to
work around the problem by killing gpg-agent entirely. But given that
`pinentry` is being passed the correct `display` option (as evidenced by
`ps ax`), the issue does not appear to be on the agent side.
If I run `pinentry --display $DISPLAY` inside my ssh session, and then
say `GETPIN`, it does not bring up a window. If I do the same in a local
terminal, it brings up the correct window.
The evidence would suggest that pinentry-gnome3 v1.1.0-2 on Debian
blindly uses `:0` no matter what parameters are passed.

@_date: 2020-03-11 10:47:19
@_author: Andrew Gallagher 
@_subject: How to use reprepro (or anything really) over ssh? 
As suggested by the stackoverflow answer here:
I used update-alternatives to change pinentry-gnome3 to pinentry-gtk-2
and sane behaviour is now observed.
The linked ticket in the above answer is still open and has seen no
activity in three years:

@_date: 2020-03-11 14:58:19
@_author: Andrew Gallagher 
@_subject: ed448 support in gpg? 
It depends on how soon you think general-purpose quantum computers will
be available. Elliptic-curve keys are *less* resistant to quantum
algorithms than classically-equivalent RSA, due to their smaller size.
Prioritising speculative future strength (on the order of decades) above
real-world usefulness in the present strikes me as a courageous
decision. :-)

@_date: 2020-03-20 11:35:34
@_author: Andrew Gallagher 
@_subject: keys.openpgp.org not working on CentOS 7 
Hi, all.
CentOS 7* uses gnupg v2.022, and it appears to be unusable with Hagrid.
Does anyone know what's going on here?
[andrewg at delphi ~]$ gpg --search-keys andrewg at andrewg.com
gpg: searching for "andrewg at andrewg.com" from hkp server keys.openpgp.org
gpg: key "andrewg at andrewg.com" not found on keyserver
[andrewg at delphi ~]$ gpg --recv-keys 00CC54C6A0C601691AF4931FFB73E21AF1163937
gpg: requesting key F1163937 from hkp server keys.openpgp.org
gpgkeys: key 00CC54C6A0C601691AF4931FFB73E21AF1163937 can't be retrieved
gpg: no valid OpenPGP data found.
gpg: Total number processed: 0
[andrewg at delphi ~]$ gpg --version
gpg (GnuPG) 2.0.22
libgcrypt 1.5.3
Copyright (C) 2013 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Home: ~/.gnupg
Supported algorithms:
Pubkey: RSA, ?, ?, ELG, DSA
Cipher: IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH,
        CAMELLIA128, CAMELLIA192, CAMELLIA256
Hash: MD5, SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224
Compression: Uncompressed, ZIP, ZLIB, BZIP2
(*) Yes, I have to use CentOS 7. Customer requirement. :-(

@_date: 2020-03-21 16:24:11
@_author: Andrew Gallagher 
@_subject: keys.openpgp.org not working on CentOS 7 
I discovered your blog on the subject[1] earlier and it helped me over
that particular hump, thank you! :-)
In order to get the distro monkeysphere to work, I also had to edit its
default PATH, force-migrate its core keyring, and hot-patch one of its
library routines to ignore subkey fingerprints. It will break on the
next upgrade, but it's CentOS 7 so it will never be upgraded.
I'm learning to live with a very low bar of "acceptability"...
Thanks again!

@_date: 2020-03-21 23:30:09
@_author: Andrew Gallagher 
@_subject: WKS server problems 
Hi, all.
I'm trying to follow the WKS instructions from the wiki[1] on a remote
VM, but it hangs at the key generation stage:
key-submission at keys1:~$ gpg --passphrase '' --batch --quick-gen-key
gpg: signal Interrupt caught ... exiting
There are no rogue pinentry processes in the `ps` list. I've tried
pinentry loopback just in case, but to no avail.
Any idea what's going on?
gpg (GnuPG) 2.2.4
[1]

@_date: 2020-03-21 23:39:19
@_author: Andrew Gallagher 
@_subject: monkeysign removal from bullseye 
It would appear that the python2/3 migration dumpster fire has claimed
yet another good package[1]:
i'm sorry to say there has been no progress and must now admit this is
the only short term solution.
I cannot stress enough how awesome monkeysign is. I have a pet project
that is only reasonably possible because of its existence, and which I
will have to abandon if monkeysign becomes unmaintained.
How much work would be involved in getting it back into production? I'm
not a python programmer (the python2/3 migration catastrophe has put me
off ever wasting my brain cells on it) but I might be willing to suffer
it for this one project.
[1]

@_date: 2020-03-22 12:36:42
@_author: Andrew Gallagher 
@_subject: WKS server problems 
Argh, thank you. I thought I had enough entropy because monkeysphere
created its trust root without issue, but installing haveged did fix the
Rule of thumb, don't debug systems at 11pm...

@_date: 2020-03-22 12:58:39
@_author: Andrew Gallagher 
@_subject: WKS server problems 
I'm using vanilla ubuntu 18.04, but I'm having no problems otherwise
with the distro gnupg's wkd/wks support:
key-submission at keys1:~$ gpg --with-wkd-hash -K "$SUBMISSION_ADDRESS"
sec   rsa3072 2020-03-22 [SC] [expires: 2022-03-22]
      ABAAE8DD259B21B4B7C65EFC40DB83CEBF81AB3A
uid           [ultimate] key-submission@
              54f6ry7x1qqtpor16txw5gdmdbbh6a73@
ssb   rsa3072 2020-03-22 [E]
key-submission at keys1:~$ gpg-wks-server --version
gpg-wks-server (GnuPG) 2.2.4
Copyright (C) 2017 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
I will be upgrading to 20.04 ASAP, however.
Yes, that's probably the issue. As mentioned in my reply to John,
haveged cleaned up the problem.
Thanks, and sorry for the silly questions.

@_date: 2020-03-22 16:42:42
@_author: Andrew Gallagher 
@_subject: monkeysign removal from bullseye 
Not really. Monkeysign is a caff replacement, not the other way around.
And monkeysign's GUI, monkeyscan, is the real killer app. I know of
nothing comparable.

@_date: 2020-03-22 18:01:09
@_author: Andrew Gallagher 
@_subject: monkeysign removal from bullseye 
Hi, Antoine.
I'm sorry to hear about the lack of support for your project. It had so
many maintainers! I personally only became aware of this when all of my
open tickets against monkeysign were forcibly closed.
GNOME keysign looks similar, but AFAICT it requires a "keysign server"
on the (mutual?) local network. That seems to be an extreme restriction,
and makes it totally useless to me (and I suspect most other people
too). It also doesn't see any of my private keys, which is a pretty big
I'm not a python programmer and my skills here are probably nowhere near
what is required. I certainly wouldn't be comfortable taking the lead on
any large porting project, but I would be willing to help out wherever I
can. If however you think helping to improve an alternative project is a
better use of time and effort, I'll defer to your wisdom.
I feel your pain. I've been trying for the past few years to knock
together a menu-driven offline-key management interface[1] for PGP CAs,
for use in corporate environments. I therefore wanted to make the entire
process (for both users and admins) as painless as possible. Monkeysign
became a key part of that once I discovered that writing my own flaky
wrappers around the gpg command line was duplicating your work. :-) And
there is approximately zero chance that I would have developed the
camera/qrcode interface myself.
If bringing monkeysign back from the dead is too much to ask, then maybe
I can work around it using caff - although I will lose much
functionality in doing so. GNOME keysign looks to have too many
restrictions to be usable (I want to run it on Tails, how on earth does
that work?). Any suggestions for workable alternatives will be
gratefully received.
Sorry again,
[1] If anyone is interested you can find the barely-functional carcass
of the project at  . Beware that
it is embarrassingly amateur, with no test suite, a shamefully
monolithic structure and lots of exposed wires.

@_date: 2020-03-22 18:01:18
@_author: Andrew Gallagher 
@_subject: monkeysign removal from bullseye 
I'm actually using Tails, and Tails is a fast-moving target. No, I'm not
going to install a VM on my Tails persistent partition.
Come back to me when there is a fully scriptable interface to gpg.
Monkeysign abstracted away a *LOT* of that pain.

@_date: 2020-03-23 09:47:32
@_author: Andrew Gallagher 
@_subject: monkeysign removal from bullseye 
This will be very useful in the future, thanks. The --quick-* options
are a great help. Unfortunately I'm trying to maintain a package that's
compatible with stable .deb distros so I can't rely upon new features
until the distros bump...

@_date: 2020-03-23 16:21:20
@_author: Andrew Gallagher 
@_subject: WKS server problems 
Yes, that's FAR too old. :-) You need to dist-upgrade to buster.

@_date: 2020-03-23 17:42:22
@_author: Andrew Gallagher 
@_subject: WKS server problems 
Try it anyway, debian often backport newer features if they have
security implications (dkg should be able to tell you definitively).

@_date: 2020-05-14 23:51:14
@_author: Andrew Gallagher 
@_subject: Comparison of RSA vs elliptical keys 
So your device is compromised by the feds and you?re worried about your gpg keyring leaking contact information, but not your inbox or your address book? And how does your encryption system work if it doesn?t maintain a mapping between email IDs and keys? I?m not convinced this threat model has been fully thought through.

@_date: 2020-05-15 14:02:34
@_author: Andrew Gallagher 
@_subject: keys require a user-id 
I think we are conflating two related but distinct ideas here.
There are use cases where you might want to transfer only the
modifications to a key, without necessarily distributing the entire key.
Publicly revoking a primary key without disclosing its user IDs, for
example. But this is distinct from being able to create a new key with
no user IDs at all, which I see no reasonable use for - if your user ID
is sensitive, then use an alias. Even in the use case described above
the keys have aliases.

@_date: 2020-05-15 14:21:51
@_author: Andrew Gallagher 
@_subject: keys require a user-id 
Ownertrust is per-key, but validity is per-UID. On my local machine `gpg
--list-keys wiktor at metacode.biz` shows:
pub   rsa4096/0x6C8857E0D8E8F074 2017-01-01 [C] [expires: 2021-01-01]
      Key fingerprint = 6539 09A2 F0E3 7C10 6F5F  AF54 6C88 57E0 D8E8 F074
uid                   [ unknown] Wiktor Kwapisiewicz uid                   [ unknown] [unknown attribute of size 83]
sub   rsa4096/0xB97A1EE09DB417EC 2017-10-18 [S] [expires: 2021-01-01]
sub   rsa2048/0x60D2F50529E2DE4F 2018-07-06 [E] [expires: 2021-01-01]
sub   rsa2048/0x97FDEF34DAB8F82B 2018-07-06 [S] [expires: 2021-01-01]
sub   rsa2048/0x3B6DFCC964CFEBC4 2018-07-06 [A] [expires: 2021-01-01]
Each of those `[ unknown]`s represents the validity of that particular
UID only. I could right now add a new UID  to
my primary key. The invalidity of  would not
invalidate .

@_date: 2020-05-15 15:43:37
@_author: Andrew Gallagher 
@_subject: keys require a user-id 
The inputs to the WoT are the signatures and the ownertrust values, and
the outputs are UID validities. "Key validity" is neither an input nor a
meaningful output of the system. It is useful only as an intermediate
step, together with the ownertrust, in the calculation of another UID's
validity. The practical outworking of any validity calculation is not
"Is this key valid?" but "Is this key valid for this UID?".
Also, the following is incorrect:
It takes one fully trusted certifier (*), or three marginally trusted
certifiers (*) on the *same UID*, for a UID to be considered valid.
Three different UIDs of the same key signed by marginal certifiers do
not increase the validity of the key, otherwise increasing the number of
UIDs on a key could boost its validity, which is perverse. ;-)
(* certification by a key that has at least one valid UID and
(full|marginal) ownertrust)

@_date: 2020-05-18 12:28:27
@_author: Andrew Gallagher 
@_subject: keys require a user-id 
If your threat model includes your endpoint device being compromised and
leaking your contact list, then you should be implementing an extra
layer of protection such as Tails and/or a hidden VeraCrypt volume. In
the vast majority of scenarios, endpoint compromise is Game Over, and
tinkering with obfuscation will not help you.

@_date: 2020-05-20 08:27:49
@_author: Andrew Gallagher 
@_subject: keys require a user-id 
This must be a Kleopatra limitation. I have successfully created IDs consisting of a single word using the gpg command line. Such a limitation would be user-hostile, as there are people in some cultures who have only one name, the Indonesian dictator Suharto being one famous example.

@_date: 2020-05-20 10:55:51
@_author: Andrew Gallagher 
@_subject: keys require a user-id 
While I agree that revocation is a Very Hard Problem, I'm not convinced
that its abandonment is warranted. Letsencrypt have sidestepped the
issue by issuing short-expiration certs and requiring users to
continually refresh. This is practical for servers under X509 (where
automation is easy and the trust model is centralised) but not for
hyper-distributed PGP. So while revocation cannot be entirely relied
upon, it's still better than nothing and I think we should continue to
support it as best we can.

@_date: 2020-05-20 19:52:56
@_author: Andrew Gallagher 
@_subject: "just invent something..." 
?Demand? is a strong word that I don?t believe is justified here, and only serves to inflame the debate. Most implementations of email require that you enter a ?real name? of some kind. OpenPGP/GPG strongly encourage you to use the same real name on your key as you use on your email profile - this is for the benefit of your correspondents, since using different IDs will likely cause confusion. You are free to ignore this recommendation but I don?t think the documentation should encourage novices to do so.

@_date: 2020-05-21 15:32:16
@_author: Andrew Gallagher 
@_subject: "just invent something..." 
I think you're getting overly hung up on the web of trust. The contents
of the User ID are independent of the WoT - they exist to tell your
email program which keys belong to which correspondents. You can use a
WoT with keys that have no email addresses in them, so long as the
verification chain is cryptographically valid and you have the
appropriate settings in your trustdb. Your WoT could be made up of
Donald Duck, Mickey Mouse and Goofy - the only time the UID's contents
become important (as opposed to its certifications) is when you want to
send an email to president at whitehouse.gov you should have a valid key
that has "president at whitehouse.gov" in either its User ID or local alias
(as RJH pointed out above).

@_date: 2020-11-02 12:06:15
@_author: Andrew Gallagher 
@_subject: ping - Governikus 
This may be an acceptable edge case for one Stefan Claas, but maybe not
for Stefan M?ller or Stefan Schmidt. Or even the other Stefan Claas, who
may not appreciate you being able to more easily impersonate him. :-)
If Governikus (or anyone else for that matter) were to start certifying
ambiguous identities, it would devalue their name across the board. Why
would they do that?

@_date: 2020-11-03 00:06:38
@_author: Andrew Gallagher 
@_subject: ping - Governikus 
Aha, so what you?re looking for is a signature over a nonced, hashed ID but without the plaintext ID being attached - in which case do you even need the plaintext ?real name? at all? After all, if there are only two Stefan Claases in Germany you?ve already leaked far too much information for the subterfuge to be worth the effort. What?s the use case?

@_date: 2020-11-04 10:32:01
@_author: Andrew Gallagher 
@_subject: GPG agent forward on Debian: setting pinentry mode 'loopback' 
Hi, Oz.
Does /run/user/1000/gnupg/S.gpg-agent.extra exist on your local machine?
To make it exist I had to add `extra-socket` to my gpg-agent.conf (I'm
on gpg 2.2.12 from vanilla debian):
$ cat ~/.gnupg/gpg-agent.conf
extra-socket /run/user/1000/gnupg/S.gpg-agent.extra

@_date: 2020-11-04 11:38:46
@_author: Andrew Gallagher 
@_subject: ping - Governikus 
OK, but what is the meaning of a certification in this context? Taking
just the email section of the above, if I want to send you an email, I
can either get the key from you by some private means, or I can look up
your key on e.g. a keyserver and check whether somebody I trust (e.g.
Governikus) has certified that your key is valid for your email address.
AIUI, you propose that Governikus certify that your key is valid for
someone called "Stefan Claas", that they know which one, but they won't
disclose that identity to me. How does that help me decide whether your
key is valid? If I have to perform a second (manual?) verification step
no matter what Governikus says, then it's a better use of my time to try
that method first, and Governikus's sig has added nothing of value.
The same argument can be repeated for the other communications methods
above. If third-party certifications are not sufficient in your security
model, then what's the point of them at all? Considering that the only
reason we use third-party sigs is to cover the cases where other,
stronger, verification schemes (physical meeting, phone calls etc.) are
inappropriate or inconvenient.

@_date: 2020-11-04 16:29:33
@_author: Andrew Gallagher 
@_subject: ping - Governikus 
You could sign it if you want, that's not the issue. The issue is what
value a third party would place on such a signature.
It does not need to bear an email address, no. But it should bear a
unique identifier of some kind. That could be a URL, or a Twitter
handle, or anything sufficiently distinctive for the purposes for which
a third party would expect to use the key.
But Facebook, Twitter etc. verify your yubikey themselves. They are not
relying upon a strange yubikey with a certification from a third party
saying "this yubikey belongs to one Stefan Claas".
Again, your credit card is certified by your bank because your bank owns
your physical credit card. They *made* your credit card. When you use
chip and pin in some shop, the card machine in the shop talks
(indirectly) to your bank, which certifies its own property. This is not
comparable to a third-party signature.
The key phrase I keep repeating in all these arguments is "third party".
For secure communication between two individuals who already have an
established relationship, there is no need for third-party
certification. I still don't see an actual use case for this.

@_date: 2020-11-22 16:06:41
@_author: Andrew Gallagher 
@_subject: Thunderbird / Enigmail / Autocrypt 
Not just yours, but unfortunately for many people it is a risk that they must absorb, because e.g. their job may depend upon it. It is not always feasible to scold your correspondents about their use of HTML mail, just as it is not always feasible to complain about their use of Microsoft Word. People need tools that work in the real world; not everyone can afford the luxury of righteous evangelism.

@_date: 2020-10-08 16:53:35
@_author: Andrew Gallagher 
@_subject: Five volunteers needed (EU .... Are you sure that this is really 
There isn't much consumer demand for it (most people don't even know
what IPv6 is), so ISPs aren't going to spend time on it unless there's
something in it for them. Eventually yes, they'll have to move to IPv6
because the world will run out of IPv4 addresses, but while that event
is looming on the horizon there's no due date for it. Also, IPv6 is only
critical if you don't already own a huge block of IPv4 (which most
established ISPs do). And since they'll have to support IPv4
indefinitely so as not to cut off access to the millions of websites
that will never migrate to IPv6, they've probably calculated that NAT4
is sufficient.
My ISP does offer IPv6 though - just not on all of its network segments.

@_date: 2020-10-23 13:23:07
@_author: Andrew Gallagher 
@_subject: Preserving public keyserver network (Re: Which keyserver) 
I've thought about this quite a bit after my previous attempts to
reconcile recon with selective retention. I believe the solution is to
segregate the "recon" part of the process from the "retention" part.
Our current recon model requires that all packets that exist in the
keyserver network be reconned via the same method. This causes problems
when trying to apply retention policies to certain packets and not
others. For example, we almost always want revocation packets to recon,
almost *never* want user-attribute packets, and other packets such as
user-id fall somewhere in between.
If we segregate the recon and retention components, we can recon an
agreed bare minimum of packet types, without needing to apply per-key
filters and thereby avoiding any split-brain or sync-storm failures.
This minimal list of packet types would have to include primary keys and
revocation keys, but little (perhaps nothing?) else.
Along with these packets each keyserver would gossip a list of
associated hints from other keyservers. These hints would declare that
an "authoritative keyserver" exists that is serving the full key,
presumably having performed validation. The full set of packets would
not be advertised for recon, but would be available through hkp(s) as
normal (for the purposes of this section, the existence of an entry in
WKD would count as an "authoritative keyserver"). Other keyservers would
gossip that they have recently been able to download the full key from
one or more authoritative locations. Such hints would not be
cryptographically part of the key in question, so they should have an
expiration date in order to prevent stale info accumulating in the network.
A keyserver that is not willing to retain the full set of packets for a
given key could instead choose to serve them via a caching proxy or an
HTTP redirect to a server that is willing. This would allow for the full
public key to be discovered and refreshed by the usual methods, but
without every keyserver in the network having to retain its own copy.
It would still be advisable for a user to upload their full key to more
than one validating keyserver, in order to guard against service
outages, but even in the case where the only copy of the full key
becomes unavailable indefinitely, primary and revocation packets
associated with it would continue to recon. This model also has the
advantage of significantly reducing the number of packets in the recon
Some other initial ideas:
* The new pool would have to be completely separate from the old pool,
because the deltas would be astronomical.
* Existing validating keyservers could cheaply "join the new pool" by
setting up a separate reconning keyserver in the pool that a) advertises
the appropriate hints on behalf of the validating keyserver and b)
submits any newly-synced packets into the validating keyserver.
* Hints could take the form of fake preferred-keyserver subpackets, in a
similar manner to fake "fpr:DEADBEEF" user-id packets that have been
previously discussed to support UID-less key refresh on legacy systems
(could both be combined in a single fake BIND sig?). These would be
amenable to recon, and naturally come with a timestamp that could be
used to expire them from the cache. Cryptographic non-verification
should ensure that real preferred-keyserver subpackets would override
such hints in client applications.

@_date: 2020-10-23 14:05:26
@_author: Andrew Gallagher 
@_subject: Preserving public keyserver network (Re: Which keyserver) 
After a little further thought, such a combined-bind is wrongheaded. The
entire point of fake userids is that userids are (potentially) personal
data and therefore can't sync. ;-) So we'd have to bind the fake
preferred-keyserver subpacket separately.

@_date: 2020-10-24 12:04:06
@_author: Andrew Gallagher 
@_subject: Preserving public keyserver network (Re: Which keyserver) 
Most SKS operators are (were?) based outside the US. This is primarily a technical challenge, not a political one.

@_date: 2020-10-31 22:27:30
@_author: Andrew Gallagher 
@_subject: ping - Governikus 
============================== START ==============================
What is governikus certifying if there?s nothing identifiable in the user id? What use is it to a third party to see such a signature on a key?

@_date: 2020-09-19 20:38:22
@_author: Andrew Gallagher 
@_subject: Which keyserver 
This is beside the point. SKS is both a protocol and an implementation. Hockeypuck is a reimplementation of the same protocol and is so is vulnerable to the same poisoning issues. The problem with the SKS *protocol* is very hard to fix, because designing a universal, publicly writable datastore means solving a trilemma: censorship resistance, vandalism resistance, and decentralisation. SKS prioritises censorship resistance and decentralisation, and so is vulnerable to vandalism. Hagrid ?solves? the vandalism problem by abandoning decentralisation. WKD steps outside the problem space by abandoning universality. All these are valid alternatives, but none can be called a ?replacement?.

@_date: 2020-09-19 21:58:51
@_author: Andrew Gallagher 
@_subject: Which keyserver 
If you have not yet read the mega threads from a year or two back over on the sks mailing list discussing how filtering is incompatible with open synchronisation, I suggest you do so before opining further. I really don?t have the energy to explain it again! ;-) tl;dr: if you don?t have either a central authority or an agreed, future-proof zkp system of verification (itself a Very Hard Problem) then your decentralised network goes split brain at the slightest provocation. I?d also suggest reading DKG?s proposals for what *is* technically possible, as they are pretty comprehensive: Finally, I would suggest continuing any technical discussions on sks-devel rather than here as we are veering off topic.
