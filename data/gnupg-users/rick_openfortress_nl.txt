
@_date: 2016-05-07 12:20:28
@_author: Rick van Rein 
@_subject: Speading up key generation 
Hi Dashamir,
Thanks for pointing to HAVEG(E), it was a new approach to me.
I don't think you meant to suggest this HAVEGE implementation [1] --
which is a PRNG based on the entrope of HAVEG -- but wanted to point out
a HAVEG implementation instead, right?
[1] Then let me be the first ;-)
There is no really solid basis for the entropy measured; it is
suggestively shown (which the authors say in their ACM paper [2]) on
statistical tests which are known to not provide certainty about the
randomness of the sequence.
[2] The guessed  per interrupt is rather high (8-64 kB) but this would
depend heavily on CPU architecture.  This means that there is no
reliable manner of having a portable implementation of HAVEG.
I also have my doubts if they actually collect this much information --
as they are only looking at the CPU counter as a summary of the complex
internal CPU state.  Different states will inevitably merge into similar
measurements, and there's probably a probabilistic distribution for
measurements -- which the statistical tests might even show if they had
been tailored to the chunk size of these measurements, and when the
measurements hadn't been shuffled in a PRNG-ish style.  The paper could
(and therefore should) have taken away this concern, IMHO.
Finally, I'm afraid that this algorithm might have solid fixpoints,
namely when an interrupt flushes all the state of the CPU.
I do like the idea of harvesting CPU-internal data, but do not feel free
of worries about this implementation style.  There should be a more
accurate model of its entropy before I'd trust it.  But once it has
this, the principle might expand to include much more probably switches,
such as through multiple processes or threading.
As far as I'm concerned: (1) because key generation is a rare event and
good entropy is worth waiting for in these special circumstances, and
(2) because this may not work as reliably as possible on a system that
is booting in a reliable manner, especially from a relatively simple CPU
(perhaps MIPS or ARM).
IMHO, this time is much less important than properly generating the keys
that you are (often) going to rely on for years.
If you want a speedup, you might look into key generation/signing
algorithms, such as ECDSA.  They need less randomness and should (in
theory) be faster to generate keys from.
I'm curious if anyone has different opinions on this!
 -Rick

@_date: 2017-08-30 21:06:19
@_author: Rick van Rein 
@_subject: Looking up keys from a massive store 
I am investigating how to use GnuPG in a content_filter.  I found an old
where the linear search through the keyring was mentioned as a scaling
for the number of keys.  That would probably hit us too.  If I've seen it
correctly, the keybox format mentioned there is not part of today's gnupg.
What key search method would you recommend that is scalable to many keys and
to many signatures being placed in parallel?  Or is it perhaps an idea to
create public keyrings just for the purpose of one email being sent?  [No
idea if that is possible at all, let alone how, just thinking out loud.]
FWIW, the intention is to fill the LDAP store with keys that are submitted
over email, and accepted based on DKIM signatures on the email.  Email that
is sent would be automatically encrypted with PGP, and DKIM would sign the
entire message in the mail server.
Rick van Rein
OpenFortres / ARPA2

@_date: 2017-08-31 20:26:52
@_author: Rick van Rein 
@_subject: Looking up keys from a massive store 
Thanks Werner!
Wow :)
Ah, that is a most useful addition :)
I also found the internal API after writing this and found that I can
load the keys, which is yet another way to get it done.  Great!
Thanks.  I am still designing, so things are still fuzzy and looking
where they fit in :)  The above is already quite helpful!
