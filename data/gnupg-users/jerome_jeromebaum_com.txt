
@_date: 2011-04-12 10:03:06
@_author: Jerome Baum 
@_subject: gpg: encryption failed: public key not found 
OT, but you should be logging in as a normal user and using sudo

@_date: 2011-04-12 18:54:09
@_author: Jerome Baum 
@_subject: gpg: encryption failed: public key not found 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Since when was "a little OT" a problem? It's when things get out of hand
and the signal-to-noise ratio gets messed up, that there's a problem.
I won't bother. "logging in as a normal user and using sudo" wasn't
meant in the "sudo is teh rulz" sense. It was meant to stand more
generally for "don't 'casually' run destructive commands (think rm) and
compile third-party software with more privileges than necessary" --
whether you do that by logging in as another user and use sudo, or
whether you implement this differently, doesn't really matter. What
matters is that you lower your privileges to the minimum required and
which can be practically applied.
If you don't want to keep OT, happy to take this off-list and have an
insightful discussion -- assuming it doesn't boil down to
mis-communication per above. :)

@_date: 2011-08-03 12:24:57
@_author: Jerome Baum 
@_subject: Extract numbers from a key 
Note that gpg uses hybrid (session key) encryption. There are various
advantages, e.g. you can reveal the session key to someone else (think
subpoena) without giving up your entire key.

@_date: 2011-08-04 15:05:31
@_author: Jerome Baum 
@_subject: Extract numbers from a key 
What is that supposed to tell you? It's not like Mathematica does an
exhaustive check either.
A healthy dose of paranoia is good though, so maybe you can decrypt
the key (set an empty password or remove the password) before sending
it to pgpdump?

@_date: 2011-08-04 15:32:21
@_author: Jerome Baum 
@_subject: Extract numbers from a key 
So just a sieve? Isn't that going to take ages on any reasonable key?

@_date: 2011-08-04 16:30:26
@_author: Jerome Baum 
@_subject: Extract numbers from a key 
Ah, I see why you referred to it as "the PRIMES algorithm" -- was mislead by
a Google search on that string.
Did you manage to get an unencrypted version of the private key?
Am 04.08.2011 15:54 schrieb "Robert J. Hansen" :

@_date: 2011-08-11 20:05:55
@_author: Jerome Baum 
@_subject: Trust model - trust level 1 and 2 
There isn't really a "standard trust model". What you should really do
is have a key signing policy and embed the URL to that policy with
every signature (plus, obviously, sign the policy). e.g. pipe
 through "gpg --list-packets" and
you'll see that the link to my signing policy is
 and per the footnote there you can
find the signature at .
That said, I believe the standard says something like "0x11 means 'I
didn't really check' " -- read your own thing into that but to me it
means the level is useless. 0x12 is a moderate check and 0x13 an
in-depth check, which everyone interprets differently.

@_date: 2011-08-11 23:33:13
@_author: Jerome Baum 
@_subject: Trust model - trust level 1 and 2 
Yeah, it says "try" -- I see the double-meaning now! -- which is meant
to say "when you check signing policies and ,
try common signature extensions because you never know if something is
signed, even if it doesn't mention it."
I was going to change it (plus remove the image, which I totally
overlooked but is an unsigned external resource), however it's quite
tedious to access my secure key so I'll probably change it when I next
use my secure key for something else. Not like it's a significant
change. I'll probably switch to a plain-text policy while I'm at it,
clear-signed instead of a separate signature.

@_date: 2011-08-11 23:00:49
@_author: Jerome Baum 
@_subject: Secure PIN entry 
I'm on Windows 7 with the latest gpg4win package, have an OpenPGP v2
smart-card and a Reiner-SCT cyberJack secoder.
Can I get the secure PIN entry (using built-in pin-pad) working for
this reader? For my homebanking software (i.e. HBCI card), it works
with CTAPI but now PC/SC. What settings can I fiddle with, and what
log/debug output is relevant?
If this isn't a configuration change, will I have to compile my own
gpg2 (per )?

@_date: 2011-08-11 23:07:21
@_author: Jerome Baum 
@_subject: Trust model - trust level 1 and 2 
Oh, and this also poses the question: Is it better to have two
separate documents, or a single policy with all that information?

@_date: 2011-08-11 23:06:28
@_author: Jerome Baum 
@_subject: Trust model - trust level 1 and 2 
Hmm I guess my policy has a dual-purpose -- key policy (how secure is
it etc.) and signing policy (how well do I check other keys). The
latter needs only a self-signature, the former is another matter. I
don't think someone else can vouch for the facts about how I store my
key, as they have no way to check -- even if I use a smart-card, how
do they know I didn't generate off-card and keep a backup somewhere?

@_date: 2011-08-12 17:30:00
@_author: Jerome Baum 
@_subject: Secure PIN entry 
How much work is it to implement this -- either by using the internal
driver or otherwise maybe using the CTAPI? Is this a very far away
target, or just "there's lots of stuff and little time"?

@_date: 2011-08-12 18:34:10
@_author: Jerome Baum 
@_subject: how can i generate a keypair without reading anwsers from stdin? 
I certainly think the batch solution is more appropriate. The batch
interfaces will be more consistent across different gpg versions,
while the numbers/letters you enter at the prompt can quickly change
if different algorithms are supported in a new version etc.
So stick with the batch and with-colons interfaces whenever you can.
They are also easier to script -- computer-readable and all that.

@_date: 2011-08-26 15:07:49
@_author: Jerome Baum 
@_subject: Which release should we be using? 
Keepass is also (usually) protected. I think you could choose not to
encrypt it but what would be the point?
What do you mean?

@_date: 2011-12-17 03:45:41
@_author: Jerome Baum 
@_subject: keyserver spam 
What problem are we solving? Keyserver spam isn't an issue yet. We don't
know if it will ever be.

@_date: 2011-12-17 14:33:20
@_author: Jerome Baum 
@_subject: keyserver spam 
What about keys without an email in the UID? What prevents me from
signing your key and distributing the signature in some other way?

@_date: 2011-12-17 14:40:41
@_author: Jerome Baum 
@_subject: keyserver spam 
Just like you shouldn't write blatantly inefficient code. But there's
also a point after which we call this premature optimization. Ditto for
putting up security measures for a problem that may well never become one.
I would be very happy to see this become a problem in fact. It would
imply that OpenPGP is popular enough to attract script kiddies & co.

@_date: 2011-12-17 15:07:11
@_author: Jerome Baum 
@_subject: keyserver spam 
Spoofing is prevented through the WoT. It's not the responsibility of
the keyserver.
I'll pose this differently: Why should the keyserver check with you that
you allow the signature to be uploaded? Why would you want to prevent me
from uploading the signature to an e.g. SKS keyserver, but not generally
from distributing it?
(After all, the keyserver is checking with you, you are controlling the
upload, so it must be in your interest. This isn't about the keyserver
being flooded, it's that you don't like me distributing this signature.)
Also note that SKS keyservers (and IIRC all common keyservers besides
the PGP ones?) don't do crypto operations on the OpenPGP packets. They
only handle the format, and only to merge the set of sub-packets. IIRC.

@_date: 2011-12-17 15:08:27
@_author: Jerome Baum 
@_subject: keyserver spam 
Yes this is definitely a subjective matter.
Sure. How many trolls do you see on gnupg-users?

@_date: 2011-12-17 16:25:56
@_author: Jerome Baum 
@_subject: keyserver spam 
I doubt the validity of those automated checks and checks on the email
anyway. What constitutes "owning" foo at example.com? To legitimately
verify this you would need to look at the domain history, conclude who
the legit owner of the domain is, contact that owner and then follow the
delegation chain to reach a real person.
Any technological solution to the problem is easy to compromise:
Accounts can be compromised, domains stolen, DNS isn't safe either and
the mail server could be penetrated. The only way to know if someone
legitimately uses a given email address is to verify the _human_
delegation chain. A computer cannot do that in the current setup.

@_date: 2011-12-17 17:34:23
@_author: Jerome Baum 
@_subject: keyserver spam 
I think the point was that with the current keyserver setup, it wouldn't
die off at all and there is basically no cost to maintaining the noise.
You can easily grow the database to a crazy size and it'll be difficult
to shrink it back down, as the keyservers keep syncing and you have to
coordinate the entire network or the noise will just keep coming back.

@_date: 2011-12-17 17:36:19
@_author: Jerome Baum 
@_subject: keyserver spam 
I just thought about this and while the crypto overhead would always be
there, my thinking is: If we're only adding, wouldn't a signature (e.g.
of a hash of the sub-packet) be okay? This works fine in terms of

@_date: 2011-12-17 17:58:28
@_author: Jerome Baum 
@_subject: keyserver spam 
Okay so we're assuming that "ownership" means being able to read mail
there. Given an attacker that cannot read mail for foo at example.com, if
that attacker uploads a key with UID foo at example.com, what value does
this verification have? If I don't verify the key, and send an encrypted
email to foo at example.com, the attacker presumably cannot read the
message anyway. So then I wouldn't even need to encrypt it. So then the
key is useless for encryption. So is the check also.
For signing, well I don't usually care that "some person who was at a
point or currently is able to receive or intercept emails sent to
foo at example.com signed this message", I usually care that "John Smith
signed it". But let's assume I care whether something really originated
with a person that was or is able to read email to foo at example.com, how
is this more useful than just emailing them to confirm?
i.e. IMO emails on UIDs are bullshit. So are certification policies that
say (or don't say but enforce anyway) that you must have an email on
your UID. Why refuse to certify _less_ information?
Disclaimer: Of course everyone can make their own choices. I am
expressing my viewpoint. My viewpoint may not necessarily be that of the
company or companies I work or have worked or will work for. Trademarks
are those of their respective owners. Copyrights are those of their
respective owners. Database copyrights are those of their respective
owners. Someone's name is also theirs. Blue means blue, red means red.
The law applies. Do not break the law. Do not read this email if it is
not intended for you. If you cannot tell that it is not intended for
you, that's your fault. I reserve the right to sue your ass anyway.
"Apple" and "i" are trademarks of Apple Inc., co., or
something like that. "Orange" is probably a trademark of someone else as
well. "Peach" is probably the trademark of the guys who trademarked
"Orange", or maybe it's Apple's trademark. Who's in for a bet that
"T-", "z", "y" and "x" are also
all trademarked? DO NOT USE THIS DISCLAIMER TO OPERATE NUCLEAR POWER
PLANTS OR WEAP... DEFENSE TECHNOLOGY. OH SHIT I LEFT MY CAPSLOCK ON ...
Do not operate this disclaimer if you are prohibited from doing so.
Operate it only when you are not prohibited from operating it.
Have a great Christmas (if you celebrate it)!

@_date: 2011-12-19 10:31:31
@_author: Jerome Baum 
@_subject: keyserver spam 
My understanding is that name + DoB + place of birth together are
unique. Sometimes. In theory.
But name + email aren't even unique then -- which is why some hosts like
Google now refuse to re-register an expired email address, so that you
can't receive emails for the previous owner. But again, not everyone
does it and policies as well as domain ownership can also change.
Wasn't there a nice paper on that problem (naming) linked to from this
list maybe a month or two ago? Or maybe it was referenced in the STEED
Was definitely an interesting read.

@_date: 2011-12-19 10:36:33
@_author: Jerome Baum 
@_subject: keyserver spam 
Oh but that doesn't mean we should all add our DoB to our UIDs now.
Remember that your DoB is actually secret and only your credit card
company is meant to know it. You know, to verify the person speaking on
the phone is really you...
(Hmm, they also asked for my account number, which I suppose is also
secret and not at all printed on all my invoices. Only a few key people,
like everyone ever involved with a wire between them and me, know the
account number. I suppose this is getting old...)

@_date: 2011-12-27 23:23:50
@_author: Jerome Baum 
@_subject: maximum passphrase for symmetric encryption ? 
I can't tell for gpg specifically but it's not so much about
"characters". It's about entropy. Natural language is redundant, and
diceware uses words from natural language.
Let's say we all adopted the convention to write every character twice,
to recover from errors in transmission. Is ttrraannssmmiissssiioonn any
more secure than transmission, given that an attacker knows you're
doubling every letter? No, because it doesn't have more entropy.
So don't measure characters, your upper bound is entropy, so 20 diceware
words apparently contain 256 bits of entropy (based on your numbers).
That means any more than 20 words isn't going to add for the case of
Like I said, this is not gpg-specific. For all I know, gpg might cut off
after the 64th character and drop entropy from your passphrase. But that
sounds unlikely.
Wikipedia is great for further reading.

@_date: 2011-12-28 03:25:33
@_author: Jerome Baum 
@_subject: --trusted-key 
You can't set ultimate trust on a public key unless you have the
corresponding private key. So this is a way of telling gnupg not to
require that, e.g. if you have the key on another computer and gnupg
can't know that.
For instance, I keep two key: 0x215236DA and 0xC58C753A. But only
0xC58C753A is on my machine, 0x215236DA is stored somewhere safe, so I
don't want it on here. But I still want to ultimately trust 0x215236DA
because, well, it's my key. So my gpg.conf says "trusted-key 215236DA".

@_date: 2011-12-29 04:04:15
@_author: Jerome Baum 
@_subject: --trusted-key 
I created the key on another computer, so the secret key was never on
this machine in the first place.
Yeah, another 8 characters would have made the line wrap around. :)
Yes, just like in my example, you would usually specify the ID of one of
your own keys.
So say I've certified your key with my 215236DA. That key is not on this
machine, but I'd like my gnupg to consider your email signatures valid.
What I'm telling gnupg is that 215236DA is my own key, so any other key
that is certified by 215236DA must be valid (presumably because I
personally checked this before certifying).
trusted-key is really there for the above scenario -- it is my key, but
it isn't on this computer, so gnupg can't know unless I tell it. There's
basically not much more to it.*
* Now, that's a meaningful sentence right there. "Ignoring anything else
there is to it, there's not much more to it."

@_date: 2011-07-13 15:04:37
@_author: Jerome Baum 
@_subject: Why sign as well as encrypt files stored on untrusted drives? 
You've said it yourself. The attack is to encrypt something else to
your public key.

@_date: 2011-07-13 15:10:34
@_author: Jerome Baum 
@_subject: Why sign as well as encrypt files stored on untrusted drives? 
Have you considered a separate key for the signature?

@_date: 2011-07-14 05:58:50
@_author: Jerome Baum 
@_subject: Why sign as well as encrypt files stored on untrusted drives? 
You mentioned not wanting to keep the passphrase in gpg-agent. That
problem might disappear with a separate key.
On the manifest file, if you're hashing the encrypted files then it's
really useless (the attacker can just re-hash and re-encrypt for the
manifest file). However, it can still be useful -- if you sign only
the manifest file, you only have to enter your passphrase once, and
you can still verify a given file.
(Watch out though: You have to make sure all the files are authentic
before you hash them -- e.g. by checking the old hashes -- but what
happens if I replace a file just after you've verified it but before
you're about to re-hash it? Kind of like a bait-and-switch.)

@_date: 2011-07-20 13:39:53
@_author: Jerome Baum 
@_subject: Can version 1.4.11 be configured to use IDEA? 
:compressed packet: algo=1
:onepass_sig packet: keyid 1E3B6A9CD77480F6
    version 3, sigclass 0x00, digest 2, pubkey 1, last=1
:literal data packet:
    mode b (62), created 1311035908, name="gpguser3.txt",
    raw data: 1884 bytes
:signature packet: algo 1, keyid 1E3B6A9CD77480F6
    version 3, created 1311035908, md5len 5, sigclass 0x00
    digest algo 2, begin of digest 1b 52
    data: [1019 bits]
Looks like this is what you get from a simple armor command.

@_date: 2011-07-20 18:48:30
@_author: Jerome Baum 
@_subject: secring and dropbox 
But that's really the point. If you want strong random data, that data
should have high entropy. But that entropy needs to come from
somewhere -- i.e., your system.
What I'd find more interesting is why you (Werner) chose quality level
1. What do these levels do? Is 2 full entropy, and 0 just urandom?

@_date: 2011-07-26 17:57:01
@_author: Jerome Baum 
@_subject: How secure are smartcards? 
Depends where you keep the backup.
(Excuse the top post -- Android)
Am 26.07.2011 16:29 schrieb "Werner Koch" :
On Tue, 26 Jul 2011 14:41, hka at qbs.com.pl said:
Well, you should have a backup of the decryption key.  It is cheaper to
steal that backup than to crack the card.

@_date: 2011-07-29 03:45:17
@_author: Jerome Baum 
@_subject: How secure are smartcards? 
Any data on that?
(and before you say it, I know you said "guess" and my question was
more rhetorical)
Agree that it's nice, but I don't think that was the intention behind
smart cards. The problem with not encrypting the keys is that a
read-out is possible -- if the keys are encrypted, the read-out
becomes a tad more difficult, depending on the length of the PIN.

@_date: 2011-06-02 21:01:42
@_author: Jerome Baum 
@_subject: problem getting gpg to work 
gpg files are usually encrypted, which means you need a key to get at
the contents. If you haven't used gpg or PGP before, then your
correspondent probably didn't encrypt the file to a public key. They
will have used a password. You need to know that password to access
the file.
I suggest you contact the person who sent you this file. They should
be able to help out.

@_date: 2011-06-02 23:16:45
@_author: Jerome Baum 
@_subject: problem with gpg 
Could you provide the script? (Make sure to remove any sensitive
contents -- replace paths, filenames, passwords, and any other private
information with e.g. ***REDACTED***)

@_date: 2011-06-12 20:00:39
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
I agree with your point and hate to be picky, but the output of
Unless, of course, the output is "I will pay John Doe 10 EUR". We can
safely ignore that case.
Doesn't make your point any less valid, but if we're going to discuss
the legal interpretation of your signature on a piece of data, we
might as well do it properly.
Now all gnupg-users have a nice Pentecost!

@_date: 2011-06-13 01:16:30
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
Who makes these considerations?
In any case, what kind of database is this that it's too much of a
hassle to copy over? What size, etc.?

@_date: 2011-06-13 02:07:36
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
I wouldn't draw that conclusion and instead ask for more information.
"lists of software packages" is not the same as "software packages".

@_date: 2011-06-13 02:54:06
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
All makes sense. Just don't get why it's so expensive to download a
small package list?

@_date: 2011-06-13 19:03:15
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
We had a discussion about smart-card signatures here and basically the
issue with passing just a hash is that you can't distinguish data
signatures from certifications/key signatures.
So, you might trust the remote server to give you a correct data hash
(i.e. you'll live with the implications of a manipulated data hash),
but not to give you a key hash. The problem is, you can't distinguish
between these cases.

@_date: 2011-06-13 19:05:27
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
To clarify, you can't tell from the hash, and you can't really add a
packet "I'm signing data here" vs. "I'm signing a key here". At least
that's what I got from the discussion on smart-cards, YMMV when it
comes to a full-blown gnupg install.
Of course, you could solve this problem by signing with a sub-key,
which isn't meant to certify other keys. I do wonder how e.g. PGP
would react on seeing a key certification from a sub-key.

@_date: 2011-06-13 22:19:18
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Yes, and it is trivial to write a fake date next to my signature. That
doesn't mean there are no legal implications. In fact, just as I can
commit fraud (under the right circumstances) by writing that fake date
on a piece of paper, I can commit fraud by using a fake time-stamp in
an OpenPGP signature.
Let's summarize: The signature time has potential legal implications.

@_date: 2011-06-14 00:09:31
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Right. I can also be mistaken when dating my signature. As I said, it
depends on the circumstances. Even if I purposely lie about the date,
if there's no damage it's not fraud. So I agree with your point about
not relying on the signature date, which necessarily includes the date
of a digital signature. That doesn't mean you should entirely ignore
it either -- sounds a bit "black and white", doesn't it? The date is
an indicator, nothing more, but also nothing less.
No-one said you should rely on that. Just as you shouldn't rely solely
on the date next to a signature. Anyone can lie.

@_date: 2011-06-14 02:42:56
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
It does, and the hash it signs is generated from that (key) data
prefixed with a string that differs between certs and data sigs.

@_date: 2011-06-14 13:51:10
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
I think it really boils down to "the details are significant". It's
not really the signature packet that is relevant, but the actual
signature (i.e. number generated using private key). This signature
definitely uses a hash. We know that hash varies between data sigs and
certs. So here's the question:
Does the (mathematical) signature differ between data sigs and certs
in any way besides the varying hash?

@_date: 2011-06-14 14:36:02
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
If only the hash varies, you need the data to be sure that the hash is
for a data sig (based on a previous discussion the hash is prefixed
with the "data vs. cert" code, so you can't partially generate the
hash and then add the code on your local machine).

@_date: 2011-06-14 14:36:59
@_author: Jerome Baum 
@_subject: Generate digest and signature seperately 
(referring to the data that is hashed, and emphasis on prefixed vs. postfixed)

@_date: 2011-06-14 22:19:24
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Not really, without any context. Nobody has to prove anything without
that context.

@_date: 2011-06-15 01:35:45
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Addressing your "?", you might sign a memo regarding a phone call.
Three years later in court, nobody will believe that you can recall
exactly what you and the other party said. However, a written note,
bearing your signature and claimed date, makes your statement that
much more believable. I think we should all remember that proving
something is, like security, not a boolean. Your signature on the memo
isn't very strong as proof. It's also not worthless!
Usually it'll be something like "false accusation", "falsification of
documents", etc. You can't say absolutely (without context) that the
fake proof is "much worse" than a fake timestamp. It really, really
depends on the context. Consider that the fake timestamp could also be
considered falsification of documents. An excellent source is the
German Criminal Code, section 267 ("Forgery"), and English translation
of which can be found at:
By the way, is there some Internet law mailing list around? I'm happy
with the "off-topic but Internet law related" posts but we might as
well cross-post for even more insight.
Why modify the standard? Look at stamper (itconsult.co.uk), which just
adds some text to the signed content about no warranty etc. Should
suffice. Of course, not easy to parse, so obviously limited mostly to
human interpretation.
Yes! Says also German legal code when it comes to electronic
signatures. You're supposed to get timestamps from a third-party, and
regularly renew those timestamps. Not just for key revocation,
consider algorithm "decay" and the implicit invalidity introduced by

@_date: 2011-06-15 01:46:03
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Err, I have to apologize if I misunderstand, not being a native
speaker, but based on  I
understand that you're saying something like this?
"You're ignore the fact that X"
(If you didn't mean to say that, ignore the rest of the email and use
the time to hack on gnupg ;)
That really surprises me because my point really was "X". I was saying
that the context is necessary and that context is a court proceeding
or something "equivalent" (in terms of what's going on, not in terms
of the legally binding nature etc).
We are discussing technological means to prove something formally, but
in court you're usually not proving anything in the logical, formal
sense. You're usually just demonstrating something with sufficient
plausibility. Now, "plausible" is definitely subjective, but to be
subjective there has to be a subject. That subject would be, say, a
All in all the entire discussion -- besides the technical parts about
timestamp notations etc. -- is huge BS unless there's a lawyer in the
audience. This is not to say that BS can't be fun to talk about.
That was my point. I'm definitely not ignoring the context that the
whole signing technology is inside. Of course, if you never meant to
say that and if I just misunderstood, disregard this email. And shame
on you for reading it and not coding!

@_date: 2011-06-15 03:16:16
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Good points (I think "notations are supposed to be standardized" is a
bit strong, but there is use in certain standardized notations so I
agree with your point overall).
So, um, let's just start using a non-standardized notation in the "
namespace and then wait for standardization? We just need to agree on
a name, maybe Werner can confirm we are free to use
"timestamp-only at gnupg.org"? What would the value mean?

@_date: 2011-06-15 12:23:40
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
I was referring to the value of the notation. We can set any value so
maybe use it for different "levels" of timestamping (like
certification levels)? Or just blank/null?

@_date: 2011-06-15 17:26:24
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
How did we miss that?
Am 15.06.2011 17:15 schrieb "Daniel Kahn Gillmor" :
I think it is a mistake to make this particular notation, when signature
type 0x40 already exists:
 I'm happy with the proposal to start using notations more, and creating
a culture of publishing well-defined semantics around them; i just don't
think this particular goal is well-served by notations, since it is
already in the core protocol specification.
       --dkg
Gnupg-users mailing list
Gnupg-users at gnupg.org

@_date: 2011-06-15 21:59:49
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Um, yeah, so you used a blurry specification of the problem that you
could adjust as needed for your arguments -- possibly in contradicting
ways? I wouldn't consider "what is being proven and who has an
interest in proving that -- i.e. who will cooperate" as a "detail",
but as a minimal basis for discussion.

@_date: 2011-06-15 23:51:44
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
See itconsult.co.uk/stamper.htm
If you only care about the week (for instance), then a timestamping
service that publishes signatures on a weekly basis doesn't require a
correct clock. In fact, a realistic question might be "did X happen
before Y", and a simple hash list of signatures, published after each
new signature, would suffice. No need for a clock at all.

@_date: 2011-06-15 23:58:27
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
So, we timestamp stuff for fun? Whether something can be "relied upon"
depends on what you're going to do with the accuracy assumption. I can
timestamp an empty document and -- besides stuff like "the key must
have existed before the timestamp" or "I must have started or
scheduled a task for the time in the timestamp" -- you can trust the
timestamp to be fully correct without consequence. There would be no
point in contesting. There would, of course, be no point for you in
trusting the timestamp, but it wouldn't be a problem either.
The signer doesn't need to do anything until, say, there is a chance
of falsification charges.
"sufficiently"? For whom? Who has this interest and who decides what
is sufficient?

@_date: 2011-06-16 00:02:27
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
My understanding of a notary's job would include "I trust this key to
be valid, in possession only of the person named in the uid, while
that person was in sufficient mental state, not being threatened at
gun-point, ..." -- why should we use a signature type that could be
misinterpreted, when there is a "timestamp" signature type that fits
our needs exactly?

@_date: 2011-06-16 00:08:48
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
So back to timestamp-only at gnupg.org (vs. 0x40 or 0x50), and blatantly
abusing gnupg.org, is other data of relevance? e.g.:
timestamp-resolution at gnupg.org = As for critical or not, I would vote for critical. Let's consider the
average OpenPGP user (*any* implementation, not just gnupg). Will they
care to display notations on data signatures, or will they see "good"
and take that key to be the author's?

@_date: 2011-06-16 01:19:03
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Who says that?
So, is it interpretation-dependent?
Looking at :
1. Referring to 0x50: "It is analogous to a notary seal on the signed
data." -- see my problem with that above.
2. If the issue is "text vs. binary", ? 5.2.1 ("Signature Types")
seems to suggest all signatures besides 0x01 are binary.
3. If the issue is "what do we sign (data vs. another signature)?", I
would say it depends what you're trying to do: Are you asserting that
you saw the signature, or are you asserting that you saw the data?

@_date: 2011-06-16 01:42:52
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
For instance, a document that I don't want to sign, only to timestamp.

@_date: 2011-06-16 01:51:39
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
A bit OT but: I looked at those guys a while ago and I don't think I
quite understand their concept. So, they publish hashes in the
newspaper -- all fine and good, in a sense better than what stamper
does. Problem is, how do I go from that hash to verifying a timestamp
without their cooperation? With stamper I can just archive the
published signatures and be done. With guardtime, as far as I can see
they would have to send over the entire hash tree -- which isn't
published, so I'd have to ask for/subpoena it -- just for a simple

@_date: 2011-06-16 02:11:59
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Actually, no. It's still evidence. It's just not evidence that says
"this document existed on the 10th of July". It's evidence that says
"someone who was at any point in time in possession of this key, and
who has the ability to manipulate the timestamp (or was in possession
at the actual time listed in the signature), is claiming that the
document existed on the 10th of July".
1. X is evidence for: A is true.
2. X is evidence for: Tom claims: A is true.
Notice the indirection.
What tricks would those be? I'd love to see a Bailiff's records
repudiated in court. The point is, just because I can falsify a
timestamp on a physical document, doesn't mean I can falsify every
timestamp that could be used to support a claim. Electronic timestamps
are not physical timestamps, records held by notaries, bailiffs, even
any other witnesses, are definitely more difficult to repudiate than
the date I put down next to my signature.
Oh, and I am pretty sure that a timestamp created in accordance with
federal electronic signature laws would be considered reliable and be
very difficult to dispute.

@_date: 2011-06-16 02:30:37
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Sounds interesting. Assuming the court will understand the second
signature to mean "I confirm that the timestamp of the other party's
signature is correct", then in your scenario A and B are both unable
to repudiate the inner timestamps. Doesn't stop a third party from
disputing the accuracy of the timestamps though, as A and B may have
shared interests in inaccurate timestamps (picture back-dating an
invoice/contract for tax fraud).
Right. The service isn't trusted, the published signatures are (and
only w.r.t. time interval/week and possibly order, depending on

@_date: 2011-06-16 02:37:19
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Yes. I can set up my own timestamping business. That would be quite
cost-ineffective though.

@_date: 2011-06-16 02:41:29
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
So, I'm stating my point? I'm seeing a lot of unqualified statements
(like "it's not evidence"). Yes, you could argue that it should be
read as: "it's not evidence [for fact X]", but being explicit can be a
Good Thing(tm).
Which point? Your point? I was making my own point (per above), not
addressing yours. My point was that I see a lot of talking past each
other and most of that is due to implicit statements. I think if we
all are a bit more explicit (e.g. what is something evidence for? for
whom is something "good enough"? in what context are we proving
something? -- i.e. yes, we *do* need context!) then we'll have a much
more efficient discussion.
Let's summarize:
You: Lawyers are able to repudiate electronic signatures with some magic tricks.
Me: Please, show me those tricks.
You: Go ask a lawyer. I only know lawyers are smart people and it
would be in their interests (really?) to repudiate electronic
*documents*. (emphasis mine, obviously)
Not really. My CPA sends me an electronic invoice that is "in
accordance with signature laws and applicable precedent". In fact, my
ISP does as well, and so does my mobile carrier. Federal electronic
signature laws are pretty simple and easy to understand. There's even
a brochure I think. :)

@_date: 2011-06-16 02:53:34
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Who does?
Yeah, uh, I can probably say "this trial is probably a con", but I
don't think the judge will buy it and acquit me.
Okay, let's take a look at the formal theory behind this:
1. The cryptographic hash function C is "secure" (i.e. not broken at
the moment -- for verification at a later time there's the whole
"resigning" thing that federal electronic signature law requires).
1a. We'll ignore those resigning signature chains for the purposes of
keeping the proof small. It is easy to adapt the scheme to include
resigning chains.
2. The issue of newspaper N for date D (called N(D) ) is "known good"
(through public archives etc.)
I can hash a document M before D and later prove in court that the
document existed before D.
Publish C(M) in N(D)
10 years later in court, show N(D), M and compute C(M). Verify that
C(M) is published in N(D). Mathematically strong proof that it is
computationally infeasible to have published C(M) in N(D) if M didn't
exist before D -- i.e. proof that the document M existed before D.

@_date: 2011-06-16 03:08:52
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
It isn't up to him to provide that evidence. As a civil case, he must
show that it is plausible that the timestamp is wrong, and he must
claim so (obviously). The evidence that his employer shows (signature
w/ timestamp) becomes weak. Again, the circumstances are really,
really important. Your employer won't usually go to court with just
that signature. Most likely, the signature will be a tiny,
insignificant, part of the case. Rightly so, as the timestamp in an
average signature is very weak evidence.
Claim you signed from another computer where you did have access to
the system time and where there was no synchronization, you set a
random time at installation, etc.
If the employer can prove you signed from that computer, and that that
computer's system time was close enough to legal time, then you're
fucked. But then, if you cheat your employer out of their money,
shouldn't you be?
Note that the scenario feels very constructed. Your employer would
likely not go to court with only that signature. They'd have all sorts
of evidence and it wouldn't be a problem if the signature turns out to
be worthless/ignored.

@_date: 2011-06-16 03:12:21
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
No, I don't rely on random people (CPA, ISP) for that. The tax office
accepts these invoices as "in accordance with signature laws [and
obviously applicable precedent]". I would assume that if they had any
chance of disputing the validity, and thereby saving all that tax
money, they would do exactly that.

@_date: 2011-06-16 03:15:15
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Does (b) not interfere? You either understand whether a strategy is
valid or not, or you don't. At the very least, if you have any
confidence in a strategy (that you are at liberty to talk about),
you'd be able to give an overview, right? Otherwise, if you are not
confident in your ability to present the strategy correctly, how can
you be confident in your ability to understand and *evaluate* the
strategy as to its correctness and success likelihood?

@_date: 2011-06-16 03:19:27
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
In fact, how about an analogy?
I have an algebra (in the high school sense) exam tomorrow. I have
prepared myself by developing the strategy: "answer every question
with '2 + 2 = 5'". I am prepared. However, I am badly prepared. If you
don't understand algebra, you can't know that. You can't know whether
I'm "well-prepared" or badly prepared, only that I am prepared in some

@_date: 2011-06-16 03:26:07
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
What jury?
What jury?
Repeating yourself does not make your argument more valid.
What juries?
Look at my signature and pay close attention to the "+49".

@_date: 2011-06-16 03:29:35
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
You'd agree that "ask Professor Lichty" doesn't count as a formal
proof (or even significant evidence), right?

@_date: 2011-06-16 03:34:23
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Do you assume that, say, the judges at the federal constitutional
court are too dumb to get a specialist and inquire as to the status of
cryptographic hash functions etc.?
I could deliver a mathematically valid proof to anyone and they could
ignore it. That is freedom of thought. I can also assume that people
with at least a basic understanding of formal logic, and the ability
to call on any subject field expert as deemed necessary to uncover the
truth, would be able to follow my train of thought. If that train of
thought proves without (significant) doubt that a timestamp must be
valid, and assuming they are impartial, they should consider the
timestamp to be valid.
Juries and judges are not the same, so you can't just apply one to the
other. A jury might not understand, a judge at the BVerfG probably

@_date: 2011-06-16 03:45:45
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
That's okay, it was a fun excursion. I believe the part of the thread
discussing timestamp signatures is still on-going, with interesting

@_date: 2011-06-16 05:23:25
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Fom :
Referring to 0x50: "It is analogous to a notary seal on the signed data."
Yeah and that was my point. The analogy is bad because a notary
doesn't just timestamp. That's not even the main purpose of a notary
(at least here in DE). Having the 0x50 signature on another signature
packet is definitely not helpful -- what part of the signature are you
asserting? The timestamp? There's a timestamp in the 0x50. The
validity signing key? No (per you). The mental state that the signer
was in? No (per you). The data and time? Yes, if we use this for
timestamping. But then, why am I not signing the data and asserting
the timestamp in my 0x50 signature packet?
I would think that, if anything, we could use 0x50 for those resigning
chains (you know, renewing the cryptographic validity of a signature).
But not for timestamping arbitrary data.
Except that, say, 0x00 "certifies that [the document] has not been
modified" as a minimum condition (owner- and authorship would both
imply this). 0x50 is entirely interpretation-dependent: Something that
a notary does, but not really what a notary does (!= timestamping),
rather something that someone does who saw some part of either the
data or the signature, or something else, and is making some kind of
Of course, I can abuse an 0x00 signature for anything I want, but the
standard at least sets a common-sense basis for what an 0x00 sig
means. An 0x50 sig on the other hand seems to have less of that basis.
I say let's put in a request for interpretation for the 0x40, as those
are designated for timestamps. That is, if we choose not to go with a

@_date: 2011-06-16 06:12:20
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Do you not agree that a bad analogy is going to cause confusion? It
already has, and likely will continue to. If the signature is
analogous to a notary signature, then other implementations will
interpret it that way. I won't forget the word notary because it's in
the standard. If it's not applicable, it shouldn't be in there. It's
in there, so there is a gap between the intention and the wording of
the standard w.r.t. 0x50. So, we shouldn't use it a.t.m. as it's
So I'm signing that the signature hasn't been changed, or that I am
the owner or author of the signature? Is that *really* what I mean
with a timestamp signature? Because the standard says that's what 0x00
"usually" means.
Don't interpret that into what I said. You may sign either the data or
the signature, but that should be explicit -- you should be signing
the signature if you saw the signature, and the data if you saw the
data (rather, it is your choice). If we use 0x50 that means it's not
your choice, as you can only sign the signature. So, how do you sign
(i.e. timestamp) data that isn't already signed by someone else?
But you can't sign data.
Exactly my point. If 0x40 is not clear enough (per others), and 0x50
isn't clear enough (per me), and a notation can be used right now with
any requests for clarification/interpretation and can be marked
critical or non-critical and be appropriately handled by existing
implementations, and if we can use it to promote notations in general,
then we should use it.
I think the general consensus seems to be on a notation anyway (as far
as there is concensus), so let's just focus on specifying the notation
more closely. Assuming Werner's confirmation, we are at this state:
1. timestamp-only at gnupg.org. If this notation exists on the signature,
that indicates it is a timestamp signature.
1 a. Should we set this notation critical, non-critical, or user's
choice? We also had the suggestion of doing two signatures, one w/
critical and one w/out. The idea was that the user will be inclined to
look more closely.
2. Suggestion: timestamp-resolution at gnupg.org. Value is number of
seconds of error in both directions.
2 a. Thinking about it, this should be two notations:
timestamp-error at gnupg.org, and timestamp-resolution at gnupg.org (the
difference being: error = clock drift, while resolution = fixed
intervals, e.g. for datestamps resolution would be 86400 and timestamp
would be at 00:00).
2 b. Need a more formal spec on how this works (how is the interval defined).
3. Other stuff?

@_date: 2011-06-16 07:32:34
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
I understood your suggestion as 0x50, not 0x50+n. 0x50+n, where n is
"timestamp-only", seems redundant.
0x50 doesn't give additional capabilities. You can sign a signature
packet with 0x00 as well. 0x50 is more restricted than 0x00, not more
In any case, let's just use a notation and concentrate on that. The
0x50, clarity/confusion, notation, 0x40, etc. discussion is wasteful
and not really fun.
I'm thinking in terms of stamper, which does timestamps at scheduled
intervals (some 10-15 minutes or so).
I rather was asking (anyone listening in) for an opinion. We've
already discussed the trade-offs that you mention. What I'm looking
for is to get this specified a bit more formally and get everyone's
input, instead of just throwing any random solution out there.
My personal vote would be for critical, because while it might hinder
compatibility, there's no chance of a user mistaking the signature for
something it isn't. The two-part signature sounds interesting but I'm
afraid one of the signatures might get lost (leaving the issue of
non-critical notation and misinterpretation) and it generally seems
somewhat overkill.
As for the error/resolution notation, someone else (can't recall who
and the gmail thread is unbearable) mentioned that this would be
relevant, and with the same breath that you could state this in your
signing policy. My thought process is, what if I have two machines,
and one is NTP-synced (or even takes legal time from the broadcast
signal) while the other regularly drifts up to 10 minutes, or runs
timestamping in batches, etc.
Of course, I could set up separate keys. Personally I'd opt for the
notation, as that's also computer-readable (think "Good timestamp from
Alice, between 10:00 and 11:00 on 2011-06-16" or whatever automated
processing people want to cook up -- e.g. keeping signatures valid
under decaying algorithms by resigning/chaining: This could be
verified by some script that you tell when each algorithm was declared
"insufficient"). Basically it allows us to do stuff that a note in my
policy doesn't, and if we think this through, it won't be very
That was the "why have this data?", here's the "how":
Another alternative is timestamp-interval at gnupg.org =  which describes the interval during which the timestamp was
made, accounting for precision and error, and leaving no room for
interpretation of the interval, but making it the signer's duty to
compute this interval. That's also a lot less complex than a
timestamp-precision and timestamp-error, so we're out of "massive
overkill" territory.

@_date: 2011-06-16 18:55:33
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
(In the context below, "we" refers to the people to whom the
respective statement applies.)
What talk of new subpackets and signature classes? Feel free to quote.
As for the misunderstanding of how notations work, what's their
purpose then? Aren't they incorporated into the standard to make it
easier to extend/add features? Is it a "bad thing" to have a
computer-readable notation?
(Of course, I'm assuming that "how notations worked" refers to "what
they are meant for", and not to the technical aspects [notations being
key-value pairs etc]. The latter would be non-sense, as we've not
shown a misunderstanding for how notations technically work.)
Haven't we proposed a specification, asked for input (discuss),
revised it (I've posted at least one update)? Just because you've
withheld your input until now, doesn't meant we haven't discussed
this, and that we aren't still discussing this.
Probably not. Everyone seems to agree that timestamps in a normal
signature are somewhat meaningless and only serve as an indicator. If
you want a reliable timestamp, why not make a timestamp signature?
In fact, even if there was a way to indicate timestamp accuracy for a
standard 0x00 (e.g. appropriately specifying the notation), I have
strong feelings against that. If I do a timestamp signature, I'm aware
that I should worry about my system time being correct. If I do a
plain 0x00 signature, I may well forget, and if my defaults say "this
timestamp is accurate, add the appropriate field/notation", suddenly
I'll be in trouble for falsification, fraud, or something of the kind.
I'm thinking of an average user here, who doesn't have 100% reliable
memory and may forget stuff. I'll simply ignore any argument that
assumes the average user doesn't forget stuff.
Looking at it though, this still doesn't speak against a notation. I
have yet to hear a solid reason for not using a notation (besides "I
like 0x50. It severely limits what you can do with it, but I feel
reuse must be done at all costs. Use 0x50" -- note that I'm not even
bringing up the confusion argument anymore, as that's highly
subjective -- but the inability to sign data is an objective fact).
timestamp-only at gnupg.org would apply only to data signatures. But see below.
We never suggested timestamp-only certifications. How would those make
sense anyway? Are you saying that this key was valixistant at some
point in time? (Sure, there can be a reason, and I'd love to hear it.
The point is, you didn't bring this up before and now you're
complaining we haven't discussed it?)
Which is why I've repeatedly asked for input on the proposed specification.
That's one of the reasons we're preferring the notation. It "just
works". In fact, unlike 0x40/0x50, we can choose how an older
implementation reacts to a notation-marked timestamp-only signature
(by setting critical or not).

@_date: 2011-06-16 19:15:39
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
Really? Maybe *you* just haven't brought up all those issues until
now. Here's what I see:
Me: Guys, we're looking to do X. Do you have any input?
You: Don't do X, do Y. Here's why: A.
Me: A is invalid. We'll still do X.
You: But A!
Me: A is invalid.
You: You still don't understand. B is a good reason not to do X. You
haven't discussed B!
You never brought up "various interactions this [notation] has with
different signature types" until now. You were suggesting to dump the
notation entirely, and use an 0x50 instead. Of course, I can only see
what you've written (and only what I recall), not what you may have
intended to write.
The goal depends on who's looking. My goal is to have a notation that
we can use for simple timestamp-only signatures on data like stamper
does, as easily as possible but still somewhat flexible -- note how
"somewhat" contrasts with "entirely". Your goal may be "to have the
best possible design", but it's not mine. I consider "best possible" a
fallacy, as there are *always* trade-offs.
There will always be gotchas, you will always wish you "would have
done xxxx". Note that I wouldn't. I would simply assume that humans
make errors, and that I am human. I would move on and work on the next
version, instead of complaining that my design wasn't "the best
Given all that, I am very happy that you've uncovered an implicit
assumption I was making: That the timestamp-only at gnupg.org notation
would be defined only on 0x00 (possibly 0x01). We need to either
explicitly add that to the spec, or change the assumption.

@_date: 2011-06-16 19:21:35
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
As the last post I will contribute to this thread (unless we get a
positive response from Werner), here's a summary of where we are:
1. timestamp-only at gnupg.org. If this notation exists on the signature,
that indicates it is a timestamp signature.
1 a. Should we set this notation critical, non-critical, or user's
choice? We also had the suggestion of doing two signatures, one w/
critical and one w/out. The idea was that the user will be inclined to
look more closely.
1 b. On what signature types may this notation be defined? 0x00
definitely, what else?
2. Suggestion: timestamp-resolution at gnupg.org. Value is number of
seconds of error in both directions.
2 a. Thinking about it, this should be two notations:
timestamp-error at gnupg.org, and timestamp-resolution at gnupg.org (the
difference being: error = clock drift, while resolution = fixed
intervals, e.g. for datestamps resolution would be 86400 and timestamp
would be at 00:00).
2 b. Another alternative is timestamp-interval at gnupg.org =  which describes the interval during which the timestamp was
made, accounting for precision and error, and leaving no room for
interpretation of the interval, but making it the signer's duty to
compute this interval.
2 c. Again, where may this be defined? At least all of # 1 b.
3. Other stuff?
Just so that Werner has a summary of what we've discussed, to base a
decision on.

@_date: 2011-06-16 20:27:38
@_author: Jerome Baum 
@_subject: what does a timestamp signature mean? [was: Re: Problem with 
this discussion is much more interesting. Let's keep the arguments
about specification, usefulness, etc. out of this thread!
I would say that it's a matter of interpretation, and often enough the
timestamps in a signature are not correct. However, yes, a lot of
people certainly watch out for correct timestamps. The problem is, if
you have a signature without a signing policy, how do you know if the
timestamp is meaningful?
The law tends to consider two parts:
1. What's noted down (in a document/signature).
2. What you actually meant.
# 1 is unambiguous. # 2 has to be interpreted (in the theoretical
model, # 2 is taken to be what an "average" person --
context-dependent! -- would have meant by noting down the stuff in #
1). So, it could be argued that the average OpenPGP user does not care
for the timestamp, or vice versa. It would depend what the judiciary
considers to be most plausible and likely.
As it's highly subjective, let's end that part right here and just say
"it depends".
Not really. What I want is some way to say "I saw this at-or-before
time X". Rather, for a third-party to say this about my data. Whether
that third-party can be trusted, or how they might publish their
records to make the data -- not the party -- more trustworthy, wasn't
the scope of the discussion. We already came to the conclusion that a
timestamp's authenticity is subjective, and it again depends: Can you
convince the judge?
Does anyone really have an interest in proving (a) (other than to
dispute (b), of course)?
(Don't take this as "you say BS", but rather as "I am honestly curious
to hear about real-world applications".)
e.g. stamper.
That wasn't the goal. You can't embed this into a signature without
real-world context. The reason is simple: Time runs in the real world.
A signature is just bits and bytes, without the "meta-data" of "when
did I create this?"
It's not the goal. Anyway, you'd have a hard time specifying (a)
entirely, as there's the problem of choice: Do I use NYT or bitcoin's
data? As for (b), the idea behind this notation was to enable lots of
smaller services, just like the WoT.
Again, wasn't the goal. As for usefulness of assertion-by-signer, see
above for repudiating that you made/intended to make that assertion.
"[citation needed]" (Just that I have a bit of a dislike against
Wikipedia. Doesn't make your point less valid in any way, I'm just
In the context of law, at least in Germany, it is assumed that there
is a single legal time throughout the whole of Germany. You don't
usually care about absolute time anyway. It's a tool to establish
ordering of events, and interval length between two events (think
deadlines). When it comes to deadlines, usually you're talking on the
order of days, weeks, months, and usually you have to act during
business hours to meet a deadline, so there is a big gap between two
"time units". No need to worry about relativity.
I also doubt that OpenPGP signatures will be relevant in a proceeding
where relativity comes into play. At least in practice.
If you think about a timestamp is for, usually you're not actually
concerned with saying "I did X yesterday". You're usually concerned
with saying "I did X within 2 weeks of your notice", or "I did X
before you did Y". Other options include "I did X before the
cancellation deadline" and "I did X within 2 minutes, so I was acting
promptly and wasn't negligent".

@_date: 2011-06-16 21:08:47
@_author: Jerome Baum 
@_subject: what does a timestamp signature mean? [was: Re: Problem with 
If this is going to be a thread about specification, then as I said I
am keeping out of it until I hear from Werner. I'll address the
non-specification comments though:
... and that is your interpretation.
Most of "us"? You really need some context to have this discussion. I
suggested the context of legal proceedings, you are free to suggest
another real-world context. The assertion then depends on that
context. I would have thought the requirement of context was a point
that's come across by now. Technology is meaningless without context.
Do you realize that I listed several options and they don't all
require the same kind of timestamping?
I want to create a basis for any kind of timestamping service. For
instance, stamper. Or, just me making the assertion that I saw some
data at some point. Those are both pretty well-specified. I already
know what semantics I need from OpenPGP: Some key makes the assertion
that some data was available to the owner of that key at-or-before a
specific point in time.
Oh, and yes, I have looked for timestamping services before engaging
in a discussion about them. Maybe you should look at the existing
options as well?

@_date: 2011-06-16 21:12:54
@_author: Jerome Baum 
@_subject: what does a timestamp signature mean? [was: Re: Problem with 
In fact, I think I'll keep out of the entire thread. I misunderstood
your original email as implying you are open for a purely academic
discussion of timestamp meaning. My bad.

@_date: 2011-06-18 02:52:14
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
In that case you have nothing to fear from your timestamp.
I personally hold the opinion that you should have a good work
relationship with your employer (including your manager), and
therefore when there is really no work to do, using it for learning
new stuff, or yes even for reading /. or TDWTF, shouldn't lead to a
court case. But, of course, you should discuss with your manager when
there is no work to do, and get their permission first. If you go
ahead and make this decision on your own, then yes you are cheating
your employer -- he might have had work for you to do if only you had
told him there's nothing left.

@_date: 2011-06-18 03:00:25
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
Which was my point about adding a resolution/interval. There's a
difference between "2011-06-17 00:00:00" and "2011-06-17/P1D" (both
technically, and in court).
Leaving my hands off the "timestamp-only" part of the thread, does
anyone have objections to "timestamp-interval" in the ISO 8601
interval format? In my head, it would be a non-critical field (as it
doesn't change the meaning of the signature, only the accuracy of the
timestamp field).

@_date: 2011-06-18 10:48:32
@_author: Jerome Baum 
@_subject: Distributed symmetric key management 
Why does asymmetric encryption not make sense? You could picture an
asymmetric key-pair as a single symmetric key. In fact, for all
practical purposes, if you never separate the private and public
components, an asymmetric key-pair *is* a symmetric key. The only
difference is: gpg has built-in functionality to handle asymmetric

@_date: 2011-06-18 14:29:29
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
Right. Which is why I wrote "2011-06-17 00:00:00" -- there are
multiple interpretations of "2011-06-17", and e.g. ISO 8601 takes it
to be the instant at the start of the day. "2011-06-17/P1D" is
unambiguous (especially if we specify "the value is an ISO 8601
Exactly. I see it as two parts:
1. Add a notation for timestamp-interval. This makes the protocol more flexible.
2. Using # 1, we can then change application code to make the
implementation more flexible. e.g.: Add an option to round down to the
start of the day and set timestamp-interval to "/P1D".

@_date: 2011-06-18 18:24:45
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
See  for details
(be sure to look at the other replies as well). I don't have ISO 8601
handy, so I can't speak first hand. However, this example seems very
"The 20th Century
1901-01-01 / P100Y
1901-01-01 T 00:00:00 / 2001-01-01 T 00:00:00"
Yes. I'm purposely leaving out the whole timestamp-only discussion.
Exactly. This would be an implementation choice. I think a good first
start for gnupg would be a parameter to specify a fake timestamp. The
notation is already possible. Then it's easy to write a command-line
wrapper for custom stuff, or even just specify a fixed notation and
fixed fake timestamp ("1970/P68Y" with timestamp 0).
Not sure. Personally I'd use P200Y. Nice "pun" there, btw. :)
Ah, we've been careless. Append a "Z" to your dates and they are UTC
(or append a timezone, if you want that). Those two intervals are
actually ambiguous AFAIK. We could specify either:
1. All times must be UTC ("Z") or have a timezone; or
2. Ambiguous times are interpreted as UTC.

@_date: 2011-06-18 23:50:08
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
Exactly. 5 Euros is still 5 Euros, whether you say "5,00 Euros", "5,--
Euros", "5 Euros, but no cents", "5 Euros exactly", "5 Euros sharp",
or just "5 Euros". Still the same thing.
I was referring to the interval notation.
Except, what is "local time" if you have two people in different
timezones? That's why we'd need either the "all times UTC" rule, or a
forced timezone in the field.
Those have timezones. Your (and my) previous examples didn't.
That isn't what I was referring to. 20110618T000000/P1D is ambiguous:
Is it 20110618T000000+0200/P1D or 20110618T000000+0100/P1D ?

@_date: 2011-06-19 01:34:09
@_author: Jerome Baum 
@_subject: formatting of gpg blocks 
This is needed to make sure OpenPGP (i.e. gnupg) doesn't misinterpret
stuff inside the block. Imagine enclosing some signed data inside a
signed block. How does gnupg tell apart the "END" lines from the
inner/outer blocks?
Shouldn't be a big problem to work with though: Just run the message
through gnupg and it'll remove the extra dashes.
Be careful to distinguish between data signatures (signing a message)
and certifications (signing a key). Are you trying to wrap a data
signature around the key? Unless you have a special use-case, that
probably doesn't make sense. Instead try to use a certification.

@_date: 2011-06-19 20:26:53
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
Why are we even talking about ISO 8601? Because I suggested it as a
format to record the data. Not seconds since epoch, twice; ISO 8601
interval, and be done.
Local display is something entirely different:
1. Protocol on the one hand (needs to be unambiguous); and
2. Local interaction on the other hand (can be local timezone, UTC,
another timezone, who cares?).
The point is, if there's no timezone noted down in the interval, there
is no way to know what the timezone was when the person made the
signature. We're talking about data at rest, that could be interpreted
many years later, and it'll be difficult to "guess" the timezone then.
Plus, it shouldn't be a guess anyway.
Ah, but now we're talking display. I was talking about the content of
the notation. Display can be however an implementation chooses to
display this (raw notation value if I just use current gnupg with
show-notations), but that isn't really a question here. What's more
important is how an implementation constructs the interval, and how
another de-constructs/parses it.
Right. So discussing your actual point (after we've resolved that we
were talking about different things/"past each other"), I would say
local timezone is fine for display. I would say, let the user choose,
give them a configuration option.
Right. Local display vs. recording. I'll just summarize again:
1. Interval is recorded as an ISO 8601 interval, and must be
unambiguous (i.e. contain a proper timezone for each timestamp).
2. OpenPGP's timestamp is not changed (seconds since epoch UTC).
3. Local display, of both the timestamp and interval, is out of the
question for now. However, I would suggest some option to let the user
configure it. It's up to each implementation anyway.
In terms of moving forward, I think the ISO 8601 ambiguity of lower
precision in an interval is something we need to resolve. Since we're
introducing the interval to allow for lower precision (e.g. round to
the start of the day), I think the interval itself should have full
precision. We would interpret any dropped components as zeros/ones
resp. ("01" for months/days, "00" for hours, minutes, seconds,
fractional seconds).
Looking at this practically, say I round down to the start of the day.
Clock drift isn't really an argument for an imprecise interval,
because "2010Z" still means "at or after 2010-01-01T00:00:00Z", but
clock drift could have me signing this on 2009-12-31Z. So in short,
clock drift, the thing that would be the most likely concern, isn't a
problem of precision (clock still resolves down to (nano-)seconds),
but of accuracy. Less precise intervals cannot solve that, bigger
intervals can.
So here's the new suggested spec:
1. timestamp-only at gnupg.org. Let's omit this part for the sake of a
friendly discussion.
2. Suggestion: timestamp-interval at gnupg.org. Value is an ISO 8601 time
interval during which the timestamp was made, leaving no room for
interpretation of the interval, but making it the signer's duty to
compute this interval.
2 a. Non-critical.
2 b. Must have a timezone associated for each timestamp. "Z", "+0100",
etc. As a safe-guard for broken implementations, should we assume an
implied "Z" if there is no timezone?
2 c. Local display/interaction is something the implementations will
sort out. We recommend at least the obvious "canonical" options of
local timezone and UTC display. Practically, after parsing the
interval into two timestamps, handling would be similar to the OpenPGP
timestamp field (except that isn't enriched with the timezone, which
you could use to enhance the output). Often enough, this boils down to
"whatever the locale is configured to do" and that sounds in line with
*NIX philosophy.

@_date: 2011-06-19 20:29:04
@_author: Jerome Baum 
@_subject: Error message when refreshing keys 
Could you post the output of "gpg --export D02B0179 | gpg --list-packets" ?
Very rough first guess: Server.

@_date: 2011-06-19 20:32:58
@_author: Jerome Baum 
@_subject: gpg fails to decrypt files encrypted to the same name as the 
That's actually quite common for software to do. There are a few
notable exceptions (sort(1) comes to mind), but it's not something you
normally have to worry about. People tend to append ".gpg" anyway. :)

@_date: 2011-06-19 20:47:39
@_author: Jerome Baum 
@_subject: formatting of gpg blocks 
This could lead to ambiguities.
OpenPGP standard, RFC 4880, section 6.
As a general recommendation, if the data is in OpenPGP format,
interpret it as such first. Then if there is other OpenPGP data
inside, use the interpreted version. Wrong interpretation ("taking
shortcuts") is what leads to all these XSS and injection
vulnerabilities we hear about every day. If your data is in format A,
use A's interpreter to understand it. If there's B inside ("A(B)"),
then use A's interpreter first, then B's interpreter. Your example is
just the case of A = B = OpenPGP.
Whose key is it? When you make a signature (whether on key or data),
you need to be aware of what that signature says. Is this your key? It
should already be signed by default. Is this another person's key? Why
are you signing it? Have you verified that the key is valid? etc. Read
through  to get a better
understanding -- before you make any certifications.

@_date: 2011-06-19 22:42:18
@_author: Jerome Baum 
@_subject: formatting of gpg blocks 
In that case there should be no need to sign it. If you want, give us
the output of "gpg --list-sigs " and we should be able to tell

@_date: 2011-06-19 22:50:22
@_author: Jerome Baum 
@_subject: Error message when refreshing keys 
Yes, that's the right output. As I get the same issues, apparently gpg
(v1 here) doesn't like non-armored keys via HTTP. RFC 4880 doesn't
discuss the issue, but in any case Jeremy would be well-advised to
upload an armored version of his key. That'll resolve the problem.
Just as a reference, can you try pulling my key (from
 importing it, and then refreshing
it? Does it throw any errors?

@_date: 2011-06-20 05:43:19
@_author: Jerome Baum 
@_subject: Error message when refreshing keys 
Okay, so Jeremy should definitely upload an armored version of the
key. That is the cause of the problem. Whether it is intentional or
not, and whether this applies to other implementations, I cannot say.
But I know for sure that if it should work for gpg, he has to upload
an armored version.

@_date: 2011-06-20 06:07:25
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
Wait. Are you assuming my interval will always be YYYY-MM-DD/P1D etc.?
How about YYYY-MM-DDT12:00/P1D?
See above.
By "not changed" I mean "the interpretation is not changed, the byte
format is not changed, etc." -- if the signer wants to round down,
they may. This is the loss of accuracy described in the
timestamp-interval field. That does not change the precision of the
timestamp field, nor does it change the fact that it is seconds since
epoch ("UTC", but that is per definition of epoch).
You've been arguing that ISO 8601 does not state this implicitly. Or
did I misunderstand what you meant with "2010-01-01 can be any time
during that day"?
Why restrict the intervals that are allowable? Why demand that the
implementations should round down? I can use the intervals to describe
accuracy, not just to hide my time management.
As for P1W, remember that there will be an associated date:
"2011-06-16/P1W" is one week, from Thursday to Wednesday.
No, just a notation. Also, rounding down is something the
implementations can do, if they choose to (e.g. through a user
option). This does not change the encoding.
That note about it being the signer's duty doesn't really need to be
said. The interval computation must obviously be the signer's duty, as
the interval will contain a date. Whether the implementation computes
this, the user sets it in the notation explicitly, the user sets a
huge interval in the configuration, or something else happens, isn't
something we're interested in -- that's the implementation and
interface level.
However, of course we need to consider this in context. I would say an
interval -- as opposed to a duration -- is ideal, as it leaves no room
for interpretation. Think "2011-06-20/P1W" vs. timestamp =
"2011-06-20T12:00:00Z" and duration = "P1W" -- one is ambiguous as to
when the week starts, the other is not (besides the issue of the first
example not having a timezone -- is "2011-06-20Z" valid?).
It would look like whatever is in the packet's timestamp field. This
could be rounded down, left at the original value, etc. The point with
a non-critical notation is that we've had some good arguments against
a critical one. For instance, it'll just break all your signatures for
current implementations.
Another option: "Usually non-critical, but up to the implementation."
This way the user/implementation can choose whether or not the
interval/inaccuracy is important enough to go in as critical, or if
it's just a "helpful note".
Wait, ISO 8601 says that if there's no timezone at all, then it's just
"local time" (i.e. unknown to us). I would have thought "-0000" is
exactly the same as "Z" and "+0000". Are you saying the standard has a
different meaning for "-0000"?
However, good point. Let's say "Must have a timezone...", but leave it
up to the interpretation to inform the user when there is no timezone,
or even reject it entirely. The protocol just has to say what's a
valid value ("Must have a timezone...") and the implementation can
handle "what happens if I get a 'mostly valid' packet?" situations.
Okay, let's suggest those three. It's advisory anyway, which is all we
can demand.
Left intact. I would say we parse it because
"20110620154236Z/P1D2H1M7S" is not too easy on the eyes. :) It's also
the reason why implementations tend to parse the timestamp field and
display it as a date, rather than displaying "1308542795".
However, it is again up to the implementations. All we specify is what
format to use and how to interpret it, input and output interfaces are
implementation-specific and we can only advise as to what we think is
best for the user/what is most "canonical".

@_date: 2011-06-26 15:40:10
@_author: Jerome Baum 
@_subject: Problem with faked-system-time option 
or even prevent anonymity (...)
Since when was it called "GNU Anonymity Guard"? Last time I checked,
it was called "GNU Privacy Guard".

@_date: 2011-06-27 14:48:06
@_author: Jerome Baum 
@_subject: how encrypt data/text stream instead of a file? 
Hey Doc,
That's what this mailing list is for.
Seems like a Perl-related issue to me, not a GnuPG-related issue.
Basically $encrypted_text is not, as you intended, the output from the
gpg -- I think it's the output from print, in this case 1 ("true") for
"yes, we managed to pipe this into gpg".
I suggest consulting with the appropriate Perl mailing list for how to
pipe into a command and get the output. Also consider "--batch" and
related options, see .

@_date: 2011-06-27 15:31:56
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
There are a lot of general purpose time stamping services, such as
 -- though that is the only one I
know of that is OpenPGP-based.
I think the timestamp-only notation has a disputable use-case, but
timestamp-interval doesn't. If this were added to GnuPG I'd definitely
enable it (and probably set the resolution to P1D). The OP gave a very
good use case when he started this thread, and we've seen other cases
where a fake or lower-resolution timestamp would be useful.
While I didn't see/read the ages-old thread that was mentioned before,
you allegedly even agreed to implement something roughly equivalent in
the past.

@_date: 2011-06-28 11:56:25
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
As I said, I didn't read the thread.
How about the use cases I presented? Any problems with those?

@_date: 2011-06-28 15:43:46
@_author: Jerome Baum 
@_subject: timestamp notation @gnupg.org 
Well the notation, as you say, wouldn't need to be coded into gpg --
it already supports notations. This is more about choosing an
arbitrary timestamp.
Why limit the choices to 0 and key creation time? How about just an
option "--set-timestamp=" that sets the timestamp? Is that easy
to do?

@_date: 2011-03-21 05:48:07
@_author: Jerome Baum 
@_subject: Deniability 
Hi all,
I  am looking  into the  "plausible  deniability" issue  again that  was
discussed here in the past. My problem definition:
    Configure gpg  in such a way  that when I  encrypt a file, be  it to
    someone else or  to myself, the recipient(s) can  deny being able to
    decrypt the file in question.  An adversary should also be unable to
    derive information about the  recipient(s) -- including their number
    -- from  the encrypted  message. Assume  I like  encrypt-to-self and
    have it enabled.
The obvious way to start is with throw-keyids. Problems:
1. The number of recipients is revealed.
2. If I encrypt to only myself, this is revealed.
I could generate some bogus  keys and throw out the secrets, effectively
making them "encryption-only" keys. Then  to solve  I just encrypt to
such a  bogus key in  addition to  my actual key.  I could also  set the
encrypt-to option  for several bogus  keys to make the  adversary's life
more difficult in determining the number of recipients.
After seeing a number of encrypted messages, the adversary will know for
how many bogus keys I have  encrypt-to set.  appears again. This could
be solved by randomly picking a  subset of the bogus keys, possibly as a
wrapper around gpg.  So, both problems can be  solved this way, although
it would be annoying  to have to put randomly-pick-some-bogus-keys.sh in
I can imagine  there are going to be  some relatively simple statistical
attacks on  this scheme (by looking  at algorithms and  key-sizes of the
recipients). What  do you  guys think? What  problems and  solutions are

@_date: 2011-03-21 14:48:39
@_author: Jerome Baum 
@_subject: Deniability 
Only one recipient. Remember I use encrypt-to-self.

@_date: 2011-03-21 14:58:02
@_author: Jerome Baum 
@_subject: Deniability 
Deniability is  "nice", but more  generally confusing Mallory is  a Good
Thing(tm) as she'll have more work to do. Providing deniability seems to
imply more work  on the part of  Mallory. Say the point is  not to prove
"Alice sent  Bob a  message", but  instead Mallory wants  to get  at the
plain-text. If she  can't know for sure that Clyde can  decrypt it -- or
any specific person -- then she'll have to steal several keys before she
finds the right one.

@_date: 2011-03-21 16:13:40
@_author: Jerome Baum 
@_subject: Deniability 
When I throw-keyids,  what's actually left over? Would  there be any way
to match the keys from several messages, besides key size and type? Also
if one (size, type) appears in all messages, I'd say the conclusion that
I'm using encrypt-to-self is pretty safe.
Then again, I could  use that to my advantage if I  want to encrypt to a
public key of the same size and type! :)

@_date: 2011-03-21 16:24:11
@_author: Jerome Baum 
@_subject: deniability 
So let's assume I'm not stupid enough to let that adversary know who I'm
sending the message to. Two options:
1. Use a newsgroup as you suggest below.
2. Randomly send  messages that can't be decrypted  to random recipients
   to obscure  matters. The adversary would  have to cope  with the fact
   that I have stuff to hide. :)
Yes, per above.
Why would I do that? That together with [9] that's exactly what gpg does
when using asymmetric ciphers.
Yes, per my original suggestion.
Yes, per above. But good idea to  not use an anonymous group -- this way
I can say I was testing stuff.
I don't  find that so  plausible but  yes, agreed that  I can make  up a
reason. Though  I don't see the  benefit in symmetric  encryption at all
for this.
Yes that, or testing.
I'd say  it's a plausible  reason to say  "I want my privacy".  But yes,
this is a good reason.
Which is what would happen if I used asymmetric ciphers.
Couldn't I also forget who the  key encrypted to?  However I might still
be forced to  surrender the session key, so  maybe encrypt-to-self isn't
such a good default?
For now just an abstract adverse adversary. :)

@_date: 2011-03-21 17:06:07
@_author: Jerome Baum 
@_subject: deniability 
You make  a point,  I should have  been clearer. Randomly  send messages
that can't be decrypted to  random recipients _from a list of recipients
that have agreed to this_ to obscure matters.
It  would be  a lot  of work  to try  decrypting with  each key  but the
recipient could have  a designated "trial" key with  no pass-phrase that
is used to decrypt some kind  of outer layer.  The adversary would still
need to steal that key only  to verify that _with high probability_, the
message was intended for this specific recipient.

@_date: 2011-03-21 17:10:08
@_author: Jerome Baum 
@_subject: deniability 
At this point however, the  scheme gets complicated and impractical. Are
there   any   practical  solutions   that   don't   depend  on   complex
implementation on the receiving end?

@_date: 2011-03-22 14:37:16
@_author: Jerome Baum 
@_subject: Deniability 
Part thought  experiment, part practical  usage. I was thinking  more in
terms of  a German court  asking me to  turn over evidence --  but then,
there still might  be a lead pipe involved outside the  scope of a court
case. I'll keep  it in mind when  it comes to practical usage,  but I do
want to keep up the thought experiment. :)

@_date: 2011-03-22 14:41:54
@_author: Jerome Baum 
@_subject: deniability 
Couldn't I just post to a test  group via tor?  Posting to that board is
like signing a  statement "yes I am guilty" (to some  at least).  As for
tor,  I was  thinking in  terms of  measuring some  kind  of correlation
between messages  appearing on  the board and  my computer  pulling more
power (think increased  CPU, etc.) -- or something like  that -- all not
proof, but given time to collect  the data, you can probably get a "high
chance" reading. So I think there are so many channels where you can get
this information once you have a  suspect, that it isn't worth trying to
hide "it's me who posted this", and instead just post lots of stuff.

@_date: 2011-03-22 14:44:14
@_author: Jerome Baum 
@_subject: Deniability 
Would that be by reusing the  session key? Or are there other properties
that we can mess with?
How about, say  I know the session key and the  public encryption key of
the suspect, can't I just encrypt the session key to that public key and
see if it comes out the same?

@_date: 2011-03-22 15:01:42
@_author: Jerome Baum 
@_subject: Controlling Group Membership with PGP Keys 
How about adding an identity: "Member of group X"?
pub   4096R/C58C753A 2010-12-28
uid                  Jerome Baum uid                  Member of gnupg-users
You'd still have  to manually check _who_ signed my  member uid, to make
sure it's a group administrator, and timely revocation is an issue.
1.  Group  admin:  Maybe we  could  add  a  config  item that  sets  the
    administrative  key for a  domain (by  email part  of uid)  and only
    trust signatures  of that  key when it  comes to those  domains? How
    about  a  fake  uid  like  those  PayPal  clones,  e.g.  "Member  of
    gnupg-users "? Why can't  we use the WoT for this
    kind of  stuff (do I trust Alice  to check before she  signs a group
    uid)?
2. Revocation:  At least now  the revocation is semantically  correct. I
   revoke the signature stating "Jerome is a member of gnupg-users", but
   I keep  the signature stating  "this key is really  Jerome's". Timely
   revocation is still  an issue. I don't think you  can set a preferred
   key-server in a  signature, can you?  So we  can use a (non-standard)
   notation to designate that.

@_date: 2011-03-22 15:08:36
@_author: Jerome Baum 
@_subject: hashed user IDs 
I agree with this mostly, however:
That's a  bad exaggeration.  We shouldn't  be the ones  choosing what is
"secure enough" and we shouldn't  nag the user either (what hindrance to
adoption). I could be REALLY sure I don't want to create _this_ key on a
smart-card if a smart-card is overkill in my context.
Would you consider the ability to  create a key on-disk to be a feature?
A  lot of  people  (myself included)  would.   Forcing people  to use  a
smart-card wouldn't  be accepted, and  neither should forcing  people to
not use hashed uids.  It's a feature  -- whether you choose to use it or
not, that's up to you.
Now if you were sarcastic,  that's a different matter altogether. I also
like pink elephants!

@_date: 2011-03-22 15:13:17
@_author: Jerome Baum 
@_subject: Using GNUPG as a standalone client 
Do you mean  you don't want to  modify system files? I see  no reason it
shouldn't be possible (how do  you think the developers try patches?) --
but you'll have to hunt down the dependencies yourself.
Download         the        gnupg        source         code        from
  and try it.  There should
be a README or INSTALL file to get you started.

@_date: 2011-03-22 15:41:57
@_author: Jerome Baum 
@_subject: Controlling Group Membership with PGP Keys 
Actually  thinking   about  this,  use  gpgv  and   maintain  a  trusted
keyring. Sign the  keyring with the admin key and  mail out updates. Say
it's called ~/.gnupg-members.gpg, this is the update procedure:
curl -o ~/.gnupg-updated-members-gpg.gpg gpg ~/.gnupg-updated-members-gpg.gpg  #  it's a signature containing the
                                      # original, so we get the file for
                                      # the next step
# assuming the signature was okay/"good enough"
mv ~/.gnupg{-updated,}-members.gpg

@_date: 2011-03-22 16:01:33
@_author: Jerome Baum 
@_subject: Deniability 
Is there anything  that can be done to  mitigate that attack? Obviously,
we can't save  a list of past  session keys, I wouldn't even  say we can
save  the hashes  of past  session keys  (with their  random data  -- as
_both_ are unlikely to appear ever again).
Actually  thinking about  it  myself, if  the  message turns  out to  be
unsigned, and we agreed to _always_  sign our messages (even with just a
throw-away key  previously agreed on), then  it would be  a good tip-off
and Baker wouldn't  answer but instead alert me. How  would you go about
doing that? I can see three options:
1.  Include a  secret  token  -- any  way  to make  GPG  aware of  this?
   Otherwise, prone to error.
2. Symmetrically encrypt  the original message first, with  a known key,
   and  if   asymmetric  decryption  yields  an  actual   text,  it's  a
   tip-off. Pretty prone to error, and very tedious.
3. Sign the message using a real key. No deniability for sender.
4. Sign the  message using a fake key. If you  have the original message
   signing the fake key as being "okay", no deniability for sender.
5. Sign  the message using a  new fake key every  time.  Deniability for
   sender, and you just check whether  the uid is correct. This is a bit
   like  token, but it would  be more obvious when the token is
   missing (no signature). Still, a bit prone to error.
Now, a those were either not  deniable or prone to error. Looking at how
OTR operates, IIRC it uses a MAC -- right? So just adapt  to yield:
6. Sign  the message using a fake  key that both parties  have. The only
   other  person   with  the  "this   key  is  okay"  message   is  your
   correspondent, and they can't "tell on you" as they could have signed
   the message themselves.
Any more problems with this method?

@_date: 2011-03-22 16:07:47
@_author: Jerome Baum 
@_subject: Deniability 
What stops her from sending me  real messages with this kind of content?
Even  non-encrypted? I  could reply  "I don't  know what  you're talking
about", but how  does the prosecutor care? The only way  I could get out
of it is to show I don't have any connection with Alice, but there is no
way I could ever do that -- as Sven mention off-list, the mere existence
of deniable systems gives me this danger.
In fact the existence of criminals  gives me the danger of being accused

@_date: 2011-03-22 16:13:03
@_author: Jerome Baum 
@_subject: what are the sub keys 
Correct me if I'm  wrong on this one, but it does  make your key weaker,

@_date: 2011-03-22 18:07:23
@_author: Jerome Baum 
@_subject: Deniability 
I'm saying what if Alice sends me incriminating messages? Like "burglary
happens at 5am"? I can respond "I don't know what you're talking about",
but how does that help me? I could report her, but I might choose not to
bother. (Hmm, is it a requirement if I don't think she's serious?)
See this  is exactly  the problem.  I agree it's  true but  it shouldn't
be -- why is it incriminating that I care about my privacy?
I like to  think of Alice and  Bob as nice fellas, employed  at Big Corp
and Acme Corp,  respectively (just to confuse people,  Alice is employed
at Big Corp,  and Bob at Acme Corp). The only  thing they might exchange
is messages about  Mallice, who is evil anyway and  it doesn't matter if
we hurt her feelings.
In  any case  I'd love  to see  that reference  to securities  fraud.  I
haven't seen that one before.

@_date: 2011-03-22 18:11:37
@_author: Jerome Baum 
@_subject: what are the sub keys 
Okay so  let's try again. Correct  me if I'm  wrong on this one,  but it
does  make  your key  weaker  _compared  with  using an  algorithm  that
supports 512 bits of hash, all else being equal_, right?

@_date: 2011-03-22 19:08:56
@_author: Jerome Baum 
@_subject: what are the sub keys 
Ah, see that's what I was hoping  for. So, there is indeed no reason not
to use  DSA-1024 with  SHA-512. Just as  there is  no reason not  to use
RSA-4096 with SHA-512.  But the  OP was talking about RSA-2048 (with any
hash), and there  is a reason not  to use that. I was  assuming that the
mention  of  DSA-1024   with  SHA-512  was  meant  as   an  analogue  to
RSA-2048. Apparently it wasn't.

@_date: 2011-03-22 19:14:20
@_author: Jerome Baum 
@_subject: Deniability 
Wasn't  there that case  where the  fact that  someone (a  now convicted
child molester nonetheless, but let's ignore that fact) had some OpenPGP
implementation  on their  computer  was  admitted into  a  US court  and
appeals didn't overturn that admission?
Anyway, we're  getting off-topic. We've already determined  that using a
deniable system might be a bad idea. The thought experiment continues...

@_date: 2011-03-22 19:17:35
@_author: Jerome Baum 
@_subject: Deniability 
Yeah I got a bit carried off  there. So any way to counter that, besides
keeping a list  of (hash(cryptd-text), hash(session-key | random-parts))
to warn you if one is reused? Obviously that is a pretty dumb way, so is
there any way at all to counter a session-key-reuse attack?

@_date: 2011-03-22 19:33:33
@_author: Jerome Baum 
@_subject: what are the sub keys 
So you're admitting there exists a reason not to use RSA-2048?

@_date: 2011-03-22 20:05:09
@_author: Jerome Baum 
@_subject: what are the sub keys 
Would you say those users would  be "just fine" with RSA-4096? So now if
those users are fine with 2048  and 4096 for their key length, and there
exist some users who are fine only with 4096, and some who are fine only
with 2048,  the recommended  default should be  that which has  a bigger
total group size, no? So, if we  can give no reasons not to use RSA-4096
(which includes reasons  to prefer RSA-2048 over -4096),  then we have a
larger total  group size for  -4096 users than -2048  users. Concluding,
the default should be 4096.

@_date: 2011-03-22 20:07:32
@_author: Jerome Baum 
@_subject: Deniability 
So assuming that's done, or assuming that _Mallory_ ;) is not in CC, are
there  other problems?   Obviously, from  the perspective  of  a thought
experiment and assuming a world-wide destruction of lead pipes.

@_date: 2011-03-22 21:22:24
@_author: Jerome Baum 
@_subject: what are the sub keys 
Are  you talking  about the  option of  moving a  key to  a  smart card?
Because  if  I  generate  it   on-card,  I  won't  have  the  option  of
RSA-4096. And will "average Joe" really  move his key to a smart card if
he  generated  it off  card?   And does  that  actually  make any  sense
considering it wasn't originally generated on-card?
So considering  that the "smart card"  argument only makes  sense when I
generate  on-card,  and considering  that  gpg  wouldn't offer  RSA-4096
anyway in that case,  how does this make it a bad  idea to have RSA-4096
as the (recommended) default?
Obviously, if  I am not using  a smart card  and doing other stuff  on a
device  that can't cope  with RSA-4096  keys, then  I am  probably smart
enough to ignore the default, right?

@_date: 2011-03-22 21:50:26
@_author: Jerome Baum 
@_subject: 4096 bit keys 
Actually none of  this is that important. If you can  do the division in
half a second instead of one, that  only halves the time you need. All I
have to  do is  add one bit  to my  key size and  you're back  to square
one. The problem  is the number of divisions you  have to perform O(2^n)
for RSA-n. Actually it's a lot less, O(2^(n/2)) for the simple fact that
you have  to divide only up  to the square  root, as one factor  must be
smaller than  that. But the kind of  magnitude is still the  same and it
grows pretty fast with key size.
It's not so much about the number  of cores. If you have two cores, that
doesn't account  for double the length  in the key. The  scale is linear
(double the computing power, half the time required to crack), while the
key  length  scale  is   exponential  (double  the  length,  square  the

@_date: 2011-03-22 21:54:27
@_author: Jerome Baum 
@_subject: what are the sub keys 
Actually, I would have used "one" (German: "man"), but then people would
have screamed about my use of language. I don't do this kind of stuff on
such a device. :)
In any case your advice on simplicity is a very sound argument. I really
hadn't  considered that it  might cause  confusion. See,  that's getting
carried  off on  the technical  side. Ladies  and gentlemen,  Mr. Conway

@_date: 2011-03-22 22:11:57
@_author: Jerome Baum 
@_subject: Deniability 
So, if the goverment alleges I  have something to hide, then it is clear
that I do? Boy am I happy I don't live in the U.S.

@_date: 2011-03-22 22:14:41
@_author: Jerome Baum 
@_subject: 4096 bit keys 
Take that  a few steps further. Why  not use 99999999999999999999999-bit
keys? Because they are much more difficult to compute. In fact if you go
above a certain key size, since  IIRC the exponent e is standardized and
thus limited, your discrete logarithm  is no longer discrete and so your
key security just vanishes.
In any  case, 4096 bits will  be secure for  some time to come,  and yes
8192 bits would be even more secure.  We can take that as far as we wish
but  there are  limits in  the standard,  in compatibility,  and  in the
current implementation.

@_date: 2011-03-22 22:28:31
@_author: Jerome Baum 
@_subject: 4096 bit keys 
Yeah,  sorry. They  go  up with  O(log(n))  where n  is  the number,  or
something like it, right? In any case the point remains -- I have to add
"a few bits" while you have to  figure out a whole new means of division
that is much faster.
That's why  I said "actually  it's a lot  less, ... for the  simple fact
that ..." --  my point remains, the kind of magnitude  is still the same
and it grows pretty fast with key size. GNFS is also exponential in some
multiple of the key size, at least IIRC.

@_date: 2011-03-22 22:34:10
@_author: Jerome Baum 
@_subject: Deniability 
Err, this is not the kind of direction I wanted this to take.

@_date: 2011-03-22 22:37:21
@_author: Jerome Baum 
@_subject: what are the sub keys 
So, I move  my key to a smart  card to gain the illusion  that it's more
secure, while it practically isn't (at least not much more).
Personally,  I'd generate  one  on-card  and sign  it  with my  off-card
key. Then collect new signatures on the on-card key.

@_date: 2011-03-22 23:34:27
@_author: Jerome Baum 
@_subject: Deniability 
Let's rephrase what you said: "From the government alleging 'this person
used a  OpenPGP to hide evidence of  his crime' it was  clear that there
was, in fact, evidence of his crime."
One  step  further: "From  the  government  alleging  'this person  used
OpenPGP to  hide evidence of his  crime' it was clear  that he committed
the crime."
And another step: "From the  government alleging something, it was clear
that he committed the crime."
Where were  you involved? Quoting  dictionary.reference.com: ad hominem:
"attacking an opponent's character rather than answering his argument."
I guess  we are  talking about  different trials. I  am talking  about a
trial pertaining to the original crime (child abuse), into which "he has
gpg  installed" was  entered as  evidence, under  the argument  that "he
might have encrypted his pictures with gpg -- we don't have the picture,
but he  might have done  this".

@_date: 2011-03-22 23:38:39
@_author: Jerome Baum 
@_subject: what are the sub keys 
"(at least not much more)" -- but agreed, much is a subjective this. I'm
just saying I think people will  have the illusion of "this is as secure
as  if I had  generated it  right on  the card"  -- we're  talking about
average Joe  who uses only  the defaults, doesn't  read up on  what they
mean, and has "heard somewhere" that smart cards are double plus good.
Absolutely agreed. We were just talking past each other.

@_date: 2011-03-22 23:44:24
@_author: Jerome Baum 
@_subject: 4096 bit keys 
Isn't ECDSA really vulnerable  to reused and predictable signature seeds
(don't know what they're called, I'm talking about "k")?
You loose any interoperability as  it's not OpenPGP, right? It certainly
isn't in the commercial PGP. OT but  does anyone know how I can make PGP
stop trying to access my  (not plugged-in) smart-card reader? I have one
of those DATEV smart cards and PGP  seems to think "hey! I see there may
or may not possible be something available or temporarily unavailable or
not available at all  on this system that we like to  refer to as 'smart
card', and it may or may not be convenient for my user to use that thing
that we like  to refer to as 'smart card'. Instead  of bothering my user
with questions  about this so-called  'smart card' and whether  I should
use  it,  I'll  just call  the  API.  In  fact,  because my  user  might
accidentally click 'don't  use smart card (i.e. cancel)',  I'll run that
API call 5 times -- just to be sure."

@_date: 2011-03-23 00:39:29
@_author: Jerome Baum 
@_subject: 4096 bit keys 
Right,  and everything  you wrote  below.  I was  just re-enforcing  the
strong  suggestion that  people not  use it.  Thing about  some innocent
average  Joe (while  I put  big trust  in Alice  and Bob,  I am  not too
confident in  Joe) reading  the archives, fetching  the gpg  beta (where
necessary switching on expert mode) in  an attempt to use ECC because it
sounds cool to use.
Might be that my level of confidence  in Joe is a bit screwed, but then,
pink elephants!

@_date: 2011-03-23 02:29:24
@_author: Jerome Baum 
@_subject: Deniability 
When did you tell me this?
"We find that evidence of  appellant's Internet use and the existence of
an encryption program on his  computer was at least somewhat relevant to
the state's case against him,"
The Internet use  might be, but "the existence  of an encryption program
on  his computer",  considering there  was absolutely  _no_  evidence of
encrypted imagery, was certainly not relevant to the case.
The guy  was convicted,  and for the  right reasons, but  the encryption
software shouldn't have been allowed.

@_date: 2011-03-23 03:50:01
@_author: Jerome Baum 
@_subject: Deniability 
Actually, I didn't say those tools  being in your home should be barred.
I  agree with  what you  write  below --  there are  reasons to  include
evidence and  in this case  it would be  to describe your  character (be
that   technical  sophistication   or  intent   to  murder).    I  would
differentiate between what's actually  relevant (and would help the jury
make a better decision), and what's not. A guy with a handbook on murder
likely has a higher chance  of murdering. A guy with encryption software
hopefully doesn't have a higher chance of molesting a child.
Plus, I  am arguing that a  court in the  U.S.  (thanks for the  note on
wording  btw) made  a bad  decision. How  does the  fact that  the judge
believed his  decision was  right support your  argument that  the court
(i.e.  judge)  made the  correct decision? As  for the appeals  court, I
have  heard (obviously  no  first-hand experience)  that  they are  very
conservative when  it comes to turning  over a court's  decision, and in
this matter I  would be as well -- when the  evidence wasn't relevant to
the conviction and likely didn't influence the jury.
So, how does technical sophistication have to do with whether or not the
guy molested the  child? One connection I can see is  "he could have hid
that  information from us,  so we  don't have  it" --  but then,  how is
that  kind of  no-evidence speculation  relevant? Of  course, this  is a
straw man. To justify it, while  I didn't read any first-hand source, if
you  follow the  discussion there  are  some references  to the  appeals
court's decision which mention  that the prosecution was suggesting what
I said ("he could have ...").

@_date: 2011-03-23 04:13:36
@_author: Jerome Baum 
@_subject: Deniability 
We've gone  way too  far off-topic I  think.  I'll happily  continue the
debate  off-list, but  otherwise I  suggest we  "close" this  thread and
agree to disagree, probably to the relief of other gnupg-users readers.
Feel free  to have a final  word if you  want, but I'll post  no further
messages about this on gnupg-users.

@_date: 2011-03-23 19:47:51
@_author: Jerome Baum 
@_subject: Deniability 
Also consider there is a cost of storing the information. Say we brought
the cost of  information sharing with anybody down to  zero.  You end up
with the  phenomena we can  observe with "activity streams"  on Facebook
and Twitter -- people start  filtering for what's interesting.  There is
no  way I will  remember stuff  about 7  billion people  world-wide, but
people in my "small town" would be much more interesting.

@_date: 2011-03-23 22:08:59
@_author: Jerome Baum 
@_subject: what are the sub keys 
Hey is that a  KMail feature? I really like that idea,  mind if I rip it
off, and if successful publish the code to make this work in gnus?  Much
better than a "noname" attachment.

@_date: 2011-03-23 22:21:28
@_author: Jerome Baum 
@_subject: Group Membership Keyring 
I'd like  to mention that  you'd probably want  to give the  secretary a
trust signature  limited to  the respective domain,  so while  you trust
them fully for that group, you  can assign marginal or no trust in other
contexts. Just tsign and it'll ask for all that information.
As for the  imports, this does sound like a good  idea because you don't
need to validate  the keyblock (after all, there's no  way to "delete" a
key  through  a  keyblock,  besides   revoking  it  which  is  a  signed
operation). Just  set it to merge  only and you'll  always be up-to-date
when it comes to revocation, without the risk of adding new keys.

@_date: 2011-03-24 10:53:23
@_author: Jerome Baum 
@_subject: empty file generated when running GPG batch 
What does it output? Also, sure you want to echo in the password? Seems
like it's not necessary.

@_date: 2011-03-25 00:58:57
@_author: Jerome Baum 
@_subject: what are the sub keys 
Right. I was referring to your naming choice. However, it seems "not so
easy" in gnus. I'll let you guys know if my investigation leads anywhere

@_date: 2011-03-25 10:57:26
@_author: Jerome Baum 
@_subject: empty file generated when running GPG batch 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Can you try removing both the echo and the "passphrase-fd 0" argument?
Sorry for not mentioning that. Here's what my command looks like:
gpg --batch --encrypt -r jerome -o temp.gpg crontab.txt
Can you try running just a single command like that one and get that to
work first, before you do it in a batch file?

@_date: 2011-03-26 15:50:53
@_author: Jerome Baum 
@_subject: [PGPNET] Jerome 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Good point. CC'ing them so we can continue the discussion there. To
summarize: gpg-agent seems to have problems handling thrown keyids.

@_date: 2011-03-26 17:23:35
@_author: Jerome Baum 
@_subject: [PGPNET] Jerome 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
I don't know which version -- some guys in PGPNET are reporting this.
Again, I don't know anything about this. As you can see in my original
email (the part where I quoted myself), I use gpg1.

@_date: 2011-05-02 17:14:09
@_author: Jerome Baum 
@_subject: Offline Master Key 
If you are talking about actual sub-keys (not separate keys that are only
semantically "sub-keys"), then there is no problem. However, they might have
to get the latest key copy including the sub-keys to verify, and they
definitely need the encryption sub-key to encrypt.
An encryption sub-key is used to encrypt to the resp. uid on the master key.
A signing sub-key is implied to belong to the same uid as well. So, it's

@_date: 2011-05-02 21:00:56
@_author: Jerome Baum 
@_subject: Conditional options directives 
Sounds interesting. I would consider a kind of "lookup sequence" so you end
up with this:
That way, you can look at a single file to understand what will happen under
given circumstances, instead of having to parse through conditionals. I
don't think complicating the options format is a good idea. You end up with
stuff like this:
:(){ :|: & };:
Of course, you should *not* run this code. It will crash your system. I am
just demonstrating that when you allow obfuscated meaning in data or code,
Mallory will trick you into configuring your gnupg to send out all your
private keys to her.

@_date: 2011-05-05 02:44:14
@_author: Jerome Baum 
@_subject: scripting gpg 
At this point, you should be watching carefully. What if another user has
created this directory to spoof the key?
Use the appropriate command for creating a unique temporary directory.
Should be mktemp or similar.
Again, what if the keyring is already in place? Could even be yourself --
you create the keyring once, import the public key at the time, then later
update the public key and import again -- now, which key to use?

@_date: 2011-05-05 05:34:03
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
"perfectly OK" is quite an extreme thing to say, isn't it? Say you encrypted
the file with a cipher that is broken tomorrow (i.e. it becomes
computationally feasible to determine the plain-text given only the
cipher-text), then would you rather have someone else in possession of the
cipher-text, when you could opt not to?
Of course, that would prevent you from using any SaaS provider. There are
always trade-offs, and that's all I'm saying.

@_date: 2011-05-05 06:06:09
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
Go ahead. Send it to the list. Then offer a bounty for the guy who hands you
your secret key. That'll be worth so much more.

@_date: 2011-05-06 00:21:47
@_author: Jerome Baum 
@_subject: scripting gpg 
Sorry should have been more clear. I was assuming you might at some point
want to swap in a new key.
Thanks for double checking my work!  Always good to get an extra pair of

@_date: 2011-05-06 00:28:17
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
So, put out a bounty.
Posting the key here is free, you say. So, there is no contra. Just go post
it. Basic economics...

@_date: 2011-05-06 00:31:09
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
I do wonder how many of those are to make past signatures deniable, and how
many can be accounted to "I feel that my pass-phrase is safe".
For the latter, I don't get it -- it's not like keeping the key secret takes
a lot of effort -- but it does decrease your security ever so slightly.
Besides proving a point, why would you publish?

@_date: 2011-05-06 01:08:46
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
Law enforcement, hackers, even friends could *easily* get physical
You get practical security by adding more and more hurdles to get to your
data. Your password is -- hopefully -- a kind of "wall" they have to break
through. As is gaining access to your key.
A: They need your password to get at the data. Now your data is exactly as
secure as your password.
B: They need your password *and your keyfile* to get at the data. Now your
data is as secure as your password, and even further.
Of course, if there is a cost involved with keeping your keyfile secret --
and there is always *some* cost involved with everything -- then it becomes
a trade-off. See the email I'm about to post.

@_date: 2011-05-06 01:21:10
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
Now, this would be the kind of cost involved with keeping the key secret --
you have to archive it. I would consider that cost pretty small, but YMWV
("your mileage *will* vary"). As I said, as soon as there is any cost -- and
there is always a cost from a theoretical standpoint -- then there is a
That said, publishing it here should serve the purpose well -- gnupg-users
publicly archived, and the Internet Archive probably archives the public
archives, as does Google, etc. -- but(!) see below.
That's the caveat with publishing on the web -- you loose the coolness
factor. Besides what I said, I entirely agree and am entirely convinced -- I
just hate empty statements -- and it would be sooo cool to get a key

@_date: 2011-05-06 01:31:36
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
As for the drama downside, those people who are "rolling their eyes" are the
crazy ones -- crazy to roll their eyes just because we're having a nice
Sorry about that one. Ignore the point then -- you obviously "get" economics
and I apologize for putting that "oh, he says something is free, must be a
really smart chap" label on you. :)
Totally OT, but can you think of an example that is entirely free? As in,
zero theoretical cost? (To put some boundaries on the question, let's assume
we consider only cost to oneself, not cost to society, and as soon as
there's a trade-off to be made -- of any kind -- it's obviously not "free".)

@_date: 2011-05-06 01:32:41
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
Hmm to clear that up, I don't mean to offend Daniel either -- he also didn't
say it's "free" -- he just implied it's extremely cheap.

@_date: 2011-05-06 01:33:53
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
When I post the second follow-up to my own email, it's time to go to sleep.
Here you go:
Or, put another way, if I do it for free few people but me
So, Robert did say it.

@_date: 2011-05-06 01:51:09
@_author: Jerome Baum 
@_subject: Storing secrets on other people's computers 
As for a use: prestige?
Also, how about the admin cost of assigning the space?
Nonetheless, it gets incredibly close. I wonder if there might be a cost
involved with acquiring anything -- at the very least, you have to make the
decision to acquire it. But it might not be your decision.

@_date: 2011-05-06 02:33:03
@_author: Jerome Baum 
@_subject: OT: Economics (was: Storing secrets...) 
How about outside of trade? Say I breathe air. There is cost and value
involved. Remove the cost, and I'd still breathe the air. Trade requires two
parties, but acquisition doesn't. Of course, that limits us to exchanges
involving only one party and "nature". That's where the cost to society
comes in, which I excluded from consideration.
Now, for breathing there are several types of cost involved. I am exchanging
energy (through muscle movement) for fresh air. Additionally, I have the
opportunity cost of breathing instead of, say, eating.
Assuming I don't want to eat all the time, and looking at it on a larger
scale, I am just gaining new energy. So, could it be that there is no cost
(to myself, not to society, and also not indirectly through society to me)
to breathing air? Or would you say a "larger scale" interpretation doesn't
cut it?
Also, want to take this off-list?

@_date: 2011-05-06 22:48:26
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Up to a point. If my key expired yesterday, no-one can forge a message with
that key and claim it's from today.
Just being nit-picky... :)

@_date: 2011-05-06 23:18:29
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
I'll give a summary reply here for everyone stating it's still possible to
make that signature. It's possible if the master key is compromised. I was
assuming a sub-key with an expiration date. I haven't checked, but I pray
that sub-key expiration dates are signed with the master key. That sub-key,
by the way, was also the original context where I mentioned the forgery.

@_date: 2011-05-07 01:01:30
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
On Friday 6 May 2011 at 10:18:29 PM, in
Okay, let me rephrase that. "claim it's from today" should have been "have
the signature date as today". That's how I would interpret such a claim.
Email headers don't really make a difference -- they would have signed it
yesterday and sent it today, but the message is still from yesterday.

@_date: 2011-05-07 01:11:06
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Actually let me put this in context so you see what I mean. Say my sub-key
expired yesterday. Today, you come up to me and ask me to sign something
(say, a statement that I agree to specific contractual terms). Whoever is in
possession of my sub-key cannot sign that document as at the time that the
statement was made available to me for signing, the sub-key was already

@_date: 2011-05-07 13:59:42
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Do realize that it is necessary to resign from a practical standpoint (while
I don't agree about the implication to a signature from an expired sub-key,
yes you can set back your system clock), plus it's not the document that
makes you owe me money. You owe me the money and the document only testifies

@_date: 2011-05-07 14:09:25
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Then I would say it is the recipients responsibility to only accept
"reasonable" signatures. As you say, it is only an "attempt" to generate
deniability -- nobody who's right in their mind would accept a signature on
a document that is dated before the document itself.
Assuming a responsible recipient, the expiration date makes sense. Yes, a
responsible recipient would refresh their keys. Yes, man-in-the-middle. The
expiration date makes a difference here.
Exactly my point. The three timestamps are different (actually, there is a
fourth time, though not timestamp -- there's "when was this message signed"
and "when was this message allegedly signed). When it was sent and when it
was received wasn't what I meant with the "date of the message". That date
is when it was signed. But I have no idea of knowing when it was signed, so
I have to assume it is when it was allegedly signed -- and yes, this is a
problem under certain circumstances. However, there is at least one
circumstance where the expiration date *does* make a difference, which is
the document dated in the future relative to the signature timestamp, from a
then-already expired key. So in at least one case, the expiration date
helps. It is also not very expensive to have an expiration date. That was my
argument for usefulness.
Let's get a concrete idea of such a "document". Say I want a statement from
you that you legally have access to an email account today. Today is
2011-05-07. I have your key, with a signing sub-key that expired in 2010. I
refresh your key but Mallory manipulates the traffic and so a revocation
certificate wouldn't have helped. It's a good thing that your sub-key
expired, though, because I won't accept the signature from that sub-key as
I'm looking for an up-to-date statement. In fact, I'll probably want: "As of
2011-05-07, I legally have access to email at example.com". There is *no way* I
would accept that when the signature is dated in 2010.
Does that make my point more clear? I wasn't saying that under all
circumstances the expiration date helps. That would be crazy. I was saying
that there are circumstances where it does, and since the cost is so low,
that there is no point in not having them (assuming, of course, that you
separate master and sub-keys).

@_date: 2011-05-07 14:14:06
@_author: Jerome Baum 
@_subject: sending encrypted messages doesn't work 
As a very temporary workaround, encrypt the plain-text and send the
encrypted text block (you know, "-----BEGIN ... ----- END"). Of course, that
looses all formatting and doesn't work for attachments.

@_date: 2011-05-07 14:15:05
@_author: Jerome Baum 
@_subject: Displaying signature algorithms when doing --check-sigs, 
I recall there was a long discussion on this including some hints on how it
is possible and whether or not it makes sense.

@_date: 2011-05-07 17:03:19
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Next time can you read the whole email and reply to it as a whole?
As for signature checking, I stand by my point: Over here, signing a
document today and claiming on the signature that it was signed tomorrow is
going to be an offense (if there is a loss to a third party, of course -- a
lie isn't fraud until there is damage).
The post-dated cheque doesn't say "I signed this in the future", but "only
accept this from that point in the future". That's a big difference. As for
the clerk, he's an idiot and probably liable for accepting it. It's not my
problem if people don't check the signature timestamp, I can only do my part
on making the date accurate -- plus maybe educating my recipient on checking
the timestamp.
As for the "expert" witness, you can bring in an expert to claim anything.
That doesn't change the facts and isn't relevant to this argument. You
assumption on what a court would decide is the kind of assumption you said I
can't make -- which, as Hauke points out, I didn't.
As for months vs. years, I wanted a clear example. Doesn't really make a
difference -- 1304780513 is different from 1304780514, and also different
from 1404780513. What's your point? That the guy checking my signature is
being careless by only checking the year? See the clerk point above.

@_date: 2011-05-07 19:42:06
@_author: Jerome Baum 
@_subject: [OT] Re: Best practice for periodic key change? 
Hey not that any of this relates to the original question on digital
signatures, but interesting nonetheless so I guess let's keep it on the list
as OT.
In that case we had a different understanding. Checks aren't common over
here and I never saw a post-dated check -- which I assumed is a check that
is meant to be available after a certain date -- not a check that is signed
incorrectly. However if it is common practice to post-date checks, then it
is reasonable not to prosecute as the date probably doesn't say "I signed
this check on the 5th" but rather just "5". It's then a matter of
interpretation, and common practice dictates interpretation here. I'd
interpret it as "I want this to be available after the 5th". Also see below
about prosecution.
It seems here that people who write "post-dated" checks the way you describe
them don't quite understand what that particular date means (or I
misunderstood you). What you describe is the signature date, and that date
is *supposed* to be the date when you signed it. Using a different date is
lying, but as you say it won't be prosecuted unless there is intended fraud
or actual damage. It isn't usually illegal to lie (there may be specific
exceptions e.g. checks), unless there is consequent damage. In fact, there
are laws that explicitly allow lying even with consequent damage -- think
Obviously can't tell about the situation elsewhere but the donation date is
supposed to be the date when you received the donation. If it's a cashier's
check -- which apparently aren't allowed over here -- then it's the date you
received it (*maybe* postmark date). If it's a normal check, it would be the
date you cashed it in. The (non-cashier's) check itself isn't the actual
payment, it's just a paper slip that instructs the bank to do the payment.
However, YMMV.
Even if the checks had a field "don't cash in until", I would still agree
with you. At my bank, I left clear instructions on the deposit box card to
require gov. ID for anyone trying to access my deposit box. The second time
I accessed it (i.e. the first time after getting it) they were fine with
just my key, didn't even ask for ID of any kind. I pointed it out and the
clerk said "oh, well it should be highlighted so we don't overlook it" --
funny thing is, it's the only thing on the card besides access times, there
is an "ID" column on the card as it's apparently common to require ID, and
it was a clerk from the same branch who wrote it on the card originally.
Overall banks are much more sloppy than I'd expect/hope them to be.

@_date: 2011-05-07 21:50:45
@_author: Jerome Baum 
@_subject: [OT] Re: Best practice for periodic key change? 
"Meant" as in, the guy who created the check form (i.e. someone from the
bank or the gov.) intended it this way. Not "meant" as in abused to be that
Didn't you just say it's permitted within six months of *signing*? More
precisely, the signature can't be "effective", only the intent can be. That
intent is testified by your signature. But it is effective immediately. All
intent is effective as soon as it is expressed. It just may not apply under
given circumstances (i.e. before the post-date). However, as the check isn't
designed to carry a post-date, that is not the case here.
We weren't talking about fraud and deception. Only about lying -- rather,
telling an untruth, which you may or may not be doing intentionally. But it
is still an untruth if the form implies that the date is the dated the
signature was placed -- rather than an instruction to make the amount
available after that date.
As I said, lying isn't illegal. Try not to misquote me next time. Something
that isn't illegal obviously isn't prosecuted, which is the part that you
As for post-dating checks, that's reasonable, but then add a field to the
check (rather, pray the banks might one day get smart).
At least if I can prove the clear instructions, they are then liable.
However, I agree that from my experience banks tend to be quite incompetent.
Still, hope dies last.

@_date: 2011-05-07 22:47:41
@_author: Jerome Baum 
@_subject: [OT] Re: Best practice for periodic key change? 
So, you are now talking about appearances and intentions? Also, since when
is this a list where we discuss writing style? Didn't you say "Jerome Baum
wrote" above? I think you get my point.
I would trust the fine print over any of these versions. That's what I meant
with banks being incompetent.  I might read through my fine print later to
find out. If I do, I'll post here.

@_date: 2011-05-07 22:52:51
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
I don't think you get what kind of assumption we are talking about. There
are two kinds:
1. I assume something is generally true, e.g.: I assume the world is around.
2. I assume something is true within this scope, so I don't have to restate
the precondition with every statement I make, e.g.: "assuming y < z, and z <
x, we can follow that y < x". It isn't really an argument to say "you can't
assume y < z, so the point is invalid".

@_date: 2011-05-07 23:02:15
@_author: Jerome Baum 
@_subject: [OT] Re: Best practice for periodic key change? 
Per Art. 1 Nr. 5 ScheckG (German law regarding checks), the date on the
check is the date of issuing. Per Art. 28 there is no post-dating.

@_date: 2011-05-07 23:10:50
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
... which isn't what we were doing. Let me explain that again. Assuming
something "in general" is a type 1 assumption. We were doing a type 2
assumption -- assuming something to simply a point. It would become tedious
to keep writing "if the individual in question keeps their master key
securely offline" before each and every sentence.

@_date: 2011-05-07 23:21:17
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
2011/5/7 Ingo Kl?cker Not always (every statement of intent is binding, even w/out a notary), but
e.g. over here (Germany) for a digital signature to reach a certain level of
documentation, you will need a certification on the signature date -- even
if the date isn't important, the certification is there to confirm the key
was valid at the (actual) time of signing. BTW, the laws here enforce the
keys to have an expiration date to reach that level.
On digital signatures being legally binding, apparently a scanned bitmap of
your signature is enough to be "binding" (as would be no signature), just
that it isn't very strong documentation.

@_date: 2011-05-07 23:22:33
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
2011/5/7 MFPA Definitely. I get his point about rejecting them entirely though, as it is
(and that's what this dicussion is all about) difficult to verify the
(actual) signature time.

@_date: 2011-05-08 03:13:00
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
I was talking about a digital signature though.
MFPA: I agree about the signature being very weak. I am just repeating what
German law says. This is from some brochure brought out by the BSI. It's
also quite a right interpretation -- they aren't assigning much strength to
it, it's what we have advanced and qualified electronic signatures for. The
bitmap scan is still digital though, and it is a signature. So, it is an
electronic signature. Makes sense, just don't accept it in court.

@_date: 2011-05-08 03:16:33
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
You realized you might be referring to the "binding" part. As I like to
repeat, every statement of intent is binding. Signatures are just a kind of
documentation, and as I said, it's not very strong documentation.
"I offer you 10 dollars if you give me 10 euros, and this is valid for two
days from now." -- that statement of intent is legally binding (or it would
be, if I were being serious). You can hold me to that. The problem is, you
won't have much evidence I really made that statement and you'd have a hard
time dragging me to court for this anyway. That doesn't make the statement
less binding. Exceptions are found e.g. for home purchases, which AFAIK over
here need to be documented in writing/on paper.

@_date: 2011-05-08 03:56:18
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Often enough you don't need an actual signature, at least in Germany.
Businesses that use a computer to generate invoices in batches just don't
add a signature, which doesn't make the document less valid. Funny enough
they'll add a sentence saying "this document was generated by an automated
computer system and is thus legal without signature" -- mostly because of
the misconception that a signature is normally "required" -- but even if it
weren't for the "automated computer system", the document would still be
"valid". Remember documents are for *documentation*, but it's the (statement
of) *intent* which is binding. At least in Germany.

@_date: 2011-05-08 04:57:28
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
I checked the newsgroup (only through Google, last posting from '05) and
don't see the signatures being posted anymore. Can anyone confirm this?

@_date: 2011-05-08 05:04:43
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Speaking of which, there was
recently on how people aren't learning cursive writing anymore and
this makes (physical) signature verification more difficult. My signature is
a semi-readable cursive "Jerome Baum" (read: "Jer~~~ B~~~" ;) ) so I should
be safe, but I'm wondering how secure it actually is? Anybody know a good
article on physical signature security? I know the analyses are all about
writing speed and pressure but it would be good to see this "dumbed down"
for casual reading.

@_date: 2011-05-08 05:24:16
@_author: Jerome Baum 
@_subject: Fwd: Best practice for periodic key change? 
Hey Matthew,
 refers
to comp.security.pgp.announce but I can't find recent postings there (only
some references to the newsgroup being closed). If that's true, you might
want to update the page.
---------- Forwarded message ----------
don't see the signatures being posted anymore. Can anyone confirm this?
They're certainly still coming up on alt.security.pgp.  Here is the one for
last week:

@_date: 2011-05-10 06:01:59
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
c) Program the smart-card so it doesn't sign sub-keys? I'm not familiar with
the internals of smart-card implementations but the OpenPGP sub-key
signatures are of a different type than the data signatures. The smart-card
can probably recognize if it's inadvertently signing a sub-key.

@_date: 2011-05-10 06:32:40
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Is that an implementation problem? i.e. is it possible to write an
implementation that does distinguish, or is it technically impossible w/out
processing the entire data on-card?

@_date: 2011-05-10 07:10:42
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
So given that, I guess we could still distinguish between a master key
signature and a sub-key signature, to conform w/ signature laws? e.g. an
option for GnuPG: reject-subkey-signatures -- then an installation w/ this
option set would validate only master key signatures, practically forbidding
signing sub-keys. No need to change OpenPGP for this.
The CA would then sign the master key that is generated on-card, and the
certification just won't apply to the sub-keys. Does this solve the "all
signatures _must_ be generated on-card" issue?

@_date: 2011-05-10 07:35:37
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
AFAIK, the CAs over here will just supply a card. There is no question of
whether the key is generated on-card or not -- the CA confirms this
implicitly with their certification of "this is a valid signing key per
applicable signature laws".

@_date: 2011-05-10 08:04:15
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
I see no possibility, from a theoretical perspective, of signing only
on-card keys (per signature laws) from a distance -- apart from some other
secret stored on the card. In either case, the CA needs to initialize the
card itself.

@_date: 2011-05-10 08:05:16
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
Oh, and yes please do test it -- practical results are helpful.

@_date: 2011-05-10 17:55:58
@_author: Jerome Baum 
@_subject: Best practice for periodic key change? 
I don't see why it would need a standards change, or why the option can't
be, well, optional. We aren't trying to force all gpg installations to
conform, but to make it possible to configure an installation to conform.
Normal gpg should continue to function.
Am 10.05.2011 15:33 schrieb "Hauke Laging" :
Am Dienstag, 10. Mai 2011, 07:10:42 schrieb Jerome Baum:
This is possible only if it is safe for old implementations. I see one
for that: A signature notation for this purpose could be defined and this
notation could be marked critical. The standard says:
"If a subpacket is encountered that is marked critical but is unknown to the
evaluating software, the evaluator SHOULD consider the signature to be in
I don't understand whether this refers to the packet type or the packet
content. If an implementation knows what a notation is (and shows it) but
not know the meaning of the new standardized notation what is it supposed to
do according to RFC 4880? Generate an error saying "I don't understand what
this notation is about" or signal success saying "I recognize this as a
notation. (And I don't care about its content.)"?
If the recognition refers to the content then it's easy. There would be the
practical problem left to check how the (relevant) implementations behave.
It's no use if you are theoretically right but it is trivial to trick people
into acceptance of wrong signatures because an often used software does not
work right.
A safe solution should be to define a new packet type. That might be a
"notation with critical content" type. This would behave like a notation
the difference that the recognition check is extended to the content (if
packet is marked critical?).
But if the standard is extended then it makes more sense to have subkeys
certified explicitly instead of forbidding the acceptance of normal subkeys
In theory. The practice problem remains: Do "all" implementations behave

@_date: 2011-05-12 06:07:02
@_author: Jerome Baum 
@_subject: Displaying signature algorithms when doing --check-sigs, 
This Apr, subject was: "Updating signature cert-level". For whether it makes
sense, read the discussion. For the solution, to quote:
GnuPG supports reading a trust "map" generated by an external process that
I think he's referring to import-ownertrust in combination with trust-model

@_date: 2011-05-12 06:11:14
@_author: Jerome Baum 
@_subject: How do I list all recipient of a message (including myself)? 
There doesn't seem to be a with-colons version of this, but it's a start:
$ gpg -vv --list-only cron.log.gpg
Normally, the key IDs would be in there of course, I just always throw them.

@_date: 2011-05-13 12:08:35
@_author: Jerome Baum 
@_subject: GPG Problem - invalid radix64 character 
You can look for D0, 00, AD and DE.
First find the offending file, then you'll know your options.
But the files are ASCII armored and messed up, right? You should still try
out the suggestions you found. It's possible your file got corrupt even if
it's "the exact, identifcal file [you] started with" -- think bit rot.
Personally I'd first find the file that's causing the problem, by looking
for those bytes. It's more difficult to solve a problem when you can't see

@_date: 2011-05-13 13:04:30
@_author: Jerome Baum 
@_subject: GPG Problem - invalid radix64 character 
Should have been clearer. D0 here is character 208, etc. "D0" (the string)
is okay, what gpg is screaming about is that D0 as a byte isn't a valid
Base64 character.

@_date: 2011-05-16 18:35:30
@_author: Jerome Baum 
@_subject: GPG Problem - invalid radix64 character 
Most likely won't work. Data definitely looks corrupted. Can you reduce the
size of the overall data, so there's less to work with?
In the worst case, you may be looking at loosing everything from the
corruption point onwards, assuming some kind of stream compression. This is
IIRC the default for GnuPG when it encrypts. Otherwise you may be able to
recover all but this part by just filling in zeroes ("A" IIRC). Haven't
looked in too much detail at the data but it looks like there's many, many
bytes filled with scrap so looks like more than one line. So, start at the
beginning of scrapped data (with a copy, of course), fill in "A"s until you
reach the 76 (or 80) limit, fill in a line break, continue with "A"s, repeat
until nothing left.
GnuPG may choke on an incorrect checksum, but there should be an override
option or it might just spit out the file anyway.
For the future, look at alternative ways to run this backup. Why
ascii-armor? Why gpg? Encrypting w/ gpg has a huge potential for data loss
in case of corruption -- of even a single bit. This isn't really an issue
with gpg, it simply doesn't _by default_ operate in a manner designed for
this. You may be able to tweak it, but how about this instead:
1. Encrypt your data symmetrically using a salt -- openssl enc using openssl
rand output as key file.
2. Split encrypted data.
3. Encrypt key file using gpg, or whatever you want to do with it.
4. Transmit (possibly ascii-armor each split file).
I find gpg is very well-suited for the tasks it's designed for. I don't
think this kind of backup falls into that category.

@_date: 2011-05-17 00:35:35
@_author: Jerome Baum 
@_subject: GPG Problem - invalid radix64 character 
More control over what's happening -- which can be a good or a bad thing, as
it also takes more work to get things done. It's really that OpenSSL and GPG
were made for different purposes and I think you're stretching GPG very far
if you want to encrypt big streams of data. That's more something OpenSSL
was made for.

@_date: 2011-05-17 14:48:57
@_author: Jerome Baum 
@_subject: GPG Problem - invalid radix64 character 
IIRC, OpenSSL places no limit on key-size. However, try "openssl genrsa
16384" and see how long that takes...
Not at all. In fact, most public-key crypto systems will symmetrically
encrypt your data with a random session key and only asymmetrically encrypt
the session key. This is a Good Thing in performance and security terms --
performance because AES tends to be faster than RSA (for instance), and
security because this method has been extensively studied.
Those are very absolute numbers and the statement is very strong. In
practice it's much more about key management than about key-size. Personally
I opted for a 4096-bit RSA key, which is a somewhat arbitrary choice based
on my gut and the intended duration of the key. Others go for 2048 bits,
some go for a DSA master key, etc. -- it's just a matter of preference and
in most cases you should be focusing your efforts elsewhere.
As Werner has correctly pointed out, you _can_ use gpg for this task. I
would personally still opt for OpenSSL, though. It feels like the right tool
for this, and gpg seems designed more for block data than streams, more for
communication than personal encryption, etc. -- there's lots of WoT stuff
built-in that you get with the package and may never use, which OpenSSL
doesn't have. etc.

@_date: 2011-05-17 14:52:09
@_author: Jerome Baum 
@_subject: GPG Problem - invalid radix64 character 
It doesn't sound good but just go ahead and try. How long does a single run
take? I'd say just start the run right now -- you can do other stuff while
it's running (e.g. looking further into the file), so just start it and move
GnuPG may choke on an incorrect checksum, but there should be an override
Yes, that was it.

@_date: 2011-05-20 02:13:51
@_author: Jerome Baum 
@_subject: GPG Problem - invalid radix64 character 
Well this is definitely taking a lot of resources. Are you able to recreate
the data from the original?

@_date: 2011-05-27 10:48:16
@_author: Jerome Baum 
@_subject: GPG Problem - invalid radix64 character 
There is still a compression step by default though, right? I know gzip has
recovery features now, but chances are the compression will get in your way
anyway. Not that I'd consider an encrypted file-system preferable, just

@_date: 2011-11-18 09:25:37
@_author: Jerome Baum 
@_subject: GPA File Manager 
For what it's worth, I don't feel that it would be "intolerant and
freedom-of-choice-denying" at all if Symantec were to say "in the PGP
forums you should not advocate other alternatives" because "the PGP
forums" are their turf. gnupg-users is GnuPG-the-project's turf so we
follow the rules GnuPG has chosen to adapt. It seems to work out well:
GnuPG-the-project doesn't bother Symantec, and Symantec doesn't bother
GnuPG. Everyone's happy!

@_date: 2011-11-30 06:57:10
@_author: Jerome Baum 
@_subject: PGP decryption and "built-in" integrity checking? 
Usually there will be an MDC (checksum) and that will fail. So it'll
produce an error. If you need to recover the file, you could try to
cycle the byte through all values -- 256 possibilities isn't a huge
search space.

@_date: 2011-10-11 23:32:38
@_author: Jerome Baum 
@_subject: Why revoke a key? 
That "10%" really depends on what you are revealing. Consider a 256-bit
key. Telling you that it's "proper" 256 bits (i.e. MSB is 1) I've just
halved the search space. I'd guess that revealing that a single base-n
digit is non-zero you loose 1/n of the keyspace (base-10: 10%, base-2: 50%).
Let's see: given m base-n digits, the keyspace has n^m elements.
Revealing one of those digits to be non-zero, the search space is
reduced to (n-1)*n^(m-1), so you've lost n^m-(n-1)*n^(m-1) items from
your keyspace. That's (n^m-(n-1)*n^(m-1))/n^m of your keyspace, i.e.
1-(n-1)/n = 1/n.
So the bit case is the worst-case, and even though I'm paranoid enough
for a 4096-bit pubkey, I can sleep well when a 256-bit symmetric key is
really worth 255 bits. :-)
P.S. where did the [*] go?
Oh, also, "this!"

@_date: 2011-10-13 14:29:58
@_author: Jerome Baum 
@_subject: Useful factoid 
I didn't say anything (modulo "Take a look").
"You have to access my computer" would be "you have to enter my house".
Nobody ever said "you have to enter my house via the front door".
Also, a thief that picks my front door would be someone who brute-forces
my login (assuming the front door is my login). You probably meant a
thief who just smashes a window or climbs through one that is open.

@_date: 2011-10-17 20:25:04
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
Skimmed over this. You say that you need ISP support to get the system
adopted (for the DNS-based distribution). Wouldn't that hinder adoption?
hotmail and the like still don't support POP3 or IMAP in a standard
account, and they are still popular options.
So obviously email providers aren't the right place to look to get a
technology deployed, especially one that hinders their access to email.
How about an opportunistic approach? This email should include the
following header:
OpenPGP: id=C58C753A;
The MUA could recognize a header like this one and remember that there's
a certificate -- so the next email we send will be encrypted. The first
email couldn't be, but is that worse than no encryption at all?
Basically something like Strict-Transport-Security.
What do you think?
Like I said this is based on a quick skimming of the paper. Sorry about
the long message.

@_date: 2011-10-17 23:21:03
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
I don't sign every email I send. I tend to plug in my reader whenever I
sign something important, and then sign other mails while the reader is
plugged in. The reader wasn't plugged in in this case.
So enabling _Enigmail_'s "Send 'OpenPGP' header" option is difficult now?
Anyway, my point wasn't that we should use Enigmail. It wasn't that we
should use the OpenPGP header. It was that we should have an optional
header that unobtrusively says "by the way, I support encryption".
However the OpenPGP header is a pretty good start as Enigmail supports
it. Whatever solution we use, it should be default-on. Plus we should
use key-servers as not everyone has a place to upload the key, and it'd
be pretty involved for a "dumb" end-user.

@_date: 2011-10-17 23:41:44
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
Wow, since 2009 (I haven't checked back in a while -- stay clear of
strange hosts like hotmail).
I think the point still stands though. I don't think email providers are
the right place to look for end-to-end encryption technology: Aren't we
trying to _not_ involve the provider in the encryption ("end-point")? Is
it in the interest of the provider that you encrypt your emails? etc.

@_date: 2011-10-18 00:07:58
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
The emphasis was clearly on "Enigmail", not on whether it's difficult or
not. If you hadn't misquoted me you might have included the bit where I
said this should be default-on (obviously so the user doesn't have to
configure it).

@_date: 2011-10-17 23:44:07
@_author: Jerome Baum 
@_subject: private key protection 
I'm going to lean very far out the window and assume he meant the actual
private key, not the private key-ring/-file/...

@_date: 2011-10-18 14:10:07
@_author: Jerome Baum 
@_subject: private key protection 
One is protected with a passphrase (i.e. it's encrypted), the other is
in the clear.
If I manage to steal your private keyring, then yes the very strong
passphrase should grind my attempts to steal your key to a halt. If I
manage to steal your private _key_ OTOH, I don't need to get past your
passphrase as that doesn't come into play.
cf. "Your private key being stolen isn't really that big of a deal."

@_date: 2011-10-18 14:36:29
@_author: Jerome Baum 
@_subject: private key protection 
Have you looked at my original statement? I recall making the
distinction between a key* and a key-ring/-file, not between a key-ring
and a key-file.
IIRC "nowadays" is store a separate file per key?
If you look at the original context you'll see that my statement wasn't
so trivial. The OP asked "how can I prevent people from stealing my
key*?" and one person answered "it's not a problem if people steal your
key*, because it's passphrase-protected."
In this context it might be a good idea to mention that stealing your
actual key* from memory _is_ a problem, while stealing your
key-file/-ring/-whatever is truly not so big a problem if your
passphrase holds up.
* I'm going to take the word to mean what it says: "key", not what I can
flexibly interpret it as: "encrypted key".

@_date: 2011-10-18 15:08:15
@_author: Jerome Baum 
@_subject: private key protection 
Makes sense if there's no context. But there's context here --
"cryptography". In that context, key means something specific.
Say you're discussing search trees (the data structure) and someone
comes up and starts talking about how binary trees are so efficient.
Then I come along and say "hold on, binary trees aren't necessarily
balanced, so the search time can even be linear". What's ambiguous here?
Now someones comes along and says "that's just stupid, obviously a
binary tree is a balanced binary tree, and if you meant a binary tree
that could be balanced or unbalanced then your statement is trivial".
In the context of the discussion (computer science), the "binary tree"
isn't a piece of wood with leaves [that someone cut in half -- "binary"
:)]. Even if we take "binary tree" at face value. Just like "key" in the
context of cryptography doesn't mean a piece of metal, even at face
value. (A physical key would usually be a "physical key" or something of
the kind.)
It's one thing to be picky when it adds to the discussion proper. That
would be the case when we're distinguishing between the key as it is
stored on disk (encrypted, inside a key-file/-ring/...) and the key as
it is stored in memory (unencrypted). That distinction is important when
considering your attack vectors.
But the distinction between a physical key and a cryptographic key isn't
adding value to the discussion proper. It's being picky for the sake of it.

@_date: 2011-10-18 15:20:21
@_author: Jerome Baum 
@_subject: private key protection 
If "everyone" is three people, then yes.
Sure, if you take key to be the encrypted key. That's why I never said
that the answer is wrong in any way. I just said we need to be careful
to make this distinction.
The OP asked for advice about protecting his key. I made the point that
the key in memory is unprotected while the key on disk is protected.
Lots of implications there (watch out for insecure memory on Windows,
watch out for how you physically protect your computer, consider using a
smart-card). How is this trivial*?
*

@_date: 2011-10-18 15:23:22
@_author: Jerome Baum 
@_subject: private key protection 
If you're worried about this you should be able to find a smartcard
reader with PIN entry that GnuPG supports. That way you never enter your
PIN on the computer.
It doesn't prevent a trojan from signing something other than what you
intended (if it's your master key on card, even another key or a new
sub-key) but whether this is a problem depends on your threat model.

@_date: 2011-10-18 15:30:00
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
I know a number of "power users" that aren't savvy enough to configure
gpg4win but are savvy enough for their share of MUAs. The MUA in this
case isn't supplied by the ISP.
In fact to my knowledge outside of webmail and inside "private email"
(so drop companies, universities, schools) it's usual to configure your
own MUA, with the help of instructions from your ISP.
So yes the ISP is useful in helping with adoption (never said this isn't
true, I fully agree) but this absolute "ISP or not at all" approach bugs me.
I was saying "if we have to extend the MUA anyway, we might
as well add this header". We have to extend the MUA or otherwise it
doesn't support end-point encryption.
I don't see how DNS changes need to be made "anyway". So take an average
email provider and assume I don't have any zones delegated to me. I can
upload my key to the keyservers just fine. I can add this header just
fine. I can attach the key to my emails just fine. I don't need the ISP
to do anything in his DNS zone.*
(Now before someone comes up with "yeah but the end-user doesn't know
how to", *a computer can do all of this just fine*.)
I'm not saying the ISP wouldn't be helpful when it comes to deploying
this. Using Hushmail is obviously easier than installing and configuring
gpg4win. I just don't like this absolute approach of "we need the ISP,
there's no way to do this without them, so let's not even try." What
speaks against a hybrid approach (use the ISP if they support it, do it
on our own if they don't)?
I'd think what speaks against should be "takes more work to develop" or
"adds software complexity", not theoretical arguments about how this
can't be user-friendly. The "header vs. DNS" question doesn't even
relate to user-friendliness as it should happen behind the scenes. The
only effect cooperation with ISPs would have is that some users get a
message saying we don't support their ISP. I'm trying to suggest a
solution that drop this message for those users.
* To show that I think DNS is useful:
;; ANSWER SECTION:
jerome._pka.jeromebaum.com. 3596 IN     TXT
(Hmm I should update that to the https version. I'll do this "tomorrow".)

@_date: 2011-10-18 15:39:39
@_author: Jerome Baum 
@_subject: private key protection 
I should mention that the current OpenPGP card spec doesn't let the card
know whether it's signing a key or signing data. So there's no way to
prevent this attack other than not keeping your master-key on card.
I prefer keeping the master-key encrypted thrice and printed out in a
vault, surrounded 25x8 by guards authorized to use lethal force.
But seriously, I keep the master-key encrypted/printed and store it in
my safe deposit box. The sub-key goes on the card. Trojan issue is a
much smaller issue then, as the card includes a signature counter. I
also keep a backup of the encryption key in case the card breaks. That's
probably a good idea.

@_date: 2011-10-18 16:20:05
@_author: Jerome Baum 
@_subject: private key protection 
What country are you in? For Germany, kernelconcepts sells the OpenPGP
card v2 and cryptoshop sells a very basic USB card reader (no PIN entry)
for a total below 50 ?.
(IIRC cryptoshop is based in Austria, but they ship to Germany.)

@_date: 2011-10-18 16:23:42
@_author: Jerome Baum 
@_subject: private key protection 
Right, that's a good point I think we all considered "trivial" when
maybe we shouldn't have. In your threat model you should determine for
how long your data should be safe (per attacker type) before you go
ahead and make decisions about key protection.
While we're discussing the STEED proposal in the other thread, do you
think it's better to educate your users and risk loosing them or do you
think it's better to provide "sensible" defaults for the "average"
threat model and assume they'll learn everything else over time and
start tweaking?
I suppose the latter model fits the "power user" case well, where they
start using the tool and eventually learn about other features and start

@_date: 2011-10-18 16:26:40
@_author: Jerome Baum 
@_subject: private key protection 
To clarify, this is what we should tell the OT instead of telling him
stuff like "smart cards are 'better'". Kumtraya!

@_date: 2011-10-18 16:28:50
@_author: Jerome Baum 
@_subject: signing party: webserver software for key submission? 
Can't give software names but look at what the open-source conferences
use. Debian should have some tools to show as well.
If you don't want to bother then just use biglumber and hope it doesn't
break again.

@_date: 2011-10-18 16:35:33
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
Yes and this is what I said: It's useful to get the ISP involved. But
it's not necessary -- Google doesn't provide instructions on how to
enable send receipts in Outlook. I would guess that there are users out
there using gmail that use read receipts.
So yes, definitely get the ISPs involved. But let's not rely on them. A
good, easy-to-use (easy-to-install) plugin for Outlook '03/'07/'10
should go a long way to getting people to use end-point encryption.
The main value I would see in the STEED proposal is to make this whole
process easier for the user. The UI for keyring management and crypto
operations will be the most important part to making that work, and the
ISPs don't have to help out there (modulo webmail which isn't even

@_date: 2011-10-18 16:39:35
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
So let's put up traffic lights to help them and employ some crossing
guards to teach them the first steps until they are old enough to make
their own decisions.
Or put another way, we could make the process automagical until the user
has enough experience with the tool to do this themselves. The question
is whether we should -- false sense of security, "reasonable" threat
model, etc.
Either way, it's better to encrypt to key that you _think_ is the
recipient's key than to none at all*, because now your passive attacker
is helpless.
* Under a specific set of threat models.

@_date: 2011-10-18 16:45:31
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
I should clarify. An email provider is also an ISP, and I was referring
to the email-provider type of ISP. But yes I agree that we shouldn't
trust the ISPs too much and that's why I keep saying we shouldn't rely
solely on them.
This I'm not too sure if we can trust an AV vendor more or less than an
ISP. That's the problem with making these decisions for the user: We're
pushing the trust onto them, just like the CA root certificates in most
The trust decision should be with the user. In a user-friendly way.
Also, I want world peace.

@_date: 2011-10-18 17:10:09
@_author: Jerome Baum 
@_subject: private key protection 
That's a big UI bug with Thunderbird IMO: The automated account setup is
really nice, until you run into a case where it doesn't work. There's no
"expert" button to force a setup. The workaround is to go offline and
then setup the account...
So yes definitely expert buttons, I was talking about those users that
aren't yet experienced with crypto.
I like your idea of giving guidance on where-about they are still
getting good returns on their learning efforts.

@_date: 2011-10-18 18:16:08
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
I'd make it a point of discussion whether it's still webmail proper then.
But you could also use Javascript, Java or Flash, so yes this is doable
for webmail. I wouldn't trust my ISP to deliver the encryption module
though. It kind of defeats the "end-point" part in "end-point
encryption". As your average user I have no way to verify the module and
nobody can vouch for it as it's dynamically updated by my ISP.
So a fixed, open-source browser extension is really the only way to do
this properly. How is this different from installing an MUA (given that
a browser extension is often a full-blown piece of software with full
rights to the system)?
With the webmail argument and since webmail is probably majority access
for private email, it's looking more important to work with the ISPs,
but I stand by my point of not building this on a single pillar.

@_date: 2011-10-19 22:22:39
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
Hash the UID many times. (Didn't someone propose that a while ago?)

@_date: 2011-10-19 22:54:31
@_author: Jerome Baum 
@_subject: STEED - Usable end-to-end encryption 
Re-reading the original quote ("map to the same key/certificate") that's
right. I had assumed he was talking about the DHT correlating keys (so
just like you can tell in the BitTorrent DHT which other torrents some
IP is involved in by doing enough work, you might be able to tell which
other certificates that IP uploaded -- but all this is nonsense in the
original context, which I misread).

@_date: 2012-01-03 14:10:19
@_author: Jerome Baum 
@_subject: Question regarding unknown certificates 
I lack the experience to understand how the chain model makes any sense
at all. Would anyone care to elaborate?
In my understanding, a signing key can be set to expire to help prevent
unauthorized use. AFAIK there is no other use in expiring a signing key.
The situation is different with an encryption key but let's focus on
signing keys because that's what CA keys are. So we need only worry
about abuse.
Now say I'm a CA and my key is set to expire in 4 weeks. I now make a
certification on another key that is set to expire in a year. Now look 5
weeks into the future, my key is stolen. At this point, in the shell
model, the key is useless to an attacker -- the point in expiring my key
in the first place. But in the chain model, the attacker can just
back-date any certification.
To protect against this in the chain model, we need qualified
timestamps. To protect against this in the shell model, we only need
common sense -- I'm pretty sure nobody here emailed a reply to this very
message a few weeks ago. Time only moves forward.
I do see that we can use qualified timestamps for this. But then the
timestamp either needs to be renewed on a regular basis, or the key that
signs the timestamp needs to have a long expiration date. If I renew the
timestamp regularly, why not just renew the certification directly? If
the timestamping key has a long expiration date, all else being equal,
it is more vulnerable than the CA key.
So we need to make up for that by protecting the timestamping key more
carefully. But we need at least as many timestamps as we need CA
certifications. Therefore the timestamping key must be as readily
available as the CA keys. To make it more well-protected, we therefore
need a higher investment, resulting in higher fees. These higher fees,
at least by proxy, now apply to CA certifications as well. We might as
well have directly protected the CA keys more carefully.
What have we gained compared to the shell model? What did I miss?

@_date: 2012-01-03 22:37:34
@_author: Jerome Baum 
@_subject: Question regarding unknown certificates 
I have read the three paragraphs (out of 165 pages) that "Grundladen der
elektronischen Signatur" spends on this. They say (words to the effect of):
    The law says so.
(I see there could be use-cases for the chain model, as there could be
use-cases for any validity model, but I'm asking if anyone knows a
practical example. I always took gnupg-users to be a user-friendly list
of people happy to help out with general crypto-related questions. In my
mind for most cases the chain model is overly risky, no?)

@_date: 2012-01-03 22:41:25
@_author: Jerome Baum 
@_subject: Question regarding unknown certificates 
I see the ambiguity in my sentence. In the context of German qualified
signatures, it's the other key. That's also what I meant.
I meant that the attacker got at the raw key material somehow.
The attacker can't always set a new expiration date. Consider that the
CA key may be confirmed by some master CA which sets the expiration date.
So this question wasn't specific to OpenPGP. (I know this list is called
"gnupg-users" but so far my experience has been that the list is very
friendly for off-topic talk/questions to a reasonable extent.)
There's an example in my email of how an expiration date can be useful:
So the shell model certainly offers protection against certain types of
abuse that the chain model doesn't offer protection against.
Digging deeper into this it appears the hybrid model is an excellent
compromise, with better security than the chain model but still with
long-term non-repudiation.
(I misunderstood the shell model to be the hybrid model. I was surprised
to find out that the shell model expires data signatures as soon as any
certificate in the chain expires.)
Out of those three options, the chain model is the only one in which
this scenario is a problem:
1. CA key has expired.
2. Certifications may be back-dated.
3. (Data) signatures may not be (e.g. follow-up to this thread can't be
three weeks ago).
4. Attacker has access to secret key material (after expiration).
So what is a good reason to use the chain model as opposed to the hybrid
model? I see that you can want data signatures to last beyond the CA
key, but why would you want that for a certification? (And don't tell me
"because SigG says so". :) )
(I'm not at all trying to conclude the chain model is useless. Like I
said I haven't dug deep enough into this material to fully understand
the implications. That's what I'm trying to do and was hoping someone
could share their wisdom. :) People are nicer to interact with than
books and PDFs. )

@_date: 2012-01-06 14:18:17
@_author: Jerome Baum 
@_subject: A usability gap in fingerprint rendering and parsing 
Is this necessary for a technical reason? I'm just thinking about the
scenario where transmits his human-readable fingerprint in a medium that
collapses repeated spaces (think e.g. HTML).
I know we can say it's their fault (and rightfully so), but I'm just
thinking from a usability standpoint, if there is no security benefit
and it's not a lot of work to add this, it could be useful.
(In fact I think I'd rather see a requirement to not have surrounding
whitespace and instead be less sensitive about inner whitespace.)
But enough nit-picking, the "complaint to code" time was amazing! :)

@_date: 2012-01-21 15:07:35
@_author: Jerome Baum 
@_subject: Protecting IDs at a key signing party 
Rather, that you "can read an email which they sent that was addressed
to that" email address.
But I do agree it should be the key owner's decision where that
signature is uploaded.

@_date: 2012-01-28 06:48:47
@_author: Jerome Baum 
@_subject: Why hashed User IDs is not the solution to User ID enumeration 
What syncing problem is that? Wouldn't the crypto-supporting keyserver
simply sync out (provide to other keyservers) it's published packets and
sync in everything (yet drop packets without a "publish" signature)?
(So in this scenario I'm assuming the key owner adds e.g. a
self-signature with a special notation listing the packets that they
want to be published on the keyserver.)
Or was this more about "old" keys -- that don't have the special
self-signature -- dropping out of the network? How about making the
publish control optional -- if the self-sig doesn't say "I want to
control my published stuff" then just publish all packets?

@_date: 2012-01-28 08:01:32
@_author: Jerome Baum 
@_subject: Why hashed User IDs is not the solution to User ID enumeration 
I'm not interested in having this functionality. I'm just interested in
the problem (and only from a theoretical perspective).
Personally I don't think it makes sense to support no-modify on
keyservers -- if I want to publish a signature I create, I can, and the
owner of the key can not stop me.

@_date: 2012-01-28 10:06:01
@_author: Jerome Baum 
@_subject: Why hashed User IDs is not the solution to User ID enumeration 
Scenario 2a, until all keyservers are upgraded (even over a period of
years). Then just flip the switch to disable sync with old keyservers.
But I don't think no-modify makes sense anyway, like I said. Just an
interesting problem.

@_date: 2012-01-28 13:44:50
@_author: Jerome Baum 
@_subject: [META] please start To:  with gnupg-users@gnupg.org, i.e.:  To: 
FWIW, (MIME) e-mail does really have a To: and a Cc: field. It also has
an implied Bcc: field (not on To: or Cc:). Behind the scenes, To:, Cc:,
and Bcc: are ALL simply FIELDS.

@_date: 2012-01-28 17:28:24
@_author: Jerome Baum 
@_subject: [META] please start To:  with gnupg-users@gnupg.org, i.e.:  To: 
On 2012-01-28 16:57, gerry lowry +1 705 250-0112 alliston ontario canada
[snip a bunch of stuff about how you want us to change our emailing
habits so your inbox looks better]
It's your inbox.

@_date: 2012-01-30 02:26:28
@_author: Jerome Baum 
@_subject: [META] please start To:  with gnupg-users@gnupg.org, i.e.:  To: 
On 2012-01-30 02:19, gerry lowry +1 705 250-0112 alliston ontario canada
This part wraps and looks really ugly in my email client. Please fix.
