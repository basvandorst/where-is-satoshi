
@_date: 2008-04-15 14:13:51
@_author: Stan Tobias 
@_subject: How trust works in gpg... 
[another newbie here]
I don't understand this.  If a public key has a UID1, which I already
trust, and a new UID2 is added, why can't I infer trust for the new uid?
My reasoning goes: UID1 is signed by its owner's private key, and I chose
to trust it (directly, or through others' sigs).  When new UID2 is added,
it must be also signed by the same private key, which is connected to
UID1, which I trust belongs to the person it says it belongs to.  So the
only person that could have added UID2 is the one that is in control of
UID1 (supposedly, it's the same person).  Why is there a need to check
Stan Tobias
[ Apologies to Peter Lewis for sending this post to the wrong address,
  and thank-yous for notifying me. ]

@_date: 2009-05-25 01:18:51
@_author: Stan Tobias 
@_subject: Can't enter passphrase in su session. 
I don't use and I don't know how `pinentry' works, so let it be a blind
shot.  `ssh' opens a new terminal session, while `su' doesn't.  When you
`su - newuser', you run with stdin/stdout/stderr attached to the olduser
terminal, with the olduser owner and most probably zeroed permission
bits for the "other" group, which means newuser cannot open /dev/tty.
If a program (like `pinentry' maybe, or `screen') run by newuser tries
to read directly from a terminal which belongs to olduser, it will fail.
I sometimes "fix" this by running `exec script /dev/null'.

@_date: 2012-08-25 16:33:16
@_author: Stan Tobias 
@_subject: what is killing PKI? 
As this thread is turning into a general discussion on privacy and
encryption, I would like just to add one more to the garden of thoughts.
I'm not making any argument for or against, I just want to say some people
find (forced) privacy detrimental, especially in a broad social context.
Some time ago, reading a discussion I noticed this particular
argument against encrypting file-sharing traffic, which can be
summarized/paraphrased as:
  "We don't want encryption, we want file-sharing be legal."
It's a strong political statement.  While privacy is important, you
don't win anything if you *have to* hide.  Freedom is often fought for
by asserting your rights.
                ^^^^^^^                  ^^^^^^^^^^^^^
This.  I wonder how certain societies got convinced that just being
nude - the most natural, beautiful and human thing - was indecent
and/or illegal.  Surely not because everyone was dressed?  Or?
Regards, Stan.

@_date: 2012-08-26 23:37:01
@_author: Stan Tobias 
@_subject: what is killing PKI? 
I'm sorry, if this is not quite topical, but the questions raised on
this list why cryptography is not taken up by Johnny Public return
here often, and I would like to share my mind and expand on my previous
In the works cited before (this thread and other discussions),
one recurring concern could be formulated as: "Why Johnny doesn't
encrypt his Christmas greetings to his granny?", with an implicit
assumption/expectation that everybody ought to use cryptography by
default for any and everything.  I'll concentrate on the encryption only.
Summary: encryption is being applied to a social problem.
I think we often conflate privacy and secrecy, which need not be the same.
Privacy is part of Freedom; both are elusive ideas, and difficult
to define.  *I think* Freedom is respect you receive from others,
on multiple levels.  Privacy are its specific rights.
My daughter has a diary.  It's not locked.  I know where to find it.
I have touched it, moved it, many times, but I have never opened it.
I teach the same my younger son.  This is privacy.
Once I have learned something by accident about someone from a note which
wasn't meant for me.  Not anything extremely important.  I have never
mentioned it to that person, or to anybody else.  That's privacy, too.
When you send a sealed letter through the Post Office, it's not the seal
that matters.  The letter can be read without breaking the seal,
or the seal can be easily removed.  What is important is that there is an
expectation of a certain behaviour, that if someone learns the contents
of your letter, they won't use that knowledge; or they won't reveal it to
others; or if it gets revealed, others will not use it; and if everybody
knows, your words will not be a witness against you in a court of law.
Write "Kill the king!" on the wall, you'll be convicted for calling to
violence; write the same in a letter - many will say you had a right
to vent your frustration this way.
Privacy is a certain aspect of social culture, it is about pretending
there are invisible barriers in an open land.  It is a Freedom you receive
from others, in exchange for the same.  Trust for trust.  This is what
builds society.  Sometimes the barriers are meant to be broken, but only
slightly, that's how we communicate, make new friends, etc.
My daughter could lock her diary from me.  It wouldn't really change
anything, but I would be sad.  Very sad.  (Translate for yourself "lock"
into "encryption" now.)
Well, the issue in itself is interesting, and I really don't know why,
but my question was meant to induce reflection and raise a certain point,
which your answer nicely resonates.
If you feel nudity should be legal, you have to show yourself naked.
If you want a right to speak, you have to go out and speak.  If you
think you have a right to gather salt on your land, you go, pick the salt
and say "My land, my salt!".  If you think you have a right to use any
bus in the city, you take a seat and announce "I'm like everybody else,
I have a right to sit here".  If you want sovereignty for Sealand, you
simply go there and announce "This is my land now!"; sometimes you have
to show your guns, too.  If you want to tell the world something which
is very important to you, you go to Wall Street.  If you want rights
for homosexuals, you go out to the street and shout "I'm a homosexual,
I'm normal, I want my rights like everybody else has".  If you want
independence for Ladonia, you simply sit down in your armchair, take your
keyboard, start Tor client, write a long blog denouncing state powers, and
demanding recognition for the Independent Republic of La... oh wait,
sorry, that hasn't worked yet.
What I mean to say is that often (but maybe not always) you need to
exercise your particular Freedom in order to gain or preserve it.
Talking about it is not enough, you have to be "there".
If you want to preserve the Privacy (like I described above), you have to
exercise it.  You have to take a risk that someone will open and read
your letter/email, and if they do, you demand them and everybody else
to leave you alone, that is to say, to respect your privacy.  If you
encrypted your letter, you wouldn't be able to exercise your right to
Privacy by demanding others not to read it.
I believe the same or similar sentiment was behind the file-sharer's
statement I paraphrased above.
Many years ago, when "London Bobby" was Great Britain's trademark,
I remember hearing in the news that British policemen opposed a new rule
that required them to wear a gun.  It was a stunning news for me back
then, because I couldn't imagine a policeman without a gun, and doubly
so, because I couldn't understand why police would want to oppose
wearing guns.  Well, IIRC, the reason was that they wanted to be seen
as community helpers, not "law enforcers"; another reason was that guns
would make them potential targets for the baddies (today many would say
"terrorists", but that meant something different in that era).
What I mean to say above, is that weapons are anti-social, they don't
build trust; and there are better means, other than guns, to maintain
peace.  Encryption is a weapon.  I believe there are many valid reasons
to use it, especially to protect other people.  It might buy you some
safety for a period of time, but it won't bring you Freedom.  You don't
get more Privacy by encrypting your messages.  If you _have to_ encrypt,
you're on the losing side.
[ I meant to write my views on the Facebook phenomenon vs privacy here,
but I want to keep more to the point, and I don't want to stretch this
post any longer; I can do it at another occasion. ]
So, if you (directed at everybody) ask Johnny why he won't encrypt his
greetings to his grandma, maybe one possible answer is that because he
simply doesn't want to live in your cage - any cage.
I hope I haven't bored you too much, regards, Stan.

@_date: 2012-08-29 00:27:34
@_author: Stan Tobias 
@_subject: what is killing PKI? 
For the lack of time, I'll be very brief.  I plan to answer Robert
Hansen's post, but I yet need to find a couple of free hours for that.
I would be violating her privacy.
Nothing, she still has that right.
If she learned I broke her trust, she would have a reason to change her
attitude towards me.  But before that, she's vulnerable.  Note I don't
require her not to lock her diary, I just said I would be sad if she did.
We're talking human relations here, it's not all black-and-white and
obvious.  Note it's usually alright to read diaries of long-deceased
persons.  For another example, suppose she was kidnaped - it would be
alright to view her diary in order to help her.
As a thought-experiment: suppose I xerox-copied her diary a hundred times
(without reading it), and then burned all the copies.  That's fine,
it's not a copyright-like issue.  But "copying" it into my brain, is
not like copying a file between two disks.
Two of multiple reasons why I won't read her diary is that by doing
so I would break my side of relation (IOW, I would hurt myself), and
second (suppose I had a tiny-little reason to read it and not tell her),
I fear that I could leak the fact sooner or later and hurt her anyway
(sometimes it's just better not to know).  Let's finish it here, we're veering much off-topic.
I think we talk different languages here.  You have a right to privacy
whether it's breached or not (I think it's kind of a human right,
to respect).  You can "enforce" it when you tell your little sister "I'll
beat you if you read my mail", or your polititian "You're finished if
police raids our houses, and we do damn mean it!".  The tool protects
your communication, but doesn't change anything in the state of your
rights.  You do have your right to encrypt your email; the question
we're discussing is whether and when it is a good or bad idea.
Regards, Irek T.

@_date: 2012-08-29 01:53:16
@_author: Stan Tobias 
@_subject: what is killing PKI? 
For lack of time, I have to be brief; I just answer the most important
I answered this in my post to Faramir, several minutes ago.
I call it a weapon, because it doesn't add anything to the message, it
only isolates it from third parties (including adversaries).  Just like
a thick castle wall, or the body armor, separates your treasure from
your enemies in space, encryption does the same in time (and maybe energy).
ACK.  It's like Peace, we all have to defend it.  But for goodness'
sake, let's not do it with nuclear missiles!
The fact of penetrating your encryption is not automatically the same
as violating your privacy, and the encryption doesn't matter here.
They might succeed and send you a message "Alert! We've broken your
communication.  For better security we advise to upgrade your rot13
cipher".  Early Unix hackers (was it RMS? - I don't have time to check)
retrieved users' passwords and wrote them "Your password is too weak,
you'd better make a stronger one"; were they breaking privacy? - I say
they weren't (with a tiny grain of doubt).  It all depends on what they
do afterwards with your message, and what their intentions are.
Privacy pertains to ethical behaviour.  Look at these three cases,
technically not differing:
- "Here's your letter, which came to the wrong address, I read it before I
  realised it wasn't for me, I'm sorry."
- "Oh well... thank you."
- "Here's your letter, which came to the wrong address, I read it before I
  realised it wasn't for me, I'm sorry."
- "Oh well... thank you."
- "If you'd like to know my opinion..."
- "Oh, no, please, I don't want to talk about it."
- "I'm sorry.  Good-bye."
- "Here's your letter, which came to the wrong address, I read it before I
  realised it wasn't for me, I'm sorry.  But I had a laugh of my life!  You
  must be really crazy to write such rubbish."
- "What?!"
It's obvious where privacy is not respected, so I'll just stop here.
Let's stop this here, IANAL, and I don't want to diverge into legal field.
I was only trying to get an understanding what privacy means for ordinary
people, in social and moral sense.  Laws differ and often don't correspond
to people's perception, so let's not further confuse matters.
I was talking about normal people, not interaction with businesses; and
about ordinary conversations - think "greetings", not "money".
I'm not arguing against cryptography, especially when there are important
reasons to use it.  Cryptography is not antisocial per se.
As a child I was taught not to whisper into the ear - it's still taught
to children, I think.  Being a guest at a table it would be very impolite
to whisper with your neighbour - just excluding others from your "private"
conversation is perceived as rude.  Your hosts perhaps could, for a short
while (for there's a reason), guests shouldn't; there is a way around it -
you could go to a side and talk private, but kind of visibly to others,
and everything will be fine.  It depends on situation, but generally people
don't like to be excluded, people want everyone to be open.
Some people (file-sharer in my previous post) in certain situations might
consider using encryption as an acknowledgment of defeat: if you encrypt
you don't stand up for common cause.  It's not that I personally support
this, it's how some people might feel, I believe.
Would you encrypt (let's say rot13) your hand-written love letters to
your fiance?
Regards, Irek T.

@_date: 2012-08-29 09:50:40
@_author: Stan Tobias 
@_subject: what is killing PKI? 
What I should have added here, is that it's a symmetric relation, and
people normally don't like to exclude others, as well.  Avoiding others
is not a trait of _usual_ _social_ behaviour, and by extension, I argue
that encryption might not be compatible with how people normally act or
perceive the world around them.
It's not an argument against encryption as such, but rather against
ubiquitous encryption.  I argue that when Johnny doesn't have anything
to hide, maybe there are good (social) reasons why he abstains from
encrypting, either consciously or unconsciously, not him just being lazy
or incapable.

@_date: 2012-08-30 14:12:50
@_author: Stan Tobias 
@_subject: what is killing PKI? 
We don't have All People Haters' clubs.  :-)
Well, I cannot explain how the whole society works.  But I would like
to add just a few points.
Clubs can be divided into  common interest (inclusive), and elitist
(exclusive), or mix thereof.  The former ones (like ours, gnupg-users)
accept anybody, but may need to defend themselves against trouble makers;
some may require membership, but anyone can have it if he sticks to
the rules.  If someone from outside, or a member, starts attacking other
members, only then he's punished by exclusion.
In the latter case - I can't say too much, I haven't belonged to any,
but I can imagine such a conversation:
  - "Hello Fred, I'm so glad I'm here with you, you're so elite!"
  - "Oh, Barney, you always exaggerate, our club would be nothing     without you!"
The point is you cannot be an elite alone, you need a little society
of other elite persons around you, and you need to care for them; IOW you need to be social within an otherwise unsocial group.
Last, but not least, I wouldn't call elitism a usual behaviour (like
people normally behave in my village, or in yours), and definitely
not social.  On YT there used to be an interview with R. Feynman in
which he tells how much he hated one "elite" students' club he once
fell into.  Excluding others is considered so anti-social, that it is
plainly illegal in some countries to set up an openly "men-only club",
or "women-only cafe" (they'll fall into anti-discrimination laws).
Regards, Stan.

@_date: 2012-08-30 15:59:48
@_author: Stan Tobias 
@_subject: what is killing PKI? 
No.  We send letters and postcards, we cannot guarantee that nobody
reads them, we cannot know if anybody reads them, and yet we can talk
about Privacy.
Privacy predates computers.  It's a concept we try to extend into
our digital world.  We require others not to read e-mails (without an
important reason), _by extension_, just as nobody is allowed to open our
envelopes.  By sending messages in the clear, we keep the issue *alive*,
we discuss it, we test it, we complain, we get offended sometimes.
Suppose, our computers were impenetrable and all our communications
encrypted.  Nobody, not even governments, can read anything we post.
Are we better off?
JUDITH:  "Here! I-- I've got an idea. Suppose you agree that he can't
         actually have babies, not having a womb, which is nobody's
         fault, not even the Romans', but that he can have the right to
         have babies."
FRANCIS: "Good idea, Judith. We shall fight the oppressors for your right
         to have babies, brother. Sister. Sorry."
REG:     "What's the point?"
FRANCIS: "What?"
REG:     "What's the point of fighting for his right to have babies when he
         can't have babies?!"
(source: I can envisage a politician comes up one day with an idea: We have
total digital privacy now, digital privacy laws are no longer relevant.
Let's abolish them!  By extension, if we don't protect digital messages,
why should we protect letters?   Keeping laws is so costly.  Let there
be no privacy laws at all!  After all, we don't take privacy from Johnny,
he can always email his granny, instead of sending a postcard, right?
Are we still better off?
I understand that the word "privacy" used in jargon, word cliches,
language phrases, and has different meanings.  It sometimes is a difficulty
for me, too.  Wikipedia says: The term "privacy" means many things in
different contexts.  I tried to identify and define "Privacy" as a *value*
in our lives, which the society protects; in this sense I use the word
in this thread.  I don't know if my vague description was the best one,
I just couln't come up with anything better.  And I don't mean to pretend
I have a complete understanding of it.
Regards, Stan T.

@_date: 2012-10-03 21:19:13
@_author: Stan Tobias 
@_subject: what is killing PKI? 
The impulse for writing my first post in this thread was frustration
about a "technological" treatment that privacy often receives, and about
a lobby that tries to tell everybody to encrypt everything, whether
sensitive or not (I think I've seen this on this list, but I don't have
the time to research now).  The argument for using encryption seems
to go like this: "privacy (value) is always good, privacy (secrecy)
is achieved by encryption, therefore encryption is always desirable".
I'm bothered when I read "privacy is achieved by encryption" (johnny1)
- okay, maybe they use it as a synonym of "secrecy", but then it blurs
the distinction between the two.
In my posts I just wanted to articulate one reason why for some people
(from "out in the field") encryption is a non-choice, and I gave some
context in which such attitude might be understandable.  In further
discussion I tried to describe Privacy as a social mechanism and show it's
not equivalent to secrecy (i.e. information leakage does not necessarily
mean loss of privacy), and therefore the above argument is non sequitur.
I don't feel the best person to discuss these things, but I thought
someone must first say an idea, so that others can use it and test it.
Before writing my first post, I had read the Gaw et al. article (by
your recommendation, actually), and I was a little less than satisfied
(perhaps because authors didn't make an effort to hide their opinions).
For this writing, I have read all the other articles mentioned in
someone's earlier post.
Please, allow me to add one more thought, which is relevant further down.
It might sound paradoxical, but openness is what protects us in our lives.
We require transparency from the government, from institutions, from
private companies (in certain circumstances), and therefore we practice
a culture of openness ourselves.  This is how we keep institutions
under control, and this is what keeps society together.  People are
more likely to support a transparent organisation.  People are upset
when public institutions become too secretive.
Facing an opponent, to avoid fight, we may run away (nothing wrong,
a normal defense), or challenge them (it often works).
I think I can understand why some people (e.g. Jenny) feel encrypting
"public" information is not appropriate: it's a challenge.  "We had
a meeting at 9, coffee was served, so what?  We are worried about new
law - every citizen has the right to be concerned.  We investigate what
BigCorp does - of course, we're ActivistCorp, it's our job, that's what
our supporters pay us to do.  Now, what are _you_ up to?".  Secrecy would
probably be not adequate, because then police could use any pretense to
enter the offices to hamper the activity.  Transparency also helps keep
internal discipline (don't do stupid things).
I didn't adapt the title without a reason, my answer was directed towards
that attitude.  "What will it take to make the use of encrypted e-mail
universal and routine?" is a quote from Gaw et al.
Do we really have evidence people can't encrypt?  For me the "johnny"
articles were not quite clear about it (they seemed to investigate a different aspect).  I don't believe people are stupid.  They can
learn to use cryptography, just as they have learned many other things
in their lives.
Another matter is what "can" does mean.  I can fly an Airbus A380.
(Sure :-^, I only have to find that "A/P" button.)  - That was
my conclusion having read "All users were able to decrypt. This is
because PGP automatically decrypts emails when they appear in Outlook
Express." (Sheng et al.).  I think what is missing from many discussions
is that to be able to _effectively_ use cryptography on computers, one
has to know much more than how to use cryptography.  (I could tell a
funny story of a security failure, not because of wrong use of GnuPG,
but because they didn't realize how a certain file system worked.)
Can you imagine a responsible person exchanging sensitive information,
while not being certain what he does is safe?  It's a matter of personal
integrity, it's not enough to tell a user "click here and there, and
you're fine"; we have to first convince ourselves what we do is right.
The upshot is that you cannot make cryptography easier for users, they
will have to study and understand it themselves anyway.
One reason I didn't like those papers is that they concentrated on a
particular version of a particular implementation, and they seemed to
make mostly ignorant users to work with it (and by my standards, they
were actually quite successful in that).  Their methods and findings
could be applied to any graphical software.  As I said, for me to be
able to use encryption means more than knowing which buttons to click.
I disagree here.  They might be difficult to quantify, but we can discuss
those issues and try to reach some conclusions, if not solutions.
One reason I like to read Schneier's blog (if I have the time) is that
he often discusses social aspects to security.
In the article I didn't find anybody who said they didn't want to be
_seen_ as paranoid, they only described certain behaviour as paranoid.
I think people use the word "paranoid" when something conflicts with
their perception of the world, and they don't know how to phrase it.
Cryptography might not be difficult to apply, but is not without its
own problems *around* it.  In my small experience, it requires a lot of
planning: what and why must be encrypted; what passwords will be used
(with many encrypted files) and how to ensure I don't forget those
passwords; how to ensure the encrypted files don't become corrupted
(so that data doesn't become irrecoverable), how do I check that they're
not corrupted, how many times will I check the files, where and how to
make backups (of course, check goes before the backups, but you have to
remember this), and many other small details in a long decision tree.
Recently I helped a friend to recover data from a broken NTFS partition -
mainly family pictures since many years ago.  Had the disk been encrypted,
the chances of recovering anything (by me, at least) would be close
to zero.  One has to be able to balance the risk of leaking information
against completely losing it, and it's a big headache, especially that
we don't realize all the factors that come into play.
Using cryptography to protect secrets is a serious intellectual
effort. Abe (in Gaw) described it as a "chore", and I think I can
understand what he meant by that.  If you want others to use cryptography
communicating with you, you want to put the same burden on their backs.
"Paranoid" in this case does not mean "tin-hat"; it just means that the
effort you put into message exchange is not proportional to its value.
As for the people you mentioned, I don't see exactly which you mean,
I didn't find any egregious carelessness (except that users didn't
understand digital signatures, but that wasn't a big issue either).
Ultimately, it's the organization management's responsibility to decide to
what degree information must be protected.  Should cleaners be required
to encrypt their emails?  What about the plumbers?  And encrypting often
isn't the only (or most important) matter to think about (WikiLeaks
"thank you" email fiasco).
Facts by themselves are not knowledge.  We gain insight by discussing
facts.  It's important to discuss before a next round of interviews,
because then we can know better what questions to ask, and how to ask.
My experience is generally in agreement with the findings of the articles.
My only addition here is that I try to rationalize certain behaviour,
which is something that the interviewees could not do on the spot,
because they probably acted on instinct rather than calculated risk.
I might be wrong about Jane, but I'm not wrong about myself, and my
writing here is another testimony.  There's no need to go far,
this mailing list is a mine of issues people deal with, of reasons
why they do or don't encrypt, and of their good and bad perceptions.
If someone had the time to sort all those things out, it might result
in another great scientific paper.
Best regards, Stan.
P.S.1. Having an occasion now, I just want to say to you, Robert, a big
       and sincere "Thank You!" for your articles on this mailing list.
P.S.2. I mentioned British police once - they still don't wear guns:
       P.S.3. Thanks to others who responded, and especially to Marco - after
       my second writing I got your reply first, and it was very nice
       and encouraging.  It's not very important what I have to say,
       and only slightly topical, but because you've asked, here goes,
       but briefly:
Facebook users have often been accused of carelessness about their
privacy, to plain foolishness (by "facebook" I understand any web-page
where users publish themselves, e.g. Wikipedia).  Once I read a discussion
on sexting among teenagers; the conclusion why they do it was that as
they grow, they announce this fact to others, it's in their nature.
(Some were harshly punished, but IMO not by life, but rather by
self-righteous adults, who disregarded their normality.)  I think the
same applies to grown-ups; I've seen people publishing uninteresting
things about themselves without purpose, I can't explain it other than
by a need to announce one's presence to the world - it's something in
the human nature.  Much "Internet" time has passed, and I haven't seen
any privacy disaster yet.  People reveal a lot, but not everything; they
make (sometimes funny) mistakes, but they also learn from those mistakes.
Privacy is not all black-and-white, and we have room to try how much we
can reveal, and when it becomes too much.
I think a lot of good results from people publishing themselves en
masse: we learn about other people, but most importantly *we learn about
ourselves*.  This helps _break social taboos_, and bring down barriers
between people.  We keep in contact with other people, share ideas,
organize ourselves, we can influence political changes.  People seek
other people, it's in their nature.  "Foolishness" is part of human
lives; I think what attracts people, is that they can make a mistake,
look foolish, and still maintain dignity, because everyone else around
is equally "foolish".  These are extremely important things, they help
us to grow up, and they change our (global) culture.  Ultimately, it
may occur that there are not so many things really private, because
essentially we all look the same, and do the same things.
I think we sometimes overestimate the negatives when people publish
their lives.  When one person comes out naked into the street, it's a
sensation.  When one thousand become naked, then effectively noone is.
Things that were inappropriate twenty years ago, are not so today.
One concern does remain: the published information remains, and we can
never be sure that it won't be used in future against us in ways yet
unknown to us.  Well, life is a risk.  We must evaluate what's more
important, creating more good and freedom for ourselves, or avoiding
the risk.  I see it as a race who will be there first, ordinary people
establishing a new standard of normality, or the self-righteous - will
they sense change in time and start regulating our lives again?
Last: here on this list we reveal a lot about ourselves, too.  If you
ask questions, or help someone with understanding cryptography, you
reveal you know something about it.  This information is potentially
more sensitive than what someone ate, or where they were on vacation,
and could be used against you.  So calling facebook people foolish on
this list is... well, paradoxical at least.

@_date: 2013-04-05 17:39:22
@_author: Stan Tobias 
@_subject: gpg for pseudonymous users [was: Re: gpg for anonymous users - 
People assume pseudonyms for various reasons, anonymity being but one
of them.  It is clear the person behind "adrelanos" wants to remain
anonymous, while giving a name to his action.  This is a narrower
application of pseudonyms, thus IMHO the subject should have stayed.
The problem we're trying to solve here is how to ascertain originality
of a software development line, IOW how to authenticate it.
I believe this has much in common with ordinary software authentication.
For instance, from _my_ perspective, "Werner Koch" is kind of an
anonymous person.  He's not actually a person, he is just the key that
signs versions of GnuPG software.  (No offense, Werner, I've seen you on
Google, so you must be true, surely. :-^ )  I don't think shaking hands
with Werner would change much in this regard.  Same goes for almost all
other signed software on my system.  What I mean to express is an idea
that in ordinary situation, the entity that authenticates (certifies)
software is the key itself, not its owner(s), whom I don't know, and who
I don't know if they exist.  (But I know the key.  Just try to imagine
the cryptographic key acquired intelligence and became a person, and
eventually - a friend; hey, I wouldn't trust a strange key, would I?)
The person(s) behind "adrelanos", in order to communicate securely and
anonymously, invents a "new person", a sock-puppet, called "adrelanos",
through which he will communicate with the rest of the world:
  I am adrelanos, the strictly pseudonymous (anonymous) maintainer
  of Whonix
For simplicity, I mentally associate this "invented person" with his
(their?) cryptographic key itself.  (Thus the name "adrelanos" is
redundant, what counts is the key's fingerprint, but it's good for
human speak.)  So when I say "adrelanos", I think of the key exclusively.
As a side note (this is not the main topic of my posting), I have two
suggestions to adrelanos.  First, I'm not sure the Web of Trust solves
anything for you.  You need to associate yourself strongly with the
project, so I would advise to put your public key into the very first
issue of the software, and sign the whole.  An attacker may do the same
with their key and claim they are the only true developers.  To thwart
this, you need to gather signed timestamps from many independent services.
(The reasoning is that someone can make a copy and claim as his for
nefarious purposes only, thus if you can prove you were the first to
own it, you can defend your authorship this way.)  Announcing on this
list (or in any public place) can also be considered as a kind of a
time-stamp (until a Ministry of Truth starts to manage our history),
but have I seen your public key here?  A third suggestion is to create
some backup keys, and somehow mention them in further software issues,
just in case you find yourself in disaster management situation and need
to identify yourself by another means.
What would such a certification accomplish?
In my lay person's understanding, the purpose of certification (key
signing) is to state that the UID correctly describes the person who
claims the key.
If you sign an anonymous key, that may be either misleading, or carry
zero information.  If you mean to certify for the real person - you
haven't met them, and there is noone who will claim the key (as long
as they want to stay anonymous).  If you sign for the "invented person"
(as I defined above), then you essentially certify that the key holding
a name "adrelanos" is correctly described by the name "adrelanos".
I understand the aim of your certification: you want to introduce
"adrelanos", and to state your association with him (although you
don't know the real person).  But can you explain this purpose in
your signature?  Is a key signing the best means for it?  Wouldn't a
better option be publishing a signed statement "I have cooperated with
an anonymous person adrelanos since ..., I believe he is the original
author of ..."?
Further thoughts for discussion:
If I told you my pseudonym was "Werner Koch" (for "John Smith" was already
too occupied), would you sign my key?  Why?  Why would it take 5 years to
convince yourself to sign adrelanos' key; why not 5 months, or 5 weeks?
If someone revealed to you "adrelanos" was a secret FBI operation,
would you still sign it?  (FBI behind "adrelanos" might be the true
original author of the software, accept bug reports, feedbacks, etc., and
I've heard they have really nice blokes there.  So essentially nothing
changes, except the state of your knowledge.)  Before signing his key,
would you check that the ID "adrelanos " was not in
use (not necessarily in a PGP key) by another person, say, a year ago from
Regards, Stan.

@_date: 2013-04-07 10:06:50
@_author: Stan Tobias 
@_subject: gpg for pseudonymous users [was: Re: gpg for anonymous users - 
(Modulo a black box in an ISP's locked room.  Modulo other circumstances.
I think it was a misguided idea from the old times that an email
could serve as a personal identifier.)
So basically you restate what I have said before: you introduce
someone (you help to start a history), and you mark your association (to
differentiate this one from other "adrenaloses"; I don't mean support, but
merely association by knowledge).  The first one is merely a side effect.
As for the latter, I don't believe it is even implicit in a certificate
(at signing parties, people sign keys to persons whom they won't know).
At best, it can be considered a side effect of your signing policy (if
you refuse to sign further "adrenaloses"), but this is not what is being
ceritified anyway.
Certificates are a message to others.  When you sign "Werner Koch"
key, you tell me that you have verified the key owner *is* Werner Koch,
and is willing to identify himself with this key.
Now, when you certify "adrelanos" key (UID, to be precise), do you mean to
tell me you have verified the "real" owner is adrelanos?  Obviously, no.
Do you mean to tell me you've verified that the anonymous owner - the
person who identifies himself by the key - uses the key "adrelanos"?
It's a tautology.  Do you mean to tell me the "invented person" is
adrelanos?  He's that by definition; it's a tautology again.  There is
nothing that can be verified, therefore nothing to certify.  I don't
see any meaning to your certificate.
As I noticed last, what's relevant is that each software issue is signed
by the same key (identified by fingerprint).  The key could be stripped
of any UIDs, and still fulfill its function well.  Thus I don't see what
a certificate could change.
I have chosen the pseudonym "Werner Koch" to make a contrast.  You suspect
fraud, and refuse to sign my key without checking, because you happen to
know a (important) Werner Koch.  Yet you're willing to sign "adrelanos"
key, because you don't happen to know another adrelanos?  I sense a
logic flaw, and thus a weakness in the signing policy.
With time, his reputation may change, and your confidence, but not
his identity.  His identity is established by fiat of his creator,
and will be the same in five years as it is now.  I think it is wrong
to assume time plays any role here.
(With time "adrelanos" may gain history which might further identify him,
but I doubt this whole history will enter his key UID.  For example, on
Werner's key I see only "Werner Koch", not where he lives, what he did,
which schools he finished, where he's been, what beer he likes, and what
his cat looks like.)
Sure.  I'd prefer you said "is known by", rather than "uses".
I'd be willing, too, to sign the Enemy's key, as long as its UID says
"Enemy" and not "Friend".  The problem is that "adrelanos" doesn't
mean anything to you, nor to me, but perhaps it might mean something
to someone else.  This is a reason for my objection to vouching for
anonymous identities.  I think it is dangerous.
Regards, Stan.

@_date: 2013-04-14 17:53:17
@_author: Stan Tobias 
@_subject: gpg for pseudonymous users 
That was just a figure of speech on my part, to express that I wouldn't
have a problem signing anybody's key whatsoever, as long as I'm sure
the UID truthfully describes them.  Any doubt is a reason not to sign.
Not really.  I wouldn't have a problem signing Lady Gaga's key, although
it's probably not what reads in her passport.  It's a pseudonym, but
she's known by that.  In fact, I don't distinguish between pseudonyms
and legal names - for me they're all names; what matters is whether someone
is known by that name.
Actually, it's about more than just being known by a name.  Our public
names are not quite our own choice.  "Lady Gaga" is an invented name,
but it will stick to her for a long time.  "Artist Formerly known as
Prince" or whatever shape he now wants to to be identified by, is still
recognized by his old name "Prince", whether he or his editors like
it or not.  If your group calls you by a nickname, it's often next
to impossible to have it changed.  You may change your legal name,
but it's not without many consequences for you.  A name becomes your
name when people call you by that name.  It's the society that keeps our
names stable.  Therefore public names can be considered good identifiers
(how good is another discussion).
In case of anonymous entities, like "adrelanos", I don't mean to say
they have no reason to protect their "brand" names: they might have
an ambition, a moral inclination etc.  But I don't see any *external*
mechanism that would glue the name to the identity.  The person behind
"adrelanos" may stop using this name when he merely gets bored, without
any consequences for himself.  Just because he can.  For this very reason
I don't consider an anonymous name a good identifier.  Just as the colour
of the tie you're wearing today doesn't identify you well.
Yes, that's my understanding:
I'm happy to say I absolutely agree.
That's a really difficult question, and I'm afraid I don't have an
"always works" answer.  I think asking a few people is better than
checking a document.
Another issue is what we use as identifiers.  I've always felt a key uid
was very small and limited in information.  In my perfect world the uid
would be... but that's another discussion.
Regards, Stan Tobias.
