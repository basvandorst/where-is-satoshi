
@_date: 2010-10-06 15:57:07
@_author: Marsh Ray 
@_subject: English 19-year-old jailed for refusal to disclose decryption 
I am thankful to not be an English "subject".
Or that the authorities didn't want to reveal their capability to break it.
Or that they wanted to make an example out of him.
Really? Who makes these tools? Where do they make that claim?
Wouldn't drive manufacturers have heard about this? What would they do once they realized that drives had this extra data storage capacity sitting unused?
I see this idea repeated enough that people accept it as true, but no one ever has a published account of one existing or having been used.
 > (secure deletion being quite unexpectedly difficult)
Sure, but mainly because of stuff that doesn't get overwritten (i.e., drive firmware remaps sectors which then retain mostly valid data) not because atomic microscopy is available.
What makes you think these investigators were well-funded?
Or they wouldn't prefer to spend that money on other things?
Or that they necessarily would have asked the jailers to release the teen because they'd been successful in decrypting it. Perhaps their plan was to simply imprison him until he confesses?
SSDs retain info too. Due to the wear leveling algorithms they're quite systematic about minimizing overwrite.
But I doubt any of that is an issue in this case.
- Marsh

@_date: 2010-10-07 19:35:42
@_author: Marsh Ray 
@_subject: English 19-year-old jailed for refusal to disclose decryption 
Is there a way to prove that you did?
If yes, your jailers may say "We know you have more self-incriminating evidence there. Your imprisonment will continue until you prove that you've given us everything."
If no, your jailers may say "We know you have more self-incriminating evidence there. Your imprisonment will continue until you prove that you've given us everything."
Get it?
If the encrypted file is large, and disk file fragmentation patterns, timestamps, etc. suggest it has grown through reallocation, the 4 KB grocery list you decrypt out of it is not going to convince anyone.
On the other hand, if you produce a sufficient amount of relatively incompressable image, video, or encrypted data from it, you may be able to convince them that you've decrypted it all.
- Marsh

@_date: 2010-09-03 11:01:09
@_author: Marsh Ray 
@_subject: Merkle Signature Scheme is the most secure signature scheme possible 
I found this to be interesting:
Danilo Gligoroski, Vlastimil Klima: Practical consequences of the aberration of narrow-pipe hash designs from ideal random functions, IACR eprint, Report 2010/384, pdf.
The theoretical loss is -log2(1/e) = about 0.66 bits of entropy per
log2(N additional iterations).
This assumes that there is no systematic correlation between the hash input and the calculation of the output, which is not really a good assumption with the MD's and SHA's in current use. They accept, process, and output vectors of 32- or 64-bit words, even preserving their order to some extent. So it would seem reasonable to expect that to the extent that these actual functions differed from an ideal random function they could easily have the type of systematic bias which would be amplified through repeated iteration.
I played with some simulations with randomly-generated mappings, the observed value would at times wander over 1.0 BoE/log2 N.
It seems like this entropy loss could be largely eliminated by hashing the previous two intermediate results on each iteration instead of just one. But this basically amounts to widening the data path, so perhaps it would be cheating for the purposes of this discussion.
- Marsh

@_date: 2010-09-03 14:26:21
@_author: Marsh Ray 
@_subject: Merkle Signature Scheme is the most secure signature scheme possible 
I represented the mapping entirely as a table in RAM (it sure is nice living in the age of the 4 GB laptop). Instead of truncated MD5, I initialized my table from a good but non-crypto PRNG. Having it in a table made it practical to do many repeated applications and watch how the rate of entropy loss varied.
I should clean up that code and graph the output, it seemed to be making some interesting curves.
- Marsh

@_date: 2010-09-07 12:21:18
@_author: Marsh Ray 
@_subject: Randomness, Quantum Mechanics - and Cryptography 
Blast it with RF for one.
Typically the natural thermal noise amounts to just a few millivolts, and so requires a relatively sensitive A/D converter. This makes it susceptible to injected "unnatural noise" overloading the conversion and changing most of the output bits to predictable values.
Using digital outputs from an enclosed module with enough shielding could probably prevent it. But there are plenty of environments which are too small (e.g., smart cards) or are potentially in the hands of the attacker for an extended period of time (smart cards, DRM devices, power meters, etc.).
- Marsh

@_date: 2010-09-07 14:12:45
@_author: Marsh Ray 
@_subject: Randomness, Quantum Mechanics - and Cryptography 
The point is that this it's a generic, relatively low-tech attack that is likely to be effective against a straightforward implementation of the general idea.
Only if the engineers know about it and spend the resources to build in such resistances to it. So the system which consumes the entropy also as to look for the "I'm not producing any more entropy" signal as well. The proper operation of this signaling has to part of the test process. So now there needs to be a way to simulate the attack scenario for testing. Presumably this becomes another input to the system which itself must be test. All this adds time, cost, and complexity and it's not surprising that they don't always get it perfect.
There is some evidence that engineers designing chips that go into actual products (little stuff like girls' toys and smart grid power meters) aren't familiar with this:
"This graph shows the counts of individual seed bytes in a poor random number generator. The sample width is a single integer, and the RNG byte is expected to be one of the very few spikes presented on this graph."
Note that the above description is a little confusing because there are multiple problems going on here. The "seed bytes" are coming from a poorly engineered radio source and are also going into a "poor random number generator".
Here's a better description:
Well, the idea of physical stress attacks is that you get the system to do something it isn't supposed to do (e.g., sign with a weak nonce).
Were they engineered for use with crypto to resist attack? Were they tested in an actively hostile RF environment?
It's really unwise to try to reason about the behavior of complex systems like digitial circuitry when operated outside of its absolute maximum specifications. You'd have to re-qualify them for such use.
And it will not get built into any product if it costs $0.01 more unless the hardware engineer is unable to justify the additional expense.
Probably very little if the engineer didn't take special precautions.
Also the attacker gets to choose the frequency and direction from which the device is most susceptible and combine this will all other techniques simultaneously. For example, perhaps would run current through the external shielding or expose it to a static magnetic field (thus heating it or saturating its magnetic permeability).
So the attacker leaves his ipod out of the faraday cage in which he's abusing the smart card or DRM device.
The attacker doesn't necessarily have to completely eliminate all entropy from the output, just enough that he can make up the difference with brute force or analytic techniques.
"Changes from Revision Original (September 2009) to Revision A" "Removed sentence that pseudorandom data can be used for security."
- Marsh

@_date: 2010-09-07 15:22:24
@_author: Marsh Ray 
@_subject: Randomness, Quantum Mechanics - and Cryptography 
The designer often has wrong information about what the system will be used for. Most systems don't see much adoption and are discontinued because they don't make any money. Systems that succeed with low-value transactions tend to get repurposed for more and more important roles until the breaking point. SSL and Zigbee are two examples.
Imagine how much an additional shielded region would cost to a cell phone that's expected to sell 50 million units. An engineer is probably going to be trading that cost off against some other feature with a tangible benefit. When the junior engineer speaks up and says "let's just use the microphone for entropy gathering instead" he's going to be considered a hero for saving millions.
An additional consideration is that the device must also operate reliably when someone puts popcorn in the microwave or uses an arc welder in the next room. The detector must absolutely never create a false positive.
Most actual consumer products sold will prefer to continue insecure operation rather than shut off. For example, the GSM standard includes a mechanism to notify the user on the display if they're connected to a cell tower with an unencrypted signal. Cell carriers typically disable this notification, presumably because it tangibly increases support costs for a benefit that appears highly theoretical. It's usually only when it's the interests of the manufacturer that are being protected that a device will actually go out of its way to find a reason to cease operation (e.g., DRM).
- Marsh

@_date: 2010-09-08 13:08:46
@_author: Marsh Ray 
@_subject: Hashing algorithm needed 
Oh good, this makes me not the new guy now :-)
These seem like nice standard, authentication system design questions. I'll give them a shot.
Using SSL here makes all the difference in the world. Without SSL, an attacker can modify your javascript to do anything he wants, such as sending the password in plaintext or redirecting the browser to a malware site.
Since SSL is required for us to even discuss security in a meaningful way, most of the rest of my comments assume all URLs are https. Ideally, the only thing you serve out of port 80 is a redirect to https and you support STS Strict Transport Security.
Still, you're sending something via a standard HTTP POST or GET method. I assume you're using a standard session cookie? Be sure it has the "secure" flag set.
Although it doesn't seem right to me either, sending the plaintext password via a HTTP POST body is really the standard way to implement a login form over https.
Again, your servers will refuse to accept credentials except over SSL, I think the words you want to use are "select a standard, well-accepted hash algorithm for use in this authentication protocol". For example, Hash functions (all functions really) by definition produce the same output for the same inputs. So you want to include "unpredictable" data in the input.
In addition to the random data chosen by the client, it would be good to have some random data sent by the server, too. Its better if this data is not sent back by the client directly, the legitimate server should know what he sent.
That's the hard part.
Standard hash algorithms usually have Javascript code available that should be fast enough for a login process. Java will have a native C implementation available in its crypto library.
The only way to do that is to "sign" the contents of each and every http request with the password. There are schemes that do this, but again it's rather pointless since the bad guy supplied the Javascript that the browser is running anyway.
It will take a little more than just comparing a received hash with a static database entry. If that were all there was to it, the transmitted hash would be a password equivalent.
In any case, if the attacker can see these transmitted hashes he can attempt to crack them at a later time to recover the password unless there was a secret he doesn't know mixed in to the hashed data (but how could there be if you don't secure the connection?) So you're putting the complexity of the user's chosen password plus a hashing function that runs quickly in Javascript in a computational drag race with the attacker's set of gigahertz CPUs, GPUs, and Amazon EC2 nodes. The best you can do is include the random data to prevent him from using precomputed tables to help with the attack and raise the cost of cracking each password.
In practice, attackers can conduct millions of tries per second so most passwords can be cracked relatively quickly. This is especially bad because 43%* of users will be using that same password for their online banking and all their accounts.
*From memory, study conducted by Sophos a few years back.
This is a good goal. Watch out for this: if the thing you send over the wire could be used to login on a different connection, then it doesn't matter if it's hashed or not, it represents a "plain text equivalent This problem has been studied pretty thoroughly for web applications over the years but it comes down to this: With SSL you might as well send the plaintext password, without it you aren't securing anything anyway.
There are attempts to improve on this. For example Micorosoft's integrated auth which can negotiate Kerberos or NTLMv2 authentication. I haven't looked into the Kerb one much, but the NTLMv2 auth has some long-known security weaknesses.
Here's an existing scheme that's a lot like what you're asking for:
Best of all, it's already built into the HTTP client and server.
So what are they going to do about it other than worry?
It's good that you're considering that from the beginning, but I suggest you reconsider that decision.
And for actual security reasons, too.
Again, it's got to be SSL anyway.
That's a good bet. Or at least you can expect that for every group of users who can handle presharing a key there exists a much larger group that includes potential users which can not.
- Marsh

@_date: 2010-09-13 23:26:07
@_author: Marsh Ray 
@_subject: Hashing algorithm needed 
flj, I appreciate your systematic and conscientious engineering approach. But I haven't heard anything in your requirements that make it sound like a journey outside of well established protocols is justified There are a few experienced people around here who could probably design come up with a new custom scheme and get it right the first time. But the history of most (even professionally-designed) new security protocols usually includes the later discovery of serious weaknesses.
I have a similar setup going in a reasonably big production environment and it's working great.
There may be a way to get a browser to generate a cert or CSR, but I don't know it. But you can simply generate it at the server side.
 >
Note that you can get the full client cert presented by the web server and compare it (or a sufficiently long :-) hash of it) directly with what you have in the database. There may be no need to check signatures and so on if your server-side is centralized.
Most apps will want to ask the human to authenticate explicitly from time to time for one reason or another.
Make sure you have at least some way of revoking and renewing a client certs, even if it's a code update. Just on the outside chance that, say, the keys got generated by Debian Etch's RNG or something.
Three more recommendations:
Don't put anything sensitive in the X509 cert. Just a minimal userid or even random junk. You're just looking it up in a database.
Disable TLS renegotiation unless you control both the clients and the servers and can ensure they're all patched for CVE 2009-3555. Don't expect to be able to use renegotiation to "hide" the contents public cert, that never worked against an active attacker anyway.
Use a separate dns name for the https site that accepts client certs from the one that does not. The reason is that the client cert will have to be requested on the initial handshake. Requesting a client cert will cause many browsers to pop-up a dialog. Not something you want on your secure home page.
Again this is a good scheme, it's the way SSL/TLS has been intended to be used for authenticated clients since SSLv3. It even offers additional protections from the server's perspective, too: the server is no longer forced to transitively trust the union of all trusted root CA certs of all allowed clients in order to prove the non-existence of a - Marsh

@_date: 2010-09-14 15:16:18
@_author: Marsh Ray 
@_subject: Hashing algorithm needed 
First, let's hear it for out of the box thinking. *yay*
Now, a few questions about this approach:
How do you deliver Javascript to the browser securely in the first place? HTTP?
How do you get the user to save his private key file? Copy and paste?
How does the proper Javascript later access the user's private key securely?
How do they securely wipe memory in Javascript?
How do they resist timing attacks? In practice, an attacker can probably get the browser to repeatedly sign random stuff with the client cert even while he's running his own script in the same process.
A sad indictment of browser vendor user interface priorities.
"This Connection is Untrusted"
- Marsh

@_date: 2010-09-27 22:16:18
@_author: Marsh Ray 
@_subject: Certificate-stealing Trojan 
While I agree with the sentiment on PKI, we should accept this evidence for what it is:
There exists at least one malware author who, as of recently, did not have a trusted root CA key.
Additionally, the Stuxnet trojan is using driver-signing certs pilfered from the legitimate parties the old-fashioned way. This suggests that even professional teams with probable state backing either lack that card or are saving it to play in the next round.
Is it possible that the current PKI isn't always the weakest link in the chain? Is it too valuable of a cake to ever eat? Or does it just leave too many footprints behind?
- Marsh

@_date: 2010-09-30 11:48:44
@_author: Marsh Ray 
@_subject: 2048 bits, damn the electrons! [rt@openssl.org: [openssl.org 
Why are multi-core GHz server-oriented CPUs providing hardware acceleration for AES rather than RSA?
There may be reasons: AES side channels, patents, marketing, etc..
But if it really were such a big limitation you'd think it'd be a feature to sell server chips by now. Maybe in a sense it already is. What else are you going to do on that sixth core you stick behind the same shared main memory bus?
I could be wrong, but I get the sense that there's not really a high proportion of sites which are:
A. currently running within an order of magnitude of maxing out server CPU utilization on 1024 bit RSA, and
B. using session resumption to its fullest (eliminates RSA when it can be used), and
C. an upgrade to raw CPU power would represent a big problem for their OTOH, if it increased the latency and/or power consumption for battery-powered mobile client devices that could be noticeable for a lot of people.
The unwrapping of the SSL should parallelize just fine. I think the IT term for that is "scalability". We should be so lucky that all our problems could be solved by throwing more silicon at them!
Well, if there are higher-layer inspection methods (say virus scanning) which don't parallelize, well, wouldn't they have the same issue without Or the vendors get to sell a whole new generation of boxes again.
It doesn't bother me the least if deployment of dragnet-scale interception-friendly SSL is hindered. But you may be right that it has some kind of effect on overall adoption.
Most sites do run "some particular application". For them, it's either a problem, an annoyance, or not a noticeable at all. The question is what proportion of situations are going to be noticeably impacted.
I imagine increasing the per-handshake costs from, say, 40 core-ms to 300 core-ms will have wildly varying effects depending on the system. It might not manifest as a linear increase of anything that people care to I agree, it does sound a bit hand-wavy though. :-)
- Marsh
