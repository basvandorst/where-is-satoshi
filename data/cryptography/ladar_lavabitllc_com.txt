
@_date: 2015-02-27 10:08:17
@_author: Ladar Levison 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
I?m about to spend a significant amount of time working on the DIME
specifications, with a focus towards writing the sections missing from
the current version, adding some of the low-level details missing from
the current draft, and incorporating the feedback the community has
provided. My goal is to publish a revised draft in conjunction with the
upcoming IETF meeting (March 22nd). To that end, I wanted to solicit
input from members of this list who haven't already sent me feedback, so
I can incorporate it, and more importantly, seek your input on some of
questions I've included below. Feel free to reply to me on the mailing
list, or if you'd prefer, in the thread I've setup on the DIME message
The December draft can be found here:
The forum topic I setup to discuss these questions is here:
Ladar Levison
*Protocol Questions*
1. While I?ve identified the majority of the functionality associated
with the access protocol (DMAP), my attempts to document the specifics
keep getting sidelined by a single question: */should DMAP be a line
based protocol, like IMAP (and POP, and SMTP), or should it be designed
as a JSON-RPC protocol, like the Magma camelface, or JMAP?/* See:
2. The current RFCs dictate that domain names are handled case
insensitively, while mailbox names (what goes in front of the @ symbol),
should be considered case sensitive. This behavior stems from the fact
that most early email systems ran atop Unix, which has a case sensitive
file system. Thus a capital letter in the mailbox would result in the
email server saving a message in a different file. These days email
systems generally operate case insensitively on mailbox names because of
the obvious implications associated with allowing email addresses which
are almost identical. The question is: */should DIME mandate mailbox
names be compared case insensitively?/* Keep in mind that if names are
considered case sensitive, a capitalized letter could result in a server
returning a different signet (with different encryption keys)!
3. Somewhat related to the previous question, */should support for
international domain names and mailboxes (using UTF-8) be mandatory?/*
Or should UTF-8 address support be optional? Systems without support for
UTF-8 addresses would be forced to use the ASCII encoding scheme defined
in the current email RFCs. Sadly, I am not an expert on
internationalization, and the prospect of normalizing UTF-8 mailboxes
and domains for comparison operations could be complicated, error prone,
and a potential source for security problems. Do the benefits outweigh
the drawbacks? (See RFCs 5890 and 6530 for a discussion of international
mailboxes and domain names.)
*Cryptographic Questions*
4. */How should ECC public keys be encoded?/* In the past I?ve used the
compressed form defined by the X9.62 standard. OpenPGP encodes the keys
as uncompressed multi-precision integers (MPI). Both are big endian
formats and rather long, leading some to suggest a more compact
alternative be used. The Ed25519 paper, for example, defines its own
compressed little-endian format to represent public keys (see endianness
question above). Anyone care to make a suggestion?
5. */What key derivation function (KDF) should be applied when deriving
a symmetric key from a Diffie-Hellman key exchange? It would be nice if
the same KDF could also be applied to user passwords. /*Note, the KDF
must provide at least 48 bytes, and looking for feedback on which of the
potential alternatives we should use. The following have all been
suggested to me: bcrypt, scrypt, Makwa, yescrypt. Some KDF?s allow for
us to pick from different hash functions as well, with SHA-512, Skein
and Blake being suggested. Currently the KDF is SHA-512.
6. */What ?special? considerations should be applied when encrypting
private keys, knowing they will eventually be stored on an untrusted
server? Should an AEAD cipher be used? /*Presumably the KDF discussed in
the above could be used again to derive the symmetric keys protecting
this encrypted data. The question, beyond using a salt, what else should
be done?
7. The current draft of the DIME spec says the E-521 curve will for
?alternate? asymmetric encryption keys, but doesn?t define an alternate
symmetric cipher to go along with it. */Should the alternate cipher
suite incorporate a different symmetric algorithm? How about a different
choice for signing?/* ChaCha20+Poly1305 has been suggested as the
alternate symmetric cipher.
8. The current draft stipulates TLS certificates are verified using
Ed25519 signatures created with an organization?s POK. */Is this
significantly more secure than providing a SHA-512 fingerprint, or just
unnecessary complexity?/*
*Data Formats*
9. Should the data formats encode binary values in little endian, or big
endian form? While most network protocols employ binary data formats
using the big endian form, a number of more recent upstarts (dare I say
rebels) have switched to little endian. The vast majority of computers
today are natively little endian (or at least bi-endian). */Should we
honor tradition, and continue using big endian, thus forcing a future
generation of programmers to convert their integers before evaluating
them. Or should we acknowledge the world has changed, and use little
*Signet Questions*
10. In the current draft, the signet informational fields are divided
into 2 ranges, with each range using either a 1-byte or 2-byte length
variable. The size of the length variable provides a technical
limitation on the amount of a data a field could potentially hold. For
example, the ?Postal-Code? field has a limit of 255 bytes, which far
exceeds any possible legitimate value. The fixed ranges were created so
parsers would know the size of the length variable when they encountered
an unrecognized field type, and skip over it. It has been argued that we
simplify the parser by using a 2-byte length variable for all fields.
The specification would then provide length limits which a parser would
have to enforce by trimming any field value over the defined limit.
*/Which strategy is better?/*
11. */Should organizational signets include a self-signature following
the cryptographic fields, like user signets, so they can be split?/*
This change would allow space constrained clients to avoid storing
information they don?t need/want about organizational domains, while
retaining the signet in a form that could still be cryptographically
validated against a management record.
*Message Format Questions*
12. This question goes toward the user experience: when accessing
displayable content, and binary attachments over a slow network
connection, */should a DMAP client be able to find out the content-type,
and/or any of the other meta information found in the MIME headers of a
body-part/chunk without having to download the entire chunk? If the
answer is yes, does the chunk?s content-type need to be encrypted? In
other words, do we consider servers knowing a chunk is video, versus
rich text, versus plain text a serious privacy leak?/* Note that if the
answer is ?yes? to both questions, the solutions will probably add fair
bit of additional complexity to the message format.

@_date: 2015-03-05 03:06:42
@_author: Ladar Levison 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
This message was indeed valuable. I've been working on breaking up and
reorganizing the specification, with the goal of making it easier to
grasp the important parts, without being overwhelmed by the details.
Reading the spec should be like sipping tea and eating crumpets, as
opposed to drinking from a well endowed fire hose.
I tried to answer the portions of the message that I could...
DIME wraps around RFC822/MIME _email_ messages, but does not transport
them over traditional SMTP. Rather, DIME uses a bastardized version of
SMTP which can be summarized by saying the localpart has been removed
from the RCPT TO/MAIL FROM commands. DMTP also requires the use of TLS
v1.2 with the ciphersuite 0xC030.  This guarantees PFS at the wire
level, and eliminates the possibility for TLS stripping attacks.
Not sure what to make of this, so I'll just address the "traffic
obfuscation is partial" by saying DIME isn't TOR. Metadata is minimized
but not eliminated. Generally speaking, the system tries to minimize
metadata down to an organizational level. Going further would be
difficult, because you'd have to address infrastructure issues, like DNS
queries going out unencrypted, or an attacker with the ability trace a
message using traffic analysis. While DIME doesn't address these issues,
we did make it easy for a domain to advertise onion addresses for
delivery and/or access. See the spec.
TLS provides PFS over the wire, but PFS for messages requires a little
more work. To attain PFS for messages, the user would need to operate in
paranoid mode (and thus avoid syncing their encrypted private key to the
server, where they could be copied). Assuming the user is operating in
paranoid mode, then they could rotate their signet every day (or so) and
delete their former private key when the expiry lapses. This would
provide PFS for any messages protected by the previous public key. I
don't expect many users to want this, but for those that do, its an
option. See the spec.
Not quite. I skipped over the parts of your message I didn't understand.
Like I said above, I will try and do a better job organizing/explaining
the details in the next draft. Or if your attending the IETF meeting, I
can sit down and explain the system more completely in person.
P.S. I noticed you discussed other aspects of the system in other
messages. I will try and respond to those when I get a chance.

@_date: 2015-03-05 03:11:54
@_author: Ladar Levison 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
Note the multiple signatures. This will allow implementations to "split"
the "core" cryptographic portion of a signet from the "full" signet,
which contains the optional "information" fields, like the image,
address, phone number, etc. "Splitting" is mentioned in the current
draft, along with definitions for the different types of signet, but it
wasn't fully discussed.
One of the survey questions I submitted to the list asked whether org
signets should also support "splitting?" Currently, only user signets
can be split.

@_date: 2015-03-05 03:24:52
@_author: Ladar Levison 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
You hit the issue on the head. JSON is common with web services, but
isn't typically used for protocols involving thick, desktop/mobile
applications. JSON-RPC web services typically use a different paradigm
than the line based protocols our mail clients use today. I have no clue
what developers would prefer, a stateless JSON-RPC protocol that is
radically different from IMAP, or a more line based protocol that looks
and feels like IMAP.
Just a random thought. You jumped on JSON as the data format, which is
slightly different than JSON-RPC as the protocol paradigm. It got me
thinking that we could keep the protocol line based, but use JSON
objects for sending/receiving structured data. Thoughts?
As for binary, I figured it would be an optional protocol extension,
just like it is with the current mail protocols.

@_date: 2015-03-11 08:52:43
@_author: Ladar Levison 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
The hooks are built in for extending it to other things, but that isn't
my focus right now. My focus is on getting the simple use case working.
Sending someone an encrypted message without them having to get a PhD in
mathematics first.
The core signet is a subset of the full signet. The core is made up of
the 5 fields required for encrypting email. Everything else is optional
and can be "split" off if the user doesn't want to store it.
A simple explanation for using the optional fields: when someone types
in your email address and your client goes out to fetch the signet, it
can display a little more info about you in the compose window. Like
your name and photo. Of course its all optional so we'll see how it ends
up getting used. Think of it has typing a business card (or vcard) to an
email address. Optional of course.
You can think of the org signet as the CA. Only in the world of DIME,
the org is the owner of the domain name. You get to pick you want to trust.
Its not a replacement. Its a wrapper for MIME messages.

@_date: 2015-03-11 09:06:14
@_author: Ladar Levison 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
In very simplistic terms, that is _exactly_ what we are building. Only
in our world the "directory" server is actually the mail server for the
recipient, which hosts the "signet." It makes sense that if the mail
server is offline, then you can't deliver mail anyways, so why introduce
an external piece to the puzzle.
All the extra complexity is either to prevent MitM, or optional.
P.S. DIME requires TLS v1.2 using the ECHDE-RSA-AES-256-GCM-SHA384
(OpenSSL name, I don't know the RFC name by heart). So yes, TLS is
required for a "conforming" DMTP server.

@_date: 2015-03-11 11:26:54
@_author: Ladar Levison 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
Most of your bullet points are simply wrong. You've managed to confuse
optional with required. Only the information needed to encrypt email
messages is required.
Yes it will require writing code. That's the hard part.
Yes the spec is too darn long.

@_date: 2016-03-16 19:25:31
@_author: Ladar Levison 
@_subject: [Cryptography] Lavabit's and Snowden's Solos 
As the sysop I feel qualified to clarify. I don't keep up with this list
as closely as I should, so Mr Young, thank you for pointing me to this
Ray, your right. The two cases are similar. They both seek to defeat the
encryption used to protect data at rest. They differ in that the Lavabit
case relied upon a surveillance order under the PRTT statue, and a
search warrant issued in accordance with the SCA. The Apple case relies
on a writ of assistance issued under the AWA. They differ
technologically in that the Lavabit case involved a MitM attack to
capture the password during login, while the Apple case involves
disabling login controls to facilitate a brute force attack.
Because both cases involve what I call "extraordinary assistance," I
co-authored an amicus brief in support of Apple. The lawyers changed the
definition of ordinary assistance at the last second, so I'm including
the correct one here:
We contend this request is extraordinary because it seeks to compel the
use, modification, or disclosure of confidential intellectual property,
such as source code or encryption keys, which belongs to an innocent
third party. In contrast, ordinary assistance requests seek access to,
or the surrender of data in possession of a third party that has been
created by the investigative target, or generated as a byproduct of the
target’s actions.
There is a short "background section" in the amicus brief which
discusses the Lavabit case, and how it differs. That said, with only 7
days to write it, we didn't include everything I wanted to say. Namely a
discussion of cyber weapons, non-repudiation, and compelled felonious
conduct. If this case continues onto a round two, I'm hoping to expand
upon what we said this round. If your interested in what we did write,
see here for a summary, plus a few pithy comments that were censored (by
the lawyers):
Or for the full brief:
All of that said, the government did try to cite the Lavabit case as a
precedent in their reply brief. See footnote  page 22 (or page 30 in
the PDF), which reads:
For the reasons discussed above, the FBI cannot itself modify the
software on Farook’s iPhone without access to the source code and
Apple’s private electronic
signature. The government did not seek to compel Apple to turn those
over because it believed such a request would be less palatable to
Apple. If Apple would prefer thatcourse, however, that may provide an
alternative that requires less labor by Apple programmers. See In re
Under Seal, 749 F.3d 276, 281-83 (4th Cir. 2014) (affirmingcontempt
sanctions imposed for failure to comply with order requiring the company
to assist law enforcement with effecting a pen register on encrypted
e-mail content whichincluded producing private SSL encryption key).
I found this citation so misleading that I decided to write a little
statement about it. Namely, the appellate court never addressed the
substantive question of whether the FBI can seize keys. The court ruled
that I waived my right to appeal (which is impossible, since a careful
reading of the facts would show I never had a chance to make the
objection they contend I should have). Because they ruled on the waiver
issue, they explicitly avoid any discussion of the lawfulness of
extraordinary assistance. If you want to read my full statement, see:
As you probably picked up on, what Ray wrote below, while it captures
the gist of things, isn't quite right on a few details. I made my
comments inline.
The FBI originally served the PRTT order around 5pm on June 28th, a
Friday. After a 2-3 hour discussion with the agents, the meeting ended
with me telling them I needed to consult with an attorney, as I was
"uncomfortable with providing the SSL/TLS private key, and didn't know
what my obligations under the law were." That very same night I received
an order to compel, issued by a magistrate judge, which ordered me to
provide all of the necessary "technical assistance" to "decrypt the
data." Since the order (and statue) made no mention of the SSL/TLS
private key, I emailed the FBI asking for them to provide a written
description of what "technical assistance" they required. They never
provided the description I asked for. I wouldn't get the written demand
for another 2 weeks, and it arrived in the form of a subpoena (which I
was later excused from, and as such didn't include in the description
above). While I waited for the FBI to get back to me I began my search
for a lawyer.
Since the following week included July 4th, it ended up taking be about
a week to find a qualified lawyer. She was referred to me by the EFF,
and such understood the relevant statues and case law. It wasn't until I
consulted with her that I understood the PRTT statue only provided the
authority to collect metadata, as the agents implied it provided the
authority to collect everything on the wire. I subsequently read the
statue, and it listed "signalling information" as one of the items they
could collect. Without a lawyer, and based on the FBI agent's
description,  I incorrectly assumed that meant the "signal to noise
ratio," where the signal represents all of the information. When it
became clear that actually was a reference to the DTMF tones sent over a
phone line, and they were only authorized to receive metadata, I did try
to work with them for a solution that would provide a technological
guarantee"they only collected the authorized metadata on the account(s)
authorized by the court.
It's worth noting my custom mail server was probably the only one on the
planet that didn't write out the required metadata to a log file. As
such I proffered several possible solutions, which I can discuss at
length later if anyone is interested. All were rejected. Amongst the
reasons the DoJ came back with were a) they didn't trust me, b) my
estimate for costs if I implemented the logging was unreasonable, and c)
my proposal didn't provide them with real time access. Note I also
discussed a situation whereby they provided the equipment and I
configured it (with there help) and we each held onto half of the
password. While I didn't like the idea because it would be hard to know
if there was a backdoor, it was quickly rejected as well.
Whether you believe the FBI really only wanted metadata probably hinges
on whether you believe a prosecutor would lie in court. It might be
worth noting there was also a search warrant issued for the source code,
the encrypted user data, and the encrypted user keys. Data that was
largely worthless without the user password. All of that said, I can
prove the (now), that the prosecutor made a significant and material
misrepresentation to the court which would have changed things had I
been able to prove it at the time. Since I haven't discussed this
publicly yet, I'll save it for another day. What I have discussed
publicly is how many immaterial misrepresentations the DoJ made about
me. Including my favorite, which insinuated I tried to avoid service by
fleeing out the backdoor of my 5th floor apartment. It was one of two
times I laughed during the whole ordeal. I really wish I could fly, or
crawl on walls, but alas I'm only human.
What Ray is probably referring to is the approximately 48 hours I had
between when I found out my first attorney couldn't represent me in
Virginia the following week (she was based in San Francisco). In that
gap I interviewed a dozen plus lawyers, but didn't find a good match
(cost, knowledge, strategy, etc) in time. I asked for more time, but was
denied. Hence I showed up pro se (if I hadn't they would have sought a
bench warrant for my arrest and dragged me to Virginia in handcuffs). I
was finally able to find an attorney the morning of my hearing, but not
in time for them to make it to court. I hired him that afternoon, and he
had a week to prepare a defense. Notably, he wasn't given transcripts of
my pro se appearance until our appeal was due.
See above, but yes, my desire to consult an attorney led to an instant
order to compel. And yes, I was unwilling to compromise the integrity of
the system, and found it even more abrasive because I wouldn't have been
allowed to tell anyone what happened. Hence the decision to shutdown
after an abbreviated court battle.
Largely true. In an interesting twist, one of the lawyers I consulted
during the 48 hour period is now representing Apple, but I couldn't
afford him, and because of the secrecy, could broadcast a call for help.
That meant even though I was aware of a couple cyber law mailing lists,
I could ask for help pro bono, or seek the money to cover the cost of a
proper defense. The fact that we were only given a week, and my lawyer
wasn't a specialist made things even harder.
Over the last 2.5 years I've certainly gained a _lot_ of knowledge about
the relevant laws which would have been helpful at the time, and will be
if/when I ever relaunch. It's also why I decided to submit the amicus.
I did fight things out in court. It just occurred in secret, and while a
proper description would require the use of vulgarity, I'll summarize by
saying I was railroaded. The length of time between when I received the
PRTT order, and when I was found in contempt (ex parte) was about 5
weeks. For comparison the /median /time between filing and disposition
of a civil contempt charge in federal court during 2013 was 6 /months/.
The contempt charge levied a fine of 5K a day for each day I didn't turn
over the keys. So I shutdown the system and turned over the keys.
Technically I complied after being held in contempt, but because the
system was shut down, prevented them from using (or at least minimized
the damage).
After raising money from the public I appealed the contempt charge. As I
mentioned above the appellate court ignored the question and claimed I
waived my right to the appeal because we didn't object to both of the
legal ground cited in the contempt charge. What they ignore is that the
order they are referring to was issued on a Friday, which read for "the
reasons stated in the governments brief," and I was found in contempt
the following Monday ex parte. Because the government included an
argument in their brief that was never discussed in court, and ran
contrary to comments the judge made in session, the appellate court
claimed we never objected to it. That said, ask yourself, did we even
have time to understand what had just happened, and make the objection?
Even then, my lawyer asked to make an oral objection to the contempt
charge, but was denied. Presto facto, a non-appealable contempt charge
is created.
Like I stated in the beginning, the ruling on waiver means no precedent
was set.
Definitely true. There are a number of ways, albeit difficult, which
would allow them to extract the data if meant that much to the
investigation. What the government wants is a public piece of case law
they can use in the future (in secret) to compel a number of even
nastier things from Apple. Like an OTA update to an encrypted device
which steals the key for your favorite messaging app right out of the
device's memory.
What they sought from me, legally, wouldn't have allowed them to compel
what they want from Apple. But it might have applied to the WhatsApp
case (I haven't read those briefs yet). That said, both cases flow from
the same sense of entitlement. As in, we are entitled to everyone's
plain text data, and if Congress won't give it to us, we'll use our 27.1
billion dollar budget, and army of 100K lawyers to take it in court.
Your tax dollars at work.
They tried. See my statement linked to in the intro.
P.S. I haven't run this email by my lawyers, but I think everything I
said is unsealed and public already.

@_date: 2016-03-17 18:17:46
@_author: Ladar Levison 
@_subject: [Cryptography] DoJ/FBI's "nuclear"/Lavabit option 
For it to be a fair comparison the contempt charge would name Tim Cook
personally, such that even if Apple became insolvent, he'd still have to
pay the fine.
Also noteworthy, while the government did get a search warrant for the
source code, they dropped that request after we indicated we planned to
it, and I had shutdown the service. In other words, why fight for source
code that no longer has value.

@_date: 2016-03-18 19:13:42
@_author: Ladar Levison 
@_subject: [Cryptography] ZDNet: "US government pushed tech firms to hand 
See the attached image for a graph showing the growth in classified
information through FY 2014. The original source for the image, and more
scary statistics:
Or for an older version of the graph (through FY 2011):
Didn't President Obama promised to improve transparency in government
when he was on the campaign trail? Makes you wonder if we can trust his
comments about proper protections for civil liberties in our law
enforcement and intelligence agencies.
I believe his background as a civil rights attorney, and professor of
constitutional law (U of Chicago), gave him the right vocabulary to
assuage the public's fears regarding increasing surveillance use (and
abuse). Whether you believe his promises is a personal decision -
because he certainly hasn't proved the system has adequate protections
in place. That would require letting everyone peek behind the curtain.

@_date: 2016-03-18 19:44:43
@_author: Ladar Levison 
@_subject: [Cryptography] Motherboard article on Lavabit case 
I haven't read the motherboard version yet, but here's the Wired
version. It's mostly accurate, although it leaves off a lot of details.
Like most recounts of the adventure, it doesn't all fit into a story of
1,000 words or less.

@_date: 2016-03-24 18:56:51
@_author: Ladar Levison 
@_subject: [Cryptography] Lavabit's and Snowden's Solos 
Not sure where you're going with these questions but...
Compelled code modification is still a murky area of law. My opinion is
the answer remains no, they can't compel you to make changes, including
disable security "shields." Of course the Apple case will test that, if
it goes forward. That said, they have compelled config changes in the
past. Hushmail enabled a "debug" config setting and used it to steal a
private key during login (at the request of the FBI). Phone companies
have been forced to modify switch settings to allow wiretapping, or
tracing. All of the cases I know of involve config settings, not code
modifications (at least for surveillance purposes). Its worth noting
that there is a body of case law on this topic resulting from FISC
warrants. Of course its classified, which is disturbing, but also means
it can't be cited as a precedent (outside of the FISC).
The impact would depend on the service, and the amount of infrastructure
they have to support the additional load. That said, botnets attack
service providers all the time. If the system is designed correctly, it
should slow things down, but wouldn't knock them offline. Also, if all
your talking about is brute forcing a login, that requires relatively
little processing, even less if the app node already has the information
cached. Your biggest concerns are likely simultaneous connections (async
IO would help with this), and bandwidth.
Typically law enforcement doesn't like to tip off a suspect they're
going after them. So collateral damage that might  provide a tip off
would be avoided. If you mean collateral damage to the service provider,
we'll it's pretty clear they don't care. From where the FBI/DoJ sits,
the stronger the security, the bigger the sledgehammer they'll use.
They've even gone so far as to say its the provider's fault for making
the system secure, so the provider should pay the price of helping them
break in. In other words its Apple (and Lavabit's) fault they can't do
what were asking. It all comes back to the fact that law enforcement
feels "entitled" to the plain text data, and like a trust fund baby,
that sense of entitlement means they don't like it when they can't have
In terms of access, federal law prevents LEOs from masquerading as
suspects, even when they know the person's password. Offline attacks are
a different story. So to make this a valid hypothetical, it would have
to be an intelligence agency, botnet, or foreign organization, assuming
its an American service provider. As always, the goal depends on the actor.
All traffic in/out of a company like Lavabit is relatively easy. The
bigger the infrastructure, the harder it becomes. Multiple uplinks makes
things harder, multiple physical locations makes it even tougher,
especially when you start crossing country borders. As for bandwidth, if
law enforcement can compel the upstream provider to provide access, odds
are they can also compel them to provide bandwidth. That's what the FBI
did to Lavabit. Your also assuming they want to send all the packets
somewhere else. It's far more likely the device will employ filtering
rules, and only send out a subset of the data. Even backbone mirrors do
basic filtering at the source.
