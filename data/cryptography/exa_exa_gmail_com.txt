
@_date: 2014-04-01 09:48:18
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] ideas for (long) Nothing up my sleeve numbers 
My best guess is "Pi and Euler's number to a very high percision", but
Sampo, thanks for a very detailed explanation, this is something I should
probably have read a bit earlier.
OK, to re-state my original requirements:
1. I need N.U.M.S. numbers so that everyone sees I'm not plotting something,
2. I need the numbers to match the specification of what the SYND's cipher
matrices need to look like.
1. gets quite trivial from this perspective. As many people here suggested,
I guess that any well-known irrational number will do. There were also
other "multi-authority decision" strategies (I'm extra grateful for the RFC
someone linked), but I'll leave that for bigger&non-pet projects. :]
2. is harder; lets get to coding theory -- so-called "random codes" (which
we are producing by this) actually have extremely high chance of having the
qualities one needs for SYND (e.g. good minimum distance and so). This
chance is usually measured from a random sample of all codes over F_2^n for
some reasonable n, from that they are called "random" and probably from
that I made the mess with using "random" word more than I should. :D
Therefore, for this purpose, it is sufficient that "there's no
(polynomially) recognizable underlying structure that could be used for
decoding" in the matrices; which has been shown to easily reduce to the
fact that the codes look "uniformly random" (words from the paper).
- generate the N.U.M.S. from everything that has been suggested here
(including bitcoin blockchain :] ),
- run some test for uniform randomness on them (I use 'dieharder' tool for
quicktesting my stuff, are there any better suggestions?)
- run some similar tests for quality of SYND output on those
- choose two best passing entries and use them
So I'm off to statistics. :D
Thanks a lot again,

@_date: 2014-03-08 11:57:05
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] RC4 again (actual security, 
Hello everyone,
I'm not sure that entering this discussion with questions about RC4 (or
Arcfour or how you like it) is generally a good idea, but well, why not.
I've used RC4 quite extensively in one of my projects, for it is a "best
fit" - wonderfully simple, and secure if used correctly. Since that, I have
been experiencing reluctant comments from all sides of users,
cryptographers, programmers and so, all of which had the common "RC4 is
broken, is it not?" part. This opinion is generally supported by all
"first-google" sources that can be found about RC4, led by wikipedia that
has sources that "argue against its use in new systems". That's quite FUD.
I'm usually proving and explaining that fact to everyone quite
successfully, but it's always better if you ask someone else about his
opinion. That is, as you can now probably see, roughly the whole purpose of
this post. If you find any errors in following statements, please report
General statement: There's no effective known attack against reasonable RC4
usage that doesn't use related IVs and discards first 1024 outputs.
All attacks I've been able to find that somehow break traditional RC4 are:
- WEP-like related-key attacks [google rc4 wep]
- newer statistical attacks against random distribution of outputs in first
bytes (for example [1] looks good)
- quite similar attacks against special usage, see [2]
- malleability (which shall not be discussed here as the simple solution
depends only on the strength of hash functions)
Claim: These attacks don't apply if you
- have good IV choices (read more below)
- discard enough of the keystream
- are reasonable and don't output gigatons of your keystreams all around
The "enough" of discarded keystream is usually determined from the amount
of keystream needed for the distinguisher (similarly as in [3]), 1024 is
more than enough for most real purposes.
"Good IV choices" are a bit harder to create. I use RC4 for two main
- CCA2 padding for QD-McEliece usually called Fujisaki-Okamoto padding, the
IV there is completely random for each usage.
- as a traditional cipher for generating keystreams for i=1,2,3.... and
some common shared key. Best approach I've seen so far is to run the RC4's
KSA twice: First time with the shared key, and then with the (somehow
padded) nonce.
- are there any other known attack types that I missed?
- Is running KSA algorithm for "squeezing more data in" reasonable? Clearly
not fo "added security", but possibly for
  * IV scheduling usage, as above
  * big keys from weird key sources (without relying on a hash function to
scale the key data down)
  * other weird RC4 usage (RC4-based hash function etc.)
- Sci-Fi: Modern CPUs are big and have lots of cache. Is there any material
that deals with RC4 that would use 16-bit internal permutation? (65536
16-bit numbers of internal state, key input/output on 16bit words,
everything else the same. Because of large memory requirement (128kB) and
relatively slow initialization phase I guess that it could be a nice
candidate for, say, password crypt()-ing or ASIC-resistant stuff; OTOH,
because byte operations are usually equally fast as 2-byte word operations
on modern CPUs, this could (very theoretically) just increase keystream
generation speed twice).
Thanks for opinions on all this,
[1] [3]

@_date: 2014-03-12 10:12:58
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Thanks for ChaCha20 suggestion, I've been poking around a bit and it
actually seems as the best choice for this case. (I already use DJB's other
product (cubehash) with great results).
I was kindof hoping to see some more RC4 support though, you know :]
with best regards,

@_date: 2014-03-12 10:29:35
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] RC4 again (actual security, 
I have been an ARC4-DROP fan for years.  I wrote the "TinyCrypt"
Great to hear about TinyCrypt :] Mine is called Codecrypt, here
I'm actually not sure if I got the Holloway attack right - from all sides I
seen it it looks just like another statistical attack that can be made
arbitrarily inplausible by increasing the DROP parameter. If I'm wrong,
please correct me.
Just opinions --
I kindof dislike OpenSSL development method (it's not really transparent
and organized enough for the most-used crypto library in the world). But
that's my opinion :]
About Snowden... AFAIK, he implied that there is properly implemented
strong cryptography that is reliable. Rumors have already been around that
"strong cryptography" doesn't include RSA-2048...

@_date: 2014-03-12 10:41:51
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] RC4 again (actual security, 
Thanks for this ^. It's the whole point I'm usually explaining summed up in
one nice paragraph.
Moreover, I consider the simplicity of basic ideas an advantage. From the
point that "there is nothing to hide", roughly referring to the bad
elliptic crypto params we've seen recently. DJB's crypto (including chacha,
cubehash and most others) is remarkably good from this perspective.
I'm actually going to implement chacha20 - it's reasonably simple as well,
and the users will be able to decide whether to use chacha20 (new&shiny) or
rc4 (tested but with somehow bad public reputation).
Thanks for the opinion :]

@_date: 2014-03-12 10:55:41
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] RC4 again (actual security, 
well, okay :]
There are two possible ways to deal with this fact: (1) Keep adding
Good point. Do you know about any symmetric cipher that is _provably_
Only one I know about is SYND that has been proven to reduce to (NP-Hard)
syndrome decoding problem.
I actually have no idea why I have ignored it so far. :D
Thanks for the opinion :]

@_date: 2014-03-12 11:04:43
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] RC4 again (actual security, 
This is a good argument. It's not effective in my case (I was "reasonable"
with the setup and I don't throw many key&plaintext ciphertexts all around
for the statistical attacks to be effective) but it is indeed a serious
vulnerability not fixed by adding more of DROP parameter.
Thanks for pointing this out.

@_date: 2014-03-13 21:22:45
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Count in DJB's excellent work on McEliece (wild Goppa codes) and actually
the whole PQCrypto project (  ) that also gives even
more efficient and secure crypto primitives than those you listed.
It's cool. :]

@_date: 2014-03-15 23:07:58
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] How can I make use of the AES hardware on new 
I would take the easiest opensource approach and look (steal) how the
others do.
For example, OpenSSL does something similar here:
And Intel has a bunch of docs here:
(There's even sample code)
crypto library that already implements this (also with the fallback).
There's also a nice (my personal favourite) article on that:
Hope that helps,

@_date: 2014-03-23 09:42:24
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] BLAKE2: "Harder, Better, Faster, 
increased security.
How? I am sorry but I can't see any cases where this would make any direct
sense; could you please explain or show some?
Otherwise, BLAKE2 really rocks; it's just common standardization pain
that's slowing the adoption.

@_date: 2014-03-30 20:43:14
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] ideas for (long) Nothing up my sleeve numbers 
Hello list,
so I am implementing a variant of XSYND The Provably Secure Stream Cipher
[1] derived from "better known" SYND [2] for my paranoid
quantum-computer-resistant pet project [3].
The problem is that I need a very big amount of provably random constants
for initialization of the content of some internal matrices (A_1 and A_2 in
the paper; only thing that the autors specify about them is that the bits
need to be uniformly random, not secret).
Therefore, the question: What is your favourite idea for a good,
random-enough Nothing Up My Sleeve data with size around 2^14 bits? (e.g.
long, reputable, randomly looking positive integer that is less than
My best guess is "Pi and Euler's number to a very high percision", but that
seems boring.
Thanks for ideas,
end note for those who have read the paper:
I will certainly not use exactly these NUMS to fill up the syndrome
matrices, I instead want to feed them to "preparation" phase that will run
XSYND with NUMS and supplied key+IV several times to generate the contents
of new A_i matrices that will be used to generate the actual keystream.
Or should I use some simpler key expansion function, even when XSYND is
there already a key expansion function?
Or did I get it completely wrong?
[2] [3]

@_date: 2014-05-08 10:24:23
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] Cryptography topic for Research Paper 
Actually, I'm honestly afraid that there aren't any practical quantum
computers in India as well as in any other country. State-of-art quantum
computers are able, AFAIK, to compute that 21=3*7 and solve some limited
linear-optimization stuff, and not much else; moreover, quantum setup for
actual quantum-cryptographical bit transmission is going to require
something a lot different than quantum computer.
In short, if you want to get practical with this research, it's going to
get tremendously expensive.
qubits in a quantum computer and the time taken to crack today?s encryption
That's a good point, and a very useful one -- while quantum stuff is
expensive and probably isn't going to get into common usage anytime soon,
there is strong fear that anyone who builds first capable-enough quantum
computer will "just be able to break anything". Someone called this fear
"post-quantum cryptography" and there's a good amount of research already
done that way.
DJB's website is a good starting point: Any theoretical work that would provide assurance that quantum computers
really can't break the post-quantum cryptosystem varieties (MQE, McEliece,
Hashes, NTRU) would be really cool. There could be also questions whether
(some) current symmetric ciphers are quantum resistant - everyone assumes
they generally are, but I've seen no actual results in that way.
Well, I hope this helps you with your choice.
With regards,

@_date: 2014-05-17 14:29:21
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] Are there other anonymous key exchange algorithms? 
Hello list,
so there has recently been a discussion about solving some previously
unsolvable examples of discrete logarithm on slashdot [1] (not
particularly harmful for cryptography though), which mostly made me to
finally ask about this.
The big question:
Is there any other anonymous key exchange algorithm than Diffie-Hellman?
Or any other good method (preferably post-quantum) that would allow
perfect forward secrecy without D-H?
Thanks in advance,
[1]

@_date: 2014-05-18 10:03:27
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] Are there other anonymous key exchange 
To sum up what you provided, generic PFS protocol could look like this:
1- both endpoints each generate a keypair and send the pubkey to the
other endpoint
2- both endpoints generate random string r, encrypt with other
endpoint's pubkey and send it
3- shared secret is hash(r1+r2).   (with no big cryptographic
requirements on the hash -- XOR is perfectly possible)
4- both endpoints make sure that privkeys get erased asap
For usage in realtime TLS or similar protocol, problems reside in step
1, generating the keypairs is usually a bit slow for realtime usage
(~200ms in my case for McE-QD, but it  can get much worse). Would
there be any serious security implications on reusing the same key in
more exchanges and having some efficient key schedule? For example,
only generating new key every minute or similar.
Post-quantum pubkeys also tend to be a bit large (around 4kB in my
case, but megabytes for generic McE and more kBs for NTRU etc.) but I
guess that isn't a really big deal - it still fits in a few packets.

@_date: 2014-05-19 20:41:58
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] Another crypto paper in the wrong place 
Just a very quick question, what methodology or tools do you use to
estimate min-entropy from such data?
Thanks :]

@_date: 2014-09-15 12:17:08
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] List of Proven Secure Ciphers / Hashes 
I'll completely ignore the discussion about P?NP that spawned here and get
Note that many cryptography problems are NP, but not NP-Hard, as reduction
of a thing that behaves "as weirdly as possible" to something that would
solve turing machine is usually a challenge. Still, NP-Hard (and therefore
NP-C) cryptography problems exist, and are usually called "provably secure"
for this. For me, this is the strongest "security proof" I'm able to
(sanely) imagine, so I'm going with it.
My favorite is SYND/XSYND which is a (symmetric) stream cipher proven NP-C.
SYND has security reduction to general Syndrome Decoding problem (SD is
known to be NP-Hard). Almost the same reduction applies to general McEliece
asymmetric cryptography. Even some fast non-general McE systems are proven
NP-Hard, for example the Qausi-Dyadic variant.
slides here, there is also a paper I can't find now:
I'm not sure whether the same thing can be applied to hash functions,
there's FSB hash based on the hardness of the same assumption (SD), but I'm
not sure whether similar security proof would be effective there, given the
limited size of "input" - at least there were some problems that removed
the original FSB from the first round of Sha-3. :D
Anyway, for the other folks here - I always wanted to ask - can RSA be
reduced to some at-least-pretty-hard complexity class?

@_date: 2015-11-17 18:41:36
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
I agree with you that there should not be restrictions on encryption.
Still, the problem is elsewhere -- we simply should not encrypt _that_
much. (also applies to your car analogy, btw).
To explain: Common people with reasonable operating systems/browsers
are now using bulk encryption on every single HTTP request they make,
on every single disk block they have, making SPF handshake with each
person they IM, etc.. Observe that only a really tiny amount of the
data is actually confidental (login tokens, business data, ...). Think
about what bulk encryption means for the consumption of computing
power (RSA ain't free, I'd actually expect more than gigawatts). Think
about what it means for law-enforcement agencies -- they can't even
simply prove that given single user is _not_ a suspect to narrow their
search. No wonder that a politician who was assigned the task to keep
the society secure&thriving would actually hate any kind of
encryption. And that is a problem, because the simplest thing he can
do is a ban.
I'd prefer something less drastic before the ban comes, like forcing
the user/software selectively choose (by some smart API or a correctly
designed UI) what to encrypt, leaving the rest (most) of data
"ecologic" and "law-enforcement friendly".
PS. In no way I suggest simply "turning SSL off", but there could be a
way that just authenticates the data without doing encryption. Method
for easily marking the "secret bits" of the stream would be cool as
PS2. In no way I suggest surrendering all our information to orwellian
big brother, but well, think of the good cops.

@_date: 2015-11-26 16:00:15
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] Security of a permute-only system? 
I was considering similar scheme some time ago. Good idea is that key
expansion to permutation is actually computable in linear-time [1]. Bad
problem is the "whiteness". I only considered a scheme where you expand any
bit string to a string with exactly 1:1 amount of ones and zeroes (that is
achievable in decent time with colex ranking/unranking, e.g. my
implementation [2]), but that is fully breakable when an attacker has a
chance to see results of n*log(n) chosen encryptions with your key. Schema
is like this, for n=8:
you encrypt 00001111
then 00110011
then 01010101
get all the ciphertexts, AND them together, and you know the position of
permuted last bit. Repeat for all other bits.
If the inputs to the permutations were hard for attacker to modify, the
scheme would be secure. Similar scheme was (successfully) applied to
original McEliece scheme - secret permutation P was used to hide the
structure of the generator matrix.
Certainly some whitening could help the situation, but I'm not sure whether
there is some decent algorithm for reversible unranking of string to
whitened counterparts. One of the simplest methods is again found in
McEliece, namely the matrix S that is used for the exactly same purpose
(whitening the input). But that is a bit hardcore for our purpose (S can
"swallow" the permutation functionality anyway).
There is probably a simpler approach - you can pad the original input with
a simple hash of the plaintext, which (after colex unranking) effectively
prohibits any fixed ones/zeros in the permutation input:
encrypt(m,k) = rank_colex( permute( unrank_perm(k), unrank_colex(m |
hash(m)) ) )
It certainly needs some more research.
Hope this helped a bit.
[1] Mares - Linear-time ranking of permutations
[2]

@_date: 2015-10-06 20:12:21
@_author: Miroslav Kratochvil 
@_subject: [Cryptography] Future GPG/PGP 
I have (some time ago) initiated the codecrypt, only with post-quantum
cryptography and some simplifications so I didn't have to implement
the PGP-compatible protocolar stuff (which are pretty brutal for folks
here I guess).
I also plan to implement the SPHINCS signatures to make it more
compatible with traditional usage of signatures.
Overall it's usuable and (to the best of my knowledge) pretty secure,
but I'd really like to hear a comment from anyone who understands PGP
and -- well -- can see all the mistakes I did.
