
@_date: 2010-08-17 11:46:54
@_author: Steve Weis 
@_subject: Haystack 
I sent an email asking for technical information several months ago
and did not receive a response. The FAQ says "the Haystack client
connects to our servers which in turn talk to websites on behalf of
our users" and "from a user's point of view, Haystack appears to be a
normal HTTP proxy". There is no binary or source available for
download and the FAQ says "revealing the source code at this time
would only aide the authorities in blocking Haystack".
Based on those statements, I'm going to speculate that the client
connects to a static list of innocuous-looking proxies and that they
are relying on keeping those proxies secret. If those servers were
known to an authority, it would be trivial to block. I think that is
why they're making the unrealistic assumption that an authority will
not be able to reverse engineer or even monitor traffic from a client.

@_date: 2010-08-18 07:57:14
@_author: Steve Weis 
@_subject: Haystack 
I emailed the author Austin Heap again yesterday to ask for some
technical details. He responded and declined to provide any
At this point, I have seen no evidence that Haystack exists.

@_date: 2010-09-14 09:57:05
@_author: Steve Weis 
@_subject: Haystack redux 
There have been significant developments around Haystack since the
last message on this thread. Jacob Applebaum obtained a copy and found
serious vulnerabilities that could put its users at risk. He convinced
Haystack to immediately suspend operations. The developer of Haystack,
Daniel Colascione, has subsequently resigned from the project.
Many claims made about Haystack's security and usage made by its
creators now appear to be inaccurate. These claims were repeated
without verification by the New York Times, Newsweek, the BBC, and the
Guardian UK. Evegeny Morozov wrote several blog posts covering this.
His latest post is here:

@_date: 2013-12-13 10:59:17
@_author: Steve Weis 
@_subject: [Cryptography] An alternative electro-mechanical entropy source 
A few comments:
1. You aren't trusting the CPU to generate random numbers, but you're
trusting the motherboard and chipset that your proposed RNG device is
plugged into. You're also ultimately still trusting the CPU which is
consuming those values.
2. How does a CPU authenticate that it's talking to a real, audited
RNG device and not a spoofed device?
3. I think an accelerometer measuring vibrations could be influenced
by the CPU fans, which can be influenced by attackers running userland
If you try to address these issues, I think you'll end up with
something that looks like a TPM: a cheap device plugged into a bus
with a slow RNG, persistent storage, & crypto functionality that is
supposedly made by a trusted manufacturer.

@_date: 2013-12-22 13:50:02
@_author: Steve Weis 
@_subject: [Cryptography] BitCoin Question - This may not be the best 
Bitcoin addresses are hashes of ECDSA key pairs:
If by "burning up" addresses you mean generating every key pair and
storing it, that's not going to be feasible since Bitcoin uses
Secp256k1 with 256-bit private keys.

@_date: 2013-12-22 17:59:36
@_author: Steve Weis 
@_subject: [Cryptography] BitCoin Question - This may not be the best 
The address has 20-bytes of hash, a network ID byte prefix, and a
4-byte checksum. So, there are 2^160 possible unique addresses. This
is converted into a 34 character base-58 string.
You do bring up one point that many key pairs will collide for a
particular address. That's why the hash function must be assumed to be
collision resistant.
As for when we might see collisions, with a birthday attack you'd
expect there to be a 50% chance of some collision existing when there
are roughly 2^80 addresses.

@_date: 2013-11-12 09:55:01
@_author: Steve Weis 
@_subject: [Cryptography] [cryptography] Practical Threshold Signatures 
Hi. I wrote a Java implementation of Shoup's threshold signature scheme a
long time ago:
I haven't touched it for years and wrote it as an undergrad, so caveat
emptor. Happy to give commit rights to the Google code project if you're

@_date: 2013-11-12 13:12:05
@_author: Steve Weis 
@_subject: [Cryptography] Looking for feedback on new Java crypto library 
Hi James. Have you checked out Keyczar? It has similar goals and Google has
been maintaining it for use in some Android libraries:
One main difference I see on quick inspection is that JACS uses InputStream
and OutputStream interfaces and derives keys from user-entered passwords.
Keyczar works on ByteBuffers, byte[], and String inputs, and handles key
versioning and rotation. Plus, it has been ported to Python and C++.

@_date: 2013-11-13 16:13:40
@_author: Steve Weis 
@_subject: [Cryptography] Looking for feedback on new Java crypto library 
(This was originally bounced for being a top post.)
Hi Max. Keyczar runs above a Java crypto provider; it doesn't replace
it. You can use Bouncy Castle as the underlying provider if you
prefer. Keyczar does use the JCE by default, though.
The goal is to abstract the Java crypto provider interface and use it
safely by default, which us similar to James' JACS.

@_date: 2013-11-15 11:00:53
@_author: Steve Weis 
@_subject: [Cryptography] programable computers inside our computers (was: 
Was there a question that remote attestation would be removed from TPM
2.0? I assumed it would continue to be included, but perhaps I'm
Remote attestation works on TPM 1.2 with TXT as you describe. You can
bring up a remote host and measure the BIOS, OptROMS, SINIT, MLE,
kernel, boot parameters, initrd, etc.
We have this working in practice on some dedicated hosting providers.
There are some security caveats and vendor-specific nits, though.

@_date: 2014-08-11 17:46:20
@_author: Steve Weis 
@_subject: [Cryptography] Matasano Crypto Challenges 
Matasano Security posted 6 sets of their crypto challenges online:
The challenges start with basics and move through a variety of attacks.
It's a great learning tool as they've provided solutions implemented in 10
different programming languages.

@_date: 2014-08-17 12:13:12
@_author: Steve Weis 
@_subject: [Cryptography] Encryption opinion 
depends on
The goTenna use case is a consumer-targeted antenna device. My concern is
that the responses in this thread are primarily focused on key length and
algorithms, and do not address any of the more realistic threats you'd see
against a consumer hardware device. Just saying "we use RSA-2048" or
"AES-256" is a red flag.
Regardless, RSA-512 is easily factorable by an individual. For example,
Zachary Harris factored Google's RSA-512 DKIM key for fun two years ago,
which precipitated major sites upgrading their DKIM keys:
Secondly, the use case isn't even feasible with the settings goTenna
describes. The original message in this thread says "we felt like 1024RSA
for a 160 character text message...". A SMS message with 160 7-bit
characters will not even fit in an unpadded RSA-1024 payload, much less
with proper padding or in a smaller ECC payload.
It's also unclear whether they're talking about using unpadded raw RSA to
encrypt SMS messages. Unpadded RSA is deterministic, not semantically
secure, and implementations are often vulnerable to message recovery

@_date: 2014-01-22 13:29:38
@_author: Steve Weis 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
Comments below..
This attack doesn't apply to standard signature algorithms, which sign
hash digests. It also assumes you use the same RSA key for signing and
encryption, which is an unsafe practice for this very reason.
I think signing ciphertexts is generally a best practice, and
certainly not a "mortal sin".

@_date: 2014-01-22 17:13:20
@_author: Steve Weis 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
Like I said, I think encrypt-then-sign is generally a best practice
for both symmetric and public-key crypto. There are some exceptions,
but I've mainly seen those motivated by performance or legacy issues.
The relay attack you describe implies a naive verifier that doesn't
check whose key signed a message. It means the verifier accepts any
well-formed signature, regardless of the key that signed it. That
seems to defeat the purpose of signing it in the first place. If
that's the case, I don't think the proposed solution to encrypt again
actually helps.

@_date: 2014-06-08 18:54:53
@_author: Steve Weis 
@_subject: [Cryptography] Aggregate signatures 
Hi. First off, the paper you linked to is a student's final semester
project. I don't know how solid it is. You may want to check out the
Boneh, Lynn, Gentry & Shacham aggregate signature scheme from:
There is an unrestricted version proven secure by Bellare, Namprempre
and Neven here: To my knowledge, none of this is standardized. As for library support,
the Relic Toolkit from Diego F. Aranha may have the support you'd
need, although I haven't looked at it closely:
Ben Lynn's PBC library also offers similar support, but I've been told
that Relic is more modern and better maintained:
I don't know of anyone using these in production or real world
applications, but would be interested in hearing about any examples. I
do know there has been some interest from the Bitcoin community in
aggregate signatures that are fast to verify.

@_date: 2014-06-17 15:07:05
@_author: Steve Weis 
@_subject: [Cryptography] Implementing constant-time string comparison 
Comments inline...
I had not considered the (d == 0) comparison as potential timing leak,
but think there is probably a good reason NaCl is using it.
I can see it would be a problem if there weren't a comparison
instruction of sufficient width, or if the compiler/interpreter did
not use it, or if that instruction itself might not be constant time.
My guess is that the first case is the issue motivating this. I'll
find out though.
Incidentally, it looks like Go implements a constant-time int
comparison function as well:

@_date: 2014-06-22 08:34:54
@_author: Steve Weis 
@_subject: [Cryptography] Nominate crypto projects that don't suck 
Hi everyone. I've started compiling a list of crypto projects that
aren't known to have major issues... that is, that don't outright
suck. The scope is broad and open to research projects, libraries, or
applications at any stage of development.
My goal is to both learn about new projects and to get an update on
the status of existing projects. I plan to summarize the results into
a blog post and am likely put together a short talk. I'll post a link
on this list when it's available.
Please submit your nominations here:
Don't worry about resubmitting duplicate links.

@_date: 2014-06-23 08:14:47
@_author: Steve Weis 
@_subject: [Cryptography] Nominate crypto projects that don't suck 
Hi. Submit whatever you'd like. I'll deal with sorting out duplicates and junk.

@_date: 2014-03-10 12:12:30
@_author: Steve Weis 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
When it comes to Intel's Haswell CPUs, AES-GCM is twice as fast as
ChaCha20. DJB's performance numbers show ChaCha20 running at 2.78
cycles / byte: Shay Gueron claims that OpenSSL's AES128-GCM implementation on Haswell
runs at 1.03 cycles / byte and that AES256-GCM runs at 1.31 cycles /
byte. For older Ivy Bridge and Sandy Bridge systems, AES-GCM runs
roughly 2.55-2.87 cycles / byte, depending on the key size:
Just to put it in perspective, the latest E3v3 Haswell CPUs run with 4
cores at up to 3.6 GHz. If I did my arithmetic correctly, that's up to
encrypting 28.51 Gbps per core.

@_date: 2014-03-11 20:03:21
@_author: Steve Weis 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Do you have CCM performance numbers to share? Or do you have GCM
performance numbers for ARM?
Krovetz and Rogaway show CCM as slightly slower than GCM on x86, ARM,
and PowerPC: For x86, this paper predates some of Shay Gueron's GCM optimizations
which are checked into OpenSSL and the PCLMULQDQ instruction in
Haswell. GCM is now running at ~1 cycle / byte.
Just out of curiosity, I ran OpenSSL speed from commit
44f7e399d342f0fbb90be023c2b9828a866fc8d1 to compare GCM, CCM, and
CBC-HMAC-SHA1 on an Intel i7-3770 @ 3.40GHz. "The 'numbers' are in
1000s of bytes per second processed."
$ ./openssl speed -evp aes-128-gcm
type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes
aes-128-gcm     383145.66k  1001505.22k  1385985.37k  1498142.38k  1527376.55k
$ ./openssl speed -evp aes-128-cbc-hmac-sha1
type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes
aes-128-cbc-hmac-sha1   278307.04k   371995.39k   561519.27k
663274.15k   699250.01k
$ ./openssl speed -evp aes-128-ccm
type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes
aes-128-ccm     532831.23k  2140334.77k  8531998.12k 34132725.42k 273049384.28k
If I'm reading it correctly, that says it's CCM encrypting 273 GB /
second on a single core. That would be clearly wrong and I'm guessing
it's an OpenSSL 'speed' bug.

@_date: 2014-05-02 16:13:52
@_author: Steve Weis 
@_subject: [Cryptography] One third IT managers think homomorphic is 
I only watched the video, but it doesn't mention anything at all about
homomorphic encryption. I suspect most of the self-reported people using
"encryption in the cloud" simply encrypt locally and store ciphertext
remotely. That would include using products like CipherCloud, Perspecsys,
Porticor, Tarsnap, Boxcryptor, Spideroak, Sookasa, and many others.

@_date: 2014-05-09 16:18:41
@_author: Steve Weis 
@_subject: [Cryptography] How to lock registers with GCC? 
Tresor uses this approach for the Linux kernel and keeps keys in debug
This only protects against passive memory extraction attacks, like
cold boot. It does not help if an active attacker can modify memory.

@_date: 2014-05-27 14:48:05
@_author: Steve Weis 
@_subject: [Cryptography] client certificates ... as opposed to password 
Just as an anecdote, MIT has been using client certificates to
authorize access to web pages since the 90s:
They either officially or unofficially support most major browsers and
platforms. The exceptions I see are Opera, Windows Phones, and
Incidentally, I ran across MIT's web single sign-on system called
Touchstone, which apparently can support federated certificate-based
logins from other organizations: In general, initial setup per device for client-side certs is still a
pain, as is maintaining support across many different platforms and
browsers. That's why I think client-side certificates have really only
worked for organizations with closed sets of users and full-time
support staffs.
However, for mobile apps, client-side certs might work well if they
were generated upon installation, without any user interaction. For
example, Twitter's app is generating a client-side keypair for login
verification, which is somewhat acting like a client-side certificate:

@_date: 2014-11-20 09:01:20
@_author: Steve Weis 
@_subject: [Cryptography] Where should I start with cryptography? 
Hi Juan. There is a set of crypto coding exercises called Cryptopals
from Matasano Security that start from the basics:
I like the approach to teaching crypto by first breaking bad crypto.
Some of the exercises are based on mistakes people make in the real
world all the time. They have solutions to everything in C++ and
should be adding solutions in other languages over time. One note,
these challenges do become progressively harder. The final set is
implementing attacks that were only published a few years ago.
I also taught a mini course several years ago with videos and a few
exercises online. It is very basic and doesn't compare to other
courses online like Dan Boneh's: Looking at open source projects is also a good way to learn. I wrote
up a list of crypto projects that "might not suck", which includes
some projects you can learn from:

@_date: 2015-08-31 09:34:06
@_author: Steve Weis 
@_subject: [Cryptography] NSA looking for quantum-computing resistant 
Here's a good summary on post-quantum crypto:
I am not losing sleep over quantum computing, but it's prudent to have
some standards to fall back on. Academia has been having conferences
on post-quantum crypto ( for 10 years, so the NSA
is not saying anything new or scary.
In terms of impact, large quantum computers will break public key
factoring-based cryptography (e.g. RSA), discrete logarithm-based
crypto (e.g. DSA), and elliptic curve crypto. Symmetric key algorithms
aren't directly broken, but may require doubling the key length to
maintain the same level of security.
Cryptosystems based on lattices, codes, hash functions, and
multivariate quadratic equations are not expected to be impacted. The
PQ Crypto conference is talking about defining standards for
cryptosystems based on these primitives.
As far as I know, the record for factoring with Shor's algorithm is
the number 21. Larger numbers have been factored (like 143 or 56,153),
but they are special forms and not relevant to RSA keys.
As a side note, D-Wave is talking about 1000-qubit adiabatic quantum
computers. I don't think that is at all relevant to running Shor's
algorithm or crypto.

@_date: 2015-07-28 13:54:30
@_author: Steve Weis 
@_subject: [Cryptography] Graphs for asymmetric crypto? 
Do you have specific graph-based schemes in mind? Or are you asking about
graphs in crypto in general?
I've seen a paper about cryptosystems from isogeny graphs of supersingular
elliptic curves ( but have not read
it. The main advantage compared to RSA and ECC is that it's supposed to be
post-quantum. I don't know of any implementation or adoption.
There also has been work on building hash functions from expander graphs.
That doesn't seem relevant to your question.

@_date: 2015-03-04 10:44:48
@_author: Steve Weis 
@_subject: [Cryptography] practical verifiable systems -- forensic and 
The process you are describing sounds like Secure Boot / Verified Boot /
Boot Guard.
When it comes to measured boots with Trusted Execution (TXT), the lack of
visibility into the BIOS is a big gap because of SMM. You can detect when
the BIOS has changed, but don't know that the SMM loaded by BIOS is
actually good.
I've talked to some platform vendors about this issue. Nobody has been able
to provide:
- A list of known BIOS measurements. A couple vendors mentioned NIST
800-155, but hadn't done anything.
- BIOS source access. One vendor said that the only people they provided
BIOS source access to were the US DoD and that was after a very long
negotiation. This is probably a non-starter.
- A SMM Transfer Montior implementation. Only one person I've spoken with
knew of an actual STM implementation, which was only for client systems
used by, again, the US DoD.
Some of the challenges I've run into:
- Platform vendors don't write their own BIOSes. They may get binary blobs
from one or more outside vendors. No single vendor seems to know what is
going on.
- SMM in server systems may actually provide complex functionality (e.g.
power management, memory hot swapping, etc). Implementing a meaningful STM
may not be possible without crippling that functionality. That's why the
only working STM is for more simple client systems which don't do much in
- One platform vendor's BIOS measurement is different on each individual
machine. This is bizarre, makes the measurement worthless, and acts
effectively as a unique machine identifier. The good news is they are
fixing the issue.
I like Coreboot but support is still pretty limited.

@_date: 2015-03-05 12:16:19
@_author: Steve Weis 
@_subject: [Cryptography] practical verifiable systems -- forensic and 
Yes, this is a very good point. Something like Intel's Management Engine is
embedded in the chipset and cannot be removed or disabled. It's unclear to
me if VT-d offers any protection -- it should in theory, but I don't know
if it does in practice.
Invisible Things Labs presented some exploits against vPro at Blackhat in
2009, so exploiting these LOM systems has been in the grasp of a couple
independent researchers for years:
My experience with LOM systems in practice is that they are garbage and
barely do their intended job, much less do it securely.

@_date: 2015-03-27 10:00:28
@_author: Steve Weis 
@_subject: [Cryptography] D-Wave, RSA, and DLP 
You should read the Dattani & Bryans paper:
They can only factor numbers that have a special form where the factors
differ in a limited number of bits. As the paper says "unless we know in
advance that the factors will differ at two bits, this reduction will not
allow us to crack big RSA codes".
That's how they are able to succinctly represent a 16-bit number if
4-qubits. I think they're encoding the two indices of the bit differences.
The probability of an RSA moduli having this property is exponentially
small. I see no practical consequence to RSA, DLP, or ECC security.
When it comes to D-Wave, it's still debatable whether it's benefiting from
any quantum effects or is even a good at solving the problems it is
designed for. I don't know the area well enough to comment and we will not
come to any conclusion on this mailing list.

@_date: 2015-05-18 13:26:45
@_author: Steve Weis 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
I think SGX is one of the most significant new security architecture
features from Intel. I'm looking forward to experimenting with it as a
defensive tool.
For those who aren't familiar with SGX, see the links below. Some pros and
cons that I see:
+ You can run code in a "secure enclave" that is not accessible from either
ring-0 code or SMM.
+ Secure enclaves are backed by physically encrypted memory, and thus not
exposed to cold boot attacks or non-volatile RAM.
+ Enclaves should be remotely attestable with CPU-bound public keys using
anonymized or pseudonymized signatures.
- Enclaves are limited in size; I think 128MB initially.
- Enclaves are user-land code only.
I expect adoption will be slow since there needs to be support in build
tools, the kernel, and around enclave management. There are also limited
applications since it's user mode only, but performing cryptographic
operations is a nice use case.
That is one of the reasons there are concerns about SGX enclaves being used
for DRM (see [2]). I think the flip side is the potential as a
privacy-preserving technology. You could run your own code on leased
hardware without the service provider being able to see what it is doing.

@_date: 2015-05-19 08:08:16
@_author: Steve Weis 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
Palladium's "curtained memory" is similar in concept to SGX secure
enclaves. However, to my knowledge, the Palladium vision of curtained
memory was never implemented. My guess is that they wanted something like
SGX in the architecture, but ended up with TPMs as a compromise.
I think there were proposals to run trusted applications inside the TPM,
similar to a smart card applications. I don't know of any TPM functionality
that would support that. I've also seen the phrase "memory curtaining"
applied to VT-d and IOMMU, which I don't think is what Palladium originally
Another key difference is that SGX is running on encrypted memory. That
didn't make as much sense in 1997, but today you have three differences: 1)
Fast hardware crypto support in the architecture 2) The cloud: people
running on servers they don't physically own 3) Likely adoption of
non-volatile RAM in coming years.
In terms of your Lenovo concern: SGX is user-mode only. If you control the
kernel, you can kill enclaves. Enclaves can't hide from the kernel like
SMM. This does mean compromised kernel code can deny service to your
enclaves though.
Incidentally, Apple's iOS secure enclave is not SGX, but I see some
similarities: backed by encrypted memory, attested, hardware-backed keys,
used for cryptographic operations, etc. See:

@_date: 2015-05-19 10:13:11
@_author: Steve Weis 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
SGX is implemented through hardware mechanisms, not through cryptography or
anything with a mathematical proof that would satisfy you. Yes, you do need
to trust Intel to implement it correctly and yes, Intel certainly ships
hardware with hundreds of errata.
You want a mathematical proof that a physical attack against hardware is
impossible? Or that memory is actually being encrypted as advertised? The
latter is easy to verify.
The closest model I can think of is physically observable cryptography:
EPID paper is here: I doubt that will satisfy you.
If Intel can't provide sound & complete & public proofs for their wet
You seem to be asking for formal proofs of both the correctness of the
architecture design and that a hardware implementation properly embodies
the design. I can't think of any hardware which would satisfy your criteria.
DARPA's TRUST and CRASH programs may be of interest:

@_date: 2015-09-01 08:42:14
@_author: Steve Weis 
@_subject: [Cryptography] [FORGED] Re: NSA looking for quantum-computing 
This is the claim of factoring 21:
I recently put my reputation on the line by predicting that by 2030,
we will have factored 35.
Meanwhile, the state of the art in dog factoring has progressed
rapidly. My neighbor's dog successfully factored 41707 last night.

@_date: 2015-09-01 15:01:52
@_author: Steve Weis 
@_subject: [Cryptography] mode of operation for file encryption 
Making up your own mode is not a good idea. Your made-up mode leaks
information in a Chosen-Plaintext attack to someone who can predict
block indices. Don't use it.
On x86 platforms, AES-GCM is very fast and library support is widely
available. It will certainly not be a bottleneck for a network-backed
virtual filesystem. I would just use GCM.

@_date: 2015-09-01 21:56:11
@_author: Steve Weis 
@_subject: [Cryptography] mode of operation for file encryption 
Your made-up mode is: C = AES-ECB(k, P xor IV xor BlockIndex)
If (P_i xor i) = (P_j xor j), then C_i = C_j. If someone sees any
identical output blocks, they learn (P_i xor P_j) = (i xor j). That's
information about the plaintext.
If you don't see any identical blocks of output, you also learn that
no pairs of plaintext satisfy that relationship. Again, that's
information about the plaintext.

@_date: 2015-09-02 09:51:24
@_author: Steve Weis 
@_subject: [Cryptography] NSA looking for quantum-computing resistant 
This is the paper "Quantum factorization of 56153 with only 4 qubits":
The authors rely on the factors of 56153 only differing in two
different bit positions (233 = 0b11101001, 241 = 0b11110001). They can
only factor composites with that special form (e.g. 143, 3599, 11663).
As the authors say in the paper: "[U]nless we know in advance that the
factors will differ at two bits, this reduction will not allow us to
crack big RSA codes." They also acknowledge that this "can easily be
solved by a classical computer, since there are only 4 variables".
As far as I know, the record of factoring with Shor's algorithm is 21
and described in this paper:
Here's a poster of their results:
