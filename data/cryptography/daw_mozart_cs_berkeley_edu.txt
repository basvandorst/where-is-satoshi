
@_date: 2001-10-01 23:22:40
@_author: David Wagner 
@_subject: Best practices/HOWTO for key storage in small office/home 
What are your security goals?  Do you want to prevent key leakage,
or merely detect if it happens?  What is your threat model?  Are you
dealing with very sophisticated adversaries, or merely "the maid
casually snoops through the wastebasket"?
For many home offices, I would imagine that the main threat is attack
via the Internet, and for that you don't really need much in the way
of physical objects.

@_date: 2001-10-14 00:35:37
@_author: David Wagner 
@_subject: Computer Security Division Activities 
I think this is a poor example.  I expect you'd be welcome to use the
name 'John Smith' and pay cash, if you like.
I think the real point is this: We see, all too often, cases where it is
claimed that sacrifices of civil liberties are necessary for security,
yet upon closer inspection one gets the impression that those sacrifices
may not provide any security benefits at all.  Identification requirements
may be a good example of this: if teenagers have no problems obtaining
fake ID, what can we conclude about a terrorist operation?
In a perfect world, we'd only sacrifice civil liberties when there is
sufficient benefit to security.  In the real world, though, it seems
that often there is great pressure to "do something" visible, even if
what you do doesn't have any true security value.  It is not too hard to
find many examples of "security mechanisms" that improve the perception
of security (i.e., give warm fuzzy feelings to the uninformed) but which
actually contribute very little to real security.  Think of those photo
ID requirements when you fly, for example -- I have yet to hear anyone
articulate how they help prevent terrorism (as opposed to improving the
airlines' bottom line or reassuring the public).  While such measures may
be politically attractive and perhaps even defensible in some situations,
they bring many risks with them, and I do think we need to be careful
about how we employ them.
As for Gilmore's specific example, I do not take a strong position in
either direction.  However, whatever you think about the specific notion
of a new short-term ad-hoc ID requirement for NIST workshops, I think
his general point has considerable merit that we should not overlook.

@_date: 2001-10-16 00:09:10
@_author: David Wagner 
@_subject: Scarfo "keylogger", PGP 
It seems the FBI hopes the law will make a distinction between software
that talks directly to the modem and software that doesn't.  They note
that PGP falls into the latter category, and thus -- they argue -- they
should be permitted to snoop on PGP without needing a wiretap warrant.
However, if you're using PGP to encrypt email before sending, this
reasoning sounds a little hard to swallow.  It's hard to see how such a
use of PGP could be differentiated from use of a mail client; neither
of them talk directly to the modem, but both are indirectly a part of
the communications path.  Maybe there's something I'm missing.
If you're using PGP to encrypt stored data only, though, then I can
see how one might be able to make a case that use of PGP should be
distinguished from use of a mail client.
Does anyone know what PGP was used for in this case?  Was it used only
for encrypting stored data, or was it also used from time to time for
encrypting communications?

@_date: 2001-09-20 20:49:43
@_author: David Wagner 
@_subject: chip-level randomness? 
Just like von Neumann's unbiasing procedure, but with a few bits of
state instead of just one.  See Paul Kocher's analysis for the details.
In short, the whitening is only enough to reduce any biases in the raw
generator, not to remove them.

@_date: 2001-10-01 03:12:31
@_author: David Wagner 
@_subject: New encryption technology closes WLAN security loopholes 
============================== START ==============================
IPsec is pretty much independent of how the bits are transmitted,
and there are a number of good references on IPsec.  Are there any
802.11-specific issues I'm overlooking that the usual places don't cover?
[Moderator's note: No. IMHO, users want to set up their tunnels
between their laptops and a firewall located immediately behind the
base station. --Perry]

@_date: 2002-08-03 20:35:59
@_author: David Wagner 
@_subject: [SIMSOFT] Protecting Privacy with Translucent Databases 
[ proposes a solution ]
I'm glad commentators are beginning to point out that
more care should be put into protected personal information.
However, solution proposed in this article seems to me to
be more complicated than necessary.
I can't find any legitimate reason why colleges should need your
SSN when deciding whether to admit you.  They get away with it because
they can, but that doesn't mean they are right to do so.
It seems to me that a much more privacy-friendly solution would be
to simply refrain from asking for sensitive personal information like
SSN and date of birth -- name and a random unique identifier printed
on the application form ought to suffice.  (If SSN is later needed
for financial aid purposes, it could be requested after the student
decides to matriculate.)
Am I missing anything?

@_date: 2002-08-04 19:02:17
@_author: David Wagner 
@_subject: Extracting unifrom randomness from noisy source 
Don't use this -- it is broken.
There is an attack: an adversary can distinguish your "pseudorandom"
outputs from a true random source, simply by decrypting the candidate
output under the public AES key and testing whether the result appears
like it could have come from the noise distribution.  If the distribution
of noise is fairly sparse, the attacker can always recognize outputs of
your construction as not truly random.  To me, this suffices to call your
scheme insecure.  (Note that the warranty on pseudorandomness becomes
null and void when the key is publicly known, so the fact that AES is
a PRF when the key is secret seems irrelevant here.)
Observe that simply applying SHA1 to the noise source does not succumb to
this sort of attack.  I believe using SHA1 is superior to your method, and
I believe "use SHA1" is still the correct advice to give to practitioners,
despite the theoretical difficulties inherent in rigorously justifying
any scheme in a reasonable model of computation.

@_date: 2002-08-06 04:50:28
@_author: David Wagner 
@_subject: Extracting unifrom randomness from noisy source 
Well, I wouldn't recommend it.  It has two disadvantages:
  o  In practice, you can only hash noise samples of up to
     256 bits, and this constraint is a big problem.  In practice,
     it's often a good idea to hash samples from as many sources
     as possible, and that may yield may kilobytes of data.
     This construction provides no good way to help with this.
  o  In theory, there's no reason to believe that this method
     is any good.  For instance, suppose AES had a class of 2^64
     weak keys: if the first 64 bits of the key are all zeros, then
     encryption is the identity transform.  Well, this wouldn't
     contradict the assumption of security against known-plaintext
     attack, as a random key would be extremely unlikely to fall
     in such a class.  Yet such a property would make your proposed
     construction a not-so-great choice for entropy hashing.
     The conclusion is that merely assuming security against
     known-plaintext attacks (or even against adaptive chosen
     plaintext/ciphertext attacks) is not sufficient to guarantee
     that this method is secure, in theory.
In my opinion, SHA1 is superior in every way.

@_date: 2002-08-06 05:00:29
@_author: David Wagner 
@_subject: Extracting uniform randomness from noisy source 
I don't believe this is secure, either.
Notice that you never gave a security theorem, or a proof of security.
If the goal is a construction with a rigorously justified security
analysis, this deficiency should be a warning sign.  And in fact, there
are some attacks, as I show below.
For instance, suppose all the entropy of the input is contained in just
one block: say, the first block varies, and all other blocks are fixed
at all-zeros.  Then we can mount the same attack I described before to
distinguish a pseudorandom output from a true-random value.  Simply take
the output, decrypt it backwards as far as you can go, assuming all-zeros
in the trailing blocks, and the result will be a candidate value for
the first block of input; if it looks like a plausible input sample,
then you probably received an output from the pseudorandom source,
else you probably received true-random bits.
This same attack works even if the varying block is in the middle.
So the first lesson is that it does not suffice just to have enough
entropy in the input; it must be well-spread across blocks.
But being well-spread across blocks is no guarantee of security, either.
Imagine: you have a semi-random source, where each 16-bit word has 1
bit of entropy, and sampled words are independent.  To accumulate enough
entropy, you sample 80 words from this source, and then compress it using
AES-CBC-MAC.  Well, this succumbs to a 2^40 meet-in-the-middle attack.
Suppose you're given an output and you want to guess whether it came
from the pseudorandom process or from a true-random process.  First,
enumerate all 2^40 possibilities for the last 40 words, and decrypt
backwards through 5 blocks to obtain a list of 2^40 candidate values for
the intermediate value halfway through the CBC-MAC.  Next, enumerate
all 2^40 possibilities for the first 40 words, and encrypt forwards
through 5 blocks to obtain another list of 2^40 candidate values for
the same intermediate value.  If there is any value that appears in both
lists, conclude that you were probably given bits from the pseudorandom
AES-based process.  If not, conclude that you were probably given bits
from a true-random source.
This second attack shows that not only must the entropy be well-spread
out, but you must have more entropy than you need, by a factor of two.
In other words, the AES-CBC-MAC construction is wasteful of entropy.
SHA1 hashing does not have any of these problems.  And moreover, the lack
of a security theorem (or proof) for the AES-CBC-MAC construction raises
the question of whether there are any more attacks we haven't noticed yet.
In short, despite all the theoretical problems with rigorously justifying
SHA1-hashing, I believe in practice it is by far the best technology
available.  If asked by any practitioner, I would gladly recommend
SHA1-hashing over the alternatives.

@_date: 2002-08-06 05:03:07
@_author: David Wagner 
@_subject: Extracting uniform randomness from noisy source 
Yes, it's true.  However, this construction has a significant
disadvantage.  If you look carefully at the proof of security for this
approach (it's usually called the Leftover Hashing Lemma), you'll find
that the approach is wasteful of entropy.  If you want a 2^80 level of
security, you need at least 240 bits of true randomness.  That's because
the theorem requires a factor of three more bits of entropy than you
might think.  SHA1 doesn't have this problem.  As entropy is hard enough
to come by as it is, I think such wastefulness is best avoided, and I
would prefer SHA1 over 2-universal hashing in any practical system.

@_date: 2002-08-07 23:03:32
@_author: David Wagner 
@_subject: Extracting uniform randomness from noisy source 
I was assuming that the first block has 80 bits of entropy, and that
the attacker can't do 80-bit exhaustive searches.  In such a scenario,
my attack applies.  The attack does not apply to all scenarios, but in
cryptanalysis we are usually willing to consider the assumptions most
favorable to the attacker, as long as they are at all plausible.
This scenario is one that might arise in practice, and it is one that
SHA gets right while AES-CBC-MAC gets it wrong, I think this is an
argument for preferring SHA over AES-CBC-MAC.  Again, the difference
arises because SHA is preimage-resistant (one-way), while AES-CBC-MAC
isn't (when the key is known).

@_date: 2002-08-07 23:09:20
@_author: David Wagner 
@_subject: Extracting uniform randomness from noisy source 
I agree these would be great properties to have.  Sadly, I don't know
of any construction that plausibly achieves all three, in theory or
in practice.
If we have to give up one, the one I'd be most willing to give up is
property a.  After all, we almost never have enough entropy, and we almost
always take the output of the PRNG and just use it in some cryptosystem
that is insecure against computationally unbounded attacks anyway.
Think of a. like asking for your encryption scheme to be information
theoretically secure.  Sure, if you can afford such an encryption scheme,
that's great.  But in practice the one-time pad is too expensive, so we
gladly settle for mere security against computationally bounded attacks.
I think PRNGs are similar.
Fortunately, SHA1 in practice seems to achieve b+c (the two properties
we'd most like to have), even if we can't prove or rigorously justify
this belief.  For these reasons, in practice I still think SHA1 is
the best solution available.  At the same time, we probably could use
further research on schemes that can be justified in a rigorous and
principled way.

@_date: 2002-08-07 23:15:13
@_author: David Wagner 
@_subject: Extracting uniform randomness from noisy source 
No.  At least, I don't see how they would change anything.
I don't believe it.  I earlier sketched a proof that no deterministic
scheme can achieve everything we'd like, if we assume nothing about the
input distribution other than that it has enough entropy.  I believe
the proof applies to all schemes, whether or not they use bent S-boxes
or other clever ideas.  I don't see how your approach evades this
fundamental barrier.  What am I missing?

@_date: 2002-12-08 21:27:06
@_author: David Wagner 
@_subject: DOS attack on WPA 802.11? 
But TKIP (the part of WPA you're talking about) is only a
temporary measure, and will soon be replaced by AES-CCMP.
The question is not "Should we replace TKIP?", because the
answer to that is obvious: "Yes, we should, and we will".
Th question is: "Why bother working on a `fix' to WPA that
will likely never be deployed and that will be obsoleted
in a few years by the spread of AES-CCMP?".

@_date: 2002-12-16 18:13:38
@_author: David Wagner 
@_subject: Micropayments, redux 
I think you misunderstand the nature of the martingale strategy.
It's not a good way to win in Las Vegas, and it's not a good way to
win here, either.  Anyway, even if it were a problem, there would
be lots of ways to prevent this strategy in a digital cash system.
No problem.  This is expected to be roughly counterbalanced by the
number of unlucky users who quite "while behind".
No, it doesn't.  It doesn't take unlimited time for lottery-based
payment schemes to average out; finite time suffices to get the
schemes to average out to within any desired error ratio.  The
expected risk-to-revenue ratio goes down like 1/sqrt(N), where N
is the number of transactions.  Consequently, it's easy for banks
to ensure that the system will adequately protect their interests.
And everything is eminently predictable.  Suppose the banks expect
to do a 10^8 transactions, each worth $0.01.  Then their expected
intake is $1 million, plus or minus maybe $1000 or so (the latter
depends slightly on the exact parameter choices).  Any rational
bank ought to be willing to absorb a few thousand in plus or minus,
at this level of business.
In short: I think your list of "problems" in the approach are not
actually problematic in practice.

@_date: 2002-12-16 23:19:17
@_author: David Wagner 
@_subject: Micropayments, redux 
Yes, that's true.  Still, the loss is bounded, even if there is no
prepayment.  Suppose that each transaction is for 1cent, and we set things
up so you pay 1/100 of the time.  Then the most any given user can walk
off by quitting early is about $1.  The costs of customer acquisition
are probably far greater than $1.  For instance, many online payment
schemes were offering $10 coupons just for signing up to the system.
Remember also that this scheme requires strong is-a-person credentials,
so each person can probably pay this game at most once.  This means
there is not much incentive for anyone to bother trying to game the
system on purpose.  And, as you say, it is not hard to tweak the system
to reduce the amount the bank can lose in this way, if you care.

@_date: 2002-12-17 00:46:38
@_author: David Wagner 
@_subject: Micropayments, redux 
Yes, but the probability of it being significantly worse than I claimed
(i.e., by more than a factor t) is exponentially small (in t).  One can
easily calculate concretely exactly what the risk curve looks like.
I'll spare everyone the details and just say that I see no reason why
this should be a showstopper in practice.

@_date: 2002-01-22 03:51:43
@_author: David Wagner 
@_subject: password-cracking by journalists... (long, sorry) 
I think our understanding of the DMCA has changed
significantly since it was first introduced, and it's
not clear to me that the DMCA provides the level of
protection that should perhaps be there.
For instance, none of the exemptions for research
apply to 1201(b), the half of the DMCA that bans making
circumvention devices (as opposed to 1201(a), which bans
circumventing and does have a few exemptions).  As far as
I can tell, 1201(b) appears to be a real concern for
certain types of research in this field.
The biggest issue for researchers may be not in the DMCA's
criminal provisions, but rather in its civil provisions.
(i.e., money, not jailtime)  And the civil aspects of the
DMCA have a truly sharp sting.
I spent a lot of time talking to lawyers at UC Berkeley and
elsewhere about this very issue, and there appears to be a real
but very-hard-to-quantify risk -- a risk to scientists that should
not be lightly dismissed.
Given this risk, I've decided I cannot afford to work any further
in the area of copy protection as long as the uncertainty remains.
And how in good conscience can I advise students working with me
to work in this troubled area?  I can't.

@_date: 2002-07-18 22:38:31
@_author: David Wagner 
@_subject: It's Time to Abandon Insecure Languages 
This seems interesting.  Can you elaborate a little more on Ada's
advantages with regard to security?  Can you give any examples?
(The URLs you mentioned didn't help me much.)

@_date: 2002-07-23 19:21:28
@_author: David Wagner 
@_subject: building a true RNG (was: Quantum Computing ...) 
No.  (assuming you're talking about lossless compression)
In general, any invertible transformation neither adds or subtracts
entropy, and hence is extremely unlikely to make any difference to the
performance of the hash function (assuming SHA-1 is cryptographically
secure, which it is currently believed to be).  Lossless compression
is just one special kind of invertible transformation.

@_date: 2002-07-27 18:08:52
@_author: David Wagner 
@_subject: building a true RNG 
None that I know of.  I'm not aware of much work in the crypto literature
on this topic.
Actually, there is not much hope for such a property.  It is pretty easy
to see that, if we make no assumptions on the entropy inputs other than
they have sufficient entropy, then no single deterministic algorithm can
ever be good at extracting randomness.  If we fix any single extraction
algorithm A, there exists a distribution D on the inputs which make it
give non-uniform output (for example, D might be the uniform distribution
on the set {x : A(x) has its first ten bits zero}).  This is a standard
observation from the theory community's work on derandomization.
The only way out of this I can see is to assume we have a small seed
of uniformly distributed randomness on the side.   This is exactly the
direction explored in the theory community in work on extractors, the
leftover hashing lemma, and the like.  However, from a cryptographic point
of view, such an assumption is highly unreasonable (even worse than the
"random oracle" assumption).
In short: I know of no better way to analyze cryptographic randomness
extraction than to use the random oracle model.

@_date: 2002-07-27 20:15:02
@_author: David Wagner 
@_subject: building a true RNG 
Alas, that's not a very precise definition.
Actually, my intuition differs from yours.  My intuition is that
entropy collection requires fairly strong assumptions about the hash.
For instance, collision-freedom isn't enough.  One-wayness isn't enough.
We need something stronger, and something that appears difficult to
formalize in any precise, mathematically rigorous way.

@_date: 2002-07-27 20:34:29
@_author: David Wagner 
@_subject: building a true RNG 
Out of curiousity, what, precisely, does "doesn't waste entropy" mean?
For instance, do you mean the following?
  Definition.  Let f:X->Y be a function, and assume |X| > |Y|.  When D is a
  distribution, we say that "f doesn't waste entropy on D" to mean that
  the Shannon entropy satisfies H(f(x)) >= min(H(x), lg |Y|), where x
  is a random variable distributed according to D.  Also, we say that
  "f doesn't waste entropy" to mean that, for every distribution D on X,
  it is the case that f doesn't waste entropy on D.
Is that what you meant?
If that definition captures what you meant, then I can prove that no
interesting function satisfies this criteria.  In particular, there is
no function f which doesn't waste entropy, unless |Y|=1.  The proof is
simple enough that you can probably find it with a moment's contemplation,
but let me know if you want to see it.
Or, maybe you consider the entropy condition above too strict.
Maybe you'd prefer to change it as follows:
  Definition.  ... satisfies H(f(x)) >= min(H(x), lg |Y|) - 1, where ...
However, even in this case there is still a strong negative result:
there will be no function that satisfies this condition unless |Y| <= 2.
I hope this illustrates why it is hard to make precise just what
assumptions on the hash function we need to make for our entropy
distillation algorithm to be secure.  This is all pretty standard stuff;
it's just not well-documented in tutorial form in the literature, as
far as I know.

@_date: 2002-07-29 15:39:32
@_author: David Wagner 
@_subject: building a true RNG 
It seems very unlikely that they can generate all 2^N outputs
(under current knowledge).  However, they satisfy the next-best
thing: their output appears to be indistinguishable from uniform to
computationally-bounded observers, hence it's "as good as" if they
could generate all 2^N outputs for most purposes.

@_date: 2002-07-29 18:30:38
@_author: David Wagner 
@_subject: building a true RNG 
The result you want should follow in the random oracle model.  (Of course,
there is no proof that SHA1 is well-approximated by the random oracle
model, though it is a common assumption.)

@_date: 2002-07-30 19:06:17
@_author: David Wagner 
@_subject: building a true RNG 
Well, the random oracle model has problems, but I think those problems
are a bit more subtle than just an assumption that is true or false.
Hmm; I thought I answered this before.  Was it unclear?  If so, please
ask.  In any case, here's a summary.  In the standard model (without
random oracles), there is *no* such assumption.  There's no hope for
finding such an assumption, if you want to build a general-purpose
entropy cruncher that works for any distribution on the input samples.
One can prove this.  No matter what function you choose, there is an
input distribution that makes this function inadequate.

@_date: 2002-06-21 22:59:43
@_author: David Wagner 
@_subject: Shortcut digital signature verification failure 
My 800MHz PIII can do about 2800 512-bit RSA verifies per second.  Dan
Bernstein has a signature algorithm where verification is significantly
faster still [1], and his ideas could probably be used to quickly reject
most invalid signatures with even better efficiency.
One of the nicest ideas from his work is easy to describe.  In plain
RSA, s is a valid signature on m if H(m) = s^3 (mod n).  Now suppose we
ask the signer to also supply an integer k such that 0 <= s^3 - kn < n;
clearly this can't hurt security, as k can be publicly computed from s.
Then the recipient can efficiently verify the validity of the claimed
signature (t,k) on m as follows: verify that 0 <= s^3 - kn < n; then
secretly pick a random 31-bit prime p, compute t' = s^3 mod p, n' =
n mod p, k' = k mod p, h' = H(m) mod p, and verify that t' - k'n' = h'
(mod p).  This requires a few reductions and multiplications modulo
a 31-bit number, and thus is faster than verifying the RSA signature
directly (the latter requires a few reductions and multiplications
modulo a 512-bit number).  Moreover, if the prime is chosen randomly,
the probability that an adversary can forge a signature that passes
this screening test is something like 2^-26 or so.  In short, invalid
signatures can be detected quickly with very high probability.
[1] D. J. Bernstein. ``A secure public-key signature system with extremely
fast verification.''

@_date: 2002-06-24 06:56:43
@_author: David Wagner 
@_subject: Shortcut digital signature verification failure 
Great questions!  The explanation is that I botched the description
of Bernstein's trick.  Let me try again and see if I can get it right
this time.
A signature on message m is a tuple (h,s,k) such that s^3 = kn + h, h =
H(m), and 0 <= h,s,k < n.
A reasonably fast way to check the validity of a claimed signature
is to apply the hash, verify h = H(m), then compute s^3 mod n using
modular arithmetic and check that s^3 = h (mod n).  This requires a few
multiplications and reductions modulo n.
A faster way to verify the validity of a claimed signature is to secretly
pick a random 31-bit prime p.  We will verify that h = H(m) and s^3 - kn -
h = 0 (mod p).  Note that the latter can be tested quickly by computing
s mod p, s^3 mod p, k mod p, n mod p, and h mod p, and then doing a few
subtractions mod p.
We can see that the second method is faster than the first method:
it replaces a few operations modulo n by a few operations modulo p.
Since p is much smaller than n, this is a win.
Did I get it right this time?  Is it clearer?  If there are any
errors above, I take full responsibility for them.  The authoritative
description of Bernstein's trick can be found in his paper (cited in my
previous email).

@_date: 2002-03-02 23:07:57
@_author: David Wagner 
@_subject: Bernstein's NFS machine 
Very interesting.  Thanks for the analysis.
Bernstein's analysis is based on space*time as your cost metric.
What happens if we assume that space comes for free, and we use simply
time as our cost metric?  Do his techniques lead to an improvement in
this case?
It looks to me like there is no improvement in the first phase, but
there is some improvement in the second phase (reduction in time from
B^2 to B^1.5).  Then, of course, we need to re-consider the parameters
to balance the work, and it seems we would want to choose E = B^1.25,
subject to the constraint that E is large enough to produce at least
B relations.  What does this solve for, in terms of L?  How much do his
matrix solving techniques speed up the total computation, in the case
where we count only the running time of the adversary?

@_date: 2002-11-07 00:03:20
@_author: David Wagner 
@_subject: New Protection for 802.11 
WPA seems to be TKIP (a short-term improvement to WEP) + 802.1x (user
authentication, typically hooked into RADIUS?).  The background is that
the IEEE 802.11i working group is developing two fixes to WEP: TKIP,
the short-term patch, and AES-CCMP, the long-term fix.  TKIP isn't
perfect but it seems to be quite reasonable.
As far as I know, WPA should fix the cryptographic attacks on WEP.
However, as far as I can tell, we may still be left with key management
and "turning on the crypto" as the two most important issues in practice.
(It's probably too soon to know for sure.)
Of course, if you don't upgrade your equipment, you don't get the benefits
of WPA.  However, it seems that the Wi-Fi consortium is claiming that in
some cases a software upgrade might be sufficient to get WPA support --
I'm not too clear on the details.
It's not clear to me if WPA products come with encryption turned on
by default.  This is probably the  biggest source of vulnerabilities
in practice, far bigger than the weaknesses of WEP.
For a little more, see

@_date: 2002-10-24 00:24:46
@_author: David Wagner 
@_subject: Why is RMAC resistant to birthday attacks? 
Not so.  This is not a required property for a MAC.
(Not all MACs must be PRFs.)

@_date: 2002-10-24 05:33:52
@_author: David Wagner 
@_subject: Why is RMAC resistant to birthday attacks? 
No, I think Wei Dai had it right.  SHA1-HMAC has a 160-bit internal state.
If you fix two messages, the probability that they give an internal collision
is 1/2^160.
Maybe you are thinking of the birthday paradox.  If you have 2^80 messages,
then there is a good probability that some pair of them collide.  But this
is the square root of the size of the internal state space.  And again, Wei
Dai's point holds: the only way to reduce the likelihood of internal collisions
is to increase the internal state space.
In short, I think Wei Dai has it 100% correct.
This is not accurate.  The original van Oorschot and Preneel paper
describes an internal collision attack on MD5 with the envelope method.
Please note also that HMAC is different from the envelope method, but
there are internal collision attacks on HMAC as well.  Once again, I
think Wei Dai was 100% correct here, as well.
You might want to consider reading some of the literature on internal
collision attacks before continuing this discussion too much further.
Maybe all will become clear then.

@_date: 2002-09-02 18:35:00
@_author: David Wagner 
@_subject: Quantum computers inch closer? 
Look again at those quantum texts.  AARG! is absolutely correct.
Quantum doesn't work like the original poster seemed to wish it would;
state vectors collapse into a random state, not into that one magic
needle-in-a-haystack state you wish it could find.

@_date: 2002-09-03 00:15:54
@_author: David Wagner 
@_subject: Quantum computers inch closer? 
Sure, but your description could be a bit misleading for the uninformed
(which is what this thread is for, after all).  The original poster seemed
to have the misconception that, if I can just describe some set S of
states, a quantum computer can somehow magically cause any superposition
to collapse onto a state S.  Well, this is occasionally true, but more
often it is just plain wrong.  Just because you can describe a special
set of lucky states doesn't mean you can set up a superposition of
the required form to collapse into one of these lucky states in O(1)
quantum operations.
Quantum computers are not a magic device for solving all search problems
in constant time.  The reality is much more complicated.
Some might think that Shor's factoring algorithm is a counterexample.
After all, if you read a popular exposition, it might seem like it sets
up a superposition of all integers less than n, then checks in parallel
which ones divide n, and somehow causes the wavefunction to collapse
onto one state containing a divisor d of n.  Well, that's probably a
misleading way to think about Shor's factoring algorithm.  In fact,
what Shor's algorithm does is set up a superposition so that collapsing
to a random state in the superposition will, with high probability, give
you useful information about the factors of n.  All the hard work, and
technical insight, is in seeing how one can set up such a superposition
using only the basic primitives available in a quantum computer (namely,
unitary transformations).
As you can see, even in Shor's algorithm, what we have is a collapse
of the superposition onto a random state.  (Of course, the notion of
"random" is not necessarily the uniform distribution -- it is weighted
appropriately, according to the amplitude of the wavefunction at
the appropriate points -- but it is still random.)  If you want to
find a needle in a haystack, you have to identify some way to set up a
superposition so that random collapse will give you the needle with high
probability.  Let me stress that setting up the desired superposition is
the hard part.  And, for the example given by the poster -- exhaustive
keysearch -- there is no way known to set up a superposition of the
desired form with O(1) basic quantum operations.  In fact, there is not
even a shred of reason to believe such a quantum algorithm might exist;
all available evidence points to the contrary.

@_date: 2002-09-03 00:19:08
@_author: David Wagner 
@_subject: Quantum computers inch closer? 
I must admit I can't for the life of me figure out what this paragraph
was supposed to mean.  Maybe that's quantum for you.
But I take it we agree: The original poster's suggested "scheme" for
cracking Feistel ciphers doesn't work, because quantum computers don't
work like that.  Agreed?

@_date: 2002-09-16 18:45:25
@_author: David Wagner 
@_subject: Cryptogram: Palladium Only for DRM 
I'm a little confused on this point.  Does Palladium really check the
hash on running software?  I was under the impression that any hashes
would be computed only when the banking software was loaded.  If this
is the case, then a virus could simply infect the software after it
has been loaded from disk.  In other words, the virus could attack the
in-memory image rather than the disk image.  Probably the Palladium
designers have noticed this.  What defenses does Palladium incorporate
against this sort of attack?
Standard process separation, sandboxes, jails, virtual machines, or other
forms of restricted execution environments would suffice to solve this
problem.  There is no need for remote attestation, for the DRM-enabling
features of Palladium, or for its other features that could be used to
take away control from the owner of the machine.  A banking application
is a great example where the user's and the bank's interests are aligned,
and hence there is no need for physical security or for a semi-coercive
infrastructure for taking control away from the owner of the machine.
It's only the fact that today's OS's aren't very good at providing process
separation that prevents us from deploying comparable defenses today.
If security for banking applications was really the goal, why tack on
these controversial DRM-enablers?

@_date: 2002-09-17 06:02:06
@_author: David Wagner 
@_subject: Cryptogram: Palladium Only for DRM 
I wasn't thinking of pure software solutions.  I was thinking of a
combination of existing hardware + new software: use the MMU to provide
separate address spaces, and use a secure VM or OS kernel to limit what
those processes can do.  As far as I can see, this can provide just as
much protection against viruses for your bank account as Palladium can.
In general, with software and existing hardware working together, I
suspect we can already do everything Palladium can do, except for the DRM
and related applications founded on taking control away from the owner
of the machine.  Maybe I'm missing something.  Still, it seems to me that
Palladium would much more compelling if it left out the tamper-resistant
chip and gave up on the semi-coercive DRM-like applications.

@_date: 2002-09-20 02:49:03
@_author: David Wagner 
@_subject: Cryptogram: Palladium Only for DRM 
Yes, but...
For me, BORE (Break Once Run Everywhere) depends on the application.
You can't analyze Palladium in isolation, without looking at the app,
too.  It doesn't make sense to say "Palladium isn't susceptible to BORE
attacks", if the applications themselves are subject to BORE attacks.
For example, if a record company builds an app that stores a MP3 of
the latest Britney Spears song in a Palladium vault, then this app
will be susceptible to BORE attacks.  Extracting that MP3 from any one
machine suffices to spread it around the world.  It won't comfort the
record company much to note that the attacker didn't learn the Palladium
crypto keys living on other machines; the damage has already been done.
Palladium doesn't make DRM resistant to BORE attacks.  It can't.
In short, there are some applications that Palladium can't make
BORE-resistant.  Some apps (e.g., DRM) are simply fundamentally fragile.
Maybe a more interesting question is: For which apps does Palladium
provide resistance against BORE attacks that is not available by other

@_date: 2002-09-21 00:04:34
@_author: David Wagner 
@_subject: unforgeable optical tokens? 
Yeah.  I think it's neat!
This is not a replacement for cryptography.  It's not biometric
authentication.  It's no good for challenge-response authentication
across a network.  It's not a secure credit card.
What is it, then?  It's a physical object that's hard to duplicate.
I'd describe their work by analogy to marbles.  Marbles are more-or-less
unique.  When I first meet you, I could give you a marble, and if I
see you again a little bit later, I can know it's you again by the fact
that it's the same marble, just by looking at your marble.  Also, their
"marble" has the property that someone else who peeks at your marble
won't be able to easily duplicate your marble.  Their "marble" requires
a special reader to scan the token, though.
What are the applications?  Well, you can imagine this might be useful
to stop counterfeiting, for instance.  Maybe our future dollar bills
could include such a strip, and cheap readers could be used to validate
the authenticity of a bill.
I think it will take some time to validate how secure their proposal
is, but it is an intriguing new idea that might just work.  Also, it
remains to be seen whether their technique will be cheap enough to be
cost-effective; still, I'm intrigued.

@_date: 2002-09-21 00:11:17
@_author: David Wagner 
@_subject: unforgeable optical tokens? 
I believe the idea is that there are gazillions of possible challenges.
The challenger picks a thousand randomly in advance, scans the token
from the corresponding thousand different angles to get the thousand
responses, and stores all them.  Then, later, the challenger can select
one of his stored challenges, pass it to a remote entity, and demand
the correct answer.  Of course, a challenger must never re-use the same
challenge twice.
I find the physical token a poor replacement for cryptography, when the
goal is challenge-response authentication over a network.  In practice,
you never really want just challenge-response authentication; you
want to set up a secure, authenticated channel to the other party,
which means you probably also need key distribution functionality.
The physical token suggested here doesn't help with that at all.
It seems to me the real value of the physical token is that it provides a
piece of hardware that is (hopefully) very expensive to clone.  That's an
interesting capability to have in your bag of tricks.

@_date: 2002-09-21 06:10:22
@_author: David Wagner 
@_subject: unforgeable optical tokens? 
But why bother?  What does this add over just using crypto
without their fancy physical token?  The uncloneability of
their token is irrelevant to this purpose.  You might as well
just carry around a piece of paper, or a floppy disk, with a
list of keys on it.

@_date: 2002-09-25 00:04:49
@_author: David Wagner 
@_subject: unforgeable optical tokens? 
I don't think this works.  A malicious reader could remember all the
challenges it gets and record all the responses it measures (before
hashing).  If the number of possible challenges is small, the malicious
reader might learn the entire challenge-response dictionary after only
a few interactions.  From that point on, the malicious reader would be
able to spoof the presence of the token.
(Of course, if malicious readers aren't a threat, then you don't
need fancy uncloneable tokens.  A simple cryptographic key written
on a piece of paper suffices.)
So I think you really do need to use a different challenge every time.

@_date: 2003-04-09 15:21:21
@_author: David Wagner 
@_subject: Via puts RNGs on new processors 
Why not?  You rely on an off-the-shelf CPU, don't you?
The CPU must be trusted just as much as the RNG.
Do you worry about this for your CPU?  If not, why should
the RNG component of your CPU be any different?

@_date: 2003-08-28 20:26:27
@_author: David Wagner 
@_subject: traffic analysis 
Are you sure you understood the attack?  The attack assumes that
communications links are insecure.  The *transmission* from Alice may
adhere to a fixed schedule, but that doesn't prevent the attacker from
introducing delays into the packets after transmission.
For instance, suppose I want to find out who is viewing my web site.
I have a hunch that Alice is visiting my web site right this instant,
and I want to test that hunch.  I delay Alice's outgoing packets, and I
check whether the incoming traffic to my web contains matching delays.
If so, it's a good bet that Alice has a connection open to my site.

@_date: 2003-02-10 21:26:20
@_author: David Wagner 
@_subject: Columbia crypto box 
It's hard to believe that RC4 was chosen for technical reasons.
The huge cost of key setup per packet (equivalent to generating 256
bytes of keystream and then throwing it away) should dominate the other
potential advantages of RC4.
In any case, WEP would clearly look very different if it had been designed
by cryptographers, and it almost certainly wouldn't use RC4.  Look at
CCMP, for instance: it is 802.11i's chosen successor to, and re-design
of, WEP.  CCMP uses AES, not RC4, and I think that was a smart move.

@_date: 2003-02-19 01:11:05
@_author: David Wagner 
@_subject: AES-128 keys unique for fixed plaintext/ciphertext pair? 
Vanishingly small, as you guessed.
Fix x0 in S.  Your probability is at most the probability that G has
no two functions f1, f2 with f1(x0) = f2(x0).  The latter is the same
as the probability that a set of 2^128 randomly chosen 128-bit values
contains no repeated elements, which is indeed vanishingly small (it is
(2^128)! / (2^128)^(2^128), which is something like 1/e^(2^128)).

@_date: 2003-01-16 01:33:33
@_author: David Wagner 
@_subject: What, me worry? 
Because those attacks will be illegal.  No, wait -- they already are
illegal.  This means that the good guys will be reluctant to break the
DRM for legitimate purposes, while the bad guys will continue to break
the DRM for illegitimate purposes.  Not exactly an ideal situation.

@_date: 2003-01-20 18:32:23
@_author: David Wagner 
@_subject: Prime numbers guru 'factors' down success 
If you compare to randomized algorithms, I suspect the answer is "never".
There are randomized algorithms that run in polynomial time that have been
known for many years.

@_date: 2003-01-20 22:18:06
@_author: David Wagner 
@_subject: Key Pair Agreement? 
You might be able to have Scott specify a 64-bit string, and then ask
Alice to come up with a RSA public key that has this string as its low
64 bits.  I believe it is straightforward to modify the RSA key generation
algorithm to generate keypairs of the desired form.
If you're worried about the security of allowing Scott to choose the
low bits of Alice's public key, you could have Scott and Alice perform
a joint coin-flipping protocol to select a random 64-bit string that
neither can control, then proceed as before.
I haven't worked out all the details, but something like this might
be workable.
In practice, you might also want to confirm that Alice knows her private
key (i.e., has ability to decrypt messages encrypted under her public

@_date: 2003-01-20 23:34:59
@_author: David Wagner 
@_subject: Key Pair Agreement? 
Hold on a minute.  The problem was to generate a new public key that
had been certified as fresh.  The original poster did not state any
requirement that the public key also be "safe".
Let's take a look at the original problem statement again:
See?  There's nothing about Alice proving that her key is safe.
If you do want to add a "safety" requirement, then the problem is
unsolvable.  Alice can always publish her private key at any time, and
there is nothing Scott can do about this.  This is true no matter what
method you use -- RSA, discrete log, or something entirely different.
So I wouldn't use this "safety" business as a way of choosing which method
to use.  If you want a "safety" requirement, give up.  If you don't,
select a method that achieve van Gelderen's requirement as efficiently
as possible, without regard to "safety".

@_date: 2003-01-24 19:05:03
@_author: David Wagner 
@_subject: [IP] Master Key Copying Revealed (Matt Blaze of ATT Labs) 
If those locksmiths didn't publish the vulnerability, phooey on them.
Matt Blaze deserves full credit for being the first to publish.
What good is it to know about a vulnerability if you never warn the
users and never fix the weakness?
In scientific research, we credit the first person to publish new
knowledge.  Sure, maybe you've invented a cure for cancer ... but if
you don't tell anyone, you don't get the credit, and you haven't done
much good for the world.
I think, on balance, Matt Blaze's paper seems likely to be beneficial
for users of locks.  It helps us more accurately evaluate our own
security and be smarter about how we select physical security defenses.
That seems likely to lead to greater security for all of us in the end.
We should be grateful to Blaze for publishing, not dismissive.

@_date: 2003-03-07 18:30:37
@_author: David Wagner 
@_subject: Proven Primes 
There are ways to prove that p is prime so that the receiver
can verify the proof more easily than it would be to construct
a proof.  The verification process is deterministic (there is
no chance of error), unlike probabilistic primality tests.
Here's a simple method, due to Pratt.  It turns out that p is
prime if and only if the multiplicative group (Z/pZ)^* of integers
modulo p is cyclic.  To show that the group is cyclic, we can
give a generator g.  To show that g is a generator, we can factor
p-1 and show that g^{(p-1)/q} != 1 (mod p) for all prime q that
divide p-1.  Thus, the proof of primality for p will be
   proof(p) = (g, q_1, proof(q_1), q_2, proof(q_2), ...)
where q_1, q_2, ... is the list of prime factors of p and where
proof(q_i) is a recursive proof of primality for q_i.

@_date: 2003-03-14 19:23:51
@_author: David Wagner 
@_subject: Microsoft: Palladium will not limit what you can run 
That's a strawman argument.  The problem is not that Palladium will
*itself* directly limit what I can run; the problem is what Palladium
enables.  Why are you focusing on strawmen?  Why did you omit the real
concerns about technology like Palladium?
Palladium could enable big vendors to limit what applications I can run.
Palladium could enable big vendors to behave anti-competitively.
Palladium could enable big vendors to build document formats that
aren't interoperable with open-source software.  Palladium could be a
net negative for consumers.
Many of these risks are already possible today without Palladium, but
Palladium may increase the risks.  These risks are by no means guaranteed
to occur, but they are a real risk.  Shouldn't we think carefully about
this technology before we deploy it?  Shouldn't we at least consider
these risks?

@_date: 2003-03-24 22:02:43
@_author: David Wagner 
@_subject: Who's afraid of Mallory Wolf? 
One possible reason: Because DNS is insecure.
If you can spoof DNS, you can mount a MITM attack.
A second possible reason: It's hard to predict
what attacks will become automated.  Internet
attacks seem to have an all-or-nothing feel:
either almost noone exploits them, or they get
exploited en masse.  The latter ones can be
really painful, if you haven't built in protection
in advance.
You could take your argument even further and
ask whether any crypto was needed at all.
After all, most attacks have worked by compromising
the endpoint, not by sniffing network traffic.
I'll let you decide whether to count this as a
success story for SSL, or as indication that the
crypto wasn't needed in the first place.
(I'm a little skeptical of this argument, by the
way, but hey, if we're playing devil's advocate,
why not aim high?)

@_date: 2003-03-24 23:22:05
@_author: David Wagner 
@_subject: Brumley & Boneh timing attack on OpenSSL 
My guess is that it's not necessary, as the attacker doesn't
have as much control over the input to the modular exponentiation
process in the case of RSA signatures.  (For RSA decryption,
the attacker can specify the ciphertext freely.  However, for
signatures, the input to the modular exponentiation is a hash
of the attacker's chosen input, which gives the attacker a lot
less freedom to play Bleichenbacher-like games.)
But then, the recent Klima-Pokorny-Rosa paper shows how even
just a tiny crack can lead to subtle, totally unexpected attacks.
Who would have thought that SSL's version rollback check (two bytes
in the input to the modular exponentiation) could enable such a
devastating attack?  Not me.
The Boneh-Brumley and KPR papers have made me much more paranoid
about side-channel attacks.  As a result, I might turn blinding on
even for signatures by default, out of caution, even though I can't
see how such an attack could possibly work.
Yes, I think I'd use side channel defenses (like blinding) here.
I don't know of any attacks off the top of my head, but it sure
seems plausible to me that there might be some.
I wouldn't tend to be very worried about ephemeral exchanges,
since all the attacks we've seen so far require many interactions
with the server with the same key.  I could be wrong, but this
seems pretty safe to me.
Good question.
Personally, I'd enable side channel defenses (like blinding) by
default in the crypto library in every place that the library does
some lengthy computation with a long-lived secret.
But I'll be interested to hear what others think.

@_date: 2003-03-25 18:17:45
@_author: David Wagner 
@_subject: Who's afraid of Mallory Wolf? 
I'm skeptical.  Just because the cost is
subjective doesn't mean we should ignore the cost.
That's using a questionable measuring stick.
The damages paid out in a civil suit may be very
different (either higher, or lower) than the true
cost of the misconduct.  Remember, the courts are
not intended to be a remedy for all harms, nor could
they ever be.  The courts shouldn't be a replacement
for our independent judgement.

@_date: 2003-03-31 21:26:41
@_author: David Wagner 
@_subject: Fw:Fraud & voting machines 
Breathless speculation aside, it oughtn't be that hard to test whether
Hagel's victory was credible.  Surely there were some polls of the voters.
You would think that if there was significant fraud through compromised
voting machines, then this fact would be very noticeable in the polls.
Does anyone know whether there is any evidence to back up these
allegations that Hagel's election results were fraudulent, or is this
article just blowing smoke?
I agree that we ought to take voting fraud seriously, and I'm very
critical of e-voting.  However, we also ought to get the facts, all the
facts, and to get them right.

@_date: 2003-05-09 15:47:01
@_author: David Wagner 
@_subject: Randomness 
Absolutely.  Suppose Y = X, for instance.  More generally, if
H(Y|X) = k, then there could well be an attack of complexity 2^k or so.

@_date: 2003-05-16 20:12:27
@_author: David Wagner 
@_subject: Modulo based hash functions [was: The Pure Crypto Project's Hash Function] 
These number-theoretic hash functions are arguably a lousy choice
for general-purpose use.  Sure, those hashes may be one-way and
collision-resistant, but these days, we expect more than just one-wayness
and collision-resistance: we often expect the hash to behave like a
"random function".  Number-theoretic hashes usually don't satisfy
this property, and thus run the risk of creating bad interactions
between the number-theoretic hash and the number-theoretic public-key
encryption/signature scheme.  For all these reasons, I prefer SHA1 for
general-purpose use over number-theoretic schemes.

@_date: 2003-05-31 15:54:26
@_author: David Wagner 
@_subject: Nullsoft's WASTE communication system 
Also, it can violate confidentiality.  If M is guessable,
the guess can be confirmed using H(M).
Even for block ciphers, it's vulnerable against chosen-message
attack, although I agree this weakness may be more or less theoretical.
I certainly agree with all your comments.  I can't imagine why
they invented their own crypto, rather than just using SSL.

@_date: 2003-10-22 22:53:01
@_author: David Wagner 
@_subject: SSL, client certs, and MITM (was WYTM?) 
I'm not aware of any such consensus.
I suspect you'd get plenty of debate on this point.
But in any case, widespread exploitation of a vulnerability
shouldn't be a prerequisite to deploying countermeasures.
If we see a plausible future threat and the stakes are high enough,
it is often prudent to deploy defenses in advance against the possibility
that attackers.  If we wait until the attacks are widespread, it may be
too late to stop them.  It often takes years (or possibly a decade or more:
witness IPSec) to design and widely deploy effective countermeasures.
It's hard to predict with confidence which of the many vulnerabilities
will be popular among attackers five years from now, and I've been very wrong,
in both directions, many times.  In recognition of our own fallibility at
predicting the future, the conclusion I draw is that it is a good idea
to be conservative.

@_date: 2003-10-23 01:35:31
@_author: David Wagner 
@_subject: SSL, client certs, and MITM (was WYTM?) 
Sure.  If I can assume you're talking about SSL/https as it is
typically used in ecommerce today, that's easy.  Subvert DNS to
redirect the user to a site under controller of the attacker.
Then it doesn't matter whether the legitimate site has a valid server
cert or not.  Is this the kind of scenario you were looking for?
Gonna make me work harder on this one, eh?  Well, ok, I'll give it a try.
Here's one possible way that you might be able to use client certs to
help (assuming client certs were usable and well-supported by browsers).
Beware: I'm making this one up as I go, so it's entirely possible there
are security flaws with my proposal; I'd welcome feedback.
When I establish a credit card with Visa, I generate a new client
certificate for this purpose and register it with   When I
want to buy a fancy hat from  Amazon re-directs me to
  My web browser opens a SSL channel to Visa's web server, authenticating my
presence using my client cert.  Visa presents me a description of the item
Amazon claims I want to buy, and asks me to confirm the request over that
authenticated channel.  If I confirm it, Visa forwards payment to Amazon
and debits my account.  Visa can tell whose account to debit by looking
at the mapping between my client certs and account numbers.  If Amazon
wants to coordinate, it can establish a separate secure channel with Visa.
(Key management for vendors is probably easier than for customers.)
I can't see any MITM attacks against this protocol.  The crucial point is
that Visa will only initiate payment if it receives confirmation from me,
over a channel where Visa has authenticated that I'm on the other end,
to do so.  A masquerading server doesn't learn any secrets that it can
use to authorize bogus transactions.
Does this work?

@_date: 2003-09-07 15:18:25
@_author: David Wagner 
@_subject: cryptographic ergodic sequence generators? 
Let E_k(.) be a secure block cipher on 31 bits with key k.
(For instance, E might be 16 rounds of Luby-Rackoff using
f(x) = AES_{AES_{k}(i)}(x) as the Feistel function in the ith round.)
Pick an unending sequence of keys k0, k1, k2, ... for E.
Then your desired sequence can be constructed by
  E_k0(0), E_k0(1), E_k0(2), ..., E_k0(2^31 - 1),
  2^31 + E_k1(0), 2^31 + E_k1(1), 2^31 + E_k1(2), ..., 2^31 + E_k1(2^31 - 1),
  E_k2(0), E_k2(1), E_k2(2), ..., E_k2(2^31 - 1),
  2^31 + E_k3(0), 2^31 + E_k3(1), 2^31 + E_k3(2), ..., 2^31 + E_k3(2^31 - 1),
  ...,

@_date: 2003-09-08 21:52:15
@_author: David Wagner 
@_subject: Code breakers crack GSM cellphone encryption 
No, no, no!  This is new work, novel and different from what was
previously known.  In my opinion, it is an outstanding piece of research.
Barkan, Biham, and Keller establish two major results:
1. A5/2 can be cracked in real-time using a passive ciphertext only
attack, due to the use of error-correcting coding before encryption.
2. All other GSM calls (including those encoded using A5/1 and A5/3) can
be cracked using an active attack.  This attack exploits a protocol flaw:
the session key derivation process does not depend on which encryption
algorithm was selected, hence one can mount an attack on A5/2, learn
the A5/2 key, and this will be the same key used for A5/1 or A5/3 calls.
(they also make other relevant observations, but the above two are
probably the most significant discoveries)
Their attacks permit eavesdropping as well as billing fraud.
See their paper at CRYPTO 2003 for more details.  I am disappointed that
you seem to be criticizing their work before even reading their paper.
I encourage you to read the paper -- it really is interesting.

@_date: 2003-09-08 21:55:41
@_author: David Wagner 
@_subject: Code breakers crack GSM cellphone encryption 
Well, one reason might be if that government agency didn't have lawful
authorization from the country where the call takes place.
(say, SIGINT on GSM calls made in Libya)
Another might be if the government agency did not want to disclose the
presence of the eavesdropping to the telephone company that is carrying
the calls.

@_date: 2003-09-09 17:14:21
@_author: David Wagner 
@_subject: Code breakers crack GSM cellphone encryption 
Yeah.  Except it would be more accurate to place A5/2's strength as
roughly equivalent to 17-bit DES.  A5/1's strength is roughly equivalent
to that of 40-bit DES.
Of course, the GSM folks didn't exactly do a great job of disclosing
these facts.  They did disclose that A5/2 was the exportable version.
However, when A5/2 was first designed, SAGE put out a report that claimed
years of security analysis on A5/2 had been done and no mathematical
weaknesses had been found.  Now that we've seen A5/2, that report suffers
from a certain credibility gap, to put it mildly...

@_date: 2003-09-09 19:37:15
@_author: David Wagner 
@_subject: Code breakers crack GSM cellphone encryption 
One point your analysis misses is that there are public policy
implications to deploying a phone system that enemy countries can
routinely intercept.  Not all attacks are financially motivated.
Is it a good thing for our infrastructure to be so insecure?
Do we want other countries listening to our GSM calls?  Do other
countries want us listening to their GSM calls?  Is it a good thing
if such interception is made easier?  Sure, it may be in the SIGINT
agencies' interests for GSM to be crackable, but is it in the
public interest?  It's not clear.

@_date: 2003-09-13 21:06:56
@_author: David Wagner 
@_subject: quantum hype 
You're absolutely right.  Quantum cryptography *assumes* that you
have an authentic, untamperable channel between sender and receiver.
The standard quantum key-exchange protocols are only applicable when
there is some other mechanism guaranteeing that the guy at the other end
of the fibre optic cable is the guy you wanted to talk to, and that noone
else can splice into the middle of the cable and mount a MITM attack.
One corollary of this is that, if we want end-to-end security, one can't
stick classical routers or other such equipment in the middle of the
connection between you and I.  If we want to support quantum crypto,
the conventional network architectures just won't work, because any two
endpoints who want to communicate have to have a direct piece of glass.
Quantum crypto might work fine for dedicated point-to-point links,
but it seems to be lousy for large networks.
For these reasons, and other reasons, quantum crypto looks pretty
impractical to me, for most practical purposes.  There is some very
pretty theory behind it, but I predict quantum crypto will never replace
general-purpose network encryption schemes like SSH, SSL, and IPSec.
As you say, there is a lot of hype out there, but as you're discovering,
it has to be read very carefully.

@_date: 2003-09-13 22:18:27
@_author: David Wagner 
@_subject: quantum hype 
Quantum cryptography doesn't assume the channel is immune from
eavesdropping.  It does assume you know who is on the other end, and
no one can splice themselves in as a man-in-the-middle.  (Even though
we have an authentic channel, eavesdropping on the channel might still
be possible.)
One could reasonably ask how often it is in practice that we have a
physical channel whose authenticity we trust, but where eavesdropping
is a threat.  I don't know.

@_date: 2003-09-14 17:54:14
@_author: David Wagner 
@_subject: quantum hype 
Yes.  Several years ago, Adi Shamir presented some fascinating
attacks on the implementation of such black boxes at Cryptrec, so
it is not something that should be taken for granted.
Well, I agree.  If we get to use complexity-based crypto that is
not proven secure, like AES, RSA, or the like, then we can do much
better than quantum crypto.  The only real attraction of quantum crypto
that I can see is that its security does not rely on unproven
complexity-theoretic conjectures.

@_date: 2003-09-17 04:36:57
@_author: David Wagner 
@_subject: Quantum cryptography finally commercialized? 
For the onlookers, this article is misinformed and should
not be relied upon for evaluating quantum cryptography.
The rest of the article contains statements like the following:
The "unbreakable" claim is unfounded.

@_date: 2003-09-23 00:19:24
@_author: David Wagner 
@_subject: quantum hype 
Exchanging authentication messages through the newly created channel is
not secure: It is vulnerable to man-in-the-middle attacks.
For instance, suppose I do a quantum key exchange to get a session key SK,
set up a channel encrypted using SK, and then do a challenge-response
authentication protocol to check whether the party on the other end of
this channel is the Bob I wanted to talk to.  The resulting protocol
looks like this:
  A<->B: [exchange session key SK using a quantum key exchange]
  A->B:  {N_A}_SK
  B->A:  {sig}_SK,    where sig = {N_A}_{K_B^{-1}}
This protocol is insecure.  A man in the middle can relay messages.
  A<->M: [exchange session key SK using a quantum key exchange]
      M<->B: [exchange session key SK' using a quantum key exchange]
  A->M:  {N_A}_SK
     M->B:  {N_A}_SK'
     B->M:  {sig}_SK',    where sig = {N_A}_{K_B^{-1}}
  M->A:  {sig}_SK
Now Alice thinks she is talking to Bob, when actually Mallet has
insinuated herself into the middle of their communication link.
The problem with doing authentication after creation of the channel is
that the authentication is not bound to the quantum key exchange itself.
The only fix I can see is to somehow authenticate the quantum link used
for the quantum key exchange.  For instance, the quantum key exchange
could be done over an authentic link -- a link where you *know* who is
on the other end, and you have confidence that no one can tamper with
the link or splice themselves in.
