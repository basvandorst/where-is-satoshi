
@_date: 2017-12-05 20:32:26
@_author: Michael Nelson 
@_subject: [Cryptography] Rubber-hose resistance? 
What's the current thinking on this? I use an old Truecrypt. As I recall, the weaknesses in it were somewhat rarefied. It might leave some key-related stuff hanging around in memory, or if you go out of the room to get coffee then the attacker can pull out the plug as she drops the pc into liquid helium at 4 deg K then get down to work, etc.
These are real attacks that apply in some circumstances. But for me, I'm only concerned with when I've pulled out my USB stick with the tc executable and volume on it, and shut down the computer, and left the house.
Anything that applies to that simple situation? E.g., backdoors in the code? I thought that the code had been looked over by some decent people, but I'm out of date. Thx.

@_date: 2017-12-13 03:01:44
@_author: Michael Nelson 
@_subject: [Cryptography] Rubber-hose resistance? 
Don't know what you are objecting to here. A fine point? Accused has plausible deniability, accuser has reasonable doubt. Sounds ok. There is a certain vagueness about what the accuser is doubting, but the listener fills that in. I don't see latter as clearly better than the former.
Now this is one I've never seen the logic of. The point is just that it's *torture cryptanalysis*. You use a rubber hose if you need plausibl... oops.. *reasonable doubt* that you have tortured someone. But why bring that extra possible component?

@_date: 2018-06-03 00:28:17
@_author: Michael Nelson 
@_subject: [Cryptography] Security weakness in iCloud keychain 
Yes, I don't know, but I imagine that not too many orgs store the OTP secrets in the db. I'll expand on that a bit. The HOTP (and hence TOTP) ietf rfc specs out a canonical and very simple way of taking a system-wide master secret, and diversifying it based on userid, via hashing. At auth time the individual secrets are regenerated.
I have built several OTP products (HOTP/TOTP and Visa Dynamic Passcode). We (I was the architect/lead, and implemented the client and server libraries) stored the master secret in an HSM. I forget whether we implemented the hashing function and imported it into the HSM, or used HMAC in a canned library that came with the HSM. You can't use a regular hash api as this does not take a handle to a secret. This is quite straightforward, and simpler than storing per-user secrets in a db. You do have to fork out for an HSM, but for a company that's serious enough to do OTP, that was ok, at least for the ones we sold to. For the different, but related, VDP, there was no choice allowed, but the banks already had the HSMs, and some of them wanted VDP rather than H/TOTP as they thought compliance would be easier.
Sure, you could do regular passwords just as securely, with encrypted passwords being passed into and HSM, and checked inside. Or you could beef up the salting, etc., as alluded to. But for a given amount of effort and complexity the OTP is a viable way to get you to a solution that protects
against the usual db swiping.

@_date: 2018-05-28 19:14:47
@_author: Michael Nelson 
@_subject: [Cryptography] Security weakness in iCloud keychain 
Jon, not sure what context you're speaking in here so apologies if I've misunderstood. But I disagree with that main point as I understand it. There are 3 main types of attack: keyloggers, phishing, and database theft. I guess what you were thinking is that database theft yields up orders of magnitude more credentials than the other methods, and that's true. However, as far as the criminals' being able to use the stolen credentials goes, that's not the end of the story.
I was very interested to read the big study article from 2017
"Data Breaches, Phishing, or Malware? Understanding the Risks of Stolen Credentials", by Kurt Thomas et al.:
They say:
"As such, while credential leaks represent the largest source of passwords in our dataset (even taking into account match rates), phishing victims are the most likely to become hijacked."
There is a lot of interesting information in that article, and there are many nuances, such as how representative the data is. But it seemed to me very good info, as far as we can get it. In that paper, "credential leaks" means database theft, while "hijacked" means that the victim's stolen data is actually used by the miscreants. Even if the nuances shift things a bit, it is quite clear that a non-phishable credential such as OTP is a major improvement over passwords.

@_date: 2018-05-28 23:25:51
@_author: Michael Nelson 
@_subject: [Cryptography] Police want encrypted radios 
The articles I skimmed were pretty lowbrow and did not seem aware of this aspect. Schneier mentions it in his blog
and one commenter says:
"TETRA systems for public safety and security agencies (PSSA) are almost always encrypted using TEA2 (Europe) and TEA3 (elsewhere). However the networks have recording systems which hold some or all call sessions for periods often exceeding 3 months. These recordings can be archived for longer periods if there is some question about the activities during the recorded period."
One assumes that such systems detect deletions, etc.

@_date: 2019-01-07 20:47:21
@_author: Michael Nelson 
@_subject: [Cryptography] Came up with a weird use case, got questions 
HSMs have a means of changing the batteries. FWIW. Not saying this is the way to go...

@_date: 2019-01-08 00:06:34
@_author: Michael Nelson 
@_subject: [Cryptography] Google Titan Security Keys 
I'm wondering how the Google Titan Security Keys work for 2FA. I'm not sure what's going on under the surface here. The Google blurb, and write-ups on various middle-brow sites, just say something like: "You enter a URL in your browser, and put in your username, and you are prompted to stick your USB/Bluetooth key where it belongs. This authenticates you based on a secret key protected in the physical key."
There was a demo phishing attack recently on LinkedIn, where the phishing site acted as MITM to LI. The user entered two factors of some 2FA (not Google Security Keys as I recall), which were happily proxied to LI, giving the phisher login access.
So with this Google key, does it do anything other than protect the 2nd factor key in a handy portable form. I presume it presents itself as a keyboard and types into the browser window. Does it somehow enforce the target URL in a way that would defeat the LI attack? The Google key is based on the FIDO/WebAuthn spec. I slogged through that stuff a year ago, and have forgotten it. Maybe part of the answer is in there. If so, can someone have mercy and save me from reading that again...

@_date: 2019-01-08 21:47:36
@_author: Michael Nelson 
@_subject: [Cryptography] Google Titan Security Keys 
Thanks David.
I checked those links. They were high level and didn't say how the keys work, though. The most technical info was in the Google link that says:
"Because Google security keys use encryption and verify the legitimacy of the sites users visit, security keys are less prone to phishing attacks."
How do they do that? E.g., a GSK could run some local code that checks the SSL cert of the browser connection, and compares it to an acceptance criterion. Or a GSK could check a signature on a challenge to be signed. This latter would not work against real-time MITM proxying, but would indeed stop most simple phishing attacks. These two are just examples to clarify the kind of info I was after -- not saying that GSKs do that, as I have no idea.
Maybe you were actually referring to the hardcore FIDO specs, rather than links like that. If no one can help me with good link or a paragraph off the top of their head, then I guess I'll slog through that mountain of stuff. I'll report back if anyone's interested, if I find an answer.

@_date: 2020-11-16 01:06:18
@_author: Michael Nelson 
@_subject: [Cryptography] FIPS 140 validated crypto module on Android? 
We need a FIPS 140-2 validated crypto module on Android mobile devices to do some simple encryption. Does anyone know of an available such module?
One issue for the provider is of course that there are many hardware platforms/models -- Samsung, Motorola, Google Pixel, etc. There are also many versions of the OS.
Ideally, there would be some module that was validated on most, or at least some, of the current configurations, and the module validation would be updated regularly for the newer phones/OS-versions.
The NIST website lists the OpenSSL fips library on the "historical" list. There are about 15 Android-related configurations ending with Android 5.0 in 2018. So that is out. It doesn't exist, but hypothetically the sort of thing that would be suitable is: an OpenSSL fips build that ran on most current Android phones, was validated on some of them, and for which the validation deltas were done once a year or something.It doesn't have to be OpenSSL.
Any pointers?

@_date: 2020-11-22 22:46:59
@_author: Michael Nelson 
@_subject: [Cryptography] FIPS 140 validated crypto module on Android? 
"Bouncy castle..."
"I'd suggest avoiding doing native code work on Android."
"I'm pretty sure that Bouncy Castle is the default Java Cryptography Extension (JCE) used on Android platform."
Thanks for your input Sid, Kevin.
I had thought that the team I'm helping leaned towards OpenSSL, because as their desktop product used it, but they are open to a Java crypto library on Android. I agree, C on Android is not a first choice...
So yes, Bouncy Castle is included with Android. As the Wikipedia link from Sid says, to avoid name clashes when installing a FIPS 140-2 build, there is a build called Stripy Castle. But one can't just drop that in and inherit the official validation of Bouncy Castle on the platforms/configurations listed in its certificate/security-policy. FIPS 140 has the concepts of Vendor Affirmed, and User Affirmed, for various different configurations, and they entail various subtleties. I'll have to dig in further, sigh. I would have thought that some vendor would make a FIPS 140-2 module for Android. You'd think that there'd be a market.
