
@_date: 2001-07-02 13:05:34
@_author: Greg Broiles 
@_subject: non-repudiation, was Re: crypto flaw in secure mail standards 
"Unauthorized" does not mean "not a party to the contract".
Also, you seem to be confusing shifting evidentiary burdens with prevailing on an issue at trial. Or does "non-repudiation" now mean we won't bother with trials any more?
One of the basic problems with "non-repudiation" is that its proponents can't even which general body of law it exists within - e.g., is it an aspect of contract law? an evidentiary rule? a rule of civil or criminal procedure? Does it satisfy an existing burden of production, or persuasion .. or create a new one? Does it establish a rebuttable or a non-rebuttable presumption, or merely a permissible inference?
It's not at all clear to me that it's had the benefit of any real attention from anyone with a legal education, much less a careful explanation of how it'd fit into existing legal frameworks, and whether it rests upon existing statutes or caselaw or if it requires new legislation to take effect.
If you are aware of this scholarship, I would certainly appreciate a reference to it.
Oh, that's a question that's very important to US contract law, which is why courts aren't about to abandon that question - or the admissibility or evaluation of evidence relevant to that question - to the result of some Even if it were to do so, how would the finder of fact learn of the result of the computations? By oral testimony? In court?
No, it's not. It's a silly distraction that raises at least as many questions as it purports to answer, and it doesn't even answer the hard questions about contract formation. As Jon Callas pointed out, the attack discussed here is really a semantic attack on the meaning of a message, not its construction or delivery. Disputes about contracts are not likely to be about which words are included in a contract (not if it's a fully integrated contract, anyway - and if it's not, non-repudiation and digital signatures are worse than worthless) - they're likely to be about what those words mean, and whether or not the parties' behavior was consistent with the meanings of the words . . . or what the appropriate relief is, if one or more parties breached.
Cryptography will never fix that problem. You will need humans to read the words and listen to arguments and arrive at a reasonable understanding of their meaning - and to hear testimony and look at evidence and decide who's right and who's wrong. There's no way to short-circuit all of that with a little extra math.
"Not a legal concept" is a critically important distinction - non-repudiation is a feature or service which has no corresponding demand or application in the real world. Yes, it is possible to imagine parallel universes where something like that would be neat. But this isn't one of them.
I am a lawyer who's worked on a product for electronic transactions which used digital signatures - and I can tell you that there's very little customer interest and no real-world courtroom/litigator interest or relevance.
Non-repudiation might work in a lower-stakes or less-due-process environment like an in-house dispute resolution system, where there's no a priori expectation of fairness or reasonableness, and where one actor can mandate use of the system - e.g., if you have a signature from your manager on your vacation request, you get to take time off, even if it's later shown that the IT guy stole the keys off of a backup tape and signed a lot of vacation requests, because the finality of the decision/result is more important to the company than the expense of internal dispute resolution. On the other hand, I really can't identify a single application where I think that'd make sense - implementing a PKI system robust enough to support non-ludicrous non-repudiation is very expensive, and I don't think there'd be a lot of institutional resolve behind the "non-repudiation" rule of law if in fact the PKI system were misused - e.g., the IT guy gives everyone 3 months of vacation .. are they really going to pay everyone to stay home for 3 months? Are they really going to promote the IT guy to CIO and give him a corner office and a big raise, just because he got ahold of the Board of Directors' keyrings? Of course not.
So when, exactly, is it useful? As far as I can tell, it's a tradeoff of certainty for accuracy in decision-making - e.g., we'll have the legal system enforce judgements based on evidence which we all agree is (in some cases) false, but we think that's a better result than we'd get if we dug deeper into the facts, because we like speed and certainty over a slow, confusing litigation process.
It sounds like the real problem is the marketing hype that's accompanied, and continues to accompany, PKI products - e.g., "buy this and you'll win all your court cases!" "nobody will be able to escape a contract with you!" "if people sign something, they'll have to perform!" "you can be sure of who you're talking to" - etc.
The flaw discussed here is an example of a case where a cryptographic product fails to live up to the expectations of its users, because they expected some sort of cryptographic magic to make sure that their communications aren't used in an unexpected fashion - and that flaw looks especially dangerous if we assume that there's also some sort of legal magic which means that people who have digital signatures win (or lose) in court automatically.
We can cure the mismatch between expectation and delivery by changing the expectation, or changing what's delivered, or both.
Immediately, we can and should change user and developer expectations - we should distingiush between means (like cryptography) and ends (like security, or reduced risk), and remember that good techniques reduce risk and increase security, but don't create a state of perfection.
We also need to pay attention to the use of terminology when crossing domains of expertise - e.g., computer science and computer security people make messes when they make assumptions about law (like the "non-repudiation" distraction, and, generally, confusion about the difference between evidence and legal arguments), and legal people make messes when they make assumptions about technology (like the ambiguity regarding ephemeral copies and copy ownership for computer software, as discussed in 17 USC 117(a)).
Eventually, maybe we will build a system of legal rules and technological artifacts and processes that interoperate to create, preserve, and represent evidence of facts which may be of importance - but we haven't done that yet, at least not in the US. I gather that the UK may have adopted some of the wilder "non-repudiation" ideas which have been suggested and I think it's a grave mistake - both for the technologists who proposed that sort of thing, and for the lawmakers who were foolish enough to accept the gambit.
Greg Broiles
gbroiles at well.com

@_date: 2001-07-03 13:15:38
@_author: Greg Broiles 
@_subject: Crypographically Strong Software Distribution HOWTO 
Because current systems don't, to my knowledge, allow the creators of revocations to specify the reason(s) for revocation, I wonder if it would be better to rely on short-lived keys or certs which are renewed frequently during a person's membership or association with a group.
Specifically, a revocation which does not distinguish between "stopped working on the project because very busy at new job" and "left laptop with private key on public transit" or "discovered installed rootkit on machine storing unencrypted private key" does not help people decide whether they can reasonably install old(er) distributions of a software package. If the package was signed by a person who is no longer participating as a builder/distributor, their key should not be current - but that doesn't mean that everything which has been signed with their key should be considered untrusted, as it would be in the case of a key compromise.
In particular, consider the example of a person who's the last within a group to maintain a port/build/distribution on a hard-to-find platform, who then leaves the group - it may be difficult to find someone else to replace them, so new builds may not be available - but software which was once considered working and "official" shouldn't lose that status because of the change in group membership.
Certainly, in the best of all possible worlds, everyone who installs software would have access to online CRL and CA resources, and we wouldn't need to think about whether or not a particular snapshot of reality is misleading in an especially optimistic or pessimistic way - but I believe we should not design (only) for that world.
In the absence of semantic information about revocations, I think that expiration is a more appropriate model where no compromise is reasonably suspected, and that revocation is a more appropriate model where compromise is suspected or asserted.
Greg Broiles
gbroiles at well.com
"Organized crime is the price we pay for organization." -- Raymond Chandler

@_date: 2001-07-05 14:07:35
@_author: Greg Broiles 
@_subject: non-repudiation, was Re: crypto flaw in secure mail 
Well, that seems like an interesting application of the technology - the downside is that it doesn't really fix the whole chargeback problem, and it conflicts with existing federal laws & regulations in the US, which are old and unlikely to change.
Specifically - one aspect of the chargeback problem is consumers who say "who are these people? why are they charging against my account? I've never heard of them!", especially versus porno web sites or phone sex, and using a PKI non-repudiation scheme in this instance might be helpful, though it's worth keeping in mind that it rests on the assumption that end-users can and will preserve the security of a couple of big numbers (their private keypair) when currently they're frequently able to escape liability by claiming to have experienced a security breach related to their preservation and use of a single, much shorter pair of numbers - their credit card number and expiration date.
What it does not, and cannot, solve, are the other chargeback issues - where people admit they had an agreement, or at least some contact, with the merchant, but claim that the merchant has not performed in some or all aspects as promised - e.g., nothing delivered, or the order was cancelled, or the goods/services that were delivered were not what was promised, or were in some other way deficient such that the merchant is not entitled to In particular, reaching my second point above, in the US the Fair Credit Billing Act (15 U.S.C. 1666-1666j) preserves the right to make arguments about the correctness of a billing (including amount, computation, timing, and delivery/receipt of goods/services) between a customer and his/her issuing bank - and also allows them to raise defenses versus the merchant, related to quality of goods/services purchased, in many instances. Those rights can't be waived by contract.
Implementing non-repudiation as a countermeasure versus spurious "do not recognize" chargebacks seems to depend on all of the following:
(a) development and widespread adoption of a secure platform for key storage and Internet use, like the system "whose user interface and underlying technology is such that the signature is unlikely to be forged . ." described by James Donald above
(b) merchants forcing customers to adopt that platform and SET-like procedures in order to carry out transactions
(c) changing the Fair Credit Billing Act to make it more difficult or impossible for consumers to dispute items on their bills.
I believe that (a) is a very attractive goal but I'm skeptical that it'll ever happen, given the average person's attention to security and risk, and the low value they place on it . . . unless and until (c) occurs, which I consider very unlikely for political reasons - sure, lenders and merchants would love to eliminate chargebacks, but it sounds like political suicide to me. Who wants to be known as the senator who introduced legislation to make identity theft and credit card fraud easier, and harder to correct?
I'm also skeptical that (b) will occur - I'd group merchants into two categories, high-margin and low-margin. Where merchants earn a high margin on each transaction - like sex/porno sites - they might as well take a chance on questionable transactions, because even a high chargeback rate on their billings is still pretty good, so long as they don't get their acquiring bank too angry with them. Where merchants earn a low margin on each transaction - mostly online sales of physical goods (like Amazon, or computer hardware) - a "non-repudiable" signature to originate or approve a transaction doesn't address the likely other grounds for a chargeback, like failure to ship, or failure to ship on time, or disputes about quality. So .. high-margin vendors aren't likely to move towards (b), because they'd make more money without it, and low-margin vendors might not mind, but it won't solve most of their problems, and may drive away or inconvenience paying customers.
Many online merchants currently benefit quite a bit from the allocation of risk in the current chargeback regs - not because they like chargebacks, but because they like the (relative) ease with which people can enter into transactions, believing they have some recourse to effective dispute resolution in the event that the transaction fails. I buy things without a lot of worry online, because I know I can call my credit card issuer and dispute transactions if the merchant didn't perform, or if a transaction appears on my statement that I didn't authorize. If that weren't the case - if credit card transactions were irreversible (or "non-repudiable") like cash transactions, I'd only do them with people I'd mail cash to in advance, a la Paypal.
This all boils down to assigning risk to one party or another - most of the technical literature treats dispute resolution and the assignment of that risk as a simple or mechanical process, which is simply wrong - both factually in terms of how things work now, and in terms of what's likely to be attractive to all parties in a transaction.
We're aware lots of simple dispute resolution protocols now - like "might makes right" or "caveat emptor" but they turn out to be unsatisfying. Some people ascribe the need for dispute resolution to human weakness and greed. Other people ascribe the need for dispute resolution to unpredictable or unsolvable complexity in transaction outcomes, and the difficulty of anticipating and providing for them in advance.
Regardless of whose fault the failures are, humans seem to want and need a collection of overlapping and interlocking systems for arguing about transactions - and where one system appears unreasonably biased towards one constituency, another system will appear which shifts the balance towards a different group. (Consider, for example, the competing state-based and church-based courts for law and equity, respectively, which appeared in the English system - or the rise and expansion of federal court jurisdiction in the US where state court systems were perceived as unfair to the poor, racial minorities, or prisoners - or our current parallel systems for consumer disputes, with a relatively pro-merchant pro-lender credit reputation/lending system, and a relatively pro-consumer unfair trade practice court system in opposition.)
People who feel their needs aren't met or their problems aren't solved will not continue to act within a system they perceive as unfair or unresponsive - they'll do business elsewhere, not do business, or arrange for a parallel system more biased towards them. That's a tendency in human history and behavior much older and longer than anything we might dream up regarding non-repudiation, and we ignore it at our peril.
I believe it would be very difficult - but arguably* possible - to achieve all of (a) - (c) above; but I don't think even that would achieve the desired ends, because I don't think the system thus constructed would be used as intended - either it would not be used (much), or an entirely separate system would be created or modified to reallocate the risks of the non-repudiation system in a fashion more palatable to participants. Law and commerce are just like computer security that way - attackers go after weak points, not strong ones, so it's not helpful to over-fortify one aspect of an installation at the expense of others.
(* On the other hand, given the enthusiastic adoption of OS's with weak or nonexistent security features, the low adoption rate of OS's which have more defensible security configurations, and the indifference/hostility and lack of interest that SET and "internet wallets" enjoyed, I'm very skeptical. I know what my answer would be if I ran across a webpage which told me that, in order to do business with that vendor, I'd need to install another OS and browser on my computer, then make a cash-equivalent payment to them before they'd even ship my merchandise.)
Greg Broiles
gbroiles at well.com

@_date: 2001-07-07 11:49:15
@_author: Greg Broiles 
@_subject: Fwd: Re: Crypographically Strong Software Distribution HOWTO 
More from Rodney - I'm avoiding the "is law relevant?" branch of this thread because I think it's wandering off-topic, but can continue in private email if any of the participants think it's likely to be productive.
Greg Broiles
gbroiles at well.com
"Organized crime is the price we pay for organization." -- Raymond Chandler

@_date: 2001-07-29 13:34:54
@_author: Greg Broiles 
@_subject: Effective and ineffective technological measures 
a technological measure ''effectively protects a right of a
copyright owner under this title'' if the measure, in the
ordinary course of its operation, prevents, restricts, or
otherwise limits the exercise of a right of a copyright owner
under this title.
Greg Broiles
gbroiles at well.com
"We have found and closed the thing you watch us with." -- New Delhi street kids

@_date: 2001-06-01 09:43:50
@_author: Greg Broiles 
@_subject: Lie in X.BlaBla...  
They were trying to address any fraudulent (not "devious") use of a certificate to gain access or information, without regard to the technical No server will ever fall afoul of the law, because servers aren't subject to criminal liability. A person or an organization might fall afoul of the law if they use a certificate server in a fraudulent way. It is impossible to violate the WA law accidentally, because a conviction under the law requires that the convicted person act with the required mental state (the part that says "shall not KNOWINGLY", emphasis added). It is possible for a person to be careless with respect to what's been forbidden by the legislature, or cavalier with respect to what they believe is achievable by prosecutors, but that's not the same thing.
Have you considered that you might be making the same misguided assumptions about the law?
Greg Broiles
gbroiles at well.com
"Organized crime is the price we pay for organization." -- Raymond Chandler

@_date: 2001-06-03 11:00:31
@_author: Greg Broiles 
@_subject: Lie in X.BlaBla...  
It does no such thing. The law criminalizes the following -
(1) Knowingly misrepresenting one's identity or authorization to obtain a certificate which refers to a private key for creating signatures (Sec. 1(1))
(2) Knowingly forge a digital signature (Sec. 1(2)), which means -
         (a) creating a digital signature without the authorization of the rightful holder of the private key
         (b) creating a digital signature verifiable by a certificate listing as a subscriber a person who -             (i) does not exist
                 (ii) does not hold the private key corresponding to the public key listed in the certificate
         (RCW 19.34.020 (16))
(3) Knowingly present a certificate for which you are not the owner of the corresponding private key, IN ORDER TO OBTAIN UNAUTHORIZED ACCESS TO INFORMATION OR ENGAGE IN AN UNAUTHORIZED TRANSACTION. (Sec. 1(3), emphasis added because it's apparently common to stop reading halfway through that Which of the above do you consider "ordinary"?
Which of those "makes felons of us all?"
I've been using PKI-based technology for a little over 8 years now, if I remember correctly, and can't remember ever needing to do any of (1)-(3) above.
Let's not turn this into another one of those "Postal service will charge $.25 per email! Write your senator!" net legends, ok?
I don't think the new law is necessary - it's basically a retread of existing fraud and computer misuse statutes - but I don't think it criminalizes anything that wasn't criminal before. I haven't spent a lot of time crawling through Washington's criminal code - nor criminal courts, where the rubber meets the road - so I don't know if the "felony" status for this is new, or meaningful, or exemplary - it sounds like overkill, to my ears, but so does much of what comes out of our federal and state legislatures so I've stopped thinking that's remarkable.
In order to obtain unauthorized access to information or engage in unauthorized transactions?
I knowingly use firearms and automobiles all the time, too - but I don't worry overmuch about laws which criminalize their misuse, because I'm not misusing them.
If your fear is that the "unauthorized" word is susceptible to later re-interpretation (as a factual matter, not as a legal matter - e.g., retroactively revoked permissions) - I agree that's a difficult issue, but this law doesn't modify an existing danger, because Washington has already criminalized (as a felony, in some cases) "gaining access" to a computer owned by another person "without authorization". (RCW 9A.52.110) I also note that inducing another to sign a written instrument under false pretenses is already a felony. (RCW 9A.60.030).
I agree that this happens, and that it's bad, but this statute is too narrowly drawn to be much use in furtherance of that project.
If the " . . in order to obtain unauthorized access" language wasn't in section (3), I'd agree with you. But it's there, so I don't think this law presents a special danger, beyond the fact that it's referring to a new technology that's not necessarily well understood. I'd have preferred that the WA legislature wait another 5 or 10 years to see what turns out to be a real problem and what doesn't - but apparently they weren't inclined to. They've already got a statutory scheme at RCW 19.34 regarding certificate authorities and digital signatures; it doesn't seem surprising that they though it was appropriate to use criminal law to address misuse of or within that framework.
Greg Broiles
gbroiles at well.com
"Organized crrch.is the price we pay for organization." -- Raymond Chandler

@_date: 2001-06-05 09:40:59
@_author: Greg Broiles 
@_subject: Lie in X.BlaBla...  
Laws are not generally written to require "sane" configurations on the part of victims in order to achieve a successful prosecution. In particular, laws may be especially useful or helpful where potential victims are unable to or unlikely to provide their own effective security. If they could provide that security, the law would be unnecessary, or at least uninteresting and redundant. It's where people can't provide for their own security with "sane" systems or configurations that law is needed.
Lest you think that's just philosophical/academic noodling, don't forget that Microsoft is based in Washington, and that Microsoft has historically had a difficult time with secure design, secure implementations, and secure operations. Further, Microsoft has already built (and experienced embarrassment and insecurity) regarding the operation of a PKI-based code-signing hierarchy, and is going deeper, farther down that road with Win2K and XP and all of the rest. It's my understanding that every app in an XP system must be signed by a key that's been certified by Microsoft as a code-signing key, though I don't think I'm particularly up to date on the specifics of that security model. Also, remember that Microsoft's .NET and Hailstorm initiatives also depend on the security of an operating CA/PKI subsystem, and that they'll likely be hosted (at least in part) in Washington.
If your argument is "nobody will ever build an insecure system, be tricked into issuing a bad cert, and then want a big stick to use to go after the person who got the cert", you should meditate on the Microsoft situation for awhile. I don't have specific knowledge of Microsoft involvement in the drafting and passage process for this statute, but I'd be wildly surprised if they weren't involved at some level, simply because of their dominant position vis-a-vis the WA economy and their position of respect on technical matters among less technical people. If they didn't have some in-house PKI smartypants talk to the drafters of this bill, at least informally, I'd say Microsoft isn't doing right by its shareholders.
I must admit I'm at a loss. A few days ago you were up in arms because this statute was too broadly drafted, such that it was going to sweep up many unsuspecting non-guilty people - now you're saying that you think it should have been written even more broadly, so that it reaches even non-electronic identity theft. Are you just generally opposed to the idea of the statute, and now fishing for a plausible argument to justify your initial opposition?
I still think the statute is a pretty reasonable attempt at prohibiting PKI fraud which is unlikely to pose a great danger to people who behave in a normal fashion (e.g., doing things that would be legal in a sane environment).
I agree with you about this - even applied to this statute - but legislators think they've been elected to Do Something, and they do.
Greg Broiles
gbroiles at well.com
"Organized crime is the price we pay for organization." -- Raymond Chandler

@_date: 2001-06-21 09:25:47
@_author: Greg Broiles 
@_subject: Cryptobox (was Re: Edupage, June 20, 2001) 
The system has been discussed some on InfoAnarchy - It looks a lot like the principal designer(s) are unfamiliar with previous work on MIXes and Crowds, and haven't addressed the collusion-based attacks described in the literature. They also seem to believe they've got something called "compromised client detection" which prevents collusion through the use of digital certificates (!).
They're unwilling to release current source code or documentation, because they're planning to patent some aspects of their work; they've also said that the software will be released under the GPL and/or the LGPL.
Their design documents will apparently be available for review and comment after the implementation is finished.
Greg Broiles
gbroiles at well.com
"Organized crime is the price we pay for organization." -- Raymond Chandler

@_date: 2001-06-24 10:32:04
@_author: Greg Broiles 
@_subject: crypto flaw in secure mail standards 
The digital signature laws I've seen don't mention and don't support the notion of "non-repudiation", which seems to be an obsession among computer security people and a non-issue among legal people. The idea that something is "non-repudiable" or unarguable or unavoidable is nonsense. I use it as a clue detector - if someone talks about non-repudiation, they don't know much about US contract law.
The attack raised - at least as it's been summarized, I haven't gotten around to the paper yet - sounds like a good one to remember, but too contrived to be especially dangerous in the real world today. How often do you, or people you know, send short context-free messages to conclude important negotiations? And how often would you rely on a digital signature to assure you that everything was kosher if an otherwise promising deal or negotiation suddenly turned bad? And if you thought you had grounds for a lawsuit, wouldn't you send a message or make a phone call first, to the effect of "I was really surprised that you ended our discussion so abruptly. I understood our agreement to require you to continue to supply me with widgets for the next 3 years. If you're serious about ending our relationship early, I'm going to have to talk to my lawyer about that, because you've put me at a serious disadvantage, now that the spot price of widgets has gone up so much."
Sure, let's work on this and make systems better, so that signatures include context which helps prevent misunderstanding or active attack. But the sky isn't falling - this attack is a nuisance, becuase it makes its victims spend a few hours on the phone ironing out a misunderstanding - and it's not at all likely to lead to serious lawsuits.
I just ran across Jon Callas' earlier message in this thread and think he's right on the money. Don't sign tiny no-context messages. Don't get distracted by the cartoonish fantasy of non-repudiation.
Greg Broiles
gbroiles at well.com
"Organized crime is the price we pay for organization." -- Raymond Chandler

@_date: 2001-05-31 08:45:34
@_author: Greg Broiles 
@_subject: Lie in X.BlaBla...  
The statute didn't say "just because" or describe a technical architecture for an access control system - it criminalized the presentation of a certificate without "owning" the corresponding private key.
Matt's point about cert chains was apropos - and it's worth thinking for a minute about what it means to own a key, rather than simply possess a copy of it, as this seems to be creating a new kind of intellectual property, if there's such a thing as title to a keypair - but I don't think that the lack of specification of an authentication protocol in the statute implies that the legislature thinks there shouldn't be one, nor that any particular one should be used. I think they got this part of the statute just right. ( .. though I'm not sure it's time to start writing new laws for PKI)

@_date: 2001-09-30 23:26:13
@_author: Greg Broiles 
@_subject: Best practices/HOWTO for key storage in small office/home 
Are list members aware of any helpful resources describing best practices or HOWTOs for protecting cryptographic keys in a small office/home office I'm aware of the following approaches, given the assumption that good physical security is unavailable -
1.      Store keys & etc on hard disk inside a laptop which is kept in a safe or similar when not in use
2.      Store keys & etc on -
         a.      hard disk in removable carrier
         b.      3.5" floppy/CD/CD-R[W]/Zip disk
         c.      PCMCIA hard disk
         d.      PCMCIA memory
         e.      Compact Flash hard disk
         f.      Compact Flash memory
         g.      Storage-only smartcard
         .. each of which are stored in safe when not in use
3.      Generate & use keys on crypto smartcard (like Schlumberger's Cryptoflex) which is stored in safe when not in use
4.      Generate & use keys in dedicated crypto processor board
5.      Generate & store or generate & use keys stored across network in encrypted form
Obviously, much of the above just rewrites a hard problem (protect this room) into an easier but not entirely solved problem (protect the interior of this safe); and it ignores security for the keys while in active use versus hostile or sloppy software which may be running on the host. It also ignores the use of keystroke recorders or visual/audio surveillance systems to gather content which is available outside of the crypto envelope/tunnel. I'm trying to come up with a list of things people can do to improve (not perfect) their security, with modest expenditures and a little bit of extra effort during operations.
Also, is anyone aware of a currently shipping crypto smartcard reader/card/driver bundle which integrates well with any flavor of PGP or S/MIME mail software? The only example I'm aware of is Litronic's NetSign bundle (Cryptoflex + serial card reader + MSIE/Netscape drivers for $99) which apparently doesn't support USB nor PGP.
Greg Broiles
gbroiles at well.com
"We have found and closed the thing you watch us with." -- New Delhi street kids

@_date: 2001-10-16 11:30:05
@_author: Greg Broiles 
@_subject: First Steganographic Image in the Wild 
I agree, but if Congress isn't careful (and they don't seem to be in a
careful mood these days), they'll end up outlawing watermarking in
digital "content", which would do to the DRM (digital rights management)
industry what they tried to do to security researchers with the DMCA.
Perhaps the RIAA and SDMI folks will now come out in favor of
steganography in order to save their businesses.
Or maybe they be forced to rewrite their complicated protection schemes
to enable "stego escrow", so that federal agents can monitor the secrets
hidden inside published content, to make sure there aren't any hidden
messages in Anthrax albums.
Greg Broiles
gbroiles at well.com
"We have found and closed the thing you watch us with." -- New Delhi street kids
