
@_date: 2002-08-05 10:45:47
@_author: Amir Herzberg 
@_subject: Extracting uniform randomness from noisy source 
Oops, sorry, I wasn't clear above; AES_k is of course using the CBC_MAC using AES. When my message is interpreted to use simply AES as a block cipher, you simply don't get any compression, and therefore the output is also not uniform, as you illustrated nicely above... You must do CBC_MAC to sufficient number of blocks of noise, containing enough entropy, to get the pseudo-random output.
Also, I didn't mention another simple secure solution, which is to use universal hash function h_k(noise), where again k is a random key (again, such a key is necessary, but can be `burned into` the hardware). Universal hash functions are easy to implement and very efficient (much more than crypto hash functions).
Using SHA1 or other crypto-hash, I think relies on it being,  intuitively, `as good as` a random universal hash function. If you somehow key the crypto-hash, e.g. by using the IV as a key or by externally keying (e.g. use SHA1(k,noise)), you could test the function for  universal hashing property; it makes sense that such tests were done to standard hash functions. Does anyone know if that was done (and published)? However, even if this was done, I am not sure that you gain anything compared to using a (more efficient) universal hash function.

@_date: 2002-12-18 13:57:54
@_author: Amir Herzberg 
@_subject: Security, Cryptography and Privacy Track in PODC 2003: 
Dear Colleagues,
Please note that the deadline for submitting to PODC 2003, and in particular to the special track on Security in Distributed Computing, is rapidly approaching - Jan 31, 2003. This event is an excellent opportunity for interaction between the security, cryptography and distributed computing communities, and I hope many of you will send excellent submissions and of course participate. PODC will be held on Sunday July 13th - Wednesday July 16th, 2003, in
Boston, Massachusetts.
The registration fee includes two interesting pre-conference tutorials on Sunday, July 13. Both are on very active areas in security in distributed computing: Incentives and Internet Computation by Joan Feigenbaum and Scott Shenker, and
Content Protection Technologies by Jeffrey B. Lotspiech, Tushar Chandra, and Donald E. Leake Jr..
Abstracts are included below, and can also be found, with bios of the speakers, from the webpage: Expect lively discussion on these and other issues related to security and privacy in distributed systems, following these tutorials, as well as our very special invited speakers on security: Ross Anderson (U. of Cambridge), Butler Lampson (Microsoft), and Silvio Micali (MIT), all of which are known for their sometimes conflicting but always interesting views.
This year, PODC will also feature a series of lectures illustrating and celebrating the impact of the work of Michael Fischer, in honor of his sixtieth birthday, by: Leslie Lamport, Microsoft, Nancy Lynch, MIT, Albert Meyer, MIT, and Rebecca Wright, Stevens Inst. of Tech.. Topics are not announced yet but considering the speakers, I am sure these presentations will also be of interest to crypto/security folks.
So, please participate and submit and encourage others to do so; e.g. please post the CFP in relevant forums. PODC especially encourages student participation, and a prize will be given to the best student paper; we may be able also to partially sponsor some of the students participating and presenting, depending on budget.
PODC'03 received generous support from Microsoft and Sun Microsystems. If you are interested in making additional contributions, possibly for sponsoring a specific purpose, please contact the general chair, Elizabeth Borowsky, borowsky at cs.bc.edu (Boston College).
Looking forward to your submissions and to see you in PODC 2003!
Amir Herzberg

@_date: 2002-07-31 18:15:12
@_author: Amir Herzberg 
@_subject: building a true RNG 
I'm not sure what you mean by `randomness` being undefinable, but yes, I'm familiar with the standard definitions of the random oracle assumption/method. And I already agreed (I think with David Wagner) that it seems that when analyzing under the random oracle methodology, a call to the random oracle extracts the randomness from the physical (imperfect) source of entropy (one of us actually need to spend few minutes to confirm this proof is indeed as simple as it seems).
But that's not the question, I think. What we really want is some assumption which we can test SHA-1, or a new `hash` function (possibly with a public key) against, and which is sufficient to securely extract randomness.
This assumption cannot be the `random oracle` since clearly SHA-1 (and any other given function) is _not_ a random oracle...

@_date: 2003-12-15 10:07:38
@_author: Amir Herzberg 
@_subject: Super-Encryption  
Matt, may I suggest you state your goal, not just `super-encryption`? The term is often used for cascading of two encryptions, usually using two different cryptosystems. Under many attack models (not all e.g. not under CCA2),  this ensures tolerance of weaknesses of one of the two cryptosystems, i.e. the cascaded encryption is secure (under many definitions) if (at least) one of the two cascaded encryption schemes is But I don't think your use satisfies this as the sender signs rather than encrypts the first symmetric key; notice you use the wrong & misleading term `encrypt with the sender's secret key` to mean signing, which may be the root of this mistake.
Your solution is therefore essentially a combination of signature and encryption; this is not as simple as it seems and indeed I happened to work on this recently with a student, Yitchak Gertner, in his MSc thesis which he completed these days. I can provide details (or paper/thesis) but first I wonder if this is what you wanted to achieve at all.
Amir Herzberg
Computer Science Dept, Bar Ilan University
Lectures:

@_date: 2003-12-17 16:54:05
@_author: Amir Herzberg 
@_subject: Super-Encryption 
Matt, in your note below you explained finally what you really want: a secure combination of encryption and signature. I explain below why your current scheme is insecure. There are simple secure designs. With Yitchak Gertner, a student, we recently proved security of one such practical design, which is essentially Sign_sender ( Encrypt_RSA_receiver (message), PublicKey_receiver). I've just uploaded the draft journal version to  so you should be able to see it in a day or so (comments very welcome as I want to finish and submit it to journal soon). Your scheme is using the Sign-then-Encrypt order, which may not be secure for some (possibly weird) encryption schemes, although may be secure standard schemes such as RSA (but I don't think this was proven yet). But as I mentioned, your specific scheme is definitely insecure, details below.
Best regards,
Amir Herzberg
Computer Science Department, Bar Ilan University
Lectures: Homepage: So (as I said before...) here you are trying to authenticate the sender - using RSA to sign, not to encrypt. I again suggest you use the right terminology i.e. call is a signature (since this is what you do!). Notice also that for secure usage, there may be some small differences in the preprocessing for encryption vs. for signature with RSA.
And I believe you didn't understand (and answer) Ben's point. I'll try to clarify. Here's the sequence you suggested:
That's the part that appears unnecessary.
This is where you actually mean RSA_Sign. And why sign `symmetric key` ? Since the attacker will know this key, why not simply sign just `message` (or SHA1(message) if you want... normally we consider hashing as part of the signature process, i.e. I'll prefer to write Sign_RSA_SHA1(message)).
So here one would expect you to simply encrypt the message, i.e. cipher2=AES_symmkey2(message); Ben asks (and I agree), what gain do you have by encrypting cipher2? As I mentioned, one could hope for gain in confidentiality, e.g. when using different encryption schemes, but not when the first key (`symmetric key`) is revealed as in your protocol...
So steps 3 and 4 are `classical` hybrid encryption of cipher1. Hybrid encryption is a standard technique so I prefer to write it as one step, i.e. Encrypt_RSA_AES_receiverPK(message), or in your case,  Encrypt_RSA_AES_receiverPK(cipher1).
Woops! what does the message consist of ? It is quite clear from the steps above and below (omitted), that it contains both cipher2=Encrypt_RSA_AES_receiverPK(cipher1) and also RSA_Sign_sender (SHA1(message) + symmetric key). Now this is a good example of why it is good NOT to confuse signature with encryption... since it is quite obvious that the attacker gets to see SHA1(message). This is not desirable. First of all, SHA1 (or any hash) is not required to preserve complete confidentiality (e.g. in the standard, the goal is only stated as being a one-way function). So attacker may be able to learn something about message from SHA1(message). As a practical example, suppose there is a very small set of possible messages, say `buy XXX for YYY' where XXX, YYY are from relatively small sets. Then clearly the attacker can simply compute SHA1(m') for all possible messages m' and identify the message sent. So this is a real possible exposure to confidentiality.
Also, you wrote...
This (item 2) is not correct. The message may have been sent to Eve (and encrypted using Eve's public key), but then Eve re-encrypted symmetric key 2 (or cipher1 itself) with the public key of another party say Bob, and sent the message to Bob; Bob has no way of knowing that the intended receiver (by the original sender) was Eve.

@_date: 2003-12-18 10:31:01
@_author: Amir Herzberg 
@_subject: Super-Encryption 
This is still not very good. Comments:
a. In (2) you obviously mean Encrypt_RSA not Sign_RSA
b. In (4) you again send the hash of the plaintext in the clear. As I explained in my previous note, this is insecure, e.g. if plaintext is taken from a reasonably sized set (which is common), attacker can find the plaintext by hashing all the possible values. There are two fixes to this: sign the encrypted message and public key (which we proved secure for most PKCS including RSA) or encrypt the signed message (which may be vulnerable to Krawczyk/Bleichenbacher's attacks).
c. Notice also (again as I wrote before...) that you don't achieve your stated goal of identifying the intended receiver. This is also solved if you sign the ciphertext and the receiver's public key, or simply sign the identity of the receiver.
Anyway, I am repeating myself, so...
Best regards,
Amir Herzberg
Computer Science Department, Bar Ilan University
Lectures: Homepage:

@_date: 2003-12-23 11:18:17
@_author: Amir Herzberg 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
Ben, Carl and others,
Any alternative definition or concept to cover what protocol designers usually refer to as non-repudiation specifications? For example non-repudiation of origin, i.e. the ability of recipient to convince a third party that a message was sent (to him) by a particular sender (at certain time)?
Or - do you think this is not an important requirement?
Or what?
Best regards,
Amir Herzberg
Computer Science Department, Bar Ilan University
Lectures: Homepage:

@_date: 2003-12-24 12:27:11
@_author: Amir Herzberg 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
Ian proposes below two draft-definitions for non-repudiation - legal and technical. Lynn also sent us a bunch of definitions. Let's focus on the technical/crypto one for now - after all this is a crypto forum (I agree the legal one is also somewhat relevant to this forum).
In my work on secure e-commerce, I use (technical, crypto) definitions of non-repudiation, and consider these as critical to many secure e-commerce problems/scenarios/requirements/protocols. Having spent considerable time and effort on appropriate definitions and analysis (proofs), I was/am a bit puzzled and alarmed to find that others in our community seem so vehemently against non-repudiation.
Of course, like other technical terms, there can be many variant definitions; that is not really a problem (the community will gradually focus on few important and distinct variants). Also it's an unavoidable fact of life (imho) that other communities (e.g. legal) use the same term in somewhat different meaning.
So my question is only to people like Ben and Carl who have expressed, if I understood correctly, objection to any form of technical, crypto definition of non-repudiation. I repeat: do you really object and if so why? What of applications/scenarios that seem to require non-repudiation, e.g. certified mail, payments, contract signing,...?
Best regards,
Amir Herzberg
Computer Science Department, Bar Ilan University
Lectures: Homepage:

@_date: 2003-12-25 12:46:39
@_author: Amir Herzberg 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
Of course! I fully agree; in fact the first phase in the `trusted delivery layer` protocols I'm working on is exactly that - ensuring that the parties (using some external method) agreed on the keys and the resulting liability. But when I define the specifications, I use `non-repudiation` terms for some of the requirements. For example, the intuitive phrasing of the Non-Repudiation of Origin (NRO) requirement is: if any party outputs an evidence evid s.t. valid(agreement, evid, sender, dest, message, time-interval, NRO), then either the sender is corrupted or sender originated message to the destination dest during the indicated time-interval. Notice of course that sender here is an entity in the protocol, not the human being `behind` it. Also notice this is only intuitive description, not the formal specifications.

@_date: 2003-12-30 11:55:13
@_author: Amir Herzberg 
@_subject: Non-repudiation (was RE: The PAIN mnemonic) 
Ben, thanks, I'll change to this term (`evidence` instead of `non-repudiation`) since it appears from this thread that it may avoid confusion (at least for some people).
Best regards,
Amir Herzberg
Computer Science Department, Bar Ilan University
Homepage (and lectures in applied cryptography, secure communication and commerce):

@_date: 2003-12-30 12:11:06
@_author: Amir Herzberg 
@_subject: example: secure computing kernel needed 
I'm not sure I agree with your last statement. Consider a typical PC running some insecure OS and/or applications, which, as you said in earlier post, is the typical situation and threat. Since the OS is insecure and/or (usually) gives administrator priviledges to insecure applications, an attacker may be able to gain control and then modify some code (e.g. install trapdoor). With existing systems, this is hard to prevent. However, it may be possible to detect this by some secure monitoring hardware, which e.g. checks for signatures by the organization's IT department on any installed software. A reasonable response when such violation is detected/suspected is to report to the IT department (`owner` of the machine).
On the other hand I fully agree with your other comments in this area and in particular with...

@_date: 2003-02-03 10:23:26
@_author: Amir Herzberg 
@_subject: Deadline for Security in Distribute Computing - This Thursday! 
Dear Colleagues,
Due to the many requests for an extension, the program chair agreed to move the deadline for submission to PODC'03, and therefore also for the special track on Security in Distributed Computing. The new deadline is this THURSDAY, FEBRUARY 6.
I think this could be a really great event due to the convenient location (Boston), key note lectures (By Lampson, Micali, Anderson, Lamport, Lynch, Meyer and Wright - at least the first three on security), two security tutorials, and the opportunity for interaction between the distributed computing, security and crypto communities. And I'm sure there will be interesting presentations and discussions. Even if you can't submit, you should plan to attend.
As before, the Call For Papers can be found at
Instructions for how to submit electronically:
We look forward to your submissions! See you in Boston on July.
Best regards, and apologies for cross-posting (as well as for sending this reminder too late...),
Amir Herzberg
Chair of the Security in Distributed Computing Track

@_date: 2003-07-08 15:49:22
@_author: Amir Herzberg 
@_subject: Fwd: [IP] A Simpler, More Personal Key to Protect Online 
Tim: wonderful concise summary and I couldn't agree more. Thanks for taking the time to explain so nicely why this kind of systems, while cute, are not really helping applied cryptography (IMHO).
Best regards...
Amir Herzberg

@_date: 2003-06-02 18:25:13
@_author: Amir Herzberg 
@_subject: Maybe It's Snake Oil All the Way Down 
Erik is right: there must be very strong motivation to consider using a cryptographic mechanism/protocol which is not `standard` (de-facto standards are Ok). When this motivation is supposedly improved security, the new (supposedly more secure) primitive should preferably be composed with a supposedly-weaker but standard mechanism, in a `cryptanalysis-tolerant` manner, i.e. an attack should apply to _both_ mechanisms. But of course other motivations (e.g. performance) may rule out this approach.
The basic security argument underlying computational cryptography is always the fact that it withstood cryptanalysis. Even when we provide `provable security`, what the proofs really show is only that the mechanism/protocol  is as secure as some other assumption. The only exception is unconditional secure systems such as one-time pad, but these are usually not practical (e.g. due to key length requirements); in particular public key systems are always `only` computationally secure.
This is not really a problem and certainly not a motivation to design new systems, without a proof of security...
Best, Amir Herzberg

@_date: 2003-06-09 13:54:16
@_author: Amir Herzberg 
@_subject: An attack on paypal --> secure UI for browsers 
Here are two...
Yuan, Ye and Smith, Trusted Path for Browsers, 11th Usenix security symp, Ka Ping Yee, User Interface Design for Secure System, ICICS, LNCS 2513, 2002.
This issue is also covered somewhat by my article in CACM (May 2002).
Best, Amir Herzberg

@_date: 2003-06-09 15:00:27
@_author: Amir Herzberg 
@_subject: PODC'03 & Security in Distributed Computing: register and 
Dear Colleagues,
This is a (late) invitation to attend PODC 2003, July 13-16, Boston, MA. PODC (Principles of Distributed Computing) is the leading conference on distributed computing and algorithms. This conference is a great opportunity for interaction and cooperation between security/crypto folks and the distributed computing community, and we hope many of you can join us. It should also be fun.
IMPORTANT DATES
Conference dates: 13-16 July 2003
Early registration deadline: 18 June 2003
Hotel reservation deadline: 12 June 2003
SECURITY TRACK: Lectures, Tutorials, and Invited Talks
The security track will include (no separate registration/fee necessary):

@_date: 2003-06-10 13:06:11
@_author: Amir Herzberg 
@_subject: Applied crypto site - lectures, notes, etc... 
Hi all,
As some of you know, I'm working on a book titled `Intro to applied cryptography  for secure communication and commerce. It takes much longer than planned (but I'm still hoping to finish it one day!). Anyway, I've removed much of the chapters from the book site while I'm revising them, but... I've now put there ( detailed lectures (foils) covering most of the material. I've also put few chapters and hope to add the rest gradually... I hope this will be of some use and welcome your feedback and suggestions; also if you ask, I'll put you on a list of people to inform when I add chapters. I can also post to the list when I add significant new content.
Here is the list of lectures and chapters at this point:
Introduction to cryptography and security
Ciphers and Pseudo-Random Permutations
Secure, Randomized Encryption and PRG
Hashing, One Way Functions and Commitment; Continue
Authentication and shared key distribution
Public Key Cryptography
Digital Signatures and Certificates
Public Key Infrastructure (PKI)
Resiliency to penetrations and exposure cont': Proactive Security
Internet Security: intrustions, firewalls, Clogging (DOS)
Standards, I: Transaction Layer Security (TLS & SSL)
Standards, II: Internet Layer/Protocol security (IP-sec)
Standards, III: XML & Security
Trusted Third Party Protocols: notarization, certified delivery, escrow, Secure Payments and Banking

@_date: 2003-06-19 16:45:06
@_author: Amir Herzberg 
@_subject: grumpf: PODC (and security in distributed computing) 
At 09:12 18/06/2003 -0700, Richard Schroeppel wrote/grumpfed:
(and went on to complain about how I forgot to explain what the conference is about thereby wasting his time)
I agree; sorry!! Please put the blame on me not on Perry... (think of his position - should he reject such a message ? With or without a note to the author? Probably easier to just fix it by himself - I am sure Perry knows what PODC is...)
PODC= Principles of Distributed Computing (imho the leading conf. in this And this year it'll have a special track on Security in Distributed Computing (which I chair), and that's why I sent it to this list.
One small excuse: I previously sent on this list the CFP and there I wrote the full names ... Ok it's a poor excuse I know...
Topic: Distributed computing, and this year special focus on distributed security and crypto
Dates: July 13-17
Location: Boston, MA
URL: Best, a very apologetic Amir Herzberg

@_date: 2003-06-24 12:12:59
@_author: Amir Herzberg 
@_subject: DIMACS Tutorial on Applied Cryptography and Network Security: 
During August 4-7, I'll give, together with Markus Jakobsson, Angelos Keromytis, Hugo Krawczyk, and Rebecca Wright, a `crash course on cryptography and its applications to secure networking and electronic commerce`, in DIMACS (located in Piscataway, central New Jersey). For details, program etc. see This is a non-profit operation and indeed fees are very reasonable (regular 250$, and 125$ discount for students, post-docs, etc.; and this includes lunch etc.), and they even say they may give financial aid when necessary. I hope we  made a good program (much of it based on my lectures/foils, see at  and that this would be a nice opportunity for people to refresh themselves on some of the fundamentals and see some new perspectives, or simply to get a quick introduction to the areas of applied cryptography and secure communication and commerce. So please consider joining us, and forward to forums or individuals that may be interested.

@_date: 2003-09-09 18:31:16
@_author: Amir Herzberg 
@_subject: Digital cash and campaign finance reform 
Steve suggested (see below) that anonymous cash may be useful to hide the identities of contributors from the party/candidate they contribute to. I'm afraid this won't work: e-cash protocols are not trying to prevent a `covert channel` between the payer and payee, e.g. via the choice of random numbers or amounts. Furthermore even if the e-cash system had such a feature, it would be of little help, since (a) there will be plenty of other ways the payer can convince the payee that it made the contribution and (b) in reality, candidates will have to return the favors even without knowing for sure they got the money - kind of `risk management` - I'm not sure what we want is to allow big contributors to gain favors while not really making as big a contribution as they promised...
Best, Amir Herzberg

@_date: 2004-01-01 09:46:17
@_author: Amir Herzberg 
@_subject: why "penny black" etc. are not very useful (could crypto 
True. But, as Ben noted, the user of the machine could and should care about the resource. Now one may claim that many users don't pay attention to viruses stealing huge amounts of their CPU time. So I agree that the `waste CPU time to pay for sending mail` may have limited effect to stop spam. I also rather dislike the notion of wasting resources to send every e-mail. But where I quite disagree with you is when you say...
IMHO, your conclusion is wrong: cryptographic authentication could be a critical tool to stop spam; someone in our community should do this (write the software) already... How? E-mail (at least from new correspondents) must be signed by an `anti-spam mail certification authority (ASMCA)` - often the ISP of the sender. Recipient's mail client (or server) will reject mail (from new correspondents) not certified by a trustworthy ASMCA. If the mail was not rejected but later identified (by end user) as spam, the recipient client/ISP will not only know not to trust the sender's ASMCA, they will also have `proof` that this ASMCA approved (signed) this spam, so they can inform other ASMCA's and mail client/servers.
- ASMCA's have strong incentive not to approve spam. They'll use appropriate measures, mainly: filtering tools and punishing spammers (blocking accounts, charging fines, etc.)
- End users whose machines were broken into will be notified by their ASMCA (usually ISP), when it detects the spamming by filtering tools or by complaints, and will (1) know there's a problem and take measures to get rid of the spamming trojan horse and  (2) maybe be a bit more careful about the machine in the future.
Desired side effects:
- users will also enjoy e-mail authentication (and confidentiality could be added trivially) - which in particular will make it a bit more difficult for e-mail viruses to propagate.
What's the bug in this simple solution? If anybody wants to implement I'm willing to assist in developing/validating the protocols.
Best regards,
Amir Herzberg
Computer Science Department, Bar Ilan University
Homepage (and lectures in applied cryptography, secure communication and commerce):

@_date: 2004-07-04 12:30:21
@_author: Amir Herzberg 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
Following some of our discussions on this list, I tried to think more seriously on how crypto could be used for the basic current security threats of spoofing, phishing and spamming. Preliminary write-ups of the results are available in the following (or from my homepage):
# Protecting (even) Na?ve Web Users, or: Preventing Spoofing and Establishing Credentials of Web Sites, at # Controlling Spam by Secure Internet Content Selection, at I believe many of you will find some interest in (criticizing?) the new ideas and proposals, and I'll be very grateful for any feedback; the works already benefited a lot from some discussions on this list, including some of you who asked me essentially to `write up your ideas`.
I am also very interested in working with potential implementors; I am already working on implementations with students, but, additional and potentially more experienced developers may help us turn some of these ideas into reality.
BTW, I'm already using the anti-spamming mechanism (trusted logo and credentials area) we developed for Mozilla, and it works great; I hope we'll feel soon confident enough with the code so we'll be able to put it in the public domain. Experienced Mozilla developers who will be willing to help test and evaluate the code are invited to contact me.

@_date: 2004-06-15 09:17:40
@_author: Amir Herzberg 
@_subject: recommendations/evaluations of free / low-cost crypto libraries 
I will appreciate experience-reports/evaluations/comparisons with free or low cost (and in particular  zero `per seat` cost) crypto libraries, especially in C / C++ (or links to web-sites containing them). If I'll get substantial useful information (off-list) I'll try to compile it and send to the list. Important aspects include reliability, functionality, performance, documentation, cost (for development system - no `per seat` cost!), and licensing terms (in particular can it be used for commercial products, and any restrictions).
Thanks a lot...
