
@_date: 2001-08-31 21:22:00
@_author: Victor Duchovni 
@_subject: Implementations of AUTH TLS in FTP clients (and servers)? 
I am looking for an FTP client (Open Source) for SunOS 5.X that
implements AUTH TLS as in:
especially one that interoperates with whatever SSL magic
is present in WS_FTP Server 2.0:
It would be especially useful if the client also supported SOCKS 5.
A server might one day be useful, but is not the focus of the current
Does anyone have any pointers to and useful reviews of such a beast.

@_date: 2001-09-10 15:01:30
@_author: Victor Duchovni 
@_subject: Sen. Hollings plans to introduce DMCA sequel: The SSSCA 
proceedings.  Unlike in civil proceedings the copyright holders don't
have to spend a dime defending their DMCA or (proposed) SSSCA rights,
the taxpayer foots the bill.

@_date: 2001-09-10 15:01:30
@_author: Victor Duchovni 
@_subject: Sen. Hollings plans to introduce DMCA sequel: The SSSCA 
proceedings.  Unlike in civil proceedings the copyright holders don't
have to spend a dime defending their DMCA or (proposed) SSSCA rights,
the taxpayer foots the bill.

@_date: 2002-07-22 08:59:06
@_author: Victor.Duchovni@morganstanley.com 
@_subject: It's Time to Abandon Insecure Languages 
False sense of security. Most security bugs reported these days are issues
with application semantics (auth bypass, SQL injection, cross-site
scripting, information disclosure, mobile code execution, ...), not buffer
overflows. Only languages that operate on semantic specifications stand a
chance, and even then the specification could be wrong or incomplete...

@_date: 2002-07-22 12:08:04
@_author: Victor.Duchovni@morganstanley.com 
@_subject: It's Time to Abandon Insecure Languages 
This is more indicative of CERT's focus than the relative frequency of
security issues. The fact that a large fraction of e-commerce merchants
let you set the price for the goods you buy is in practice a larger threat
than the widely publicized buffer overflows.
Semantic security bugs in individual web sites do not rate highly enough
on Cert's seismograph, but are in practice far more common.

@_date: 2002-07-22 12:50:45
@_author: Victor.Duchovni@morganstanley.com 
@_subject: It's Time to Abandon Insecure Languages 
CERT is far from a comprehensive source of security bug reports. Does
anyone have statistics of bug types for Bugtraq or Mitre's CVE?
I get daily bug reports via FS/ISAC. Most of these are not
sufficiently severe or broadly applicable to be CERT advisories. These are
mostly application logic issues, but the evidence is I must admit
anecdotal. I don't have survey results.

@_date: 2002-10-21 22:39:12
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Why is RMAC resistant to birthday attacks? 
The RMAC FIPS draft does not appear to explicitly state when RMAC is
useful. What is the scenario in which (presumably unlike some other keyed
MAC algorithms) RMAC is resistant to birthday attacks? More broadly for an
arbitrary keyed MAC (in a plausible application!) how does the birthday
attack come into play?
With unkeyed message digests encrypted by a public key, the attacks are
clear, Alice sends Bob message A, Bob agrees to message A, and signs it.
Later Alice claims that Bob signed message B. The birthday paradox
helps Alice because she can generate lots of minor variants of each
message, generate ~sqrt(2^n) hashes of each and have a good shot at
finding a collision.
With keyed MACs Alice and Bob share the same secretkeys, either can
freely generate messages with correct MAC values, so the MAC cannot be
used as evidence to a third party that Alice is the signer of the
In this case the attacker is clearly not either Alice or Bob. So Eve wants
to convince Bob that a message really is from Alice. What does Eve do?
Does Eve somehow entice Alice to send ~sqrt(2^n) messages to Bob? How does
the birthday attack come into play when the attacker cannot independently
test potential collisions?
Please pardon the naive question, I just want to understand the premises
of the problem to which RMAC is a solution.

@_date: 2002-10-22 10:15:46
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Why is RMAC resistant to birthday attacks? 
This is interesting, but it does not help me to understand what threat
model is addressed RMAC, or more generally how do birthday attacks play
out against (shared secret) keyed MAC algorithms. The details of the RMAC
algorithm itselft are not at issue here, I want to understand the problem
so I can use the solution under the right conditions.

@_date: 2002-10-22 15:17:37
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Why is RMAC resistant to birthday attacks? 
I know, but this is not my question.
So the threat model assumes that there is a MAC oracle. What is a
practical realization of such an oracle? Does Eve simply wait for (or
entice) Alice to send enough (intercepted) messages to Bob?
Are there any other birthday attack scenarios for keyed MAC? In many
applications the collection sufficiently many messages between Alice and
Bob is simply out of the question. In such cases if Eve cannot mount the
attack independently and cannot collect 2^(n/2) messages from Alice to
Bob, presumably RMAC does not offer an advantage over any other keyed MAC.
I am not confused by the RMAC algorithm or so the associated work factor
estimates, I want to understand the assumptions (threat models) behind the
work factor estimates. Does the above look right?

@_date: 2003-04-28 16:22:39
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Fwd: [Asrg] A New Plan for No Spam / Velocity Indicator 
Seems rather naive to downright ignorant to me:
  1/3rd of the emails were not correctly addressed to the recipient.
  These messages could be excluded by simply enforcing the RFC822 message
  standard that requires every message to have a valid To: CC: or BCC:
  field identifying the recipient, making adjustment where necessary to
  account for messages relayed through mailing lists.
[END QUOTE]
Since when does the recipient get to see the contents of the BCC field?
Since when do the recipient and sender necessarily agree on the
recipient's email address?
This requires global replacement of all MUA software and hardware. This
fails to address BCC email (e.g. mailing lists). This fails to address
in-transit header rewriting. (The "To:" header is not suitable for
signing, the signed recipient would need a new header). The chances of a
a free system of this sort gaining any wide acceptance appear minimal to
me a royalty based system seems substantially less likely to take hold.

@_date: 2003-12-07 12:00:38
@_author: Victor.Duchovni@morganstanley.com 
@_subject: yahoo to use public key technology for anti-spam 
To avoid replay attacks one needs to sign a string that is tied to a
specific message or time period and is invariant under forwarding through
various relays and gateways. The header and envelope sender and recipients
are often subject to rewriting, the Message-Id can be cloned. What exactly
would they have the sender domain sign.
I am skeptical that such a proposal can acquire any traction. Also curious
to see the details...

@_date: 2003-12-07 14:58:40
@_author: Victor.Duchovni@morganstanley.com 
@_subject: yahoo to use public key technology for anti-spam 
This is misguided, but we should not start that flame-war here.

@_date: 2003-12-31 14:43:27
@_author: Victor.Duchovni@morganstanley.com 
@_subject: why "penny black" etc. are not very useful 
Wildly unrealistic IMHO. I would predict that email transmission *will*
remain essentially free.  Spam detection software will be deployed more
broadly, and spammers who use trojaned machines will at some point in the
not too distant future (when the DAs wake up to this widespread criminal
activity) be successfully prosecuted.
Of the ~750000 messages inbound message recipients a day on the gateways I
manage, 40% are rejected by RBL lists and private blacklists/content
checks. 5% of the remainder is caught as spam by a commercial anti-spam
content filter. The filter's detection rate against this RBL pre-screened
sample is ~90%, the false positive rate is less than 0.01%. So we get rid
of ~99.5% of spam with no hash-cash. This is good enough. I am not about
to implement any CPU burning stamp generators any time soon.
The recent Microsoft and Yahoo announcements get a lot of publicity, but I
am skeptical that they will ever be widely adopted.
It is reasonable to note that Microsoft sells a lot of the clients
(Outlook & OE), so they have a better chance of getting their technology
adopted, but even Microsoft has a hard time getting users to upgrade from
Windows 98/Office 97 which continue to perform well enough for most users
(security flaws and all).

@_date: 2003-07-09 10:32:34
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Voltage - Identity Based Encryption. 
No, this (like Kerberos) works best in a federated model. Each
organization (or group of organizations that trust a common third
party and have mechanisms to authenticate their users to said party) runs
a key server.
The recipient's address together with the organization-wide public key of
the recipient's server (s.P) allow the sender to unilaterally construct a
session key that is only recoverable by recipient's private key which is
derived from the recipient's server secret and the recipient's identity.
The recipient needs to (at least once) authenticate to *his* server and
get his private key.
The server secret "s" (like a KDC master key in Kerberos) yields
*everyone's* private key in the organization in question. Unlike a KDC the
database consists only of a single secret! If a user's key is compromised,
the user needs to change "identities" (email adddreses). If a server key
is compromised, ...
This obviates the need for key exchange between individual users, but
creates a need for a TTP in each participating organization or consortium.
I look at this as a Kerberos alternative with a public/private master key.
Creating a session key does not involve any calls to the KDC because the
KDC public keys are published.
Interactive user principals can avoid storing their keys in persistent
storage, by authenticating each time (the mail client starts),
disconnected users or server applications store secrets in access
controlled storage (analogous to keytabs).
In an AD environment the authentication to the new key server can use the
"real" Kerberos...
Unlike the real Kerberos this does not require (n^2)/2 keys, but it
does require (n^2)/2 key exchanges of n keys, otherwise one gets back to
Verisign style models for server key signing.
Key management does not ever go away! How does one secure the key
management? (Bilaterial diplomatic cases chained to wrists work, but are
difficult on an Internet scale)...
If all server keys are held in write-only tamper-proof hardware, perhaps
server key revocation will be rare and key exchanges might be less
As on online protocol, it resembles Kerberos even more, but perhaps works
better accross organizational boundaries. Each organization periodically
obtains via some secure channel the public keys of their business
partners. These are leveraged to create secure channels between users.
The channels are not server mediated so unlike a VPN or SMTP+TLS, the
crypto is end-to-end with the servers at each site holding a secret that
can compromise every user.
I doubt Voltage.com will be able to sell everyone on a single server for
the whole Internet so the bilateral key management problem does not go
away, it just gets factored into clumps...
Please correct my impression if I got this completely wrong...

@_date: 2003-06-09 14:56:25
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Keyservers and Spam 
There are plenty of sources from which harvest email addresses,
including the archives of this and other public mailing lists. Spam
prevention should not require one to keep one's email address a secret.
While lurking does cut down on spam, it is not an option for those who
participate in a public discussion forum.
If no-one knows you exist, don't publish your key on a keyserver...

@_date: 2003-06-24 22:45:43
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Mozilla tool to self-verify HTTPS site 
How many users can remember MD5 checksums??? If they were rendered into
something pronounceable via S/Key like dictionaries it might be more

@_date: 2003-05-13 12:32:01
@_author: Victor.Duchovni@morganstanley.com 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?)  
This started in Sep 2002, the first example was the JEEM trojan. I got two
emails via JEEMs just today, a few thousand JEEMs are listed at
The JEEM trojan installs an open SOCKS 5 proxy, an open HTTP proxy and and
open SMTP relay on three random looking TCP ports in the range 3000-9999.
Because the JEEM proxies lack access controls, they are relatively easy to
identify and blacklist. More advanced trojans could be invisible except to
authenticated spammers, it is hard to say whether these exist at this
time, but eventually they will.
I think that this delivery channel will remain popular primarily for
delivery of illicit content (offshore underage porn, etc.).

@_date: 2003-10-02 17:17:24
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Monoculture 
Speaking as a Postfix developer, it would be very useful to have a
non-blocking interface that maintained an event bitmask and
readable/writable callbacks for the communications channel, allowing a
single-threaded application to get other work done while a TLS negotiation
is in progress, or to gracefully time out the TLS negotiation if progress
is too slow. This means that the caller should be able to tear down the
state of a partially completed connection at any time without memory leaks
or other problems.

@_date: 2003-09-06 15:53:11
@_author: Victor.Duchovni@morganstanley.com 
@_subject: cryptographic ergodic sequence generators? 
Why does it need to be strictly non repeating? Is 2^n always large enough
that sequences of length > 2^n are uninteresting?
If sequences longer than 2^n are practical and *every* subsequence of 2^n
elements is free of duplicates the entire thing is periodic, this may or
may not be a problem...

@_date: 2003-09-09 12:51:52
@_author: Victor.Duchovni@morganstanley.com 
@_subject: X9.59 where is it? 
Is X9.59 actually in use for consumer retail transactions anywhere?

@_date: 2003-09-19 10:34:33
@_author: Victor.Duchovni@morganstanley.com 
@_subject: quantum hype 
Actually it still is F = m.a, but the numbers depend on the observer.
F=m.a is a fundamental consequence of the conservation of momentum, which
in turn is equivalent to the isotropy of inertial reference frames. This
fundamental princinple was reinforced by Einstein's relativity which made
conservation of momentum work accross a much larger range of physical
phenomena (classical dynamics + electromagnetism + gravity).
Quantum mechanics introduces into our understanding not only new
"approximate truths", which are subject to later revisions, but also some
fundamental concepts, that will be features of all future theories.
I am not necessarily claiming that the non-cloning theorems are on as
solid a footing as conservation of momentum and energy, but it is
quite plausible that while quantum *dynamics* will continue to be
refined by future theories, that quantum statistics is fundamental.
This still does not mean that QKD is commercially useful, but what it does
mean is that there is little reason to believe that the physics will be
found wrong. QKD *is* good and interesting physics. QKD is not
commercially sound security technology for terrestrial fibre optics.
Out in space, with line of sight communications, two infosec minded
starship captains might engage in QKD secured crypto some day :-) They
will still face the black box problem, and need to secure the channel
between the person and the device (internal security). It seems unlikely
that they will not have any simpler (easier to trust and verify, closer to
the endpoints of communication) technology available.

@_date: 2003-09-26 09:47:20
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Reliance on Microsoft called risk to U.S. security 
While part of the security problems in Windows are Microsoft specific, in
my view a large part is inherited from earlier graphiscal desktop designs,
and is almost universal in this space. Specifically, when a user clicks
(or double-clicks) on an icon there is not a clear distinction between
"Run" and "View". Instead we have the polymorphic "Open".
If files always opened in a safe viewer, (e.g. clicking on a .pl file
fired up an editor, not the ActiveState Perl interpreter) a good part of
the security problem with Graphical desktops, Microsoft's, Apple's,
RedHat's, ... would be solved. The bizarre advice we give users to not
open message attachments would be largely unnecessary (one also needs to
close the the macro invocation problem, but this is not insurmountable).
It is my contention that so long as activating an icon does not
distinguish between "Run" and "View" all Graphical Shells will be

@_date: 2003-09-27 11:12:48
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Reliance on Microsoft called risk to U.S. security 
And what privileges should the Perl interpreter run with when I click on a
".pl" file? How would the graphical shell know what privileges to assign
to each file?
Also security is not closed under composition, two individually secure
components can combine to produce an insecure system. I think that no
such secure *non-trivial* least privilege system exists for a
graphical general purpose computer either in theory, or in practice.
On the other hand a *trivial* privilege system: "View" (zero privs) vs.
"Run" (full privs) is viable, and is one of the pre-requisites for a more
secure UI, along with the previously discussed trusted path issues,
non-spoofing of the security interface, ...

@_date: 2003-09-27 15:48:29
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Reliance on Microsoft called risk to U.S. security 
You have not met my users! This is really rather naive. Users don't
understand pop dialogues, they raise their stress level, always clicking
"yes" makes the problem go away.
See above.
What fraction of "real" users will be able to use these systems? Will
users really understand the composition properties of security policies?

@_date: 2004-04-03 14:59:46
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Do Cryptographers burn? 
It seems most unlikely that anyone's opinion on this subject will be
anything other than light comic relief. Rent a good conspiracy-theory
holywood flick, I assure you it will be substantially more entertaining!

@_date: 2004-08-31 15:50:55
@_author: Victor Duchovni 
@_subject: Compression theory reference? 
More simply:
Choose any injection (e.g. lossless compression) from the set of finite
length messages to the set of finite length messages. Suppose for
*some* finite number N the injection has the property that no message
of length *at most* N bits encodes in more than N bits (some might get
longer while staying under N+1 bits, some shorter we don't care). Since
there is a finite number of messages that are N bits or less, and the
injection is from a finite set to itself, the injection is a bijection
(no missed outputs). So from the weaker assumption we conclude that all
N bit or less outputs correspond to N bit or less inputs, and therefore
that the injection we are looking at for the given number N never encodes
a message of length N+1 or greater in N bits or less.
N has the above (weaker for any *given* N than always compressing)
property, never encodes a message of length N+1 in N or less bits. The
only candidate injections are then simple length-preserving permutations.
This is a question in elementary finite set theory, not computer science
(whatever that is :-). All proofs will involve some mathematics. The
above is I think simpler than your original argument and is the simplest
I can come up with...

@_date: 2004-08-31 18:31:49
@_author: Victor Duchovni 
@_subject: Compression theory reference? 
This proof as written (the theorem is still true of course) relies on
the algorithm always compressing, rather than never expanding. It is
much simpler as a result, is there an equally simple argument to prove
that all non-expanding codes never compress?
Note that it is possible to turn any compressor into one whose expansion
is at most one 1 extra bit:
If F(x) is shorter than x by at least one bit output 0|F(x) if F(x)
is the same length as x or longer output 1|x. So we can lose 1 bit of
efficiency in compressed strings to gain at most 1 bit of overhead in
uncompressed strings.

@_date: 2004-12-22 12:10:18
@_author: Victor Duchovni 
@_subject: SSL/TLS passive sniffing 
Actually reasoning along these lines is why Lutz Jaenicke implemented
PRNGD, it is strongly recommended (at least by me) that mail servers
use PRNGD or similar.  PRNGD delivers psuedo-random numbers mixing in
real entropy periodically.
EGD, /dev/random and /dev/urandom don't produce bits fast enough. Also
Postfix internally seeds the built-in OpenSSL PRNG via the tlsmgr process
and this hands out seeds for smtp servers and clients, so the demand for
real entropy is again reduced.
Clearly a PRNG is a compromise (if the algorithm is found to be weak we
could have problems), but real entropy is just too expensive.
I use PRNGD.

@_date: 2004-12-22 22:53:59
@_author: Victor Duchovni 
@_subject: SSL/TLS passive sniffing 
I think I made a mistake, my primary email servers don't have /dev/urandom
and the choice between EGD and PRNGD came down clearly on the PRNGD side,
but indeed /dev/urandom should suffice on Linux and other systems. Postfix
takes additional steps to reduce demand for raw entropy (in the tlsmgr
process, ...) but /dev/urandom works fine as an external entropy source.
I have not followed the debian issue, perhaps that really is just an
Exim+TLS design problem...

@_date: 2004-01-02 10:40:29
@_author: Victor.Duchovni@morganstanley.com 
@_subject: Meander - from "penny black" back to TCB protections 
No, this is not known to scale well to large sites. Also widespread
adoption of sender verification encourages joe-jobbing, for the victim the
torrent of spam bounces and abuse complaints are worse than spam (one of
my users was getting 10000 messages for a while...).
A high quality open proxy/open relay RBL combined with a good spam
detector (Spam Assasin or a commercial offering) are good enough in
A lot of the damage to email infrastructure associated with spam is caused
by misguided spam-fighters, rather than spam itself.
I am waiting for the law to be enforced, not for CPU waste proofs.

@_date: 2004-01-02 12:19:52
@_author: Victor.Duchovni@morganstanley.com 
@_subject: why "penny black" etc. are not very useful (could crypto  stop 
This is impractical. No such infrastructure will exist. Trust management
on the scale your propose is not feasible or desirable. The key feature of
email and what makes it the Internet's "killer application" is that anyone
can send email to anyone else. No central authority is needed to vouch for
the sender or the content.
Again, we do not need to cripple email to stop spam. For my mailbox, of
the 1000 spam messages a month that get past the RBL, 925 are caught by
the spam filter. I am left with 2-3 spam messages a day, why again do we
need to cripple the most important application on the Internet?

@_date: 2004-07-05 18:55:08
@_author: Victor.Duchovni@MorganStanley.com 
@_subject: Use cash machines as little as possible 
Why on earth do they suggest that using ATM cards in retail stores is
safer than using them in an ATM machine? I know about problems with ATM
machines in convenience stores, but why is use of ATM machines in bank
branches less safe than point-of-sale ATM transactions at a supermarket?

@_date: 2004-05-28 15:20:52
@_author: Victor.Duchovni@MorganStanley.com 
@_subject: Yahoo releases internet standard draft for using DNS as public 
And indeed some will view the various sender authentication proposals as
misguided solutions for the wrong problems, while others will be simply
disinclined to spend money to upgrade their working "just fine" MTAs so
these will by no means be universally adopted.
The spammers will increase the cost of receiving a clean mail stream, but
if that increase is not too high and the filter accuracy is high enough,
email will continue to work just fine.
The bargain basement email providers may be disinclined to pay more to
provide a commodity service where the competition often offers the service
at no cost. There may in the future be a larger market for premium email
services, with a second market for low to zero cost mailboxes subjected to
a kinder, gentler spam stream (likely from the email provider).
How soon will the spammers get into the business of hosting free mailboxes
for people who actually buy spamvertized products. Much easier to send the
spam to their own users, let them indicate their preferences, set up
forwarded notifications, ...
What things brings us to is that a major part of the problem are of course
the people who buy the spamvertized products. So long as there is a new
sucker born every minute, there will also be someone ready to take
advantage of same.
Can spam be solved through end-user education? "Do not buy spammed
products" campaign signs right next to the public health signs against
smoking? "How to not be this minute's sucker" education in schools? :-)
Is spam really that important a societal ill, if the spammers had better
parenting, schooling and better career prospects would they still spam or
litter the sidewalk? Are human societies free of spam and more serious
ills possible or even desirable (what is the cost of eliminating the
We get too carried away with spam, as threats to our way of life there are
far more serious problems...

@_date: 2004-11-30 13:39:42
@_author: Victor Duchovni 
@_subject: SSL/TLS passive sniffing 
The third mode is quite common for STARTTLS with SMTP if I am not
mistaken. A one day sample of inbound TLS email has the following cipher
8221    (using TLSv1 with cipher DHE-RSA-AES256-SHA (256/256 bits))
6529    (using TLSv1 with cipher EDH-RSA-DES-CBC3-SHA (168/168 bits))
 186    (using SSLv3 with cipher DHE-RSA-AES256-SHA (256/256 bits))
 117    (using TLSv1 with cipher RC4-SHA (128/128 bits))
  59    (using SSLv3 with cipher RC4-SHA (128/128 bits))
  40    (using SSLv3 with cipher DES-CBC3-SHA (168/168 bits))
  28    (using TLSv1 with cipher RC4-MD5 (128/128 bits))
  16    (using SSLv3 with cipher EDH-RSA-DES-CBC3-SHA (168/168 bits))
  14    (using TLSv1 with cipher DES-CBC3-SHA (168/168 bits))
   1    (using SSLv3 with cipher RC4-MD5 (128/128 bits))
   1    (using SSLv2 with cipher DES-CBC3-MD5 (168/168 bits))
it is my perhaps misguided impression that the both the EDH and the DHE
cipher-suites provide PFS. Is there in fact a difference between EDH
and DHE?

@_date: 2004-11-30 22:53:38
@_author: Victor Duchovni 
@_subject: SSL/TLS passive sniffing 
I only have stats for accepted mail, not for invalid recipients, RBL
rejects (apologies to gnu at toad.com), and so on. Of the accepted mail in
the sample, TLS accounts for 15212 out of 144843 messages or 10.5%. So TLS
is not uncommon (volume weighted) among email senders. Email encryption
is mostly opportunistic: peer verification is the exception rather
than the norm. For example, Sendmail.com's certificate is self-signed
and the CN (tls.sendmail.com) does not match the name of the MX host
    $ host -t mx sendmail.com
    sendmail.com mail is handled by 50 righton.sendmail.com.
    sendmail.com mail is handled by 10 smtp.sendmail.com.
    $ openssl s_client -starttls smtp -quiet -verify 3 \
    	-CAfile /etc/postfix/serverCAs.pem \
    verify depth is 3
    depth=1 /C=US/ST=California/L=Emeryville/O=Sendmail, Inc./OU=IT/CN=Sendmail Certification Officer/emailAddress=rootca at sendmail.com
    verify error:num=19:self signed certificate in certificate chain
    verify return:1
    depth=1 /C=US/ST=California/L=Emeryville/O=Sendmail, Inc./OU=IT/CN=Sendmail Certification Officer/emailAddress=rootca at sendmail.com
    verify return:1
    depth=0 /C=US/ST=California/L=Emeryville/O=Sendmail, Inc./OU=IT/CN=tls.sendmail.com/emailAddress=postmaster at sendmail.com
    verify return:1
    220 foon.sendmail.com ESMTP Sendmail Switch-3.1.7/Switch-3.1.7; Tue, 30 Nov 2004 19:44:59 -0800
This is not surprising. Since MX lookups are not protected by any
cryptographic mechanism, sites that want to exchange email securely
with the *right* TLS peer need to bypass MX lookups and hardcode each
other's MX hosts in their mailer (aka transport) tables, otherwise peer
verification is largely useless, anyone who can redirect the SMTP stream
can also redirect the DNS queries (or did the former via the latter).

@_date: 2004-10-25 09:45:31
@_author: Victor Duchovni 
@_subject: Are new passports [an] identity-theft risk? 
Is the problem discriminating the RFID response, or supplying power so
it can respond at all?
How much power does the reader need to emit to activate the RFID? What
sort of equipment is needed to deliver the power directionally?

@_date: 2004-09-07 12:42:31
@_author: Victor Duchovni 
@_subject: Maths holy grail could bring disaster for internet 
I bet the reporter had to scrape the bottom of the barrel to find someone
willing to make this claim. Nice for making a sensational article, but
otherwise entirely worthless.
Whether the proof is complete/correct or not, the gist of it seems to be
a construction of a Hilbert-space of entire functions in whose context
the zeta function, suitably transformed so that the critical line is
mapped onto the reals, becomes a self-adjoint operator. To go from
this to the reported claim is at least premature and likely ludicrous.

@_date: 2004-09-07 15:37:53
@_author: Victor Duchovni 
@_subject: Maths holy grail could bring disaster for internet 
RSA is useful for more than X.509... and of course the reporter is prone
to flights of fancy...

@_date: 2004-09-10 11:40:08
@_author: Victor Duchovni 
@_subject: Perplexing proof 
So at least now we have a named source, even one who works on generalized
zeta functions. The out of the blue "prime spectrometer" claim is still
rather puzzling... Does anyone know why Du Sautoy is making this claim
(if it is indeed reported correctly).

@_date: 2005-08-02 11:51:14
@_author: Victor Duchovni 
@_subject: Last WWII Comanche "code talker" dies in Oklahoma 
No, the Navajo code talkers were used in the Pacific, in Europe it was
the Comanches.

@_date: 2005-08-03 21:02:39
@_author: Victor Duchovni 
@_subject: Cross logins 
This requires B to trust A, and trust requires a shared key or
equivalently a trusted introducer. Given a shared key, A is able to sign
(shared secret HMAC, public/private keys or signed Kerberos message)
assertions about the user for B's consumption. The signature can be
in a referral URL.
    Absent a valid cookie for a B session, B redirects the user to A's
federated login generator page (passing B's name and the url the user
wanted), and A redirects the user back to B's federated login verification
page passing back the authentication data and the original url, so the user
is taken to the right place after the credentials are verified.

@_date: 2005-08-04 10:03:01
@_author: Victor Duchovni 
@_subject: Query about hash function capability 
Sure, just pick the lexicographically first cycle and hash
that. This is an invariant of all cyclic permutations of the
More generally given any automorphism group on the input strings, hashing
the lexicographically smallest member of the orbit of an input string
under the group gives a hash that is invariant under the group operation.

@_date: 2005-08-05 17:02:48
@_author: Victor Duchovni 
@_subject: [Clips] Does Phil Zimmermann need a clue on VoIP? 
That is sure some sweet coolaid George got his hands on! I wonder where
I could get some. :-)

@_date: 2005-08-22 10:48:52
@_author: Victor Duchovni 
@_subject: online MD5 crack database 
More plausible perhaps if they had used a space/time tradeoff, to make
the space manageable, then the question is whether CPUs were fast enough
or character set sufficiently restricted to make the pre-computation

@_date: 2005-08-31 12:06:58
@_author: Victor Duchovni 
@_subject: Another entry in the internet security hall of shame.... 
At least here, the front-end servers handle a plethora of authentication
types including client certificate (so client password in TLS should work
too) and the authentication context is then propagated via cookies to
the deep stack of applications behind the perimeter servers. This said,
indeed this is a challenge. Any site that can get client certs working,
can handle variations on the theme, if their authentication happens
deep inside the system (say AD Domain controller behind the webservers)
it won't work.

@_date: 2005-12-02 13:05:05
@_author: Victor Duchovni 
@_subject: Proving the randomness of a random number generator? 
It can't be done. What can be done instead is that multiple parties
participate in a random number generation protocol. The protocol ensures
that all can be confident that the number is at least as random as each
one of them wants it to be. If at least one party is using a decent PRNG,
or a physical source of "real" entropy then all the parties get random
numbers, and no-one feels cheated if they like the randomness of their
own contribution to the protocol.

@_date: 2005-12-03 14:59:31
@_author: Victor Duchovni 
@_subject: Proving the randomness of a random number generator? 
Actually, this is inaccurate, proving the strength of AES or factoring is
difficult, and may never happen, we may even prove AES to be not secure
(in a broad sense) some day. Proving an RNG secure is *impossible*.
A replay of an AES tranmission remains confidential, a replay of an RNG
generated sequence, is no longer random.
Think of the scam in "The Sting", a time-delayed random outcome is no
longer random. It is not possible to prove to a passive observer that
information he is receiving is not time-delayed and was not available
to other observers in advance.

@_date: 2005-12-04 19:31:47
@_author: Victor Duchovni 
@_subject: Proving the randomness of a random number generator? 
Wrong threat model. The OP asked whether the system generating random
numbers can prove them to have been "randomly" generating to a passive
observer. The answer is "no", this is not possible for the reasons
explained before. This is different from security of random numbers I
generate against being predicted by an adversary.

@_date: 2005-12-05 10:21:43
@_author: Victor Duchovni 
@_subject: Proving the randomness of a random number generator? 
I read the question as something akin to what an on-line gambling site
might seek to assure its customers that its dice are not loaded.
The outcome is equally surprising to all observers, having it be
completely predictable by all observers is an uninteresting degenerate
There is no way to prove that dice you are watching on TV are not loaded
(even if the value distribution is fair). If one gets to participate in
a verifiable protocol that rolls the dice, the picture is different.
Actually, even a perfect hardware RNG is of no use in convincing the
skeptical remote observer. How do you prove that the output came from said
RNG?  How do you prove that it is "delayed", and that other participants
are not viewing the output a few steps ahead of the skeptical observer?
If I understood the OP's question correctly (indeed it was not precise),
the answer is that no proof is possible for a non-interactive RNG.

@_date: 2005-12-09 15:46:45
@_author: Victor Duchovni 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
This is true for use in geodesic networks, but not true for
inter-organization email, one ends up introducing gateway systems, that
create an ad-hoc PKI of gateways that have exchanged keys and users
that have authenticated to the gateways when one of the sides has no
such gateway. Key management does not go away.
I disagree here, with IBE there still needs a way to securely obtain
the site public key for each site. Granted, you don't need a per-user
key, but this does not make the problem of key management go away.
My *personal* view is that patent encumbered technologies don't have a
major role to play in anything quite as ubiquitous as email.

@_date: 2005-12-22 12:10:57
@_author: Victor Duchovni 
@_subject: RNG quality verification 
This is impossible. You don't see the raw "random" inputs: the CSR does
not disclose the input primes, it only discloses their product. The real
problem is deeper: there is no such thing as a single number that is or
is not random, a random *process* produces the same discrete outputs as
a similar non-random process.
Furthermore, it is impossible to prove an untrusted sampled process to be
securely random. To have *assurance* of randomness you need to participate
in the process, and to have access to the raw random data. This of
course you cannot do as a CA, because you don't have legitimate access
to the private keys. If you must police the users, hand them their keys
on smart cards (or other suitable hardware) that you initialize.

@_date: 2005-02-10 15:59:04
@_author: Victor Duchovni 
@_subject: TLS session resume concurrency? 
If multiple processes (or threads) have access to a shared TLS session
cache, does the cache need N sessions to serve N threads? Or can (I
think unlikely if sessions resume stream-ciphers from internal state
in the cache) the same session be used by multiple clients?
Postfix only has one TLS session slot per-peer, and so high concurrency
destinations will typically renegotiate (N-1)/N connections. If an SSL
session can be resumed from the same saved state multiple (overlapping)
times the design need not change. Otherwise the problem calls for a
multiple-session per destination cache...
If the symmetric cypher is fully re-keyed when sessions are resumed
while avoiding the fresh start PKI overhead, then life is simple
and sessions can be re-used unmodified. Otherwise I may need to
ponder on designs for a multi-valued cache.
 /"\ ASCII RIBBON                  NOTICE: If received in error, \ /
 CAMPAIGN     Victor Duchovni  please destroy and notify
  X AGAINST       IT Security,     sender. Sender does not waive
 / \ HTML MAIL    Morgan Stanley   confidentiality or privilege,
                                   and use is prohibited.

@_date: 2005-02-11 14:00:10
@_author: Victor Duchovni 
@_subject: TLS session resume concurrency? 
Thanks, this is very useful. This means that the Postfix session cache
does not need multiple cached sessions per end-point. That makes TLS
session management much easier. A single initial session can be re-used
by overlapping subsequent deliveries.

@_date: 2005-06-17 10:53:30
@_author: Victor Duchovni 
@_subject: AES cache timing attack 
Doesn't the Kerberos TGS, for example, somewhat resemble Dan's server?
Yes, it does not report fine-grained time-stamps or do everything in
mememory. Still, if one sends data that looks like authenticator + TGT,
the TGS is going to decrypt the TGT with the ticket granting service
key, getting nonsense and will report an error. The time taken to
report the error will be data dependent, and Dan's attack may apply.
This is speculative. Has anyone studied the applicability of Dan's
attack to a Kerberos 5 KDC with an AES TGS key?

@_date: 2005-06-20 12:36:08
@_author: Victor Duchovni 
@_subject: AES cache timing attack 
Dan, have you looked into or thought about the applicability of your
attack to the Kerberos ticket granting service (measure error response
time for authenticator + "random" ticket). The KDC needs to decrypt the
ticket with the TGS key, recover the session key and principal name, then
check the authenticator. Presumably the time to perform AES decryption
will show the same key/data correlations.
Quantizing the error response delay could solve this problem, though
I for one don't know how to do that portably in a way that guarantees
no leakage of timing information.

@_date: 2005-06-24 00:42:32
@_author: Victor Duchovni 
@_subject: AES timing attacks, why not "whiten" the implementation? 
Perhaps something along the lines of:
    "Provably Secure Masking of AES": Just found the paper, can't speak to its quality or applicability,
but it appears to tackle this sort of problem, and if it fails to cover
cache timing, that too is interesting...
There was recently some discussion of the the family of ciphers
dual to AES, and the fact that some of the equivalent ciphers yield
efficient hardware implementations. It is interesting to ask whether the
existence of dual ciphers can be used in approaches to thwart cache timing
attacks... This thought is not new, at the bottom of page 12 says:
The existence of dual ciphers can also be used to protect implementation[s]
against fault-analysis and power-analysis, by selecting a different dual
cipher at random each time an encryption or decryption is desired.

@_date: 2005-06-24 08:54:35
@_author: Victor Duchovni 
@_subject: Optimisation Considered Harmful 
The idea is that each choice leaks side-channel information about its
algorithm, but the attacker does not know which one was chosen. And,
repeated observations do not on average (over all algorithms) show
correlation between the key or data and side-channel information (other
than the final output). Is this possible? There is a paper that claims
no correlation with any any single intermediate result, is that strong

@_date: 2005-06-27 15:47:20
@_author: Victor Duchovni 
@_subject: WYTM - "but what if it was true?" 
Well cracking the bank application is not really in the user's interests
in this case. My view is, that when the banking application delivery
platform becomes cheap enough (say $50 or less), it will make sense for
the bank to provide a complete ATM system (sans cash) to each user.
The personal ATM appliance should be difficult to tamper with and should
accept only a single set of accounts (so that stolen pin numbers are not

@_date: 2005-03-04 16:18:31
@_author: Victor Duchovni 
@_subject: MD5 collision in X509 certificates 
What is the significance of this? It seems I can get a certificate for
two public keys (chosen, not given) while only proving posession of the
first. Is there anything else? In what sense is the second public key
useful to the attacker?

@_date: 2005-03-05 16:22:58
@_author: Victor Duchovni 
@_subject: MD5 collision in X509 certificates 
I've read very similar posts a few times before, and agree with them all
wholeheartedly! My question is however about this specific exposure. This
collision is between two keys generated together by the attacker, not
someone else's given key and another generated by the attacker. Yes,
this allows one to obtain a certificate for a public key whose private
key did not sign the CSR, but what does this mean in practice? It appears
that neither public key can be used to impersonate anyone else...

@_date: 2005-05-31 12:52:40
@_author: Victor Duchovni 
@_subject: Citibank discloses private information to improve security 
The solution for intramural use of SSH is to use Kerberos for mutual
authentication, this obviates the need for per-user known hosts files.
Though it took some time for the code that correctly integrates Kerberos
into OpenSSH to be adopted, AFAIK this is now done. If it is not (please
apply suitable prods to maintainers, as the code has been available for
some time).
The key obstacle was to allow Kerberos mutual auth to not only log the
user in, but to also authenticate the server despite any mismatch in the
(now ephemeral) RSA keys.

@_date: 2005-11-09 11:54:33
@_author: Victor Duchovni 
@_subject: RSA-640 factored 
It is not reasonable, because the biggest constraint is memory, not
CPU. Inverting the matrix requires increasingly prohitive quantities
of RAM. Read the DJB hardware GNFS proposal.

@_date: 2005-09-14 14:06:47
@_author: Victor Duchovni 
@_subject: MIT talk: Special-Purpose Hardware for Integer Factoring 
Is it politically correct to not cite DJB in this context (perhaps
it is since the talk invitation is not the paper, but the ommision
really caught my attention).

@_date: 2005-09-16 11:03:52
@_author: Victor Duchovni 
@_subject: Clearing sensitive in-memory data in perl 
While some of the fault is perhaps in the core language, my contention is
that the real problem is the anemic standard C-library. When working on C
projects that have (and uniformly use) their own mature string handling
libraries (I was a contributor to Tcl in the 90's and am now working
in Postfix) I found that buffer overflows (and with Tcl for reasons I
won't go into here also memory leaks) were a non-issue in those systems.
With either Tcl_DString or VSTRING (Postfix), one simply loses the
habit of needing to keep track of buffer lengths. When combined with a
compatible I/O interface (say VSTREAM), argument vector library (ARGV)
hash table library, ... one no longer in practice manipulates bare
null-terminated string buffers except when passing (usually read-only)
content to system calls via the C-library.
I continue to write code in C, free of buffer overflows and memory leaks,
not because I am more manly than the next programmer, but because I am
attracted to working on well-designed systems, whose designers took the
time to develop a richer set of idioms in which to construct their work.
My view is that C is fine, but it needs a real library and programmers
who learn C need to learn to use the real library, with the bare-metal
C-library used only by library developers to bootstrap new safe

@_date: 2005-09-19 12:05:21
@_author: Victor Duchovni 
@_subject: Defending users of unprotected login pages with TrustBar 0.4.9.93 
You could consider hashing Just all  content,
the action URIs of all forms, and the targets of all links, ignoring
superficial content changes and changes in layout (sort the hashed

@_date: 2006-04-13 12:35:44
@_author: Victor Duchovni 
@_subject: "Secure Blue" from IBM 
"Easy enough" for ephemeral data (RAM, network, ...), but what do they
propose for stored data? Is this an architecture for general-purpose
computers, or for special-purpose media devices? Is more detail available?
As soon as data is stored, new key management issues come to the surface.
I for one would not want to lose my hard-drive if the CPU is fried...

@_date: 2006-04-26 15:43:33
@_author: Victor Duchovni 
@_subject: History and definition of the term 'principal'? 
The way I see it, the common English sense is "direct participant, not
a third party".
During TGS requests the Kerberos KDC is a *principal* in the TGS
transaction. Soon after, the acquired ticket and session key are used
to communicate with the intended service and the KDC is then a third
party and not a *principal*.
So with Kerberos the word hasW its narrower "named security entity"
technical meaning. With X.509 one tends to talk of "subjects", "issuers",
"registration authorities", "certification authorities", ... and the word
"principal" is less common.
Seems to be mostly a matter of perspective, on the wire single-sign-on
systems authenticate principals, while in the OS or application server
ACLs authorize subjects. Oddly enough the difference in terminology
better reflects the power balance between the royal "issuer" and petty
"subject" in X.509. Wild guess, perhaps more seriously this dates back
to X.509 as a supporting technology for X.500 ACLs.
In the context of Kerberos, I think of principals as living in an external
global (or at least potentially larger) namespace, while subjects or users
in ACLs are often local system specific entities. This means that one
often needs a mapping from principals (global naming) to subjects/users
(local naming). So principal != account.

@_date: 2006-02-10 15:15:32
@_author: Victor Duchovni 
@_subject: GnuTLS (libgrypt really) and Postfix 
If I may be granted the segue, the Postfix documentation has recently
been updated to include the following text:
    NOTE: Do not use Gnu TLS. It will spontaneously terminate a process
    with exit status code 2, instead of properly reporting problems to
    Postfix, so that it can log them to the maillog file.
This was discovered when the Postfix cleanup(8) daemon was reported
exiting in LDAP initialization.  The system LDAP library was linked
against GnuTLS, and /dev/urandom was missing from the chroot jail.
The real culprit is libgcrypt, whose log_fatal() macro terminates the
calling process. This is undesirable in a general purpose library. If
the authors of GnuTLS have any influence on the design/implementation
of libgcrypt, I hope they will make an effort to see this issue addressed.
  cipher/cipher.c: log_fatal("cipher_encrypt: invalid mode %d\n", c->mode );
  cipher/cipher.c: log_fatal ("cipher_decrypt: invalid mode %d\n", c->mode );
  cipher/dsa.c: log_fatal("DSA:: sign, verify failed\n");
  cipher/elgamal.c: log_fatal("ElGamal operation: encrypt, decrypt failed\n");
  cipher/elgamal.c: log_fatal("ElGamal operation: sign, verify failed\n");
  cipher/primegen.c: log_fatal ("can't generate a prime with less than %d bits\n", 16);
  cipher/random.c: log_fatal ("failed to create the pool lock: %s\n", strerror (err) );
  cipher/random.c: log_fatal ("failed to create the nonce buffer lock: %s\n",
  cipher/random.c: log_fatal ("failed to acquire the pool lock: %s\n", strerror (err));
  cipher/random.c: log_fatal ("failed to release the pool lock: %s\n", strerror (err));
  cipher/random.c: log_fatal ("failed to acquire the pool lock: %s\n", strerror (err));
  cipher/random.c: log_fatal ("failed to release the pool lock: %s\n", strerror (err));
  cipher/random.c: log_fatal(_("can't read `%s': %s\n"), seed_file_name,strerror(errno) );
  cipher/random.c: log_fatal ("failed to acquire the pool lock: %s\n", strerror (err));
  cipher/random.c: log_fatal ("failed to release the pool lock: %s\n", strerror (err));
  cipher/random.c: log_fatal (_("no entropy gathering module detected\n"));
  cipher/random.c: log_fatal ("failed to acquire the pool lock: %s\n", strerror (err));
  cipher/random.c: log_fatal ("failed to acquire the pool lock: %s\n", strerror (err));
  cipher/random.c: log_fatal ("No way to gather entropy for the RNG\n");
  cipher/random.c: log_fatal ("failed to acquire the nonce buffer lock: %s\n",
  cipher/random.c: log_fatal ("failed to release the nonce buffer lock: %s\n",
  cipher/rndegd.c: log_fatal ("EGD socketname is too long\n");
  cipher/rndegd.c: log_fatal("can't create unix domain socket: %s\n", strerror(errno) );
  cipher/rndegd.c: log_fatal("can't connect to EGD socket `%s': %s\n",
  cipher/rndegd.c: log_fatal("can't write to the EGD: %s\n", strerror(errno) );
  cipher/rndegd.c: log_fatal("can't write to the EGD: %s\n", strerror(errno) );
  cipher/rndlinux.c: log_fatal ("can't open %s: %s\n", name, strerror(errno) );
  cipher/rndlinux.c: log_fatal("stat() off %s failed: %s\n", name, strerror(errno) );
  cipher/rndlinux.c: log_fatal("invalid random device!\n" );
  cipher/rndlinux.c: log_fatal("read error on random device: %s\n", strerror(errno));
  cipher/rndw32.c: log_fatal ( "rndw32: can't get module handle\n" );
  cipher/rndw32.c: log_fatal ( "rndw32: failed to get a toolhelp function\n" );
  cipher/rndw32.c: log_fatal ( "rndw32: failed to take a toolhelp snapshot\n" );
  cipher/rndw32.c: log_fatal("can't run on a W32s platform\n" );
  cipher/rsa.c: log_fatal("RSA operation: public, secret failed\n");
  cipher/rsa.c: log_fatal("RSA operation: secret, public failed\n");
  src/secmem.c: log_fatal ("failed to reset uid: %s\n", strerror (errno));
  src/secmem.c: log_fatal ("can't allocate memory pool of %u bytes\n",
  src/secmem.c: log_fatal ("failed to drop setuid\n");

@_date: 2006-02-10 15:19:10
@_author: Victor Duchovni 
@_subject: Nonrepudiation - in some sense 
And only if EDH (or more generally all PFS) ciphers are disabled. This
is AFAIK common with HTTP servers, but the majority of TLS capable MTAs
negotiate EDH ciphers.

@_date: 2006-02-13 10:57:11
@_author: Victor Duchovni 
@_subject: GnuTLS (libgrypt really) and Postfix 
No, libraries don't enough to decide what's fatal. The calling
process (trying to an LDAP lookup via nsswitch.conf say...) may have
other reasonable sources of data, and having the library kill it is
Not being able to access a resource is not an "impossible"
state. Impossible states are corruption of internal data structures,
invalid function arguments, ... Failure to obtain seed data is an
error and needs to be reported as such.

@_date: 2006-02-13 11:13:58
@_author: Victor Duchovni 
@_subject: GnuTLS (libgrypt really) and Postfix 
Yeah, right, really easy when GnuTLS is called from the system LDAP
libraries... In any case the only way for the handler to avoid
process death is longjmp() to a context created before calling
GnuTLS/libgcrypt()... not a particularly robust solution.
    void
    _gcry_log_fatal( const char *fmt, ... )
    {
    }
the handler is invoked in _gcry_logv()... The Postfix TLS functionality
is built over OpenSSL (not GnuTLS) and OpenSSL has an error stack, which
the application can process as it sees fit. The libgrypt approach to
error reporting is not acceptable.

@_date: 2006-02-14 00:29:59
@_author: Victor Duchovni 
@_subject: X.509 Phishing license 
The phishers are launching sophisticated attacks on less known (to the
X.509 CAs) financial institutions...
    ...
    This one -- targeting the tiny Mountain America credit union in Salt
    Lake City, Utah
    ...
    Geotrust's cert verification process is largely automated: when
    someone requests a cert for a particular site, the company sends an
    e-mail to the address included in the Web site's registrar records,
    along with a special code that the recipient needs to phone in to
    complete the process.
    ... [Geotrust] doubted that inserting a human into that process
    would have flagged the account as suspicious.

@_date: 2006-02-14 12:47:42
@_author: Victor Duchovni 
@_subject: GnuTLS (libgrypt really) and Postfix 
Absent good library design, the developer's goals are best accomplished
with the roll-your-own standard.
If the authors of libgrypt instead of saying "sorry, we know, it is a
difficult problem, we are working on it", instead become defensive and
erect false dichotomies to defend the developer from his own folly, I
can add libgrypt to my list of tools to avoid when building large systems.
As I said before, Postfix does not use GnuTLS directly, rather it is
sometimes a victim of libgrypt design via GnuTLS imbedded in the system
LDAP library.
The current libgrypt is IMHO not suitable for linking into LDAP libraries,
database client-server communication libraries, SMTP servers...
As for Postfix, it does entropy gathering out-of-process (in the tlsmgr(8)
daemon). The SMTP server and client daemons get entropy indirectly from
tlsmgr(8) to seed their internal PRNG. Postfix uses OpenSSL, and error
conditions in OpenSSL are recoverable (Postfix can and will return 454 in
response to STARTTLS, fatal errors are not appropriate in this context).
Postfix makes use of error reporting hooks in MySQL, PgSQL, SASL, OpenSSL,
(non-GnuTLS) OpenLDAP... none of these have been reported to abruptly
terminate the calling process instead of reporting errors to the caller.

@_date: 2006-02-14 13:57:56
@_author: Victor Duchovni 
@_subject: GnuTLS (libgrypt really) and Postfix 
Thanks, this makes the point very clearly!
The pass-a-function pointer approach covers the simpler cases. Large
utility libraries (OpenSSL, Kerberos, ...) sometimes have a tougher
problem to solve.
- The function needs error detail arguments so it can take the
  right actions.
- Errors may need a classification system, so that new errors
  of the same type can be handled generically in legacy code as
  the library evolves.
- The function needs an application context argument so it has
  access to the data it needs to take the right actions.
So, the more sophisticated C-language designs (e.g. OpenSSL or Kerberos)
include an error management API. These are clearly work-arounds for
lack of real exceptions. They take care to design and implement, and
it may be difficult or impractical to retrofit an existing design that
did not pay the price from the start, but I find claims that the exit()
approach is best *on architectural grounds* rather surprising...
ERR_get_error(3)                    OpenSSL                   ERR_get_error(3)
       ERR_get_error, ERR_peek_error, ERR_peek_last_error, ERR_get_error_line,
       ERR_peek_error_line, ERR_peek_last_error_line, ERR_get_error_line_data,
       ERR_peek_error_line_data, ERR_peek_last_error_line_data - obtain error
       code and data
                 unsigned long ERR_get_error(void);
        unsigned long ERR_peek_error(void);
        unsigned long ERR_peek_last_error(void);
        unsigned long ERR_get_error_line(const char **file, int *line);
        unsigned long ERR_peek_error_line(const char **file, int *line);
        unsigned long ERR_peek_last_error_line(const char **file, int *line);
        unsigned long ERR_get_error_line_data(const char **file, int *line,
                const char **data, int *flags);
        unsigned long ERR_peek_error_line_data(const char **file, int *line,
                const char **data, int *flags);
        unsigned long ERR_peek_last_error_line_data(const char **file, int *line
                const char **data, int *flags);
       ERR_get_error() returns the earliest error code from the thread's error
       queue and removes the entry. This function can be called repeatedly
       until there are no more error codes to return.
ERR_GET_LIB(3)                      OpenSSL                     ERR_GET_LIB(3)
       ERR_GET_LIB, ERR_GET_FUNC, ERR_GET_REASON - get library, function and
       reason code
                 int ERR_GET_LIB(unsigned long e);
        int ERR_GET_FUNC(unsigned long e);
        int ERR_GET_REASON(unsigned long e);
       The error code returned by ERR_get_error() consists of a library num-
       ber, function code and reason code. ERR_GET_LIB(), ERR_GET_FUNC() and
       ERR_GET_REASON() can be used to extract these.
       The library number and function code describe where the error occurred,
       the reason code is the information about what went wrong.
       Each sub-library of OpenSSL has a unique library number; function and
       reason codes are unique within each sub-library.  Note that different
       libraries may use the same value to signal different functions and rea-
       sons.

@_date: 2006-02-16 13:04:07
@_author: Victor Duchovni 
@_subject: GnuTLS (libgrypt really) and Postfix 
Who said the program's primary function is data security? The program
may be handling entirely public data, available from multiple sources.
One of the sources may offer "opportunistic" encrypt, which though
potentially useful, is inessential and mostly "does no harm". It takes
hubris for libgrypt to *assume* that is functions are essential.
The dichotomy between pretending to encrypt data and exiting is false.
It is plainly correct to not encrypt any data and say so (return
errors from the encryption API).
I'm outta here. I did not expect any controversy on this point, and don't
expect views to shift dramatically. If the developers were open to the
issue, the request might have been fruitful. If they dig in their heels,
I am free to use other libraries.

@_date: 2006-02-24 12:01:49
@_author: Victor Duchovni 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
More strongly, if we've never met, and you are not in the habit of
routinely signing email, thereby tying a key to your e-persona, it
makes no sense to speak of *secure* communication to *you*. Which "you"
would that be, the one who sent me all those exciting zip files of W32
executables, or the one I think is posting to this list?
The only identity you (who hypothetically do not garnish each message
with a signature) have is your mailbox. I can bootstrap that (with
questionable initial security) to a key via a "private" unencrypted
email message, and over a time as the key is consistently used grow to
associate the key with an on-line persona.
Is such a virtual persona what most people look for in "secure" email? I
think not, rather I think they are looking for secure email for the
eyes of real-world people, and so, in a strong sense ubiquitous secure
mail for the digital world in unattainable, because the underlying human
relationships do not exist. The world of digital relationships is much
broader than the world of personal real-world relationships...
I think that key management (while quite difficult) is not even the real
problem, the more intractable problem appears to be trust management:
how to distinguish a con from the real-thing... This problem is also
applicable to the real-world, but the digital manifestation is more

@_date: 2006-02-24 12:09:51
@_author: Victor Duchovni 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
One of the issues with S/MIME is that most mail clients have no useful
support for self-signed keys. I want to be able to generate a self-signed
key (ala PGP) and have my friends bind it mo my identity. Nothing in the
message format prevents me from doing that, but the products insist on
only trusting CAs, not keys. To generate keys for email to/from my wife I
configured my and her Thunderbird to treat each of us as a trusted CA :-(

@_date: 2006-02-27 10:12:34
@_author: Victor Duchovni 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
Likewise the rise of the telephone over paper mail, but the phone does
not obviate the need for paper mail.
spam quite nicely.
Where's Gaddi Evron when you need him? This is just not true, the spam
volume is rising for both blogs and IM.
Likewise I have secured email communications with my wife via a single
key exchange, so what? Skype has not "easily" created an interoperable
federated system that secures all IM communications end-to-end, and
many of the issues in doing that are non-technical.
IM is "islands of automation", luckily email works globally.
This is naive, IM will become federated and decentralized and abuse
issues will be the same as for email. You can't fence the bad guys
out of the network.

@_date: 2006-02-28 16:28:51
@_author: Victor Duchovni 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
This is neither surprising, nor relevant to email.
We are at this point reasonably good at encrypting unicast traffic and
the associated key management problem is often viable. Encrypting stored
data is a substantially more difficult problem.
We have increasingly common opportunistic TLS encryption of email traffic,
with occasional fully verified secure-channels between some pairs of
sites. We could conceivably some day (political barriers primarily
at this point) have a secure DNS for secure MX record lookups and key
distribution enabling secure channels between most sites. This is viable,
traffic encryption is a tractable problem.
Encrypting email content, to be stored encrypted, and decrypted when
read off-line, or read again later, ... is a problem that the IM
and VoIP vendors don't have to solve. They also don't have to solve
global federation of universally interoperable systems...

@_date: 2006-06-09 11:10:47
@_author: Victor Duchovni 
@_subject: mailer certificate retrieval via LDAP? 
Thunderbird supports PKCS plugins modules, so all you need is PKCS
plugin for LDAP. So question looks like a question about availability
of plugins, rather than MUAs...

@_date: 2006-03-01 13:55:38
@_author: Victor Duchovni 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
Federated accross millions of account issuing organizations, not
technologies, and email did do that, and IM did not. IM is like email from
a choice MCI, Sprint or AT&T, sure they can control the medium better,
but this is a temporary state of affairs...
These are closed systems that compete with each other, once
they become federated, they can no longer compete on end-to-end
security, because that is a property of the interoperability
framework, not the individual product. Also with millions
of account issuers, the abuse and identity problems become
just as bad as for email. The problem is intrinsic, is not
the result of lazy RFC writers.

@_date: 2006-03-08 15:20:29
@_author: Victor Duchovni 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
What is the value of such "authentication"? Which organizations will you
trust? For example, most mail that passes SPF is spam... Authentication
by the issuing organization is only useful, if you can keep bad issuers
of the net... If federated Jabber becomes universal, the bad guys cannot
be excised from the network. The botnets cannot be excised from the network,
The problem is technology neutral. Loosely along the lines of Goedel's
incompleteness theorem, any universally deployed federated communications
medium will exhibit spam.
    Either it is not mature enough, or it has spam.

@_date: 2006-03-08 17:45:33
@_author: Victor Duchovni 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
Time will tell. All I expect from the ultimate (~3 years out) rollout
of email authentication is less backscatter, not less phishing or
Of course new domains are less than $4 each in bulk... How will you
lock out throw-away domains? The black-list problem for email is not
solved. The good lists are nowhere near 100% effective. Is the equivalent
of port 25 blocking tractable for Jabber? Is there a difference between
the user-to-server port/protocol and the server-to-server port/protocol
in Jabber?
Yes petname systems are an important UI tool for preserving the integrity
of existing peer communications. If IM is to "replace" email as some
want to claim, it needs to support messages from a fair share of total
strangers (we have never met).
My claim is that, while indeed it is easier to set the initial barriers
higher when you design with greater hindsight, and some of the tractable,
but not widely deployed email security measures will be there in IM
systems from the start, never the less IM systems if they are to encroach
on the ubiquity of email for ad-hoc communications between strangers
(it is far easier to address strangers via email today) will encounter
exactly the same intrinsic issues, and that technical measures will have
equally partial efficacy.
I am willing to speculate that the more likely scenario is that IM will
not become the ubiquitous medium that email is, and will escape the
problem by avoiding scope creep.
I am willing to speculate that people will continue to unfairly tarnish
the competence of the email RFC writers, without regard to the intrinsic
properties of the medium.

@_date: 2006-03-10 09:45:33
@_author: Victor Duchovni 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
The federation mechanism in Usenet is explicit host peering. While the
posters may be strangers to the readers, they are not able to unicast
their content to arbitrary strangers. Joe Consumer does not use Usenet,
they use email and perhaps Yahoo groups. Moderators of groups and
server administrators can block or cancel spam posts. There is no useful
analogy here.
The federation mechanism for email is DNS MX records. Email is ubiquitous,
you don't need to peer with UUnet. When Jabber is ubiquitous (i.e. every
domain with Jabber users has a Jabber SRV record and peering is direct)
it will have more spam.
The problem with email is that it is more useful and more ubiquitous, and
therefore a more attractive target. Security protocols, authentication,
and so forth, should help to identify wanted email and perhaps make
tracing abuse easier, but the fundamental problem is that among the
billions of people from whom you potentially want to be able to receive
email, there are a few hundred sociopaths.
It is IMHO naive to claim that email would not have a serious spam problem
if only it were designed now rather than in a kinder, gentler past. It is
in the nature of an always on, universally addressable service that it is
open for abuse. The problem is compounded by the presence of millions of
unsecured broadband consumer-operated machines.
It is not just that deploying a more modern email infrastructure is
complex. I have not seen any designs for email (deployable or not)
that realistically curtail abuse.
And correspondingly the utility and ubiquity of the service are limited.
Are you proposing a fendced-in network of privileged email servers?
Well, this is a popular viewpoint, but I suggest that it misses the
*intrinsic* difficulty of the problem.

@_date: 2006-03-16 10:41:29
@_author: Victor Duchovni 
@_subject: Zfone and ZRTP :: encryption for voip protocols 
Indeed, but it looks to be the right security model for the mass market.

@_date: 2006-03-22 16:46:19
@_author: Victor Duchovni 
@_subject: passphrases with more than 160 bits of entropy 
We may want to cut the OP some slack... When a sequence is computed
from output of a generator, it is meaningful to ask how much entropy the
sequence retains... If regardless of the generator output the sequence
is { 0, 1, ..., 255 }, we have zero entropy. Otherwise (and in any case)
the entropy can in theory be computed from the probability distribution
of the possible output sequences which is in principle available from
the distribution of the generator outputs and the deterministic functions
that create the sequence.
Actually calculating the entropy for real-world functions and generators
may be intractable...

@_date: 2006-03-22 21:04:54
@_author: Victor Duchovni 
@_subject: Linux RNG paper 
Why would a trojan running in your security context bother with attacking
a PRNG? It can just read your files, record your keystrokes, change your
browser proxy settings, ...
If the trojan is a sand-box of some sort, the sand-box is a different
security context, and in that case, perhaps a different RNG view is
Some applications that consume a steady stream of RNG data, maintain
their own random pool, and use the public pool to periodically mix in
some fresh state. These are less vulnerable to snooping/exhaustion of
the public stream.
The Postfix tlsmgr(8) process proxies randomness for the rest of the
system in this fashion...

@_date: 2006-03-29 14:01:37
@_author: Victor Duchovni 
@_subject: [Cfrg] HMAC-MD5 
Is there already evidence of progress in that direction?

@_date: 2006-05-05 13:18:50
@_author: Victor Duchovni 
@_subject: Linux RNG paper 
Exactly, many file systems rely on block devices with atomic single block
(sector) writes. If sector updates are not atomic, the file system needs
to be substantially more complex (unavoidable transaction logs to support
roll-back and roll-forward). Encrypted block device implementations that
are file system agnostic, cannot violate block update atomicity and so
MUST not offer integrity.

@_date: 2006-05-14 19:32:39
@_author: Victor Duchovni 
@_subject: picking a hash function to be encrypted 
Security is fragile. Deviating from well understood primitives may be
good research, but is not good engineering. Especially fragile are:
- Non-mainstream ciphers (often broken once someone good bothers to try)
- Stream ciphers (additive)
- RC4 (poor key schedule)
- RSA (multiplicative)
The first is to be avoided entirely, the second and third should be
used only under duress, when block ciphers are a very poor fit for the
application. RSA needs to be used only in very specific ways (PKCS 2.1,
for example) that avoid the common pitfalls.
TLS (available via OpenSSL) provides integrity and authentication, any
reason to re-invent the wheel? It took multiple iterations of design
improvements to get TLS right, even though it was designed by experts.

@_date: 2006-05-14 21:49:12
@_author: Victor Duchovni 
@_subject: picking a hash function to be encrypted 
Once upon a time, everyone agreed that cipher design was hard.  Later
people discovered that protocol design is hard too.  More recently
people are discovering that given solid ciphers and protocols, secure
implementations are still hard... I could be wrong, but it does not
seem that the trend is towards "increasingly easy" security, in the
sense that anyone who learns a programming language reasonably well can
develop security toolkits. :-(

@_date: 2006-05-29 12:03:05
@_author: Victor Duchovni 
@_subject: Status of opportunistic encryption 
It only guards against *passive* eavesdropping. Active attacks can
forge DNS MX records, inject BGP routes, ... Actual MITM resistant
peer authentication with SMTP+TLS is extremely rare. I know it happens
sometimes because I have it running for a small number of destinations,
otherwise I would suspect that nobody is doing it.
    Once the new 2.3 TLS code is folded into the production Postfix 2.3
snapshots (at which point the new documentation will be published), see
          It is regrettably the case, that TLS secure-channels (fully authenticated
  and immune to man-in-the-middle attacks) impose constraints on the sending
  and receiving sites that preclude ubiquitous deployment. One needs to
  manually configure this type of security for each destination domain,
  and in many cases implement non-default TLS policy table entries for
  additional domains hosted at a common secured destination. With Postfix
  2.3, we make secure-channel configurations substantially easier to
  configure, but they will never be the norm. For the generic domain with
  which you have made no specific security arrangements, this security
  level is not a good fit.
  Historical note: while the documentation of these issues and many of
  the related features are new with Postfix 2.3, the issue was well
  understood before Postfix 1.0, when Lutz Jaenicke was designing
  the first unofficial Postfix TLS patch. See, his original post
   and the first
  response  The
  problem is not even unique to SMTP or even TLS, similar issues exist
  for secure connections via aliases for HTTPS and Kerberos. SMTP merely
  uses indirect naming (via MX records) more frequently.
I should also note that once one abandons the (still) unrealistic
assumption of a secure DNS, it is not just SMTP + TLS that runs into
For example, many Kerberos client libraries do a forward lookup (to
alias- expand CNAMEs) and some perversely a reverse lookup (often the
owner of the IP address is the worst source of the machine's name), and
then give you a mutually authenticated channel to whatever principal
they construct from now rather questionable data. This carries over
to SASL GSSAPI, where GSSAPI abstraction makes working around this
(in practice nobody tries even with native Kerberos) even harder.
Consequently, also SSH with GSS KEX, is not MITM resistant when the
attacker can tamper with DNS responses.
Ultimately, to close similar security issues in many other protocols,
we need a secure DNS, but I am somewhat pessimistic about the likelihood
of this happening soon.

@_date: 2006-05-30 21:45:19
@_author: Victor Duchovni 
@_subject: Status of opportunistic encryption 
Active attacks at the network layer are relatively rare, but definitely
not non-existent. Spammers occasionally hijack BGP prefixes, send some
spam and move on. They can also hijack nameserver IPs, MX host IPs, but
for now they prefer sending over receiving. This will likely change,
the playbook of organized crime on the net has been expanding steadily
when money overtook teen-age dare-do as the most common motivation for
active attacks in ~2002.
They keep moving around, some ISPs turn a blind eye in return
for the revenue stream.
No, that's the whole point. What works for the individual administering 10
machines, does not scale to organizations with hundres of administrators
managing tens of thousands of machines. With KEX you trust Kerberos,
not your key store. The problem is that one also ends up trusting, DNS
or NIS or LDAP, ...
Quite the converse, the PKI keys are too durable. (Segue to Wheeler &
Wheeler) the Kerberos online verification model is actually superior,
but in practice the implementation runs into issues with insecure
nameservices. We need a more secure stack.
Yes, but the scammers are getting into more markets, first spam and
advance fee scams, then phishing, now pump and dump scams, they are
evolving fast. We are largely standing still.
Workable DNS-SEC exists, what lacks now is the will and political muscle
to make it happen. Signing is done on update, not on read.
The real question is not how to do DNS-SEC, but how soon, and then how to
leverage it in real protocols. Will there be a reasonably comprehensive
set of Internet integrated services that work *together* "securely" in
a reasonable fashion, or are we still building the tower of Babel (now
in software). A more trustworthy DNS would IMHO be a good foundation.

@_date: 2006-05-30 21:53:57
@_author: Victor Duchovni 
@_subject: Status of SRP 
The obvious solution is perhaps more difficult to deploy in an environment
where loss of ubiquitous access trumps security gains. It takes years to
*field* new infrastructure. When the designer calls the problem solved,
the real work begins, or not, if the market is not yet ready for the

@_date: 2006-10-18 00:00:41
@_author: Victor Duchovni 
@_subject: hashes on restricted domains: random functions or permutations? 
Hash functions are supposed to be pseudo-random. For a 160 bit hash In
an input set of 2^80 elements we should expect to find a collision...
If we iterate from a random starting point we expect to enter a cycle
of length ~2^79 after ~2^79 initial outputs. So the subsets on which
an iterated hash acts as a right-shift are expected to be ~2^79 in
An intuitive (but possibly grossly wrong) leap is that there should be
~~2^80 disjoint cycles with half of the inputs outside a cycle and half
inside a cycle. None of this should lead to any apparent weakness after
a modest number of iterations.

@_date: 2006-10-18 12:29:35
@_author: Victor Duchovni 
@_subject: hashes on restricted domains: random functions or permutations? 
This part is right.
This had to be wrong of course, the range does not separate into
disjoint loops with a single linear strand leading into the loop. There
is branching before the loop and multiple entry points into the loop.
This reminds me of the analysis of the space-time tradeoff for brute
forcing password hashes. Don't have it in front of me, but in that work
effective estimates of the branching were taken into account.

@_date: 2006-09-14 17:21:28
@_author: Victor Duchovni 
@_subject: Why the exponent 3 error happened: 
If so, I fear we are learning the wrong lesson, which while valid in
other contexts is not pertinent here. TLS must be flexible enough to
accommodate new algorithms, this means that the data structures being
exchanged are malleable, and that implementations must validate strict
adherence to a specifically defined form for the agreed algorithm,
but the ability to express other forms cannot be designed out.
This, in my view, has little to do with ASN.1, XML, or other encoding
frameworks. Thorough input validation is not yet routinely and
consistently practiced by most software developers. Software is almost
invariably written to parse formats observed in practice correctly, and is
then promptly declared to "work". The skepticism necessary to continually
question the implicit assumption that the input is well-formed is perhaps
not compatible with being a well-socialized human. The attackers who ask
the right questions to break systems and the few developers who write
truly defensive code are definitely well off the middle of the bell-curve.
It is not just PKCS or X.509v3 that presents opportunities for crafting
"interesting" messages. MIME, HTTP, HTML, XML, ... all exhibit similar
pitfalls. Loosely speaking, this looks like a variant of Goedel's theorem,
if the protocol is expressive enough it can express problematic assertions.
We can fine-tune some protocols to remove stupid needless complexity, but
enough complexity will remain to make the required implementation disciple
beyond the reach of most software developers (at least as trained today,
but it is not likely possible to design a training program that will
a preponderance all strong defensive programmers).

@_date: 2007-04-05 12:13:24
@_author: Victor Duchovni 
@_subject: DNSSEC to be strangled at birth. 
The story makes no sense, so I am inclined to discount it. This is a
signing key, not an encryption key, there is no reason for the DHS to
have it, so I am assuming that they won't have it, and perhaps the story
is the result of confusion/incomptence somewhere.

@_date: 2007-04-06 14:02:22
@_author: Victor Duchovni 
@_subject: hoofbeats of zebras, was DNSSEC to be strangled at birth. 
Exactly, no need to assume a deep conspiracy when mere incompetence
explains this quite well. I expect that this story will be long forgotten
by the time the root zone is signed, and that the keys will not be given
over to DHS or any other agency that is not ICANN/IANA or whoever is
actually responsible for the root zone at that point in time.
Note also that a small, but non-negligible number of sites obtain the
root zone via FTP, and run nameservers authoritative for ".". The zone
is small enough to make this a good idea, may even a poorly publicized
best-practice. Name server operators who serve their own root zone
should notice any changes. The "attack" is most practical against SOHO
DHCP users known to get all their DNS from upstream providers. I don't
believe this is useful enough to warrant the bad press. Time will tell
of course, but my instinct is that this is story is only interesting to
the extent that it makes the feared scenario less likely, so though I
don't find it a credible threat, the publicity may help to avert any
silliness from coming to pass.

@_date: 2007-04-19 16:30:46
@_author: Victor Duchovni 
@_subject: AES128-CBC Question 
Is the same key ever used to encrypt multiple streams?
This is a protocol question, not an algorithm question, so you need a
security review of the protocol (which you have not described).

@_date: 2007-04-20 11:58:46
@_author: Victor Duchovni 
@_subject: More info in my AES128-CBC question 
You still have not described the protocol, or how keys are used/managed.
The question has no answer outside the context of a specific protocol,
other than in general it is best practice to use random IVs or otherwise
unlikely to repeat IVs.

@_date: 2007-08-31 13:58:35
@_author: Victor Duchovni 
@_subject: World's most powerful supercomputer goes online 
Isn't most of the cost/complexity of super-computers the interconnect
fabric and memory system, not the CPUs... Clearly for easy to partition
problems this beats the "super-computer" systems, but many large problems
won't tolerate Storm's interconnect latency...
The LINPACK benchmarks on super-computers largely measure memory-bandwidth
not CPU power, but the memory pre-fetch pipeline depth is not unbounded,
most algorithms will stall if latency is too high... Simulations of
supernova explosions or aircraft wing dynamics probably don't easily
scale on Storm...

@_date: 2007-12-11 13:44:44
@_author: Victor Duchovni 
@_subject: Flaws in OpenSSL FIPS Object Module 
But also to be expected, because the feature in question is "unnatural":
the software needs a testable PRNG to pass the compliance tests, and
this means adding code to the PRNG to make it more predictable under
test conditions.
As the tests only test the predictable PRNG, it is easy to not notice
failure to properly re-seed the non-test PRNG. One can't easily test
failure to operate correctly under non-test conditions. And the additional
complexity of the test harness makes such failure more likely.
The interaction of the test harness with the software under study needs
close scrutiny (thorough and likely multiple independent code reviews).
Similar bugs are just as likely in closed-source software and are less
likely to be discovered.

@_date: 2007-12-19 03:05:02
@_author: Victor Duchovni 
@_subject: crypto class design 
APIs don't solve security problems, just code re-use problems. Teaching
smart people how to do threat analysis is a better bet. Untrained
developers will choose an API that solves the wrong problem.
And who does key management? I bet the key will be right there with
the data on the same disk, probably logged in the clear in application
logs too...
Encryption is almost never the problem, design is the problem, with a
good design, the crypto is already available.
Why yet another crypto library? Invest your energy in complete designs and
code of realistic show-case solutions to real-world problems, not APIs.
Good designs will get copied whole-sale, and morphed. If well documented,
the developers can learn by reading the sample code, and training can
be based around the approaches taken in the show-case systems.
When I hear developers demanding "security APIs" I pretend to be deaf...

@_date: 2007-02-04 02:15:30
@_author: Victor Duchovni 
@_subject: OT: SSL certificate chain problems 
Does this actually work with OpenSSL and v3 CA certs that have "X509v3
Authority Key Identifier" extensions? With these extensions present
(default when OpenSSL constructs CA certs, ...), certs whose serial number
does not match the "serial" field in the extension are not considered
to be root CA certs (not self-signed), and CA certs sharing the same
keys and DN, but carrying different serials, simply don't match.
If I roll-back the serial numbers and issue a cert with all the details
(including serial number, ...) the same, but just the start/end dates
changed to start before the expiration of the verifier's expired CA,
and end after today's date, the verifier ends up with a trust chain that
starts with the expired cert and fails, regardless of whether the server
sends the new root CA cert or not.
    CA0.pem:
    --------
    serial=C27B874157E381C0
    issuer=     subject=     notBefore=Jan  1 00:00:00 2007 GMT
    notAfter=Jan 31 00:00:00 2007 GMT
    ...
    X509v3 Authority Key Identifier:
    CA1.pem:
    --------
    serial=C27B874157E381C0
    issuer=     subject=     notBefore=Jan 15 00:00:00 2007 GMT
    notAfter=Feb 28 00:00:00 2007 GMT
    ...
    X509v3 Authority Key Identifier:
    SRV.pem:
    ---------
    serial=C27B874157E381C1
    issuer=     subject=     notBefore=Jan 15 00:00:00 2007 GMT
    notAfter=Feb 28 00:00:00 2007 GMT
    ...
    X509v3 Authority Key Identifier:
A client with CAfile containing just "CA0.pem" fails to verify a server
configured to send the SRV,CA1 trust chain. My verification callback is
called three times and produces:
  Trace: certificate verification depth=1 verify=0 subject=
  Error: CA certificate verification failed for  certificate has expired
  Trace: certificate verification depth=1 verify=1 subject=
  Trace: certificate verification depth=0 verify=1 subject=
If the verifier trusts the "CA1.pem" cert, I see instead:
  Trace: certificate verification depth=1 verify=1 subject=
  Trace: certificate verification depth=0 verify=1 subject=
How does one construct a working (re-issued root CA) example with OpenSSL?
Am I setting this up incorrectly, or does OpenSSL not in fact support
establishing trust in re-issued root CA via now expired root CAs?
I have not tried to do this without the "issuer key identifier" extension,
but don't really expect to find anything different...

@_date: 2007-02-15 11:36:35
@_author: Victor Duchovni 
@_subject: Failure of PKI in messaging 
Well, you certainly don't want to use email when coordinating a place to
meet in the next 10-15 minutes, while on the move with a cell phone, or
other near-real-time social activity so important to the next generation
while they are still the "next" generation.
I challenge the myth that this means that email won't be more important
to them as they mature.
I may be able to get you a data-point on that. Qualititatively external
email is not shrinking in significance here.

@_date: 2007-02-15 11:52:40
@_author: Victor Duchovni 
@_subject: Failure of PKI in messaging 
O.K. inbound external email is ~20% of our traffic.

@_date: 2007-01-02 17:25:07
@_author: Victor Duchovni 
@_subject: SSL (https, really) accelerators for Linux/Apache? 
I don't have any experience with any hardware in this space, but you
should be clear about one thing:
    - Are you trying to accelerate symmetric bulk crypto of the SSL
    payload, or the PKI operations in a cold SSL handshake?
Depending on the application and load, and given a suitable SSL session
cache, the PKI load may be negligible. For example, traffic between two
fixed MTAs with caches on both sides only does one SSL handshake per
cache TTL and then just bulk crypto for many deliveries that reuse the
cached SSL session.
So what is your load like?

@_date: 2007-01-13 13:35:16
@_author: Victor Duchovni 
@_subject: A web site that believes in crypto 
Their public email gateways don't believe in crypto nearly as much as
cs.columbia.edu does.
    $ for d in cia.gov cs.columbia.edu; do
    	echo; dig +sho -t mx $d | sort +0n |
    	tee /dev/tty |
    	perl -lne 'm{(\S+)\.$} && print $1' |
    5 mail2.ucia.gov.
    10 mail1.ucia.gov.
    smtp-finger: Connected to mail2.ucia.gov[198.81.129.148]:25
    smtp-finger: < 220 mail2b.ucia.gov ESMTP
    smtp-finger: > EHLO amnesiac.ms.com
    smtp-finger: < 250-mail2b.ucia.gov
    smtp-finger: < 250-8BITMIME
    smtp-finger: < 250 SIZE 104857600
    smtp-finger: Connected to mail1.ucia.gov[198.81.129.68]:25
    smtp-finger: < 220 mail1a.ucia.gov ESMTP
    smtp-finger: > EHLO amnesiac.ms.com
    smtp-finger: < 250-mail1a.ucia.gov
    smtp-finger: < 250-8BITMIME
    smtp-finger: < 250 SIZE 104857600
    100 cs.columbia.edu.
    200 ober.cs.columbia.edu.
    200 opus.cs.columbia.edu.
    smtp-finger: Connected to cs.columbia.edu[128.59.16.20]:25
    smtp-finger: < 220 cs.columbia.edu ESMTP Sendmail (8.12.10/22/jtt/sed/ib42) is thrilled to serve you at Sat, 13 Jan 2007 13:27:13 -0500 (EST).
    smtp-finger: > EHLO amnesiac.ms.com
    smtp-finger: < 250-cs.columbia.edu Hello amnesiac.ms.com [192.0.2.1], pleased to meet you
    smtp-finger: < 250-ENHANCEDSTATUSCODES
    smtp-finger: < 250-PIPELINING
    smtp-finger: < 250-EXPN
    smtp-finger: < 250-VERB
    smtp-finger: < 250-8BITMIME
    smtp-finger: < 250-SIZE 25000000
    smtp-finger: < 250-DSN
    smtp-finger: < 250-ETRN
    smtp-finger: < 250-STARTTLS
    smtp-finger: < 250-DELIVERBY
    smtp-finger: < 250 HELP
    smtp-finger: > STARTTLS
    smtp-finger: < 220 2.0.0 Ready to start TLS
    smtp-finger: certificate verification failed for cs.columbia.edu[128.59.16.20]:25: untrusted issuer /C=US/O=Equifax Secure Inc./CN=Equifax Secure Global eBusiness CA-1
    smtp-finger: TLSv1 connection to cs.columbia.edu(cs.columbia.edu[128.59.16.20]:25) with cipher DHE-RSA-AES256-SHA (256/256 bits)
    smtp-finger: > EHLO amnesiac.ms.com
    smtp-finger: < 250-cs.columbia.edu Hello amnesiac.ms.com [192.0.2.1], pleased to meet you
    smtp-finger: < 250-ENHANCEDSTATUSCODES
    smtp-finger: < 250-PIPELINING
    smtp-finger: < 250-EXPN
    smtp-finger: < 250-VERB
    smtp-finger: < 250-8BITMIME
    smtp-finger: < 250-SIZE 25000000
    smtp-finger: < 250-DSN
    smtp-finger: < 250-ETRN
    smtp-finger: < 250-AUTH PLAIN LOGIN
    smtp-finger: < 250-DELIVERBY
    smtp-finger: < 250 HELP
    smtp-finger: Unverified: subject_CN=cs.columbia.edu, issuer=Equifax Secure Global eBusiness CA-1
    smtp-finger: Server session id: 8EA8B66A9DCCA0903BF75B7FC71316CE201330A0B1B09114FB6BE15E25AA9827
    smtp-finger: Common Name: cs.columbia.edu: matched
    ---
    Certificate chain
     0 s:/C=US/O=cs.columbia.edu/OU=  (c)04/OU=Domain Control Validated - This is a GeoTrust QuickSSL Premium(R) Certificate/CN=cs.columbia.edu
       i:/C=US/O=Equifax Secure Inc./CN=Equifax Secure Global eBusiness CA-1
    smtp-finger: Connected to ober.cs.columbia.edu[128.59.18.100]:25
    smtp-finger: < 220 ober.cs.columbia.edu ESMTP Sendmail (8.12.10/22/jtt/sed/ib42) is thrilled to serve you at Sat, 13 Jan 2007 13:27:14 -0500 (EST).
    smtp-finger: > EHLO amnesiac.ms.com
    smtp-finger: < 250-ober.cs.columbia.edu Hello amnesiac.ms.com [192.0.2.1], pleased to meet you
    smtp-finger: < 250-ENHANCEDSTATUSCODES
    smtp-finger: < 250-PIPELINING
    smtp-finger: < 250-EXPN
    smtp-finger: < 250-VERB
    smtp-finger: < 250-8BITMIME
    smtp-finger: < 250-SIZE 25000000
    smtp-finger: < 250-DSN
    smtp-finger: < 250-ETRN
    smtp-finger: < 250-STARTTLS
    smtp-finger: < 250-DELIVERBY
    smtp-finger: < 250 HELP
    smtp-finger: > STARTTLS
    smtp-finger: < 220 2.0.0 Ready to start TLS
    smtp-finger: certificate verification failed for ober.cs.columbia.edu[128.59.18.100]:25: untrusted issuer /C=US/O=Equifax Secure Inc./CN=Equifax Secure Global eBusiness CA-1
    smtp-finger: TLSv1 connection to ober.cs.columbia.edu(ober.cs.columbia.edu[128.59.18.100]:25) with cipher DHE-RSA-AES256-SHA (256/256 bits)
    smtp-finger: > EHLO amnesiac.ms.com
    smtp-finger: < 250-ober.cs.columbia.edu Hello amnesiac.ms.com [192.0.2.1], pleased to meet you
    smtp-finger: < 250-ENHANCEDSTATUSCODES
    smtp-finger: < 250-PIPELINING
    smtp-finger: < 250-EXPN
    smtp-finger: < 250-VERB
    smtp-finger: < 250-8BITMIME
    smtp-finger: < 250-SIZE 25000000
    smtp-finger: < 250-DSN
    smtp-finger: < 250-ETRN
    smtp-finger: < 250-AUTH PLAIN LOGIN
    smtp-finger: < 250-DELIVERBY
    smtp-finger: < 250 HELP
    smtp-finger: Unverified: subject_CN=ober.cs.columbia.edu, issuer=Equifax Secure Global eBusiness CA-1
    smtp-finger: Server session id: BD13DB29EA51632C6AA3B32CD2418E468DE27FF24FD1E2DDAF41E8F9C0D127A3
    smtp-finger: Common Name: ober.cs.columbia.edu: matched
    ---
    Certificate chain
     0 s:/C=US/O=ober.cs.columbia.edu/OU=  (c)04/OU=Domain Control Validated - This is a GeoTrust QuickSSL Premium(R) Certificate/CN=ober.cs.columbia.edu
       i:/C=US/O=Equifax Secure Inc./CN=Equifax Secure Global eBusiness CA-1
    smtp-finger: Connected to opus.cs.columbia.edu[128.59.20.100]:25
    smtp-finger: < 220 opus.cs.columbia.edu ESMTP Sendmail (8.12.10/22/jtt/sed/ib42) is thrilled to serve you at Sat, 13 Jan 2007 13:27:19 -0500 (EST).
    smtp-finger: > EHLO amnesiac.ms.com
    smtp-finger: < 250-opus.cs.columbia.edu Hello amnesiac.ms.com [192.0.2.1], pleased to meet you
    smtp-finger: < 250-ENHANCEDSTATUSCODES
    smtp-finger: < 250-PIPELINING
    smtp-finger: < 250-EXPN
    smtp-finger: < 250-VERB
    smtp-finger: < 250-8BITMIME
    smtp-finger: < 250-SIZE 25000000
    smtp-finger: < 250-DSN
    smtp-finger: < 250-ETRN
    smtp-finger: < 250-STARTTLS
    smtp-finger: < 250-DELIVERBY
    smtp-finger: < 250 HELP
    smtp-finger: > STARTTLS
    smtp-finger: < 220 2.0.0 Ready to start TLS
    smtp-finger: certificate verification failed for opus.cs.columbia.edu[128.59.20.100]:25: untrusted issuer /C=US/O=Equifax Secure Inc./CN=Equifax Secure Global eBusiness CA-1
    smtp-finger: TLSv1 connection to opus.cs.columbia.edu(opus.cs.columbia.edu[128.59.20.100]:25) with cipher DHE-RSA-AES256-SHA (256/256 bits)
    smtp-finger: > EHLO amnesiac.ms.com
    smtp-finger: < 250-opus.cs.columbia.edu Hello amnesiac.ms.com [192.0.2.1], pleased to meet you
    smtp-finger: < 250-ENHANCEDSTATUSCODES
    smtp-finger: < 250-PIPELINING
    smtp-finger: < 250-EXPN
    smtp-finger: < 250-VERB
    smtp-finger: < 250-8BITMIME
    smtp-finger: < 250-SIZE 25000000
    smtp-finger: < 250-DSN
    smtp-finger: < 250-ETRN
    smtp-finger: < 250-AUTH PLAIN LOGIN
    smtp-finger: < 250-DELIVERBY
    smtp-finger: < 250 HELP
    smtp-finger: Unverified: subject_CN=opus.cs.columbia.edu, issuer=Equifax Secure Global eBusiness CA-1
    smtp-finger: Server session id: 66B95E48EF282B6D96E87D317E17822417AED06377ECCA2300B3ECF09E19E10A
    smtp-finger: Common Name: opus.cs.columbia.edu: matched
    ---
    Certificate chain
     0 s:/C=US/O=opus.cs.columbia.edu/OU=  (c)04/OU=Domain Control Validated - This is a GeoTrust QuickSSL Premium(R) Certificate/CN=opus.cs.columbia.edu
       i:/C=US/O=Equifax Secure Inc./CN=Equifax Secure Global eBusiness CA-1

@_date: 2007-01-18 20:39:24
@_author: Victor Duchovni 
@_subject: It's a Presidential Mandate, Feds use it. How come you are not using FDE? 
Yesterday, in the case of OpenSSL, though I was only looking at how
ASN.1 strings that store the subject CN and subjectAltName deal with
the various possible supported encodings, embedded NUL octets, ...
It took reading the code to determine the following:
    - ASN.1 Strings extracted from X.509v3 certs are not validated for
    conformance with the declared character syntax. Strings of type
    PrintableString or IA5String may hold non-printable or non-ASCII
    data.
    - Rather in OpenSSL all the ASN.1 string types are opaque TLV byte
    arrays, with a manifest type and arbitrary content that may or
    not be consisten with the type, and may hold embedded NUL bytes
    which require some care in C applications, but at least it *is*
    possible if is careful, to check that:
    	ASN_STRING_length(s) == strlen(ASN1_STRING_DATA(s))
    - Conversion to UTF8 is implemented correctly, without prematurely
    stopping on internal NUL octets. This also checks that BMPString and
    UniversalStrings have encoded lengths that are even or divisible by
    4 respectively, and that UTF8 input is valid and "minimal".
This means that as a user of the library, I must (and fortunately can):
This is not the same as a full code review, but having access to the source
means that I can make sure that my code is a correct use of the interface,
that I am not making unfounded assumptions, and there are no obvious bugs
in the part of the library that I am reviewing.

@_date: 2007-01-20 13:58:05
@_author: Victor Duchovni 
@_subject: It's a Presidential Mandate, Feds use it. How come you are not using FDE? 
I understand the motivation, and agree that this is the right thing to
do, indeed in the application (Postfix) I just map the content to UTF8
(using the identity mapping where appropriate) and then decide what
characters are acceptable, I don't need the original ASN.1 string type
after the string is in canonical form.
My point was that not all the fine details are always documented (even in
closed source libraries with funded documentation teams), and having the
source allows me to move beyond cargo-cult programming and to understand
how to use the library correctly. I guess this is RTFS to extract the
semantics out of the syntax documentation.
In addition, I think that the library should-provide idiot-friendly
interfaces for handling ASN.1 string data holding security sensitive
information (CommonName, subjectAltName, ...), because the code one
finds and copies from other projects is not sufficiently careful.
RFC 3820 suggests that it is OK to consider strings of different ASN.1
types as different content for comparison and then, by implication,
just compare the raw content when the types match, but what one finds
is that applications mostly IGNORE the ASN.1 string type and use the
raw octets for comparison, display, ... and they do that at their peril.
It is also almost universal practice (in C code anyway) to not check
for embedded NUL in the ASN.1 strings, and I wonder how may CAs would
issue "eve.biz" a cert for "alice.com\0.w (If the CA's code
handles NUL in octet strings as just another byte, this could happen.
But we digress again, the source is useful in any case, and not just
for full code reviews, used with care it is the ultimate documentation.

@_date: 2007-01-24 17:37:41
@_author: Victor Duchovni 
@_subject: OT: SSL certificate chain problems 
It is much more typical of openssl-users, which is probably a better
bet for this question.
Generally it is enough for a TLS server or client to present its own
certificate and all *intermediate* CA certificates, sending the root CA
cert is optional, because if the verifying system trusts the root CA in
question, it has a local copy of that root CA cert. There be limitations
in some verifier implementations that make it necessary to supply the
root CA cert anyway.
    No you concatenate multiple certificates (server first, then issuer,
then issuer's issuer, ...) into a single file and set that as the Server
Cert file, not the CA file.
Please take any further questions to openssl-users at openssl.org (via
majordomo at openssl.org).

@_date: 2007-01-25 15:17:22
@_author: Victor Duchovni 
@_subject: analysis and implementation of LRW 
This is quite wrong. 2^64 * 2^4 = 2^68 not 2^32, I don't know where you
lost the factor 2^36, but it sure makes a big difference.

@_date: 2007-01-26 11:42:58
@_author: Victor Duchovni 
@_subject: OT: SSL certificate chain problems 
Wouldn't the old root also (until it actually expires) verify any
certificates signed by the new root? If so, why does a server need to
send the new root? So long as the recipient has either the new or the
old root, the chain will be valid. Is the problem case when the verifier
has both roots, and the older of the two has expired?

@_date: 2007-01-28 01:08:11
@_author: Victor Duchovni 
@_subject: OT: SSL certificate chain problems 
I am curious how the expired trusted old root helps to verify the as
yet untrusted new root... Is there a special-case behaviour when the
old and new root share the same DN and public key? Is such special-case
behaviour standard for trust chain verification implementations (allowing
the lifetime of root CAs to be indefinitely extended by issuing new certs
with the same keys)?

@_date: 2007-01-28 13:00:09
@_author: Victor Duchovni 
@_subject: OT: SSL certificate chain problems 
The key extra information is that old and new roots share the same issuer
and subject DNs and public key, only the start/expiration dates differ,
so in the overlap when both are valid, they are interchangeable, both
verify the same (singly-signed) certs. What I don't understand is how
the old (finally expired) root helps to validate the new unexpired root,
when a verifier has the old root and the server presents the new root
in its trust chain.

@_date: 2007-01-30 20:34:37
@_author: Victor Duchovni 
@_subject: OT: SSL certificate chain problems 
So this is a special trick to extend root CA lifetimes. How widely is
this logic implemented, and is extending root CA key lifetime in this
manner standard practice? I may have to revise the Postfix documentation
to advise users to send the root cert.
My most recent experience is ironically in the opposite direction:
    Peer finally upgrades from Windows Server 2000 to Windows Server 2003,
    and replaces unexpired Verisign CA certs (updated at some point in
    the past in the working Windows 2000) with now expired CA certs that
    were good way back, when the Windows 2003 CDs were burned :-)

@_date: 2007-06-21 10:41:20
@_author: Victor Duchovni 
@_subject: Blackberries insecure? 
The key issue is who manages the (not necessarily, but often Exchange)
mail store. Enterprise BlackBerry devices should be safe from external
attacks, consumer BlackBerry devices use servers provisioned elsewhere.
Are the officials using "Corporate" or "Personal" BlackBerry devices?

@_date: 2007-06-21 13:09:12
@_author: Victor Duchovni 
@_subject: wrt "Network Endpoint Assessment" 
Nothing, the technology is not sufficient, merely necessary...

@_date: 2007-06-21 13:20:35
@_author: Victor Duchovni 
@_subject: Quantum Cryptography 
Quantum Cryptography or Quantum Computing (i.e. cryptanysis)?
    - Quantum Cryptography is "fiction" (strictly claims that it solves
      an applied problem are fiction, indisputably interesting Physics).
    - Quantum Computing is "science fiction". Some science fiction
      eventually becomes reality.

@_date: 2007-06-22 10:37:26
@_author: Victor Duchovni 
@_subject: Quantum Cryptography 
Secure in what sense? Did I miss reading about the part of QKD that
addresses MITM (just as plausible IMHO with fixed circuits as passive
Once QKD is augmented with authentication to address MITM, the "Q"
seems entirely irrelevant.

@_date: 2007-06-22 12:07:51
@_author: Victor Duchovni 
@_subject: Quantum Cryptography 
If I want to encrypt a fixed circuit, I assume that eavesdropping is
omni-present, and furthermore don't want to be constrained to transmit
only when the eavesdroppers have chosen to take a lunch break.
"Warm fuzzies"?
An interesting assumption.
I would conjecture that a lot more people grasp undergraduate mathematics
than undergraduate quantum mechanics...
"Warm fuzzies" is not in conflict with "fiction".
Suppose I install a fake subway entrace, and MITM all the interactions
between the victim's card and the real turnstile where I have a card that
proxies the victims interactions with the fake terminal. Is the system
still secure? Likely not, I would bet The threat model was card forgery,
not MITM.

@_date: 2007-06-22 15:33:52
@_author: Victor Duchovni 
@_subject: Quantum Cryptography 
QKD fails to "come into the picture", because its key exchange is
I can do secure unauthenticated key exchange at zero cost using EECDH
with no special quantum hardware. If the link is MITM-proof, I am done.
What bulk-encryption system am I going to use that is usefully stronger
than EECDH over secp384r1 (or tinfoil hat secp521r1). It is also not
useful for key distribution. It remains (charitably) "fiction".

@_date: 2007-06-26 13:11:40
@_author: Victor Duchovni 
@_subject: Quantum Cryptography 
Does QKD address a real-world risk at a reasonable cost without unreasonable
application constraints?
If I am very concerned about PFS for secrets that must stay secure for
decades and 521-bit ECDH is broken, yes I lose PFS. So there may be a
market for fixed direct circuits used by a small number of agencies, but
if I were a budget director I would spend the money elsewhere...
Indeed, what was the legal question that got us here?

@_date: 2007-03-03 16:32:29
@_author: Victor Duchovni 
@_subject: Cracking the code? 
If you are not a security consultant hired to find and close this type
of vulnerability, and don't want to follow in the footsteps of Randal
L. Schwartz, it is sadly best to stay ignorant of such matters...

@_date: 2007-05-21 16:32:10
@_author: Victor Duchovni 
@_subject: 307 digit number factored 
When do the Certicom patents expire? I really don't see ever longer RSA
keys as the answer, and the patents are I think holding back adoption...
FWIW, Postfix 2.5 in Q1 08 will have EC support when compiled with (likely
officially released by then) OpenSSL 0.9.9, the recommended curve is
"prime256v1" with "secp384r1" for "encrypt until it hurts" users :-).
The other issue is that sites will need multiple certs during any
transition from RSA to ECC, because the entire Internet won't upgrade
overnight. I am not expecting public CAs to cooperate by charging the
same price for two certs (RSA and ECC) for the same subject name(s),
this also may significantly impede migration.
With EECDH one can use ECDH handshakes signed with RSA keys, but that
does not really address any looming demise of 1024 bit RSA.

@_date: 2007-05-21 23:52:04
@_author: Victor Duchovni 
@_subject: 307 digit number factored 
We are not talking about this year or next of course. My estimate is
that Postfix releases designed this year, ship next year, are picked up
by some O/S vendors the year after and shipped perhaps a year after that,
then customers take a few years to upgrade, ... So for some users Postfix
2.5 will be their MTA upgrade in 2011 or later. So we need to anticipate
future demand by a few years to be current at the time that users begin
to use the software.
As 1024 RSA keys are not a major risk *today*, but that may be in sight,
it is not unreasonable to explore the (multi-year) road to ECC adoption.
There are many obstacles, it may take a long time, but I am removing
the one obstacle I can remove...
Initially ECC in Postfix will be used by private arrangements between
sites that manually exchange keys and have no need of a public CA.
Postfix, 2.5 also includes a new "fingerprint" security level, where
the SMTP client verifies the server certificate by its md5, sha1, or
SHA256/384/512 fingerprint. (No support for web-of-trust, one step
at a time).

@_date: 2007-05-23 00:48:19
@_author: Victor Duchovni 
@_subject: 307 digit number factored 
Indeed, and since the certs I acquire from CAs today expire in a year,
I don't feel at all guilty about generating CSRs with 1024 bit keys.
Clearly, a public CA cert with a lifetime of 10-20 years is another
matter, but otherwise in most cases there is no need to panic.  Not too
many organizations outside the TLAs are using RSA to encrypt multi-decade
Software that will be in the field for a long time, should support
stronger keys and if possible alternative algorithms (say ECC), but
short-term authentication keys deployed today, are just fine as they are.

@_date: 2007-05-23 12:56:51
@_author: Victor Duchovni 
@_subject: 307 digit number factored 
There is no need to store routing information:
The short summary is that full security is only available when the
receiving MX hosts have certs that match the recipient domain, or
the sender is willing to manually (in his MTA configuration) bind the
recipient domain to the subject names (or in 2.5 fingerprints) of the
appropriate MX hosts.

@_date: 2007-05-24 19:13:46
@_author: Victor Duchovni 
@_subject: SSL certificates for SMTP 
The main difficulty with SMTP, is that indirection via MX records
maps poorly onto X.509v3 CommonName, and only slightly better onto
SubjectAlternativeName(DNS). Users don't request delivery to an MX host,
they request delivery to recipient at domain.
Indeed DNSSEC + certificates in a trusted DNS would be vastly better,
but not only are we not getting there, we don't even seem to be going
there at all.

@_date: 2007-11-02 08:40:32
@_author: Victor Duchovni 
@_subject: Picture signatures as (hand-held device) biometric passwords? 
Via Slashdot:
An interesting variant on biometrics, can't easily be reproduced with
pieces of one's body separated from the whole, and involves in part
something remembered. No hard numbers were provided on FP/FN rates.  Also,
no mention of how "compexity rules" might be handled. CISOs might not
be too happy without a warm fuzzy that their users have decent passwords
on their BlackBerry devices. Is my "X" more secure than your "X"?
This may not work for everyone, some people are more verbal-sequential
than visual-spatial. I for one don't really have a stable hand-written
signature, but have no problem memorizing long passwords (and can store
them in a password-safe).

@_date: 2007-10-05 15:00:11
@_author: Victor Duchovni 
@_subject: Undocumented Bypass in PGP Whole Disk Encryption 
The article is sensational nonsense. The quote is right on the money,
businesses require disk encryption companies to support one time unprotected
reboot (enabled securely before reboot) to support automated rebuilds.
Without this requirement, the Windows desktop support teams refuse to
field the products. The problem is not interesting, the feature cannot
be enabled after the fact.

@_date: 2007-10-13 03:20:48
@_author: Victor Duchovni 
@_subject: Quantum Crytography to be used for Swiss elections 
Why so shy? What threat model could have justified this approach?
So they are assuring the integrity of stored data by doing ephemeral
communications (not stored data) integrity! Neither the integrity of
the data entry, nor the integrity of the data leaving the QC network
and stored on the disk are actually assured. I am really impressed.
Looks like a finely staged circus act.
Now we find out what problem this really solves.
But instead of signing the actual counts entered into the computer, they
mysteriously choose secure the communication line...
Common sense is a rapidly disappearing commodity.
There is real charm in the phrase "endowed with relevance and purpose".
One might, by analogy with the 2nd law of thermodynamics, speculate that
prior to some of the relevance and purpose of the election data rubbing
off on the QC system, the QC system was the one more lacking in these
desirable attributes. If wants to really go out on a limb, one might
try to apply the fist law also, and conclude that the election data has
as a result less relevance and purpose.
In our physical analogy, heat is replaced with "trust/relevance/purpose".
One can transfer this "heat" from the election to a technology or from a
technology an election, always in the expected direction.

@_date: 2007-09-04 16:46:58
@_author: Victor Duchovni 
@_subject: Neal Koblitz critiques modern cryptography. 
The way I read it, it is a critique of the (somewhat inevitable) poor
quality of peer-review for conference proceedings, and the author is
indirectly complaining that more traditional journals are not always
the norm for crypto research that sets best-practice standards.
In a nutshell: important ideas deserve time, rather than Internet-time.
This part is not too radical. The more specific scepticism of security
proofs (I am reluctant to agree that these are actively harmful), seems
to be a combination of the peer review issue above, and (often?) lack of
tight bounds that make the proofs applicable to realistic parameter sizes.

@_date: 2007-09-20 01:09:02
@_author: Victor Duchovni 
@_subject: Scare tactic? 
I am not a cryptographer, but the article appears silly.
First the verification algorithm as stated is wrong:
    * Verify that 2 <= K_a <= p - 2
    * Verify that (K_a)^g = 1 (mod p)
The first condition is correct, but the second is not, that "g" should
be a "q", where "q" is a large prime divisor of "p-1" and "g" is chosen
so that the order of "g" mod "p" is "q". The correct second test just
verifies that K_a is an element of order q (true for all non-trivial
powers of g).
Even with the verification algorithm K_a can still be equal to a small
power of "g", which the passive eavesdropper can quickly brute-force.
In fact the entire threat model is broken, because if Alice wants Eve to
be able to crack Alice's key exchange with Bob, Alice can just send Eve
her secret exponent. Why waste time with weak exponents that Bob may be
able to detect if he so choses?
So verification of the peer exponent has nothing to do with Allice
colluding with passive eavesdroppers.
Rather the issue is small-subgroup attacks, which are of interest
in some cases (and not applicable in others).
    Have not looked at IKE closely enough to comment on whether small
subgroups are a concern in that context.

@_date: 2008-04-01 01:01:14
@_author: Victor Duchovni 
@_subject: how to read information from RFID equipped credit cards 
Which ones do you think are doing a decent job of this?
Lock USB down completely, or block most devices and allow approved
ones?  There is a non-empty set folks doing the latter, which opens
the possibility of this type of device being permitted, while others
are restricted.
Since *all* it needs is the ability to call "home" to its server, and
register to send/receive messages, it will not look like mass-storage,
and should not look like a network interface. Data leakage should not
be a concern if the device is built/marketted correctly.

@_date: 2008-04-21 13:43:55
@_author: Victor Duchovni 
@_subject: Cruising the stacks and finding stuff 
This is usually the point where I stop reading. Of course 10 orders of
magnitude is ~33 bits, so unless the A5 attacks crack a cipher with ~95
bits security, the estimate is grossly wrong.
If (generously) A5 is 64 bits of work, AES is ~20 orders of magnitude

@_date: 2008-04-28 22:03:38
@_author: Victor Duchovni 
@_subject: SSL and Malicious Hardware/Software 
Expectations of privacy at work vary by jurisdiction and industry. In
the US, and say in the financial services industry, any such expectations
are groundless (IANAL).

@_date: 2008-12-09 11:27:22
@_author: Victor Duchovni 
@_subject: AES HDD encryption was XOR 
In the well-known Indian fable, the King was bankrupted by doubling grains
of rice on a 64-square chess-board. Back in the USSR, every school-child
learned this fable. Oh, and chess was pretty popular too...
The fact that the fable refutes the *sustainability* of Moore's "law"
seems to be under-appreciated on this side of the Iron-curtain. It is
not a question of whether, but rather when the departure from Moore's
"law" will take place.
The computing power of the microprocessor is still under 32 powers of
2 from its inception, naive extrapolation to the next 32 powers of 2
is unwise.

@_date: 2008-02-06 13:51:10
@_author: Victor Duchovni 
@_subject: TLS-SRP & TLS-PSK support in browsers (Re: Dutch Transport Card Broken) 
It is a bit early. OpenSSL 0.9.9 is not yet released. I wish OpenSSL
releases were more frequent, and each added fewer features, allowing
features to be released as they mature, this would also reduce pressure
to add features to stable releases (which occasionally break binary
compatibility, and lead to vendors back-porting fixes rather than deploying
the next patch level of the stable release).
While Firefox should ideally be developing and testing PSK now, without
stable libraries to use in servers and browsers, we can't yet expect
anything to be released.

@_date: 2008-02-07 10:37:57
@_author: Victor Duchovni 
@_subject: TLS-SRP & TLS-PSK support in browsers (Re: Dutch Transport Card Broken) 
I don't have any idea why or why not, but all they can release now is
source code with  openssl >= 0.9.9  ... do PSK stuff ... with binaries (dynamically) linked against the default OpenSSL on the
oldest supported release of each platform... For RedHat 4.x systems,
for example, that means that binary packages use 0.9.7...
Distributions that build their own Firefox from source may at some point
have PSK (once they ship OpenSSL 0.9.9). I don't think we will see this
available in many user's hands for 2-3 years after the code is written
(fielding new systems to the masses takes a long time...).

@_date: 2008-02-09 23:21:13
@_author: Victor Duchovni 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
Microsoft broke this in IE7... It is no longer possible to generate and
enroll a client cert from a CA not on the trusted root list. So private
label CAs can no longer enroll client certs. We have requested a fix,
so this may come in the future, but the damage is already done...
Also the IE7 browser APIs for this are completely different and rather
minimally documented. The interfaces are not portable between browsers,
... It's a mess.

@_date: 2008-02-10 18:45:48
@_author: Victor Duchovni 
@_subject: TLS-SRP & TLS-PSK support in browsers (Re: Dutch Transport Card Broken) 
You are probably right about that, they use the "NSS" library. It is
sometimes easy to forget that not all the world is OpenSSL...

@_date: 2008-01-07 23:09:04
@_author: Victor Duchovni 
@_subject: Foibles of user "security" questions 
Why enter your mother's actual maiden name when prompted for it? A
security savvy user will recognize this as a second password, that
multiple sites seem to want to share, and enter something unique and
unmemorable (stored on a "keychain" or just discarded if the primary
password is similarly safely stored).
When asked to provide answers for security questions, mine are always
either the output of "openssl rand -base64 N" (with N = 6, 9 or 12),
or more memorable non-sequiturs when that is more appropriate. Here's
a new reasonably memorable variant.
    Q: Mother's Maiden Name:
    A: Winston-Delano-Stalin

@_date: 2008-01-23 12:50:33
@_author: Victor Duchovni 
@_subject: SSL/TLS and port 587 
Nothing of the sort, TLS on port 587 protects replayable *authentication*
mechanisms, suchs as "PLAIN" and "LOGIN". It can also allow the client to
authenticate the server (X.509v3 cert) and preclude MITM attacks on
mail submission. I've not seen any reputable parties claiming that TLS
submission is protection against intercepts.
I maintain the TLS code for Postfix, the documentation does not anywhere
make such claims. However we do support TLS sensitive SASL mechanism
        which is highly suggestive of using TLS to protect plain-text passwords
in flight.

@_date: 2008-01-30 14:47:46
@_author: Victor Duchovni 
@_subject: Dutch Transport Card Broken 
Jumping in late, but the idea that *TCP* (and not TLS protocol design)
adds round-trips to SSL warrants some evidence (it is very temping to
express this skepticism more bluntly).
With unextended SMTP for example, the minimum RTT count is:
so it takes at least 6 RTTs to perform a delivery (of a short
single-recipient message), but only 1 of the 6 RTTs is TCP
"overhead". This is improved with PIPELINING:
Here the application protocol is pipelined, and 5+n RTTs becomes 4 RTTs.
The solution is not replacing TCP, but reducing the number of lock-step
interactions in the application protocol.
If someone has a faster than 3-way handshake connection establishment
protocol that SSL could leverage instead of TCP, please explain the
The TCP handshake adds a 1-RTT delay at the start of the connection.
What 0-RTT algorithm will allow the server to delay creating expensive
connections to clients until the client acks the server response or
discover the MSS before sending the first segment? With TCP, at least
SYN floods require unspoofed client IPs.
Most of the application protocols we wrap in TLS are not DNS. Sure if
you can guarantee a single packet response to a single packet request,
TCP is not the answer. Otherwise, claiming that SSL is less efficient
over TCP smacks of arrogance.

@_date: 2008-01-31 15:34:51
@_author: Victor Duchovni 
@_subject: Dutch Transport Card Broken 
SMTP does not need TCP to provide reliability for the tail of the session,
the application-level "." (end-of-data) and server "250" response complete
a transaction, everything after that is optional, so for example Postfix
will send (when PIPELINING).
and will disconnect after reading the "250 response" without waiting
for the 221 response. The TCP 3-way shutdown (FIN, FIN-ACK, ACK) happens
in the kernel in the background, the SMTP server and client are by that
point handling different connections. So the reliable shutdown latency
is of no consequence for application throughput.
A pipelined SMTP delivery can be completed over TCP in 5 RTTs not 7.
TCP is fine, latency is primarily the result of application protocol
details, not TCP overhead. The only TCP overhead above is 1 extra RTT
for the connection setup. Everything else is SMTP not TCP, and running
SMTP over UDP (with ideal conditions and no lost packets, ...) would
save just 1 RTT.

@_date: 2008-01-31 23:12:45
@_author: Victor Duchovni 
@_subject: Dutch Transport Card Broken 
============================== START ==============================
Thanks, an excellent reference! Section 6.2 is most enlightening, we were
already considering adopting HPN fixes in the internal OpenSSH deployment,
this provides solid material to motivate the work...

@_date: 2008-07-07 13:10:45
@_author: Victor Duchovni 
@_subject: Permanent Privacy - Snake Oil or unbreakable encryption? 
This reads like snake oil.
This reads like a pump'n'dump stock scam.

@_date: 2008-07-09 13:02:57
@_author: Victor Duchovni 
@_subject: Kaminsky finds DNS exploit 
The "discovery" is almost certainly a generalization of:
specifically the second paragraph the mentions the "Birthday Attack". The
assumptions of that paragraph can be relaxed in a natural way to broaden
the scope of the attack.

@_date: 2008-07-21 12:03:50
@_author: Victor Duchovni 
@_subject: Looking through a modulo operation 
After any consecutive 96 outputs, the 97th is a fixed linear function of
those just observed. It is not necessary to determine the internal state.
The internal state is s_n = (A**n)(s_0) for a fixed 96x96 matrix A (the
fact that it is a direct product of 3 32-bit matrices is not important).
This matrix has a minimum polynomial of degree at most 96.
The 32-bit output then also satisfies:
for the same coefficients.

@_date: 2008-07-21 15:21:44
@_author: Victor Duchovni 
@_subject: Looking through a modulo operation 
I skipped over this part when reading the original message. Expecting per
Florian's original message the outputs to be a "linear" function of the
inputs, but they are not.
This of course applies to the 32-bit output of the RNG. The operation
of reducing the 32-bit output modulo 28333, is not "linear" (over the
F_2 bit string vector-space). While:
this is only true bitwise modulo 2. It is not obvious how one might
recover the full 32-bit outputs from the truncated outputs.

@_date: 2008-06-01 00:07:48
@_author: Victor Duchovni 
@_subject: Protection mail at rest 
S/MIME does not encrypt any headers. It only encrypts the
    payload. Some S/MIME applications don't leave any useful
    headers in the outer message, others leave the sender and
    subject in the clear.
Take PGP Universal gateway and turn-it inside-out. Clear mail on the
Internal encrypted mail on the intranet between the gateway and the
mail store.
Take a vanity domain, run an encryption gateway, forward everything to to
an ESP. The ESP's search engine will not do you much good with encrypted
mail, so indexing is up to your IMAP client, if it can cache/index
decrypted content.
Not much demand for this yet, so I don't expect mature offerings any
time soon. We'd have to build a boutique service for cipher-punks.

@_date: 2008-06-03 22:44:54
@_author: Victor Duchovni 
@_subject: Protection mail at rest 
S/MIME supports enveloped MIME objects, if PGP does not work out for MIME
entities, you could try that. S/MIME is natively supported in Thunderbird,
Apple Mail, and similar MUAs.

@_date: 2008-03-30 23:07:58
@_author: Victor Duchovni 
@_subject: [p2p-hackers] convergent encryption reconsidered 
PBKDFS2 is excellent for turning interactively typed pass-phrases into
keys. It is not entirely clear that it is a good fit for a filesystem.
Updating any single file is now a computationally intensive process, the
performance impact may be unacceptable. With PBKDF2 and the iteration
count set to the for now popular "1000", a 64K byte file will now trigger
~~2 million sha1 compression function computations (if I remember the
sha1 block size correctly as 512 bits or 64 bytes).
A crude cost estimate on typical hardware (openssl speed):
    Doing sha1 for 3s on 8192 size blocks: 57316 sha1's in 3.00s
Extrapolating from this, on 64K sized files, we get ~1200 HMAC operations
per second. If we iterate that 1000 times, 1.2 key derivations per
second. The throughput to disk is CPU bound at ~64KB/s, which is rather

@_date: 2008-05-05 21:08:50
@_author: Victor Duchovni 
@_subject: User interface, security, and "simplicity" 
The TLS support in Postfix tries to behave sensibly with "easy" setings.
    - Cipher list selection is indirect, via grades: "export", "low",
    "medium" and "high". The actual ciphers for each grade are buried
    in parameters users are advised to not mess with.
    - The cipher grade for opportunistic TLS is "export", but you single
    out a destination for mandatory TLS, the grade rises to "medium".
    - The "secure" peer cert validation level compares the peer's cert to
    the nexthop domain (allowing a sub-domain match by default). Hostnames
    derived from MX lookups are of course subject to DNS MITM and are not
    trusted.  If you want to trust your DNS you can use "verify" instead.
                        - With the upcoming EECDH support, users don't choose curves
    directly, they again choose a security grade, and the correspnding
    curves are configurable via parameters they are not expected to
    ever look at or modify.
If you don't botch your CAfile, it is rather easy to provision
secure-channel connections to a select set of high-value peers.
If you don't trust any CAs:
    once you have a system designed in all its features to behave sensibly
by default (e.g. with an empty main.cf file), making security behave
sensibly by default is not that unnatural.
So I think there should be a broad design bias towards *implicit* correct
behaviour in all system features, with rope available for advanced users
to *explicitly* craft more complex use-cases. Once you have that, practical
security is not too difficult.
The same is true in the source code, unsafe practices are avoided
globally, (e.g. both strcpy() and strncpy() are absent together with fixed
size automatic buffers) rather than used with care locally. I won't bore
you with all the implementation safety "habits", but there are many.

@_date: 2008-05-06 15:52:51
@_author: Victor Duchovni 
@_subject: User interface, security, and "simplicity" 
They are not *asked* to make any cipher choices. The are able to make:
The users in question are email administrators, not end users, and you
missed my point. They are not asked to choose ciphers, these are chosen
for them, and the default choice is even context dependent, so you get
sensible combinations of security properties:
This is what is done (using OpenSSL's "HIGH", "MEDIUM", ... selectors).
You don't know how TLS is used with SMTP. Most TLS is opportunistic and
plain text is used if TLS is absent. In such an environment insisting
on 128 bits is silly, even 40 bits is better than plain-text.
Breaking interoperability by limiting cipher selection and causing mail
to queue is not cheap.
Practices are "culture" not "technology", and it is difficult to displace
existing cultures with new ones :-(

@_date: 2008-05-06 21:44:34
@_author: Victor Duchovni 
@_subject: User interface, security, and "simplicity" 
This too is dealt with. Message sizes are bounded, recipient counts
are bounded, duplicate elimination cache sizes are bounded, command
lengths are bounded, logical header lengths are bounded, body content
is processed 2K bytes at a time...
The requirement is stronger than just not running a single process out of
memory, the entire multi-process Postfix is designed to run in (realistic)
bounded memory (no "fork: out of memory").

@_date: 2008-05-13 17:10:00
@_author: Victor Duchovni 
@_subject: The perils of security tools 
Upstream authors can take defensive measures against ill-advised
patches of this sort. For a while, distributions were in the habit
of Patching the code that Postfix uses to learn the its own hostname.
Invariably, they botched it. The code now reads:
  /* get_hostname - look up my host name */
  const char *get_hostname(void)
  {
    char    namebuf[MAXHOSTNAMELEN + 1];
    /*
     * The gethostname() call is not (or not yet) in ANSI or POSIX, but it is
     * part of the socket interface library. We avoid the more politically-
     * correct uname() routine because that has no portable way of dealing
     * with long (FQDN) hostnames.
     *
     * DO NOT CALL GETHOSTBYNAME FROM THIS FUNCTION. IT BREAKS MAILDIR DELIVERY
     * AND OTHER THINGS WHEN THE MACHINE NAME IS NOT FOUND IN /ETC/HOSTS OR
     * CAUSES PROCESSES TO HANG WHEN THE NETWORK IS DISCONNECTED.
     *
     * POSTFIX NO LONGER NEEDS A FULLY QUALIFIED HOSTNAME. INSTEAD POSTFIX WILL
     * USE A DEFAULT DOMAIN NAME "LOCALDOMAIN".
     */
    if (my_host_name == 0) {
      /* DO NOT CALL GETHOSTBYNAME FROM THIS FUNCTION */
      if (gethostname(namebuf, sizeof(namebuf)) < 0)
      namebuf[MAXHOSTNAMELEN] = 0;
      /* DO NOT CALL GETHOSTBYNAME FROM THIS FUNCTION */
      if (valid_hostname(namebuf, DO_GRIPE) == 0)
      /* DO NOT CALL GETHOSTBYNAME FROM THIS FUNCTION */
      my_host_name = mystrdup(namebuf);
    }
    return (my_host_name);
  }
The addition of "/* DO NOT CALL GETHOSTBYNAME FROM THIS FUNCTION */"
every couple of lines appears to have solved the problem: it deliberately
breaks all prior patches (context diff overlaps), and strongly signals
that the code must not be messed with.

@_date: 2008-05-27 17:05:10
@_author: Victor Duchovni 
@_subject: RIM to give in to GAK in India 
But this is not news. It is well known (at least among the Enterprise
Remote Computing wonks) that only the Enterprise RIM service provides
"end-to-end" security, while the consumer service does not. There is
nothing new here. It is not even marketing spin, without your IT shop
hosting your content, it is hosted by providers subject to CALEA, ...
The good news about RIM is that it has been one of the few devices that
actually provides end-to-end security for Enterprises. This has been a
selling point that helped get them a large share of the Enterprise market.

@_date: 2008-05-30 13:41:10
@_author: Victor Duchovni 
@_subject: RIM to give in to GAK in India 
The keys are symmetric 3DES, and encrypt message chunks (IIRC either
256 or 1K bytes) sent asynchronously to the enterprise messaging gateway.
RIM does not have a secure session with the device. This is not like
S/MIME except that as with S/MIME, this is not hop-by-hop encryption.

@_date: 2008-05-30 15:22:10
@_author: Victor Duchovni 
@_subject: RIM to give in to GAK in India 
Not "to the RIM gateway", "via the RIM gateway" the payload is destined
for a corporate messaging server.
Presumably the device has a KEK, and generates a session key for each
message, encrypting that under the KEK. The KEK is used for a long time
(~90 days) and periodically renegotiated. I don't recall how the KEK is
agreed to. Perhaps there is PKI involved in that step, or it could just
negotiate the new KEK using the current KEK. There is not in practice
any need for a PKI in this context, it looks rather a lot more like
Kerberos than PKI.

@_date: 2008-09-16 17:08:27
@_author: Victor Duchovni 
@_subject: RSA modulus record 
Are the primes actually known, or just "guaranteed to exist"?
In what sense is this "impressive security"?
    - Impressive 10 MB wide RSA signatures?
    - Impressively long time on super-computers to verify said signatures
    - Impressively few potential users, with at most one known key pair?
This is likely real progress in computational number theory, but it is
not clear how it is an advance in "security".

@_date: 2008-09-29 11:29:06
@_author: Victor Duchovni 
@_subject: TLS Server Name Indication and IDNA? 
I am considering adding TLS Server Name Indication support in the Postfix
SMTP server and client. I am puzzled by the exceedingly terse description
of the semantics of the HostName sent in the SNI extension:
           If the hostname labels contain only US-ASCII characters, then the
       client MUST ensure that labels are separated only by the byte 0x2E,
       representing the dot character U+002E (requirement 1 in Section 3.1
       of [IDNA] notwithstanding).  If the server needs to match the
       HostName against names that contain non-US-ASCII characters, it MUST
       perform the conversion operation described in Section 4 of [IDNA],
       treating the HostName as a "query string" (i.e., the AllowUnassigned
       flag MUST be set).  Note that IDNA allows labels to be separated by
       any of the Unicode characters U+002E, U+3002, U+FF0E, and U+FF61;
       therefore, servers MUST accept any of these characters as a label
       separator.  If the server only needs to match the HostName against
       names containing exclusively ASCII characters, it MUST compare ASCII
       names case-insensitively.
At least the Postfix SMTP client does not normally work with IDNA domains
directly. In queued email messages the recipient domain is already ACE
encoded, e.g. . Suppose Postfix is configured
to establish a TLS secure-channel with a mail server for this domain, and
now wants to signal the required certificate name to the receiving SMTP
What should the SMTP client put in the RFC 4366 section 3.1 "HostName":
    - The ACE domain it is working with (xn--exmple-cua.com)?
    - The underlying UTF8 domain name? (ex?mple.com)?
What should the server do when it receives the client's "HostName"?
    - Convert ACE to UTF8?
    - Convert UTF8 to ACE?
When searching for certificates with matching domain names, the receiving
server may need to look at:
    :
    :
What type of comparison is the server expected to perform?
    - Convert UTF8 CommanName to ACE (also leave IA5 alone) and then compare?
    - Convert ACE names in either subjectAltName or CN to UTF8 and then
      compare UTF8 strings (with NAMEPREP, STRINGPREP and all that jazz)?
This can be (to say the least) rather unpleasant. If IDNA is only between
the user and the UI, with everything on the wire in ACE form, then all
the pain is avoided:
          the CommonName where the name in question is a domain name.
If instead, client and server have to jump through hoops doing (tersely
specified, and unlikely IMHO to inter-operate) IDNA conversions, then I
may just bag the whole idea and do something more useful.
Anyone have any insight on what implementations are supposed to do?

@_date: 2009-01-09 23:09:07
@_author: Victor Duchovni 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
All fine and good, but no existing OpenSSL release (including
0.9.9-dev) will by default inter-operate with the resulting (SHA2)
certificates. The SSL_library_init() call only initializes "ssl"
ciphers and digests, which do not include SHA-2. So most SSL
applications won't be able to verify the certificate signatures.
One needs to call OpenSSL_add_all_algorithms() before SHA-2
signed certificates work.
Bottom line, anyone fielding a SHA-2 cert today is not going to be happy
with their costly pile of bits.

@_date: 2009-01-10 23:06:46
@_author: Victor Duchovni 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
Extremely unlikely in the case of SSL/TLS and X.509 certs. There is
a huge install-base of systems on which SHA-2 certs will failed SSL
handshakes. When Windows XP systems are <1% of the install-base, when
OpenSSL 0.9.8 is <1% of the install-base and 0.9.9 too (if the
support is not added before it goes official), and all the browsers,
Java libraries, ... support SHA-2, then you can deploy SHA-2 certs.
I would estimate 5-8 years, if developers of all relevant mainstream
implementations start to address the issue now. SHA-1 will be with
us well after 2010. New applications written in 2010 will ideally
support SHA-2, but SHA-1 will probably still be the default digest
in many applications through 2013 or 2015.

@_date: 2009-01-19 13:14:40
@_author: Victor Duchovni 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
It would be helpful if as a first step, SSL_library_init() (a.k.a.
OpenSSL_add_ssl_algorithms()) enabled the SHA-2 family of digests,
I would make this change in the 0.9.9 development snapshots.
[ Off topic: I find OpenSSL release-engineering a rather puzzling
process. The "patch" releases are in fact feature releases, and there
are no real patch releases even for critical security issues.  I chose
to backport the 0.9.8j security fixes to 0.9.8i and sit out all the
new FIPS code, ... This should not be necessary. I really hope to see
real OpenSSL patch releases some day with development of new features
*strictly* in the development snapshots. Ideally this will start with
0.9.9a, with no new features, just bugfixes, in [b-z]. ]

@_date: 2009-01-23 10:36:33
@_author: Victor Duchovni 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
Don't want to start a long debate here, but I do want to respond to this.
You seem to be out of touch I am afraid. Just look at what many O/S
distributions do. They adopt a new OpenSSL 0.9.Xy release from time to
time (for some initial "y") and back-port security fixes never changing
the letter. One can't actually tell from "openssl version" what version
one is running and which fixes have been applied.
Why am I back-porting patch-sets to 0.9.8i? Is that because there is no
demand for bugfix releases? There is indeed demand for real bugfix
releases, just that people have gotten used to doing it themselves,
but this is not very effective and is difficult to audit.
OpenSSL has not infrequent security advisories, and these are always fixed
in new feature releases not bugfix releases (which are misleadingly called
"patch" releases).
     HEADER_OPENSSLV_H
    /* Numeric release version identifier:
     * MNNFFPPS: major minor fix patch status
     * The status nibble has one of the values 0 for development, 1 to e for betas
     * 1 to 14, and f for release.  The patch level is exactly that.
     * For example:
     * 0.9.3-dev      0x00903000
     * 0.9.3-beta1    0x00903001
     * 0.9.3-beta2-dev 0x00903002
     * 0.9.3-beta2    0x00903002 (same as ...beta2-dev)
     * 0.9.3          0x0090300f
     * 0.9.3a         0x0090301f
     * 0.9.4          0x0090400f
     * 1.2.3z         0x102031af
     *
     * For continuity reasons (because 0.9.5 is already out, and is coded
     * 0x00905100), between 0.9.5 and 0.9.6 the coding of the patch level
     * part is slightly different, by setting the highest bit.  This means
     * that 0.9.5a looks like this: 0x0090581f.  At 0.9.6, we can start
     * with 0x0090600S...
     *
     * (Prior to 0.9.3-dev a different scheme was used: 0.9.2b is 0x0922.)
     * (Prior to 0.9.5a beta1, a different scheme was used: MMNNFFRBB for
     *  major minor fix final patch/beta)
     */
     OPENSSL_VERSION_NUMBER  0x0090809fL

@_date: 2009-07-01 12:49:14
@_author: Victor Duchovni 
@_subject: password safes for mac 
Spefically, Kerberos to *login* to the system. I use Kerberos on the
Mac all the time, but never to login, have not figured out how to
make it not get in the way of using the laptop when the KDC is not
Also, I roam between two Realms, office and non-office (used for IMAP and
SMTP submission) and neither makes sense as the primary platform login.
If I had a stationary desktop Mac at the office, that *would* use Kerberos
for login. Still would be in a tiny minority though...

@_date: 2009-06-06 23:10:30
@_author: Victor Duchovni 
@_subject: Factoring attack against RSA based on Pollard's Rho 
Several aspects of the RSA encryption algorithm can be attacked:
    attacks against the quality of the entropy pool used by the random
    number generator (RNG) that creates the p and q primes; ``side
    channel'' cryptanalysis attacks where key materials are divined from
    power rails, shared bus architectures, shared memory segments etc;
    exponential ``increase by two'' factoring attacks and
    more esoteric subexponential factoring attacks
    ----------------------------------------------
    such as the General Number Field Sieve; and, even the tried and true
    (and highly effective) Rubber Hose Cryptanalysis method.
What you call "more esoteric" is properly called "more sophisticated"
or "more effective". Your "attack" is not sub-exponential, and is of no
practical interest for RSA moduli of cryptographic strength.
    I have not yet compared the performance of this Reduction Sieve
    method to GNFS or any other subexponential factoring methods.
    Future testing of this factoring method will include deployment into
    an 80+ node VMware cluster at our datacenter and experimentation
    with on-demand cloud computing infrastructures such as Amazon?s EC2
    Elastic Compute Cloud.
Such performance comparisons are unnecessary, and would be a waste of
CPU time and money. GNFS is substantially faster than Pollard's rho for
RSA moduli of interest in cryptography.
There is nothing new here. First of all, if N mod 9 is a multiple of 3,
then N is divisible by 3, so those cases are of no interest, you would
factor N/3 instead.
For the other cases,
    * Either N mod 9 is a quadratic residue mod 9, in which case
      p*q == N mod 9 has 4 pairs of solutions,
      	(a,a), (b,b), (c,d), (e,f)
      where a and b are the two square roots of N mod 9, and c,d,e,f
      are the remaining units.
    * Or N mod 9 is not a quadratic residue mod 9, in which case
      p*q == N mod 9 has 3 pairs of solutions:
      	(a,b), (c,d), (e,f)
Now indeed if N = p*q for some pair of primes, and N is not a multiple
of 3, then p mod 9 is one of six possible values and q is the reciprocal
(mod 9) of that value.
Now, the "Pollard rho" algoritm is based on the birthday paradox for
differences between pairs of random values (x,y) mod N, being *divisible*
by a factor "p" of N, i.e. gcd(|x-y|,N) > 1, allowing the attack to run
in n^(1/4) time instead of n^(1/2) time for naive division trials.
It should be noted that knowing p mod 9 does not tell us much about (x-y)
mod 9. We need (x-y) to be random mod "p" and thus be zero mod "p" with
the expected birthday paradox probability. So there is no reason for
(x-y) to be any particular value mod 9, even multiples of 3 are fine,
nothing wrong with (x-y) being divisible by 3p.
For the birthday paradox we can't control the difference (x-y) mod 9 for
all pairs of a large set, because if (x_1 - x_2) = a mod 9 and (x_2 -
x_3) = b mod 9, then (x_1 - x_3) is a + b, mod 9, and the additively
closed subsets of z_9 are:
so you can't practically limit (x-y) mod 9 to a given unit and still use
the birthday paradox to make "rho" fast.
Speaking of birthday paradoxes and making "rho" fast: your code appears
to completely omit any use of the birthday paradox, and so would run in
n^(1/2) time instead of n^(1/4) time. If so it is far worse than the real
Pollard algorithm that you seem to not have studied with sufficient care.

@_date: 2009-06-07 14:17:52
@_author: Victor Duchovni 
@_subject: Factoring attack against RSA based on Pollard's Rho 
Well, if this were a correct implementation of Pollard's rho, with a
polynomial (not some unspecified PRNG) iterator coupled with a cycle
finder (not just the computation of the gcd of each term with N), then
the run time would be a non-interesting O(2^256).
Now the claimed improvements of 80% are for a misconceived Pollard rho,
which uses random trials gcd(PRNG, N), with a non-polynomial PRNG and
no cycle finder. This should have a run-time of O(2^512), and the author
claims an 80% cost reduction to ~O(2^509), but even this claim is dubious.

@_date: 2009-06-07 23:51:50
@_author: Victor Duchovni 
@_subject: Factoring attack against RSA based on Pollard's Rho 
To be blunt, I see no significance of any kind...
You have observed that unless N is divisible by 3, p and q are both also
not divisible by 3. This is not new, and does not speed up factorization
in any significant way (yes, you can skip candidate factors that are
divisible by 3, but this is not new, and only speeds up the really slow
naive algorithms like trial division).
You have also observed that:
this too is not new, and does not speed up factorization. One does not
search for both p and q simultaneously, finding the smaller of the two
is sufficient, and with q not in the picture the "p" candidates are not
constrained in any way by this relation: any prime < N has an inverse mod
m, provided p does not divide "m". So for every prime candidate ( that
is not a factor of "m") the equation N = p * q (mod m) has a solution.
Certainly C.F. Gauss was aware of interesting properties of this
type. In Section VI, Articles 329-334 of "Disquisitiones Arithmeticae",
he showed a sieve for prime factors of composite numbers based on
quadratic reciprocity.
This sieve was useful (no computers in ~1800) for numbers difficult to
factor by hand without effective short-cuts, 7-10 digit numbers with 3-5
digit prime factors. Gauss had tables of residues that made it possible
to quickly read off primes that simultaneously satisfied all the residue

@_date: 2009-05-01 00:10:53
@_author: Victor Duchovni 
@_subject: SHA-1 collisions now at 2^{52}? 
Perhaps, though the MAC in TLS cipher-suites needs just 2nd pre-image
resistance, not collision resistance. The collision resistance is more
relevant to X.509 authentication, and even there only when CA practices
are sub-optimal.
Yes, by all means, new hash functions, but lets not over-emphasize the
magnitude of the problem. This is not a SHA-1 pandemic...

@_date: 2009-05-11 17:13:11
@_author: Victor Duchovni 
@_subject: Warning! New cryptographic modes! 
Indeed. If the remote copy is a "backup", and the local file-system
supports snaphots, then it is far better to arrange for the remote
backup to always be a copy of a local snapshot, and to compute the rsync
"delta" between the local copy of the remote snapshot and a newer snapshot
locally, and then rsync the delta. Sure, snapshot file-systems are not
yet universal, but given disk size and file-system trends, I would base
encrypted remote backups on a foundation that assumed the existence of
local before/after images.
A cipher that produces largely identical cipher-text for largely identical
plaintext in the face of updates, inserts and deletes, is unlikely to
be particularly strong.
The CBC IV reset should not be too disasterous if the IV is an encrypted
block counter under a derived key. Drive encryption basically does the
same thing with 512 byte blocks. This fails to handle inserts/deletes
that are not multiples of the "chunk" size.

@_date: 2009-11-03 11:40:33
@_author: Victor Duchovni 
@_subject: Truncating SHA2 hashes vs shortening a MAC for ZFS Crypto 
No difference, SHA224 *is* a truncated SHA256 (with a different "random"
IV), so in both cases you are computing SHA256, and either truncating
once or twice.
Well, hashes have a birthday paradox, so a 128-bit hash is not
"stupendously" strong against collision attacks. One may be tempted
to trade off IV length for a longer hash, if collision resistance is
important. If you only need pre-image resistance, then you probably don't
need a longer hash (MD5 is still mostly holding up against pre-images).
Figure out whether you need collision resistance, or whether pre-image
resistance is sufficient.
Without question.
The MAC looks too short to me. You don't want MAC collisions, and 64
bits is too close for comfort IMHO.
This looks reasonable, if collision resistance is a concern. it is
a "balanced" design, because all the elements are 96-bit strong
(hash 96-bits of collision resistance).
On the other hand, if you only need (which is likely true, but you
need to examine the attack scenarios) pre-image resistance, then
you don't need to reduce the MAC strength to strengthen the hash, and
Option 3 is likely better.

@_date: 2009-11-09 20:08:23
@_author: Victor Duchovni 
@_subject: TLS break 
Not entirely unnoticed:
    For HTTPS, it has been observed that this is not entirely different
from existing CSRF attacks, but it should be noted that with the new
attack, checking "Referrer" headers is no longer effective, so anti-CSRF
defenses have to be more sophisticated (they *should* of course be more
sophisticated, but they rarely are, if they are present at all).
I am looking forward to analyses for other protocols.
There is almost certainly a problem for FTP (over TLS), where just
banning re-negotiation on the server is perhaps reasonable.

@_date: 2009-11-16 12:27:52
@_author: Victor Duchovni 
@_subject: TLS break 
The re-negotiation handshake does not *commit* both parties in the
new handshake to the previous cryptographic state of the TLS connection.
If the man in the middle is willing to encrypt/decrypt handshake packets
between a client new to the connection, and a server with which the
MITM completed an earlier handshake, the MITM can "transfer" an existing
session from himself to the client (victim), after injecting some initial
data into the connection.
The integrity and confidentiality properties of the origimal MITM<->server
connection only protect both parties if neither party is willing to
compromise those properties by proxying a 3rd party into the session.
The new ingredient here, is that the 3rd party can be a victim, who is
unaware of the proxying. The victim's handshake with the intended server
is proxied into an already established TLS session by the MITM who is
privy to the session state.
The solution is to *commit* the two parties to a re-negotiation handshake
to the previous handshake.

@_date: 2009-11-17 14:14:13
@_author: Victor Duchovni 
@_subject: Crypto dongles to secure online transactions 
Which is perhaps why it is not a good idea to embed an SSL engine in such
a device. Its external interface should be as simple as possible, which
suggests a message-signing device, rather than a device that participates
in complex, evolving, interactive protocols with remote network services.
The integration of the message signing device with a complete system
(computer with browser + device) should include most of the complex
and likely to change software. The device itself, is just a display +
encrypt then sign black-box for suitably simple (to unambiguously
display) messages, and the transmission of the signed message to the
appropriate destination can be left to the untrusted PC.
Such a device does however need to be able to suppor multiple mutually
distrusting verifiers, thus the destination public key is managed by
the untrusted PC + browser, only the device signing key is inside
the trust boundary. A user should be able to enroll the same device
with another "bank", ...
The proliferation multiple of SecurId tokens per user in B2B financial
services has led to a search for greater than "drawer-full of SecurId
cards (with PIN glued to the back of each)" usability. The alternatives
are not always very strong, but a would be more-secure solution needs
to keep usability in mind for the case when the user needs to conduct
secure transactions with multiple parties.

@_date: 2009-10-03 16:52:48
@_author: Victor Duchovni 
@_subject: Question about Shamir secret sharing scheme 
Lagrange interpolation works for polynomials over a field. The most
convenient *finite* fields in this context are the Z_p for prime p.
In this context it is also easy to make a uniform choice of a random
coefficient and to quantify the work-factor for a brute-force attack.
With rationals, everything is much messier. There is no good reason to
work over Q.
An algorithm is not the same an implementation. There was no Java back
then either, and people still somehow wrote working code in '79.

@_date: 2009-10-05 15:27:15
@_author: Victor Duchovni 
@_subject: Question about Shamir secret sharing scheme 
When using a finite subset of a totally ordered coefficient field
(such as Q) whose "+" operator is order preserving (a < b => a + c < b + c
for all c), we always see some outputs leaking more information
than others. This covers any subsets of Z as Z is a subset of Q.
A finite subset of such a field always has a minimal element.
For example, if all the coefficients happen to be equal to the least
possible coefficient, the person with share "1" easily concludes that
he has the least possible sum, and recovers the secret coefficients.
Using infinite subsets means unbounded storage requirements for the
coefficients, and necessarily a non-uniform distribution of coefficients,
with some polynomials more probable than others, so again data leakage.
Leaking no information is only possible in a finite field, of which the
Z_p are the "simplest", but (as pointed out upthread) Galois extensions
of Z_2 are typically more convenient computationally.

@_date: 2009-10-19 12:24:41
@_author: Victor Duchovni 
@_subject: Possibly questionable security decisions in DNS root management 
Yes, normal DNS traffic is not the issue.
The optimization is for DDoS conditions, especially amplification via
forged source IP DNS requests for ". IN NS?". The request is tiny,
and the response is multiple KB with DNSSEC.
Some (e.g. DJB, and I am inclined to take him seriously), are quite
concerned about amplification issues with DNSSEC. Packet size does matter.
Well, most of the hundreds of years don't really matter, modern number
theory starts with Gauss in ~1800, and the study of elliptic curves begins
in the same century (also Group theory, complex analysis, ...).  It is
not clear that the pedigree of RSA is much stronger than that for ECC.
Perhaps believed sufficiently secure, but insanely large for DNS over UDP.
Packet size does matter.
There is no incentive to use keys smaller than the top of the range. An
algorithm that cracks k-bit RSA keys, will crack all keys with n That way, there'd be no "sweet spots" at 1024 or 2048. There is no sweet spot. These sizes are believed to approximately match
80-bit, 112-bit, 128-bit ... sizes for symmetric keys (for RSA 1024,
2048, and 3072).
Why should one bother with a random size between 1024 and 2048, if
everyone supports 2048, and 2048-bit signatures are practical in the
context of the given protocol?

@_date: 2009-09-30 15:57:40
@_author: Victor Duchovni 
@_subject: Merry Certmas! CN=*\x00thoughtcrime.noisebridge.net 
If anyone is curious about the impact of this on the Postfix TLS engine
(March 2006, version 2.3.0 and later releases):
1. Postfix checks subject domains obtained from either subjectAltName or CN
   to ensure that the ASN.1 string object length is equal to the C string
   length. Certificates that fail this test are considered anonymous. These
   checks were added in the Spring of 2005 when the contributed TLS patch
   adopted in the 2.2 release was significantly extended and revised.
2. Postfix only matches *.example.com certificates against single-label
   sub-domains of example.com. Thus for example, the Postini wild-card
   certificate for:
   does not match (say Verisign's), MX records of the form:
   (Postfix also does not, for "secure-channel" destinations, trust DNS
    enough to let MX records influence the name expected in a peer
    certificate. So Postini's wildcard certificate is perhaps only useful
    with other sending systems).
   So a "*" certificate will never match any peer domain.
Bottom line, this issue does not impact the Postfix secure-channel TLS
use case.

@_date: 2010-04-20 21:40:35
@_author: Victor Duchovni 
@_subject: What's the state of the art in factorization? 
This conclusion is arrived at in a rather ad-hoc fashion. One can equally
easily reach opposite conclusions, since the majority of administrators
will not configure trust in static keys below the root, and in many
cases domains below the root will have longer keys, especially if the
root keys are not conservative.
Sure, cracking the root will not be the easiest attack for most,
but it really does need to be infeasible, as opposed to just
difficult. Otherwise, the root is very much an attractive target
for a well funded adversary. Even if in most cases it is easier to
social-engineer the domain registrar or deliver malware to the
desktop of the domain's system administrator.
EC definitely has practical merit. Unfortunately the patent issues around
protocols using EC public keys are murky.
Neither RSA nor EC come with complexity proofs.

@_date: 2010-10-08 18:20:23
@_author: Victor Duchovni 
@_subject: Disk encryption advice... 
Commercial products have a mode in which you can drop the requirement
for a key for one reboot. Presumbly the key is then erased. This may
a reasonable compromise. The devil is in the details.

@_date: 2010-09-04 09:07:37
@_author: Victor Duchovni 
@_subject: RSA question 
Instead of imagining, one could look-up the brute-force cost of RSA
vs. (ideal) symmetric algorithms, and discover that while brute forcing
an ideal symmetric algorithm doubles in cost for every additional key
bit, GNFS factoring cost is approximately proportional to
where "n" is the number of key bits.
So compared to 1k RSA bits, 16k RSA bits has a GNFS cost that is
(16*1.96)^(1/3) ~ 3.15 times higher. If 1k RSA bits is comparable to 80
symmetric bits, then 16k RSA bits is comparable to 80*3.15 or 252 bits.
The mystery of the NIST numbers goes away, and one learns that the
"blowing-up" of RSA key sizes relative to symmetric key sizes is less
than cubic, and so definitely not "exponential".
    \lim_{n \to \infty} \frac{\mathrm{RSA}(n)}{n^3} = 0
where RSA(n) is the number of RSA bits to match an n-bit symmetric key.

@_date: 2010-09-08 12:52:18
@_author: Victor Duchovni 
@_subject: Randomness, Quantum Mechanics - and Cryptography 
This glosses over the *fundamental* complexity of non-linear classical
dynamics. It is a leap to claim that the underlying determinism of a
classical dynamical system leads one to conclude that it is even in
principle "predictable", in the presence of chaos.
We should not short-change classical "chaos" which is an emergent property
of complex deterministic systems.
        ...
    Riddled Basins      The notion of determinism in classical dynamics has eroded since
    Poincar??'s work led to recognition that dynamical systems can exhibit
    chaos: small perturbations grow exponentially fast. Hence, physically
    ubiquitous measurement errors, noise, and computer roundoff strongly
    limit the time over which, given an initial condition, one can
    predict the detailed state of a chaotic system. Practically speaking,
    such systems are nondeterministic. Notwithstanding the quantitative
    uncertainty caused by perturbations, the system state is confined
    in phase space (on an "attractor") so at least its qualitative
    behavior is predictable. Another challenge to determinism arises
    when systems have competing attractors. With a boundary (possibly
    geometrically convoluted ) between sets of initial conditions tending
    to distinct attractors ("basins of attraction"), perturbations
    make it difficult to determine the fate of initial conditions near
    the boundary. Recently, mathematical mappings were found that are
    still worse: an attractor's entire basin is riddled with holes on
    arbitrarily fine scales. Here, perturbations globally render even
    qualitative outcomes uncertain; experiments lose reproducibility.

@_date: 2010-09-30 21:41:22
@_author: Victor Duchovni 
@_subject: 2048 bits, damn the electrons! [rt@openssl.org: [openssl.org 
============================== START ==============================
Presumably, this would only speed-up private-key operations. Public-key
operations (which is all one sees on the wire) should be the same whether
there are 2 or 4 unknown factors, one just uses the 2048-bit modulus.
Even the signing CA would not know how many primes were used to construct
the public key, provided software implementations supported 4-prime
private keys, I would naively expect the everyone else to not see any
Should we be confident that 4-prime RSA is stronger at 2048 bits than
2-prime is at 1024? At the very least, it is not stronger against ECM
(yes ECM is not effective at this factor size) and while GNFS is not
known to benefit from small factors, is this enough evidence that
4-prime 2048-bit keys are effective?
