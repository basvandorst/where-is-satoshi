
@_date: 2013-09-06 19:53:42
@_author: Marcus D. Leech 
@_subject: [Cryptography] Washington Post: Google racing to encrypt links 
One wonders why they weren't already using link encryption systems?

@_date: 2013-09-06 21:49:26
@_author: Marcus D. Leech 
@_subject: [Cryptography] In the face of "cooperative" end-points, 
It seems to me that while PFS is an excellent back-stop against NSA having/deriving a website RSA key, it does *nothing* to prevent the kind of
   "cooperative endpoint" scenario that I've seen discussed in other forums, prompted by the latest revelations about what NSA has been up to.
But if your fave website (gmail, your bank, etc) is disclosing the session-key(s) to the NSA, or has deliberately-weakened session-key negotiation in
   some way, then PFS doesn't help you.
I agree that if the scenario is "NSA has a database of RSA keys of 'popular sites'" then PFS helps tremendously.  But if the scenario goes    into the "cooperative endpoint" territory, then waving the PFS flag is perhaps like playing the violin on the deck of the Titantic.
Do we now strongly suspect that NSA have a flotilla of TWIRL (or similar) machines, so that active cooperation of websites isn't strictly    to derive their (weaker) RSA secret keys?

@_date: 2013-09-06 23:51:49
@_author: Marcus D. Leech 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
I find public-key cryptography to be full of "dirty little secrets".  Some of the notions inherent in public-key *infrastructure* are, on the face of them,
   preposterous.  Consider the notion of a certificate authority.  I am to trust some third party (the CA) that I've never met, and have not the    reason to trust, is able to make a "believable" assertion about the identity (and corresponding public-key binding), of some *other* party I've never
   met, and have no real reason to trust.  It always struck me as another instance of "there's no problem in CS that can't be solved by adding another
   layer of abstraction".   I think this is an instance of a general problem with digitally-signed documents of all kinds: confusion about exactly what they
   are--a signature on a document (like a certificate) says nothing about the *essential truth* of the statements contained within the document.
   When SlushySign issues a certificate for " there's a subtle distinction between "we believe this to be the appropriate binding
   between this public-key, and an entitity known as   and "this really is the binding between this pubic-key, and the entity you
   all know as I started thinking about the "essential truth" problem back when the whole TPM thing was popular, and proponents were talking as if the digital
   signature of a computer stating that it was "sane" was somehow the same is said computer actually being "sane".   Absent independent    there's no way to distinguish a strongly-signed "lie" from a strongly-signed "truth".   That isn't necessarily a problem that's confined to PK systems.
   Any digital-signature scheme has that problem.
The other thing that I find to be a "dirty little secret" in PK systems is revocation.  OCSP makes things, in some ways, "better" than CRLs, but I still
   find them to be a kind of "swept under the rug" problem when people are waxing enthusiastic about PK systems.
However, PK is the only pony we've managed to bring to this circus, so, we we "make do" with making the "dirty little secrets" as inoffensive as we can.

@_date: 2013-09-07 00:40:43
@_author: Marcus D. Leech 
@_subject: [Cryptography] Using Raspberry Pis 
I implemented a lightweight, tightly-focused (well, it started out that way), capabilities-like system for Android kernels last year. It was a monumental PITA
    largely due to interior kernel-side APIs changing so frequently across kernel versions.
We had mechanisms for binding "capabilities" to ELF binaries in a way that the kernel could verify.
The project failed, largely because it kept being dragged around by marketing so often, that we never got it really nicely robust in any given direction.
   "This week, it's a floor polish.  Next week, it's a turbine maintenance system."

@_date: 2013-09-07 23:16:22
@_author: Marcus D. Leech 
@_subject: [Cryptography] In the face of "cooperative" end-points, 
There's no question in my mind that PFS helps.  I have, in the past, been very in much favor of turning on PFS support in various protocols, when it has
   been available.  And I fully understand what the *purpose* of PFS is.
But it's not entirely clear to me that it will help enough in the scenarios under discussion.  If we assume that mostly what NSA are doing is acquiring a site
    RSA key (either through "donation" on the part of the site, or through factoring or other means), then yes, absolutely, PFS will be a significant roadblock.
    If, however, they're getting session-key material (perhaps through back-doored software, rather than explicit cooperation by the target website), the
    PFS does nothing to help us.  And indeed, that same class of compromised site could just as well be leaking plaintext.  Although leaking session
    keys is lower-profile.
I think all this amounts to a preamble for a call to think deeply, again, about end-to-end encryption.    I used OTR on certain chat sessions, for example,
   because the consequences of the "server in the middle" disclosing the contents of those conversations protected by OTR could have dire    for one of the parties involved.
Jeff Schiller pointed out a little while ago that the crypto-engineering community have largely failed to make end-to-end encryption easy to use.  There are
   reasons for that, some technical, some political, but it is absolutely true that end-to-end encryption, for those cases where "end to end" is the obvious
   and natural model, has not significantly materialized on the Internet.  Relatively speaking, a handful of crypto-nerds use end-to-end schemes for e-mail
   and chat clients, and so on, but the vast majority of the Internet user-space?  Not so much.

@_date: 2013-09-10 10:59:37
@_author: Marcus D. Leech 
@_subject: [Cryptography] Thoughts on hardware randomness sources 
I wonder what people's opinions are on things like the randomsound daemon that is available for Linux.
Similarly, any hardware with an ADC input can be used as a hardware random noise source, simply by cranking up the gain to suitable levels
   where the low-order bit is sampling thermal noise.
I currently play in the Software Defined Radio space, and there are these very-cheap SDR "dongles" that could easily be used as a hardware
   random noise source.
I think it would be hard for NSA to hack *all* hardware that includes an ADC and some gain in front of it, since there's a dizzying array of it
   available, cheaply, for PC hardware.
A related issue is getting sites to *use* enhanced random sources, even when "easy and cheap".

@_date: 2013-09-10 12:30:06
@_author: Marcus D. Leech 
@_subject: [Cryptography] Thoughts on hardware randomness sources 
I haven't actually looked at the code. Conceptually, anything with an ADC can produce thermal and or 1/f noise in the lowest-order bits.
   Even if it's somewhat biased (like having 60Hz hum embedded in it), with a suitable whitening function, it should produce
   high-quality entropy at rates of at least several hundred bits/second.
The idea is to have *diversity* of physical random sources, to make it difficult for "bad actors" to subvert said hardware.
It's fairly easy to "audit" these sources of random bits, since said bits won't have had any processing done to them in support of their random
  properties (unlike the Intel HW RNG).
But this is just one aspect of a much-larger problem of "trusting trust" (in the Thompson sense).

@_date: 2013-09-11 21:06:35
@_author: Marcus D. Leech 
@_subject: [Cryptography] Radioactive random numbers 
And this is the reason that I'd be in favour of "diversity" -- using sound cards, lava-lamps, etc, etc.  Sources that don't explicitly identify themselves
   as "the random number generator".
There's no way for a bad actor to cover "all the bases", and since these things are primarily used for things other than random-number sources,
   it may be hard to "break" them in ways that doesn't also break their primary purpose (although, if you're just mucking with the low-order
   "noise bits" of some arbitrarily-chosen digitization of a real-world source, it would be hard to tell the difference).

@_date: 2013-09-12 23:06:06
@_author: Marcus D. Leech 
@_subject: [Cryptography] Thoughts on hardware randomness sources 
There are a class of hyper-cheap USB audio dongles with very uncomplicated mixer models.  A small flotilla of those might get you some fault-tolerance.
   My main thought on such things relates to servers, where power consumption isn't really much of an issue.   Similarly these hyper-cheap    DVB-T dongles based on the RTL2832U can be made to run in "SDR" mode, and give you a basebanded sample stream of a wide variety of tuned
   RF frequencies--put a terminator on the input, chose your frequency, crank up the gain, and pull samples until you're bored....
This topic has suddenly become interesting to me in my work life, so I'm currently looking at the sensors API for Android.  I thought I had left Android work
   behind, but it's coming back to haunt me.  I was playing with the sensor outputs on a Nexus tablet today, and it has an impressive array of sensors.
   I suspect each of them could contribute a few bits/second of entropy without too much trouble.  More investigation is necessary.

@_date: 2013-09-13 23:51:04
@_author: Marcus D. Leech 
@_subject: [Cryptography] Thoughts on hardware randomness sources 
I was mostly contrasting with "mobile" systems, where power consumption is at an absolute premium.
The USB sound systems I'm thinking of consume 350mW while operating, and about 300uW when idle.   A couple or three of those on even
   a stripped-down server would contribute in only the smallest way to extra power consumption.  And the extra computational load?  When these
   servers things are running flat-out serving up secured connections?  I would guess the phrase "an inconsiderable trifle" would apply.

@_date: 2014-12-18 14:05:21
@_author: mleech@ripnet.com 
@_subject: [Cryptography] MPAA hasn't given up yet on breaking DNS 
The MPAA take themselves very, very, seriously. I work for a company
that has to provide services under MPAA "security" policies. It's
 absurd. I've worked on government clearance-required projects that
didn't have as much nonsense as the MPAA requires. The MPAA need to be taken down several notches. They are arrogant,
wrong-headed mouth-breathers who unfortunately pull a lot of the strings
in many parts of the world.  [3]

@_date: 2015-01-12 22:53:03
@_author: Marcus D. Leech 
@_subject: [Cryptography] The Crypto Pi 
Newer GPU cards for the X86 world have little TEEs tucked into the corner to do MPAAs bidding, in a sense.  It allows you to do "secure"    decrypt+decode right on the graphics card, with just enough obscure dancing-about to make it "difficult" to be attacked by the legit owner of
   the hardware--the decrypted stream never appears in the PC memory space, where it's easiest to siphon.
I worked on software related to that nonsense at my current company, but never actually laid my hands on the hardware.  The "industry" calls this
   "Media-Path Protection".
Anyway, I have no idea if ARM SOC graphics/GPU subsystems have adopted a similar model or not.  And many models of ARM have a TEE built in to
   them, which nearly-nobody takes any advantage of.
Also, with the introduction of the Odroid C1, the rPI has a very-serious competitor at the $35.00 price range.  I have a trio of them at the moment,
   and they're quite nice.

@_date: 2016-07-21 08:20:48
@_author: Marcus D. Leech 
@_subject: [Cryptography] Entropy of a diode 
Something useful to note is that the noise goes up considerably for higher-voltage Zeners, which is why almost all commercial noise sources
   for RF use Zeners rated at about 20V, and run them at 28V.
I use ordinary Zeners all the time (12V and higher) as RF noise sources.  They work well.
