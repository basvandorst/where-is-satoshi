
@_date: 2007-03-21 23:21:16
@_author: The Fungi 
@_subject: virtualization as a threat to RNG 
I will note that, on User-Mode Linux at least, a good approach seems
to be using the UML kernel option/driver to broker access to the host's
entropy via a faked hardware RNG. The down-side is that your host may
well need a boosted entropy source, if you have a lot of guests
using this feature. I'm unsure, however, how other virtualization
platforms handle this issue...

@_date: 2008-01-29 18:34:29
@_author: The Fungi 
@_subject: two-person login? 
Try searching for "secret splitting" instead.
I don't think it's security theater at all, as long as established
procedure backs up this implementation in a sane way. For example,
in my professional life, we use this technique for commiting changes
to high-priority systems. Procedure is that two security admins
(each with half of a cryptographic key) collaborate on updates. Sure
there's still the risk that one is nefarious and will socially
engineer a back door in while his/her counterpart is watching, but
that is not so much the risk we are attempting to thwart. The real
goal is to reinforce policy which requires collaboration between
administrators for major changes to these important systems.
Technology can't effectively *force* procedure (ingenious people
will always find a way around the better mousetrap), but it can help
remind them how they are expected to interact with systems.

@_date: 2008-01-29 21:52:57
@_author: The Fungi 
@_subject: two-person login? 
Certainly, but then neither does a one-person login (people can
always log into a system and then walk away to get a cup of coffee,
for that matter).
Of course, this is common sense. These are human problems which I do
not think can *ever* be solved through application of cryptography.
As I said, requiring two sets of credentials can act as a reminder
to work together, nothing more. There's no way that I know of to
force a person to pay attention, or for that matter do anything they
do not wish to do.
Agreed--it would be nonsense to dream otherwise. My only point was
to suggest that there are some circumstances in which a system like
this can be helpful/useful, which was one of the questions John
asked. It is simply necessary that when employing such a system, you
be aware of what problems it actually *can* solve, and what problems
it cannot. I have no doubt that some people attempt to employ these
sorts of solutions in ways which they are indeed inapplicable (or
put too much faith in the false sense of security it gives them),
possibly at the urging of their snake oil vendors. This is why
scrutiny of the *application* of a technology is at least as
important as scrutiny of the technology itself.

@_date: 2008-06-10 23:40:51
@_author: The Fungi 
@_subject: Ransomware 
Per the computerworld.com article:
   "Kaspersky has the public key in hand ? it is included in the
   Trojan's code ? but not the associated private key necessary to
   unlock the encrypted files."
This would seem to imply they already verified the public key was
constant in the trojan and didn't differ between machines (or that
I'm giving Kaspersky's team too much credit with my assumptions).

@_date: 2008-06-11 15:59:23
@_author: The Fungi 
@_subject: Ransomware 
Maybe I missed it in one of the articles, but was it stated that the
blackmailer did reveal a private key? Couldn't they simply request
the encrypted data and return the decrypted version?

@_date: 2008-03-16 14:26:56
@_author: The Fungi 
@_subject: cold boot attacks on disk encryption 
Saw an interesting free software example of this the other day (not
for Windows, of course) using loss of signal from a particular
bluetooth device (mobile phone, et cetera) to lock your machine or
run other designated commands:
   It also supports *unlocking* on approach, but that's a bad idea
unless they can start providing a client to run on the "token"
device (maybe using asymmetric key crypto to sign and verify a
challenge string instead of just looking for the device's BT

@_date: 2008-05-27 22:14:22
@_author: The Fungi 
@_subject: The perils of security tools 
This statement seems a little confused. If you 'man 4 random' on a
Linux system, you will see:
   The random number generator gathers environmental noise from
   device drivers and other sources into an entropy pool. The
   generator also keeps an estimate of the number of bits of noise
   in the entropy pool. From this entropy pool random numbers are
   created. When read, the /dev/random device will only return
   random bytes within the estimated number of bits of noise in the
   entropy pool. /dev/random should be suitable for uses that need
   very high quality randomness such as one-time pad or key
   generation. When the entropy pool is empty, reads from
   /dev/random will block until additional environmental noise is
   gathered.
So /dev/random on Linux isn't so much a PRNG seeded by entropy, as a
direct means of pulling (hashed) entropy directly out of the pool.
For each byte of /dev/random you read, the entropy pool is depleted
by the same amount. When there are no estimated bits of entropy
remaining, further reads are blocked until new entropy is available
(it doesn't just "slow down a lot"). Since /dev/random use depletes
the pool directly, it is imperative that wasteful reads of this
pseudo-device be avoided at all costs. By contrast, /dev/urandom
*is* a PRNG (optionally) seeded by available entropy. If its seed
value is known, output sequence can be determined until it gets
For the sake of this discussion, "the entropy pool" should be
defined as a pool of all entropy sources available to the system.
Thus, the idea of "an additional entropy pool" wouldn't make any
sense, though "additional sources of entropy feeding/mixed into the
entropy pool" might be what you were getting at (such as a hardware
RNG chip, webcam pointed at a few lava lamps, microphone aimed at
the nearest freeway, et cetera).
Well, /dev/urandom (on Linux) represents a PRNG while /dev/random
does not. I suppose if you read from /dev/urandom byte-at-a-time and
reseed it with a byte from /dev/random between each read, it will
essentially be (deterministically because you know how to predict
the mapping between seed and sequence number n) a duplicate of

@_date: 2008-05-28 14:15:24
@_author: The Fungi 
@_subject: The perils of security tools 
Oh, agreed wholeheartedly. I simply meant that *wasteful*
(gratuitous) reads of /dev/random should be avoided. Justifiable,
conservative reads of /dev/random are, of course, why it exists in
the first place!
And fopen/fread is definitely a bad idea in this case for the
reasons you point out. In general, anything which prefetches
potentially excess data in a read from /dev/random is destructive to
the entropy pool.

@_date: 2009-01-27 18:46:21
@_author: The Fungi 
@_subject: What EV certs are good for 
I often use this (though there's probably an easier way)...
echo|openssl s_client -connect  x509 -text
Quick and dirty, but gets the job done.

@_date: 2009-11-16 17:30:44
@_author: Jeremy Stanley 
@_subject: Crypto dongles to secure online transactions 
But even then, poor planning for things like key size (a la the
recent Texas Instruments signing key brute-forcing) are going to be
an issue.

@_date: 2009-11-17 14:18:03
@_author: Jeremy Stanley 
@_subject: Crypto dongles to secure online transactions 
I might have, perhaps, phrased it a little better. Regardless of
initial planning, TI continued selling devices relying on this
particular code signing implementation well past what the original
design engineers hopefully expected would be its maximum lifespan.
If this is true, then it makes an interesting case study for the
topic of this thread...
Not such a low-end product, when compared to the bank transaction
authenticating crypto we're discussing (I had a TI-83 back when they
first came out, and it was far from cheap on a starving student
budget). Assume what TI had built was one of these banking crypto
devices... they implemented a code signing mechanism so it could be
updated in a secure fashion, since they didn't want it to be so
disposable... the best code signing mechanism the processor could
handle... in 13 years a hobbyist with a few months and basically no
budget is able to trojan these devices.
This speaks to an inherent lifespan for "low-end" devices anyway,
since a time will come when they need better code signing than their
processors can handle. If the hobbyist can do it 13 years later for
a relatively low-value target (programmable calculators), how about
something which has a lot more potential for profit? A decade ago I
was working on (relatively) low-budget beowulf distributed compute
clusters which easily rivalled the speed of the machine used to
crack TI's code signing keys. This was well within the budget of a
criminal organization--probably a tiny fraction of what they could
have made selling the code signing keys for widely-deployed bank
transaction authenticator devices.
Maybe calculators are a bad example, but if 3-4 years is all it
takes to put the code signing key for an inexpensive device in the
hands of criminals, then is it worth the risk (or even expense) to
make dedicated banking crypto hardware updateable?

@_date: 2010-08-13 20:21:33
@_author: The Fungi 
@_subject: Has there been a change in US banking regulations recently? 
In the past month, we've had several customers at work suddenly
insist that we make modifications to their firewalls and/or load
balancers to redirect *all* incoming HTTP traffic to HTTPS (which of
course isn't always entirely sane to do on proxying devices, but
they apparently don't trust their server admins to maintain an HTTP
redirect). Most of them cited requirements from their PCI-DSS
auditors. One apparently was outright told that their redirects were
"a security problem" because they presented an open socket on port
80, and they needed to be refusing all HTTP to their servers at the
firewall. I think we gave them sufficient wording to convince their
auditor that blocking access to the redirect itself wasn't going to
do anyone any good.

@_date: 2013-09-01 01:16:50
@_author: Jeremy Stanley 
@_subject: [Cryptography] Thoughts about keys 
At free software conferences, where there is heavy community
penetration for OpenPGP already, it is common for many of us to
bring business cards (or even just slips of paper) with our name,
E-mail address and 160-bit key fingerprint. Useful not only for key
signing (when accompanied by photo identification), but also simply
allows someone to retrieve your key from a public keyserver and
confirm the fingerprint matches the one you handed them.

@_date: 2013-12-26 21:44:20
@_author: Jeremy Stanley 
@_subject: [Cryptography] code review (was: RSA is dead.) 
The OpenStack project provides a counterexample here: a coalition of
more than a hundred different (but related) individual software
projects whose community has evolved a "code review culture" such
that no changes are merged without review by multiple developers
experienced in those projects.
    And yes, it's expensive (a majority of contributors and reviewers
are employed full-time by various member companies who donate labor
and other resources for those projects). Similar code review
patterns are commonplace for WikiMedia and Google free software
projects as well, and are rapidly being adopted by other large
communities who want a workflow similar to that of the Linux kernel
but with the benefit of a more open and decentralized approval

@_date: 2013-10-11 20:39:16
@_author: Jeremy Stanley 
@_subject: [Cryptography] PGP Key Signing parties 
Within more active pockets of the global free software community
(where OpenPGP signatures are used to authenticate release
artifacts, security advisories, election ballots, access controls
and so on) key signing parties are an extremely common occurrence...
I'd say much more so now than a decade ago, as the community has
grown continually and developed an increasing need to be able to
recognize one another's output in a verifiable manner,
asynchronously, distributed over great distances and across
loosely-related subcommunities/projects.

@_date: 2013-09-04 03:08:09
@_author: Jeremy Stanley 
@_subject: [Cryptography] Thoughts about keys 
Perry was recounting a specific anecdote of meeting others at
conferences (well, in bars after hours at conferences) and needing
to exchange contact info spontaneously in person with an expectation
of being able to securely communicate later. His implication was
that this is an unsolved problem, and I was merely pointing out that
an already-existing culture of non-trivial size has been doing
precisely this on a regular basis for years. Perhaps the academic
conference and free software conference worlds are so far apart as
to make this a poor comparison after all, but it seemed a relevant
data point.
The "average" user is going to have bigger problems... glancing at a
sequence of 40 hex digits to compare them to the fingerprint GnuPG
gives them for your public key they just pulled from a keyserver is
merely the tip of a much bigger key vetting and signing iceberg, but
the in-person introduction piece is not that hard with a little bit
of preparation (I've gotten in the habit of carrying key fingerprint
cards in my wallet everywhere I go).

@_date: 2013-09-05 03:24:08
@_author: Jeremy Stanley 
@_subject: [Cryptography] Thoughts about keys 
You could do the same with OpenPGP keys too (look for my key at any
modern keyserver, I'm fungi at yuggoth.org there) but that misses the
possibility that in the future someone might upload a trojan key
claiming to be me and use it to sign and send them a spoofed
nefarious message, source code release tarball, git tag, whatever.
Handing them a copy of the key fingerprint gives them a means to
confirm the key they just pulled from the server is really the same
person who showed them a passport at the conference the month
If there's no way for anyone to impersonate examplenick at forum
example.net then, sure, maybe simpler... but that forum is probably
not a distributed, highly available, cryptographically-verifiable
pool of key distribution API servers either.

@_date: 2013-09-05 23:32:33
@_author: Jeremy Stanley 
@_subject: [Cryptography] Thoughts about keys 
Right, so I guess we're talking about different sets of risk
factors. In the global free software community the proliferation of
OpenPGP is more for the benefit of authenticating signed
announcements and software release artifacts, less about privacy and
anonymity (though some of that does come into play when
communicating embargoed security vulnerability information).

@_date: 2014-10-06 14:01:06
@_author: Jeremy Stanley 
@_subject: [Cryptography] 1023 nails in the coffin of 1024 RSA... 
There's now a blog post[1] and English translation[2] which have
been making the rounds...
[1] [2]

@_date: 2014-10-06 22:24:29
@_author: Jeremy Stanley 
@_subject: [Cryptography] 1023 nails in the coffin of 1024 RSA... 
2^512/ln(2^512) is still ~2^504 primes which would need to be found
and stored. That's... a _lot_ of "hardware."

@_date: 2015-08-03 12:27:00
@_author: Jeremy Stanley 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
I think the term you're looking for is "benevolent dictator" (at
least that's how it's typically phrased in free software
Agreed, at least this is the mechanism I've seen work out most
I'm involved in collaborative development with a free software
community who embrace (perhaps sometimes even enshrine)
consensus/distributed decision-making. Often this works to our
benefit, but there are somewhat frequent cases where a particular
group fails to reach any clear agreement and for this we have
leaders elected by the community to make those decisions (team leads
within subgroups, and a separate body of technical leaders within
the larger collective community).
It doesn't _always_ help because there can be a pressure within the
collective for a leader to not alienate any one set of opinion
holders, and so a default non-decision outcome can still happen. In
those cases, "start implementing all relevant proposals and see
which turns out to be better/easier" is a useful fall-back position.
This has the benefit that the race to a solution will most often be
won by those with either the simpler solution or the most
development support (either of which are great proxies for
identifying which choice was actually the superior one).
This thread has reminded me that I should make groups aware on
controversial decisions when they appear to cross the line into that
realm where the decision-making process has become more important
than the decision being made.

@_date: 2015-07-11 00:42:44
@_author: Jeremy Stanley 
@_subject: [Cryptography] Apple requires 2048 bits for email DH, 
Apple's not alone. I became aware of the same thing this week with
some Outlook users no longer able to connect to a Courier IMAP
server I help maintain. Seems it began with the May monthly updates
to Windows 8.1 but will likely spread to older supported versions of
Windows soonish. The solution, unsurprisingly, was to adjust the
mkdhparams defaults and regenerate dhparams.pem on the mailserver.
There's some indication that Thunderbird 38.0.1 has done this too.
In the case of MS and Moz minimums were apparently only bumped to
1024 not 2048 so carnage may not be quite so widespread for them;
pretty sure this is just all the vendors reacting to Logjam.

@_date: 2015-03-11 20:43:33
@_author: Jeremy Stanley 
@_subject: [Cryptography] Digital Certificate Forensics: Clinton Email 
There is a statue of Gen. Winifield Scott a.k.a. "Old Fuss and
Feathers" in the Georgetown district of Washington, DC. It's on 16th
St. NE by the Australian Embassy. There are currently a couple of
cafes bordering Scott Circle Park there, and the closest to his
statue is currently "Nage" on the corner of 16th St. and Rhode
Island Ave.
No idea if that's it, but it's what comes to mind.

@_date: 2015-03-28 13:55:45
@_author: Jeremy Stanley 
@_subject: [Cryptography] Drop Zone: P2P E-commerce paper 
I find myself wondering exactly what sort of person is perfectly
happy to ignore commerce laws, but still cares what the FCC thinks?
After all, Dominique and Blank Reg were able to broadcast Big Time
Television from a bus. Hard Harry transmitted his pirate radio
station from a Jeep. It can't be that hard to evade triangulation
for brief AX.25 packet radio exchanges.

@_date: 2016-12-05 15:14:17
@_author: Jeremy Stanley 
@_subject: [Cryptography] OpenSSL and random 
Keep in mind that "time" may also be a poor choice as many of these
systems boot without a persistent state and so all start with their
clocks reading the same value (e.g., 1970-01-01T00:00:00Z). Often
they won't have a proper current time until well into the boot
process (or even later still). Best case you'll be feeding in the
relative variability of timing for the boot process up to the point
where the clock gets sampled. Depending on sample precision and the
unpredictability its component hardware enumeration process this
could still be plenty, I suppose, but that does of course support
your position that different platforms will require different sets
of inputs for a viable solution.

@_date: 2016-05-12 18:30:07
@_author: Jeremy Stanley 
@_subject: [Cryptography] 2nd Amendment Case for the Right to Bear Crypto 
It can be illegal in parts of the USA depending on your criminal
conviction history. Also there's still H.R. 378[*] (Responsible Body
Armor Possession Act) up for consideration, though it's not been
visibly active for over a year and will hopefully die in committee.
[*]

@_date: 2016-11-14 18:41:15
@_author: Jeremy Stanley 
@_subject: [Cryptography] October 28th is now National Cryptography Day 
I can't tell if this was meant to be sarcastic, or legitimately
ignoring that one half the globe simultaneously observes opposite
seasons from the other half. As it made me chuckle, I'm inclined to
assume the former. ;)

@_date: 2016-11-30 20:23:31
@_author: Jeremy Stanley 
@_subject: [Cryptography] Is Ron right on randomness 
Looks like libressl-portable already started doing that a couple
years ago:
    Similar effort for OpenSSL seems to be under discussion:

@_date: 2017-12-20 18:31:24
@_author: Jeremy Stanley 
@_subject: [Cryptography] Rubber-hose resistance? 
Also, when crossing some borders, your devices may leave your person
and be out of visual range for extended periods of time before you
get them back. In such circumstances do you consider them probably
compromised (perhaps even at the firmware or hardware level) and
quarantine or dispose of them accordingly?

@_date: 2017-12-21 18:53:50
@_author: Jeremy Stanley 
@_subject: [Cryptography] Rubber-hose resistance? 
That's fairly similar to how I've been handling things. When I
travel domestically I do so with homebrewed netbook-like devices
cobbled together from SBCs with commodity tablet-sized display
panels and USB mini-keyboards obtained from inexpensive tablet
cases. I'm a little uneasy trying to cross international borders
with homemade computers though, so I've resorted to using very cheap
"burner" mini-laptops that I won't be too upset if I have to ditch
(I tend to keep one in checked luggage and one in my carry-on in
case that happens). Most recently I've been using the Fusion5
lapbooks which run around us$160 and can run a fairly unmolested
Debian install with a mainline Linux kernel, but Chromebooks are
another popular choice for this among my colleagues who take similar
I've also invested in bulk packs of tamper-evident evidence bags
large enough to put my devices in, and rolls of tamper-evident
serial number labels to cover all ports on them. These are obviously
not foolproof, but they increase the amount of time an adversary
needs to muck with my hardware and still go undetected (I bring a
stack of bags, so that when I go out to dinner I can put my devices
in a fresh bag before putting that in the not-terribly-trustworthy
safe in my hotel room).
And as mentioned elsewhere in the thread, I too have determined that
a good, strong memorized password/passphrase is a safer choice to
bring across borders than an SSH key when it comes to having a way
to bootstrap my actual keys once I reach my destination. It's about
the only time I SSH with a password (been meaning to set up a second
sshd specifically for this with some sort of port-knocking scheme so
it's not easily discoverable by all the brute-forcing portscanners
out there, and then I can leave my normal sshd set for key-only
auth). I also tend to make short-lived keys I'll use while
travelling and yank their access as soon as I get home, just for
good hygiene.
Of course, travel into mainland China adds an extra layer of fun
here, but for the moment it's still possible to use a wireless modem
or phone tether with a SIM for a non-Chinese mobile provider on an
international roaming plan to get around the GFW block for SSH and
VPN protocols.

@_date: 2017-12-21 22:32:24
@_author: Jeremy Stanley 
@_subject: [Cryptography] Rubber-hose resistance? 
So far it's gone through the X-ray conveyor zipped up (I have it
strapped into a modified fabric CD organizer for convenience) at
least a couple dozen times and not raised any red flags. I expect it
looks pretty much like a typical tablet or netbook on profile.

@_date: 2017-03-03 19:56:04
@_author: Jeremy Stanley 
@_subject: [Cryptography] TPM and SHA-1 
It's a good question. The upstream OpenStack Administrator Guide
covers that feature at
which goes into a fair amount of detail, though the service
documentation at
currently lists the TrustedFilter as "experimental" so YMMV (the
developer community is typically pretty conservative about not
calling a feature production-ready until they're very comfortable
it's working and stable). There was also some discussion of
shortcomings and possible deprecation a couple years ago which can
be found at
and  if you're
I don't think the periodic OpenStack User Surveys ask any questions
about deployments using trusted compute pools, but I'll suggest it.
I do at least see Red Hat's documentation mentioning the possibility
under "Host Aggregates and Availability Zones" at
so maybe some of their customers are doing it. There's also an Intel
glossy at
with some more markety diagrams/bullets about how it works.

@_date: 2018-08-09 18:02:16
@_author: Jeremy Stanley 
@_subject: [Cryptography] PGP -- Can someone help me understand something? 
The terms you're looking for are "asymmetric encryption" and
"public-key cryptography."
This has less to do with PGP itself, and more to do with the various
asymmetric cryptographic algorithms on which it relies. The answer
as to "what makes them hard to solve?" differs depending on which
algorithms is in use, but a good example to take is RSA. The
Wikipedia article on RSA provides a fairly straightforward
    Your hypothesis that this should be solvable with basic algebraic
reduction assumes there is an algebraic solution to factorization
(in the case of RSA anyway). There are plenty of equations for which
algebra or any other known techniques are simply not effective at
finding a solution. As of now at least, there is no publicly-known
method for factoring the product of large and well-chosen prime
numbers which can be accomplished in polynomial time (that is to
say, particularly faster than just trying every possible value until
one works) even with the aid of current computing technology. The
problem of recovering the private key when you only know the public
key and the plaintext message is basically the same as the problem
of recovering the plaintext message when you know only the public
key and the encrypted message.
In a more general sense, not speaking of just RSA, the algorithms
used by PGP are chosen for their lack of a known solution which can
be attempted in a useful amount of time when employing sufficiently
strong keys (where "useful" is generally defined as something less
than the eventual heat death of the Universe).

@_date: 2018-08-30 22:28:32
@_author: Jeremy Stanley 
@_subject: [Cryptography] WireGuard 
I don't know about you, but I publish SSHFP RRs in DNS for my
systems, so my users (as long as they have working DNSSec) don't
_need_ to call me up. Sometimes there are ways to make these sorts
of models work fine.

@_date: 2018-01-06 14:37:56
@_author: Jeremy Stanley 
@_subject: [Cryptography] Crypto for optimistic transactions ? 
Also amusing (to me at any rate) is that OpenBSD preemptively
implemented basically the same mitigations a decade ago, in the wake
of the 2006 Intel Core 2 errata. This rant from Theo is remarkably
    Now fast-forward to modernity:

@_date: 2018-06-19 17:08:12
@_author: Jeremy Stanley 
@_subject: [Cryptography] How to make rowhammer less likely 
Funny you should use that as an example. Over the years I was
responsible for a number of facilities whose fire marshals for their
respective jurisdictions required quite a lot of our electronic door
locks to fail open in the event of power loss or system failure (and
especially in the event of a detected fire) so as to provide safe
egress from the premises. Granted we selected latch mechanisms which
only allowed one-way traffic toward the exits, but security was
diminished as we were no longer able to track who exited and when
under such circumstances (except via surveillance systems, assuming
they remained operational).

@_date: 2018-03-31 23:53:38
@_author: Jeremy Stanley 
@_subject: [Cryptography] Password entry protocols 
When booted under a default-configured Linux kernel using a QWERTY
or AZERTY keyboard, Alt+SysRq+K is the "secure access key." In
actuality it implements this by killing any processes associated
with the current virtual console. Granted, the relevant section[*]
of the Linux kernel user's and administrator's guide provides the
following disclaimer:
    "In its true form it is not a true SAK like the one in a c2
    compliant system, and it should not be mistaken as such."
[*]

@_date: 2018-11-10 01:09:44
@_author: Jeremy Stanley 
@_subject: [Cryptography] Seeking recommendations for a dedicated 
If the free/libre open source software movement is important to you
and you'd rather not financially support the likes of Amazon, Google
or Microsoft,  (a Canadian provider though they
do also have a presence in a USA facility now) runs a very
up-to-date deployment of OpenStack and has amazingly responsive and
knowledgeable customer service. Not only do they run their service
on free software, but they participate heavily in the community
developing it and contribute valuable hosting resources to a lot of
other free software communities too. I'm a very happy customer.

@_date: 2018-11-23 21:16:16
@_author: Jeremy Stanley 
@_subject: [Cryptography] Buffer Overflows & Spectre 
This has been available for years. I work on one such project in use
by a number of public "cloud" service providers. The current
challenge, to this day, is getting or designing your own server
hardware which can't be persistently backdoored by hostile users.
Most commodity servers rely on malleable code in firmware to
implement their firmware reflashing functionality. All it takes is a
crafty backdoored firmware payload uploaded by the customer (or more
likely someone who compromised them) which emulates the normal
features necessary to reflash various system firmwares while still
preserving itself in the process. For this particular business model
to operate securely, you need systems with no ability to directly
alter their own firmware but then some (preferably automated)
external solution for reflashing them with new firmware payloads
when it's time to upgrade.

@_date: 2019-12-11 16:13:26
@_author: Jeremy Stanley 
@_subject: [Cryptography] FBI: Don't trust IoT devices 
For wired LANs, the most common solution is referred to as "port
isolation" or "Private VLAN" but Cisco has a patent stranglehold on
the concept laid out in IETF RFC 5517 and has litigated against
perceived infringers who don't bow to their demands for license
For IEEE 802.11 wireless, many WAPs implement something called
"wireless client isolation" or "AP isolation" to prevent client
systems from communicating with anything besides the Internet
So the options are there, but I agree, if I hadn't spent years as a
network engineer I probably wouldn't begin to know what to look for.

@_date: 2019-12-15 13:58:12
@_author: Jeremy Stanley 
@_subject: [Cryptography] FBI: Don't trust IoT devices 
Are you talking about between your client and your gateway? Why
bother with a VPN, you can just do IPSec in transport mode instead,
no need for tunnel mode in such cases.
Well, the specific technologies I described are more about securing
things at the Ethernet frame switching layer (not at the IP packet
routing layer), disallowing flows between clients so that they can
only send frames to and receive frames from the port where your
gateway (or other shared devices you want them to reach) is
connected but cannot reach or "see" each other at all. And it's not
*just* Cisco routers which do these sorts of things, for example
I've seen discussions about using filtering rules in ebtables on
OpenWRT to similar ends. The implementations are not standardized
mainly due to the situation with RFC 5517, but as PHB pointed out,
US6741592B1 is expiring early next year so maybe this will improve.
Keep in mind that a compromised client device running a packet
sniffer to eavesdrop on traffic from other client devices would need
to overcome basic switching optimizations on any modern (that is
produced in the past two decades) switched network to begin with,
for example by spoofing the victim's address on frames sourced from
the attacker's interface or flooding the switch with frames from
lots of bogus spoofed addresses so as to overload its bridge table
and cause it to fall back to forwarding all frames to all ports. To
mitigate this, such isolation schemes are usually coupled with "port
security" measures which tell the switch to shut down a port as soon
as it sees frames from a different hardware address than the one
which was previously communicating through it (also good for
blocking rogue bridges). Switching gear which supports port
isolation invariably includes port security features as well,
because you can't really trust isolation unless you have control
over what you're isolating. And for 802.11 wireless, this isn't
really even needed as far as I'm aware, because client-to-client
communication requires either being forwarded through the AP or
explicitly creating a separate ad hoc network between them.
I can't tell if your concern is strictly with rogue clients (such as
IoT devices) connected to your network, or with the forwarding
infrastructure for your network. Ethernet layer isolation
technologies are useful for preventing the problems you describe
with the former, but honestly if the concern is for the latter it's
already game over. Unless you move to end-to-end encryption between
sensitive devices and whatever they communicate with on the
Internet, at some point you have to trust a forwarding device,
whether it's your switching and routing gear or your VPN gateway,
and in many cases they may all be the same device. Adding more
network equipment to deal with a lack of trust in your network
equipment is also a questionable approach, because with more devices
comes more complexity and an increased risk you'll introduce more
vectors for attack.

@_date: 2019-06-21 13:57:04
@_author: Jeremy Stanley 
@_subject: [Cryptography] Shamir's secret sharing 
This is one way open source "cloud" infrastructure is superior. The
major proprietary providers have financial incentives to concentrate
operations so getting geopolitical diversity with any one provider
is challenging, and writing your software or deploying your own
abstraction layer so that it works consistently across multiple
proprietary providers is also daunting. If you choose a single
infrastructure API provided as a service by a variety of independent
providers, you can distribute your application, data, key shares,
whatever, across not only different geographic regions and different
legal jurisdictions, but also across different providers so that the
loss of any one service provider is no longer a catastrophic
failure. As an example, the OpenStack community says there are
providers offering its software as a service in >20 countries:
    I distribute my personal systems between providers in Australia,
Canada and Poland. Professionally I help maintain one application
which distributes its work across providers in Canada, China,
France, Japan, Sweden, the UK and the USA who all provide the same
basic infrastructure APIs.

@_date: 2019-05-09 19:20:00
@_author: Jeremy Stanley 
@_subject: [Cryptography] peering through NAT 
You're probably looking for the IGD (Internet Gateway Device)
protocol commonly implemented via UPnP (ISO/IEC 29341 a.k.a.
Universal Plug-n-Play) in popular consumer routing devices for well
over a decade.
Couldn't tell ya, never touched the stuff.

@_date: 2019-09-12 01:50:19
@_author: Jeremy Stanley 
@_subject: [Cryptography] Need some help regaining access to a server 
This is short some critical bits of context: is it a real piece of
hardware to which you have local physical access? If rebooted does
it require any additional passwords/keys to alter BIOS settings or
boot order, to alter bootloader configuration, or to decrypt the
root filesystem?
If you have console access and can alter the kernel command line or
boot from removeable media and there's no disk/fs encryption to
overcome then there are a myriad of ways to get direct root control
of the system, reset passwords, replace or add keys, and so on
without needing to exploit any privilege escalation vulnerabilities.

@_date: 2020-04-08 23:45:37
@_author: Jeremy Stanley 
@_subject: [Cryptography] Jitsi versus Zoom 
Well, and it uses standards-based protocols, and you get all the
source code, and you have the right to modify and redistribute it,
and the ability to run it without having to pay licensing fees to
the authors, and... basically all the benefits of relying on
free/libre open source software instead of some proprietary platform
which you'll at best be able to audit under a nasty NDA and won't be
able to legally modify at all if you need (and I say this as someone
who's in the process of helping stand up a slightly modified version
of Jitsi Meet for an open community who's wary of Zoom and similar
closed offerings, the patch we're applying is for integration with
another open collaboration tool we use and we're planning to work
with the Jitsi maintainers to get that incorporated upstream... try
doing that with Zoom?).

@_date: 2020-04-09 06:11:16
@_author: Jeremy Stanley 
@_subject: [Cryptography] Jitsi versus Zoom 
[...snip remaining rant about how there are bugs in software...]
So the fact that everyone has access to the source code for software
with bugs makes it inherently worse than software with bugs only the
authors have the source code for? Got it. Thanks for the insightful
life lesson.
Your premise seems to be that because some open source software has
flaws and some proprietary software is well-looked after, the former
is inferior to the latter. It's a specious argument at best. Over
the years I've seen plenty of commercial products with glaring
security holes the owners refused to even acknowledge much less fix,
or who would sweep problems under the rug when they did eventually
start to get exploited, or who would even threaten legal action
against anyone who tried to bring them up in public venues. Yes,
that's the inherent "security" of proprietary software and free
market forces at work.
And I don't have time for software I'm not allowed to modify. Each
to their own.
Especially when they realize they can take the same money and, you
know, not actually bother to keep the software secure but still
claim they do (and before you say third-party audit, the same goes
for so-called "reputable" firms who happily look the other way as
long as a client pays their tab). That's money in the bank, that is.
In all seriousness though, your use cases are not my use cases and
maybe they're also not Marc's use cases. You may value having some
company you can pay to assume liability, but I find little value in
that myself. I don't know if Marc, who initially asked the question,
agrees with either of us for that matter, but it's good to point out
the benefits of each option and for at least *some* people (me for
one), free/libre open source software *is* a benefit. Your mileage
may vary.

@_date: 2020-04-10 01:08:47
@_author: Jeremy Stanley 
@_subject: [Cryptography] Jitsi versus Zoom 
And my point did have to do with source availability, in that I
wanted to run my own instance of Jitsi Meet and needed to make some
modifications to suit my particular use case. Zoom does let people
(for a price) run standalone instances of their server too, but it
doesn't seem they're generous enough to give out the source code and
tools to modify and rebuild it. The reason I mentioned "auditing" at
all was to say that (see quote above for context) the *most* they'd
probably let you do is audit (that is, look at) the Zoom source code
under an NDA but would almost certainly not license you to modify it
and distribute your modifications to others who might want to do the
same. I didn't originally mention a desire to audit the source code
for Jitsi (in fact I'm not really that interested in "auditing" much
of anything unless it's to work out how to fix a bug I've
encountered in it or make some other improvement), you jumped to
that conclusion on your own.
Anyway, I think we've probably both made our points, and each
started to come across as fanatics of one flavor or another by now,
so we should just agree to disagree and move on.

@_date: 2020-12-30 02:22:25
@_author: Jeremy Stanley 
@_subject: [Cryptography] Bitcoin is a disaster. 
Which Internet was that? Surely not the one which was started to
more quickly and reliably communicate between USA military
installations and defense-funded research teams at various

@_date: 2020-07-09 22:52:56
@_author: Jeremy Stanley 
@_subject: [Cryptography] "Home router warning: They're riddled with known 
Or spend a little more and get an open hardware SBC which doesn't (I
use the PCEngines APU1D4 which has open source BIOS/firmware and
drivers for all its hardware are mainline in not only Linux kernels
but also *BSDs, I happily run latest OpenBSD on mine).
At a minimum. And if you can set up hardware address filtering or
port/client isolation on your switches and WAPs so that each device
can only communicate through the gateway, all the better. If you
just stick your untrusted devices on a LAN together, then they can
still be leveraged to compromise each other after all. You don't
want whoever's pwn3d the company that provides your "smart
thermostat" to hack your television's voice activation feature and
start listening to all your conversations.

@_date: 2020-07-11 14:05:41
@_author: Jeremy Stanley 
@_subject: [Cryptography] "Home router warning: They're riddled with known 
I don't know how many network interfaces you can cram into a Pi and
still get decent performance, but there are plenty of relatively
inexpensive SBCs out there designed for network applications which
ship with 3+ Ethernet interfaces on-board. You can get radio modules
for them which are well-supported by Linux and *BSDs, and some also
have switch modules available if you need more interfaces than can
reasonably be handled across the system bus.
I'm not sure why that sounds simple, unless you're expecting to have
an operating system on the gateway which can't isolate traffic
between interfaces.
For me that's a few lines of configuration for dhcpcd, and enabling
rad on the inside interfaces. Then dhcpcd takes care of requesting
them so rad can announce them on each of my LANs (I wish they'd get
with the times and let me request a single /56 to carve up, but
honestly at this point I'm just thrilled this ISP has working
DHCP6-PD at all).
With unbound listening as a recursive resolver on the router's
internal interfaces, I can set it in dhcpd and also still override
specific hostnames associated with any systems for which I want to
give static leases (even though it's not authoritative for those
Any general-purpose *nix should do if you choose an appropriate
device. If you're looking for one with a fancy Web interface
specific to this purpose, then maybe PfSense, but there are quite a
few like that to choose from really. Perhaps what's actually missing
isn't hardware or software, but some standardized network models,
configuration and wiring diagrams? The "hard" part is teaching basic
networking concepts to the layman, they're going to just want simple
instructions on how and where to connect things.
Then again, this is precisely what a number of the SO/HO router
companies are selling, and to get back to the original point, what
they're doing a terrible job of is keeping the software and firmware
updated on their customers' devices. In what ways would this project
succeed where they're failing? Operating system and firmware updates
can go disastrously if you lose power at the wrong moment, and even
"unbrickable" boards still usually need you to open up the case and
plug in an override BIOS to be able to boot far enough to reflash
everything, so automatic updates are likely the hardest part if you
want to avoid leaving someone with no Internet access to even look
up how to recover their Internet access.

@_date: 2020-06-04 21:57:33
@_author: Jeremy Stanley 
@_subject: [Cryptography] Zoom publishes draft cryptographic design for 
This is a poor example in one sense, but perhaps a very good one in
another. Early versions of Skype were brought to by the makers of
KaZaA, notorious for bundling both adware and spyware free in every
download. If you wanted to make sure you got your system backdoored
quickly, their software came highly recommended.
Corruption can happen at any level. Bigger players may buckle to
nation-state pressure, but smaller ones can get away with selling
you out to the highest bidder and then walking away as soon as
anyone comes looking for them.

@_date: 2020-03-04 18:56:19
@_author: Jeremy Stanley 
@_subject: [Cryptography] Ex-CIA Joshua Schulte Describes His Data/Crypto 
Solid state storage devices typically have some (one reference I
found suggests 7.3%) of their physical blocks hidden in reserve to
accommodate reshuffling around bad blocks and to ease transparent
wear levelling. The "physical" block addresses to which your
operating system's device driver writes aren't all the actual blocks
on the device, nor even the same actual memory locations each time
you "fill up" the ones it tells you are there.

@_date: 2020-03-05 23:42:00
@_author: Jeremy Stanley 
@_subject: [Cryptography] Possible reason why password usage rules are 
Except that authorities (at least in my country of residence) are
happy to issue duplicate/replacement/extra photo identification
under a wide variety of circumstances. Heck, one person could be
flying with my passport whilst another flies with my driver's
license and another with my military ID (if I had one, which I
Alternative theory: if you don't require people to get photo IDs
reissued with some periodicity, the photo looks less and less like
the person over time.

@_date: 2020-03-05 23:50:02
@_author: Jeremy Stanley 
@_subject: [Cryptography] Possible reason why password usage rules are 
This one is a little easier to understand at least (and the minimum
validity timeframe varies depending on the country you're visiting):
they would like to make sure you'll be out of their country again by
the time your passport expires. Of course the country you're
entering will typically take the precaution of issuing a visa for
less than the remaining lifespan of your passport, but people
frequently end up having to overstay or extend an entry visa for a
variety of reasons, so making sure the passport is valid for a few
extra months on top of that helps.
