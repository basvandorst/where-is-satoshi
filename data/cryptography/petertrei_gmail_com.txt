
@_date: 2013-12-24 15:41:15
@_author: Peter Trei 
@_subject: [Cryptography] RSA is dead. 
I have to say that the latest news makes me both heartbroken and angry.
I worked at RSA for 10 years, starting at Security Dynamics in 1997, when
RSA Data Security Inc. was a recent acquisition. I was hired largely
through the work I'd done in creating the Symmetric Key Cryptography
Let's not forget that RSA, for many years, strove to bring strong
cryptography to the world (modulo requiring licensing of the algorithm).
RSA opened an office in Australia so that independently developed crypto
could be sold without export restrictions, and the symmetric key contests
contributed to the relaxation of crypto export laws. For a very long time,
the relationship between RSA and Federal agencies was far from cozy.
While I was there, I saw RSA Labs (which RSA DSI became) get moved from
Silicon Valley to Bedford, MA, and gradually shrink in size and lose
independence. When I left in early 2008, it was a not-very-long row of
offices on one floor. The company culture changed greatly over time, first
when Coviello took over from Bidzos, and then with the purchase by EMC.
The BSAFE library was at one point one of the most widely distributed
pieces of software in the world, present in every copy of Windows, as well
as most browsers. This is the library in which the compromised PRNG was
made default (a process in which I had no part whatsoever; I'm not
qualified in that area).
Despite the brave words of marketing, after the RSA patent expired in 2000,
BSAFE sales plummeted. I just checked, and it looks like my current Windows
system no longer has a copy.
I'm heartbroken, because I was proud to have worked there, and now I find
that they sold their birthright for a mess of pottage.
I'm angry, because the next time I interview for a position, this is going
to come up.
Peter Trei

@_date: 2014-04-06 12:25:53
@_author: Peter Trei 
@_subject: [Cryptography] Verifying X.509 Verification - how about an updated 
We've now seen critical errors in two different TLS implementations,
both of which centered around (different) failures to properly
verify X.509 certificate chains.
As problematic as PKI is, these are bugs that shouldn't have happened. But
they're both 'Type II' errors; a failure to recognize a problem that
should have generated an alarm. The 'happy path' code gets tested
all the time - normal operation relies on it working. It's the 'unhappy
path' which only gets exercised when something is going wrong that
implements these holes. Testing the 'unhappy path' is crucial,
since normal operation doesn't run that way. Apparently this wasn't done.
Hard experience has taught us all that its difficult to get developers
to do thorough testing of code that is rarely if ever run, especially if
there's a lot of work involved in setting up the tests.
I found myself thinking about a test suite of certificates which had
known problems, and which *should* cause apps encountering them
to throw errors. Never one to re-invent the wheel, I started poking
 around.
What I found was PKITS:
Its about 10 years old.
Reading the tests and related documents, this seems a pretty
reasonable set of tests. It even includes a set of certs which
*should* generate failures.
I'm fully aware that anything crypto-related coming out of NIST
today is viewed with a jaundiced eye. But the tests PKITS claims
to perform seem a good start, and include the critical Type II error
Can we use an updated version of PKITS? Would such a suite have
picked up the iOS and gnuTLS bugs? I haven't tried yet.
I expect we'd have to generate a new set of busted certificates;
aside from the trust issue, the included certs are all RSAsha1
with 1024 bit keys, and the validity dates are aging out.
Looking at the PKITS tests, can anyone spot anything critical missing?
Does anyone want to update this?
Peter Trei

@_date: 2014-04-10 18:29:39
@_author: Peter Trei 
@_subject: [Cryptography] cryptography Digest, Vol 12, Issue 9 
- start quote -
While everyone's madly rushing around to fix their bits&bobs, I'd
encouraged you all to be alert to any evidence of *damages* either
anecdotally or more firm.  By damages, I mean (a) rework needed to
secure, and (b) actual breach into sites and theft of secrets, etc,
leading to (c) theft of property/money/value etc.
In risk analysis, we lean very heavily on firm indications of actual,
tangible damages, because risk analysis is an uncertain tool and the
security industry is a FUD-driven sector.  Where we have actual
experiences of lost money, time, destruction of property or whatever,
this puts us in a much better position to predict what is worth spending
money to protect.
- end quote -
There are now suggestions that Heartbleed has been exploited in the
Even if this is not the case, I reject iang's (facetious, I know :-)
Security flaws aren't the same as tsunamis. Reporting a power station's
possible vulnerability to the former doesn't make tsunamis more likely.
However, the wide dissemination of a previously unknown security
flaw *does* make its future attempted exploitation a near certainty.

@_date: 2014-04-17 17:01:32
@_author: Peter Trei 
@_subject: [Cryptography] Something that's bothering me about the heartbleed 
We're all talking about a serious bug in OpenSSL code.
But the bug itself isn't a crypto bug. It's a general programming bug, which
could occur in any server code when the client can say 'send me the first X
bytes of buffer FOO', and the server does that without checking that
X <= length(FOO).
Its a bounds checking bug, which just happened to appear in security related
The same error could occur in many other parts of a server program, with the
same devastating consequences.
Fixing OpenSSL is important. But we need to look at ways of
preventing this kind of bound check error generally. Discussing fixes that
specifically make crypto code more reliable won't catch issues outside of
crypto code.

@_date: 2014-04-17 22:28:57
@_author: Peter Trei 
@_subject: [Cryptography] Something that's bothering me about the 
I think you may have missed my point. This style of security hole could
exist in server programs which don't use OpenSSL; indeed, which don't use
crypto at all. All it requires is that the client/server protocol allows
the client to cause a unchecked read as I described, and sensitive data be
available in program-accessible memory, whether put
there by the server, or dredged up unzeroed in a malloc.
Fixing crypto code, and/or walling it off as you suggest, won't prevent
style bugs in other server code.
We've known for years that buffer overflows can be used for code injection.
In Heartbleed, we're seeing the same problem being used for data
Fixes which prevent read/write access to code segment memory, or execution
of data as code, won't solve this. Perhaps Intel MPX will, once we move to
processors  which have it, compilers support that feature, and server
is rebuilt.
Peter Trei

@_date: 2014-04-30 12:17:00
@_author: Peter Trei 
@_subject: [Cryptography] cryptography Digest, Vol 12, Issue 31 
Remember 'Sink Clipper!'?
Here's something more recent.
When shirts bearing this image appeared on Zazzle, the NSA had them pulled.
It took a lawsuit to stop the NSA's supression of free speech:
Peter Trei

@_date: 2014-08-19 13:55:35
@_author: Peter Trei 
@_subject: [Cryptography] GPU Farm (Marco Streng) 
There's an obvious classic target: The RSA Challenge Numbers.
Way back when the RSA algorithm was just getting established as a usable,
was considerable doubt over its security. In 1991 RSA (the company) posted
a set
of  'Integer Factoring Challenges', with cash prizes attached. See:
In 1996 RSA also posted a set of 'Symmetric Key Challenges', with messages
encrypted using DES and various strengths of RC5. I was the proposer of
these challenges, and the brute forcing of DES and increasing key
lengths of RC5 contributed to the relaxation of crypto export rules in 2000.
The longest key brute forced was 64 bits. distributed.net is still working
the 72 bit challenge.
The prizes were withdrawn in 2007, on the grounds that they'd served
their purpose - RSA was still 'not broken' at adequate modulus length;
(no general break had been found), and exportable short symmetric keys
were no longer required. (There was another problem that individuals
were getting in trouble for using slack cpu on machines they did not own
(ie, their employer's) for brute force calculations).
I don't see the Symmetric key challenge messages up on the RSA
site, but I could probably track them down.
Forcing a symmetric key isn't interesting at the moment - most
responsible sites are using at least 128 bit keys. However, 1024
bit RSA keys are still in wide use, and factoring the RSA-1024
challenge number would pressure people to update their systems.
Sadly, it won't get you the $100k prize, but the publicity would
be valuable.
Peter Trei

@_date: 2014-08-24 13:37:22
@_author: Peter Trei 
@_subject: [Cryptography] On 40-bit encryption 
"Success has many fathers, while failure is an orphan."
There were a lot of factors.
Another one, which I was personally involved in, was the demonstration that
40 and
56 bit bit encryption was insecure.
Members of the 'cypherpunks' mailing list organized a distributed brute
force of a
40 bit key in 1995. It took about 300 PCs, and three weeks.
This was important, because it gave the lie to government claims that 40
was 'good  enough'. All of a sudden, the international market dropped out
under US software exporters of secured products. This threw market forces
to the side of stronger keys - 40 bit crypto became a laughingstock, and its
use clearly did not meet due diligence.
The USG response, within a few months, was to up the limit to 56 bits -
single DES. The RSA Secret Key Challenges were the response. Single
DES was first brute forced over several months in early 1997, and by 2000
this was done in under 24 hours.
Soon after, the export restrictions were eased.
The challenges were hardly the only reason, but they provided an easy to
understand and impossible to deny proof that software engineers and
purchasers could put in front of their managers, and which corporate
management could present to the government.

@_date: 2014-08-27 15:21:10
@_author: Peter Trei 
@_subject: [Cryptography] cryptography Digest, Vol 16, Issue 26 
?>roads, but I've gotten three e-mailed bills in the last two weeks
Apparently some do, most don't. EZ Passes are made by
Kapsch (Kapsch.net), which has data sheets available, and has
made their protocols open source.
You can easily modify one to inform you of when its queried:
...and it turns out they're queried all over the place, not just at
tolls. There have been proposals for a 'kill switch' which would
allow you to disable it except when approaching a toll, but I
haven't seen that.
But its moot, anyway. Transponders are being replaced by
license plate scanning. This is yet another case where we
accepted something (permanently visible LPs) on the basis
that no one could track every plate, everywhere, all the time.
Technology moved on, and invalidated that promise of

@_date: 2014-02-04 18:54:47
@_author: Peter Trei 
@_subject: [Cryptography] (MIT) TALK: Thursday 02-06-2014 Thursday 02-06-14 
I know this is late notice, but some here may be interested.
NSA Surveillance and What To Do About It
Speaker: Bruce Schneier
Host: MIT Big Data Initiative at CSAIL
Host Affiliation: MIT CSAIL
Time:  5:00 PM to 6:00 PM
Refreshments Time: 4:45 PM
Location: 32-123
Edward Snowden has given us an unprecedented window into the NSA's
surveillance activities.  Drawing from both the Snowden documents and
revelations from previous whistleblowers, this talk describes the sorts of
surveillance the NSA conducts and how it conducts it.  The emphasis will be
on the technical capabilities of the NSA, and not the politics or legality
of their actions.  I will then discuss what sorts of countermeasures are
likely to frustrate any nation-state adversary with these sorts of
capabilities.  These will be techniques to raise the cost of wholesale
surveillance in favor of targeted surveillance: ubiquitous encryption,
target dispersal, anonymity tools, and so on.
[I cut out Bruce's bio - no one here needs it  - pt]
Relevant URL:  For more information please
contact: Susana Kevorkova, 617-324-8424, skevorkova at csail.mit.edu

@_date: 2014-01-14 10:36:14
@_author: Peter Trei 
@_subject: [Cryptography] Dumb idea: open-source hardware USB key for 
I only get the digest, so someone may have pointed this out already:
...pretty much what you're asking for.
Peter Trei
BAE Systems
Message: 2

@_date: 2014-01-14 10:38:37
@_author: Peter Trei 
@_subject: [Cryptography] Dumb idea: open-source hardware USB key for 
[without the top posting, sorry]
Peter Trei
BAE Systems, Inc.

@_date: 2014-01-15 15:13:54
@_author: Peter Trei 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
Just to correct history, Bidzos was *long* gone when RSA was sold to EMC.
Coviello was in charge many years at that point, and still is.
Bidzos was unpopular for zealously maintaining the RSA patent, but he stood
up to
considerable pressure from the USG to keep good crypto available. AFAIK, he
on good terms with R, S, and A.
Coviello, I don't want to discuss.
Peter Trei

@_date: 2014-01-19 13:58:28
@_author: Peter Trei 
@_subject: [Cryptography] cheap sources of entropy (Bill Frantz) 
Bill Frantz  wrote
One thought I've had on this applies only to wearables (smartphones,
many contain accelerometers which allow them to determine orientation,
motion, etc.
Since these accelerometers are also used in very low power gadgets such
as fitness activity monitors, (Fitbit, etal), where they operate
it seem plausible that they are cheap (in power terms) to run.
My suspicion is that these can act as a low-bandwidth source of entropy,
by the usual mechanisms involving timing of successive transitions.
randomness which can be added to the pool.
Any thoughts? I expect this has been suggested before.

@_date: 2014-06-05 13:44:54
@_author: Peter Trei 
@_subject: [Cryptography] Fork of TrueCrypt 
Can you name one for TC? That is to say, a page which lists the current
versions of (for example)  TC, Safari, Opera, and Firefox, and which was in
place before the recent commotion? I'm not aware of such a page.
course, you reveal your interest.  But that's true *no matter how
connect reveals your interests.  Shock, horror.  Tor.
It's important to remember that TC and other FDE and file encryption
systems are used by people with a wide range of threat models. Sure, it
includes corporations protecting IP and/or sensitive customer data, who are
mainly worried about the data being stolen. However, it also includes
political dissidents, foreign correspondents, and others who may be Not At
All Popular with the powers that be where they operate, including locations
where the rubber hose is regarded as a cryptanalytic tool.
For the latter, not raising flags that they are crypto users is critical,
and plausible deniability when that fails a Good Thing. While you rightly
note that using Tor is difficult to hide, it is a network protocol - it
MUST communicate on the net. FDE and file encryption doesn't have to.
Automatic checks and updates are a nice-to-have feature, but aren't an
essential requirement.
If the userbase includes people who are trying to maintain a low profile,
it is essential that any application-specific communication with the net
take place only when and where the user OKs it.
Even a low profile user can usually find routes to safely perform checks
and and obtain updates; that's how TC has been used up till now.
Peter Trei

@_date: 2014-06-06 13:00:51
@_author: Peter Trei 
@_subject: [Cryptography]  Google "End to End" 
This is actually kind of interesting. The FAQ is quite clueful, and is
aimed at developers.
What they've done is implemented OpenPGP with EC in Javascript,  as a
plugin for the Chrome browser. At the moment only source code is available,
and they request that developers not include it in fielded apps until its
more baked. It generates only EC keys (haven't dug into the sources to find
the details yet), but you can import RSA based keys generated by GnuPG. It
maintains its own keyring, with both public and private keys. It encrypts
message bodies, but not attachments, subject: or to: lines.
They're very aware of the criticism they'll get for doing crypto in JS.
They feel they're protecting data in transit, and the sandboxing protects
them against other Chrome extensions. They explicitly don't claim
protection against non-browser malware.
Security bugs you find are eligible for the Vulnerability Awards program.
To me, one of the interesting aspects is that this breaks part of Google's
business model; they wont be able to scan message bodies for keywords on
which to target advertising.

@_date: 2014-06-12 13:37:38
@_author: Peter Trei 
@_subject: [Cryptography] Swift and cryptography 
security. The
semantics that
platform dependent,
(It's been said that the fastest way to get an informed answer on the
Internet is to
post an uninformed opinion. So maybe someone who actually knows what the
is will respond if I post this...)
I think the problem is that there are a lot of OS level operations that can
prevent proper
sanitization, and which are hard to fix at a language level. OSs have
historically been
designed to be time-efficient, in ways that conflict with security.
1. OSs supply memory management services. For efficiency, they generally
don't clear
memory when it's returned to the pool, or when reallocated.
2. OSs swap program space to disk and back. Same problem as above.
3. Machine level stack operations move the SP up and down, without clearing
that's been popped off.
4. Optimizers will eliminate code which sets a value which is never read.
Generally, programs don't get the option to tell the OS to do otherwise.
This would
be a nice addition to an OS, but isn't part of the language. It is clearly
platform (OS & HW)
1 & 2 could be fixed at the OS level, at some cost of memory (for
sensitivity flags) and
time (for clearing). 3. would need to be fixed at the microcode or HW
level, in instructions
that modify the stack. This would get tricky if you want to specify what's
and what's not. Tagged memory would make it a lot easier.
Further from the metal, things might be easier for dealing with (4) above.
I could
imagine a 'sensitive' key word on declarations and mallocs (or your
equivalent) which would tag that entity as one which which must be cleared
when it goes out of scope - I think this would be easier than having to
clear it in a destructor.
A 'do not optimize' keyword would be difficult to implement, since code so
may call code which doesn't have the keyword, and which should be subject
optimization in most cases. When do you propagate the property down the call
tree, and when not?
Peter Trei

@_date: 2014-05-01 21:42:31
@_author: Peter Trei 
@_subject: [Cryptography] Interesting reddit AMA re crypto 
There was a reddit Ask Me Anything thread today:
Lots of good questions and answers regarding useability, ubiquity, and
Not deeply technical by this list's standards, but worth checking out.
Opening message:
- start -
*My short bio:* Representatives from Access, CDT, EFF, Silent Circle, and
the Sunlight Foundation will discuss efforts to strengthen encryption
principles and remove the NSA involvement in the standard setting process.
Snowden documents have revealed NSA efforts to undermine encryption
standards set by the National Institute of Standards and Technology
(ironically the NSA?s mission includes ?information assurance?). Between
Heartbleed, large-scale data breaches, and overbroad surveillance, data is
being compromised at an unprecedented level. We will talk about efforts by
coalition of digital rights, technology, privacy, and open government
groups to call on NIST to strengthen cryptography principles.
Participants include: Amie Stepanovich (astepanovich), Access Joseph Hall
(joebeone), CDT Nate Cardozo (natecardozo), EFF Kurt Opsahl (kurtopsahl),
EFF Sean Vitka (svitka), Sunlight Foundation
- end -
Peter Trei

@_date: 2014-05-28 23:05:01
@_author: Peter Trei 
@_subject: [Cryptography] What is going on with TrueCrypt? 
[I get the 'digest' form of this list around noon each day, so I'm probably
throwing this into an already active discussion.]
1.0 What do we know?
1.1 The truecrypt.org website has been redirected to a SourceForge
page, which claims
"WARNING: Using TrueCrypt is not secure as it may contain unfixed
security issues."
1.2 It goes on to recommend that users migrate to BitLocker or
OsX encrypted virtual drives. No particular recommendation is made
for Linux.
1.3 Includes TrueCrypt binaries ("version 7.2") for Windows,
Mac, and Linux. The 7.2 version has only decrypt functionality,
it cannot encrypt.
1.3.1    These binaries are signed with a 2004 truecrypt gpg key.
    1.4 A post has been made to HackerNews by a person claiming to be a
SourceForge employee, to the effect that there doesn't seem to be
anything unusual in recent traffic and usage of the TrueCrypt account.
1.5 This is odd, seeing as the site has been only sporadically
available due to exceeding bandwidth limits; this not 'not unusual'.
1.6 The TC devs are haven't been heard from yet (but that would
not be too unusual, in the *normal* run of things).
2.0 Theories (just off the top of my head):
2.1  This is a hack attack.
2.1.1  ...as a prank.
2.1.2  ...to spread FUD about TC.
2.2 This is real; a serious compromise has been found in TC.
2.3 This is a Warrant Canary of some kind.
... I'm sure this list can be extended.
(the following is just speculation on my part)
The suddenness with which the shutdown occurred, the elaborateness
of the effort (setting up modified binaries, and getting them signed),
along with the non-explanations from the TC devs, tend to suggest that
this is not a simple prank. It also fits poorly with a real fault have been
found - the communications are all wrong.
That leaves an attempt to spread FUD about TC, or a Warrant Canary
scenario. The statement at the top of the current TrueCrypt.org page
is trivially true; *all* security related programs 'may' be insecure due
to 'unfixed security issues'. (Yes, I know this isn't a proper 'Warrant
Canary',  but TC sadly didn't have one in place; it may be this is the
best they could legally do.)
I'll throw in that TC recently passed the first round of an independent
audit with good grades, and in the courts LEAs have been treating it as
secure when carefully used.

@_date: 2014-05-29 11:03:55
@_author: Peter Trei 
@_subject: [Cryptography] What is going on with TrueCrypt? 
Good point, but that's not really consistent with the form of the change -
they'd have no reason I can think of not to call it out.
Another possibility I've heard is that there's been a falling out among the
(anonymous to most) devs, and one decided to send the project up in
flames. However, the provision of modified versions seems over-elaborate
for such an action.
ATM, I'm still thinking 'Warrant Canary'. The longer the site remains
modified, and the devs silent, the stronger that option becomes, imho.

@_date: 2014-05-31 13:04:46
@_author: Peter Trei 
@_subject: [Cryptography] cryptography Digest, Vol 13, Issue 30 
At this point, I'm starting to agree that this is starting to look more
like a takedown by the dev team.
I was initially pretty sure of the Warrant Canary hypothesis, now I'm not
so certain.
Factors that feed into this change of view:
* The TC code base has legal and license issues; these may have just made
it too difficult to
do further development.
* The code needed a thorough rework, not just to improve password hashing,
but also to move
it to a modern development environment. That the devs didn't to this
suggests a lack of interest,
or a legal issue with doing so.
* The audit suggests that there is just one active dev. Perhaps he/she just
got tired of it.
* Steve Barnhart's contact with the devs (see upthread), seems to confirm
What I still find mysterious is the manner of the takedown. Unless there
*is* a fundamental
vulnerability, why not just post 'We're tired of working on this. We can't
relicense it so others
can fork it, so we're shutting up shop. So long, and thanks for all the
Even if there *is* a fundamental flaw, they could have said a little more
than they did, such
as why they weren't going to fix it.
The lack of a public statement, and the hurried and poor advice on
replacements, combines
with the time and effort that must have gone into creating version 7.2 to
create a head scratcher
of a situation.
That this is taking place in the current environment of the US Intel
community going
ballistic over the Snowden revelations, while he used TC to protect data,
certainly makes
it easy to imagine TLA involvement. I wouldn't rule that out, but would add
that Life
Happens, and the dev(s) may simply have other reasons why they didn't want
to continue.

@_date: 2014-11-09 18:59:27
@_author: Peter Trei 
@_subject: [Cryptography] From IP: Peter Swire looking for crypto policy 
Slightly off-topic, but may be of interest to some:
*From: peter at peterswire.net (*Peter Swire)
*To: *Dave Farber *Date: *November 7, 2014 at 8:46:30 AM EST
*Subject: **request for assistance for debate on encryption with former FBI
General Counsel*
Hello Dave:
On Monday, November 17 the New America Foundation will be hosting a debate
on the topic of FBI Director Comey?s criticisms of Apple and Google for the
encryption changes to their phones.  The moderator will be Nancy Libin,
formerly of both CDT and the Department of Justice.
Former FBI General Counsel Andrew Weissmann will be presenting the Comey
side of the argument. Andrew is an experienced litigator, former head of
the Enron Task Force and other major prosecutions.  I was in school years
ago with Andrew, and the debate will be on the merits but not personal.
 With that said, only the best arguments will work.
With that in mind, I was wondering if readers of your list might send
(off-list) resources to prepare for the debate?  Many people, in diverse
outlets, have been writing about these topics.  Although I am currently in
the midst of hiring a full-time researcher, I don?t have that help at the
If useful, I could circulate a bibliography once the debate happens.
For those in DC, the debate will be 4:00 to 5:30 p.m.  at New America,
address 1899 L St. NW   it will be webcast, and may be on C-Span.

@_date: 2015-01-03 11:45:15
@_author: Peter Trei 
@_subject: [Cryptography] on brute forcing 3DES to attack SIMs 
[Full disclosure: I persuaded RSA to set up the Symmetric Key Contests back
in the
90s, which broke single DES. I contributed one of the early brute force
tools, and
set up the format of the contests, and verified solutions].
I was quite boggled to see this claim. Digging through to the original
article, it looks
like they have a system to crack single DES - which is totally plausible -
Deep Crack could do that in 1998.
However, the longest key that I know to have been publicly brute forced was
RC5 with a 64 bit key, by distributed.net back in 2007(8?). d.net is
working on a
72 bit key, but have barely made headway. 112 and 168 bit keys (2 and 3 key
3DES) remain computationally infeasible to brute force.
The claim vs 3DES is couched in terms of a 'partially known key', without
much more
info, so I can't really evaluate it.
They also point out they can circumvent A5/1 encryption, which is a bit
since the A5 suite of stream ciphers was pretty well broken over a decade
ago, by
Barkan, etal.
The exposure of poorly protected SIM cards is a Good Thing, since it may
prod the manufacturers to up their game. But some of the claims seem more
then a little inflated.
Peter Trei

@_date: 2016-01-07 21:34:51
@_author: Peter Trei 
@_subject: [Cryptography] Chaum Has a Plan to End the Crypto War 
be far more controversial: a carefully controlled backdoor > that allows
anyone doing something "generally recognized as evil" to have their
anonymity and privacy stripped altogether.'
Those of us who have been in the field for a while will (hazily) remember
that back in the 80's, Chaum invented the first
practical cryptocurrency. However, he patented his 'blind signature'
algorithms, which were the heart of the system, and he and
the DigiCash corporation (which was created to exploit the patents) were
extremely restrictive in their licensing. Reportedly,
this was because Chaum was concerned that Bad People might use it for money
laundering.The system saw very little
use. Much more detail can be found in the cypherpunks mailing list archives.
....which is a long way of saying that for Chaum to cripple his system with
a back door seems consistent with his earlier
reported behavior.
Peter Trei

@_date: 2016-03-24 13:11:04
@_author: Peter Trei 
@_subject: [Cryptography] OTP phones - arrested for buying phones. 
2006, 2 cases
Three Middle Eastern Men Found With 1000 Cell Phones
Police investigate suspicious purchase of cell phones
Police, FBI called after men purchase hundreds of phones from Missouri
Walmart stores
Peter Trei

@_date: 2020-01-14 13:45:34
@_author: Peter Trei 
@_subject: [Cryptography] improved identification of non-targets 
I'm a little late to the party here, but lets remember that 'false flag'
are an accepted part of war, and not a war crime as long as they are used to
get close to the enemy. Its expected that combatants will show their true
colors before actually engaging in combat.
In the past, aircraft were expected NOT to do this, because of the
of changing paint jobs as they enter combat. Not that that stopped anyone -
Wikipedia page for 'false flag' starts with a photo of a US plane in Cuban
prior to the Bay of Pigs.
Electronic IFF systems could - perfectly legally - identify as anything
want up until they release weapons. Use of stolen IFF gear and codes,
real time retransmission of another plane's signal, or radio silence, or
jamming are not war crimes.
The people in charge of the Ukranian flight should have recognized that
just hours after attacking US bases, the airspace over Iran was dangerous,
and not flown.
Peter Trei
