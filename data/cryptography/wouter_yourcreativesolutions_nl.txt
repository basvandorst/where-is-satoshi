
@_date: 2002-02-06 08:10:49
@_author: Wouter Slegers 
@_subject: Welome to the Internet, here's your private key 
If all of the random data is provided by the manufacturer, this is a
good point. However you can use such random data to strengthen the
security if the card contains no, or an untrustworthy, random generator
by using the manufaturers randomness as a seed or encryption key for the
generator part (in Yarrow style random generators). If done correctly, this makes the output at least as random (or more
specificly: unpredictable) as the minimum of the sources. With
non-random seeding data (e.g. manufacturing fault or foul play) the
security of such a scheme against attacks by the manufacturer is as low
as it was before, but against others still high.
Of course, if you can keep some random pool on the chip, you can keep
mixing in randomness from sessions, which will make an attack on the
random generator much less interesting. A backdoor is then more
interesting for a rogue manufacturer.
Only if they are the _only_ randoms provided. For seeding the random
generater I think they are a Good Thing(tm)
For non-repudiation, nobody must be able to duplicate the secrets, with
or without seeing it. A secure cloning operation (such as many of the
HSM SSL-cards provide) is also not allowed.
With kind regards,
Wouter Slegers

@_date: 2008-11-02 13:36:19
@_author: Wouter Slegers 
@_subject: Who cares about side-channel attacks? 
Peter convinced my to publicly comment on this.
That was also my first response. In evaluation labs specialized in
checking devices (mostly smartcards and other financial devices) the
whole spread of attacks are tested against. Side-channel analysis is
arguably the most sexy of them all, but I have yet to see any hint let
alone proof that it is used in the field.
Perturbation attacks (messing with the execution of the code) by means
of glitches in the supply voltage is still the undisputed number 1 in
field attacks on individual smartcards.
Protocol/API-level attacks are the biggest one on system level in my
opinion. Card sharing is currently a good example.
Timing analysis is quite possible to pull of in straightforward
implementations as demonstrated over the Internet on OpenSSL prior to
their implementation of blinding
( But frankly, I
have never heard of such an attack actually being used in the field.
Real side channel analysis (DPA, EMA etc) seems mostly limited to
academics and labs, not the field.
attack (the academic papers are good, but do not underestimate the
difficulty in implementing it in non-ideal noisy environments), which
suggest that protecting for it is not such a high priority at the moment
(it is not the weakest link).
Which suggests that keeping side channel analysis as part of the
possible attacks is a good idea. The broad scope of attacks seems to be
done in the field, which means that it is interesting for the defenders
to invest effort in that also.
In a way, the enthousiast attackers on the internet form a sort of
loosly parallel attack, not so much obviously focussing on one weak
spot but using a broad spectrum approach.
I'm afraid that the best at this moment is mostly rumors. There is some
knowledge about attacks in the field but it is spread out a lot and the
ones that aggregate this information are not sharing this (it also gives
the attackers a view on what works and what not).
I've seen quite a few publicly available examples of voltage
manipulation on old style smartcards, (not so-)secure embedded CPUs. Old
style physical reverse engineering is getting within the range of
students now (recent reverse engineering of crypto-1 is a good example).
Examples of side channel analysis on real systems I however have never
seen in the field. Any rumors would be highly appreciated.
?? As I read his story, he eavesdropped the bus between the bridge chip
and the CPU to recover the real bootloader code with the real RC4 key,
not the incorrect one in the ROM (very nasty trick, kudo's for the
Microsoft development team there ;-) ). Ref Nevertheless, this is a good example of economically unreasonable
attacks: Bunnie spent something like 4 months of his master thesis' time
on hacking the Xbox and then gave that knowledge away for free on the
internet. 4 months of "honest work" would have bought him that Xbox and
all consoles he could have wanted for quite some time...
[snip good list of things to consider]
I agree. From commercial point of view, the developer's point of view of
side channel analysis protection (and most other protections I think)
is I think:
Costs: - Additional resources in the device (memory, CPU time). Unless the
  device is severely resource bound (like a very tight power budget,
  really limited memory sizes like in a smartcard), this is not really a
  cost.
- Significant and specialized additional development resources to
  implement the countermeasures well. To do the whole protection, not
  just the blinding, well is a real engineering effort. It also requires
  a specific type of expertise that is not so easy to get or develop
  (although it is great fun to do for the developer as a person), i.e.
  it is expensive in your development personel costs.
- Testing and production might suffer from the security measures. This
  can be surprisingly expensive in terms of production speed.
- Reliability in the field of the product is potentially going to
  suffer, because of the risk of the countermeasures tripping in the
  field. Out there the power is bad (looking just like a voltage glitch
  attack), the sun is on the device (looking just like a temperature
  attack), the device falls of the counter (causing a short disconnect
  in the tamper sensors connectors, looking just like a tamper event).
  Because it is hard to get good information on these events in the
  field (attacks and accidents alike), the reliability takes an unknown
  but potentially high hit. This is the big cost in the eyes of
  management (and in mine).
- No compromittation of the resources. But in many cases, it is not the
  product's resources that are compromised...
- Warm fuzzy feeling.
If you look at it this way, it makes no sense to implement
countermeasures. Unless the costs are reduced by doing exactly what
Peter had already excluded: using a ready made crypto library /
smartcard /... that is already tested and shown to work.
Or, which is my experience, because regulations in the product domain
force the developer to have these countermeasures and show them to be
effective to third parties (evaluation labs). This is the domain of
financial organisations with their accreditations, and government(-like)
organisations requiring Common Criteria evaluations.
(Which also is excluded by Peter: the group that does this because they
have no choice).
For real threats out there, I agree that it is not as high a priority
as perturbation or API attacks are.
It is however relatively easy to implement only the blinding of the SCA
protection (just take a crypto library that does this). Implementing the
real anti-perturbation and side channel analysis protection, that is
where it becomes a serious amount of work.
So in short, I would see the group that Peter was looking for, as an
economic anomaly ;-) Although I would be fascinated to hear why it is
interesting for them to do anyway.
With kind regards,
Wouter Slegers

@_date: 2008-10-24 16:23:36
@_author: Wouter Slegers 
@_subject: combining entropy 
I take the last item to mean that you do not mind wasting entropy but
want to be sure the resulting random number is unpredictable.
If you add one additional assumption:
* The sources are independent of each other
then the XOR of the random sources will be at least as unpredictable as
the most unpredictable individual random source (to keep away from the
entropy discussion). As far as I can se, this the "if at least one
source is unpredictable for a workload of x, the resulting random is
also at least that unpredictable" property that you seem to be looking
If the sources are not independent, in the most extreme case: the sources
are the same, the result is not so good. XORing in the same RNG stream
twice, however good the RNG, is not so useful ;-)
Without the threatmodel, I am not sure if this is a problem for you, but if the attacker has control or knowledge of some of the sources, he also knows the XOR of the remaining ones. In the case he knows all but
one sources, and the remaining source is not so unpredictable (LFSR,
poorly biased noise source), the result can be quite predictable (and in
weak RNG designs, the remaining source might be compromised).
Note that this could also be used to force the combined RNG to more
likely generate a chosen output.
Using hashfunctions to combine the randoms makes it computationally
harder for such chosen results to be generated, it quickly becomes
effectively a search problem for hash-collisions where you have only
limited choice on the input. Also temporary lulls in the quality of the
random sources are much better handled. Peter Gutmann's dissertation
has a very good description of what he did for hardening his cryptolib's
the random generation from many such attacks/mistakes.
With kind regards,
Wouter Slegers

@_date: 2013-10-11 20:23:58
@_author: Wouter Slegers 
@_subject: [Cryptography] Broken RNG renders gov't-issued smartcards 
Dear Ray,
This is a misunderstanding of the CC certification and FIPS validation processes:
the certificates were issued *under the condition* that the software/system built on it uses/implements the RNG tests mandated. The software didn't, invalidating the results of the certifications.
At best the mandatory guidance is there because it was too difficult to prove that the smart card meets the criteria without it (typical example in the OS world: the administrator is assumed to be trusted, the typical example in smart card hardware: do the RNG tests!).
At worst the mandatory guidance is there because without it, the smart card would not have met the criteria (i.e. without following the guidance there is a vulnerability)
This is an example of the latter case. Most likely the software also hasn't implement the other requirements, leaving it somewhat to very vulnerable to the standard smart card attack such as side channel analysis and perturbation.
If the total (the smart card + software) would have been CC certified, this would have been checked as part of the composite certification.
(I've been in the smart card CC world for more than a decade. This kind of misunderstanding/misapplication is rare for the financial world thanks to EMVco, i.e. the credit card companies. It is also rare for European government organisations, as they know to contact the Dutch/French/German/UK agencies involved in these things. European ePassports for example are generally certified for the whole thing and a mistake in those of this order would be ... surprising and cause for some intense discussion in the smart card certification community. Newer parties into the smart card world tend to have to relearn the lessons again and again it seems.)
With kind regards,
Wouter Slegers

@_date: 2014-01-30 08:46:06
@_author: Wouter Slegers 
@_subject: [Cryptography] cryptography Digest, Vol 9, Issue 29 
In the Common Criteria world, especially for smart cards, BSI?s AIS31 TRNG requirements are pretty much the high end of evaluated TRNGs and effectively mandated for smart cards under the German CC scheme: Note that the CC process assumes a non-hostile developer and production facility, so this does _not_ cover backdoors in the design/implementation, although the location of the entropy measurement does help in getting some assurance on the raw noise quality (and is also a major hassle in product design: how to get the raw signal out from a supposedly closed chip).
It does give some rigour to defining what entropy is, what the quality is of the output, expected short and long term failure detection mechanisms, and how to show and verify these. And there is a decade+ of experience applying these requirements (although a lot of it is painful ;-)).
Some reading notes:
AIS31 = true random number generators, i.e. mostly the hardware ones
AIS20 = Deterministic random number generators
TOE = Target of Evaluation, i.e. the thing that is evaluated, here the thing that includes the RNG.
With kind regards,

@_date: 2017-02-21 20:16:16
@_author: Wouter Slegers 
@_subject: [Cryptography] HSMs or Intel SGX? Which is harder to hack? 
CC also depends on the claims (SFRs in CC language) and the expected environment (Objectives for the Environment).
Yes, I would advise that too. It is quite likely that the HSM is evaluated under the assumption that the environment provides significant protection against leakage already. In that case, the threat model possibly does not include leakage.
A recently formalised Protection Profile ( i.e. a definition of the minimum security requirements to be tested against, states that the environment should:
Rough translation: the evaluation is under the assumption that the HSM is in a trusted environment. Stealing the HSM, more intense physical and side channel analysis (such as common in the smartcard domain), messing with the settings by a malicious/incompetent system administrator, these are all not considered in the evaluation under the quoted PP.
That thee environment objectives are assumed to be followed in the CC is a fundamental choice of blinders to make an evaluation actually end (not a lot of products are secure if the administrator can’t be trusted, etc etc).
Other HSMs do not have such assumptions that the environment counters these attacks, and should be tested against side channel attacks etc. Just how strong the attacker considered was, is defined by the number at the end of “AVA_VAN.”.
This number goes from 1-5, with the rough meaning of:
AVA_VAN.1: The attack isn’t yet on the internet as a tool or easy technique at the time of evaluation.
AVA_VAN.2: No easy modification of such tools is possible, or a few days of prodding the product didn’t work.
AVA_VAN.3: The evaluators determined that it won’t be easy to break the product. They’ll have spent a few weeks to determine this.
AVA_VAN.4: The evaluators got serious to determine this. Attacks should be months to do, or require very special equipment/knowledge/… Posting a successful attack will get you some respectful nods.
AVA_VAN.5: The evaluators went pretty much all out within a budget of ±100-300K€. Posting a successful attack will get you some serious respect (and probably job offers from the labs and the other developers).
Considering the advances in this field, the formal validity of the certificate is 2 years. Certificates older than 5 years don’t have a lot of value anymore, the attack technology has improved too much.
With kind regards,
Wouter (who works in the CC domain, mostly smartcards but also HSMs and such)
