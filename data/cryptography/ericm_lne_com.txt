
@_date: 2001-07-10 17:48:34
@_author: Eric Murray 
@_subject: Crypto hardware 
Was it the BBN Safekeeper?
I haven't seen one, but I have had it described
to me as a PC welded into a box, intended for
use as a CA.

@_date: 2001-07-27 16:26:59
@_author: Eric Murray 
@_subject: Criminalizing crypto criticism 
Like an Adobe product- PDF uses RC4 for it's "password protection".

@_date: 2001-06-01 14:53:29
@_author: Eric Murray 
@_subject: Lie in X.BlaBla... 
I'm not a lawyer but I read it the way Greg does.
Intent is required, so simply sending a cert that's part of a chain
and which you don't hold the corresponding private key for, or
acting as a directory, isn't illegal.
But I'd bet that some enterprising DA, given a case where someone
sends four certs in a chain and got the EE cert by fraudulent means, will
charge them with four counts of violating this law.

@_date: 2001-06-21 09:02:32
@_author: Eric Murray 
@_subject: Cryptobox (was Re: Edupage, June 20, 2001) 
...unless they're running one of the myriad existing solutions
(like IPSEC, PGP, S/MIME, SMTPS).
I love it when journalists regurgitate press releases without
doing even the most basic research.
More on Cryptobox at:
  and

@_date: 2001-05-25 15:18:04
@_author: Eric Murray 
@_subject: Tamperproof devices and backdoors 
(for software folks, JTAG is a 2-wire debgging interface
that's usually hooked up to all the registers.  It lets you
shift out the register contents via a seperate path
and often lets you shift in new values... very
useful for debugging a new chip that only half works).
Yes.  Hardware designers are very resistant to removing it though. :-)
I've been able to talk hardware designers into fusing the JTAG
lines with fusable links, or simply not bonding out the wires
in production.  But both of those solutions suck, since they're
relatively large features and would be subject to micromanipulation.
[Not to mention that JTAG interfaces are highly useful for people
trying to debug software problems. My company uses JTAG based
debugging equipment for this purpose... --Perry]

@_date: 2001-11-27 13:20:40
@_author: Eric Murray 
@_subject: private-sector keystroke logger... 
Many PC users have outgoing firewalls that prevent and/or raise an
alarm when their machine tries to make an outbound connection
on a "unapproved" port.  Zonealarm is one of thses.
The attack S/W could simply modify the firewall's config files.
Or, since outbound traffic to port 80 is almost always left open, encrypt the key logging data in the attackers key and
then use dejanews to post it to alt.anonymous.messages.
A lot of 'root kits' and similar programs that set up slaves for
DDOS attacks announce their availability on IRC.
Emailing to a fixed address indicates to me that the attackers aren't
serious about actually receiving the key logging data.

@_date: 2001-09-25 09:29:02
@_author: Eric Murray 
@_subject: [FYI] Did Encryption Empower These Terrorists? 
Actually SET wasn't all that inconvienent for cardholders.
There was a registration (cert issuance) stage.  After that
it was pretty much invisible, except that you used a 'wallet'
rather than typing in your CC number.  Of course finding an actual
SET merchant was nearly impossible, and finding one that was
selling something interesting was impossible.
What killed SET was:
-SETco charging a huge amount of $$$ for standards, compliance testing, etc.
 This was rough on small companies, who were doing most of the
 actual implementation.
-very complicated standards which were difficult to understand, let
 alone implement or do a security review on.  (the docs were decent, it's
 just that the standard was so much more complex than was required)
-a (valid) perception that MC/Visa owned the standard and could (and did)
 change it capriciously, then demand that implementers follow suit.
-Visa/MC didn't want it to succeed.
After working with SET for a couple years and attending numerous SET
meetings, I figured out that the people running SET (not the technical
folks, but their masters) wern't as incompetent at getting a standard done
as it appeared.  Rather, they were purposefully sabotaging it. SET was
meant as a counter to Cybercash and Mondex.  Those didn't go anywhere,
so SET wasn't required.  The current situation (CCs over SSL)
makes MC/Visa a lot more money than SET would since they're all
card-not-present transactions charged at high rates.

@_date: 2002-08-01 14:45:52
@_author: Eric Murray 
@_subject: Challenge to David Wagner on TCPA 
TCPA (when it isn't turned off) WILL restrict the software that you
can run.  Software that has an invalid or missing signature won't be
able to access "sensitive data"[1].   Meaning that unapproved software
won't work.  Ok, technically it will run but can't access the data,
but that it a very fine hair to split, and depending on the nature of
the data that it can't access, it may not be able to run in truth.
If TCPA allows all software to run, it defeats its purpose.
Therefore Wagner's statement is logically correct.
Yes, the spec says that it can be turned off.  At that point you
can run anything that doesn't need any of the protected data or
other TCPA services.   But, why would a software vendor that wants
the protection that TCPA provides allow his software to run
without TCPA as well, abandoning those protections?
I doubt many would do so, the majority of TCPA-enabled
software will be TCPA-only.  Perhaps not at first, but eventually
when there are enough TCPA machines out there.  More likely, spiffy
new content and features will be enabled if one has TCPA and is
properly authenticated, disabled otherwise.  But as we have seen
time after time, today's spiffy new content is tomorrows
virtual standard.
This will require the majority of people to run with TCPA turned on
if they want the content.  TCPA doesn't need to be required by law,
the market will require it.  At some point, running without TCPA
will be as difficult as avoiding MS software in an otherwise all-MS
office.... theoretically possible, but difficult in practice.
"TCPA could be required" by the government or MS or  is, I agree, a red herring.  It is not outside
the realm of possibility, in fact I'd bet that someone at MS has
seriously thought through the implications.  But to my mind
the "requirement by defacto standard" scenerio I outline above
is much more likely, in fact it is certain to happen if TCPA
gets in more than say 50% of computers.
I worked for a short while on a very early version of TCPA with Geoff
Strongin from AMD.  We were both concerned that TCPA not be able to
be used to restrict user's freedom, and at the time I thought that
"you can always turn it off" was good enough.  Now I'm not so sure.
If someday all the stuff that you do with your computer touches data that can
only be operated on by TCPA-enabled software, what are you going to do?
BTW, what's your credentials?  You seem familiar with the TCPA spec, which
is no mean feat considering that it seems to have been written to
make it as difficult to understand as possible (or perhaps someone
hired an out-of-work ISO standards writer).  I think that Peter's
guess is spot on.  Of course having you participate as a nym
is much preferable to not having you participate at all, so don't
feel as though you have to out yourself or stop posting.
[1] TCPAmain_20v1_1a.pdf, section 2.2

@_date: 2002-08-01 15:06:38
@_author: Eric Murray 
@_subject: Challenge to David Wagner on TCPA 
Nope.  They care that the Fritz chip is enabled whenever
their content is played.  There's no need to make it a legal
requirement if the market makes it a practical requirement.
The Linux folks just won't be able to watch the latest
Maria Lopez or Jennifer Carey DVDs.  But who cares about a few
geeks?  Only weirdos install alternative OSs anyhow, they can be
ignored.  Most of them will probably have second systems
with the Fritz chip enabled anyhow.

@_date: 2002-01-28 16:16:58
@_author: Eric Murray 
@_subject: Fingerprints (was: Re: biometrics) 
[reasons why the FBI wants so many minutae deleted]
As an example of the real world, a couple years ago I put together
a working demo of a smartcard authenticated by a fingerprint
(the card then went on to participate in SET).  The pre-release
fingerprint chip I used would regularly grab about 20 minutae, more
like 10 on a bad scan (dirty finger, poor position, etc).
If you set the macthing parameters to require all minutae to match,
you'd get a positive (i.e. match all minutae) on about one in ten scans.
And of course the other reason for wanting such good prints is simply
that the FBI can demand them.

@_date: 2002-03-26 17:36:07
@_author: Eric Murray 
@_subject: 1024-bit RSA keys in danger of compromise 
Here's the distribution of RSA key sizes in SSL servers, as
recorded by my SSL server survey in June 2000 and June 2001
RSA Server Key size
   Key bits                    2000         2001
2048                             .2%             .2%
1024                           70%             80%
<= 512                          25%             17%

@_date: 2003-04-09 10:03:41
@_author: Eric Murray 
@_subject: OT: cypherpunks 
You got unsubscribed when mail to you was bouncing.

@_date: 2003-04-10 13:08:56
@_author: Eric Murray 
@_subject: Revenge of the Wave-oids (was Re: Trusted Computing Group trying to be TCPA follow-on [eetimes] 
Wave'a a bit player in TCPA, just hoping to get a few
crumbs from the big boys.  It's Microsoft and Intel and Compaq/HP
who're dictating the action.

@_date: 2003-07-08 13:22:59
@_author: Eric Murray 
@_subject: LibTomNet [v0.01] 
Attempts to do new stuff should not be discouraged.
But like home-made ciphers, they should be viewed as interesting
learning exercises rather than serious secure protocols.
Unauthenticated Diffie-Hellman has been in SSLv3 since the beginning.
Rejecting SSL because it "uses certifictes" is either a result
of ignorance of the spec or an excuse for re-inventing.
If you are into wheels, it's more fun to (re-)invent the wheel the wheel
than it is to use the existing wheels laying about.  The posters here
are wheel geeks ("look, I can build a 12-spoke wheel!")  who are not
interested in the reliabilty of the bicycles that the wheels are used on.
If you start with the same assumptions you will wind up
with something that looks very similar to SSL.  Once you have discovered
and addressed all the same holes and pitfalls that is.
While it's a fun learning exercise, it's not useful to the rest of
the world... SSL, because it has had more review than your protocol
will ever get, will be more secure.
The only way to end up with something significantly different
is to address a different set of requirements...  and more different
than "no certificates".
A good place to start is Eric's _SSL and TLS_ book.  How can you make something better without understanding the mistakes
of the past?

@_date: 2003-07-08 14:20:46
@_author: Eric Murray 
@_subject: LibTomNet [v0.01] 
For comparison purposes, I have a copy of an SSLv3/TLS client library
I wrote in 1997.   It's 56k of (Intel Linux) code for everything
except RSA.   That includes the ASN.1 and X.509 parser.
Implementing the server-specific parts would add only another
couple k.  This was done for a handheld computer but runs on
unix as well.
OpenSSL is huge because it's also a general purpose crypto lib, supports
a bunch of hardware and a bunch of algorithms, SSLv2 (ew), old apis, non-blocking, etc etc.

@_date: 2003-07-10 07:27:57
@_author: Eric Murray 
@_subject: SSL 
I'd recommend Eric Rescorla's _SSL And TLS_ book for
learning about the protocol itself.  It's a very
good explanation of the protocol.
A concise explanation of the basic protocol
is in the original SSLv3 protocol spec from Netscape.
It's short but must be read carefully.
There's also a book on Openssl itself, that, from the parts I
have looked at, seems pretty good.
_Network Security with OpenSSL_ (Viega Messier & Chandra).
Like we've covered in this thread, Openssl  has a whole lot of stuff
that isn't needed for doing SSL.  It's the last place you want to start
trying to understand SSL.  Instead, first get a basic understanding of
the SSL protocol from Eric's book.  Then look at Openssl.  Unfortunately
the simpler SSL implementations seem to not be freely available.
If you do java, try Eric's 'pureTLS' java implementation.  To start in Openssl, look at how the sample client and server apps
work.  Then step through them with a debugger.  The way that Openssl
is constructed with many macros and tables of pointers to functions makes it
difficult to simply read until you come to recognize the names.  Also, to
be honest, the code is written in a style that makes it more difficult to
understand than it should be.  Nothing against Tim and Eric or the current
Openssl crew, but anyone who uses that many single character variable
names needs to be whacked on the butt with a rolled-up copy of K&R C
and be told "NO" in a very firm voice.
Openssl is still changing and what little documentation
they have is often stale.
The openssl-users mailing list is quite active and is pretty
good about answering questions.

@_date: 2003-06-02 09:24:29
@_author: Eric Murray 
@_subject: Maybe It's Snake Oil All the Way Down 
Some who can't understand SSL won't be able to do better.
Especially since there is at least one very good book on it.
The original SSH protocol had holes so large that
you could drive a truck through them.   Tatu posted
it to various lists and got lots of advice on
how to clean it up.  It still had holes that were being
found years later.
SSLv2, which was also designed by an
individual, also had major flaws.  And that was the
second cut!  I haven't seen v1, maybe Eric can
shed some light on how bad it was.
Peer review is not "design by comittie".  It is
the way to get strong protocols.  When I have to roll my
own (usually because its working in a limited environment
and I don't have a choice)
I get it reviewed.  The protocol designer usually misses
something in his own protocol.
0. USE EXISTING SECURITY PRIMITIVES
which allows you to
Rolling your own crypto is where 95% of crypto apps fail...
the developers either take too much time on it to the detrimient
of the useability because it is the sexy thing to work on, or
they write an insecure algorithm/protocol/system.    Usually
they do both!

@_date: 2003-06-04 07:40:48
@_author: Eric Murray 
@_subject: Maybe It's Snake Oil All the Way Down 
It's the I part of PKI that's hard.  That the assumptions built
into X.509 (i.e. a rigid certificate hierarchy) don't work everywhere
just makes it harder.  And the obstinance of the standards organizations
involved don't help.
Too often people see something like Peter's statement above and say
"oh, it's that nasty ASN.1 in X.509 that is the problem, so we'll just
do it in XML instead and then it'll work fine" which is simply not true.
The formatting of the certificates is such a minor issue that it is lost
in the noise of the real problems.  And Peter publishes a fine tool
for printing ASN.1, so the "human readable" argument is moot.
Note that there isn't a real running global PKI using SPKI
or PGP either.
The largest problem with X.509 is that various market/political forces
have allowed Verisign to dominate the cert market and charge way too
much for them.  There is software operable by non-cryptographers that
will generate reasonable cert reqs (it's not standard Openssl) but
individuals and corporations alike balk at paying $300-700 for each cert.
(yes I know about the free "individual" certs, the failure of
S/MIME is a topic for another rant).
This is why lne.com's STARTTLS cert is self-signed.  Verisign
isn't getting any more of my money.

@_date: 2003-05-03 14:18:08
@_author: Eric Murray 
@_subject: The Pure Crypto Project's Hash Function 
This idea doesn't actually reduce code size.  Look at
any software implementation of modexp or the libraries plus
device drivers for any hardware modexp.  The code for a simple implementation of SHA1 is trivial
in comparison to either of those.  But even the simplest
bignum modexp isn't a trivial amount of code.
This idea is only "small code size" if one waves his hands
over the details of the modexp implementation...
And of course doing a modexp for _each byte_ of the hash would
make this unbeleivably slow.
SHA1 as a primitive can be used for other things
like making a symmetric encryption algorithm.  There have
even been some research papers published on the strength
of SHA-MDC.

@_date: 2003-05-09 10:17:54
@_author: Eric Murray 
@_subject: A Trial Balloon to Ban Email? 
Weinsteins proposal is DOA because of the centralized control and the
lack of anonymity (oh, but Pit issuers may issue special anonymous certs
to "applicants with special needs for identity protection (e.g., human
rights groups operating in "hostile" areas, etc.)".  Right.)
The people like us who would implement it won't.
But it's technically possible.  The technological issues are the
easy part.   Creating a new email system is one thing, getting people
to use it is another.  This idea is pretty unrealistic...  sort of the
Underpants Gnomes plan for ridding the world of spam:
1. create completely new parallel email system
2. ???
3. no more spam!
I read it as the Pit is a signature over the Pit contents
and the email.   It'd include the certs needed to authenticate
to the appropriate CA.  A PKCS detached signature or
similar structure would work fine.
The crypto part is the one part that's easy.
See the 'getting people to use it' argument above.
Solve that and any of 20 different technical solutions would work.

@_date: 2003-05-16 10:22:48
@_author: Eric Murray 
@_subject: using PoW + filters to avoid false positives (Re: Re: A Trial Balloon to Ban Email?) 
There is already a reasonably good proof-of-work mechanism built
into SMTP-- START_TLS.
Any server that is willing to do TLS with mine is very unlikely
to be a spammer.  In fact a quick check of about 8000 spams I have
shows that two of them used TLS.  (both in the last week.   hmm.)
While it's true that the TLS protocol allows a client to subject
a server to a DOS attack by getting the server to do the expensive
crypto operation first (as the Dean & Subblefield paper points out)
in order for a MTA to deliver mail, it's got to complete
the TLS handshake.
So, to fix the spam problem, all we have to do is require START_TLS. :-)
Now, to generate an 8192-bit key....

@_date: 2003-10-01 11:41:46
@_author: Eric Murray 
@_subject: Monoculture 
Yep.  It's a bit of work, and more work to ensure that
there are no programming bug type security holes, such as those
recently announced, but it's not rocket science.
Yes and yes.  Most SSL/TLS implementations let the application designate a
set of certs as trusted CA certs for purposes of authenticating SSL peers.
If his client is programmed to let him, Bob can delete Eve's cert from
the trusted CA list.  Many browsers let you do this although it's often
hard to find in the config menus.
For (b), Bobs client would need to be able to mark Bob's copy of Alice's
cert as "trusted" even though its not a self-signed CA cert.  This is
also just a matter of programming, but most browsers don't let you do
this-- their programmers decided that in order to simplify operation,
they would not allow browsers to mark non-selfsigned certs as trusted.
The SSL/TLS spec is pretty quiet about what peers use to authenticate
the certs that they receive.  You'd be free to implement a PGP-style
web of trust in your TLS implementation as long as the certs themselves are
X.509 format.

@_date: 2003-10-01 17:16:18
@_author: Eric Murray 
@_subject: anonymous DH & MITM 
No, it doesn't.
The non DH suites are there in the spec for use when
your security model allows.  Not many uses of TLS do.
Last time I checked, which was a while ago now, very few deployed
https servers offered anon DH suites.  Which is appropriate
since MITM breaks the https security model.

@_date: 2005-12-14 15:34:29
@_author: ericm@lne.com 
@_subject: crypto for the average programmer 
An application programmer who is using PKCS1 doesn't even need to
know the small amount of ASN.1 in the spec... libraries that
implement RSA PKCS1 take care of the ASN.1 for the programmer.
There's no need for the consumer of a crypto API to look into the
bigints that make up an RSA key.  Even if you did for some
reason, many APIs I have used don't represent RSA keys at the
API level with the ASN.1, they use their own bigint format.
The part you need to look at is the padding, and even for that
you will be using some library's padding routines, not writing your own.

@_date: 2005-02-04 06:58:18
@_author: Eric Murray 
@_subject: Using TCPA 
I have an application for exactly that behaviour.
It's a secure appliance.  Users don't run
code on it.  It needs to be able
to verify that it's running the authorized OS and software
and that new software is authorized.
(it does it already, but a TCPA chip might do it better).
So a question for the TCPA proponents (or opponents):
how would I do that using TCPA?

@_date: 2005-09-12 07:25:25
@_author: ericm@lne.com 
@_subject: Is there any future for smartcards? 
.  I've
A company I worked at developed a secure smart card reader/keyboard in
1997/98 .  It had a display and enough crypto capabilities that it could
do the cardholder side of SET.  It would get the PIN or fingerprint
from the user, use that to unlock the card, then verify the merchant's
signature on the payment request it got from the PC and display that to
the user and get acknowledgement before having the smart card sign the
payment message and handing that back to the PC to send to the merchant.
I spent a lot of time meeting with bankers and going to standards
comittees.  The credit card industry basically said "Very nice.
It's secure.  But who is going to pay for it?"  The added security
wasn't worth the added cost (~$20 BOM cost) to the card card issuers.
The fact that it did SET and SET didn't go anywhere didn't help, but after
shoving SET on there, we could have put anything on (and did do EMV).
But no credit card issuer bought the concept.  They all said that if
we could get them deployed, they'd like to be able to use them.
The problem in the case of credit card issuers is that they aren't
the ones who bear the cost of card fraud-- the merchants generally bear
the cost of the goods stolen.  They just figure that as part of
the overhead.
Amex did at one point give out SET smart cards and dumb card readers using
code written by a competitor of ours.  The SET code didn't actually work,
and even if it had, there were no merchants using it.  The Amex card was
a cool partially transluctent card with the smart card 'bug' highlighted,
so it impressed clerks at Frys.  But that was all it was good for.

@_date: 2005-09-13 09:43:34
@_author: ericm@lne.com 
@_subject: Clearing sensitive in-memory data in perl 
There's been work on "secure" dialects of C. Cyclone
( is one.

@_date: 2006-07-29 13:40:23
@_author: ericm@lne.com 
@_subject: Noise sources: multi-oscillator vs. semiconductor noise? 
All the commercial RNGs are part of chips ("cores"), rather than
circuits made from discrete parts.  From what the hardware people I
have worked with have told me, the free-running oscilator design is
easier to get through chip-design software that generally considers
analog circuits to be errors.  It's also easier to simulate.

@_date: 2009-03-02 10:02:47
@_author: Eric Murray 
@_subject: X.509 certificate overview + status 
openssl will print certs in a more human readable but
slightly less complete format than dumpasn1:
% openssl x509 -text < cert
dumpasn1 does not read PEM, so you need to do
% openssl enc -d -c < cert > cert.der; dumpasn1 cert.der
It's a little old but RFC3280 is the most concise
and easiest to understand description of X.509 et. al.
that I have found.

@_date: 2010-08-26 10:10:02
@_author: Eric Murray 
@_subject: questions about RNGs and FIPS 140 
FIPS 140-1 did allow non-deterministic HW RNGs.  If you used one
then you had to run a boot-time self-test which, while not even close to an
exhaustive RNG test, would hopefully detect a HW RNG that had failed.

@_date: 2010-08-26 14:13:46
@_author: Eric Murray 
@_subject: questions about RNGs and FIPS 140 
Yes.  (assuming you mean FIPS certification).
Use the TRNG to seed the approved PRNG implementation.
That won't pass FIPS.  It's reasonable from a security standpoint,
(although I would use a hash instead of an XOR), but it's not FIPS 140
Since FIPS can't reasonably test the TRNG output, it can't
be part of the output.  FIPS 140 is about guaranteeing a certain level of security, not maximizing security.

@_date: 2010-07-12 10:36:38
@_author: Eric Murray 
@_subject: Intel to also add RNG 
I completely agree.  But HW RNGs are a pain in a lot of ways- modern chip
design libraries don't include RNG modules.  You have to make your own.
Verification software won't verify it and considers it an error.
When it runs it sucks a lot of power and generates a lot of heat.
Not a problem for Intel, but if you're using a contract fab (TSMC)
they probably won't guarantee that part of your chip will even work
because according to chip design rules, it's wrong.
Then there's FIPS- current 140 doesn't have a provision for HW RNG.
They certify software RNG only, presumeably because proving a HW RNG to be
random enough is very difficult.   So what's probably the primary market (companies who want to meet FIPS) isn't available.
So while I think it'd be great to have a decent RNG on chip
(no more blocking on /dev/random!) I don't see it being much of
a market advantage and would not be surprised if it never makes it in
to a shipping product.
Mixing the output with something else would address any lack of randomness
either deliberate or accidental... but still wouldn't meet FIPS.
BTW Intel isn't close to the first to put an RNG on a CPU chip. I worked for
a company in the late 1990s that did it and I'm sure we wern't the first.

@_date: 2010-07-12 13:13:44
@_author: Eric Murray 
@_subject: Intel to also add RNG 
Last FIPS cert I did (140-2, a couple years ago), it was SWRNG only. X9.62 or FIPS 186 or X9.31 or SP 800-90.
I couldn't even use a HW RNG for the seed.  /dev/random was acceptable.
True that.

@_date: 2013-09-05 13:33:48
@_author: Eric Murray 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
The NYT article is pretty informative:
"Because strong encryption can be so effective, classified N.S.A. documents make clear, the agency?s success depends on working with Internet companies ? by getting their voluntary collaboration, forcing their cooperation with court orders or surreptitiously stealing their encryption keys or altering their software or hardware."
"N.S.A. documents show that the agency maintains an internal database of encryption keys for specific commercial products, called a Key Provisioning Service, which can automatically decode many messages. If the necessary key is not in the collection, a request goes to the separate Key Recovery Service, which tries to obtain it.
How keys are acquired is shrouded in secrecy, but independent cryptographers say many are probably collected by hacking into companies? computer servers, where they are stored"
Also interesting:
"Cryptographers have long suspected that the agency planted vulnerabilities in a standard adopted in 2006 by the National Institute of Standards and Technology, the United States? encryption standards body, and later by the International Organization for Standardization, which has 163 countries as members.
Classified N.S.A. memos appear to confirm that the fatal weakness, discovered by two Microsoft cryptographers in 2007, was engineered by the agency. The N.S.A. wrote the standard and aggressively pushed it on the international group, privately calling the effort ?a challenge in ?Eventually, N.S.A. became the sole editor,? the memo says."
Anyone recognize the standard?

@_date: 2014-08-20 11:54:37
@_author: Eric Murray 
@_subject: [Cryptography] On 40-bit encryption 
You can find much of the background export control information on Bert-Jaap Koop's Crypto Law Survey:
Also good information on the various lawsuits challenging export control over the years.
One of the reasons for relaxing the export regs was that they were hurting US businesses.
The regs made creating crypto products much more complex as you needed to have different versions for different export regimes.
