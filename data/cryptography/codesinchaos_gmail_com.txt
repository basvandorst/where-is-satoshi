
@_date: 2013-12-23 16:05:25
@_author: CodesInChaos 
@_subject: [Cryptography] BitCoin Question - This may not be the best 
Collisions in bitcoin addresses don't matter. An attacker doesn't gain
anything from generating two private keys mapping to the same address.
They need to match an address currently owned by somebody *else* that
contains a non negligible amount of money. This is a variant
of a multi-target second pre-image attack.
For example if there are 4 billion addresses with non negligible money
in them in use at the same time (currently there are much fewer),
an attacker will need to generate 2^160/(4 billion) = 2^128 key-pairs
to match steal a single one of them. This is too expensive for current
Or a different way of looking at it: For 2^160 work, an attacker gains
the total value of bitcoins, something like 20 billion USD for now.
This means that they
gain 1 USD for every 2^125 key-pairs they generate. The cost of this
attack *vastly* exceeds the gain.
In general bitcoin has been designed for a 128 bit security level:
* Where collisions are threatening, use 256 bit hashes => 2^128 attack cost
* Where collisions are irrelevant, but multi-target second-pre-images
are a threat, use 160 bits, which for 4 billion targets results in a
2^128 bit security level
* 256 bit ECC which can be broken with 2^128 effort.

@_date: 2013-12-30 04:29:36
@_author: CodesInChaos 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
C# has the using statement, which is a bit of syntax over try-finally,
probably similar to try-with-resources in java. Typically looks like
using(var file = File.Open(path))
  // do something with file
For C# it works like this, for java it's probably similar: For
disposable classes that implement both `Dispose`/`Close` and a
finalizer, when the GC attempts to collect the object it runs the
finalizer which releases the resources. But there are some issues with
* The GC can collect the object much later. So if your resource is
expensive, that can be unacceptable. For filestreams it might keep
files locked for an indefinite amount of time. This is the main reason
why manual disposing is recommended.
* there are some tricky cases regarding multi-threading and locking
* finalization happens in undefined order. This can be tricky if
resources depend on each other.

@_date: 2013-11-10 14:14:57
@_author: CodesInChaos 
@_subject: [Cryptography] NIST should publish Suite A 
How would you verify that the published "Suite A" is the real Suite A?

@_date: 2014-04-23 23:50:20
@_author: CodesInChaos 
@_subject: [Cryptography] swap needed, or not 
If you have no swap space available (even if never used in practice)
you need to either overcommit or you waste RAM, since you need to
reserve physical memory for every potential copy in a copy-on-write
scenario. While that memory can still be used as read cache (since
those can be discarded at will), it can still be limiting when you
have a lot of sharable memory.
Windows chose to reserve commited memory, unixy systems usually overcommit.

@_date: 2014-06-13 21:44:06
@_author: CodesInChaos 
@_subject: [Cryptography] ghash.io hits 50% of the Bitcoin compute power 
What kind of mining protocol does this pool use?
* The pool builds the block, decides on the transactions etc. The
miners are just dumb nonce incrementing slaves (modulo whatever tricks
are used nowadays to work around 32 bit nonces efficiently).
* The miners gather transactions and build blocks by themselves. The
pool pays them for work if it's the target of the coinbase
While such a large pool is problematic in either case, it's much more
severe with the former protocol compared to the latter protocol.

@_date: 2014-10-14 10:34:21
@_author: CodesInChaos 
@_subject: [Cryptography] factoring small(ish) numbers 
512 bits is certainly in the breakable-by-a-hobbyist range using
existing applications:
Tom Ritter wrote a how-to:
It's not using a single computer, but rents cloud resources for about $100.

@_date: 2014-10-25 13:33:41
@_author: CodesInChaos 
@_subject: [Cryptography] Simon, Speck and ISO 
I'm not sure if "weak against differential cryptoanalysis" is an
accurate summary of those papers.
These are attacks against round reduced versions of the ciphers, and
every blockcipher suffers from such attacks.
The important question is how many rounds are broken by these attacks.
In the case of SIMON/SPECK roughly half the rounds are broken. This
isn't exactly a confidence inspiring security margin, especially
considering that these are the first analysis results. On the other
hand it seems hardly surprising that the security margin of
lightweight primitives is lower than that of conservative designs like
If you want to argue for the exclusion of these ciphers based on these
cryptoanalytic results, it'd be nice to compare this security margin
against the margin of competing lightweight ciphers. The opinion of
experienced cryptoanalysts as to how likely it is that this analysis
can be extended to more rounds would be nice as well, even if this is
inherently subjective.

@_date: 2014-10-28 21:53:40
@_author: CodesInChaos 
@_subject: [Cryptography] EMV as a fraud enabler 
If I read that article correctly, the main issue is that certain banks
didn't bother to verify signatures and as a secondary issue don't
bother checking nonce uniqueness either.

@_date: 2014-09-16 13:56:35
@_author: CodesInChaos 
@_subject: [Cryptography] RFC possible changes for Linux random device 
I like having a secure RNG that's fast, even for short messages,
so I like the idea in principle.
Getting rid of all those fragile fork related hacks is very nice as well.
Might have been lost in the summary, but using a fixed key is not a good idea
since it doesn't offer forward secrecy.
The simplest way to avoid that is using the first 32 bytes of output as new key,
pretty similar to what fortuna uses.
The problem with that is overwriting the key is that it requires synchronization
or thread local keys to ensure thread safety.

@_date: 2014-09-18 11:09:50
@_author: CodesInChaos 
@_subject: [Cryptography] RFC possible changes for Linux random device 
1) How would per-process keys interact with shared memory?
2) This interacts badly with forward secrecy

@_date: 2015-01-31 11:54:15
@_author: CodesInChaos 
@_subject: [Cryptography] Introduction to EC that is actually an 
Unless your audience has a lot of mathematical background and already
knows that, I'd spend a lot of time on explaining (finite) groups.
In particular:
* The additive group modulo n
   This group is very helpful for understanding the implications of
the group order. Prime vs. composite order, subgroups, when scalar
multiplication is lossy etc. This is probably the most intuitive
finite group, the main property it lacks is that DLP is easy (modular
inverse via extended euclidean). Operations on scalars are always
performed in this group.
* The generic group model
   Here group elements are simply a blackbox around scalars that only
allows a few select operations. Now DLP is hard and you can do
Diffie-Hellman, Schnorr signatures, etc.
   Generic attacks like Pollard rho work, which explains why the
security is at most the square-root of the order.
Then introduce elliptic curves as a concrete way to construct a good
approximation of the blackbox used in the generic group model.

@_date: 2015-06-01 20:54:16
@_author: CodesInChaos 
@_subject: [Cryptography] [FORGED] Re: Why is ECC secure? 
One of DJB's 64 bit asm implementations of Curve25519/Ed25519
contained a carry bug. I'm pretty sure that this bug allows key
recovery when using a long term DH key.
As far as I can tell, nobody actually used this implementation. But it
shows that even with a nice Montgomery curve you can get a hard to
detect bug that allows key recovery.

@_date: 2015-03-19 18:51:29
@_author: CodesInChaos 
@_subject: [Cryptography] Kali Linux security is a joke! 
A collision attack requires attacker control over the original file.
In that case MD5 is utterly broken.
This would matter if the maintainer decided to produce two packages,
one malicious and one harmless with the same hash.
But if an attacker has no such influence they need a second pre-image
attack against the hash.
The best public (second) pre-image attacks are slightly faster than
brute-force and thus far from practical.
MD5 certainly isn't a great choice, but for software fingerprints it
isn't that big a risk.

@_date: 2016-06-07 13:39:41
@_author: CodesInChaos 
@_subject: [Cryptography] GNU's "anonymous-but-taxable electronic payments 
How do you handle the case where GCD(m, n) != 1 where m is the message
(i.e. the full domain hash) and n the modulus? Do you reject that
message and generate a new one?
AFAIK zerocoin has unconditionally secure blinding but factoring the
accumulator modulus allows minting new coins. (I only looked into the
original zerocoin, not the newer zcash)
