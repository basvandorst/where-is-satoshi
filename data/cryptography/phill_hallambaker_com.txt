
@_date: 2014-08-01 17:26:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
The attacks are also a lot more expensive than one AES operation. So
we don't need to be precise to the bit. Work factor is not an exact
measure and nor is performance. They all depend on assumptions.
Performance differs on AMD, Intel, ARM, FPGA and work factor can
reduce dramatically when people are allowed to assume they have an
Exabyte of RAM for scratch storage.
Microsoft presented multiple options for the curve that we would still
need to consider the pros and cons for, not just twisted Edwards.
Here the competitors on offer are:
E-480 is not just slightly less secure than E-512, the work factor is
reduced by 2^16, that's 65,536 times less security than we asked for.
And the so-called 'Goldilocks curve' is twice as fast but the E-512 is
4 billion times harder to break.
E-521 is only an order of magnitude more secure and. It is a little
faster on typical architectures but dramatically slower on machines
with an internal 512 bit data bus like most modern GPUs.
So no, I think the argument for the 512 bit prime is pretty clear.
Note however that all the same arguments actually argue for accepting
Curve25519 even though it isn't exactly WF128
Yep, one reason I only use SHA-512.
No. I disagree.
Tell people to pick one or the other. They can have bleeding edge
performance with a curve that is chosen for speed or they can choose a
curve with no security compromises.
It is as simple as that: Performance or No-Security-Compromise.
I don't want you to be deciding that I should be using a curve that is
three or seven orders of magnitude less secure than I asked for in the
name of 'security'. If you want performance go for the smaller curve.
The problem is that the arguments have to be understood by people who
are not in the field. And that means that they have to be straight as
a die.
To start using these curves we have to explain why we are not using
the NIST curves. And that has nothing to do with performance. It isn't
even that we think they have been bongoed. We know who generated them
after all. If he could think up the seed for his RNG we might be able
to go back to using them.
The reason that we are changing is that we cannot make an unqualified
argument to someone not in the field that there is no possibility that
they have been bongoed. And once we put that possibility on the table
we have to make sure that nobody can raise the same argument against
We could argue for doing more than doubling the WF exponent but
anything less means we are eating into our safety margin.
Meet in the middle is always going to be of interest in an attack on a
function with an input and an output.
It depends on what machine you have for a start. Performance has
always been highly subjective.
Exactly. I don't think we are going to find performance is a useful
discriminator. It certainly isn't an interesting criteria for me at
If I want performance I will go for a shorter key.
I would not use DSA to authenticate the ephemeral key. I would use
ECDH to establish a master secret and use that to authenticate the PFS
exchange and derive the encryption keys as a one-way function of both.
That way I have WF256 encryption guaranteed and WF128 forward secrecy.
It also makes far better sense from the design of the handshake as it
saves a round trip.
The reason we used to use DSA with DH was to avoid the RSA patent. It
is not an approach I like because it creates a non-repudiable proof
that someone was a party to a communication which is information I
don't need to leave.

@_date: 2014-08-02 11:24:34
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
Once you decide on a safety margin you should meet it. I want a safety
margin that is good enough to maintain WF128 even if someone works out
the ECC equivalent of meet-in-the-middle.
The point I am making here is that when we are talking about making
compromises between speed and security we need to look at the actual
work factor, not its logarithm.
Going down from WF256 to WF240 is not a small change and going to
WF224 is a huge change.
Going from WF256 to WF254 is well within the margin of error measuring
performance and the argument might be stretched to WF250. But any
further and you are eating into the safety margin.
There are only two poles that are helpful here 'high security with
performance' and 'beyond any rational doubt'. Any ECC scheme that is
lower than WF250 is definitely going to create reasonable doubt.
Data paths come in binary exponent widths, there are machines with 32,
64, 128 and 512 bit data buses in common use. Choosing the strongest
work factor that does not exceed a data bus size is a really good way
to get rigidity.
The task here is to make a decision. Binary exclusionary criteria are
more useful than grey scale.

@_date: 2014-08-02 13:30:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
I am saying that the work factor rigidity argument constrains to a
range. But if you want strict rigidity then you match the prime size
to the data bus width which is an integral multiple of 64.
I don't think the work factor rigidity argument rules out Curve 25519
or E510. But it is an exclusion criteria for E480 and E448.
Curve 25519 then.
I seem to remember that you need rather more bits to get to WF256. And
there are backwards compatibility reasons that make using RSA16K
prohibitive. Most implementations have limits on the cert sizes they
will accept for understandable DoS reasons

@_date: 2014-08-15 20:18:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cost of remembering a password 
First year electronics lab we had a project where we had to build
stuff using stuff from the department stock. We had a budget of GBP15
and most of the parts were a few cents except for ICs which were more.
Potentiometers cost 20p for the part plus 5.00 for any manual
adjustment. The point of the project was you had to work out how to
avoid needing to use them.
So what would be an appropriate price in an application or Web site
design for requiring the user to remember a password? I am thinking at
least $25 and double that if the user has to append '1', '!' or '1!'
to pass the lame strength' tests people still insist on.
Not sure what the price for a CAPTCHA should be but there should
definitely be one. What really drags is when failing input validation
on a form requires the user to answer another CAPTCHA.
Perhaps if there was a cost penalty for using passwords, designers
would be more interested in using public key techniques that allow the
job to be done right.

@_date: 2014-08-16 14:47:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cost of remembering a password 
That is bad security thinking. The objective is to make things more
secure. And the baseline is passwords that we know are insecure.
Telling people that the alternative to their ox-cart is a Mercedes
does not help.
Most uses of passwords do not require any security at all. I would be
very happy to tell you my nytimes password if I hadn't used it at 50
other Web sites because I don't care about the security of the NYT's
assets, its the NYT that is bothered, not me. So transferring costs to
me is kind of stupid because I'm not the one interested in the
The point I am trying to raise here is that passwords do impose costs
even if they are hidden ones.
Most people have resorted to some sort of password manager for the
passwords they don't care much about. Rather than thinking of these as
competitors to secure, public key techniques, lets embrace them as a
transition strategy.

@_date: 2014-08-17 13:26:59
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cost of remembering a password 
Its not just considered trusted, it is trusted. So was MSDOS back in the day.
It wasn't trustworthy though.
Trusted Computing Group did not like it when I raised that nit at
their meeting...
Another area where common practice is utterly wrong.

@_date: 2014-08-19 11:00:03
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Which big-name ciphers have been broken in 
Responding to multiple threads,
SHA1 broken? Nope, it has been deprecated because the security is less
than the security advertised. But it has not yet been broken in the
sense of someone has created a collision. And Bruce is suggesting 2021
as the time for that:
There are plenty of ciphers that have turned out to be dodgy in that
way. IDEA for example. But MD5, SHA1, RC4 and IDEA are the only ones
that turned out to be seriously weaker than the design intent.
Now fortunately SHA1 being weakened is not really a big deal because
we have SHA2 already deployed in most browsers. And breaking SHA1 only
makes future traffic vulnerable, not previous conversations.
And even though SHA1 is weaker than expected, it is hard to see how a
collision attack compromises it for most of the situations in which it
is used since TLS and PKIX don't really rely on collision avoidance.
If an attack involves a trusted party that is not trustworthy then it
is probably a deminimis concern.
RSA2048 is really not a problem. It is RSA4096 that gives people the
real concern. The keys are huge but we are well over the knee in the
work factor graph and those extra key bits are doing almost nothing
for us. Hence the interest in ECC.
I agree with Victor that fallback algorithms should be upgrades, not
mere precautions. And I would like to see us move to a point where
every IETF protocol has exactly one mandatory to implement algorithm
suite, exactly one set of alternative algorithms in case there is a
need to transition and a set of acceptable algorithms that are
previous mandatory algorithms for purposes of interop.
Other than that, I would like the IETF out of the algorithm anointing
business altogether. Because once you start giving a code point for
CAST you have set yourself to give one to GOST and then you are in for
two dozen sets of national labs vanity crypto. Set the protocol up so
that other algorithms can be used, definitely. Create a registry where
anyone can get a code point for their algorithm, sure. But make sure
that there is no implication that anyone is sanity checking the
submissions because they are not and they can't check each one
anywhere near thoroughly enough.

@_date: 2014-08-20 16:22:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cost of creating huge theft targets [Was: Cost 
Which is of course the sensible thing to do unless you like liability.
Last night I went to a class on laser cutters. Their tube is mostly
made in Germany but it is sold to a company in China who fills it with
gas and ships it on. The main function of the company in China being
to 'fill the tube up with liability'.
It is important to cost out every step in the process even though we
know cost shifting is happening. Shifting cost does not mean shifting

@_date: 2014-08-28 14:01:33
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Google proposes a Web of Trust replacement to 
It is not necessarily a replacement
I proposed something very close.
The point is that when you fix an assertion in time, the cost of
forgery goes up to more or less infinity.

@_date: 2014-08-29 09:54:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Google proposes a Web of Trust replacement to 
Actually this could be an opportunity. If SKS is under threat in this
way then there is an incentive to move to a different protocol.
Yes we can move to a hash of the email address. But only after all the
clients are updated to the new protocol. This could be another PGP
only protocol or it could be a more general protocol that enables a
bridge to a next generation protocol. We don't need to know what that
is before we build the bridge.
Using a hash of an email address mitigates some of the privacy
problems but not all.
i can imagine that there will be some folk who only want to give out
their key to authorized parties who might be friends they have met or
friends of friends.
It is also going to be essential to lard up any repository with
honeypot entries.

@_date: 2014-12-04 09:34:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Why Alexander Hanff won't be using "Let's 
Well they seem to be making a push to remove the most important CA
operational criterial which is the insurance requirement.
When I worked with Michael Baum, Warwick Ford and Michael Myers at
VeriSign we established a system that was designed to provide a
demonstration that a CA was demonstratively in compliance with its
certificate policy. One aspect of that was audit, but audit is
actually a fairly weak requirement on its own as the existence of
corrupt audit firms like Arthur "Enron-Deloran-Sunbeam' Anderson.
Putting the insurance requirement in was a meta control on the audit
control. The reason insurance makes a difference is that the insurer
has skin in the game while the auditor does not. There is no penalty
for a sloppy audit but an insurer could be out a lot of money in the
case of a failure.
In the event DigiNotar failed in a manner that was not anticipated by
our original architecture which was to provide a commercial service to
enable e-commerce. Government actors were not considered in the design
and at the time most people thought that we were being overly
paranoid. Which given the number of failures since, we probably were.
The browser providers find a security bug in their code every week. CA
misissue is much rarer, so rare in fact that they decided they didn't
need to bother with the revocation/status controls.
One consequence of the manner in which DigiNotar was breached is that
the company was shut down and put into bankruptcy through government
decree. As a result the insurance controls were never activated, there
wasn't time.
The bigger problem with LetsEncrypt is understanding their finances
and whether they can support free certificates at Internet scale. And
while the marginal cost of issuing a certificate is negligible, the
fixed costs are far from negligible. It does not cost Intel very much
to run raw silicon through their fab. The biggest variable cost in a
chip is actually the carrier. But I just paid $500 for one of those
chips because Intel has to recoup the multi-billion dollar cost of
development and the fab.
Open source software works fine because a billion times zero is zero.
A billion times a 'negligible' cost starts to add up. Which is why
open services tend to be free on introduction and gradually become
limited and paid. My Verizon modem lets me subscribe to one of five
built in 'free' dynamic DNS providers. Guess what, none of them is
free any more for an unrestricted service. I have to keep renewing my
account every 30 days to get free.

@_date: 2014-12-05 18:46:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] cost-watch - the cost of the Target breach 
This suggests that it is Target's responsibility to maintain the security
of the card payment system rather than the banks
I do not agree. The banks have had ten years to deploy chip and pin which
would eliminate the breach. That was pure negligence on their part. Target
should not be held responsible when the banks decided that it would be
cheapest for them to not bother with card security.
This has worked out fine for the banks for as long as they have been able
to achieve cost shifting for the inevitable breaches. But they are the
party that is best placed to mitigate this risk so why should they be able
to recoup their losses from someone else?

@_date: 2014-12-06 20:28:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] cost-watch - the cost of the Target breach 
No he really didn't.
Chip and PIN is really difficult to defeat if the legacy magstripe channel
is disabled. Card present fraud is virtually non existent on chip and pin
and in particular large scale breaches like Target are not an issue.
If they were, it would be fixable.
There is a difference between going to sea in a boat that takes on some
water and going to sea in a boat with a giant hole in the bottom. Ross
greatly overstates his case.

@_date: 2014-12-07 08:31:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] cost-watch - the cost of the Target breach 
Yes, yet another attack against the legacy support for magstripe cards in
The US banks only have themselves to blame here. It certainly isn't a
merchant issue.
Relying on password security for financial transactions is stupid. Printing
the password on the front of the card is triple stupid with a side order of
The reason these attacks are taking place is the creaky financial services
network infrastructure. The US banks are so far behind their authorization
systems can't even reject the transactions as presenting an unknown
authorization system.
This is not a situation that Target or Home Depot have any ability to
control. The solution is 100% in the banks court. They have access to the
technology, they bear the loss, they should either eat it or pay to deploy
technology that would eliminate the fraud channel.

@_date: 2014-12-08 22:55:24
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] North Korea and Sony 
The hackers who rolled Sony are now allegedly threatening to destroy the
company by exposing all its company secrets if they publish a movie
critical of the tin pot dictator of North Korea.
While the Snowden files don't seem to have caused much of a push for
corporate security, this one might. Particularly if it turns out they are
not bluffing.

@_date: 2014-12-09 08:40:04
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] North Korea and Sony 
What worries me is that past performance is no guide to the future where
security risks are concerned.
Back in the 90s people got really comfortable with the idea that hackers
were just fluffy bunnies who were overly curious and would never try to do
something like steal money. The threat of organized cyber-crime was
poo-poohed as self interested panic mongering.
Today the threat of espionage against commercial targets is mitigated by
the fact that the people who steal the information have an interest in
preserving its value. China does not want to help its competitors with
secrets they have stolen fair and square.
Whether this is one disgruntled insider or a nation state, or both does not
matter unless you are in the shutting stable doors business. We know North
Korea has the expertise to pull of big jobs. And even if they weren't
behind it, their cyber spymaster will be tracking the Western press and
telling the dear serial killer, 'we didn't do this but we should start'.
It really would not cost a lot to perform a broad attack against commercial
targets. Pick the tope five in each sector. Dump data on one of those five
to drive them out of business. Then move on to the next. And fund the whole
exercise with side bets on the stock market, the ultimate pump 'n dump.
This is the real threat to the US economy. Hayden and Alexander built a
machine whose sole purpose is attack. Hayden has no comprehension of the
value of defense and his understanding of the importance of civilian
infrastructure is strictly tactical. He knows what he would attack, power,
water, etc.
The Snowden files show an organization that is entirely devoted to attack.
Even their defense efforts have to be presented as attack because thats all
the senior brass respect and its an up-or-out hunger games environment.
Since we have reportedly caused $140 billion worth of damage to Russia's
economy, it is no stretch of the imagination to expect that Putin might
expect to do the same back.

@_date: 2014-12-12 14:17:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Iranian Hack of Las Vegas Sands 
One question, why stop at messing up his casino? Assassination would be
cheaper, easier and possibly more effective.
There are probably several reasons but one is almost certainly that this
type of cyber attack is not considered a red line by anyone. Stuxnet
targeted an Iranian nuclear facility and could have been considered an act
of war. Iran chose not to.
Going after Adelson rather than allies of the President is also rather
interesting. It suggests that the Iranians (probably correctly) guess that
the administration isn't going to make protecting Adelson's pocket book a
As I keep saying on drones, what looks like a peachy idea when only we have
the capability turns into reheated turd when the other side can play the
same game.

@_date: 2014-12-12 14:23:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] When did zero day attacks become commonplace? 
Back in the mid 1990s, the idea an attacker would hit you with a 'zero-day'
was considered a mythical possibility. Anyone who suggested it might happen
was scaremongering. Then within the space of a few weeks they went from
being unheard of to routine.
I am trying to track down when the transition occurred for a talk. I
remember there being a sharp transition but I can't place when.
These government political cyberattacks seem to be following the same
pattern. I got a lot of criticism for attributing the attack on Comodo to
Iran. Until recently that attack and DigiNotar were still considered to be
I think that has just changed.

@_date: 2014-12-15 22:43:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Sony "root" certificates exposed 
There are three possible scenarios here
1) Only the certificate leaked, very limited security consequences
2) The internal CA was breached and induced to issue bogus credentials,
pretty serious.
3) The private key was disclosed, game over...
Secure hardware makes it pretty much impossible for (3) to occur unless
there is an insider attack or a physical attack. I am pretty sure there
would be no report for (1) so my guess is that (2) occurred.
Given Sony has hired lots of ex-NSA security staff over the years, (3)
would be an awful embarrassment for Fort Meade.

@_date: 2014-12-17 12:09:04
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
Ah but does China have access to the same source as the NSA?
Not suggesting that they don't. But establishing a means to prove that they
do could be an interesting challenge. And given the reported impact of
Snowden on Cisco's sales, possibly one that is commercially important. In
the post-PRISM age, every vendor is having to prove that it is not peddling
wares with backdoors for their local spy agency.
You would need to either provide a build chain that allows them to confirm
the executables they run were generated from the source provided or you
would need some Certificate Transparency log type solution, or maybe both.

@_date: 2014-07-01 11:19:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Preventing co-op notary defection 
One of the reasons that I am interested in BitCoin is that I want to be
able to ground the PPE PKI in some form of Certificate Transparency type
append-only log. For my purposes the proof of work concept is just not
viable (and I don't think it is viable for BitCoin either after the minting
So here is my alternative, a co-op notary which operates under rules that
are designed to make it coercion proof after some time t which is
sufficiently close to the current time (i.e. no more than one to 24 hours
behind depending on taste).
We distinguish between the following attacks
1) An attack in which a defecting or coerced notary rewrites the log output
for time t-n (n positive)
2) An attack in which a defecting or coerced notary rewrites the log output
for time t+n (n is >= 0)
We are only concerned with providing relying parties with an assurance that
the system is proof against the first type of attack. For the purposes of
analysis coercion and defection have the same effect. For the sake of
convenience lets call this an external failure.
The second attack is one example of an internal failure. An internal
failure is not considered a failure of the system but it might lead to
consequences and possibly the notary being booted from the co-op.
Another example of an internal failure would be if a notary failed to
provide their next state within the timeframe for the next update.
A co-op notary would consist of a set of notaries N_0, N_1, .. N_n each of
which is a peer. Ideally n should be sufficiently large to ensure that
coercion and collusion are improbable, 5 being a bare minimum, 16 being a
better one. But admitting members does impose an administrative cost and
there is probably little value in having n be greater than 64. If a very
large number of parties (thousands) wanted to run a co-op notary it would
probably be best to organize it as multiple co-ops participating in a
Membership of the co-op is dynamic. Members join and leave periodically. In
the case of a defection (or suspected defection) the members of the quorum
may vote to eject a member.
The co-op maintains a single log chain. For the sake of argument, lets
assume it is stored as a Merkle tree for efficiency but there are other
All actions of the co-op are recorded in the log-chain. These include votes
to accept/reject new members and votes to eject members.
At each time interval, each member m provides an input value I_mt (i.e. the
head of their local notary chain) and a Signature value S_mt described below
The output of the log chain at time t is O_t
O_t+1 = H ( O_t + I_st + S_st)
Where I_st is the set of input values and S_st is the set of signature
S_m = Sign ( t + O_t + I_mt  + X , k)
Where X is some additional information that might turn out to be needed and
Sign (x,k) returns x along with the signature of x under key k.
X would at minimum include all the signed votes cast by that member.
Ideally the set I_st and S_st should be complete, i.e. have an entry from
every member. But that might not always happen. One possibility is that the
member comes under a DoS attack.
Each member is obliged to publish the S_m value within some fixed interval
of a new output being decided. This would be to a publicly visible site
that can be seen by relying parties.
Each member fetches the S_m values from every other member and publishes
them on their own site.
Each member is obliged to publish its best proposal for the set S_st' and
thus the next output of the log chain some time interval before it is due.
Each member would then review the proposals and cast a (signed) vote for
what they believe the next S_st' should be. A majority being required for a
decision. Each notary being obliged to vote for the proposal that includes
the most information.
If a notary produces multiple signed outputs for a given value then that is
a defection and on the signed proof being published members would be
obliged to exclude data from that notary unless and until there was an
affirmative vote to include it again.
If the number of members was very large it would not be necessary for every
member to vote on every time beat. Voting rights can be assigned
pseudorandomly using the previous O_t as the seed.
A key design objective of the proposal is that all that is necessary to
validate the future outputs of the log chain is to know the output value
for just one point in time.
Unlike my previous proposals it is not necessary to know any public keys of
the members. There are no quorate votes. Everything is in the archived log
chain. One trusted output value suffices to validate the certificates that
can then be used to validate the future log values.
For the sake of efficiency, the current state of the notary membership,
their signatures keys, etc. could be recorded in a 'crib' that is agreed
upon by the members and included in their signed outputs.
A relying party looking to verify a notary output may do so with varying
degrees of trust.
* Always rely on one given member (e.g. US courts might be required to rely
on the NIST value).
* Always rely on one randomly chosen member.
* Choose a set of members and rely on a quorum of signatures.
* Check every signature from every notary.
One nice feature of the co-op approach is that it allows for gradualism.
The co-ops could be started by grad students at universities and as
reliance on the system grows, the functions might be taken over by their
Commercial providers are interesting in that they bring an exceptionally
high level of resources compared to institutions or even government
departments but they are inherently short lived. Google and Facebook might
look like they will last forever but so did Netscape and Sun and DEC. IBM
once looked more permanent than any of them and it isn't a major force in
the businesses it once used to rule.

@_date: 2014-07-06 22:15:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Preventing co-op notary defection 
Somewhat, and that is similar to a scheme I have proposed in non-bitcoin
contexts before. The difference is the level of detail.
The change over my previous iterations is that I originally assumed that
the members of the association would have to be very carefully selected and
agree to operate the service essentially forever. A bit like being a DNS
root. The only way out is to pass the responsibility on to someone else.
I now think that the co-op can be a lot looser and essentially
In particular a concern I had before was that a notary could defect by
refusing to notarize an input and required a super-nortary to decide what
was going to be signed. Closer analysis suggests this possibility can be
controlled if the members of the co-op monitor each other and vote for the
next hash to be signed.
So yes, your mintettes are voting in a similar way but as part of a
"central authority". I think the voting scheme brings sufficiently
effective controls as to dispense with the need for a central authority. I
think it is possible for it to become a genuine peer scheme with loose
Maybe not such a big step technically but I think it would make a huge
difference to how certain parties would accept the scheme.

@_date: 2014-07-07 08:38:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Preventing co-op notary defection 
Well I'm not actually interested in the currency problem so I haven't
considered whether the consensus approach is sufficient for them.
The log contains all the administrative decisions of the co-op. So given
one valid checkpoint the RP can roll forward to get a current state that
can only be bogus if a majority of the co-op members defected.
Well it depends on whether you take loose binding to mean that the members
are chosen at random with no filtering at all or if you accept that there
is still going to be filtering but the trustworthiness of the system
doesn't rely on it being absolutely accurate.
I was not thinking that the notaries would be random anonymous volunteers.
Obviously there have to be controls in place to prevent a majority
defection which means that attempts to set up sock puppet notaries have to
be avoided.
And whether the system is viable is going to depend on what use you attempt
to make of it. As the Paypal folk found out, everything changes when money
is involved. Paypal's initial fraud rate was devastating. One of the
signals that BitCoin is going to have an ugly future is the fact that so
much of the infrastructure is based in countries where organized cybercrime
runs rampant.
Designing a system that is acceptably secure against an adversary averse to
publicity, armed with legal threats of limited territorial extent is
entirely feasible. If the attackers are looking to make billions in bitcoin
then its more likely the coercion will include threats of or actual murders
and the system falls down.

@_date: 2014-07-14 10:26:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Security clearances and FOSS encryption? 
What it is meant to do is to discourage the worst security risks from
applying in the first place. It also ensures that an enemy attempting
blackmail has to dig deeper than the positive vetting process. And in the
pre-electronic age that would be difficult to do without making a lot of
The possibility of subversion by government agencies is always going to be
there, if not Ft Meade then the Kremlin, IRG, etc. The only difference with
Ft. Meade is that we do actually have a possible defense in moral suasion.
Snowden defected because he believed that the NSA had crossed the line and
became a threat to democracy in the US. So the question needs to be asked
where the line should be drawn. And this is an issue I have discussed with
ex-Directors of the NSA so don't dismiss my analysis out of hand as overly
left wing/libertarian.
Ft. Meade isn't the enemy.
Its the people inside and only some of them that are the concern. One of
the first things I learned in politics was that everyone has their own
agenda and that almost none of the people who get to the top give a hang
about patriotism or the good of the country. They like to think that they
do but they find excuses and pretexts for considering their own self
interest the national interest.
The US government is not the enemy but its agencies are the only threat.
Yes Putin is a dictator slowly turning Russia into a Fascist regime. They
have done Communism and it is discredited, Fascism is the only political
model they have left. But at the end of the day Russia has 750K men under
arms and most of their equipment is from the 70s at best. Russia can barely
keep hold of Crimea and has been forced to abandon attempts to annexe East
Ukraine. Their least awful noncontiguous ally is Iran (!) China has
deliberately entangled its economy with the US so that a war between the
two would destroy both, it is thus not a threat either.
The problem with Ft Meade is that (1) it is a military organization that is
spying on the bulk of the civilian population (2) Until the mid 1970s a
country was far more likely to suffer a coup by treasonous colonels than an
external invasion. (3) Most of those coups, including many against
democracies were engineered with the help of the Enigma type decryption
capabilities performed at Fort Meade.
Given the volume of anti-constitutional chatter on the right in the US and
the marked preference of the NSA/CIA for suppressing elected governments
they consider to be intolerably left wing, I see Fort Meade as a real
threat. So did President Eisenhower, quite possibly because the coup in
Iran was organized without his advance knowledge.
At the moment we have a lack of balance and too much concentration of power
in the hands of the NSA generals. Deploying strong civilian cryptography is
a necessary counterbalance but so is developing a set of norms for
I have been pushing for the adoption of a norm that we consider cyber
attacks of all types against civilian infrastructure in the same class as
terrorism. This is of course anathema to people who have built their
careers around attacking things and blowing them up.
I do not of course expect the adoption of such a norm to be immediately
observed by any side. But I do think that we can put a stop to NSA attempts
to sabotage civilian cryptography efforts. And if that happens it will be
in their interest to make sure nobody else is doing the same thing.
For years, I have been arguing that open source code is no more secure than
proprietary, it is only the small subset of open source code that has been
extensively reviewed that is more secure. I still stick to that analysis
except that there is now a caveat: Any code base that is widely used is now
going to be scrutinized for potential vulnerabilities by foreign and
domestic spy agencies. In the past the NSA assumed it was the only party
doing this analysis and kept schtum when it discovered something. What is
the NSA going to do now when it knows that the Russian, Iranian and Chinese
intelligence services are looking at least as hard as they are?

@_date: 2014-07-15 14:00:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Security clearances and FOSS encryption? 
Exactly, the people to worry about are the people who don't declare their
affiliations and/or clearances.
And that is why what the NSA did with the Bullrun program is such a
problem. How would a government spy be likely to behave?
One possibility is that they would be a very visible and prominent
technical contributor leading a major working group working for a company
like BBN or Van Dyke or SAIC or one of the other beltway contractors that
is likely a wholly owned subsidiary of the CIA/NSA from the days that they
had to conceal the funding sources to the black budget.
But another possibility is that they would be a less technical, non
technical type who was always willing to do work like write up reports or
drafts or chair a working group and you would wonder how they managed to do
so much without an apparent source of funds.
In other words an NSA plant looking to derail a project is going to look
just like the 10% of IETF members who do 80% of the actual technical work.

@_date: 2014-07-16 09:46:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] multi-key encryption of "meta" data 
Actually it was IBM and Microsoft who wanted to sell lots of high priced
consultancy that was the problem with WS-*
I have not exactly disavowed my role there. But I do now have a suite of
code based on JSON that does all the same stuff but the description is less
than 100 pages of RFC of which about half is worked examples.
I agree that we should redo mail. And this is one of the things that I
address in my scheme currently code-named PRISM-PROOF to be launched as
Privacy Protected Everything on Sunday in NYC.
The missing links that makes PGP and S/MIME unworkable from a usability
point of view are
1) No consistent infrastructure for key discovery
2) No mechanism for stating security policy
Security policy is the vital part. Before Alice sends Bob an email she
needs to know
1) What transport layer protections does Bob's email server support
2) What end-to-end protections does Bob support
3) What end-to-end protections does Bob prefer
4) What authentication would be required to use end to end
2 and 3 might look like the same question but they are slightly different
because Bob probably reads his mail on multiple machines and he might not
have his private key available on them all.
In PPE the solution I adopt is 'Phingerprints' and 'Phingers'. A
Phingerprint is simply a hash of the KeyInfo block of a master public key,
i.e. algorithm + key parameters. A master public key being the root of a
PKI, typically a personal PKI.
A phinger is a JSON document that contains certificates and policy
statements that are signed under a particular master key. The document
itself is not signed but individual policies may be signed.
So in this case if Alice knows Bob's Phingerprint his phinger can be
retrieved automatically via HTTP and the .well-known scheme. This can
contain answers to the policy statements above. It could also contain a
statement of the form 'I accept JMTP, the JSON Mail Transport Protocol'.
So a security policy distribution mechanism is also a mechanism that could
be potentially used for protocol selection as well. And I think it is clear
that any new protocol would make a clean distinction between protocol
metadata (Received headers) and content metadata (To, From, Subject, Date,
I don't think there would be any point to JMTP though. At this point we
have a whole rash of synchronous and asynchronous messaging protocols that
require different clients even though they are all much more the same than
they are different. An instant message is simply a short email. Chat, Voice
and Video are essentially just a messaging protocol where the peers talk
directly rather than through intermediary servers, Dropbox is just a
version of mail where the outbound MTA stores the bulk of the message until
the recipient requests delivery. Etc. etc.
Quite. I know that it would be much easier to design a new messaging
infrastructure that is secure de novo. Just as it would have been much
easier to work from the basis of PGP rather than S/MIME.
The reason I took the design choices I did is because it is the way that
Tim Berners-Lee approached the Web. In fact he was the person who persuaded
me to do X.509 in the first place. He didn't like SGML any more than I like
ASN.1. But SGML is what the publishing industry had standardized on.
So this has to be a multi-step process:
Phase 1: Give people as much security as is possible with existing mail
clients and protocols. PPE works with unmodified Thunderbird, Windows Live
Mail and Outlook. No plug ins required. Leverage the existing S/MIME and
PGP infrastructures.
Phase 2a: Improve the configuration user experience by migrating the mail
sending functions currently implemented in the PEEP email proxy into the
Phase 2b: Deploy a next gen key discovery infrastructure built on JSON/REST
protocols and Certificate Transparency approaches.
Phase 2c: Replace the existing PKIX/PGP trust models with a synthesis of
the two. PKIX end entity keys may now be used to endorse other end-entity
keys. All endorsements are timestamped by the notary infrastructure.
Phase 3: Introduce a new messaging protocol that is based on JSON/REST.
Now based on experience of using PROTOGEN, my protocol compiler, I could
deliver specs and reference code for phase 3 in about a week. But nobody
would be in a position to use them till we were well into phase 2.

@_date: 2014-07-16 13:22:26
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] VCAT report on NIST's process review 
ISO-9000 is really a standard for auditing a manufacturing process. The
purpose is to enable an astute and knowledgable customer to outsource
manufacturing. You still have to read the process descriptions that were
audited. Only those are often trade secrets(!)
It is the same with PKI. You can indeed write a CPS that says 'we give any
certificate to anyone who asks' and you will be fully compliant with the
IETF RFCs. You would not however be compliant with the CABForum Certificate
Policy requirements and your applications to get your root included would
likely be rejected.
BTW, the other thing ISO 9000 is really good for is documenting a
manufacturing process before shipping the jobs offshore.

@_date: 2014-07-16 18:00:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] multi-key encryption of "meta" data 
Exactly, any user defined policy has to be very very simple and high
level. But some policy details can be set automatically. But even that
is a little tricky. Experience from email spam control is that
security policies often need to be curated.
  The security policy that would make sense there would be something like:
That is actually more detailed than I would want a user to see.
The only policy that I would want a user to be setting is 'Encrypted
email is preferred' and there would be a warning box coming up to the
effect 'Hey if you set this then you will only be able to read your
email on devices that you have set up to get you private key, are you
The automatically generated policy elements would be things the client
can determine like the cipher suites it supports (so we can use AES
with S/MIME at last) and the transport protocol options.
To make ubiquitous end to end email viable it is going to be necessary
to have a mechanism to make it easy to update private decryption keys.
At the moment I am using a standalone tool. But this is obviously a
feature I would want to integrate into the clients themselves.
Each device is going to have a per-device authentication key and
encryption key that are permanent for the life of the device, never
get exported type keys. When the S/MIME key is rolled (i.e. once a
month) the devices pull their encrypted copy of the new private key
from a service via OmniPublish. This would also be used to grab the
new authentication keys as needed.
What I definitely want to avoid in the policy layer is complexity. I
do not see the need to make it Turing complete (like policymaker back
in the day).
To make the mechanism palatable to end users I am simplifying the
mechanism for configuring all the parameters an email client needs to
access an account. All Alice should need to connect to an email system
is her email address and the domain of her security provider.
Given those two pieces of information and a previously established
security context at the provider, client should be able to get all the
information it needs to connect to the email account via the security
provider, including any necessary authentication information. All that
the user would need to do is to accept the connection request from
their authorization device and they would get a question 'want to let
this new ipad to connect to your account'
The policy problems do potentially get rather more complex if we move
from email messages to documents in a CRM type system. My longer term
goal is to turn PPE (Personal Privacy Environment) into a CRM scheme
as well just as soon as the Wiener-Ford patent expires.
The reason this gets harder is that when someone sends an email
message they know who it is being sent to. When they write a document
deciding the intended readership is rather more complicated.
Given the abject incompetence demonstrated by the NSA in this area
with two major leaks in as many years, I think this is something that
NIST should be looking into urgently. It is clear that the NSA is
actually the International Insecurity Agency: Their only talent is in
breaking things. They have not done a good job of keeping stuff secret
that should be secret. That is they haven't provided the US with
security, that has not been a priority.

@_date: 2014-07-17 08:42:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] multi-key encryption of "meta" data 
Actually there was one main architect. The mistake I made was probably
to avoid kibitzing everything lest a design-by-committee result occur.
The big problems were over-modularization of the architecture and the
over-complexity of XML. XML is a document markup format and makes a
lousy data encoding. The problem is that every different WS-*
application can make its own set of choices. Since WS-* is
infrastructure it can't impose anything.
SOAP was really designed to replace DCOM which is already a
complicated mess. So you have XML which is overly complex, COM which
is a mess and a complicated architecture, what could go wrong?
But the other problem is that a lot of the specs are not really fully
specified as far as requirements go. They are like subroutine
libraries without the architectural document.

@_date: 2014-07-18 09:13:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] prismproof.org 
Having got the code out the day before, I spent yesterday putting up a
Web Site for Personal Privacy Environment (aka Prism Proof Email).
Found a style sheet developed by Twitter called Bootstrap that seems
to work pretty well, got it going in a few hours including writing the
This has links to all the papers, specs, videos etc. What I haven't
done yet is to put together an introduction to what PPE is and how it
works on the site itself. I'll try to do that after the Toronto IETF.

@_date: 2014-07-19 12:11:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The role of the IETF in security of the 
the net?
The thing about categorical statements like this is that they are
almost certainly wrong.
There is really no problem with a trusted proxy, the question is
whether the proxy is trustworthy or not. Consider the following
1) A trusted proxy run by Vladimir Putin (or choose your favorite war criminal)
2) A trusted proxy you run yourself on a machine that you deployed
situated in a secure location.
Yes, a trusted proxy might not be trustworthy. But it is certainly
possible to deploy a trusted proxy in circumstances that are more
trustworthy than the end point device you happen to be using.
I can't see a great deal of leverage in the approach but it might have
benefits. I certainly don't see any call to attack the IETF for daring
to consider it.
Conventional wisdom very frequently gets it wrong. It is really easy
to get obsessive about one security problem to the exclusion of all
others and to ignore the problem that is the real one.
So while a trusted proxy might not be the best idea, people who try to
slap the idea down without actually thinking about it are not
contributing to the conversation. In fact I am pretty sure that sort
of behavior is how the paid NSA trolls have discouraged consideration
of ideas that would cause real difficulty for their schemes because
they could be widely deployed in favors of crypto-perfectionist
schemes that will only ever be used by crypto-geeks and then only
So when people slap ideas down without giving an argument please
either ignore them or seriously consider the possibility you are being

@_date: 2014-07-19 22:50:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The role of the IETF in security of the 
the net?
Yes, a distinction that got me kicked to the kerb when I raised it in
a very early Trusted Computing Group meeting.
Only folk to see it my way were Microsoft and they were accused ever
after of doing marketechture using the right terminology.

@_date: 2014-07-26 11:58:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Ancient cryptography 
I have been reading Richard Carrier's On the Historicity of Jesus.
Leaving aside the main argument he makes, this depends on examination
of various ancient scriptures written by folk who believed they were
receiving divine messages directly or deciphering hidden messages in
existing texts.
Forget the religious meaning. This is an ancient form of digital signatures.
In particular the gospel of Mark (and much else) is written using a
structure called Chiasmus. Which is a structure ABC ... CBA. This
repeats many times with large and fine grained Chiastic structures
throughout the text. And Mark himself is surely giving away the key in
Mark 10:31 "But many who are first will be last, and the last first."
This was a very common literary form at the time and appears in the OT
as well, it is the reason why Genesis has two accounts of creation
back to back which mirror each other. That isn't an editing mistake or
two versions being mashed together. It is very deliberate.
So why would Mark write like this? Well leaving aside the religious
reasons, it makes it much more likely that the original text will
survive redaction by later scribes.
Lets say that there was some ancient controversy (for the sake of
argument use of motor cars) and some activist decided to settle the
matter with recourse to authority. He reads Mark, can't find anything
relevant so he decides to use the then popular technique of making
s**t up and inserting it. So he crafts a verse or two about the Lord
riding into Jerusalem on a Ford Model T (if he is pro cars) or
condemning a motorist (if not) and inserts it into the story where he
hopes nobody will notice.
This is easier than it might seem as all he needs to do is add in a
marginal note or at worst rewrite a whole page. Then he pulls out the
scroll and says 'aha'. But the chiastic structure is a dead give away
because any insertion on one arm of the structure has to be balanced
by an insertion on the other. Making one change fit the text without
sticking out like a sore thumb is actually quite hard. Particularly if
we are looking at a major rewrite such as Mathew's redaction and
expansion of Mark. Fitting the older text into an expanded work is
The chiastic structure is working like a tamper-evident marking for
the manuscripts. If a library happened to have two copies of a scroll,
one of which had been tampered with, the one with the better chiasmus
would be preferred for accuracy. Unless of course there were criteria
other than accuracy like suiting an agenda.

@_date: 2014-07-26 14:32:46
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
There was much discussion on new curves for ECC. The discussion looks
like it is down to choosing curves that are close to powers of 2 which
can be computed twice as fast as the traditional random curves in a
constant time implementation.
The choices on the table right now are the NUMS curves proposed by
Brian LaMacchia and co at Microsoft and Dan Bernstein's Curve 25519
One point of comparison of course is performance but it is actually
quite difficult to compare like with like. There does not seem to be
more than a 15% difference between any of them. Most of the other
differences fall away when the point compression patent expires which
I am told is a matter of weeks.
Another point that is important for me is consistency. I want as few
choices as possible. Given that the CA industry is going from RSA2048
with a putative work factor of 2^120 and all of these alternatives are
much faster and with much shorter keys, I can't see why I would go for
a 2^128 work factor. So I am only really looking for 2^256 work
So leaving aside the technical differences (which don't seem to be
decisive), and the choice of curve created with the primes (there are
twisted curves, Edwards, Montgomery etc), the main political
difference is that the NUMS curves do have a deterministic choice
procedure. The primes chosen are the largest prime smaller than the
nearest power of 2.
This does remove subjectivity from the equation but (possibly) comes
at a (modest) performance penalty.
Curve 25519 is close to 256 and its easy to make the argument. But
there isn't a convenient prime near to 2^512. When we come to choosing
curve E521 its a gut check sort of thing...
What do folks think here? I see a bunch of possibilities
1) We choose the NUMS curve for the 2^256 work factor curve and Curve
25519 for 2^128
2) We choose NUMS for both
3) We choose Curve25519 and E521
4) We spend several years arguing to no point
Right now my preferred choice would be either (1) or (2). It is a
split the baby approach but I think it would stick because the folk
who care about the NUMS argument are not likely to be interested in
the lower strength curve anyway. Meanwhile the folk obsessing about
speed tend to be more likely to go for Bernstein's argument than
Microsoft's even if its really BAL behind it all.

@_date: 2014-07-26 16:33:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
It isn't all I do. But these curves are being picked for TLS which
means they would impact PKIX which means they will effectively choose
the default curves for everything.
The reason I want 2^(128*2) as the work factor for public key is that
1) Long term public keys are the highest value crypto assets to
target. Getting one AES key does not buy very much unless one message
is fantastically valuable. Getting a public root key gives huge
2) There are attacks that reduce the strength of a crypto system to
half the bit size of the key, meet in the middle attacks for example.
But its hard to think of an attack that gives dramatically more
leverage than that. 2^128 is sufficient confidence to eliminate brute
force as an attack. Going to the square is a pretty good confidence
So I probably want 2^512 primes for my EC roots. I can't see a good
reason not to use that for everything.
I already use SHA-2-512 everywhere and truncate it if fewer bits are
desired rather than use SHA-2-256 and I will probably use AES-256 as
default as well.
I am not sure thats right. Dan is many things. More open to contrary
viewpoints than Brian LaMacchia isn't one of them.
Brian's argument for his curves is precisely that they are more
objective. They are simply the curves which are closest to the minimum
power of 2 necessary to give the desired work factor.

@_date: 2014-07-27 09:30:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
Should have said 15% for the curves, rather than the actual
parameters... But the problem in the meeting was there were two
partisan sides presenting the curves. Independent measurements are
The point is not whether you need exactly that amount of security. It
is whether you can argue that the curve has not been selected for a
hidden reason.
If it was a choice between A with exactly 2^256 and B with slightly
less it would be one thing. But once you open up anything less than
the full work factor its not just one alternative curve, its six or a
dozen. And the choice is subjective.
Absent a definitive way to choose between them, I can't really pick
any. Its back to the 2^512-x curve

@_date: 2014-07-28 22:17:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
No, we are a standards organization.
One curve with a work factor 2^128 for minimum security apps plus one
high strength curve with a work factor the square of that.
The approach you suggest was abandoned about ten years ago when we
discovered that the security of an application was determined by the
security of its weakest cipher. Adding strong ciphers does not make an
app more secure. Only stopping using a weak cipher makes it more
We do insist on algorithm agility but no more of the algorithm zoo
these days. So there is a requirement for a backup algorithm that is
believed secure if the base is broken. These are backups for RSA2048.
Yep, that is exactly what Microsoft did. The problem is that it is not
exceptional speed wise. The fast moduli are 2^521 and 2^480.
Curve 25519 (2^255-19) is quite a bit faster than the 2^256 curve. And
its arguably the same strength (what is half a bit?). But even so, its
a subjective argument that X% faster is worth losing a tiny bit of
security and the more bits get dropped, the more subjective it gets.
The other way to make the argument would be to say that for a given
amount of security, what is the fastest curve that delivers it. Which
means that we reject the shorter modulus and go for E521.
Its a good argument but still a harder sell than the NUMS argument of
'pick a strength, pick a modulus and choose the largest prime that is
less than 2^(strength*2).
Its not so much a technical argument as a 'how do we decide what color
to paint the bikeshed'

@_date: 2014-07-31 12:12:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
Its important to remember that organizations are made up of people. In
this case the person driving this is Brian LaMacchia who is well known
in the community. He set up the PGP key server most people still use
at MIT.
It also goes the other way. Saying 'I trust the NSA' is ridiculous
because it is an organization made up of people. I do trust some of
those people. But there are also some people in very senior positions
I don't trust and with cause. I don't trust them to tell the President
what they are doing, there is a long history of abuses there. And I
certainly don't trust them to interpret their oath to uphold the
constitution in a reasonable fashion. In fact its rather clear that
they model their interpretation of the constitution to fit an agenda.
At the IRTF meeting I suggested we split the baby and adopt 2^255-19
for fast encryption and 2^512-569 for signature and high security
encryption. I am thinking that is the right approach.
DJB does have some deployment momentum for his curve. There is a switching cost.
If someone is worried that the NSA has bongoed the curves or has a way
to bongo them then they should be using the 2^512 curve and not
Curve25519.It is pointless worrying too much about the minutiae of
lower security options.
Since I am doing PKI and static encrypted data, I have long term
security concerns and any decision I take now will have long term
consequences. I want 50+years security on stored data keys and at
least 20+ years on PKI key signing keys.
So for me 2^512-569 is the logical choice.
For the TLS group, there is a big performance issue and so a 2^128
work factor is defensible, particularly for PFS keys. I would even
defend deriving a 256 bit key for AES 256 from a 256 master secret and
a 128 bit PFS mixin.
DNSSEC is a trickier question. I would argue for the harder work
factor regardless but I can see how the key size could be a concern
given the constraints of DNS.
Of course, it almost certainly is the case that is Curve25519 takes
50% of the time that an alternative takes then cryptanalysis takes no
more than 50%. But that is fine. I care about the work factor ratio,
how much harder the problem is for the attacker than the defender
What would worry me a lot is if the work factor was reduced by a lot
more than half, like an order of magnitude.
That is an unsolvable problem. Particularly where GCHQ and NSA are
concerned. Nobody who is credible in the US or IETF crypto world is
more than one degree of separation from very senior NSA people or two
degrees away from the current NSA director and all the living
I know DJB and he isn't a good enough actor to be an undercover mole.
The NSA would have far more valuable work for him to do than peddling
bongoed crypto for use by US companies.
Another reason I don't think the NSA would be behind all this is the
NOBUS doctrine 'nobody but us' [1].
Peddling a set of curves that were created so that there is a backdoor
only the NSA can use is compatible with NOBUS. Only the generator of
the curves can use them.
These curves were not made by the NSA and any weird mathematical trick
that is hidden inside is a property of nature that the Russians or our
rapidly dwindling supply of national foes might find and use against
us. That would be contrary to NOBUS.

@_date: 2014-07-31 18:39:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
The requirement for a 2^512 bit prime comes directly from the security
requirement of WF256. And WF256 is currently the upper end of AES,
SHA2 and SHA3 key sizes.
Not really, we have no objective reason to believe they are more
secure and using random curves introduces the risk of them being
bongoed and thus require lots of controls that are not necessary for
the NUMS approach where there is only one solution for a particular
security level.
Yep, rigidity is good here.
Not if it was a public key system type property similar to using a
composite modulus in RSA (see Moti Yung)
Well that depends on whether they want public or private key to be
fast. To use ECC we have to go to Diffie Hellman and as someone
pointed out to me this morning, our performance advantage flips on
signatures from the verify being fast to the sign.
No, my specific concern is that there is a hole in the algorithm that
makes it vulnerable to a currently unknown form of cryptanalysis.
The most powerful general technique against non trivial crypto is meet
in the middle type attacks that reduce the work factor to half the key
length. So taking a computationally infeasible key length and doubling
it is a defensible choice.
We know that the reason that there is a 256 bit key size in AES has
nothing to do with a potential weakness in Curve 2^256-569.
As soon as you allow performance to factor at all it becomes
subjective. This is not a big problem for Curve25519 but it is really
problematic for WF256 where there isn't a clearly best curve. E521
requires a data path that is not a multiple of 64 which means that
dedicated hardware has to be very dedicated.
My current mobile phone is faster than the fastest computer at CERN
when we built the Web.
More choices is not necessarily better. We get a factor of two
improvement just by waiting 18 months.
If the protocol is designed right the attacker has to break the 256
bit master secret before they can attack the PFS mix in. One scheme
suggested being using the PFS data to give the IV. I have not checked
on the security of that yet though.

@_date: 2014-06-01 08:30:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What is going on with TrueCrypt? 
Well that might have been the intention. I know that in the past
employers have released under GPL rather than BSD precisely to prevent
competitors from making use of the stuff in their products.
As for not lawyering the license, that would only make a difference in
litigation. And spending a half million dollars to prevent someone
using stuff that you gave away for 'free' usually does not make much
There are two occasions where a corporate lawyer would read such a
contract. The first is when they are asked if the company can use the
product. And then they are going to give a very pessimistic view that
makes no account of any possible loopholes. They are only going to
make use of loopholes in the second when it comes to litigation.

@_date: 2014-06-02 07:50:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is it mathematically provably impossible to 
Why do we have to make such a fetish of the block chain being computed
by 'wading through treacle'?
BitCoin has achieve notoriety and fame but little else. it is a
complete failure as a currency, the float is purportedly worth $5
billion but nobody would claim that anywhere near $5 billion of
bitcoin commerce has occurred. Most of the transactions are endless
churning to create the illusion of activity.
We can achieve a robust notary infrastructure that is proof against
defection for considerably less money. Let there be 32 independent
notary log maintainers who maintain a Harber-Stornetta style hash
chain log (i.e. what is used in Certificate Transparency). Each notary
has very limited defection opportunities and any defection would be
quickly noticed.
Now let each notary include the outputs from the other notaries once
an hour. Now it requires every notary to defect for a defection to
succeed without being noticed.
Unlike the BitCoin system, this one does not waste more electricity
than is used by some nation states (currently they are consuming more
electricity than Cyprus). Further the possibility of the log being
rewritten is considerably less, the system is always predictable.

@_date: 2014-06-03 13:03:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is it mathematically provably impossible to 
A chained notary is only trusted as far as the last outputs that have
not been recorded by other notaries. So even in the case of total
collusion, default is very limited.
The organizations I am looking at to run notaries are
1) National laboratories e.g. NIST and its equivalents in Turkey,
Brazil, France, UK etc.
2) Certificate Authorities
3) The major engineering universities: MIT, Stanford, METU, Southampton
Now obviously there is a theoretical possibility that they all might
collude and default but it is pretty unlikely that they would and it
would certainly be noticed. I think that is far better in practice
than the BitCoin block chain with its known vulnerability to unwinding
Coming back to the subject line, I think it illustrates perfectly the
different between actual and mathematical proofs of security.
In theory one time pads are perfectly secure. But people who try to
use them in practice quickly discover that the many compromises
required to make them practical makes them much weaker in practice
than mechanisms that are not provably secure. The same objection
applies to quantum cryptography which is not unbreakable in practice
because the real world implementations have mechanical imperfections
that make them vulnerable.
I am not too interested in being able to prove an implementation
perfectly secure mathematically because I expect that a system that
limits the rate of default to an insignificant level is actually going
to be sufficient.

@_date: 2014-06-04 12:14:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] It's GnuTLS's turn: "Critical new bug in crypto 
Me too. I have a whole box of rubbish WiFi routers that died before I
bought an AirPort but even that won't reliably service a house with
multiple access points connected by ethernet on one SSID. The
configuration does not even seem to have been considered.
What I do find rather problematic is that people are not looking at
this as a system and ideology is being used as a substitute for
I was doing Open Source before it had a name. The whole of the
original CERNLib for WWW was in the public domain. Not GNU, not BSD,
public domain. And that was because no restrictions at all was the
best way to achieve the objective of getting people onto the Web.
But I have never argued that open source guarantees security or
necessarily even improves it. I have never found anyone who enjoys
reviewing other people's code. So the idea people will do code reviews
because something is open source is rather silly. There are a handful
of projects that do serious code reviews but I see those as code
review projects that happen to be open source rather than the reverse.
It does not surprise me then that open source software has bugs. What
does surprise me is that the response from some is 'well open source
is still better and the real problem is still the CAs'.
Well if the system was working right the problem SHOULD be at the CA
because the CA is the interface between the world of software and
hardware where we have control and the real world where we have none.
When I started working on the WebPKI my expectation was that the error
rate would be between 0.1-1.0%. I was wrong. It was so much lower that
most of you ignored all the technical controls that we specified
because you don't see the need for them.
Can we just agree that anyone who turns off revocation checking loses
the right to gripe or grumble about any other part of the WebPKI being
On the embedded systems thing. Well as people know I am writing a
protocol compiler, no have written a protocol compiler.
At the moment what you do is that you give Protogen a description of
the data that goes into the messages and press a button and out pops:
1) Code to implement a client API in C# and C
2) Code to implement a server that listens for the calls in C# (C to come)
3) Reference documentation in IETF Internet Draft format (HTML or XML2RFC)
4) A pony (planned for version 2.0)
It now takes me roughly two days to write a spec that includes
examples from actual running code (another part of the tool). This is
one I did in two days recently:
Oh and its all Open Source and up on Sourceforge
At the moment it generates code to implement the protocol in JSON over
either HTTP or UDP transport. But other transports and encodings can
be added.
Now where I am headed with this is that I have completely defined the
interfaces I need to the networking hardware. So now I have code that
can run on a very very minimal operating system. Something like ArdOS
which is a 1.6KB operating system for the Ardulino.
So if people were to take a look at my protocol compiler and check
that it did not put any backdoors into my code and some other folk
looked at a very basic multitasking plus networking layer, we could
use the combination of the two to arrive at code builds for devices
that we could consider to be fully verified.

@_date: 2014-06-04 13:46:33
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is it mathematically provably impossible to 
I have managed to construct formal proofs for very large real world
systems. But my approach is not one that I was able to make generally
usable as I spent my post-doc at CERN working on a network hypertext
system for publishing pictures of cute cats instead.
The way I generated proofs for the ZEUS data acquisition system was to
design a very very high level language that was specific to a task and
then generate the code and the proof together from the specification.
What makes the system work is that these are not specifications in a
generic language, they are specifications in a language for writing
FSRs or Parsers or a routing harness on a parallel processor.
The halting problem is irrelevant to these applications because we
don't have to develop a tool that guarantees to produce a proof of
correctness for every possible or even every valid input. The only
proofs of correctness that matter are the proofs for the code that we
actually generate.
This is the tool for building code generating tools. It is the tool I
used to build the protocol compiler I mentioned in the previous post.

@_date: 2014-06-05 08:35:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is it mathematically provably impossible to 
Its easy to show that the proof applies to the code, the validator
will check that.
The hard part is whether the code matches the actual problem which is
the real problem that proving the code matches the specification is
meant to check.
In practice I have not found a proof that the code matches the
specification to be the show stopper, its showing that the
specification actually describes the real world problem.
For example the problem I was given during my interview for a DPhil
place at Oxford: How do you write a specification for a sort. Most
people get that it has to be a monotonically increasing series but
only about 50% remember to specify that the output is a permutation of
the input. Now I had read Tony Hoare's Turing award address so I knew
about that one. But 50% were still failing.
What made me rather disillusioned about formal methods was that
problem, it is much harder for the average programmer to describe
their problem in Z or VDM than in the programming language they are
But that does not mean they don't work. Prof Hoare used to say that
waterfall development methods 'dont work', meaning that you can't
expect to write a perfect specification, implement it perfectly and
then test to see that it solves the problem. The understanding of what
the problem is will change during development. But as I wrote to him a
few months ago, that just means that the waterfall methods don't work
for the customer. They work brilliantly for the consultant looking to
extract the maximum rent from their victim.

@_date: 2014-06-05 21:38:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is it mathematically provably impossible to 
No, it is A threat model. Don't use the definite article when it does not apply.
And not a very good one. And there is still no possibility of default
that can't be noticed by an external passive audit party.
Collusion between the notaries only enables them to rewrite parts of
the log that have not been made public already.
I can't even revoke a few certs without someone decompiling Mozilla's
latest update, extracting the CRLs and squawking.
The NSA will do a lot when they don't think anyone will notice. The
term is 'NOBUS' Nobody but us. They do not do stuff that attracts
public attention. Threatening the German and Brazilian governments to
unwind a national notary to intercept private communications without a
warrant is not going to happen.
Remember that the current President of Brazil lived under the
government that Nixon and Kissinger installed with the help of NSA
intelligence. The US colonels helped the Brazilian colonels murder
some of her friends.

@_date: 2014-06-06 16:14:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is it mathematically provably impossible to 
I have always loved the Harber-Stornetta scheme for this very reason.
The notary is only trusted for the shortest possible interval.
Reinforcing the system is more about ensuring continuity of service
than anything else.
The big challenge has always been putting it to use. BitCoin has
inspired some useful stuff in that regard.
Actually no, the US state dept is not bound by NSA precedent.
The way I look at Putin's recent activities is that he is essentially
trying to duplicate the CIA tactics of 1953 and operation Ajax. The
Ukranian communications are probably completely visible to the KGB
because they installed them. So its like a CIA/NSA coup where the
plotters can read all the communications of the target. The use of
agent provocateurs etc was very much like the way the CIA hired thugs
to take down Mossadegh. One of those thugs being the Ayatollah
Khomenei which is why he knew about the coup and Carter did not. And
also the reason he had to get his people into the US embassy to
destroy all the evidence that he was a US tool in the 1953 coup.
But the tactics have moved on since. In 1953 democracy was a
distinctly minority form of government. The US and UK were pretty much
the only countries with more than a century of democratic traditions
and institutions. Most countries were run like Saudi Arabia and about
half the world population had a government like North Korea's.
Today there is no US sphere of influence, the US doesn't need one. 50%
of the world population lives in a liberal democracy. Almost
everywhere else is either getting there or trying to.
We can list the problem countries much quicker than the decent ones.
Being able to poke and pry into other country's communications is
destabilizing. And right now we are the ones interested in stability.

@_date: 2014-06-08 07:48:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Google "End to End" 
I did wonder why they were doing PGP when most actual use of
end-to-end email is S/MIME. Turns out the two systems have roughly
equivalent userbases, the number of certs issued by CAs is roughly the
same as the number of PGP keys registered. But we know that there are
government users required to use S/MIME every day.
But given the limits of working in Javascript, maybe it is a good
thing to start with the userbase that is not doing the mission
critical stuff for an employer.
But the main thing is that they are telling people not to worry about
their business model.
I have talked to a lot of Google folk about doing end-to-end secure
email in Webmail and none of them has raised their business model as a

@_date: 2014-06-09 12:52:34
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Swift and cryptography 
Looks to me as if they have backported the most important parts of the
C world to the C world.
What I want from a modern language is classes, single inheritance,
interfaces, properties and a clean syntax that does not
It would be interesting to see how they manage strings. Do they
support something like the C# 'protected' class...

@_date: 2014-06-09 12:42:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Yet more formal methods news: seL4 to go open 
Folk should remember that for the purposes of security, the most
important concern is not whether the algorithm is 'correct', it is
whether the code has buffer overrun, memory leak or access to
unallocated memory.
So we are solving a problem that is much easier than the 'Turing
complete' or 'AI complete' problems that people like to use as 'proof'
formal methods don't work. We don't have to prove every aspect of
every program to make advances.
But equally, a managed language such as C# provides the above concerns
for free. Which is why I switched from C as soon as the managed
languages became good enough and the IPR issues were clarified.

@_date: 2014-06-09 13:25:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Yet more formal methods news: seL4 to go open 
But the other reason to look at formal methods is that they stop the
protocol getting complicated.
Having learned formal methods I quickly discovered that the best way
to get to a proof was to start from a compact, well engineered
starting point. So I became rather intolerant of the 'five ways to do
everything' school of protocol design.
IPSEC did junk ISAKMP in favor of IKE in the end but if a formal proof
had been expected, ISAKMP would never have been suggested in the first
At the moment we have TLS and IPSEC which both have a full set of key
exchange and PKI management interfaces. And we have Kerberos that does
it all again in symmetric key with the option of using 40 different
authentication floozles. And each of these has the option of 50
different algorithms, a half dozen different key management policies
and they still don't do what a lot of folk want because the protocol
designers assumed that the scheme would be used a certain way and
baked their assumptions into the protocol.
If we start from scratch and separate out the problem of security
context negotiation from the packaging we can use one key
establishment mechanism to support any layer in the protocol stack
from IP, through TCP to Messages/Transactions.

@_date: 2014-06-10 17:36:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Bitcoin compute power (was Re: Aggregate 
Fortunately it probably does not matter much when 99% of all bitcoin
activity is hoarding coins that will magically go up in value when
bitcoin replaces the dollar.
The Internet removes the middle man, BitCoin is a Ponzi scheme that
removes the need for a Bernie Madoff running it.
I would be less worried about the open 51% attack than the covert,
unannounced attack in which the same organization fronts multiple
pools. Another big concern should be what would happen if the cost of
mining exceeded the cost of running an appreciable percentage of the
rigs. At that point the only way to make money would be to shut down
the rigs, let the difficulty factor ease off and then bring them back
in bursts to unwind the chain.

@_date: 2014-06-11 10:25:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Bitcoin compute power (was Re: Aggregate 
Yes, there are two breakpoints and that is where the incentive to
default comes in.
A guy who spends $1 million on a rig that is only producing $500K/year
worth of coins at a cost of $250K/year is not going to see a return on
his investment. But he is going to keep mining to limit his loses.
If someone then comes in with a new $1 million rig that produces twice
the coins for the same electricity it is going to look like a great
But as soon as that rig is in service (and everyone else upgrades
likewise) the difficulty goes up, lets say it doubles.
So now the old rig is only making $250K worth of coins and the new one
is just as unprofitable as the old. But it has to be run just to
mitigate the loses.
Unless the owner of that old rig shuts it down as it is now breakeven at best.
But what if one of those groups that has got close to 50% of the
mining pool suddenly brings a large quantity of its dark mining power
online? They can make money in the interval between starting to mine
with it and the point where the difficulty is increased.
BitCoin isn't a currency, its a free money scheme.

@_date: 2014-06-11 08:23:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Subject: Re: Swift and cryptography 
Well it all depends on the argument being made.
If the argument is 'yes you can do this in C++ if you hold your nose
while doing it' then its a valid argument.
If the argument is that the C++ way is so good that there is never a
need to consider doing it any other way then BS.
The problem of programming is how to get the intention of the designer
into machine code. A programming language, formal methods are only
tools to help to that end.
The way I view the problem, I want to reduce the mental gap to the
shortest span possible. I want the programmer thinking in terms of the
problem space.
This is of course what the functional language advocates claim they do
but I don't see that they succeed. All they have is a different model
of computing that is closer to one particular set of problems.
Crypto is a problem that is almost uniquely suited to a conventional
imperative language. So the question of interest should probably be
whether SWIFT is a language that would be useful as a medium for
interchange of algorithm specifications.
On the plus side it is certainly cleaner than C. But thats about it.
How easy would it be to convert AES code from SWIFT to C or Python? Do
they intend to provide a formal semantics that would allow the
conversion to be done rigorously?
Apart from that, they add array bounds checking to C and make it
ubiquitous. That is a major, major win for security code.
Unfortunately what it does not do is to provide a drop in replacement
for C.

@_date: 2014-06-11 15:47:24
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Languages, 
By close to the problem I mean something like this code I wrote when my end
to end email scheme needed a http client I can trust:
 Protocol Goedel.HTTP HTTP
Structure Common
String Content_Type
Integer Content_Length
DateTime Date
Structure Request
Struct RequestLine Line
Inherits Common
Struct QTag Accept
String Authorization
String Cache_Control
String Connection
Struct HostSpecification Host
String Referer
String TE
String User_Agent
That code does depend on some additional FSR code that does the RFC822
funky parse stuff. But if they add a header line to the spec and it does
not introduce yet more wierdness, just declare it there and the handler
code can access the variable.
The way I write user interface code is essentially the same: write out the
abstract code and let the UI compiler generate code for X-Windows or
command line or whatever.
C provides you with more ways to shoot yourself in the foot than anyone
could ever want or need. You have everything from pointy sticks to RPGs.
I am currently unwinding some code that was written expecting long == Int64
which would be the logical thing to do.
Rather more oddly, on a 64 bit machine size_t is defined as unsigned int!
I find that I can code art roughly the same speed in C or C Except that
is when I am spending a week adding features to C that I need like memory
management or the like or trying to resist doing the job properly and
working round C's lossage.
But will it be C with added bits or C with stupidity stripped out?
What I want is a language I can use to write code modules that don't
require a custom runtime and can run native on any platform.

@_date: 2014-06-13 09:46:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
But that is another area where formal logic can fail. DES is not a group,
but all it takes to stop something being a group is for one mapping to not
meet the criteria.
So lets say I am using the original Cesar cipher with a displacement of n
characters, A->D, B->E, etc.
This is a group because modular addition is a group.
But now lets say that we have a modified cipher which has a displacement of
n characters except that character n always maps to itself and so does the
character that would map to it.
The new cipher is not a group. But it is close enough to being a group as
to make no difference from a cryptanalysis point of view.
It is a similar problem with public key, people thought that an np-complete
problem would make a good cipher till other folk showed that heuristic
approaches break them.

@_date: 2014-06-13 12:46:46
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] ghash.io hits 50% of the Bitcoin compute power 
This is only a risk if you want to spend or transfer your coins. If you are
a hoarder it doesn't matter.
The mining pool has approached 51% attack territory before and the mining
pools split. The question is whether the fact that they didn't do that this
time round suggests they are getting sloppier.

@_date: 2014-06-15 09:59:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] ghash.io hits 50% of the Bitcoin compute power 
Oh great so now even the speculators have to mine to maintain the value of
their investments.
Maybe this is a clever way for a bunch of Ukranian/Russian cybergangs to
force someone to buy their bitcoin mining rigs that can never payback their
capital cost by mining.
It really is a self-Ponzi scheme. Once folk are bought in it is impossible
for them to escape unless they can persuade someone else that its a good
investment. So Bitcoin is like those lobster pots that get lost and sit
about in the sea with one creature after another going inside to eat the
bait then dying and becoming bait for the next.

@_date: 2014-06-16 10:16:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] ghash.io hits 50% of the Bitcoin compute power 
Nobody would do a 50% attack to unwind the whole stack. It would be
pointless to go back more than a couple of hours. Just long enough to move
the money somewhere else.
The prime directive of the longest fork is sufficient for any practical
attack. So the blockchain scheme does not really deliver any security value
over a network of Haber-Stornetta notaries.
But its also a mistake to think Gash.io can only defect by unwinding
transactions. If they have 51% of the compute power their most profitable
approach will be to simply ignore all the other miners and work extending
their own chain.
Lets say that the starting block is B_t another mining pool wins block
B_t+1. Gash.io can either switch to mining the new chain or they can
continue to mine from B_t. Both approaches have the same expected reward,
there is a 50% chance of 1 coin or a 25% chance of 2 coins.
Gash.io doesn't do any better if the mining network synchronizes
instantaneously. But they do have an advantage when synchronization takes
time because they keep mining the old block without a pause rather than
moving to the next one.

@_date: 2014-06-16 21:02:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Help please, 
So I am almost at the stage where I can loose PPE (Privacy Protected
Everything) onto the world.
I would like to do a sanity check on the design before starting to get
actual users since once you do that...
The ideas are
1) Ease of use must be as good or better than no security at all except on
the rare occasion where a user wants to confirm the level of security
2) Format agnostic: I am building on S/MIME right now but the approach
works with OpenPGP just the same.
3) Trust model agnostic: Must support direct, trusted third party and web
of trust models. Plus mixtures of all three.
4) One size (usually) fits all, no 'high security' or 'advanced user'
options unless there is a specific reason to believe that only advanced
users need SHA512 or AES 256 or might lose their key. Requiring everyone to
have split keys, a personal CA root etc. whether they think they need it or
not saves a lot of problems
So naturally I need to give everyone a personal CA hierarchy as follows:
1) Lifelong master root key, The hash of the public portion of this key is
the user's life long phingerprint. Cert has 100 year expiry, subject +
issuer name is the phingerprint
2) Subroot, is signed by the master root, valid for at least ten years.
Subject name is the hash of the subroot key
3) Static encryption key shared across all user's devices.
4) Device signature/authentication key that is unique to a particular
So if Alice lives 100 years she might have 2 phingerprint / master roots
for her whole life (assuming she creates a new one at 18), maybe a dozen
subroots. 1200 encryption keys and 400 or so device keys.
Only the master root key has to be escrowed outside the system and this can
be done through a paper based mechanism as discussed earlier on the list
and this is entirely under control of the person.
While (1) signs (2) using X.509 semantics for simplicity, the use of the
sub-root (2) to sign keys of type 3 or 4 does not need to be through PKIX.
This is where I want a JSON type format so that I can make statements such
'My encryption key for July-2015 if foo, it is preferred that all email is
encrypted using S/MIME and AES-256. The key may also be used with the
OpenPGP format.'
When people endorse each other's keys in this scheme they are going to be
endorsing their lifelong phingerprint corresponding to a masterroot, not
the subroot or use keys.
I see root keys and endorsements being entered into Certificate
Transparency like logs.

@_date: 2014-06-17 21:36:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Help please, 
Well first let me backtrack and say 'potentially lifelong'. I think many
people would want to rev their master key when they hit 18 for example.
But the point I want to get away from here is the assumption that key
management problems can be swept under the carpet by suggesting rolling
keys is a trivial issue.
To answer Ian, yes, there needs to be provision for someone being able to
say that 'this master key is no longer safe to use' and 'this master key is
replaced by that one'. But I think that statements of that sort are not
part of the PPE base, they are part of the trust systems that can be built
on the PPE framework.
The bottom line is that people can change their lifelong keys but doing so
except in the simplest 'roll over to this new stronger key' case is going
to introduce the risk that relying parties won't accept the change. Which
might of course be exactly what you want.
It is not yet in the code by where I want to go is that the master key is
encrypted [NOT as a P12, I don't trust the code, too damn complex, delivers
zero value.] under a strong algorithm and the key is split and the user is
given the two halves of the key which can then be printed out on paper.
The only way to keep a key really safe is not to have it in a computer at
 And if they aren't encrypted, then they will be
Banks have safe deposit boxes.
Most people would probably be more concerned about the mechanism to escrow
their decryption key. I an thinking that would use the same scheme but have
not come up with the mechanism yet.
I choose the passwords, they are random with 128 bits of ergodicity.
Court orders is another layer. I am not so worried about that though since
its lawful intercept which is a very different issue from a Junta of
Colonels deciding that they want to read mail of those suspicious hippie
types. Lets deal with PRISM and the rest of the illegal stuff first.
Again, this type of issue is something that is best left to the trust
model. And the idea of PPE is that you can build any trust model on top of
the provided tools.
I'm really not sure how the word simplicity can be honestly used in the
I have no problem with chucking a specification in the bin, standard or no.
And ASN.1 is horrible. And I am not even that bothered by 1 million S/MIME
and 1 million PGP keys out there: I think most of the people using those
would switch if there was an easy to use alternative.
The thing that I can't walk away from is 5 billion email clients that can
read encrypted mail sent to them in S/MIME format without the need for
additional plugins. I have to be able to read my email on any device if I
am going to set the 'please encrypt mail to me' flag but I don't
necessarily have to be able to send encrypted mail from my iPhone.
that will work without any additional work if the public key is presented
in a PKIX certificate. So the key manager has to do PKIX.
And that is why I have spent today working to make C# emit a certificate.
Rob tells me the ASN.1 is right but the signatures on the certs won't
verify and the private keys won't export despite being marked for export.
And Windows Live Mail can't or won't import them.
Now I am perfectly happy providing a second certification path using a
sensible format like JSON. Can do that in half an hour with my tools.
Personally, over beers, I'd say forget JSON.  Roll your own binary, you
Yep, already did that, I have a scheme JSON-B which is the whole of the
JSON tag set but with additional code points to allow blobs of binary data
and Unicode strings to be specified as length delimited chunks of data and
numeric codes for integers and floating point.

@_date: 2014-06-19 08:27:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Help please, 
As many as they like.
I have not fully considered how this would be applied to authentication.
The system has the ability to create strong identities but any system that
can create strong identities can also be used for creating weak ones.
As a practical matter Facebook has never deleted any of my 100+ accounts
and the only one they have ever frozen is my real one. Oddly enough some of
my fake ones get more friend requests than the real which suggests to me
that I'm not the only person doing that sort of thing.
The problem that would arise is that if there is a system for creating
strong identities, sites might insist on their use. And there is a good
reason they might want to - spam. Unfortunately there are also many bad

@_date: 2014-06-23 20:26:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What has Bitcoin achieved? 
And for there to be more real transactions and not just endless churn to
give the appearance that Bitcoin is taking off.
But one of the central conceits on which BitCoin is based is the idea that
it is 'proving' that the system works when the real BitCoin system has not
started yet. Everything will change when mining stops.
25 BTC every ten minutes is what, $1.8 million/day? I am pretty sure that
even within the ideology on which BitCoin is based, the injection of
$2/million a day of new currency into a system that maybe supports that
amount of external economic activity in a month must have a huge effect.

@_date: 2014-06-24 00:02:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Help please, 
I have thought quite a bit about that scenario having had to deal with it
clearing up estates. There are secrets that might want to be divulged after
I am gone (details of all my bank accounts, the apartments where I keep my
mistresses, etc.) And there is information that I want to be destroyed.
One thing I learned from the Web is that it takes people time to get used
to the technology. We had blogs with comment forms in 1994. They didn't
really take off till 2000+. Same thing with social networking, there were
dozens of failed attempts before Facebook.
Only some of this is people coming up with the right idea. A big part is
that people had to get used to hyperlinks and forms before they could move
on. Web 2.0 was really about rebranding what Web 1.0 was meant to be about
all along.
In the short term probably what we need to do is impress on people that
fear of a warrant is probably less important for most people than losing
their entire life digital history, photos, documents, etc.
But for those of us who have had Anna Chapman attend seminars with us...

@_date: 2014-06-25 19:48:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] a question on consensus over algorithmic agility 
Exactly one preferred algorithm and one backup algorithm per crypto
function and this should be consistent across all protocols.
A problem with mix and match crypto is that people mess up with assumptions
such as stream ciphers being secure against known plaintext attacks and
such. 'Never send a stream cipher to do a block cipher's job' as Jon Callas
said to me once.
Then there are the attacks against the negotiation mechanism.
This is a draft I was asked to write on this but nobody seemed interested
The idea here is that there would be two algorithms, a primary and a backup
that are MUST and SHOULD compliance requirements. Specifications must still
be agile to allow the use of any algorithm but the mechanism need not be
efficient or pretty. So I would have no qualms about requiring algorithms
to be specified by ASN.1 OID injected into the slot for ciphertext as a
prefix and junk all the per protocol algorithm registries.
I am not sure what the question is here.
I certainly don't believe in frameworks for negotiating key exchange
mechanisms. Just have one algorithm and do the job right.
When we designed IPSEC, PGP and S/MIME RSA was expensive. Even at 1024 bits
it was a notable machine drag. Today I was testing a key manager for
Prism-Proof-Email which generates 4 2048 bit keys when it initializes a
user's personal PKI hierarchy and found it was only a minor inconvenience
testing the registry setting routines.
In 1995 the choice to do an ephemeral key exchange made sense. Today, just
do it, it will take longer to find out if you need it than to just do it.

@_date: 2014-06-30 15:01:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] a question on consensus over algorithmic agility 
Not really.
The reason I specify AES as the mandatory to implement algorithm in
protocol specifications is that it is the only algorithm currently in use
that satisfied all the following criteria:
1) Informed option considers the algorithm to be acceptably secure for all
encryption applications.
2) Is the result of an open selection competition that is generally agreed
to have been reasonably transparent and to have made the decision on
empirical grounds,
3) Is ubiquitously supported on all platforms including hardware.
A new more complex algorithm would not meet those criteria. But that is OK
because my criteria for a backup algorithm are not the same as my criteria
for a default algorithm. I am quite happy with the idea that SHA-2 is the
current mandatory to implement algorithm (because even though it was not
developed in an open process it is the defacto standard) and SHA3 is the
mandatory to implement backup algorithm.
We do need a replacement backup algorithm for symmetric encryption though,
it is the only major algorithm class that we do not currently have an
acceptable replacement algorithm for. It is easy to see that we will in due
course transition from RSA+DH to some variation of ECSignature + ECDH and
the only thing holding us back is Patent FUD.
It is about time we had another cryptography competition. And I have at
least one sponsor interested in funding part of one. Just about the right
time has elapsed since the last one.

@_date: 2014-06-30 16:19:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] a question on consensus over algorithmic agility 
Of course the primary has to be (almost) completely trusted. But you also
want to plan ahead for the next transition. And at a given time you might
be at a different stage in the lifecycle of your different algorithms.
The backup is always the candidate for the next primary so it should make
use of a different principle to the primary (SHA2 was a bad choice of
backup for SHA1)
I suggest the following stages:
Green: You have a primary algorithm and you are 100% happy with it. There
is no backup
Amber: You have a primary algorithm that you are less than 100% happy with,
there is no backup
Red: You have a primary algorithm that is broken and no backup
Gold: As for Green except that you also have a deployed backup that is
based on a different principle and appreciably stronger (e.g. more rounds).
Silver: As for Amber, except that you have a deployed backup that you are
transitioning to and an agreement for the next.
Bronze: As for silver, except that you don't know where to go after the
The key objective is to avoid ever ending up in the state Red. From a
security point of view, a breach is unlikely in any other state. But the
difference between Silver and Amber is that if you are in Silver you have a
chance of getting back to Green or Gold while if you are in Amber you have
a much higher risk of ending up in Red.
Right now the situation as I see it is that we are in the following states:
Symmetric Encryption: Green (AES, no backup)
Symmetric Hash: Silver (SHA-1 transitioning to SHA-2 with SHA3 as the new
Asymmetric Signature: Green (RSA is OK right now)
Asymmetric Key Exchange: Gold (RSA with ECDH the likely successor)
Agreeing on what the next signature algorithm is, is only hard because
there are a few parameter choices that might matter. But we could probably
agree on those if we had a summit with the relevant folk to all agree to go
the same direction.
I would like to get to the gold state on symmetric encryption and the hash
function is moving towards gold naturally.

@_date: 2014-05-17 13:24:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [cryptography] Is it time for a revolution to 
Well they were thinking more generally, they wanted to secure other
protocols like NNTP
The design goal was to make shopping online as secure as shopping in
person. Which did not mean eliminating all risk, the goal was to
reduce the risk to the point that the insurance surcharge on credit
card transactions covered the losses.
And that enabled electronic commerce which has added about a trillion
dollars to annual GDP. Which is a pretty good result.
Well EKR and myself were proposing to add security at the message
layer (S-HTTP, SHEN). Which is a scheme I have resurrected recently
because with Web services TLS is not really a good fit for client
authentication because a Web service transaction often has endpoints
that are not the TLS transaction endpoints.
These days of course the main impact of that early work is in patent
lawsuit defenses.
I don't think we will ever want to get abandon security at the
transport layer. But supplementing it at the message layer makes a lot
of sense.
Twenty years ago we barely had the CPU to do RSA1024. We had to make a
choice between layers. Today we should be doing multiple layer
security. Transport AND Message layer.

@_date: 2014-05-19 14:29:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Facebook on the state of STARTTLS 
Cost of a CA issued certificate = $50 /year [Comodo cheap SSL]
Cost of finding a PKI consultant = $2,000
Cost of a PKI consultant = $200/hr
[Above prices are typical, hiring me costs rather more]
Crypto expertise is expensive if you buy at retail prices. It is a lot
cheaper if you buy from a provider whose operations are designed for
For the same reason, folk whose DNSSEC obsession is kicking CAs out of
the market are on a hiding to nothing because the cost of a 3-day
DNSSEC course is about $3000. I can deliver DNSSEC to people who don't
know DNSSEC and have no interest in knowing DNSSEC for far less.

@_date: 2014-05-19 22:34:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Back to the initial generation of public keys 
So I have a refinement of the 'jelly-bean jar' random number generator
I proposed a while back. (Having eaten all the jelly beans).
The new setup has an 8x8 frame and a set of 256  six sided dies. These
are painted white on three sides and black on three sides.
As before the frame is shaken up and the resulting pattern recorded.
However this time the pattern is formed in a single layer using only
the coarse information of whether the die is white face or black face
up. And there are two separate public key generators, each of which
has a separate camera.
For the system to be accepted, the two generators must generate the
same key for every roll of the dies.
The device is operated in two modes, first with the end cap removed so
that the positions of the dies is visible and for 'production' runs
the endcap is closed.
The advantage of this approach is that every aspect of the operation
of the device is auditable. Especially if the code for the two
generators comes from separate sources.
To effect secure readout, the use of the type of printer used for bank
PIN codes could be used. As a further protection, the keys are split
into two with each generator printing a separate half. So if the
halves don't match the keys won't checksum correctly and will be
rejected when there is an attempt to use them.

@_date: 2014-05-22 13:09:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The proper way to hash password files 
Lots of sackcloth and ashes as EBay loses a password file.
It occurs to me that most of the time, machines do password files
wrong. Rather than using a salted hash, a better approach would be to
use a MAC with a randomly chosen key that is never disclosed.
Now this seems obvious but I can't recall ever seeing code set up to
do the job this way...

@_date: 2014-05-22 19:54:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The proper way to hash password files 
Well all cryptography ever does is reduce the volume of the problem.
Having to secure 128 bits is easier than securing 150MB.
I would definitely want a HSM involved and the same sort of chain of
custody controls that we have for traditional PKI. I would want to
talk to the HSM as a network service and have essentially two commands
byte [] validator EncodeNew (string password)
bool Verify (string password, byte [] validator)
The validator codes would be stored in secure storage of course but
they can't be attacked by brute force unless the HSM is compromised.
Salting does not make any difference unless the HSML is breached as it
is a 128 bit search space.
Unless it can be fixed so that access to data secured in hardware is
required to decode.

@_date: 2014-05-26 21:53:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [PHC] Re: The proper way to hash password files 
The salt does not affect the difficulty of a brute force attack without a key.
It does however prevent the attacker who knows that they can steal the
password file from using the hashing device as an oracle. One can
imagine an attack where someone creates 1 million accounts with the
top million password values.
Even with a captcha in place, at the current rate of a cent per capcha
solution, thats only $10K to get the passwords entered (though
creating a million accounts from one IP address is still a challenge.
So there is a value to having a salt and it is cheap. But the system
depends on it to a much lesser degree which is a good thing.
If Hongjun or someone can forward a link to the email, I'm happy to
credit them. Though I somewhat suspect that there are earlier claims.
At this point a more important step would be to write a protocol that
allows us to talk to a network based HSM password checker.

@_date: 2014-05-26 22:24:35
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Langsec & authentication 
I am not sure ASN.1 is the best choice for illustrating what they are
about. ASN.1 is after all a formalized grammar and should be the sort
of tool that is part of the solution set they are looking for. Its
fact that ASN.1 is horribly designed and has got far worse over time
that disqualifies it rather than being an ad-hoc approach.
For the protocols I have developed with Protogen, every one is defined
using a formal grammar and the parser code is generated from that
grammar. Most of the applications are in JSON because its the simplest
of the commonly used encodings and none of the others offer an
[I do have an ASN.1 encoder in the system but it seems to have a bug
in it, I can't get other programs to accept my certs right now. Or
maybe I am just doing the byte ordering wrong on the signature...]
For each client/server interface there is a rigorous separation of the
message and API. First the entire message is read in and
authenticated. Only if the message verifies is it passed to the
parser. And only messages that parse correctly are passed to the
Rather oddly, there is quite a resistance to this approach. People
don't seem to be able to grock that a network application is really
just a remote procedure call (though possibly the server making a call
to the client rather than the reverse).
One of the reasons I want something more than TLS authentication is
that there is no guarantee that the TLS framing of authentication will
match up with what the application authentication requirement is.
So for example, imagine we have a TLS session using RC4 encryption
that plops a MAC value onto the pipe every 64Kb. And the target
environment has some sort of SSL accelerator in place. Unless the
application developer reaches into the TLS stack to assure themselves
that their packets are too going to be authenticated properly it is
quite possible that the receiving end pulls a 2048 byte transaction
'fire the nuclear missiles' out of the TLS stream and acts on it
before the MAC value is found to be bad and the socket closes. Since
we are using a stream cipher with chosen plaintext it is easy to
recover and reuse the cipherkey.
Requiring every transaction to have a separate application layer
authentication blob protects against any nonsense at the transport
layer and protects against injection attacks. There is no possibility
of injecting commands when every command requires a separate
authentication value.
Using a parser generator tool to parse e.g. DNS protocol messages is
rather easier than writing the code without a tool and it does mean
that a rigorous approach to buffer allocation can be taken and we can
abort on data streams with errors like length-A [ length-B [  Data ] ]
where Length-B > Length-A.

@_date: 2014-05-26 22:44:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] USG asks for time served (7 months) as Sabu's 
The request makes clear he is admitting to a lot more than just the
well publicized hacktivism. Monsegur admits to hacking for profit
including major credit card frauds. That sort of behavior isn't
exactly the sort of thing Anonymous and lulzsec used to publicize
their involvement in.
Also note the suggestion that no prosecutions have resulted from the
anonymous part of the investigation. I wonder why not. Did they fail
to identify the members or is there some reason not to prosecute (like
information that might be revealed if they did).

@_date: 2014-05-26 23:18:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] eBay hack 
If true, all EBay would need to do to make their system secure against
loss of the database would be to keep the public key used to encrypt
the data secret.
Which means that this is arguably prior art for the HMAC scheme I and
others proposed (albeit a slow one). Not revealing the public key is
arguably obvious because EBay never published it.
Of course date of publication... if it was never published its not prior art...
Slow is only good if you are not using some form of trustworthy
hardware to lock up the key :)

@_date: 2014-05-27 07:47:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Langsec & authentication 
Not in my code. But then again I only implement the parts of ASN.1
required to encode and decode X.509v3 certs. I don't implement the
macros and I don't use the ASN.1 schema language.
The problem I have with 'compiled' SQL is that I am not at all sure
that the drivers would be using it like that.
I think that has to be a consequence of the decoder design rather than
the format.

@_date: 2014-05-27 15:03:24
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [PHC] Re: The proper way to hash password files 
Netdulino 2 Plus is $60... All we need this to do is a MAC.
I think the salt should maybe come from the party that interns the
password value.
Problem with the device being a network device is that then it ends up
having a network stack. And that is a lot of complexity to check.
Can do a further hash to the password certainly.
The Netdulino has an onboard SD card, maybe write the log out to it
and stop answering queries when it is full.
No, the user ID definitely not needed.
Not sure that I would want to do public key though. I am thinking that
a kerberos style solution would be better.
I would prefer a $60 solution that could be deployed now than a
FIPS-certified solution in 4 years.
Plus would have to be sure FIPS describes relevant controls.

@_date: 2014-05-28 08:42:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] client certificates / client-side proxy 
A client side proxy is better than a plug in in the same way that
having a root canal is better than having your eyes gouged out with
hot pincers.
Better does not mean 'good'.
The problem with plug ins is that they don't compose and they aren't
maintainable. They are a fine platform for testing and
experimentation. They are a lousy long term solution unless backed by
a huge developer team. Google Toolbar is probably the exception that
proves the rule.
What using a proxy does force is a frictionless user interface. I am
using a proxy in my mail encryption project because I want to prevent
any additional UI burden on the user.
There are far too many security proposals of the form 'if every Web
user does X every time they use the web we will be secure' not least
because X is often obscure and complicated and tedious. Even the
proposers of these schemes don't use them.

@_date: 2014-11-03 14:09:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Security of wireless keyboards and mices. 
Has anyone looked into the security of these devices?
Given experience with car locks, garage door openers, etc., I am not
expecting the results to be good.
The reason my interest was piqued was a journalist inquiring about the
alleged takeover of a Benghazzzzi conspiracy theorist's laptop. I
suspect that particular case is most likely explained by the device
being paired to a bluetooth keyboard that a cat decided to sit on. But
I have been thinking about the wider case.
Logitech claim to have 128 bit AES. But what do the doofus vendors use?

@_date: 2014-11-07 14:46:36
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Third amendment crypto defenses 
No Soldier shall, in time of peace be quartered in any house, without
the consent of the Owner, nor in time of war, but in a manner to be
prescribed by law.
One of the main differences between GCHQ and the NSA is that GCHQ
reports to the foreign office while the NSA is a part of the military.
This has profound implications for the way that the NSA works. It is
also an issue that might well be fixable under the next
The problem with the NSA at present is that it puts far too much power
in the hands of the military. The CIA was under the remit of the
Secretary of State before it was put under the DNI because it is a bad
idea to have a bunch of spooks advising third world generals on how to
enact a coup d'etat to be reporting to your own generals.
The NSA has been promoting its notion of 'cyberwarriors' performing
attacks. They have also been performing work for the FBI which lacks
the necessary skills to intercept many modern communications. Looking
at the third amendment, I think there is a reasonable interpretation
which would find that the military should not have anything to do with
such activities.

@_date: 2014-11-19 21:07:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] STARTTLS, 
Did anyone take a look at what they were doing on the SUBMIT port?
Given that it is wireless, I suspect that some idiot compression
scheme was the issue rather than anti-spam or malice. If it was only
on port 25 it was likely because the people doing it were too
ill-informed to know about SUBMIT.
Its just an attack and the security protocol should defend against it.

@_date: 2014-11-20 09:33:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] New free TLS CA coming 
I don't see the issue here. Comodo has been giving away certs for 8
years now. So have other CAs. Mozilla has known about that. It has
never been raised as an issue at roll over.
The issue with CACert wasn't that they were refused, they withdrew
their application after they realized that they were never going to
meet the audit criteria.
The only different thing here is that this time there is a proposal
for an automated enrollment protocol as well and presumably a
commitment to implementing it.
I have been calling for an automated enrollment protocol for quite a
while. This is the one I wrote for PRISM-PROOF email:
I was considering a wide range of scenarios ranging from EV certs to
certs for the coffee pot. Paid, unpaid, strong validation, DV, etc. My
model is subtly different but that was in part because I have worked
with Stephen Farrell, the current Security AD on five different
enrollment protocols over the years and I wanted to avoid the 'what
again?' response.

@_date: 2014-10-06 09:24:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] 1023 nails in the coffin of 1024 RSA... 
Optimization error or not, RSA has been tested quite extensively with
mismatched p and q and it works just fine. The only reason not to do
that is that the work factor depends on the size of the smaller of p
and q rather than the size of the modulus. So the work factor of
asymmetric p/q is not attractive unless you are also doing something
else thats odd like Chaumian blinding or modulus compression or anti
kleptography or the like.

@_date: 2014-10-11 10:43:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Sonic.net implements DNSSEC, 
It isn't clear but what they appear to be doing is turning on DNSSEC
validation in the resolver, then editing the results.
This is something I predicted long ago and the problem is that the DNS
architecture as received is stupid. DNS is a trusted service so you
should only use a trustworthy DNS service. DNSSEC only ensures that
you do not receive bogus responses. It does not ensure that you
receive a response.
The original idea of DNSSEC was to use the DNS as a distribution point
for keys for use in IPSEC and SSL like protocols. Then it was co-opted
as a mechanism for making the resolver untrusted which was stupid. Its
the tin-foil hat version of crypto-autarky where you use crypto to
eliminate reliance on any party at all, except of course for the ones
you don't notice like ICANN (a US QANGO) or the resolver.
Yes, the DNS resolver can MITM you. Which is why the communications
between the resolver and the client must be encrypted and
authenticated so that you can be suer that you get the DNS service
from the service you chose and not a service that your ISP chose.
I have this machine set up to connect to the Google public DNS. But a
few weeks ago I was seeing Verizon sitefinder inserts. The bastards
had MITM the NXTDOMAIN responses.
So I wrote this spec and have some running code
The first step is to choose your DNS service or set up one of your
own. The client binds to the service using a TLS secured key exchange
that spits out a Kerberos ticket type object. And then DNS
transactions with the service are encrypted and authenticated in both
directions using the ticket.
The design is stateless on the server side and should not impact
performance at all for modern machines. The crypto overhead is
Now for the mind bending part, you probably don't want the
authoritative DNS responses unless they are DANE records or otherwise
contain a key. If it is an A record or a AAAA record you might well
want the resolver to have the ability to modify it.
One reason is to block access to known bots. Just because the Russian
Business Network has bought a domain does not mean that I want my
machine to resolve it. And I have lists of a million bots. I don't
want my machines connecting to them either.
If the policy is chosen by the end user then this is anti-virus for
the Internet. If it is imposed by the carrier or government it is
One particularly fun approach is using it for IPv6 to IPv4 gateways.
This allows a machine that is pure IPv6 with no IPv4 whatsoever to
survive on the transitional Internet without a performance drag.
When the IPv6 client attempts to connect to a resource that is IPv4
only, it returns an IPv6 address at the best available IPv6-4 gateway.
This might be a local gateway or a gateway closer to the desired end

@_date: 2014-10-11 23:20:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cryptography, backdoors and the Second Amendment 
The Supreme Court only recognized an individual right to bear arms in
2008. And three of the judges in the 5-4 majority voted to stop
counting the votes in Florida in 2000.
So its a pretty thin reed you are depending on there. Scalia and
Thomas make no pretense about consistency, they just make stuff up to
suit their prejudices.
The best you could hope for by persuading the judges that crypto and
firearms are the same thing would be to see them return to the pre
2008 approach to firearms. In the wake of Sandy Hook, the only
politician to deliberately raise gun control this cycle was a
Republican who wanted to downgrade his NRA A rating to an F by backing
background checks.
As it happens, it does not matter very much because Holder isn't the
administration any more than Louis Freeh was. He only came out with
this talk after he decided to hand in his resignation. Which pretty
much tells us how much support he has for the position.
Since the democratic nominee is virtually certain to be Clinton, it is
rather more likely that the state department view will win out over
FBI, Justice and the military. Not least because Clinton is not at all
amused that due to the incompetence of the NSA, Chelsea Manning was
able to leak those embarrassing cables.
The Republicans usually give the nomination to the guy who came second
last time round. And Ricky Santorum looks as good as any of the
alternatives likely to run. I don't know what his position on crypto
is but I doubt it is a liberal one.

@_date: 2014-10-15 10:51:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Compressed CRLS 
Rob Stradling and myself have been looking at the revocation problem
again. Using traditional techniques some CRLs have expanded to 3 MB.
Using a novel compression technique we can create a CRLSet that allows
encoding densities of about 6 bits per revoked certificate.
In practice this means that we can give the status of every unexpired
WebPKI SSL certificate from every public CA in about 170KB. [Rob
scraped the Web and collected up 2.5 Million certs of which 250
thousand were revoked].
Delta CRLsets are also possible, a daily update would be about 5KB.
The asymptotic space requirement (in bits) is |B| (log2 (|A|+|B|))
where A is the set of valid unexpired certs and |B| is the revoked
The compression technique is described here:
Note that IPR claims do apply but it is understood that any
application to the Certificate Revocation problem for the Web would
have to be open source compatible.
The key to efficiency here is that the CRLSet only allows us to
distinguish valid unexpired certs from revoked unexpired certs. While
it gives exact answers for these cases it gives a random answer for
certs that are not in A or B.
The paper describes the simplest approach we came up with. Rob's
improvements double the efficiency.
I will be in Hawaii if anyone wants to talk to me there.

@_date: 2014-10-15 15:48:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [messaging] Gossip doesn't save Certificate 
CT gives me an infrastructure of notaries that I can use as the
starting point to hang useful stuff on. Think of it like the olympics.
No city wants the olympics, they are a pain. But if you want to have a
subway line built out from Boston to (say) Woburn it will take 50
years through incremental expansion of the green line. Stick the
olympic stadium in Woburn and construction has to be done inside a
five year window.
The big problem in PKI has always been revocation. The Diginotar event
would not have been half as bad if we could revoke the certs. The idea
of CT is to provide earlier notice that a CA has been breached and not
noticed, an event that has so far happened once in 20 years. But
without revocation it doesn't do much.
Fortunately, compressed CRLs solve the revocation problem. But to
apply our scheme you have to have a complete list of issued certs. So
CT is convenient.

@_date: 2014-10-26 08:36:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Arduino Enigma simulator 
I have one of these, it has an emulation of the plugboard etc.
I have not got round to building a wood box yet.

@_date: 2014-09-08 13:22:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] sunsetting SHA-1 in Chrome 
I think the point here is that the birthday attack is only relevant in
certain circumstances. If you are using SHA for authentication then
what matters in most contexts is if the sender really sent what they
In PPE I am using 128 bit hashes of keys because the ability to
generate two keys that hash to the same value would only harm the
party generating them.
But then again I generate those keys using SHA-2-512 and truncate...

@_date: 2015-04-03 11:36:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cipher death notes 
When I proposed the same scheme (based on Rivest/Shamir suicide notes)
in the wake of the SHA-1 breach, I got two responses:
1) A cipher becomes unfit for use long before a it is possible to
perform the hardest attacks. SHA-1 has not been broken, even MD5 is
not completely broken. It will never be possible to extract a DES key
used to encrypt a random plaintext. etc.
2) What do you do if the note is activated?
The second question is one that the folk who think DNSSEC is a
mechanism for securing the DNS have never really had an answer for.
What do I do if the DNSSEC chain does not validate?
It is also a problem in a lot of spam control schemes. It is easy to
write a procedure that does the right thing in situation A, It is easy
to write a procedure that does the right thing in situation B. But
when you don't know ahead of time whether you are in situation A or
situation B, the trivial solution which builds the decision into the
process no longer works.

@_date: 2015-08-01 13:38:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Windows... Your choice but make it informed. 
I think folk are not quite appreciating that what Microsoft is trying to do
here is actually very hard to do and as far as the typical user is
concerned, protecting their data for confidentiality is a lot less of a
concern for them than the risk they might lose their data.
None of the consumer products come with strong encryption turned on out of
the box. So what Microsoft is offering here needs to be compared to the
alternative of no encryption at all. It is a big improvement. When Vista
was launched, the main upgrade was to security which in turn meant a huge
increase in workload for system admins. So to avoid the need for all that
extra work, the system admins found it much easier to convince people that
what they really wanted to do was run Windows XP.
That said, I think Microsoft has to consider their position very carefully
because they are now caught between a rock and a hard place. On the one
hand they are going to have a huge blowback from the lazy system admins and
users upset at losing all their data if they try to force people to use too
much security. On the other they face a huge blowback from the privacy
advocates if their solution is to back everything up to a trusted Microsoft
cloud. And yes, there is a huge intersection between the two groups.
I think I have an answer for them. The problem with Microsoft's cloud is
that we are forced to trust it. But the Mesh I am working on provides the
same set of capabilities without requiring the end users to trust it.
Now my solution isn't for everyone, you would have to have enough skill to
be able to print out the recovery codes on paper and store them somewhere
safe. But offering it as an option would be a way to avoid the privacy
onslaught facing them.

@_date: 2015-08-04 11:09:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
I am very sure I have seen exactly that.
Back in 2000, after VeriSign bought Network Solutions, Warwick Ford and
myself took a look at what it would take to deploy DNSSEC which was one of
the main reasons behind the purchase. There was a huge scalability problem
in the spec which required an NSEC record to be inserted for every record
in the zone.
The DNSSEC code was written and would have deployed when VeriSign deployed
ATLAS in 2002. The only reason that code was pulled was that a faction in
the IETF refused to allow a very minor change to the DNSSEC spec so that
NSEC would only cover signed zones.
The extra cost of the original approach was over $30 million as it would
require the use of 64 bit machines rather than 32 bits. The choice was
between modified DNSSEC and no DNSSEC at all. But the NSA BULLRUN folk were
able to derail the discussion and block the change. They also made sure
ICANN would not permit deployment of any DNSSEC scheme that was not IETF
The spec was eventually fixed, many years later. But that is why you don't
have security in the DNS today. The difficulty of deploying an
infrastructure change like that goes up the longer deployment is delayed.

@_date: 2015-08-15 12:11:03
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] SHA-3 FIPS-202: no SHAKE512 but SHAKE128; 
Actually, it might be better to have that conversation here.
Something that really worries me about the OpenPGP discussion is the tone
of the discussion is 'prove to me that this attack is a problem' not 'prove
to me that this attack is not a concern'.
I think the IoT space is so diffuse that we risk ending up talking
nonsense. I see three distinct classes of machine:
1) Effectively unconstrained. Any desktop, smartphone or tablet. Anything
at or above Raspberry Pi capabilities.
2) Demanding thought and care
3) Ridiculously underpowered. Anything with an 8 bit core.
Yes, there will be devices in the third category. But guess what, they
don't have to do public key at all. Or if they do they only need do it
during one time initialization.
The hard bit is the bit in the middle. And even Windows 10 IoT is likely to
pose issues. Yes, you can use a Raspberry Pi2 to develop and the chip at
the center of the device only costs a buck. But that is a development
environment. If you went into production you would want to go for the
lowest power, lowest cost or otherwise best chip you can find.
Raspberry Pi can easily do AES256. But you might well want to ask yourself
if you really, really need AES128 and AES256. Every module you add to your
device means more memory, longer startup times and so on.
Right now we do have a defacto consensus algorithm suite:
AES128 CBC
The main problem with this set is the RSA part and in particular key
generation which is difficult and painful. The strength is not ideal either
and RSA really hits diminishing returns above 2048 bits.
I think we will settle on a new defacto consensus. But I think its going to
be centered on the 256 bit algorithms:

@_date: 2015-08-16 13:49:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] SHA-3 FIPS-202: no SHAKE512 but SHAKE128; 
Read and respond to what I wrote if you want to accuse others of myopia.
Your eyesight is clearly faulty.
"The strength is not ideal"
RSA2048 is reckoned to present a work factor of 2^112 which falls short of
the 128 we prefer.
To get to 128 bits we need 3072 bits. And even then that is only 128 bits
against the best attack currently known.
"RSA really hits diminishing returns above 2048 bits."
 If we want to get to 2^256 work factor we need to more than double the
number of bits, we need 15360 bits which is ridiculous.
And I'm not sure why you say 'RSA really hits diminishing returns
The tone of your response suggests that you need to consider the fact that
if someone is saying something that appears to be stupid, you are reading
it wrong rather than the other person wrote something stupid.

@_date: 2015-08-18 08:20:24
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] SHA-3 FIPS-202: no SHAKE512 but SHAKE128; 
Speed is not fine and many of the libraries don't support RSA keysizes
above 4096 bits.
What I originally said was that RSA hits diminishing returns and the math
completely justifies that statement. There certainly wasn't any reason for
the type of response I got from Gilmore. It is not clear to me what 'Binary
RSA Myopia' might be or why it would be appropriate to use such language.
People are going to be using RSA for a very long time. It is not exactly
broken but there are very good reasons that people are using it at 2048
bits rather than 4096 and the industry is looking for ECC based schemes
rather than even larger keys.

@_date: 2015-08-27 10:03:46
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] 3DES security? 
It is probably OK for any practical use where you are still allowed to use
it. Yes there are ways to tradeoff performance for memory and maybe shave
the key space a little with a vast number of known ciphertext/plaintext
pairs. But unless you are doing something really, really secret, the chance
anyone is going to go after your crypto is very small.
Carders didn't find a way to reverse engineer PINs by cracking the DES
crypto, they did it by driving bulldozers into an ATM and reverse
engineering the hardware.
So it is probably OK to use in the same way that SHA-1 is still OK to use.
If you have a legacy system that would cost a lot of money to upgrade, you
can probably spend the $$$$ on other improvements. But the main risk you
will face in doing that is that everyone else in the industry considers it
obsolete and that imposes costs on you as well.
Being secure isn't enough these days, you have to show you are secure. And
SHA-1 or 3DES is going to require an extra review every single time the
system is audited. If it takes a day each time at $3,000 a day, that starts
to mount up.
At some point it is going to be difficult to find the library support. You
don't make a system more secure by adding new stronger ciphers, you make it
more secure by taking out the duff ones. DES should be gone already, I
would want to take 3DES out along with SHA-1.

@_date: 2015-08-28 13:09:42
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Augmented Reality Encrypted Displays 
That is overly negative. Chaum did some interesting stuff a while back for
Where I think the augmented reality bit will fall apart is that augmented
reality tends to depend on things like cameras analyzing the environment so
that it can register an overlay. So unlike Chaum's system in which you have
a piece of inanimate paper and an inanimate overlay foil, in augmented
reality you have at best an inanimate hacker-proof physical display and an
eminently hackable IoT device that knows both parts of the puzzle.
Yes, yes, you can split the signal paths, yada yada. But you are still back
in the problem of trusted but untrustworthy devices and you are vulnerable.
Crypto is hard...

@_date: 2015-08-28 14:28:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A thought about backdoors and quantuum-resistant 
It is certainly possible to design a protocol that has effective
countermeasures to prevent this.
Consider the problem from the attacker's point of view. A public key
encryption scheme has three sets of parameters:
Private Key  K
Public Key    P
Shared parameters. S
A crypto system is QM secure if someone with a quantum computer cannot
obtain the private key or decrypt messages using the Public key and shared
public parameters using a QC.
What you are suggesting here is a backdoor in the shared parameters such
that these are chosen so that the attacker has leverage but other users of
the system are not. In effect we have a second public key crypto system
built into the shared parameters and the attacker has generated these
shared parameters as some function of a master secret X so that S = f(X).
Call this type of system 'backdoor QM insecure'.
Note that X has to be sufficiently large that the system is still secure if
the attacker doesn't know it. Otherwise this isn't a cipher with a hidden
NSA backdoor, it is a cipher that has a set of weak keys that enable an
attack method known to the attacker and not anyone else.
Call this system 'unknown attack QM insecure'
While it is certainly possible to imagine that a function f(X) might exist,
it is fairly clear that from this point on, any and all parameters used in
any standard for public key cryptography must be rigid so that an attacker
cannot choose a set that provides them with a backdoor. MD4 introduced the
notion of using parameters taken from an arithmetic function (e, pi, etc).
The CFRG is looking at fast primes.
So yes there is a risk here but we already have an effective control: rigid
According to my source, the relevant NSA doctrine is NOBUS 'nobody but us'.
So they might peddle an unknown attack QM insecure system like they did
with Dual_ECRNG, but unknown attack would leave US IT systems vulnerable to
attack by China, Russia, etc.

@_date: 2015-12-01 08:09:53
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve 
The claims all specify a proof that the keys were generated with a specific
As DJB points out 'nobody does that'.
It might be something you should arguably do for ECDHE but the spec doesn't
support that.

@_date: 2015-12-01 12:48:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve 
No, the operative clause is "and a proof that the keys were generated by a
specific algorithm"
What is being claimed here is the invention of a method that allows relying
parties to verify that a public key has been generated securely without
compromise to the key itself.
There are certainly novel ways of doing that, in fact I have a patent
application in process that suggests a new one.
I suspect that the basis of their claim is that shared ECC parameters are
part of the public key and those are in fact subject to public review, see
CFRG process. But that also fails. "wherein said constructing of said proof
requires access to said secret key" The generation of a curve does not
require knowledge of any private key in any of the crypto schemes we use.
The generation of shared parameters does not require knowledge of a private
key by definition.
I have found that in the typical patent case that I am involved in, I am
the first person with specific expertise review the patent for either side
and usually that is a few weeks before the initial findings have to be
submitted. This looks like something that a non-expert might imagine would
be done in TLS. But as it happens, the protocol doesn't support anything of
the sort.
Sometimes the plaintiffs are so ignorant of the weakness of the claims that
they go looking for punishment. I was due to give a deposition last month
as a third party. When the plaintiff discovered that in the ordinary course
of business I regularly refer to the original PEM specs that the patent
application in question was simply a copy of, they dropped the case

@_date: 2015-12-01 20:41:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve 
There are three main routes to getting a patent thrown out
* Invalidity (didn't pay fees, claims are ambiguous, expired, etc)
* Prior Art (invention was published before the application was filed)
* Non infringement (defendant doesn't do what was claimed)
Now I am not a lawyer, but I do take work as an expert witness in patent
cases. The first issue, invalidity is purely the domain of the lawyers but
the last two actually work together.
Early in the case there is a hearing to construe the patent and define what
it means in the context of the case. That is critical because it will often
determine whether it is a prior art case or a non infringement case.
In this particular instance, the patent can be read as describing El Gamal
signatures which are actually used in ECC certificates since DSA is a
variation of El Gamal. But that approach falls foul of prior art because El
Gamal and DSA were both published long before the patent was issued.

@_date: 2015-12-02 16:54:25
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve 
Schnorr is also expired. But the reason I didn't reference it is that the
Schnorr part does not seem to be relevant to the claims.
The CFRG signature algorithm is equally irrelevant as nobody can possibly
be infringing with an algorithm we haven't invented yet.

@_date: 2015-12-02 19:19:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] JSC notifies on introduction of National security 
BTW, this isn't the-istan where the dictator in chief had the leader of the
opposition boiled alive. That is Uzbekistan.
*From 1 January 2016 pursuant to the Law of the Republic of Kazakhstan **On
communication Committee on Communication, Informatization and Information,
Ministry for investments and development of the Republic of Kazakhstan
introduces the national security certificate for Internet users.*
According to the Law telecom operators are obliged to perform traffic pass
with using protocols, that support coding using security certificate,
except traffic, coded by means of cryptographic information protection on
the territory of the Republic of Kazakhstan.
The national security certificate will secure protection of Kazakhstan
users when using coded access protocols to foreign Internet resources.

@_date: 2015-12-02 19:35:24
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Large companies sued for using Elliptic Curve 
Your faith in the ability of IRTF/IETF to complete the above work item
expeditiously is noted.
Having had RFCs that are about to issue for several years, I'll consider
the work completed when the RFC issued.

@_date: 2015-12-03 21:27:56
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Anyone else seen some odd shipping delays? 
Twice in the past week, I have ordered a computer and it has been subject
to odd shipping delays and the UPS data makes no sense.
I don't think it is seasonal, other stuff arrives fine. Only computers seem
to be held up.
So anyone have ideas for checking over a QNAP box to see what surprises
might have been planted in the firmware?

@_date: 2015-12-04 11:10:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Anyone else seen some odd shipping delays? 
Well I would not use the box for code development. This is a RAID array for
the home theater. The source code is going to be managed on SourceForge and
there is a firewall between my office and the rest of the house.
Yes it is.
Which is why I do not have any connection to the operational environment.
I am very interested in open source HSM efforts. But that isn't currently
my focus.
What is in my scope is considering supply chain security and the risks of
precisely this type of compromise. I do build my development machines
myself but that only ups the work factor rather than being a protection. I
like these Raspberry Pi devices as I can load them with an O/S build of my
choice from a reasonably secure media. Again, not perfect proof.
Thing is that I have attended MIT workshops where we discuss this sort of
thing with people who retired from the most senior positions of certain
three letter agencies. One of the hypotheses I put forward at that meeting
is that
1) China has good reason to fear cyber attack from Russia (look at a map,
all those countries between them are highly unstable and have large Russian
and Han minorities)
2) China's policy of stealing IP has prevented the country developing a
native design capability. We hire lots of Chinese engineers who can't find
work at home to do anything apart from reverse engineering.
3) Therefore, China has to get the US/Germany/etc. to do the R&D for the
cyber defense technologies it needs so it can steal them.
4) China has no purchasing power because it steals everything.
5) Therefore China's optimal cyber strategy is to attack the West in the
very open manner we see in the expectation that this causes us to develop
the cyber defense technologies they need.
So maybe they are just attempting to use the strategy I suggested to apply
my thought to the supply chain problem they would like to see me solve
rather than the other problems they do not want to see solved.

@_date: 2015-12-04 16:25:31
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Anyone else seen some odd shipping delays? 
Certainly in terms of capabilities. But there aren't very many issues that
are likely to spark a US/China conflict. There is North Korea, Taiwan and
Tibet, all of which are persistent stalemates. China's engagement strategy
with the US is one of entanglement. There are simply too many areas of
mutual interest to make provoking a conflict worthwhile.
If you look at the area round the Caspian sea, there are a half dozen
ex-Soviet states with a large Russian speaking minority that are unstable
as heck. The sort of place where the President has the leader of the
opposition boiled alive. Many of those places have large Han populations as
well. The risk of a conflict that pitches Russian and China on opposite
sides is very high.
China's response to this situation has been to form an alliance with
Russia. But it isn't an alliance of equals. It is an alliance of a rising
power with a much weaker empire that has shrunk by 60% in the past 25
years. And the weaker power is the more aggressive.
The threat to China from the states is not the US administration, it is the
military. Going to these workshops I get the feeling that many of the
retired generals etc. are thinking they can make some good money if 'cyber'
becomes a domain along with air, sea, land and space and with a budget to
match of course. And I suspect there are similar empire builders on the
Chinese side.
If we are not careful, these two gangs of crooks could get us into a very
expensive game of cyber-escalation.

@_date: 2015-12-04 17:30:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] JSC notifies on introduction of National 
Solution for state mandated: TLS in TLS. The outer envelope can be
decrypted and can pass the censorship mechanisms unless they look for the
inner stream. But that is trickier than it might seem because HTTP actually
has an in-channel upgrade option.

@_date: 2015-12-05 23:49:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cryptography is not a science currently 
They certainly do it for the Russian and Chinese cyber researchers. It
would make sense to do it for domestic folk who are so much easier to
collect information on.
There is a long history of corruption in the US. And the FBI and NSA were
certainly not immune. The abuse of the FBI to pursue Hoover's racist
political agenda, LOVEINT, etc.
There is also a long history of hiding behind the flag. If the military is
doing it, then anyone who complains about it is disloyal to the country.
Phil knows all about that. I don't think he was downplaying them. What he
was doing and what needs to be done right now is to point out that we are
not the ones re-fighting the cryptowars of the 1990s.
What we discovered in the Snowden docs is that the NSA eased off on the
cryptowars because they thought that the increase in information being
transmitted would greatly outweigh the loss due to crypto.
What the NSA/FBI don't seem to realize is that when they made the pragmatic
choice to give up the attempt to impose Clipper, they had conceded the
moral victory. So when the Snowden papers came out 20 years later they
suddenly realized that the technology had moved on and it would be very
easy to send much of Fort Meade dark. I assume Google now encrypts
everything everywhere inside the corporation.
Truly Rogaway is the Chomsky of Cryptography. Chomsky will deny the
Chomsky was maliciously misquoted.
What he actually said was that there was more evidence for the genocide
taking place in East Timor, a genocide the US denied the existence of
because it was being perpetrated by an ally than for the Cambodian genocide
which everyone, Chomsky included accepted as a fact.
The East Timor massacre is now acknowledged as a historical fact. But only
after the establishment accepted there was no further need to prop up
I don't think that there are many cryptographers that fail to understand
their work has political dimension just as there are very few people
involved in the Web or IETF that are not aware of the political dimension.
But there are degrees. Tim wanted to build a collaboration tool. I wanted
to disintermediate the establishment media and unleash chaos. Having been
born into the British establishment and knowing that so much of what the
public was told was utter lies, I wanted to introduce a feedback mechanism.

@_date: 2015-12-06 14:50:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cryptography is not a science currently 
Read 'Legacy of Ashes'. But the CIA gets all the glory for the same reason
that Special Branch did: they were the part of the intelligence world that
was allowed to have a public profile. And to a large extent, Dulles was
permitted and even encouraged to be a braggart as it distracted attention
from the NSA.
Read the history of operation Ajax and ask yourself why Dulles would have
the nerve to attempt a second coup after the first attempt had collapsed.
The only reason that makes sense to me is if he had very very good signals
intelligence. It stands to reason that the Iranian govt. would be using
Enigma style rotor machines.
Funny story about Beria. I was talking to a KGB officer and he asked me why
I thought Beria was assassinated. According to the Western account the
other communists were afraid he would liquidate them. But that wasn't the
reason at all, in fact the survivors knew they survived precisely because
Beria didn't think they were a threat.
According to my source, the reason they liquidated Beria was that after it
was decided he would succeed Stalin but before he had been officially given
the job, Beria suggested that the current Soviet approach was failing and
the Soviet union needed to de-escalate the cold war and normalize relations
with the US if it was going to survive.
That isn't the point.
The point I was making is that the deployment of crypto inside Google is
surely deep and pervasive enough at this point for the NSA to understand
that the writing is on the wall. It is not a question of whether Amazon,
etc. have done likewise today, indeed there would be no point restarting
the cryptowars if they had as there would be nothing left to play for.
No he isn't. We all knew that something like PRISM was going on. Some folk
were perhaps surprised by the scale but not everyone. Also remember that
the slides we have were all written by Majors who were trying to make
Colonel. Their intercept capabilities probably work about as well as
Reagan's SDI program does. We are seeing the color glossies, not the
realistic view.
The reason Snowden was a game changer is that now we can talk to people and
not be dismissed as conspiracy nuts. That changes everything.

@_date: 2015-12-09 15:47:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Satoshi's PGP key. 
It seems like a very bad situation to be in. Satoshi generated about a
quarter of the coins in the blockchain back before the system caught on.
He may have generated the coins and destroyed them or he might still have
the private key. In either case he would find it impossible to convince an
extortionist or kidnapper that he doesn't have the money.
Given the extensive use of bitcoin by the criminal community, the risk of
that type of attack is very high.
That is why I don't speculate about his identity and would urge others to
do likewise.

@_date: 2015-12-14 09:28:38
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Satoshi's PGP key. 
Well plenty of people were killed or kidnapped for cowry shells back in the
day. it was a major currency in the slave trade.
I have come to learn that when people tell me that I am wrong or being
stupid in a very particular tone, it is because I am absolutely, 100%
right. The argument for BitCoin has always been, 'we need a new money
system, therefore BitCoin must be that new system'.
BitCoin is part technology, part wishful thinking and part tulip mania.
Every possible aspect of BitCoin is taken as being positive, all negative
aspects are dismissed on the grounds that the system is still
It is like those folk who drone on endlessly about how Linux is absolutely
better than Windows in every possible way. This is an absolute fact that
cannot possibly be untrue in any respect. Therefore any facts which
conflict must be false. When I point out that I can buy pretty much any
graphics card from any manufacturer and be confident my Windows system will
boot flawlessly while my Linux box is unable to drive the nVidia Dual-DVI
card I bought to use with it this is an 'nVidia problem' and they are
'known to be problematic' and what I should actually do is to write my own
A minimal test for BitCoin would be if the amount of real world
transactions in BitCoin actually exceeded the amount spent on mining. I
rather doubt it.
Equally, any sane test of a 'decentralized currency outside government
control' has to require that people don't end up getting ripped off. So far
there has been vastly more BitCoin fraud than actual trade in legitimate

@_date: 2015-12-14 20:18:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Photon beam splitters for "true" random number 
There was a booth at the 2013 RSA show where a company was selling one. I
forget the price.
The problem with such devices is that when you make a physical anything,
you end up with biases. And then when you try to correct for the biases you
lose the perfect theoretical security.
Like one time pads, quantum crypto is perfect in theory but the proofs tend
to be very brittle. I much prefer a system that isn't provably secure but
is demonstrably robust over one that is provably secure but has a single
point of failure.

@_date: 2015-12-14 23:32:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] GCHQ puzzler for xmas 
An interesting hypothesis and one that should be tested.
So first we set up a committee to solve the puzzle, then send in entries
under names selected at random from the telephone book and watch to see how
many disappear.

@_date: 2015-12-15 23:29:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What should I put in notifications to NSA? 
I am working on staging the code for the Mesh on SourceForge.
There is this bit to do:
You must notify BIS and the ENC Encryption Request Coordinator via
e-mail of the Internet location (e.g., URL or Internet address) of the
publicly available encryption source code or provide each of them a
copy of the publicly available encryption source code. If you update
or modify the source code, you must also provide additional copies to
each of them each time the cryptographic functionality of the source
code is updated or modified. In addition, if you posted the source
code on the Internet, you must notify BIS and the ENC Encryption
Request Coordinator each time the Internet location is changed, but
you are not required to notify them of updates or modifications made
to the encryption source code at the previously notified location. In
all instances, submit the notification or copy to crypt at bis.doc.gov
and toenc at nsa.gov.
What do folk normally do here? I was thinking of giving them the URL
of the repository and a statement to the effect that by complying I do
not wave my first amendment rights

@_date: 2015-12-17 09:15:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What should I put in notifications to NSA? 
I'm not the type of crypto hacker that develops a strong encryption scheme
just to disable NSA mass surveillance.
I'm trying to be the type of crypto hacker that develops a strong
encryption scheme to disable NSA mass surveillance and then sells the same
scheme to the NSA to secure all those documents that Snowden and Manning

@_date: 2015-12-19 11:42:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What should I put in notifications to NSA? 
Math doesn't have a moral conscience. All that you can do is decide which
use cases you are going to address.
Looking back at the use of the ULTRA type decrypts after WWII, I am forced
to conclude that they were a net negative. Operation Ajax was a US driven
coup which replaced a democratically elected government with a
dictatorship. That coup was only possible because the US was decrypting all
the internal communications of the Iranian regime.
And there are still people in the establishment whose response to this
atrocity is 'Mosadegh had it coming'. I consider such people to be a threat
to the republic. There is far too much seditious talk in the US to start
with and it does not sound any different to me to the treason talk from
countries where a dictatorship was installed. What happens if the NSA
decides that an Obama or a Clinton 'has it coming'. If Sanders was elected
president they might well attempt a coup on the spot.
But they won't win unless they have the tools. Remember when the spate of
coups ended, it was the mid 1970s. One reason was the fall of Nixon and the
election of Jimmy Carter. But they did not restart under Reagan. By that
time the mechanical systems were being replaced by electronic and the
number of weak ciphers began to rapidly decline. There is a big difference
between being able to decrypt most traffic in any government being targeted
and being able to trick an occasional government into using kleptographic

@_date: 2015-12-22 12:45:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Juniper & Dual_EC_DRBG 
We have an interesting new possibility, that this isn't an NSA
backdoor, it is the work of someone who re-engineered the NSA backdoor
for their own purposes.
If true, that gives us a new proof point in the argument against
mandatory backdoors.
Another possibility is that someone changed the constants to close the
presumed NSA backdoor but did not intend to create a new one. We only
know that there was a compromise at this point. We don't know if it
was exploited or by whom.
Backdoors are like landmines, they get buried in old code and blow up
long after the people who originally placed them have forgotten about

@_date: 2015-12-23 21:30:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A different twist on the constitutionality of 
I think there might be an argument to be made that cryptography is
protected under the bill of rights under the fourth amendment as well
as the first.
In numerous cases the court has found that a search is legal because a
party did not have a reasonable expectation of privacy. The assumption
being that if you don't act to make something private then it is
That argument presumes that there are steps that a person could have
taken to protect their privacy and chose not to use. Ergo, if they are
denied the right to protect their privacy with encryption they are
denied their right to protect themselves against unlawful searches.

@_date: 2015-02-03 13:43:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Best Practices for Passwords 
Best practice: Allow the user to get rid of them wherever possible.
For example, right now I am seriously considering changing my hosting
provider from 1and1 because they only offer password based SFTP for upload
to a Windows host. This in turn means that I can't use scripts to upload
work without either hard coding the password into the script (eek!) or
having to enter it every damn time.
How should this work?
1) I create a public keypair such that the private key is registered to the
machine, cannot leave the machine and can only be accessed by a signed
script that has a specific authorization to do so.
2) I register the public key identifier with the hosting provider as being
permitted to upload to that account.
Now I can add in my strong account names to simplify the process but they
are merely a bit of syntactic sugar to combine an account name and a key
fingerprint so I can do cut and paste.
What I think I will do instead is:
1) Create the public key pair, mark this non exportable
2) Generate a random password that I register with the hosting provider
3) Encrypt the random password under the public key and write it to a file.
4) Write a utility that pulls the random password from the file and uses it
for SFTP log in.
The more stupidity people pile on password restrictions, the more likely it
is I have to write the password down. Because chances are, your digital
assets really are not at all valuable to me.

@_date: 2015-02-05 23:21:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] best practices considered bad term 
Oh please...
Comparing Microsoft to Apple, you have to compare like to like. Which means
comparing Apples crappy 1980s based O/S without memory protection to
Microsoft's crappy1980s based O/S without memory protection. They are both
equally crappy.
Before his Steve-ship took over, Apple had another source of crappiness,
the old hardware was chronically unreliable. My mac would die many times a
day at a time when Windows could last several days.
By 2000 Microsoft had three different O/S builds current, all with very
different security issues. Apple was down to OSX.
If you want a completely secure machine run Open Genera. Not because the
O/S is any more secure than Windows, etc. Because we know the names and
address of everyone who every worked out how to use it and if they do
something bad we can get 'em.

@_date: 2015-02-09 11:23:19
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What do we mean by Secure? 
This is the wrong policy. You are never going to open those files, nor is
your wife. You don't speak binary.
Applications are going to open those files and what matters is that one
application does not go rogue.
We have the wrong metaphor for applications. They are not static objects,
they are zombies or gollems . We can give them tasks, but their true
masters are the wizards that originally brought them to life by their
Of course, I don't know of any system that would make such a policy viable.

@_date: 2015-02-16 20:45:04
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] phishing attack again - $300m in losses? 
Banks don't worry about fraud losses, they worry about the cost of fraud.
And $300 million is about the cost of 1,500 loaded staff. So proposals that
would require ten banks to spend 150 person years effort are not going to
interest them.
They are remarkably impervious to the argument that their fraud costs can
rise very quickly.
I remember when the rogue trader in France cost their bank a billion
dollars. Turned out that their compliance apparatus consisted of Excel
spreadsheets maintained manually.
What we could do to start with a fix is to recognize the need for malware
type filtering on all network connections and build in a standard socket to
the stack for that purpose. So if anyone is going to http:://
alwaysmalware.com/ they get a message back saying, 'oh no you are not'.
Google and Microsoft etc. all have these safe surf programs but they can
only say 'we don't advise that' because their relationship with the user is
that the user is their customer and they can't tell the customer what to
do. Anti Virus vendors can tell the user what to do because that is what
they pay us for.
I made a proposal 'Omnibroker' that would provide a standards based socket
that every application can plug into when opening up a network client
connection. I think that is a part of the solution.
Another part though would be to change the way applications are installed.
The default should be that an application runs in a separate partition and
does not see the shared file system or the general network. Least privilege
is your friend.
Unfortunately, as with many much needed developments, the response is
always 'users will never understand'. I think they underestimate the users
who have no difficulty using well designed tools. The problem comes when
the tools are botched.
It takes about 45 minutes to configure S/MIME in Outlook as supplied by
Microsoft. I have a tool that has no user interaction at all that does the
same in 5 seconds. If you want an external CA issued cert you may have to
give one extra piece of info - the DNS name of the CA. But even that can be
done away with.
The thing is that ALL of the actions required to administer certs in S/MIME
applications are unnecessary makework. But the failure to use encryption is
put down to the user when it is actually the fault of Microsoft management
for not telling their programmers that they have to do better.
What we need is a Steve Jobs who cares about security. It is quite possible
to implement secure systems that have Apple quality look and feel.

@_date: 2015-02-17 08:41:13
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] phishing attack again - $300m in losses? 
I think it would be very easy to set up a scheme for program installation
where all code has to be signed to run. The permissions are granted to the
signer. The first time code runs, the user is asked what set of permissions
it should run with. 'Game' would be a standard minimum priv setting that
causes the program to run in a sandbox.
Any attempt at privilege escalation is reported and goes to the signer's
This approach would make for a better development environment, everything
would automatically run in a custom sandbox.
The US is currently working up to spending tens of billions in
'cyber-defense' that does not include any defense at all. A fire department
has to know how buildings burn but that does not mean they have to devote
99% of their budget to training arsonists. Burning down buildings in Russia
and China is not going to make our buildings any more fireproof.

@_date: 2015-02-27 11:01:03
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
I have been using a Raspberry Pi 2 as a burner machine in a legal case. The
nice feature of the Pi being that I can pull the O/S image card, drop it in
an evidence bag and FedEx it to the lawyers.
This approach lets me:
* Use a machine in a verifiable known state
* Control exactly what is on the machine
But I would like to go a little further. In particular i would ideally like
a complete, signed record of every keystroke and the video output.
Some folk have been setting up screencapture (scrot) with a crontab job.
Since this is X-Windows, is there an easy way to insert an X-Windows logger
in the path?
This is all preparatory to being able to dump the recorded stream into a
timestamp notary system.

@_date: 2015-01-07 13:11:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
That is my understanding as well. It took me a long time to work out what
the steckering did because I could not really see what the point was. They
could have achieved a lot more bang for the buck if the steckering had some
sort of interaction with the reflector. As it was they just had two
orthogonal ciphers, a rotor cipher and a Ceasar cipher that was easily
stripped off with a meet in the middle approach.
In addition to what Jon raised, one of the biggest operational defects was
the habit of sending out 'test' messages of a single letter repeated. that
combined with the reflector no letter maps to itself defect made it really
easy to spot cribs.

@_date: 2015-01-07 22:42:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
I think people fail to take account of the advantage Enigma gave the NAZIs
early on. The Blitzkrieg strategy would have failed without efficient and
secure battlefield comms.
I think that is also what made them so confident in the Enigma. It was the
Fuhrer's prized secret weapon, suggesting it was breakable was to question
the Fuhrer himself.
Later on, what really destroyed the NAZI war machine was the paranoia that
the ULTRA decrypts introduced. Hitler believed everyone was stabbing him in
the back. Rupert Murdoch's wiretapping victims had the same experience,
they trusted their phones and the only explanation they could see for the
stories was that one of their friends had betrayed them.
This is why I didn't want folk going off looking for the NSA moles in the
IETF in the wake of BULLRUN. The damage done by the witch hunts would be
far worse than the continuing damage the moles could perpetrate.

@_date: 2015-01-12 11:01:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Compression before encryption? 
I think it is a bad idea to take too much from HTTPS experience. The
problem is much narrower and much more general.
First the HTTPS attack: if you put active code into a system and you allow
someone to manipulate one part of a message, this may allow them to deduce
other parts of the message. Well we could blame the compression but the
real problem here is the active code and the use of bearer tokens for
authentication: Get rid of one or the other or expect the pain to recur.
If you are using active code then you should assume that EVERY part of
EVERY message that the active code can initiate is disclosed to the code.
But turning off compression is a much easier fix than changing the way
cookies work. So we take the easy route as always and will wonder why it
breaks again.

@_date: 2015-01-13 23:22:35
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Summary: compression before encryption 
Its a little off topic but not much, but Rob Stradling and I have a way to
compress CRLs that are essentially just collections of hashes.
Yes, it is not possible to compress encrypted data if the encryption is any
good and this is actually a good check to see if you have goofed by using
ECB or whatever. But don't be too sure that random data can't compress.
Sometimes it can - we get down to 3-4 bits per revoked cert.

@_date: 2015-01-19 18:24:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Summary: compression before encryption 
Reading through a lot of the replies, it occurs to me that compression
isn't the problem, lack of padding is.
If confidentiality is an issue then message length almost always reveals a
great deal. I added padding to my DNS Privacy proposal because I realized
how much is given away by the message length.
But I am starting to think that the rule should be 'always pad if
confidentiality is an issue'.
In most cases, confidentiality is only a weak concern, its authenticity
that is the prime Web concern most times.

@_date: 2015-01-28 10:32:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Introduction to EC that is actually an introduction? 
I am being forced to give a talk on EC which requires me to understand it
to a rather deeper degree than hitherto. Or rather, at a lower level.
All the primers on the net I have found so far seem to be copied from the
Certicom one and don't actually explain a damn thing. They just draw a
couple of squiggles and put a line through them.
Has anyone seen a primer that is actually done well that I can crib from?

@_date: 2015-01-28 17:42:03
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Introduction to EC that is actually an 
Thanks all, am finding the DJB talk pretty useful.
What I use to explain the difficulty of Diffie Hellman is to show a plot of
a logarithm in regular math, nice smooth curve that people can see has an
easy to calculate inverse. Then I chop the curve into bits by introducing
modular arithmetic. Now it isn't nice and smooth.
Might be interesting seeing the graphical effect of the modular arithmetic
on the elliptic curve.
The Wierstrass curves that Certicom and most folk use to explain EC are
pretty much the worst ones to pick from the point of view of giving an

@_date: 2015-07-09 09:12:25
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The Mesh 
I posted this on the IETF lists, folk here might be interested in this work
Draft at:
After working on the problem of securing end-to-end email for quite some
time. I now have a scheme that really does meet my design goal of being
just as easy to use as regular mail.
If you are on a Windows box using Windows LiveMail (nee Outlook Express)
and you run the mesh profile manager it will automatically create and
register your S/MIME keys in the Mesh, apply for certificates and configure
your client to use them. The only thing the user has to do is to select
which accounts to enable for use with 'endymail' - end to end encrypted
email. Once the keys are registered, use is totally automatic.
If you then want to enable endymail on a second machine, all you have to do
is to go to that machine, run the profile manager, give it your account
name, request that it enable that machine, then go back to your first
machine (or another machine you have approved for admin access) and approve
the request. Job done.
Behind the scenes, the necessary private keys are being encrypted and
shared through the mesh. Unlike systems such as LastPass, the mesh is not a
trusted service, the keys used to exchange the configuration for endymail
in the public PKI (e.g. CA based, OpenPGP, something new) are managed using
a personal PKI.
There is some cleanup work to be done. The code does not support OpenPGP
yet but that is just a matter of some code. Getting the code so it will
work outside my lab is taking some time.
Before working on that, there is another, much more important problem to
solve - deployment. And to do that I need to think about deployment
engineering as a separate problem. The value of a scheme in which anyone
can send endymail is in the $billions ($1 per email recipient times 3
billion users ~= 300 billion). The current value my system adds to email is
$0 ($1 per email user times 0 recipients times 1 user).
And S/MIME and OpenPGP face the same problem. They have never achieved
critical mass and so all the potential of 'network effects' and 'viral
marketing' become the 'chicken and egg' problem.
So here is how I propose to address deployment. Endymail isn't very
valuable to the individual user until widely deployed. So instead provide a
system that addresses their biggest pain point - remembering the usernames
at all the 100s of Web sites they use that require username&passwords.
Remembering passwords is easy because you just use the same one everywhere.
Unless they have a password manager, that is.
Systems like LastPass have appeared to meet a real user need. But they
don't use end to end security and they aren't built on open, widely
reviewed standards. So the user is putting themselves in the hands of a
third party who demands way too much trust.
The mesh is designed be an untrusted service that can support secure
exchange of any sort of data through end to end encryption. It is sort of
like NNTP for cryptographic keys. To prevent abuse there will have to be
admission control or else we will have idiots trying to stream 4k video
over it. Denial of Service by people trying to wreck the mesh is a bigger
problem, any system that claims it can't be breached will have people
trying to attack it regardless of the fact that the breach claim only
covers confidentiality and integrity, not service.
In the short term that will probably mean requiring some form of proof of
work scheme so that the cost of an attack to an attacker is less than the
value. But once we get the email scheme built out, an introductions model
could offer the same degree of protection without the overhead.
Right now I am reworking the code and specs to make the scheme as
application neutral as possible and to stand up a test mesh.

@_date: 2015-07-09 19:32:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The Mesh 
It is currently a 'work in progress' which means that currently I have
three parts that all work on their own that I am trying to bash into one.
This is down from six modules three weeks ago.
The basic idea is that every user has their own personal pki. At the moment
I am using X.509 but it could just as easily use JSON, XML or whatever.
Each user has a personal profile which contains exactly one personal master
signing key which serves as a permanent root of trust. Every cert in the
user's personal PKI will ultimately chain to this root. The root has a UDF
fingerprint, for example: MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ-SV75J
[ has the details of
UDF, its basically just a generalization of PGP fingerprints using base32
encoding with some features to prevent data type substitution attacks]
So the key point of this scheme is that when a device tells the user that
its root of trust is MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ-SV75J, they know that
either that device is lying (i.e. the device is compromised) or it is under
the user's trust profile.
Every device also has a device profile that contains a device signing key,
a device encryption key and a device authentication key. These would
typically last the lifetime of the device.
So to join a device to a personal profile what the user sees is:
* They run the profile manager on the new device, they give their mesh
account id.
* The device gives the UDF fingerprint of the profile, they check it is
* The user then goes to a device they authorized as an administration
device for their profile, there will be a message waiting telling them that
such and such a device is trying to connect. If they approve the
connection, they can then select the applications they want to enable for
that device.
* They go back to their device, it is now working with the specified
The mesh does not do any cryptography at all, it is just a dropbox for
exchanging small quantities of crypto info. So in the above example, the
admin machine pulls the S/MIME and OpenPGP decryption keys that the device
is going to need to read emails and encrypts them under the device key and
uploads the profile to the mesh.
Note that this is not just configuring crypto. It can configure account
network connections as well.
Lets say someone is using mail on their admin device. And for the sake of
demonstration, lets say it is Windows Live Mail. The current code will
slurp up the configuration info from the app. Then it will ask which
account the user wants to enable (if there is more than one).
The tool will then automatically pull the network connectivity info from
Livemail, create S/MIME signing and encryption certs and configure LiveMail
to use them. And the user does not need to do anything.
OK so now the user buys an Apple Ring (oh you know thats what is next after
the watch), they connect it to their profile, include mail in the apps it
is enabled for and it is now configured to do email. The SMTP, IMAP,
servers are set up, S/MIME, everything.
So don't think of this just as a way to manage crypto. It can be used to
share any sort of application profile. Though its a pretty poor profile
that doesn't have crypto. You can have a network profile with your DNS
resolvers and protocols, VPN info, etc. You can have a Jabber profile,
password manager, SSH, pretty much anything you like.
There are proprietary schemes that do something of the sort of course. But
they are intentionally non-interoperable. I can't easily exchange my Chrome
bookmarks with Firefox for example. Chrome does not support the bookmarks
of the Google toolbar.

@_date: 2015-07-10 23:37:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The Mesh 
There are different levels of secret keys. The master keys are only ever
constructed once unless there is a complete catastrophic meltdown requiring
recovery. The admin keys would normally be password protected and kept on a
few machines.
Remembering ONE [Singular] password as a second factor without any idiotic
pa$$w0rd rules is pretty easy actually. Especially if you can have two
words in the password. But since it is only ever used to unlock a private
key that is on the user's device, brute force attacks aren't possible until
after the user has been breached.
The administration device at least must store the personal PKI's root
Actually, I have combined an idea by Brian LaMacchia and Phil Z.
The certificates for use in the mesh have a particular profile
1) The Subject key identifier is a UDF fingerprint (i.e. truncated
SHA-2-512 digest) of the KeyInfo Block
2) So is the Authority Key Identifier.
3) Policy constraints and other PKIX idiocy are utterly ignored as they are
utter crap.
4) Not using PKIX mechanisms for revocation. That is something that only
really makes sense in a public PKI.
5) Each will eventually have a timestamp embedded that has the current
integrity value of the mesh when it was created. This provides a method of
defeating backdating attacks.
6) I add my own extension OID allowing me to specify the mesh purpose of
the cert.
Reading through the docs on various chain building engines, I realized that
getting them to do what I want would be very hard. Implementing what I want
with some profile constraints, much easier.
A private PKI consists of of more than a dozen or so Certificate Signing
Certs. When I read them into my cert collection, I can construct all the
cert chains etc. with little difficulty. I verify that each cert is valid
according to the profile requirements etc, and check that it chains to the
root of the personal PKI.
I suspect you'll run into all the
You would not know you were using it. In use, the entire system is
completely frictionless. The only time a user ever needs to be aware of
using encrypted mail is when they want to force use of encryption or force
use of encryption with a key they have a verified fingerprint of.

@_date: 2015-07-11 13:49:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The Mesh 
Making trust decisions in a personal PKI is trivial. Either it chains up to
the personal root of trust that has his personal fingerprint or it does
not. The only way that a certificate can chain to her personal root is if
1) Alice signed it
2) Alice lost control of her key
3) The algorithm has been broken
I don't try to stop (2) beyond keeping the master keys offline and locking
the online admin signing keys to specific devices, instead I provide a way
to recover if there is a disaster.
 In use, the entire system is completely frictionless.
Yes and that goal comes before perfecting the security. This is pretty good
security, not perfect.
Using strong email addresses, the fingerprint of the root of trust for the
receiver is embedded in the email address. So if you send an email message
MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ?phb at hallambaker.com
The email address is legal rfc822 and can be stored in a contacts directory
but the username isn't legal on any operating system or sensible webmail
system (injection error city).
If the message is sent through the prismproof.org email proxy, it will
strip out the fingerprint, try to pull an email profile with the specified
fingerprint from the mesh and extract an S/MIME key that chains to that
[OK so right now it is doing that without actually doing the path math to
validate the chain but that is just a matter of coding]
Again, I think the scheme does not answer the most important question of
The mesh isn't a trust infrastructure. That is a separate problem. I have
written a paper on the problem but before I can work on the trust problem I
need to solve the distribution problem.
One layer of security is provided by having a CA issue a cert using an
email loopback challenge.
I am also looking into doing a peer to peer loopback automation scheme.
This is a consequence of working out how to automate S/MIME cert issue
(same approach works for OpenPGP of course).
Alice sends an email to Carol (who may or may not be a CA). It contains
ACME: MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ?alice at example.com;
   challenge=VGhpcyB3YXMgb2J2aW91c2x5IGFuIGV4YW1wbGUu
Carol responds:
ACME: MOF3W-K23MN-BYWY2-3FNJT?carol at example.com;
   challenge=cXdsa2VrbHF3amhlZmxranFoZGZsa2poYWRsa2ZqaGFsc2Rsa2pobA0K
ACME-Response: MOF3W-K23MN-BYWY2-3FNJT?carol at example.com;
   by=MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ?alice at example.com;
   challenge=VGhpcyB3YXMgb2J2aW91c2x5IGFuIGV4YW1wbGUu;
   nonce=d2xrZWpmaGFsa3NqZGZobGtzYWpoZGZsa2phaHN;
   result=kZmtsamhrbGFzZGtsZmtsYWpzZGhma2xqaAYUxLZXJ5M28
[Alice will now respond in like form in their next interaction]
So if the response is valid Carol has demonstrated:
 1) The ability to read email sent to carol at example.com.
 2) Control of a private key trusted in the personal pki with the root
that is authorized to respond to challenges.
This is a pretty good starting point for Alice and Carol to start
exchanging messages that are encrypted by default.
Of course, it is really desirable for any mail exploder or the like to
strip out the headers and responses should be ignored if there is an
exploder header in the response. Otherwise some mailing lists will get lots
of encrypted mail. But at this point there aren't many mailing lists that
are that broken.

@_date: 2015-07-12 21:07:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The Mesh 
Agh, no. The proxy code is available from there. You connect up to a proxy
on each local machine (127.0.0.1) and it uses TLS to boot.
 it will strip out the fingerprint, try to pull an email
Well the proxy is just an interim measure for most users until the email
apps have native support.
But if you are that paranoid, it is much easier to verify the open source
proxy isn't doing anything wrong than your email client.
But again, these are not the types of concern that 99% of users care about.
Right now the objective is to provide pretty good security, not absolutely
proven to not be sabotaged.

@_date: 2015-06-01 13:34:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Uniform Data Fingerprint 
Base32 does the same thing by excluding the corresponding numbers. Of
course, both could be less confusing. The coding was originally proposed by
Phil Zimmerman.
Maybe an explanatory note...

@_date: 2015-06-05 08:02:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Why is ECC secure? 
While we are on it. I can understand how DH works in any cyclic group.
Thats obvious.
The part I have difficulty with is why an ECC operation is a group. I can
kinda sorta see that for Edwards curves but the idea that the Wierstrass
operation is a group is distinctly non-intuitive.

@_date: 2015-06-06 13:48:35
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Why is ECC secure? 
I think that once you get above a certain level in math, everyone is
essentially self taught.
What makes subjects difficult to learn is often the set of assumptions that
people writing books make about what people already know. One of the
reasons the Feynman lectures on physics are so good is that he does not
make a lot of assumptions about what the students know.
That is why I start teaching public key cryptography with digital
signatures rather than encryption. The need for two keys in signatures is
much more obvious than with encryption. Instead of teaching about an X they
already know and then about a better X working on a very different
principle, teach a Y.
One of the things that makes the prior art searches I do quite challenging
and a work in the history of computer science is that assumptions about
what people knew have changed greatly over time.

@_date: 2015-06-14 09:28:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] let's kill md5sum! 
Breaking existing userland stuff isn't something you can fix
We had a long discussion of this on the OpenPGP list. This is the result:
The basic idea is that the fingerprint consists of a version/algorithm
identifier which is initially one byte and an optionally truncated hash
value. The default encoding is Base32 which is the best compromise between
density and convenience.
The initial spec has code points for SHA-2-512 and SHA-3-512 (the latter
obviously not implemented yet).
   The binary encoding of a fingerprint is calculated using the formula:
   Fingerprint = Version-ID + H ( Content-ID  + ':' + H(Data))
The point to this scheme is that it allows one fingerprint to be used to
declare a trusted anchor of any type or format. In the crypto space these
might be:
* Open PGP Key Binding   application/openpgp-key-v5
* PKIX KeyInfo element    application/pkix-keyinfo
* DNSSEC trust anchor   application/dnsssec-key
If you don't know the content type of a data blob, you can efficiently
check against a list of known content types without having to reprocess the
content each time.
A code distribution is a type of trust anchor. We could use the content
type application/executable but it is probably better to differentiate
according to processor architecture, binary format, etc.
One of the changes in the industry that more folk should be taking notice
of is that Microsoft has put their .NET code out under an MIT open source
license and will be supporting OSX and Linux platforms. Starting to use
managed code by default for crypto and network code would be a huge step
forward in security.

@_date: 2015-06-15 13:44:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Sunday Times Snowden Decryption claims 
By now you are probably familiar with the claim that among the papers
released by Snowden was a 'NOC List' of agents working under cover that the
Soviets decrypted and have used to kill them all.
Some folk have been suggesting the story is a nonsensical fraud on the
silly and spurious grounds that:
* There is no such thing as a NOC list outside stupid Hollywood movies.
Names of agents are never ever written down, let alone compiled in lists.
* MI6 has Officers working for it, CIA spies are called operatives. An
agent is a source and can be any source. Half the people on this list are
probably regarded as 'agents' because whether intentionally or not, knowing
or not, they have provided information to an operative in the past.
* If such a list did exist, it would be compartmentalized intelligence.
There would be no reason for a signals intelligence outfit to have such a
list, let alone Snowden.
* If such a list did exist, it would be encrypted with 256 bit encryption
minimum and the suite A ciphers are almost certainly at least as good as
But no, these are silly quibbles.
NSA can break any encryption. That is just a fact. So it is time that we
have to admit it and remove all the silly export restrictions on encryption
algorithms that can be broken because everything can.
Carry on.

@_date: 2015-06-15 20:16:26
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Sunday Times Snowden Decryption claims 
When a publication as authoritative and respected as the London Sunday
Times states that Russia can break NSA crypto at will, who can gainsay them?
The original story was so absurd I thought it more interesting to point out
that it actually argues against their objective rather than in favor.

@_date: 2015-06-15 21:43:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Sunday Times Snowden Decryption claims 
Quote: "when you are dealing with the world of intelligence it is
impossible to say anything with certainty"
The scientific term for this is 'bollocks'. Here are some things we can say
are impossible with absolute certainty.
1) Snowden disclosed US plans for a warp drive
2) Snowden disclosed US plans for a teleportation device, replicator or
any other Star Trek type technology.
3) Snowden disclosed plans for a time machine
The idea that the US would use a cipher so weak that the Russians could
break it is only slightly less preposterous. The idea that such an
incompetent agency would then find out about it...

@_date: 2015-06-17 10:59:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Anyone know of crypto hooks in webmail systems? 
Webmail is beginning to dominate. But adding end to end crypto to Webmail
is hard. Various platforms tout their extensibility. But finding a single
line of documentation is hard. And the documentation provided tends to be
pretty useless.
Extending webmail to handle OpenPGP or S/MIME or the next nest thing should
be fairly straightforward:
On reading: Just spawn off a separate viewer for the content type.
On composing: Activate the compose pane in a separate process so that Web
content can't see what is being done.
Anyone know of these or similar hooks?

@_date: 2015-03-01 08:47:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
Pretty much the whole Web Services world is going to JSON because it is a
simple data model that is widely supported. Unlike XML there is pretty much
only one way to serialize a data stream on the wire rather than fifty.
Which is why some of us suggested that we would like a binary encoding for
the JSON data model so that an encoder could emit either and a decoder
could read either.
I wrote this up as:
JSON only uses 7 bit ASCII code points for control data. That leaves 128+
data points for tagging binary data types which is more than enough.
All that is really essential to encode crypto data nicely is an option to
encode text strings and data blobs as length-data items. JSON-B adds those
plus binary integers and floats. There is also a compression option to
allow the text headers to be dispensed with and a data variant with more
floating point types.
For security reasons, only atoms are encoded in length-data format. Lists
are delimited by an end list control. This produces much more reliable
coding and avoids read past end of buffer errors.
In particular, a decoder can verify the syntactic correctness of each token
in the stream in a single pass using only the data previously read.
Checking correctness of an ASN.1 file is a real horrorshow because an inner
length encoding can be inconsistent with either an outer or an inner one.

@_date: 2015-03-01 08:52:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
If I am using a Raspberry Pi with a clean O/S install from a source I have
checked the thumbprint of, I have a lot more control than is possible using
a TPM.
The TPM is really designed to solve a different set of problems to do with
running the system for a long period of time. All I am doing here is
reading some Web pages with Chromium.

@_date: 2015-03-01 09:43:25
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
This is rhetoric, not argument.
Yes, I have read the Thompson paper and like much of the UNIX security work
I find an obsession with issues of mostly academic importance.
I remember back when folk were doing all the work on cryptographic
elections in the 1990s and the concern was to protect confidentiality.
People really didn't get my assertion that what I was interested in was the
ability to audit the election.
The concern here is to be able to provide the exact same environment to
opposing counsel so they can examine it.
A TPM really does not help very much because it is a sealed box that the
whole security of the system depends on and I can't audit it. I certainly
can't expect to explain it to counsel.
It is really easy to throw the 'transitive trust' problem, the TPM is just
as vulnerable.

@_date: 2015-03-01 10:58:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
I don't think it is possible to put any system beyond the possibility of
doubt. The point is to reduce the attack surface as far as is practicable
but not demand superhuman efforts. Yes, an intel agency might have got into
ATMEL and jiggered the microcode of the chip. But at least when I am using
a Pi I only have the microcode and a very small bootstrap reading data from
the SD interface to worry about. That is a lot less than a BIOS.
If we are considering questions such as whether Bob who is divorcing Alice
snuck into her house and planted a trojan on her machine so he could spy on
her with his webcam, I don't think we need to consider the possibility that
the NSA corrupted the hardware.
The machine I am checking the image fingerprints on actually has a TPM. But
I don't see how it helps in the slightest.
If an intel agency can jigger the pre-boot firmware of a Raspberry Pi, they
can jigger the TPM.
What I could do to improve the scheme would be to move the checking of the
image fingerprints off onto another machine that is entirely offline.
A TPM really does not help very much because it is a sealed box that the
That is way beyond what any counsel would ever put in front of a judge
unless absolutely vital.
It is really easy to throw the 'transitive trust' problem, the TPM is just
The silicon foundry undoubtedly has a broader attack surface. But thats OK
because another group I work with are very concerned about the problem of
making those secure...
As far as court cases go, the criteria is 'best evidence' not 'beyond
possibility of doubt'. We put evidence in tamper evident bags for example
but it is normally assumed that a forensic investigator isn't engaged in
perfidious behavior and deliberately sabotaging things.
Look, if you're happy with your approach in court, power to you. It's
Well there are two parts to the problem. The first is how to establish a
trust axiom. The second is how to collect and preserve evidence from the
I am focused on the second part and removing as many variables as I can
from the evidence collection phase.

@_date: 2015-03-01 15:07:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
Which in practice means rewrite every damn library yourself if you want to
be sure.
Yes, I can write that code but I don't and can't trust anyone else to.
Still, I'll agree that people get this on-its-face trivial bit of coding
Which is what I use for everything: JSON, XML or ASN.1. I have one for
RFC822 headers as well. I use a tool whether I am going to use C or C
Problem is when you encounter other people's stuff.
XML DER is the pits because the length values are themselves of variable
The trick I have found with XML DER is to actually write out the structures
in reverse. This has the effect that the length of each structure can be
finalized at the time you emit the data and you can do everything in one
pass. Or if you want to pre-allocate the data in one chunk and not worry
about having to extend the output buffer, make two passes.

@_date: 2015-03-01 19:17:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
The question I think is who you have to make the proof to.
Normally I am using a machine and wanting to prove to MYSELF that nobody is
attacking ME.
In this case the problem is how to show that I have nothing up my sleeves
to third parties. And this is the same problem we face on things like the
I don't think that works either. I think that we have to get into
ceremonies and protocols here. For starters, lets have more than one person
make a device.
Lets say I go through a ceremony to create an image, sign it and post it on
a site. I then ask everyone here to download the image, put it through
their local tools and tell me if there is a difference.
Can even do the same thing with commitments etc.
Sure there are still going to be holes in the protocol but each layer of
ceremony is increasing the opponents work factor. And work factor is what
it is all about.
One reason I prefer something with SD card firmware. But again, not perfect
as they have some firmware etc on them these days.
The other thing that Emin was perhaps hinting at regarding malware in the
And so much better if we have created the image in advance of the case

@_date: 2015-03-02 22:47:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
OK how about this for a protocol
1) We make the hardware and seal it in some sort of tamper evident resin.
2) We set up a notary log infrastructure. Let N(t) be the output at time t.
3) To notarize a document we first encrypt under key N(t) thus creating a
document that nobody could predict how to decrypt when the device was made.
4) We calculate hash values etc. over the encrypted data.
5) We have two devices. The first takes the SD card and produces an
encrypted image. This is then transferred to the second that calculates the
hash value.
6) We then use the decrypted image as the master????

@_date: 2015-03-03 08:51:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proof of preservation... 
So folk have probably seen the flap over Clinton's emails. The latest claim
being that all the mails were archived.
Leaving aside the politics of the situation (GWB era emails went through a
server run by a GOP political outfit that was probably infiltrated by every
intel agency on the planet), how would folk go about establishing a proof
this had been done?
In the past the reason to avoid the govt. servers would be wanting to avoid
getting into an Ollie North situation and be proven to have lied to
Congress in the recovered emails. But it is also possible that a concern
was not wanting the NSA to know what State is up to.
Some sort of notary log would be required of course. But that only allows a
demonstration that the archives are complete with respect to the log which
isn't the same as ensuring they are complete.

@_date: 2015-03-03 12:56:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
Err where do I plug in the keyboard and screen? How do I use this system to
make the forensic investigation from?
Can I pull content off YouTube and watch it? Can I pull data off a hard
A TPM is designed to permit trusted code implementing a small number of
very security critical functions to operate in a trusted environment.
Things like public key crypto and such.
A TPM does not and cannot protect every O/S function and applications have
to be specially written to make use of it.
No thanks, I think I will use one that provides an SLA and is run by
someone who I trust and can act professionally in a public forum thank you.

@_date: 2015-03-04 11:47:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
My machine works exactly the same regardless of whether the module is
plugged in or not. So how is it protecting me? Like firewalls, I worry that
TPMs risk becoming a +5 amulet of protection against the undead rather than
being understood as a tool that has a very specific purpose.
Some might say the Thompson ?Trusting Trust? paper makes that goal
Thompson was provoking an argument. He never argued that the problems were
impossible to solve.
Security is risk control, not risk elimination. What I am looking to do
here is to see if we can work out to apply parts of what we applied when
setting up the original VeriSign PKI to a wider field. The VeriSign
approach is documented in the CPS so I am not divulging proprietary
information and in any case Symantec came to CABForum to share the same
with the CA world in general.
In particular, I like the use of ceremonies to formalize process.
[Something Carl Ellison has also said a lot of useful stuff on]
I want to look for ways to make collection of digital forensic evidence as
airtight as possible without introducing unreasonable expense or requiring
exceptional expertise or special hardware.
The reason I am starting with a Raspberry Pi 2 is that it is a very simple
device with minimal moving parts that boots from removable media. But if a
case involved a specific brand of computer such as Windows or Mac, I would
want to have a protocol and a ceremony that covers that eventuality as
well. [Windows for Raspberry Pi is also very interesting of course].
Extending to Beaglebone and using devices of one type to cross check
another seems like an excellent move as well.
There are some very small and constrained builds for Raspberry Pi. Console
only O/S etc. Those would also be very interesting to look at.
My understanding is that TPMs are limited to a very small set of functions
such as ensuring that private keys generated on the device can't be
exported or become visible to a program that might export them.
Also TPMs and trusted boot are two different things.

@_date: 2015-03-04 20:09:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] FREAK attack 
0. You don't get more security by adding stronger ciphers to a system. You
get more security by stopping use of the weaker ones.
Also, I note that we get one of these events about once a month while CA
issues occur at a much lower rate. Every time there is a CA event there are
people proposing to do away with CAs. But nobody ever seems to come to the
same conclusion about browsers...

@_date: 2015-03-05 08:18:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
I think we need to take a step back and ask why anyone is going to move to
a new messaging platform and work from there. Security isn't the answer,
that is merely an abstraction to most users.
Instead, consider the following problems with current messaging platforms:
1) They are fractured. In the old days we had mail and news that were
almost but not quite the same thing. The Web started to bring them closer
together and then Netscape decided to blow them apart. Today we have mail,
chat and webcams in the one to one space and mailing lists, blogging, blog
commenting, Tumblr-ing and tweeting in the many to many space.
2) The messaging platforms are widely abused. This is largely due to a lack
of accountability and the notion that publishing an email address is
license for anyone at all to send content of any type.
3) Ownership of the forum and the content has been appropriated by
intermediaries. In most cases merely because they got there first. Facebook
and Google have too much power over what is said.
4) They don't protect provide necessary confidentiality or integrity
similar. MIME content types and URIs solved the problem of supporting
diverse content types in one medium long ago. But we still have the
artificial boundaries between modes of communication.
Now developing an infrastructure that replaces all the existing messaging
forms just to add crypto might seem like a boil the ocean approach. But
that is exactly what Tim did with the Web which replaced all the extant
information sources with one user interface via gateways.
Now that Google is getting a bit impatient with its Google+ strategy not
outstripping the Facebook walled garden with a walled garden of their own,
perhaps they might be interested in getting behind something designed to
knock the walls down.

@_date: 2015-03-05 20:00:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Anyone know of a hackable VOIP server with 
Does anyone know of a hackable VOIP server that has like *complete*
instructions on how to set it up, including where to go to get a phone
number routed for it, etc. etc. Does such a device require a static IP
address, etc.
Also where to get the hardware necessary to plug my home phone system into
said box?
In the past I have asked and people have said 'go look at asterisk' but the
documentation is of the 'if you already know what you are doing' type.
What I am thinking of is that it would be nice to be able to plug the home
telephone handsets into a box with the property that it looks at the number
dialed and if it starts with a certain area code (666) it then look them up
in a local directory and places the call via an end to end encrypted VOIP
link and bypasses SIP, etc. etc. entirely.
There would then be a Web interface to said server that would allow me to
define mappings from the 666 exchange too my private directory and the
public key identifiers to use, etc. this would in turn allow me to dial
people from the commodity handset as if they were a regular phone number.
The reason for choosing 666 is that I doubt the US telco service is ever
going to use it (though a lot of folk would probably pay for it).
Plenty of closed systems on offer of course. But I would like something
like a DIY vonage box.

@_date: 2015-03-07 13:36:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] FREAK attack 
I think the question is still not very useful. At each moment in time there
was a preferred algorithm for security and a necessary algorithm for
Due to poor design in the TLS upgrade mechanism, the transition time from
one to the other is about ten years. And what makes things worse is that
the browser folk have historically taken too long to deploy new algorithms,
then when the old ones have looked ropey they have made a great show of
rushing to the exit.
So my list of preferred ciphers is fairly short, starting in 2000 when the
export control laws were abandoned:
2000 Necessary: RSA1024, SHA-1, RC4
2001 Preferred: RSA2048, SHA-2-256, AES-128
2010 Preferred: RSA2048, SHA2-512, AES-256
201x Preferred: IETF-EC-448, SHA2-512, AES-256
Curve 25519 is acceptable for perfect forward secrecy but only with some
changes to the key exchange so the session keys are generated from the
WF128 and WF256 keys and not just the weaker one.
Now if we get into modes, then we can discuss HMAC versus AES MAC modes.
But I don't think the above would have been unreasonable.
I would like to see us clean up house for 201x and kill off the zoo of
legacy ciphers. Every one of those ciphers is a potential weak algorithm.
At each time we should have exactly one necessary algorithm and one
Vendors should commit to a ten year service life for any crypto algorithm
that starts to expire only when they ship the replacement. In the case of
SHA-1 that was Service Pack 3 in 2008. So guess where the blame for the
phase out of SHA-1 taking so long should really belong?
This is not an argument for staying with SHA-1, rather it is an argument
that Microsoft should pull its finger out and start shipping SHA-3 now.
Because otherwise we are going to be going through the whole SHA-1
transition again in 2025 or so.
Vendors have to learn that you don't wait till SHA-1 is considered
vulnerable to start shipping the replacement.
The ECC thing is a little different because the situation there has been
complicated by too many specifications and too few actual standards.
All in all, this would be a good time to checkpoint the TLS stack and
declare a TLS/2 that kills the legacy cruft and starts from a solid
baseline. So no ocsp stapling option, stapling is mandatory, instead of 200
cipher suites reduce it to one mandatory to implement plus one backup and
then push all the rest of the crud out to optional proprietary extensions.
Make PFS and SNI required, introduce a mechanism to allow the handshake to
be encrypted under temporary keys passed in the DNS. Etc etc.

@_date: 2015-03-09 12:40:28
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cheap forensic recorder 
And guess who was unpopular at the kick off meeting for the Trusted
Computing Group when he made that point?
MSDOS was trusted, didn't make it trustworthy.
Overall, this discussion would have been better informed if the assumptions
Which is how I use this list. If I knew what the requirements were I would
have the solution.
Most people find it difficult or impossible to really discuss requirements
without some sort of strawman solution. Like my college tutor, Tony Hoare
used to keep pointing out to us, a waterfall model of developing the
perfect requirements statement followed by the perfect specification and
then implementaion almost invariably fails.
A while back I wrote to him pointing out that it actually works pretty well
for the consultants as a way of extracting money from their
victims/clients. I haven't fallen for that one directly but I have been
involved in acquisitions where the first thing you have to do is to tell
the manager to fire the company they paid $10 million for a project that
has delivered nothing but specifications and the next thing you do is have
someone fire the manager.

@_date: 2015-03-12 08:53:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Digital Certificate Forensics: Clinton Email 
I have been reading the various pronouncements on the email server. It
seems that a lot of people are making statements that are idiotic and wrong.
As a general rule, I don't comment on other people's security issues unless
they have asked me to or it affects the rest of the community directly.
I have seen many people comment on the situation and in every case the
money quote from the techie is that Clinton's email server suffered from a
particular security problem that just happens to be the one that their
product fixes. And none of the journalists have picked up on that.
It is generally agreed that penetration testing servers is quite difficult.
Anyone who thinks they can pen-test an email server five years after it was
installed should quit the industry and become a psychic. There is a
vacancy, Sylvia Brown died a couple of years back. And she made more money
than most folk in our line of work.
These statements are not just unprofessional, they are career limiting and
can cost business. Venafi is now on record having made a partisan political
statement attacking the person generally considered the front runner in the
2016 Presidential race.
Someone might think that running Microsoft IIS without their security
product makes them woefully insecure. But saying so in this context is
self-serving marketing rather than an objective expert opinion.
When I was working with the Executive Office of the President on some of
the whitehouse.gov systems, an individual known to us all here was in
Congress being asked about security scanners. He claimed that he had
scanned the whitehouse.gov domain and found the systems to be vulnerable.
Five minutes later they were slammed by people launching probes.
Someone who does not know what is behind the fence has very little way to
know what is inside. And when the systems in question are running Open
Genera (the lisp machine O/S) over a stripped down version of ULTRIX,
chances are that any holes are not going to be uncovered by the typical
probe. Since there was no reason to let people on the outside know what was
inside, the servers intentionally reported false server version
What makes this whole situation even more ridiculous is that we know for a
fact that the official state dept systems that 'should' have been used were
completely insecure because Chelsea Manning has provided us with copies of
all the cables.
Clinton was working within the paradigm set by gwb43.com. If it was legal
for members of the Bush administration to use non-government email then it
was legal for members of the Clinton administration to do so. The question
then is why both parties would want to do such a thing.
In general, politicians are very aware of and concerned about security
because they are highly visible targets for attack. But the form of attack
they are most concerned about comes from their political opponents.
Being aware of this issue, it is normal practice for politicians to avoid
ever committing statements they know might be incriminating to paper. I do
the same. Even though I have secure email and my telephone conversations
can be intercepted fairly easily, I use the telephone for a lot of
sensitive conversations because they are less likely to be stored and
Without end-to-end security, SMTP email puts users totally within the power
of the network managers, many of who are likely to support the other party.
The state dept classified cables were in fact attacked in this way but this
is discounted because the perpetrator was opposed to both political
Disclosure under FOIA is not at all the same thing as having a partisan
investigator like an Issa or an O'Keefe publish a subset of the messages
that intentionally misleads.
The solution then is to develop and deploy security systems that meet the
needs of both the politicians and the public. We already have pervasive
deployment of S/MIME capable clients, all we need is to solve the usability
problems so that people can use them in practice. S/MIME is capable of
solving the disclosure issue. If we combine that with an extension of the
Certificate Transparency technology, we can address much of the records
issue concern as well.

@_date: 2015-03-12 09:48:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Securing cryptocurrencies 
There is a much more interesting result in social engineering: It is not
necessary for a Ponzi scheme to be orchestrated by a profit seeking
individual. A group of highly intelligent people are quite capable of
constructing a private reality and commit roughly a billion dollars of real
money to it despite abundant evidence that what they are doing makes no
The Euro recently declined by 25% in a year and people are wondering about
its viability because price stability is an essential property of a
currency. Meanwhile we are told that bitcoin is great because of the
This result is important because it provides an explanation of the workings
of Wall Street and other financial markets that would otherwise be
On the plus side, BitCoin fever has brought a lot of new folk into the
crypto field which remains understaffed. But in the short term a lot of the
new entrants have let to learn than running a BitCoin wallet app on your
phone and reading the literature on it does not make a person an expert in

@_date: 2015-03-13 12:35:28
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IBM looking at adopting bitcoin technology for 
The idea of using a hash chain as the ledger in a settlement system is well
established. It would not be remotely difficult to find prior art. Harber
and Stornetta discuss such schemes in their original paper.
The only thing BitCoin added was the idea of combining the blockchain with
the proof-of-work notion and using the latter to get the early adopters
invested in the scheme.
The proof of work scheme is not the only way to prevent a notary defecting.
In fact it isn't even a particularly good way to achieve it. A much simpler
approach it to establish multiple notaries and have them engage in a mutual
meta-notarization protocol on a periodic basis.
While this second approach does open up the possibility of a default, the
operation of the notaries is transparent. There would be no difficulty
identifying the party responsible for the breach and taking them to court.
This is a much better scheme unless the BitCoin ideology is swallowed whole
and we are to believe that the future of commerce lies therein.

@_date: 2015-03-25 17:57:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] How to crypto secure speed limit signs 
The context information is provided by the spacing of street lights (!)

@_date: 2015-03-26 14:05:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Zero Knowledge for Opening the Cockpit of an 
This is sadly a very well known problem in security: Almost every
security problem has a very simple solution if that is the only
problem that is a concern.
If all you care about is hijackers boarding planes you barricade the
cockpit door. If all you care about is pilots crashing planes in a
suicide you remove the cockpit door.
Exactly the same problem occurred with London Taxis a while back. Due
to a couple of design flaws (reverse hinged doors, latches that look
like window winders) people kept getting killed accidentally opening
the doors. So journalists started a campaign and poo-pooed suggestions
that if the taxi driver controlled the door lock they might kidnap
women and drive around not letting them out. Guess what happened when
they introduced locks?
Security is hard because it requires consideration of multiple issues.

@_date: 2015-05-08 22:37:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A Fun Trick: The Little MAC Attack 
There is actually a mode where they could matter. There exist
applications where a MAC is used as the digest for a signature. This
enables a mode where the signature can only be verified by someone who
knows the secret without the loss of non-repudiation that a straight
HMAC entails.

@_date: 2015-05-10 15:45:49
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A Fun Trick: The Little MAC Attack 
At the time HMAC was proposed we did not have AES. In fact we didn't
have any encryption scheme that was satisfactory. The best was 3DES
which was a hopeless performance suck.
As a matter of principle, I dislike your scheme because it will go
belly up if the same key is used for authentication and encryption.
A better approach would be :
hash(key + Encrypt(key, message) )
Of course at this point we are into the realm of authenticated
encryption and we might as well use a construction that is provable.

@_date: 2015-05-19 12:06:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] NYT on Nick Szabo and Bitcoin 
My concern would not be government retaliation but the risk of kidnapping,
extortion etc. by folk wanting to get their hands on the reputed $1 billion
in bitcoin Satoshi stashed away in the early days.

@_date: 2015-05-19 17:57:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
Fortunately, the SHA-1 deprecation is going to kill most of the unpatched
XP versions.

@_date: 2015-05-27 17:28:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Uniform Data Fingerprint 
We use message digests as data fingerprints in lots of places. OpenPGP
being the most visible of course but fingerprints are also used in BitCoin,
for software distribution and even in S/MIME
The OpenPGP group was discussing approaches to a new fingerprint format
based on Base32 so that we can squeeze more bits out of the data on a
business card. So generalizing a bit, I came up with this:
The basic function is
   Fingerprint = Version-ID + H ( Content-ID  + ':' + H(Data))
   Where
   H(x) is the cryptographic digest function
   Version-ID is the fingerprint version and algorithm identifier.
   Content-ID is the MIME Content-Type of the data.
   Data is the binary data
Putting the MIME content type in the scope of the digest means that if the
same data string has meaning in two different contexts, an attacker can't
perform a substitution attack. It also means that whoever is interpreting
the hash has to know the context in which the data is being used.
The fingerprint is base32 encoded and set in chunks of 5 characters for
easier reading/verification. The precision is always a multiple of 25 bits
using simple truncation:
100 bits - MB2GK-6DUF5-YGYYL-JNY5E
150 bits - MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ-SV75J
The version/algorithm identifier also defines the algorithm used. The
predefined identifiers are 96 for SHA-2-512 and 144 for SHA-3-512. These
produce mnemonics for 'Merkle' and 'Spongeworthy'
This might seem a little overdone, but the payoff is that say you have
trust list as follows:
You can have a trust list embedded in a device and it can stand for
anything you need to be trusted. Could be the operating system executable,
could be a PKIX root cert, could be a PKIX CTL, could be a PGP key. We can
now direct all queries of the form 'is this anchor trustworthy' to this one
list regardless of context.
That is something simple enough that we can think about silicon
implementation someday.

@_date: 2015-05-27 23:08:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Dark Web should really be called the Twilight Web 
Tor certainly works for some of its intended uses. If you are in a
repressive state and want to get access to CNN or the like, Tor is your
friend. It isn't going to prevent a police state noticing that you might be
up to some sort of unapproved activity but they won't be able to tell the
difference between a dissident and someone surfing for porn etc. So it is
useful and reduces risk in countries like Iran or Russia. But using it in
North Korea would mean risking a death sentence.
Where I don't see Tor being remotely safe is trying to operate an online
Drug bazar as a hidden service. I mean seriously guys, cryptography isn't
magic and traffic analysis is a very effective tool. Tor is still going to
help your customers keep their identity secret but it isn't going to stop a
determined law enforcement team with pervasive Internet access tracking
down your server. Not when the hidden service is trying to become a
consumer brand with global reach.
So I think a change in terminology is needed. It is not just that people
are not taking security precautions due to a false sense of security, some
people are ordering up mob hits because they think they are in a permissive
environment that is accountability free.
Rather than calling it the dark web, the term Twilight Web seems more
appropriate to me. It is possible to hide but only if you know how and only
among the trees.

@_date: 2015-05-28 14:16:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Dark Web should really be called the Twilight Web 
Well they certainly have Tor instrumented and they certainly have channels
for passing information to the FBI. That was one of the things they were
hit for.
Which might just explain one of the Silk Road issues that has not been
explained which is what happened to the $1.1 million that DPR paid to what
now appears to have been a clever con artist.
The emails sent by Dread Pirate Roberts are fascinating as he was persuaded
to pay a guy $650K to organize five hits and then lent him another $500K.
All in bitcoin.
But the thing that I find odd about the scam was that he had the background
knowledge on DPR and his activities to know how he could be conned.
Seems to me that a very plausible explanation would be that the NSA
analysts who originally tipped off the FBI were behind the scam.

@_date: 2015-05-28 15:13:35
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Dark Web should really be called the Twilight Web 
Fill is very expensive at the network layer but (almost) trivially cheap at
the link layer. The cost comes in having to think about how much data is
disclosed in the link layer framing. This is not necessarily a performance
issue but can certainly be an architectural constraint.
If a non-fill switch has no load, a packet is going to appear on one port
and be routed to the destination immediately. That provides a tell for the
path taken by that packet.
If the switch has link layer fill so that every link is encrypted and
exchanges garbage during quiet time, a packet arriving in the situation
above will either end up queued behind a junk frame or require the junk
frame to be aborted in some fashion.

@_date: 2015-05-30 11:02:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Uniform Data Fingerprint 
Yes, had difficulty drafting that bit. At this point I am keeping the
architecture requirements and the implementation completely separate since
other folk may disagree with either (and have reason). If I have left out
an important requirement it might require fundamental changes to the
At this point the consensus on the OpenPGP list seemed to be for reserving
a byte for version ID.
Putting the MIME content type in the scope of the digest means that if
Yes, was just being lazy with the content-type declarations :)
Interesting idea. I don't think there is going to be much need for this
however as I don't expect to add a third value for a decade at least,
probably longer. I don't think the typical user needs to know which one is
used. The only exception would be trying to use an Sxxxx- fingerprint on a
machine that does not implement SHA-3-512 which is pretty common right now
as the FIPS isn't published.
I'm unsure about section 4.  What's the point in just talking about it?
PGP Word List is one possible choice, but it was designed almost 20 years
ago when memory etc. were very scarce and it is designed to be read out
over a VOIP connection. Those constraints limit it to an 8 bit encoding.
The 16 bit encoding I have someone working on would require half the number
of words to give the same strength.
At this point I don't want to make a fixed choice. It would have to be
internationalizable in any case.
Another similar issue is curating an image alphabet for the same purpose.
Back in 1995 this approach would have to use a very limited number of
images because we didn't have ubiquitous networking and we didn't have the
option of looking images up.
Another very important change is that problems that require a lot of
unspecialized effort may be more practical than problems requiring a small
amount of highly specialist knowledge. Finding five people to write (good)
crypto code is hard. Finding a thousand people to crowdsource an image
library might well be easier.
If the image library is stored on a bunch of servers round the world and
authenticated under a Merkle tree, a connected device can convert a
fingerprint to images very quickly.

@_date: 2015-05-31 10:00:19
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] open questions in secure protocol design? 
I think the original question was baddly worded. The choices offered were
one child and 19 and counting. There are obvious problems with both. Which
is why most people look for an heir and a spare.
One of the problems with algorithm agility is that the mere ability to have
a hundred algorithms does not provide any agility in practice because the
tendency has always been to implement the current algorithm and a half
dozen legacy algorithms.
Microsoft .NET gives you lovely algorithm choices, If SHA-2-256 doesn't
meed your needs you can use MD5, SHA-1 or RIMPEMD.
The reason it took so long to deprecate SHA-1 is the long tail of machines
from the era when regular O/S upgrades were expected. Even now there are
all those companies whose IT departments show their uncompromising
commitment to security by continuing to run Windows XP.
Which is why I think that for future protocols we have to have TWO
mandatory to implement algorithms, at least for not severely constrained

@_date: 2015-11-01 12:45:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Are zero knowledge authentication systems safe? 
The model I have always used to attempt to demonstrate robustness is
fairly simple. I start with the private key and look at everything
that 'touches' the key, i.e. has a dependence on it.
So the CPU touches the key and it consumes power and emits radiation.
Here we have a choice of two authentication algorithms. In particular
we potentially emit
ZK: x+r
PHB: H( e^xy + r )
where r is random
For the ZK proof we are absolutely depending on the randomness of r.
If there is any pattern in r then x will leak, no question. So it is a
brittle system.
For the PHB preferred approach, we are leaking a value that has a
strong dependency on x but it isn't a useful value. The only case in
which the value is going to be useful is if r is repeated. And if we
did that in the ZK proof the system becomes an oracle for r because
the attacker can simply ask for r instead of x+r.
We can save the simple ZK system though. let us say that as with the
simple ZK system we begin by committing e^r and the challenger has a
choice of
1) returning the proof that they didn't fake the commitment. (i.e. r).
2) presenting e^y and returning H(e^xyr)
It is still going to be a bear as far as CPU goes - 128 ECC
operations. That is a problem even for ED25519.
We can parallelize the rounds easily enough. This shouldn't be more
than a 2 or 3 round protocol. But the person attempting to log in is
going to present n*256 bits of commitments at some point where n is
the number of rounds we want. Thats 4KB for a WF of 2^128.
We could also offload operations from the client to the server so the
client does 196 ECC operations to 65 for the server.
Using a fast machine and an optimized implementation and Adam
Langley's code which is 200 microseconds for DHE, that would be 50ms
or so. Not horrible but still quite significant.
Hmm, might be do-able but is the extra security worth the effort? Its
not just implementation etc. I would have to spend a week crawling
through the literature to see if anyone else had the same idea and
patented it.

@_date: 2015-11-02 12:09:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Are zero knowledge authentication systems safe? 
This isn't an issue with the formal approach, it is a problem with the axioms.
In a perfect world XOR (x, RANDOM) is a perfect cipher. In practice
the best you can do is XOR (x, RANDOMISH) and you don't have
In the real world H(x) is not a perfect one way function but we can
make a one way function that is good enough to prevent someone
reversing it except by brute force. Even fairly weak digest functions
are still secure for this purpose.

@_date: 2015-11-07 15:47:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Literature on reusing same key for AES / HMAC? 
I think this particular discussion demonstrates the difference between
the breaker and the builder mentality and why being skilled at one is
not necessarily an indication of skill at the other.
risk from using one key with two separate ciphers is irrelevant as
that is something I never do. If I need separate encryption and
authentication keys, I will generate them using one way functions k1 =
H(m, x1), k2 = H(m, x2). I always take the conservative approach
unless there is a really, really good reason to work at the bleeding
should have built the system isn't very relevant. What they care about
is whether a particular system can be broken. And so if you are
starting from a system that has mixed up two types of crypto, the
question is very relevant.
What I think the industry needs is more of a balance between breakers
and builders and in particular, we need builders to step up and be
willing to be as visible as the breakers. Building secure systems is
hard. And people start laughing the minute you even suggest you can do
Breaking is also rather more entertaining. I love to hear someone
describe how they roto-rooted the braindamaged security system in some
car as much as the next person. That stuff is funny. And so we have
conferences that now have more than half the tracks made up of
'hackers and threats' tracks.
This is a problem because the reason employers send people to those
conferences is that they want secure stuff, not employees who have
been thoroughly entertained for a week hearing about the braindamage
in other people's products.
Google's recent change of slogan from 'don't be evil' to 'do the right
thing' is actually an important and necessary step. It is a sign of
maturity. As Marcus Ranum pointed out, enumerating badness is a
failing objective, there is an infinite amount of badness and so if
your guide to choosing a path is not doing the wrong thing, you will
never start off. 'Don't do it wrong' is a paralyzing approach to
security because there is very rarely a perfectly secure option on the
table and sometimes what appears to be the correct path isn't the
right one to take.

@_date: 2015-11-09 23:53:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cryptogit 
As some folk will know from my facebook feed, I have been struggling
with git over the past week.
With a considerable amount of hassle, I now have the systems running.
Its not pretty and there are good reasons for the usability horrors.
SSH and GIT both bump up against the PKI bootstrap problem when in
comes to sharing public keys. Fortunately that is the problem I am
currently working on and git is now one of the applications I hope to
make a lot easier to use with the Mesh.
Anyhoo. Let us imagine for a moment that it is really easy to connect
up to a git repo in the cloud. On your Google drive or your 1Tb
OneDrive or whatever.
Wouldn't it be really nice to be able to automatically encrypt the
data you store in the remote .git repo?
It probably wouldn't be all that hard to arrange either. Just a few
extensions to the git file format to write out encryption headers into
each of the object files and encrypt the body.
As folk have noted, proxy re-encryption 'recryption' can be used as
leverage to simplify the key management problem once a certain patent
expires in a couple of years.
Anyone interested?

@_date: 2015-11-12 20:07:36
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Ransomware: Newest viral marketing gimmick ? 
What the NSA keep for you.
They won't give it you back when you ask

@_date: 2015-11-15 23:48:22
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Satoshi's PGP key. 
If I was going to try breaking Satoshi's keys... that isn't the one I
would pick.
Not unless the price of bitcoin drops a lot.

@_date: 2015-11-17 13:18:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
It is assumed that the terrorists used encryption. However other
reports mention use of a Playstation 4 and that the VOIP channel isn't
As Perry knows, I don't agree with him on gun control. But even I am
not going to argue that gun control would have stopped this attack. We
can argue over whether DAESH is a state or not. But what is not
disputable is the fact that they have state level resources. They are
not the resources of a rich developed state but they aren't
inconsequential either.
DAESH seems to have no difficulty obtaining AK-47s and brand new
Toyota Highlanders. They can obviously find a hacker who can vet
OpenPGP sources and compile it for them.
Limiting access to crypto ability might arguably allow Fort Meade the
opportunity to dump some crypto with a backdoor on DAESH. But we can't
base public policy on that sort of remote possibility.
The other part of the 'regulation' proposal is that there isn't any
proposal there. The idea seems to be that NSA/GCHQ makes a demand and
those clever boffins working for Microsoft and Google produce a scheme
that will meet their requirements without the requirements even being
The people behind these proposals have a top down view of the world in
which the general orders something and it is done. They might as well
order us to come up with a tractor beam or a transporter. The NSA has
been unable to develop a working security scheme themselves, that is
how they were rolled by Manning and Snowden.
Are we supposed to re-engineer the platforms so that it is impossible
to run crypto code?
Are we supposed to put backdoor keys for the US into products sold to China?
How about the reverse? Backdoors for everyone?
And just what do we do if the problem we are facing in 24 months time
is the remnants of DAESH hacking into US and UK critical
infrastructure? What happens if we are trying to keep information
confidential but we can't because we have agreed to a UN sanctioned
backdoor scheme and one of the members is giving the access codes to
whoever is hacking into nuclear power stations?

@_date: 2015-11-19 09:53:36
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] 
I am getting so fed up with unsourced nonsense stories.
The CIA is fully capable of making an official statement. The CIA
director and the DNI regularly give press interviews, public speeches
and testify in Congress. If either the NSA or the CIA believes these
things are happening and believes we should know that is the case,
they can do so by having a named spokesperson give an on the record
So there are three possibilities when it comes to evaluating claims:
* The 'official sources' either are not sure about the information or
are simply lying
* The 'official sources' are leaking information that the agencies
would rather remain confidential for operational reasons.
* The claims don't actually come from an official source, they come
from someone who is pretending to know more than they do or have come
from an official source through a long line of intermediaries who have
completely misunderstood or misrepresented what was said.
It now turns out that there is absolutely no evidence of a Playstation
4 being involved in the attack. What happened was that this was put
out as a hypothetical to show how hard the problem of intelligence is
today and this hypothetical was assumed to be an example.
It now turns out that there is absolutely no evidence of the Paris
attackers having used encryption. The cell phone that was recovered
has only short SMS messages that would only convey information to
someone who already knew the plan. There is no need to encrypt a
message that says 'Go'.
The Paris attacks were conducted by a group of people who had military
weapons and had been trained to use them. There is no evidence of any
communication between DAESH HQ and the attackers of any sort. But even
if the attack was performed on orders from HQ, there is no reason to
believe that these amounted to anything more than 'kill as many
infidels as you can in a European capital of your choice as soon as
possible'. There is no reason to believe that DAESH HQ would have
anything to contribute to the planning of the attack.
So what we have here is a clash of cultures. The highly centralized,
rigid, US military is unable to function without constant
communication. At this point, the decision to launch missiles from a
drone is frequently taken at the level of Colonel or above. Being used
to this situation, the US military seems unable to comprehend that
another organization would not consider it necessary. Which is really
odd since only a few decades ago, US special ops would have conducted
operations under complete radio silence as a matter of course.

@_date: 2015-11-21 17:15:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on key 
Oh Its obvious, isn't it. To break AES at 128 bit strength:
1) compile yourself the biggest rainbow table you can - say 2^64
plaintext, ciphertext blocks.
2) Troll through 2^64 blocks of ciphertext, looking to see if anything
becomes recognizable.
3) Repeat
Chances are that you will get a match that you can leverage further at
least 1% of the time.
So anyone using less than AES 256 is making a big mistake. In fact all
block ciphers are vulnerable to this form of meet in the middle.

@_date: 2015-11-21 17:23:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on key 
OK to explain further. Yes, you have to do 2^128 operations but we are
not doing 2^128 crypto operations, we are just looking for ciphertext
blocks that match our cribs.
What we did to prime the attack is to start by encrypting a set of
chosen plaintexts that we know recur in the messages. Setting up a
finite recognizer to decrypt those messages is then fairly
Yes, you are only going to decrypt a small percentage of the messages.
But that might well be enough.

@_date: 2015-11-21 22:05:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on key 
Probably more often than you would want. Known plaintext is fairly rare but
very guessable plaintext is much more common and using that only adds a
little to the complexity of the attack.
The point here is that I don't just get the decrypt of one block, I can
work out the key used to encrypt that block. And if I know that, I can
(usually) work back to figure out what the original key was.
There are a couple of ways to defeat this type of attack. One would be to
effectively randomize the plaintext by pre-encrypting with something like
RC4. This would make it much harder to use the 'guessable plaintext' attack.

@_date: 2015-11-22 00:48:22
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Chrome dropping DHE (was Re: [FORGED] Re: 
Doing a DHE should never have reduced the effective security.
If the cert has an RSA2048 bit key, you should never have to get less
than RSA2048 bit security. Instead, the protocol was jiggered so that
the strong key negotiated with the cert is only used to authenticate
the ephemeral key and the result of the weaker exchange is used.
I am pretty sure that was an example of 'BULLRUN' in action.
We should insist it is fixed when we move to the CFRG ciphers.
Using a 1 bit ephemeral exchange with a 255 bit static ECC key should
mean you end up with 255 bits of static security and negligible
ephemeral and not negligible security.
The keys should be constructed using H ( StaticAgreed + Ephemeral ).
It is the obvious way to do it.

@_date: 2015-11-22 16:06:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] US Congress Vows To Criminalize First Amendment 
She appears to be saying she is backing crypto controls but when you
look at what she actually says, she is saying nothing that isn't
Yep, we have told the US govt that no compromise exists. There is no
pixie dust technology that allows the good guys to read the bad guys
Problem is that producing a crypto infrastructure to secure the
communications of a tightly knit group of terrorists is actually
rather easy. AES/RSA-2048 and a bit of simple steganography (PNG files
using the least significant bit) is a high school project level
programming task.
The systems we produce don't attempt to defeat targeted surveillance,
or traffic analysis at anywhere near the level that a non standards
based scheme designed for a handful of highly motivated users can.

@_date: 2015-11-23 09:42:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] US Congress Vows To Criminalize First Amendment 
So she is demanding we do something we are doing already and you are
getting upset?
Which is currently her job.
But right now she is also setting a rather low bar for us to cross in
order to declare the encryption issue settled.
I am quite happy working with the feds on next gen crypto. I can show
them how to avoid that problem they were having with Snowden and
I have the Mesh running and I am itching to release a demo. But I am
not going to pour fuel on that particular fire right now.

@_date: 2015-11-23 12:30:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on key 
Unless someone was to goof and leak the key by screwing up the XOR.
Problem is that you need to know the XOR value or the key for the other
en-whitener (e.g. RC4). If you don't have a separate key derivation
mechanism, you aren't actually getting the benefit. You have just invented
a new cipher with an extra round. Albeit an extra round of a very different

@_date: 2015-10-01 08:27:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Insecure Chip 'n' PIN starts tomorrow 
Are there any attacks against EMV that don't involve using the payment
mechanisms that only require the card number?
If the magstripe transactions go away, how much card present fraud is left?

@_date: 2015-10-01 19:54:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Insecure Chip 'n' PIN starts tomorrow 
Both papers describe attacks on the legacy or transitional features.
If the banks are checking the transactions correctly, the counter based
fraud is detectable. And the rest is the 'fallback fraud' that depends on
being able to circumvent the EMV system completely.
Neither is a good reason to delay deployment of EMV.
The most important change that comes with EMV is realigning ability to
impose security measures with liability for the loss. The fact that a bank
can screw up and get defrauded is irrelevant AFAIC f they are going to be
bearing the responsibility for the loss. Companies that sell crap POS
terminals will get sured out of business.
Which is of course where most of the complaining about Chip and Signature
Incidentally, it seems Chip and Sign is actually a better security solution
overall because Chip and PIN encourages people to enter their PIN into
things that are not ATMs. And the ATMs are taking the longest to get
switched over from magstripe.

@_date: 2015-10-02 10:52:04
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Insecure Chip 'n' PIN starts tomorrow 
So, what they can do is to downgrade a Chip and PIN transaction to a
Chip-only transaction.
Its only a break in the protocol if the designers weren't aware of the
It is fixable, but in 2010 the fixin's I would use were patented.

@_date: 2015-10-09 08:04:13
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Spec for SSLv1 
I pointed out the lack of authentication but not as concisely. Alan
Shiffman made the comment. Later Simon Spero pointed out a long list of
problems, most of which were fixed by Paul Kocher who got a ten days of
consulting to design the protocol.
I don't follow TCPINC.

@_date: 2015-10-09 18:59:59
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Reproducible results, scientific method, 
I would discount that sort of claim because one of the things about fraud
is that most of the widespread ones tend to move through affinity groups.
A while back we noticed that a heck of a lot of dentists were being caught
up in Ponzi schemes, not just one scheme but several. And so people were
theorizing about dentists being more susceptible.
Then there was the Madoff fraud where he had separate feeder funds for the
Jews, the Christian evangelicals, etc. and the reason was clear. Basically
the reason the frauds spread is because the groups communicate. Doctors go
to conventions, dentists go to conventions, they know each other through
loose connections on a once a year sort of basis. Retirees go to
'investment seminars' as something to do.
Any large scale fraud requires a feeder network to support it and while
some of those get rolled up when the scheme crashes, some do not and they
have address books full of contacts in one particular community.
Finally criminals prefer to rob rich people than poor people and they
prefer not to try robbing people who might spot what they are up to. So
boiler room operations are not going to go after Wall Street investment
bankers and lawyers are a bit risky. Who is the next richest group of
easily identified professionals?

@_date: 2015-10-09 22:18:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Elliptic Curve Key Sharing 
What I would do is encrypt the data under key S, then split that into SA,
SB, SC and encrypt SA under a key agreed with XA, SB under a key agreed
with XB, etc.
There are extensive games that you can play with the DH cryptopuzzle. In
fact it is rather more open to them in many ways than RSA is. If P and Q
are DH public keys, then so is P+Q. And you can calculate X^(P+Q) = X^P .
There are some IP claims but the one that gets in the way should expire in

@_date: 2015-10-11 19:42:59
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Collisions w/SHA-1 ~$100,000 TODAY 
What have my ears got to do with anything?
Could people please stop panicking? Even if an attacker can cause a total
collision, it should not allow them to do anything bad in PKIX or TLS
unless someone goofs.
The WebPKI is like a car that has run flat tires. It is *designed* to be
safe to drive with four flat tires but unless you have a really good reason
not to, you should get the tire replaced as soon as it blows.

@_date: 2015-10-16 18:47:35
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Fwd: freedom-to-tinker.com: How is NSA breaking 
If you don't use a pre-computed prime you have to check the prime
presented every time and that is something we can't trust people to do
The solution is to compute the session key so that it is a product of
the pre-master secret and the ephemeral exchange.
What the protocol does right now is generate a strong shared secret
(s1) and then use it to authenticate a DH exchange with shorter keys
producing a weaker shared secret (s2).
The problem is eliminated if w use H(s1 + s2) as the shared secret.
Which is what I proposed at the time and got told I was being a
trouble maker, unhelpful, etc.
I am pretty sure that there was at least one NSA snot involved in
making sure that didn't get fixed. BULLRUN shows they were spending
$250 million a year sabotaging security standards work. One way you do
that is to introduce subtle flaws but another, equally important thing
is making sure that you don't let anyone who is too clever near the
control levers.

@_date: 2015-10-17 16:45:53
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Fwd: freedom-to-tinker.com: How is NSA breaking 
If you could collect the private keys you could do a MITM attack.
That really isn't as easy as you suggest. But in general, every
cryptosystem should be designed so that even if one component breaks,
the system remains secure.
When using PFS with ECC keys you probably want to use a 255bit PFS
exchange with a 448 bit key for performance but you don't want to
reduce your overall security level.

@_date: 2015-10-31 11:42:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] composing EC & RSA encryption? 
They now have a pretty unique challenge. They are charged with
protecting information security for the US govt. while simultaneously
having been caught boasting internally about their attempts to
undermine those efforts.
The NSA is not a monolithic organization and it doesn't have a single
view. The folk we talk to are almost exclusively from the civilian
side where all the expertise lies. The folk who set policy are the
management class who are exclusively military. And those are the
people who represent the organization in Congress and the WH.
The US military hasn't really thought about defense except in terms of
attacking and annihilating the enemy since the civil war. If you read
the Snowden papers as a group of majors campaigning for promotion to
colonel by stroking the egos of the generals with stories of their
daring conquests. War is so much more fun when you don't have to even
mention to the President what you are up to. Cyberwar is their new
growth opportunity. The US govt already spends a trillion dollars a
year on militarism and the generals would very much like to add cyber
as a new, fifth domain with a 25% increase in funds to match.
They aren't used to accountability either, or having their ideas
challenged. The US culture of deference to the military is peculiar
and dangerous: We will honor the sacrifices of the enlisted man of
life and limb by never questioning the actions of the generals who
decided those sacrifices were necessary. Of course, not being a US
citizen, I have a somewhat different perspective to those who are. We
went through the imperial phase once as well.
The civilian side knows about this of course and so do many retired
senior NSA generals. They understand that cyber isn't like any other
form of warfare, it is like terrorism, a domain where the great powers
and in particular the West are uniquely vulnerable. We can't terrorize
ISIS and not for lack of trying. The torture chambers of Abu Ghraib,
Gulag at Guantanamo, the daily drone strikes only make them worse. We
can't win an offensive cyber-war but we keep trying. Stuxnet may have
delayed the Iranian nuclear program by a month. It is still launched
daily with payloads targeting us.
If you are in a glass house, it is a bad plan to throw stone throwers
with an inexhaustible supply of ammunition.
So the NSA is in the position of having unique expertise in the field
and is uniquely untrustworthy and they are trying to lead without
being visible.
The Suite B advice does make sense as input from the civil side. Right
now it is clear that ECC is suddenly starting to move. I expect to see
ECC become the default in crypto apps in the next 5 years. Suite B was
developed a decade ago, it reflects a different era of cryptographic
At this point it is clear that Suite B isn't going to be the standard
for public key crypto. The CFRG algorithms will - unless they do
something deranged. But those aren't finished yet and certainly not in
a form that the US govt can endorse. So the NSA move makes perfect
sense, they withdraw the advice that is about to be rendered obsolete
rather than suffer a visible defeat and they remind folk that they
have expertise and knowledge the rest of us don't. Specifically, they
know if they have a Quantum Computer and we do not.
I expect that what we will see is that when CFRG is completed, those
algorithms will be endorsed by NIST. Then there will be a major
bureaucratic fight in 2017 when the next administration takes over and
attempts to transfer responsibility for cyber-defense from NSA being
the primary lead to NIST or some new agency in the civil sector.

@_date: 2015-10-31 22:04:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Are zero knowledge authentication systems safe? 
Let us assume that we have a provably secure zero knowledge system. Is
it actually more secure in practice than other techniques?
The reason for my concern here is that one time pads are theoretically
perfect but practical versions have been broken see Venona.
So for example, looking at the version in Wikipedia:
In each round, Peggy commits to e^r mod p and reveals either r or x+r
mod p where x is her private key.
Now if the random number generation is perfect, nothing is lost. But
what if it isn't? What if the random number generator has been bongoed
or is just bad? If the random number generator has only 32 bits of
ergodicity and Peggy reveals x+r, she has given Mallet the ability to
break her key.
Now consider a non zero knowledge mechanism, Peggy knows x and
discloses e^x. Bob challenges her with e^y, Peggy returns H(e^xy).
In this scheme, Bob knows something that he couldn't know any other
way. But we can make that knowledge arbitrarily useless by adding in
information that is specific to the protocol, the time, the place,
parties, etc.
Lets say we are doing this for authentication to a mail server. Let
R=e^xy. Let the proof value be H (R + "Peggy" + "Bob" + "Using this
for email" + "2015-10-31"). There is a small risk that information
might leak and be useful to someone but it is very small. Peggy
certainly hasn't put her private key at risk in any way at all unless
the hash is astonishingly broken. More broken than MD4 broken.
Am I just missing the point or is this particular zero knowledge proof
rather brittle in practice?

@_date: 2015-09-03 11:26:03
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
This is another reason to move to Diffie-Hellman. It is somewhat ironic
that all this time later we suddenly relearn that the very first public key
scheme was actually a lot better than those that 'improved' on it.
DH does not allow you to encrypt data directly. But it does allow you to
exchange a session key and that is all that is needed. Indeed the fact that
neither party has direct control on the choice of key provides something of
an extra check.
So what happens if you have a chip with a DH private key on it and you
modify the private key by one bit?
I can't prove it right now. But I am pretty sure by a handwavy argument
that you are still secure since there are no weak keys in DH (except for
keys like 0, 1 which are only weak because they are close to the default
starting point for brute force).
The mental map I have on RSA is islands of security in a sea of insecurity.
If you have a product of two primes you are on an island and safe. But
otherwise you are in the sea and the sharks can bite yer. DH is only solid

@_date: 2015-09-03 12:54:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
But if you are using ElGamal you get a signature scheme that is based on a
secret DH key. OK so you have that secret in there that mustn't leak or it
will divulge your key. But I think the robustness argument should still

@_date: 2015-09-11 10:53:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] millions of Ashley Madison bcrypt hashes cracked 
A large number of the users likely had multiple accounts. The way sharks
work is that first they try chatting a woman up with approach X till they
are rejected. At that point they have invested some time in finding out
about them and have as collateral a lot of personal details. So on approach
2 they can refine their strategy, oh I am also into ultimate pogo-frisbee
what a coincidence!
Welcome to fin-land.
Reading the forums, it looked like men were creating female accounts so
they could see what approaches other men were taking.
Thing is, you only need to convert 3% of 30 million accounts to have a
million paid accounts. I suspect most people signed up for the lowest tier
and realized it was a scam. That is still $60 million.

@_date: 2015-09-13 22:28:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [FORGED] Re: millions of Ashley Madison bcrypt 
Yes, but they were taking them off-site TO ASHLEY MADISON. That's where
they got their associate fees from.
So you really can't judge AM fake profiles by the same standards. Nobody
was spamming AM to sign folk up for other sites, they would have to pay for
each contact.
Basically, the site seems to have worked on the same basis as those in-room
porn movies that weren't actual porn because that might get them into
trouble. Collecting $15 from enough mugs trying the wares in the hope of
getting the good stuff was enough to make a pretty pile...
Still, how do we do AM right with cryptography? That should be the thing we
look at!

@_date: 2015-09-14 11:34:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
No, we have very different values. Comey works from an office building
named after an individual who committed some of the worst abuses of office
in any democratic country. And he committed those abuses to deny black
people civil rights and to deny union workers the right to fair wages and a
whole raft of causes I do not recognize as any type of 'value'.
Comey's office is unique in a democratic county in combining the office of
head law enforcement with head of counter-intelligence. The techniques and
methods that are appropriate to one are completely incompatible with those
that are appropriate to the other.
The blurring of the lines of responsibility meant that there was no
distinction made between FBI law enforcement activity and counter-espionage
activity. And since counter-espionage is also an NSA function, between the
FBI, a civil law enforcement agency and the NSA, a military agency run by
generals who I have heard to talk in private like a Pinochet or a Franco.
I believe in accountability and the FBI obviously does not. There have been
no investigations, let alone prosecutions of the officers and politicians
involved in the Bush era torture program. And every officer serving in the
NSA does so under an 'up or out' promotion program that requires them to be
promoted every two years or lose their job. This inevitably means that
there is no internal accountability as any officer who refuses an illegal
order from a superior is simply denied promotion and eliminated. That
approach to management is what permitted and sustained the culture of
criminality at Enron.
The fact that the FBI has found even the laughably lax requirements for
getting a court warrant too much of an inconvenience is ample demonstration
that they don't believe in accountability.
And that is before we get to the fact that information gathered under the
PRISM collection of programs was used for a long list of illegal purposes.
Including as swap collateral with Israel.

@_date: 2015-09-14 14:36:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [FORGED] Re: millions of Ashley Madison bcrypt 
This is at a lower level than I was thinking. Sure Tor is an OK technology.
But lets architect on a clean sheet of paper and then decide on the best
I see a number of requirements here:
1) Ability to advertise a service / interest / etc. anonymously.
2) Ability to review advertisements anonymously.
3) Ability to express an initial interest in connecting to someone via some
sort of restricted, reputation filtered channel designed to mitigate spam.
4) Ability to respond to such requests with accept / reject.
I think 1 & 2 can be served by any old Web / Blog hosting service. So all
we need is the link in to 3. Which I think need be no more than a handle on
some network that binds to a public key:
MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ at cheaters-r-us.com
So I pull the profile for MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ from 'somewhere'
(doesn't need to be the hook-up point). That gives me a description of how
to contact that person that is signed by a key that is signed under the
root of trust with the UDF fingerprint MB2GK-6DUF5-YGYYL-JNY5E-RWSH.
The contact details could simply be, 'here is a dead drop box, send me a
message'. Or it could require a proof of work to deter spam and so on.
Hard one to deal with is reputation. Sites that work tend to use
reputation. If you use reputation it becomes very easy to map out the
social network and that tells you everything.

@_date: 2015-09-18 14:11:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Microsoft's new, free, 
No, it is highly characteristic of them. They have been releasing code
under an MIT license for most of the 20+ years I have been working with
When Bill Gates criticized the 'viral' nature of GNU, he gave his explicit
personal support to the BSD and MIT licenses at the same time. Gates never
criticized open source software as a whole, what he objected to was the
clause that makes it impossible to use GNU licensed software in proprietary
or MIT licensed work.
And before folk fly off the handle and try to tell me that I am wrong, no I
am not. I have discussed this at some length with RMS when he complained
about the release of libwww as public domain code rather than under a
restrictive license like GNU. That was a decision the CERN team made
deliberately and consciously so that the code could be used and reviewed by
people working for DEC and Microsoft in particular. Microsoft did not come
to us, we went to them and asked them to make the Web a part of Windows 95.
One of the reasons we are unlikely to ever see an open source version of
Windows is that nobody knows the exact copyright status of the code and it
would cost a fortune to work it out. Microsoft didn't write all the code.
Large parts were written under contract. Before Microsoft could release any
of the code they would have to go through it and determine where each line
of code came from and whether the licensing terms permit release.
What Microsoft has just done which is of great significance, I believe is
to release the core of the latest version of .NET and the C# compiler under
an MIT license.
What this means is that for the first time since the decline of the
p-system we have a genuinely open, widely supported and unencumbered
infrastructure for managed code. As my college tutor, Tony Hoare observed
in his Turing lecture, people who are serious about security use languages
that are capable of making run time checks for array bounds checking.
If you are serious about security in 2015 you are writing managed code.
Unlike Java, the .NET system is based on the intermediate representation
used by the compiler rather than a byte code designed to be interpreted. As
a result, .NET code is considerably faster than the Java JIT compilers can
produce. The system is also free of the proprietary claims that have been
raised by Sun and now Oracle.
This isn't an accident. When DEC started to collapse in the mid 90s,
Microsoft was one of the principal recruiters of DEC staff. Anyone familiar
with the DEC house style is immediately familiar with most Microsoft
developer systems. Visual Studio is the logical successor to LSE and
VAXSet. Digital was one of the principal companies that instigated the
X-Windows and OSF consortiums, both of which adopted MIT license.
So no, this is not at all out of character.

@_date: 2015-09-20 19:28:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Microsoft's new, free, 
Yes, that and being unable to modify a printer because the code was closed
At the time there was something of a racket in which people would take
millions of dollars in US govt. grants to build software systems that would
then be claimed as proprietary property. That was one of the issues that
Gates agreed was problematic.
Getting back to security, one of the majort changes with managed code is
that unless deliberate steps are taken to obfusticate, decompilation is
fairly straghtforward.
Having source code seems to me to be a 1990s level concern. Having source
is good but not enough. The biggest problem I have is knowing provenance,
is the code I am going to run the code I intend to run. Does the compiled
match the source.
Using the CLR approach provides the opportunity to optimize to the specific
platform with only one executable to sign.

@_date: 2015-09-22 16:35:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Follow up on my password replacement idea 
I disagree.
I think what is needed is a mechanism for managing a personal PKI so that
there is no need for device authentication.
So what I do with the mesh right now.
* Every user has their own profile with a master signing key.
* Fingerprint of the profile is the fingerprint of the master signing key.
* Every device has a device profile
* Every device profile contains a unique signature key.
So if Alice has a master signature key with the fingerprint:
Anyone can go to the Mesh and pull the profile for that fingerprint. That
contains a collection of device profiles which are signed under an
intermediary key which is in turn signed by the master signature key.
So from a protocol point of view, I think it is obvious that we can very
easily set up a scheme so that the device can prove that it has knowledge
of a private key that has a credential chain under MB2GK... to authorize
use as an authentication key. Further I think we all know good ways to
ensure that the private key can only be unlocked if a passphrase is entered
into the device to give a second factor (e.g. x = y + H(passphrase))
What I need to show then is how easy it is for Alice to add and remove
devices from her profile published in the mesh.
To add a device like a cell phone Alice has to do the following
1) Post a connection request to her mesh profile through her chosen portal
(e.g. alice at cryptomesh.org).
2) Check that the request is posted to the right profile by verifying that
the profile tool returns the correct fingerprint.
3) Confirm the connection request from a device that is authorized for
administration and has the right key.
At this point the profile manager on the admin device adds the new device
to the profile and posts the update to the mesh.
Removing devices is trickier because it amounts to revocation of an
assertion. That means that the portal has to be trusted to actually post
updates to the mesh.
And that is a known hard problem. We can bound it in time by requiring
Alice to log into one of her admin devices once a month so that an updated
profile gets pushed. We can also use blockchain/CT like techniques to make
default visible. I have several solutions that work, it is a question of
how much effort is required for how much security.

@_date: 2015-09-22 21:08:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Follow up on my password replacement idea 
Still a ways off, getting close though. About a month of coding and a
couple of weeks documenting.
Protecting the keys is easier if every machine has different keys and keys
are never ever removed from devices, only deleted.
I am particularly interested in Matt Blaze's proxy re-encryption work that
was mentioned here. That can be added in as an extra layer of security.
One criticism I'm sure you hear is that the Mesh publishes private keys to
I am applying some things I learned working for Tim Berners-Lee on the Web.
(Meta Mathematical Mesh is MMM which is a reflection of WWW). One of the
most important being get the user interface right as your first priority.
Don't be afraid to do less than 100% of the problem in the first iteration.
The web succeeded in part because it just threw out search and referential
transparency as problems to be solved by other means. Google and web
authoring tools with checking for dead links filled those gaps.
Once we get something working, we can work on reducing the scope for
traffic analysis. Once very simple control is to pad profiles to prevent
attacks based on guessing the number of characters used. Another is to use
the hash of key values for indexes rather than the values themselves.
Yet another scheme to consider is that there is a division between the
portals (DNS registrar equivalent) and the mesh providers (a sort of
confederated registry). At present updates are reflected in real time. But
I am thinking that should change and instead a given portal should limit
mesh updates to one per profile every 24 hours. That limits the amount of
churn in the mesh without significantly exposing users to a portal capture
attack (user switching costs must always be negligible). It also limits
privacy leakage to a minimum.
But using the Mesh is going to expose people to a degree of traffic
analysis, no question of that. Just like the PGP key servers do. I am ok
with that if the amount of leakage isn't significant compared to what we
leak by using IP in the first place.
Yep, these are tough problems.  To take this to the next level, the Mesh
An authentication profile could specify geolocation data and that could be
used to limit access. But then you leak more information.

@_date: 2015-09-23 10:40:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Follow up on my password replacement idea 
One of the things this has forced me to do is to abandon the notion that we
just think about stopping breaches. If you put crypto in the hands of
ordinary people they are going to mess up. Even professionals have messed
up without external attackers trying to provoke it.
Having separate device keys does not reduce your attack surface, that is
true. But it gives a lot of leverage for mitigating the damage. Devices are
going to be stolen. Right now if you lose a device, it (typically) has all
the access codes for all your apps and you are completely pwned.
Right now I am coding for phase 1 which is based on RSA with no exotic
crypto at all. In phase 2 I am going to be looking to add proxy
re-encryption 'recryption' techniques to further mitigate disclosure risks.
There are two objectives here:
1) Give the typical user 'pretty good' security. This means a security
scheme they can use without burning themselves. Static encryption keys have
to be escrowed or they will sob when they lose the pictures of the kids
taken at 3 years old.
2) Give a knowledgeable user the ability to completely control their
security without having to know math or use unfriendly applications.
At a minimum, you want signing to be done a separate process running as a
Yes, you are right that this is an area where real value can be added.
Right now I am building on Windows since there are at least hooks that
could in theory link to a TCB. If you have something better, that could be
added in or you could offer it as a value added.
Yup. I am so pissed about the folk who spent so much time and effort
tailing against 'trustworthy computing'. They were carrying water for the
NSA even if they didn't know it.
It means that each device can have a separate decryption key for a single
public encryption key.
This gets us into the realm of trusted untrusted services. Like the key
generation scheme I described a while back, the Mesh has the property that:
1) The Mesh itself is always an untrusted service. It does not offer any
confidentiality guarantee and therefore cannot suffer confidentiality
breach. It offers only a qualified service guarantee that is time bounded
by blockchain techniques.
2) A Mesh portal is a trusted, untrusted service.
2a) A Mesh portal cannot compromise a user unless a user screws up.
2b) If a user screws up, a Mesh portal can help the user mitigate the
damage as a trusted service.
In this case lets say Alice has three devices, A, B, C and A is the admin
machine that has the decryption key for the encryption key. This is used to
generate a recryption/decryption keypair for each of B and C. The
recryption key goes to the portal.
In normal use, the portal can't decrypt the message because it only has a
recryption key.
If Alice loses device C, she can tell the portal to stop recrypting to C.
The portal still can't read any messages but Alice is trusting them to help
mitigate the risk.
Actually, I meant privacy issues similar to what we see today with
This is where I want help from folk here. The Mesh is like the Web, it is a
platform for deploying crypto that is intended to let people plug lots of
things in.
Again, we can apply the recryption trick. So I create a username N paired
with a public key e^X. I then provision each connected device with a device
specific authentication key and recryption key d, e^(X-d). These are
encrypted to the device master encryption key and provisioned via the Mesh.
This allows each device to have access to that site via the authentication
key without linking it to the profile in any direct way.
The aim is to get to the point we reached with the Web. Until late 1994 we
were pushing a heavy rock uphill. After whitehouse.gov went online we had
reached the top and it went down the other side of its own accord.
I am sure lots of people will be able to add FIDO or go beyond.
A major challenge in authentication is doing it in the presence of
Well one of the reasons Comodo is backing this is that it creates brand
awareness for our anti-Virus.

@_date: 2015-09-23 15:16:19
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Follow up on my password replacement idea 
With the Mesh there should never be a need for an application key to be
exported from any device with the exception of some RSA decryption keys for
apps like S/MIME. And that should be closed in phase 2.
What this means is that it should be possible to raise the bar to a breach
by using trustworthy hardware to store the keys in a non-exportable fashion.

@_date: 2015-09-24 12:30:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] VW/EPA tests as crypto protocols ? 
The only approach I can see working is to make the sensor a trusted,
trustworthy device.
That means that the sensor has to have a CPU with public key crypto
capability so that it can authenticate itself to the EMU on engine startup
and authenticate every message using a MAC.
That would add a few pennies to the sensor but that is cheap compared to
what the fines are going to run as.
It would be very difficult for a manufacturer to cheat as the test lab is
going to replace the sensor before the test. In fact you would probably
want to require that the sensor be a standard part so it can be required to
be replaced every so often.
BTW, when I was interviewing for an apprenticeship before University, I did
the tour at Austin Rover. They had a GM car on the test rig being stripped
down to see how it handles and a Ford sitting next in line.
The idea that none of the other manufacturers knew this was going on is
ludicrous. The only reason for not reporting would be if they were up to
the same sort of thing themselves.

@_date: 2016-04-01 16:41:25
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] O(q^(1/24)) ECDLP attack? 
Like the liar sites that infest FaceBook etc., just more clickbait. I
doubt that more than about 5% of the audience would spot that the
article is a hoax so it wasn't actually funny.
The Onion stories aren't true either. But they don't try to be taken
as real and the point they are making is usually real and serious.
ECDLP is not broken in 24-th root time
Posted on April 1, 2016by ellipticnews
In case anyone has not figured it out, yesterdays blog post was an
April fools day hoax. The mathematical arguments written in the blog
post make absolutely no sense at all.
Normal service is now resumed. Ellipticnews will continue to be the
most reliable news source on the internet for information about new
results on the ECDLP.
 Steven Galbraith, April 2 (New Zealand time)

@_date: 2016-04-07 11:19:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Hillery's Email 
We know that the State Dept cables were leaked by a political opponent
(Chelsea Manning). We also know that every secretary of state who has
had email has been on a private net (Powell, Rice, Clinton) or on
NIPRNET (Kerry) which is not secure. We also know that SMTP email is
not secure without end-to-end layered encryption that makes the
placement of the mail server irrelevant.
My experience of the EOP systems in the Clinton WH was that the
X.500/SMTP mail systems were treated as telephone calls - assume they
are insecure. I am certain that dealing with the actual TOP SECRET/CSI
material would be the job of a dedicated staff.
What is really annoying me here is that there is a huge sound and
furry that Clinton did not choose to make use of a mail server that
was insecure would allow her political opponents to illegally leak
information to her political opponents in congress and there is
absolutely no attention given to the fact that 20 years after email
security became practical, it still isn't ubiquitous.
That is one of the things I want to change with the Mesh.

@_date: 2016-04-08 01:17:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Hillery's Email 
Just got back from drinking with the IAB and IESG at IETF '95. This
may make no sense.
One big difference between the Whatsapp protocol and SMTP is that
Whatsapp is an intranet mail app. One company controls the sending and
receiving clients and the server. It is a three corner model
SMTP is much more complex because it is an internet mail app, the
sender and receiver do not use the same app or share a server in the
general case. It is a four corner model (client -> outbound -> inbound
-> client) and that is the simplest case.
So SMTP is a lot more difficult.

@_date: 2016-04-08 18:26:09
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Text of Burr-Feinstein encryption backdoor bill 
It is a draft, but right now the bill does nothing but huff, puff and preen.
What are the penalties for non compliance?
What if the technology used makes compliance impossible? The bill
specifically states that it does not mandate the use of any specific
The bill is very very strange. It doesn't appear to be intended to go anywhere.

@_date: 2016-04-10 10:23:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] At what point should people not use TLS? 
The proposal looks rather complex to me.
TLS is complex largely because the original design tried to be over
simple and as a result, lots of things that should have been core
ended up as options. Fast restart was a poorly thought out extension.
Suites were meant to simplify algorithm negotiation, they didn't.
I find the handwaving introduction of a completely new PKI most
unconvincing. Either change the protocol that consumes the PKI or
change the PKI. The WebPKI is complex because it is the interface of
the crypto to the real world. And the real world is complex.
If people wanted a simpler X.509 then they would use SAML assertions.
The SAML assertion layer was originally designed as an XML based PKI
to replace X.509. It has all the same capabilities in one coherent and
consistent system. SAML is a very successful protocol but nobody has
really seen the need to apply it as an X.509 replacement.
Pushing the cert exchange into DNS is another matter, yes, that has
been discussed for the purpose of closing the SNI privacy hole. Yeah,
it is possible but you have to be clear about the difference between a
host and a service running on the host.

@_date: 2016-04-12 14:51:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is storing a hash of a private key a security 
A better way to phrase the question is probably to ask whether this
introduces more vulnerabilities than a general compromise of hash
functions or the public key algorithm would.
Given that a lot of public key systems break catastrophically if a
single bit fault occurs, this looks like a necessary robustness
countermeasure. However, a better approach is probably using systems
like Diffie Hellman that don't have that problem - although signature
schemes based on them do!
Security is risk management, not risk elimination - as I pointed out
to someone who ad just written about the risks of PKI that people like
me allegedly weren't telling y'all about.

@_date: 2016-04-12 17:13:38
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is storing a hash of a private key a security 
That does not necessarily guarantee a machine in a single stuck fault
state will calculate the wrong result.

@_date: 2016-04-20 14:19:22
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is "drivers for foo" a major malware vector? 
There are multiple problems.
One is that many manufacturers see control of the driver as an
opportunity to install crapware of their own on user's machines. I
stopped buying Brother printers in favor of HP purely because there
was much less bloat in their driver stack.
Another problem is that there are many sites that make money by just
aggregating information people might want and creating SEO lures to
get search engines to index them. And a lot of those sites do not care
very much if at all about where the stuff they are aggregating comes
from. Collections of drivers are an obvious set of material to
So if someone throws a malware infested driver up on one site, it can
quickly be caught up and published far and wide.
These days, there is really no need for any code other than the
display drivers to run in kernel mode. Converting documents to the
format understood by the printer and sending them over the network is
a user mode task if I ever saw one. Come to that, it is a bit idiotic
that so many printers need drivers at all. I have a 36" plotter that
is a bit old but works fine for my purposes. Every time I use it, I
have to futz with the drivers as HP don't support it any more. Some
time I will get round to making a RaPi into a print server just for
it. Right around the time I make my fifth dalek.
Drivers are a choice malware target as users are primed to give them
full system privs on install.

@_date: 2016-04-28 11:08:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] WhatsApp: Why asymmetric key instead of 
The work factor is well over 2^128 which is the baseline for security these
days. The IETF is currently adding support for Curve25519 and Curve448 to
all their active security protocols.
Curve 448 offers a workfactor believed to be greater than 2^256 which is
the highest we bother with. that being of the order of the number of atoms
in the universe.
I don't plan to use Curve25519 for stored data encryption or long term
authentication credentials. I will use Curve 448.
That said, we have a much bigger problem with public key systems in general
and quantum computing. We have to start planning a fallback in case they
At this point it seems most likely that someone will find a way to build a
sufficiently large quantum computer to break RSA before they manage the
next breakthrough in number theory to break public key systems
algorithmically or the computers get fast enough to break RSA2048.

@_date: 2016-04-30 11:21:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] US Case: Infinite Jail Contempt for Disk Crypto, 
Well that should not be too hard to prove. In addition to his 5th amendment
privileges, the defendant's counsel can argue that either the information
on the disk is incriminating or it is not.
If the information is not incriminating then there is no reason to force
him to reveal it.
If the information is incriminating then the threat of jail is not going to
be effective as he is certain to go to jail and be forced to sign the
offenders register which is a life long punishment. The threat being used
to force him to incriminate himself is less than what he will suffer if he

@_date: 2016-08-18 13:18:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Confidential Document Management, 
So, I am working on a document to describe the use of Mesh/Recrypt, a
messaging infrastructure built on the Mathematical Mesh that uses Proxy
Re-encryption to allow control of access to confidential documents.
Before getting too far, yes, there is a patent on this obvious application
of Proxy Re-encryption but not one that is too much of a concern as it is
most unlikely we could build anything before it expires (18 months).
One of the biggest problems I see is that the use of cryptography in this
field has been mostly focused on the problem of 'Digital Rights Management'
by which is meant control of copyright material. And that is an anathema to
many people.
The problems with cryptographic enforcement of copyright are obvious. The
more people you share information with, the more likely it is that the data
will leak. In the copyright enforcement model the customer is the
adversary. The requirement is to design a system consisting of hardware and
software that allows information to be given to an attacker in a form that
allows them to use it but not to pass the data on to another party.
While it is certainly possible to design a DRM scheme that mitigates
extraction of controlled content, all DRM systems are inevitably imperfect
as DRM is a break once, run anywhere problem. The attacker only has to
crack one Blu Ray player or set top box or monitor to gain access to the
plaintext copy of The Force Awakens and they have a property they can
bootleg for millions.
Yes, I do get that. But that is not the problem I want to solve. Nor do I
believe that it is important to solve the weaker problem of 'Content Rights
Management' in which we attempt to develop an infrastructure that allows a
small, closed set of users to read content without the ability to pass it
In the typical enterprise (e.g. the NSA) there are large quantities of data
that are confidential for some reason (e.g. the powerpoint slides
describing PRISM) that must be stored on enterprise controlled servers
managed by people who do not have a need to know the contents of the
material they manage (e.g. 29 year old contractors).
If such an enterprise was security conscious and technically capable, it
would surely want to restrict the distribution of such confidential
material to exactly the set of people with a need to know. And this is
where proxy Re-Encryption is such a powerful tool.
The encryption key of a proxy re-encryption keyset corresponds to a
security label (e.g. prism at nsa.gov)
The decryption key of of a proxy re-encryption keyset corresponds to the
right to administer that security label (e.g. Col. Mustard)
Recryption keys in a proxy re-encryption keyset are generated by the
administrator and correspond to a grant of read access to the material
(e.g. Cpt Prang).
I believe that a security infrastructure that has the ability to manage
confidential data according to this approach offers a great deal of
security value to the typical enterprise even if the ultimately insoluble
problem of content forwarding is not addressed at all.
Restricting the distribution of the documents to Cpt Prang and others with
a need to know is the first and most important task. Preventing Cpt Prang
from forwarding the document to North Korea is a separate task and one that
we should not expect a perfect solution to.
So what I need is a new name that dispenses with the onward distribution
baggage that the DRM and CRM terms focus on. My objective is to control the
distribution of confidential documents so that these are secured end-to-end
and are not visible to administrators of servers, anyone who might find a
thumb drive or buy a hard drive off EBay.
So the names I am considering are:
Confidential Document Control
Confidential Document Management
Confidential Content Control
Confidential Content Management
Or is trying to separate this problem from the established CRM problem too

@_date: 2016-08-19 09:42:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Phishing Attacks - Alice, HAL and Bob 
When I was looking into turning a Raspberry Pi into a crypto processor, I
was planning to pot it in two coats of epoxy resin, an opaque inner coat
and a transparent outer coat with a mix in of glitter.
I know from my experience with props that it is pretty much impossible to
match grain surfaces even when the surviving photographs are hilariously
low resolution. People went to ridiculous lengths to clone Star Trek
communicator props, but even if you have the correct period Kydex, aligning
it in a vacuum press to get precisely the right positioning is essentially
impossible. There are props we can be very confident are authentic as they
continued to match after work was done to remaster the series for DVD.

@_date: 2016-08-19 12:05:33
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Robust Linked Timestamps without Proof of Work. 
I disagree. What gives robustness to the blockchain is the use of linked
timestamps, not the proof of work part.
Whenever dealing with claims about blockchain, we have to analyze two
separate systems:
1) The ideal blockchain deployment that gives perfect security
2) The actually deployed blockchain that has any number of kludges to make
it work.
Yes, in theory the blockchain is determined by the longest chain. In
practice, it is not. There is a consensus among the users that once the
blockchain has advanced n blocks it is not going to be rewritten. And that
consensus is in fact essential to making BitCoin marginally practical as a
value transfer scheme.
Of course, I can't propose a scheme that is more robust than the ideal
Bitcoin deployment in which all operational practicalities are ignored. But
I have built real world PKIs that have endured a lot longer than BitCoin
and I am pretty sure that I can provide a scheme that at least matches
BitCoin for security without proof of work.
Let us say for the sake of argument that in the near future there will be
100 OpenPGP KeyServers that operate in a manner similar to today's servers
based on Brian LaMachias' MIT server with two changes:
1) Every key server maintains a link timestamp of all data submitted (keys,
signatures, etc.)
2) Every hour, each server cross-timestamps their current timestamp value
with at least ten other servers chosen at random
Let us further assume that I can establish a userbase of a million users.
Which I think is actually quite plausible if I can persuade the S/MIME folk
to use the infrastructure as well as the OpenPGP folk.
To verify a timestamp value, a verifier checks the timestamp chain of five
or so randomly chosen servers.
The metric I use for evaluating the security of a PKI is a time based
work factor priced in dollars. Obtaining bogus Domain Validated
certificates in quantity in the WebPKI has a certain cost, lets say $500,
an EV certificate has a much higher cost, about $5000. The cost values here
are not just the price of acquiring the cert, they are also the cost of
covering their tracks. The out of pocket cost of obtaining a single bogus
cert is much lower because it is very unlikely that is going to be
detected. But obtaining large numbers without establishing a pattern is
So how does BitCoin fare? well the cost of mining 24 hours of bitcoins is
large but its less than a million dollars.
The work factor of my scheme is rather higher because in order to backdate
the timestamp by one hour without detection, the attacker has to compromise
ten servers and every user that has recorded the timestamp values. To go
back 6 hours without detection, the attacker has to compromise all the
servers. To have a chance of fooling someone in a detectable fashion it is
necessary to compromise more than half.
While it is certainly conceivable that someone might be able to compromise
100 independently operated servers at the same time, the cost of doing so
is a heck of a lot more than mining 6 hours worth of bitcoin.
This approach is not theoretical either, it is my design for phase 2 of the
Mathematical Mesh, the Meta-Mesh. I have to finish part 1 first of course
Ben Laurie has proposed similar ideas in his critique of BitCoin but I
think I came to this independently.

@_date: 2016-08-19 12:19:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Confidential Document Management, 
That is precisely what I am getting at.
I want a mechanism that makes it easy for people working inside an
organization to pass documents around with the same freedom that they do
today that greatly mitigates the risk of an accidental disclosure and
limits the number of parties that can perform a malicious disclosure.
A hostile foreign power that has invaded two neighboring countries and
maintains an army of street thugs to intimidate opponents has hacked into
the email servers of a US national party with the objective of changing the
outcome of the election.
This is or at least should be above part as I am absolutely certain that if
the FSB was in the DNC servers then they were in the RNC servers as well.
It probably isn't a complete accident that a man who was recently managing
a $12 million Russian slush fund became Trump's campaign manager. Quite
possibly similar activities played a role in the curious collapse of
certain rival campaigns.
Making email, making confidential documents secure is now a matter of vital
national interest. And I would argue that preventing Putin choosing the
President of the United States through cyber attacks is a much much greater
threat to national security than anything ISIS, Al Qaeda or the rest might
Hilary's email server has been identified as a weak link in the custody of
confidential material. Fine, rather than spending another $100 million on
Benghazi blamestorming, lets rejig the mail protocols so that mail servers
are no longer a weak link no matter who is managing them.
Yes, in some circumstances it might well be desirable to back up
Confidential Document Controls with trustworthy hardware. But we have spent
the past 20 years putting the cart before the horse, obsessing over the
security of the trustworthy hardware while ignoring the fact that we don't
have a viable cryptographic architecture.

@_date: 2016-08-19 20:55:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Robust Linked Timestamps without Proof of Work. 
Explain the attack more fully. Assume that each server is signing each
output value and has a trust relationship with the parties it exchanges
values with.
The key servers are not anonymous entries or random bloggers.
You think Bitcoin miners are incorruptible? I rather doubt it.
It's unclear if you're talking about a permissionless network where anyone
I regard BiTcOiN as a religion rather than a technical infrastructure.
 Any attack against Bitcoin's PoW is useless unless it can be sustained.
 If you compromised a mining pool, you wouldn't own it for very long if you
tried to use it to your advantage. People would notice and either the
hashpower would be pointed to a different pool or the pool operator would
shut down the pool until they could re-secure it.
Which is exactly the point I made at the start. The security of the
blockchain is not secured through the proof of work mechanism at all. That
is just an unnecessary distraction.

@_date: 2016-08-20 13:22:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Robust Linked Timestamps without Proof of Work. 
It isn't Trent though. Its a hundred Trents. And as the BitcOin folk
admit, the security of their scheme actually rests on exactly the same
There are in fact suppliers that rent the scale of computing resources
required to break bitcoin, they support the animation industry.
Rooms full of machines loaded with GPUs isn't an economic way to mine
coin but it still works.
And lets just get real for a minute. People are always claiming how secure
BitCoin is and how it doesn't need any trusted parties. How many bitCoins
have been created to date? How many biTcoinS have been stolen in frauds at
exchanges? If you ignore the Bitcoins that Hal probably dumped into the bit
bucket in the early years and have never been available to spend, the
typical Bitcoin in circulation has been stolen twice or so.
This is what many of us find so frustrating about analyzing Bitcoin. The
actual real world experience of running the system and the actual code is
ignored. Meanwhile hypothetical problems that don't actually turn out to be
problems in the real world banking systems are presented as insuperable
The total number of BitCoin transactions in the history of the system are
substantially less than the amount one of the ACH systems handles in an

@_date: 2016-08-20 16:03:31
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Robust Linked Timestamps without Proof of Work. 
Like it or not, the fact is that the WebPKI is deployed and meets the
intended design goal. The CA model has not failed, it has outperformed its
What has not worked is that the WebPKI worked so well initially that the
browser providers decided it was expedient and acceptable to fudge
In comparison, BitCoin exchanges seem to be being breached for millions or
hundreds of millions of dollars on a regular basis. 
I don't see how any impartial observer can call the WebPKI a failure and
BitCoin a success.
The only 'mumbling' going on here is invoking Sibyl attacks. In the scheme
I propose I expect the key servers to establish processes that give each
other a reasonable degree of trust and for end users to select a subset
they can trust.
Trusting Comodo, Google and Symantec not to all screw up when they are each
watching the other and being watched by 97 other Trents isn't a very large
leap of faith and there is no Sibyl involved.
Trusting MtGox on the other hand...

@_date: 2016-08-24 14:45:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Insecure email might be an even bigger problem than 
Over the past few months we have seen some very remarkable and quite
unexpected developments:
1) Donald Trump wins the GOP Primary.
2) Voters in the UK vote for Brexit.
3) Fox News abandons a longstanding policy of paying off sexual harassment
claims against senior management.
4) Trump appoints Breitbart staff to his campaign in an apparent bid to
pilot the launch of Trump News
5) Despite knowing that Trump plans to usurp them, Fox News curiously keeps
giving Trump free air time.
We also have the following observations
1) Cyber espionage attack against the DNC by the FSB and GRU
2) Cyber espionage attach against the New York Times by same parties [*]
Cui bono?
* Trump appoints Manafort as campaign manager
* Trump states that NATO Article 5 will only be enforced at his personal
* Trump states that Russia has not invaded Ukraine
* Corbyn, leader of the UK Labour party states that NATO should be shut down
* Trump News would function as Russia Today USA edition
Note that I am not saying that I am 100% sure that these events are
connected or that they are the result of Russian covert operations. It is
however impossible to assert with confidence that there is no connection
and that we are not seeing the results of a Russian lamplighter operation
that has succeeded beyond the wildest expectations of the planners.
[*] When I first started writing this memo yesterday it was a private memo
for the managers of News Corporation. It was of course obvious that if the
Russians attacked the DNC they would attack the RNC as well. And there
would be no way to leverage that information without knowing which
journalists would be willing to make use of it, how they would react etc.
So an attack on other media would be an essential part of the attack. Fox
News is essentially the real RNC so they were an obvious target.
The way I would engineer such an attack would be to gather as much data
within the political campaigns and the media. Then look to 'nudge' parties
into making moves that I want them to. I ensure that potential litigants
against Fox discover that there are other potential lawsuits. I discover
who the private investigators that are being used by Fox are and I either
bribe them or feed them false information.
If you have someone's entire email history, manipulating them into taking
actions you want them to take becomes quite easy.
Which is why we absolutely must stop worrying about the 'terrorist' threat
if the NSA is unable to read all the email on the Internet and instead
start worrying about the threat posed by Putin's minions being able to read
all the email on the Internet.

@_date: 2016-08-25 10:19:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Say 'unguessable' not random 
The bridge problem illustrates some of the problems when we try to achieve
'randomness'. It is impossible to audit processes to see if they are truly
random. And even defining what 'randomness' is tends to lead to circular
What we really need is cryptographic secrets that are unguessable.
Unguessability is both the necessary and sufficient criteria.
So for the bridge contest, why not get rid of the random numbers altogether
and instead employ a commitment scheme in which each of the players
introduce as much unguessability into the seed as they like? There would
have to be some form of trusted party that would take in the encrypted
seeds, decrypt them, prepare the hands and then release the seeds at the
end so the process can be audited. But the seeds themselves need not be
Thinking in terms of unguessability also helps us when we look at the
reason why passwords fail. The problem with passwords is that the user is
asked to chose a secret that they can remember but an attacker is unlikely
to guess. Of course it is going to fail.

@_date: 2016-08-26 10:04:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Insecure email might be an even bigger problem 
One of the TV tropes I find least convincing is the 'people will think I
am mad' trope. Every week the crew of the Star Ship Enterprise meet aliens
with previously unknown powers. Yet they dismiss evidence as
We have abundant knowledge of the type of attack described. Some of us have
helped perpetrate attacks very similar. We all watched as Crimea was
invaded by Putin's 'little green men' which he denied were Russian troops
for over a year.
But the problem is not just the attacks, it is the distrust that they
engender. The long term cost of Operation Ajax was that a large part of the
world has good reason to be distrustful of US motives.
My former colleague Roger Hurwitz spent his last decade trying to get
people in government to think about cyber attack as a new type of threat.
It is very clear that cyber engagement is nothing like nuclear warfare but
the consequences can be equally significant.
The problem with nuclear weapons is that their strategic value is infinite
and their tactical value is zero. Cyber weapons are almost the exact
opposite, they have immense tactical value and no strategic value. You
don't even know if the weapon will work when used. If it does work the
enemy can take your weapon, change the payload and lob it back at you.
I believe that cyber-warfare should be considered in the same bracket as
terrorism and chemical weapons, tactics that the great powers have banned
because their use has no advantage to us while having the potential to
create great harm.
For the past twenty odd years there have been two sides in the US Crypto
Wars. On the government side there have been the representatives of the NSA
and FBI who run the US pervasive surveillance infrastructure and on the
other there are the civil society people (including most of us here) who
are suspicious of their motives.
But what if we widen the scope and consider the likes of Putin? We now have
concrete evidence of FSB and GRU interference with US elections. And if we
looked we might well see their fingerprints on much more, even Brexit
If the only threat that is recognized is the likes of ISIS and such, then
the likes of Comey and Freeh have a point, cryptography is going to be a
useful tool for terrorists. That is not enough to support a ban in itself
of course, terrorists find many things useful. Guns for example.
If however we consider Putin as a threat, the need for a comprehensive and
pervasive cyber-defense infrastructure becomes a goal that everyone on the
government side should agree to and civil society should concur.

@_date: 2016-08-30 12:22:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Key meshing (Re: [Crypto-practicum] Retire all 
What I don't understand is why the various symmetric cipher modes we have
keep the key fixed and modify the data.
So for CBC we take
C0 =  E (B0 XOR IV, k)
C1 =  E (B1 XOR C0, k)
Why not use:
C0 =  E (B0, k)
C1 =  E (B1, k + 1)
This has the advantage that it can be applied to the use cases that
motivated ECB and CBC. It doesn't require an initialization vector either.
Of course with DES you have the problem of weak keys but these days we
consider weak keys as disqualifying a cipher completely.
The main reason for not doing this seems to be that the key schedule has to
be recalculated and that was expensive for DES. But that shouldn't be a
major problem on a modern CPU.

@_date: 2016-12-05 14:50:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Recryption API 
I have been working on an end to end encrypted Web site using Proxy
Re-Encryption 'recryption'. The basic idea is that Alice is the
administrator, she creates a keypair for 'Group W' and published the public
part. Anyone who wants to can publish material encrypted under this key.
For each person Alice adds to the group, she creates a recryption keypair
[recrypt, decrypt], the first key is sent to the online recryption service
chosen by Alice. The second is encrypted under Bob's public key and
uploaded to the recryption service.
The net effect is that it is impossible for any party to decrypt the
content on the site unless they have either:
* The private key held by Alice
* The private key of one of the group members and at least an oracle that
will preform the recryption step.
This is true end to end encryption. An attacker can breach both the cloud
services and the material is still confidential.
So to implement this I need an API. OK so first off, I need an API for DH
key agreement:
            var AliceKeyPair = new DiffeHellmanPrivate();
            var BobKeyPair = new DiffeHellmanPrivate();
            var AlicePublic = AliceKeyPair.DiffeHellmanPublic;
            var BobPublic = BobKeyPair.DiffeHellmanPublic;
            var AliceAgree = AliceKeyPair.Agreement(BobPublic);
            var BobAgree = BobKeyPair.Agreement(AlicePublic);
            if (AliceAgree!=BobAgree) {
                Console.WriteLine("Fail");
                }
[This is of course eliding all the code that would move the data between
Alice and Bob]
This looks nice and symmetric. AliceAgree  is currently returned as a
BigInteger. This should obviously be fed into a hash function in some
fashion to derive a key. But that would be part of DH-SHA2-512 or the like
which would wrap this class.
OK so what does a recryption scheme look like?
            var GroupKeyPair = new DiffeHellmanPrivate();
            var GroupKeyPublic = GroupKeyPair.DiffeHellmanPublic;
            var BobSplit = GroupKeyPair.MakeRecryption(2);
            var BobRecryption = BobSplit[0];
            var BobDecryption = BobSplit[1];
            var AliceAgreeW = AliceKeyPair.Agreement(GroupKeyPublic);
            var ServerAgreeW = BobRecryption.Agreement(AlicePublic);
            var BobAgreeW = BobDecryption.Agreement(AlicePublic,
            if (AliceAgreeW != BobAgreeW) {
                Console.WriteLine("Fail");
                }
This is pretty similar to the previous verison. The only changes are making
the recryption set (MakeRecryption) and there are now two agreement
operations instead of one. The first is exactly the same as before and the
second requires the output of the first as a 'carry'.
One thing I don't much like about this approach is that it enforces
sequential processing. That is pretty much inevitable with two parties. But
with more parties you might well want to perform the agreement steps in one
place and then the combination elsewhere.
            var ServerRecrypt = BobRecryption.Agreement(AlicePublic);
            var BobRecrypt = BobDecryption.Agreement(AlicePublic);
            var Recrypts = new BigInteger[] { ServerRecrypt, BobRecrypt };
            var BobAgreeW = BobDecryption.Agreement(Recrypts);
Does this make sense?
Here is the code that implements the methods:
        public BigInteger Agreement(DiffeHellmanPublic Public) {
            Verify(Public);
            return BigInteger.ModPow(Public.Public, Private, Modulus);
            }
        public BigInteger Agreement(DiffeHellmanPublic Public, BigInteger
Carry) {
            Verify(Public);
            var Partial = Agreement(Public);
            return (Partial * Carry) % Modulus;
            }
If the basic framework is right, it should be possible to implement this
for the curve-x algorithms. If I can work out what the functions
corresponding to ModPow and * are from DJB's code.

@_date: 2016-12-14 08:26:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] 5 Questions to Ask your IoT Vendors; 
The questions I would want answered in addition would be whether it
requires the use of a separate service, how long the service will be
supported, what information does it collect, etc.
I had this Revolv hub that claimed it would integrate all my devices in the
house. Google bought the company and shut it down. They repaid me the $300
I paid for the hub but I ended up with $3000 worth of installed devices
that became useless until another company made something similar.
Yes, I know the security is junk, that is why I installed it.

@_date: 2016-12-15 09:49:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Say no to a Comey Key. 
Personalizing an issue is usually a bad tactic in politics. But there are
important exceptions.
Whether or not you believe Comey's letter changed the outcome of the
election, there is more than enough reason to believe that it was intended
to have that effect. And you can be certain that he will be considering
himself head of the queue when it comes to being rewarded.
There is absolutely no secret about what Comey wants in return: a backdoor
key into every cryptographic application. That is what Freeh wanted when he
conspired with the Republican party to impeach Bill Clinton and it is what
Comey wants in return for sabotaging the campaign of Hilary Clinton.
Of course it goes without saying that Comey's own actions have demonstrated
the reason why he must not on any account be allowed to have a backdoor.
Comey was told that his intervention in the Presidential was completely
contrary to DoJ policy, he did it anyway. So from this point on, we don't
have to consider the possibility that the FBI might abuse its intercept
capabilities to interfere with an election, Director Comey has already
ripped up department policy to interfere in an election.
There must be a reckoning and a part of that reckoning must be the eventual
dismantling of the FBI itself. The combination of police force and
counterintelligence was always dangerous to democracy and that fact has
been proven under Hoover, Freeh and Comey. The agency must be split into
two parts and neither part should be called the FBI, hang any portraits of
past FBI directors or name their headquarters after them.
In the short term however, the immediate fight must be to prevent any
legislation mandating backdoor crypto passing through Congress and
designing technical infrastructures that make backdoor crypto infeasible.
Personalizing the issue by calling backdoor crypto a 'Comey key' raises the
cost to Democrats who might vote for the Comey bill. But it isn't just
Democrats who had problems with Comey's action. Many Republicans realize
that they are likely to be facing a Democratic administration in 2020 or
2024 and they are concerned about what might happen when the jackboot is on
the other foot.
But more importantly, personalizing the issue highlights the real problem
with any backdoor crypto: the people. Politicians tend to be reflexively
deferential to institutions such as the FBI or the NSA. But people are a
different matter. Asking if the FBI should have mass surveillance powers is
not the same for them as asking if they trust Comey with those same powers.

@_date: 2016-12-22 10:02:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] USB hardware token for $2?? 
I saw this:
It has an 8 bit CPU with 512bytes of RAM and 2K of ROM. There is a fuseable
link for fixing the firmware.
Any chance one of these could be used as a low cost HSM? Specifically, the
use I would have for it would be to provide a second factor for sensitive
key management operations. I would not store the whole key on the device,
just a share of the key.

@_date: 2016-12-23 08:13:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [FORGED]  USB hardware token for $2?? 
Not quite, the board has to plug into a USB socket rather than having a
USB socket to be useful.
You can use a cross compiler to target the chips used in the Arduino from
Visual Studio. Now whether the 8 bit chip is supported is another matter.
There are plug ins that provide full single step debugging.
[0] Everything on Kickstarter has to be at least one, possibly more of, the
Because if it isn't new in some way, there isn't any point in paying
someone who might not deliver eight months in advance.
Generating the keys onboard is nice. But the defining feature in my view
is that the keys never leave once installed.
As far as endpoint compromise is concerned, it is a complete crock in my
view. Something that is not just not worth worrying about, it is positively
harmful to worry.
Anything you use, absolutely anything is just another turtle on the stack.
Anything that is sold as a crypto module is going to be 1000% more likely
to be attacked than anything else. Windows XP is going to be less likely to
be compromised with a targeted vulnerability than a sealed HSM sold by a
highly reputable vendor.
Yes, there is a value to having a HSM, the keys never leave, the operators
cannot default without visible evidence that shows up in an audit. But
don't treat them as unhackable as they aren't.
Do people really believe that Moti Yung was the first person to work out
how to compromise an RSA HSM by manipulating the modulus? How many people
have stripped down an HSM and checked the firmware.
So what I have been looking at is ways to use insecure HSMs in a secure
fashion. Which is what schemes such as my co-operative key generation do.
I have just bought eight of the devices for $10, delivered. That is the
reason I am interested. They are dirt cheap.

@_date: 2016-12-27 12:07:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Should we always KeyWrap, even with Key Recovery? 
I am just working on some code and it occurs to me that the use of RSA to
encrypt data under a session key might give an attacker more leverage than
we need to allow.
With RSA we typically generate a random session key and encrypt that. The
counterparty decrypts the blob to recover the key. If there are n
counterparties there are n different encryptions of the same data under
different RSA keys.
With DH we don't encrypt, we have a key agreement. If we have only one
counterparty then we can perform the key agreement and use the result to
generate the session key, preferably involving some sort of digest step. If
however we have more than one recipient, we have to wrap the session key
using the result of the key agreement.
It seems to me that the second approach is a lot more robust in the case of
related key attacks. It also provides a much more straightforward defense
against the types of attack Rogaway identified.

@_date: 2016-12-27 12:35:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Photojournalists & filmmakers want cameras, 
Most pro DSLRs have some sort of image authentication built in. None that
have been examined have turned out to be competent. The tell is usually the
need to buy special apparatus to verify the signatures. That means they are
doing some sort of idiot HMAC scheme with a shared key across every device.
The fact that you can get a sensor without any security controls in limits
what yuou can hope to achieve in trustworthy hardware. Any sequence of bits
that you generate with your trustworthy camera, I can generate by splicing
a hardware emulator for the sensor onto the trustworthy DSP.
The only way you could get to a trustworthy device would be if you can put
the image authentication on the chip. And that is a huge problem for all
sort of reasons.
Absent custom VLSI for this purpose, the best you can hope for is:
Confidentiality: Encrypt on the device to a public encryption key. Images
can only be decrypted using the corresponding decryption key. For added
security, decryption may be controlled further by splitting the decryption
key so that participants can only decrypt with the participation of a
recryption service.
Integrity: Hash the image as it is recorded to storage medium and enroll
the hash in a linked log (aka blockchain) as soon as possible after the
photograph is taken. A photograph of the JFK assassination known to have
been taken before 19:00 UTC on 22 November 1963 is a lot more trustworthy
than one that was only found last week. This interaction can be achieved
over a very low bandwidth link.
Availability: Upload the image or a downsampled version thereof to a
service. This does require a lot of bandwidth though.
You can go a little further if you use steganography of course. But that is
not remotely practical for a commercial product as the steganography will
be known.

@_date: 2016-02-06 12:04:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] DH non-prime kills "socat" command security 
Is there any particular reason to think anyone thought it was a prime
as opposed to just a large random number?
DH works fine in a non prime field. It is just less secure.
Before worrying about whether this is an example of a Fermat test
prime that turned out to not be, ask if this is simply a test vector
that was meant to have been replaced that wasn't. Or alternatively
someone didn't understand that the tests have to be done multiple
times or they mucked up the code.
For open standards the point is now moot as we will be doing ECDH on
fast prime curves.

@_date: 2016-02-06 13:39:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The Mathematical Mesh 
Some of you will have seen this on other lists. My approach is
probably less of a surprise to people here.
I haven't yet finished the description of how this works but the
answer is pretty much, 'how would you do this if you were not shy of
using a very large number of public key pairs'. In the example shown,
12 keypairs are generated.
If you think of a cryptographic system as an animal, a cryptographic
keypair signing another keypair is sort of like a joint. I introduce
'joints' into the architecture at every point where I need a new point
of articulation, a separation of concerns.
Project Website: PrismProof.org
The project WebSite has links to the GitHub repository (MIT License),
the Internet Drafts and podcasts demonstrating the Mesh in use.
As most of you know, for the past couple of years I have been working
on a way to do secure email in a completely painless manner. It should
be exactly as easy to send secure mail as insecure. When you are
starting your car you do not need to remember to press the button
marked 'do not explode'. But that is what we demand of users when we
require them to click the 'encrypt message' button to do S/MIME or
I did a demo of that scheme 18 months ago. Since then I have been
looking at the problem of how to persuade people to change to a new
email infrastructure. My conclusion being that secure email isn't
going to be enough.
The only way we are going to get a billion people using secure
Internet applications is if doing so makes using the computer easier.
This seemed like an impossible challenge until I realized that:
1) Most users have multiple devices these days
2) Configuring devices is fiddly and complex enough without cryptography
3) We can use strong end-to-end cryptography to make the process of
transferring configurations from one device to another very, very
4) Manufacturers make money by selling more devices to existing
customers. Anything that makes it easier for a potential customer to
part with their cash is going to be interesting to a large number of
The breakthrough came when I realized that instead of just putting a
user's S/MIME and OpenPGP keys into a profile, we could put all the
configuration data for email into a profile. So when Alice buys a new
laptop, she can configure it to use all her email, instant messaging,
VOIP, VPN, SSH, etc. etc. accounts in one go.
For years, the IETF has had the attitude 'we don't do UI'. Well maybe
that is the right approach after all because most times if you are
presenting the user with UI, you are doing it wrong. The Mesh allows
all the configuration decisions a user has to make to be gathered into
one place and administered from there. I can manage my 3 laptops, 4
desktops, 2 phones, 4 tablets and the watch from one machine.
There are of course obvious applications of this approach to IoT. The
biggest challenge in IoT is how to connect to the user's 'management
console' which currently doesn't exist. There are obvious enterprise
applications as well. But I think we need to build up experience of
using the mesh in standalone mode before going down those paths.
I chose secure email because it is the hardest problem to solve. If I
can configure a machine to use the S/MIME built into the current
release of Windows Live Mail and Outlook without the user having to
think about the process, we can support pretty much any application
protocol. In particular:
* Web password manager,
* SSH configuration
* OpenPGP
* VPN configuration
I have 100s of Web site accounts, most of which have the same weak
password because I don't actually care about them. Yes, there are many
proprietary password managers but I really wouldn't ever use them for
anything I relied on because I don't know how they are secured, I
can't audit them.
SSH is easy to congiure insecurely, thust create one keypair and copy
it to every machine. Using SSH with separate keys on each machine is a
lot more involved. And it is a hard bootstrap problem because you are
trying to configure a machine to do things securely before you have
security. Most people I know who do this right and have separate keys
on every machine and rotate them regularly do so with custom written
scripts. I would much rather trust a reviewed standards based protocol
than a script.
OpenPGP is of course one of the applications that must be supported. I
don't support it right now because configuring closed source
applications is actually the harder test.
VPN configuration is something that should have been solved long ago
but has not. Every corporate VPN I have used has required me to use a
proprietary or add-in client for access. Which is really strange when
Windows and OSX ship with IPSec built in. Configuring a VPN as a
remote user is absolutely no fun at all. It requires multiple emails
and phone calls and even then may not work at all.
The Mathematical Mesh is an untrusted cloud service that supports two
principal functions:
1) A place for users to store encrypted configuration 'profiles' for
their accounts and applications.
2) An infrastructure through which they can publish public aspects of
that profile to allow others to interact with them.
At present we are focusing on applications that only require the first
function. But the architecture of the Mesh is mostly designed to meet
the requirements of the second. The Mesh does not offer any
confidentiality guarantees, in fact it is assumed that all the bits
that are published to the Mesh are made public:
We distrust governments, corporations and users.
We believe in strong cryptography and secret keys.
Currently all the data in the Mesh is encrypted under RSA2048 and
AES256. That will change to CFRD448 when the spec is fully baked and
code is available.
As with DNS, it is of course possible to run the Mesh in a completely
stand-alone fashion. But if you want to be able to communicate with
anyone at all, you want your data to be available to anyone at all.
That is the role of the Inter-Mesh. So my email
Users access the Inter-Mesh through a portal provider. These providers
act as abuse filters for the Mesh. That is important because the Mesh
runs as a blockchain: every byte that is added to the Mesh must remain
there in perpetuity. There are ways to avoid someone deliberately
tainting the Mesh logs with kiddie porn or other prohibited material.
But if a user is allowed to to a billion transactions in an hour,
there is going to be a few gigs of transaction log that have to be
maintained forever.
A user can change their portal provider at any time however. There is
no 'lock in' effect.
Each mesh user has a master profile that can in principle be used
their entire life. This profile has a master key that is used to sign
updates to the master profile. The master profile then signs an
administrative profile which in turn...
In short, there is a lot of crypto going on. And each one of those
crypto steps is used to meet a very specific user requirement. One of
the big mistakes in traditional PKI was to think that some features
are for 'experts'. Key escrow for example, you want to be able to get
your data back if a machine fails. So key escrow has to be offered as
an option. But isn't the novice user at least as likely to blow up
their machine config and lose all their data as an 'expert'. In fact
using crypto *without* escrow is the thing that should be left to the
We could not have done something like the Mesh in 1995. Each user has
a personal PKI with four levels. In 2016 that is no burden at all even
with RSA2048 and it is even faster with CFRG448.
The Mesh provides for recovery of the user's private key. User's are
not required to use this feature but it is recommended. I do have
material that I would rather lose than have disclosed. But I would
rather the vast majority of my data was disclosed than risk losing it.
So I use escrow keys knowing that there is some risk of being coerced
to disclose.

@_date: 2016-02-06 13:35:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] DH non-prime kills "socat" command security 
This is exactly the same as what passes for political argument on the
Internet. People want the number to be prime and so they assume it
MUST be prime. Checking the facts doesn't matter.
In another part of the net I am trying to convince someone that the
reason Wentworth house needs $80 million in repairs is the subsidence
due to the mine that runs directly under (parts of) the house. The
fact that there is a mine under the house isn't really disputable
because the house was built with the fortune from the mines. But oh
no, the idea that plutocrats of a past age would have caused the
destruction of their quarter million square foot Palladian palace
doesn't fit their ideology. So the cause must be the open cast mining
Manny Shinwell ordered after WWII.
Proof by wishful thinking is a real problem.

@_date: 2016-02-08 11:32:35
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] New block cipher competition 
2^256 is a very big number. About 10^77
Or roughly the number of atoms in the known universe
After roughly 100 trillion years, the universe runs out of gas for
stars to form naturally. If we express this in planck time we get
10^62 planck instants in the lifetime of the universe.
So if someone was being ultra, ultra cautious, one might use a key
that is 512 bits long, that being the lifetime of every atom in the
universe in plank time.

@_date: 2016-02-08 11:54:49
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Basic auth a bit too basic 
Digest is the way it is because it was invented by two people who
didn't talk to anyone else before throwing the feature into the spec.
At the time, all IETF specs used password in the clear for
authentication except for Kerberos.
I proposed Digest 24 hours after I discovered what they had done. But
it was too late. Basic had been out for a week by then and the people
who had written it were happy that it solved their needs which
included being able to authenticate against the existing UNIX password
At the time people were only just getting their minds round the idea
that a world readable password file was a stupid idea. These days of
course, everyone knows about shadow password files. But there was a
time when they didn't exist and the same sort of people who tell you
how clever UNIX is because shadow passwords would tell you how clever
it is to make the password file world readable.

@_date: 2016-02-09 23:49:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proof that the NSA does not have a quantum computer 
Proof that the NSA does not have a quantum computer capable of
attacking public key crypto (yet)
A) Assume that the NSA has such a machine.
B) Large areas of the bitcoin mining pool have never been spent.
A,B) Anyone with a QC could use it to break the keys of the wallets
holding $500 million.
C) This has not happened.
D) The NSA has awful internal security, (see Snowden). NSA resources
are known to have been diverted for LOVINT. It is unlikely NSA
employees are more honest than those of federal law enforcement whose
investigator ripped off the Silk Road operator for at least half a
million. The third in command at the CIA was recently prosecuted and
copped a plea for participating in the 'Duke' Cunningham bribery ring
poker and prostitutes parties at the Watergate. Oh and Secret
Service... need I go on.
C,D) it follows that the NSA is not capable of breaking bitcoin
Therefore NSA does not have a quantum computer (yet).

@_date: 2016-02-10 19:58:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Basic auth a bit too basic 
Actually, I proposed what became DIGEST in 1993.
I reviewed the CHAP design and rejected it as unsuited. Photuris
didn't meet the requirement for being unencumbered because Diffie
Hellman was still encumbered.
By the time people decided they wanted to do DIGEST as an RFC, I was
telling them to do a DH based scheme instead. But by that time all the
EKE variants were encumbered.

@_date: 2016-02-11 14:54:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proof that the NSA does not have a quantum 
I was asserting that the funds would be diverted for personal
purposes, not to fund the agency.
$500 million might be chump change to the agency but Hanssen defected
for a lot less.

@_date: 2016-02-15 23:06:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The Mathematical Mesh 
I have gone a bit further for IoT devices.
Machine boots with clean O/S, it creates a unique device profile and
is connected to a personal profile.
Now it can download the full description of all the packages to
install, services to configure and where to go to get ground truth for
the trust infrastructure.
Working to do it on the controls for a robot dog. Machine will boot
and download its firmware. Hopefully.

@_date: 2016-02-17 11:58:34
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Thoughts on the Apple iPhone fiasco 
It seems to me that Apple should 1) comply with the warrant and 2) fix
their code.
I was quite surprised by these conclusions. I had been thinking that
the response should be to dig in. But when I look at the
circumstances, this looks remarkably like Lavabit. Cryptography is
involved but the design allows a trusted party to disclose the key.
This is a trusted third party that got themselves into a situation
where they could be coerced.
Rather than have them march their men up to the top of the hill only
to march them down again, better to get on with the next bit.
This is an example of a situation in which there is a conflict between
personal privacy and public safety. Consider the circumstances:
1) The phone belonged to a person who is believed to have committed a
mass murder.
2) The owner is dead.
3) The phone is locked
4) Apple has the ability to bypass the lock mechanism
The responsibility to decide where the proper balance between privacy
and public safety lies with the courts. Just as it isn't the FBI's
prerogative to make such decisions, it isn't Apple's either.
In this case, I don't think it is a close call. The phone's owner is
suspected of being a mass murderer and they are dead. I don't think
anyone has the right to privacy in those circumstances.
It seems to me that Apple is fighting the wrong fight here. Any
security system that depends on a trusted third party not being
coerced is flawed. Waffling on about 'precedent' isn't going to help
The only way for Apple to provide a credible assurance that it is
protecting user privacy is to provide a system that verifiably puts
the device beyond their control. That may not be possible when the
operating system can upgrade itself without requiring the user to
unlock it. My experience is that the phone demands the pin to upgrade.
Some stories suggest that later iPhone models do have hardware
enforcement of the 10 password attempt lockout. If so, it would seem
that any precedent set in the San Baradino phone incident would be
short lived.
Perhaps the bigger concern is that once Apple has signed an O/S
version, the same signed image could be used against other phones. It
seems to me that Apple could mitigate this by limiting the O/S load to
only work against the one phone involved in this particular incident.
The serial number of the phone is known.

@_date: 2016-02-17 13:51:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Apple ordered to decrypt cellphone 
So it was a government owned phone? Even less reason to go to the mat over this.

@_date: 2016-02-17 18:03:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Thoughts on the Apple iPhone fiasco 
My understanding is that the 5C is one of the phones that was designed
before they slammed the door shut. So it is possible for them to
bypass the protections on that particular phone.
On the 6 and later, the phone has to be unlocked to authorize an O/S
update and the keys are stored in a secure enclave with TPM like
My concern is that by making a stand in this case, they are going to
create a bad precedent precisely because they will inevitably fold.

@_date: 2016-02-19 12:20:42
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Thoughts on the Apple iPhone fiasco 
I have no problem with Apple resisting the subpoena. What I take issue
with is their rhetoric.
The fact is that this is a phone that has a backdoor in it. The
backdoor exists. It is there in the phone already and it will continue
to exist irregardless of the outcome of the case.
Having created a phone with a backdoor, Apple is now arguing that it
should not be required to open it. And to make its argument it is
blurring the distinction between being ordered to open an existing
backdoor and being ordered to create a backdoor.
I don't see that Apple can expect to avoid opening the backdoor that
is already in the phone. There is no end of precedent for that.

@_date: 2016-02-19 18:49:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is Apple correct? 
The payload is signed so any change to the serial number info would
cause the payload to be rejected.

@_date: 2016-02-20 14:01:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Apple 3rd Party dilemma 
Yes, that is my belief as well.
Apple set itself up not just as a 3rd party but as an essential,
non-replaceable third party. There is no choice but to trust Apple for
the iPhone security.
It didn't have to be that way. There could be the option of installing
your own root of trust into the hardware.

@_date: 2016-01-08 14:41:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Plan to End the Crypto War 
Is this really intended to be a proposal to end the crypto wars or is
his real purpose to demonstrate that the demands of Comey et al. are
not actually achievable because they are not even consistent.
First off, is there the slightest possibility that the Internet could
use a networking technology that is effectively Tor on steroids
privacy wise and telegraph era latency wise? I don't see how anyone is
going to tolerate that type of overhead unless they are up to no good.
Certainly not for anything other than asynchronous messaging like
email, maybe some document exchange.
It isn't difficult to come up with similar schemes. The ingenuity here
is the nature of the exceptional access mechanism.
But is the exceptional access really going to satisfy the FBI? They
demand access to the communications without any form of
accountability. That is why National Security Letters exist. Though
the idea that a government agency could issue such a demand without it
being a search is ridiculous. As is the notion that a government
agency can prohibit discussion of the demand without it being a breach
of the first amendment. The whole point of the constitution was to
fetter the executive so that they could not engage in either activity
without the express permission of the courts.
For historical reasons, the FBI is both the national police force and
an intelligence service and the NSA is a military organization. Both
situations are anomalous as far as I am concerned. MI5 and MI6 always
reported into the Cabinet Office except when there was a War Office.
Special branch acted at the direction of the Secret Service but the
Secret Service never exercised police powers.
The problem with the current situation is that there is effectively no
firewall between the civil police power and the military. The FBI has
been using the military to perform pervasive surveillance and then
laundered the evidence so as to conceal the source when bringing
prosecutions. Why does this matter? Well lets play family fortunes,
what word most commonly occurs before the word 'coup'?
Chaum's system purports to divide up responsibility between n parties
but the government has the ability to coerce all n parties. So from a
cryptographic point of view these are n independent agents but from
the social point of view there is only one. And given the willingness
of former FBI director Louis Freeh to engage in a Constitutional Coup
against Bill Clinton, assisting Kenneth Starr in the construction of a
perjury trap intended to bring about the impeachment and conviction of
President Clinton, this is not a power I am willing to confer to the
FBI. Freeh's attempted coup was only 17 years ago. This is recent
And of course it is no little irony that his motivation was revenge on
Clinton for blocking Freeh's anti-crypto agenda. One of the many
things that we discovered in the wake of 9/11 was just how incompetent
and ignorant Freeh had been. He had been so desperate to collect
information he was utterly unaware of and totally neglected the
ability to analyze it.

@_date: 2016-01-09 21:29:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Verisimilitrust 
The WebPKI was designed for the purpose of allowing people to buy
stuff from online stores with at least the same degree of security as
through traditional mail order or in traditional stores. That is all
it was ever designed to do. If you are upset that it is not proof
against certain attacks ask yourselves why you were using a system
that was never designed to meet those requirements.
Oh thats right, the WebPKI is the only open PKI that has ever been
deployed and become ubiquitous. Plenty of folk had much better ideas
about how to make much more capable systems than I ever did. Which is
of course why you have all been using them for the past decade.

@_date: 2016-01-10 21:25:53
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Verisimilitrust 
Not at all. I would have much rather avoided X.509 entirely. The only
things used in the Web PKI are certificate chaining, the basic key
formats and the notion of extensions.
There were requirements considered outside retail but mostly in the EDI area.
Open PKI is a technical term, Skype is not an open PKI, it is closed
model which greatly simplifies their trust considerations, all the
parties have direct contractual relationships. SSH is not really a PKI
in the sense of providing a general trust infrastructure, it is
limited to point to point. It certainly doesn't meet Baum's definition
of an Open PKI.
And as usual, everyone dumps on my work. To which I say, fine, there
are things I would like to change as well. But lets not start from the
assumption that the only thing holding the industry back is the one
solid achievement we can claim.

@_date: 2016-01-15 09:20:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Verisimilitrust 
On new trust models,
What I have done with the Mathematical Mesh is to apply many of the
concepts of X.509 PKI but to a completely different domain - managing
a personal trust infrastructure.
I have code and documentation that currently work and I am in the
process of putting both out in the real world.
In traditional PKI we spend all our time working out how Alice can
trust Bob's key. That was the problem in 1990. Today the much bigger
problem for Alice is working out how she can trust her own keys. How
does Alice trust Alice?
We all have lots of devices and we are acquiring more. Now that a
computer can be bought for $5 (albeit on a long waiting list), they
are going to accumulate even faster. Last night I bought a couple of
Windows PCs for $100 each (the kickstarter is still open, LattePanda).
Alice is only going to talk to Bob occasionally, she will be talking
to her networked devices constantly and they will be talking to each
Anyone who has set up SSH knows how hard the process of managing keys
actually is. I have two computers and I want to be able to SSH from
either to the other. This sounds all very simple and straightforward
until we remember that the tool we use to connect is SSH. So we end up
with a bootstrap issue.
Looking at instructions on setting up SSH for git on the Web, most are
designed to 'make it work'. The fact that all the machines have the
same private key and this is a bad thing doesn't register. Nor is the
fact that the private key ends up being copied onto public /temp
Now try to do the same thing with devices that don't have a keyboard
or a display...
It is possible to do the job right but only just and I certainly would
not want to have to try to explain that to someone else. So lets give
people tools that do the job really right. Every machine has its own
unique private key for each account. The authorized keys files are
maintained automatically so when a new machine is added, it gets the
appropriate authorizations. Server key fingerprints are registered in
the user's central directory, etc.

@_date: 2016-01-18 17:59:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Plan to End the Crypto War 
And moreover, Chaum is first and foremost showing a new technique
here, applying homomorphic encryption to a particular problem. Folk
who are spending their time complaining about the requirements he has
chosen should note that as with most cryptography, the same technique
can be applied to many requirements.
The impossibility of government backdoor access doesn't come from any
lack of cryptographic capability, it comes from the utter incoherence
of the requirements. I was reading a piece by Kaminski on BitCoin
where he complained that it claims the advantages of both its current
and its future architecture and leverages one off against the other. I
get a similar feeling when I am reading the government backdoor
proposals, they are fully accountable but do not want to have to
bother with warrants, they are only demanding exceptional access but
every transaction must be visible, etc. etc.
Chaum's proposal is a useful contribution to that debate insofar as
the FBI will clearly reject it and so would anyone who might choose to
use a mix network. Identifying a mid point between the positions of
the two camps that is obviously infeasible is a good step towards
showing that the intersection between the two positions is the null

@_date: 2016-07-07 00:03:09
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Some questions for a course 
I am giving the third part of my crypto course at the Artisan's Asylum
tomorrow. I am down to the wire.
Does anyone have a cost for breaking 512 bit DH on Amazon compute cloud or
similar (order of magnitude would be fine) ?
And same for Logjam type attack on the prime.
Also source for Work Factor or RSA2048, I am pretty sure it is 112 but my
Google karma has deserted me.
The rough podcasts for parts 3 and 4 are on YouTube (hidden). Have to error
check them.
The new approach I am trying seems to work a lot better than the
traditional one. It is more of a top down approach starting at a high level
and showing how all the pieces fit together first. Do integrity before
encryption and don't bother with things like block ciphers vs stream
ciphers and AES modes till you start looking at how crypto breaks.
Also, whats the favorite AES-MAC mode. Authenticate and Encrypt seems to be
GCM, what about straight MAC?

@_date: 2016-07-07 01:12:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What to put in a new cryptography course 
The more complex you make the system, the more time you will spend
analyzing it and the less complete your analysis will be. So learning to
simplify without loss of functionality is critical.
But you also have to watch the problem of complexity through over
simplification which is how PKIX got in such a mess. Instead of having one
mechanism to do a job, people bleated 'keep it simple' and so each
mechanism was not quite powerful enough to do the job intended. And so
instead of one mechanism covering CRLs and OCSP we ended up with two and
then SCVP and many variations thereon.
And of course the people who bleated 'keep it simple' the loudest then
went and invented policy constraints.
Another example of false simplicity is attempting to reuse a tool that
isn't designed for the task. The use of PKIX certificates as a delegation
mechanism for BGP security is utterly nuts. Just give each RIR a cert and
they sign their list of BGP assignments once a day.

@_date: 2016-07-08 16:21:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Putin goes full Stasi; 
Just a nitpick.
I have no problem telling people my encryption keys.
It is the decryption keys that I care about.

@_date: 2016-06-07 12:14:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] GNU's "anonymous-but-taxable electronic payments 
This is something that I see as a trend in modern crypto that is worth
reminding people of.
Back in the 1980s, we faced some really difficult deployment challenges:
1) Machines were slow. Even RSA1024 was slow enough to have a serious
impact on your application.
2) Network connectivity was the exception. Applications had to be written
so that someone could dial into their ISP, upload their outgoing mail and
download their incoming and disconnect without any user interaction.
3) Some idiots thought that ASN.1 was actually useful.
None of these restrictions apply to the vast bulk of machines and network
users today. Yes there are parts of rural Montana and remote parts of
Nigeria where connectivity is still 'batch mode'. But those folk are not
going to be early adopters for anything. Yes there are more 8 bit CPUs
being produced this year than at any time in the past. But those devices
never supported IP and never will.
It is very easy for people to look at the legacy crypto applications and
assume that those represent timeless design truths. They don't. Those
systems were designed around constraints that no longer exist.
Whit Diffie originally proposed a public key directory. Lauren Kohnfelder
invented certificates as a mechanism to make PKI practical with unreliable
connectivity. Now that we have reliable connections we have infrastructures
like OCSP and XKMS that are actually trying to bend the model back to
Diffie's directory.
Oh and BTW, CAs sell management of PKI credentials, not certificates.
Whatever you try to replace PKI with, there will be a market for services
that establish trust.

@_date: 2016-06-09 16:36:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] GNU's "anonymous-but-taxable electronic payments 
Maybe so.
But preventing double spending pretty much makes some form of network
connectivity a requirement.
The attempt made to allow wallet to wallet transfers in Mondex was
hilariously bad.
Avoiding double spending means that you can be confident that you have
reference to some universal consensus on the state of a ledger.

@_date: 2016-06-20 09:33:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Digital currencies 
I think it is a fundamental error to confuse a payment transfer system and
a currency.
BitCoin is a conflation of the two but there is no reason why a ledger
based payment system requires a new currency.
Harber Stornetta hash chain notaries are inherently stable. Using as much
electricity as the island of Malta does to distribute the ledger is an
abomination. Ultimately BitCoin is betting on the ultimate dotcom bubble,
the only value in the currency is that people want the currency.

@_date: 2016-06-20 14:43:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Digital currencies 
Which is really sad because it is actually rather easy to establish an
append only notary infrastructure. We have a few emerging including
certificate transparency and my Mathematical Mesh.
Link a few independent notaries together and it becomes impossible to
backtrack very quickly.
Yep, and Harber Stornetta works great as a hierarchical scheme.

@_date: 2016-06-21 21:05:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Code is Cruel -- The DAO 
Hacking and design are very different mindsets.
Designers have to be able to break systems. But the very best breakers are
very rarely good designers. To be a good breaker you have to be really
comfortable with complexity. To be a good designer you have to be the sort
of person who finds complexity ugly, something to be eliminated wherever
Sure building javascript into the Web did allow for some Web site effects
that weren't possible before. But it took over five years for the
javascript implementations to become stable enough to be minimally useful.
The first version of Javascript would crash the browser if there was the
smallest bug in the code - or no bug at all.
So building Javascript into a payments system was really the sort of thing
that was too clever by half. It was clearly doomed from the start.
Only these guys have a billion dollars of live cash in their system. And
they are currently changing the system code to claw back money that they
consider ill gotten. So they are in effect rewriting the rules book without
any consideration of the legal implications of doing so.
If people are going to design cryptocurrencies they really need to start by
considering what the law says rather than assuming that math trumps law. It

@_date: 2016-06-23 00:19:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] craig steven wright 
There are many reasons to think the patent applications would fail. Not
least the fact that the core technology was published on this list six
years ago. Any pre publication voids a UK patent application.
US patent applications have had to be published within 18 months of filing
for quite some time now. So the idea of a secret list of patents is silly.
The core of the scheme is the Haber/Stornetta catenate certificate patent
that expired yonks ago. There are plenty of ways to make a linked timestamp
stable and the use of linked timestamps to support ledger transactions is
well explored.
Well work for those of us who work as expert witnesses.

@_date: 2016-06-23 00:33:35
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What to put in a new cryptography course 
I am giving a course on cryptography starting tomorrow at the Somerville
Artisan's Asylum. The plan is to give 8 modules of roughly an hour, two per
week. The whole point being to film the presentation and publish it as free
YouTube videos.
One of the reasons for giving the course is that the range of crypto
opportunities has moved on since 1990 but our tools haven't. The algorithms
have changed but we still use the same repertoire of primitives that were
used in PEM and PGP.
* All the 1995 patents have expired, there is a lot of basic crypto being
* Machines, even the slowest machines are much more capable than in the
So the question for this group is what crypto have we been ignoring that we
should be using. And here I am looking for stuff that is useful rather than
Some of the points I am planning to make are:
* The heart of cryptography is integrity, not confidentiality.
* Symmetric key is not just an inferior scheme to public key that you use
for bulk work and then forget.
* The most important data security risk is loss. See cryptolocker. So don't
just blithely encrypt stuff without planning to make absolutely sure of
* Cryptography doesn't solve any security problem. All it does is reduce it
in size to 128 or 256 bits.
* Proxy re-encryption is the key to making multi-party security work.
* End to end security is meaningless unless you define the endpoints in
your system and then it becomes complex.
* Message, transport security are not alternative choices, do both.
* Complexity is the enemy of security.

@_date: 2016-06-23 10:21:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What to put in a new cryptography course 
Oh one thing to definitely cover is the fragility of formal proofs. Yes
formal proofs of security are good. But not if they force you to design the
system in a way that makes it less robust.
Classic example is one time pads. Yes they are 'provably secure' but
implementations of them are almost invariably less secure than systems
using AES.

@_date: 2016-03-02 00:03:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The FBI can (almost certainly) crack the San 
Unless you have something like the secure enclave, i.e. a dedicated
CPU with direct connection to the associated storage, the system is
going to be hackable.
I have been rather peeved by Apple's approach here because they have
taken a very high risk approach that seems to be more about covering
up the fact that the phone as designed has a backdoor that can't
actually be closed.
This was the ground that the FBI chose, a high profile terrorist case.
Now that Scalia is dead, the strategy does not look quite so reckless.
But there is still a substantial risk that if Apple wins in court, the
response is likely to be a push for new legislation.
A system that relies on the manufacturer refusing to obey a warrant
for security isn't acceptably secure.
Yes, Apple's newer iOS models have the secure enclave. But what about
their desktops? What about Windows? What about Linux?
Microsoft did some really good work on the TPM system some years back,
work that I was mighty upset got a really bad reception from the
EFF/GNU/BULLRUN crowd.
Having a Security Computing Unit (SCU) should be as ubiquitous in
computer hardware as a GPU or a WiFi chip.
Yes, infrastructure such as TPM chips and secure enclave could
conceivably be used by DRM systems. But that isn't why those systems
were developed and that is not what they are actually good at.
Stopping leakage of private keys is actually quite a straightforward
technical challenge because to succeed in a confidentiality attack on
MY data you have to break one of MY devices. And I don't have that
many devices connected to my Mesh profile. I very much doubt that I
would ever allow more than a few dozen machines connected to my
confidential data profile. An attacker has to get hold of one of those
physically and decap the SCU.
Stopping leakage of copyright content is a much harder problem because
DRM is a break once, run anywhere problem. Having an SCU might make
the task of the DRM folk a little bit easier but it is still an
intrinsically harder problem than protecting personal digital assets.

@_date: 2016-03-02 15:41:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] iPhone hardware attacks 
The NSA would not tell them about their capability. The NSA is not
testifying and so the NSA can lie to the FBI and let the FBI testify
on that lie to Congress without having perjured themselves.
Not that that would be a concern for them. Clapper got away with it.
On the broader question, I think part of the issue is what the
probability of success is. The software route is pretty much 100%
guaranteed to work. I don't think you can say that for decapping. A
bit too much acid, a slip of the hand, light erasing the stored
data... Lots of opportunities for a slip twix cup and mouth.

@_date: 2016-03-04 17:35:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] EFF amicus brief in support of Apple 
I think it is a weak argument to use in this case.
The FBI can reply by writing the code itself and then getting a
warrant forcing Apple to sign it. Code is speech but is adding a
digital signature? I rather doubt it.
One of the reasons that we backed the Google Certificate Transparency
effort was the concern that someone might coerce one of our affiliates
into a mis-issue. CT does not provide an access control but it does
add audit and accountability. The FBI is very unlikely to try to get a
mis-issued certificate if the fact is going to become public.
Put your trust in crypto, not the courts or the willingness of
corporations to defy them.

@_date: 2016-03-07 21:28:13
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Two questions of security 
I just released a new set of Mesh specs, I am now working on getting
the site set up with a decent explanation of what is going on. In
particular, I am trying to compress the following argument to a couple
of pithy one liners. Was wondering if people might have ideas:
Traditional access control approaches were created in the era when the
problem was how to divide the computing resources of one machine
between many people. Today our typical security problem is the exact
opposite - one user has many, computing devices. And as every consumer
good 'becomes intelligent' or at least adds networking capabilities,
the problem gets worse.
As a result, we end up authenticating the wrong thing. Instead of
authenticating the users, we need to authenticate machines.
The Mesh reduces this problem to two questions:
1) Do I want to control this device? If so, for what purposes?
2) Is this device under my control?
I buy a new device, it might be a laptop, a mobile phone, a new car
but in this case it is a garage door opener.
I tell the garage door opener it is under my control, the only purpose
it supports is opening the door. The door opener confirms that it is
under my control. Now I can press the open door button in my car and a
cryptographically secure challenge response protocol using real
cryptography rather than junk that was broken 20 years ago takes

@_date: 2016-03-08 09:29:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Two questions of security 
I like the idea of all the LED lights in the data center blinking in
synchronization and outputting the UDF fingerprint of the common axiom
of trust.
Someone sitting in the data center can instantly tell which device(s)
are not synced to either the common time source or the common root of
It means that there is actually a point to all those blinking lights.

@_date: 2016-03-10 04:58:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Help with Raspberry Pi IoT initialization... 
So here is the deal, I have a draw full of Raspberry Pi devices. I would like to be able to take create a variation of the Raspberry Pi boot media that provides the Pi with the ability to securely boot into my cryptographic environment (aka Mesh Profile) and provide SSH access, TLS cert chained to my root, etc. etc.
The idea is that I take a RPi out of one draw, I take an SD boot card out of another drawer that has my personal boot media image. The machine boots and creates a set of machine specific private keys for SSH, TLS, IPSec, applications, etc. I can now interact with the device using secure credentials unique to that device.
As evidence that the device is now securely bound to my Mesh profile and time source, the device blinks its status LED to publish the UDF fingerprint of the axiom of trust that it is bound to. [Thanks to Natanael for that suggestion]
The way I propose to do this is as follows:
The boot media has the following additional information:
* My Mesh profile fingerprint and account identifier* A temporary device profile that contains a signature key pair* A run once configuration tool* A digital signature of the boot partition excluding itself
When run, the run once tool does the following:
? Verifies the boot media signature* Creates a unique device profile for the device [forget the randomness issues, I have this covered other ways]* Requests connection to my Mesh profile using the temporary device profile authentication key.* On acceptance * Creates all the necessary device application keys ? Erases temporary device profile key(s) * Starts the blinkenlights display to confirm that the device * Waits for further commands authenticated by a key authorized under my Mesh profile
The bits I am having a little difficulty with are the ones marked ?
What is the best way to gurantee that I am authenticating the device boot media?What is the best way to guarantee that the temporary key is erased from the boot media?
I am assuming that on a UNIX build, this is going to mean manipulating the RAW devices in some form. But what makes me a little nervous is the possibility that I 'delete' the data by creating a new entry in the log file that supersedes the old rather than overwriting the original storage cells on the chip.
Sent from Outlook Mobile

@_date: 2016-03-10 19:57:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Help with Raspberry Pi IoT initialization... 
So I have the option of putting the SD boot disk into a trusted device
(e.g. my personal laptop that never leaves my sight) and verifying
that nobody has tampered with it while in the drawer.
I am aware of the problems with the bootstrap trust problem. That is
not what I asked for help with.

@_date: 2016-03-12 11:29:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is Non-interactive Zero Knowledge Proof an 
I am not sure I have a good answer to Charlie's question. What we have
here is a situation where a series of operations which are
individually zero knowledge are composed in a system that is not.
This type of problem is one example of a broader problem I am seeing
with formal approaches to cryptography. What you can prove to be
secure is frequently very much less secure than robust but
non-provable crypto systems. The difficulty is that to make a system
tractable in a system of formal logic, we have to simplify it and
strip it back to the simplest possible scheme that lacks robustness.
The prime example of this is 'one time pads' which are at the same
time the only provably secure encryption scheme and the most certain
indicator of cryptographic snakeoil.
There is currently a kickstarter for a 'provably perfectly secure'
encryption scheme using one time pads. So I asked them how they were
exchanging the cipher stream and of course they encrypt that when they
exchange it. They have this idea that if I can't attack the exchange
of cipherstream and I can't attack the messages, their system is
secure. Of course, what I would do is attack both at once. So what
they have managed to do is to reduce AES to a stream cipher - yuk!
I see the same problem in a lot of other academic systems.

@_date: 2016-03-15 08:49:31
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Govt Can't Let Smartphones Be 'Black Boxes, 
I was at an MIT/Harvard workshop on norms in cyberspace. It was
focused on inter-government norms because that is where most of the
participants worked.
Non state actors are also bound by norms. ISIS being the exception
that proves the rule. The price they have paid for their norm flouting
behavior is to create a grand alliance of every bordering power, every
regional power and every great power against them.
PRISM and the mass surveillance program violated our norms, no
question. But these were not a surprise to anyone who had been paying
attention. The big surprise for me was the Abu Ghraib photographs. Any
way you consider them, the photographs demonstrate a total collapse of
the moral fabric of the US military. And to this day, nobody has been
punished for committing the torture. The only jail sentences handing
down was for taking the photographs which led to the program being
Which is why this is a fight that is mostly being pressed by the FBI
right now. The military are much more worried about the threat of
hackers devastating the critical infrastructure than the rather modest
operational capabilities that crypto provides actual terrorist groups
A case could be made but the interpretation of that case would depend
on a supreme court where four of the justices will reject your
argument because they always favor every government surveillance
capability and the other four will reject your argument because they
consider the second amendment to be limited to allowing the states to
form militias to round up run away slaves.
The only recent SCOTUS judge that might have accepted your argument is
the one they just buried.

@_date: 2016-03-17 09:23:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Clinton asked for a secure email Blackberry in 2009 
OK so lets try to avoid Hilary bashing and focus on the policy issue please?
A long time ago now, I worked on the MIT system deployed in the
Clinton WhiteHouse that included email. I doubt the situation has
changed much since.
What has sickened me in this attack from the start is that people were
making national security a partisan issue. What HRC did as SoS was no
different to what Rice or Powell had done in the previous
The email system is insecure and that is what has the national
security implications. No matter whether Clinton's email packets are
going over NIPRNET or Comcast, they are not secured with message layer
cryptography and the transport layer cryptography is easily defeated
with a downgrade attack.
Obama required the NSA to provide him with a secure Blackberry and
they were unable to refuse. But the NSA could and did refuse Clinton.
The questions for a hearing are pretty obvious:
1) Does the Secretary of State have an urgent need for mobile communications?
2) Should the Secretary of State have secure communications?
The answers are obviously yes. The Secretary of State travels more
than any other member of the cabinet. Her need for secure mobile
communications was arguably much higher than that of the President.
I think that this particular issue actually bleeds into the Apple/FBI
case. At the same time that the FBI is arguing for the ability to
break any system, the Federal government is unable to meet the
security needs of the Cabinet member with the most need for secure
mobile communications.
The cost of the PRISM, TAO, etc. programs was needing to preserve the
vulnerabilities they exploited. And they certainly haven't ended
completely. Only the other day I found myself having to argue that no,
a 2^128 work factor is not sufficient for every need and yes we do
require a 2^256 work factor.
The original reason I wanted to go to elliptic curves in the first
place was to get the 2^256 work factor I can't get with RSA without
silly key sizes (16K). But no, I have to spend time making the case.

@_date: 2016-03-17 09:42:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Formal Verification 
There is another approach that I developed in my doctoral thesis 25
odd years ago.
First you develop a language that is precisely targeted to your problem domain.
Then you develop a code generator for that language to your target language.
Finally, you augment the code generator to generate the proof as well.
C and C# are general purpose languages that talk about what the
machine should do. If you are writing a communication protocol you
have a collection of finite state machines at various levels. Some are
used to map bits to data structures, others orchestrate the state at
the protocol ends, etc. etc. C and C# require the programer to do the
mental map from the problem domain to the target.
With the Goedel meta-synthesizer, you can quickly develop a
mini-language that describes a ridiculously specific language and
create a code synthesizer for that domain. So instead of a completely
unrestricted parser generator like yacc, a Goedel generated parser
would only work for RFC822 style message headers.
Using this style of coding removes a vast amount of the cruft that
clutters up traditional implementations. In my experience, the largest
number of coding errors come from the mismatch between the problem
domain and the implementation and that applies to formal methods as
well. A broken specification is as much a bug as a broken program.
Which is why I originally started looking at this approach in the
first place.
But if you want to use Goedel to develop a formal proof of
correctness, you can do that as well by generating the proof just like
you would generate any other bit of code.
I recently cleaned up all the code so that I could use this to build
the Mathematical Mesh. The code is on SourceForge and GitHub under an
MIT license. You can get there from The tools are available as standalone tools or integrated into Visual
Studio as VSIX extensions.
If you use them to develop protocols, there is a set of other support
tools that allows the entire production chain to be automated. If you
look at my Internet Drafts for the Mesh, all the examples are
generated from running code that was generated from the protocol
specification by a generator. The reference sections for the draft
come from the same source. This ensures that all my examples match the
reference section.
Now I am not currently using this system to develop formal proofs, I
do not have time to go down that route at present. But it would
provide a good platform for that approach.

@_date: 2016-03-17 15:44:33
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Formal Verification 
My thesis but it is a bit old.
I got distracted by a side project called the Web or something. Only
just got back to it.
Not for TCP/IP but if I was going to write a v6 stack I would want to
use the approach.
The tools are here:
As I said, they are all open source. I am documenting them as I
document the Mesh.
Unlike traditional formal methods, this is a major productivity
improvement. I can generate a protocol spec from scratch in under a
week elapsed time and no more than about 20 hours work. The LURK
specification I am currently writing for a BOF at IETF95 uses these

@_date: 2016-03-17 17:23:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Clinton asked for a secure email Blackberry in 
I am not sure they do actually. I would have to think really hard to
work out if quantum computing against RSA is harder than ECDH. I
rather suspect it is because the factoring attack is exploiting one
weakness and QC is attacking another.
A Quantum computer to break a 16 bit RSA key would likely have to have
a very silly number of QBits.
No, the reason I use 256 bit crypto everywhere is simply because it is
simpler to use 256 bits for everything than provide two speeds and let
people choose. Even on the very weak computing devices I am using for
IoT, there isn't much to choose between 128 and 256 bit work factor
because they send so few messages and only need to rekey once a year
if that.
If I am happy with 128 bit WF then RSA2048 is near enough and already
ubiquitous. No need to change.

@_date: 2016-03-18 12:18:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Code beg... C#... 
Does anyone on the list have knowledge of a library that implements
the new CFRG elliptic curve algorithms in C
I am currently trying to get a draft out for Monday for IETF'95. My
original plan was to only do RSA but it has gone has gone faster than
I had hoped and I am thinking that I will have time to show key
agreement as well. It would be more interesting to do that for ECDH
than DH.
Given that this is an IETF draft, I want to use the IETF curves and algorithms.
Worst case, I will probably use ED25519. But I didn't follow closely
enough to know if there is a delta I have to cope with.
Thanks in advance for any help. I will put the finished LURK
implementation up on GitHub under an MIT license.

@_date: 2016-03-21 11:36:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Paris attackers used OTP's: One Time Phones 
Each year, the family goes to the Arisia convention. A couple of years
ago I bought a couple of Pay as you go phones for the kids.
This year, I couldn't find one of them so I bought a pair of pay as
you go Android phones - $20 each.
I noticed that these attackers were activating the phones only just
before they used them. Presumably they were bought for cash. They
would have to have some way of knowing the number they had to call
after activation so they could talk to other co-conspirators but that
would be pretty easy to mask.
About the only likely point of commonality then would be where the
phones were bought, the model, etc. I suspect you could probably trace
them all back to a couple of shops and that they would all be the same

@_date: 2016-03-21 22:03:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] This is not the end... 
I think we need to clarify where the lines are.
The iPhone 5 was not sold as being secure against government warrants.
That didn't come till later.
What matters is the right to build and sell stuff that is secure
against mass surveillance. Putting a backdoor into future phones is
the problem.
A system that requires someone to commit contempt of court to preserve
its security isn't secure enough any more.

@_date: 2016-03-22 10:58:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] And they're off... 
Where are you seeing this? All I could find was this:
about rather than something Schiff brought up.
Burner phones are the new encryption it seems.

@_date: 2016-03-23 20:08:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Paris attackers used OTP's: One Time Phones 
A crate of phones bought at the same location would be traceable.
A smart terrorist is going to spread their purchases.

@_date: 2016-03-26 12:30:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] On the Impending Crypto Monoculture 
We ended up with a different construction for Curve25519 crypto and
Curve448 in fact.
Remember that you don't get stronger crypto protocols by adding
stronger algorithms. You get stronger crypto by taking out the weak
Right now, about 70% of the crypto algorithms commonly deployed are
junk and we have a lot of pointless variation in variants between
protocols. In particular the EC curves situation is a mess. We had too
many choices and no idea which were backdoored or not. And no,
brainpool didn't solve that
I would like us to get to the point where we have two algorithms for
each primitive that are implemented for every active IETF protocol.
These are a current algorithm and a backup in case of problems.
I am not so happy with the Cha-Cha and poly choices. I would prefer
that we had a competition to choose a backup symmetric algorithm.
Right now RSA is still the default algorithm and the Elliptic Curve
algorithms are going to be backups. I suspect that will remain the
situation for quite a while, possibly until we start getting quantum
resistant algorithms we can use.

@_date: 2016-03-28 11:00:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Gates are cheap. Should cipher design change? 
Looking at the S-box discussion, I was reminded that DES was optimized
for hardware implementation. If you are doing crypto in hardware, an
S-Box is probably the most gate efficient way to do it.
There is a catch though. DES was also designed at a time when fitting
the encryptor on a chip would likely require an iterative approach in
most cases. So the 16 rounds of DES had to be essentially the same.
Today we have a very different situation. AES has found its way into
many crypto suites as a set of instructions for executing a round. And
that is to be expected in an era where one of the chief problem of CPU
design is to find a useful way to spend the available gates.
So now we have a cipher designed for efficient software implementation
being migrated into the hardware. Which sounds like a big deal except
that what is really happening is that the software has moved from
executable code to microcode.
What would a modern cipher designed for efficient hardware
implementation look like? Is it just DES with more rounds and a bigger
block size? How about mixing up different cipher principles in one
cipher? So start with a Feistel, then an S-box, then...
Another possibility to consider is what could we do if we mixed those
single instruction AES rounds with another cipher entirely.

@_date: 2016-03-28 23:22:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] USG Moves to Vacate Apple Decrypt Order 
Some random thoughts
* Apple wins big. First, they beat off the FBI warrant, second
everyone with less than a 5s has to buy a new phone.
* The new phone might still be crackable by someone who has the tools
to reverse the secure enclave. But Apple isn't one of the parties that
can do that.
* FBI might in future be able to subpoena information to use it for
making a break attempt against the secure enclave.
* If your security depends on someone else refusing to obey a
subpoena, change your security.
* If their security depends on you refusing to obey a subpoena, get another job.

@_date: 2016-03-29 12:17:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] On the 'regulation proof' aspect of Bitcoin 
I am getting rather fed up of all these BitCoiners telling me how
their scheme can't be taken down like the Feds took out Gold Age. And
back when I was predicting the Feds would take out Gold Age like they
took out Liberty Reserve they were telling me how that wouldn't happen
because no extradition treaty. And before that they were telling me
they couldn't touch Liberty Reserve like they took out E-Gold because
no US servers and before that they were saying E-Gold was untouchable
because it was incorporated in St Nevis and Kitts.
Telling me that something is impossible is like making it a challenge.
I have seen a dozen of these schemes over the years and every one of
them has told me how they are utterly unlike any religion before and
that theirs is the true God. The fact that the genuine innovation in
BitCoin is that it is a Ponzi scheme without a central mastermind only
makes matters worse. People never want to be told that Madoff has
stolen their money rather than getting that 20% return or that the
Nigerian Prince isn't going to send that money ever.
Greed is a powerful inhibitor of curiosity.
So given that the gauntlet has been thrown down, here is how I would do it:
First note that for purposes of preventing Bitcoin being used for
criminal purposes, it is sufficient to significantly degrade the
infrastructure to the point where it is no longer a practical
mechanism for extracting ransomware payments, purchasing illicit
materials, etc.
1) Federal Reserve issues notice stating that all BitCoin transactions
regardless of size require a Currency Transaction Report (CTR) to be
This immediately makes running a US based exchange impractical. It
also means that any direct transfers between a US bank/financial
institution and a foreign exchange are subject to notification. The
Fed maintains various watchlists of foreign institutions whose
activities are automatically considered to be suspicious.
Still want to buy that weed with BitCoin? Better hope the Feds don't
decide to raid you for kiddie porn.
At this point notice that there are two sets of effects on the BitCoin
infrastructure. One is purely practical, preventing the use of the
currency as a means of exchange in the US. The other is economic. The
less attractive it is to hold BitCoin, the lower the demand. The lower
the demand, the less the value. The less the value, the less incentive
to mine new coins.
I rather suspect that merely issuing the notice would be sufficient to
start a run on BitCoin. But let us assume for the moment that it is
2) Partner with EU regulators.
BitCoin is not exactly popular in Europe either. But it is tolerated
largely because nobody considers it significant enough to make a fuss.
The development that is likely to start people making a fuss is the
use of BitCoin to collect ransomware payments.
Most EU regulators have the same toolset as the Fed and they have
recently been using it to impose sanctions on Iran. Unlike Iran,
suppressing BitCoin does not create foreign policy concerns. Plenty of
countries wanted to sell exports to Iran or buy cheap Iranian oil.
BitCoin isn't a country so there isn't the same incentive to protect
BTC commerce.
3) Start making examples of BitCoiners in the US.
There have already been some arrests of people who were marketing
BitCoin as a vehicle for evading currency controls. The main
difficulty in bringing charges being the ambiguous status of BitCoin
transactions. But once the Fed has ruled that a CTR must be filed,
merely using BTC becomes cause for criminal complaint.
OK so at this point it is really difficult to transfer money into or
out of BTC from the US and attempting to do so risks a jail term. do
you think BTC is going to return to $1000 under those conditions or
sink like a stone?
Sure you could bring a lawsuit. But on what grounds? Control of the
currency has been considered a core government function for thousands
of years. Article 1 Section 8 of the constitution clearly and
unambiguously gives the Federal government the exclusive right to
regulate minting of coin.
Even if a lawsuit was brought, it would be three years before any
final decision and in the meantime, the value of BTC would drop like a
So why doesn't the Fed do this?
My guess is that until ransomware, BTC just wasn't a big enough
irritation and there is always the knowledge that as fast as one
scheme is shut down, another pops up to take its place.

@_date: 2016-03-29 16:25:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] On the 'regulation proof' aspect of Bitcoin 
Collecting cash via BitCoin requires no infrastructure. Using mules is
much more complex and a lot riskier.
Not all victims are actually victims. If I have a backup I will rat
out the mule in a heartbeat. In fact I will infect machines on
Mules take time to recruit. If it takes them eight hours to recruit
and train a mule and they are caught after ten drops, that limits them
to ten drops a day.If they are burning 20 mules a month, they are
going to get caught.
The offshore mules have to deliver the cash to the criminal remember.
And they take a cut. And they might just run off with the cash. So
they need someone to keep them in line.
I did. It was an obvious consequence of the decentralization. That
comes at a severe cost.

@_date: 2016-03-30 13:21:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] On the 'regulation proof' aspect of Bitcoin 
Well the point here is that the principal reason for the extreme
decentralization in BitCoin is political rather than technical. And
that political constraint comes with a cost. If the decentralization
does not meet the requirement driving it then future schemes should
avoid it.
Bitcoin is at least two different things, it is a mechanism for
assigning value and it is a mechanism for transferring value between
I would like to be able to make use of a BitCoin like transfer scheme
without the mining bit. I don't think that is actually necessary to
maintain the integrity of the chain.

@_date: 2016-03-31 10:19:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] On the 'regulation proof' aspect of Bitcoin 
Well the Merkle chain is remarkably resilient by itself.
Consider a situation in which we have ten independent notaries
maintaining separate public chains. Every day they take the output
from every other chain and enroll it as an input. Any attempt at
rollback now requires every notary to collude and even then the
defection will be obvious to anyone keeping notes.
This is where I got the idea of calling the system a 'Mesh'. Its like
a huge collection of gears all meshed together. None can turn unless
every other one turns.
It is pretty easy to see that any system that has chained notaries
will quickly end up making interchange agreements and that these will
rapidly converge into one system.
So the upshot of all this is that if you want to fix data D in time,
you simply calculate H(D, tx), where tx is the current output token of
any notary and then enroll that result into a notary. The time at
which this occurs is precisely fixed in time. It cannot be moved
forwards or backwards.
The workfactor for moving the notary timestamp is effectively breaking
the underlying hash. So we can take it as being infinite (I only use
The notary isn't actually a trusted third party in the long term.
After the data is enrolled in the mesh, it no longer has any more
ability to assist an attacker in any fashion whatsoever.
I had to look at rsync in detail as prior art for a client. Under the
covers it is very similar to git in fact.

@_date: 2016-03-31 12:53:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] On the 'regulation proof' aspect of Bitcoin 
That is the great thing. It really doesn't matter. All a notary needs
to do is to establish an agreement with at least one other notary to
enroll their data and to furnish customers with a proof chain to that
notary. Once those have happened, the transaction is fixed.
At a cost of using more electricity to mine than the island of Malta.
$400 million a year is not something you can simply dismiss.
The cost of participation in the Mesh is remarkably low in comparison.
Just find one source that will provide a connection.
In practice, I would expect some sort of consortium to emerge that
creates a single, dependable chain that essentially becomes the
network standard.
As I said, I would expect a hierarchy of chains to emerge naturally
with some being considered 'core'. All you need to do to get to ground
truth is to get your data enrolled in a network that feeds into a core
chain and then record the proof chain to the core.
For financial transactions there are a number of different time points
of interest:
1) When is the transaction initiated?
2) At what point does the transaction become immutable?
3) At what point does the immutability of the transaction become public?
To give an example, I sell you some widgets for $10. At what point do
I know that I will get the money and at what point can I then spend
the money?
The two have to be different in a real financial transaction because
clearing a payment and settling it are different things.
I understand that you want the transactions to be instantaneous and
irrevocable. There are very good reasons why such capabilities don't
exist in the current payments infrastructure.

@_date: 2016-05-05 22:33:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proof-of-Satoshi fails Proof-of-Proof. 
Which algorithm was used to sign the 'proof'. I tried to work it out but
couldn't tell for sure. But it looks to me like it was some form of ECDSA.
[Trying to simplify for an audience not familiar, have I gone too far?]
Now if you sign a document X with RSA, the signature will be the same every
time. But with all forms of DH based signatures, a random number is
generated and that affects the signature value. In effect, every signature
has a salt value.
Which means that a document X will only have the same signature a second
time if the same random number is used. And if that happens and you sign
any other document it allows an attacker to work out the private key. So
anyone doing DSA has to be very careful to avoid that.
So not only is it very suspicious that 'Satoshi' would choose to prove who
he is with an authentication proof that the real Satoshi would laugh at,
there is really no way that legitimate signature software would produce the
same signature twice.
This is not proof that the guy is not Satoshi. But it is definitive proof
that he is lying when he makes the demonstration. The only circumstance in
which the real Satoshi would do this rigmarole would be to attempt to
squash rumors it was him.

@_date: 2016-05-06 21:04:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proof-of-Satoshi fails Proof-of-Proof. 
Damn, forgot about that bit. Yes, have to make sure that the thing doesn't
leak the private key...

@_date: 2016-05-12 09:09:26
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] 2nd Amendment Case for the Right to Bear Crypto 
Never use the second amendment when you can use the first.
The interpretation of both amendments have changed over time. Less than a
hundred years ago, Eugene Debs was in prison in the US for exercising his
free speech right. But there is a strong consensus on the first amendment
that is really not under serious challenge in any part of the
establishment. Politicians and judges agree on an interpretation that is
very close to being absolute.
The current SCOTUS interpretation of the second amendment is very recent,
it was handed down by the Rehnquist court and even that interpretation is
far from absolute. Even Scalia probably wouldn't have found for a personal
right to have hand grenades. And what is coming with DIY drones carrying
IEDs is likely to scare future courts into being very very restrictive
Cryptography was being regulated as a munition during the Rehnquist era.
The case was won on first amendment, free speech grounds.

@_date: 2016-05-14 13:17:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] 
We should probably have someone make a point of debunking snakeoil crypto
on Kickstarter.
Recently there was a guy claiming to have 'unbreakable' crypto based on an
OTP. So I asked how he exchanged the keystream. "Encrypted under AES256'.
Despite my many attempts, he was unable to understand the fact that if the
keystream is disclosed in any form, encrypted or not, the proof of
unbreakability is lost. While the encrypted keystream and the ciphertext
are unbreakable on their own, they are not unbreakable if an attacker has
The only effect of the scheme was to double the data volume and reduce AES
to stream cipher robustness. Stream ciphers can be secure but they are
fragile as heck.

@_date: 2016-05-28 21:32:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Anybody sorted out the MQV patent claims? 
I don't know and I don't care.
The first patent has a priority date in 1995 so it has expired. The second
mentions a signature in the independent claim. I do not believe that an
authentication protocol should use signature unless the purpose of the
exchange is to provide non repudiation in which case they should probably
just be signing the data.
Diffie Hellman is a fine key exchange protocol as it stands. All you really
need to provide authentication proofs to each party is for each side to
contribute a random nonce (to prevent replay attacks) and to push all the
output data through a one way function.
e^x, y -> e^xy
e^y, e -> e^xy
Agreed Key = H (e^xy + nx + ny)
Proof = If you want an ephemeral then use it as a mix in on the master key, not a
replacement for it.
I am sure there are examples of that protocol written down back in the
1980s. It works, it is robust. Recent supreme court precedent holds that
replacement of like with like is 'obvious' and so upgrading from DH to ECDH
isn't an enforceable claim.
I am pretty conservative when it comes to patent claims. I am sure that the
ContentGuard patent that I found the other month isn't actually enforceable
but why risk it when the patent expires in 18 months and I will be hard
pressed to have a working demo by then anyway.
In this case, I don't think there is anything to worry about but as always,
I am not a lawyer, use at your own risk. If you want to pay me I can give
an expert opinion but nobody is an infallible expert in what a jury might

@_date: 2016-05-31 10:34:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blue Coat has been issued a MITM encryption 
For the benefit of us who can't remember, what is the effect of path-len 0?
As in, what is the effect on systems out there in the wild as opposed to
what does the spec say. Is there a difference and if so for what systems?
Does 0 = infinity? Probably not in the spec but what about elsewhere?

@_date: 2016-05-31 13:25:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blue Coat has been issued a MITM encryption 
One of the things I learned from experimental physics was that you should
always ask the question even if you think you know the answer.
I deliberately asked what the *effect* was, not what the specification
says. The questions are not the same.
What I had forgotten is:
    CA(BC:pathLenConstraint=0) -> CA(anything) : OK
Which is kinda screwed up. I am still not seeing how to turn this into an
exploit if Symantec hold the private key.
OK so that possibility out.
Does any browser use GnuTLS though? I don't think we need to panic if the
code is being used for STARTTLS in SMTP or the like as those aren't
typically tied to a root of trust in any case.

@_date: 2016-11-05 10:35:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
The cryptographers have only interpreted insecurity, in various ways; the
point is to change it.
Document level security isn't enough, you need to protect the transport as
Transport level security isn't enough, you need to protect the document as
Security must be pervasive and automatic. The user who must think about
security is the user who doesn't think about security on the occasion that
it matters.
Tell the computer what to do, not the user. Any set of user instructions
can be reduced to code.
I spent last week writing up the documentation for the Mathematical Mesh. I
hope to get that converted into HTML and loaded onto the site next week.
After that, I just need to refactor the code so that it matches the docs
and people can start playing with it.
The core idea of the Mesh is that it is really easy to apply cryptography
to any application if every device and every user has a set of private keys
that you can use as anchor points. So making it easy for users to achieve
that allows all else to follow.

@_date: 2016-11-08 21:33:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "Evil Maid" attack? 
The idea that the GOP would have overlooked this is ridiculous.
This is actually what Deutch was cashiered for. Note that he did not go to

@_date: 2016-11-12 15:18:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] October 28th is now National Cryptography Day 
If Hilary had encrypted her email, she would almost certainly be president
It doesn't matter if you believe the analysts who say that the attacks on
the DNC came from Russia or not. That is a question about the past. The
question now is whether future elections are going to be influenced by
cyberattack by hostile foreign powers whether the meddling comes from
Russia, China, the US or anyone else.
We need a national day for cryptography and October 28th is a good choice.
It provides a way to insert the cryptography issue into the closing days of
future elections in the US.

@_date: 2016-11-12 22:09:28
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] would email encryption have saved Hillary 
There were three separate email issues:
1) The private Secretary of State server.
The GOP would not have been able to turn this into a campaign issue at all,
let alone win with it had the messages been end-to-end encrypted using
S/MIME. 
Further, I am certain that the real reason for the private server was
that Clinton (correctly) assumed that Republican operatives in the GSA
would pilfer the emails and leak them to political enemies. As it turns
out, Manning did exactly that with the State dept cables.
A lesson that needs to be drawn here is that it is not enough to be secure,
you have to be able to prove that the system is secure. This is something
we understood early on in the CA business and the reason why it isn't quite
as simple as many assume.
2) The DNC emails.
The attack on the DNC computers did begin with spearfishing, but some of
the most damaging information was again found in emails stored on the mail
server. Again, end to end encryption would have mitigated the problem
3) The Podesta emails
Podesta's email account was hacked after an aide sent him the account
password in a cleartext email. Again, good end-to-end encryption could have
prevented this.
Now these are not the only lessons to be learned and email is not the
only link in the chain that needs to be locked down. But it is a good
starting point for discussion.
Those of us in the business understand that there is more to security
than encryption. But one of the consequences of the election result is that
henceforth, all political discussion will take place in tweets of 140
characters or less.
Hilary could also have won by finding a way to give his twitter account
access back. But that is out of scope here.

@_date: 2016-11-12 22:28:13
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Need a better name 
We all know about using a digest to create a unique fingerprint for a
static file.:
Fingerprint = Presentation ( SHA-2-512 ( fred.txt ) )
I find it is useful to distinguish the presentation of the digest value
from the digest value itself and fingerprint is as good as anything for
But what if the file isn't static? Well the obvious approach is to use a
public key signature in some way. In the Mesh, I use this to authenticate
profiles as follows:
1) Each profile has a unique signature key.
2) The unique identifier of the profile is the fingerprint of the public key
There are some other features I might add in the future such as
checkpointing against a linked log but that is the basic concept.
Problem is, what to call it?

@_date: 2016-11-13 09:23:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] October 28th is now National Cryptography Day 
The principal policy objection made against her private server was that it
might have been compromised by a foreign power and classified information
might have leaked. Encryption would have completely blocked that attack.
Government emails have caused problems in every administration since the
first Clinton administration. And not just for the reasons known in public.
The EOP and much of the federal government was using a DEC all in one mail
system in 1993 which had been discontinued. So there was a shift to a new
system (Lotus Notes??). This was not a happy process. The new system didn't
archive stuff as it was meant to. If you remember, back in the day, there
was a fuss over Vice President Al Gore's lost emails after one of the mail
servers broke and it turned out there were no backups.
A large part of the Gore scandal involved allegations that emails involving
fund raising activities might have been sent over government computer
systems and thus break the Hatch act. So to avoid that problem, the
incoming Bush administration mostly used a mail server run by an RNC
contractor. Not only was it hideously insecure, the nationalities of the
administrators makes for interesting reading.
So the requirements are much broader than just 'encryption'. At a technical
level it is necessary to:
* Restrict ability to send to the govt. email addresses so that it isn't
necessary to keep the spam.
* Log all messages in a notarized linked log
* Modify the Hatch act to permit limited use of electronic communications
for party purposes by elected officials.
On the confidentiality side, I am already working on a system that uses
Proxy Re-Encryption to enforce access controls to SCI. This is
Mesh/Recrypt. Each security label maps to an encryption key. The
administrator holds the private key and splits out recryption/decryption
pairs to individual users/devices.
I don't have much on Mesh/Recrypt on the site yet, but I pushed the rest
of the Mesh docs last night:

@_date: 2016-11-13 17:06:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] October 28th is now National Cryptography Day 
It didn't need to. The election came down to 100K votes in three states.
What I am certain of is that 28th Oct is a day that is going to resonate
with at least one party. 

@_date: 2016-11-14 16:22:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] October 28th is now National Cryptography Day 
While there are seasons in southern hemisphere, Jo-berg
is on the Southern equivalent of the latitude of Miami. I was in Buenos
Aires during the winter there this year and it was rather nicer for
purposes of holding a demonstration than a Boston summer. It is closer to
the equator than Washington D.C.
The point of holding a national cryptography day in the US would be to
protest Comey's attempts to ban the use of crypto. So holding it on the day
he abused his office to interfere with an election is a very effective way
to bring home the importance to journalists covering the events. 
Holding it on the day of Pearl harbor etc. would not have the same media
impact, it allows the opponents of using strong crypto off the hook.

@_date: 2016-11-15 20:26:04
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] On the deployment of client-side certs 
This is exactly what I am working to do with the Mathematical Mesh.
I have just uploaded a new site with all new content.
The Mesh is a user centric PKI for managing client side keys. It makes
using computers easier by making them more secure.
The only configuration the user is ever asked to do is to confirm
fingerprints when adding or removing devices. That is it. Everything else
is automatic. Certificate enrollment, renewal, everything. The code
supports X.509, SSH and OpenPGP format keys.
Keys are rigorously separated by function and device. So if you are
logging in to a machine using Mesh authentication, each device you own has
a separate authentication key. That makes it possible to de-authorize the
key if the device is lost or stolen without having to do anything drastic.

@_date: 2016-11-22 10:13:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] combining lots of lousy RNGs ... or not 
No. random XOR squish = squish
If I can interfere with squish, I can undo your random if I know it. And in
real world systems I can often know it.
A better equation is H (random + squish) = random

@_date: 2016-11-22 14:50:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] On the deployment of client-side certs 
The git hub repository links should work. The reference material links to
the documentation first as that is what people are more likely to be
navigating to on a regular basis. The repositories are listed under
I am currently testing out the instructions on how to start your own
portal. Taking a little more time than I hoped.
The cloud part of the Mesh does not store any confidential data. All the
confidential data is encrypted end to end under keys held at the devices.
At present the main function of the cloud service is simply to provide a
dropbox that is always available that devices can connect to. Pure peer to
peer systems are difficult to use because both peers have to be on at the
same time.
Later on, I would like to be able to expand that role so that the portal
becomes a hub through which devices can consume a range of security
services. In the near term the most important of those are secure time and
curated DNS.
For security purposes, access to a reasonably accurate clock is really
important. I am aware of Secure NTP of course. But... Well for my purposes,
I really want multiple statements about time:
1) A statement that applications can be ~100% certain of that states 'this
time has passed' which can be 24, 48 hours in the past.
2) A statement that applications can be reasonably certain of, that a
trusted party asserts that the current time is within 10 seconds of a
stated value.
3) An untrusted statement that the current time is X which is accurate to
100ms or better
That combined with the ability to make statements of the form 'I want to do
X provided you can complete before the time you think is Y' allow me to
address most of my time based security concerns.

@_date: 2016-11-30 10:40:38
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] End to End encrypted Web 
The code isn't complete yet, but I thought I would share my work on
building an end-to-end encrypted Web server and comment blog. I am calling
this Mesh/Web. I am also calling proxy re-encryption recryption as it is
shorter and less confusing when there is a Web proxy involved.
Here is the setup:
* All the files that make up the  and comment forum are hosted on Carol's
content delivery network. Neither Carol nor any of her employees has any
access to the plaintext of the content or comments.
* Carol's CDN is entirely stock. The only thing that is at all different is
that the content type returned is application/remesh
* Alice, is the group administrator. She holds the encryption keypair for
the site. When she adds users to the reading group, she cuts a recryption
key and a decryption key for the new user and creates a recryption access
entry (RAE) for that user.
* The RAE is encrypted under the public key of a recryption server chosen
by Alice. This is an online server that performs one half of the
decryption, allowing the other party to complete it.
The users access the site through one of
* A standard Web browser connecting through a proxy that performs
conversion of the application/remesh content to unencrypted content.
* A standard Web browser with a plug-in
* A standard Web browser that supports the new scheme.
* A separate Web browser that supports the new scheme that is limited to
only access sites of the new type. This might be bound via trusted hardware
in some form.
This scheme allows anyone to read the encrypted material if Alice grants
access. Alice can withdraw that access at any time provided that the
recryption service refuses future requests from the blocked user. It is
obviously not possible to retroactively block content the user has already
read. Future access will be cut off completely after rekeying occurs.
The system presented is end-to-end secure. The main problem being that Web
endpoints are notoriously squishy. In particular we have to cope with the
abomination that is JavaScript.
One very simple solution is to require all active content to be signed by a
key that is endorsed by Alice. This is quite practical as the
application/remesh content type can have signature capability.
Web sites are interactive. How can a site be interactive if the server
can't understand the content? It isn't difficult. The application/remesh
content type could support a 'log mode' in which the file contains a list
of comments. The site knows what node the user has commented on but not
what the node says or what the comment was.
Of course we can add further privacy enhancements but the core concept here
is that what is stored in the cloud need not risk confidentiality.

@_date: 2016-11-30 15:20:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
I don't think there is any interest in the measurements themselves. The
real objective is to control when the devices turn on and off. Either
directly through commands to the device or indirectly by changing tariffs.
Generation and distribution are split and they operate very differently.
The coal generators only make money at peak rate. But renewables make money
whenever demand isn't saturated. Persuading people to run their dishwashers
or charge their plug in hybrid cars when the electricity utility chooses
allows for demand shifting and that allows for wind and solar to grow
further than without.
The rather obvious next phase in electrification is to require taxis to be
plug in electric vehicles in some major city. This will be done to reduce
pollution but also to reduce carbon emissions. To make the scheme viable,
the battery pack has to be rented rather than bought and there has to be a
'fast swap' filling station. So the taxi can stay out on the road without
having to wait for the battery to charge. And to make that possible you
have to have an infrastructure to track the battery, who is currently
renting it, who owns the depreciation, etc.
Expect to see all that crypto that was originally designed to support card
payment schemes like Mondex be recycled for tracking those battery packs.
Once there is a network of battery swap stations round the country,
all-electric vehicles become a lot more attractive. They are cheaper to
make for a start. No engine, no transmission, simplified suspension. The
only moving parts are the motor/rims, steering, brakes.

@_date: 2016-10-04 14:10:03
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Debunking the "SMTP TLS "s a mess" myth. 
The way to improve upon STARTTLS isn't actually to use DANE.
It would be to develop an infrastructure in which the active attacker
doesn't know if their attack is going to be detected or not until after
they have committed.
Something like 'pinning with fangs'.

@_date: 2016-10-27 22:34:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] How to prove Wikileaks' emails aren't altered 
Given that the latest leaks haven't told us anything we didn't know
already, chances that they are forged are low.
What I am disappointed about is that there is nothing about the use of Air
Force One for running cocaine, Hilary's murder of Vince Foster etc.
To be serious, the value to the attacker here is not in stealing the
election. I was at an event at the JFK school tonight on the attacks. There
are many motives that make more sense than rigging the election.
* From Russia's point of view, these attacks represent retaliation for the
Panama papers, or maybe the Ukraine election. Both of which Russia claims
were orchestrated by the US.
* Demonstrating the ability to hack into email systems makes claims that
electronic voting machines are rigged more credible.
* Delegitimizing the process and the outcome of US elections diminishes one
of the core pillars of US soft power.
* Putin rigged his last election and will rig his next one. and he will
cite 'the election rigging' in the US as cover for those acts.
What these leaks do provide is a way for one political party to set the
agenda. Trump would much prefer to have the media discussing anyone's
emails than the 12 women who allege he sexually assaulted them. And the way
the media in the US works a leak of information is considered to be 'news'
even if the information itself is already in the public domain. Why is it
news when information readily available on the FEC web site is taken from a
'leaked' email?
In conclusion, we have to fix the damn email system. We need to make end to
end security the default for all mail. And that means that it has to be as
easy to use the encrypted system as the insecure one.

@_date: 2016-09-01 13:55:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Key meshing (Re: [Crypto-practicum] Retire all 
Great point there. If we designed the cipher with two key inputs, we
could create better chaining modes.

@_date: 2016-09-08 07:13:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Strong DNS Names 
OK so replying to various comments.
On the upper case thing, yes of course, its case insensitive. I was cutting
and pasting...
On the issue of other algorithms, in my UDF scheme, the first byte is a
version identifier that can be used to change the digest algorithm and/or
the construction. The UDF draft reserves one code for SHA-2-512 and another
for SHA-3-512. These have been intentionally chosen so that they give the
first characters M (for Merkel-Damguard) or S (for Spongeworthy).
I am currently writing an update tothe UDF spec that proposes using a
further 7 version IDs for 'work hardened' fingerprints. If the first 25
bits of your digest value are 0, then you could shorten the fingerprint
value by 5 characters and a 15 character fingerprint is sufficiently secure
for many purposes. Unfortunately there are patent encumbrances that would
have to be settled with the rights holder to use it which may not happen in
time to use it for OpenPGP.
And the digest is not just over the content of the digested message, it is
over the digest of a content type identifier (MIME type) and the digest of
the content. That makes it possible to use the same scheme for S/MIME and
OpenPGP and SSH etc. Or any new thing you want to define.
In answer to Donald, yes I am being greedy. But not as greedy as the folk
asking for $250K per TLD.
Since these are fingerprints, the chance of an accidental collision are
very very small, 2^100 for the examples I gave. And those are before
fingerprint improvement to 250 bits. I don't think there is any reasonable
chance that another DNS address would conflict by accident.
That said, the request for some sort of mechanism to distinguish the
identifiers syntactically may be useful. I did actually consider the ta--
prefix. But I want the fingerprints to look as close as possible to the
presentation in other contexts. What we could do is this:
Given that the UDF scheme has internal expansion flexibility built in, the
idea that anything that has two dashes at indexes 5 and 6 is a UDF
fingerprint seems reasonable to me.
Alternatively, if we were going to go that route we could make the first 2
characters the version ID giving us 26*36 = 936 possible code points.
So the UDF fingerprint would be m
On Thu, Sep 8, 2016 at 12:07 AM, Christian Huitema This is of course spot on. To get the maximum value from this scheme,
Alice has to have a fingerprint that is as stable as possible, potentially
something that she can keep her whole life.
And that is the requirement I have designed the Mathematical Mesh
to fulfill. The Mesh uses JSON encoding instead of ASN.1 and drops 90% of
the junk from PKIX/X.509. But it supports the same type of certificate
chaining that CAs use in X.509.
So the idea is that Alice has a life-long public key pair that can in
principle be kept offline and only used to sign administration keys that
are used in her devices to sign application profiles, connect devices to
her profile, etc. The only time the master key is ever needed is if Alice
has 'messed up' and it is necessary to sign a new administration key. 
Of course there may be cases where Alice wants more than one master
fingerprint of change her life long fingerprint. But the system is designed
on the principle of not forcing this to happen unless it is necessary.
Depending on which fingerprint is used, we can achieve different results.
Let us say that Alice and Example Inc. Both have persistent Mesh profiles.
We can create two different addresses:
alice at example.com.me--
alice at example.com.me--<
Example Inc.
Which one I wish to use depends on the context in which I am interacting
with Alice. In some circumstances I may wish to talk to the Alice I met
personally in a previous job. In other circumstances I may wish to contact
her as an employee of Example Inc.
The message I send may end up being sent encrypted under different keys as
a result. If I am contacting Alice to tell her I have found as zero day bug
in a major operating system I may not want Example Inc. to have access to
that data. If on the other hand I am conducting a business transaction with
Example Inc and there is a contract, it is vital that Example. Inc. have
access to that contract and the discussions if Alice falls under a bus.

@_date: 2016-09-08 12:38:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Secure erasure in C. 
For the general case, I think you have to look for this as a platform
supported capability. There is nothing that an application process can do
to guarantee that data will be correctly erased from cached memory or swap
I run my machines without swap for that reason but most people don't.
On Windows platforms, Microsoft has a library that offers some form of
secure erasure but I haven't used it directly. Instead I rely on the crypto
implementations using it.
Documenting support for similar features in OSX and *nix would be a very
useful community service. It might well be necessary to write them first

@_date: 2016-09-09 10:35:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Secure erasure in C. 
I don't think that is sufficient. Virtually every machine has a memory
manager that is continually copying blocks of memory between disk, DRAM and
Unless you know that the platform is correctly zeroizing pages on load and
writing through cache values, there is no guarantee that any application
layer code will reliably erase.
I think the C part can be given a miss. It is a systems issue.

@_date: 2016-09-15 09:53:33
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] massively parallel processing 
My work machine for over a year now has been a 12 Thread Intel CPU with
twin Nvidia GTX980s with 2048 cores each.
I am not sure quite where it lies on the SIMD/MIMD chart, I know there is
more than one instruction pointer involved but not how many. The latest
versions of DirectX have been gradually making this GPU power available to
programs but I don't think they are there yet.
It might well be time for the industry to start re-learning the things Bill
Dally and David May were talking about in the 1980s when I did my DPhil. on
applying formal methods to a large array of transputers.
What most folk miss about Moore's law is that most of the improvement comes
from more transistors. The transistors themselves have not been getting
much faster for reasons of heat dissipation. And we ran out of useful
things to do to use extra gates to optimize a single core a decade ago.

@_date: 2016-09-26 19:24:38
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Yahoo is sued for gross negligence over huge 
In general, a contract cannot exclude claims for negligence. The fact that
a contract purports to do so does not mean that it does. The principle that
negligence claims are inalienable goes back to Roman times. And it has a
major impact on attempts to replace instruments like letters of credit
because it is not possible to construct the equivalent of a letter of
credit using contract law.
Yahoo/Verizon may be able to enforce clauses preventing class action suits
or requiring binding arbitration or they may not. Same goes for application
of California law.
Since I am not a lawyer the only thing close to legal advice I would give
is never put yourself in a situation in which you are relying on such
contract terms to avoid costly damages. The most expensive security experts
will cost you less than the cheapest lawyers, why? Because if you get to
the lawyers stage you will be hiring them along with the lawyers as expert

@_date: 2016-09-28 12:59:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Use Linux for its security 
There is no way that I would ever donate a minute of my time to reviewing
Linux code for security issues. And the reason is that I am not prepared to
work with someone who behaves the way that Linus does.
In particular, consider the following case:
The issue that set Linus off in this case was that someone attempted to
use a set of compiler macros that establish guards against certain types of
buffer overrun issue.
The conflict I get is due to stupid new gcc header file crap, he writes.
But what makes me upset is that the crap is for completely bogus reasons.
No, the reason the programmer made use of the features is that he knows
that the design of IPv6 is a nightmare from the point of view of buffer
overrun errors. Each packet can have multiple options and each option is
described in a length-data delimited structure. Now length-data isn't
necessarily a security issue but nested structures certainly are. Given L1
( Data+ L2 (DataB)), many programmers will allocate a memory buffer using
L1 and entirely forget to check that L2 isn't larger than L1.
This was a good faith attempt by someone trying to solve a real security
issue and they got slapped in the face and ridiculed for their trouble.
That is not the way to get good security and even if it was, that is not an
environment in which I am prepared to work.
Being the slave of an alpha dog does not make you alpha, it makes you a

@_date: 2017-04-04 10:04:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Does anyone here know PAM? 
This is a call for technical assistance with a crypto project. Hopefully it
will be of wider benefit if successful.
The Mathematical Mesh has the goal of making computers easier to use by
making them more secure. Note the order. While there are some times that it
is appropriate for a cryptographic key to require the user to enter a PIN
or the like to use it, that cannot be the default requirement, nor is it
acceptable to just leave private keys sitting on disk unencrypted.
Windows and OSX both provide features that cause private keys and other
credentials to be unlocked automatically using the user's password as a
PIN. I want to achieve the same on Ubuntu. I am happy if the solution can
also be carried across to other Linux and FreeBSD but don't have resources
to cover anything else.
The authentication mechanism is PAM. So far, the only documentation I have
found has been of the barely more comprehensible than the code variety.
So the main questions are:
* Is hooking PAM the way to go or should I try to make use of an encrypted
directory mechanism instead?
* If PAM is the way to go, where might I find a working example for using
the login password to unlock a private keystore?
* Has someone already done this for GPG Agent?
In addition, one of the layered applications, Mesh/Confirm offers two
factor authentication (among other things) so an example showing how to
integrate a network authentication mechanism would be useful.
The architecture I am thinking of would be:
1) User logs in with password.
2) Password is passed to the unlock keys mechanism which uses it to unlock
a master key.
3) Processes running under the master key account can request unlocking of
profile data stored under it.
Of course, it is quite possible that the magic required to bridge the gap
between 2 and 3 means effectively recreating GPGAgent.

@_date: 2017-04-06 07:43:36
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Does anyone here know PAM? 
Well until yesterday, Ubuntu wasn't using Gnome. Now they are abandoning
Unity and moving to Gnome and so the desktop is more or less going to be
unified again.
Thanks all, this should be enough for demo purposes.

@_date: 2017-04-06 08:11:49
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Key escrow scheme 
If we are going to encourage people to use strong encryption for stored
data, the absolute first priority must be to make sure they don't
cryptolocker themselves and lose the pictures of the kids.
Making such a scheme usable is somewhat tricky because we would want to
make the shares used to secure the key to be as small as possible for
convenience which indicates 128 bit work factor for the master key. But I
would really like to make use of 256 bit AES throughout. This got me
thinking about the nature of the work factor requirement with more
precision than just 'make it 256 bit WF everywhere. In particular I want
* A 2^128 WF against brute force attack
* A 2^256 WF against related key attacks
It seems very probable that any conventional machine attack that is more
efficient than brute force is going to be exploiting some form of related
key attack. Even with quantum, the efficiency is coming with the ability to
test on relations between multiple keys simultaneously.
[BTW, has anyone considered the possibility that the Skyrim God of the dead
Shor is a reference to Peter Shor. Skyrim's world is of course entirely
generated by computer and an algorithm that breaks crypto...]
So my scheme is the following:
1) Generate a 128 bit master secret using the best random number generation
2) Split the master secret into m of n shares using XOR is m=n=2 and Shamir
secret sharing otherwise.
3) Stretch the key using HKDF (RFC 5869). The parameters are
* Master salt (applies to the set of keys) is constructed from the IANA
protocol identifier plus a protocol specific extension.
* Key salt, is the key function 'Encrypt', 'Authenticate'.
4) Encrypt the private key set using AES-256. Right now I am using CBC and
HMAC-SHA-2-512 but I will move to GCM when I can.
5) The identifier for the key is a UDF fingerprint formed using a one byte
version prefix, SHA-2-512, base 32 encoding of the master secret and
truncating to 25 significant characters.
6) Publish the escrow package to the Mesh.
What I hope to achieve with this scheme is a situation where brute force
attacks and anything more powerful are both infeasible.

@_date: 2017-04-06 12:37:33
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Should the IV of an encryption operation be input to 
Further to my explorations of HKDF (RFC 3394) I am thinking as follows:
Most cryptographic modes use the same key to encrypt a message. CBC, GCM ,
etc all perform operations on the input data, the key is constant.
When using a public key for exchange, we choose a session key which is
random every time. This each message is guaranteed to be encrypted under a
different key.
If I use KDF with a fixed salt (the norm for most protocols) I get
inter-protocol separation but not separation per message. The IV provides
some protection but I am still handing the attacker a possible advantage.
So what if I was to use the IV of the encrypted data as a part of the salt
in the Key derivation function? Is this a good idea or a bad one?

@_date: 2017-04-09 10:06:36
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Key escrow scheme 
I am using Shamir Secret Sharing. But that only gets you from a set of key
shares to a master secret. You still have to get from the master secret to
the encryption key.
If you use 256 bits for the master key you end up with 256 bit shares.

@_date: 2017-04-10 09:57:56
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Key escrow scheme 
No, that is not the problem I am trying to solve.
Lets say we are doing RSA 4096. My scheme still allows me to escrow the key
using a set of 128 bit shares as the only thing the user keeps track of.. I
encrypt the RSA private key in AES 256 and store it on a cloud service as
the first step.
The steps for recovery are thus as follows:
1) Reconstruct the 128 bit master secret from the shares.
2) Take the UDF fingerprint of the master secret, this is the identifier
used to store the recovery blob in the cloud.
3) Use HKDF (RFC 5869) to derive the 256 bit key unwrapping key
4) Use AES Key wrap (RFC 3394) to recover the key used to encrypt the
recovery blob.
The last step is only necessary because my content encryption scheme is
designed to minimize the number of code paths. Since key wrap is needed
sometimes, I require it always so as to simplify implementation.
What I am looking to do is to achieve a brute force work factor of 2^128
but to present the higher 2^256 Work Factor for anything that is faster
than brute force. It seems like to me that anything faster than brute force
is going to depend on some relationship between keys but I can't prove that

@_date: 2017-04-12 20:49:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Key escrow scheme 
From a practical point of view, the recovery information required is going
to be vastly more than the user can be expected to store. This is just the
apex of the user's personal PKI, the keys required for recovery. They are
keys that are not used for any other purpose.
Back in the 1990s, the idea that Internet access was ubiquitous was barely
acceptable. Today it is fine. The idea that we can find enough people
willing to save a few TB of personal PKI data for the planet is no longer
at all unreasonable. I am pretty sure a dozen people on this list will make
their own copies.
Beyond that, the chief concern motivating escrow of keys is to be able to
recover stored data. So it isn't hard to store a copy of the master escrow
profile etc. with the data itself. Most cases these days, the data is being
stored in the cloud anyway. 
What I a certainly not going to do is ask the user to re-escrow their keys
every time they make a change to their environment like adding a device. 

@_date: 2017-04-28 14:12:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Escrowing keys 
I am currently wrapping up the Mesh code. At this point I am halfway
through the set of test cases for the line mode client. And almost all the
functionality being tested is already tested at the library level.
One area I am still working to get right is the offline escrow mechanism.
The basic idea of the Mesh is that we want to enable people to use a single
fingerprint to identify their personal root of trust and this should be
able to last their entire life. I have eliminated the idea of
pre-determined certificate expiry completely.
So the root of trust comes down to:
1) The master signature key
2) A list of master encryption escrow keys
Yes, there are certainly cases where you do not want to escrow an
encryption key. Transport encryption keys should never be escrowed but
encryption keys for static data usually do require escrow. In 99% of cases,
the loss of the data would be a far more serious risk than disclosure.
One corollary of this is that all message encryption schemes require
separate transport and message level security.
Trusted hardware is really interesting and useful. But I don't think it
actually helps in this application. The main advantage of using HSMs in CA
Key Ceremony is that they allow audit. The use of the key requires a
physical device and that can be monitored. Even better of course would be
HSMs that track each private key operation.
But no hardware can really be trusted beyond a ten year service life. CAs
provide continuity using a very expensive to manage set of processes. These
really don't work for the individual. So I prefer a process in which the
only data that needs to be trusted can be written down on a sheet of paper
by hand. Hence Shamir secret sharing.
So my current escrow scheme looks like this:
meshman /personal test at prismproof.org
Created new personal profile MD2DE-5Y2KJ-DIIFI-GNKOA-NG6YX-EKRDZ
Profile registered to test at prismproof.org
meshman  /escrow /quorum 2 /shares 3
Created offline escrow entry Shares=3, quorum=2
Share ECTQR-Z3C2F-GJSPM-PNX4K-TY7IL-E5QC
Share EERHF-HOJTU-YZQV2-OCXM3-WYLAL-QAQ
Share EKCNW-UZQNI-LJO4I-NXW44-3X6XL-3DQA
The escrow record itself is stored in the cloud encrypted using AES-256. To
decrypt the escrow record, you need the escrow record data plus two of the
three shares. The master escrow key is 128 bit, a KDF is used to extract
the AES256 key. The secret sharing scheme is based on Shamir.
So this means that the brute force difficulty of breaking the key is 128
bits but conventional cryptanalysis is almost certain to present a 256 bit
The index of the escrow record is the fingerprint (SHA-512-T) of the
encryption key. This provides a simple mechanism to validate the recovery
OK so that is the default way to store keys. If we assume the Mesh business
model works then it seems pretty certain someone will store the offline
escrow blobs in perpetuity even if only out of curiosity. The blobs are 21K
in JSON encoding and would be rather smaller in JSON-B encoding. The escrow
records for the entire planet could sit comfortably on a $5K RAID array.
But as John Gilmore points out, that isn't going to be enough for everyone.
So in addition, I have an option to write out an escrow entry to a file
meshman /escrow /quorum 2 /shares 3 /file escrow.json
Written to file escrow.json
Share EBOOQ-VFCBQ-BZNXV-NX76I-MDII3-X2QA
Share EGAS3-LKK2K-SFILU-S3J5N-HTSYO-GOQC
Share EK7XE-BPTS5-DBG7T-W6X4B-7EFJA-VCQ
OK so far, not controversial. Now I am also thinking about providing an
option to simply write out the private keys without any encryption. This
will greatly simplify my development/debugging process but will introduce a
possibility that end users screw up bad.

@_date: 2017-04-29 15:57:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Escrowing keys 
Same as the Web. Mass market. Looking to be equally ubiquitous.
Even if people only need to rejig their personal mesh once a decade it is
going to be serious upheaval and I don't see a security return.
The big problem I have with hardware is that it is likely to be lost.
Particularly when it isn't going to be used on a regular basis. The idea of
the escrow scheme is to assure people that they won't lose the pictures of
the kids when they were 5 if the house burns down.
In a corporate market, yeah, HSMs are definitely the way to go. And we can
have great fun developing infrastructures that help enterprises support all
of that. But in the consumer space, they are likely to be more trouble than
they are worth for apex trust.
What I can see is a dedicated HSM targeted at consumers for managing the
equivalent of the intermediate cert key. Take an android tablet, install a
single purpose stripped down OS with just the key management tools. Use
that as the terminal for managing the whole smart house network. I totally
see the value there. I also see value in some sort of Raspberry Pi class
device that is an always on, always connected home hub for the mesh
systems. But any time you install hardware, you have to have a plan for
what to do if it breaks.
At some point, the turtle has to be standing on something that isn't a

@_date: 2017-04-30 10:37:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Escrowing keys 
The fact that a device might last longer than ten years is irrelevant.
My two daily driver cars are a couple of Jaguar convertibles built in 1999.
They are surprisingly reliable, they give less trouble than the GTi we
traded in after five years because it was always breaking down.
The objective here is to provide a mechanism that is capable of giving
people as close to 100% certainty that they will be able to recover their
private keys in the case of a personal catastrophe. However great your CRT
telly is, I am pretty sure you won't be running into your burning home to
rescue it.
And no, my target audience is not limited to only being people who are
satisfied with or too mean to replace technology that has long been made
obsolete. The Mesh is for people who saw the genius in the first generation
iPhone, it is for people who are unsatisfied with second best.

@_date: 2017-08-01 19:39:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Bitcoin Blockchain Has Been Forked (New: 
So what happens if someone spends the coins on both forks???

@_date: 2017-08-24 20:25:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] PGP-Signed Email 
I disagree with the analysis. Signed email is no more complex if every
mail is signed and will be rejected otherwise. At that point, the
complexity is reduced because spam is a very different issue.
A more precise analysis would be signed SMTP mail is more complex.
The 'legal' analysis is naive and wrong. Adding a digital signature does
not change your liability because an electronic signature is equally
binding. The risk of a lost private key is irrelevant because a signature
only creates a rebuttable presumption of validity.
Many schemes bind a disclaimer into the signature, this is why SAML
assertions have an audience condition.
In short, these are issues that a protocol designer has to bear in mind
when developing a messaging application. They are not reasons it cannot

@_date: 2017-08-26 10:24:26
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] PGP-Signed Email 
The comments were about OpenPGP which is problematic in the extreme when
it comes to the trust model. PGP was pretty good PRIVACY and crap
authentication. And authentication is vastly more important. But that is OK
in a 1990s tech.
If a message is signed using S/MIME, we have a fairly good trust chain
that can tell us that a message came from a sender working for Fidelity
Investments or Bank of America. It is not perfect but it is good.
And here is the problem I have with amateur usability analysis, and much
professional for that matter: Usability is nowhere near as difficult as
some people make it out to be, just think.
Take the mental midget that designed the Siri/Apple Maps interface.
"Directions to Home"
Would you like directions to home?
Are you really sure
Here are directions to home
Directions shown
I might be off by one but it takes at least four interactions to start the
directions and three to stop them.
If that is how bad what is meant to be a user experience professionally
engineered by one of the top usability companies can be, we don't need to
be scared of it.
The real reason that Apple used to be good was that engineers used to know
that if they produced crap, Steve would throw it at them.
We do not need to be at all worried about giving users information that
has a 1% chance of being wrong. Today those users are 100% sure of the
authenticity of information that anyone can fake.
If we can't achieve the security requirements within the constraints of
SMTP then we need to change SMTP. It is not impossible. tens of millions
have moved to proprietary messaging systems that are secure within a walled
garden. Making an open system that provides the same security enhancements
is not difficult.
Any system that supports public key encryption of async messages has to
solve the problem of distributing public keys. Now if I have Alice's
fingerprint in my contacts directory, we can easily see how we can convert
that to a record with the current public key. And if we have that, we can
also have a note that says Alice also supports JMTP mail which is a
protocol I just made up. 
All we need then is a set of mail clients that will transparently switch
from legacy SMTP transport to JMTP when needed.

@_date: 2017-08-30 10:49:19
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Any PAM experts out there? 
So I now have the Mesh at a very advanced stage. If it wasn't for a patent
expiry issue I would be pushing the Mesh/Recrypt code this week. I now have
practical three key cryptography running. What this means is that I can add
crypto to an application without the user being barely aware of a change
(other than for the better).
One of my objectives is to tie the code to the native platform features for
key storage. So if the user is using password to log in on Windows or OSX,
we make use of the platform keystore because that is unlocked by the O/S
using the user's password. Not perfect security but pretty good (I will get
to good-to-great later).
Unfortunately, I don't know how to do this on the Linux platforms. One
option would be to use GPGAgent but that means we end up with
crypto-platforms calling crypto-platforms. What I would prefer is to be
able to simulate the Windows/OSX keystores. The simplest way to do that
would be to create an encrypted directory in the user's home directory and
automatically decrypt it using the password.
Has anyone got a setup already written that I could crib (with attribution
Longer term, I want to be able to use my watch or phone to unlock the
machine. This will enable me to make use of the split key crypto that I do
a lot of to create a strong binding.
One killer app that I came up with and will implement next week is a random
password generator and a generic password storage profile.
Lets say I want to extract a private key as a p12 encrypted under a
password. The shell commands would be something like:
$password = ( meshtool /random )
meshtool mail /extract alice at example.com /out=mykey.pfx /pass=$password
thunderbird /addsmime mykey.pfx /password=$password
rm mykey.pfx
These are generate a new random password (25 chars), assign it to a shell
variable, create a p12 encrypted under the password, install it in an
application, delete the shell variable, delete the p12
Ok that sorts out lots of cases involving installing keys in applications.
But what about the more common case where I have an FTP site I want to sync
with my machine and have to use a password to log in? I don't want to store
the password on the machine, I certainly don't want it in the script. So
lets store it in a mesh profile which is end-to-end encrypted. Then I can
write something like
$password = (meshtool password get ftp.example.com)
sftp sync /pass=$password
Of course getting rid of passwords altogether is much better. But the Mesh
does that as well if the service is capable of using public key. Working
with the legacy infrastructure and delivering value is essential to build
critical mass.

@_date: 2017-08-31 18:11:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] TEXTCOMBINE-REV, 
pseudo-randomness in practice (replacing an earlier retracted software)
On Thu, Aug 31, 2017 at 5:26 PM, mok-kong shen What is the application?
Cryptography requires numbers that are unguessable. Numbers that are
random are not necessarily unguessable

@_date: 2017-12-04 20:00:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Transparent remote file access 
My objection to LDAP is the X.500 data model which as was mentioned is
I have sat through endless meetings in which people have bike-shedded their
DIT arc ad nauseam. Often taking two, three years to agree and then start
from scratch when a re-org hit.
Vast amounts of complexity, negligible functionality.

@_date: 2017-12-16 14:25:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
Since a vast proportion of the market cap of BitCoin has been stolen at
some point, clearly it isn't a bar to whatever it is Bitcoin it adopted
for. It does disqualify it as a payment transfer system.
Here is the central problem with BitCoin. Proponents wave away all
objections claiming that cryptocurrencies are in their infancy and these
will be solved. What they refuse to acknowledge is that every solution to
these problems that has shown to work in practice requires the introduction
of the trusted third parties and intermediaries and regulation that they
claim to have made obsolete.
Its like taking the alternator off your car and showing it will still
start, it just won't run for very long without tons of batteries and that
therefore the alternator was never necessary because someone will find a
solution that doesn't need such big batteries. Of course such a solution
already existed and was known - the alternator.
Not by enthusiasts. 
None that I can see.

@_date: 2017-12-20 23:16:25
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Delaware allows blockchain stock registry 
Easy to solve with foresight. Impossible to otherwise.
The problem will be solved in the general case as it is obviously not going
to work for the stock exchanges otherwise.
A more interesting question is why a blockchain backed by busywork mining
that is essentially worthless should be worth more than one backed by an
actual company, no matter how lame.
Comparison to things we know the value of is usually the best approach to
valuing things we don't understand the value of.
Though the value of Tesla which is apparently worth more than the rest of
the automobile industry combined...

@_date: 2017-12-21 13:09:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Web voting service 
I am currently deploying the Mesh services for an external test and looking
for small, self-contained applications that can be supported thereon.
The basic premise of the Mesh is that it becomes really easy to do a lot of
cool cryptography iff we get to a point where use of private keys for
security purposes is as fluent as passwords.
One facility I will eventually need is the ability to checkpoint assertions
about public keys in a linked hash log (aka Blockchain). Since I am not of
the proof of work faith, I am looking to DAG type approaches to assure
integrity of the hash log (aka HashGraph). So I am looking for a smallish
project that could showcase the effort and create a nucleus of services
that could later be built into a HashGraph infrastructure.
One facility I think we need is the ability to record non-anonymous votes.
This happens a lot in industry consortia where each member has a vote and
the way that they vote is public. [Yes anonymous is more interesting as a
problem but that can be built on the public voting scheme].
So the basic idea is that there is a Web Service that accepts two types of
data and records them in a hash log:
1) Votes
2) Witness values.
Assume I am not stupid and the votes are authenticated appropriately,
timestamped, etc. Votes can be encrypted until the close of the ballot is
declared, etc.
The Witness values are any unpredictable value published by any other
source that can be verified retrospectively. For example:
* A signed time source
* Any block chain output
Each witness value contains sufficient information to allow a third party
to verify it. Typically this would be a URI and possibly a date-time or
index value.
The hash log is signed every n minutes. When a vote (or any other value) is
enrolled in the hash log, the service provides a signed receipt. This
enables the voter to call fraud should their vote not be recorded. [For
additional bonus points we can add in Micali Fair Contracts which went out
of patent recently]
Now consider a situation in which there are multiple vote servers accepting
votes on the same ballot. If one goes down, another server can accept it.
All the vote counter then needs to do is check all the approved logs. This
prevents a form of fraud where the vote server goes down (or is DDoSed)
when the ballot is in one side's favor.
One building block for such a system would be a disclosure service which
publishes a list of public keys and then releases the corresponding private
key at a specified time. So I would probably publish key pairs for each
hour for the next 30 days, for each day for the next year and each week for
the next decade on a rolling basis. Easy enough to do from a single master
Using the same techniques as proxy re-encryption, people can choose
multiple services and build n of m type quorum schemes using Shamir secret
sharing on top. So if encrypted ballots are used and one of the disclosure
services dies, the system remains robust.

@_date: 2017-02-03 14:10:04
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IRS W-2 'Verification Code' == Hash ?? 
64 bits is more than enough to cut down the incidence of fraud to 1/2^64
th of its current rate. the attackers only get one chance per target.
Given that I had my tax 'refund' stolen last year, I can see the point. Of
course I always make sure I have no refund precisely because they are so

@_date: 2017-02-18 15:19:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Security proofs prove non-failproof 
I note that a lot of folk in the crypto world did Formal Methods at
university and don't seem to be all that keen on formal security proofs,
myself included.
One problem is the difficulty of defining what security is, another is that
the proofs of security we have are based on a set of security assumptions
that are themselves not provable. Which is problematic to say the least.
Formal verification of code such as a compiler or a kernel like Perry
suggests is a very good thing. We can define the problem and the security
properties (no buffer overrun, etc.). Security properties of crypto
protocols on the other hand hit the problem that what we can prove to be
secure often requires us to make simplifications that make the protocol
less robust and thus less secure in practice.

@_date: 2017-02-19 16:25:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Fwd: Securing the full TLS handshake including SNI 
I have been looking at various ways to protect the TLS handshake including
the domain name of the site being accessed. To do this, it is necessary to
put 'some form' of key into the DNS record for the host.
While many people have suggested schemes in the past, these have all been
based on the legacy RSA exchanges and in ways I find unconvincing. Not
least because TLS is a protocol with 25 years history and has been patched
and repatched many times.
I would prefer to use a scheme that has the following properties
1) Only use DH/ECDH key exchange.
2) Enables use of hardware host keys
3) Provides perfect forward secrecy by default.
4) Has integrated support for client auth.
The type of approach I like best is the one used in the noise protocol
which underpins Signal, etc. The wonderful thing about DH is that it is
composable to as many keys as you need. So the basic idea is to have each
of the parties identified by a key:
* KH - The Host is identified by a host key that is distributed through a
DNS TXT record.
* KS - The Service is identified by a WebPKI certificate (EV / OV or DV)
* KC - The Client SHOULD be identified by a client key.
* EC - An ephemeral mix-in is supplied by the client.
* ES - An ephemeral mix-in is supplied by the service.
Let A(k1, k2...) be a function that creates an agreed key from k1, k2, etc.
Let KDF (x,p) be a key derivation function for purpose p.
A brief sketch of the protocol would be:
Client obtains KH from the DNS, creates A(KH, EC)
Client encrypts initial contact message under KDF (A (KH, EC),p1) this
   * Client cert (if used) (contains KC)
   * DNS name of Service to be contacted
   * sundry flags
Service reply is encrypted under KDF (A (KH, EC), p2). This contains
   * Service certificate + chain (contains KS)
   * ES
   * Opaque identifier (for fast restart)
   * sundry flags
The rest of the conversation is encrypted under KDF (A(KH, EC) + A (KS, KC,
ES),p) where p = p1 or p2 depending on the direction.
The reason for not using a quintuple exchange for the service exchange is
that this approach allows different curves to be used for the host and
service level agreement. It is very likely that 25519 is sufficient for the
host level but there are definitely cases where 448 is needed for the
service level.
I have not looked into how to squeeze this into TLS data frames but that is
just bit shuffling.
While I can't see a case for moving away from X.509 for the service cert,
it might well be that we would want to use a different cert for the client
part. In particular, I can see the use of some form of blinding or
annonymization being layered in.
Note that with EC, multi-key exchanges don't actually take more time than
two key. The private keys add and the public keys multiply. So there is
only one modular exponentiation or other costly operation.
One odd feature of this exchange is that practically every part of it is
already specified by IETF docs. I built it from code I already had to
implement KDFs etc.
One possibility that I like a lot is that we can have client authentication
at the transport level for free. Which is useful for SMTPS / IMAPS / etc.
That does not do away with the need for application level authentication of
course, but we have the option of a transport binding.
I would like to see an option that allows a client to prove that they are
the same client that contacted earlier and that this be unlinkable across
DNS domains. Easy enough in DH//ECDH. If x is a device bound key, we can
use KDF (x + H(Domain), p3).

@_date: 2017-02-20 11:59:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Security proofs prove non-failproof 
You are conflating two things
1) Formal proofs of code correctness
2) Formal proofs of algorithm or protocol security
I very strongly believe the first is possible. My doctoral thesis is on a
formal proof of correctness for a significantly large system.
I remain skeptical on the second and suspect that the current state of the
art is doing more harm than good.

@_date: 2017-02-21 13:52:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Security proofs prove non-failproof 
I certainly agree that formal analysis can reveal certain types of flaw.
My skepticism comes from seeing how restricting designs to what can be
analyzed with formal methods has led to fragile protocols.
To give an example. TLS ephemeral key agreement is botched. The results
from the master key agreement are not fed into the ephemeral. So if the
ephemeral is weak, the key agreement is weak even if the master agreement
was strong. One of the reasons given for not chaining the master key
agreement into the ephemeral was concern for preserving some sort of half
baked model.

@_date: 2017-02-23 18:41:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Security proofs prove non-failproof 
Prof Hoare was my college tutor.
Most of it can be automated, the main issue is providing invariants for
loops and arriving at the specification in the first place. Getting a
specification correct is as hard as getting a program correct.
The biggest value I think there is to formal methods is actually in forcing
people to design systems that are simple enough to be tractable. I have
removed about 10,000 lines of code from the Mesh code over the past year by
refining the design.
The tools I use do allow me to code at a very high level, which is very
close to a specification language. My goal is to take the language in which
I specify the problem as close as I can to the structure of the problem

@_date: 2017-02-23 20:29:34
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] SHA1 collisions make Git vulnerable to attakcs 
Which means there is reason for concern and urgent efforts to fix Git.
There is no reason to panic. But we do need to act.

@_date: 2017-02-28 20:07:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Google announces practical SHA-1 collision attack 
Looking at the resources required, they sound excessive until you think,
'how would I test a new data center before bringing it on line for
production work'.
Another possibility is that they make running the code the default null
task. Google probably has more compute power going to waste than most
national labs have compute power. I did that sort of thing myself when
testing out some of the systems at ZEUS, despite the commissioning date
(1990) the data system could process 6Tb/sec of data. You could do some
interesting stuff on that.
On the Quantum Computer issue, it occurred to me that there is likely to be
a rather slow takeup. Moore also said that the fab to build each generation
of machines would cost twice the cost of the previous generation. Finding
tens of millions of dollars for this sort of research is easy. Finding
billions a year to sustain an emerging industry is a different matter.
I rather suspect that Quantum Computers are likely to be Heath Robinson
affairs for quite a while to come.
Oh and unless Peter has found a new form of Quantum Cryptanalysis, SHA-1
not a good showcase.

@_date: 2017-01-03 01:15:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] where shall we put the random-seed? 
I don't see an issue.
First, mark a random source as having been used before you use the data out
of it.
Second, always put the source through a digest function and mix in a
guaranteed monotonically increasing value, e.g. current time.
At a practical level, SHA-2-512 (seed + counter + datetime) is pretty
robust because what matters is not how much ergodicity is in the pool, it
is how much unguessability is there.
Repeating use of a seed value kills unguessabilty but if the seed was
unguessable, different calls to the digest function need only have their
input vary by one bit to preserve unguessability.
There is often a tension between using formal methods and robustness. What
you can prove to be secure and what is robustly secure in use are often
very different.

@_date: 2017-01-09 11:02:53
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Looking for MIT License or better implementation of 
I am looking for an implementation of Curve25519X and Curve448X as
specified in RFC7748 that meets the following criteria. It would be even
better if support for draft-irtf-cfrg-eddsa-08 was present or planned.
The criteria it needs to meet are
* MIT License or less restrictive (NOT GPL v anything)
* Implemented in C or C# (NOT Python, Go, Erlang, Brainfuck or anything
I can upgrade from C++ to C if necessary.

@_date: 2017-01-13 09:03:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain to Secure Nuclear Weapons? 
Everything is blockchain now, even things that aren't. The insanity of
blockchain is proof of wasting electricity*. Take that away and you have an
object model in which the current value of any object is that last value
registered in the blockchain which is slightly more than Harber and
Stornetta but not much.
[*] Rumor has it that Bitcoin was actually designed by Charles Koch as
part of his James Bond villain scheme to destroy the earth with global

@_date: 2017-01-18 15:54:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cryptocurrency Exchange without a trusted third 
As a meta-point, isn't it rather odd that BitCoin makes such a big thing
about the size of the float being fixed when what has been created is an
additional source of float to the currencies already in circulation?
The claim BitCoin is deflationary only holds if you ascribe to the peculiar
notion that it will replace all other currencies. This for a system whose
transaction bandwidth is insufficient to support sales at CostCo, just one
If we accept that the USD is not going to disappear, the net effect of
BitCoin is to pump a modest quantity of additional currency into somewhat
limited circulation.
And that is before we get to the fact that deflation is actually a worse
economic problem than inflation. Go ask the Japanese how their economy has
been doing. Or the various victims of the Euro.
the BitCoin deflationary multiplier does however encourage the notion that
the value of Bitcoin will appreciate over time.

@_date: 2017-07-01 10:50:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Possible SHA2 vulnerability 
Thats not something I think of as an IV because it is fixed.
I was trying to work out how someone could have mistakenly thought that
there was an issue or for that matter what the issue was.
Did I tell you about the time I broke 'MD5'? I was reading Bruce's book,
trying to work out how the function worked and trying to solve it
algorithmically and to my great surprise, succeeding.
Turns out, that the version in the first edition is wrong, it misses out a
critical addition term that is the thing that makes everything go
non-linear. Fortunately, I checked the RFC before going down the hall to
ask Rivest. When I told him about it, his response was 'well those addition
terms are very important'.

@_date: 2017-07-03 11:13:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Satoshi's Trump Card 
There are many problems:
1) Does Satoshi have the coins?
It is assumed that he has the wallets with the coins in. But I suggest that
being a hairshirted ideologue, he thought he should not profit personally
and mined the genesis blocks into the bit bucket.
I am pretty certain this happened because otherwise Satoshi would have
moved the genesis block around precisely to avoid the risk of extortion etc.
2) Is Satoshi alive?
We have not had any evidence of Satoshi being involved in Bitcoin in any
way for years now. The most likely reason is medical.
It seems almost certain that Satoshi was a pseudonym being used by one of
the well known BitCoin developers in the early days when the BlockChain was
still covered by the patents. Maintaining his anonymity would have become
necessary as the value of the genesis block soared and kidnapping became a
real risk.
Given the circumstances, I think it most likely Hal Finney was Satoshi and
he mined the genesis block into the bit bucket. Then when he needed the
money, he didn't have it.
A tragedy.

@_date: 2017-07-10 11:35:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Trump wants to collaborate with the Russians to 
There is actually a lot of interest in establishing norms for government
interventions in cyberspace. But this one crosses a whole series of what
were red lines in prior discussions.
Russia and China have consistently demanded that the US take action to
prevent the use of the Internet for 'terrorism'. By which they mean any and
all speech critical of Putin or the Chinese communist party from any
quarter. Russia and China already police their own citizens to suppress any
speech critical of the other.
The suggestion is disingenuous on many levels, not least the fact that
actual vote tampering is one of the few things that Russia has not been
accused of. There is evidence of a Russian intrusion into some computers
that had a certain connection to the ballot. But that came very late in the
game and might well have been planted with the intention of creating a
false lead.
When the UK peer Lord McAlpine faced very well documented accusations of
funding the libel cases of over 30 pedophiles senior in the Conservative
party and thus the implication that he was likely one himself, McAlpine was
conveniently accused of being a pedophile by a former victim who retracted
the claim almost immediately. McAlpine had previously written a book
advising readers to use just such a strategy.
So I really don't see that there is any good faith intention to make
elections more secure. Rather it is the intention to disrupt the narrative
of the now well established evidence of FSB/GRU hacking of political
parties and operatives and spur allegations of Russian tampering with
actual votes.
As for the proposal, it is stupid. Neither the US nor the Russian
government has any special expertise in the field of election technology
that could be shared with any other party that is not already being shared.
There is some relevant expertise (e.g. NIST etc) but those teams are much
smaller than those working in industry. The large teams that really do have
the expertise needed are at NSA and in the very deepest parts thereof. And
while they can pass messages to the outside world, on occasion, my past
experience of such is that they are not very useful.
Now is not the time for any cyber security treaties. The first step in
forming a treaty is to establish a common understanding of terms and the
range of problems. From there you can go on to establish norms which may be
new norms or new applications of old ones.
Most treaties are actually codification of what is already considered to be
a norm. The Geneva conventions did not introduce novel ideas, they just
eliminated the possibility of exceptions.

@_date: 2017-06-29 13:56:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Possible SHA2 vulnerability 
I am confused. Since when did SHA-256 have an initialization vector?
If IV input to the MD construction and the output are the same for any
block input, construction of an arbitrary number of collisions is trivial
since H (X) = H (X+X) = H (X+X ... X)
What is being shown here?

@_date: 2017-03-01 12:53:53
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Google announces practical SHA-1 collision attack 
We do not know the full attack yet. But I suggest that reading between the
lines in the release we will find that it involves finding a weak point
where the planets align and the SHA-1 internal state collapses to a small
work factor and then looking for an exploit for that weak point.
It is very likely that finding a second exploit for the same weak point
requires only the 110 GPU hours...
Another point to ponder is that while CPUs are not getting much faster year
on year, GPUs still follow Moore's law. I remember when cracking DES went
from Deep Crack and custom VLSI to a $30K machine to a standard GPU...

@_date: 2017-03-07 10:37:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Can someone explain small order subgroups? 
I was trying to work out quite why my code was behaving oddly and then I
discovered that I was calculating the order of the group wrongly.
What I am trying to do/have done is to make proxy re-encryption (and some
other related tricks) work in Elliptic Curve. Right now I am working on the
Edwards curve Ed25519 but the same scheme could work for Montgomery with
some additional math to recover the X point and permit addition to be
So the basic idea is that
Normal DH agreement: x.y.B = y.x.B
Split DH agreement: x.y.B = a.y.B + b.y.B where x = a + b
In the DH case, the same scheme works for x = a + b mod (p-1) since e^(p-1)
= 1 mod p.
In elliptic curve:
q.X = Neutral
Where q is the small order subgroup.
I am trying to get my head around what this means geometrically.

@_date: 2017-03-07 17:11:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] In ECDSA, 
garbage
On Mon, Mar 6, 2017 at 8:22 AM, Georgi Guninski It is the property that gives rise to the malleability property (I think)
Yes you can create a valid ECDH signature for garbage. But the garbage
does not match the hash of any data you know the value of.
And yes, it is known because this is the mechanism that it is claimed was
used to empty Mt Gox.
ECDSA includes the hash function. It is not an optional part.

@_date: 2017-03-21 09:44:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Crypto best practices 
OCB is patented but:
Filing date Jul 30, 2001
Priority date Oct 12, 2000
Fee status Lapsed
I will add it to my list that I am working on:
We could contact Phil and put him on notice. Though I rather doubt he
could explain not paying the patent fee for 5 years.
As always, I am not a lawyer, get your own legal advice, etc.
The fee was paid on 8,321,675. So the situation is a little complex. But
all these should expire in Oct 2020.

@_date: 2017-03-28 13:40:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] UK targets WhatsApp encryption after London 
More like made a bunch of fairly ignorant comments about what is purported
to be a 'problem'.
The point to be concerned is when politicians start trying to make
What I see as the big problem with WhatsApp is that it is a walled garden
with the operator providing the application. So there is a single point of
failure. OpenPGP and S/MIME are not vulnerable in the same way as there are
multiple clients.
Of course it is also a fair point to say that S/MIME and OpenPGP  are not
vulnerable because nobody uses them because they are nearly unusable and
unusable and incomprehensible.
Both are fixable though.

@_date: 2017-03-29 09:51:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "Perpetual Encryption" 
I have a snakeoil crypto scoring scheme.
Any mention of 'keyless' 10 points
Any claim of 'strength' greater than 2^256, 10 points
Any claim of 'mathematically unbreakable', 20 points
Any mention of One Time Pads, 50 points
Pretty Web site entirely devoid of actual technical content, 20 points.
Looks to me like a home grown stream cipher which may or may not be
trivially insecure and will almost certainly fail on analysis.

@_date: 2017-03-29 16:03:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "Perpetual Encryption" 
There are two tests that are critical. Attackers being unable to break the
system and users being able to use it in practice.
Any system that claims to have a one time pad is either utterly
impractical or not a one time pad. Thus the claim is a near infallible
indicator of bogosity.
The one class of system involving an OTP that could arguably be harder to
break (but not impossible) is to mix a random stream of bits into the
stream in a fashion that effectively increases the key length.
So lets say your initial key is k.
We encrypt the first AES block as follows.
Generate a random value the same size as the block. R
Let RH, DH be the high bytes of the random and data blocks respectively and
RL, DL be the low.
Output = AES (DH+RH, k) + AES (DL+RL, k)
k' = AES (R, k)
What this achieves is it doubles the size of the cipherstream and stalls
the AES encryption every two blocks.
What it might achieve is some degree of additional work factor but I doubt
A more difficult to break arrangement might be
Output = AES (R, k) + AES (D^R, k')
k' = AES (R, k)
It is of course total bollocks though. It is not making the cipher
unbreakable and the work factor is actually unchanged.
There are infinitely many similar schemes. And they all fall short because
the width of the key isn't increased.

@_date: 2017-05-02 14:50:25
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [FORGED] Re:  Escrowing keys 
The electrics are all made in Germany,
 So
My MGB does have Lucas electrics, being essentially relay based the
reliability is poor but the repairability is high.
The reason I don't want to trust my keys to a black box is that I have no
way to repair it. However low the probability of a fault is, there is no
 way to recover from it.
I used to be a control engineer.
It isn't really the case that control systems were expected to last a
hundred years. Most would be ripped out and replaced on a regular basis.
But they are designed in a very different way to most network software.
They don't use encryption because they want every signal to be observable.
But they are very interested in adding authentication.
In their world it isn't
Confidentiality Integrity Availability
It is:
Confidentiality << Integrity < Availability

@_date: 2017-05-05 23:54:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Escrowing keys 
It would not work because the courts will just say that the law nullifies
the contract terms and if you are sued in another country, that is your
funeral. 
People have ended up going to jail because they were in a situation where
they would break US or Swiss law. The courts have no sympathy. You cannot
use the law to evade the law.
On the hardware issue, I still don't understand if people are even
disputing my proposal. I suggest the following as a logical extension of
Jon Postel's proposal.
Design your hardware to last 20 years.
Design your system assuming some will die after 20 minutes, 20 days, 20
I design protocols. If people think they can engineer perfect electronic
hardware, more power to them. I will still design assuming a non trivial
failure rate. Applying Murphy's law, we should design the system assuming
any single electronic device might fail.

@_date: 2017-05-05 23:55:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] French election attacked. 
Might we hope that this is a huge deal for cryptography? France has
traditionally been the Western country with the most restrictive laws on
the use of cryptography.
Perhaps now that the political class will realize that it is in the
crosshairs of an attack by an enemy power (and yes, it is obviously another
Russian attack). And if they realize they are the main group requiring
cryptography, they will stop trying to prohibit it.
When I worked on crypto as part of the Web team at CERN, I was once
searched three times on one trip to see my parents. Once by UK customs
going in, once going out and again by French customs entering. One of the
main reasons the Web does not have the security infrastructure we wanted
was the constant harassment in the 1990s.
We must defeat the attempts by Comey to get similar controls introduced in
the US. Ever wonder why Comey hated Hilary Clinton so much that he broke
DoJ policy and sent his infamous letter? Ever wonder why Louis Freeh got
involved in Ken Starr's plot to perjury trap Bill Clinton? I believe the
crypto issue played a large part in both decisions.
The FBI Directorship has long been a malignant office that has engaged in
criminal activities for despicable ends. It is time to eliminate it. It is
time to make strong end-to-end encryption the ubiquitous in Internet
emails. The threat is Comey. The threat is Putin. They are both enemies of
democracy and the free world. They must both be defeated.

@_date: 2017-05-07 10:35:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchained code signing. 
Someone brought up the Apple code signing infrastructure. Yes, there is an
issue there, yada, yada. And not just with Apple, it is a basic problem
with signing any platform: How do you know the distribution is to be
Here is how: You use Certificate Transparency.
Only instead of enrolling certificates, you enroll signatures on code
releases. And you establish an update process that ensures that code
updates will only be retrieved if the signature is properly enrolled.

@_date: 2017-05-15 16:48:56
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Virtual reality Bitcoin viewer 
Does anyone know of a VR program that provides visualizations of
transactions in 3D?
I am not looking for functionality here, I am looking for flashy graphics.

@_date: 2017-05-19 09:39:33
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "WannaCry" ransomware has any payment resulted 
So not only was there no way to pay up, turns out that they didn't delete
the private key from memory.
Very interesting.
Was this ransomware or merely a large scale attack pretending to be

@_date: 2017-05-24 17:22:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "Post-quantum RSA" 
RSA seems like a poor choice since the value of adding bits to the key
seriously diminishes. 2048 bit RSA is only a little better than 1024, to
get to 2^256 work factor you need 16Kb keys.
The work factor curve gets really flat for RSA. Which is why ECC looks a
better bet without quantum. Once you get into 'improved' quantum algorithms
that are not Shor, I would expect the same tricks apply because the
weakness of RSA at higher bits is determined by the structure of the
underlying problem.

@_date: 2017-11-08 09:42:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy 
The fact that it is taking $100 worth of electricity per BitCoin
transaction is in fact significant.
What it is proving is precisely the fact that BitCoin is not a
functioning payment system, let alone a currency. It is simply a
digital asset that people are fighting over. It is the electronic
equivalent of valuable baseball or magic the gathering cards.
As ever, we have the chopped logic which means that everything must be
interpreted in the sense most favorable to bitcoin. BitCoin ideology
is founded on the premise that it will one day replace the global
payments system. Thus the fact that the use of BitCoin for actual
payments is negligible is not a small detail that can be hand waved
away, it utterly demolishes the original premise.
Proof of work is not essential to the running of a notary log. Surety
managed just fine before BitCoin was invented. Last week we saw people
pushing the name 'hashgraph' to describe an alternative technique. I
see this as some very smart people who have invested heavily in
Blockchain technology looking for a way to decouple from the BitCoin
bubble before it bursts.
Of course the bubble will burst, they always do. At the current rate,
there will be more BitCoin than USD within two years.I haven't done
the sums recently but we are surely past the point where BitCoin has
exceeded the total amount of USD in specie. Two years after that,
there will be more BitCoin than there is money of all types.
Of course it is very easy for people to convince themselves that they
are creating money by sitting in their basement running a mining rig.
The fact that other people don't 'get it' is taken as proof that the
miner is really really smart and the critics are not.
Sound familiar? It is the same effect that has people voting for Trump.

@_date: 2017-11-17 18:47:46
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is ASN.1 still the thing? 
I found the lack of binary capabilities to be problematic and so I
defined a set of extensions. Note that unlike every other 'Binary
JSON' proposal I have seen, JSON-B is a genuine superset of JSON.
Every JSON encoding is legal JSON-B and every JSON-B document can be
converted back to JSON. Although obviously using features like int64s
which are not supported by some JSON readers will be an issue.
This works because the only valid JSON tags are in the range 0-127.
Bytes > 127 can only occur inside a text string.
I am not that bothered about the possibility of using tags that are
not supported by any other language. I have a switch in my compiler
generator that limits the tags I use to alphanumerics. That is not
necessary for my tooling but I see no reason to use others and RFCs
are only accepted in ASCII at present so why bother doing anything
You might want to look at this. It is designed to produce fingerprints
of any typed object. The fingerprint is over the object type and
object data so that a trusted OpenPGP key cannot be inserted into an
S/MIME application as trusted causing possible semantic substitution
Having developed the fingerprint, we can use it to create Strong Internet Names:
alice at example.com.mm--mb2gk-6duf5-ygyyl-jny5e-rwshz
This is a name that can only be interpreted in the context of a
security policy that has the UDF fingerprint
Of course, this is a technology that is rather easier for me to
promote after we sold the CA. The security policy could be the ICANN
trust root, a local trust root, a JSON document describing more

@_date: 2017-11-17 18:56:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is ASN.1 still the thing? 
I have yet to hear anyone give a good use case for canonicalization.
VeriSign certificates were BER encoded for years until someone finally noticed.

@_date: 2017-11-19 16:59:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is ASN.1 still the thing? 
ASN.1 DER is unsafe and ASN.1 BER can be unsafe.
The issue is simple: Some people are unable to write secure code. If
you use an encoding that makes it more likely such people will write
an incorrect implementation that leads to buffer overrun errors then
that is your fault.
Specifically, the issues that occur are of the form
LengthA:{LengthB:{Data}, LenghtC:{Data}}
It turns out that in many implementations of IPv6, ASN.1, JPEG, etc,
it is possible to cause a buffer overrun by creating such as structure
with LengthB > LengthA.
Checking to get this right is time consuming and difficult to get
right. A crap ASN.1 decoder can be done in a week, a really good one
with every possible corner case is enormous and might take a year. So
just don't use ASN.1 it is utterly awful.
Incidentally, anyone remember Linus Torvald's 'compiler masturbation'
rant? He was upset because someone had written bound checking
assertions into the IPv6 stack and because he didn't immediately
understand the reason it was there, he fired off a shitty rant because
he is a nasty bully and people are willing to think he is God. I
really don't like that kind of behavior.
More importantly, I don't trust Linux code as secure because I know he
engages in that kind of behavior.

@_date: 2017-11-19 19:58:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is ASN.1 still the thing? 
Well it isn't managed code for a start. So I would have to have
someone audit it. And that is serious money to do it right.
The issue is not whether the code is reliable, it is whether it
responds correctly and securely when presented with a malicious input.
And unless the code is written in a language that has built in bounds
checking, I cannot trust it no matter how much it has been used
because these issues keep being uncovered decades after code was
I have written four ASN.1 decoders or encoders over the years. I am
very familiar with the scheme and that is why I simply don't use it
for any new work.

@_date: 2017-11-24 15:36:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [FORGED] Re: Is ASN.1 still the thing? 
The most important issue for me is not having to bother with the whole
ASN.1 hate thing. Too many people have been burned by ASN.1 already.
They just don't want to hear about it.
Missing important considerations is a risk but I find JSON with very
minor extensions has met all my needs and the Mesh is pretty
Since I already generate ASN.1, JSON, TLS and XML
serializers/deserializers from my tool set, I could almost certainly
add Protocol Buffers in a couple of days if I needed. I very much
doubt I have left any important requirement out since I have already
supported all the most commonly used formats.
Actually, the ASN.1 schema format is worst of all. I just could not be
bothered with it and so I created my own, lust like I did with XML. If
needed, I would generate ASN.1 from my schema along with the
Main objection I would make is 32 bit lengths are rather short for modern needs.

@_date: 2017-11-25 22:53:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [FORGED] Re: Is ASN.1 still the thing? 
Nothing could be a tenth the burden that Asinine One has been.
JSON-B adds the missing binary type and an unescaped string type. Job done.
There is actually something I hate more than ASN.1 and it is SQL.
Why on earth would I want code injection heaven near my systems?
I could produce ASN.1 simply by changing one switch on the synthesizer
but I won't because ASN.1 is less popular than Ebola in some parts and
I am not going to spend my time and effort on restoring its
Or just use a modern encoding like JSON-B.

@_date: 2017-11-27 10:59:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Transparent remote file access 
So I have been configuring my development machines so that I can use my
Windows box to cross develop to Mac and Linux. And so I have fstab files
filled with usernames and passwords to grant access. Which would be
unacceptable of course if the cross platform targets were not dedicated
build machines situated in the same physical space and under the same
administrative control.
But this approach is of course fundamentally unclean. The problem is, I
don't see anything that is more than a cosmetic improvement.
Yes, I can put the username and password information in a separate file
that is attached to the account rather than in my fstab. But that only
moves the problem a little
In theory, I could use an encrypted partition on my user account. But that
breaks when I try to invoke scripts on the build host remotely unless I
provide the password.
Something is broken here and I think it is because there is a fundamentally
difficult problem which I am not aware anyone has really solved yet. So I
am asking if someone can see a solution, that is a full solution and not a
workaround to the problem of logging into a remote machine and carrying
across all the privileges.
Kerberos solved some of these problems of course. But a Kerberos KDC has
absolute God level privileges to achieve that. If the KDC is ever
compromised you are hosed. Mallet is my sysop, I don't trust him. If I use
a KDC based on symmetric crypto, I give Mallet root access to everything.
What I want is to address scenarios such as the following without any
password based credential whatsoever. There might be a PIN to unlock a
private key but I don't want any password based credential or proof of
knowledge of a password to go on the wire.
*Scenario 1:*
Alice is sitting at host Machine1, she connects to Machine2 (e.g. by SSH).
She runs a script that reads files on Machine1 and deposits the result on
The sysops of Machines 1 through 3 are different. The sysop of Machine 1
could install software that could steal Alice's credential and make use of
it on Machines 2 and 3 but the sysyops of Machines 2 and 3 can only
compromise the data that passes through their own host, they cannot
compromise Machine1.
*Scenario 2:*
Alice writes a cron job to run at a particular time to perform an operation
on a particular set of files. on Machine 1.
In this case, the machine has sufficient data to compromise the data
hosted. But the data should be secure if someone with physical access takes
the disks.
What I am looking for is not necessarily cryptographic enforcement of the
access controls. When faced with an insider threat, it is pretty much
inevitable that the data on that particular host is going to be hosed if a
user loads it into the memory space of some application.
But looking at recent attacks, I am seeing that a LOT of the threats we are
facing are coming from sideways contamination. The Russians attacked thirty
DNC staffers with phishing emails, they only compromised one and not the
machine that they were after. But once they were past the firewall, they
could hop from one machine to the next without difficulty.

@_date: 2017-11-30 09:00:24
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Transparent remote file access 
I have already removed the DNS admin from the trust nexus using Strong
Internet Names which are essentially PGP like fingerprints embedded in DNS
I would rather poke my eyes out with a stick than use LDAP.
This is really not helpful. I am aware that there are many security
concerns. Right now, the security concern I am looking at is
confidentiality risk from Mallet having god access to my enterprise file
If I had thought up a solution to a different problem then I would be
asking about that. Right now, I am focusing on the problem I have a
solution for and looking to see if someone else has solved it already.

@_date: 2017-10-02 14:05:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is there any advantage to canonical fingerprints. 
So I was working on my UDF fingerprint scheme. Using base32 to encode a
fingerprint and adding an 8 byte version prefix means that a fingerprint
with a 117 bit work factor looks like this:
Its not bad but how about we ease up on the work factor. The absolute
minimum I would want to have is 92 bits.
Now suppose that the first 25 bits of the fingerprint are zeros. The 92 bit
fingerprint that would look like this:
Now looks like this:
It is the exact same workfactor as all we have done is used compression.
The version byte indicator is 97 instead of 96 to show that 25 leading
zeros were omitted.
Finding that fingerprint ("290668103" in text/plain) by exhaustive search
took me about 10 minutes using a single core. To save another character, or
improve the work factor by 5 bits will take 32 times as long. Which is
manageable if I multithread the code for all 12 cores. But going much
beyond that is going to be impractical without a BIG machine.
If I am taking a fingerprint of an ECDH key, the keygen overhead is not
terrible. But I certainly can't compress RSA keys this way. And I really
can't see saving more than 25 bits of work factor being practical unless
either I use the GPU or rent space on a BitCoin mining farm or the like.
Point being that if I am going to do either, I am really going to want to
calculate H(Key+Salt) and do exhaustive search on the salt rather than
H(Key) and vary the Key.
To reduce the fingerprint to a memorable 10 characters would take a million
times the compute power I used to shorten to 15. But I can see some people
being willing to pay for that.
My brief investigation suggests that current bitcoin mining difficulty*
is 1123863285133, or 2^40. So assuming people are spending less than the
coins are worth to mint them, say $1000, getting to a 10 character
fingerprint would cost a million bucks right now. Which means only pharma
Bro is gonna be buying and that after he gets outta club Fed.
But going the other way, 35 bits of compression is $4 worth of compute
power. And that means 102 bit work factor in 15 characters. Which fits on a
business card.
One of the innovations in PrismProof email is Strong Internet names that
allow fingerprints to be used as DNS name components, thusy:
alice at example.com
mail to Alice without requiring security enhancements.
alice at mm--mf2gk-6duf5-ygyyl.example.com
mail to Alice. If the MUA is SIN-Aware, it MUST resolve the security policy
specified by the fingerprint and apply security enhancements as mandated by
that policy.
alice at example.com.mm--mf2gk-6duf5-ygyyl
send mail to Alice if the MUA is SIN-Aware, it MUST resolve the security
policy specified by the fingerprint and apply security enhancements as
mandated by that policy.
More info in:
[*]Yes, I know BitCoin uses SHA256. I deliberately chose SHA512 for that
exact reason as the ASIC is only going to do SHA512 if it is designed for
that purpose.

@_date: 2017-10-02 19:56:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Is there any advantage to canonical fingerprints. 
Ah now I remember why I didn't do it this way. We talked about it, i
looked at the patent and thought, nope not doing that, then seem to have
re-invented it when I came to implement. Ooops!
9 Jun 2015 FP Expired due to failure to pay maintenance fee
Effective date: 20150419
So looks like you have won yourself a citation in my draft :)

@_date: 2017-10-03 11:16:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Some terminology issues 
I am just putting together a little protocol to perform a key exchange over
some DH like protocol and spit out an opaque identifier which will
typically be a ticket of some sort.
[Oh yes, I am considering going down the tickets with embedded public keys
route, it solves a lot of server side issues maybe]
So, I don't actually have the usual opaque nonces in my code, I am doing
the signal trick of a multi-way handshake using one time use keys as
nonces. So my question is, should I be calling them a nonce or is that
going too far and going to confuse folk.
This is a presentation layer (i.e. HTTP) exchange which has the primary
purpose of authenticating the client to the server and establishing a
shared secret that will be used in future communications and binding it to
an opaque identifier which is typically a ticket.
So the client knows a, b, and in the initial connection sends:
{ClientCredential, ClientCredential} being e^a, e^b
The service knows x, y, replies with
{ServerCredential?, ServerNonce} being e^x, e^y
The agreed key is either e^aby or e^abxy and the usual key derivation is
used to establish the session key to be used on subsequent communications.
The response and all future messages are authenticated according to the
requirements specified in . If encryption is specified, this is
used for all messages following the response (because the client has to be
able to read the response to decrypt it).
Authenticating at the message layer in this way achieves the following
1) Determines that the message was sent by the client.
2) Since each transaction MUST have separate authentication, frames
transactions to defeat script injection attacks.
3) Enables but does not provide defense against replay attack.
The protocol schema is shown below, assume that Algorithms contains
something sensible. Right now I am only supporting AES-CBC and
HMAC-SHA2-512 (truncated) because that is what my libraries support.
    Transaction Admin Exchange ExchangeRequest ExchangeResponse
Message ExchangeRequest
External Goedel.Protocol.Request
Struct Key ClientCredential
Struct Key ClientCredential
Struct Algorithms Offer
Message ExchangeResponse
External Goedel.Protocol.Response
Binary Ticket
Struct Key ServerCredential
Struct Key ServerNonce
Struct Algorithms Choice

@_date: 2017-10-05 12:50:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Double ratchets, useful or PITA? 
I am reading the double ratched docs again, trying to see if there is any
real advantage over just doing a rekey.
My basic key exchange is to use a 3 or 4 way DH as follows (ignoring the
mod p part)
Sender has long term credential {a, e^a} creates an ephemeral {x, e^x}.
Sends public keys e^a, e^x to recipient.
Receiver has long term credential {b, e^b}, optionally creates an ephemeral
{y, e^y}. Sends public keys e^b, e^y to recipient plus a witness value
Shared secret is s=KDF(e^abxy, m), witness value is KDF(e^abxy, w)
Receiver also replies with an opaque identifier for the connection of up to
1Kb (or so) which may be kerberos ticket style.
I am anticipating a situation where Alice and Bob might have tens of
different encrypted streams between them simultaneously. They might have a
couple of web cams, a chat, shared desktop, etc. Some or all of these may
be across different device pairs.
Yes, I can do the ratchet but it seems to me that it is not buying me a
great deal that I can't get better by using the old ticket and shared
session key to get a new ticket and session key.
I can always do s_n+_1 = KDF(e^abxy+s_n, m)
But what is that really buying me? I cannot expect every party to keep
state on every possible sender/receiver pair. So an attacker can always say
'lets set up a completely new session'.
My protocol already has forward secrecy as the client and server both
contribute a nonce per key exchange and discard it.

@_date: 2017-10-05 15:13:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Double ratchets, useful or PITA? 
What I am looking into doing right now is specifying the rekey mechanism
as follows:
* One of the outputs of the HKDF function is a 'RekeySalt' value
* Rekey Messages are authenticated and optionally encrypted under the
previous session key
* The RekeySalt value is the salt for the next HKDF Expand.
One of the peculiarities of the key agreement mechanisms that I am looking
at is that they all seem to be fixated on use of signatures for a key
agreement. Why not use a key agreement for a key agreement?
Both sides contribute an ephemeral key and an identity key, Bam, done!
Both sides are protected against perfidy by the other if they choose a
random ephemeral. It doesn't even need to be secret to protect against
small subgroup games.

@_date: 2017-10-08 22:14:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Some recent work 
I thought people might be interested in two pieces of recent work.
The first is a cryptographic container format that provides a combination of
* Zip file finctionality
* Blockchain with Merkle tree functionality
* Append only atomic log
* Efficient random access with zero initialization overhead.
* PKCS
The key idea here is that the frames have length markers at the front and
back so that it is equally efficient to access the last frame and work back
as to read forward. So you can write out a file and then stick an index on
the end.
It also serves as a PKCS replacement that avoids the need for ASN.1. The
nice thing about this approach is that you can create an archive of
encrypted and/or authenticated objects with separate public key information
for each frame or information shared across frames as is needed.
The second is a new key exchange that uses public key composition as the
Something that has always struck me as odd with TLS is that we use
encryption and signature to achieve key exchange. Why not just use Diffie
My exchange uses up to four keys. The client and the server ALWAYS
contribute an ephemeral key that has the function of a nonce and also
providing side channel resistance and forward secrecy. The client and/or
server MAY also contribute an identity key.
As the full paper shows, this key exchange is intended for use inside a TLS
encrypted tunnel to authenticate transactions. Each transaction message is
authenticated using a separate MAC. So injection attacks are defeated
because only one command per message is valid.
TLS client auth does not work very well because the TLS endpoint is usually
not where you want it. So performing a second key exchange and
authenticating within the tunnel is best.
This leads to what I call the Triple Lock with three layers of encryption:
Transport, Presentation and Data level. This provides for comprehensive
protection unless traffic analysis with multiple observation points is a
concern which can only be reasonably defeated using link layer encryption
of some sort (including onion).
The scheme may be used for rekey with a ratchet. The main reason for the
ratchet is to make sure that rekey key exchanges never dilute the key
strength. So if you start with a Ed448 exchange and then rekey with
Ed25519, you still have the full Ed448 strength.
If people look at the full prismproof.org site, you will note that I have
authored 12 specs this year and have essentially designed and implemented
an entire PKI from scratch in three years. I could really use some help on
this. I am pretty sure that I can prove the key exchange correct but I
don't have time to spend on that right now.

@_date: 2017-10-16 19:41:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Millions of high-security crypto keys crippled 
I just love those prime numbers that are prone to factorization.
Its like when I go to the Outback and Prime Rib is served in 8oz, 12oz
and 14oz. None of which are prime.They are however one greater than a

@_date: 2017-10-24 09:37:53
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Transactional software updates 
(Also posted to SUIT which is a proposed IETF WG on the topic, I
thought it might be of interest here).
I don't know about you, but I am fed up of the time it takes for
software updates on my desktop. First the update has to be downloaded
and then it has to be installed. Why can't this be instantaneous?
What I would like is to download the software update and then tell the
O/S to simply overlay the update on top of the file system as an
atomic operation. So installing a software update takes a millisecond,
no more.
Rolling back a software update is just a matter of telling the O/S to
stop applying the overlay.
It seems to me that this sort of capability would be very useful at
the device level as well. Even more so as the chief concern in any
software update scheme is that you end up bricking a device. Building
the ability to roll updates forwards and backwards is powerful.
I would also like this to be integrated into software signing and in
an intelligent fashion so that the signature encompasses both the code
and the data and it is possible to validate components independently.
There is of course going to be a cost and it is the need for storage.
The traditional file system organization is a response to highly
constrained storage. I have not yet fully considered space
optimizations because I have been thinking about the constrained
device but I think my approach could be modified for a fairly
constrained device. My approach is not going to be appropriate for
your PIC controllers but it is definitely feasible at the Arduino
level and above.
My approach is based on a Merkle Tree based container format. This may
sound intimidating but it shouldn't be. I designed, documented and
implemented the scheme in under a week:
or in HTML with diagrams at
The draft describes a container format that consists of a sequence of
variable length chunks that has the property that the sequence can be
traversed with equal efficiency in the forward and reverse directions.
This can optionally be indexed via a binary tree to allow random
access to any frame in log(n) time. Chain and (Merkle) tree digests
may be constructed which may be signed.
Each frame consists of a header and an optional payload. The payload
may be encrypted and/or signed using JOSE. The only fixed requirement
for the header encoding is that frame 0 has to have a header encoded
in JSON (for interop). The code supports use of JSON, JSON-B, JSON-C
and ASN.1 for header encoding, the container uses JSON-B frame
encoding because it has to support the read in either direction
The original concept here was to provide an append only container
format that could be used as the basis for synchronizing Mesh portal
logs between nodes and also as an encryption format for end-to-end
encrypted Web sites. Static content is straightforward, but people
expect to be able to support applications like Web forums. The idea
was to see if we could support a Web forum run on a cloud server that
does not have the ability to read any of the content (yes).
The authentication scope is intentionally limited to the payloads, and
the signature parameters. The headers are not authenticated which
allows them to be mutable. A device may store the whole update as a
single file or break it apart into attachments. The latter approach
making garbage collection of unused attachments possible without a
separate sweep/collect cycle.
I am not sure that the encryption capability is needed for software
update but it might turn out to be useful allowing devices to be
shipped with code for a wide range of applications and only enabling
the specific modules required. I do not like devices to have more code
than is necessary for their purpose. Authentication is obviously
The way I would see this applied to software update is that the
device/desktop would download and verify the incremental updates as a
background task (when bandwidth permits). It would then request user
permission to apply the update (if required) and set a flag internally
telling the loader to use the new version in place of the old. Any
processes that needed to be restarted would be restarted.
This could be used to effect updates across multiple devices at the
same time. It could also allow support for features such as testing
the configuration and performing an automatic rollback if the test
Besides providing a more secure process, this provides a better user experience.
The code required to support the container format is comparable to
that required to implement a SHA-2 or the like. implementation in a
TPM or such would be entirely feasible.

@_date: 2017-10-26 15:52:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Mesh Key Recovery 
I am currently working on documenting the Mesh tools and producing a
user guide. This is not yet complete but I wanted to show people the
section on disaster recovery for comment at an early stage as I am
sure that it will be controversial.
The concern here is that the Mesh needs to reflect the security
concerns of its user and not just those of its creator or its early
In the real world, houses are destroyed by flood and fire, people are
displaced by war or tyrannical governments. If we are to meet the full
security requirements of users we must consider data availability to
be at least as important as data confidentiality.
Thus some form of key recovery capability is essential. But support
for personal escrow need not entail support for government backdoors.
It is one thing for me to prove to myself that I can recover my keys,
it is quite another thing for me to demonstrate to a government that
they can transparently access my escrowed keys without my knowledge or
Of course any scheme that provides a user with more opportunities to
recover their data will inevitably create a larger set of
circumstances in which they may be coerced to disclose the keys
against their will. This is certainly a concern but it is not the only

@_date: 2017-10-26 21:51:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Mesh Key Recovery 
Absolutely. And I discuss those use cases in the paper:
I want my family to know where I buried Aunt Agatha's jewelry but not
where I buried Aunt Agatha.
Yes. But this sets up additional UI overhead and is not something I am
going to attempt to implement in a line mode client.
The way that I would implement these use cases is by using
Mesh/Recrypt which uses proxy re-encryption. I would add the family to
the recryption groups I wanted them to be able to recover and not to
the groups I did not want them to be able to recover.
Right now, the percentage of PGP users that use PGP is vanishingly
small. I think we need to fix that before attempting requirements with
more demanding UI needs.

@_date: 2017-10-26 22:02:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Transactional software updates 
I think the talk of file systems is missing the point here.
Yes, you can do stuff that requires kernel mode features and a fancy
file system. But these capabilities are MUCH better supported in user
mode with a small piece of code in the program loader to perform the
necessary validation and signature checking.
There are software distributions that include data that is mutable but
this is rare. Most cases, a software package consists of executable
images, shared libraries and static data. These may be unpackaged into
the file system but almost all of that work is to duplicate the
developer's environment on the target machine.
If the necessary indexes are provided, there is no reason that most
software distributions couldn't simply execute straight out of the
distribution zip file.
I really, really dislike the idea that any code that is not shipped by
the platform vendor should ever modify any part of the platform. I
detest shared libraries, I see absolutely no reason for them on modern
machines when a 0.25 TB SD card can be had for a few bucks.
The only time a shared library is ever justified is when the platform
itself is being extended. Installing the latest version of DirectX for
example. But the cases where I see a need on modern machines is almost
Rather than using shared libraries, I would like to see the use of
approaches that strip down linked libraries to exactly the methods
that are actually called.

@_date: 2017-09-16 12:31:20
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] letsencrypt.org 
I can't parse that.
The objective of Let's Encrypt is to go to a 100% encrypted Web. That has
obvious benefits if all you care about is stopping mass surveillance. But
that is not the only effect.
Once you decide that every Web site has to have a certificate, it follows
that either CAs become censors or there must be some class of certificate
that can be obtained by any party with a valid ICANN domain name. This is
very problematic because the WebPKI was not developed for confidentiality,
it was developed to provide authentication and accountability. If you
recall, we were limited to 40 bit crypto in the early days of SSL.
Thus certificate issuance is fundamentally vulnerable to MiTM
The rather subtler issue with LE is that the single most effective check
in the DV system for consumer protection is the pre and post issue checks
on the credit card. Phishing sites didn't like using DV certs because they
had to use phished credentials to get the cert. If the fraud was
discovered, they would lose the site.
You were unclear then. The specification makes clear that CAs are required
to perform DNSSEC validation if a zone is signed. However a zone is not
required to have DNSSEC to publish a CAA record. That is intentional
because conflating the two is what killed DANE.

@_date: 2017-09-26 13:17:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Altcoin volume 
And the two are one and the same.
The cost of setting up an altcoin and generating the first million coins is
essentially nil. If you do it right, you can create the illusion of there
being an open mining effort. If you have a reasonable chunk of chain you
can spend time shuffling it between your accounts, buying and selling to
create a false market.
If the rubes take the bait, your million coins can be worth $100 million on
paper pretty quick. There probably isn't the liquidity to cash out direct
but you can probably swap for some Bitcoin and get out that way.
The thing about a Ponzi scheme is that the folk caught up in the fever
will never thank you for pointing out they bought a bubble:
* There is no value being created. Electricity is turned into coins but
you can't turn the coins back into electricity (or Tesla would used it for
their cars).
* BitCoin has not demonstrated ability to function except when the value of
Bitcoin is increasing exponentially. Within 2 years, the total value of
BitCoin will exceed the value of USD in circulation. In 4 it will exceed
all currencies.
* The reason BitCoin functions at all is that it is being used to evade
China's currency controls. Which probably does not worry China overmuch in
itself. What is probably more worrying is the amount of cash moved in to
BitCoin that isn't moving out. If the bubble bursts (and it will), that
will be an instant fiscal crisis for China if they don't take steps soon.

@_date: 2018-04-10 08:26:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The surest way to prevent WPA3 
And why would you want to do that?
I did try to get to the IAD site to read the specs but their cert is not
trusted and so the idiot browser won't let me see the page. It would let me
see the page without any encryption of course.
The CNSA suite looks like it is the standard NIST set which is mostly OK.
Certainly fine for link layer encryption as anything of important should be
protected at the transport layer. The NIST curves are not fashionable but
they are almost certainly OK. The generation approach was not ideal but it
isn't the worst security issue we face right now and the WiFi alliance will
almost certainly move to the CFRG curves when NIST does.

@_date: 2018-04-18 19:03:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Will We Ever Learn? 
Not because it was the only one to be launched, because it was the one
that brought the Internet down. There was also the Wang Worm and we had
numerous breaches of Internet facing machines due to Sendmail
For years, UNIX systems eschewed shadow password files as 'security
through obscurity' until Crack appeared and suddenly having a world
readable password file was a bad idea.
Windows was not conceived as a multi-user or a network OS. So it is hardly
surprising that the effect of adding it to a network was interesting.
Windows NT was designed as a network OS but it was only when the Vista
switchover occurred that the desktop OS moved to a fully NT based security
scheme and that transition was resisted by many lazy admins who found the
security got in the way of their work and it was easier to tell users they
didn't want Vista than deploy it.
What has changed since is that the Internet is no longer just one network,
it is all networks.

@_date: 2018-04-25 13:40:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A new approach to encryption formats 
We have had PKCS Cryptolopes and now JOSE for ages but none of them
really does what I want when designing a protocol.
In a protocol it is quite usual for the key exchange to be separate from
the encrypted data. It is also usual to want to amortize a key exchange
over multiple encrypted data chunks.
Traditional approaches for static data give me a key exchange that gives me
as output:
Encryption algorithm
Initialization vector
Encryption key
Authentication key (optional)
TLS does things differently of course but the key exchange is welded into a
protocol that assumes the ability to perform at least one round trip at
some point. For static data encryption, there is no synchronous
communication. But I still like the idea of separating out the key exchange
part and the key application part.
I would also like to eliminate as many code paths as possible. Thus I
always require a key wrap with a DH or ECDH operation so that messages with
multiple recipients are handled in the exact same fashion as messages with
one recipient.
So my key agreement structure has the following information
* The (default) bulk encryption/authentication algorithms and modes
* For each recipient key
    * Recipient key identifier
    * Encrypted key exchange data
    * Wrapped key [if a key agreement is used]
The wrapped key is the master secret.
Note that the IV is NOT part of this data. This is instead prepended to the
encrypted data chunk as follows:
[Length] [Header]
[Length] [Salt]
([Length'] [Non-terminal data chunk]) *
[Length] [Terminal data chunk]
[Length] [Trailer]
The tagging scheme allows terminal and non terminal chunks to be
distinguished. The trailer is only present if required by the bulk
The header slot is usually empty which incurs a one byte penalty per
message but provides a place to put the key exchange information if this is
desirable. This allows a Web server returning one encrypted item from a
sequence to present it as an atomic package similar to PKCS
Alternatively the Header may be used to specify a key identifier for the
The trailer slot is also mandatory (learned my lesson with HTTP chunking)
and is used to specify such authentication data as the bulk algorithms
The IV and key(s) for the bulk encryption/authentication algorithm are
calculated from the master secret using the specified salt.
The main advantage of this approach is that correctly implemented, it
guarantees that a different key is used to encrypt each chunk of data even
when hundreds of chunks of data are encrypted under the same key.
The structure of the salt is opaque to the encryption format but MAY be
constructed from:
* A counter. This provides a means of recovering order from a sequence of
encrypted packets without additional data.
* A random value with 128 or more bits. This is interesting as it provides
a simple way to 'delete' data by simply overwriting the salt value with 0s.
This provides a 128 bit work factor for decryption if a 128 bit salt was
* A counter plus a random value.
* A counter plus the authentication tag of the previous block. This
provides a handy means of providing a sufficiently random salt without
requiring additional data.
The approach should be compact enough to allow use on UDP data streams. The
absolute bare minimum overhead is 4 bytes (null header, trailer and salt,
data is 127 bytes or less).
If applied to field level data, I guess it might well be acceptable to drop
the header and trailer slots. This is not going to be viable for 'encrypt
in place' type applications so ciphertext stealing probably isn't relevant.
The consequences of this approach are as follows:
* Multiple blocks of data are automatically encrypted under separate IVs
and Keys
* Supports all the functionality of PKCS / JOSE
* Single processing path regardless of encryption options
* Straightforward format with no unnecessary hierarchy
* The encryptor has no direct control over the encryption key used.
* Supports embedded/detached key exchange modes and allows one to be
converted to the other.
* It is not possible to exchange previously encrypted data using this
format unless an option is provided to support an additional key wrap.
* The use of key wrap in the DH/ECDH exchange provides a subliminal channel
for the encryptor.
One of the really nice features of this approach is that it maps nicely to
a messaging service where we want to be able to encrypt summary data
(subject, recipients, sender) separately from bulk data.
A single 'email' might consist of a summary "These are the latest project
summary results, lets talk about them", a push message [The description of
the data] and an optional pull data item [several GB of raw data]. Alice
wants to send all three but Bob only wants the first two on his phone and
only the first on his watch or dashboard/inbox.

@_date: 2018-04-27 09:47:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Review of UBIC 
UBI is something that anyone serious about tech needs to be thinking about
because our current capitalist economy is based on the assumption that
labor is a scarce resource and is structured to allocate it efficiently (by
some measure).
As Karl Marx pointed out, the system will fall when automation reaches the
point that labor is no longer a constraint. The reason that we have avoided
that situation and its consequences is that we have dramatically increased
consumption. On the positive side, we increased production of food (two of
Marx's children died of malnutrition and they were middle class) and of
health care. On the negative side, vast sums were and are spent on building
military machines whose size and power makes a state of near-constant war
necessary to justify them.
As with Malthus, the reason Marx was wrong is that he underestimated our
ability to adapt to circumstances. But that does not mean that the
fundamental issue can be ignored. We have to continue to adapt.
The argument about finite resources entirely misses the point. Labor is no
longer a finite resource. We can build any amount of machinery. We have
already deskilled and automated primary and secondary industry and Web
services are about to do the same to tertiary.
Fifty years from now, some means of recycling the wealth will become
essential as work of any type becomes scarce and meaningful work becomes a
luxury. Most people who are serious about the effects of technology on the
economy get that fact. What has not been examined is how to get from where
we are now to where we need to be.
One of the major maladaptions of our current society is the Protestant work
ethic. This is particularly bad in the US where Puritans fleeing religious
persecution in Europe came to set up a new society based on slave labour
and to seek the opportunity to visit intolerance on others. It is always
the folk who live of the sweat of others that are keenest on the moral
virtues of manual labor. The UK is currently in the grip of a similar
faction led by the moral imbecile Theresa May whose explicit goal is to
make life as unpleasant as possible for those less fortunate than herself.
We don't have the economic resources to implement UBI at present and the
transition from the labor based economy to the automated economy is going
to be difficult and likely unpleasant. But what we can surely do is to
repudiate policies based on the notion that forcing sick people and mothers
of infants to work for their living is helping them.
We cannot afford UBI today but we can afford universal healthcare and we
can afford to eliminate workfare programs for the disabled and sick and to
dismantle all the infrastructure of that type of politics.
There are certainly challenges to be faced here but they are exclusively
social and political. This is not a problem that can be solved by
technology, it is technology that has created it! More specifically, the
idea that merely changing the way that value is exchanged addresses the
fundamental issues is flawed and plain wrong.

@_date: 2018-04-27 16:39:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cryptographic challenge 
OK here is an interesting cryptographic puzzle which I believe will
probably have no satisfactory solution but is fun anyway
Traditional public key encryption schemes are either a 'true' encryption
scheme that provides for message recovery (e.g. RSA) or a key agreement
which establishes a shared secret that both parties know but neither party
has direct control over.
There are advantages and disadvantages to both. The advantage of using RSA
is that if a message is sent to 100 recipients, the output of the RSA
decryption operation is exactly the same for each one and can be used as an
encryption key directly.
That is not the case with DH and ECDH of course, each recipient has a
different output value and the only way to encrypt a message for multiple
recipients is to wrap the key for each recipient.
In either of these cases, the approach works but there is one niggling
problem, the data is encrypted under a session key controlled by the sender
which provides an opportunity for a kleptography attack. The sender can
deliberately choose a weak key or use the key to transmit information.
When a message is end to a single recipient, the DH scheme has the property
that it is free of subliminal channels. There is no part of the output
message that is not either constrained by the input or has been processed
through a one way function. The generator of the message can choose the
ephemeral private key but can only use the public key as a channel through
'brute force' type approaches requiring vast amounts of processing or large
numbers of messages to communicate.
I am currently writing a spec for Data At Rest Encryption. For the sake of
minimizing the number of code paths to the absolute bare minimum, I am
using key wrapping in every case. Which leaves the opportunity for a
subliminal channel which is an irritating but probably essential compromise.
But is it possible that there is a public key cryptosystem that allows a
message to be encrypted to multiple recipients that does not have this
I have thought up many solutions and then realized that they are flawed
because while it is easy to prevent the generator having direct control of
the ciphertext encryption key and/or IV by using hashes, this is about
preventing any nonce like information being passed to the recipient.

@_date: 2018-04-30 12:55:04
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Data erasure by erasure of a salt 
I am just working on the DARE (Data At Rest Enhancement) spec and was
interested to know what the Quantum difficulty of a particular attack would
The basic concept of DARE is that we perform one master key agreement and
then apply the result to multiple Enhanced Data Sequences:
"A DARE message MAY contain multiple Enhanced Data Sequences. The message
body, cloaked headers, annotations and signature values are all presented
as Enhanced Data Sequences"
The reason I like this approach is that it provides a simple and
straightforward means of supporting features that are really essential in
application messaging such as the ability to encrypt the subject line and
message body separately and to encrypt signature values etc.
Unlike in other formats, each Enhanced Data Sequence is encrypted under a
unique key and IV. These are derived from the Master Key by means of HKDF
and a salt that is unique to that EDS.
So if we are constructing a message we can very easily ensure that each
salt is unique: Just use a counter and increment by 1 for each EDS we
But when we get to the message body, we might want to be able to
effectively erase the body by erasing the salt value:
"For data erasure to be effective, the salt must be constructed so that the
difficulty of recovering the key is sufficiently high that it is
infeasible. For most purposes, a salt with 128 bits of appropriately random
data will be sufficient."
Now the neat thing here is that even if I am using AES-256, a salt of 128
bits is almost certainly sufficient because it is a 'hard' workfactor. We
are literally deleting that part of the key. 2^128 is an infeasible work
factor, the only reason to go higher is because we worry about the
algorithm not being as good as we think, not because someone could build a
machine that could break a workfactor that size.
Or can they? Does Shorr's algorithm mean I need to go longer or does the
same argument apply?

@_date: 2018-08-03 13:33:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Perfect Integrity? 
I don't think they do. Rather, I think they provide you with a bounded
proof of security that depends on some safe but real assumptions.
The integrity equivalent to a One Time Pad is to keep a copy of the data
itself as evidence of integrity. Like an OTP, perfectly secure and
perfectly useless.
Apart from applications like RAID1 mirroring and such that is.
Cryptography is really about compressing the security problem scope.
Instead of protecting all these terrorbytes of data, I just have to protect
a few little bits of key.

@_date: 2018-08-16 20:27:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Rescuing Encrypt-then-Sign 
This paper shows many of the arguments surrounding the order of signature
and encryption
The paper recommends that data be signed and then encrypted. But I dislike
that order because it means that it is only possible to verify the message
after it has been decrypted. This violates a layering principle in which
data is only exposed to a device that contains a private key AFTER we know
it doesn't come from a malicious source.
So here is the alternative approach. I generate my message encryption keys
from a master secret established by the key exchange by means of a key
derivation function (HKDF) and a unique per-message salt. (I also generate
the IV for encryption and the MAC key if required).
Each set of keying material is extracted with a different and unique info
tag 'encrypt', 'mac', 'iv' and so on.
I would like to include an additional witness value that is derived from
the master secret using the KDF using another unique info tag 'sign'.
This does not quite guarantee that the signer knows the plaintext or even
the master key but does prove that whoever had the master key authorized
them to sign. That might be an interesting property.

@_date: 2018-08-23 16:26:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Rescuing Encrypt-then-Sig 
OK, here is how I 'solved' the problem:
To encrypt, I establish a master secret using the key agreement
information. I then derive encryption parameters (key, IV, MAC key) from
that master key using a KDF and a unique 128+ bit nonce(salt). Key = KDF
(salt, "encrypt") and so on
I encrypt the plaintext, calculate the digest of the ciphertext and sign.
To provide proof of knowledge of the plaintext, I provide a separate
witness value Witness = KDF (salt, Signature) and provide that as an opaque
value together with the signature. This has some very interesting
One of the most important for me is that I only require the signature to be
authorized by a party with actual knowledge of the key exchange parameters.
It is not necessary for the signer to have the plaintext, just the digest.
This is much easier to support when the signer is a remote device.
While this does not eliminate all the possibilities of protocol confusion
arising from what the signer intended, I don't think the signing order is
sufficient to address those either. Those are questions of cryptographic
application design and it is naive to think that a single approach can
address every concern in every case. It is not Alice who encrypts the
message it is a collection of computer systems nominally under her control
that sign the message.

@_date: 2018-08-23 16:53:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Next steps in the Mesh 
So, I have completed the specs for DARE: Data At Rest Encryption. There is
a message format and a container format. I am now working on applying those
to the design of the Mathematical Mesh in the hope I can simplify greatly.
When I first proposed the Mesh I realized that if Alice is going to join
her laptop and her phone together in some sort of personal PKI, I was going
to require some form of 'postbox' service to allow messages to pass between
the devices in a fluent way. It is not possible to expect two consumer
devices to communicate directly as peers. It is not possible to expect a
consumer to have a server. So I ended up with an untrusted cloud service to
act as a dead drop.
By 'untrusted' I mean that the cloud service has no confidential data that
is not encrypted and has no control over the user's actions other than
refusing service. So if I am using Google as my sole service provider and
get into a row with them and they drop me, I can simply create a new
account on Yahoo, synchronize my profile and continue with almost no
interruption. Since my contacts all know my profile fingerprint, all I need
to do is send out an (automated) contact update notice and I am back in
business. They can talk to me and I can talk to them.
Having developed the Mesh concept, I then started defining applications
based on the Mesh capabilities and specified these as separate services. I
now realize that was a mistake. Users should only have to worry about one
type of service and one type of account. Separating the Mesh profiles from
other types of application data does not help, it only hinders.
Here, my applications are of two basic types, one is an application that
makes an existing infrastructure such as SMTP mail or SSH secure and easy
to use by managing key information. The second is entirely new applications
that make use of the three key cryptography I use.
So in the new approach, Alice has a Mesh profile that is hers and she
controls absolutely. She can use a single Mesh profile to connect to Mesh
services offered by multiple sites and create multiple accounts at a single
site that are all linked to one profile. If Alice wants to connect a new
device to her profile, she can use any of her accounts for this purpose.
Every Mesh application service has to support the subset of messages that
enable devices to be connected to a profile.
I also noticed that most of my Mesh applications consist of nothing more
than synchronizing a set of discrete objects across a set of devices, for
example usernames/passwords, calendar entries, contacts entries, SSH client
and host descriptions, email account descriptions. In the new approach, I
have a single protocol that synchronizes a 'catalog' of such objects (and
updates thereof) across the devices.
Messaging applications are very similar with the important proviso that the
request to append a message to a catalog comes from a third party which I
may or may not wish to grant that access to. So I have a series of layered
message types:
1) Connection request
2) Text only message
3) Message with attachments
4) Task item (calendar entry, task entry, buy this at Costco entry)
Connection requests should be short but not too short and allow just enough
information to know if someone is a person I want to add.
Task items and other messages that might interrupt me are obviously going
to require authorization. At minimum they have to be a contact but I
suspect I will require rather more personally!
I have not yet considered synchronous messaging but one feature that I have
always wanted is 'callback when free' integrated into the system. So if I
want to talk to someone, rather than set up an appointment, I ping them and
if they are busy, my request goes in their queue and when we are both free,
we are connected automatically.
Make sense?

@_date: 2018-08-30 11:39:59
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Need a list of Solinas/pseudo Mersene Primes. 
I am using Shamir secret sharing as a recovery mechanism for private keys
and would like to extend this to recover quantum resistant keys. As a
result, I need a nice round prime greater than 2^256.
Finding a nice round prime smaller than 2^256 is easy, 2^255-2^19-1. But I
need 2^256-x. I was looking for lists of Solinas primes but can't find one
with what I need.
Anyone got a pointer?
For public key crypto, AES256 with a key derived from a 128 bit secret
seems sufficient as with Quantum attacks in view, I can't expect my public
key to present a higher work factor than 2^128. Since the size of recovery
shares does matter quite a bit, I think 128 bit shares are appropriate.
For quantum, I really need 256 bits to justify the exercise at all. Now I
could just do two 128 bit polynomials but that seems like a hack to me and
I would have to describe and test both code paths.
I have completely re-written most of the Mesh documentation. You can review
the first installment of this work here. DARE (Data At Rest Encryption)
message and container are designed to work together to support incremental
encryption and authentication. Think of it as blockchain that you can use
to encrypt as well.
So imagine you have a server, it writes 100 entries to the log every
second. We do not want to do a key exchange for every entry as these would
be larger than the log entries. The DARE format allows us to do one key
exchange when the server starts and then use it for as long as it likes. It
is even possible for multiple servers to write to the same log under
separate master keys.
I may well cut out some of the container types. At the moment there are
five different types depending on whether they have a chained digest,
Merkle digest or no digest and whether they have a tree index or not. The
chain is probably not very useful.
I am now writing the fun document that describes all the features that are
new to PKI in the Mesh. They are not new to crypto of course but we have
not moved the state of crypto we use in the public domain much since PGP
made public key crypto for email practical apart from BitCoin adopting 30
year old hash chain technology.
The new technology includes:
* Shamir secret sharing for recovery of master private keys.
* Distributed key generation/Proxy re-encryption to support group access to
* Co-generation of public key pairs to mitigate risks of weak key
* Quantum resistant signatures to enable recovery in the case someone makes
quantum computing practical.
I would much appreciate review of these documents and if we are going to
make them industry standards, expressions of interest in the IETF.
Designing a new cryptographic message format is not something to be done
lightly. PKCS7 has served us well. BUT, I can't add even half of these
capabilities to PKCS7 without losing backwards compatibility. And it is
difficult enough coping with the complexity resulting from the
cryptographic issues without also having to consider backwards
compatibility. If people really really want to add these capabilities back
into legacy formats, lets at least do the design in a clean environment.

@_date: 2018-08-30 20:33:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Need a list of Solinas/pseudo Mersene Primes. 
I need a value greater than 2^256, sorry. 2^257-n
So what is the lowest value of n that is prime? Did not see that in safe
primes :(

@_date: 2018-08-31 12:05:42
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Need a list of Solinas/pseudo Mersene Primes. 
Thanks to everyone who responded. I could have spent the time to learn the
tools but that would be pointless as I would have never trusted my result.
The answer from three sources is 2^257-93
The way that I drafted the spec, it requires the number of bits to be a
multiple of 8 and the prime to be the largest prime that is smaller than
the next power of two. Thus, folk can apply the spec to secrets of any
length without re-writing the spec.
I am considering changing this to require the number of bits to be a
multiple of 32 and giving the primes for use with up to 512 bits.
The reason for this change is my strategy for introducing an XMSS key into
the scheme to provide a bridge to a QRC world. The basic idea is that the
user creates a master secret of at least 256 bits and then uses that and a
HKDF to generate an XMSS tree that can be used to sign at least 16
messages. That should be enough to make a bootstrap possible. They then
calculate the corresponding public key and put the fingerprint of that
public key in their Mesh profile.
The design choice I am now having to make is whether to put the XMSS
parameters in the secret record or the profile. I will probably need to
implement the spec first before I decide.
Like the second card slot on the Z7, I do not expect anyone will ever
seriously need the Quantum Recovery stuff. My experience of the particle
physics field suggests to me that keeping a machine running for the time it
would take to factor Ed448 or RSA2048 is prohibitive. But like the second
slot, considering these possibilities is something that we absolutely had
to do if a proposal isn't going to get pecked to death. [If you are not
following slotgate, see my podcast later on.]

@_date: 2018-08-31 12:53:42
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Precise definition of zero knowledge? 
OK, so I know what we normally mean when we talk about zero knowledge and
the bit about the cave.
It suddenly occurred to me that the approaches I am using to generate
keypairs for cogeneration and proxy re-encryption could be seen as 'zero
knowledge' but the approach is direct, there is no proof.
Now as with everything 'Meshy', the way I see things, my approach is simply
a logical extension of the approaches of Torben Pedersen and Matt Blaze.
Others are saying that I am actually doing something different. And that is
quite possible given how much I am bending stuff to meet my requirements.
For example, when an administration device is provisioning a new
application keypair to a connected device, the conventional way to do that
is to generate the new keypair, encrypt it under the device encryption
public key and publish the result to the device in some fashion.
If we are using DH/ECDH, we can do the same thing in a much better way.
Let the device keypair be {y, e^y}. The administrator generates a new
keypair {x, e^x) and sends it to the device via some encrypted channel. The
device then calculates the application private key a= x+y. The public key
e^a = e^x. e^y.
The administrator has no knowledge of the application private key. All they
have done is to choose a random number. The device gives no reply to the
administrator so the administrator has learned absolutely nothing. I would
say 'zero' but it is not a zero knowledge proof, it is proof that the
administrator learns nothing.
The same is true of the construction of recryption key sets only this time
we start from a public key pair and split it into two.
Let the group recryption key be {g, e^g}. To add a new member to the group,
the administrator generates a new random value r which is smaller than the
order of the DH group (the prime minus one for DH, different for ECDH).
The administrator then generates the decryption key d = (g-r+o) mod o and
sends this to the user via some encrypted channel. This then allows the
recryption service and the group member to perform private key operations
but only if they both participate. Neither can do decryption on their own.
This time we do not actually achieve zero knowledge but we are very close.
The recryption service only has a random number, it does not have any
information that requires knowledge of the key. Unfortunately, decryption
key has to be communicated to the group member at some point. So we do
create additional information that an attacker could exploit.
This is not a concern for my application as the encryption of the
decryption key blob is at least as strong as the encryption of any message
under the encryption blob. So maybe its blob-complete or something.

@_date: 2018-08-31 14:22:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Need a list of Solinas/pseudo Mersene Primes. 
Awesome thanks!
Writing these docs is a real bear and being able to ask folk for answers to
this type of thing allows me to keep focused on the other bits.
While we are at it, if someone could recommend a good algorithm
implementable in C# for point addition on Montgomery curves, that would be
very helpful. I found this:
The reason this is needed is that I am using the key combination and result
combination properties of DH systems to support Recryption and key
Right now I am using Ed448 for encryption because the libraries define
point addition. I do not have code that implements point addition for
Montgomery curves.
I have something close to code but it needs generic functions that are
common in numeric tools like Mathematica but are not found in C or python
which is what I need for a spec

@_date: 2018-12-09 14:10:38
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Does anyone have info on the Chrome password storage 
I am looking for pieces of Mesh functionality that can be separated out.
One of the most obvious uses for it is to provide a true end-to-end secure
password manager in which the only information stored in the cloud is AES
encrypted data and a bunch of random numbers.
What I want to do is to be able to write a plug in so that
1) When Chrome asks to store a password it stores it in the Mesh
2) When Chrome starts, it retrieves the list of sites for which the
passwords are known from the Mesh.
Unfortunately, trying to find this information turns out to be really
challenging my Google fu as Google has recently announced a technology that
makes it easier for people to use their own password storage tech on their
site which is the exact opposite of what I want.

@_date: 2018-12-18 12:06:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Komitments 
A friend posed the following problem for which I have developed a
cryptographic solution that I would like your feedback on.
While working for Alice, Bob has discovered that Konrad is an enemy agent
and notified Carol the cop. Carol tells Bob not to tell anyone about the
discovery in the hope that surveillance of Konrad will lead to exposure of
his co-konspirators. Meanwhile, Bob would like to be able to prove to Alice
that he had made the discovery after Konrad has been arrested without
revealing anything to Alice before the arrests are made.
The side constraint here being that the scheme must use only simple
cryptographic constructs and not require Alice to have an encryption key of
any sort.
The commitment string, s = "Konrad is an enemy agent"
Naive method.
witness= Base32t ( H (s))
where Base32t(x) is a truncated base32 encoding of the octets (x) and H (x)
is the SHA2 digest function.
The obvious problem with this approach is that it is subject to a brute
force attack. While the commitment string has quite a few characters, many
of them are guessable.
Improved method.
r = random (128)
witness= Base32t ( SHA-2-512 (s + r))
Adding a sufficiently large nonce to the scheme makes the brute force
attack infeasible. This makes things a little harder for Bob as he has to
keep the random value in order to be able to make a claim against the
witness value.
I am sure this has been done before, just didn't see it in the books I
looked at. Is there an obvious flaw?

@_date: 2018-12-18 15:57:25
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Komitments 
I intended the + sign to stand for concatenation, sorry if that was not
more clear.
I guess that what I should probably do to make things clearer still is to
use a HMAC instead of a digest since the nonce has a key like function.

@_date: 2018-12-18 16:12:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Komitments 
Certainly relevant and 20 years old to boot. I like 20 year old papers.
The problem they are solving is rather more complicated as the message is
published and it is the identity of the publisher that is concealed. So
that opens up a whole line of attack that I think I can avoid.
But what I will probably do is to present my protocol solving the simpler
problem first and then show how changing the problem very slightly
introduces a vulnerability into the system. Thus demonstrating that
security by analogy is a really risky and unsafe approach. Back in the day,
Ameritrade had a four digit PIN as the password on their Internet brokerage
accounts because if that is good enough for an ATM... oops.
The hash chain protocol then gives a bridge for talking about BitCoin and

@_date: 2018-12-19 16:54:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Komitments 
Indeed and if a system is going to be any use at all, it has to be
implemented and if it is to be widely used, the human factors considered.
A lot of my frustration with the literature is that if you do a search for
commitment schemes, you get dozens of hits for esoteric protocols with zero
knowledge proofs and such. Practical considerations of the simplest schemes
are much harder to find.
Also, we have a tendency to reach for encryption as our go-to tool even
when the problem at hand is authentication. And rather oddly, the converse
is also true with people proposing blockchain as the answer to every
confidentiality problem.

@_date: 2018-12-22 01:31:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Komitments 
OK, so I have added the capability to the UDF scheme used in the
MatheMatical Mesh:
Just wanted to make sure I hadn't overlooked something basic while writing
I considered a choice of using an HMAC or concatenating the key into the
second Hash operation. I prefer the second approach on balance. While this
is a keyed hash and HMAC is the primitive for that purpose, the
construction of HMAC isn't really that far from the concatenation approach
and this is a lot simpler to implement and debug. I can probably be
persuaded otherwise.
KeyedFingerprint =  + H ( + ?:? + H() +
':' + )
The Mesh is finally at a stage where (parts) of it are useful as a
standalone capability. I am working on the unit tests etc. to nail things
This first release is pretty boring as all it provides are some digest,
fingerprint and commitment capabilities, the last two in a scheme only I
use at the moment. The mesh should become much more interesting once people
can use the Mesh service as an end-to-end secure password manager. The
release plan is as follows:
1) Standalone tools not requiring key management
2) Profiles, key management, configuration on a single device (no service),
Credential Catalog
3) Personal Mesh service, users can only exchange messages between their
own devices.
4) Contact Catalog, ability to send/receive messages with other users.
Over the past year I have cut the number of lines of code in half while
extending functionality. The major simplification comes about from the use
of a cryptographic container based on a Merkle Tree. Yes, it does look a
little blockchainy but I am pretending not to notice.

@_date: 2018-12-27 11:30:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Amongst the requirements for digests... 
I was just looking through some articles on cryptographic digests setting
out the criteria for acceptance and it occurs to me that as specified they
are necessary but not sufficient.
*Pre-image resistance*Given a hash value *h* it should be difficult to find
any message *m* such that *h* = hash(*m*).
That is necessary but I would want h to effectively disclose no useful
information whatsoever about m. Not the number of bits, not the parity,
So I have been designing deranged hash functions that have the correct work
factor but are wrong, wrongety wrong.
So SHA2-Yuk is defined as
H(x) = (SHA2(x OR 1) OR 1) XOR (x AND 1)
Where the boolean operators only act on the last bit in the input.
The intent here is to ensure that the hash values of adjacent inputs are
paired such that H(x) XOR H(x XOR 1) = 1.
This would obviously be a highly undesirable property in a digest but it is
not excluded by our traditional definition of second preimage resistance.

@_date: 2018-02-06 10:49:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 

If the fact BTC hit $22K made you a genius, then the current price of $7K
and falling makes you what exactly? Now that the price is in free fall the
structural flaws inherent in the use of proof of work to finalize the
BlockChain are becoming clear. What we need to make sure of is that the
BitCoin circus and its chorus of ideological zealots don't kill legitimate
strong crypto.
Proof of Work is the worst way to do a BlockChain
Now that BitCoin is going back down to $0 is an opportunity to re-examine
the weakest link in the cockamamie scheme: Use of proof of work to finalize
a notary digest chain.
Notary digest chains (NDC) are not new. The patent on them ran out seven
months after BitCoin was launched. The reason nobody could do anything of
interest with the technology was purely the absolute myopia of Surety, the
patent rights holder.
The only real problem with an NDC is knowing what the last block value to
validate against should be. Harber and Stornetta proposed publishing the
output value daily in a newspaper which in those days were printed on
paper with something called ink.
The simplest way to arrive at a stable NDC value in the real world is to
have a large number of NDCs operate by different authorities. So we might
have NIST, Press TV, NYT, Google, Bank America etc. all run their own NDC
and cross link the output from everyone elses NDC every 30 minutes. This
would make it pretty much impossible for any one party to defect without
the defection being visible. And it is impossible for any party to fool a
party running their own NDC.
The degree of collusion required to break such a system is at a level that
if you can find a single cause that would make all those actors be willing
to defect at the same time then it is probably going to be a good enough
reason that you would agree with it as well.
Given that I have no problem with the fact that my broker could steal
pretty much all my money without me being able to do a thing about it, the
idea that we need worry about every bank and broker defecting
simultaneously is David Ike alien reptile impostor level whackaddodle.
But no, the BitCoiners insist. We must obsess about this one particular
threat to the exclusion of all else because gubermints and the bankers are
evul and untrustworthy and we should instead trust the security of a scheme
with a hole big enough to swallow it whole.
The Achilles heel of proof of work schemes is that the mining capacity
grows in direct proportion to the incentives. BitCoin is like a star that
has to constantly fuse hydrogen into helium to create the outward pressure
necessary to prevent its collapse under its own gravity. When the price of
BitCoin hit $1000, the mining capacity expanded and the difficulty
increased so that the cost of mining increased to keep the system in
And here we get to the interesting bit: Tether. If the price of BitCoin was
denominated in real money, the system would have to be constantly sucking
real money in to sustain itself. BitCoin does require quite a large amount
of real money to pay for the electricity to fuel mining rigs which should
in theory prevent the type of rapid price rises we have seen. But the price
of BitCoin is not denominated in real money, it is denominated by a
hypothetical currency called Tether which is alleged to be backed dollar
for dollar with real USD but as with much else in the cryptocurrency world,
this claim has never passed a third party audit.
Tether became a necessary part of the cryptocurrency world when governments
started to make it difficult to move real currency into or out of the
system. A large fraction of the cryptocurrency exchanges do not cash out
BitCoin to actual dollars, they only cash out to Tether which might or
might not be exchangeable for real cash when the time comes.
It is rather curious isnt it that a scheme which in theory frees us all
from the tyranny of having to trust financial institutions instead puts us
at the mercy of an unregulated, unaudited shadow banking system whose
architects pride themselves on their ability to make themselves judgement
There is an old poker adage that if you cant see the fool at the table,
its because its you.
So now we have a perfect storm of a government crackdown on BTC and its ilk
and the largest drop in the history of the stock market. And these are of
course interconnected. The BTC bubble has grown to a size where central
banks around the world are forced to consider the impact when it bursts.
BTC is currently below $7K and looks set to lose a quarter to a third of
that today. We are getting perilously close to the point where the only way
to make money out of BTC mining rigs is to attack the blockchain itself and
use surge mining on a 51% attack to unwind previously committed
The way this works is that the attacker makes a series of large BTC
transactions which are committed in the original blockchain and then
repudiated a few hours later by mining a different fork.
This particular attack can only work if the attacker has at least 51% of
the mining capacity. And here is the problem, while obtaining 51% of the
total mining capacity is very hard, obtaining 51% of the active mining
capacity in the wake of a pullback is potentially rather easy.
Bitcoin mining difficulty doubled between 5th December 2017 and 29th Jan
2017 and so did mining capacity. Over the same period, BTC price declined
from $16K to $11K but this merely shows that total mining capacity lags
price somewhat. If we map peak to peak, it appears that difficulty lags
price by one to two months which is what we would expect.
The danger point is reached when the price of BTC drops below the cost of
mining. At that point the least cost efficient rigs will be idled and the
active capacity will drop.
As with any other bubble, what keeps BTC price high is irrational
expectations. All it takes to cause a collapse is an irrational fear. Any
long term decline in the hash rate is going to raise concern that a 51%
attack may be attempted.
BitCoin ideology has an answer to this issue of course. Ideologues always
do. The fact that I chaired a conference on Digital Cash in Amsterdam a
quarter century ago is irrelevant, my opinion on the topic is uninformed
and I need to educate myself and do some research. Strangely enough,
none of the people who used to argue that BTC=$20K proved them to be
experts seem to have concluded that BTC=$7K has any significance.
Of course BitCoin will adapt. Only BitCoin cannot change because the
whole value proposition to BitCoin is precisely the fact that the rules are
embedded in the code and nobody can change it. Either BitCoin eliminates
intermediaries or it does not. I for one see no value in swapping a world
in which the financial rules of engagement are set by entities such as the
Federal Reserve which are subject to at least some oversight and
transparency for one in which a shadowy cabal of crooks and conmen set the
rules while denying that such a thing is even possible.
Of course other coins will replace BitCoin. Only there is really no
reason to believe that any alt.coin will survive the collapse in confidence
in cryptocurrencies as a system that would follow a collapse in BitCoin.
Of course fiat currencies are also a consensual illusion. But so are
governments. In all of human history, there is only one major instance in
which governments suddenly collapsed because the people withdrew their
consent. It was 1989 when communism collapsed in Eastern Europe because the
people withdrew their consent. And the unanimous first demand of those
people? A new government.
The approach used by BitCoiners is the same 'Mao Mao' tactic that used to
be popular with parts of the far left. As soon as an unacceptable opinion
was voiced, it was shouted down with cries of  'Mao Mao Mao'. It is
essentially the same tactic George W. Bush used to start the Iraq war and
the one Trump is attempting to use to start a war on North Korea.
I have seen this story before. I never invested in WebVan or Pets.com or
any e-tail dotCom because it was obvious that the stories they were telling
simply did not make sense. The grocery business is notorious for its wafer
thin margins. Companies like WalMart and Costco are only able to turn a
profit because of their aggressive use of sophisticated high technology in
their distribution chains. It was obvious nonsense to suggest that a
capital intensive online only operation could make better margins on online
sales than paying a shelf filler to wheel a shopping cart round an already
bought and paid for store. Today, the market is making the rather absurd
proposition that Tesla, a company that has yet to make a profit on a single
car it has made is worth 50% more than Ford which sells ten times as many
cars and sells them at a profit.
The notion that cryptocurrencies will somehow revolutionize the business
of finance is not just a part of the sales pitch, it is the whole of it. It
wasnt just Pets.com that was crushed in the dotCom bust, even mighty
Amazon crashed from $90 to $5. I find it really hard to believe that
Etherium or any of the other coins purportedly better than BitCoin are
different enough to survive without BitCoin.
Popping a bubble as it inflates is always a lose-lose proposition for
government regulators. They will be blamed for allowing the bubble to
inflate that far and blamed for the consequences of its collapse. The
ideology of BitCoin and in particular the aggressive opposition to all
forms of government interference raises the political cost of
interference further. But the recent decline in price by two thirds have
given regulators both the opportunity and incentive to make sure that the
bubble is on no account allowed to re-inflate.
Fed to BitCoin: You have fallen and now I am going to give you such a
kicking to make sure you never get up.
So now we appear to be in the end game for BitCoin and probably for
cryptocurrencies in general. It is of course possible that BitCoin might
stage another rally, but the technical analysis (and what else is there?)
suggests a continued decline. I may well be wrong in expecting the bubble
to finally burst this year, after all, I predicted the dotCom bubble would
burst in 1997, 1998 and 1999.
What I think important is that we dont let the collapse of BitCoin take
cryptography with it. NDCs are a very useful invention, an invention that
existed long before BitCoin and an invention that should survive long after
BitCoin ideology meets its well deserved end.

@_date: 2018-02-18 00:35:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proof of Work is the worst way to do a BlockChain 
As someone working closely with Microsoft's anti-spam team at the time,
including working on a joint proposal very similar to DKIM that was never
launched, I am pretty sure that proof of work never played any part in
their strategy beyond the fact that Adam Back may have been working for
them at the time.
The achilles heel of proof of work was that it would merely give the
spammers incentive to hack machines to generate proofs on. There would
never be a point where proof of work made an email less likely to be spam.

@_date: 2018-02-27 23:38:46
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Any reason not to use key derivation to determine IV? 
I am doing some work with a JOSE-ish encryption container. The traditional
scheme is
Generate symmetric master key
Encrypt master key under recipient(s) public key to create key blob.
For each chunk of data to be encrypted:
Generate session key
Wrap (i.e. encrypt) session key under master key.
Derive encryption key from session key, generate random IV
Now usually in JOSE, these are options. Well, I do not believe in options.
I would rather have as few code paths as possible. So rather than make the
keywrap step , I always require keywrap, I always require keygen. that way
there is only one possible way for A to talk to B with a particular set of
I sometimes need key derivation, (e,g, when I am stepping up from 128 bit
to 256 bit or when I have encrypted metadata) So I always require it.
Now given that I need the key derivation step, is there any reason not to
use it to generate the IV as well as the encryption key?

@_date: 2018-01-01 12:44:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Hashgraph 
It is not clear what SwirlID are claiming. They certainly cannot claim the
idea of cross linking multiple independent Harber-Stornetta notary logs.
People have been discussing approaches to doing that for years. The
original CT specs had in them the notion of chattering between the logs to
bind them into one.
I am not sure why consensus is desirable other than trying to reconstruct
Blockchain ideology without mining.
Let us say BofA, Chase and Barclays are running a notary chain and they
cross notarize every hour. All that means is that when I make a
transaction, on the BofA chain, then BofA could in theory repudiate it in a
60 minute (max) window and for that 60 minutes I have to trust BofA. So
what? I already trust my banks with my money.

@_date: 2018-01-02 16:40:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Hashgraph 
Given that setuid was one of the very first software patents, the notion
that it was filed as a defensive measure sounds like an example of
revisionist history to me. 
Bell labs existed to file patents and software patents did not become
notorious until much later. UNIX did not become an open system until much
later on, all the early UNIX flavors were licensed from AT&T.
Yes, defensive patents are common today but I can't see SwirlID being
likely to have amassed the millions of Venture Capital they have without
promising rewards.
At the end of the day, the voluminous prior art of the Certificate
Transparency 'gossip' proposals is likely our best defense.
The big problem with US patents is that you can use a technology for a
decade while an application is varied to thread itself through the eye of
the needle. So when assessing patent risk it is the potential claims, not
the actual ones that are the issue.

@_date: 2018-07-03 21:59:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Non-deterministic PRF as a MAC-and-Nonce for 
Everyone needs their hand held. Everyone.
I have seen enough screw ups to know that Crypto is something best done as
a team exercise.
To the original point, back in the 1990s it was ok to just design a
protocol that was secure when implemented properly. That is no longer the
case and we demand protocols to break gracefully.

@_date: 2018-07-06 14:11:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Encrypt then Authenticate, Why not have both? 
So I have been struggling with that perennial question of whether to
Encrypt then Authenticate or Authenticate then Encrypt. There are pros and
cons to both and there are equally vehement exhortations on both sides.
One factor that does play into this is that it is easier to create proofs
of security for one than the other. While that has to be considered as a
factor, I don't think it should be the only factor. I studied formal
methods for my doctorate, I know their strengths, I also know that they
have weaknesses. In particular there is a tendency to design to the
capabilities of our proofs rather than to what is secure and robust in
The problem with Encrypt then Authenticate is that there is no evidence
that the party authenticating saw the actual data. This purportedly creates
serious protocol level attacks. Though I don't quite see how they produce
practical issues unless there is another failure in the protocol.
The problem with Authenticate then Encrypt is that only parties that are
able to decrypt the data can authenticate it. I would like to be able to
check the signature on a message before I let it near any sort of private
So here is what I have come up with.
A DARE container is a sequence of records presented in an append only log
format. The log format provides Merkle Tree and Chain digest capabilities.
Individual records from a container may be extracted and presented as a
DARE message which is a self contained unit containing all the
cryptographic annotations (signatures, recipient blobs, etc) required for
Records and messages consist of a header, a body and an optional trailer.
Headers may contain multiple encrypted data sequences and even encrypted
headers. This allows a recursive approach to encrypting the body data for
Kimono protocols.
Encryption and Signature may be applied to individual records or to
non-contiguous records in the same container. The only constraint being
that the key exchange has to be written before the first record encrypted
under it and the signature has to be written on or after the last.
This provides a mechanism that is perfect for encrypting log files. A
single key exchange can be amortised over a sequence of log entries. It is
even possible for two different processes to write to the same log file
simultaneously, provided that the individual record writes are smaller than
the atomic write primitive of the O/S (believed to be 4096 bytes for
everything that matters).
The cryptographic processing pipeline for the body has four elements:
MAC -> Encrypt -> Package -> Digest
Keys and IVs are derived from a master secret by means of a KDF and salt.
Each record has a unique salt of at least 128 bits. Each encrypted data
item (other than the body) has a unique salt suffix. Thus erasing the salt
is sufficient to prevent decryption of the encrypted data and does not
disrupt validation of the container contents using the digest.
Since this construction means that a party cannot know the MAC Key unless
they know the Encryption key and vice versa, I suspect the order of MAC and
Encrypt no longer matter.
The Digest is only computed over the message body and nothing else. If an
application needs to sign something, it has to present it as a message body.
This requirement is important as it allows headers to be manipulated after
the fact. Signatures can be added or removed, A container can be redacted
so that it only contains a subset of authenticated records and the
cryptographic data moved to the position it is required. This could prove
useful in file archive formats, an application updating itself just syncs
the records that have been updated since it last synchronized, ignoring any
that were deleted before it could synchronize. If storage is scarce, the
archive may be periodically purged to eliminate deleted items.
Great care has been taken to ensure that DARE Messages can be written out
in a streaming mode without the need for unbounded buffering of data. This
is not true of containers which requires the final length of a record body
to be known before the record is written. So streaming of video data would
require streams to be split across multiple records.
Anyway, so to my question. The scheme described provides the cryptographic
capabilities I require but is subject to the semantic substitution attack
in which Mallet signs a message that was written by Alice and this allows
him to impersonate Alice 'somehow'. One possible approach to preventing
this attack would be as follows:
* Header of first signed record contains the list of signing keys that will
be used to sign the message.
* The digest of this value feeds into the message Salt in some verifiable
* The Salt feeds into the signature in some fashion.
If the protocol requires the signer to be authorized by the party that
performed the encryption, it checks to see that the key is listed.
I am also looking into ways of locking the Salt values into the payload
digest value so that it is possible to verify container structure
efficiently without calculating the payload digest.

@_date: 2018-07-26 10:33:19
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cryptokitties: When you've still got money to 
I proposed a cryptocurrency monetized on pictures of kittens five years
ago. All I have is the domain. Willing to sell to anyone who will give me
$50,000 in cold hard cash.

@_date: 2018-06-28 14:20:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Wi-Fi WPA3 announced 
There is a good argument to be made for 256 and 128 bits. I have never
seen a good case for 192.
The case for 128 is that it is the bare minimum required to make the brute
force work factor infeasible on traditional machines. The case for 256 bits
is that it provides a safety margin for quantum resistance.
The number of rounds is 10,12 and 14. for 128, 192 and 256 bit keys. At an
RSA, Adi Shamir suggested that NIST increase the number of rounds in 128
bit AES to provide something of a safety margin. Which is why I always use
256 for my work.
I cannot imagine anyone using a quantum computer to break link layer
encryption (which is what WPA3 is) but then neither can I imagine the range
of uses and abuses people will put WPA3 to.
I would have gone to 11. Even on the smallest devices, I don't know of a
situation where 128 bit AES is acceptable but 256 is not. I know plenty of
cases where AES won't work at all but none so close to the edge that 40%
extra time is significant.

@_date: 2018-03-07 01:05:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] How fast can a blockchain go ? 
The real question is how fast can you finalize a transaction so that it
is fixed. Blockchain is a silly way to do that because there is a ten
minute gap between blocks being added and the chain does not become
dependable until several blocks are added.
I have not benchmarked my stuff but the only real limit is how fast the
database can serialize transactions. I see no problem getting 10K
transactions a second per node. The number of nodes is essentially
unbounded and a node can cross-link with another at any time.
Hashgraph and others are developing similar structures.
If someone needed a blockchain fast enough to keep up with the NASDAQ, it
would be reasonably straightforward to do. Just spend enough cash. The
transactions only settle at the end of the day and there are intermediaries
who hold liability during the day. So the system is kept in check.
The under appreciated part of BitCoin is the smart contracts. They don't do
much in Bitcoin world because it isn't really connected to anything real.
But if you were doing a system in which party A exchanges money/stock with
B and each then want to trade with C and D, you could use conditional
contracts, this one is good if node X has fixed point Y.

@_date: 2018-03-18 11:56:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Avoiding PGP 
Perfect? Good grief... only if you haven't used any application developed
since 1995 or so.
If you think it is perfect you understand nothing about usability. When
people blame the users rather than the developers, they are always wrong
because the users have no ability to change anything, only the developers
I was utterly dumfounded when I used the GPG plug in and received my first
encrypted email and had to tell the app to decrypt it. No, that is not
WoT sounds great until you realize that most people just use the keys on
the MIT key server and make no effort to validate them whatsoever. So
really good trust has been downgraded to none.
There is no infrastructure to manage private keys for users so they can
receive mail on multiple devices. PGP/MIME isn't really standardized, etc.
S/MIME has problems as well. And the biggest problem of all is the format
war between the two is still going on.
Neither is fit for purpose today. If not for the standards war, I would say
lets fix one or the other but that isn't possible when one has mindshare
and the other has deployment. We never really got past the VHS/Betamax
standards war either, that was ultimately decided when Sony started work on
What I am trying to do with the Mesh is two step:
1) Make it as easy as possible to use PGP and S/MIME today by performing
all the private key operations for users, automating all the make work
maintenance tasks etc.
2) Introduce a new secure messaging infrastructure that provides
functionality neither PGP nor S/MIME offer, that is group messaging and
document level encryption. The infrastructure that lets you securely share
your Word and Powerpoint documents online can also be used for
intra-enterprise mail and messaging and is secure and can also be used
externally because it is an open standard.
Users win because they get secure messaging apps that are exactly as easy
to use as their current insecure apps.
Enterprises win because this is security people will use.
Vendors win because they can sell new stuff even if it isn't strictly

@_date: 2018-05-14 11:14:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Attacks on PGP (and allegedly S/MIME) 
There is a new attack going round. Whether it is significant or not is
debatable since it rather depends on the plaintext of the ciphertext being
attacked being a URL fragment. But still...
Rather more interesting is the gadget attack. I think this is further
support for my approach of using a key derivation function to obtain the
encryption, authentication keys and IV from the session key.

@_date: 2018-05-17 08:33:31
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Attacks on PGP (and allegedly S/MIME) 
I am even stronger than Stephen on this. Basically, if your security
product requires the user to think AT ALL then is it utterly useless. Users
have real work that they are thinking about and if you are distracting
them, you are going to be ignored.
Very often, I am asked to do security related tasks that require ME to
exert effort to protect an asset belonging to someone else who is not
paying ME to protect it. So I have absolutely no qualms about putting 0%
effort into making sure it is secure.
As was pointed out by Jim Schadd in another place, the HTML email RFC
requires that each HTML text be in a separate document. It was never legit
to split HTML over MIME boundaries. I know of no situation in which a MUA
is likely to generate such an email, the only sender likely to ever do that
is an attacker.

@_date: 2018-11-01 09:21:09
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] hash size 
This is something I have spent quite a bit of time thinking about in the
design of the Mesh.
The only digest algorithms I use in the Mesh are SHA-2-512 and SHA-3-512,
truncating to whatever number of bits I need to achieve the necessary work
factor. The Mesh uses UDF fingerprints which are presented for human
readability in Base 32 with as many digits as are needed to provide the
desired precision:
   Text Presentation (100 bit)  SCFIN-CQGDR-KG47R-7OVPZ
   Text Presentation (125 bit)  SCFIN-CQGDR-KG47R-7OVPT-TCHZ5
   Text Presentation (150 bit)  SCFIN-CQGDR-KG47R-7OVPT-TCHZ7-UXY4I
   Text Presentation (250 bit)  SCFIN-CQGDR-KG47R-7OVPT-TCHZ7-UXY5S-
      CFSMN-YBKBP-FELHX-I56EH
The scheme also allows for compression. If the first 25 bits are all zero,
there is an efficient way to express this that saves five characters.
How many bits do you need though? It really depends on the work factor you
require to prevent an attack against a particular use.
When people are exchanging credentials peer to peer, then 100 bit work
factor is probably acceptable (today at least). But 125 bit is obviously
The truncation mechanism is deliberately designed to allow users to
truncate the UDF by truncating the string. This allows for fingerprint
strengthening. if a short UDF is matched against a long one, the longer
representation is stored for future comparison. This allows use of a
shorter representation for user interface tasks without compromising future
25 characters (125-8 bits) are acceptable for a business card. 50
characters (250-8 bits) probably aren't.
The other use I make of digests is to create strong internet names (SINs).
This is a DNS name that contains a UDF fingerprint of a security policy
statement that controls the interpretation of the name. So if SCFIN-- is
the fingerprint of the ICANN root cert (it isn't), we can create an
absolute SIN that says 'validate this against DNSSEC'
alice at example.com.mm--SCFIN-CQGDR-KG47R-7OVPT-TCHZ7-UXY4I
Or if we want to have our own root, we can do that instead, which means
that we can create DNS names that are absolute and independent of any
Trusted Third Party. (NB, I no longer work for a CA).

@_date: 2018-09-01 15:25:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] WireGuard 
The problem with a lot of the approaches is that the folk proposing them
start from the objective of eliminating all dependence on third parties,
not minimizing risk.
Governments are bad, CAs are bad, yak yak yak, chunter, chunter, chunter,
etc. etc.
The Web PKI was designed to authenticate and authorize Web sites. The
encryption part was merely a byproduct. The original design brief was to
make shopping online at least as secure and convenient as offline.
I find it rather interesting that some folk who were not part of those
discussions try to lecture those of us who were. But I digress.
I think that we could make key pinning practical but it would require folk
to limit their objective to protecting the user and require them to be less
absolutist about support for corner cases.
Remember that when all is said and done, Google, Mozilla, Apple, Microsoft
or whoever will be the third party you trust, likely two of them plus your
AV provider.
The question to ask is what to do if a certificate is presented that does
not meet the key pinning criteria. And this is a policy that the key
pinning mechanism should allow the subject to specify ranging from, 'accept
an alternative cert provided it is EV to require countersignatures from
five EV CAs to 'shoot me in the foot, I have a death wish'.
Remember that any subject security policy can always be overridden by your
browser provider and/or your platform provider.

@_date: 2018-09-02 22:17:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] WireGuard 
The number of active CAs is more like 50 and declining rather than
increasing. The EFF study that found hundreds was based on a fundamental
misunderstanding of how PKIX works. The fact that they never retracted the
false claims after the flaws in their methodology were pointed out is a
useful reminder that just because someone says they are on our side doesn't
mean they are.
CAs are now required to process the CAA record that I proposed in 2010
which addresses the issue you raise.
Every security problem has an easy solution provided you decide to ignore
all the other problems. The problem with pinning proposals was that they
didn't want to face the fact that operator error is a real concern and if a
site ends up offline because of it, the consequences are usually rather
more serious than most attacks.
If I was going to revisit this issue, I would propose enrolling the CAA
statements in the CT logs.
It enabled Amazon and online commerce. It has worked for 20 years. Nation
state attacks tend to be mitigated by their reluctance to get caught.
Though not always. Skripal was obviously attacked with the nerve agent to
leave no doubt as to who was behind it. Though that game is rather more
desperate and higher stakes than most.
That is certainly not true. Browser vulnerabilities are so common that they
aren't even news.
It is rather difficult to know whether any AV software has been an attack
vector but we do know that Kaspersky's son was kidnapped and then returned.
And we know that their AV agent runs in god mode on the machine, same as
any other AV does.

@_date: 2018-09-04 10:56:42
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] WireGuard 
Exactly my point. The pinning stuff looks like it was designed by folk who
start with the notion 'lets shoot all the lawyers (CAs)'.
That has not been a very productive approach in the 30 years we have been
doing commercial PKI. I have a similar problem with Blockchain, instead of
reforming how we exchange money and make that cheaper, BitCoin attempts to
redefine what we mean by money.
Security is always a property of a system and never a property of a
component in isolation. It is trivial to solve almost any security issue in
isolation. So when people are talking about 'implementation details' they
are ignoring the fact that it is all the details that are the issue.
I am pretty sure that when we get hold of the NSA BULLRUN manual it will
say something like 'identify key details that will render the protocol
unusable if neglected, use your influence in the working group to ensure
that they are neglected and work to isolate and marginalize WG members who
demand they be considered'
It wasn't just myself who was made unwelcome in the DANE WG, they also made
sure Ben Laurie at Google knew his input would be ignored and made sure
nobody from Microsoft or Apple was involved. So they ended up with a spec
nobody will ever implement but will squat on the 'security policy in DNS'
slot until someone deploys something ignoring the DANE work. The same
individual who made sure DANE went down that path did the exact same thing
on DPRIV. Now I am not saying he was the NSA mole but he was almost
certainly one of the people the NSA mole knew to manipulate.
I don't think the NSA is doing that any more as it is realized that the US
lives in an impressive glass house and the cyber command operations are
throwing stones. There is never going to be a return to the 1953-1973 era
when the NSA ability to break mechanical ciphers allowed the NSA/CIA to
stage coups from Iran to Chile. Blocking deployment of strong cryptography
left the US vulnerable to Putin's attacks.
What should we do instead? Well first, we should define ONE way for an
Internet client to discover an Internet service and associated description.
Most of this work is already done by Stuart Cheshire and Co at
Apple [RFC6763]. I describe how to apply this to Web services here:
DNSSEC is an absolutely rotten trust infrastructure as there is only one CA
and it is vulnerable to being ordered to defect by one nation state. But if
you ignore the issue of who signs the root and TLD zones, it is pretty much
OK for the purpose of signing SECURITY POLICY.
"Always use TLS 1.2 or higher"
"Certificates MUST be validated under trust roots A AND B"
To address the problem that ICANN can't be trusted, see Strong Internet

@_date: 2018-09-04 10:31:33
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] WireGuard 
I said 'tend to be'. The US govt has been risk averse in this respect, the
Snowden papers clearly show that they did exactly what they thought they
could get away with without being caught. Which was a heck of a lot!
The Iranian govt had a different objective in that they wanted their
population to know that they were being watched. In fact that was their
chief goal above and beyond actually catching people. If they catch people,
they have to do something with them and that is actually rather hard in the
Shi'ia theology because the legitimacy of the ruler depends on how they
The problem with the Iranian approach is that it was externally visible and
didn't last very long as a result. It lasted for a critical period when the
regime was under huge pressure though.

@_date: 2018-09-04 12:44:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] WireGuard 
The cheapest and most effective attack on BitCoin or any other system of
its ilk is probably to infiltrate some of the tech-bro sex parties and drop
the tapes on the net.
Like PRISM, we all know what is going on and who is likely involved and the
likely effect of it becoming public knowledge, but knowing and being able
to prove are two very different things.
Yeah, very few of us would be surprised or offended. But couple those
activities with some of the other things certain tech bros are accused of
and maybe there is a PR issue. What is consensual between peers becomes a
problem when there are power differences. Elon Musk recently discovered
that when you are a CEO, a joke tweet can lend you in jail, it will
certainly lead to expensive lawsuits. Well maybe some other CEOs are in for
a learning experience.
People are not going to stop buying phones, playing video games or using
social media. But they might just question the notion that techtopia is the
place they want to be taken and they will almost certainly question being
taken there by the tech bros. I don't think any company with a solid P/E
need worry but those are not the companies that I hear about in relation to
this stuff. Those are the ones that manage to trade for decades losing
money hand over fist. Uber was the first domino.
When it comes to losing money, Bitcoin requires miners to sink several
billions of dollars a year into a startup that will never ever produce any
thing of value by design.

@_date: 2018-09-06 21:39:38
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] WireGuard 
I am not so sure how extensive use of IPSEC is for security though.
The main reason I use VPNs is that they are the only cross-platform means
of proxying the IP stack so you can access from different geo-IP locations.
I would not describe IPSEC as a standard as it is difficult enough to get
OpenVPN to talk to OpenVPN.

@_date: 2018-09-09 18:05:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] WireGuard 
No folklore. Some people just have miserably low standards for
documentation and usability.
A product is only as good as the first five how to guide that appear in a
Google search for help.

@_date: 2018-09-30 12:57:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Did Spectre help torpedo Qualcomm? 
============================== START ==============================
There are a few applications and a few deployments in which SPECTRE might
lead to a compromise. Most of them are SSL private keys leaking in
co-located Web server environments.
As far as cryptography goes, just do all your private key operations on
trustworthy hardware, problem solved.
I suspect that a much bigger issue for Qualcom resulting from SPECTRE would
be that Intel suddenly required a large number of additional engineers and
were willing to almost pay anything to get them.
Before doing crypto, I did massively parallel computing. People should
probably start revisiting the Transputer architecture. Take a processor
with 16 cores, 16GB Ram and a 512GB CF Express card and you have a server
in a module the size of a 2.5" disk drive. Add a couple of 10GB Ethernet
ports and your only real problem is how to dispose of waste heat.

@_date: 2019-04-03 12:41:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Master key rollover in the Mesh 
One of the key simplifications I made to the design of the Mesh was to
eliminate certificate expiry which provides little real utility and causes
a dramatic increase in complexity.
If a user only uses their master profile key to periodically authorize
administration devices, what does it matter if it is valid for 50, 100
It has since occurred to me that I can in fact support a key rollover
mechanism using the key combination law that ECDH (and all DH variants)
supports and enrollment of the profiles in an append-only notarized log.
So imagine for the sake of argument that the user's original master
signature keypair is {a, a.P} and her fingerprint is therefore H(a.P). She
enrolls a profile containing a.P in the notary log.
Alice can now generate a new master key {b, b.P} and enrolls a rollover
assertion in the notary log. This is an assertion signed by key b. that it
is a rollover of the key a.P which it proves by providing the value (b-a).P.
One of the rules of the Mesh is that master keys are only ever used to sign
administration keys. And the reason you would probably want to be able to
rollover the master key is to revoke authorization of an administrative key
that was lost.
So we are going to need a little bit of glue to save the appearances here.
But we only need to play about with the key composition law etc when we are
validating the administration key.
I have not fully worked out the best way to apply this. But at least in
principle, we have a mechanism that can be used to disable use of a master
key and replace it with a new one.

@_date: 2019-04-06 16:56:13
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Name for three key ECDH 
One of the features I am using in the Mesh is the an authenticated and
encrypted ECDH mode. I will explain in discrete log but y'all know what I
mean here.
One of my hold ups here is what to call this exchange.
I am trying to tweak this to get the desired properties.
* Every message should be authenticated under the sender's key.
* The communication should not create a non repudiable proof of the
involvement of either party
* All communications after the first request to be encrypted
* Enable pre-calculation of the exchange on the client side to the greatest
extent possible
The last was something I was thinking about this morning. If I have a light
bulb and it is using a stream cipher, I don't really need to wait to do any
of the calculations normally required to encrypt a request. I can prepare
the 'encryption' part of the request when the device turns on and
immediately after a message is sent.
So Alice has long term credential {a, A (= e^a mod p)} and the service has
long term credential {s, S}. At the start of the communication, Alice does
not have the Service credential but we assume she can authenticate it from
a fingerprint or whatever.
There isn't much Alice can do until she knows the public key of the service
except send her own public key. We generate a nonce n_A and use it to
create a blinding function N_A. The key that we will use is (A.N_A) mod p.
Alice-> Service  [ A, N_A, Cert-of-A ]
At this point the Service can verify A is properly certified and calculate
the client ephemeral key (A.N_A) mod p. This has exactly the same
properties as a normal ephemeral DH exchange but with the additional
feature of having authenticated the source.
The Service also generates a nonce n_S and responds to Alice
Service -> Alice [S, N_S, ID, E (payload, k) ]
Where k = KDF ( e^((a+n_A).(s+n_S))) =
    KDF ((S.N_S)^(a+n_A)) =
    KDF ((A.N_A)^(a+n_S))
This is then used as the shared secret for future exchanges. ID is an
identifier for this master secret which may be a Kerberized ticket.
The protocol requires that the response be either encrypted or
authenticated with a MAC. (Or else why bother with a key exchange at all).
Since I use a key wrap with integrity checking, there is no need to provide
for a separate check (though I could add one if needed).
The DARE Message Format never uses the master key for any purpose other
than key generation which is keyed with a unique value on each use.
The exchange as I currently have it does not actually achieve the first.
The request could come from any party which is OK if this is merely for an
initial 'hello' null transaction. Is there a cheap means of providing for
this authentication that does not amount to a signature?

@_date: 2019-04-13 11:02:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Making scenarios realistic 
The point of it all of course is that Alice and Bob aren't Turing machines,
they are people.
So the reason Alice and Bob are worried about Eve overhearing their
conversations is that Alice is married to Eave but she really wants to have
an affair with Bob who is really interested but a little worried that Alice
might turn out to be an axe murderer. And yes, Alice does have an axe
hidden under her bed because she is 4'11" tall weighing less than 100lb and
Bob is the Naval mixed martial arts champion.
So unknown to Bob, Alice enlists the help of Carol the cop and engages in
some protocol to escrow contact details with her in such a way that these
will only be released if Doug doesn't see Alice the next morning. Only
Alice doesn't really want Doug to know that she is doing this unless it
turns out to be necessary because Bob is Doug's Ex.
Now a particular constraint we wish to enforce here is to ensure that Carol
only obtains decryption warrants in very specific circumstances and not
because she might try to blackmail Alice threatening to tell Eve about Bob.
My point here is not humorous. These are the real problems people face in
the real world. Security protocols that assume all the actors are operating
openly and in good faith to all are brittle. Given what people really use
the Web for (Tindr, Grindr, Club Penguin, FetLife), I am astonished that we
don't have an epidemic of serial killings and missing persons (unless of
course we do and nobody noticed because everyone is focused on whatever we
are focused on).
I also have this follow on scenario in which Alice and Bob ask Phill the
photographer and Vinnie the videographer to join them and share the events
with exactly a dozen of their very close friends without Eve finding out. I
am not sure if that one really has a solution but people ask me about that
scenario all the time.
Ooops, sorry. Nobody has ever asked me about it, they just did it anyway
knowing that there was a risk even though they were worried about it at the
The cryptography is the easy part. I have running(ish) code that addresses
all of these. The hard part is working out what the scenarios should be.
Perhaps a business model for a Web MetaNotary is selling the key escrow
service to Alice.

@_date: 2019-04-15 11:27:42
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Making scenarios realistic 
I have made no such decision and I will just point out that most folk who
have claimed they know what my business model is have proved to be wrong in
the past.
The paper is from 1997. Think about that for a while. Back then we thought
that the biggest issue any crypto system had to address was how to
absolutely guarantee any possibility that the FBI could gain any imaginable
advantage in any circumstance whether realistic or not.
Yes, I know that the paper addresses the legitimate uses of local escrow
and if you look at the architecture I have in the Mesh, it follows largely
the approach suggested. But the paper itself was written as a rebuttal to
Louis Freeh when he was approaching peak crazy. A few months after it was
written, Freeh conspired with a corrupt prosecutor to impeach a President
in revenge for being snubbed on the key escrow issue.
It was ideology, not security.
And it hurt us badly because instead of actually solving real problems
people needed solving and delivering products that they could use, we
insisted on addressing really difficult problems like end-to-end secure
email and sneering at partial solutions such as transport security.
STARTTLS is pretty much the only email security in place today. We got it
ten years later than we could have had it and we ended up with end-to-end
email take up of about 2 million S/MIME and 2 million OpenPGP users having
registered a key - about -.1% of users. and they use it for maybe 1% of
their email.
We spent inordinate amounts of time making sure that IPSEC delivered
'perfect' forward secrecy and as a result delivered a specification that
still doesn't actually work out of the box, is a pig to use and can only be
made tolerable with proprietary hacks.
Ideology does not deliver security.
As with the end-to-end arguments paper, this is a paper that is shared far
more often than it is read. The arguments made in the paper are not the
same as the ones that people seem to think. I suggest people read it. They
may well be surprised.
That said, it is a pity that the group didn't include any people with
experience of running a commercial CA. Otherwise they would know that there
is actually a very solid reason for escrowing signature keys and every CA
makes use of it. On the other hand, very few people were doing that in
1997. I wasn't one of them then.

@_date: 2019-04-16 16:14:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Making models + scenarios realistic 
The Mesh is infrastructure. The threat model for infrastructure is not the
same as the threat model for applications. It is not even clear to me that
there should be a threat model for infrastructure. It is probably better to
think in terms of security considerations because requirements inevitably
The risk of generalizing scenarios is that the details may be the important
part. The reason I specified Alice was 4'11" was because I wanted to point
out that she was physically very much smaller than Bob and that is likely
to be very significant for a scenario in which they are attempting to have
casual sex without anyone else finding out without the risk of either rape
or an axe murder.
It is very tempting to look for the 80/20 rule and try to find the middle
path. But the problem is that none of us is normal. Attempts to find a
family that matches the 'average' on more than a handful of counts (average
income, average number of children, etc) quickly results in nobody
matching. Human populations are diverse and so are their security
Whenever I make a protocol suggestion, the counter-arguments that are
invariably made have to do with limited access in rural African communities
using obsolete equipment from the 1970s. This despite the fact that there
is probably not a single Vax 11/780 in operation on the entire continent
that is not kept as a collector's piece. Obsolete infrastructure
accumulates in the places where the infrastructure was first deployed. More
recent deployments leapfrog to the newest technology.
So I think it important that infrastructure be neutral with respect to the
assumptions it makes about security tradeoffs. We all face the same CIA
triad but the concerns are very different depending on who you are.
Confidentiality is almost invariably over-prioritized. Unless you happen to
be a field agent engaged in espionage, Integrity trumps Confidentiality and
Availability trumps both. And if you are a field agent, your need for
confidentiality is so great that you require steganography as well as
The main reason I don't use data encryption as much as I might is because I
do not trust the recovery systems. The risk that someone might view
confidential material is a lot less important to me most of the time than
the risk I might lose the data. So personal escrow has to be a tool that is
available in an infrastructure to manage key pairs for personal use.
The chief concern in the escrow department is coercion. If I set up a key
escrow scheme for my use, I can be coerced into revealing the data. Is that
something I want to risk or not? That is my decision and mine alone and my
user's decision and their's alone. It is not for me to presume to
understand their security concerns so fully as to decide them for them. I
can help them make an informed decision and I can establish infrastructure
which ensure that third parties that they may decide to rely on are held
accountable for their actions. But it isn't my place to live their lives
for them any more than it is my place to suggest to Alice and Bob that
their affair is a really poor choice on both their part but especially on
Bob's part because Alice is a psycho with an axe under her bed for Odin's

@_date: 2019-08-13 11:12:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Mathmesh mailing list 
The IETF has started a discussion list for the Mathematical Mesh in
preparation for a Working Group forming BOF at the Singapore meeting in
We should get started on the discussions later today. People here might
want to subscribe ahead of time.
mathmesh at ietf.org
Subscription page:
The Mesh is two separate things at this point
1) A protocol that makes it easy to manage private keys (and other
application configuration data) across a user's devices.
2) The cryptographic platform that was originally designed to support (1)
but can be used to build applications in its own right. These technologies
A generalized fingerprint format allowing digest values, cryptographic
keys, keyshares and nonces to be represented in compact (BASE 32 form).
*Data At Rest Envelope (DARE)*
A PKCS type format for use with JSON signature and encryption and an
append only log format that supports BlockChain type integrity checks and
incremental encryption.
*Personal Mesh*
A JSON based client-side PKI. This has many of the features of SAML and
PKIX but is designed to support management of trust relationships and keys
from the point of view of the end-user.
*Mesh Account*
An extension of a Personal Mesh that represent's a particular external
persona (e.g. personal, business use).
*Mesh Service*
An untrusted cloud based service protocol that supports a messaging
infrastructure used to manage a personal Mesh.
*Meta Cryptography*
The Mesh makes use of a number of key splitting and key combining
techniques that are made possible by the features of Diffie Hellman and its
EC variants.
A key innovation in the Mesh is that unlike in traditional Internet
protocols where an account is created by and belongs to a service provider,
Mesh accounts are created by Mesh users and ultimately controlled by a
private key held by the user. Thus while Alice may begin by creating a
personal account and binding it to alice at example.com for service, she can
change her mind at any time and change her service provider to example.net.

@_date: 2019-08-16 11:18:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The actual history of EV. Was: Well, 
OK, since you keep asking, I will tell you the reason we actually designed
VeriSign Class 3 the way we did and why (together with Melih) I called the
meeting that led to CAB Forum and EV and why Microsoft made it happen.
At this point, I am not employed by any CA (or indeed being paid by anyone)
and I am busy working on my next PKI project, the Mathematical Mesh. The
Mesh makes the Internet easy to use by making it more secure. If you are
interested, there is a mailing list where we are discussing the possible
formation of an IETF working group:
The Mesh neither requires nor replaces CAs. However as with any technology
that makes use of cryptography and involves management of trust
relationships, it does create commercial opportunities for individuals and
enterprises with the relevant resources.
The original design brief was to enable online commerce by making use of
credit cards online at least as safe as in a store or failing that, at
least as secure as traditional Mail Order/Telephone Order (MOTO)
transactions. The principal concern.
Confidentiality was not part of the design brief. Nor was preventing
government intercept. If you recall, export browsers were limited to use of
40 bit encryption. Though that was eventually solved by Mike Meyers and
Warwick Ford developing Server Gated Crypto which allowed banks and some
others to use 128 bit crypto (albeit using RC4 so the work factor was much
less than 2^128).
The primary goal of  VeriSign Class 3 was to prevent merchants setting up
fraudulent Web Stores. This is not much of a concern today because
Amazon/EBay/Alibaba operate what are in effect a cartel which requires 95%
of merchants to sell through their portals. The model the Web has adopted
its the medieval model in which all trade takes place in walled cites where
the Lord takes a cut off every transaction in return for providing an oasis
of safety in the middle of a landscape controlled by bandits and thieves.
The tool it uses is accountability. To get a class 3 certificate, subjects
had to establish a legal presence in at least one jurisdiction that could
hold them accountable in law and the CA was responsible for validating that
The goal of class 3 was to deter merchant impersonation fraud by making it
unprofitable. Specifically, the cost of acquiring a certificate would be
greater than the gain when performed repeatedly. While it is not
particularly difficult to make a single fraudulent company registration,
doing it repeatedly and not being caught becomes very expensive. On the
gain side, the purpose of revocation is to narrow the window of opportunity
in which the certificate may be exploited.
People can argue over whether this was a good idea or not but that is what
Michael Baum, Warwick Ford and myself designed the VeriSign PKI to do. And
like it or not, that approach is so far the only open PKI that has
succeeded in becoming ubiquitous. There are other PKIs of similar scale
(EMV, Apple's Developer program) but they are all serving closed
communities and do not allow unauthorized use by relying parties.
What we did not anticipate was that when the Clinton administration finally
dropped the export controls on crypto in 2000, this turned SSL/TLS into a
general purpose confidentiality solution. This completely changed the
nature of domain validated certificates from being a cheap means to acquire
credit cards to being the gating function on use of crypto.
The CA issued trust model was adopted because it met the needs of the
design brief I was working to. While I was working at W3C, I proposed a
scheme for code signing that looks very much like a LE type approach backed
by something as close as was possible to Certificate Transparency given
that the Surety patents were still in force.
What I have proposed at multiple times since is that Web browsers should
accept any certificate whatsoever to establish an encrypted connection
without complaint. Browsers should not warn the user about self signed or
expired certs. They should merely treat them as if they were http sites
unless there was a specific indication that a stronger security policy
should apply.
The reason I proposed what became EV was that the DV certificates
eliminated the accountability required to prevent fake merchant fraud. The
reason Microsoft backed EV was they were concerned that Internet fraud
represents a vast potential liability for the browser providers. That is
why VeriSign was created in the first place - to isolate the liability from
RSA Labs in the first instance and then Netscape/Microsoft going forward.
Contrary to the claims made, VeriSign did not propose EV to increase its
profits. VeriSign had exactly no idea what I was doing at the time the
meeting was called. When I first proposed an industry effort to stop the
'race to the bottom', my VP told me to prevent any sort of industry
association being formed at all costs as it would threaten our position as
market leader. Why bother trying to develop new products in a market
growing by 20% a year? Much easier to attempt to increase margins and
preserve market share. The NYC meeting was held in the 4 month interval
between his sudden departure from the company and the appointment of his
replacement: FYIFV
Of course these days, everyone seems to be very willing to mansplain to me
the reasons why we did what we did. But I was there. I know what I did and
But that is all history and what interests me now is the present. In 2016 a
dictator managed to use compromise of the DNC systems to perform a
reputation attack that installed a corrupt property developer in the White
House. The task we face now is to deploy strong end-to-end security
ubiquitously and hang the consequences.
The Mesh is designed to make that possible.
To privacy advocates, I say that the Mesh provides the capabilities you
need to make strong end-to-end security actually easier than the present
Internet. The reason TLS is ubiquitous is that it makes no demands of the
user for attention or time yet it is remarkably secure. We can and must
design end-to-end systems as easy to use and we must make them open.
Signal, KeyBase and the rest provide security, but they are dead ends
because they are closed services. The problem isn't solved until
alice at signal.com can call bob at keybase.com without both having to create
accounts on the same system.
To the Certificate Authorities, I say that you have made a lot of money
over the years from my designs in the past. You can ride the WebPKI train
for a decade at least and it will continue to deliver revenues, you can be
content to attempt to increase margins and preserve market share. Or you
could take a gamble on the possibility that PHB's latest idea could make
you even more money than the ones that are making money for you now.

@_date: 2019-08-18 11:57:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Let's not talk about DoH, or Well, 
Although there are some uncontroversial uses of DoH (e.g. letting
My specific problem with DoH is that it moves the control point from the
user to one of the sites they are visiting.
What we need to do is to move the control point to the USER or a party
chosen by the user.

@_date: 2019-08-26 09:34:42
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "Entropy as a Service: A New Resource for Secure 
Rather than talking about 'random numbers', I prefer the term 'unguessable'.
An unguessable number must be random but a random number can be guessable.
In particular if it starts from a guessable seed. When Netscape first
started working on navigator, I spent several weeks trying to explain to
the guy who began the SSL protocol that putting 30 bits of ergodicity into
MD5 would not produce 128 bits of randomness.
Just about the only (cryptographic) use I could see for this service would
be to initialize the random numbers in hardware devices during manufacture.
And even then I would probably prefer to have multiple sources and use a
digest function to combine them. And I would want to have ceremony aspects
to ensure none of the services/devices were jiggered. And even then, I
would not (fully) trust a manufacturer's claim to have done it properly.
So for example, my IoT device initializer consists of a randomness service
that delivers random numbers to the provisioner. I can test the provisioner
in isolation by connecting it to a known stream of data and checking that
its behavior matches what I expect.
Next I can construct a more trustworthy source of randomness by combining
three independent sources and then checking the combiner in isolation.

@_date: 2019-08-31 13:36:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Bitcoin Royale: Peer-to-Peer No-Theft Electronic 
Yet another payments proposal that misses the point:
People were using payment systems long before cryptographic systems were
developed. Payments are a social construct first and foremost. The role
that cryptography can play in any such system is really very small.
The first thing that any system has to get right is the social constructs
and the idea that any scheme can provide a 'long term store of value;
before it can solve the problem of paying for cups of coffee is utterly
I have been tracing crypto-currency payment schemes since I wrote the
survey paper while I was at MIT 24 years ago and the field hasn't moved
since. Proof of work is an application of the peppercoin scheme Adi Shamir
developed with Ron Rivest. Blockchain is the Haber-Stornetta hash chain
The only thing that has changed in all that time is that we have moved from
the store of value moving from the promise that someone has chunks of gold
in escrow to the promise that if we all clap our hands and say we believe
in tinkerbell, we all become rich.
Ten years on, BitCoin still defends itself from all criticism with the bald
statement that it is early days and nobody can know how the system will
adapt to meet the challenges. That is total hogwash. We know how the system
will adapt because we have been watching for ten years - it won't adapt at
Ten years after the financial crash, BitCoiners still splutter about the
corruption of the global financial system while the BitCoin float is stolen
over and over again. Fraud accounts for much less than 1% of actual value
transfers in real world payment systems. Actual value transfers account for
much less than 1% of the fraud in the BitCoin system.
Ten years ago, the largest online retailer of note to accept BitCoin for
payments was Overstock.com. Ten years later the largest online retailer of
note that accepts BitCoin for payments is Overstock.com. And they will be
dropping BitCoin in the coming months as the CEO has had to resign after
having an affair with a woman now in jail for being a Russian spy and then
posting bizarre rants about the deep state.
Give it up folks, BitCoin has a carbon footprint that is ridiculous and as
soon as Cheto Christ is out of the White House, the war on carbon is going
to be the best way that the US and the UK have to get back at Putin. The
value of BitCoin depends on the hope that it is possible to redeem large
numbers of Tethers at par. If Tether is a fakecoin, it is game over for
BitCoin and game over for every other crypto currency. And like Trump, the
one thing BitFinex will never ever do is to allow a forensic audit of their

@_date: 2019-12-04 08:47:28
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] 795-bit factoring and discrete logarithms 
We have been due a new factorization of RSA for some time. It is clear that
bits is now within reach for an attacker that really wants to break a key.
there shouldn't be so many 1024 bit keys left that matter.
What does give me concern is that right now, everyone seems to be focused
on the
threat from Quantum cryptanalysis and the threat of algorithm improvement
seems to
be ignored.
Yes, people are doing bigger and bigger science projects. But that is all
they are. We
could build a 10,000 Qbit machine today. What we can't do is operate one
long enough
to make real use of more than a dozen of those QBits.
There are very good reasons to continue to look at Quantum. Not least that
it seems
likely consciousness will turn out to be a Quantum effect. Just as turnips
happily fix
nitrogen without using the temperatures and pressures of our industrial
processes, it
is possible that low temperatures aren't needed for quantum interactions.
The state of quantum certainly justifies serious concern and development of
plans. But that is a really low bar. Even a 1% probability of successful
development of
quantum cryptanalysis within 20 years demands the current level of
attention QR is getting.
But the current state of quantum does not justify writing off public key
crypto yet. Or
abandoning any public key approaches that we can't be confident can be made

@_date: 2019-12-10 13:56:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Stupid movie encryption scenes 
Watching Agents of Shield, I noted a scene which combined most of the
stupid hollywood 'encryption' tropes.
* Character recognizes the file is encrypted 'with a scheme they have never
encountered before'
* The file is decrypted in a few hours using nothing more than a laptop
* The encryption scheme is always symmetric, no use of key sharing.
* Geolocation encryption - can only be decrypted at a specific position.
* Have to find the person who encrypted the file to decrypt it.
* Nonsensical graphics, particularly of the 'finding parts of the password
individually' type as if encryption works like a safe.
I was wondering if there were any particular scenes in other movies that
are similarly egregious. My plan being to string them together for a
training video on what encryption ain't.
Could then follow up with an alternative primer on how to write realistic
schemes using public key crypto, threshold crypto, key shares, HSMs,
biometrics and so on.

@_date: 2019-12-11 14:19:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] FBI: Don't trust IoT devices 
US6741592B1 Filed: May 22, 2000
There are some HP patents from the same era that should be expiring as well.

@_date: 2019-12-12 08:35:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Stupid movie encryption scenes 
Side channel would be a cool way to extract a key in a realistic treatment.

@_date: 2019-02-10 11:19:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [FORGED] Schneier in Wired: There's No Good 
At this point, the main concern I have related to these schemes is that
they mustn't be allowed to pull the whole field down with them when they go
down the plughole.
It is impossible to have a serious discussion with a group of people who
are convinced that they are exceedingly clever and are part of a small
select group that has found a way to make a fortune by virtue of their
being so very very very very clever.
It was the same with the 'High Income Yield' scams (or whatever they were
called). It isn't an accident that Bitcoin started its rise six months
before Liberty Reserve was raided.
The whole Bitcoin system is a lab experiment that escaped. It takes the
'credit' for every success while disowning every failure and problem
identified as being a result of the immaturity of the system.
The biggest conceit is that they have eliminated fraud. Which they have
done by defining all fraud to be the fault of the user and therefore not a
problem of the system.
Another conceit is that their system is sound unless someone can prove that
it isn't. That is the wrong standard. Banks have compliance departments
that are based on the assumption that nothing is legitimate unless it can
pass an audit. Bitfinex have been promising an audit of Tether for years
now, it has never happened and anyone looking at how the BitCoin price
miraculously recovers after a dip knows it never will.
I don't believe BitCoin is worth $3,500. It is only worth 3,500 tethers and
nobody really knows how many of those can be redeemed at par before the
founders do a Quadriga. They may be running an honest operation but they
don't feel the need to demonstrate this. If someone tells me that I can
become exceedingly rich if I just let them hold my money for me for a
little while, I start with the assumption they are going to cheat me.
And of course, absolutely none of these issues have anything to do with the
cryptography. Which is important to keep pointing out because when these
Ponzi prats all start dropping off window ledges, mainstream media is going
to be asking why we never warned them. And of course most of us did and we
were ignored.
All in all BitCoin is just a more sophisticated Nigerian prince scheme.
Only instead of making the money moving the gold out of Nigeria or removing
diepack off dollar bills, the marks are supposed to double their money in a
month 'investing' in BitCoins and instead of the scammers making their
money by asking for advance fees, they persuade the 'investors' to let them
hold their stake for them.

@_date: 2019-02-16 14:48:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Questions of taste on UDF presentation 
I have made significant changes and extensions to the UDF specification.
The old draft is in the links below but I am about to replace it with a
very much more powerful scheme. UDF began as an attempt to bring PGP
fingerprints into the 21st century. I have since extended the scheme to
cover nonces, encryption keys, key shares and commitments.
The question I need to answer right now is whether to group UDF values in
groups of 4, 5 or 5+3 alternating.
The following fingerprints all represent the text/plain string "UDF Data
MDDK7-N6A72-7AJZN-OSTRX-XKS7D (5)
MDDK-7N6A-727A-JZNO-STRX-XKS7 (4)
MDDK7-N6A-727AJ-ZNO-STRXX-KS7 (5/3)
The comparison is not quite fair in that the 5 group version provides
125 bits of precision while the other two provide only 120. But 120
bits is much easier to code because it is a multiple of 8 bits.
Adding another 20 bits to the 4 and 5/3 character version gives us a
work factor of 132 bits, thus meeting the 128 bit work factor we like
to work to:
This is one of those choices that you only really get one go at. The
minute I acquire a user is the minute I can't change the architecture.
The 8 bit clean groupings are going to be easier to code. The 5 bit
groupings are likely to be more robust in use.
One of the new UDF types is the Encrypted Authenticated Resource
Locator. I am looking for backers to see if we could use this to fix
filing of expenses, invoices, etc. This is an idea that I proposed
over 20 years ago and was told it was stupid because there is no
business model. Well I have yet to see a better way put into practice.
I have full prior art disclosures on this going back a decade so
nobody even dream of perjuring yourselves to the USPTO like so many
other bastards have in the past.
So lets imagine we are on a business trip. We stay at a Hilton, we get
a drink at Starbucks, etc. and when we get home we have a pile of
receipts that we have to remember to turn in.
What if each of those receipts had a QR code that linked to an
encrypted version of the receipt? What if we didn't need any PKI or
even public key to decrypt it? What if this could be the first step on
the road to finally getting rid of emailed invoices, tax forms, etc.
[Yes, can also do it over near field communication and we could
integrate the payment mechanism. Got the specs for that as well.]
So I am going to need some people/governments to invest in this to
realize the full potential. I know that. I also know that this is one
of those schemes that only works as public goods if everyone plays the
same game. So if people want this to happen, it needs a band leader.
Which is where my business model comes in.
Lets start off with a random value
Now lets turn that into a URL:
Now we take the electronic versions of the receipts. We can have the
OMG XML invoice, a PDF, etc. as many as are useful. These are
distinguished by content type so we can sort them out using standard
HTTP content negotiation.
We encrypt each of out documents using DARE Message format using
ECDV6-- as the master key. Each document has a separate nonce value in
the KDF function used to obtain encryption keys and IVs
We calculate the UDF fingerprint (SHA2-512) of the random value and
express it with twice the precision.
We post the docs to the web site example.com as
[If we have multiple content types, configure Web service appropriately]
So when I scan the QR code, the app can perform the same conversion
and retrieve the encrypted, authenticated document and then decrypt it
with the secret key.
[I have elided many of the technical details here that avoid crypto failures]
So to make this happen in real life, what I plan to do is:
1) Finish the revisions to the spec
2) Release the reference code (C enabling the non QR code version
3) Make a You Tube video describing the scheme
6) Profit?

@_date: 2019-02-17 11:22:01
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Questions of taste on UDF presentation 
Stop using C/C++, use Java, C# or any modern language that has array bounds
checking built in and 99% of the current attack vectors are shut
I am actually looking at QR codes as a means of secure credential/contact
Spam is of two types, there is the criminal unsolicited spam that is 99%
and is possible because SMTP email is not access controlled by default.
Then there is the ordinary junk mail problem. Conflating these two problems
is like conflating insults with a knife attack.
It is actually useful to have credential exchange via QR code because it
provides a means of authenticating credentials in-person. Sure Starbucks
could spam you. But if all their emails are authenticated, you have no
difficulty sending them to the bit bucket if you do.
Tough titty. If you choose to live in a fascist state, I am NOT going to
design my systems so as to protect you from your moronic police force.
QR codes are widely used today by billions.
Why would you do that though?

@_date: 2019-02-19 11:48:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Questions of taste on UDF presentation 
While this is true, it is also true that array bounds checking is a
particularly egregious hole. My college tutor was so concerned about the
security implications of dropping bounds checks that he made them the
subject of his Turing award acceptance speech.
The Java VM is written in C of course, as are most VMs. So it isn't a new
set of vulnerabilities, it is the old vulnerabilities at a higher level
plus some reinventions of the old ones at a different layer of abstraction.
Writing C does not have to mean insecure though. If you use the right set
of macros, you can implement memory management and array bounds checking.
We did this in the CERN libwww, every string manipulation used a macro that
did allocation checks.
At root, any exploit has to affect program control. That means that it has
to manipulate the program counter in some way. Now it is quite possible
that my approach does not close every crack. But I think we can do a lot
better than leaving the front door (buffer overrun) open and the backdoor
(scripting language injection) open.

@_date: 2019-02-22 15:10:24
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Best way to create a MAC from SHA3 
I am just finishing off the UDF draft.
What is the best way to create a MAC from a SHA3 digest function? For this
application I need a 512 bit output so no need to SHAKE.
HMAC is an obvious choice but it was designed to overcome the limitations
of Merkle Damgard construction. Is there a more appropriate, spongeworthy

@_date: 2019-02-28 20:15:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] In the event of my death, master password 
============================== START ==============================
So as it happens, I pushed out this draft last week. The code is not quite
ready yet but it will be very soon. I just have to get the version that
produced the draft to pass all the unit tests:
UDF is simply a modern way to present and use PGP fingerprint-ish types of
So a 128 bit key looks like this:
Key: EA6Q-YPKA-WZH4-64VU-ADGN-4UGM-TSXQ
The data format has a one byte type identifier followed by n bytes of data.
In this case it is a 132 bit key. intended to be used as input to a KDF so
the encryption can still be 256 bit.
We can share the keys using Shamir secret sharing, for example, this is 3
shares with a quorum of 2:
Share 0: SAQB-7EV5-OUJG-ZWXJ-BRRC-HMOB-TEZT-Q
Share 1: SAQQ-EGJ5-VFXI-TZS7-MTBX-VBJS-MXE4-C
Share 2: SARO-JH55-3XFK-N4OV-XUSN-CWFD-GJQH-2
OK, so far nothing you haven't seen before but this is actually documented
and written up so its a bit more than a suggestion.
Now for the new part. We can create a UDF URI. So lets say our secret was:
We create a UDF URI with a domain name where we are going to store the
We can turn that into a QR code.
To resolve the URI, the app first takes the Content Digest fingerprint of
the secret. We use twice the precision of the input.
Now we do Web Service Discovery to find the Web Service Endpoint and splice
the fingerprint on the end.:
So now we have a mechanism for going from a QR Code to locate an encrypted
copy of your document in the cloud and decrypting it without putting the
encryption key at risk.
I am pretty sure that we could use this mechanism to make payment of
invoices easier. Existing electronic means based on email are insecure and
account based schemes only solve the problem for the biller, not the
It could probably be used to achieve HIPPA compliance. The key thing is
that the documents in the cloud are encrypted but the keys are never in the
This is one of my bootstraps for the Mathematical Mesh. Instead of
insisting on going all electronic cold, provide people with the on-ramp.
The process of resolving the linked document could be used to trigger a
binding of credentials that allow us to make use of Mesh Secure
Transactions (different name for secure email not based on SMTP, not trying
to replace regular email, just eliminate the clutter that makes securing
email so hard).

@_date: 2019-01-03 13:29:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain without proof of work 
As of 1st Jan, I am no longer employed by Comodo Group or any other CA or
browser provider. So I am looking at new directions. One of these is a
video blog: PHB's CryptoWar which will follow my various interests from
politics, to cryptography to prop making.
To start it off: here are three commitments which are the names of three
individuals who I expect to see indicted/charged with serious crimes in the
near future:
[These names are also known to at least two international news
organizations who like myself are allowing the authorities to complete
their work.]
The kommitments provide a cryptographic means of proving that I knew
something at a particular time without revealing it (yet). They demonstrate
both the use of a digest function and the advantage of using a key.
The next obvious technical topic to tackle is blockchain. Right now,
blockchain is using more electricity than Ireland and minting several
billion worth of new currency to process fewer transactions than a
moderately busy CostCo.
So what is the current state of the art on blockchain without proof of
work? Harber and Stornetta suggested publication in the Times. Which is of
course recourse to a higher level notary. The next obvious approach is a
circular firing squad of notaries that cross notify. Has anyone published
anything further I should present?
Of couse, I could do what I usually do and re-invent stuff because I am too
lazy to read the literature. But I rather doubt there is a literature in
this case...

@_date: 2019-01-04 16:59:34
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain without proof of work 
Thanks, that is what I am looking for. I consider all proof of resource
schemes equally obnoxious. I started in this business writing arcade games
for 8-bit CPUs with Arduino class processing and memory.
The basis for modern cryptography is the assumption that the attacker has
dramatically greater resources than the defender so that they can afford
work factors of 2^64, 2^72 or even higher to break schemes. So proof of
work/ space/ stake/ pudding are all unacceptable to me.
The number of patents is discouraging and mean that I probably face a
choice between patenting anything I invent myself or having someone else do
that. Someone once told me there are over a hundred US patents on
technologies I invented that don't have my name listed as an inventor.
Thats how I became an expert witness in the WebMail case (a Web Mail
service written as a thin wrapper round VMS mail was the test case I used
for for HTTP that led to the Content-Length field being added to make the
POST and PUT methods work).
The reason BitCoin is successful is of course the belief that people are
making money. Most people find it much easier to believe things that they
agree with. And what is there to disagree with about getting rich? It is
why people get into Ponzi schemes or support obviously corrupt politicians
who tell them while male heterosexual people like themselves are morally
superior to all other folk.
The thing with money is that money is whatever people believe to be money
so the Tinkerbell spell works as long as people believe. Which is of course
why 80% of the folk on this list saw the BitCoin announcement but only a
tiny number ever bothered to mine on a serious basis. We are skeptics and
don't believe. Perhaps because we saw GoldAge, e-Gold and the rest.

@_date: 2019-01-04 20:09:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain without proof of work 
OK so I have decided to make a few changes to the structure here so the
values will change.
Let us say that m = "Konrad is a Kompromised agent".
first choose a random key kt = P (0xB0 || rand (512), 125)
(where P is the presentation/truncation function using Base32 putting in
dashes every 5 characters and truncating to 125 bits)
We use SHA-2-512 to construct a Keyed UDF, so HKDF(), H(), HMAC() are
functions all using that as the base digest:
k = HKDF (kt, 512)
f = HMAC (k, ct || ':' || H(m))
udf = P((v || f), 125)
Where v is simply a tag to identify the fingerprint type and ct is the IANA
content type
So the core here is that we have a fingerprint of the data that can only be
verified if the key kt is known. Since this is a keyed digest, we are using
an HMAC for the purpose.
I have pushed out the code to GitHub but I need to clean it up a bit. The
version prefixes have been chosen so that the version number shows the
fingerprint type. A SHA-2 fingerprint will always start with an M
(Merkle-Damguard) and SHA-3 will always start with an S (Spongeworthy).
Random numbers will always start with R and I had chosen K for Keyed hash.
It since occurs to me that I should probably use K for actual Keys so maybe
I need to move the prefixes about.

@_date: 2019-01-05 17:25:49
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain without proof of work 
A straight hash function would allow a dictionary attack. Adding in the key
means that a brute force attack has a work factor of the dictionary size
times 2^512 which is obviously infeasible.
That is important and useful functionality for key fingerprints. The
compression function does not affect the brute force work factor for the
attacker. What it means is that if the user puts in a Work Factor of 2^24
on key generation, the work factor of the resulting 125 bit fingerprint
will be 2^(117+24) rather than 2^117.
That is a standard construction that has been reviewed by the IETF.
Unfortunately, there is a patent on a particular approach held by
Microsoft. While they have licensed that for certain IETF protocols, it is
not generally licensed.
Probably not. That is currently just a placeholder. It doesn't even accept
longer fingerprints to check against shorter patterns.
That is historical due to the fact that .NET was changing as I was writing
the code. So when I originally wrote the code it had to be able to swap out
the core crypto depending on whether it was Mono or .NET Framework.
Microsoft has since fixed that and I am currently going through the code to
eliminate the historical functions.
I would really like it if Microsoft would get with the program and actually
implement SHA3, Ed448, Ed22519, X448 and X25519. And I expect they will.
but in the meantime, I had to write some placeholder code.
I don't plan to rely on constant time implementation to protect against
side channel attack. It tends to be brittle in the face of aggressive
compiler optimization. The Kocher patents should expire soon if they
haven't already and they provide a more powerful approach that I need to
implement for other reasons.

@_date: 2019-01-06 13:29:46
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain without proof of work 
[Thanks for the feedback here it is helping, the design has evolved over
time and not all the features may be apparent.]
I think your confusion is probably due to the fact that I haven't pushed
out the draft yet which gives the context. This is a fingerprint scheme
that has been extended to support commitments. It was not designed as a
pure commitment scheme.
This is the latest draft but it is not complete. It may still have the
previous construction in places that did not use HMAC.
The starting point is I wanted a more robust, flexible PGP fingerprint
scheme that protects against semantic substitution, has a readable
presentation, etc. So a UDF fingerprint with a work factor approximating to
the 128 bits we like to work from (actually 117 bits) looks like this:
That is something I can put on my business card. But it is still a little
long. Hence the need for the compressed version:
That has a work factor of 116 bits. If I could press my GPUs into service,
I could generate a public key with a 124 bit work factor without too much
The reason for rendering the key as text is that it allows me to write it
down on paper without going to a printer. We only need as many bits of
randomness in the input to the HMAC as we will report in the output.
It is stretched to 512 bits using HKDF because that is the function that is
designed to convert strings to keys. It is overkill for this purpose but it
means I use the same function everywhere.
I can't make sense of what you're trying to say here. The initial
It would not break anything at the technical level but it would make the
usability worse.
One of the antipatterns I see when using BASE32 fingerprints is that folk
end up generating fingerprints like MONEY-SXCSN-BFY3H-JBAAD-XKS7D or
Which seems great at first until you realize that a human is only ever
going to check the readable part. so now there is an in for the attacker
who generates
That is completely different but is going to be confused. For even more
confusion, match the first and last segments:
I disagree. Humans do need to be able to enter fingerprints in certain
circumstances. But the short fingerprints should never have a work factor
of less than 2^110.
The long fingerprints in UDF are 250 or 500 bits. That is clearly not
something that a sysop should ever type. The situation in which I would see
these being used would be something like the following.
1) User sets up new device, it reports its UDF as
2)  User cuts and pastes the UDF into an admin tool
3) Admin tool talks to device, gets the document corresponding to the UDF,
calculates the long UDF: MDDK7-N6A72-7AJZN-OSTRX-XKS7D-JAFXI-6OZSL-U2VOA-
4) Admin tool determines that the user fingerprint matches the one
calculated and declares it a match
5) Admin tool stores the 250 bit fingerprint in the device database.
I don't see how constant time would be relevant for a digest operation. The
implementations of Ed/X 448/25519 are not constant time because they are
only placeholders for use until Microsoft releases some proper

@_date: 2019-01-06 16:22:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Came up with a weird use case, got questions 
It is actually an example of a very common requirement for timed release of
information or release on specific criteria.
This is in part what the blockchain's smart contracts are a nod towards.
Use cases include:
* Release of a person's will on their death
* Release of a person's bank accounts etc.
* Release of family secrets, national security, etc.
I have a lot of information I would like to keep secret from my family
until after my death and some stuff longer than that. I want them to know
where I buried Aunt Agatha's jewelry but not where I buried Aunt Agatha.
The timed version is going to require some form of notary. But it is easy
enough to provide a robust disclosure protocol and I have anticipated this
requirement in the Mesh tools which allows use of Shamir secret sharing to
provide additional robustness.
[I have not yet implemented this particular service but I might well do so
earlier than I planned as it gives me a podcast.]
So let us imagine that disclosure authority (DA) creates a sequence of
keypairs that are dated as follows:
Hourly - for the next 240 hours.
Daily - for the next 365 days.
Monthly - for the next 120 months.
Annually - for the next 100 years.
The DA releases the corresponding private key at the specified time. So for
the simplest escrow protocol, we simply encrypt under the corresponding
public key.
This is not very robust though and especially so if we want to achieve long
escrow times. For this we need to provide for separation of duties and use
multiple DAs with a quorum.
So let us say we want to escrow the data for ten years. Three DAs and a
quorum of Two should be sufficient. We encrypt the data under a master key,
split the master with Shamir Secret Sharing and encrypt each share under
our selected DAs.
If we want to keep the data for twenty, thirty or more years, we would need
to have more shares.
This protocol is not perfect, it is still possible for a coercion attack to
work. So if I was going to escrow really important information I would want
there to be additional controls provided through use of verifiable
ceremony. But as soon as you go to ceremony you are limited to quarterly
We can also make use of threshold crypto at the DA level. So the DA might
actually have three hosts that each disclose a share.
The most useful form of DA would be one that will disclose information
UNLESS the party takes some action. So the data is disclosed unless I say
it should be kept private. But that is really difficult to achieve
robustly. The nearest I have is that the DA reads a list of signed notices
saying 'don't release X' and only decrypts the escrowed data that isn't on
the list.

@_date: 2019-01-07 01:38:38
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Came up with a weird use case, got questions 
So... about the incentive to break a key...
Let us imagine that we got millions of people to take cat pictures and
escrow them. Then there would be an incentive to break the key.
Problem is that it is impossible to predict how fact hash mining will be in
five years let alone 100 so those schemes fail. People really like cat
The rocket solutions are in effect merely a different type of clock. And
the physics of those are really hard because electronics degrade in space
and things burn up in the atmosphere.
The most robust schemes in practice are going to involve ceremony and some
form of trusted hardware. We could build a HSM such that it will only
release the data if it receives a signed statement of the current time from
a trusted source. Throw it in a vault and bring it out after 100 years. It
will probably work. If built right.
Establishing a quorate notary that can be trusted to sign time is rather
easier. Each notary would have to delegate its function to a successor
periodically but that should not be too difficult to ensure.
Of course there is then a real risk that the data is lost because the
notaries don't continue their function.

@_date: 2019-01-08 03:29:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Came up with a weird use case, got questions 
My current solution is to laser etch anodized aluminium plates with Shamir
secret shares...

@_date: 2019-01-09 10:48:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Came up with a weird use case, got questions 
It was that or porn.
Each notary would have to delegate its function to a successor periodically
I was assuming that there would be a financial incentive. But it needn't be
too much.
For example, how about we begin by encrypting the notary master key under
AES512 and splitting the master key 5 ways with a quorum of 3 and laser
engraving the shares onto anodized aluminum plates which are immediately
put into a tamper-proof evidence bag.
OK so now lets put the shares somewhere public like a box in the center of
DisneyWorld. The fact that there is a concentration of secret knowledge
there becomes a tourist attraction in itself. This is part of what I mean
by 'ceremony'.
I love what you've talked about here. I just worry about the ramifications
The societies don't need to be secret, they just need to keep a secret. One
could imagine founding a Freemason's lodge for the sole purpose of managing
the secrets.
And yes, there is a religious aspect to this. Many early religious
practices are intricately bound to preservation, propagation and use of
manufacturing secrets. The process for making Samurai swords for example.
Every step is part of a ritual ceremony whose purpose is to ensure the
correct outcome.

@_date: 2019-01-10 16:24:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Digital dyes for tracing digital leaks ? 
There are many schemes of that type, see Blue Spike etc.
Basically they use steganography and massively redundant coding to encode a
hidden tag into audio and/or video.
Also there are schemes for Word Documents and such that ensure each
recipient of a classified document has a slightly different one and so on.

@_date: 2019-01-13 23:31:51
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain without proof of work 
It certainly would and moreover, that is exactly what is done in HKDF and
other key derivation functions.
Nor is collision resistance the consideration here. If I am using the
digest to authenticate a public key pair, the work factor of interest is
how many keys do I have to generate before I can impersonate someone
(anyone at all). Which for a 25 character UDF and a user base of a billion
keys is approx 2^117/2^30 = 2^87. Which indicates that we should move to
150 character fingerprints as the user base grows or use key compression to
increase the work factor.
 No, I like that better than anything to do with blockchain.

@_date: 2019-07-05 00:20:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Fwd: [Secdispatch] Call for Agenda items 
I have just released a new set of docs for the Mesh. It is nearing
completion. The last thing to do is to put the output of the examples into
the documents and I am using that as an opportunity to make a last editing
pass getting everything I can as correct as I can.
I will be at Montreal IETF if people are going.
Right now, the only person funding this work is me (though I am grateful
for the considerable amount of previous support from Comodo). I am
currently looking at options to take the work further. The one
non-negotiable criteria being that this is at root a communications system,
it can only reach its full potential if it is unencumbered, that means
anyone can use it or extend it without fees, licenses or permission.
The objective of the Mesh is to make computers easier to use by providing a
security infrastructure that works without users needing to be aware that
they are using it.
The Mesh can be used as a mechanism for managing credentials (passwords,
private keys, etc.) for existing security applications (SSH, OpenPGP,
S/MIME) or it can be used as a platform for developing new applications
(end-to-end secure password catalog, secure contact exchange).
One of my frustrations with the current situation in the industry is that
we haven't moved on from cryptography developed in the 1980s. We have
better algorithms to use in place of DES, MD5 and RSA but we haven't added
a new capability since BitCoin added hash chains to the canon ten years ago
and the patent on that was 1990.
The Mesh introduces a new set of cryptographic techniques:
*Uniform Data Fingerprints*: Think of this as 'Cryptography on rails'.
Rails is a powerful framework because it uses the same name for the same
field in every situation. UDF does the same for cryptographic keys.
*QR Codes*: Imagine being able to scan a QR code on your bills, your pay
stubs, tax advice, etc and get to a machine readable copy of the document
you are reading. That is what EARLs provide.
*Multi-Party Key Generation*: Weak keys have been a problem for decades and
now we have to consider the possibility that a key was compromised by the
device manufacturer. But keys generated during manufacture that cannot be
extracted could be the very best keys to use (if we can trust them).
Combining keys generated on multiple devices allows this concern to be
*Multi-Party Decryption*: Traditional CRM schemes use the Ford-Wiener key
release with a key server in the cloud dispensing decryption keys to
authorized readers. The problem with this approach is that our chief data
confidentiality concern is a breach of the cloud, i.e. the key server.
Separating the decryption function into two parts and requiring both to
participate enables a key server to control decryption of data without
being able to decrypt.
*DARE Envelope*: This is a new PKCS type format built on JOSE which
provides the hooks needed to support the Multi-Party Decryption scheme DARE
*DARE Container*: An append only log format supporting incremental
encryption and authentication. If I am talking to VC, I might even call it
a block chain.
*Shamir Secret Sharing*: Personal Escrow of the user's keys is supported
with up to 16 shares and a quorum of 1-15.
There is quite a bit more to the system but it remains remarkably compact
and especially so considering the scope of its capabilities.
One innovation that addresses a current concern is that Mesh Accounts are
the property of a user and not the service provider. So if I want to change
my service provider from example.com to example.net, I can do that at any
time of my choosing and I don't need example.com to co-operate of give
permission for the transfer.
The trust model does have a role for Certificate Authorities but this is
optional and limited to the discovery process, CAs are not ongoing
participants in every transaction. Direct exchange is also supported via
both an in-person model (e.g. QR code exchange or bump phones) or remotely.
All the reference code is MIT License and copyright Comodo Group (to
Version 2.0) and Comodo Group and myself (3.0 on). The tool chain used to
build the system is MIT License and my copyright. I have attempted to avoid
encumbered technology and I am not aware of any valid claims on the current
specs but make no warranties in that regard.
I have submitted all the documents as Internet drafts but there is a catch,
I am writing the documents assuming that the transition to HTML RFCs is
going to happen. So you can read them as plaintext drafts if you insist.
But the HTML documents have diagrams and use superscripts and subscripts
for the math rather than X_A which makes them a lot easier to read.
The architecture draft provides an overview of the project:
The following drafts are nearing completion. I am currently working on
getting the worked examples from the running code worked in:
I might have the protocol specification available by Montreal but that
might slip.

@_date: 2019-07-18 12:19:56
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
Trump is probably just upset about Facebook not using USD as the basis for
their Libre coin.
Libre is a cyptocurrency only in name. It is essentially nothing more than
Disney dollars for the Web. Mickey Mouse money. Only that is exactly what
the Web needs - a low friction way to pay for Web content that is universal.
If Libre was denominated in USD, people in Europe would be constantly
exposed to exchange rate risk both as providers and consumers. Using a
weighted basket of currencies mitigates that exchange rate risk. So if an
article is 1 Libre it will cost roughly $1 / ?1 / ?1 / 100?. But I don't
need to know the dollar / yen exchange rate when I am buying an article on
a Japanese site. I will know the USD/Libre exchange rate from last time I
topped up my Libre account.
This is what we needed all along and the cost of running the system will be
addressing all the hard problems that BitCoin ignores by refusing to
acknowledge them as problems.
This is good news for crypto because one of the biggest reputation risks
the field faces is general disillusionment with crypto after BitCoin goes
the way of Gold Age/eGold and all the dozens of Ponzi schemes that preceded
it. Instead of the press saying the collapse of Tether proves BTC was a
scam start to finish, they will be saying that BTC failed because the big
boys took over and did the job properly.
Trump is upset because Facebook will be launching a new international
reserve currency in place of the dollar right when he is trying to chest
thump his way to re-election.

@_date: 2019-07-20 20:41:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
Putting the amount at $10 billion might well put you into hat-eating
territory. You would probably be safe at $50 billion though.
There are 4 billion Web users. FB gets 10% of them on Libre, an average
float of $20 puts them at $8 billion. But that really isn't a lot of money
at Internet scale.
It is entirely possible that Libre becomes a reserve currency in its own
right but it won't happen overnight and if it does happen it will be simply
because it turns out to be convenient for international companies to use
for settlements reducing the currency risk on both sides. And if that did
happen it would likely be through some EFT like structure that is actually
separate from the exchange system.
I can see Libre becoming a $400 billion company in its own right because
that is what Visa corp is today. But it will take quite a while getting
What Libre won't do is to replace the dollar or euro or the like.

@_date: 2019-07-21 15:47:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Our leader opines on cryptocurrencies 
I sense something of a US-centric bias here.
To understand the attraction of a global currency, you really have to be
one of the people whose native currency isn't USD. The point is pretty
clear then.
Don't get me wrong here, this is not going to upend the international
finance system or anything close. It is an incremental development whose
significance is probably on the order of the switch to 4K TV at the very
most (i.e. important for the industry affected but not dramatically so).
That said, I expect Libre to have infinitely more significance than all the
rest of the crypto currencies combined because almost nobody actually uses
them for anything of consequence (that is legal).
The technology does not have to be at all complex at this point. Doesn't
even need to involve a hash chain of any type.

@_date: 2019-07-21 15:50:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Accounting Resource Location (was: Questions of 
I am just about to present on the Mesh as a whole to IETF and tomorrow at
SECDISPATCH and 13:30 local.
I went with 4:4:4. The new draft is here:

@_date: 2019-06-04 11:00:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] [FORGED] Crptographic ticket tape (fake news) 
This is what blockchain was originally invented for at Bellcore. And it is
pretty much the only thing it IS good for.
You don't need proof of work or any of that nonsense because the base tech
is so resilient all by itself. The user chooses a notary and takes their
output token, hashes that with their content and presents that as an input.
They receive back a notary entry/tree that fixes their act of presenting
their input between the two dates. The security of this token depends only
on the assumption that the hash chain was secure when the token was created
and the notary has not defected.
To put the system beyond feasible possibility of tampering it suffices for
the notary to cross notarize with other notaries. A meta-notary has the
property that none of them can defect successfully without all of them
defecting. [I go into the details in a paper]
So with some fairly straightforward engineering, you end up with a series
of nested proofs with different degrees of trust:
Assuming the immediate notary did not defect - bound time to 1 minute
Assuming none of the 10 nearest neighbors did not defect - bound time to 1
Assuming no notary anywhere in the world did not defect - bound time to 1
A notary is proven untrustworthy if they ever sign two divergent outputs.
If we have Iran, Venezuela, France, the US and Canada operating national
notaries, there will be meta-notaries that bridge them. So while any notary
can defect at any time, they cannot maintain the defection for very long
without collusion by everyone else.
The meta notary system described here is provably at least as strong as any
other scheme (e.g. proof of work blockchains) because you can always absorb
their outputs as inputs. But it is in any case because proof of work alone
doesn't actually achieve finality. Any ledger based system falls if a
position of extreme solipsism is taken.

@_date: 2019-06-04 16:10:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] About Secret Sharing Schemes and a Question 
There are some very nice theoretical schemes but when you start to
implement them for real, they tend to collapse down to all being variants
of the same thing.
This is a work in progress.
I use Shamir Secret sharing for the purpose of providing a key escrow
mechanism that does not depend on hardware for key recovery.
I also use a very simple key splitting mechanism where I require m of m
keys to be used to decrypt. This covers the case where Alice wants to read
her end-to-end encrypted mail on her mobile phone but have some means of
disabling access if the phone is lost, she is passing through customs, etc.
So if her private key a = x+y, she puts x on her phone and y in the cloud.
The cloud machine cannot encrypt on its own and neither can her mobile.
They must both co-operate.
Now I can imagine extending the same approach to allow the key to be split
so that n

@_date: 2019-06-05 14:37:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] About Secret Sharing Schemes and a Question 
This discussion was very useful as I have suddenly realized I can in fact
support pretty much exactly the use case that I believe likely to turn up
in practice.
First to rewind, I divide the traditional CRM/DRM problem into two parts:
Confidential Document Control and Redistribution Control. I define the
first problem to be meeting requirements concerning controlled release of
documents etc. to a user and the second to be requirements governing what
they can do with the material after they have acquired it.
My strong belief is that obsessing about the redistribution problem has
caused us to effectively punt on the control problem. Redistribution is a
really really hard problem that requires trustworthy hardware and imposes
serious usability obstacles on users. So we have documents that are
unencrypted and available to 20,000 people in an organization instead of
just the 200 that might actually need them because we can't get a handle on
the theoretical problem of one of the 200 misusing them.
I do have an answer to the redistribution issue but it is an accountability
approach, not a control approach: Log access to the documents in real time,
put a value on each one and flag excessive consumption on access. If a low
level tech is reading every diplomatic cable, find out why.
But anyway, the way I (may) end up implementing Shamir Secret Sharing in
the Mesh is a fairly simple twist on the code already written which shares
a decryption key x between two parties x = a + b. So to calculate e^y^x we
calculate e^y^a . e ^y^b.
In the existing code, the private key a typically lives in the cloud on a
server and is called the recryption key. Its partner decryption key b is
encrypted under the user's decryption key and can be registered on the
cloud server along with a. The effect being that the user can only decrypt
if the cloud service permits this by using the recryption key to do its
part of the work but the recryption service cannot decrypt by itself.
So let us consider the problem where we want a particular document to be
available if 3 out of 5 recryption services permit. We encrypt the document
under a master key m as usual and then split the master key using Shamir
secret sharing 3 of 5 times and encrypt each share under the master key of
a different service.
This is a lot simpler than the schemes I have seen written up in the lit.
But it meets the needs I see which have much more to do with being robust
in the face of service failures or mitigating coercion attacks.

@_date: 2019-06-13 10:58:13
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Call for nomenclature... 
OK, this might sound like a trivial request but it really isn't.
As you know, I am finishing the first release of what is now the third
version of the Mesh architecture and I think I have it right this time
because I have reduced the number of moving parts drastically. The Mesh now
has three main parts:
1) An infrastructure that allows users to manage their devices by
connecting them to a personal Mesh
2) An infrastructure that allows users to exchange credentials with other
users using the trust validation criteria appropriate for the intended use.
3) An infrastructure that allows users to manage application configurations
including but not limited to managing cryptographic credentials.
This is all built on three new cryptographic primitives.
1) Uniform Data Fingerprints provide naming and addressing infrastructure.
UDFs are not URIs but can be used to construct URIs. UDFs are used to
represent cryptographic digests, nonces, keys and key shares.
2) DARE (Data At Rest Encryption) Messages: Are a JSON-ish equivalent to a
PKCS wrapper with support for the meta-cryptography used in the Mesh.
UDFs are used for addressing type purposes.
3) DARE Containers: Are a sequence of DARE Messages and provide Blockchain
type functionality for authenticity with incremental encryption capability.
Containers are used as the basis for DARE Catalogs which contain sets of
items, DARE Archives which are an encrypted file archive expressed as a
DARE Catalog and DARE Spools which contain queues of tasks, messages.
The problem I have come to is that I am now using the term message as a
term of art to mean two different things in different parts of the same
system. This did not matter when the terms were defined as DARE was an
application built on top of the Mesh at that point. Now it is the platform
on which the Mesh is built. And so there is a lot of scope for confusion.
So what can I use as the name for a DARE Message?

@_date: 2019-06-15 12:57:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The Encrypted Room Re:  Call for nomenclature... 
OK, so now need a name for this? Black chamber?
Thanks for all the suggestions. I have gone with envelope but I am thinking
I will also use parcel for a collection of envelopes.
Envelope works when I am describing things to non technical people.
Transparent envelope = wrapped plaintext
Transparent, sealed envelope = signed
Brown envelope = encrypted
Brown, sealed envelope = signed and encrypted
So now the challenge is to find a name for a metaphor for a general
approach to a problem that occurs in medicine and home automation.
I don't see how true homeomorphic encryption is feasible. That is the
ability to perform an algorithm on encrypted data without decrypting it.
The Fourier transform apart, almost every interesting analysis technique
requires conditionals. Most interesting algorithms are np-complete
asymptotically but have efficient solutions or efficient approximations
that exploit the structure of the data. Any optimization that makes use of
such structure in the data must reveal such structure and thus disclose
information about the content.
So leaving that aside, what is the closest we can get using only
unencumbered crypto?
Lets start with separation of duties
Alice writes a program
Carol operates a cloud service that receives packets of encrypted data,
processes them using the program written by Alice and returns the result
This system works up to a point but requires more trust in Alice and Carol
than is necessary. Is Alice going to introduce malicious code? Is Carol
going to keep the decrypted data? Lets introduce more parties:
Sue verifies the code and signs it
Vera writes code that observes the inputs and outputs of the code provided
by Alice and checks to see that they are consistent with the specification
of the code. If this is the case, the result is signed, otherwise an
exception is signaled.
Gordon acts as a gatekeeper, he receives requests from customers, strips
out the identifying detail, submits them to Carol and receives back the
result which he returns to the customer who asked for it.
And of course, add crypto to taste to lock down all these relationships.
So what do we call Carol's service? It seems rather like Searle's Chinese
Room. Is it a cell? What?
And it need not be a program doing this work and it need not be a cloud
service. I believe we should adopt precisely the same approach to security
if we are doing a sensitive operation on a local compute service as on a
third party service. So I might outsource my voice recognition to Alexa or
Siri if they provide a hard anonymization service like the one outlined
above but if I am more privacy conscious and want to run it on the device I
own and operate personally? Why wouldn't I want the exact same set of
cryptographic protections in case I have been sold a compromized device?
The approach I am advocating here is radical distrust. We start from the
assumption that at least some parts of our system are compromized and look
to mitigate the consequences. This has two prongs, first applying the
principle of least privilege at a granular level, second examining the
behavior of modules to check that they are operating correctly.
Separation of duties minimizes opportunity to create side channels. It is
not a perfect guarantee but nothing ever is.
The immediate applications I see for this approach are for privacy
sensitive applications like analyzing voice, X-rays and MRIs to detect
cancer, etc. etc. But the same approach could be applied to forensic
Forensics can be divided into three parts:
1) Data collection
2) Excluding suspects
3) Identifying culprits
The first two are relatively uncontroversial (but many practices are awful
and sloppy). The third is coming under serious challenge of late as it is
pointed out that while it is clear that Xavier didn't open the safe if he
fingerprints don't match, the claim that a match confirms it must have been
Xavier is no longer as certain.
So deploying this approach to operations performed by human technicians, we
would include quality monitoring and constantly rank labs according to
empirical measures. We would use the same anonymizing approach and add some
blockchain (the VCs would insist if we didn't) to provide some non

@_date: 2019-06-19 13:30:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] FT explains Facebook's Libra 
It is basically Disney dollars for the Web. Which does nothing for the folk
who believe crypto currencies are all about destroying governments but is
exactly what the Web actually needs.
The currency isn't going to deflate automatically making early adopters
rich. It is going to be pegged to a basket of currencies which basically
means that it is going to be like trading in an index fund of currencies.
It is going to be like an average of the USD, yen, Euro and GBP. Which is
going to make it a very interesting currency for folk doing international
business. For most it is going to be more stable than any of the
alternative foreign currencies.
They mention the ability to prevent fraudulent activities. Which means that
they must have some sort of chargeback mechanism. So this is not going to
become a new vehicle for ransomware or hard drugs. The interesting part of
course is going to be where they draw the line. BDSM porn? Sexual services?
The big interest I have in it is that it is a backstop for the crypto
industry when BitCoin and the Ponzis collapse. The FB coin will be a
success because it fills a real need for a means of paying for internet
content. It is a better version of Dogecoin. My big worry has been that
when the scams finally collapse, they will take legit crypto with them
because they have created a huge expectations gap. If that were to happen
after FBCoin is on the table, it would look more like succession than proof
that the technology was flawed (even though they are not doing proof of

@_date: 2019-06-19 21:35:49
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] =?utf-8?q?Shamir=E2=80=99s_secret_sharing?= 
It doesn't matter how much compute power you have. Unless there is some
weakness in the choice of the shares, Shamir Secret Sharing is provably
secure because if you have a quorum of n shares, you have a polynomial of
degree n-1.
It takes two points to define a line, three a quadratic curve, etc. etc.
There simply isn't enough information to reconstruct the polynomial unless
you have sufficient shares.

@_date: 2019-06-29 12:24:50
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The CryptoWars restart. 
Forbes confirms yesterday's story in Politico:
It is clearly too soon to panic. But I must admit that I have been
expecting this to happen and planning for it.
Signal, WhatsApp etc. are all fine but they are all designed as secure
networks with a single service provider. Sure, other folk can use their
code but you can't contact anyone on a different service, you can't run
your own service.
Any single point of failure is a potential point of coercion.
Following John Gilmore's criticism of an earlier version of the Mesh for
requiring use of a service provider, here is my attempt at a solution.
The Mesh is separated into two major parts, a personal part and a service
The personal part of the Mesh comprises device and account management.
These are coded in a way that means that user's don't need to use any
network service at all. So if Alice joins here laptop and mobile device to
her Mesh, they stay connected even if she changes her Mesh Service provider
or disconnects from service providers entirely.
Alice can create as many accounts as she likes as part of her Mesh. So she
can have accounts for personal, business, etc. I have re-engineered the
system so that Alice can choose to advertise that an account is connected
to her personal Mesh or not.
The second part of the Mesh is the service layers and these are messages
exchanged between devices Alice has connected to her Mesh and messages from
external parties. The second case requires us to consider access control to
mitigate abuse of course.
Unlike with traditional Internet protocols, accounts are not owned by
service providers, they are owned by the user. This means that if Alice
changes her Mesh service provider from alice at example.com to
alice at example.net, the process is as seamless as it could possibly be. All
Alice's prior contacts can update their contact catalogs to use her new
address. If the old service provider is willing, it can provide forwarding
but Alice's contacts all have the fingerprint of her account or her Mesh
and can get her new (authenticated by digital signature) contact info from
a public directory.
With the Mesh, users can change their service provider at any time without
switching costs. They can even run their own service. Thus, the potential
for coercion is minimized.
Admittedly, running a Mesh without any Mesh Service whatsoever is going to
severely limit functionality and convenience. It is really difficult to
provide an easy means of connecting new devices without either a direct
connection between the devices or some sort of postbox capability to serve
as a staging post for messages. But this might well be something you could
tolerate if you were using Mesh Messaging within an IoT cluster or a robot
with multiple systems.

@_date: 2019-03-01 12:43:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] In the event of my death, master password 
Such as?
There is absolutely nothing proprietary.
Do you actually read anything before you respond with accusations?
As for novelty, name another technology that makes it possible to bind an
arbitrary Internet address to a particular root of trust. Name another
technology that allows QR codes to be used to provide access to a resource
of arbitrary size with (essentially) the same degree of security as if the
data was in the QR code.
Come on, name them.
It requires a web service to be maintained by the user. How can the user
It does not actually. All it requires is HTTPS. Read the spec.
Looks like someone is projecting here.
You misrepresent my work and then tell them not to read it. Very
What are you selling eh? All my work is open source and unencumbered.

@_date: 2019-03-06 20:06:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Adi denied visa to visit US 
It is not clear if the visa was denied or they simply failed to process it
in time due to the shutdown. But still significant that someone this
prominent would not get a visa as a matter or priority.

@_date: 2019-03-21 09:13:17
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Mix Messaging in the Mesh 
I am now working on the Mathematical Mesh full time and independently. At
present, I am working through the Mesh specifications and code piece by
piece getting the specifications in line with the code as implemented.
My new company 'Venture Cryptography LLC' is in process of formation (read
Phill better get his application in to the IRS for a tax code so he can
register it). The business model I am currently looking at is basically a
branding play. In the first phase someone has a startup and they want to
persuade people they have some clue about security we can look at their
stuff and see if it makes sense on a fee plus equity basis. Once we get to
some idea of quantifiable security assurances for IoT etc. devices we can
start an approval mark program.
The Naming (UDF) and Message Format (DARE Message/Container) parts are more
or less complete and I am now working to get the profile and messaging
documentation properly in sync.
One major change in the specifications is that I realized that I could
generalize all the various Mesh applications (Contacts, Calendar,
Bookmarks, etc) into two general structures, Catalogs and Spools.
A Catalog is simply a collection of objects which is managed by a single
party. So the set of my usernames and passwords is the credentials catalog.
The set of tasks is my calendar and so on.
A spool is a queue of messages. Messages are the only structure that are
exchanged between users. So if I want to ask Alice to add me to her
contacts, I send her a contact request message which is access controlled
for spam prevention and added to her inbound message spool. If she accepts
the request, she marks it as read by appending a message read entry to the
spool and then adds the contact to her contacts catalog.
Spools and catalogs are both implemented as DARE containers which are
append only logs. So the only protocol primitive needed is the ability to
synchronize a container from a master to a set of (possibly redacted)
As I was working on this structure, I realized that it would be awfully
convenient to bound the size of messages so that the spools remained
compact. Bounding the message size to 63K allows messages to fit into one
IP packet with some headroom for tunneling (yes, I know that the current
MTU limit is 1500 bytes or 9000 ish ).
This decision came from the decision to support very large payloads. Once
you decide to support email transfers of 4K video files between users, it
is obvious that you need to separate control and data paths. So large
messages are going to have to be sent as attachments separate from the body
or as I call them, detachments. This approach has other advantages, it
means I can send a living document that is being constantly updated with
the same ease as a static finished one.
So my messages are all looking like they will be less than 64K. (Possibly
less than 9K). Perhaps I should make all the messages the same size so as
to provide protection against traffic analysis.
I don't plan to implement this feature at this stage and will probably
leave that to others to do. But what is the current state of the art in
mixmaster type networks for asynchronous messaging?
In particular, where is the optimum tradeoff between security and
When I read crypto papers, they seem to assume that the ideal is to achieve
anonymous communications with the intermediary nodes being unable to trace
the path of the packets. I really doubt that capability has more than
theoretical application. Being able to protect a military network against a
Pentagon Pizza Parlor attack is probably much more useful. It is certainly

@_date: 2019-03-21 21:57:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Mix Messaging in the Mesh 
Because if security is going to be any use to people it has to be easy
enough that a 60+ year old grandmother who left school before the Internet
arrived can use it because she is the US Secretary of State.
We have tried the maximalist approach to security for 30 years and it has
been a complete failure. We have one widely deployed Internet security
protocol and it is limited to the transport layer.
The reason I was asking about mixmaster was to see what the set of
capabilities in that space people find actually useful.

@_date: 2019-03-23 22:49:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Clinton email issues 
This is very close to my theory which is that she didn't trust the GSA
staff. Nor should she as the behavior of the NYC FBI proved. If she had
used the GSA server, her emails would have been leaked to the Republicans
in the House for their Benghazi treachery.
All of which is why I have spent the past five years working on making end
to end email security practical and easy to use.
I can now make end to end encryption exactly as easy as regular email. Just
put the email address in the message as normal and send.
OK so there is some magic: I change the email address to embed the
fingerprint of the recipient:
alice at example.com.mm--mb2gk-6duf5-ygyyl-jny5e-rwshz
If the email client is Mesh enabled, it can recognize this as a SIN and
work out that it needs to apply a security policy (OpenPGP or S/MIME) that
has the fingerprint mb2gk--
The Mesh code is all open source. I am currently working methodically
through the documentation. If someone would write an SMTP proxy that
intercepts the outbound email and applies enhancements, we could get this
into people's hands sooner than if I write all the code on my own.

@_date: 2019-03-24 17:10:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Clinton email issues 
To answer Arnold, etc:
The repo is That is a good question of course. But that is the introduction problem and
it is separate from the connection and re-connection problem. The idea of
SINs is that they are the fixed points that require no external trusted
party to interpret once introduction is complete.
Introduction may be achieved through multiple mechanisms depending on
whether we meet face to face or not. And we can use a technique I call
precision strengthening. So connection mechanisms from most to least secure:
1) We meet face to face and one of us scans the QR code of the other from a
cell phone. I have a secure mechanism that establishes bidirectional
exchange of contacts with a 2^128 workfactor using reasonably small QR codes
2) Scanning a static QR code (printed) same work factor but only
authenticated in one direction.
3) We rely on a trusted third party introducer (CA).
4) We read out the UDF code over an insecure channel
5) We read out the first 10 segments over an insecure channel.
6) Pull it off the Web
7) Trust after first use.
But the real advantage here is that all of these are unlinked from the mail
program. The app that pushes the contacts into the contact directory does
not need to be a mail client. It can be much smaller.

@_date: 2019-03-24 18:16:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Clinton email issues 
The code is in C# because that is the most popular C like language that is
unencumbered and provides array bounds checking with type safety.
The native crypto libraries are used for everything except for the
Ed25519/448 and X25519/448 and SHA3 which is not supported in dotnetCore
right now.
    b) how you intend to protect the encryption keys
The Mesh master profile keys are ideally escrowed using Shamir secret
sharing and erased from the machine. The secrets can be recorded as paper
shares. Application keys may also be escrowed if desired.
Protection of application keys depends on the algorithm chosen and the
platform. Wherever possible I use the native capabilities of the platform.
As far as implementation goes, the priorities are Windows and Mac. There
are ways to secure Linux but I will not be the one implementing them.
As far as RSA keys goes, I don't really care. I consider this obsolete. My
focus is on the ECDH modes.
For ECDH I use key cogeneration to combine keys created on the device with
keys generated on the administrator machine. This provide protection
against weak key choices on constrained devices and also against
manufacturer key compromise. It is sufficient for either the admin machine
or the application machine to generate a secure key and not compromise it
for the user to be secure.
By default, keys are unlocked by the user logging into the machine, their
login is used to decrypt the key store.
If higher degrees of security are required, keys can be encrypted by an
additional password. But the near term goal is to unlock the use of
application private keys using a trusted personal device (watch, phone)
ideally with biometric security.
See my other reply on the introduction problem. I have also written this
but it is now out of sync with the code and the other specs.
Microsoft has already done a great deal of work on Trustworthy computing.
My ultimate objective is to make is possible for them to use the native
capabilities of their platform they have been working to establish.
Combined with the use of split key generation techniques, this enables the
use of 'blackbox' crypto tied to the machine without trusting what is in
the black box to do anything more than prevent the application keys being
used off the machine.
If the crypto is not done on the user's machine, then you
I am doing the crypto on the user's machine and in the cloud. I am not
using two key public key crypto, I am using three and four key techniques.
In particular I split the decryption key into two so that use of both
halves is required to decrypt. This allows the use of a cloud service to
block decryption by lost or stolen devices. Or just temporarily when going
through an airport.
This is not just openPGP or S/MIME crypto. It is making use of techniques
developed by Matt Blaze, Torben Pedersen and others since OpenPGP and
S/MIME were developed. It is true end-to-end encryption but with the same
flexibility and ease of use that Ford-Wiener style key release affords.

@_date: 2019-03-27 10:20:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Clinton email issues 
============================== START ==============================
version of the spec which uses Base32 in groups of 5 characters. The new
spec uses groups of 4. The same arguments apply though.
mb2gk- was just an abbreviation for mb2gk-6duf5-ygyyl-jny5e-rwshz.
That is about as long as can be put on a business card. It presents a
2^(125-8) work factor which is more than sufficient for the purpose of
introduction. If we were using a QR code introduction then we would go for
30 significant characters which is 2^(150-8) = 2^140, ample.
The birthday attack is not relevant in this case as we are presented with a
particular address that must be attacked.
When a SIN is first processed, the tools will pull the Mesh profile and
verify the hash. In the process reconstructing the full 512 bit SHA-2-512
output. The recommended approach is to store this value and store the
result with 250 bit precision for future comparison. I call this key
More bits is only more secure if people keep using the technology. The
longer the fingerprint, the less likely they are to use it. So there is a
balance point. But a SIN can be expressed with arbitrary precision.
One way to address this is with fingerprint compression. If the last 16,
32, 48 or 64 bits of a fingerprint are zero, this is noted in the lead byte
which encodes the digest algorithm and purpose. So there is the option to
perform proof of work hardening on the identifier allowing a 20 significant
char fingerprint to be used safely.
The other use for the proof of work might well be in spam control.

@_date: 2019-05-01 10:46:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain for encryption 
Looking for review and comment on the following:
The context for which this is designed for is described here but that
document is not complete, it is waiting on the code being finished.
I presented a part of the Mesh to a closed audience yesterday. Their
response was 'this is blockchain for encryption'.
Now as many of you know, I avoid the term 'blockchain' because, well there
is a huge amount of fraud in the crypto-currency world and one of the
biggest frauds is the security claims being made. And there is a huge price
bubble that is inevitably going to burst some time. And there is that
business of using 0.5% of global energy to support the system.
The audience in question specializes in information engagement and they
told me that what I was describing was blockchain encryption and either I
described it as such or people won't understand it.
The DARE container format is an append only log file with integrity checks
via a Merkle Tree and incremental encryption. Any record in the chain can
be encrypted under the (salted) result of a key exchange presented earlier
in the chain.
So one application could be incremental encryption of server log files.
Attempting to encrypt a log file by performing an RSA encryption of each
entry is obviously nonsense from the performance and data volume point of
view. Curve25519 is a little more practical but is still more overhead than
is likely to be tolerable.
The DARE structure uses a public key exchange to establish a master key.
Individual records can then be encrypted under a key generated from that
master key by means of HKDF Key Generation with a unique per entry salt.
The net result is that the DARE format can be used to encrypt arbitrary
numbers of entry or arbitrary size bounded only by the limitations of the
encryption algorithm (2^39 for AES), data length (2^63) and nonce size
(2^125 for the UDF scheme). These limitations could be lifted if people
think there is a good argument to do so. The only one I think might be an
issue is the one imposed by AES.
As you would expect from me, the format supports use of split decryption
keys so that decryption of the data can be gated on a decryption key share
in the cloud that does not have decryption capability by itself.
The container format supports rapid traversal in either direction by the
inclusion of frame length indicators at the start AND end of each frame
(always), Merkle tree indexing (optional) and direct indexing (defined but
not yet implemented).
The Merkle tree can be signed to provide non repudiable authentication for
the entire tree.
Besides GDPR compliant server logs, I can think of many, many applications.
I use the structure extensively in the Mesh to manage sets and lists of
entries. One of the applications I have always had in mind is end-to-end
secure Web services including chat rooms and comment forums/mailing lists.
So is there anything I must add?
Right now, I have not published my MetaNotary protocol because I haven't
implemented it. I have published the basis for the analysis though in the
trust paper.
A MetaNotary is simply any notary that includes the outputs of other
notaries. Thus it is possible to prove quite easily that no other scheme
can ever present a higher work factor than a MetaNotary since if such a
notary existed, the MetaNotary can simply consume its output as an input
and present at least equal the work factor.
The incentives for participating in a MetaNotary are very interesting and
very similar to the arguments I made when I invented the referer field in
HTTP as a mechanism to support advertising.
Let us say that there are notaries A and B who both serve separate
communities. The communities rate their notaries according to the work
factor that they present. Let us also suppose that notary C would like to
enter the market.
Notary C can offer a higher work factor than A or B by consuming both as
inputs. A and B can however match the outputs of C by agreeing to consume
each other as input.
Simulations show that the optimal strategy for notaries would be to consume
as many other notaries outputs as possible so as to increase their work
factor as much as possible and also to provide an incentive to other
notaries to consume their outputs as input.
The net is that I expect to see a notary structure emerge that is similar
in structure to the PGP keyserver infrastructure that has emerged based on
Brian LaMacchia's original MIT key server. Essentially, any notary will be
able to gain notarization of their output and fixing of their input by
contributing to and consuming from one or more public metanotaries.
In short, the system will hold together through reciprocity. Since
metanotary.com was taken, I call this the emergent reciprocal meta-system
the internotary.
While there are still arguable advantages of the Satoshi consensus
mechanism in terms of performance, it is an algorithm that cannot be made
efficient because it is the inefficiency of the algorithm that makes the
Satoshi consensus work. The internotary offers a different but compelling
compromise between partitioning, availability and consistency at negligible
cost. Furthermore, the internotary consensus does not require any
consumption of resources of any type.

@_date: 2019-05-02 09:05:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Blockchain for encryption 
Thank you for the comments.They are useful.
There are applications for which forward secrecy is essential and
applications where it is impossible. Forward secrecy makes no sense in an
infrastructure sharing credential information between devices. So I tend to
think we over-emphasize forward secrecy.
That said, I do have a design for forward secrecy, it just isn't made clear
in the current documents. I will add it to part 8 which describes the
cryptographic algorithms. The key agreement schedule uses a mix-in key on
both sides of the DH exchange as a nonce. All you need to achieve forward
secrecy is to pre-share the mix in keys and throw away the private keys
when you are done with the key exchange. This is essentially the photoris
This is not going to appear in the container format because the key
management has to be handled synchronously and containers are a storage
I have not given much thought to container roll-over at this point. There
are multiple ways of using containers and it is not clear whether roll-over
is a feature of containers or of a particular application of containers.
The first record of log file containers and persistence store containers is
usually empty. It would be logical to place a notary entry in the first
record. This could link to previous containers in the series and to
external notary sources.
At present, the question I have kinda punted on is whether to introduce
notary sources as content data or as header data. It might well be that
different approaches are appropriate for different container applications.
BitCoin is not my intended field of application :-)
This is more for applications like GDPR.
[Thanks for introducing the term traversal, I was using the word index to
mean two different things, will fix]
There are three traversal options, chain, tree and indexed. Which is used
depends on the application.
I have considered getting rid of chains entirely. But it is impossible to
differentiate these from indexed containers that have not been finalized
yet. One of the cool things about containers is that the append only
structure allows us to have multiple concurrent writers. So one process can
be appending to a file while another is compiling an index on it. Yet
another possibility is that the index could be maintained in a file
separate from the container that is indexed.
So consider a file archive. The most useful traversal mechanism would be to
have an index of every record in the file in the last record. This would
allow O(1) access to any record in the file if the index was appropriately
represented (i.e. JSON-B binary representation using table of fixed length
Index at the end is not possible for log files though. So we would likely
want to decide on some max chain length m (128 entries for example) and
then create a delta index every n entries and compile these into delta
trees giving us O (m + log2 (n) - log2(m) ) efficiency in time for O(nl/m)
additional space (where l is the length of the index entry)
The notaries can collude but the collusion is visible to anyone running a
notary or observing the system. If the system is sufficiently large and
public, we would have the US, Russia, UK, Iran, France, Cuba national
notaries all in the mix and they would all have to collude. Plus the EFF,
Microsoft, Apple, Google.
Collusion can be proved because the notaries sign their terminal nodes
according to a published schedule. Any notary that fails to deliver its
signed node is in arrears, any that is shown to have signed two
incompatible terminal nodes has defected. Defection is highly visible.
Applied to finance, the question that I think BitCoin folk miss entirely is
that the banking system has held together for 300 years performing
reconciliations only at the end of each day. I just moved my 401K from one
institution to another by way of a cheque. Looking at the possibilities for
default in that system, the possibilities for default in the internotary
system look rather minor. Notaries can collude but only so long as they can
prevent any leakage of the signed notary outputs outside the system they
have defected on. Once they defect, they must continue to maintain a second
chain. Defecting multiple times requires multiple chains.
The cost of maintaining the defection rises exponentially as the outputs
are introduced to other notaries which must also be induced to collude.
Ultimately, I believe the internotary system must hold together as the
incentive to refuse defection rises as the value of the system rises but
the incentive to coerce defection is never as great as the value of the
system and is likely constant.
So when the system starts, I would not expect many people to put much trust
in it so there would be essentially $0 incentive to induce a defection.
Five years on, we might have a dozen groups at the likes of MIT, Apple, EFF
etc, running 'unofficial' services. It is doubtful that such a system would
be used for financial transactions but there might be a $1 million
incentive to induce a defection to assist a US criminal investigation.
Well, we already know what happens to those.
Ten years on we might well be using the system for financial purposes and
have a few hundred banks running notaries. At this point it is infeasible
for any one government to subpoena all the notaries and attempt to coerce
them. So there might be a $30 million incentive to coerce a defection (i.e.
upper level of FBI most wanted bounties) but the incentive to resist
defection would be $1 billion with expectation of rising to $1 trillion.
Yes, collusion is possible but the system would be in the hands of the
people who have the greatest investment in the system itself. The system
hangs together because of accountability. Any defection is certain to be
detected and lead to consequences.
Now there would of course be small scale 'defections' resulting from
technical issues and even small scale fraud. But it is highly unlikely that
this would ever spread from one notary to another.

@_date: 2019-05-06 10:16:55
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Schnorr multisignatures based on ED22519 
I think the Schnorr signatures are really useful and important. But I would
need to see a CFRG RFC and peer review before making use of them in a spec.
I do use the same types of technique for encryption but that doesn't worry
me because DH key agreement doesn't disclose the private key even if you do
it wrong. El Gamal signatures do.
It is not just disclosing the private key that is bad. There are pairs of
numbers that can be disclosed that allow an attacker to create new sigs
even if they don't know the private key.
There is a vast amount of detail there that I just don't have swap space
for in my brain right now. So lets pass it on to the people who think about
nothing else and get some grad students on the problem

@_date: 2019-05-17 10:07:08
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Voynich Solution Claimed 
At the time it was written, alchemy and divination were considered valid
modes of scientific inquiry.
I rather suspect that the work is asemic writing produced by a skryer,
quite probably under the influence of some drug.
There are few examples of that type of work that have survived which is
hardly surprising as possession would be dangerous and could easily end up
with the owner on a bonfire along with the book. We do not at this point
know if John Dee actually owned the Voynich manuscript as Voynich himself
believed but we do know that he owned at least one book of this type and
that he employed a skryer.
The manuscript itself suggests that it was written by someone who had been
trained in or was at least familiar with calligraphy. That is probably why
it survived. Most examples of the form would be produced very quickly in a
trance like state. This one is the opposite. It clearly took considerable
time and investment to create. Parchment was expensive. But some of the
illustrations appear to have been produced by a child and there is evidence
of many hands.
i think the most likely explanation for Vonyich is the same as the unsolved
Beale ciphers: Gibberish produced to make money.
I suspect that the author-group discovered that they could sell works of
divination to some patron and the more complex, the higher the price. So
they started making increasingly elaborate illustrations and decorated them
with fake texts. At some point, the collection grew to the point that it
was compiled into the current folio which has survived because it is pretty.

@_date: 2019-05-19 00:01:44
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A two key file/program 
Splitting keys is fairly straightforward, Shamir secret sharing does the
But that doesn't meet your requirements as stated and to get the best
solution you probably want to step back and look at the security of the
system rather than the security of the passwords. Passwords are a terrible
security mechanism to be avoided whenever possible. Unfortunately, that is
rarely possible right now.
I am working on a system that might eventually be relevant but is not going
to be ready for that type of application this year.

@_date: 2019-05-19 18:47:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Network Time Protocol security 
Let us step back and ask what the actual security requirements are. I don't
think they are quite the same as what secure-NTP would provide.
There are three separate issues:
1) Is the current time after time t1?
2) Is the current time before t2?
3) Did event A happen before or after event B?
For purposes of preventing replay attacks, use of expired credentials, etc.
it is usually acceptable to have the current time correct to a few hours.
For purposes of timestamping logs, etc, I would normally want the time to
be correct to ten seconds or better.
For purposes of performing transaction processing, I don't need time at all
to decide if A happened before B, I need a transaction log.
So the sort of answers I am looking at are very much more along the lines
of 'blockchain without the inefficiency of proof of work, stake, etc.'
Since the time is a subjective quantity, this is an area where some form of
trusted party is going to be inevitable but we can use meta-notary type
techniques to produce ridiculously high work factors.

@_date: 2019-05-23 11:47:26
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Craig Steven Wright's Bitcoin Copyright 5-20-2019 
Those of us in the email space will remember the story of a chap whose
claim to have invented email rests on having 'copyrighted' the term. This
is obvious nonsense of course because his claim was filed long after
Tomlinson actually invented email. But he has sued a number of places for
calling him out as a liar.
He tried to run for Senate against Warren and some of his posters are still

@_date: 2019-05-28 15:44:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Craig Steven Wright's Bitcoin Copyright 5-20-2019 
On the contrary, it prevents him adding me to the list of defendants in his

@_date: 2019-05-28 16:53:54
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The race to Quantum machines. 
Oh the number of Qbits needed has indeed reduced. But the optimizations
that they are employing are not necessarily valid for the problem of
factorizing RSA moduli. Consider for example, this special case:
Pretending to factor large numbers on a quantum computer
Basically, Smolin and Co show that the optimizations being employed to
reduce the number of QBits required to implement Shor's algorithm kinda
depend on already knowing the factors of the number.
So yes they are implementing Shor's algorithm but no, they are not
developing systems that can break a deployed RSA scheme.
Oh and it gets worse (or better from my point of view). The claims being
made for increasing the number of QBits don't necessarily represent an
increase in processing capability.
It is all really murky. The bottom line is that we need to take the
potential for quantum cryptanalysis seriously because it could be
devastating for electronic commerce. But we certainly do not need to panic.
The engineering obstacles that need to be overcome to make Quantum
Cryptanalysis viable are of the same order as those required to make fusion
power work.
The other point to bear in mind is that we won't know whether there is a
limit to quantum entanglement until we encounter it. There is no law of
physics that states we must be able to form arbitrarily complex
superpositions of quantum states. That is an assumption in our current
models of physics.

@_date: 2019-05-29 09:34:19
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The race to Quantum machines. 
"All attempts to find an experimental regime where quantum mechanics fails
have failed"
That is not remotely true. We still haven't figured out how to make gravity
work. More relevantly, what exactly do we mean by decoherence? what exactly
is it that causes it?
The assumption here seems to be that the only reason to build quantum
computers is to break RSA. That is not the case. Quantum simulation is the
real prize and what I am saying is that we might well find that there is
some effect that imposes a limit there.
We have yet to see a situation where investing $x.Y produces a quantum
computer that is more than x times faster than investing $Y in a quantum
computer. It is not just the number of QBits that is at issue here, it is
the number of operations you can perform before you lose coherence.
People should recognize that quantum computers are a cheap way to do
experiments in fundamental physics at this point. This is science, not
engineering. I used to do experimental particle physics so it is science I
am somewhat familiar with. But it is still not engineering and unlikely to
be for another decade or two if ever.

@_date: 2019-11-07 10:49:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Libra is technical junk 
Use of threshold signatures in this context is just bizarre. If you want to
know if Alice and Bob both signed a message, the simplest mechanism is for
Alice to sign it and Bob to sign it and put both signature blobs on the
I see absolutely no reason not to do that in a new protocol or for that
matter in any protocol where the signatures come from different parties.
The only use case I have for threshold signatures is to enable the private
key operations to be split across devices. That is a completely different
case to the one Libra appears to be addressing.
I am not at all opposed to the use of crypto that is outside the canon. But
anything we add has to be added for a really, really good reason. It is not
clear to me that Libra has good reasons, it seems like it might be more
like someone is trying to use as many bright shiny objects as possible.

@_date: 2019-11-08 23:38:19
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] References for recovering the y coordinate in a 
I have a problem, I am trying to add two RFC7748 aka CurveX25518 points and
it is only working half the time.
The problem here is that the montgomery ladder only uses the X point, the y
point is ignored. And that means that the sign on the y point is also lost.
Since the curve is symmetric about the x axis (y^2 = ...), guessing y is
positive (or even) and drawing a line between the two points is going to
give the correct x if both guesses are right or both are wrong. If one is
right and the other is wrong... oops.
I have found some discussion on the net on recovering the y coordinate from
the Montgomery ladder. But it is kinda icky to refer to random blog posts
in a spec. And not being a number theorist, it is going to take me quite a
while to get familiar with the notation in the original papers.
Can anyone point me to a crib?
Preferably with like working code in Perl or C# :-)
One of the accumulators is sU. The other seems to be (s+1)U. Since all I
need is the sign bit, I could try suck it and see.... but seems icky.

@_date: 2019-11-19 13:52:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] How can poor/bad/compromised random number 
But don't allow this or any other failure of BitCoin security ever lead you
to doubt the absolute inevitability of the global financial system being
This is differential security: No insecurity in the BitCoin system can ever
be considered significant because it is only a proof of concept. At this
stage it is sufficient to demonstrate that there exists the possibility of
a security control that might address the issue with some degree of
effectiveness sometime.
Meanwhile any and every failure in the existing payments infrastructure is
not only a valid criticism, it is proof of its inevitable collapse.

@_date: 2019-10-17 16:23:31
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Very best practice for RSA key generation 
A question has come up for generating key pairs from a specified random
seed. I am just looking to add this to UDF and would like advice as to what
the very best practices are for RSA keygen.
The use case here is that the user wants to be able to be very very sure
the key was correctly generated and that they can recover it. So lets say I
want to configure OpenPGP with the same keypair on three different machines
without the full Mesh PKI.
The basic idea is that a user has a key which expressed in Base32 looks
like this:
The first three bytes are
C8     Type code for key generation with 16 bit key type]
00,00 RSA 2048 bit key pair
The remaining characters are to provide randomness for the key
generation function. A minimum of 112 bits (work factor of RSA 2048) are
required. So 112+24 = 136 bits
To generate keys, HMAC-KDF is used
p0 = KDF ("ZAAA-UJUY-H7TF-SFLK-CWAW-TKC4-O5HQ".FromBase32(), "P")
q0 = KDF ("ZAAA-UJUY-H7TF-SFLK-CWAW-TKC4-O5HQ".FromBase32(), "Q")
p = next_prime (p0)
q = next_prime (q0)
So that is the RSA part.
I don't plan to do DH. For ECDH, I suggest the NIST and CFRG curves only.
OK so some interesting variations. Lets say I don't trust the random number
generator on any one machine. So lets use Shamir Secret sharing on three
different machines for a 140 bit output:
f(1) = SAYE-UHOY-TVZO-LPGT-ZAGE-7JUW-6MTJ-I
f(2) = SAYX-4HWP-3753-L4P3-N4S6-C2G4-QVPA-A
f(3) = SAZD-HQNJ-KSDK-HAY7-BIFO-34Y2-NH7O-C
We can now combine the shares on the target machine to (re)generate the
keypair. We can also give ourselves a couple of additional shares as well:
f(4) = SAZW-WBTE-7MJ2-44B6-TC5X-KRKQ-UEEW-U
f(5) = SA2C-H3IC-2ORN-NOK2-DM3X-OX37-FJ6W-Q

@_date: 2019-10-20 18:51:09
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Very best practice for RSA key generation 
Easy enough to implement and eliminates the issue.

@_date: 2019-10-20 20:37:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Very best practice for RSA key generation 
Absolutely. And the spec and the code say to do exactly that!
Unfortunately... I forgot to set the topmost bit to 1 which is also
I turned this out on Friday to further discussions:

@_date: 2019-10-22 20:53:25
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Very best practice for RSA key generation 
Yes, that is actually the scheme that I implemented in my code. I will
include Christian and Jonathan's point in the next iteration of the draft.
The part I am still trying to work on is exactly where the MUST/SHOULd
boundary lies. There are some requirements for P+/-1 be auxiliary primes
which I am thinking are best punted on (if people care about such things,
generate seeds until you get an acceptable result).
One thing I had not expected was that it turns out that some
implementations require p>q or q>p even though the algorithm should be
neutral on that issue.

@_date: 2019-10-24 10:55:22
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Jim Baker explains encryption to us 
But is he actually wrong?
"But, for the reasons discussed above, public safety officials should also
become among the strongest supporters of widely available strong
There isn't a single set of arguments against backdoor encryption and some
of the arguments made are far weaker than many on this list imagine. This
is not a US issue, it is a global issue. Europeans are far better informed
on the origins and effects of the second amendment than its adherents
The argument that backdoor cryptography is technically infeasible is also
rather weaker than many imagine. A very large part of the reason the
telephone system failed to develop is that it was locked into an obsolete
architecture by the demand for intercept capability. In the UK, System X
had a feature that allowed any landline to be turned into a listening
device whether it was off the hook or not. Maintaining that capability
required that the choice of telephones available in the UK be limited to
the standard GPO model, the trimphone and a mickey mouse model.
Of course there are serious technical and political difficulties in
mandatory backdoor cryptography. Not least being that most of the computer
equipment sold in the US is made in  a police state with a million
political prisoners being held in internment camps in the North West
province. Does the US really want lawful intercept at the price of giving
China access as well?
But I am certainly not going to pretend that it is the technical concerns
that motivate my actions. I have purposefully designed the Mesh so as to be
as resistant to the introduction of backdoor cryptography as possible and I
am not going to pretend otherwise for imagined political expediency.
The reason we have to win this is that we simply cannot trust the FBI to
implement the checks and balances promised. The whole history of the
organization, from J. Edgar Hoovers political abuse of his powers to crush
the civil rights movements to Jim Comey's letter which put his thumb on the
scales of the 2016 election.
If we do indeed face a 'going dark' issue, then the FBI needs to begin by
demonstrating good faith itself. This must begin with the removal of the
name J. Edgar Hoover from its headquarters and the separation of the police
and counter-intelligence roles into separate agencies in separate
buildings. Such changes would not make me change my position but they are
the minimum needed to demonstrate a modicum of sincerity.
As most of you know, my personal family history means that my experience of
terrorism long predates 9/11. I find it really difficult to take the
purported opposition to terrorism seriously when the President's personal
lawyer is a man who for many years raised many millions of dollars to help
by bombs and bullets and guns to murder people in my country.
The US is about to impeach the President and quite possibly remove him from
office for systematic abuse of power. But I for one am not minded to
provide any covert surveillance capabilities to any country where one of
the major parties will tolerate a candidate for political office who
screams 'Lock her up!' as a staple of his Nuremberg rallies.

@_date: 2019-10-28 12:52:26
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Very best practice for RSA key generation 
That is already a suggestion in the Internet Draft but not one that has
been implemented yet.
The basic idea is to take dictionaries of 32,768 or so words for common
languages, form a Merkle tree out of them and print the apexes out. These
can then be used in combination with a simple Web Service that simply
extracts the proof chain for specific words.
With 65K words (feasible for English), that means 16bits per word. A 2^128
work factor requires ten words including the overhead.

@_date: 2019-09-19 16:29:58
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Fwd: How much data should Mesh Services see? 
I sent this to the IETF Mesh discussion list but would appreciate folk here
joining in the discussion as there is an important and difficult problem at
issue here. I have just rewritten the Mesh so that there is now almost no
information on the service except for the minimal amount of metadata
required to enable the service to perform the tasks delegated to it by the
The interactions supported by the Mesh do require some form of drop-box
type functionality and at least a part of that functionality must be in the
cloud. I can reduce the degree of trust in that service to the bare minimum
but while I can prevent confidentiality breaches and provide strong
guarantees of integrity, the service is by its nature always going to be a
point of vulnerability for traffic analysis, metadata and service attacks.
The IETF list is here, conversations there are covered by Note Well.
I am almost done getting the 3.0 reference code to run. This was a very
substantial rewrite as it meant using the features I intended to build on
top of the Mesh to secure the Mesh itself.
At the moment there are three basis constructs
*Mesh*: User Alice has exactly one Mesh to which she connects all her
*Account*: Alice can create as many Mesh Accounts as she likes and they are
each insulated from every other account. A device may be connected to
multiple accounts.
*Service*: A minimally trusted Internet service that provides a point of
contact through which devices connected to a Mesh Account may be
It is not necessary for Alice to create multiple Meshes to protect her
privacy because it is a purely personal resource that is only used for the
management of devices and accounts.
A Mesh account may be connected to multiple services but only one of the
services is authoritative. The user may change their service at any time. I
have not implemented a transition protocol but since every Mesh contact
exchange is bound to the account UDF fingerprint, we can easily effect a
change of service by simply dropping a signed assertion into some sort of
public log.
"MeshAccount" : { "ServiceIDs" : ["alice at example.com",  "alice at example.net
"KeyEncryption": "MD67-UDAY-6JTI-BVTV-ZQBE-S2L5-HXCX"
 MDXC-UHN2-UXXU-3MAD-QHPR-3VMA-WOXA
Where  MDXC-- is a key attesting to the account profile...
OK so the idea of the service is that it just holds a sequence of DARE
catalogs which are just lists of envelopes with a header, encrypted blob of
data and a trailer.
The problem lies in the fact that the service needs to know some of the
contents of some of the catalogs. Specifically:
Device catalog -
    Needs to know if a ConnectionDevice has been updated or revoked.
    Needs to be able to retrieve the device entry by an index known before
the device is connected.
Contacts catalog -
    Needs to be able to determine that an inbound Mesh Message is sent by a
party authorized by the recipient.
    Need to be able to determine that an outbound message sent by the user
is not likely to be abusive.
Filtering inbound messages is relatively straightforward as we can easily
require the message envelope to carry whatever information we like. We
could even require it to contain a token of the form 'Alice is allowed to
speak to Bob', i.e. a capability. I think it more likely however that we
would want to enable anyone to communicate with anyone else without
requiring every possible link be represented as a capability. Not least
because I don't think Bob wants Alice to know precisely what those
capabilities are.
So I think the wrapper of a Mesh Message from Bob to Alice is going to be
limited to a signature by Alice's device and an authentication chain plus
the strong address of Bob, i.e. the service address plus the mesh
fingerprint of the account.
Which means that the contacts directory is going to need to include some
unencrypted information that allows it to 1) locate Bob's entry in the
contact catalog using his strong address(es) as index and 2) determine if
the strong address is authorized for the operation in question.
I am aware that there is something of an efficiency issue here and it is
probably not desirable for an Internet service to be constantly parsing
structures as complex as a DARE Container every time a message is received.
But this is fairly easy to address using a 'hot index' file which the
service can compute from the container as an offline task. We can now
perform a lookup in O(1+u) time where u is the number of updates written to
the container since the index was calculated. The container file format
even allows such an index to be written to the end of the container itself.

@_date: 2019-09-22 14:25:59
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "How Long Will Unbreakable Commercial Encryption 
I find it really difficult to believe that there will be governments in the
EU that are strong enough to push through such a ban in the next decades.
The UK Tory party has just split and will quite probably not form another
administration in our lifetime. It is highly unlikely that there will be
any single party government in a major European country for the next decade
or more.
The other major issue is that the current President of the United states
gained election by corruptly conspiring with a foreign dictator. He has
since attempted to blackmail another foreign leader to fabricate a case
against the leading contender for the opposing party nomination. And he is
openly abusing his office to cover up both crimes. It is hard to see in the
present political circumstances how there is going to be any willingness to
grant the executive greater surveillance powers. The president's opponents
fear they would be abused, his allies fear that they will be used against
There is a considerable amount of concern about the power that Google,
Facebook, etc. have acquired. But that is in relation to their
custodianship of information that has little if anything to do with
cryptography. It is the use of Deep Learning etc. to uncover information
that society assumes to be private that is of concern.

@_date: 2019-09-23 22:40:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Crown Sterling debunked 
Yes... I know...
But it seemed to me that Bruce didn't quite get the right smackdown. Yes,
has all the signs of snake oil cryptography. But this is cryptanalysis
and so in addition to all the points he raised about snake oil algorithms
being stinky, there is a second list of issues that apply to cryptanalysis
Not least of which is 'why not solve the RSA1024 challenge puzzle'.
Given the Quantum Computing related snake oil claims we all know are
coming, it is probably worth while practicing smackdowns or the press will
be full of 'em.

@_date: 2019-09-24 10:14:02
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Crown Sterling debunked 
Are they? I can see that breaking the discrete log is going to affect
elliptic curve DH. Or at least could do.
But the ECDH problem is multiplication of a point by a scalar x.y.P ==
y.x.P. How does a logarithm come into it? extracting the private key from a
public key would be solving the point division problem surely (x = x.P/P) ?
Not saying you are wrong, just interested in the reasoning here.

@_date: 2020-04-02 23:57:53
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
It is all fixable. Question is whether they will have the nouse to fix it
or not.
We should have an open standard for end-to-end secure video conferencing
that uses a client that doesn't have HTML, Javascript and all that stuff
included in it. Which leaves out WebRTC as well.
Having been thinking on these lines, the pushback I have got from the
people in the field are that the reflector has to be able to see the
plaintext of the fields because that is the only place they can think of to
change the resolutions.
I think the obvious answer is to do resolution changes at the device that
is originating that image. So there are three basic possibilities. My
camera is off, My camera is on and I am sending a thumbnail image and My
camera is on and I am sending separate thumbnail and large images.
Of course 'thumbnail' probably means dropping the bit rate as well. So we
want to expose enough information to the reflector to allow it to know
which encrypted frames are the keyframes, which are the deltas and so on.
So the hard part is in the encoding stuff. And you have to really have a
handle on that because all the major platforms have very different API
models so that they can make use of the hardware assistance for the CODECs .
I remain profoundly unmoved by the obsession certain folk have with 'off
the record' capability. The MLS tree is just too complex to be viable in my
opinion. I want end-to-end secure communications of course. And sometimes I
want forward secrecy. But in an enterprise setting I want to record a lot
of calls and store them on disk forever because this is about getting work
done, not playing Mission Impossible. I never did understand why the
recording announcing a mission self destructed when it came with a big fat
dossier that was far more sensitive.
So the approach I am taking is to make use of threshold cryptography to
provide end-to-end security. There is an encryption key for the group and a
separate threshold split of the private key for each member the
administrator adds.
In the case that we want a portion of a conference to be off the record
(i.e. with forward secrecy enforced), each participant's device posts an
ephemeral key that is used to establish a second shared secret with either
the key management service or an administrator. If you have 100 people in
the channel and you rekey once an hour, having that performed by
administrator's machine is not a problem. If you have more than 100 people
in the conference your cryptography is nowhere close to being your weakest

@_date: 2020-04-05 12:07:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
Looks like the system has the same problem as Signal: Yes the
communications are end-to-end but you are trusting the provider of the
client (and possibly the service) to not defect in the face of a government
warrant. If there is only one client provider, they can change the protocol
without telling anyone. Signal is particularly awful in this respect as it
seems to demand an update every ten days.
My concern about the risk of government mandated backdoors is considerably
greater with the greatly increased likelihood of an attempt to cancel the
November election in the US.
The underlying problem is that no communication infrastructure built on a
monopoly service provider can be secure against this type of attack.

@_date: 2020-04-05 16:32:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Privacy post COVID 
In the short term the choice is going to be wear a mask and run a GPS
tracking app whenever you step outside. And there is going to be an
effort to continue that level of surveillance after the COVID crisis has
It is also possible that the reverse will happen and that having sensitized
everyone to the privacy implications of Bluetooth etc, there is a backlash
against tracking technologies of all types.

@_date: 2020-04-08 11:39:59
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Privacy post COVID 
There are two problems here. One is how to end the lockdown and the other
is how to protect privacy.
I am pretty sure we are going to be seeing attempts to introduce
surveillance technology that is a lot more intrusive. But thats not the
only thing likely to be happening. A lot of countries are likely headed for
a lot of civil unrest. Authoritarianism is a brittle form of government,
they are prone to collapse.
The normal pushback against surveillance is that the authorities are only
interested in 'those' people so if you are not one of 'those' people, you
have nothing to worry about. That tends to fall apart when everyone is one
of 'those' people. The consequences of mass surveillance are suddenly
I am seeing a lot of people making unilateral demands for privacy
protection and a lot of people making unilateral demands for tracking of
potential infection. But I am seeing almost no interest in attempting to
find solutions inbetween. And if push comes to shove, I can't see privacy
winning if the alternative is staying inside for two an extra months.
What we need to be looking at is what is essential in an infection tracking
technology and what is not. And that is pretty difficult when we have a
bunch of governments still trying to cover up for their earlier blunders.
The UK govt. is still trying to argue that it wasn't a mistake to keep the
schools open for two weeks longer than the rest of Europe which is a big
problem when there are ministerial advisers whose only qualification is in
Greek poetry arguing to re-open the schools right now.

@_date: 2020-04-10 12:14:35
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] But Zoom is fixable 
A quarter century ago, I was in a meeting at MIT where we reviewed a number
of new security protocols. One of them was so hilariously bad it was broken
less than ten minutes into the presentation.
That protocol was the never-released SSL/1.0 which eventually evolved into
TLS and is the basis for almost all the security in use on the Internet
Thats the way we do crypto: people try stuff, it sucks, we fix it. It would
be nice if they came and asked us before they put a product out but Zoom
lost $10 billion off their market cap over this flap. Good crypto people
aren't cheap but Zoom can easily afford to fix this. I am sure there will
be no shortage of top rank folk willing to join up to their technical board
because this is a technical board which might actually meet (virtually) and
do something for a change.
There are quite a few constraints that make this an interesting problem.
One constraint that I see a lot of people failing to understand is that
ease of use is king. Security that demands anything of the user is not
going to fly. The challenge is not to make a version of Zoom with all the
usability of the PGP mode in vi. The E2E version has to be
indistinguishable from the regular Zoom experience unless the user decides
to ask how secure they really are.
When the phishing issue hit the banks hard at the turn of the millennium,
one of the things the Bank America people told me was they wanted a
solution for the banking industry, not just for BofA: We don't compete on
There are really good reasons why the banks don't compete on security.
Breaches at one bank cause a general loss of confidence in banking. The
banks were keen to see their customers banking online, not inline at their
expensive to maintain branches.
We have to approach Zoom security with the same mindset. This is an
industry problem and we need to fix it. Given the circumstances, the short
term fix is going to have to be a proprietary one with limited
functionality. But the long term goal should be an industry standard
security protocol that provides E2E all the time unless there is a gateway
to a non E2E system in use.
Threshold crypto allows features like cloud recording to be supported.

@_date: 2020-04-11 15:38:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Apple releasing a crypto spec COVID-19 tracking 
I have been looking at this proposal and it looks to me like we are only
seeing half of it. So I am having to infer quite a bit.
So the basic math seems to be device generates a master key from which a
series of daily keys are generated using the number of the day as a salt.
These are then broadcast via bluetooth. If the user is found to have been
infected, the subset of the daily keys is called the 'diagnosis keys'. This
is then communicated to some form of publication service.
What is not immediately clear is how secret the master key is. The spec
implies that this is fixed for a given device for reasons I am not
completely clear on. It is not clear that the device manufacturer can't
reconstruct the master key.
The other part that is less than clear is what is then done with the data
in the case someone is identified as having the disease. One possibility is
that everyone downloads the entire database each day and sees if they have
been infected. Another is use of some form of homomorphic scheme to allow
Alice to determine if her daily key is among the ones possibly contaminated
or not without disclosing that information to anyone else. This bit of the
description seems a bit sketchy...
So the intent seems to be to construct a scheme that allows
1) Alice to determine if she was in proximity to other people who were
2) Allows the authorities to determine how many other people Carol with
Covid was in proximity with but not who they are.
The scheme seems to be relatively robust in isolation. If this is all the
information I was giving out I don't think it would represent a huge
privacy concern given my current travel pattern. The identifiers are only
linkable across a day and I go to about one shop a week if that.
Where the scheme probably fails is when this data is mixed in to all the
other linkable identifiers my devices are constantly spewing. There are the
pressure sensing caps on the tires of the car for a start. And the phone is
spewing identifiers and the MAC address on the WiFi and the bluetooth.

@_date: 2020-04-25 00:00:03
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Introductory course on Cryptography 
I have started filming an introductory course on cryptography and data
security. The first two modules are up:
Also a bonus episode looking at the Apple/Google tracing scheme:

@_date: 2020-04-28 23:36:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The EFF 650 CAs lie 
Years ago, the EFF set up its infamous Certificate Observatory, looked at
the network of public intermediate certificates that had been issued,
called each intermediate a 'CA' and issued what has become the zombie lie
of 650 CAs.
It was not a deliberate lie at the time it was said but it has become a lie
since with the obstinate refusal to correct the record. I am going to be
taping a module on PKI for my course on cryptography and it would be much
better for all concerned if I could say the EFF has finally retracted this
I have no idea who I could contact at EFF who could get this fixed but the
lie continues to be repeated and it is high time it was retracted.
As was explained at the time and on numerous occasions since, a CA is a
body that has control of at least one Certificate signing key. The vast
majority of the '650 CA's identified in the study control no signing keys.
They are simply customers of a CA whose certificates are issued off a
separate intermediate root.
That the EFF analysis was off should have been apparent from the fact that
a very large number about a third of the total of the intermediate certs
are all subordinate to one CA, the DFN root. The failure to check up with
DFN to find out what was going on smacks of agenda pushing and frankly a
willingness to fund raise off a lie
Had the researchers contacted DFN, they would have discovered that DFN is
the only party that acts as a CA, the only party that has the ability to
sign certs, no cert signing keys have been passed to other parties etc.
This was pointed out at the time and many times since.
Ideally, an intermediate issuer would be constrained using PKIX
constraints. Unfortunately, the PKIX specification and the Apple
implementation make that impossible as some idiot thought it a good idea to
require constraints be marked critical (i.e. use the break if the extension
is not understood feature) and Apple's browser didn't understand them at
the time. One of the sad mistakes in PKIX was giving the criticality flag a
name that caused people to mistake it for meaning 'this is very very
important'. It means nothing of the sort it means 'break everything if this
is not understood'. And it should never be used unless failing to
understand an extension would cause an invalid cert to be considered valid.
The article is still on the EFF site. It is high time it was retracted.

@_date: 2020-04-30 13:29:56
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The EFF 650 CAs lie 
As with Trumpian lies, the problem is that different criteria are applied
to the statements at different points in the argument.
When asserting that there are 650 'CAs', an informal standard is used.
When asserting the number of CAs is a serious concern, the technical
standard is used.
EFF repeatedly used this study to argue that there were too many parties
with the ability to sign certificates. They used the informal definition to
claim there was a large number of CAs and then the formal definition to
assert that there was an unacceptably large number of signers.
Actually it makes a vast difference both legally and technically.
The question is who can be held accountable for mis-issue. An LRA or RA
cannot be held accountable, only the CA can. Only the CA issues a
Certificate Policy and Certificate Practices Statement. If there is a
mis-issue, it is the CA that suffers consequences.
The suggestion that there were 'thousands' of CAs is still used today to
justify changes
The question is where that demonstration is verified.
If someone is making a claim there is an order of magnitude more
verification points than actually exist, that is a problem.
If we are going to improve the current situation, we have to be honest
about what the problems were with the old.
If someone is attacking a witness for 'not taking a lie detector test', I
will invariably object that means nothing because the tests are bogus. And
I do that regardless of whether I consider the witness otherwise credible
or not. Introducing a false claim into the argument confuses the issue.
The problem with DNSSEC is that there is only one provider. And that
provider is (justifiably) regarded as a US government agency by Russia and
China. And so they have made plain that they will not tolerate widespread
use of DNSSEC.
But the real problem of the WebPKI today is actually the exact opposite of
'too many CAs'. The market has consolidated to the point where two
providers have an effective duopoly on the commercial side and there is one
free provider.
So now we have the 'too big to fail' problem. And note that when one of
those three recently screwed up in a far more egregious fashion than
Symantec did, they were not shut down.

@_date: 2020-04-30 13:49:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The EFF 650 CAs lie 
============================== START ==============================
That is not what I am criticizing them for. Anyone can get the analysis
The problem is the refusal to correct the mistake after it was made.
It took me less than an hour to find out what was going on at DFN. I sent
them an email and they replied. I forwarded the response to the EFF.
EFF has known that the claims made about DFN were bogus all along. They
were told within days of publishing the original claim. They have repeated
the claim multiple times since without modification.
Oh yes and that business of me working for a 'for profit' CA. That has not
been true for well over a year. At this point it is now the EFF that is in
a position to profit greatly from the situation they helped create. Lets
Encrypt is probably worth in the region of half a billion dollars.
Oh! Oh! people shout. But Lets Encrypt is 'not for profit'.
Well so was the PIR registry behind .ORG, guess what happened to that.
TrustE began as a not for profit as well.
I knew the reason for that. We had a two day conference at NIST and finally
worked out why the spec was broken and unfixable. Can't remember the
PKIX is a very old and complex spec. I spent 25 years wrestling new
features into it. And most of the time found it wasn't possible.
Not if it is an additional control rather than a critical control.
Setting the critical bit meant the certificates would be rejected by a
significant proportion of the installed base. So no CA was going to issue
certs with it set. Contrawise, Apple had no intention of implementing a
feature 'nobody used'.
The requirement to set the critical bit sets up a deployment deadlock.
The minute CAs start issuing certs with soft constraints, browsers that
didn't implement them have an immediate incentive to change because if they
accept a cert that should have been recognized as invalid, they are now at
fault for not implementing that feature.

@_date: 2020-08-06 14:13:15
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] What type of nearest prime is most likely to be 
A while back, I asked about next prime generation for use with Shamir
secret sharing.
I have since revised my spec after discovering that my previous approach of
rounding up secrets to a multiple of 32 bits was a bad plan. So I now have
a list of offsets that are to be used to deterministically generate a list
of primes p such that:
2^n < p < 2^(n+8)
I am using these for Shamir secret sharing which is information theoretic
secure so there are two obvious choices:
p = Nextprime (2^n)  or   p = PreviousPrime (2^(n+8))
I have generated both tables (attached in case someone feels like
checking). Question is which is the better choice for other applications?
I am inclined to pick  p = Nextprime (2^n) because that results in the
least bias when selecting a random number in the interval 0 <= r < p using
the modulo reduction approach:
Select n+8 bits of randomness, reduce modulo p.
So for an 8 bit value p = 257. Generate a 2^16 bit value and the
probability the result is 0 will be 1/256 and the probability it will be
1-256 will be 1/255. Which is not completely flat but near enough for most
purposes. And we can get the result as flat as we like using n+32 or such.
So what to pick or doesn't it matter?
        public readonly static int[] PrimeOffsetNext = new int[] {
            1,            1,         43,          15,
            15,          21,         81,          13,
            15,          13,          7,          61,
            111,         25,        451,          51,
            85,         175,        253,           7,
            87,         427,         27,         133,
            235,        375,        423,         735,
            357,        115,         81,         297,
            175,         57,         45,         127,
            61,          37,         91,          27,
            15,         241,        231,          55,
            105,        127,        115,         231,
            207,        181,         37,         235,
            163,       1093,        187,         211,
            21,         841,        445,         165,
            777,        583,        133,          75
            };
        public readonly static int[] PrimeOffsetPrevious = new int[] {
            5,           15,          3,           5,
            87,          59,          5,          59,
            93,          65,        299,          17,
            17,          75,        119,         159,
            113,         83,         17,          47,
            257,        233,         33,         237,
            75,         299,        377,          63,
            567,        467,        237,         189,
            275,        237,         47,         167,
            285,         75,        203,         197,
            155,          3,        119,         657,
            719,        315,         57,         317,
            107,        593,       1005,         435,
            389,        299,         33,         203,
            627,        437,        209,          47,
            17,         257,        503,         569
            };

@_date: 2020-08-24 12:38:03
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] any reviews of flowcrypt PGP for gmail? 
Telegram and Signal have the same issue with the possibility of downloading
a poisoned update. Signal in particular demands weekly updates.
The only way to be confident of the code is if there is a genuinely open
standard and open service model. Neither Signal nor Telegram qualified.

@_date: 2020-08-25 23:31:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] any reviews of flowcrypt PGP for gmail? 
I don't see additional functionality between updates. If they are having to
make updates that frequently just to patch security holes, something is

@_date: 2020-12-17 11:23:49
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Am I missing something about CBDC ? 
This is how I would do it.
Think of it as a return to 19th century banking. Every bank runs their own
ledger. So there are 20 banks (say). Every transaction is between customers
of the same bank or between the customer and their own bank.
Interbank transfers are then handled by a system of settlements that clear
daily/hourly whatever. Probably passing through the central bank or some
other clearing house. And this last loop is the only part where real money
is involved.
That is the way I would do it at any rate. Its just bank issued scrip.

@_date: 2020-12-17 23:15:41
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] BitCoin as Quantum Cryptanalysis canary. 
Like many others, I believe it most likely that Hal Finney was Satoshi and
following a misguided hairshirt morality mined the genesis locks into the
bit bucket. This hypothesis saves all the appearances and is far simpler
than any competing explanation.
If we accept this hypothesis as fact, there is only one circumstance in
which the genesis block coins are likely to be spent - if the public keys
are broken.
Contrawise, in the case that a quantum computer capable of factoring the
keys was ever built, what is the chance that it would end up being used to
factor the keys that would unlock a few billion dollars worth of moolah?
We may therefore regard the genesis blocks as canaries for quantum
cryptanalysis or some equally powerful advance in cryptanalysis of public
key cryptography. If the coins from those blocks are ever spent, time to
get worried.
Unless of course, the whole BTC system collapses under the weight of its
own ridiculousness first...

@_date: 2020-12-21 01:19:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Solar Winds hack 
Well stories about Solar winds execs dumping stock a few days before the
Anyone paying attention will know that breaches never seem to hurt a stock
for very long. But its a bad smell.
What I am finding interesting is that so many people are going on about the
fact that a weak password was chosen.
All passwords become weak as soon as you stick them in a shell script and
upload the result to a public server...

@_date: 2020-12-21 13:29:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Cryptographic archive format 
[Yes, I have researched ZIP, yes, it is easier to chuck away the legacy and
start from scratch, no, it is not useful to discuss these design
So, one application for the Mesh is to enable people to exchange 'encrypted
ZIP files'. The encryption here being threshold encryption.
So Alice ( is working on a project, she creates a callsign for the
project  and encrypts a bunch of files.
meshman dare archive /out=secrets.dar
meshman dare append secrets.dar file1.txt
meshman dare append secrets.dar file2.txt
At this point, nobody can read them, not even Alice, she wants to share the
data with Bob so she adds them both to group W:
meshman group add  meshman group add  Bob now has access to the files and can decode them. But only so long as he
is a member of the group. If Carol replaces Bob on the team, Alice can
remove Bob from groupW and replace him with Carol.
The trick here is that Bob and Carol can access the files they have been
authorized to access at any time. Alice doesn't need to be online. They can
read any file that has been encrypted to group W without any changes to
that file. The cloud service running the key server cannot decrypt any file
ever. That is only possible if an authorized user also defects.
So assume this is integrated into Word, Powerpoint, Excel, etc. Alice, Bob
etc. can all do their work using encrypted documents and share them with
exactly the same ease of use as for unencrypted. The only constraint being
that Alice has to agree.
[NB, this is only confidential document control, not full CRM. If Bob can
decrypt a document, he can also create a copy for Mallet. but that is a
separate problem]
The key service is a minimal trust service but not zero trust. The reason
it is not zero trust is that 1) the service is trusted to grant access to
Bob when authorized, 2) the service is trusted to deny access to Bob after
he has left the group and 3) we will almost certainly want to add
accounting and velocity controls to the key service to implement additional
controls beyond basic access.
OK so that is why I need a new format, it is simply not worth the effort to
back-haul the necessary changes into an existing scheme and the systems
won't be compatible anyway. Another difference is that the new format is
not a compression format for good reasons I won't go into here. the TL;DR;
is that compression is better applied at the application file level these
days. There is no value to compression in an archive format when people are
archiving bundles of JPGs. It might make sense to automatically encode HTML
in Brotli but for most purposes the value is likely small.
Now the (hard) question:
What precautions do I need to take in recording file paths in the archive?
The risk here is that someone crafts a malicious file path and sticks it
into an archive so that the files end up overwriting the system files.
So I have been compiling a list of dangerous file paths.
Any I am missing? The plan here is to ban these for the format itself so
these are prohibited on Windows and Linux and OSX.
Of course, this means there will be files that can't be encoded but that is
a secondary issue.
The type of attack I am concerned about are malicious paths like:
And so on.

@_date: 2020-12-29 23:54:53
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Bitcoin is a disaster. 
Hal shipped the prototype because he had just been told he had a terminal
illness. He couldn't even wait the seven months for the patents to expire.
Ray seems to have managed a fairly complete enumeration of the reasons
BitCoin sucks. But every single one of them has been understood for over a
decade. I would add that it isn't actually government proof either but long
experience (eGold, GoldAge, etc. etc.) tells me that is something that will
only be accepted when the next iteration of the schimera has been launched.
There is a particular syllogism that recurs in this type of reasoning:
A is bad. Therefore anything that is not A must be good. Therefore all and
any defects in the alternatives to A must be temporary and easily solved.
Therefore anyone who argues against the alternative needs to do more
research, or is a tool of the capitalist fractional banking doodahs or both.
The refusal to believe that recourse is essential has been a problem since
Chaum's DigiCash. And it is a recurring issue because the only reason the
credit card system hangs together is it provides recourse and the only
reason it can do that is every transaction is covered by insurance.
I wouldn't say that. Tim didn't understand network hypertext when he
invented the Web and Marc didn't understand crypto when he invented SSL.
But the BitCoin groupies are not the ones making the proposal. In fact I am
not sure what they are doing other than calling anyone who doesn't agree
with their ideology names and making bets on their tulip craze.

@_date: 2020-02-12 13:16:32
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography]  
As with the Snowden papers, there is a big difference between knowing and
being able to talk about a thing without being dismissed as a raving
Many of us knew that something like PRISM was going on because we knew
about similar efforts in the past. System-X had a feature that turned any
telephone in the UK connected directly to a switchboard into a passive
bugging device on the room. Thatcher pleaded with Gorbachev to send in the
tanks and stop the fall of the Berlin wall.
Trump is not the first politician to use gaslighting as a primary political
strategy. He is just the first one to be so bad at it that it has
failed almost all the time.
We knew Crypto-AG was crooked but not that it was owned by the CIA/German
intel. We knew that the mechanical Haeglin machines were breakable but
nobody proved the later electronic versions were backdoored as far as I
know, we just suspected that (correctly).
What hasn't been made public yet is how. I suspect that the side channels
identified by Moti Yung in RSA will turn out to have been used. If you have
a 2048 bit RSA public key, you can generate it in such a fashion that the
top 1000 bits are chosen. Which means that you can encipher the seed used
to generate the key in those bits. A 1000 bit RSA key is probably
sufficient for purposes of NOBUS.
So just why did we decide as an industry that RSA was so much better than
DH anyway? DH has a number of really useful advantages. The key agreement
value doesn't present a side channel, nor does the public key. And you can
do all the compute intensive work of Schnorr signature before you know what
you are signing.
So how did we get directed down the RSA path and not the Diffie-Hellman
And what are the same people doing today? Who slinks round the IETF
dripping poison into people's ears? Who drove DANE and DPRIV down a dead
end? Who persuaded the IESG to stand their ground rather than deploy DNSSEC
in 2002?
Disinformation isn't just for Twitter. It only takes a small number of folk
colluding behind the scenes to isolate people with threatening ideas in a

@_date: 2020-02-12 17:41:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography]  
The other dimension of the puzzle is to ask why this material is being
declassified and why now.
I rather suspect that the Huawei situation may be the answer. Suddenly this
is 'a game that two might play' as the Duke of Wellington remarked turning
down Cochrane's proposal for developing chemical warfare capabilities.
The problem isn't just China or Huawei either. Cisco was hit after the
Snowden papers were released.
How do we provide an assurance that a device hasn't been compromised at the
firmware or the circuit level?
I believe threshold cryptography may provide part of an answer.

@_date: 2020-02-13 15:59:47
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography]  
Indeed, provable security has proved remarkably brittle in practice. The
big problem with formal systems is working out the requirements. Been
there, done that, wrote my doctoral dissertation on the subject.
The thing that held back Rabin was the RSA patent which RSA labs asserted
covered Rabin's scheme.
What worries me on post quantum is that we have this binary approach
assuming that urgent planning for post quantum means it is inevitable. That
is the wrong way to look at things. Given the reliance on public key
crypto, we have to take very seriously a 5% risk that someone will build a
quantum cryptanalysis class machine in the next 20 years.
But then we have folk saying 'don't do anything new that isn't post quantum
secure'. Well that is turning a 5% risk into a 100% certainty and the state
of the physics doesn't justify that. I did particle physics experiments and
that is essentially what today's quantum machines look like. Sure people
can add more QBits to a supercooled computer and get press out of it. But
we all know that is a dead end. The real game is trapped ions and we aren't
really close to getting them to the point where we can run them at
significant scale.

@_date: 2020-02-13 18:40:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] SSL Certificates are expiring... 
I think this is an unhelpful way to think.
IoT needs a PKI. But PKIX has a bunch of assumptions built in that are
unhelpful (to say the least). Sure, we need something a bit different but
who is going to design and deploy that infrastructure?
If the assumption is CAs, then of course they are going to pick up PKIX
because (1) that is the only infrastructure their back end supports and (2)
that is the only infrastructure currently specified.
How many people do you know other than myself who is currently active
designing an alternative PKI approach? As far as I know, the answer is
zero. And at the moment, I am the only person backing the work. So we are
in Victorian lone gentleman inventor mode for your IoT PKI.
It really isn't the CAs driving this monoculture. When people wanted a BGP
PKI, they decided to start with PKIX despite the obvious fact it is the
worst match imaginable. So lots of baroque and non standard path
They didn't need a certificate based PKI at all, they just needed a
sequence mapping IP address allocations to BGP signature keys and sign it
hourly. Every relying party needs every assignment assertion. There aren't
all that many of them (There were only 16 million class Cs) oh and they
don't change all that often. Less than once a year. But they wanted the
warm comfort of PKIX and there were no CAs involved in that choice.

@_date: 2020-02-14 12:46:22
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] 'The intelligence coup of the century' 
The side channels were so powerful on the Commodore PET that some games
came with an audio channel that you picked up on an AM radio.
Which was really odd given that the case was metal.

@_date: 2020-02-14 12:59:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Crypto AG and CIA project exposed 
No captured ENIGMA machines were given to African colonies. The British
destroyed ENIGMA machines that were captured as well.
The East Germans kept using the ENIGMA though. Right up to the publication
of the Hut 6 story...
The beginning of Crypto-AG in the mid 50s is around the time that the
British Empire was in its final stage of collapse.

@_date: 2020-02-16 12:15:43
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] SSL Certificates are expiring... 
People have been complaining about my work for decades. The WebPKI met its
design brief and it was deployed at global scale. The same cannot be said
of any other alternative that was proposed.
The WebPKI design brief was very narrow, I know this because I wrote it
together with Michael Baum, Warwick Ford. The objective was to make
shopping online as safe for the customer as shopping in a store. That is
all. Confidentiality was not a primary concern, that was a secondary
concern necessitated by the fact that credit card numbers are bearer tokens.
The WebPKI was designed as an accountability infrastructure. The goal being
to ensure that if a merchant did not deliver, there would be consequences.
The objective was never to prevent the possibility of merchant fraud, it
was to limit the rate to an unprofitable level.
And the system worked so well fir the first decade, a lot of arrogant sods
decided they knew better and could start hacking parts out arbitrarily.
Like the revocation infrastructure. And then folk decided that it was an
all purpose confidentiality infrastructure because that is the only type of
security they can understand.
People can ignore me if they like, but blowing off the anti-Trust concerns
that drove Microsoft's contribution to the WebPKI is going to look like a
terrible idea pretty soon. 'Big Tech' is becoming a slogan and not just on
the far left, the GOP is actually rather more concerned. Facebook took
their party away from them and gave it to Putin/Trump. The whip of choice
will be anti-Trust and WebPKI will be just one of its tails.
The flaw in the WebPKI is that the design brief really calls for an
introduction scheme and TLS is configured as a transaction authentication
scheme. That is in part a consequence of not having the tools at the time
to make an introduction scheme portable across browsers and hosts. It is
also a consequence of the fact that a merchant does not necessarily defect
immediately and it takes time for defection to be observed. Oh and the fact
that many Web sites are incapable of managing PKI with the fidelity
required for pinning trust anchors.
The RSA and DH patents expired in the 90s, there was plenty of opportunity
to propose something different.
The problem is path dependence, not some conspiracy. We could have adapted
TLS for IoT devices really easily, just make use of self signed certs
painless. I suggested that on a half dozen occasions and it never happened.
You can't trust manufacturer inserted device keys and they turn out to be a
liability for the manufacturer - just ask Huawei.
The approach I am proposing in the Mesh is to use threshold key generation
so that manufacturer installed keys are only ever used during onboarding.
The administrator issues a seed from which a second keypair is generated
deterministically and the sum of the two private keys is used for the
private key of the device within a particular Mesh.
So if the built in device key is {d.B, d} where B is the base point and the
administrator device provisions {a.B, a}, the composite key pair is
{d.B+a.B, (d+a) mod Q} where Q is the order of the subgroup.
The really nice thing about this approach is that we don't (usually) need
to worry about proof of possession. The admin device can calculate the
public key of the device in the user's Mesh without knowing d. And that is
what they credential. So the device can't actually make use of the
composite private key unless they know d.
[Yes, there are some pitfalls to watch out for, this approach means that as
far as external parties are concerned, the private key is at lest as strong
as the stronger of the two key contributions. Unfortunately, the public key
turns out to be as trustworthy as the least trustworthy of the
contributions. Which leads to rogue key attacks...]

@_date: 2020-02-16 12:56:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] SSL Certificates are expiring... 
I made myself unpopular at the first Trusted Computing Group meeting
pointing out that MSDOS is trusted, it just isn't trustworthy. Microsoft
got the point, most others did not.
Yes, I get the fact that most people in this business are inclined to a
suspicious view of the world. But if we are going to have people who have
never met trust each other sufficiently to accurately assess the risk of a
transaction, our choices are limited. We can either trust them blind or
make use of a TTP.
What I plan to do once I can work again is to write up ceremonies for
onboarding and contact exchange. Carl Ellison raised this years back.
One tool we need to make use of is the Haber-Stornetta hash chain notary
(without the blockchain ideology). This is interesting because it gives you
many TTP capabilities in an untrusted or very limited trust service.
Ceremony: QR code exchange of credentials.
Alice meets Bob in person, they both have smart phones with display, camera
and network affordances. They agree to exchange credentials.
Alice starts her credential exchange app and selects the credential she
wishes to exchange, it presents a QR code.
Bob scans the QR code and selects the credential he wishes to exchange.
Protocol stuff happens using the QR code to establish a work factor of at
least 2^128.
Alice and Bob review the credentials their device received and accept (or
reject) them.
Ceremony: Conference notary binding
Now lets say we do exactly the same but at an IETF and Alice registers her
credential with a kiosk. And then we enroll the result in a DARE Sequence
(which is authenticated by a Merkle tree).
Notice we did not actually validate Alice's credential. But even without
that we have an interesting data point, someone attended a conference and
purported to be Alice in Feb 2020. And we know that date with essentially
100% assurance because of the Merkle tree (assuming we tie that to other

@_date: 2020-02-19 13:12:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] SSL Certificates are expiring... 
The WebPKI was only calibrated for credit card transactions where every
transaction carries insurance. The argument was based on velocity, window
of validity and cost of repeatedly applying for class 3 certs without being
Sure you can set up one scam company. But if they only last 48 hours, you
need lots and if you repeat your approach you will establish a pattern
Sure it has worked for much beyond the design brief. But dont blame me for
the limitations.

@_date: 2020-02-19 15:58:31
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] With an e2e network, 
Mesh messaging makes use of three layers of encryption.
Communication between the client and service is over TLS for Traffic
analysis resistance.
Each request and response is authenticated and optionally encrypted under a
key agreement between client and service auth keys. This provides access
The Mesh Messages themselves are limited to 32KB and are end to end
encrypted under the key of the recipient or group. This is for end to end
security. Note that use of threshold decryption means we could use the Mesh
for the cryptography list and achieve true end-to-end encryption without
the need to make the membership of the list public.
Limiting the message size so severely might seem odd. But s message can
contain a link to an external body which is larger. The payoff is that we
can easily pad every message to 32KB and give ourselves a lot of traffic
analysis resistance by onion routing later.
I am also strongly considering how we might make use of Micali simultaneous
transactions. Though folk are already complaining about PHB's grand unified
theory of crypto.
There is a complete set of videos describing the design of the Mesh in
detail on YouTube. I can type but I cant speak at this point.

@_date: 2020-02-22 21:02:18
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Apple's 13-month certificate policy 
With automated renewal, limit validity to 7 days and renew daily. No need
for OCSP or CRLs.

@_date: 2020-02-23 22:28:23
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Apple's 13-month certificate policy 
Yes, it does have the payment flow.
But the reason the commercial CAs weren't leaping to do ACME was they had
all solved the problem years ago and have their own APIs and some are
integrated into the likes of C-Panel. So a standard for automated issue for
the bulk of certs was never really a priority.

@_date: 2020-01-07 11:30:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Recent factorization of RSA-240 & DLP 
The hiatus in factoring is probably just the result of interest waning
after 768 was broken. There is no really interesting target till we reach
1024 which is of course very interesting indeed. Folk will be able to start
cracking the early RSA labs and VeriSign roots (long since expired of
I strongly suspect the above crack was a result of the Crown Snakeoil
Factoring PR stunt renewing interest.
As for memory, it is now possible to buy a machine with 1.5TB of memory if
you would prefer owning that to owning a Mini Cooper with every possible
option etc. and the compute part now takes place in the cloud. So we should
expect to see a shift from the CPU part to the memory part.

@_date: 2020-01-13 11:36:21
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] improved identification of non-targets 
There is a large body of work looking at identification of aerial drones.
And it is a tough problem because many of them have really limited power
etc. Do one public key operation on certain systems and 10% of the battery
life just went.
If you want to get anywhere on the airline problem, the first thing you
need to do is to get all the parties to agree there is a problem and
establish a new set of international norms to cover drones, etc. And that
is really hard because neither Iran, Russia nor the US wants to really own
the fact that they have shot down a civilian airliner.
Reagan never apologized for shooting down Iran Air Flight 655, he should
have. But did not. Russia is still denying shooting down Malaysia Airlines
Flight 17 and is aggressively circulating conspiracy rumours online and
through their various disinfo channels (RT, Mint Press News, Alex Jones,
Iran is actually the first country to apologize for this type of act and
the reason it did is that the government is divided between an elected
civil government and a theocratic dictatorship. And the dictatorship knows
that they can't expect to keep the information suppressed because the civil
government will out them.
The proximate reason that the flight was shot down was of course the US use
of force killing a top Iranian general in Iraq. Should Trump pardon himself
for his multiple US crimes he can always be extradited to Iraq to stand
trial for the murder. But the much deeper reason for the shoot down was
forty years of 'Death to America' chants in Iran. And now the price of
those chants is being recognized.
This might be the event that causes the Iranian revolution to enter its
thermidorian phase.
There is at this point absolutely no prospect of any new international
norms being established in the technical space. Russia views its cyber and
parapsychology units as its edge. China is embarked on a new red terror
against its muslim minority. A change in US leadership is a necessary but
not a sufficient condition.
[1] [At this point, it is obvious Alex Jones ain't making money the way he
claims. So why assume he is unpaid?]

@_date: 2020-01-18 22:49:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Redundant Array of Cryptographic Services 
One of the feature sets for the Mesh requires a set of cryptographic agent
functions. I have generalized these as follows:
1) Haber-Stornetta Hash Chain notary
Yeah, gets request, signs it, chucks it in a blockchain, blockchain then
cross notarizes periodically with others. Job done.
Groups of notaries may offer joint signatures through a PRE-ESTABLISHED
agreement among the notaries.
2) Micali simultaneous contracts notary
The patent has expired. Time to use this.
This is a scheme that allows Alice and Bob to both obtain a signed receipt
on a document or neither does.
3) Key Escrow Agent
The proxy publishes and commits to follow a key use protocol for the key
{X, x} as follows:
1) The public key X
2) The DateTime at which the proxy will begin servicing decryption requests
3) The DateTime at which the proxy will cease servicing decryption requests
4) The DateTime at which the proxy will dispose of the key
5) Whether the private key x SHALL be destroyed or published on the
disposal date.
6) Additional requirements for access control on service provision
It is my belief that it is sufficient to offer non-threshold escrow. Users
who want to ensure they can decrypt a document in the case that one or more
notaries fail, can perform (n,t) secret sharing over the session keys.
So here is the plan, I want to implement a reference service for test
purposes this year with a view to hardening it later on. But I still want
to have good crypto hygiene and survivability.
I don't feel good trusting HSMs. They can be compromised at source and they
can fail. So I want the escrow keys to be represented on paper.
I am considering the use of an ink jet printer with UV 'invisible' ink for
this. The key shares used to generate the master keys can be printed out,
distributed, locked in safes, etc.
The response to getting a (lawful) writ will of course be to do whatever
the court requires. If people want greater assurances, use multiple
I do have some ideas for using notary chain services to nail down the
crypto further. But they kinda depend on having another notary service
there to tie to. So the idea of starting a reference service is in large
part to enable the creation of production services.
[And no, there shall be no proof of work element and no minting of

@_date: 2020-01-21 20:10:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Redundant Array of Cryptographic Services 
Good point. I have considered these at length though.
Kiddyporn is easy, just notarize the hash of the data rather than the data
itself. I have also constructed the DARE Sequence format in such a fashion
that it is possible to erase the body of the sequence entries without
disrupting the chain calculations.
It is easier still when encryption is used, a single asymmetric exchange
may be applied to encrypt multiple block by means of a nonced KDF. If the
nonce is sufficiently large (i.e. 128/256 bits) then erasure of the nonce
is sufficient to render the ciphertext unavailable.
Spam is a different matter. Basically these are Web Services that require
authenticated requests from authorized users. Every Mesh Message is subject
to access control.
DDoS is another issue entirely. That is not one of the problems I am
worrying about right now. The assumption being that if one agent is down,
you pick a different one. Or you wait.

@_date: 2020-01-23 11:35:26
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proper Entropy Source 
I told Netscape that their random number generation was broken in 1994,
they were broken in 1995 and again in 1997.
Wait long enough and the same old bugs return. Someone made off with plenty
of BTC loot by looking for wallets with weak keys and emptying them all.
This is why I am proposing this
The device chooses a random seed, the administrator chooses a random seed.
The final keypair is produced from both seeds in such a fashion that both
parties can prove that their seed material was included.
The key point here is that we need unguessable seeds not just randomness.
The UDF key derivation scheme I am using for the Mesh provides additional
assurances. Every key whether RSA, ECDH or anything else is generated from
a seed via a KDF. Thus a suspicious party can verify that an implementation
is behaving as it is supposed to by separating the seed generation. seed
combination and key generation processes and checking each in isolation.

@_date: 2020-01-26 14:57:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Conservation of security in threshold crypto... 
As folk know, I have been working on various threshold crypto schemes. I
recently realized a rather stunning anti-symmetry akin to conservation of
well something.
Recall that if {A, a}, {B,b} are {public, private} ECDH keypairs that we
can construct a new keypair {Z, z} as follows:
z = a+b mod Q
Z = A+B
(where Q is the order of the prime subgroup.)
A = a.P, B = b.P =>
Z = A+B = a.P + b.P = (a+b).P  = ( a+b mod Q).P + nQ.P = z.P
Now for the interesting part. There seems to be a conservation of security
law going on.
The unguessability of z is the maximum of the unguessability of a, b. If we
design the protocol right with appropriate hashes to avoid stride issues,
we can get the  unguessability to be the sum of the  unguessability of a, b
(with a ceiling of course)
Bottom line, using this approach to generating private keys means that you
can mitigate many weak key attacks that are real issues in deployed systems.
But now lest see what happens when you try to play games on the public key
side to achieve integrity. It turns out that the trustworthiness of the
composite public key is the lesser of the trustworthiness of A, B.
Lets say Alice and Bob both contribute keys to a joint signature key Z and
Alice goes first. Bob can determine the value Z buy picking B = Z-A.
This is the basis for rogue key attacks in threshold signatures.
So it seems like there is a conservation thing going on. Using naive
approaches, we get the maximum trustworthiness on the private key side and
the minimum on the public key side.
Of course the control here is to either use a key generation approach that
constrains Bob in some way (e.g. he has to commit to his value B before he
sees A) or we have to limit the functionality we provide. I do not support
threshold signatures created by people specifying their own independently
generated keys. I only support generating a key pair and then splitting it.
So I effectively eliminate the attack by ruling it out as a security
control being provided.

@_date: 2020-07-01 11:12:40
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Statement from Attorney General William P., 
The attempt to regulate use of codes is rather older and the concern was
commercial. The ITU was originally formed to co-ordinate regulations
preventing use of codes on telegraph systems.
The concern was purely commercial. Telegrams were priced by the word and
codes were used to reduce costs.
The prohibition on use of 'codes' in ham radio probably comes from the same
commercial concerns. Though by that time the anti-trust movement was
getting going and they might have needed to conceal their true motives.

@_date: 2020-07-11 20:54:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Further thoughts on threshold key infrastructure. 
I am now calling the Mesh a 'Threshold Key Infrastructure'. As far as I am
aware, this is the first serious attempt to build a Key infrastructure with
and for threshold keys. It turned out to be as different from PKI as PKI is
from SKI (e.g. Kerberos).
I am now starting to think about how users can make use of multiple keys.
Alice (alice at example.com) and Bob (bob at example.com) both have multiple keys
for stored data. They have standardized (case insensitive) names:
message: For confidential messages, key is escrowed so that it can be
recovered after death.
data: For confidential data, key is escrowed so that it can be recovered
after death.
burner: For very confidential messages that it is intended for the key
holder only. This is not normally escrowed.
When creating a contact, multiple keys can be specified. Bob doesn't give
everyone his burner key but he has given it to Alice.
Alice can direct her messaging client to send a message to a particular key
using the syntax $ e.g.:
burner$alice at example.com
The reason for picking $ is that it is a legal RFC5322 email address but
rarely used. So it will be possible to record this type of address in many
email client address books but isn't likely to cause issues.
The reason for not picking ^, & or | is that in a TKI we can perform REGEX
like operations on keys, for example to specify that an email message will
be encrypted so that multiple keys are required to decrypt:
burner$alice at example.com & 2020-07-18$expire at example.com
Here expire at example.com is a public service that will perform a decryption
operation against the 2020-07-18 but only up to 18th July 2020 when the key
will (allegedly) be permanently and irrevocably erased.
In addition to the and operation, we can have an or.
Mapping to SCI labels is pretty straightforward:
hayden at nsa.gov & noforn at sci.gov
I would imagine we would also have an escrow key service that would only
begin providing the decryption service on a specific date. 2020-07-18$
escrow at example.com
It is probably a bad idea to enforce the semantics of the keys in the spec
but people will naturally develop conventions in the same way that
microformats are used for HTML forms (one of my proposals that people
laughed at when I first made it in 1995).
I am not sure how far to go with the key operations, is it useful/necessary
to try to specify t out of n shares? Obviously, the escrow at example.com
service should be using key splitting under the covers.
Until now, I have been thinking of Shamir secret sharing in terms of
splitting a key after it is created. But I have started to think that is
maybe too restrictive.
Lets say that we have a set of key share holders that each generate random
points in the space {1..P', 0..P'} Where P is the Prime field for our
elliptic curve.
We can now generate t out of t key shares simply by choosing any subset of
these  share holders and treating them as a Shamir/Lagrange key set.
Or maybe we can get the parties to cooperate to generate additional shares
for a particular set in a Lagrangy sort of way so we can get to t out of n
shares (with appropriate verification proofs).
Not sure quite what to do with this capability at this point but the
earlier stuff looks useful.

@_date: 2020-07-16 19:23:09
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Terakey, 
Principles
That is almost but not quite what happened.
There was a TV special on the building. The architects had covered the wind
load issue correctly, the student was correct but so were the architects.
But it was when replying to the student and their prof that the architect
revisited a different issue which was the decision to bolt the cross
members in place rather than weld.
They re-ran the numbers on that and discovered that they had the serious
issue. And so they ended up having to send in crews every night to weld all
the cross braces in place.
There is a good book on this sort of stuff 'why buildings fall down'.
I will see if I can locate my copy.

@_date: 2020-07-19 00:55:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
At the time of SSL, 20MHz was still a common CPU speed. We were having real
difficulty with the number of public key operations required to process
cert chains. I am not surprised they were unwilling to do PFS then.
But when we did eventually do PFS, why did the design throw away the
initial key agreement completely? Why not feed the PFS output and the RSA
encrypted output into the KDF to form the session key? Then you can do 512
bit PFS without compromise to a 2048 bit RSA exchange.
We now know that $250 million a year was being spent on BULLRUN to sabotage
standards work. I rather doubt that the individuals doing the sabotage were
the obvious ones though. Much more likely it was those individuals whose
means of financial support was always cloudy but were always ready to write
a document, the people who made sure everyone with PKI knowledge was made
unwelcome in DANE, the folk who persuaded the IAB to dig their heels in and
prevent deployment of DNSSEC in 2001, etc. etc.
There are a few individuals who seemed to be always there to pour poison in
people's ears and to encourage them to 'stand their ground' when insisting
on some asinine security requirement that makes the whole thing
Take the decision to make sure IPSEC wouldn't pass through NAT. I am
certain neither security AD at the time was working for the NSA. But
someone managed to reinforce their prejudices against NAT and the result
was a failed design.

@_date: 2020-07-21 01:50:09
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
The DANE group needed Google's support to get in the Browser so why
make such a deliberate effort to kick Ben Laurie out of the effort?
You assumed that the only purpose the PKI world would have was to
sabotage DANE. What we were in fact looking to do was to upsell our
existing certificate customers with managed DNSSEC.
The only part of x.509 was
There were multiple issues. One of them was the insistence on DNSSEC. The
was welding the policy aspect of 'must use TLS' to the publication of the
Yet another problem was the restriction to TLS policy
VeriSign's ATLAS infrastructure was originally built to deploy DNSSEC. But
lack of opt-in on the NXT record made it impossible to deploy using the
of the day. 64 bit machines were only just becoming available and the NXT
more than quadrupled the size of the .COM zone.
I think it highly unlikely as well. Not least because the NSA got a severe
wake up
call in the wake of the Manning and Snowden breaches. They failed in their
to protect US secrets.
Yet, the fact that we see the above in complete different ways, suggest
And who was it persuaded you of the need to hit the red emergency button and
kick out the PKI people? Same guy who managed to persuade DPRIV to adopt
an asinine set of requirements.
They failed to understand that if you have two networks with different
schemes, any interoperability capability must inevitably involve
translation of

@_date: 2020-06-04 23:27:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Zoom publishes draft cryptographic design for 
When we were building stuff on Open Genera for the White House project, we
used to joke that if it was ever broken the list of suspects would be very
Claims about the comparative hackability of OS tend to be editor war stuff
rather than reasoned arguments. OS without memory protection are
intrinsically easier to break. OS without accounts are easier to break,
etc. But once we get to the commonly used platforms it is a matter of
incentives and how many people have the necessary skill set and which
systems they like working on most.
Oh and don't forget that the person who smugly lectures folk on how
insecure Windows is will probably be running PHP or the like on their Linux
Web server...
Yet I think there is something to that argument, because widely used
I think this is what people are really missing with Skype/Signal/Zoom etc.
End to End makes no damn difference if the service is only accessible from
a single app provided by the service provider who can force an automatic
Lawful intercept of a Signal or Zoom call is merely a matter of getting a
warrant that requires the service provider to drop a client with a backdoor
onto the specific users they want to intercept. Oh and of course a court
can and will tell you to lie about how many warrants you have been served.
I can't see a judge being remotely impressed by warrant canaries. If a
person intentionally constructs a situation that makes it impossible for
them to comply with a court warrant in good conscience, that is their
problem, not the court's.
It then became much more vulnerable to pressure, and
How many users did Lavabit have when the FBI went after them? You only need
to have one customer to get a warrant if it is the wrong customer.
The only robust solution to this problem I can see is an open standard for
end-to-end communications that covers all the common modalities and is
supported by multiple implementations and the updates to those
implementations are subject to some form of transparency controls.
NOBUS is the key here: NObody But US. NSA is not going to rubber hose my
company to force it to issue a backdoored version of the code if they think
the backdoor can be used by someone else. Nor are they likely to want to do
so if the compromise is likely to be discovered.
So lets say that I have a code updater that is the only tool authorized to
update certain apps on a device. It notes the existence of an update,
downloads the code, verifies the signature of the provider and then checks
to see that that particular build has been registered with a transparency
log before it OKs deployment.
Could even go a stage further and require that the build has been validated
as corresponding to a particular GitHub version branch, compiler version,

@_date: 2020-06-08 11:57:00
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Zoom publishes draft cryptographic design for 
I was considering the issue more as a research challenge problem for the
general case.
End to end is important but Zoom is not my first concern. There is
relatively little I can learn from video quickly unless people are
livestreaming activities that would render them vulnerable to coercion. I
stated that in the first video I made on Zoom crypto.
What worries me most are shared documents. An attacker can download them
and use regex searches to find the good stuff in megabytes of material. So
Google Docs, Dropbox, Slack etc worry me more. Github is also a concern.
Next concern after that is asynchronous messaging such as email. It should
be clear at this point that S/MIME and OpenPGP don't meet the user
requirements to become ubiquitous and never will.
On the code transparency/validation front, I think we are going to have to
start seeing 'designed for validation' as part of the spec. For example,
anything that can read/write arbitrary files on disk is going to be really
hard to verify. That risk can be minimized by funneling all file handling
system calls through a single point that limits access to the limited
directory locations an app is allowed to access. Essentially the principle
of Hoare's monitors brought into the application layer.
Assume for the sake of argument that we are using a managed code language
such as C# and that we do not allow code obfuscation or some of the more
aggressive features (e.g. ability to generate and compile code on the fly).
Further assume that it provides the .NET style 'strong assembly' capability.
Using those capabilities it would be possible to determine by static
analysis of the executable that it was using a particular support library
that prevents the code exceeding its intended privileges. Essentially
providing a 'trusted computing base in software'
Instead of validating the entire program, it would be sufficient to check
that it only used managed code libraries with no native code and that the
support library had the appropriate checking.

@_date: 2020-06-11 12:16:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Taking CT to its logical conclusion 
Micali's Fair Exchange with Invisible TTPs is now out of patent so I
started a draft describing an implementation.
That got me thinking about another expired Micali patent: Revocation trees
(also invented by Paul Kocher at the same time).
While musing on how to implement those, it occurred to me that we missed
something: Mekle certificate trees.
In this model the CA would create a Merkle tree of all the certificates it
issued and signs the tree every day. So if they issue a million certs, the
tree will be 20 nodes deep and a path will be 20*64 = 1260 bytes.
Check the apex signature for the day and we have no need to perform any
more public key signature verifications for that issuer for that day.
Revocation is handled automatically: just leave the bad cert off the tree.
It is probably too late to think about retrofitting this approach to X.509,
it is a product of its day after all. But it might be worth considering for
a successor.

@_date: 2020-06-15 16:07:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Broadcast security identifier 
Keys are either public keys or private keys right? Well what if we had a
key that was a bit of both?
Specifically, what if we had a key that could be used to decrypt a document
and to verify that the contents are correct without the ability to sign.
I found a need for this type of key in my contact exchange protocol.
Consider the case that we have a document that we are going to retrieve by
means of a QR code. We have three separate requirements:
1) Locate the data
2) Decrypt the data
3) Verify the data
Authenticated encryption really doesn't cut it for the verification
requirement as anyone who can read the data can fake the authentication
tag. A MAC is only a MAC.
We can communicate through two separate channels, through the QR code and
through the document we retrieve. The QR channel being limited in space of
Lets take the last of the requirements first, We want to verify the
document. So lets generate a new signature key pair and sign the document.
We put the public key parameters in the document itself and we embed the
SHA-2 digest in the QR code, truncating to a reasonable number of bits
(i.e. at least 128 but no more than 256).
SignatureKeyPair = {VerifyKey, SignKey}
Digest = Hash (ToBytes(VerifyKey), bits)
Next we need to generate an encryption key. So lets use HKDF to derive an
encryption key from Digest and a Salt value.
Salt = Random (128)
EncryptKey = KDF (Digest, Salt)
Now we envelope the data using our cryptographic keys:
Document = Envelope (SignEncrypt (Data, EncryptKey,SignKey), Salt,
Encrypt(VerifyKey, EncryptKey)
The locator for this document on the service is the Hash of the Digest
Locator =  Hash (ToBytes(Digest , bits)
[I am eliding the Sign/Encrypt order debate here].
The QR code for the document is a URI which has embedded in it the
following information:
* Domain of the resolution service
* Locator
[Eliding the niceties of URI syntax etc.]
So now we have a URI which allows us to locate, decrypt and verify Data by
working in reverse. The URI tells us where to find the document. We present
only the hash of the decryption key IKM to the service to identify the
document we wish to retrieve. The document gives us the necessary
information to complete the derivation of EncryptKey.
To verify the signature we take the values from the document envelope,
decrypt the VerifyKey, check that the value Digest is correct and presents
a sufficient number of bits to be trustworthy, and validate the signature
[It is necessary to encrypt VerifyKey or else this will allow someone to
reconstruct Digest!]
So besides comments on the proposal, has anyone seen a scheme like this
I am thinking it is probably still a public key scheme as we are still
establishing two separate roles. Anyone with the QR code can decrypt but
they can't sign. So the roles are divided into broadcaster and receiver.

@_date: 2020-06-22 17:52:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Side channel nomenclature 
I am looking into making some videos on side channel attacks. There are two
separate types of attack I am looking at.
The first, I am calling 'leakage' where an unintended side channel leaks
information to an attacker. Timing attacks, power etc come under this
The second I am calling 'exfiltration' in which the system designer
intentionally leaks information. For example, Dual EX RNG, or Moti
Yung's smuggling the RSA seed in the top bits of an RSA modulus.
In between there are induced side channel attacks such as hitting a chip
with radiation while it is operating, smartcard in microwave, etc.
Does this leakage/induced/exfiltration nomenclature make sense or should I
use something else?

@_date: 2020-06-23 10:07:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Side channel nomenclature 
That is one of their jobs.
In the wake of the Snowden breach coming out, I was at a meeting of
governmenty types where it was being discussed and the general opinion was
Alexander should not resign because PRISM etc was doing his job. I pointed
out that the NSA was responsible for protecting the nation's secrets and
had just suffered a catastrophic breach. it was shameful Alexander hadn't
resigned already. Shocked faces all round. Two weeks later he was gone and
that was now seen as inevitable.
Another major change in the NSA mission is going to come from the outcome
of the 2016 election. The policy of disrupting attempts to deploy strong
crypto has to end. It was the lack of end-to-end encryption that allowed
Putin to hack the DNC and collude with a traitor to install him in the
It also violates the NOBUS principle. Anyone who reverse engineers the code
can use the backdoor. Dual-EC-RNG only allows the party that knows the
private key to work out the sequence.
I think it is very useful because even if you control the entire process
and still do things in a trusted fab etc. the laws of physics still means
you face risks from leakage.
Threshold allows for separation of duties which can in turn address some of
the exfiltration attacks. And some algorithms are much more vulnerable to
exfiltration than others. RSA has the huge modulus with 1000 bits that can
be used as a side channel. ECC doesn't offer anything remotely similar.

@_date: 2020-06-30 12:03:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Statement from Attorney General William P. Barr 
The Aurora shooter used kevlar armor to make themselves invulnerable. The
result was a lot of dead people.
The second amendment is a local ordinance at best. And the interpretation
was changed radically by the Renquist court. Given the current state of the
country with confederate statues being toppled, the idea that the
established order must prevail seems rather silly. The folk toppling the
statues are the folk who are looking to reduce and constrain the power of
the police and they are the people winning at this point. Mark and Patsy
pointing guns at protesters in St Louis look like they are on the losing
side of history to me.
People are not really linking guns to crypto to protect crypto, they are
making the argument to defend an extremist position on gun rights that
consistently polls at 60% or less.
The NRA is currently on the verge of collapse due to a protracted
corruption scandal. That is not an organization that is going to wield
power or influence.
I don't argue about technical impossibility either, that is another losing
argument: I can build escrow features into my systems, in fact I have done
exactly that. If people are going to use strong encryption of data escrow,
they need escrow.
The argument I make is very different:
The reason the US has the government it does at present is that email is
insecure, James Comey grossly abused his office and Donald Trump colluded
with Russia to obtain political advantage from the DNC email attack.
The Democratic party cannot trust the FBI. Freeh colluded with Kenneth
Starr, Comey colluded with the Trump campaign. This is not the time to be
giving more power to the FBI. It is time to do what should have been done
in the 60s: Dismember the agency separating the Law Enforcement and
Counterintelligence functions. And since we are demolishing monuments to
racism, Hoover's name has to come off that HQ building.
Edward Snowden taught the NSA that it had been derelict in its duty to
defend the US against cyber attack. The lack of end-to-end security in
email, the fact that messages are stored in the clear on mail servers
allowed Putin and the FSB to change the outcome of the 2016 US Presidential
Strong cybersecurity is in the US national interest. Ubiquitous deployment
of effective cryptographic security must be made a national security
I do have a technical argument as well but I am not going to lie about my
technical capabilities
What I cannot do is to cause people to forget how to use encryption
technology. Terrorists were using RSA to encrypt messages long before PGP.
In the 1980s there was certainly a tactical advantage in keeping competent
crypto out of their hands. But the information on how to do it right has
circulated freely for three decades and there is no shortage of strong
crypto available. All that governments can do is to deny access to crypto
to the general public.
Governments can put pressure on large corporations like Apple and Facebook
but they can't put pressure on private individuals living outside their
borders. Russia has been trying to shut down Telegram for years without
The Internet is an international infrastructure. Does the US Congress want
me to add backdoors for Russia, China and Iran or just the 'good guys'?
Absent a global government, I can't see how an escrow scheme is going to
work in an open, standards based communications infrastructure. People are
not going to use applications with backdoors for governments that cause
them concern. They will choose other providers. And if 2016 taught the US
intelligence community anything it should be that Russia is rather good at
persuading US citizens to distrust their own government more than they
distrust Putin's dictatorship where elections are won by gunning down the
leader of the opposition on the streets of Moscow.
In short, don't argue about the technical challenges of building the one
ring. Instead focus on the impossibility of controlling it.
And stop using walled garden communications systems. Within five years,
Apple, Microsoft and Google will control the entire vertical stack from
silicon to device to application. So you only need to trust one party.
That same situation is going to put Apple, Microsoft and Google under
severe pressure from the US government, the EU. Other governments will not
be so polite, they will just try to infiltrate people into the teams that
might gatekeep whatever backdoors the five-eyes might achieve. If Facebook
is lucky, they may likewise be feeling the pressure but it looks rather
more likely to me that they will be taken to the woodshed as an example to
the others. Zuckerberg's super-power turns out to be making enemies of
every member of Congress, who knew?

@_date: 2020-06-30 14:23:14
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Statement from Attorney General William P. Barr 
It is my habit to be as precise as possible in my language. I said 'The
result was a lot of dead people'.
Do not misrepresent my argument. A shooter armed with a military rifle and
military body armor is going to be able to kill a hell of a lot of people.
Security is the property of a system and a gun/body armor system results in
a lot more dead people than just the guns alone.
Defensive capabilities can facilitate an offensive. That has been known
since the epic of Gilgamesh, the construction of city walls was a cause of
war. The whole argument against deployment of ABM/Star Wars technology
during the Reagan era was based on the fact that if one side has a shield,
they can attack the other with impunity.
I have no time for your gunsplaining arguments. And particularly not when
you begin with condescension and misrepresenting my position. I refer to
the NRA as the North America Man-Gun Love Association because I consider
them lower than pedophiles. And that is not hyperbole or exaggeration on
my part: I argued the same point with Timothy McVeigh before he murdered
168 people for his crazed ideology.
I see absolutely no value in making my argument for unfettered access to
technologies of freedom by tying it to a cause I consider an abomination, a
death cult.
The whole argument against allowing free access to encryption is based on
the premise that it allows 'terrorists' to protect their communications.
Comparing cryptography to body armor does not help the cause in the
slightest. In fact it puts cryptography in a category that is already

@_date: 2020-03-03 14:59:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Ex-CIA Joshua Schulte Describes His Data/Crypto 
Thermite is almost certainly easier to use.
We should start holding thermite parties. Anyone got a suitable back yard?

@_date: 2020-03-05 09:25:59
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Possible reason why password usage rules are 
Peter is probably right in asserting that the principle of changing
passwords regularly is probably inherited from having to change watchwords
on a daily basis. But the other part of the pain comes from the idiot
requirements of capitalization, numbers, special characters, etc.
These rules were all brought into being in response to the publication of
Crack which sped up exhaustive dictionary search of passwords to 22
attempts a second on a SPARC model of the day.
Now up to that point, there was a flamewar going on between the UNIX and
VMS advocates on USENET with the advocates of the UNIX approach insisting
VMS IS INSECURE because the password hash file was protected at the system
level while the UNIX password file was proudly world readable. UNIX did not
ship with shadow password support turned on by default at the time, some
distributions didn't even support it at all. System protections on the
password file were derided as 'security through obscurity'.
This actually had a serious impact on the design of the Web. The reason we
got plaintext password rather than my digest scheme for HTTP was that you
can't protect the authentication secrets on the wire and in storage unless
you make use of public key cryptography which was still under patent in
1993. Some folk were bought into this 'security through obscurity' UNIX
fetish and insisted we send the passwords over the net en-clair so they
could be obfuscated on disk.
Anyway, Crack changed all that and within a few weeks the following had
become firmly established 'facts':
1) Every UNIX system supports shadow passwords and has always supported
shadow passwords.
2) Nobody has ever been so foolish as to suggest shadow passwords were
security through obscurity.
3) The argument must have been over the lack of shadow password files in
VMS, yes that was it.
4) Everyone must add a special character to their password to make it
The last part of this CYA is still with us despite the fact that it
actually decreases security. We don't use dictionary attacks any more.
There have been crackers that can exhaust the 8 character possibilities for
the Windows hash in less than a day for almost a decade now. The special
characters actually reduce the search space as there are more alpha
characters than special ones.
In the real world, all these requirements mean is that instead of using
'password', Alice chooses 'Password1' or 'Password1!'. They do absolutely
nothing for security. And if people are required to change their passwords
regularly, it is 'Password2!', etc.
We have to get away from passwords altogether and later this year, I will
be launching the first part of the Mesh which will make that possible as a
kickstarter. The Mesh is all open source of course and will remain so. But
I reckon many people will be willing to pay $20 or so for someone else to
host a service rather than run their own with all the hassle that
inevitably entails. And if I can get enough $20s, I can hire people to run
the service and write code to integrate into Chrome, Edge etc.
So the big idea here is to write a tool that provisions public key pairs
and credentials to every device the user connects to their personal Mesh
and then use those keys to
1) Provide access to an end-to-end secure password manager.
2) Authenticate to services using strong public key authentication.
3) Provide a second factor authentication capability that provides an audit
log of the actions taken.
If you have access to your password vault on every device you own and if it
is integrated into your browser on every platform, you can use different,
machine generated passwords for each site. And they can have as strong a
work factor as that site allows.
So this is a LastPass type play except that every device with access to the
passwords is also capable of public key based authentication which is
phishing proof because the authentication protocol does not require release
of the authentication secret.
I am not aware of any existing password vault that is end-to-end secure. My
proposal provides a further control using threshold cryptography so that
you can disable access to a device if it is lost or stolen or if you are
going through an airport in a hostile country.
Oh and it can also provision your keys for S/MIME, OpenPGP and SSH so that
best crypto practices are maintained. It can exchange contacts through
various types of ceremony from in-person QR code exchange to remote with
TTP attestation and it has a complete end-to-end secure asynchronous
messaging infrastructure.
It is time to make this happen. I am still nailing down the last bugs in
the reference code but I will be shortly looking to start a business to
commercialize this technology and doing the usual things of seeking a COO,
angel investment, etc.

@_date: 2020-03-05 15:06:19
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Possible reason why password usage rules are 
Yes and no.
The WebPKI is not just an authentication scheme, it conflates
authentication and authorization. CAs can and do revoke certificates for
breaches of faith. This is particularly common for code signing. Domain
Validation and free certs have pretty much eliminated the accountability
the WebPKI was designed to provide.
So the reason for expiry is to cap the window during which certificate
status is reported so that it is possible to revoke a cert for a host whose
key was compromised or has been used in violation of TOS.
Now also remember that in 1995 when we were putting this together, we were
using RSA1024 and RC4. We were not at all confident in the work factor of
any of our cryptographic algorithms. Today we are very confident in the
security of X.448 and AES256.
In the Mesh I have taken a totally different approach. I don't have
automatic expiry of assertions. I separate authentication and authorization
and I use a blockchain-ish approach to deal with changes of authorization

@_date: 2020-03-10 17:22:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] RSA Attendee tested positive for COVID 
Not a surprise given the size of the event. 35,000 people is a lot...
In other news, IETF 107 was just cancelled.

@_date: 2020-03-19 13:14:56
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] COVID: Design problems 
I am connected to a large number of groups looking on  grassroots response
to COVID. There are two design problems in particular that are of interest
1) Marketplace for PPE supplies
There is going to be a major shortage of Personal Protective Equipment
supplies for at least the next three weeks. At that point we can hope that
the government mobilization begins to meet those needs.
So we need to have an infrastructure to match supply and demand. What we
are looking at is a multi-layer system with a large public portal that
allows doctors etc. to advertise their needs which ad hoc makers can
respond to. This will probably be built on some existing platform.
This is of course going to require some level of vetting on the requests
and possibly responders. There is no time to do this in code so we are
going to have to use people.
2) Ending the lockdown
China has been able to ease its lockdown with a variety of technological
measures. People are using their phones to gain entry to places etc. And
this is used to track potential re-infection. We are going to have to
either adopt something equally effective or stay in lockdown until there is
a vaccine.
There are people with resources to write apps. But no design yet.

@_date: 2020-05-01 23:52:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The EFF 650 CAs lie 
Now that is an interesting data point. Any idea what would be driving the
Are these unconstrained CAs that can issue any cert or a cross certified
issuer operating under a constrained intermediate?
This is one of the reasons accuracy matters. If we accepted the 650 CAs
number as valid, this would look like a reduction. But the number seems to
actually be increasing. And its hard to see what the commercial driver
would be for that at the moment what with one of the dominant players
giving away the product for free.
If it is driven by governmental concerns, that would be interesting. Though
another possibility is that the cost of setting up a CA has reduced over
time due to standardization of practices and procedures, the time taken for
a CA to be useful has reduced due to mandatory browser updates and
former affiliates to major CAs are trying to establish their own.
It would be interesting to know what the reason is.

@_date: 2020-05-02 01:42:22
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] NSA security guidelines for videoconferencing 
I went into this issue when I did a youtube segment on security of Zoom.
The problem with 'end to end' encryption is that it isn't the same as end
to end security and the developers may have a different definition of what
an 'end' is.
Have spent way too long explaining to folk that no, their data center is
not an end as far as end to end security is concerned.
I don't see why  folk are beating up Zoom and blithely using dropbox and
slack. Well I do, but...
If you want end to end you need to do the whole job. Not just point
solutions. But right now, anyone proposing anything of that sort is called
over ambitious.
The NSA report really only contains one important piece of information:
They are aware of the security issues and are going to learn the parties
concerned to fix them.
Or point them to people who can.

@_date: 2020-05-03 01:46:24
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] NSA security guidelines for videoconferencing 
Zoom have released more details of their protocol which I looked at in the
video. Will try to do a write up as well at some point. But this is one of
those 'among the problems' situations.
Zoom have a lot of problems but most of them are relatively easy to fix
given money and the will to do so. Some are not. The reason Zoom is so easy
to use is in part the almost complete lack of authentication. They just
give you a meeting id and a 'password' which might as well just be part of
the meeting ID given the way it is handled.
I don't think user-to-user encryption is the term we need because that is
what a lot of the video conferencing systems have AES running from one user
to the other. But they don't have user to user security because the key
exchange is happening in a cloud service they control completely (people
using ECB mode probably aren't using threshold techniques).
That is one reason I think we need to go to 'security' rather than just
For certain applications, we do need to recognize ends other than users. If
Alice is talking to Bob the Broker, the conversation is with an
organization, not just Bob the person. So the endpoints are Alice and the
But random datacenters run by cloud service providers should never be an
One of the really odd things about the Zoom situation is they seem to have
a thing about wanting to stamp out zoom sex parties using AI to detect
images breaking their 'terms of service'. Suggests a failure to understand
their role.

@_date: 2020-05-04 11:11:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The EFF 650 CAs lie 
The claim repeatedly made was that there were 650 entities could issue a
certificate for *ANY* domain. That was not true. It should not have been
said. It should not continue to be said.
It is an accountability control. The entire WebPKI is put together as
layered accountability controls. Having a Verisign class 3 cert didn't mean
you weren't a crook. What it meant is that you were accountable in a
certain way. You have to have a company address, you are subject to
Now sure, it is possible to set up a fake company. As in ONE relatively
easily. But try to do it a few hundred times without being caught. That is
why revocation was critical to the model. The point was to make merchant
fraud unprofitable. All the WebPKI was designed to do was enable Internet
It is possible, that is in fact very close to the model I am looking at.
But making it scale is anything but trivial. It requires an infrastructure
to collect the data on the TLD keys. That is non trivial.
And all you get from such a scheme is an authenticated encrypted channel to
a DNS name. You are not going to get accountability. So the result turns on
encryption but it isn't doing anything about enabling companies other than
Amazon and a few well known names to trade online.
And the only security level supported is piss-poor security for stopping
snooping that we could have implemented just as well by configuring TLS to
support use of self signed certs without user notice.
Well given the anti-Trust suits Google is facing, their decision to
overlook the one and stamp out the other is going to put them in a very bad
place. And various folk on CNBC seem to think the appetite in Congress for
taking down 'big tech' has not been abated by the Corona virus situation.
The Google lawyers really need to start looking at the liability exposure
they are creating for themselves here. Getting rid of your aggressive
harassment types by sending them out to do external standards work takes
them out of the corporate work place but it is a terrible advert for the
corporate culture.
I disagree on the hierarchy issue. I am only interested in bringing control
back to the individual. Most are going to delegate that control to some
authority. Just like they do with AV scanning. But there is a market for AV
scanning tech these days, not a monopoly. And they work for the user who is
paying them for the service.
The alternative to the 4 browsers choosing the trust anchors according to
their corporate interests is to have the 30-odd AV companies do it
according to their interests which are much more closely aligned with those
of the user because the user is the customer. For Google and Mozilla, the
customer is the product.
Apple and Microsoft are in a slightly different position. But the problem
there is neither has much intention of leading in this space.

@_date: 2020-05-04 22:11:27
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] NSA security guidelines for videoconferencing 
Since I regularly stream HD video over an IPSEC VPN using AES, my hardware
can clearly keep up.
There are issues that probably need to be considered though. If you want
the video to look good over a jerky connection, you need to be able to drop
frames so you can catch up. Or switch to a different resolution, etc. etc.
So the approach I think we are going to want is not full hard boiled end to
end encryption but a sequence of encrypted frames so that the reflector has
sufficient metadata to intelligently manage the video but no access to the
And for a full solution, I would want the client to have the option to send
a low res stream on a best effort basis and then forward the full HD stream
when it can.

@_date: 2020-05-05 10:02:06
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Using the NFC chip of the Passport to do 
If you assume that everyone has the same trusted hardware, you don't need
proof of work. You can just have the secure hardware restrict the rate at
which signed evidences are produced.
There is a relevant patent covering the application to anti-Spam messaging
There is an earlier patent, presumably expired which described the more
general scheme.

@_date: 2020-05-05 10:11:05
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] The UK tracing app 
They are not using the Google/Apple scheme.
The paper goes into much more detail on the topic of preventing abuse. The
crypto is completely different but still relatively conventional.
It appears to provide more contact tracing capability, not sure what the
privacy tradeoff is at this point.

@_date: 2020-05-06 02:13:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] NSA security guidelines for videoconferencing 
I have nested crypto in my schemes currently but I am not doing real time
video (yet).
In my view you need to have a transport layer enhancement to protect
against traffic analysis AND a message layer enhancement for data at rest
Data At Rest is going beyond 'end-to-end' to address the real problem which
was that the DNC emails were stored in the clear on the server. OK so
'end-to-end' covers the mail server. But what about the file server where
the employees have their mail spools?
Yes, S/MIME and PGP absolutely give the right protection (when used right).
But the bigger point is that this is about more than data in motion. it has
to be data at rest as well.
One of the things I am doing in the Mesh is to separate bulk data from
control. Control messages are limited to 32KB. That is large enough to
allow for all of the 'setup' messages I have devised so far but not so
large as to cause performance issues when synchronizing a mail spool or the
like. It is also short enough that padding out the packets to a fixed size
becomes practical. (and yes, 8096 might make more sense so messages fit in
a jumbo packet)
The control messages are between the client and service by definition so
they are going to be transport layer encrypted. If there is an enclosed
data message then that portion will be encrypted twice.
So if I was moving bulk data between clients via a reflector on UDP, my
approach would be to reserve the first block (i.e. 128 bits) and put the
frame information (sequence number, stream, number of bytes) in that. Then
I would encrypt that ECB under a key shared between the client and service
because why give Mallet anything to work with? ECB is going to be fine for
that purpose as the sequence numbers are going to be unique (or we can
ensure that this is so).
DTLS doesn't really do it for me... I would much prefer I could separate
out the TLS key agreement and roll my own framing. Use OCB3 instead of GCM,
that sort of thing.

@_date: 2020-05-06 12:45:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Making ceremonies robust 
I came across an interesting detail while implementing a PIN code based
authentication scheme for the Mesh which I think indicates a much wider
security concern.
Carl Ellison argued that we need to treat user interface 'Ceremony' as an
intrinsic element of the protocol. My standards process experience is that
is absolutely essential. Unless you model the user as part of the protocol,
the user becomes a magic asterisk solving all the security concerns using
information they haven't got.
So the specific question that comes up is this: Alice issues a PIN
authentication code to allow connection of a device and hands it to Bob out
of band. The PIN is used to authenticate a device. What should happen when
it is then used to authenticate a second device before the code expires?
The traditional response to this is to essentially ignore the second
connection attempt. Report it to the user as an error but thats pretty much
it. Thinking the ceremony aspects through, I think that is the wrong
approach. What should probably happen is to refuse the connection and place
the previously connected device on hold.
What I haven't managed to do yet is to work out how to generalize the
approach. Perhaps it is as simple as 'error messages don't transfer
responsibility back to the user'. By which I mean tell the user something
happened but don't assume that is the end of the matter.

@_date: 2020-05-21 17:03:12
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Does this provide any extra value? 
So I have the following issue:
Imagine that we have a catalog of encrypted items that a user is going to
access by means of a QR code containing a hash of a secret value from which
we derive both a locator key and a decryption key.
So lets say the key is NCCZ-QP4L-2QFS-YFT7-KQAO-RF4F-SSAA
And we can turn this into a URI with some access info that we stuff into
the QR code:
This is expanded to a http: url:
Where MDGC-... = H (NCCZ-...)
And the data is encrypted under the key NCCZ-...
So only a person with the QR code can obtain the locator and fetch the
encrypted data and decrypt the data.
But here is the thing, someone with the locator can still fetch the data,
albeit encrypted. Is this something that should be of concern?
One possibility I am toying with is to add in an authentication public key
into the mix. Generate the key pair deterministically from the shared
secret and specify the public key in the record. Then do an ECDH auth
Question is, is this really necessary or am I just overthinking this?

@_date: 2020-05-24 14:15:10
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Proposal for a PoS blockchain 
There are two separate questions for 'securing blockchains'.
1) Can the chain be forked without this being noticed?
2) Does the scheme provide a basis for distributing new currency?
The second criteria is of course utterly unnecessary as far as the security
of the chain goes. But it is the governing concern for most people
developing 'blockchain' versions of what I call 'one way sequences'. It is
this bogus constraint that restricts selections to some form of 'proof of
If we focus on the security requirement alone it is pretty clear that
almost any scheme is sufficiently secure because Haber-Stornetta hash
chains are pretty much unbreakable to start with.
BitCoin cheats by making itself secure 'by definition'. Saying that the
longest chain is the right one makes the system impossible to attack by
definition. But if we reject that definition and instead ask 'what is the
work factor for unwinding the chain by n steps', the BitCoin algorithm
becomes hilariously weak when we attempt to use it outside BitCoin.
Consider the case in which Alice and Bob decide to create a private
'crypto-currency' just for themselves and a few hundred friends. Is this
secure? Of course not, lets say that they have ten million bucks in the
scheme and it is costing $100 to mint a new block. Mallet can come in and
unwind any transaction within ten cycles for a mere $1000. And within a
hundred for only $10K. A 51% attack is completely plausible against this
So contrary to the ideology, the algorithm is not secure in the slightest.
It is only the system that provides any security. But we are not allowed to
criticize the BitCoin system because that is only a proof of concept. It is
work in progress. It will evolve into something that is secure. It is too
soon to criticize the system after a mere ten years of operation. To
criticize people's religion is wrong. People who criticize BitCoin only
ever do so out of ignorance. Yada yada.
There is however one very simple step Alice and Bob could take that would
make their chain at least as secure as BitCoin's and that is to include the
BitCoin output into their chain every five blocks and to inject their
output into the BitCoin chain every five blocks. This effectively binds the
two chains together and neither can defect without this being noticed
within five steps.
But at this point, there is no need for Alice and Bob to bother with proof
of waste at all. They sign their output with a signature key every step.
They are (mostly) free riding on BitCoin's work factor. They can however be
caught out if they are found to have signed two different chain values for
the same point in time. And if they ever start doing that, they have to
continue maintaining both forks forever.
Now imagine that we take this to the limit and we have a hundred similar
chains all interlinked and all ultimately free riding on BitCoin's proof of
work and we take BitCoin away. What is the work factor then?
Point is that it is not zero. It is only possible for one of these chains
to defect if they can somehow persuade all the rest to defect. And these
defections are visible and auditable. Anyone who can publish two
inconsistent signed outputs for the same output index can prove that a
notary defected.
So I conclude that proof of work/waste/stack etc. are unnecessary for
'security'. Their only real purpose is to provide a means of enriching some
people by allocating what they imagine to be 'currency'.

@_date: 2020-05-30 19:39:22
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Zoom publishes draft cryptographic design for 
Because all the elliptic curves are isomorphic and offer the same security
and we don't particularly rate the choices of the BitCoiners. In case you
hadn't noticed, there are multiple billions of dollars of cryptocurrency
fraud a year. So chosen by that crew isn't exactly much of a recommendation.
The reason we chose the keys we did for the CFRG curves are well documented
and have to do with developments since Hal developed BTC. Things like the
DualECRNG issue. The curves are chosen for speed and to limit the choices
to the point where nobody can accuse anyone of having chosen a curve with a
hidden agenda. If there is a particular reason why 2^255-19 is jiggered, it
is unlikely to just affect that number and it certainly isn't something
that NSA has a leg up on breaking. So if the NSA did promote that curve
because it was weak they would break the NOBUS doctrine.
I haven't looked at the zoom spec. I'm a little sceptical because people
They have a particular set of concerns that may be considered 'ideological'
wrapped around the axles.
They are obsessed with forward secrecy. Which is nice only for a business
call we often want to archive the call. So forward secrecy is moot.
I don't see the need for this for typical meeting sizes. If you have less
than 20 people in the call, just have a leader compute rekeys for everyone
every 5 mins. Much less complicated than the tree systems which in my
experience are flaky as heck.
It's a hard problem. I assume Zoom limits the problem set to "the leader
I am not sure what is meant by 'fake user' in this context though. It
really depends on the model of who is trusting whom. If I can get a 'fake
user' into the group, well I am already in, aren't I so can't I just defect
The real difficulty here is setting up the security requirements and
deciding what you want them to be. And I get really skeptical of models
that claim more than two people are peers.

@_date: 2020-11-17 15:41:07
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
IETF was set up to allow the DARPA program managers to monitor all the
grants they had awarded. That is where the IAB and IESG really come from.
It is also where the 'consensus' thing where the politburo get to decide
everything comes from.
Of course, DARPA/ARPA haven't been an issue in IETF for decades now. But
the legacy remains. The people with the authority have no accountability.
And that means they can't take important decisions.
So the answer is to not do that - not do committees, working groups, and
If you look at the successful security protocols in use today, only TLS was
a group effort and that was largely because the principal architect wasn't
legally allowed to work on it. PGP and SSH were both the work of one
individual who got from the initial design to an advanced prototype alone.
The real inventor of TLS was Marc Andressen. It is ironically, the one bit
of the Web he was the prime mover on and the one bit has never received
credit for. At the time the idea of a Transport layer solution 'secure
sockets' was really not the way to do things. Application layer was
obviously more powerful. Only we didn't have the technology to do message
layer at that time and the machines weren't up to it. Marca couldn't work
on SSL directly though because he was under a non-compete to EIT. And while
he had the top level architecture right, he didn't have the experience to
get the lower levels right.
Problem with the individual inventor model is that there are maybe 1000
people in the world with the necessary skills. Of those, only a small
number have the ego required to stand up and make a proposal. Being the
target of other people's scorn is a lot harder than throwing rotten eggs at
other people's stuff. And only a very small fraction of that number have
the independent means to allow them to spend two to five years working
without an immediate income.
Sure, I do have an end to end secure password vault and it is almost ready
for release. How sure would you want to be that the code is correct before
YOU release?
The problem here might be how to stop nefarious agencies (NSA) from spiking
Don't assume the NSA is still the enemy. The Snowden breach has really
changed attitudes. So has the DNC hack and the proliferation of
disinformation operations and intelligence gathering operations posing as
'transparency organizations'. They are suddenly aware that the US is a
really big glass house and the opposition is throwing stuff a lot bigger
than their stones. One of the reasons I changed the name of PRISMProof to
the Mathematical Mesh was that it is the technology that the NSA needs more
than anyone else.
There is a piece of information I was given that I was told is the key:
NOBUS. Nobody but US. It is still NSA doctrine as far as I am aware.
Basically, they are perfectly happy creating backdoors when they can. But
they must satisfy NOBUS - only 'we' can exploit them. If you look at
DualEC-RNG, that satisfies NOBUS.
But it isn't just the US that is manipulating the standards processes these
days. We have China and Russia pushing their own agendas as well. It is
instructive for people to look at John Young's dump of the emails
discussing the creation of Wikileaks. One minute there is an open,
cooperative effort to build a transparency group, the next, there is one
person in sole control and pretty much everyone who helped him set it up
has been kicked to the curb.
Besides metrics for crypto, I think we need metrics for transparency
organizations and investigative journalists. Was the outing of Manning and
Reality Winner really an accident or does the FSB just find that having
some martyrs helps their cause?

@_date: 2020-11-17 16:09:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Possible reason why password usage rules are 
Reply to various points.
Some of the password stupidity we suffer from today comes from the two
weeks after the release of Crack. At the time, UNIX password files were
world readable by default and anyone suggesting shadow password files was
the way to go was attacked for 'security through security'. Crack upped the
ante because it could make 6? 60? attempts a second and so a moderate sized
cluster of SPARCstations could test every password in a million entry
dictionary in a weekend.
And so the solution to this was to insist on the special characters which
increased the cost of a dictionary attack by an order of magnitude (sorta).
Only they don't because...
Modern cracking machines can do 600 billion attempts per second and exhaust
the Windows NT 4 password space in a few hours. And no, slower digest
functions are not a solution because there is simply no password that is
long enough to be secure that is short enough to be memorable. Battery
Horse Staple Correct is 2^60 bits of work factor. That is not strong enough.
So yes, we have to move away from human memorized passwords. And I have
been building a threshold PKI to make that practical. And it is very very
nearly complete. The current status is that all but 5 out of 400 unit tests
are passing. I should have the final unit tests cleared in a few weeks and
then be able to start deployment.
Yes... but who wants to start off trusting a completely new password
So I am looking at some slightly lower sensitivity applications first.
For password replacement, I think we need a two stage approach.
1) Long term has to be to move to public key based authentication for the
Web so that we don't expose the secret we are using as the basis of
authentication to authenticate.
2) Transition strategy has to be a password manager that provides end to
end security such that the cloud has no access to the stored passwords in
any form and is ubiquitous so that the user can access their password vault
from any device, any browser they authorize to access it. Only then can the
user start using machine generated passwords in place of memorized ones.
The first is actually a precondition for the second. Any system that
deploys the private keys necessary to make the password vault end to end
secure is also going to be able to support PKI based replacements for
The second is what I am using the threshold encryption for. And I am now
very confident that I have the right model. I have tested out every part of
the system in isolation, I just need to complete the integration.
The hard part is making the vault 'ubiquitous'. Up to now, password vaults
have been proprietary solutions that are all about locking the user in to
one provider. I am all about giving the user autonomy. So the password
vault is going to need some sort of service to provide a synchronization
point between devices. But the user should have a free choice, not be
forced to pick iCloud or OneDrive or Google cloud because that is what
their Web browser is welded to. And having made a choice, users should be
able to change it any time they choose without any switching cost
So the requirements for this type of password vault are:
1) True End to end security, only the user's devices ever have access to
the plaintext of the passwords. The cloud controls decryption (so it can
disable lost devices) but cannot decrypt.
2) Open specification, documentation
3) Open service: Anyone can set up a service without permission from a
central authority. People can run their own services.
4) Autonomy: Users can switch services at any time without changing their
call sign (aka address). If Alice switched from Verizon to Comcast, she
remains Note that making the service unsticky might well be the key to deployment.
A lot of people used their Comcast or Verizon emails when they first got
broadband. And the ISPs loved that because the customers were sticky -
changing providers meant an expensive change of email address. But
customers quickly realized that was a problem the first time they moved and
couldn't keep their old ISP. Hence the rise of Gmail etc.
Switching costs break both ways. They keep your existing customers in but
they make it harder to expand as the customers wise up.
Current status is I have addressed the first three and have a plan for the

@_date: 2020-11-19 05:46:30
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Possible reason why password usage rules are 
Password cracking doesn't use dictionaries any more... brute force is
Sure, nobody leaves the front door open on the password file any more. But
breaches occur regularly and the password files leak...
Retired bitcoin mining rigs... 600 billion a second. 0.6 THz... That system
is six years old now.
This gets me to an oft ignored point: passwords (something that has to be
No they aren't. Not in practice because the user has absolutely no control
over how the password authentication data is going to be stored.

@_date: 2020-11-21 23:21:39
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Possible reason why password usage rules are 
What is a reasonable fee for memorizing a piece of information?
If someone wanted to hire me to remember a piece of information, I would
charge them at least $2500. So hell yes, I reuse passwords. I reuse
passwords for assets that DO NOT BELONG TO ME unless I am being paid to
protect them.
I find that the assumptions of technologists tend to be really arrogant at
times. When it comes to security, it is not just a mistake to expect the
user to make an effort, it is almost always unreasonable.
I wrote the HTTP digest authentication spec because I knew there was no way
in heck that users would possibly use a different password for every site
and that was the best I could do with unencumbered technology until the
Diffie Hellman patent expired.
You have an unacknowledged cost transfer in your proposal. And that is why
it is never going to work. Real users are not going to remember multiple
passwords. We have to stop trying to learn them how to do things properly
and take responsibility. This is our problem to fix, not theirs.
As I said, as the user, I have no way of auditing the site. So yes, I
assume that some don't even hash.
I have a large collection of plain-text passwords that have publicly
While the origin of the restrictions is almost certainly stupidity, there
is plenty of cargo cult implementation as well. We know that special
characters actually weaken most user selected passwords because it
effectively reduces them by one character. The obvious way to respond to
such stupid is to stick ether 1 or 1! on the end as necessary to meet the
idiot requirement. So while I accept the premise...
I am saying we need to abolish memorized passwords as a means of site
authentication and we have the means to empower the user to do just that.
Provide the user with a Web browser on every one of their devices that can
fill any form with a username and password pulled from an end-to-end secure
vault and they can use a different, strong password for every single site.
And they are very likely to do so because this will be the easiest thing
for them to do.
Additional security can be provided by adding a second factor (biometric,
memorized PIN) to access the vault.

@_date: 2020-11-22 11:40:16
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Possible reason why password usage rules are 
Those types of check are better than nothing but not really providing very
much security and introducing an incredible level of user aggravation.
Password authentication is beginning to fail in the same way that email is
now failing as a result of countless ad-hoc attempts to mitigate spam.
Passwords were a way to authenticate user actions in the past but now we
The argument I am making is that we need to design an infrastructure for
this express purpose rather than continue to try to cobble together 'good
enough' security based on what inevitably turn out to be half-assed guesses
as to what security is actually being achieved.
IP addresses change regularly. Users make use of different browsers on the
same machine. SMS is not secure in any shape or form, SS7 hijacking is a
trivial technical challenge yet it is depended on, etc. etc.
Time to do the job right.

@_date: 2020-11-24 13:10:29
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Make it rain, baby girl. 
I?m trying to explain to him, in as much detail as I can muster as he
Soros isn't a life peer. He isn't even a UK citizen.
Near as I can make it out, the argument here is 'it could have happened so
it must have happened'.
There is an argument to be made that the process of voting must be above
suspicion. But anyone taking a serious look at the accusations made by
Giuliani and co quickly notices that they haven't actually made any
substantive claims. All they keep doing is promising they will make a claim.
So, I?m very prepared to believe Sidney Powell.
Well it seems nobody else was as she has just been fired.
I just saw a NewsMax clip on YouTube(spit!) where she says she?s gonna kick
The Civil Rights Act of 1965 makes it a crime to fail to count, tabulate,
etc. any lawfully cast vote. It is also a crime to attempt to coerce
someone to do so. Looks like Lindsey Graham is going to be spending quite a
bit of time with federal and state prosecutors in the near future.

@_date: 2020-10-15 20:45:52
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Secret sharing for family members 
OK so one thing you might want to use here is Shamir Secret Sharing. I have
a spec for that:
So what I would probably do is to create a Mesh account  and
make sure that is on the recipients list for any data I want my heirs to
inherit. Then create a recovery key set for the secret seed for that
account. The heirs can now decrypt any of the data.
The crypto is the easy part. Easy peasy. Have had that specified for over
18 months and running.
The hard part is making it easy for people to use it. That is where the
Mesh Groups come in. I can create a group  and add to that group. So I only need to be thinking about encrypting to one
recipient. I don't need to encrypt to  and  separately.

@_date: 2020-10-16 10:49:13
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Secret sharing for family members 
[Earlier comments lost from the thread]
OK so I do not have code right now that is responsive to the original
question. I may have code in a few weeks or months but releasing encryption
code is a tricky thing, I want to be as certain as I can before launch.
I don't see anyone else with a product there that really meets this need.
So what I propose to do instead is look at what it would take to get us
I see no value in them at all for data storage. The only reason I use them
at all is that if I buy music from the iTunes store, I have to go through a
faf to get the data. I have a process for ripping CDs. It is pretty clear
that CDs will be gone soon. SSDs have a finite lifetime. but lets do this
Confidentiality - can anyone read the data before they should?
Integrity - can the data be modified without detection?
Availability - could we lose the data?
The most important of these is the last so we should consider it first.
At this point the only data that a normal user is likely to have that is
going to tax their storage system is video. Even a professional
photographer shooting 45MP RAW would have difficulty filling up a hard
drive with stills.
So it looks to me like the best solution for availability is going to be to
outsource that to a cloud service. And it seems to me that a $25 one off
fee for a small amount of permanent storage (50GB say?) separate from
everything else would be quite practical.
There is a marketing issue there in that the only companies that I would
trust to provide such a service, that is are likely to still exist in ten,
fifty years time are ones that are unlikely to be interested in offering
it. The only one that might is Google which has a really rotten reputation
when it comes to committing to support their services over long periods of
OK, so cloud means we have to have confidentiality which means encryption.
UDF Shamir secrets are simply Base32 strings with separators:
   f(1) = SAYN-KTFM-QSEH-5LYP-HTSI-XEV4-MFCG-E
   f(2) = SAYR-CV3K-UBS5-PIKF-SUD2-5PGS-IR3H-6
   f(3) = SAZH-5BO3-QPXT-AZ7Z-YHMJ-YTSZ-TI4R-O
   f(4) = SAZR-ZV77-F4SI-SAZL-YNLV-IR2S-MKF4-I
   f(5) = SA2O-YTOV-UIC6-C4W3-TGB5-NJ54-TVXO-Y
The above are five shares with a threshold of three which may be used to
recover a 128 bit master secret which is a sufficient work factor for the
non quantum cryptanalysis case. If you want 256 bits, the shares will each
be twice as long.
There is a small amount of control information in the above, the first two
bytes specify the type of key (Shamir/Lagrange secret share), the x
coordinate and the threshold.
At this point, QR codes will be with us for the next thousand years. There
might be a better technology but it will supplement, not replace.
meshman does exactly that but it isn't quite ready for use yet.

@_date: 2020-10-18 14:29:22
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Secret sharing for family members 
Thanks, the code is at:
The UDF implementation is just one file in the goedel.cryptography library.
It is in C# but conversion to C or Java should be straightforward. That
class is implemented as a static class to facilitate translation to C. Java
should be even easier.
If all you want is the Shamir/Lagrange part, its probably no more than 300
lines of code.
So what I would probably do is to create a Mesh account  and
The Mesh provides a data at rest encryption scheme that is designed for
integration into applications like Microsoft Office. So recovery of the
Mesh key gives decryption of sets of documents.
The tool provided can also be used to create RSA and SECDH keys from a seed
value using a deterministic procedure which could be used to decrypt
OpenPGP or S/MIME docs if you wanted to go that way.
That is one challenge. I am developing a platform on which such apps can be

@_date: 2020-10-19 21:50:57
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Fun with printers, 
I designed my system with secrets short enough to be written out by hand
precisely because of these issues.

@_date: 2020-09-03 00:13:49
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] any reviews of flowcrypt PGP for gmail? 
The solution here is an open standard that allows two apps to talk to each
other. And that is what the IETF should have done instead of MLS.
Developing a technology for folk to apply to their walled gardens... that
is really not what the IETF should be about.
Oh and, I don't see emoji as much of a problem to implement. Its just
unicode at this point. Same as support for any non-Latin character set.
At this point I have 'most' of an end to end secure messaging scheme. But
that is not the area to address to find an early adopter community.
Contact, Bookmark and password management provide a unilateral benefit even
if nobody else uses the Mesh while still building a user base that can
start to exploit a network effect if it reaches critical mass.
I would not want to copy the Signal approach because I really don't think
it scales. Messaging in a room with 20 people can be peer to peer it
rapidly collapses if more than that try to engage at once. So there are no
peer to peer rooms with 1000 people in, not even 100. So you have to
introduce structure to keep the system running. That's why the Hells Angels
use Robert's Rules of Order for their meetings.
There is no real difficulty doing 20 ECC key exchanges to rekey a smaller
meeting. And that allows a much more reliable approach than the tree.
Having been in multi person Signal rooms... nope, not copying that.

@_date: 2020-09-22 11:55:36
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for the 
I have restarted work on the Mesh after a short holiday. The revised
architecture document should be ready in a fortnight. There is one very
critical piece of infrastructure I haven't mentioned yet, the naming
system. I suggest that people read the whole post before reacting rather
than assuming that I am the usual sort of capitalist despot.
The Mesh is a Threshold Key Infrastructure which is basically a PKI but
making use of the fact that we can split private keys into shares etc. I
have tried to minimize the need for a service element and to minimize the
degree to which the user needs to trust the service element. But the Mesh
incorporates an asynchronous messaging capability which necessarily
requires some sort of service to act as a dropbox to which messages can be
posted for later collection. I call this a Mesh Service Provider.
Alice and Bob are probably capable of running their own MSPs, they have
been doing crypto together for over 40 years after all. But most users
won't. They are going to have to outsource their MSP provision to some
third party. And I think that is completely OK, most of us outsource SMTP
email service these days. What is not OK is the SMTP model where the email
address is tied to the service provider so that changing email providers
incurs an enormous switching cost.
The current corporate model for Internet services is to try to make
everything sticky. I don't want that even though one of the businesses I
have started is going to be an MSP. The Mesh is all about putting the user
in control. User's can't be in control if they are chained to the service
So what we need is a simple registry that provides service discovery. The
very simplest form of registry would be to map a UDF of a Mesh fingerprint
to the service provider. So mb2gk-6duf5-ygyyl-jny5e -> alice at example.com.
And we could have a few of those. But that wouldn't last long because users
would much much rather just be something like So I don't want Alice's address to be alice at example.com. I want her to
be  And I want her to be able to use that same account and address
at cryptomesh (my MSP) or Comcast or Google, or whoever. This makes it very
easy for Alice to be her own MSP if she chooses, it isn't a lifetime
This is the point at which someone fisking the thread will write, 'but
Phill, you don't understand, running a naming system is really hard, just
look at ICANN'. Yeah, like I wasn't Principal Scientist of VeriSign for a
dozen years when we bought Network Solutions. This stuff is difficult and I
have been lucky in the past. But meeting Tim BL was luck, joining VRSN and
creating the WebPKI was not.
So if  wants to send a message to  his MSP will lookup  in
the registry, discover that it is currently serviced by example.com and
send the message there.
This is a difficult problem if you decide to make it so. It really doesn't
cost $250,000 to decide if someone should have a TLD. That is pure rent
seeking. And no, I don't want to enter into discussions of why that is OK
or why we should embrace an organization charging $250,000 for a
registration as the operator of the successor to the WebPKI where CAs
charge a few hundred dollars a year. The important point we will come back
to later is that while the registry I describe would cost almost (but not
quite) nothing to run, it would potentially generate a vast amount of
value. People will be willing to pay significant sums for names such
as  etc, there will be trademark issues with  etc. etc.
And again, the only reason I am stating the blitheringly obvious here is
the alternative is a series of comments of the form 'Phill, you ignorant
OK so the simplest record for alice would be something like:
alice :
    udf: mb2gk-6duf5-ygyyl-jny5e
    service: example.com
    registration: initial
And we put this all in an append only log authenticated by a Merkle Tree
and sign it once a minute. But unlike in the DNS system, the registry does
not provide a query service. Instead, MSPs maintain a local copy of the
registry of names and use that to respond to queries from their users.
Getting rid of the registry query service immediately removes 99% of the
cost of running the registry. It also means the system is inherently
failsafe. The worst that can happen if the registry is completely destroyed
is that the ability to post updates will be lost. A DDoS attack that takes
out the Comcast MNS service is not going to take out Verizon. The fact that
attacks cannot cause a global outage will greatly reduce the incentive. And
since an attack on Comcast can only come from Comcast customers they are in
a much better position to defend themselves.
Since we have a DDoS resistant infrastructure, why not use it to publish
delegations for DNS services as well?
    udf: MB5S-R4AJ-3FBT-7NHO-T26Z-2E6Y-WFH4
    dns: 68.87.72.244
    dns: 69.252.250.103
ICANN world DNS can go down now and we can still reach  if her MSP is
comcast. Ain't that interesting?
At which point we should better think about the trustworthiness of the
entries. Aren't we putting a lot of trust in the registry?
The simplest record is not the best one because we want to have
authentication etc. etc. And so we are actually going to maintain two
separate logs. One of which contains the data we want to query, the other
of which contains the proofs.
Every change made to a record in the registry must be supported by an
assertion signed by the name holder.
The registry signs both append only logs once a minute. Validating MSPs
download both logs and check that every entry added to the log is supported
by proof. If everything is OK, the validating MSP sends a token back to the
registry saying 'I checked the log up to this point in time' and this is
entered into the registry log.
The net effect of this scheme is that as far as each MSP is concerned, they
are the root of trust for the append only logs: Any defection by the
registry will be detected. It is not possible for any of the parties to
defect without their defection being visible to all unless they all
collude. So we get the Blockchain type effect of preventing rollback but
with a 1 minute period instead of ~10 and without the need for proof of
So now, when  Bob sends that message to  he can be really sure it is
going to the right place, is end to end secure, etc. The only reason there
might be an issue is if the name has been reassigned because of a trademark
As a practical matter, I think it is essential that a naming system meet
the reasonable expectations of the users and that expectation is
that  goes to Microsoft corporation not some scammy namegrabber.
But  certainly doesn't go to Prince Sports, it goes to the artist's
estate. So some legal and UI issues there. I think it fine for names to be
reassigned provided that nobody USING the original name is affected and
that the reassignment is completely visible. So if  is reassigned
to  anyone using the name is warned.
There is also an IoT play here, what if we want to send a message to
Alice's coffee pot? Well that is coffepot at alice.
We can represent these names in the DNS by defining our own TLD. No, I do
not feel inclined to pay ICANN's rent. One of the features of the Mesh is
provisioning network configuration information. So we can tell connected
devices which DNS service to use and that can map  to alice.mm--
which is not a valid TLD ICANN can assign.
Oh look, we have a new bit of censorship resistant technology. All she
needs is an authoritative DNS service and Alice can publish her stuff at
 and that will be stable regardless of what ICANN
does. And her coffee pot can offer status info at
 under a certificate that is signed under the
root of trust mb2gk-6duf5-ygyyl-jny5e.
No, I am not putting the CAs out of business with this. But I am
eliminating the need for LetsEncrypt and NSA corrupted botches like
DANE/TLSA. This will replace DV certs over time but the need for EV will be
just as important because creating a trust relationship requires a source
of accountability. And besides that, the Mesh creates more interesting
opportunities for CAs as Mesh applications will present logotype
information to the user.
OK so what about the business model for the registry? I expect this to cost
about $2 million a year to run it properly (no I am not spending that on
the prototype). We could go round with a begging bowl but look where that
got us with the NSF.
I think it much better just to charge for the names. But the incremental
cost of servicing a name is close to $0 and the cost of maintaining a name
IS $0.000000/year. There is no need for renewal fees. Names are for life
(unless sold or reassigned).
So one business model would be to charge $0.10 for a name with up to 50
change of service registrations included. Which is fine and the model I
would like to go with for names of 8 characters or more.
But why leave money on the table? My problem with the ICANN model isn't
just that they are corrupt rent seekers buying themselves bigger yachts, it
is the fact that (almost) none of the money ends up going to people who are
contributing to the development of Internet technology. It is just absorbed
by a clique of rent seekers and lawyers.
So what if we charged more for the shorter names that are going to be in
high demand and used the revenues to fund development of new Mesh
technology? The charges would increase exponentially as the name became
shorter. $100 for a 7 letter name, $1,000 for six, all the way up to $10
million for single letter names.
This approach has the important advantage of creating a disincentive for
namegrabers. Nobody is going to spend the $100,000 needed to namegrab knowing that it will be reassigned.
The Mesh is a binary prospect. I don't think it can be a modest success.
Either it succeeds on global scale or not at all. So the registry is
potentially worth of the order of a VeriSign Inc. And so the only way that
it can possibly be allowed to succeed is as a form of public goods. Which
is fine, its not like I personally need the cash (and I will have the MSP
to unload). The only thing that can be done with wealth on that scale is to
hoard it (pointless), give it away or spend it on parties. What I propose
to do here is essentially short circuit the process so that the registry is
run by the Mesh foundation which spends a large proportion of it supporting
the developer community with consulting contracts, salaries and conferences
in really nice places. Think of it as the equivalent of making club in the
sales dept.
I see this as a win-win-win for everyone apart from (some of) the
Right now the IoT space is being dominated by five major players all trying
to establish themselves as the monopolist. And at least two of those are
starting to realize that the eventual monopolist isn't going to be them.
The Mesh provides an open playing field.
So in case the point of this message is not clear, I think I am close to
done with the design of the Mesh. I am going to need a vast number of
people to deploy it, many of whom are here. I don't have the funds to hire
everyone on contract but if we are successful there should be a foundation
that has the means to 'do the right thing' for everyone involved, including
the folk at Comodo who originally financed this work.

@_date: 2020-09-24 14:01:42
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
I do support that capability as well but in the Mesh Contacts catalog. And
that is critical because I want the voice command 'open the garage door' to
be context sensitive and open the door of the garage of the house I am
currently in, not my main home when I am 2000 miles away. But local names
are not usable as universal names. They are only useful in SDSI type
fashion of bob at phb - that is 'PHB's bob'. And I might even end up using
that notation when we get to web of trust type issues.
The problem of multiple people wanting  is easy - none of them get it
because it is one of the names I am reserving for example use. And it is in
any case a five letter name so it would be ~$10,000 if it was for sale.
So people are going to have to be  or  or the
like. And those are $0.10 names and for life.
Sure, there will be collisions. But its first come first served and I am
completely OK with that limitation. I would much rather than than the
situation on Facebook where there is the pretense of using real names only
they are not checked and Facebook don't even stop people creating copycat
accounts for scamming people.
The users of Twitter seem to have worked this out without too much adverse
effect. And it is not my problem to provide something that is perfect, all
I am looking to do is to provide something that is better than ICANN and in
particular something where names do not expire and trademark owners do not
have to repurchase their names in an infinitely expanding universe of
namesqatter TLDs selling at $250,000 a time.

@_date: 2020-09-24 14:09:48
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
Underneath, your name is a sequence of 24 random Base32 characters... That
is the fingerprint of your public key with a work factor of 2^112.
Thats an OK way to label things internally. But it really isn't something
most users will find usable. And thats fine. This can be a naming
infrastructure that is only used by the 99% not the technorati.
The naming is just a side benefit from the need to map profile fingerprints
to service providers so that you can change your service provider at any
time with zero switching cost. If you don't want to use it, fine. I might
even support profiles that don't have an alias for free.
But if this succeeds, there will be plenty of people who will pay silly
prices just to have a short name. And whatever their motives, that money
will go to fund the development of the Mesh into the future. And probably
quite a bit else.

@_date: 2020-09-25 22:34:59
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
No. That name space is taken by the telephone system and there is an
existing authority that assigns and reassigns the dwindling pool of
numbers. It is the use of telephone numbers that I find the weakest part of
There is already a DNS to telephone numbers hack used by SIP. Let that
infrastructure die a gradual but hopefully final death. Like USENET it is
being spammed to death. 70% of the telephone calls I get on the landline
are spam. Which is why that line is going to be going away very soon. The
only reason we have it is the cell phone carrier demands a stupid rate for
international calls.
If you want to pick 8 random characters for your Mesh name, fine. But I
want a vanity name myself ( and I want to have a decent title for the
controller  (as in Bond's quartermaster, not that other jerk). And I need
to have a way to fund the development lab and I don't do cryptocurrencies.
If we are going to do telephone numbers, we can just require the
international code to always be there. so  But That is
something I would reserve so that if at a future date we decide it is worth
doing, we do it properly and map to the actual legacy telco network. But
that would be a transitional technology to absorb the remaining remnants of
the telephone system, not something I would lead on.
So reserve all numbers and dashes for future use.
I have yet to see any problem that is solved by federation except the
problem of how a large number of pre-existing institutions fight over the
The division between .com .net and .org was a fiasco for the Internet. The
real world does not fit an arbitrary taxonomy thought up with five minutes
thought. It doesn't fit any taxonomy. All the division did was force people
to re-register their names in each one - if they were important. And now
for the price of $250,000, you can apply for your own right to extract
money for defensive registrations. The number of TLDs being kept at a level
considered judiciously within the boundaries of what will avoid a revolt.
Every single one of the new GTLDs could be shut off tomorrow and almost
nothing of consequence would happen.
So no, I am not interested in 'federating' the namespace.
On Thu, Sep 24, 2020 at 6:13 PM Richard Outerbridge (eventually) get Microsoft, Apple, Google, etc. to adopt it and integrate
it into their platforms. Of course they have their walled garden,
interactive TV plans right now. But this ain't my first rodeo. Time Warner
had Interactive TV. Yes, there is a lot of money that has been pumped into
IoT because they all have this idea they are going to emerge as the
monopolist. Which is why I waited to the point where more than one of the
big boys has already started to realize it's not gonna be them and so they
should think defensively and making sure that their rivals don't win the
monopoly and shut them out.
If you are going to play with that crew, they are going to insist on owning
their names and such. So I am fully OK with the idea that whichever scam
artist decides to register ' discovers they don't get to keep it
or to extort the trademark owner. And I am equally OK with the industry I
helped to create, the CA industry being a part of a solution to that
problem. But that doesn't mean anyone can demand  because they
would rather like to have it. ICANN has been through all that. We can
re-use those parts of the design. But we don't need to fret about the
details at this point.
What I propose for this issue at this point is the ability to post a
'challenge' against a name. This would have a fee associated with it, say
$1000. So if someone is squatting on a trademark, someone can issue a
challenge and at some point we can develop a process for working out how to
handle those. And if the name is re-assigned, this is visible in the log.
So anyone who has connected to the old  will be notified of the
fact when they try to use that contact and they will be connected to the
one they choose.

@_date: 2020-09-26 12:41:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
Here is how I would see things going.
First off, nobody uses telephone numbers for dialing any more. They are
used to establish an initial connection and then get stored in a contacts
Secondly, if you build on the legacy telephone infrastructure, you are
going to end up finding yourself regulated under CALEA. Not good.
So let us imagine that parallel to the Mesh naming system, there is a Mesh
telephone number tracking system. I can register my telephone number and
bind it to a Mesh account. And this is authenticated and periodically
re-authenticated by means of a callback. Maybe the service tracks the SS7
system to see if things have been reassigned.
Alice has +1-617-666-1234 registered in this service and it binds to
alice at service.
So now lets imagine that Bob is using his Mesh enabled comms app to call
Alice. She is not in her contacts, he dials the number on her business card
* Consult the telephone number registry, the name is there, use the Mesh
VOIP protocol to establish an end to end secure voice call to alice at service.
* (Optional) try other non telephone providers.
* If not found, drop down to standard SIP based VOIP telephony (however
that works) through her telephony provider. Since Alice doesn't know Bob
(yet) this is likely to be a voicemail box because the legacy telephone
system is so spammy these days it is dying and will soon be dead, dead,
The advantage of going through the Mesh first is of course we can then
achieve end-to-end secure and have the ability to shift to a different
modality (message, video) if desired. And since Alice doesn't know Bob in
this use case, she can require him to perform a contact request first
unless Bob has a credential from some group Alice has put in her accept
The way I see things, traditional telephone and SMTP email are dying
because they are too spammy to live. And the only thing keeping them alive
for now is the fact that they are the only open, interoperable game in
town. If there is a viable spam free alternative that is open, it will
start to acquire users and will be supported by a large number of ISPs etc.
who realize that they are not going to establish themselves as the monopoly
provider of the replacement system.

@_date: 2020-09-27 00:08:45
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
This gets away from my naming system and back to the original core of the
Mesh. I must say that nobody seems to have raised the expected objections.
So folk are ok with the basic structure I am proposing, thats fine.
On the bridging issue, that is where I started. One of the really important
contributions to the Web was the scheme part to the URL which was
originally proposed by Dan Connoloy. The two most important parts of the
strategy to me are the Credentials Catalog and the Contacts Catalog.
Combined with an intelligent client, they help us move from where we are to
where we want to be.
The key to both is that all Alice's devices are glued together to form a
single Gestalt UNDER HER CONTROL. So she adds a password on her mobile, it
is on the laptop and desktop. So Alice can get out of the business of
remembering site passwords which are stupid and no longer functional.
Nobody can remember a hundred passwords of any quality. Certainly not a
hundred strong ones. So put them all in a password vault, share it across
every machine Alice owns and she never has to remember passwords. And if
Web sites get bent out of shape about that, well they can get a clue and
use the fact the Mesh provides public key based auth across those devices
as well.
Its the same for Contacts. Alice can put all her walled garden contact
addresses in her contact data she publishes. So people know how to get her
on Skype, Zoom, Signal, etc. etc. And she can reach the people who aren't
yet on the Mesh in their walled gardens. But here is the thing, an open
system always beats a walled garden in the long run. Skype has got about as
big as it will get. Signal can grow quite a bit still. But there are limits
to any closed system.
What the Mesh does which I have yet to see anyone else do is address the
problem of managing keys across devices. And that is really hard to do in
PKI. In fact I tried to do that for 20 years before I realized that PKI
can't do that, you need threshold so its a TKI.
So if someone else tries to create an open system, well I will add them to
my scheme and I guess they will add mine to theirs if I have any user base.
At which point they will just be two views of the same space.
Yes, privacy is an issue. BUT from the start I have wanted to design a
system that would allow Madonna or Lewis Hamilton to use their own names as
identifiers and not get spammed to heck as a result: Everything is under
access control. So one way to approach privacy is to mitigate the cost of a
privacy breach. I think we need to use that more.
If people want their actions to be untraceable by the authorities... well
they better use identifiers that are opaque and not publicly link them to
their other identifiers. At this point I am trying to avoid giving out
metadata unnecessarily but there are pragmatic limits to the amount of
traffic analysis resistance can go into the base system. Maybe we layer on
TOR like techniques later on. Certain aspects of the design are designed to
facilitate that (limit on message size, every MSP has a complete copy of
the naming registry).

@_date: 2020-09-28 12:18:38
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
Well nobody cared about the Web either until it took over the world. Tim
came into my office one morning to say he had been asked to give the
keynote at the Hypertext conference that rejected his paper only the year
People seem to care about breaches of data in the cloud. Threshold is the
obvious technical control to prevent those breaches. As of now, I seem to
be the only person pushing for use of threshold technology, I am certainly
the only person who has build a Threshold Key Infrastructure.
I am getting some traction but it is slow. I gave the presentation showing
threshold was the way to address the Snowden breach in March 2017, the
Vault 7 breach was announced during the meeting. The NIST effort began nine
months later and might actually turn into a program March next year.
Meanwhile, Microsoft has delivered a minor, non threshold patch for their
CRM product.
I am very much aware that I am the only person who seems interested in this
problem right now. But as I pointed out on the CFRG list, I have deep
contacts in the mainstream media and I can make a hell of a lot more noise
than most. And my crypto isn't fake. So what are folk going to tell their
CEO when she asks them about the new technology they have just read about
in the NYT? When I had that job I made sure I could answer that question
every time.

@_date: 2020-09-28 12:30:56
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
No, you don't own it. You rent it. That is the difference between a Mesh
name and an ICANN name.
If you have  it is yours forever unless it is reassigned because of a
trademark issue. And we can make the limits on that type of reassignment
far more stringent than ICANN's rules that are tilted to the IPR sharks.
ICANN registries have to work night and day to maintain your record. My
architecture only ever has to respond when you decide to change your
service provider. And I have included a number of free changes of service
in the base cost of the name so you can't be extorted on that.
Should my name registry default, all the data is stored in the public log
which is replicated at every MSP. So it is a trivial matter for them to
roll out a fork of the name service. The name service only maintains its
position as long as it is generally considered to be doing the right thing.
In other words, there is accountability.
I have tried a number of different designs. The problem is that if you try
to go fully peer-to-peer, you end up in a situation where there is
certainly a huge imbalance in power but nobody can be held responsible for
their actions. The BitCoin world shows this sort of behavior. Rather than
get hung up on ideology, I would prefer to have an organization but
minimize its authority to the absolute minimum and hold it accountable for
the rest.
In the m-o-o-t name system there is are no ties at all. Anyone can
That is another approach. But I think it clear that people really do want
the option of a vanity name. Sure it adds some cost. But it creates vastly
more revenues and allows the Mesh Naming System to replace the corrupted
ICANN scheme.

@_date: 2020-09-28 19:07:11
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
What percentage of Internet users own a domain? Certainly less than 1%.
$10/yr is not much for you or me but it is a lot for many people. Oh and
yes, they do lose their names constantly because they fail to pay the rent
on them. When I was at VRSN I would get a rando trying to get me to fix
their lost domain pretty much once a week and I didn't work for that
$0.10 one time charge is much simpler, cheaper and fairer. It gives Alice
the power to choose his own destiny.

@_date: 2020-09-29 11:25:37
@_author: Phillip Hallam-Baker 
@_subject: [Cryptography] Exotic Operations in Primitive Construction 
The reason we get rotate is that it is cheap: It is in essence a
combination of a Left shift and a right shift.
Besides division, they are used for multiplication. Pretty much every
modern FPU has a big barrel shifter in the middle of the data path.
One somewhat strange fact is that pretty much every CPU in use today
supports 80 bit floating point arithmetic but no commonly used programming
language I am aware of makes that accessible to the user except through
specialized libraries.
There is of course no reason that a strong cipher couldn't be created using
FPU operations. But implementation would be very hazardous and likely to
raise numerous incompatibilities between chips.
