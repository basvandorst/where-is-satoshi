
@_date: 2008-09-08 09:59:14
@_author: Darren J Moffat 
@_subject: Quiet in the list... 
I don't know what OS you are running Skype on but for me on MacOS X I never have to enter my Skype password because it is saved in the MacOS X keyring and Skype isn't set to start at system boot (user login really) for my account.

@_date: 2008-09-08 16:16:46
@_author: Darren J Moffat 
@_subject: once more, with feeling. 
Hopefully this is interesting enough to get forwarded on...
Sadly this practice is all too common, and often goes hand in hand with the other "cardinal sin" of https that of mixed http/https pages.
I believe the only way both of these highly dubious deployment practices will be stamped out is when the browsers stop allowing users to see such web pages. So that there becomes a directly attributable financial impact to the sites that deploy in that way.
As much as I like Firefox & Safari [ the only two browsers I use now ] this has to be led by Microsoft with Internet Explorer since that will have the biggest impact, given IE 8 is in beta this seems like a perfect opportunity to get this in as a change for the next version.
Warnings aren't enough in this context [ whey already exists ] the only thing that will work is stopping the page being seen - replacing it with a clearly worded explanation with *no* way to pass through and render the page (okay maybe with a debug build of the browser but not in the shipped product).

@_date: 2008-09-18 10:19:22
@_author: Darren J Moffat 
@_subject: once more, with feeling. 
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
I seriously doubt that even a single digit percentage of end users out on the internet know anything about the different types of certificates used in SSL/TLS and what they mean.   I know none of my family (other than my wife: but given she worked for a large CA doing authentication and verification) knows what SSL really means never mind what the different types of cert are supposed to indicate and what to do about them, yet they buy stuff on the internet.  It doesn't mean they are ignorant it is just the normal case.
Even if you got the UI to do "the right thing" it still doesn't mean anything real about trust all it really means is how much money was invested in getting the cert and setting up the "correct" information about the "company identity" behind it.

@_date: 2009-08-03 09:55:34
@_author: Darren J Moffat 
@_subject: Unattended reboots (was Re: The clouds are not random enough) 
Not only that but many will be multi-node High Availability cluster systems as well or will be horizontally scaled.  This means that there are multiple machines needing access to the same key material.  Or it means putting a crypto protocol terminator "on the front" - the down side of that is loosing end to end security.
This is because availability of the service is actually more important to the business than "real" security.
 > the PINs to the hardware
Or at least a broker for the application.
The way we have traditionally done that in Solaris for IKE is to write the passphrase/PIN in the clear to disk but rely on UNIX permissions to "protect" ie readable only to root or the user account the service runs as.
We recently added this ability for the IKE daemon on Solaris/OpenSolaris for the case when the private keys IKE uses are stored in a PKCS keystore (HSM or TPM).  However we don't expect this to be used in the case where unattended reboots or cluster failover be used.
This is really no different to storing a root/host/service keytab on disk for Kerberos - yet that seems to be accepted practice even in organisations that by policy don't want passphrase/PIN on disk.

@_date: 2009-08-25 16:44:38
@_author: Darren J Moffat 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management, 
Versioning catches a large part of it, but that alone isn't always enough.  Sometimes for on disk formats you need to reserve padding space to add larger or differently formatted things later.
Also support for a new crypto algorithm can actually be done without changes to the software code if it is "truely" pluggable.
An example from Solaris that is how our IPsec implementation works.  If a new algorithm is available via the Solaris crypto framework in many c cases were we don't need any code changes to support it, just have the end system admin run the ipsecalgs(1M) command to update the IPsec protocol number to crypto framework algorithm name mappings (we use PKCS style mechanism names that combine algorithm and mode).  The Solaris IPSec implementation has no crypto algorithm names in the code base at all (we do currently assume CBC mode though but are in the process of adding generic CCM, GCM and GMAC support).
Now having said all that the PF_KEY protocol (RFC 2367) between user and kernel does know about crypto algorithms.
Not just on the wire protocols but persistent on disk formats, on disk is a much bigger deal.  Consider the case when you have terrabytes of data written in the old format and you need to migrate to the new format   - you have to support both at the same time.  So not just versioning but space padding can be helpful.

@_date: 2009-08-27 15:45:55
@_author: Darren J Moffat 
@_subject: AES-GMAC as a hash 
Ignoring performance for now what is the consensus on the suitabilty of using AES-GMAC not as MAC but as a hash ?
Would it be safe ?
The "key" input to AES-GMAC would be something well known to the data and/or software.
The only reason I'm asking is assuming it can be made to perform on some classes of machine better than or close to SHA256 if it would be worth considering as an available alternate now until SHA-3 is choosen.

@_date: 2009-02-12 19:26:40
@_author: Darren J Moffat 
@_subject: Property RIghts in Keys 
I'm can if I squint enough see some cases where the protections of copyright/license and trademark might come into the needs of certs.
1. You don't really want a derivative work - eg the same non crypto elements in a new cert :-)
2. Some of the non crypto elements maybe trademarked names, eg the subject and/or issuer.
3. A CA cert really is only issued as a Trust Anchor and shouldn't really be used for anything else.
However I don't really see a need to attempt to assert this in legal (or more likely attempted legal) terms.  Given they are all implicit in the meaning of what a CA cert is and why it exists.
Darren J Moffat

@_date: 2009-02-23 22:16:25
@_author: Darren J Moffat 
@_subject: SHA-3 Round 1: Buffer Overflows 
As long as you mean use an alternate language for the competition. Realistically there has to be C (or in many cases even asm) implementations of these algorithms if they are actually going to be adopted in real operating systems and real applications.

@_date: 2009-01-19 13:38:02
@_author: Darren J Moffat 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
Can you state the assumptions for why you think that moving to SHA384 would be safe if SHA256 was considered vulnerable in some way please.
SHA256,384,512 are a suite all built on the same basic algorithm construction.  Depending on how SHA256 fell the whole suite could be vulnerable irrespective of the digest length or maybe it won't be.
Until we know how the SHA3 digest is actually constructed the same could even be true of that.
I don't think it depends at all on who you trust but on what algorithms are available in the protocols you need to use to run your business or use the apps important to you for some other reason.   It also very much depends on why the app uses the crypto algorithm in question, and in the case of digest/hash algorithms wither they are key'd (HMAC) or not.

@_date: 2009-07-09 16:56:23
@_author: Darren J Moffat 
@_subject: Weakness in Social Security Numbers Is Found 
I wonder if the UK NI numbers suffer from a similar problem.
The look a little like this:  AB 12 34 56 C
Information on how they are strutured is here:
However given we don't use the NI number in the UK like the SSN is abused in the US there isn't the same security risk in guessing them. Although the Wikipedia article claims they are sometimes used for identification I know I have never been asked for mine other than by an employer or suitably authorised government body how has a real need to know.

@_date: 2009-07-16 09:54:14
@_author: Darren J Moffat 
@_subject: Physical security rather than crypto---but perhaps of interest 
When I first read the article title I assumed it was going to be about Ethernet over Powerlines and how they had weak or non existent crypto.
When I read this and my first thought was: "exactly how is this new research or news ?"  This is exactly the type of threat that TEMPEST protection is intended to provide risk reduction for.
So yeah not new or news to some people but certainly scary for the masses.
Now to bring it back to crypto.... this shows the danger of assuming that local "links" don't need to be encrypted and that cables are "more secure" than wireless links (eg Bluetooth, WiFi etc).

@_date: 2009-07-24 09:42:33
@_author: Darren J Moffat 
@_subject: Fast MAC algorithms? 
The SCA-4000 card from Sun provided the ESP/AH IPsec offload as well as a general purpose crypto acceleration.   The ESP/AH wasn't able to deal with all cases (if I remember correctly some fragmented packet cases) so we still had to "punt" to software IPsec and use the hardware crypto on the same card to do the decrypt/mac.   It turned out that in almost all cases we got better over all throughput of the machine (and ironically lower CPU utilisation as well) using the card as a hardware crypto accelerator rather than an IPsec offloader.   This card didn't do TOE though because Solaris/OpenSolaris doesn't do TOE because we don't need it (and thus have no interfaces for it).   This was 3DES, MD5, SHA1 era So when its successor came along, the SCA-6000 (adding AES), the NIC was

@_date: 2009-05-01 11:29:25
@_author: Darren J Moffat 
@_subject: full-disk subversion standards released 
I wouldn't normally play marketeer but since you asked did you look at this product ?   Either way I'd be interested in your view on it.
Please ignore the "sslaccel" in the URL this card doesn't know anything about SSL it is a pure Crypto accelerator and keystore with a FIPS 140-2 @ Level certification.  Support on Solaris, OpenSolaris, RHEL 5 and SuSE 10.
It has the ability to have centralised key management and shared keystores (within and across machines).
It even has Eliptic Curve support available.
Darren J Moffat

@_date: 2009-05-01 13:48:43
@_author: Darren J Moffat 
@_subject: full-disk subversion standards released 
CA-6000 supports on board key storage and key wrapping.  It even supports the NIST AES Keywrap algorithm.
This card is certainly newer than 5 years old, in fact when we first released it we had some deployment issues because we had created a PCIe only card and several customers wanted to put on in machines that didn't have PCIe capability.
Darren J Moffat

@_date: 2009-05-01 11:35:24
@_author: Darren J Moffat 
@_subject: full-disk subversion standards released 
We recently had some discussion about this inside Sun.  Not just for TLS but for IKE as well.
Until very recently our IKE daemon required the PKCS PIN to be on disk (readable only by root) even if you were using sensitive and non extractable keys in a hardware keystore.   We changed that to provide an admin command to interactively load the key.   However we know that this won't actually be used on the server side in many case, and not in a cluster (the Solaris/OpenSolaris IKE and IPsec is cluster capable).
For Web servers the situation was similar, either the naked private key was on disk or the PKCS PIN that allowed access to it was.
The Sun CA-6000 card I just pointed to in my other email is such a card it uses Broadcom 582x.
Darren J Moffat

@_date: 2009-05-12 09:43:18
@_author: Darren J Moffat 
@_subject: Warning! New cryptographic modes! 
That is basically what I'm doing in adding encryption to ZFS[1].  Each ZFS block in an encrypted dataset is encrypted with a separate IV and has its own AES-CCM MAC both of which are stored in the block pointer (the whole encrypted block is then checksumed with an unkeyed SHA256 which forms a merkle tree).
ZFS already supports gzip compression but only does so on ZFS blocks not on files so it doesn't need to do this trick.  The downside is we don't get as good a compression as when you can look at the whole file.
ZFS has its own replication system in its send/recv commands (which take a ZFS dataset and produce either a full or delta between snapshots object change list).  My plan for this is to be able to send the per block changes as ciphertext so that we don't have to decrypt and re-encrypt the data.  Note this doesn't help rsync though since the stream format is specific to ZFS.
[1] Darren J Moffat

@_date: 2009-05-27 10:01:19
@_author: Darren J Moffat 
@_subject: consulting question.... (DRM) 
I assume the Apple reference here is aimed at iTunes.  You do know that iTunes Music Store no longer uses any DRM right ?

@_date: 2009-11-03 17:34:38
@_author: Darren J Moffat 
@_subject: Truncating SHA2 hashes vs shortening a MAC for ZFS Crypto 
Which is is where I was originally, the IV wasn't stored because there was a way to derive a secure (for CCM/GCM use) IV from other things in the block pointer.
The IV needs to be stored in ZFS because of some future ZFS features where I can't use a derived IV (the first of which will be the project that brings device eviction, this involves "moving" encrypted blocks to a new place and must work without the keys present).
Right.  The reason for using the CCM/GCM AuthTag (MAC) was well as a SHA256 hash of the ciphertext is to provide some protection against an attack where the root of the Merkele tree is modified in such away that the SHA256 hashes all match.
That is my plan longer term, it will come partly from the ZFS crypto project and partly from another OpenSolaris project called Validated Right and verifying the decryption key does happen with enough confidence with the CCM/GCM AuthTag.  We don't want ZFS to return "garbage" if given a wrong decryption key we want it to fail and tell the user (via the normal UNIX errno system for system calls).
Correct, I wasn't suggesting using the MAC for dedup.
I'm going to have both a SHA256 hash of the ciphertext and the CCM/GCM AuthTag and I need to store the IV because of other ZFS features.
The main reason for asking here for advice was on the issue of how big should the CCM/GCM AuthTag be versus the size of the SHA256 hash of the ciphertext, given I have to make a trade off.
Darren J Moffat

@_date: 2009-11-04 15:04:48
@_author: Darren J Moffat 
@_subject: Truncating SHA2 hashes vs shortening a MAC for ZFS Crypto 
That is exactly my concern and why I came here for advice.
I think I'm now convinced that truncating the SHA256 hash would not be a good idea even though we do have an additional MAC.
In a given birth transaction (txg) there may be many blocks being encrypted under the same key, so the txg alone isn't enough.  The combination of txg, objset and block id are unique - but that is 192 bits.
One of the possible future features that would need access to the IV is if we do a version of 'zfs send' (which takes a ZFS filesystem and makes a stream out of it for replication purposes) that transfers the blocks as they are on disk (ie compressed and encrypted).  Currently the 'zfs send' works at the DMU layer of ZFS and doesn't deal in transactions or even disk blocks - it deals in DMU objects and the send stream is all decrypted and decompressed.   To be able to send ciphertext blocks we will need to send the IV to the remote side too.  Which is why we need to store the IV rather than calculate it - the remote side won't be putting that ciphertext on disk in the same txg number.   I don't want to do anything now that would make that difficult to do later.
The SHA-256 is unkeyed so there would be nothing to stop an attacker that can write to the disks but doesn't know the key from modifying the on disk ciphertext and all the SHA-256 hashes up to the top of the Merkle tree to the uberblock.  That would create a valid ZFS pool but the data would have been tampered with.   I don't see that as an acceptable risk.
I can't make the SHA-256 keyed because there are ZFS operations that we must be able to perform with the decryption key is not available: resilvering a mirror/raidz, disk removal (raid relayout), hotspare, scrub (proactive resilver).
By using a MAC we reduce that risk because now the attacker needs to forge the MAC and modify the SHA-256 Merkle tree all the way to the uberblock as well.  Depending on the type of modification the attacker may actually need to forge multiple MAC tags.
A given MAC tag applies to a single ZFS block that is between 512 bytes and 128k.
So if I don't truncate the SHA-256 how big does my MAC need to be given every ZFS block has its own IV ?
Darren J Moffat

@_date: 2009-11-23 12:40:34
@_author: Darren J Moffat 
@_subject: Crypto dongles to secure online transactions 
That reminds me of the Lenslok copy protection device on the Elite (and others) game from the '80s[1]
[1]

@_date: 2009-10-29 13:59:35
@_author: Darren J Moffat 
@_subject: AES-CBC + Elephant diffuser 
^^^^^^^^^^^^^^^
That is the key issue here, it is a disk encryption algorithm independent of the filesystem that sits above it.
If instead you put the encryption directly into the filesystem, rather than below it, then the restrictions of sector size that mean you can't easily use a MAC go away.
This is exactly what we have done for ZFS, we do use a MAC (the one from CCM or GCM modes) as well as a SHA256 hash of the ciphertext (used for resilvering operations in RAID) and they are stored in the block pointers (not the data blocks) forming a Merkle tree.  We also have a place to store an IV.  So every encrypted ZFS block is self contained, has an IV and a 16 byte MAC.   This means that the crypto is all standards based algorithms and modes for ZFS.

@_date: 2009-10-30 17:30:03
@_author: Darren J Moffat 
@_subject: Truncating SHA2 hashes vs shortening a MAC for ZFS Crypto 
============================== START ==============================
For the encryption functionality in the ZFS filesystem we use AES in CCM or GCM mode at the block level to provide confidentiality and authentication.  There is also a SHA256 checksum per block (of the ciphertext) that forms a Merkle tree of all the blocks in the pool. Note that I have to store the full IV in the block.   A block here is a ZFS block which is any power of two from 512 bytes to 128k (the default).
The SHA256 checksums are used even for blocks in the pool that aren't encrypted and are used for detecting and repairing (resilvering) block corruption.  Each filesystem in the pool has its own wrapping key and data encryption keys.
Due to some unchangeable constraints I have only 384 bits of space to fit in all of: IV, MAC (CCM or GCM Auth Tag), and the SHA256 checksum, which best case would need about 480 bits.
Currently I have Option 1 below but I the truncation of SHA256 down to 128 bits makes me question if this is safe.  Remember the SHA256 is of the ciphertext and is used for resilvering.
Option 1
IV		96 bits  (the max CCM allows given the other params)
MAC		128 bits
Checksum	SHA256 truncated to 128 bits
Other options are:
Option 2
IV		96 bits
MAC		128 bits
Checksum	SHA224 truncated to 128 bits
Option 3
IV		96 bits
MAC		128 bits
Checksum	SHA224 or SHA256 truncated to 160 bits
Option 4
IV		96 bits
MAC		32 bits
Checksum	SHA256 at full 256 bits
Option 5
IV		96 bits
MAC		64 bits
Checksum	SHA224 at full 224 bits
Option 6
IV		96 bits
MAC		96 bits
Checksum	SHA224 or SHA256 truncated to 192 bits

@_date: 2009-09-01 10:39:21
@_author: Darren J Moffat 
@_subject: AES-GMAC as a hash 
Thanks, that is pretty much what I suspected would be the answer but you have more detail than I could muster in my head at a first pass on this.

@_date: 2009-09-22 13:57:36
@_author: Darren J Moffat 
@_subject: FileVault on other than home directories on MacOS? 
Note my information may be out of date.  I believe that MacOS native encrypted disk images (and thus FileVault) uses AES in CBC mode without any integrity protection, the Wikipedia article seems to confirm that is   (or at least was) the case There is also a sleep mode issue identified by the NSA:
TrueCrypt on the other hand uses AES in XTS mode so you get confidentiality and integrity.

@_date: 2009-09-25 10:13:33
@_author: Darren J Moffat 
@_subject: FileVault on other than home directories on MacOS? 
For those not familiar this is because Jim and I choose to use CCM/GCM with AES.  ZFS is already using a copy-on-write validated merkle tree. The 16 byte tag/MAC from CCM/GCM is stored in the block pointer above forming a merkle tree.  Each encrypted block in ZFS has its own IV.  ZFS "disk" blocks are variable size from 512 bytes to (currently) 128k.
Which is really what I was trying to say and over stated that XTS provides integrity. When really what it does is as you said, provides a better protection for certain classes of ciphertext modification than just using CBC.
