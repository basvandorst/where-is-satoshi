
@_date: 2001-07-30 12:34:20
@_author: Paul Onions 
@_subject: Effective and ineffective technological measures 
Indeed, my reading of the following extract defining 'encryption research'
in the DMCA seems to indicate that it is easier to prosecute someone for
exposing a vulnarability in a weak system than for a stronger system.
  `(1) DEFINITIONS- For purposes of this subsection--
  `(A) the term `encryption research' means activities necessary to
  identify and analyze flaws and vulnerabilities of encryption
  technologies applied to copyrighted works, if these activities are
  conducted to advance the state of knowledge in the field of encryption
  technology or to assist in the development of encryption products; and
  `(B) the term `encryption technology' means the scrambling and
  descrambling of information using mathematical formulas or algorithms.
The reasoning being that exposing a vulnerability in a weak system will not
'advance the state of knowledge in the field of encryption technology'.
e.g. telling the world that product X uses ROT13 is of no interest to the
cryptographic community. So an individual (not engaged in developing
encryption products) exposing a 'ROT13 product' does not qualify for the
encryption research exemption.
So a technically savvy person stating the technically obvious had better
be careful!
Is this a reasonable interpretation? (I have only read exerts of the act
that have been posted here and there, so am missing much information :-)

@_date: 2003-05-07 12:39:41
@_author: Paul Onions 
@_subject: Randomness 
Interesting article, certainly gets one thinking!  One point though.  Quoting from the top of page 6:-
    Another question is how much state should be shared between the various
    different APIs. If one assumes the PRNG is secure, then this seems to be
    easily resolved: they can all share all the state, except insecureprng(),
    which requires less conditional entropy. Once there is sufficient entropy
    for the other APIs to start working, then even insecureprng() can share
    their state.
Can insecureprng() really share the same state as the secure PRNGs?  Since there is no requirement for unpredictability it would seem that an instance of insecureprng() that leaks the internal state is not disallowed.  So maybe it's possible for an adversarial process to reconstruct the internal state from calls to insecureprng(), and then effectively know the answers that will be given to the queries by other processes to the secure PRNGs (or at least acquire enough information to be able to restrict the search for the secure PRNG seeds).
I guess it all depends on the system as designed and implemented, so maybe some kind of (formal) model is needed to describe such a system (allowing one to derive its security properties from the model).

@_date: 2003-05-09 09:37:15
@_author: Paul Onions 
@_subject: Randomness 
Oh okay.  But a small doubt still remains - is a secure-PRNG still a secure-PRNG when multiple instantiations are run in parallel and (at least partially) sharing the same state information?
Correct me if I'm wrong, but I don't think this question has been addressed in the literature.

@_date: 2003-05-09 15:02:45
@_author: Paul Onions 
@_subject: Randomness 
Let me put it this way.  A design for a pseudo-random bit generator (PRBG) is analysed by assuming that it is seeded from a perfect random source and then showing that its output bit sequence is indistinguishable from a random bit sequence of the same length.
By perfect random source I mean the n-bit vector that is the seed has entropy n bits.
Now assume I have two PRBGs of the same design.  One is seeded with X, the other with Y.  Assume that X, when considered on its own, has entropy H(X) = n, but that Y is related to X such that H(Y|X) < n.  Now, if an adversary has access to the output streams of these two generators, is it able to distinguish them from the random case?  That is, in world 1 the adversary is presented with the two PRBG streams, and in world 2 is presented with random streams.  Is it possible that the adversary can determine the world in which it resides?
If so, then it may be possible to break some schemes that use one of the PRBGs, because the PRBG is being used outside of the model in which its security was analysed.
If all seeds of all PRBGs are independent, then I think we will regain our security guarantees, but without this then I think there may be problems.  I don't know if this is guaranteed by the system you propose because state is shared between generators.
