
@_date: 2001-10-04 08:33:50
@_author: Eric Rescorla 
@_subject: BXA notifier? 
I seem to remember that someone had set up a site to which
you could send your BXA export notification and which would
archive a copy and transmit it to BXA.
Does this sound familiar to anyone?

@_date: 2001-10-07 11:51:36
@_author: Eric Rescorla 
@_subject: ANNOUNCE: Introduction to SSL Programming 20011005 
OpenSSL Example Programs 20011005
by Eric Rescorla
October 5, 2001 Edition
This package consists of a set of documented sample programs showing
how to perform basic programming tasks with OpenSSL. wclient	    -- a simple web client emulator
wserver	    -- a simple web server emulator
wclient2    -- a version of wclient with some extra options
wserver2    -- a version of wserver2 with some extra options
sclient	    -- a simple client program that echos from the keyboard
The documentation is in several files
RUNNING	    -- documents the command line switches for these programs.
part1.pdf   -- a detailed description of what's going on in
These programs and their associated text were originally written for a
series of articles published in Linux Journal. The first article was
published in the September issue and is included here as
part1.pdf. The second article, describing wclient2, wserver2, and
sclient will be published on the web in early October.
This explains why we have both wclient and wclient2 (and wserver and
wserver2). The first editions appear in the first article and the
second ones in the second article. This structure also lets the reader
learn the basics without advanced features getting in the way.
My agreement with LJ requires that they have a one month exclusive on
the articles. Expect to see part2 published as part of this package in
a month or so.
To download, see

@_date: 2001-09-14 21:00:22
@_author: Eric Rescorla 
@_subject: chip-level randomness? 
It's  physical noise generator feeding into some postprocessing.
See:

@_date: 2001-09-16 20:03:53
@_author: Eric Rescorla 
@_subject: How to ban crypto? 
Even leaving aside the issue of critical infrastructure, the situation
is dramatically different than it was in 97-98 in one very important
sense: installed base. Pretty much anyone who downloaded a browser
since the big liberalization in 1998 now has strong crypto, at least
for HTTPS and quite possibly for e-mail as well. Even if we assume
that users are willing to change their browsers--a big if--
transitioning them is a nightmare.
In the best case scenario, the user is running the absolute most
modern version of the browser and so you just need to replace it with
a crippled version that is otherwise the same. This sort of software
changeover doesn't break things that often but with many tens
(hundreds?) of millions of users we're going to see a lot of broken
installations anyway.
Moreover, the best case isn't that common. Many people are running
downrev software and will have to upgrade (downgrade?) to the newest crippled version. This sort of upgrade causes a lot of
breakage. In the worst shape will be users who are using operating
systems for which new browsers are no longer available. For instance,
you don't seem to be able to get IE 5 for Windows 3.1 at all and
I don't seem to be able to get IE 6 for Win95. Do we expect Microsoft
to release new versions of IE 5.5 with GAK? IE 4?
I don't see how a switch like this could be made to work in practice
even if the users wanted it. Since a substantial number won't want
to--or may not even know how--I don't see how it can be done at
[Eric Rescorla                                   ekr at rtfm.com]

@_date: 2002-08-10 10:23:40
@_author: Eric Rescorla 
@_subject: adding noise blob to data before signing 
It's generally a bad idea to sign RSA data directly. The RSA
primitive is actually quite fragile. At the very least you should
PKCS-1 pad the data.

@_date: 2002-02-05 08:11:19
@_author: Eric Rescorla 
@_subject: Cringely Gives KnowNow Some Unbelievable Free Press... (fwd) 
Although the headers and quoting have gotten munged, this
appears to be a reply to my message.
And this is how fast?
It's the only real argument that ECC's got going for it. RSA can
be made arbitrarily fast by making it arbitrarily slow.
If you care about Perfect Forward Secrecy, you shouldn't be using
RSA at all. You should be using DH with a fresh key for each
exchange. The probability that in the next 50 years your key will
be compromised in some other way than factoring is sufficiently
high to motivate this tactic. (In my view, it's vastly higher
than that of your key being broken by factoring).
This message actually makes my point quite nicely.  I frequently see
long detailed arguments by ECC proponents about how wonderful ECC is
and how it should replace RSA. This is one such argument. That's not
what's needed.
For ECC to take off, someone will have to actually write it into
protocols. This requires someone to identify a specific ECC algorithm
that meets the properties that I laid out, and document those
properties with literature citations, performance numbers, securtiy
estimates, etc. That's what's needed before the COMSEC people will
feel comfortable adding ECC to their systems.
Until someone's willing to step up to the plate on that, we're not
going to see ECC deployment in standard protocols.

@_date: 2002-01-10 08:22:49
@_author: Eric Rescorla 
@_subject: ANNOUNCE: Introduction to OpenSSL Programming 20020110 
We are happy to announce the availability of the January 10, 2002
edition of "An Introduction to OpenSSL Programming", containing a pair
of articles describing how to use OpenSSL for common programming
tasks, complete with documented, complete, and compilable example
code. The code is made available under a BSD-style license and so can
be copied and pasted into your programs as necessary.
More information below.....
An Introduction to OpenSSL Programming 20020110
by Eric Rescorla
January 10, 2002 edition
This package consists of a set of documented sample programs showing
how to perform basic programming tasks with OpenSSL. wclient	    -- a simple web client emulator
wserver	    -- a simple web server emulator
wclient2    -- a version of wclient with some extra options
wserver2    -- a version of wserver2 with some extra options
sclient	    -- a simple client program that echos from the keyboard
The documentation is in several files
RUNNING	    -- documents the command line switches for these programs.
part1.pdf   -- a detailed description of what's going on in
part2.pdf   -- a detailed description of wclient2, wserver2, and
These programs and their associated text were originally written for a
series of articles published in Linux Journal. The first article was
published in the September issue and is included here as
part1.pdf. The second article, describing wclient2, wserver2, and
sclient was published on the web in October and is included here as
This explains why we have both wclient and wclient2 (and wserver and
wserver2). The first editions appear in the first article and the
second ones in the second article. This structure also lets the reader
learn the basics without advanced features getting in the way.
To download, see

@_date: 2002-01-12 11:02:12
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
No. It means that your credit card info goes to people who have
been authorized to use the domain name "store.palm.com". The
certificate reflects that. This appears to be a case of Is your claim that Modus Media is NOT authorized to operate
"store.palm.com"?

@_date: 2002-01-14 06:37:15
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
While this is true, I'd point out that all the security software
you're using disclaims any responsibility for not having gaping
security holes.

@_date: 2002-01-14 07:10:21
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
In that case, why should the liability also apply to CAs, despite their

@_date: 2002-01-14 07:24:25
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
Right. My point is this:
Security people often argue that PKI is worthless on the grounds that
the CAs disclaim all liability. This argument leads to the conclusion
that security is essentially worthless since scurity software
almost invariably comes with a disclaimer of all liability.

@_date: 2002-01-14 09:44:16
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
These are inextricably connected. If you want to know that
your communications are private in the face of active attack
you need to know who you're talking to as well.
How exactly does the difficulty of getting certificates help browser
What are you talking about? An nslookup call wouldn't help anything.
The essential problem is establishing that the public key you receive
over the network actually belongs to the person you think it does.
In the absence of a prior arrangement, the only way we know how
to do this is to have that binding vouched for by a third-party.

@_date: 2002-01-14 13:59:21
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
This is confused. What sells certificates is "security". Users
aren't sophisticated enough to understand the difference between
confidentiality and authentication, but they've been told by
the browser manufacturers (rightly) that in order to have security
they need to have certificates.
Saying that SSL without certificates is fine as long as you
don't have active attacks is kind of like saying that leaving
your front door open is fine as long as noone tries to break
This is essentially the PGP model. It doesn't really work acceptably
for large scale e-commerce.
Since when? As far as I know, Microsoft and Netscape just send you
to VeriSign.
It certainly isn't true that you need a "major client browser development
kit" to engage in e-commerce. You can do just fine with ApacheSSL or
mod_ssl. You do generally need a certificate.
Both DNS and whois can be spoofed by an active attacker.

@_date: 2002-01-14 14:19:51
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
The certificates say EXACTLY that. They say that this entity is authorized to use the domain name store.palm.com.

@_date: 2002-01-14 14:47:30
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
So? This would be exactly the case if the certificate were
issued to Palm rather than Modus. VeriSign's procedures ensure
(one hopes) that only someone authorized by Palm could have
gotten this certificate, thus cutting out the middleman
of the extra certificate. Aside from inflexibility, I don't
see any problem with the security guarantees this provides.
No possible security system can protect people who trust
whatever logo happens to be transmitted to them in web pages.

@_date: 2002-01-14 15:44:40
@_author: Eric Rescorla 
@_subject: CFP: PKI research workshop 
I didn't say that it wasn't possible to secure logos. I said that
you couldn't protect people who trusted logos that were transmitted
to them in Web pages. This is not the same thing. The point is
that such logos are transmitted in-band and are part of the web
page. Therefore, they are not cryptographically verified.

@_date: 2002-01-27 14:33:15
@_author: Eric Rescorla 
@_subject: Cringely Gives KnowNow Some Unbelievable Free Press... (fwd) 
[Discussion of patents deleted]
I see this sort of point-by-point discussion of EC patents a lot. I think
it misses the point. If you want to see EC used you need to describe a specific algorithm
which has the following three properties:
(1) widely agreed to be unencumbered, particularly by the big players.
    [extra points if you're willing to indemnify]
(2) significantly better than RSA (this generally means faster)
(3) has seen a significant amount of analysis so that we can have
some reasonable confidence it's secure.
Until someone does that, the cost of information in choosing an
EC algorithm is simply too high to justify replacing RSA in
most applications.
Mr. Beberg's comment about avoiding ECC like the plague matches my
impression of the COMSEC community pretty well. I'm not really part
of the crypto community so I can't speak for that.

@_date: 2002-01-28 17:56:02
@_author: Eric Rescorla 
@_subject: Cringely Gives KnowNow Some Unbelievable Free Press... (fwd) 
I don't know exactly what Pegwit does, but most of these schemes
are still vulnerable to dictionary attacks by trying arbitrary
passphrases and seeing if they generate the correct public key.
It's of course slower since the test operation is slower.
And of course you can do the same sort of thing with RSA by using the
passphrase as the seed for the PRNG. This is quite practical on
modern machines where RSA key generation is extremely fast.
(And practical even on slow machines if you use Schiller's trick
of remembering a "hint").

@_date: 2002-01-29 07:38:14
@_author: Eric Rescorla 
@_subject: Cringely Gives KnowNow Some Unbelievable Free Press... (fwd) 
I agree.
Unfortunately, "dictionary attack" is used differently by different
people. There are two different kinds of attacks here:
(1) A brute-force attack such as is used by Crack where you
successively try a small subset of the passphrase space in
the expectation that it is the space that people are likely
to populate. (This is what RFC 2828 calls a dictionary attack).
(2) A table-driven attack where you have an enormous table (say of passphrases to keys) and just do a lookup in the table.
I was referring to the former, which is quite practical against
such a system. The latter probably consumes too much memory to
be practical.

@_date: 2002-06-24 09:48:37
@_author: Eric Rescorla 
@_subject: X.509, SSL & security of decentalized certification (RE: RSA getting rid of trusted third parties?) 
We could only hope :( It should be in the dNSName but actually,
it's usually stuffed into the Common Name, unless things have changed.
As far as I know, this is completely the case.

@_date: 2002-03-01 16:11:25
@_author: Eric Rescorla 
@_subject: ANNOUNCE: PureTLS 0.9b2 
ANNOUNCE: PureTLS version 0.9b2
Copyright (C) 1999-2002 Claymore Systems, Inc.
PureTLS is a free Java-only implementation of the SSLv3 and TLSv1
(RFC2246) protocols. PureTLS was developed by Eric Rescorla for
Claymore Systems, Inc, but is being distributed for free because we
believe that basic network security is a public good and should be a
commodity. PureTLS is licensed under a Berkeley-style license, which
basically means that you can do anything you want with it, provided
that you give us credit.
This is a beta release of PureTLS. Although it has undergone a fair
amount of testing and is believed to operate correctly, it no doubt contains significant bugs, which this release is intended to shake out. Please
send any bug reports to the author at .
MAJOR CHANGES FROM 0.9b1
        Security fix: protection from injection attacks
We consider PureTLS 0.9b2 to be the best available version of PureTLS.
We strongly recommend that users of older versions upgrade as soon as
WEB SITE

@_date: 2002-11-17 08:46:43
@_author: Eric Rescorla 
@_subject: Security holes... Who cares? 
I thought this paper might be of interest to the cryptography folks.
                      Security holes... Who cares?
                              Eric Rescorla
                      RTFM, Inc.   We report on an observational study of user response following the
OpenSSL remote buffer overflows of July 2002 and the worm that exploited
it in September 2002.  Immediately after the publication of the bug and
its subsequent fix we identified a set of vulnerable servers. In the
weeks that followed we regularly probed each server to determine whether
it had applied one of the relevant fixes. We report two primary
results. First, we find that administrators are generally very slow to
apply the fixes. Two weeks after the bug announcement, more than two
thirds of servers were still vulnerable. Second, we identify several
weak predictors of user response and find that the pattern differs in
the period following the release of the bug and that following the
release of the worm.
The paper can be downloaded from:

@_date: 2002-10-16 17:36:22
@_author: Eric Rescorla 
@_subject: ANNOUNCE: PureTLS version 0.9b3 
Claymore Systems is pleased to announce the availability of
PureTLS version 0.9b3. PureTLS is a free Java-only implementation of the SSLv3 and TLSv1
(RFC2246) protocols. PureTLS was developed by Eric Rescorla for
Claymore Systems, Inc, but is being distributed for free because we
believe that basic network security is a public good and should be a
commodity. PureTLS is licensed under a Berkeley-style license, which
basically means that you can do anything you want with it, provided
that you give us credit.
This is a beta release of PureTLS. Although it has undergone a fair
amount of testing and is believed to operate correctly, it no doubt contains significant bugs, which this release is intended to shake out. Please
send any bug reports to the author at .
MAJOR CHANGES FROM BETA 2
* SECURITY: Improved Bleichenbacher (Million-Message Attack) protection
  (only relevant for servers)
* Improved certificate checking, including:
    	Basic Constraints (CA certificates only)
* Allow clients to continue if client auth is requested but no cert available.
* Fixed RSASignature to avoid a 1/255 chance of generating a bad signature.
* Tightened up a lot of checks for bad protocol data to improve error
  reporting.
* Many bug fixes.
We believe that this is the best version of PureTLS available.  Users
are advised to upgrade as soon as possible. Server users using RSA
should upgrade to get the improved Bleichenbacher protection.
PureTLS can be found at:

@_date: 2002-09-13 13:37:08
@_author: Eric Rescorla 
@_subject: OpenSSL worm in the wild 
Since this workaround requires changing the configuration file, it's equally easy to disable SSLv2 entirely--especially
since one could easily modify the worm to attack all servers
or, perhaps, those which only display Product ID :)

@_date: 2002-09-13 14:08:43
@_author: Eric Rescorla 
@_subject: OpenSSL worm in the wild 
... or maybe not.
I hadn't seen a copy of the worm yet, so I guessed from your
description that it was using the Server: value to detect who is
running downrev versions of OpenSSL. Not so.
Upon examination, it looks like the worm uses the server version to
decide what section of memory to overwrite (based on the target OS)
and server version. So, if people reconfiged their servers to not give
you this information, a worm author would either have to have the worm
try all possible exploits (not a big deal with only 20 architectures
to search) or have some other evidence as to what OS/Apache version
people were runnning.
Note that for this to be a 100% countermeasure you'd have to
reconfigure your server not to advertise Apache at all. Otherwise,
it looks to me like the worm assumes that you're running
Red Hat/Apache 1.3.23, in which case there's a real chance
that the worm will crash your server by using the wrong
overwrite offset.

@_date: 2003-04-28 09:19:37
@_author: Eric Rescorla 
@_subject: DRM technology and policy 
I don't actually believe this. As far as I can tell, the SPP doesn't
adequately address the free rider problem. Sure, I'd be willing to pay
$5 (or whatever) to see a new Motorhead album released, but the
probability that it's my $5 that pushes us over the limit is so low
that it's a dominant strategy to simply wait for everyone else to
pitch in. Of course, everyone can engage in the same reasoning,
and that's the problem.
[Eric Rescorla                                   ekr at rtfm.com]
           Web Log:

@_date: 2003-12-29 12:50:04
@_author: Eric Rescorla 
@_subject: I don't know PAIN... 
It's worth pointing out that this isn't how RSA is used in practice,
for two reasons:
(1) Most everyone uses one of 3 popular RSA public exponents
    (3, 17, 65535) and then computes the private key from p and q.
(2) PKCS-1 RSAPrivateKey structures contain the public key.

@_date: 2003-02-04 13:23:34
@_author: Eric Rescorla 
@_subject: question about rsa encryption 
Yes. Notice that the next sentence was:
        "You should consider padding every block encrypted with RSA
        with randomized salt, if you can; 100 bits or more will make
        any of these attacks fail completely."

@_date: 2003-02-10 06:28:56
@_author: Eric Rescorla 
@_subject: Columbia crypto box 
This isn't 100% true.
There were known (less practical but still better than just theoretical)
attacks on RC4 as used in WEP even before the RC4 weak key work.
WEP was a bad design through and through.

@_date: 2003-02-20 16:50:10
@_author: Eric Rescorla 
@_subject: [Bodo Moeller <bodo@openssl.org>] OpenSSL Security Advisory: Timing-based attacks on SSL/TLS with CBC encryption 
Here's a fairly detailed description of how the attack works.
You can also find a writeup by the authors at:
EXECUTIVE SUMMARY
This is a potentially serious attack for automated systems that rely on
passwords. Effectively, it potentially allows the attacker to recover an
encrypted password. It doesn't appear to be serious for non-automated
Imagine you have some protocol that uses passwords and the password
always falls in the same place in the message stream.  (IMAP, for
instance). What happens is that the attacker observes a connection using
that password. He then deliberately introduces a bogus message into the
encrypted traffic and observes the server's behavior. This allows him to
determine whether a single byte of the plaintext is a certain (chosen)
value. By iterating over the various bytes in the plaintext he can then
determine the entire plaintext.
HOW THE ATTACK WORKS
Basically, the attack exploits CBC padding. Recall that the standard
CBC padding is to pad with the length of the pad.  So, if you have an
8 byte block cipher and the data is 5 bytes long you'd have XX XX XX
XX XX 03 03 03. This technique allows you to remove the pad by
examining the final byte and then removing that many bytes. [0]
Typically you also check that all the pad values are correct.
Say the attacker intercepts a pair of consecutive blocks A and B,
which are:
        A = AA AA AA AA AA AA AA a
        B = BB BB BB BB BB BB BB b
And the plaintext of B corresponds to
        P = PP PP PP PP PP PP PP p
The attacker wants to attack B and guesses that p == y. He transmits
a new message A' || B where
        A' = AA AA AA AA AA AA AA (a XOR y)
When the server decrypts B, the final byte will be (p xor y).
If the attacker has guessed correctly then there will appear
to be a zero length pad and MAC verification proceeds. Since
the packet has been damaged, the MAC check fails. If the
attacker has guessed wrong then the last byte will be nonzero
and the padding check will fail. Many TLS implementations generated different errors for these
two cases. This allows the attacker to discover which type
of error has occurred and thus verify his guess. Unfortunately,
since this generates an error, the attacker can only guess once.
The attack described above was discovered a year or two ago
and implementations were quickly modified to generate the same
error for both cases.
This attack introduces two new features:
(1) The authors observed that if you were moving passwords over
TLS then the password would generally appear in the same place
in each protocol exchange. This lets you iterate the attack over multiple character guesses and eventually over multiple
(2) Even if the same error message generated the MAC check takes
time. You can therefore use timing analysis to determine what
kind of error occurred. This has the downside that there's some
noise but if you take enough samples you can factor that out.
Let's estimate how long this will take. Most passwords are 7-bit ASCII,
so naively we need to try all 128 values for each character. On average
we'll get a hit halfway through our search so we expect have to try
about 64 values for each character position. If we assume an 8 character
password this means we'll need about 8*64==512 trials. Now, you
could be smarter about what characters are probable and reduce these
numbers somewhat but this is the right order of magnitude.
Now, things are complicated a bit by the fact that each trial creates an
error on both client and server. This has two implications. First, it
creates a really obvious signature.  Second, it requires that the client
create a lot of SSL connections for the attacker to work with. This is
only likely if the client is automated.
REQUIRED CONDITIONS
So, under what conditions can this attack be successful?
(1) The protocol must have the same data appearing in a     predictable place in the protocol stream. In practice,
    this limits its usefulness to recovering passwords.
    However, this condition pretty common for things like
    HTTP, IMAP, POP, etc.
(2) The SSL implementations must negotiate a block cipher.  Many SSL
    implementations choose RC4 by default and RC4 is not vulnerable
    to this attack.
(3) The attacker needs to be able to hijack or intercept TCP
    connections. There are tools to do this that require varying
    degrees of sophistication and access to use.
(4) The client must be willing to initiate a lot of connections
    even if it's getting SSL errors. As a consequence it almost
    certainly needs to be an automated client.
(5) The attacker and the server must have a reasonably good network
    connection between them. The noisier the network, the more
    trials you need to distinguish the two outcomes.
OUTCOME OF A SUCCESSFUL ATTACK
A successful attacker will be able to recover the plaintext of
whatever connection he's attacking. In general, this will be most
useful when the data is a password. If he captures the password
the attacker will be able to pose as whatever user owns the
password. The demonstration described by the authors is against IMAP (Outlook as
the client).  In that case they recover the password after about an
hour of observation. Note that the authors had to turn off RC4 to get
an attackable connection.
NOT AFFECTED
This attack doesn't pose a threat for a number of important (and common)
(1) Manual remote login by users, like over SSLtelnet (because
    you won't get enough trials). Note, however, that if you
    use the same password for POP or IMAP and telnet then you
    could recover the password using IMAP and then use it to
    log in remotely.
(2) Credit card transactions from web browsers (not enough trials
    and because most Web SSL traffic uses RC4).
It's also important to recognize that just using OpenSSL doesn't
necessarily make you vulnerable. So, for instance, OpenSSH uses
OpenSSL for its crypto engine but this problem doesn't affect
OpenSSH at all. This is an SSL-specific issue. I would expect
other SSL implementations to be vulnerable to the same attack.
[0] TLS uses a variant of this scheme in which you have a pad length
byte and then pad with the value, so the above block would be
XX XX XX XX XX 02 02 02. But the principle is the same.

@_date: 2003-02-21 09:21:00
@_author: Eric Rescorla 
@_subject: Swiss Researchers Find A Hole In SSL 
It's worth noting that the paper describes a specific client
(Outlook) that in fact does gneerate large numbers of connections.

@_date: 2003-02-21 09:32:53
@_author: Eric Rescorla 
@_subject: [Bodo Moeller <bodo@openssl.org>] OpenSSL Security Advisory: Timing-based attacks on SSL/TLS with CBC encryption 
And of course, both attacks resemble the old password guessing
attack on character by character passwords where you time how
long password verification takes. (The details are pretty
hazy but ISTR that you arranged for the password to cross
a page boundary to increase the time discrimination).

@_date: 2003-01-07 16:10:27
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
No, this isn't true. Say that Americans are willing to pay 50% more
for DVDs than Europeans. It would make sense for producers to attempt
to segment the market.
The interesting thing about market segmentation (as Mr. Denker pointed
out) is that it's often good for everyone, particularly in cases
where marginal costs of production are low. Consider the following simple case:
        A a publisher is deciding to publish some book X. The marginal
        cost of production is zero but it costs $7 to do the initial
        setup (writing, typesetting, etc.)
        There are only two possible customers for this book. One of
        these customers is willing to pay 6 for the book and the other
        3.
        There is no uniform price at which this book can be sold that
        doesn't result in the publisher losing money. If he charges 6,
        he will sell one copy and be out a dollar. If he charges 3 he
        sells two copies but is still out a dollar. Under these
        conditions, the book will not be produced.
        However, if he can price discriminate, he can sell two copies,
        one at 3 and one at 6. This makes it profitable for him to
        produce the book.
Hal Varian has a very readable exposition of this topic
(from which I got this example) at:
I don't speak for Mr. Denker, but the point I think is relevant here
is that there are a fair number of situations in which removal of
some freedom would result in a superior situation for everyone
(Pareto-dominant). I'm not convinced that maximising freedom
is the best approach in all such cases.

@_date: 2003-01-08 08:17:41
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
Well, that's certainly one option. However, there are certainly
other examples, such as senior citizens discounts. I think part of the point here is that legal measures to enforce price
discrimination might well be Pareto-dominant in some cases. When
there is a conflict between liberty and Pareto dominance, economists
get a headache. [1]
[1] Obligatory reference. Amartya Sen "On the impossibility of the Paretial liberal".

@_date: 2003-01-08 08:45:04
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
Maybe. Not necessarily if that meant that no new movies ever got
made. Now, the UK isn't a big enough market for this, but consider
what would happen if the US said "listen, free drugs would be great
for consumers so let's get rid of all drug patents". This would
probably dramatically increase social welfare at the moment, since
there are quite a few people who would buy drugs if they were
cheaper. (It's of course not Pareto dominant). However, it seems
likely that this would have such a negative effect on future
production that it would lower social welfare in the future.

@_date: 2003-01-09 17:35:03
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
[..] Of course. But the point that you seem to be missing is that there are
situations where a monopoly can Pareto-dominate non-monopoly situations.
Of course. Because it's far harder to explain the principle without
perfect information. That doesn't make it wrong, however.
You're implicitly assuming some method of price discrimination (in
this case auctions). Without the ability to get one consumer to pay
more than another, we're back to the situation that we had before,
namely that it's unprofitable to produce the commodity. Most consumer
goods are not sold at auction and thus more subtle forms of price
discrimination are required.
Incidentally, it's not clear that an auction will produce the effect
you suggest. It's not necessarily your best strategy to bid up to
your true value on the first of a series of identical items.

@_date: 2003-01-10 07:35:28
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
Regulation is a qualitatively different kind of barrier from
patents. I agree that it's rather more difficult to argue that
FDA-style regulation has increased welfare. That's an empirical question that hasn't been determined.
However, it's certainly the case that case that expensive drugs are
better (Pareto dominant) than no drugs at all, which I claim is gthe
outcome of removing patents.
Sure, but that doesn't make the economics much different.

@_date: 2003-01-10 07:46:15
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
But that's wrong, because the monopoly allows market segmentation,
which allows new products to be introduced that otherwise would
not be.
Maybe you live in some alternate universe where companies don't
to practice price discrimination, but here on planet Earth,
companies routinely offer products at widely variable prices
to different consumers.
I'm not sure what you mean is irrational.
(1) It's not irrational to pay a different price from other people.
    On the contrary, if the price isn't available to you for some
    reason, it's absolutely rational.
(2) As stated many times, it IS rational to force people to pay
    different prices. I advise you to go back and read Varian's
    papers. Moreover, it's done all the time with things like
    educational discounts, senior citizens discounts, etc.
Of course, but the producer uses things like past experience and
marketing studies to decide what they expect. There may be errors,
but that doesn't invalidate the basic analysis, which is that if
the producer doesn't EXPECT to make a profit they won't produce
a product.

@_date: 2003-01-10 10:33:24
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
I was thinking in particular of Sen's "Impossibility of
the Paretian liberal". That's not the context in which I mean liberty. Rather, I'm
talking about global restrictions. Consider the following
situation as described by Steven Landsburg
        Here's a stylized example: Suppose some people (call
        them the "prudes") cherish their freedom of religion, but not
        half so much as they would cherish a general ban on
        pornography. Others (call them the "lewds") cherish their
        right to read Lady Chatterley's Lover but not half so much as
        they would cherish a general ban on religion. Then if you
        outlawed both pornography and religion, you'd make everyone
        happier, while simultaneously making everyone less free.

@_date: 2003-01-10 10:52:40
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
Clear, cogent, and wrong.
No. Each individual DVD is a new product as far as this model goes.
Actually, it works just fine. Varian gave a number of examples in
his paper and I gave several (that you elided) in my response to you.
I'm afraid that's not the case. Restaurants, for instance, quite
frequently offer senior citizens discounts. They are widely
advertised. They also offer early bird specials, also widely
advertised. Bars offer lady's nights. Manufacturers offer "versioned"
products. All of these are classic examples of market segmentation and
they're not secret. Quite the contrary.

@_date: 2003-01-10 12:03:50
@_author: Eric Rescorla 
@_subject: DeCSS, crypto, law, and economics 
This did in fact cause headaches when Amartya Sen made this point.
The original paper is considered a classic of the economics
literature. It's in, for instance, Moser's "Rationality in
Action".

@_date: 2003-07-07 16:04:42
@_author: Eric Rescorla 
@_subject: LibTomNet [v0.01] 
[Standard rant follows... :)]
I'm trying to figure out why this is a good idea even in principle.
I've seen <100k SSL implementations and that included the ASN.1
processing for certs. I would imagine that one could do a compliant
SSL implementation that used fixed RSA keys in roughly the same
code size as your stuff.

@_date: 2003-07-07 16:28:16
@_author: Eric Rescorla 
@_subject: LibTomNet [v0.01] 
Funny, none of the 30 or so other people who have done SSL
implementations had any problem.
I'd be interested to know in what way you believe the TLS RFC is
not sufficient to write a complaint implementation. Except for
some edge cases, it's fully specified as far as I know. Anyway,
I'm the document editor so it's my job to fix it.
This isn't an invitation to complain more about the writing
quality (for which I'm not responsible in any case). But if you
think that there's actually something that's unspecified, I
want to know about that.
As for the complexity of TLS, that's what happens when you design
a general protocol. I can pretty much guarantee you that every
part of TLS has been used by someone at one time or anotehr.
And we got SSLv2 and v3 in <100 kb without trying particularly
hard, using BSAFE, which is enormous. This isn't much of an argument,
This striked me as quite confused. What makes developer's lives
simple is simple APIs, not simple implementations.

@_date: 2003-07-07 16:53:22
@_author: Eric Rescorla 
@_subject: LibTomNet [v0.01] 
In other words, this is just an exercise in Not Invented Here. Wonderful.
If the past 20 years of security work have taught us anything, it's
the value of standardized tools that get a lot of review so that
we can be confident that they're not totally hosed. When people go
off and invent their own stuff without good reason, that's not
good security practice. That's fine if they're just screwing around,
but when they come up with all sorts of bogus reasons why people
might want to use their homegrown stuff instead of the standard
stuff, that's not so fine.
Moreover, your original message said that you intended to use
SSL, but as you yourself admit, you don't understand it and yet
you feel comfortable holding forth about it's merits compared
to your brand new protocol. Huh?
P.S. You claimed earlier that you didn't think RFC 2246 was clear
enough to write a complaint implementation. I was sincere in asking
what you find underspecified. It's my job to make it as complete
as possible.

@_date: 2003-07-07 17:36:28
@_author: Eric Rescorla 
@_subject: LibTomNet [v0.01] 
No, you don't need my permission. You can do any fool thing you
want. It would just be nice if you were spending effort filling some
actual need, rather than reinventing the wheel.
Netscape. However, the situation was different then. There
was actually a market niche that SSL didn't fill. It has yet
to be established that LibTomCrypt is in that position.
You don't seem to understand the issue. It has nothing to do with
how competent you are and everything to do with the fact that
people make mistakes and so homebrew stuff is bad when you can
avoid it. Everyone I know who has worked in this field has made
a bunch of mistakes and depends on others to catch them. And I claim that SSL implementations can be gotten down to very nearly
that size, especially if you're willing to compromise a lot of the
features, so what virtue is your library providing?
No, it just means that it's never going to get the kind of security
analysis that SSL has, which means that there are probably a bunch
of undiscovered holes.
It turns out that doing a principled job is a lot more complicated
than doing key exchange. That's one of the things that one discovers
when actually writing a full protocol rather than just whipping something
Seeing as I didn't write SSL, I'm just the document editor, that
just makes you look silly.
Your protocol does not use appear to have any protection against
active attacks on message sequence, including message deletion,
replay, etc.  True, the attacker can't inject *predictable* plaintext,
but he can inject garbage plaintext and have it accepted as real.
Your protocol is susceptible to truncation attack via TCP FIN forging.
Your server doesn't generate any random values as part of the handshake,
thus, leaving you open to full-session replay attack.

@_date: 2003-07-07 17:57:24
@_author: Eric Rescorla 
@_subject: LibTomNet [v0.01] 
Uh, this is exactly what I said. If you delete messages or replay
them, they will pass through the HMAC and be decrypted (thus giving you unpredictable garbage) and passed to the
application layer.
Yes, but if I forge a TCP FIN in between blocks, you can
generate a fake connection close. This is a problem if the
protocol layered over top uses connection close to indicate
end of data as (say) HTTP does. That's why SSLv3 and above
include a close_notify message in the alerts.
This doesn't always help, unfortunately.
Consider the case where you're using a replayable authentication
scheme such as passwords over your encrypted session. This is
perfectly natural and people do it with SSL all the time.  So, the
attacker captures you doing some transaction replays it to the
server. Congratulations, you've now done it twice.
The standard procedure to prevent this (used in SSL, IKE, etc.) is for
the server to send the client a nonce in his hello message, thus
preventing client-side replay.

@_date: 2003-07-08 11:53:13
@_author: Eric Rescorla 
@_subject: LibTomNet [v0.01] 
I'm not sure why you think that these two views are
inconsistent. Sure, SSL embodies lots of mistakes, and I'm hard on
some of those in my book. However, my experience is that when people
sit down and try to do a better job, they generally bungle it.  Tom's
attempt is only the latest example.
This is just wrong. There are extensions to SSL to support Kerberos,
SRP, and even primitive shared keys (see Peter Gutmann's latest draft
on this topic).
It's not just SSL. I've beaten up on people who were trying to
reinvent S/MIME in this very forum. It's just that people seem to try
to reinvent SSL about 5 times more often than they try to reinvent
anything else. My guess is that that's because the channel security
problem *looks* so simple and so it seems like it should be easy to do
something simpler and better than SSL.
Incidentally, I suspect that this is what was going through Hickman's
head when he designed SSLv2, which is no doubt why it's such a botch.
Are you on crack? SSL HAS won in the market place.  It's only the
amateurs who persist on trying to reinvent it.
You know, Ian, this argument would be a lot more convincing
if the people who tried to reinvent SSL didn't always
botch the job. I've yet to see one of these things that didn't
have glaring flaws that wouldn't have been made by someone
who had taken the time to really understand SSL. No doubt
that's because once you've spent some time thinking about
the problem you get driven to roughly the same set of
design decisions SSL embodies. This isn't because the
SSL authors were such geniuses, but rather because there's
basically one best way to do things.

@_date: 2003-07-08 12:19:54
@_author: Eric Rescorla 
@_subject: LibTomNet [v0.01] 
As I said before, the problem here isn't SSL. Rather, it's the way
that OpenSSL does things.  Now, it would be a real contribution for
you to write a simple wrapper for OpenSSL. I've seen people do stuff
like that, but it's generally too custom for general use.

@_date: 2003-07-08 17:31:45
@_author: Eric Rescorla 
@_subject: LibTomNet [v0.01] 
That's certainly not true. He had a message integrity
construct. It just didn't include anti-replay measures.
Actually, I think this attitude is generally unproductive.
All else being equal, a protocol which provides more security
is better than a protocol which provides less. Now, all things
aren't equal, but if you can offer substantially more security
with only a modest increase in code complexity, that's generally
a good thing. Where hard tradeoffs have to be made is when
the users are inconvenienced. A little additional programming
doesn't seem like a high cost at all.
I don't find this sort of "sure, it's nowhere near as secure as
secure as SSL, but it takes up a little less space" argument
very compelling at all.

@_date: 2003-07-09 10:46:36
@_author: Eric Rescorla 
@_subject: replay & integrity 
Tom, I'm sorry you're taking this personally, since it's not really
about you. I take Ian to be making a generic argument
that there's not a need for these features in a channel
security protocol. I've certainly hear this argument
before and I think it's worth discussing--even though
I think he's wrong.

@_date: 2003-07-10 11:36:31
@_author: Eric Rescorla 
@_subject: SSL 
Thanks for the kind words.
Actually, the price should be $40 US. That's the price at Amazon.
No payoffs, but I'd love to know what you've discovered :)

@_date: 2003-06-01 15:08:56
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
Hmm.... I'd characterize the situation a little differently.
There are a number of standard building blocks (3DES, AES, RSA, HMAC,
SSL, S/MIME, etc.). While none of these building blocks are known
to be secure, we know that:
(1) They have withstood a lot of concerted attempts to attack them.
(2) Prior attempts at building such systems revealed a lot of problems
    which these building blocks are designed to avoid.
(3) People who attempt to design new systems generally make some
    of the mistakes from (2) and so generally design a system inferior
    to the standard ones.
We're slowly proving the correctness of these building blocks and
replacing the weaker ones with others that rely upon tighter
proofs (e.g. OAEP for PKCS-1) but it's a long process. However, I don't
think it's helpful to design a new system that doesn't have any obvious advantages over one of the standard systems.

@_date: 2003-06-01 16:33:10
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
It's vastly better than "just designed last week by someone
who has no relevant experience"

@_date: 2003-06-02 12:14:07
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
I don't think this is likely to be true. In my experience,
people who learn enough to design their own thing also learn
enough to be able to do SSL properly.
That's not true as far as I know. V1 and V2 were designed
by the same guy (Kipp Hickman). V1 is actually very similar
to V2, except that the integrity stuff is all screwed up.
As far as I can tell, the fact of the matter is that Kipp didn't understand the security issues until Abadi and
to some extent Schiffman sold them some clues.
As far as I know, that's not the case. The original Netscape
team was very small and there really weren't any significant
choices to be made.
That's not my experience. WEP and PPTP come to mind.
I would say the highest level primitives you can get away with.
SSL is quite fine for chat, actually. It's one of the major things that people use for IM. The issue with
speech and media isn't connection-orientation but
rather datagram versus stream data.
The history of people who go this course suggests otherwise.
They generally get lousy solutions.

@_date: 2003-06-03 08:41:31
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
One learns by *practicing*.
That said, though, there's next to no need for people to know how
to design their own communications security protocols, so it's
not really that important for them to learn. The rough version of it is in my book.

@_date: 2003-06-04 09:06:08
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
Because HTTPS is designed to let you talk to people you've
never talked before, which is an inherently harder problem
than allowing you to talk to people you have.

@_date: 2003-06-04 16:42:32
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
Nonsense. One can simply cache the certificate, exactly as
one does with SSH. In fact, Mozilla at least does exactly
this if you tell it to. The reason that this is uncommon
is because the environments where HTTPS is used
are generally spontaneous and therefore certificate caching
is less useful.

@_date: 2003-06-04 20:37:49
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
The only solutions to that problem involve getting rid of
passwords and credit card numbers. SSL does that job about
as well as we know how.

@_date: 2003-06-05 17:57:18
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
This isn't really true in the SSL case:
To a first order, everyone ignores any extensions (except sometimes
the constraints) and uses the CN for the DNS name of the server.

@_date: 2003-06-06 14:16:34
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
I've had to do this on environments where threads weren't a viable
option. See, for instance, my paper from USENIX Security 2002.

@_date: 2003-06-06 14:49:37
@_author: Eric Rescorla 
@_subject: Maybe It's Snake Oil All the Way Down 
Unfortunately, 2817 is totally broken. What you want is the
TLS extensions draft, which is on its way to RFC even as we speak.

@_date: 2003-06-11 09:51:12
@_author: Eric Rescorla 
@_subject: An attack on paypal 
This is being fixed. See draft-ietf-tls-extensions-06.txt

@_date: 2003-03-16 08:40:06
@_author: Eric Rescorla 
@_subject: How effective is open source crypto? 
You still need a round trip in order to prevent replay attacks. The
fastest that things can be while still preserving the security
properties of TLS is:
ClientHello       -> ClientKeyExchange ->
Finished          ->
                  <-  ServerHello
                  <-  Finished
Data              ->
See Boneh and Schacham's "Fast-Track SSL" paper in Proc.ISOC NDSS 2002
for a description of a scheme where the client caches the server's
parameters for future use, which is essentially isomorphic
to having the keys in the DNS as far as the SSL portion goes.
In any case, the optimization you describe provides almost no
performance improvement for the server because the load on the server
derives almost entirely from the cryptography, not from transmitting
the ServerHello [0]. What it does is provide reduced latency,
but this is only of interest to the client, not the server,
and really only matters on very constrained links.
[0] With the exception of the ephemeral modes, but they're simply
impossible in the scheme you describe.

@_date: 2003-03-16 09:30:55
@_author: Eric Rescorla 
@_subject: How effective is open source crypto? 
This wasn't clear from your message.
TCP setup is 3 packets. The teardown doesn't have any effect whatsoever
on the performance of the system (and often isn't done anyway).
It's a very modest load on the network and one which is far
outstripped by the traffic sent by SSL and HTTP.
It's considered bad form to design systems which have known replay
attacks when it's just as easy to design systems which don't.
If there were some overriding reason why it was impractical
to mount a defense, then it might be worth living with a replay
attack. However, since it would have only a very minimal effect
on offered load to the network and--in most cases--only a marginal
effect on latency, it's not worth doing.

@_date: 2003-03-16 10:41:42
@_author: Eric Rescorla 
@_subject: How effective is open source crypto? (bad form) 
You've already missed the point. SSL/TLS is a generic security
protocol. As such, the idea is to push all the security into the
protocol layer where possible. Since, as I noted, the performance
improvement achieved by not doing so is minimal, it's better to just
have replay protection here.

@_date: 2003-03-31 13:41:31
@_author: Eric Rescorla 
@_subject: Russia Intercepts US Military Communications? 
Credit where it's due. Netscape was responsible for this.

@_date: 2003-05-03 13:21:14
@_author: Eric Rescorla 
@_subject: The Pure Crypto Project's Hash Function 
Can you explain every single line of the modular exponentiation
routine you're using? Every single line of the compiler you're
using to compile the code?
Why? The amount of math you would need to demonstrate the security
or insecurity of your hash algorithm is incredibly prohibitive,
and vastly larger than the amount of effort required to analyze the
C code in SHA-1.

@_date: 2003-05-04 07:01:54
@_author: Eric Rescorla 
@_subject: The Pure Crypto Project's Hash Function 
This would be funny if it weren't sad. There's all this
code in the Python interpreter that is doing your modular
exponentiation for you that you haven't audited at all.
You might as well argue that using SSL is simple since all
you have to do in some APIs is do: open("
Nor do you have any reason to assume that OpenSSL's SHA-1 code
has been botched but you seem quite ready to assume that.
I have. I'm not convinced.
Strangely enough, people have spent the past 20 years or so trying to decide if things like DH and DSA were secure and
we still find new stuff, despite primes "making things simple"
in those cases.

@_date: 2003-05-04 08:16:59
@_author: Eric Rescorla 
@_subject: ANNOUNCE: PureTLS 0.9b4 
ANNOUNCE: PureTLS version 0.9b4
Copyright (C) 1999-2002 Claymore Systems, Inc.
PureTLS is a free Java-only implementation of the SSLv3 and TLSv1
(RFC2246) protocols. PureTLS was developed by Eric Rescorla for
Claymore Systems, Inc, but is being distributed for free because we
believe that basic network security is a public good and should be a
commodity. PureTLS is licensed under a Berkeley-style license, which
basically means that you can do anything you want with it, provided
that you give us credit.
This is a beta release of PureTLS. Although it has undergone a fair
amount of testing and is believed to operate correctly, it no doubt contains significant bugs, which this release is intended to shake out. Please
send any bug reports to the author at .
0.9b4 is a bugfix release which includes protection against timing
attacks on RSA (Boneh-Brumley/Kocher) and CBC padding (Vaudenay).
Server users and clients who do client authentication should upgrade.
Client-only users may not need to.
WEB SITE

@_date: 2003-05-05 16:58:57
@_author: Eric Rescorla 
@_subject: The Pure Crypto Project's Hash Function 
Sure, but this isn't practical for building all but the simplest
applications. In my view, the downsides of having things be
inconvenient in order to make them amenable to this kind of proof far
outweigh the downsides of having usable systems which you cna't prove
to be correct.

@_date: 2003-05-13 08:03:19
@_author: Eric Rescorla 
@_subject: ANNOUNCE: PureTLS 0.9b4 
That protection has been there since PureTLS 0.9b3.

@_date: 2003-05-30 08:54:52
@_author: Eric Rescorla 
@_subject: Nullsoft's WASTE communication system 
It's utterly baffling to me why people like this choose to design
their own thing rather than just using SSL. I've looked through their
design documents and glanced at their code they don't provide any
security features that SSL doesn't, and they appear to have made a
number of questionable design decisions:
(0) Their messages don't appear have any sequence numbers, making them
    potentially open to a wide variety of integrity attacks. They have some sort
    of guid but unless you intend to keep a record of all guids through
    a session (horrible) this is only a partial fix for replay and     not a fix at all for removal.
(1) They use MD5 instead of HMAC for message authentication. Scary.
(2) They use the same encryption keys in both directions. At least
    they have the sense to run separate PCBC counters. However,
    based on the code it doesn't look like they reset the PCBC
    counters after a bad message is received so you may be able to
    mount a reflection attack.
(3) They use Blowfish (why not AES?) in PCBC mode (huh?)
I don't think it's worth much time analyzing this... Just one
more case of NIH.

@_date: 2003-05-30 17:05:13
@_author: Eric Rescorla 
@_subject: Nullsoft's WASTE communication system 
There are three possibilities here:
E(M) || H(E(M)) -> This is radically insecure.
E(M) || H(M)    -> This is still quite dangerous.  If the attacker                    can somehow reset the IV, then they can mount
                   an attack on the first cipher block.
E(M || H(M))    -> This is hard to attack with block ciphers, but
                   easy with stream ciphers.
It looks to me like it's the third case, but I'm not totally sure.
In any case, a keyed hash would be much safer.
I don't understand what you mean here. They're already doing
key exchange for Blowfish. There's no reason you couldn't hash
the keys to generate MAC keys, as SSL does.
Actually, it looks like this is impossible since they claim that
they destroy the connection after a bad message. My bad.
Still, I'd prefer to see different keys for each direction.
I'm not sure how PCBC would be any better than CBC for this
application. FWIW, the source code appears to actually use CBC,
the doc notwithstanding. This isn't exactly confidence inspiring.
I just looked in citeseer and it seems to me that AES has gotten much
more attention. It certainly will be getting much more in the future.
I consider AES best current practice and so do most of the
professional protocol designers I know. If one has some reason not to
use AES, then 3DES is the appropriate choice. I can't see any reason
to choose Blowfish.

@_date: 2003-10-01 08:53:39
@_author: Eric Rescorla 
@_subject: Monoculture 
I hear this a lot, but I think that Perry nailed it earlier. SSL, for
instance, is about as simple as we know how to make a protocol that
does what it does. The two things that are generally cited as being
sources of complexity are:
(1) Negotiation.
(2) Certificates.
Negotiation doesn't really add that much protocol complexity,
and certificates are kind of the price of admission if you want
third party authentication.
But here's you're talking about something different, which is
OpenSSL. Most of the OpenSSL complexity isn't actually in The way I see it, there are basically four options:
(1) Use OpenSSL (or whatever) as-is.
(2) Strip down your toolkit but keep using SSL.
(3) Write your own toolkit that implements a stripped down subset
    of SSL (e.g. self-signed certs or anonymous DH).
(4) Design your own protocol and then implement it.
Since SSL without certificates is about as simple as a stream
security protocol can be, I don't see that (4) holds much of
an advantage over (3)

@_date: 2003-10-01 15:29:40
@_author: Eric Rescorla 
@_subject: how simple is SSL? (Re: Monoculture) 
Right, but that's a DESIGN cost that we've already paid. It doesn't add significant implementation cost. As in check
out any SSL implementation.
I said WITHOUT certificates.
Take your SSL implementation and code it up to use anonymous
DH only. There's not a lot of complexity to remove at that point.

@_date: 2003-10-01 15:33:33
@_author: Eric Rescorla 
@_subject: Monoculture 
I disagree. If someone doesn't understand enough about SSL
to understna where to simplify, they shouldn't even consider
designing a new protocol.
I'm not buying this, especially in the dimension of code
size. I don't see any evidence that the people complaining
about how big SSL are basing their opinion on anything
more than the size of OpenSSL. I've seen SSL implementations
in well under 100k.

@_date: 2003-10-01 16:27:20
@_author: Eric Rescorla 
@_subject: anonymous DH & MITM 
It doesn't protect against MITM. You could, however, use a static DH key and then client could
cache it as with SSH.

@_date: 2003-10-03 10:20:51
@_author: Eric Rescorla 
@_subject: Simple SSL/TLS - Some Questions 
I wouldn't use quite that terminology. Noone talks about SSL version
3.1, but rather TLS 1.0. However, if we're just speaking about what's
in the version numbers in the wire protocol you're right.
No, but it's like this: There's no way to advertise that you speak "only TLS 1.0".
So, if, for instance, a client says "I speak TLS 1.0" then
the server is well within its rights to say "thanks, let's to
SSL 3.0". The only thing the client can do is break the connection.
This isn't a disaster since the alternative would be for the
server to break the connection when it discovered that the client
only spoke TLS and it only spoke SSL, but it's a bit inefficient.
Not at all. If you want to do this you will have to use the ADH
mode. The alternative is to write a new ciphersuite specification.
This has been an enormously contentious issue. I advise you to tune
into the IPsec mailing list of about 6 months ago for all the
arguments for and against suites. There's no point in reprising
them here. That's just the way TLS is.
You need to submit it to the TLS WG for approval. That said, I'm trying to figure out why you care about this. The defined algorithms are good enough for almost all purposes.
0xff* is all private.
See A.5 of RFC 2246. You have read the RFC, right?
There is an Extensions RFC. Can't remember the RFC number offhand.
There's a similar answer. Currently there is a draft on TLS compression.
TLS is basically agnostic on certificate validation and construction.
It references PKIX but in practice you can do whatever you want.
I'm a little puzzled by some of these questions:
(1) Don't you want to be able to communicate with standard TLS
    implementations? If so, the kind of stuff you seem to want
    to do will in often break that.
(2) I thought your goal was simplicity. All these options for exotic
    mechanisms will make things less simple.

@_date: 2003-10-03 10:49:50
@_author: Eric Rescorla 
@_subject: DH with shared secret 
The problem with this protocol is that a single MITM allows a dictionary attack. There are better ways to do this.
Keywords: EKE, SRP, SPEKE

@_date: 2003-10-06 07:54:03
@_author: Eric Rescorla 
@_subject: Simple SSL/TLS - Some Questions 
You'll definitely have to. I think that "SSL and TLS" is pretty
thorough as a protocol book goes, but it's not designed to
let you implement the protocol without reading the RFC.
Uh, this is all sounding very non-simple. Since algorithm negotiation
is one of the things that people generally cite as making TLS too
complicated (not that I agree) I can't see why you'd want to make
it more complicated in this way. Moreover, I would think that
part of making something "for the masses" would be making appropriate
design decisions so that people can't shoot themselves in the
foot. If people are competent to make those decisions then they
should have no trouble figuring out how to use OpenSSL.
GnuTLS already exists.
This is a PKIX issue. Check out RFC 3280. Anyway, the answer
is "no". A certificate has one signature. The X.509 way to have this
is to have multiple certificates issued for a given DN/key pair.

@_date: 2003-10-06 09:02:35
@_author: Eric Rescorla 
@_subject: Simple SSL/TLS - Some Questions 
The way that TLS works is that you can identify record size
by the record header (first 5 octets). Only when you have
a complete record in hand can you start to parse.

@_date: 2003-10-07 12:09:16
@_author: Eric Rescorla 
@_subject: Simple SSL/TLS - Some Questions 
This doesn't provide equivalent services to TLS--no anti-replay
service for the server.
With the result that it is now screened out by your current
firewall policies. Good idea.
This also isn't TLS. It's a protocol that bears some vague resemblence
to TLS.

@_date: 2003-10-07 12:27:45
@_author: Eric Rescorla 
@_subject: Simple SSL/TLS - Some Questions 
But calling it "KISS TLS" is very inaccurate, since it
doesn't provide equivalent security guarantees. What you're
proposing doesn't really have any connection to TLS.
Extensive performance analysis shows that the performance cost
in TLS is cryptography, not message passing. Your suggestion
doesn't improve that much at all.

@_date: 2003-10-13 09:37:39
@_author: Eric Rescorla 
@_subject: WYTM? 
Ian, you and I have discussed this before, so I'll
just make a few comments.
As you know, I think it's more in the middle. As I've
mentioned before, password sniffing was a real problem
before SSH. I totally agree that the systems are
insecure (obligatory pitch for my "Internet is Too
Secure Already") which makes some of the same points you're making,
though not all.
I think it was chosen for two reasons:
(1) It actually was once a viable threat model, especially
    for military and financial communications, where the
    end systems were secure.
(2) It's a problem we know how to solve.
I don't think that solving the problems one knows how
to solve is always a bad thing, as long as they're
real problems. What's not clear is how real they are.
This isn't strictly true. IPsec and S/MIME use the
same threat model, for instance. And even SSH mostly
adopts it, since there's actualy a fair amount of
concern about active attack after the first leap
of faith. One could, after all, just use encryption
with no message integrity at all.
Actually, I was there, though I was an outsider to the
process. Netscape was doing the design and not taking much
input. However, they did send copies to a few people and one
of them was my colleague Allan Schiffman, so I saw it.
It's really a mistake to think of SSL as being designed
with an explicit threat model. That just wasn't how the
designers at Netscape thought, as far as I can tell.
Incidentally, Ian, I'd like to propose a counterargument
to your argument. It's true that most web traffic could be encrypted if we had a more opportunistic key
exchange system. But if there isn't any substantial
sniffing (i.e. the wire is secure) then who cares?

@_date: 2003-10-13 16:12:10
@_author: Eric Rescorla 
@_subject: WYTM? 
Maybe so, but it coincides relatively well with the
common Internet threat model, so I think you can't
just dismiss that out of hand as if it were pulled
out of the air.
You keep talking about the server locking you in, but it doesn't.
The world is full of people who run SSL servers with self-signed
And on the client side the user can, of course, click "ok" to the "do
you want to accept this cert" dialog. Really, Ian, I don't understand
what it is you want to do. Is all you're asking for to have that
dialog worded differently? It's not THAT different from what
SSH pops up.

@_date: 2003-10-13 17:57:12
@_author: Eric Rescorla 
@_subject: WYTM? 
Disagree. Once again, SSL meets the consensus threat
model. It was designed that way partly unconsciously,
partly due to inertia, and partly due to bullying by
people who did have the consensus threat model in mind.
That's not the design process I would have liked,
but it's silly to say that a protocol that matches
the threat model is somehow automatically the wrong
thing just because the designers weren't as conscious
as one would have liked.
I would hardly characterize "Failure to do something Ian wants done
automatically" as "lock-in". It's not like it takes a genius to type
"make cert".
You'd get a lot less argument from me if you'd tone down the hyperbole
a bit.
Because it's giving you a chance to accept the certificate,
and letting you know in case you expected a real cert that
you're not getting one.
SSH in terminal mode says:
"The authenticity of host 'hacker.stanford.edu (171.64.78.90)' can't be established.
RSA key fingerprint is d3:a8:90:6a:e8:ef:fa:43:18:47:4c:02:ab:06:04:7f.
Are you sure you want to continue connecting (yes/no)? "
I actually find the Firebird popup vastly more understandable
and helpful.

@_date: 2003-10-13 21:43:03
@_author: Eric Rescorla 
@_subject: WYTM? 
Most comsec people I know subscribe to it. I don't
have a study to show it.
I don't know what this means. If you'd asked a bunch of
comsec people what the appropriate threat model for SSL
was, they would have given you something very much like SSL.
What, you've never heard of Google?
Mozilla is effectively slimmed down Mozilla. The Mozilla dialog is
somewhat more aggressive.

@_date: 2003-09-03 07:22:25
@_author: Eric Rescorla 
@_subject: Is cryptography where security took the wrong branch? 
This really depends on your definition of market.
SSL was designed to protect credit card transactions, period.
For that, the market penetration is near 100%.
That $50 limit is a funny thing.
I look at it this way:
You don't PERSONALLY eat the cost of fraud on your own
card but you eat the cost of fraud on other people's cards.
Thus, as in many situations, it's in your interest for
everyone else to practice good hygiene.
In this particular case, the issuers were *very* wary
of providing credit card transactions over the Internet
without some sort of encryption. So, SSL is what enables
you to do e-commerce on the net. That seems like a large
subjective good.
Vis a vis SHTTP, I'm not sure if that was the right design
or SSL was. However, they had relatively similar threat models.
I agree. After all, I occasionally come upon a network I'd
like to use and WEP stops me cause I'm too lazy. On the other
hand, MAC restrictions would have done just as well for that.

@_date: 2003-09-06 11:30:35
@_author: Eric Rescorla 
@_subject: SSL's threat model 
Yeah.  You can kind of infer it from the security analysis at
the end, but I agree it's not optimal. It's important to
remember that the guy who originally designed SSL (Kipp Hickman)
wasn't a security guy and doesn't seem to really have had
a threat model in mind.
When I write about it, generally try to summarize what I think
the implicit threat model is based on my memory of the zeitgeist
at the time and the characteristics of SSL.

@_date: 2003-09-07 09:44:40
@_author: Eric Rescorla 
@_subject: Is cryptography where security took the wrong branch? 
My view would be that SSL is a channel security product designed
to be used with HTTPS, which is pretty clearly a credit card
security product. But like I said, the people who designed it
weren't very sophisticated about such things. I remember Marca
or Jim saying that they just wanted to solve all security
problems in one shot.
There's also the issues of Kaufman's law, which is that
if you design something useful people will use it for
purposes other than what it was intended for and you'll be
criticized for being shortsighted. And as I've said,
Hickman wasn't very experienced.
[Note to people who just came in: the people who designed what
everyone thinks of as SSL, SSLv3, were relatively sophisticated, but
the security model comes from SSLv1 and SSLv2, which were designed by
See above. The Netscape philosophy was simplicity uber alles.
If you look at SHTTP you can see that that's clearly not
my philosophy. (Though if I were designing it today it would
be simpler). I don't think of hygiene as opposed to risk management.
It's a risk management tool. I doubt that. Do you have any data to support this claim?
SHTTP assumed the Internet Threat Model. We did so explicitly
(though not in the document) whereas Hickman kind of stumbled
into it via a bunch of course corrections by more experienced people.
SHTTP, however, had a more generalized usage model than SSL.  Thus,
SHTTP did one really important thing that SSL is still struggling
with: it could protect passive content.  Say you want to provide
static content for download and provide security for it. If you use
SSL and your server gets hacked you're SOL. If you use SHTTP, however,
you can presign things and have your server immune to that attack by
keeping the key offline.  We were designing with more than credit
cards in mind.
Incidentally, when designing SHTTP we envisioned that credit
transactions would be done with signatures. I would say that
the Netscape guys were right in believing that confidentiality
for the CC number was good enough.

@_date: 2003-09-07 09:48:22
@_author: Eric Rescorla 
@_subject: Is cryptography where security took the wrong branch? 
To follow up on this line a little more, I don't see why you're so
hung up on SSL here. SSL is perfectly capable of supporting an
SSH-style "leap of faith" authentication model or an anonymous
model. In fact, this is pretty much exactly how it's used for SMTP over TLS. It seems to me that your issue is with the authentication
model enforced by browsers in the HTTPS context, not with
SSL proper.

@_date: 2003-09-07 12:46:17
@_author: Eric Rescorla 
@_subject: Is cryptography where security took the wrong branch? 
That's not data, it's an anecdote--and not a very supportive one
at that. As far as I know, there isn't actually more total
SSH deployment than SSL, so you've got to do some kind of adjustment for the total potential size of the market, which
is a notoriously tricky calculation. Do you have any actual
data or did you just pull 2-5 out of the air?
I don't know where you got the idea that the server insists on cert
correctness. Neither ApacheSSL nor mod_SSL does.
Maybe, maybe not. You've never heard of price inelasticity?
The fact of the matter is that we have no real idea how
elastic the demand for certs is, and we won't until someone
does some real econometrics on the topic. Unless you've
done that, you're just speculating.

@_date: 2003-09-07 14:12:47
@_author: Eric Rescorla 
@_subject: Is cryptography where security took the wrong branch? 
No. There are lots of other things you CAN do with SSH
that people don't do that often. Data precedes analysis.
Elasticity is about how much consumption changes when price
changes, not about what people who were already going to buy
choose to buy.
Look at it this way:
If Pepsi cut their price by 50%, it might affect their
market share but would have only a very small amount of
effect on how much fluid people consume overall. The market for beverages is competitive but not particularly
elastic. That could easily be happening here.
Ian, it's a major econometrics project to determine how elastic a given good has. To imagine that you can do
it with a little handwaving is simply naive.

@_date: 2003-09-07 14:13:31
@_author: Eric Rescorla 
@_subject: Is cryptography where security took the wrong branch? 
Well, I'd certainly like to believe that this is true, since
it would mean that Allan and I were right all along. :)

@_date: 2003-09-07 15:13:43
@_author: Eric Rescorla 
@_subject: Is cryptography where security took the wrong branch? 
Yeah, I'd noticed that being able to buy stuff at Amazon
really didn't benefit me at all.

@_date: 2003-09-07 20:10:30
@_author: Eric Rescorla 
@_subject: Is cryptography where security took the wrong branch? 
Ian, The situation is really simple:
"The other thing to be aware of is that ecommerce itself
is being stinted badly by the server and browser limits.
There's little doubt that because servers and browsers
made poorly contrived decisions on certificates, they
increased the overall risks to the net by reducing the
deployment, and probably reduced the revenue flow for
certificate providers by a factor of 2-5."
I asked you where you got the factor of 2-5 and you waved your hands a
lot and didn't really provide any real answer. As it happens, I'm
extremely familiar with the set of techniques that one would use in order
to derive a number like this and it's quite apparent that you
haven't used any of them. As a consequence, there's no reason to take
your estimate as anything other than some number that you pulled out
of the air.
None of this is to say that it's not potentially worth trying to
change things and see if it makes a difference.  What I object to,
however, is quantitative claims made without evidence, which is what
you have been doing here.

@_date: 2003-09-27 15:42:02
@_author: Eric Rescorla 
@_subject: Tinc's response to "Linux's answer to MS-PPTP" 
Nitpicking alert:
"Draft Standard" is the technical term for the second tier of
IETF standardization. (Proposed, Draft, Full). The term for
something that has not yet been approved and given an RFC #
is "Internet Draft". SSHv2 and TLSv1.1 are Internet Drafts.

@_date: 2003-09-29 07:53:29
@_author: Eric Rescorla 
@_subject: New authentication protocol, was Re: Tinc's response to "Linux's answer to MS-PPTP" 
I'm trying to figure out why you want to invent a new authentication
protocol rather than just going back to the literature and ripping
off one of the many skeletons that already exist (STS, JFK, IKE,
SKEME, SIGMA, etc.). That would save people from the trouble
of having to analyze the details of your new protoocl.
Why are you using RSA encryption to authenticate your DH rather
than using RSA signature?
Depending on *exactly* how you do things, there are MITM attacks:
Consider the following protocol:
M1={DHx}RSAy         ->
                    <-              M2={DHy}RSAx
           ZZ = DH shared key
HMAC(ZZ,M1,M2)      ->
                    <-              HMAC(ZZ,M2,M1)     [Reverse order to prevent replay]
Now, the attacker chooses 0 as his DH public. This makes ZZ always
equal to zero, no matter what the peer's DH key is. He can now forge
the rest of the exchange and intercept the connection.

@_date: 2003-09-29 09:35:56
@_author: Eric Rescorla 
@_subject: New authentication protocol, was Re: Tinc's response to "Linux's answer to MS-PPTP" 
And I'm trying to understand why. This answer sounds a lot
like NIH.
Was there any technical reason why the existing cryptographic
skeletons wouldn't have been just as good?
But that's not a harmless change, which is the point of the potential
attack I just described.
Define "ripped". This certainly is not the same as TLS.
Actually, no. People are willing to take a quick look and
then shoot bullets at your protocol. That's not the same as
doing a thorough analysis, which can take years, as Steve
Bellovin has pointed out about Needham-Schroeder.
There's no difference if it's done correctly. If it's not done
Except that the way you compute DH is to do Y^X rather than X^Y. Look, there's nothing wrong with trying to invent new protocols,
especially as a learning experience. What I'm trying to figure
out is why you would put them in a piece of software rather than using one that has undergone substantial analysis unless
your new protocol has some actual advantages. Does it?

@_date: 2003-09-29 11:54:20
@_author: Eric Rescorla 
@_subject: New authentication protocol, was Re: Tinc's response to "Linux's answer to MS-PPTP" 
In what way is your protocol either simpler or more efficient
than, say, JFK or the TLS skeleton?
It doesn't appear to me that you've used the TLS skeleton.
The protocol you described really isn't much more like TLS than it is like STS or JFK. On the other hand,
all these back and forth DH-based protocols look more
or less the same, except for some important details.
Again, it's important to distinguish between learning experiences
and deployed protocols. I agree that it's worthwhile to try
to do new protocols and let other people analyze them as
a learning experience. But that's different from putting
a not fully analyzed protocol into a deployed system.
Well, I'd start by doing a back of the envelope performance
analysis. If that doesn't show that your approach is better,
then I'm not sure why you would wish to pursue it as a
deployed solution.

@_date: 2003-09-29 11:56:07
@_author: Eric Rescorla 
@_subject: New authentication protocol, was Re: Tinc's response to 'Linux's answer to MS-PPTP' 
Not necessarily.
If you're using fully ephemeral DH keys and a properly designed
key, then you shouldn't need to validate the other public share.

@_date: 2003-09-30 16:47:20
@_author: Eric Rescorla 
@_subject: New authentication protocol, was Re: Tinc's response to "Linux's answer to MS-PPTP" 
In order to hide the identities of the communicating peers.
Personally, I don't have much use for identity protection,
but this is the reason as I understand it.

@_date: 2004-04-07 07:52:50
@_author: Eric Rescorla 
@_subject: Blind signatures with DSA/ECDSA? 
Does anyone know if there is a blind signature scheme that works with
DSA or ECDSA? I know about Camenisch, Pivetau and Stadler's "Blind
Signatures Based on the Discrete Logarithm Problem" (1994), but as far
as I can tell that doesn't produce straight DSA-verifiable signatures
and so is a lot less desirable than it might otherwise be.
Has there been any better work on this?

@_date: 2004-08-16 12:32:57
@_author: Eric Rescorla 
@_subject: SHA-1 rumors 
Ed Felten's blog is carrying the rumor that a break in SHA-1
is going to be announced soon:
I've also done some off-the-cuff analysis of how bad this
would be in practice, which you can find here:
The key question is whether it's just collisions, which would
be embarassing, but which don't affect most applications, or
whether there is forward progress in finding preimages.
Anyone know anything about this rumor?
P.S. AFAIK, although Dobbertin was able to find preimages for
reduced MD4, there still isn't a complete break in MD4. Correct?

@_date: 2004-08-16 14:35:11
@_author: Eric Rescorla 
@_subject: MD5 collisions? 
Check out this ePrint paper, which claims to have collisions in
MD5, MD4, HAVAL, and full RIPEMD.
The authors claim that the MD5 attack took an hour for the first
collision and 15 seconds to 5 minutes for subsequent attacks
with the same first 512 bits.

@_date: 2004-08-16 18:02:24
@_author: Eric Rescorla 
@_subject: A collision in MD5' 
I've now successfully reproduced the MD5 collision result. Basically
there are some endianness problems.
The first problem is the input vectors. They're given as hex words, but
MD5 is defined in terms of bitstrings. Because MD5 is little-endian, you
need to reverse the written byte order to generate the input data. A
related problem is that some of the words are given as only 7 hex
digits. Assuming that they have a leading zero fixes that
problem. Unfortunately, this still doesn't give you the right hash
The second problem, which was found by Steve Burnett from Voltage
Security, is that they authors aren't really computing MD5. The
algorithm is initialized with a certain internal state, called an
Initialization Vector (IV). This vector is given in the MD5 RFC as:
word A: 01 23 45 67
word B: 89 ab cd ef
word C: fe dc ba 98
word D: 76 54 32 10
but this is little-endian format. So, the actual initialization values
should be 0x67452301, etc...
The authors use the values directly, so they use: 0x01234567,
etc... Obviously, this gives you the wrong hash value. If you use these
wrong IVs, you get a collision... though strangely with a different hash
value than the authors provide. Steve and I have independently gotten
the same result, though of course we could have made mistakes...
So, this looks like it isn't actually a collision in MD5, but rather in
some other algorithm, MD5'. However, there's nothing special about the
MD5 IV, so I'd be surprised if the result couldn't be extended to real

@_date: 2004-08-16 18:25:30
@_author: Eric Rescorla 
@_subject: Source code for MD5' collisions 
I've posted source code that demonstrates the MD5 collisions
on my web site at:
It's just a modified version of the RFC1321 MD5 source code
with the byte-flipping in the state initialization. It also
includes machine readable test vectors and a makefile. Just
run 'make' and you get the following output, at least on
gcc -o md5prime -DINVERT_STATE -DMD=5 md5.c mddriver.c
# X1 and X1' with ordinary MD5--no collision
./md5 X1.bin
MD5 (X1.bin) = e115410841d7a06f2913be15e1760fd1
./md5 X1prime.bin
MD5 (X1prime.bin) = 7005ea821bcc0e64d0eb9852f2bec2bd
# X1 and X1' with md5prime--collision
./md5prime X1.bin
MD5 (X1.bin) = 8ada1581c24565adac73a2d27160ca90
./md5prime X1prime.bin
MD5 (X1prime.bin) = 8ada1581c24565adac73a2d27160ca90
# X2 and X2' with ordinary MD5
./md5 X2.bin
MD5 (X2.bin) = 55f94e8f79e8a9795fad79f4c6ab5f11
./md5 X2prime.bin
MD5 (X2prime.bin) = 47aaf6e98d0799f9a85db9fd86cb392a
# X2 and X2' with md5prime
./md5prime X2.bin
MD5 (X2.bin) = 1a2a1d55c87318422367ae3462143fb6
./md5prime X2prime.bin
MD5 (X2prime.bin) = 1a2a1d55c87318422367ae3462143fb6

@_date: 2004-12-01 07:26:48
@_author: Eric Rescorla 
@_subject: SSL/TLS passive sniffing 
Just to be completely clear, this is exactly whatthey TLS_RSA_DHE_* ciphersuites currently do, so it's purely a matter
of configuration and deployment.

@_date: 2004-12-01 11:18:28
@_author: Eric Rescorla 
@_subject: IPsec +- Perfect Forward Secrecy 
Sorry, when I said IPsec I mean IKE. I keep trying to forget
about the manual keying modes. AFAICT IKE always uses the
DH exchange as part of establishment.

@_date: 2004-12-07 21:01:40
@_author: Eric Rescorla 
@_subject: MD5 To Be Considered Harmful Someday 
Dobbertin's collision in the MD5 compression function was published
in May of 1996.

@_date: 2004-07-10 12:46:24
@_author: Eric Rescorla 
@_subject: EZ Pass and the fast lane .... 
Precisely. Moreover, you can presumably use fairly unsophisticated
data mining/fraud detection techniques to detect when a unit has
been cloned and then go back to the photographs to find and punish
the offenders.

@_date: 2004-07-14 13:45:40
@_author: Eric Rescorla 
@_subject: Koblitz and Menezes on Provable Security 
If you haven't already, you should check out the Koblitz and Menezes
paper about Provable Security on eprint:
Here's the abstract:
We give an informal analysis and critique of several typical "provable
security" results. In some cases there are intuitive but convincing argu-
ments for rejecting the conclusions suggested by the formal terminology
and "proofs," whereas in other cases the formalism seems to be consistent
with common sense. We discuss the reasons why the search for mathemat-
ically convincing theoretical evidence to support the security of public-key
systems has been an important theme of researchers. But we argue that
the theorem-proof paradigm of theoretical mathematics is of limited rel-
evance here and often leads to papers that are confusing and misleading.
Because our paper is aimed at the general mathematical public, it is self-
contained and as jargon-free as possible.
You can also find my amateur's writeup at:

@_date: 2004-07-15 11:43:14
@_author: Eric Rescorla 
@_subject: Humorous anti-SSL PR 
What's wrong with a condom that protects the pipe? I've used
condoms many times and they seemed to do quite a good job
of protecting my pipe.

@_date: 2004-07-15 13:55:51
@_author: Eric Rescorla 
@_subject: Humorous anti-SSL PR 
Actually, that's a pretty reasonable way of assessing safety in
systems where there's no attacker specifically targeting you.
Or are you claiming that we shouldn't have confidence in the MMR vaccine because there's a small possibility that
someone will engineer a vaccine-resistant strain of measles?
Yes, I'm quite aware that it's traditional to assume a threat
model in which there's a very smart attacker dedicated to
attacking you in particular, but 99.9% of the time that's
not the situation, and it's silly to suggest that something
is worthless merely because it doesn't provide protection that .1% of the time.
P.S. FWIW, I've skimmed Articsoft's web site and as far as I
can tell their product is "superior" in two respects:
(1) The data is transmitted as an encrypted OpenPGP message
    so in theory it's protected even at rest. In practice,
    of course, to do real-time processing the server needs
    to be able to decrypt, so it's not clear that any actual
    benefit obtains here. There are advantages to message-oriented
    security (cf. S-HTTP) but this doesn't seem like a very convincing
    one.
(2) They control the client side so they can enforce a more strict
    integrity/authenticity check than the browser does. Of course,
    the browser's weak cert checking is an intentional feature,
    not a mistake--users got tired of not being able to get
    to web sites just because the certs were bad.

@_date: 2004-07-16 09:49:40
@_author: Eric Rescorla 
@_subject: Verifying Anonymity 
That's clearly a much harder problem--and indeed I suspect it's behind
the general lack of interest that the public has shown in anonymous

@_date: 2004-07-17 16:55:39
@_author: Eric Rescorla 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
I don't accept this argument at all.
There are at least three potential kinds of attack here:
(1) Completely passive capture attacks.
(2) Semi-active attacks that don't involve screwing with
    the network infrastructure (standard phishing attacks)
(3) Active attacks on the network infrastructure.
SSL does a fine job of protecting against (1) and a fairly adequate
job of protecting against (3). Certainly you could do a better job
against (3) if either:
(a) You could directly connect to sites with SSL a la
    (b) The identities were more user-friendly as we anticipated back in
    the days of S-HTTP rather than being domain names, as required by
    SSL. It does a lousy job of protecting against (3).
Now, my threat model mostly includes (1), does not really include
(3), and I'm careful not to do things that leave me susceptible
to (2), so SSL does in fact protect against the attacks in my
threat model. I know a number of other people with similar threat
models. Accordingly, I think the claim that "secure browsing
is not secure" rather overstates the case.

@_date: 2004-07-17 19:27:26
@_author: Eric Rescorla 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
I'm not sure what you mean by "bypass". I'm talking about attacks
where the attacker cons you into dereferencing the wrong
How? No COMSEC protocol that anybody is seriously considering protects
against these attacks. The secure payment protocols that involve
signing sort of do, except that they don't protect against all
sorts of account-based attacks.
I thought they were fairly obvious:
(a) Given that you know Expedia's URL and you type it in, and you
get SSL, and the certificate is from a real CA, then you are indeed
protected against all conceivable network-level MITM attacks.
(b) If customers were able to actually examine the name of the
site they were connecting to, and it was human readable,
e.g. "Microsoft Expedia" or a logo or whatever,
phishing would be a lot harder.
Don't be silly. It's not a threat because people generally use
SSL. Back in the old days, password capture was a very serious
threat. It went away with SSH. It seems to me quite likely that
it would be a problem with web browsing in the absence of SSL.
What they have to do with it is that although the attacker
is actively sending you mail, they're not intercepting the
connection as they would in a standard active attack.
So, your argument is that one shouldn't wear body armor
(which only protects against bullets) because someone might
nuke you? Don't be ridiculous.
It certainly does not remain unchallenged. As I said, given the actual
threat model as it actually obtains, secure browsing indeed provides
some, but not total protection. Nothing wrong with that. Yes, it's
disappointing that there's a new attack, but at heart phishing is a
con job. It's no more a failing of SSL/TLS that it doesn't protect
against it than that it doesn't protect you if you're conned into
typing your credit card in the clear.
That said, I don't have any illusions that I'll convince you
and I have no desire to get involved in an endless debate.
Accordingly, I'll end my half of the conversation here. Feel
free to have the last word.

@_date: 2004-06-03 17:42:52
@_author: Eric Rescorla 
@_subject: Chalabi Reportedly Told Iran That U.S. Had Code 
What I think is interesting is to ask how this happened at all.  After
all, we usually think of modern algorithms as essentially
unbreakable. It would certainly be really big news if the NSA knew how
to break AES. Some of my speculation about what "broken the
communications code" means can be found at:

@_date: 2004-06-10 11:37:06
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
Cryptography readers who are also interested in systems security may be
interested in reading my paper from the Workshop on Economics
and Information Security '04:
    Is finding security holes a good idea?
    Eric Rescorla
    RTFM, Inc.
    A large amount of effort is expended every year on finding and
    patching security holes. The underlying rationale for this activity
    is that it increases welfare by decreasing the number of bugs
    available for discovery and exploitation by bad guys, thus reducing
    the total cost of intrusions. Given the amount of effort expended,
    we would expect to see noticeable results in terms of improved
    software quality. However, our investigation does not support a
    substantial quality improvement--the data does not allow us to
    exclude the possibility that the rate of bug finding in any given
    piece of software is constant over long periods of time. If there is
    little or no quality improvement, then we have no reason to believe
    that that the disclosure of bugs reduces the overall cost of
    intrusions.
Paper:    Slides:

@_date: 2004-06-11 15:15:17
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
All of the above? Probably my favorite would be finding mechanical
ways to make programs more secure--e.g. stuff like Stackguard,
etc. As you say, moving to non-C languages would be a really
good start!
Good point.
Excellent point. There's no real data on this topic but my intuition would be that better IDS/anomaly detection would be
a useful tool here. Also, some kind of automated
forensic network recording so that when intrusions are
detected it's easy to backfigure what happened.

@_date: 2004-06-14 08:07:11
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
Well, this is just the abstract... The full argument is laid out
in the paper. Roughly speaking:
If I as a White Hat find a bug and then don't tell anyone, there's no
reason to believe it will result in any intrusions.  The bug has to
become known to Black Hats before it can be used to mount
intrusions. This can either happen by Black Hats re-finding it or some
White Hat disclosing it.  So, the question is, at least in part, what
the likelihood of these happening is...

@_date: 2004-06-14 13:25:01
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
I think it's importances to distinguish between new classes of
bugs and new instances of old bugs. I agree that new classes
of bugs are potentially interesting, however, I don't think
that this argument applies to the 513th buffer overflow. See S 8.4 of the paper.
I never claimed that. What I said was that the evidence that the
positive effects of bug reporting in terms of reduced intrusions did
not clearly offset the negative effects of said reporting.
I'm not sure how to answer this. In my view it's a bad idea to
be confident of propositions when one doesn't have empirical data
to support them.

@_date: 2004-06-15 13:32:15
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
The extent to which bugs are independently rediscovered is certainly
an open question which hasn't received enough study. However, the
fact that relatively obvious and serious bugs seem to persist for
long periods of time (years) in code bases without being found
in the open literature, suggests that there's a fair amount of
independence.

@_date: 2004-06-15 21:37:38
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
Well, SOME bugs are being found. I don't know what you mean by
"these" bugs. We don't have any real good information about
the bugs that haven't been found. What makes you think that
there aren't 5x as many bugs still in the code that are basically
like the ones you've found?
I don't think that's clear at all. It could be purely stochastic.
I.e. you look at a section of code, you find the bug with some
probability. However, there's a lot of code and the auditing
coverage isn't very deep so bugs persist for a long time.

@_date: 2004-06-15 21:37:42
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
This only follows if there's a high degree of overlap between the
bugs that the black hats find and the bugs that white hats would
find in their auditing efforts. That's precisely what is at

@_date: 2004-06-16 08:40:35
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
<40D05109.2030401
I agree that this is a possibility. We'd need further research
to know if it's in fact correct.

@_date: 2004-06-16 14:12:18
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
I'm sorry, but I don't think this follows at all.
Let's assume for the sake of argument that two people auditing
the same code section will find the same set of bugs. So, how
to account for the fact that obvious errors persist for long
periods of time in popular code bases? It must be that those
sections were never properly audited, since by hypothesis
the bugs are obvious and yet were not found. However, this
happens fairly often, which suggests that coverage must
be pretty bad. Accordingly, it's easy to see how you could
get low re-finding rates even if people roughly think alike.
Now, you could argue that because people think alike, everyone
looks at the exact same sections of the code, but I think
that this is belied by the fact that many of these self-same
obvious bugs are found in obvious places, such as protocol
parsers. So, while I think it's almost certainly not true that bug finding
order is completely random, I think it's quite plausible that it's
mostly random. Ultimately, however, it's an empirical question and I'd
be quite interested in seeing some studies on it.
I think I've said enough on this general topic. If you'd like to have
the last word, feel free.

@_date: 2004-06-17 07:34:37
@_author: Eric Rescorla 
@_subject: Is finding security holes a good idea? 
It's true that the Browne paper doesn't apply directly, but I don't
actually agree that rapid spreading malware alters the reasoning in
the paper much. None of the analysis on the paper depends on any
particular C_BHD/C_WHD ratio. Rather, the intent is to provide
boundaries for what one must believe about that ratio in order to
think that finding bugs is a good idea.
That said, I don't think that the argument you present above is that
convincing. it's true that a zero-day worm would be bad, but given the
shape of the patching curve [0], a day-5 worm would be very nearly as
bad (and remember that it's the C_BHD/C_WHD ratio we care about).
Indeed, note that all of the major worms so far have been based on
known vulnerabilities. [0] E. Rescorla, "Security Holes... Who Cares?", Proc. 12th USENIX
Security, 2003.

@_date: 2004-11-30 07:15:44
@_author: Eric Rescorla 
@_subject: SSL/TLS passive sniffing 
Yep. ssldump ( for instance, will
do this.
Client certificates and DH key exchange are orthogonal. Client auth
looks just like non client auth SSL except that the client signs
some data with its private key and provides its certificate. In general
it has no effect on the keying material. It's true that there is a mode
where the shared key is derived from the client and server's DH shares
in their certificates (static DH) but to a first order it's never used.
The environment in which SSL was designed to operate was one where in general only the server would have a certificate. In this environment,
there are approximately three different approaches:
1. Use RSA as in the current approach.
2. Have the server's DH key in its certificate and the client generates
   a random DH key for each connection. 3. Have the server generate a new DH key for each connection and    sign it with its long-term key.
Now, modes (1) and (2) both have the property that someone with the
server's private key can recover the connection plaintext (you only
need one of the DH shares to recover the shared DH key). Only mode
(3) has the property (called Perfect Forward Secrecy) that having
the long-term key doesn't let you get access to the plaintext.
SSL has all three of these modes, actually, so perhaps the question
you want to ask is why noone uses  The main argument against it is
that it's about half as fast (on the server) in the best case because
you need to do both a signature and a key exchange operation.
On the client it's *much* slower because RSA public-key encryption
is very fast (private-key decryption is much slower). For obvious reasons, the server operators want to minimize costs
on their side and since they're the ones who would be in a position
to mount this kind of attack, they're probably not overly concerned
about it. And since the users don't demand it...

@_date: 2004-10-10 18:16:21
@_author: Eric Rescorla 
@_subject: Certificate serial number generation algorithms 
Does anyone know the details of the certificate generation algorithms
used by various CAs? In particular, Verisign's is very long and I seem to remember someone telling
me it was a hach but I don't recall the details...

@_date: 2005-08-25 14:09:48
@_author: Eric Rescorla 
@_subject: Another entry in the internet security hall of shame.... 
Most chat protocols (and Jabber in particular) are server-oriented
protocols. So, the SSL certificate in question isn't that of your
buddy but rather of your Jabber server.

@_date: 2005-08-25 21:12:15
@_author: Eric Rescorla 
@_subject: Another entry in the internet security hall of shame.... 
Absolutely, but that's not the scenario in which this particular
check is occurring...

@_date: 2005-08-26 14:57:00
@_author: Eric Rescorla 
@_subject: Another entry in the internet security hall of shame.... 
Well, it's still attractive to have channel security in order to
prevent hijacking. (Insert usual material about channel bindings

@_date: 2005-12-24 08:51:20
@_author: Eric Rescorla 
@_subject: browser vendors and CAs agreeing on high-assurance certificat 
24 Dec 2005 15:08:46 +0000")
Actually, the big problem if you run a virtual hosting server
is that every time you add a new virtual domain you need a new
cert with that domain in it. And that applies even if you put
all the names in one cert.
Really, the ServerHostName extension is better.
The problem is that the ServerHostName extension that signals
which host the client is trying to contact is only available
in the TLS ClientHello.

@_date: 2005-12-28 09:38:07
@_author: Eric Rescorla 
@_subject: Hey kids, come join the NSA! 
Hey boys and girls! Want to help your country defeat that mean old
Osama? Then check out the National Security Agency's CryptoKids web site
    On this site, you can learn all about codes and ciphers, play lots
    of games and activities, and get to know each of us - Crypto Cat,
    Decipher Dog, Rosetta Stone, Slate, Joules, T.Top, and, of course,
    our leader CSS Sam.
    You can also learn about the National Security Agency/Central
    Security Service - they're Americas real codemakers and
    codebreakers. Our Nation's leaders and warfighters count on the
    technology and information they get from NSA/CSS to get their jobs
    done. Without NSA/CSS, they wouldnt be able to talk to one another
    without the bad guys listening and they wouldnt be able to figure
    out what the bad guys were planning.
    We hope you have lots of fun learning about cryptology and
    NSA/CSS. You might be part of the next generation of Americas
    codemakers and codebreakers.
The site comes complete with a bunch of material on making and breaking
simple codes (cool), resources to teach kids about crypto (also cool),
and detailed biographies of the CryptoKids characters (kind of
creepy). Here's some of what CryptoCat does for fun:
    I'm usually hanging out with my friends at the mall or catching the
    latest movie. I love helping people so I find different ways to help
    out around the community. Right now, I volunteer as a swim coach for
    children with special needs. Its a lot of fun AND I get to spend
    extra time with my sister who has Downs Syndrome.
The NSA Gifted and Talented program looks pretty cool, though.

@_date: 2005-02-10 16:29:57
@_author: Eric Rescorla 
@_subject: TLS session resume concurrency? 
You can have multiple simultaneous TLS connections that are
rooted in the same session. It's possible that the TLS server
will check the IP address of the client but that's not
specified in the protocol and AFAIK TLS servers do not.

@_date: 2005-07-01 08:57:50
@_author: Eric Rescorla 
@_subject: Menezes on HQMV 
There's an interesting paper up on eprint now:
Obviously, this is of inherent interest, but it also plays a part
in the ongoing debate about the importance of proof as a technique
for evaluating cryptographic protocols.

@_date: 2005-06-02 09:25:33
@_author: Eric Rescorla 
@_subject: ANNOUNCE: PureTLS 0.9b5 
ANNOUNCE: PureTLS version 0.9b5
Copyright (C) 1999-2005 Claymore Systems, Inc.
PureTLS is a free Java-only implementation of the SSLv3 and TLSv1
(RFC2246) protocols. PureTLS was developed by Eric Rescorla for
Claymore Systems, Inc, but is being distributed for free because we
believe that basic network security is a public good and should be a
commodity. PureTLS is licensed under a Berkeley-style license, which
basically means that you can do anything you want with it, provided
that you give us credit.
This is a beta release of PureTLS. Although it has undergone a fair
amount of testing and is believed to operate correctly, it no doubt contains significant bugs, which this release is intended to shake out. Please
send any bug reports to the author at .
CHANGES FROM B4
* SECURITY: Zero OPTIONAL values before parsing. This prevents   bleedthrough of those values from previously parsed certificates
  into certificates where they are missing. This is a workaround for a   bug in the Cryptix ASN.1 kit.
  The only relevant values are Extensions and Algorithm.Parameters.
  In practice this should not be a problem with Algorithm.Parameters
  Since they're NULL in RSA certificates and always present in real   DSA certificates. If you rely on Extensions you should upgrade
  as soon as possible.
  Note: extensions processing is still only partially tested (see
  below). * Trim all leading zeros from DH shared keys. This fixes a rare
  compatibility problem.
* Fix handling of pathLen constraints. We were off by one, causing
  some valid certificates to be rejected.
We believe that this is the best version of PureTLS available.  Users
are advised to upgrade as soon as possible. In particular, if you rely
on X.509 extension processing you should upgrade as soon as possible.
This will most likely be the last release of PureTLS distributed as a standalone package by Claymore Systems. We have given
the BouncyCastle ( permission to
integrate the PureTLS source code with their library and
we expect them to deliver an integrated system in the future.

@_date: 2005-06-13 08:05:00
@_author: Eric Rescorla 
@_subject: Collisions for hash functions: how to exlain them to your boss 
While this is a clever idea, I'm not sure that it means what you imply
it means. The primary thing that makes your attack work is that the
victim is signing a program which he is only able to observe mediated
through his viewer. But once you're willing to do that, you've got a
problem even in the absence of collisions, because it's easy to write
a program which shows different users different content even if you
without hash collisions. You just need to be able to write
For more, including an example, see:

@_date: 2005-06-13 14:09:26
@_author: Eric Rescorla 
@_subject: Collisions for hash functions: how to exlain them to your boss 
Yes, this is all true, but it's kind of orthogonal to my point,
which is that if you're willing to execute a program, this attack can be mounted *without* the ability to produce hash
collisions. The fact that so few people regard PS, HTML, Word,
etc. as software just makes this point that much sharper.
As far as I can tell, the ability fo produce hash collisions just
makes the attack marginally worse.

@_date: 2005-06-14 06:36:54
@_author: Eric Rescorla 
@_subject: Collisions for hash functions: how to exlain them to your boss 
But everything you've just said applies equally to my JavaScript
example. It's not a security vulnerability in the browser or the
data format that it displays differently depending on the context.
It's an intentional feature! I agree with this. I'm merely observing that many of those
data formats in practice have features that let you mount
isomorphic attacks even if you can't break the hash function.
And it's equally impractical for people to be experts on which
of them allow such dual interpretations. And because of this
the *incremental* insecurity offered by the current generation
of hash attacks is extremely small.

@_date: 2005-06-14 10:34:36
@_author: Eric Rescorla 
@_subject: expanding a password into many keys 
Some terminology first. Let's assume that we have a password P and
that we want to generate a series of n keys K_1, K_2, ... K_n, each of
which has a label L_1, L_2, ... L_n. What we want is a function
F(P,L_i) that produces K_i values. There are a number of desirable
elements that one would like to incorporate in such a scheme.
The most basic one is that it the best attack should be to brute force
the password space.
So, this means that:
1. You shouldn't be able to compute P from K_i in any less    time than exhaustive (or at least dictionary) search of P.
2. You shouldn't be able to compute K_j from K_i (for i!=j)
   in less time than search of P.
Hash-based constructions are the standard here, but I'm generally
leary of using a pure hash. Probably the best basic function is to use
HMAC(P,L_i) or perhaps HMAC(H(P),L_i), since HMAC wasn't designed to
be used with non-random key values.  You'd need someone with a better
understanding of hash functions than I have to tell you which one of
these is better.
But this only gets you part of the way there. We'd really like
to make it harder to dictionary search the password. We can
do this by making F slower. The standard way to do this is simply
to iterate the underlying function. This is what PKCS  does.
This of course slows down the user, but that's barely noticeable
in ordinary operation and it of course slows down the attacker
by a comparable margin.
An additional trick, used by Halderman, Waters, and Felten [1]
(which pretty much embodies the state of the art here)
is to have a two-level system where you substitute K in F with
G(K), where G(K) is computed by a similar, very expensive iterative procedure. The idea is that the first time you
use the password generator on a given computer, you compute
G(K) and then cache it. This takes maybe a minute or so,
but in the future all of your authentications are fast and this
obviously really slows down the attacker.
Halderman, Waters, and Felten, "A Convenient Method for Securely Managing
Passwords", WWW 2005.

@_date: 2005-11-30 08:06:04
@_author: Eric Rescorla 
@_subject: Session Key Negotiation 
May I ask why you don't just use TLS?
Well, in TLS in RSA mode, the client picks the secret value (technical
term: PreMaster Secret) but both sides contribute randomness to ensure
that the Master Secret secret is unique. This is a clean way to
ensure key uniqueness and prevent replay attack.
In DH mode, of course, both sides contribute shares, but that's
just how DH works.

@_date: 2005-11-30 09:02:09
@_author: Eric Rescorla 
@_subject: Session Key Negotiation 
I hate to sound like an advertisement, but why not use
Datagram TLS?

@_date: 2006-02-04 11:16:43
@_author: Eric Rescorla 
@_subject: EDP (entropy distribution protocol), userland PRNG design 
Look, this design just reduces to a standard cryptographic PRNG with
some of the seed being random and periodically being reseeded by the
"random" network stream you're sending around. There's no need to
worry about the integrity or confidentiality of the "random" stream
because anyone who controls the network already knows this input. The
only information they don't have is your "random" private key.
That said, frankly, this is all rather silly. A good cryptographic
PRNG seeded with a few hundred bytes of high-quality randomness is
good enough for bits of randomness is good enough for practically any
purpose. Practically the only thing it's not useful for is for
generating OTPs, which, as people have repeatedly told you on this
list, you shouldn't be doing anyway.
Note further that no CPRNG can be safely used to generate OTPs--except
for rather short ones--because the entropy of the resulting randomness
stream is bounded by the size of the CPRNG state no matter how many     bits of entropy you feed into it. The technical term for this is a stream cipher.

@_date: 2006-02-04 22:19:16
@_author: Eric Rescorla 
@_subject: EDP (entropy distribution protocol), userland PRNG design 
Well, for starters the assumption that nobody is monitoring the
network traffic is in general unwarranted. However, the equivalence (or lack thereof) to a HWRNG depends entirely
on the details of the mixing function in /dev/random, network
buffering, etc. But since /dev/random is basically a PRNG, it's
not clear why you think there's any difference between your and
my designs.

@_date: 2006-02-26 10:28:03
@_author: Eric Rescorla 
@_subject: hamachi p2p vpn nat-friendly protocol details 
This isn't quite accurate.
SSLv2 didn't do any kind of downgrade protection at all, for the
version number, cipher suite, or anything else. SSLv3 used a MAC
across the entire handshake. The tricky problem is to protect
downgrade from SSLv3 to SSLv2, which obviously can't be done with the
SSLv3 mechanisms. The trick that SSLv3 used was that when falling back
to SSLv2, SSLv3-capable clients would pad their RSA PKCS blocks
in a special way that SSLv3 servers would detect. If they detected
it, that meant there had been a downgrade.
Unfortunately, not all clients correctly generate this padding
and the check wasn't universally implemented correctly:

@_date: 2006-05-14 16:36:10
@_author: Eric Rescorla 
@_subject: picking a hash function to be encrypted 
It's not safe to use a hash function this way if the content is known
to the attacker.
Consider the case where you're transmitting message M. The hash is H(M). You then encrypt (M || H(M)), generating
K XOR (M || H(M)). If the attacker knows M and H, he can
compute (M || H(M)) and compute K. Then he can re-encrypt
a message M' of his choice.
If you want integrity with a stream cipher you'd really
be much better off using a MAC.

@_date: 2006-05-15 20:26:58
@_author: Eric Rescorla 
@_subject: picking a hash function to be encrypted 
There have been a number of attacks on TLS since Mitchell et al's
paper was published in 1998. The most well known are the attacks
on CBC mode described in
