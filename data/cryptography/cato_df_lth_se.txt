
@_date: 2002-11-09 01:13:05
@_author: Krister Walfridsson 
@_subject: Did you *really* zeroize that key? 
My experience is that in practice the opposite is true. Nonconformant
source code usually contains constructs that will give unexpected results
when optimized using newer ideas in the C language (such as aliasing),
so the compiler will in general be much more conservative when doing
optimizations on such code.
Consider for example the code (we assume sizeof(int) == sizeof(long))
   {
      int a = 23;
      long *p;
      p = &a
      *p += 5;
      if (a > 23)
      {
          foo();
      }
   }
If we opimized this as if it was confomant code, then we would determine
that p cannot alias with a (since they has different type), so the if-
statement will always evaluate to "false", and may thus be removed, i.e.
the code snippet collapses to
   {
      int a = 23;
      long *p;
      ptr = &a
      *p += 5;
   }
This kind of optimization is a really big win in some kinds of real world
programs, but cannot be done on nonconformant code.
Btw. one of the more important reasons that gcc does never optimize away
volatile is that every time this optimization is mentioned, there is
always a lot of flamage from embedded programmers that fear what will
happen when their timing loops
   volatile int i;
   for (i=0; i < 100000; i++)
      ;
gets optimized...
   /Krister

@_date: 2003-03-12 23:08:26
@_author: Krister Walfridsson 
@_subject: Encryption of data in smart cards 
This is not completely true -- I have seen some high-end cards that use
the PIN code entered by the user as the encryption key.  And it is quite
easy to do similar things on Java cards...
   /Krister

@_date: 2004-10-24 00:52:33
@_author: Krister Walfridsson 
@_subject: Are new passports [an] identity-theft risk? 
One thing that I have seen confuse people writing about the
new passports is that RFID may mean different technologies.  So
I'd like to mention that the passports will not use the simple
bar-code kind of RFID tags -- they will use chip cards
communicating over ISO/IEC 14443.
The current technology has big problems with working at a distance
(in fact, the tests done with COTS 14443 readers shows that most
have problems with reading passport-like cards even when placed at
the optimal distance...), but I don't know enough about antenna
technology to be able to guess what can be done by a dedicated
    /Krister
PS.  Most of the MRTD (Machine Readable Travel Documents) specifications
are available at PPS. Most people on this list seems to be interested in the US
passport, so you may be interested in that the US department of
state, and department of homeland security, seems to be doing a
pilot of the new passport.  The RFP is available from:
   with some consolidated Q and A at

@_date: 2006-09-09 02:54:29
@_author: Krister Walfridsson 
@_subject: link fest on fingerprint biometrics 
I have never understood the hype around creating fake fingers; looking
at the technology behind the sensors makes it rather obvious that
it is possible -- in fact, there is a discussion within ISO JTC1/SC37
(the ISO group standardizing biometrics) about evaluating the quality
of images produced by fingerprint scanners by using a synthetic finger created following a standardized procedure [1] in order to get reproduceable results.
But I agree that it is sounds cute that you can create fake fingers out
of gummy bears...
One IMHO more interesting question is the FAR (False Accept Rate = the
probability that an impostor is accepted) of the algorithm.  (And I
note that some of the gummy finger articles I have read have been done
with algorithms with low enough FAR that the author could have got a match
by inviting ~5 friends to try to match against his finger...  This is
probably a more realistic attack, but it also mean that the fake finger
may work even if it look rather different from the real fingerprint.)
It can be a bit hard to get relevant numbers from vendors, but NIST has
recently done extensive testing using real world data.  The result [2]
gives a detailed picture about the performance of fingerprint systems
(the Minex test was however done using standardized templates; the result
of each vendor is in general much better when using proprietary templates.
See e.g. [3] for an older test using proprietary templates).
The NIST image group web site [4] has more nice stuff, including a rather
good implementation of a fingerprint matcher.  I can also highly recommend
the book [5] in case you are really interested in algorithms for fingerprint recognition...
    /Krister
[1] Document 37N0847 and 37N1661 in case you have access to the SC37
     document archive.
[2] [3] [4] [5] "Handbook of Fingerprint Recognition"
     Davide Maltoni, Dario Maio, Anil K. Jain, Salil Prabhakar
