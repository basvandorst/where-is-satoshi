
@_date: 2013-12-23 13:33:33
@_author: Benjamin Kreuter 
@_subject: [Cryptography] how reliably do audits spot backdoors? (was: Re: 
I have been wondering for some time if this might be more a symptom of
the languages we are using than a fundamental difficulty in the
auditing process itself.  Quite a few UCC entries rely on undefined or
counterintuitive behavior in C.  A better language might improve the
auditability of code, particularly in cases where we do not really need
to squeeze every last bit of performance out of our computers (e.g. for
something like OTR, where you are not going to be sending hundreds of
messages per second).

@_date: 2013-12-24 17:12:24
@_author: Benjamin Kreuter 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
On Tue, 24 Dec 2013 17:42:33 +1000
So the fact that it is possible for the sum of two positive integers to
be a negative number is idiomatic?  C has many of the features that make
writing reliable (let alone secure) code difficult, and almost none of
the features that make it easy.
Nonsense.  The UCC entries win points for not be obfuscated or
uglified or complicated.  That is the entire point of the contest.
There is a sufficient amount of undefined behavior in C to make such
things possible, which is part of the problem.
So what do we do when we are asked to check an already completed
program for back doors?  This conversation started with the common
suggestion that open source software is more secure because we can
check the code for problems.  Rewriting the Linux kernel or OpenSSL is
not typically considered to be something that is on the table.
Now, if it is on the table, then I do not see any reason why it would
be desirable to choose C over a more well-defined language.  If a
complete rewrite is something we can undertake, then even if *none* of
the languages available now fit the bill, why not just create a new
one?  Why not just identify that subset of C that is "good" and write a
compiler for that language, without any undefined behavior?  Why not
create a new language that we can audit more easily if something like
OCaml is "too slow" (or whatever reason people are giving for avoiding
high-level languages these days)?

@_date: 2013-12-24 20:48:14
@_author: Benjamin Kreuter 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
On Wed, 25 Dec 2013 11:34:42 +1000
1. You just referred to *undefined behavior* as "intuitive."
2. For that to be intuitive, you must have un-learned the first N years
   of your mathematics education.
I would have called such code *hard to read*.  I understand that in C
such things are common, but I would much rather write code in a
language that forced me to explicitly declare the fact that I am using
modular arithmetic (and what modulus).
Great!  Now you just need to convince all those other developers in the
world, whose code you are not directly overseeing, to do the same.
I think this is demonstrably false, given the numerous feature-complete
projects written in high-level languages.
Are you claiming that the situation is worse than it is in C?
How is C any different in this regard?  You still need to audit all
those libraries that your C code depends on.
I am not even sure what it is that you are referring to here.

@_date: 2013-12-25 12:35:21
@_author: Benjamin Kreuter 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
On Wed, 25 Dec 2013 17:57:18 +1000
Signed integer overflow is undefined behavior in C.
Really?  Installing C programs is generally a matter of following this
(find missing dependency)
(find missing dependency of dependency)
(figure out why it didn't compile)
make install
(find another missing dependency)
Is that what you call "simply installing?"  I call that a nightmare of
tracking down libraries and dependencies, no different from the
nightmare one would face with software written in any other language.
That is why so much effort was put into repository systems and
installer programs.

@_date: 2013-12-26 20:28:34
@_author: Benjamin Kreuter 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
On Thu, 26 Dec 2013 14:45:31 -0500
In fact, it is undefined behavior in C -- because it is an signed
arithmetic overflow.  You are thinking of unsigned overflow, which is
Really, if we are going to be doing modular arithmetic, *we should have
to be explicit about that*.  The fact that the auditing process must
include steps like, "What is the size of the register this is stored
in?" or "Is this signed or unsigned overflow?" is a problem.  Either
overflows should be trapped and reported as an error, or the default
integer type should be arbitrary precision.
I am pretty sure that nobody on this mailing list can claim to
understand all of the behavior of their CPU.  Modern CPUs are
complicated and come with numerous undocumented features and
behaviors.  There are inconsistencies between Intel and AMD
implementations of the same instructions (unsurprising given just how
many x86 instructions there are), and even between different Intel
The more your code depends on particular CPU implementations or
features, the harder your code is to audit.  Even depending on
something as seemingly innocent as register sizes makes auditing more
complex than it should be.

@_date: 2013-11-25 19:27:57
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Email is unsecurable 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
On Mon, 25 Nov 2013 09:01:31 +0300
In my experience, there is a more fundamental problem with PGP:  it
works as designed.  The problem here is that what PGP is designed to do
conflicts with the expectations users have about their email, their
usage patterns, and so forth.  People want to be able to go to their
friend's house, log in to their email using their friend's computer,
and actually be able to read it.  People use email as a way to transfer
files to computers they do not control e.g. to print from a public
library, just email yourself a PDF.
Even if PGP were the most user-friendly program ever created, it still
does the wrong thing for most people.  The problem is not the UI, it is
the system itself.
Fortunately, there is a solution that we have long been aware of, which
is smart cards.  You can plug a smart card into a computer, let it do
the decryption of your messages, and thus enjoy typical usage
patterns.  One can imagine some simple security features to help deal
with compromised computers.
Of course, standing in the way of this is the fact that such a system
would require a bunch of new hardware to be deployed, and the only
organizations that have the resources to do so (at scale) have an
interest in preventing such a system from being deployed.  The demand
among users is also a bit low, as most people do not really understand
the security implications of email (and even among those that do, it is
often not taken very seriously).  The only exception to these two
statements are banks, but banks have found other ways to deal with the
problem of insecure email.
This is a separate security problem, and there is a mountain of
research on solving it.  It is certainly a hard problem, but it is not
out of reach -- we do have anonymous remailers and they do work, albeit
with quite a bit of latency.
I think this brings up another important point:  we do not all agree on
what it means to "secure email."  Does it mean protecting the body of a
message?  Does it mean protecting headers also?  Does it just mean
authenticating the sender i.e. is digital signing enough?
The solution is spam filtering.  Modern spam filters have basically
killed spam; the profit margins for spammers are so small that they
are barely staying in business.  Yes, a lot of that is due to third
party spam filtering i.e. spam filtering done by email service
providers, but I suspect that we could do a good enough job with
client-side filtering (maybe a little more spam would get through, but
we would not see anything like what we saw a few years ago).  Spam
filtering would also get a nice boost from message signing, since we
could associate reputations with public keys (if someone never sends
you spam, then a signature with their key is a strong indicator that
the message is not spam).
It is also worth pointing out that if we required that all email
messages were signed and/or encrypted, the rate at which spam could be
sent would plummet.  Public key cryptography is costly, and although
the recipients would have to pay for each decryption, a spammer would
have to pay as much as all the recipients combined (within a constant
I think this is a defeatist attitude.  For certain definitions of
security, email is very much securable.  I would love to see PGP or
S/MIME signatures on emails from my bank.  I would love if stores
encrypted the receipts they sent me.  We are not merely trying to
defend ourselves from the NSA, there are still a lot of other attackers
we need to deal with.

@_date: 2013-11-27 22:25:11
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Email is unsecurable 
Hash: SHA512
On Wed, 27 Nov 2013 20:00:31 -0500
The ability to fab our own CPUs in our homes, and to do so using
minimal computing power (i.e. something you could bootstrap from CMOS
logic). I would not hold my breath, and this is obviously something
that only experts would be able to do.  A possible compromise would be
FPGAs, but only if we had a good way to thwart backdoors (e.g. if we
could randomize the logic in some way).

@_date: 2013-10-01 12:56:00
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Why is  emailing me my password? 
Two things to keep in mind:
1. The damage one can do to you with knowledge of this password is
   beyond minimal.  You might have your list subscriptions changed; so
   what?
2. The password is sent just in case you forgot it and want to
   unsubscribe.  Without the password, any troll might unsubscribe you
   from the list by simply forging headers.  Were this to be encrypted,
   you would wind up with the classic problem of lost private keys,
   leaving people who forgot their password unable to unsubscribe (at
   least in any automated fashion).

@_date: 2013-10-03 09:36:02
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Why is  emailing me my password? 
Assume for a moment that there are no other systems involved, and
compare the failure of a nuclear power plant to a leaked mailman
password.  On its own, a failure at a nuclear power plant can render
tens of thousands of square miles uninhabitable.  On its own, a leaked
mailman password causes a few minutes of annoyance.
Really, the issue here is not mailman.  Mailman passwords address a
very minor security issue and mailing them in plaintext has no effect
on said security.  The real issue is that passwords are being used in
places where security really does matter, and that someone might have
used the same password for mailman as they did for one of those
systems.  If you ask me, the problem is not mailman sending out the
passwords, nor the fact that people often use the same password
everywhere; the problem is that passwords are being used to secure
important things.

@_date: 2013-10-21 10:42:26
@_author: Benjamin Kreuter 
@_subject: [Cryptography] prism-proof email in the degenerate case 
On Thu, 10 Oct 2013 14:20:21 -0700
I am not sure this is the whole story.  The key word in John's
suggestion is "protocol" -- what immediately comes to my mind is PIR,
which would allow you to fetch your messages more efficiently without
generating more metadata.  One practical consideration is that people
might be receiving different numbers of messages, but this can be
addressed by having everyone fetch a fixed number of messages every $n$
minutes; you probably need to do this regardless of PIR to prevent
other forms of information leakage.
There are probably a few other practical considerations here, but at
least in theory PIR could help with efficiency without compromising

@_date: 2013-09-06 11:28:22
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
On Fri, 6 Sep 2013 01:19:10 -0400
Not necessarily.  A bad implementation of a block cipher will be
probably spotted quickly if you need it to interoperate with a good
implementation; a bad implementation of a public key cipher might
interoperate just fine with good implementations.  Public key systems
often have parameters or requirements that affect security without
affecting the correctness of encryption or decryption.  ElGamal
encryption might appear to work even though you are using a group where
the DDH assumption does not hold.  Elliptic curve systems have even more
parameters that need to be set correctly for security.
I am not saying that we should abandon public key cryptography, I am
just saying that there a number of ways for public key systems to go
wrong that do not apply to symmetric ciphers.
Just my 2 cents,

@_date: 2014-04-13 11:30:38
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Heartbleed and fundamental crypto programming 
It is also one of the few languages where this is of critical
Again, this is critical in C and C++ where you have no particular
guarantees about memory safety.  It is certainly relevant in other
contexts, but not nearly as important as it is in languages where you
can read memory directly and ignore whatever abstractions you have set
As opposed to all the discipline you must enforce by yourself in C++?  A
dangling pointer could cause key material to be copied somewhere else,
and then your whole technique becomes irrelevant.
For what it's worth, it is possible to do something similar with most
Lisp compilers I know of.  You can create an array, pin it (so the GC
will not copy it), and then clear it and unpin when you are done.  A few
macros to ensure this always happens for sensitive data, and you get
exactly what you described from C++ -- and you do not need to worry that
some dangling pointer somewhere will break your abstraction.

@_date: 2014-04-19 18:10:54
@_author: Benjamin Kreuter 
@_subject: [Cryptography] It's all K&R's fault 
This is a non-sequitur.  Sure, it is *possible* to write reliable and
secure code in C, it is just difficult to do.
"Possible" is not the same as "probable."  I have far less confidence in
the security or reliability of C or C++ programs than programs written
in Haskell or ML.  It's not that Haskell is a guarantee of security,
it's that the effort needed to avoid certain classes of errors is
substantially reduced.
Yeah, and C programs routinely die on segmentation faults.  The
difference is that C programs also do not die when pointer arithmetic
goes wrong -- which is what we had with Heartbleed.  In C and C++ you
can use pointers to break any higher-level abstraction; the effect is
that in addition to worrying about the correctness of your high-level
abstractions you must also worry about whether or not those abstractions
will even be respected.  That makes the rest of the process of writing
secure and reliable code much harder (even if we ignore the plethora of
other undefined behaviors, many of which surprise programmers with years
of experience).
"Eliminate" bugs is far too high a standard.  Reducing the likelihood
that bugs will be created is not so hard to achieve -- we already
achieved it, and we got there decades ago.
At this point the problem with moving to better/safer languages is the
enormous and valuable ecosystem of C and C++ code.  We are not going to
escape these languages any time soon.

@_date: 2014-04-20 19:24:32
@_author: Benjamin Kreuter 
@_subject: [Cryptography] It's all K&R's fault 
I do not think these issues are as orthogonal as you make it seem.  You
cannot really say that an application does not leave copies of
confidential data lying around without being confident that the
application behaves as intended.  This is painfully apparent with
heartbleed:  data is unintentionally copied because array boundaries are
not enforced.
On the other hand, if we had the motivation, we could certainly create
an ML that presents a "secure buffer" data type that cannot be copied
and that will be cleared when it is no longer in use.  Then we would
have a much stronger guarantee about "not-to-be-copied" data actually
not being copied.

@_date: 2014-04-20 20:07:21
@_author: Benjamin Kreuter 
@_subject: [Cryptography] bounded pointers in C 
Yeah but even spelled out, there is the potential for disastrous
behaviors in C++.  Here is an obvious problem that can easily become
unique_ptr bar(new Foo);
unique_ptr baz(bar.get());
That kind of bug could be introduced across several modules in multiple
patches, and could easily escape even diligent reviewers.  Sure a tool
like Valgrind might pick it up -- or it might not, depending on what
code paths are executed.
The problem here is not sloppy coding.  The problem is that pointers in
C, and by extension in C++, allow you to break any abstraction.  It is
not just about array boundaries; stack frames, private class members,
control structures, etc. can all be violated.  Modern C++ helps, but it
also gives you all these escape hatches (which should really be called
landmines) and retains an enormous amount of undefined behavior that
surprises even experts with years of experience.

@_date: 2014-04-29 23:21:24
@_author: Benjamin Kreuter 
@_subject: [Cryptography] GCC bug 30475 (was Re: bounded pointers in 	C) 
Maybe so, but it is also not prohibited to remove it.  I would want this
to be optimized by my compiler:
if(x > x + 1) { /* ... */ }
Yet someone might have been using "x > x + 1" as a way to check "x ==
INT_MAX", and such an optimization would cause a problem for them.
Perhaps a language that requires arcane techniques to write safe code
should not be used for anything security sensitive.
How do you know something is a safety check?  What you are really saying
here is that compilers should never silently optimize undefined
behavior.  This is probably not possible, so at best you will have a
compiler that warns about *common* undefined behaviors that are easy to
detect (which popular compilers already can do).
If optimizers were truly *forbidden* from relying on anything that might
be undefined behavior in C, almost no good optimization would be
possible.  It is reasonable and necessary for the optimizer to leave it
up to the programmer to prevent undefined behavior.

@_date: 2014-04-30 20:59:44
@_author: Benjamin Kreuter 
@_subject: [Cryptography] GCC bug 30475 (was Re: bounded pointers in 	C) 
Right, and my point is that it is not evil for a compiler to optimize
code in ways that could cause a program to behave differently when
undefined behavior is triggered.
I might not have written that line; that line might have been a result
of other optimizations.  Here is a simple example:
 void foo(int x, int y) {
  if (x > y) {
    printf("Greater\n");
  } else {
    printf("Lesser\n");
  }
int main() {
  int x;
  scanf("%d\n", &x);
  foo(x, x+1);
  return 0;
Copy propagation (a textbook optimization) would cause "if (x > x+1)" to
appear.  If the next step is algebraic simplification (also textbook),
then the behavior of this code when x is INT_MAX will change.  In fact,
on my system GCC goes even further -- it replaces the call to "foo" with
a call to "puts:"
Yeah, and that is a *problem* that we should be trying to solve.
The way C programmers do that is by not writing programs with undefined
behavior.  Writing programs with undefined behavior is writing programs
with bugs.
assert is a way for programmers to find bugs, not a substitute for
actually performing safety checks.  Using assert instead of an explicit
check means that you think an explicit check is not needed -- that your
program would run fine without it.  There is a standard way to globally
disable asserts at compile time without touching the code at all (define
NDEBUG) and it is not at all uncommon to do so before releasing a
That is only true when the program's behavior is well-defined.  If the
behavior is undefined there are no guarantees at all.  Even a minor
change to the code generation strategy (e.g. what order function
arguments will be evaluated in) might affect undefined behavior.  There
is no reason to believe that the optimizer will not change undefined
Something important to keep in mind is that undefined behavior can be
affected by changes to other sections of code, even if those changes do
not affect any well-defined behavior.  For example:
char c[] = "abcdefghij";
int x, y, z;
x = 45;
y = 10;
z = x + y;
printf("%s %d\n", c+20, z);
return 0;
Note that we could change this so that we have "z = 55" without
intermediate variables, but the program's behavior changes on my system
even with optimization disabled (actually, it changes *only* when
optimization is disabled):
char c[] = "abcdefghij";
int z = 55;
printf("%s %d\n", c+20, z);
return 0;
That kind of basic change to a program is commonly performed by
optimizers.  Would you suggest that compilers should avoid this, or that
programmers should be warned about changes optimization stages make to
stack frames?
Again, look at the above examples.  Basic textbook optimizations would
be crippled if the optimizer could not change undefined behavior.  I am
not sure that anything beyond peephole optimization would even be
Note that I said "anything that *might* be undefined behavior," which is
exceedingly common in C programs.  Integer arithmetic can trigger
undefined behavior.  Accessing arrays, dereferencing pointers, passing
arguments to functions, etc. all have the potential to trigger undefined
behavior.  Again, look at the examples above for evidence.
You keep referring to optimizers as saving "nanoseconds" as if we
should all believe that optimizers are just toys.  Modern optimizers do
more than shave off a few nanoseconds.  In the general case optimizers
are better at producing fast code than human beings.  Optimizers can and
do analyze code across entire programs, finding simplifications and
eliminating unnecessary code.  The difference can be very big in both
speed and program size, and it can be measured in dollars saved on
equipment, electricity, cooling, etc.

@_date: 2014-04-30 22:39:55
@_author: Benjamin Kreuter 
@_subject: [Cryptography] GCC bug 30475 (was Re: bounded pointers in 	C) 
============================== START ==============================
Actually the assumption holds for all defined behavior; it may fail for
undefined behavior.  Undefined behavior is undefined; the optimizer can
safely ignore it and focus only on defined behavior.
Right, but that is not what we are talking about here.  We are talking
about bugs that arise because of the assumption that undefined behavior
is defined in some particular way.
There is no "proper" implementation of undefined behavior in any
language.  It is your job as a programmer to ensure that your program's
behavior is not undefined.
Undefined behavior is not just a problem for optimization.  A change in
the code generation strategy might change undefined behavior.  A change
to the register allocator could do it.  The environment variables that
are set when your program is executed might change undefined behavior.
Undefined behavior should always be considered a bug.
You call it "over-optimizing," but I call it "textbook."  Eliminating
the "if" statement in my example would happen with basic optimization
techniques that you can read about in a typical compilers text.

@_date: 2014-08-04 17:41:44
@_author: Benjamin Kreuter 
@_subject: [Cryptography] ADMIN: Periodic reminder about top posting 
Really?  Outside of technical mailing lists and Usenet, almost everyone
I correspond with top posts.  Even among technical people it seems like
the majority top posts.

@_date: 2014-08-12 13:46:03
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Dumb question -> 3AES? 
If you are going to say that DES was cracked, as opposed to having too
short of a key length, then you should also be saying that AES was
cracked.  In both cases there are attacks that are theoretically faster
than brute force but which are basically irrelevant in practice.
A much simpler solution is to use larger keys.  Whatever upper bound on
key size that you would feel comfortable with in your scheme could just
be the only key size we use.  The overfunded agency will spend just as
much time trying to build a machine that can factor keys up to that
maximum size either way.
Would you really want that added complexity in your crypto software?  I
think the lesson to be learned from TLS, IPSec, etc. is to keep things
simple.  The more complexity you add the more ways things can go wrong.

@_date: 2014-08-14 18:56:50
@_author: Benjamin Kreuter 
@_subject: [Cryptography] cryptography Digest, Vol 16, Issue 11 
Are you not counting OFB, CTR, or GCM mode as "stream ciphers?"  I do
not see any meaningful distinction there.

@_date: 2014-08-14 19:20:10
@_author: Benjamin Kreuter 
@_subject: [Cryptography] cryptography Digest, Vol 16, Issue 11 
That philosophy motivated the choice of 32 rounds for Serpent:  the
authors deemed 16 rounds sufficient and chose twice as many to improve
the security margin.  Rijndael was selected for AES despite having a
smaller security margin, and one of the important reasons was
performance.  Rijndael's better performance allows it to be used in more
applications, which is a good thing.
Skipjack was meant to be used in a real-time application, so performance
was important.  It was meant to be implemented in hardware, which makes
chip area important.  The combination of those requirements makes extra
rounds very costly, and those costs have to be weighed against the
potential security advantage of extra rounds.  What makes Skipjack so
remarkable is that it has exactly the number of rounds needed to be
secure (as far as the public scrutiny has revealed), which suggests that
the NSA has highly advanced cipher design techniques (no surprises

@_date: 2014-08-15 14:40:56
@_author: Benjamin Kreuter 
@_subject: [Cryptography] cryptography Digest, Vol 16, Issue 11 
How do you define "big-name?"  Does A5/1 count?
Performance is one possible reason.  It is hard to make the comparison,
but AES seems to outperform Skipjack in terms of throughput, while
achieving a higher security level.  Serpent also seems to perform better
than Skipjack.  It is possible that a lot of tweaking could yield a
faster Skipjack implementation, but I doubt that 3-Skipjack or
Skipjack-X can outperform Rijndael.  Speed and chip area matter for many
important classes of applications.
Skipjack itself is not the bounty.  There is plenty to learn from the
design of Skipjack, but it does not meet the needs of a modern general
purpose cipher (the block size is pretty small, the keys are pretty
short, it is on the slow side, etc.).  The ability to design a cipher
that so exactly achieves a security goal is what the public can learn
from NSA-designed ciphers.

@_date: 2014-08-22 16:52:26
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Cost of creating huge theft targets [Was: Cost 
That is not really a problem you can engineer around.  If you install
software updates -- and for good reasons we overwhelmingly advise
everyone to do so -- you run the risk that whoever provides those
updates will be compelled by their government to insert a backdoor.

@_date: 2014-12-03 17:31:06
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Toxic Combination 
It also needs to be secure against forwarding, since a phishing site
might simultaneously communicate with you and with the real site e.g.
forwarding (possibly modified) messages between you and the site.  That
is a complicated way to say that we need non-malleable identification.
The good news is that we know how to make NM zero-knowledge
identification protocols; the bad news is that we have yet to deploy
such things, and that is the harder problem (IMO).
I do not think a CA of any kind is needed for identification.  A
phishing site should not be any different from a non-phishing site that
was hacked.  It makes no difference who I identify myself to if it is
not possible to impersonate me.
Of course there is more to most applications than just identifying
yourself, so CAs might still be needed in real applications.  The point
is that we do not need to rely on CAs to securely authenticate users.

@_date: 2014-12-12 08:34:02
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Sony finding SHA1 collisions? 
This article seems to be saying that Sony has been using SHA1 collisions
to attack BitTorrent:
Does anyone know if that is what Sony is actually doing?  I cannot seem
to find more details after ~5 minutes of Googling.

@_date: 2014-12-22 16:23:51
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Certificates and PKI 
How is a key any different from all the files and databases websites
need to maintain backups for?  I think this is a tooling problem more
than anything else:  make it easy to back up keys, and this is less of
a problem.
Is this a worse situation than what we face with the PKI?  Right now if
my key is leaked, I am in trouble.  I am also in trouble if any CA key
is leaked, even if I take every precaution with my own key.
I am not sure this problem is necessarily insurmountable.  If I still
have access to my leaked key, I can use it to sign a new key -- such a
mechanism would be necessary anyway.  Yes the attacker can also issue a
new key and trick users who are already being attacked, but at least the
attacker cannot do anything more than that (I can stop the attacker from
compromising more users).  Sure, even after the attack is done users who
were attacked will lose access until the pin expiration, which makes
attacks somewhat more damaging, but in return we would not be reliant on
It is supposed to work like SSH.  Yes, it is possible to be compromised
by an active attacker with SSH, but there is only a small window of
opportunity for the attacker.  Not many people actually check SSH keys
when they log in for the first time, yet there are few reports of
successful MITM attacks on SSH despite its widespread use and the high
value of many SSH targets.
One of the advantages of the SSH approach is that it makes hiding MITM
attacks difficult.  The only way to know if a user will be warned is to
actually try the attack; if the attack fails the user will be warned.
Compare that to a system with a CA-like entity, where you can compromise
the CA and thus guarantee that your attack will not result in any
What we have now is not really working, so instead of asking for a
"workable" alternative perhaps we should ask for a "better" alternative.

@_date: 2014-07-27 12:42:33
@_author: Benjamin Kreuter 
@_subject: [Cryptography] propaganda on "hurdles for law enforcement" 
That is probably not going to work.  Suppose we lived in such a world
and the government established a "lawful intercept requirement."  Ten
years later all the newest software and devices on the market would have
back doors, and only a small group of hackers and activists would be
using good crypto.  Even that small group would have to use the
backdoor'd products for day-to-day things like banking.
The government has a lot of experience with phasing out products, even
when it requires coordinating individual households.  Analog TV is gone
despite the proliferation of analog receivers.  Tetraethyl lead is only
used for niche purposes like aviation, despite the fact that once upon a
time people drive cars designed for leaded fuel.  The government could
treat cryptography the same way if it wished.
Yes, do this, but bear in mind that high-minded ideals carry less weight
than fear.  Here in the USA people are convinced that dangerous
criminals are lurking behind every corner, and so it is difficult for a
politician to explain why they voted against giving more power to the
police.  People keep hearing about child abusers that use cryptography
to evade capture -- how is a politician supposed to tell people that it
is wrong to create back doors when the police are saying that back doors
would help them protect the children?
The importance of privacy and related civil rights are hard to explain
to people who never lived under the Stasi or the Securitate.  People
have trouble understanding why it is a problem for the police to receive
help from the NSA.  The immediate threat of a child predator living near
a school is easier to comprehend than the long-term danger of tyranny.
Unfortunately some of the technical arguments made in the 90s are harder
to make today.  Hushmail has hundreds of thousands of users, despite
having an obvious backdoor that has been used on numerous occasions to
respond to warrants.  Lavabit had given plaintexts to the government
several times before its spectacular shutdown.  The government can point
to these popular services as successful examples of the kind of thing it
wants, and we are left talking about hypothetical dangers.
You should write to your representatives, because that is part of the
power you have.  I am not terribly hopeful, though, as the last time I
wrote to my congressman about this issue I received a generic reply
about the importance of keeping our communities safe.

@_date: 2014-05-02 08:44:03
@_author: Benjamin Kreuter 
@_subject: [Cryptography] GCC bug 30475 (was Re: bounded pointers in 	C) 
Yeah, and once upon a time people made use of gets().  The response was
to demand that people replace gets() with fgets().  Why should the
response to this class of bug -- relying on undefined behavior in a
safety check -- be any different?
Maybe I call foo with different parameters in different places and for
maintainability I do not want to copy and paste things.  In context,
calling the function like that might make sense -- especially if it has
a more complicated body that *happens* to reduce to something simple
with (x, x+1) as arguments.
It makes no sense as a way to check for overflow, since it is dependent
on undefined behavior doing something highly specific.
Yeah and maybe you actually meant to write "foo(y, x+1)" or maybe the
call to foo was spurious.  Compilers cannot really make those kinds of
judgments.  It could be that "foo(x, x+1)" is intentional, and in some
situations that would make sense.
"x > x+1" is not a check for signed integer overflow.  Even if the
optimizer does not remove it, there is no guarantee that an overflow
would be detected by that.  A compiler might not emit the signed
arithmetic code that you expect.  What you think is "32 bit signed
arithmetic" could actually be compiled as "64 bit signed arithmetic
using a sign-extended representation," and then "x > x+1" will be false
even if X=INT_MAX.
Consider this function:
int fact(int x) {
  if (x <= 1) return 1;
  else return x * fact(x - 1);
Would you expect that to compile, or for it to be an error?  If
potentially undefined behavior is a compiler error, that code cannot
compile, since the multiplication might cause an overflow.  If you only
call the function with a small argument, the behavior is not undefined,
and it would have been a waste of time to write a version that
guarantees no overflow (better to just document the acceptable range of
"x" as a precondition).
Yes, if your code has undefined behavior it is a bug.
No, because pointers might be function arguments, functions might be
linked dynamically, etc.  There is no way for a C compiler to verify
that bounds checks occur, any more than that integers are in the proper
If your bank runs inefficient code and passes the extra operational
costs on to you, will you be comforted by the knowledge that they did
not use an optimizing compiler?
The optimizer is not removing "signed integer overflow."  It is
simplifying expressions based on how they behave under well-defined
circumstances.  Those performance gains are typically large, especially
if you write code that can assume that its preconditions are met (i.e.
that its integer arguments are within some range that will not cause
Again, even with optimization disabled the behavior of signed integer
overflows is undefined and cannot be relied on, even if your
architecture uses 2s complement representation.

@_date: 2014-11-04 18:28:50
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Security of wireless keyboards and mices. 
How different is this from the various side channels on wired keyboards
and wired mice?  Computers give off all kinds of emissions.  Sure, it is
higher power, but still milliwatts -- if your threat model includes an
adversary who can pick that up, it should probably include one who can
pick up all those other emissions too.
The more interesting question is about authentication.  I am much more
worried about an attacker that can send arbitrary keystrokes to my
computer.  This is even more concerning given the use-case for
Logitech's hardware:  a convenient little dongle that you can leave in
your laptop even when you are away from your mouse and keyboard.  If it
is not authenticated and not secure against replay attacks, the attacker
might only need to sit a few feet away from you at a cafe to completely
compromise your system.

@_date: 2014-11-04 19:52:59
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Paranoia for a Monday Morning 
Given that there is no market demand for such a thing, and increasing
demand for better security and improved privacy, the only way it will
happen is if a law is passed requiring it.  The FBI and DOJ have been
begging Congress for that law for decades, but it has not happened and I
doubt it will happen at this point.  No matter how many times the
intelligence and law enforcement agencies shout "terrorists" and "child
predators," people are more afraid of having their intimate photos
leaked than of some hypothetical terrorist attack.

@_date: 2014-11-30 21:25:38
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Toxic Combination 
The second issue is more important than the first.  In an ideal world we
would use a non-malleable zero knowledge protocol of some kind, so that
authenticating yourself to some scammer would not allow the scammer to
raid your bank account.  What is unfortunate is that such protocols are
not readily available to programmers, and so we are unlikely to see them
deployed any time soon.

@_date: 2014-10-11 12:40:24
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Cryptography, backdoors and the Second Amendment 
1. The second amendment is not without limits.  You cannot possess a
machine gun without a license, for example.  The second amendment is not
a free pass to possess or distribute arms.
2. The classification is only relevant for exporting a product from the
USA.  Nothing stops you from possessing or distributing cryptography
within the US.
Really though, that classification is an anachronism that predates PCs
and the Internet.  Instead of invoking it (which is a kind of
endorsement), we should be trying to get rid of it entirely.  We need to
make the case that cryptography is not some kind of military device, but
a necessity in a computerized society as a low-cost safeguard against
various abuses and crimes.  Calling cryptography "munitions" is as
absurd as calling combination locks "munitions," and that point needs to
be driven home.
What makes you think that laws matter when it comes to the NSA?  There
have been no consequences for the NSA's violations of the law.  They
openly ignored a court order, and nothing happened.  Their leadership
lied to Congress, and nothing happened.  They have conspired with
federal, state, and even local police forces and prosecutors to break
the law, and nothing happened.  Lawsuits are shut down in the name of
We are past the point of legal arguments.  We should think of the NSA as
we would think of the Chinese government: big, scary, actively working
to subvert computer security, and beyond the reach of the law.

@_date: 2014-10-12 12:04:15
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Cryptography, backdoors and the Second Amendment 
Interpretation is an important component of any law, including the
constitution.  Laws are not software, courts are not computers, and
nobody would want to live in a society where the law is completely
inflexible.  Laws tend to be written non-precisely, and even the bill of
rights is not so precisely as to require no interpretation at all.
As for the authority to judge, the answer is that "judges" have that
authority.  Courts exist to settle disputes about the meaning of the law
and whether or not it is being followed.  I would say that some kind of
court system is necessary for the rule of law.
Unfortunately there is not much else that can be done.  In theory
Congress could pull the plug, but that does not look terribly likely
right now.  Obviously we should advocate against this kind of behavior
whenever possible, as long as it remains legal to do so.
Beyond that, the public cryptography community needs to design systems
with the understanding that this kind of adversary exists.  Yes, the NSA
is actively sabotaging our work.  Now we need to design systems that are
harder to sabotage, easier to check, etc.  It is not easy and I am not
going to claim that I have a magic formula, nor am I claiming that there
is a magic formula.  What I will say is that we should be trying to
reach such a state, and that when we have a chance to move closer to
that goal we should do so.

@_date: 2014-09-04 16:46:06
@_author: Benjamin Kreuter 
@_subject: [Cryptography] List of Proven Secure Ciphers / Hashes 
Define your terms.  What do you mean by "proven secure?"  We commonly
say that e.g. ElGamal is provably secure, but:
1. That is based on an unproven assumption
2. The proof only covers chosen plaintext attacks
If you want things that can be proved without any assumptions at all you
will have to exclude most cryptographic constructions.

@_date: 2014-09-10 22:48:34
@_author: Benjamin Kreuter 
@_subject: [Cryptography] List of Proven Secure Ciphers / Hashes 
Actually it is easy to factor integers using a SAT solver.  Start with a
circuit that outputs 1 if N = P*Q and 0 otherwise, with P and Q as
inputs and N fixed to the integer you want to factor.  Now for each bit
of P, fix the bit as 0 (leaving the others unknown) and apply your SAT
solver; now you know which bits of P are 0 i.e. you know the value of P.
You can do something similar for DLOG.

@_date: 2014-09-10 23:11:29
@_author: Benjamin Kreuter 
@_subject: [Cryptography] List of Proven Secure Ciphers / Hashes 
(Technicality:  The circuit should actually output a 1 if N=P*Q and

@_date: 2014-09-23 22:16:11
@_author: Benjamin Kreuter 
@_subject: [Cryptography] new wiretap resistance in iOS 8? 
Unfortunately there are some who see no problem with this aspect of the
leaks.  In the USA we still have a lot of law-and-order/tough-on-crime
types who view civil rights as an obstacle to public safety rather than
as a protection.  There is still a lot of pressure on the police to do
more to keep everyone safe from criminals and terrorists.
It does not help that people feel less safe now than they did when crime
rates were much higher:

@_date: 2014-09-29 22:37:10
@_author: Benjamin Kreuter 
@_subject: [Cryptography] new wiretap resistance in iOS 8 
Except that the FBI has been calling attention to the so-called "going
dark" problem for years, and has failed to get much support.  The
Justice Department has been beating the "lawful interception" drum since
the clipper chip era, to no avail.  The legislation to cripple
cryptography has not materialized.  Why should we think it is any more
likely to materialize following the Snowden leak?

@_date: 2015-04-16 09:16:30
@_author: Benjamin Kreuter 
@_subject: [Cryptography] upgrade mechanisms and policies 
Suppose a tyrant rises to power a few decades from now, and starts
purging anyone who ever criticized him.  Suppose that tyrant is
currently a local politician in your town.  You probably would regret
sending unencrypted messages in which you call him a moron -- even more
so if the messages were authenticated.
My point is that deciding what is "important enough to encrypt" is
awfully difficult.  We should instead be focusing on reducing the costs
and inconvenience of encryption, so that we do not have to sit around
wondering whether or not something is "worth encrypting."  This is
nothing new but we have a long way to go and progress has been a bit

@_date: 2015-08-31 20:19:32
@_author: Benjamin Kreuter 
@_subject: [Cryptography] NSA looking for quantum-computing resistant 
More worrying.  A scalable quantum computer would mean that
cryptosystems based on RSA and discrete logarithms (and related
assumptions), including elliptic curves, could not be considered secure.
It would mean almost all of the public-key crypto in use today would
need to be replaced.
The good news is that we have candidate cryptosystems that are secure
against quantum computers.  The bad news is that in many cases it is
unclear what the real security level of those systems is and performance
is a possible concern (huge public keys and sometimes lots of
computation).  We also do not have much real-world experience with those
Also, remember that the key word is *scalable*.  There are tons of
quantum computers out there, but none of them scale to arbitrarily large
problem sizes (not counting limited computers like D-wave, since that is
irrelevant to crypto).  We know how to increase key sizes arbitrarily,
so a quantum computer that does not scale is not hard to defeat.

@_date: 2015-12-22 22:45:59
@_author: Benjamin Kreuter 
@_subject: [Cryptography] What is encryption good for? - was Re: Hillary 
Ensuring that private (intimate, sexual, etc.) photos and video chats
actually remain private, including from the government (see e.g. GCHQ
collection of Yahoo! users' video chats).
Protecting against misbehavior by ISPs and other services (e.g. privacy
violations, censorship, etc.).
Protecting against mass surveillance programs and other forms of state-
sponsored espionage.
Protecting against abuses of power by police forces e.g. surveillance
of peaceful protesters (this is unfortunately relevant not only in
places like Hong Kong, but also in Europe and the USA).
These are examples of legal and ethical reasons why people would use
end-to-end encryption or whole disk encryption, which is what the
current debate is about.

@_date: 2015-12-29 12:20:30
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Nervous Nellies want to gut the First Amendment 
...and everyone knows this and therefore adjusts their sensitivity to
Internet postings.  There is a pretty well-developed notion among the
general public that skepticism is the default for things said online.
It does not apply, end of discussion.  US law, including the
constitution, ends at the US border.  This is a common source of
confusion for my fellow Americans, which is why US passports have to
include a page reminding people of that fact.

@_date: 2015-12-29 13:06:25
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Senators: Time for Pre-crime 
What Burr et al. are doing is, in a subtle way, dismissing the experts;
when the experts conclude something that these senators do not like,
they just call in another panel of experts and dismiss the previous
conclusions.  It is basically "ask mom, ask dad" but with matters of
national security.

@_date: 2015-02-16 17:43:36
@_author: Benjamin Kreuter 
@_subject: [Cryptography] phishing attack again - $300m in losses? 
The browser is just one piece of the puzzle.  Another piece is hardware
tokens and NMZK identification protocols, so that a malicious site
cannot forward login credentials (which is what phishing is really about
in most cases).
At this point it is a matter of economics.  We know how to make
practical NMZK identification and there is nothing special about
hardware tokens.  Judging by the increasing interest in 2FA I think we
are almost at the point where the damage done by phishing justifies the
cost of deploying hardware tokens (both buying all that hardware and
dealing with lost/stolen/damaged tokens).
The problem with having the browser "defend itself" is that we will need
to deal with legitimate sites becoming malicious.  The entry-level
attack would be something like this:
A more sophisticated attack would try forwarding credentials in real

@_date: 2015-02-17 21:14:19
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Passwords: Perfect, except for being Flawed 
Phishing is a counterexample.  The best implementation of passwords
would still be vulnerable to phishing.  Phishing uses a tiny bit of
social engineering to exploit a fundamental flaw with passwords.  That
flaw is also exploited by keystroke loggers, people looking over your
should while you type in your password, etc.  Your password is only
secure as long as it is not copied, but it is not particularly hard to
copy a password.
Which is why passwords are never going to work in a distributed system
like the Internet.  People are not going to stop being human beings, no
matter how much we yell at them.  People are going to continue to be
tricked by phishing sites (and phishing sites are going to become more
Phishing cannot be solved with just passwords, no matter how fancy your
protocols are.  As long as people can be tricked into logging in to a
web page that looks just like their bank's web page (that is unlikely to
change any time soon), passwords will be insecure.  Any solution to
phishing is going to involve credentials that are hard to copy -- in
other words, some kind of new hardware will need to be deployed
(keyfobs, phones, smartcards, whatever).
We are almost at the point where deploying all that new hardware becomes
economically justifiable.  The rise of OTPs and SMS-based 2FA is
evidence of just how close we are.

@_date: 2015-02-23 20:44:36
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Lenovo laptops with preloaded adware and an evil 
Ah, but like any effective parasites, they have learned to cause as
little disruption as possible.  They only survive as long as their host
survives, after all.

@_date: 2015-01-16 14:35:49
@_author: Benjamin Kreuter 
@_subject: [Cryptography] FCC commissioner Pai statement on Netflix encryption 
I am not really sure what it is that he is claiming here, but he seems
to be taking issue with the use of encryption to prevent DPI.

@_date: 2015-11-01 13:01:06
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Are zero knowledge authentication systems safe? 
Actually this problem likely applies any protocol whose security
definition calls for a knowledge extractor.  You see extractors in a lot
of security definitions; ZK proofs-of-knowledge are a well-studied
The reason for this weakness is that extractors must use a combination
of rewinding and interaction to "trick" a party into revealing its
secret.  The rewinding process is equivalent to repeating a protocol
execution with a party that has no source of entropy; so the security
argument *depends* on the protocol being sensitive to poor entropy!
On the other hand there are cases where it is not clear clear how to
define security without extractors.  In other words, sometimes security
depends on high-quality sources of randomness (but we already knew that,

@_date: 2015-11-01 18:18:53
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Are zero knowledge authentication systems safe? 
Sort of; I think it is more that the proofs show *exactly* what they
claim, but the claims are very easy to misinterpret.  The typical
example is a proof of some asymptotic result that ignores polynomial
losses in security -- resulting in a system that is only secure for
completely impractical parameter sizes.  Another example that Koblitz
and Menezes bring up are security definitions that do not properly
capture real-world attack scenarios -- i.e. proving the wrong thing.
It is kind of hard to know what this statement means.  If there is no
reason to think an algorithm is secure, how can we say it was weakened?
What appears to be a weakness may actually be key to security.
Really though, as cryptography is applied to more complicated problems,
ad-hoc approaches to security are almost certainly going to become less
common.  The process by which TLS*, IPSec, SSH, etc. were designed would
be a disaster for multiparty computation (which is already seeing
real-world use and will almost certainly become more common in the near
future).  Security arguments based on *tight* reductions to some
underlying assumptions are going to be necessary if we ever want to do
more than encrypt and authenticate data.

@_date: 2015-11-17 22:57:51
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
How do we even make that determination?  People do not think about
operational security when they use their computers and software is not
even remotely intelligent enough to automate the process (and think of
all the electricity such an AI would require).
Case in point:  how does my laptop know whether or not I am dealing with
business data?  That is why we use FDE -- even if most files are not
confidential, there is no way people are going to remember to encrypt
truly sensitive files, so we just encrypt it all to leave no room for
I would expect it is nearly negligible compared to what is being spent
on other, far more questionable things.
In my country, the police have to prove that someone *is* a suspect
before they are allowed to conduct surveillance (or at least that is the
theory; in practice there are tons of exceptions and violations, *which
is why we need more encryption*).
Forcing users to choose what should be encrypted is the definition of a
bad UI.  Users are not going to think about what needs to be encrypted,
they are just going to use their computer to accomplish their tasks with
the minimal effort necessary.  If you force the choice (think Windows
Vista), you'll wind up training users to click "no" (after all, most of
the time, there is no reason to encrypt), and then when it matters
you'll see tons of mistakes.
Who is going to decide what requires authentication and what requires
encryption?  Getting programmers to use TLS *in the first place* is like
pulling teeth.  You want to force programmers to decide whether the data
needs authentication or encryption?
It is easy to predict the result:  most developers will mark nothing as
secret because they are too busy trying to get their software to work
correctly.  Again, just getting people to use TLS is an uphill battle;
adding more complexity is completely counterproductive.

@_date: 2015-11-22 22:49:27
@_author: Benjamin Kreuter 
@_subject: [Cryptography] US Congress Vows To Criminalize First Amendment 
What she is saying is that cryptographers should work with the
government -- as if that did not happen already.  Quite a few big names
in cryptography research published work on back doors and key escrow
Cryptographers generally agree on the conclusion of all that research:
For Mrs. Clinton it makes absolutely no difference whether or not any
research has been done.  All she needs is a chance to display her
leadership skills, and what better chance than two groups of people who
fundamentally disagree on an important issue (at least according to the
narrative told by the media)?  She is trying to be the voice of reason
and score a few votes.

@_date: 2015-09-15 22:42:56
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
Comey is conflating "encryption in transit" with end-to-end encryption,
so I do not think he has any point.  The point of end-to-end encryption
is that we do not trust mail servers with plaintext, regardless of what
they are doing with it.
This is not necessarily true.  You can imagine a multiparty protocol
that targets ads based on email plaintexts without revealing information
about plaintexts to an ad broker, while still ensuring that payments
occur properly.  It is all theoretical for now and there are a lot of
complexities and subtle (and not so subtle) assumptions, but at least on
paper we could do it.

@_date: 2015-09-16 08:31:29
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
The point is that nobody would know who was receiving fertilizer ads, or
since I prefer non-terrorist examples, let's go with gay nightclub ads.
As a simple example, suppose that ad targeting algorithms are not secret
and that billing is not an issue.  Then you could have each user locally
determine which ad matches the plaintext and use a private information
retrieval protocol to fetch that ad.
Of course, billing is an issue and targeting algorithms are proprietary,
so you need something better.  Imagine that there are two email users.
The two users and the broker will use a 3-party computation protocol to
both target ads and compute billing information (i.e. which advertiser
needs to pay the broker).  The broker will learn some aggregate
information e.g. that between the two users one of them saw a gay
nightclub ad, but nothing more, and the users will not know how ads are
actually targeted (other than the number of computation steps involved).
You could do the same for any number of users -- assuming the users are
willing to check their mail synchronously (though you might restrict
this to "users that happen to be logged in" or something like that).
As I said, it is all theoretical right now.  Implementing such a
protocol in practice, in a way that makes economic sense, is still a
long way off.  There are also certain assumptions hiding in all this,
like that the ad broker is not engaged in a "sibyl attack."  Again, the
point is that in theory end-to-end encryption is not incompatible with
targeted ads.

@_date: 2015-09-19 18:57:03
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
That depends on whether or not they receive output.  A secure protocol
should not allow parties that are not supposed to receive outputs to
learn anything (this follows from the real/ideal paradigm for security
For search or filtering, there is no reason the mail server should
receive any outputs.  Ad targeting is different because of the need to
charge advertisers when their ads are displayed (or clicked on, or
whatever the pricing model is).  On the other hand, if you can involve
the advertisers themselves as parties in the protocol, you can avoid
revealing anything to the mail server by using an anonymous payment
system; in that case the server would receive a payment as output, but
because of the unlinkability property the server will not know which
advertiser's payment it received (the advertisers would have to send a
payment as their inputs to the protocol, and those who did not have
their ads displayed would receive their money back as output -- so each
advertiser will know how many times their ads were shown).

@_date: 2016-04-09 10:09:27
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Text of Burr-Feinstein encryption backdoor bill 
It is worse than that; it would basically ban open source projects in
the US. Â At the end of section 3 there is a requirement that anyone who
distributes software must vet that software for compliance. Â I am
guessing that was meant to target app stores to stop people from just
downloading crypto apps, but as far as I can tell it would also cover
Github, basically all Linux distros, PyPi, etc. Â The great part is that
this provision would accomplish nothing for exactly the same reason it
was conceived: people can also host software outside of the US, and
people in the US can download software from other countries.

@_date: 2016-04-14 06:15:04
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Feinstein-Burr crypto bill introduced 
Relevant quote from Section 3, part (C):
10 (c) LICENSE DISTRIBUTORS .âA provider of remote
11 computing service or electronic communication service to
12 the public that distributes licenses for products, services,
13 applications, or software of or by a covered entity shall
14 ensure that any such products, services, applications, or
15 software distributed by such person be capable of com-
16 plying with subsection (a).
So yeah, it is meant to cover app stores generally. Â It would also
cover Linux distros, Github, etc., though given the overall technical
illiteracy of the proposal I have some doubts that Burr or Feinstein
are even aware of such things.

@_date: 2016-02-08 22:03:36
@_author: Benjamin Kreuter 
@_subject: [Cryptography] DH non-prime kills "socat" command security 
Also note that allowing people to generate their own parameters adds
complexity to protocols that are already notoriously difficult to get
right, and to their implementations which are also notoriously
difficult to get right. Â IMO it is better to choose common parameters
large enough to resist nation-state attacks, and for everyone to use
those parameters.

@_date: 2016-02-09 22:48:55
@_author: Benjamin Kreuter 
@_subject: [Cryptography] DH non-prime kills "socat" command security 
Getting the group operation right for general parameters is only part
of the story (and really, you would probably implement it this way
regardless of whether the parameters are standardized). Â You also need
to deal with the procedure for agreeing on parameters and for dealing
with bad parameters, which is where things would probably go wrong. Â At
a minimum the extra agreement steps and validation will increase the
attack surface of implementations, even if the protocol is flawless.

@_date: 2016-01-10 13:15:04
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Plan to End the Crypto War 
Except that it needs to look more than plausible to law enforcement, it
needs to convincingly satisfy their requirements.  At a minimum we know
that law enforcement requirements include real-time access and that a
judge should be the arbiter of when that access is granted.  Chaum's
proposal will remove power from judges and the need to form a consensus
among nine parties will preclude any real-time access.
Let's not go there.  If we start accusing anyone with a bad idea of
secretly trying to sabotage everything on behalf of the NSA, we are
never going to make any progress.  Everyone in this field has had bad
ideas; the constructive thing to do is to explain to everyone what was

@_date: 2016-06-14 08:23:35
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
There are various ways this is resolved in the offline pen-and-paper
case; e.g.:
* Introduce certification authorities (notaries) who assert that a
contract was signed no later than some time.
* Sign multiple copies and deposit some copies with other parties, who
can produce them on demand.
* Use certified mail or some other reliable delivery channel.
As someone pointed out earlier, the two-generals problem is inherently
hard to deal with.  People have had some awareness of this problem for
a very long time, long before the concerns of the Internet age, and
various solutions have been devised.  Treaties are signed in the
presence of witnesses and copies are sent to various countries.  The
USPS has long offered certified delivery and in some cases it is
required by law.
So for email, you would send a commitment to the signed contract to a
public mailing list or Usenet group, and if there is a dispute later
on, you can open the commitment.  The timestamps of list/Usenet
archives would prove that it was signed on or before some particular
date, and the binding property of the commitment would prevent

@_date: 2016-06-18 10:49:15
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Digital currencies 
I am not sure any electronic payment system or even a combination of
systems could replace paper money completely.  Paper money supports
offline and anonymous payments, but does so without requiring any
particular identification, registration, or secret keys.  An electronic
system likely cannot properly support this:  without identification,
"truly" offline payments cannot be secured, and identification requires
both a secret key of some kind and some kind of registration.
Really though, I do not see why the goal of any electronic payments
system should be to replace paper money.  There are some problems that
can be solved with electronic payments; other problems can be solved by
a paper money system; some can be solved by either.

@_date: 2016-06-20 20:02:15
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Digital currencies 
Ignoring, of course, the massive difference in scale here.  Bitcoin
does not even come close to the total number of transactions that even
a small credit card processor will handle in a given day.
What makes you think that Bitcoin is any different in practice?  The
overwhelming majority of Bitcoin users rely on exchanges and treat
Bitcoin as a convenient intermediate system for transacting in their
nation's currency.  Bitcoin exchanges are no different from any modern
financial institution and require all of the same infrastructure and
overhead you mentioned.
Except that Bitcoin has no particular incentive to reduce energy
consumption.  Miners only reduce their energy consumption in response
to increasing energy prices or decreasing prices of Bitcoin relative to
their nation's currency.  A technology that improves the efficiency of
mining will only result in an increased mining rate.  The only reason
it has not happened immediately with ASICs is that ASICs cannot be
produced quickly enough.
By comparison, most payment processors have every incentive to minimize
their energy consumption.  A technology that improves the efficiency of
processing payments will not result in banks doing more work, it will
result in banks consuming less energy.
Bitcoin's biggest problem is that it is trying to eliminate banks from
the monetary system.  As soon as you allow for a bank that issues
money, you can not only get a wildly more efficient system, but also a
system that has a rigorous and well-defined security model and which
supports anonymous payments, offline payments, and so forth.

@_date: 2016-06-21 17:14:26
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Digital currencies 
How do debit cards fit into this world view?  My statement is equally
true for debit cards, and even for ACH and SWIFT.  Bitcoin handles
something like 200,000 transactions per day when last I checked.  SWIFT
transmitted an average of 18,000,000 payment messages per day in 2012
and has grown since then.
Debt is a red herring here.  The issue is with processing transactions,
regardless of what those transaction represent or how those
transactions are organized.

@_date: 2016-06-24 09:22:52
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
You need to define "fully committed." After step 2 of your protocol,
Alice has a choice to make: she can output her second signature and
finish the protocol, or she can pretend she never saw Bob's message.
There is some period of time where she can make that choice; but by
that point, Bob cannot back out, since he already sent his signature.
Of course, Bob does have one signature from Alice -- but is that enough
to say that Alice agreed to the contract? If it is, then after step 1,
Bob can choose to send his signatures or to pretend he never got the
message. There is some period of time where Bob can make this choice,
but Alice cannot back out.
So, please clarify: is Alice's first signature enough to say that she
signed the contract, or is the contract invalid if Alice does not send
her second signature?
The issue is not whether or not signatures are valid, it is how the
parties know that their contract has been signed. In other words, at
some point each party must make a decision about whether or not the
protocol has finished and what the outcome is i.e. whether or not the
contract has been signed.
In that case Alice could cancel after Bob accepts, by pretending not to
have seen the acceptance message (the two signatures).
This is why precision is needed. The impossibility of solving the two
generals problem in the general case has been proved rigorously and is
not in doubt. It is possible that your protocol involves some different
assumption e.g. a reliable channel. Another possibility is that you are
assuming more than two parties, in which case you are dealing with
Byzantine agreement and everything will depend on how many parties are
colluding with each other. Yet another possibility is that you are
achieving a slightly different goal e.g. TCP does not actually solve
the two generals problem because it involves a timeout.
Let's suppose that neither of those caveats apply and that your
protocol does indeed achieve its apparent goal -- two parties are able
to guarantee that at every point in time the contract is either signed
by both or signed by neither, and they do not require any assumptions
about clocks, third parties, reliable links, etc. Great! Now, instead
of using TCP, what I will do is for each bit I want to send over an
unreliable channel, set up two contracts C0 and C1, and then sign C0
before C1 to represent a '0', and sign C1 before C0 to represent a '1'.
(Can I force one to be signed before the other? Of course: whatever
message I am supposed to send first in the protocol, I simply delay
until the other contract is signed.)
That would imply a solution to the two generals problem and contradict
the impossibility proof. So we know that we are not in such a
situation. That leaves us with a question: what sort of situation are
we in?
So, please, be more precise about your protocol, the assumptions you
make, the setting you are in, the definition of "signed," "committed,"
and "fair," and so forth.

@_date: 2016-03-13 13:31:12
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Is Non-interactive Zero Knowledge Proof an 
That is not true; NIZKs can also exist in the random oracle model.
Actually the CRS needs to be handed down from above, which is what
gives the CRS model its power.
The real point here is that the definition of "zero knowledge" is that
a simulator exists and that it can produce a convincing transcript of
the protocol.  In both the RO and CRS security models, the simulator
has extra power:  to simulate the RO or to generate the CRS.  That is
what makes NIZKs possible in those models, but it also undermines the
intuition behind the security definition.

@_date: 2016-03-12 22:04:59
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Is Non-interactive Zero Knowledge Proof an 
That intuition works in the standard model, but the actual definition
only requires that a simulator exists, which in other models might
violate that intuition.  For example, in the random oracle model the
simulator also simulates the random oracle itself (this is what gives
the ROM its power), so the deniability property you are describing does
not necessarily hold (the simulation might require control over the
random oracle, which no real party should have).
Here is a relevant that you might want to read:

@_date: 2016-05-03 08:57:43
@_author: Benjamin Kreuter 
@_subject: [Cryptography] WhatsApp, Curve25519 workspace etc. 
Well, if you want something larger, there are other Edwards curves you
can use; for example, Curve41417:
The nice part about modern cryptography is that you are free to choose
the security / computation cost trade-off that makes sense for you.

@_date: 2016-05-06 12:23:11
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Why two keys? [was: Re:  WhatsApp, 
Typically it is considered bad practice to use one key for two
different purposes.  Also the proof of security for encrypt-then-MAC
relies in subtle ways on the keys being different, so reusing the key
can be insecure -- certainly true for CBC-MAC when the same block
cipher is used for encryption.  Entropy is not really the issue here,
since the encryption and MAC keys can safely be generated using a PRNG.

@_date: 2016-11-05 19:04:53
@_author: Benjamin Kreuter 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
The fact that the server might be hacked is *exactly* why end-to-end
encryption is needed.  PGP is not really about protecting mail on the
wire, it is about dealing with the fact that "sending" mail really
means creating copies on multiple machines, any one of which might be
compromised, and those copies might be stored indefinitely.  Huma
Abedin just learned that lesson the hard way.
I think insider threats are not really a cryptography problem, although
certain approaches to dealing with insider threats call for some sort
of cryptography.  Modern cryptography is about dealing with the
security problems that arise when information flows across some
organizational or security boundaries.  Such problems are inherent to
any Internet-connected system and to any application that uses the
Exactly: the server is not trustworthy, simply because it is connected
to the Internet.
How would using PGP fail to move the threat needle?  If the mail on the
server was encrypted the needle would have been moved, in the sense
that hacking just one server would not give you access to anything.  If
the private keys are kept on a hardware token that requires a periodic
button press to decrypt anything, the needle moves even more (and the
usability benefits of having keys on a token are nice too).

@_date: 2016-11-06 14:46:29
@_author: Benjamin Kreuter 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
Does averting a nuclear war count?
Secrecy can certainly be abused, but the reality is that sometimes the
right thing to do is unpopular and would not be doable without some
Even ignoring extreme examples there is the fact that diplomacy often
involves a mix of repressive and democratic governments.  The
repressive governments will keep their negotiations with other
repressive governments secret; if the democratic governments did not,
it would put repressive regimes at an advantage.
Basically, the only world in which radical transparency would work is a
world in which nobody ever breaks any rules.  It is hard to imagine
something further from the world of diplomatic relations.

@_date: 2016-11-07 21:18:40
@_author: Benjamin Kreuter 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
That is true but is a somewhat different issue.  It is difficult to
secure a box that has already been compromised, but it is not so
difficult (technically) to ensure that older, pre-compromise mail
remains secure (though the UI still needs a lot of work).  By analogy,
it is definitely possible for someone to steam open your letters, but
that does not allow them to look back in time and see mail you received
before they started spying.
PGP actually solves several immediate security problems.  Phishing is
much harder -- just knowing the password is not enough.  Mass
surveillance is harder -- you cannot just compromise a single server,
you need to compromise all the clients.  Older messages can remain
secret even after a successful attack.
Again, PGP is not about the wire, it is about "the node."  The most
important thing PGP does is to limit the scope of attacks to the users'
machines.  True, those machines could be attacked, but then you can
just record what the victims are typing anyway (which is basically what
the government of Vietnam did with their keyboard driver backdoor).  We
can come up with all kinds of things PGP will not protect you from, but
so what?  PGP does solve several glaring security problems with email
that are immediately relevant.
Ignoring the issue of whether Bitcoin solves that problem, or frankly
any problem, and whether or not that even is a problem in need of a
solution (i.e. let's just skip the Bitcoin economics flamewar), how are
you defining "insider threat" here?  One of the few things about
Bitcoin that actually is clear is that it is not meant to fit into some
kind of organization (anyone can join, without needing to authenticate
themselves in any way) -- so who is an "insider" and who is not?
OK, but then the attack surface is reduced from clients and servers to
just clients.  How is that not a big move of the threat needle?
Which is why carrying the key on a token is better than trying to keep
it on client machines.  In my (humble) experience one of the biggest UX
failures of PGP is that there is no easy way for people to sit down at
some random computer and read their mail.  That is how people use
email; a hardware token is one of the only good ways to align email
encryption with that usage pattern.
Maybe people would find that annoying, but I doubt it -- 2FA has been
pretty successful despite requiring people to carry around something
extra, and even if it is riskier in terms of compromise, a smartphone
could be a convenient "token."
No, and in fact the failure to even deploy 2FA (i.e. some kind of
hardware token for reading mail) has been a criticism that I have seen
even in the typically clueless media.

@_date: 2016-09-11 19:29:49
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Secure erasure in C. 
I have to wonder about the tradeoffs here.  Let's ignore for the moment
the fact that regardless of what language you use it is possible for
the host system to be copying pages of memory without your knowledge or
control.  Let's assume for the sake of argument that you could
guarantee that an array is not copied, and that when you intend to
"clear" it (e.g. overwrite it with 0s) you can really ensure that it
will be cleared.
Is it worth all the downsides of C?
Consider:  a read past the end of a buffer might cause you to copy the
very same array you thought you had "ensured" would not be copied,
potentially even to something you thought was safe to write to some
output (sound familiar?).  Sure, you can try to minimize the risk by
only having your keys be live while you need them -- unless, of course,
you are reading past end of that array while encrypting.
The problem with C, C++, and related languages is that they do not have
reliable abstractions.  You think "static volatile" means something,
but it is only a hint to your compiler; whatever guarantees you thought
you were getting can be violated by other language features.  It makes
writing secure or reliable code very difficult.
I know someone will chime in with, "But you can have buggy code in any
language!" and that is absolutely true.  The difference is that C et
al. allow for a much broader class of bugs.  For the most part, any bug
you could write in a "safer" language could also be written in C, but
many devastating bugs in C are exceedingly difficult (to the point of
impossibility) to write in "safer" languages.
As for the original point about secure erasure, you need OS support for
that regardless of what language you are programming in.  Your OS has
plenty of opportunities to copy memory and the only way you can stop it
is if there is a system call for doing so.  I would argue that safely
exposing such functionality to C is actually harder than it would be in
other languages.

@_date: 2017-02-21 16:47:49
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Security proofs prove non-failproof 
What is the alternative?  For something like TLS, maybe we can avoid
formal methods, but what about protocols that solve more complex
problems?  Secure multiparty computation is seeing use in more and more
real-world settings, and I would be skeptical of any MPC protocol that
did not undergo at least some formal analysis.
Yes, it is sometimes the case that fragility or complexity is added to
a protocol just to make a proof work.  That needs to be weighed against
the benefit of catching subtle flaws early, before a system has been
deployed and before there can be any real damage.  Maybe the benefits
do not justify the costs for TLS, but there is not much doubt about the
value for cryptographic protocols in general.

@_date: 2017-02-21 17:17:09
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Security proofs prove non-failproof 
This is not true.  In academic work, there are plenty of protocols that
do seemingly pointless things to make a security proof work.  One
common technique is to design the protocol so that one party will prove
a statement like, "Either I am not cheating OR I know your secret key."
 It may appear to be fragile and complicated, but it often makes
proving security easier (or maybe it prevents some real attack, and we
just do not yet know what that attack looks like).

@_date: 2017-02-25 21:21:48
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Schneier's Internet Security Agency - bad idea 
(Typically dominated by libertarians, but I'll be a proud exception.)
Except that is not the only solution to market failures.  The other
solution is to change the rules so that the market stops failing.
In this case, strict liability for security failures seems like a
reasonable approach.  IoT vendors are free to try different things, but
if their devices are hacked, they have to pay the device owners.  Let
the market figure out how to keep that damage down to a manageable
Markets are really just a way for society to deal with the problem you
described: not knowing what to do.  In general markets can only exist
in the context of a legal system that makes a market possible.  If a
market is failing, the right answer might be to change the law so that
the market succeeds.

@_date: 2017-01-15 22:00:30
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Cryptocurrency Exchange without a trusted third 
In other words, some people disagree with mainstream economics, the
modern view of money, and the modern concept of banking.  I thought we
already knew that about a certain group of Bitcoin users?
Really though, Bitcoin should not be viewed as currency.  In practice
it is just another electronic payments system; most Bitcoin users have
no interest in receiving Bitcoin payments and will almost immediately
convert what they receive into some nation's currency.  It has been
years now and Bitcoin is mature enough that we can safely put to rest
any fantasy of Bitcoin as a currency.
Bitcoin is better viewed as a consensus system.  Consensus can be used
to keep banks in check -- in fact, I have been told by people working
in the banking industry that this is exactly what has banks interested
in block chains.  Of course, Bitcoin is a massive energy sink because
it is permissionless i.e. nobody has a fixed identity, but this is not
needed for consensus or for keeping banks honest.
As for electronic payments / currency, I have said for years that
Bitcoin solves a non-problem while ignoring real problems.  A real
problem in electronic payments is the lack of anonymity, which I would
say puts persecuted minorities at risk.  Also problematic is the lack
of offline electronic payments, which raises costs (infrastructure
requirements), puts persecuted minorities at risk (e.g. of having their
transactions blocked), and is less reliable and less efficient.  We
already know how to solve all these problems on paper, so now it is a
matter of engineering.  If we could just stop worrying so much about
the existence of a central bank...

@_date: 2017-01-16 08:27:12
@_author: Benjamin Kreuter 
@_subject: [Cryptography] ZK meeting scheduling protocol? 
This is not true.  ZK is used as a building block for designing secure
computation protocols as well.

@_date: 2017-07-14 19:07:24
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Defeating timing attacks 
If we are allowed to assume special non-leaky instructions then we can
do better.  Give us an instruction that computes the AES function
without leaking anything, and we can use it to generate a garbled
circuit (which necessarily leaks nothing during its evaluation
regardless of what sort of CPU is evaluating it).  This assumes a CPU
architecture where explicit load/store instructions are not required or
 where load/store instructions are also not leaky.

@_date: 2017-07-16 06:01:18
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Defeating timing attacks 
Maybe more, but this was a theoretical exercise so I gave a theoretical
answer ;)

@_date: 2017-03-05 20:36:56
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Secret Handshake problem. 
Well, one theoretical solution would be to take whatever algorithm
verifies membership in the club (i.e. whatever information you could
reveal to prove your membership without privacy), express it as a
boolean circuit, and then use a garbled circuit protocol to evaluate it
for both parties' inputs.  Then you just need an AND gate for the
output, so that you only reveal membership when both are members, and
otherwise you reveal nothing.  A similar approach can be used for N

@_date: 2017-05-04 03:00:28
@_author: Benjamin Kreuter 
@_subject: [Cryptography] [FORGED] Re:  Escrowing keys 
That is not quite right; while the design of that equipment is decades
old, most of the parts have to be replaced periodically.  Those
machines are electromechanical and they have all the failures one would
expect of gears, levers, and vacuum tube relays.

@_date: 2017-11-06 17:21:23
@_author: Benjamin Kreuter 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy 
For a payment system, the energy needed to process a payment is the
metric that matters; the simple way to compute this is to divide the
total energy consumption of the system in a given time period by the
number of transactions processed in that period.
OK, we can revise the energy use estimates once that technology is
deployed.  We will certainly be able to estimate the transaction volume
regardless of what technology is in use.
Bitcoin is incredibly wasteful: the energy needed to defend the system
exceeds the energy needed to attack it.  We can do much better by just
accepting the existence of banks and designing systems that prevent the
banks from abusing their power.
There is no "massaging" involved here: Bitcoin consumes vast amounts of
power while processing miniscule numbers of transactions (compared to
other systems).  As I said, we can revisit that issue when "payment
channels" are more widely used, but for the time being, yes, Bitcoin is
a huge waste of energy.

@_date: 2017-11-07 20:56:29
@_author: Benjamin Kreuter 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy 
That is also wasteful.  Compare that to the energy needed to secure a
bank.  If the volume of transactions being processed grows, the energy
that is needed to secure the transactions will also grow; if the volume
shrinks, the energy needs shrink.
OK, but then for Bitcoin you would have to include all the Bitcoin
ATMs, exchanges and their energy needs, and the materials, energy, and
physical security surrounding the supply chain for mining hardware. Even then, you would still not have an apples-to-apples comparison if
you did not account for the scale at which Bitcoin operates versus that
of Visa or ACH or Swift.
And the price of Bitcoin will approximately track the number of
transactions being processed, at least as Bitcoin currently works, as
demand will increase when transaction volume increases (maybe some
other technology will change things and we can revisit all this if and
when that happens).  So we should expect to see, and in practice have
seen, the mining effort increase as the transaction volume grows.
Not entirely; the energy requirements of Bitcoin must at least equal
the effort attackers are willing to devote.  What if the reward for an
attacker exceeds the mining reward?  What if the attacker is willing to
steal electricity i.e. if the attacker does not actually pay for the
energy they use in their attack?
Right, because for the conventional financial system, the incentive is
pretty consistent: banks will always have an incentive to *reduce*
their costs and become more efficient.  If Visa could halve the energy
it spends on security and still securely process the same volume of
payments, there is no doubt that they would do so.  On the other hand,
the existence of a newer, more energy-efficient mining technology would
not actually reduce the energy consumption of Bitcoin.
Right, and yet again, Bitcoin is wasteful.  When you make an ACH
payment, the energy consumption is limited to you, your bank, the
recipient's bank, and the recipient.  With Bitcoin, enough energy must
be spent to broadcast the transaction all over the world.  Were it not
for checkpointing it would be even worse: the energy would have to
spent over and over as the chain is sent to newly installed clients.
Of course, compared to the mining cost, the broadcast cost of Bitcoin
is miniscule.  Likewise, compared to the effort devoted to fraud detect
ion and other security measures, the communication cost of ACH etc. is

@_date: 2017-11-07 21:08:17
@_author: Benjamin Kreuter 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy 
Cash is a decentralized payment system, and we already know how to
achieve the same thing cryptographically if we are willing to assume
the presence of a bank (in fact we can achieve much more than Bitcoin
in that case).  The goal of Bitcoin was originally to eliminate banks
from the monetary system; decentralized payments are merely a
consequence of that.

@_date: 2017-11-14 22:08:36
@_author: Benjamin Kreuter 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy 
...because someone trying to attack a payment system will definitely
pay their taxes, and under no circumstances would they be willing to
spend 3x the money on completing their attack.
Really, at best, the security of Bitcoin scales with the energy spent
on defense, which must always exceed the energy spent attacking the
system.  Reduce the energy spent on mining by a factor of 3, and your
security margin has been reduced by a factor of 3.

@_date: 2017-09-13 20:10:19
@_author: Benjamin Kreuter 
@_subject: [Cryptography] After Equifax pwning, 
It was not supposed to be, but, much like driver's licenses, it was
convenient.  I suspect that any government-issued identification would
wind up being used in this manner unless it was impossible (i.e.
cryptographically hard) for non-governmental entities to verify or
track.  When social security numbers were introduced, that would have
been difficult, but today we have the technology to create such things.
Not really -- it is short and hard for people to change.  Birth
certificates are cumbersome by comparison.  Driver's licenses are
something people carry with them, which is why, despite being equally
cumbersome, they wind up being widely used.
Universal ID cards are not objectionable to most people; again,
driver's licenses basically act as this in practice.  Passports are
also commonly used for this purpose.
Why?  Banks are more than capable of keeping track of their customers;
social security numbers are just one of many ways that banks do so, and
I doubt most banks would have difficulty dealing with customers not
having one.
Frankly, I would rather not have to use the same ID for both government
business like social security and for my everyday banking.  I would
rather have to deal with fewer things in the event of an ID being
compromised.  Recovery from compromise is missing from your list of
requirements; it should be considered as important as being hard to
forge, given that this system needs to be used by the general public.

@_date: 2017-09-13 22:25:10
@_author: Benjamin Kreuter 
@_subject: [Cryptography] After Equifax pwning, 
I suspect that has more to do with legal requirements (KYC laws etc.)
and the convenience of SSNs than with an actual need.  I suppose I
should clarify my statement: if banks were unable to use SSNs, I doubt
most would really have difficulty identifying their customers.  In
fact, I see this statement:
as saying that banks have enough other ways to identify their customers
that SSN fraud is not a big problem.

@_date: 2018-08-03 20:23:46
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
Except that we know how to solve that problem without all the expense
of blockchains.  You use Chaum-style e-cash that supports at least one
offline transaction "hop."  The activist group could then receive and
spend money without having to interact with the bank.  You also have
the advantage of having a payment system with a well-defined security

@_date: 2018-08-05 19:40:24
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
Which is why I said at least one offline hop.  Once you have a
certificate from the bank, your ability to use the system cannot be
revoked unless you are caught cheating.  With one offline hop, you can
receive and spend money without communicating with the bank.
Sure, the government might decide to just kill the whole system, but
how exactly is cryptocurrency different?  If the state wanted to cut
off access to Bitcoin, it could -- for example, nobody in North Korea
can access Bitcoin.
Modern banking does not work like that.  Nothing is "vaulted," it is
all just book entries until you withdraw cash, and there is no reason
it would be any different with e-cash.
Now, it is true that a state could force banks to rewrite their ledgers
and deny someone their money.  If that is something you are worried
about, you are stuck living an all-cash life; or, if e-cash were
deployed, you could use e-cash only, assuming you have the chance to
get a certificate from the bank in the first place (I think this fits
the threat model you are describing, where someone already had a bank
account and the government decided to raid it).
Perhaps cryptocurrencies also protect against these sort of abuses, but
they do so at great expense and the security model is not nearly as
well-understood as the e-cash security model.

@_date: 2018-08-06 16:00:27
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
That is not the point; the point is that you cannot actually be cut off
from the system for arbitrary reasons.  Or to put it another way, this
is the kind of decentralization that is actually useful in dealing with
the "abuse-of-power attacks" you had mentioned.
Now you are shifting the goal posts.  I suggested e-cash as a way to
defend against attacks on the users of the payment system e.g. a
government pressuring a payment process to shut down some user's
account.  If the attack you are worried about is against the payment
system itself...well, as I said elsewhere, there are no Bitcoin users
in North Korea.  A government that wants to shut down an entire payment
system can shut down the entire payment system, regardless of how the
system works.

@_date: 2018-08-06 16:11:28
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
Not true, you can create a threshold scheme if you wanted to do so.
As others have asked, what is the problem we want to solve?  The
beginning of this thread was a proposal that the problem is that the
government might target an activist group's finances.  Now it sounds
like you are talking about the government trying to attack the entire
payment system.
No, e-cash is not going to help if the government wants to forbid any
use of the system -- but neither will cryptocurrencies based on proof-
Get back to me when the Internet itself cannot be shut down by the

@_date: 2018-08-09 15:33:18
@_author: Benjamin Kreuter 
@_subject: [Cryptography] PGP -- Can someone help me understand something? 
Strictly speaking, the private key could be computed, but the amount of
time required would be so large that nobody needs to worry about it.
Here is a straightforward example using (textbook) ElGamal encryption:
Message:  M
Ciphertext:  (g^r mod P, M g^(r X) mod P)
Secret Key:  X
Clearly it is possible to find X if you know M and the ciphertext, but
doing so would require inverting a discrete logarithm.  The best known
algorithm for doing so runs in O(2^(cuberoot(N))) time, where N is the
size of the modulus P.  So by choosing P to be large (around 3072 bits)
and of the right form (e.g. P = 2 Q + 1 with P, Q both prime), we can
ensure that it would take a longer period of time than any of us need
to worry about.
The amount of work is not trivial.  If you do not believe me, you can
try it yourself; here are some numbers to work with (sorry for the bad
formatting; everything is base 10):
This is an encryption of the message '1'.  Find X.

@_date: 2018-08-09 19:19:48
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
Sorry, but I do not follow.  I will have a certificate from the bank,
signed with the bank's public key that everyone uses to verify that my
certificate is real.  I can present that certificate to whoever I am
trying to pay, and they can check that my key is not on the most recent
copy of the CRL they have (and if we really wanted to, we could have
the users distribute CRL updates to each other, so that even users who
for some reason cannot receive the CRL directly from the bank can get
updates).  For the CRL to be valid, revocations would have to include
evidence that the key was used for invalid transactions (double
So where is the part where the bank can target a specific user and deny
them the ability to use the system (assuming they had already received
a certificate at some previous point in time)?
This is not allowed by the security definition for offline e-cash as
far as I know.

@_date: 2018-08-11 08:17:48
@_author: Benjamin Kreuter 
@_subject: [Cryptography] PGP -- Can someone help me understand something? 
It sort of does, given that we can construct PKE with security against
chosen-plaintext attacks from any trapdoor one-way function (and the
proof of CPA security is a reduction to the hardness of the OWF).

@_date: 2018-02-04 15:53:54
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Do some exploits require imagination/creativity 
In theory creativity will always be needed in exploit development due
to Rice's theorem (the existence of an exploit is a non-trivial
property of a program, so simply deciding whether or not an exploit
exists is not computable).  I would expect that any advance in
automatic exploit finding will coincide with advances in code hardening
techniques or formal methods, so in the worst case we will always have
the status quo.

@_date: 2018-01-04 13:17:15
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Speculation re Intel HW cockup; 
To be clear, there are two vulnerabilities:  Meltdown and Spectre. Neither is really about x86.  Meltdown is fairly specific to Intel, and
seems to not affect AMD.  Spectre seems to affect x86 in general, as
well as ARM, and maybe also PowerPC and other higher-end architectures.
 So switching away from x86 will not get you as much as you think.
This has nothing to do with Snowden, other than the NSA likely having
discovered the attacks long before now (it is exactly the kind of side
channel attack they would love to use).  A brand new architecture would
likely be vulnerable since Spectre is based on textbook approaches that
are widely used.
It is not clear that Intel was actually aware of Meltdown until 2017,
and Intel is not the only company to develop something like ME.  If you
want an architecture that is not vulnerable you need something without
branch prediction and related performance features.  There is not much
of a market for that -- most people would rather take the risk and use
software approaches to mitigate the attack.  It is going to be a while
before new architectural patterns are developed that properly separate
speculative instructions, and it will almost certainly come at a cost.

@_date: 2018-01-09 07:51:45
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Speculation considered harmful? 
The entire point of these attacks is to turn eviction into a more
informative side effect.  Basically the line that is evicted will
depend on the value of a byte you were not supposed to be able to read
i.e. you use a value as the index in an array you can legally read.
One possible way to reduce the information revealed by evictions would
be to forbid speculative loads based on speculative results, which
would at least solve these attacks (there may be others).  To deal with
this in general you would probably need to have an entire separate
cache for speculation, with multiple such caches available to deal with
nested branches etc.

@_date: 2018-01-09 07:56:02
@_author: Benjamin Kreuter 
@_subject: [Cryptography] Speculation considered harmful? 
AFAIUI that does not deal with all variants of the attack i.e. it
solves the Meltdown problem but not the Spectre problems.  Meltdown is
much easier to exploit and needs immediate attention, but the long-term solutions should deal with Spectre as well.

@_date: 2019-01-16 13:36:34
@_author: Benjamin Kreuter 
@_subject: [Cryptography] pseudo-homomorphic encryption ?? 
Coauthor of the relevant cryptography paper here (link below).  The
project does not use homomorphic encryption; it is an interactive
protocol based on secret sharing (MPC).  The basic idea is that if
Alice has X, Bob has Y, and Catherine has Z, then we can do this:
Alice and Bob agree on a random A.
Bob and Catherine agree on a random B.
Catherine and Alice agree on a random C.
Alice sends X+A+C to the server.
Bob sends Y-A+B
Catherine sends Z-B-C
The server can now compute the sum:  (X+A+C)+(Y-A+B)+(Z-B-C)=X+Y+Z
If we can compute sums we can compute linear combinations, which is
what we need for Federated ML (basically, the training is divided into
a non-linear step that can be done on a single device, and a linear
step that requires inputs from many devices).  Most of the work that
went into the design involved optimizing for communication and dealing
with a large fraction of devices failing to complete the protocol.  Our
paper has the details (this was also published at CCS):
HE could be used here (additive homomorphic schemes are already being
used in practice in other settings), but it would still require an
interactive protocol because a threshold scheme would needed.  Our
protocol is more communication efficient than a threshold HE approach
would be according to our analysis.
We were working in a "single server" setting i.e. all the servers are
under a single party's control.  If there are servers controlled by
multiple parties you can get an even more efficient system; for
example, Prio, which is being deployed by Mozilla for gathering usage
statistics about Firefox:

@_date: 2020-04-05 13:14:06
@_author: Benjamin Kreuter 
@_subject: [Cryptography] "Zoom's end-to-end encryption isn't 
Currently users receive a URL by email, and then Zoom is launched as
needed for their platform (with the browser being used as a last resort
if no standalone app can be launched).  One very convenient aspect is
that the URL can also be added to a person's calendar, which really
helps in the "enterprise" setting.
What are the participants going to receive by email?  The real issue is
that somehow the participants need to learn each other's IP addresses
if there is no central directory service or infrastructure (e.g.
federated servers, as one has with SIP) to coordinate everything.  It
is the same peer-to-peer bootstrapping problem that people have been
working around for decades.
Which would be great if the conference host has a reliable and high-
throughput connection.  Unfortunately that is not always true, and
becomes more and more difficult as the number of participants grows. In some cases it would become hard even with fiber optic service; for
example, if a single person is presenting to 1000+ participants (i.e. a
broadcast scenario).
Actually it is functionality, which is what drives income; security is
an orthogonal concern.  The fact is that peer-to-peer video
conferencing is hard to do.  Most people have the requisite software
(netmeeting, ekiga, etc.) to do peer-to-peer video conferences, but
without at least having a directory service it is just too painful to
set up just a 1:1 chat, let alone multiparty conferences.  As for end-
to-end encryption of video conferences, it is a technically challenging
problem and there is a long history of broken protocols (including
several cases of the notorious problem of bad composition of
compression with encryption).
(Not that any of this excuses Zoom's claims about end-to-end encryption
nor their decision to roll their own cryptosystem.)
