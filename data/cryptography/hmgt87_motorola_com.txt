
@_date: 2007-11-19 12:03:11
@_author: Crawford Nathan-HMGT87 
@_subject: Adi Shamir's microprocessor bug attack 
Some important things come to mind:
1.) It isn't necessary to try an exhaustive search to prove that the
hardware multiplier works correctly.  Hardware multipliers multiply by
shifting and adding; the failure mode would be one of failure to shift,
or failure to add.  The code to test every bit in two 64 bit multiplies
is probably less than a thousand lines of C code, and involves far fewer
operations than an exhaustive search.  Testing the integer units in a
modern CPU would fall well within the time constraints required by a
typical cryptosystem implemented on a PC.
2.) The simplicity of integer hardware is such that the design can be
formally proven with a minimal amount of effort. I'm inclined to say
that it might take a competent engineer a week; an outstanding engineer
could probably do it in a day.  Given the emphasis most engineers place
on getting it right the first time, and the triviality with which
multiplication is implemented in hardware, it is quite likely that an
engineer who couldn't correctly design a multiplier would also be unable
to get their processor to work at all.  The dispatch and retirement
units of a modern CPU are far more complicated that a multiplier, and it
seems the industry has no problem with this challenge.
3.) A cryptographer suspicious of his CPU can always multiply and divide
the old-fashioned way, with a series of bit shifts and additions.
Of course, there's always the possibility that the CPU itself is
compromised; how does anyone know that Intel didn't put secret NSA
backdoors in the CPU?  One can do a lot with 135 million transistors.
Ken Thompson's Reflections on Trusting Trust is very relevant here.
Best Regards,
Nathan Crawford
-----Original Message-----
[mailto:owner-cryptography at metzdowd.com] On Behalf Of ' =JeffH '
Sent: Saturday, November 17, 2007 1:25 PM
Adi Shamir's note on a microprocessor bug attack on public key
cryptography featured in the NY Times today:
The NYT report:
Research Announcement: Microprocessor Bugs Can Be Security Disasters
[reformatted to 64 cols single-spaced]
Adi Shamir
Computer Science Department
The Weizmann Institute of Science
With the increasing word size and sophisticated optimizations of
multiplication units in modern microprocessors, it becomes increasingly
likely that they contain some undetected bugs. This was demonstrated by
the accidental discovery of the obscure Pentium division bug in the mid
1990's, and by the recent discovery of a multiplication bug in the
Microsoft Excel program. In this note we show that if some intelligence
organization discovers (or secretly plants) even one pair of integers a
and b whose product is computed incorrectly (even in a single low order
bit) by a popular microprocessor, then ANY key in ANY RSA-based security
program running on ANY one of the millions of PC's that contain this
microprocessor can be trivially broken with a single chosen message. A
similar attack can be applied to any security scheme based on discrete
logs modulo a prime, and to any security scheme based on elliptic curves
(in which we can also exploit division bugs), and thus almost all the
presently deployed public key schemes will become vulnerable to such an
attack.  The new attack (which we call a "Bug Attack") is related to the notion
of fault attacks discovered by Boneh, Demillo and Lipton in 1996, but
seems to be much more dangerous in its implications. The original fault
attack required physical possession of the computing device by the
attacker, and the deliberate injection of a transient fault by operating
this device in an unusual way (in a microwave oven, at high temperature,
with high frequency clock, or with a sudden spike in the power supply).
Such attacks are feasible against smart cards, but are much harder to
carry out against PC's. In the new bug attack, the target PC can be
located at a secure location half a world away, and the attacker has no
way of influencing its operating environment in order to trigger a
fault. In addition, millions of PC's can be attacked simultaneously,
without having to manipulate the operating environment of each one of
them individually.
We now describe the basic idea of the new attack. We assume that the RSA
decryption (or signature generation) is using the Chinese Remainder
Theorem (CRT) which speeds up the operation by a factor of 4 compared to
naive implementations, that each multiplication of big  operation by a
factor of 4 compared to naive implementations, that each multiplication
of big numbers proceeds by breaking them into the largest words which
can be handled by the native multiplier in that microprocessor
(typically 32 or 64 bits), and that all pairs of such words from the two
numbers will be multiplied in some order. Knowing the target's public
key n, the attacker can easily compute a half size number c which is
guaranteed to be between the two secret factors p and q of n. For
example, a number c which is the square root of n (rounded to the
nearest integer) always satisfies p<c<q, and any number close to c is
also likely to satisfy this condition. The attacker now chooses a
message m which is equal to c, except that two low order words in it are
replaced by a and b, and submits this "poisoned input" to the target PC.
The first step in the CRT computation is to reduce the input m modulo p
and q. Due to its choice, m will be randomized mod the smaller p, but
remain unchanged mod the larger q. The next step in RSA-CRT is always to
square the reduced inputs mod p and q, respectively. Since a and b are
unlikely to remain in the randomized value of m (mod p), the computation
mod p is likely to be correct. However, mod q the squaring operation
will contain a step in which the word a is multiplied by the word b, and
by our assumption the result will be incorrect in at least one bit.
Assuming that the rest of the two computations mod p and q will be
correct, the final result of the two exponentiations will be combined
into a single output y which is likely to be correct mod p, but
incorrect mod q. The attacker can then finish off his attack in the same
way as the original fault attack, by computing the gcd of n with y^e-m,
where e is the public exponent of the attacked RSA key. With very high
probability, this gcd will be the secret factor p of n. This completely
breaks the security of this key.  How easy is it to verify that such a single multiplication bug does not
exist in a modern  microprocessor, when its exact design is kept as a
trade secret? There are 2^128 pairs of inputs in a 64x64 bit multiplier,
so we cannot try them all in an exhaustive search. Even if we assume
that Intel had learned its lesson and meticulously verified the
correctness of its multipliers, there are many smaller manufacturers of
microprocessors who may be less careful with their design. In addition,
the problem is not limited to microprocessors: Many cellular telephones
are running RSA or elliptic curve computations on signal processors made
by TI and others, FPGA or ASIC devices can embed in their design flawed
multipliers from popular libraries of standard cell designs, and many
security programs use optimized "bignum packages" written by others
without being able to fully verify their correctness. As we have
demonstrated in this note, even a single (innocent or
intentional) bug in any one of these multipliers can lead to a huge
security disaster, which can be secretly exploited in an essentially
undetectable way by a sophisticated intelligence organization.

@_date: 2008-04-25 11:16:55
@_author: Crawford Nathan-HMGT87 
@_subject: "Designing and implementing malicious hardware" 
I suppose Ken Thompson's, "Reflections on Trusting Trust" is appropriate
here.  This kind of vulnerability has been known about for quite some
time, but did not have much relevance until the advent of ubiquitous

@_date: 2008-02-07 14:46:42
@_author: Crawford Nathan-HMGT87 
@_subject: Gutmann Soundwave Therapy 
either end of the connection restarts
Which is what makes good crypto challenging.  I think, though, that
because people can understand the concept of physical locks and keys,
that this should be carried forward...
Good security is based on something you have, something you know, and
something you are.  While the third case would be rather difficult to
reliably implement on a mass-market scale, the former two are not
difficult at all.  Especially now that USB drives and CDROMs are the
defacto media standard.
Passwords do have known weaknesses - people tend to pick easily
remembered (and easily guessed) passwords.  However, when used in
combination with an external key, the security damage is at least
partially mitigated.  A system which relied on both would probably be
more secure than one which simply relied on the user entering their
I've been floating the idea of selling keys on removable media.  The
core idea would be that if you get the user to use crypto keys in a
manner similar to the way they use physical keys, that you could avoid a
substantial amount of confusion, and would keep them from doing insecure
things.  You know, the typical weak password kind of thing.  If the user
has to physically plug in a USB stick for every secure session:
1.) It mitigates to a small degree the danger of key leakage because the
keys are only present on the system for small periods of time.
2.) It makes it easier for the user to use crypto - a weak password to
access the key database does not carry forward to a weak password for
session purposes.  That is, the user can have a weak key database
password without compromising the security of the underlying crypto used
for the session.
The problem is not that strong crypto is elusive, but rather, that using
it is often non-intuitive for the average user.  An unusable, or
error-prone crypto system is often worse than having none at all.

@_date: 2008-02-11 12:36:38
@_author: Crawford Nathan-HMGT87 
@_subject: Toshiba shows 2Mbps hardware RNG 
I'm wondering if they've considered the possibility of EMI skewing the
operation of the device, or other means of causing the device to
genearate "less than completely random" numbers.
It is certainly an interesting device; I think this would find
considerable use in communication infrastructure and high-bandwidth
applications.  As someone else mentioned, generating a single, random,
128 bit seed is not too difficult with current technology, but it
doesn't address the issue that often times you want more than just a
single key.  One of the problems with the Linux random number generator
is that it happens to be quite slow, especially if you need a lot of
Some potential uses:
1.) Secure file erasure.
2.) OTP keygen for those _really_ high security applications.
3.) Faster symmetric keyset generation.  You know, when you need to
build 32k keys...
4.) Random seeding of communication packets.
There used to be (maybe still) a TCP spoofing exploit that relied on the
timing of packets; there are also various de-anonymization attacks based
on clock skew.  With a chip like this, you could add a small, random
number to the timestamp, or even packet delay, and effectively thwart
such attacks.  Such systems need high-bandwidth, random number

@_date: 2008-01-29 14:34:47
@_author: Crawford Nathan-HMGT87 
@_subject: Dutch Transport Card Broken 
Why require contactless in the first place?
Is swiping one's card, credit-card style too difficult for the average
user?  I'm thinking two parallel copper traces on the card could be used
to power it for the duration of the swipe, with power provided by the
reader.  Why, in a billion-dollar project, one must use COTS RFIDs -
with their attendant privacy and security problems - is beyond me. A little ingenuity would have gone a long way.
-----Original Message-----
[mailto:owner-cryptography at metzdowd.com] On Behalf Of Karsten Nohl
Sent: Monday, January 28, 2008 12:41 AM
You are raising a very interesting point. The constraints under which
RFIDs and contactless smart-cards need to operate seem to vary widely
depending on the application.
The Mifare Classic cards, for example, authenticate in under 2 ms, but
wouldn't need to be that fast as you point out. Their crypto is also
very small, much smaller even than their flash memory. What good is it,
though, to have a lot of memory that is badly protected?
Last, the power consumption of the Mifare cards is certainly lower than
others, which doesn't matter, though, in the near-field where even
micro-processor based designs can operate. This is where contactless
smart-cards and RFIDs get confused often. Only for the latter ones power
consumption is a limiting constraint.
To answer your question directly: Within the limits of Mifare Classic
(48-bit cipher, 16-bit RNG), one can build a 64-bit cipher that
generates 'random' numbers internally. Within the same limits, one could
almost implement TEA which at least has undergone its share of
peer-review. Again: Trading some of the memory for this much higher
level of security would certainly have been worth it.

@_date: 2008-01-30 12:39:32
@_author: Crawford Nathan-HMGT87 
@_subject: Dutch Transport Card Broken 
> Folks on this list and its progenitors have long noted that
cryptography is a matter of economics.
Agreed, but using an insecure technology doesn't make sense from even an
economic perspective.  They spent enough money that they could have
implemented a secure system, but instead, made two fundamental errors:
1.) The cost of fraud is probably much less than the cost of the system
- 2 billion.  So, even if the system were completely secure, they still
might have been better off using paper tickets and the honor system.
seems likely that the technology was not chosen because of technical
reasons or economic reasons, but rather, because someone was familiar
with it.  Perhaps it was suggested by a politician, and his cronies made
it their mission to make it happen.  Perhaps someone thought that it
would impress visitors; maybe it was a matter of national pride.
2.) The implementation was insecure.  Yes, there were probably technical
factors involved, but for the cost of the project, they could have
implemented a secure system, using other means if necessary.  The
problem, as I see it, was not an economic one, but rather, that the
developers relied on the secrecy of the algorithm for security, rather
than the size of the key.  Even unpaid, open-source developers have
produced secure systems for far less than the Dutch spent simply because
they followed good cryptographic design guidelines.
The question about mag strip versus RFID versus physical-contact readers
is a valid one.  For 2 billion, the cost/convenience difference between
radio and contact cards would have to be rather large to justify
implementing an insecure system.  Even a swipe time of 100 ms is enough
to implement a secure solution.  I find it very unlikely that a
competent engineering firm could not implement this in a reliable,
secure, and fast manner given this project's budget.
If the assertions are correct - that the subway is used 1,000,000 times
(or by 1,000,000 people?) a year, spending 2 billion on the fare system
means approximately 2,000 per user/time.  For those math types, that's
~~5.50 per day just to pay for the fare system, not to mention the cost
of electricity, trains, maintenance, etc...  How many people spend more
than 5.50 per day on train/subway/bus fare?  This system, and its
attendant costs - though obsolete even before its inception - will
probably be amortized over a few decades.  Which is why fraud is a very
important issue.  In that time frame, it is very likely that the
criminal underground could produce, and profit from, counterfeit cards
on a large scale.  Unlike turnstyle jumpers, fraud of this kind could
easily become so widespread that the subway system operates at a
significant loss.  A turnstyle jumper is easily caught; a rider with a
cloned card is virtually undetectable (without expensive upgrades to the
system).  If this system had been securely implemented, we might be able
to know if the fraud prevention would ever have exceeded the 2 billion
cost of the system; but because it isn't, the Dutch have essentially
flushed the money into the sewer.
And, bringing economics back into the picture, the purpose of the Mifare
system is *to prevent fraud*.  I seriously doubt that such a system -
especially now that it is broken - will eliminate 2 billion worth of
fraud.  It seems the Dutch would have been better off simply issuing
paper tickets and relying on the honor system.  Most people are honest;
the purpose of the ticket system is to keep people that way.
Unfortunately, it fails from both perspectives: it isn't economically
viable, and neither is it secure.
