
@_date: 2003-09-24 08:54:11
@_author: Dirk-Willem van Gulik 
@_subject: Peppercoin Raises $4 Million in First Round Funding,  Appoints 
Actually - for amounths under 5 euro (or there about) generally a minum
fee between 0.15 and 0.35 euro kicks in. And it is not uncommon to see
rates of 10% to 15% if your transactions are consistently in the 5-15 euro
range.  So that makes 7% of the transaction regardless of size actually a
very good deal for an interesting part of the marked which is badly served
by the current US style credit card / merchant approach. Add to this
possibly different cost recovery priorities in case of fraud and it
certainly may be able to find a place to survive.
It'll serve roughly 80% of the marked, add Mac and you hit your 99% of the
desktops. More varied/important may be the server side - and I'd be
prepared to bet that any platform is supported when the volume is high
enough - down to VAX/VMS :-)
Personaly I am quite impressed by a company which in this stage of their
cycle has that many almost real customers.
:-) though I doubt that this is anyones intention - and I'd worry more
about VISA taking an interest and buying the bits they need and shelving
the parts we'd think are cool.

@_date: 2004-04-01 11:22:47
@_author: Dirk-Willem van Gulik 
@_subject: Verisign CRL single point of failure 
Though I have no particular experience with the virus-scan software; we've seen exactly
this behavior with a couple of medical app's build onto the same libraries. Once any cert
in the bundle is expired the software -insists- on checking with the CRL at startup. And it will
hang if it cannot. When it gets the info back - It does not cache the (negative) information;
nor does that seem to trigger any clever automated roll-over. We tried tricking it with flags like
'superseded' and cessationOfOperation in the reasons/cert status mask - but no avail. The
only workaround  we've found is to remove all expired certs from the system asap.
My guess it is just a bug in a library; albeit a commonly used one.

@_date: 2004-12-01 01:53:19
@_author: Dirk-Willem van Gulik 
@_subject: SSL/TLS passive sniffing 
Access to the private key of the server cert gives you the ability to do
active sniffing and in some subset of cases passive sniffing. Access to
the session key (which requires the right permissions and access to the
httpd server) gives you passive sniffing.
It is not uncommon to set this up for customers in the commercial/banking
sectors to help them comply with certain audit requirements.
Note however that in each case it requires violating the web servers
security realm and/or storing something in two places. So technically it
may make much more sense to plug a module into each webserver itself with
a sufficiently secure agregation backend to accomplish this.
However due to widely varying workflow/bisprocesses at customers I have
found myself doing both.
As a closing note - the attitude of personal towards the confidentiality
of data gathered by IDS and Firewall running departments is often a lot
different than that of those directly resp. for the biz processes due to
their different roles and responsibilities ('everyone is bad' v.s.
'customers are sacret') - which is something you want to take into

@_date: 2004-12-01 23:12:51
@_author: Dirk-Willem van Gulik 
@_subject: SSL/TLS passive sniffing 
Note that in a fair number of Certificate issuing processes common in
industry the CA (sysadmin) generates both the private key -and-
certificate, signs it and then exports both to the user their PC (usually
as part of a VPN or Single Sing on setup). I've seen situations more than
once where the 'CA' keeps a copy of both on file. Generally to ensure that
after the termination of an employeee or the loss of a laptop things 'can
be set right' again.
Suffice to say that this makes evesdropping even easier.

@_date: 2004-05-30 16:37:24
@_author: Dirk-Willem van Gulik 
@_subject: Satellite eavesdropping of 802.11b traffic 
If you assume a perfect vacuum (and note that the athmosphere is fairly opaque at 2.4 Ghz) and perfect antenna's etc - then the specific detectivity needed in space suggests a not unresonably sized (m2's) and cold antenna (below 180k) by very resonably NEP which is commercially available. Given the noise from the earth background (assuming a black body radiator) at 2.4, the Sun and the likelyhood that that largish antenna catches a fair chunk of exactly that  then you are at the edge of what would be realistic. However with some clever tricks and processing, like a phase array, you certainly should be able to at least detect that short (1-2mseconds) 100Khz wide 2.4Ghz transmisison at 0.1 watt is happening - assuming you know where to look. Listening in over a country-sized swath over a prologned periods of time is an entirely different story. Given that you then need to be at least 3-4 order's of magnitude better - and that you only get at best square root when increase the easy things like  detector size etc, at best  - my guess would be that some flying or earthbound is a heck of a lot cheaper and more realistic.
There are some good papers on Lidar and Radar detections of clouds in the 3Ghz range at 12km which should give you more of an idea of the spatial resolution you could accomplish. When looking at these - bear in mind that the 2-3kWatt used is reflected by the ice particles - so what gets back is 30-40dBZ less - and that you can use a phased locked loop amplifier easily.

@_date: 2004-10-07 08:33:48
@_author: Dirk-Willem van Gulik 
@_subject: Undergraduate wireless LAN security project? 
(Free)BSD implementation/BSD license implentation of a 802.1x stack usable
in a wireless environment where your links are rather _untrusted_ and
where even the level of trust in an the wireless nodes is not all that
high (so the more trust which can be build without even having private
keys on nodes the better) - ideally in combination with things like:
to deal with things on radio level and avoid abuse up to a certain level.
All in all quite harrd to get right from a practical ops perspective with
just the right level of security. If you need a city wide testbed - we'll
have one for you :-).

@_date: 2004-09-30 11:22:53
@_author: Dirk-Willem van Gulik 
@_subject: Customs and Excise Electronic Returns 
Right; that is often forgotten and very useful - as the dutch root PKI was
signed under rather dubious circumstances (and its safeguarding even more
circumspect) we recently guided a customer through essentially accepting
any customer key (plain, self signed or 3random rd party signed) and
simply got them into the habit of keeping lists of keys accepted (and the
mapping to -their- idea what identity it represents).
And all in all that maked things a lot more practical; and fitted
exactly with the existing paper work flow where they would accept based
on caller-ID and a password list.

@_date: 2005-07-07 20:27:56
@_author: Dirk-Willem van Gulik 
@_subject: [Forwarded] RealID: How to become an unperson. 
And you may have then noticed the interesting effect; in Germany we have
mandatory cards - carry them round always - but virtually have to show
them. And only to officials often.
In the US they have no official card - yet even the lowest clerk at the
blockbuster video asks for one...

@_date: 2005-06-09 02:34:38
@_author: Dirk-Willem van Gulik 
@_subject: encrypted tapes 
Eh - my experience is that that is where 99% of the cost is - in the whole
human procedures and vetting around it. The paper work, the auditing,
dealing with corperate power shuffles, getting 'hard' retention rules out
of the resonsible people and their conflicting advisors, etc.
We've been doing systems much like this; with the added twist that a) data
is keyed to a key matching how long its retention policy is, b) every
month or so certain private keys are destroyed as the data keyed to has
reached its limit and c) they are stored (with a recovery scheme) on
tamperproof dallas iButtons (which have a reliable clock) to make the
issues around operations (destroy at the right time) and trust (no need to
trust they key maker).
And in actual practice we do not see this in the real world. We -do- see
serious issues with the compression used inside the drives though.
Specialist can help you - and the data you get back from them can then be
decrypted. The fact that it is opaque is not a problem for those recovery

@_date: 2005-10-26 07:47:22
@_author: Dirk-Willem van Gulik 
@_subject: [smb@cs.columbia.edu: Skype security evaluation] 
You may want to read the report itself:
and perhaps section 3.2.3 (about padding) and 3.2.2 (about how RSA is
used) may help with this (and what it is used for in section 2).

@_date: 2007-12-03 12:20:26
@_author: Dirk-Willem van Gulik 
@_subject: PlayStation 3 predicts next US president 
It is getting fairly common for notaries in for example the  Netherlands to timestamp or otherwise attest that an (asset with) hash  (e.g. MD5 an) was presented to them by a person or company with such  and such credentials.
E.g. NotarSign (diginotarl.nl) its email service will attest such in  an automated fashion.
Essentially what you are getting is a notarized statement containing  the credentials as presented, the hash, a timestamp and a notarized  (backed with an Appostille of the Hague if to be used internationally)  declaration that such was presented.
Note presentation of the asset is quite optional in this process. And  for practical reasons it is quite common now in certain trade- environments to _not_ sent the actual document to NotarSign but just  the statement with an MD5* and a https URL to the Purchase Order  (where the biz. partner needs his x509 or a physical RSA token to pick  it up) - to be forwarded to the trading partners.
THIS is what makes this "tongue in cheek" example 'somewhat' relevant  for day to day workflows for those who are still using MD5s.  'Somewhat' - as ultimately in this example it is hard to argue  entirely accidental tampering. However - in some biz. sealed-bid  processes the damage is done by that time.
Keep in mind that the notary is still 'careful' -- effectively they  sign the hash -- rather than the document; and state either such (e.g.  in the case of some software/code where you do not hand over the  actual code) or state that _a_ document was presented with said hash.
The _assumption_ that there is a 1:1 mapping is one left to the  reader. Compare it to the passport/personalia -- the statement of fact  usually says that a person appeared in front of the notary which  presented... rather than Mr X submitted himself to...
*) The above example falls somewhat apart as the current message      an 'at&t 'sum', md5, SHA-256, SHA-512 and the length - and almost      ERP systems check all but the AT&T checksum.

@_date: 2007-12-05 10:55:03
@_author: Dirk-Willem van Gulik 
@_subject: PlayStation 3 predicts next US president 
Not sure - lets take a similar example - the role of Chamber of  Commerce in repetitive/renewal public tender/bid processes - who  essentially makes you use an RFC 3161 service to sign any MD5 (Well -  SHA1 is the actual default) for companies; typically a PDF or Word  document of a bid for the purpose of 'locking' in the date of  sumbission. And on unsealing day, which for tax reasons can be months  later,  the govt. entity just checks the MD5's versus the RFC3161  attest. (The reason for this time-stamping is threefold a) make it  fair between entities regardless as to how good their postal system  is, b) 'date of postoffice' is a bit buyable in some places of the  world and c) some bid processes require the digital document to be  hand delivered on sealing day to alleviate the confidentially burden  of the govt. of keeping the bids secure).
An in-house Mallory (at the bidder) may well want to tweak things a  bit and make several doctored copies with different bid levels; and  send in the one joint MD5 through the RFC3161 service.
And then depending on the information leaking/gossip of the industry -  choose later than the others which one to 'really' submit. As its  competitors, as is common in the industry, tend to get a lot less  tight lipped once the deadline has passed.
What is new is that Mallory can generate several documents with the  same MD5 with a few days of 'work'.
That endagers workflows where you assume that a party cannot  intentionally create more than one asset with has the same MD5.

@_date: 2008-12-09 07:18:59
@_author: Dirk-Willem van Gulik 
@_subject: Why the poor uptake of encrypted email?  [Was: Re: Secrets and cell phones.] 
A later follow up (s/mime; more focus on the KDC):
is IMHO more interesting - as it explores a more realistic hostile  scenario, seems to pinpoint the core security issue better; and goes  to some length to evaluate remedial steps. And it does show that a  large swath of issues in PGP are indeed solvable/solved (now)

@_date: 2008-02-14 12:49:56
@_author: Dirk-Willem van Gulik 
@_subject: Toshiba shows 2Mbps hardware RNG 
Assuming that it is impossible to introduce a bias externally and the  randomness can be specifically cryptographically qualified - and such  can be cheaply explained to an auditor - I can see a fair bit of use  to reduce the 'cost' you spend on convincing that same auditor that  your poker, roulette, etc site is fair, that you are keying all your  RSA/DH/whatever exchanges off the right randomness, etc.
I've had cases where a simple nonce (which was just required to be  different each time, so a i++ would do, not even unpredictable) ended  up being changed into some sha1() of some i++ ^ RNG -- as that was the  quicker way to get something argued live. So beeing able to wave a  magic wand over a large part of your infrastructure may be just the

@_date: 2008-02-15 13:07:21
@_author: Dirk-Willem van Gulik 
@_subject: kit to prevent computers from losing power during seizure. 
There is another interesting one there - which is just as crucial, or
perhaps even more so, and effective --
Interestingly enough - there is already enough counter measure/detection
going on that there are variants - which move the mouse slower and
identify diferently (e.g. as a graphpad) as to voil simple 'count the # of
mouse counts'

@_date: 2008-01-24 02:51:16
@_author: Dirk-Willem van Gulik 
@_subject: patent of the day 
Hmm - it is commonly mentioned that (early) hardware based trusted
computer environments store a small key (or part thereof, the other part
beeing some PIN, etc) in their tamperproof environment (wired as to be
ereased when any tampering, xraying, temp shock, etc is detected) which is
during normal operations used to decrypt some flash or disk based larger
bit of key material inside the secure environment.
The other senario is that of using a multitude of public keys (with some
organisational semantic) which are used to encrypt a backup; destruction
of a specific private key then selectively takes out a certain set of
file(s) from the backup tape without having to drag that tape out of the
vault and having to erase a small piece of it.

@_date: 2008-07-30 23:13:43
@_author: Dirk-Willem van Gulik 
@_subject: On the "randomness" of DNS 
Sorry - but something like AES(static-key) encrypt of i++ or SHA1(i++)  will pass each and everyone of those test very nicely - but with a bit  of code or silicon peeking - one can probably 'break' this with  relative ease.
I fail to see how you could evaluate this without seeing the code (and  even then - I doubt that one can properly do this -- the ?old? NSA  habit of tweaking your random generated rather than your protocol/ algorithm when they wanted your produced upgraded to export quality -  is terribly effective and very hard to spot).
Or am I missing something ?

@_date: 2008-07-30 23:14:15
@_author: Dirk-Willem van Gulik 
@_subject: On the "randomness" of DNS 
But even then - is that really 'possible' - or is this fundamentally a  black art ?

@_date: 2008-06-04 21:30:44
@_author: Dirk-Willem van Gulik 
@_subject: the joy of "enhanced" certs 
Sorry - not quite good enough. You lack that key thing to make this secure and win the war on them internet terrorists.
You totally missed the fundamental crucial and the totally aspect of your Unique Selling Proposition: it _has_ to be very very very expensive. And people have to know that it was, indeed, very very expensive.

@_date: 2008-03-16 19:31:50
@_author: Dirk-Willem van Gulik 
@_subject: delegating SSL certificates 
Agred - that (signing) in itself not important  - however in a (large)  corporate environment overall plain keys does force one to re-invent  the same kind of CA and/or CRL wheel with respect to the expiring and  the lack of a managed authority.
I recently came across two installations where ssh public keys where  used to great avail (combined with a command="" construct which would  launch various curses/IBM tn3270 user interfaces), in one case  combined with a commercial product where a x509 on a chipcard would  login and 'unlock' a users windows home directory/registry. This  system had been going on for many, many years and had seen several OS  With the advent of faster moving windows/laptops - a lot keys had been  'lost'. Some due to real loosing of a laptop; most due to automated  upgrades wiping the users transients home-directory/registry.
After a bit of scripting it seemed that for every key which had been  used in the last few weeks; a little over 8 keys where 'dormant'. A  manual quick sample confirmed that most of those where associated with  lost/retired equipment (hire/fire was a well controlled HR process).  Looking at an  authorized keys file revealed little - as few, if any,  comments where filled out.
Couple of things suprized me, and/or where a serious of an eye opener  to me:
A	Even very experienced sysadmins can make the conceptual
B	The very nature of the ssh public key (esp. when generated
C	The lack of expiry _combined_ with the lack of easily
And as an aside - as one of the organisations already had a PKI rolled  out into every nook and cranny - so using the Roumen Petrof patches  which add x509 to openssh* - has helped solve some of the worse  excesses virtually overnight.
So I'd argue that while x509, its CA's and its CRL's are a serious  pain to deal** with, and seem add little value if you assume avery  diligent and experienced operational team -- they do provide a useful  'procedural' framework and workflow-guide which is in itself very  valuable, relatively robust and are a little bit organisationally  "inherently fail-safe". The latter as you are forced to think about  expiry of the assertions, what to do when a CRL is too old and so on.
Or perhaps we're comparing apples and oranges; ssh is just a pure pub/ priv key pair -- whereas x509 is a management framework in which you  happen to also have embedded and manage a pub/priv key pair along with  a whole lot of other things.
However - as firewalls and hardening of the far-outer perimeter is  increasingly becoming ineffective, as you increasingly look at fine  grained controls close to the user and (end) applications -- we do  need to come to grips (much) better with the distributed management  tools which let us map those controls to the desired social/ organisational model they are functioning within.
*:  (and I'd love those in  openssh itself, and in solaris please :)
**: not in the least as they force you to tackle nasty organisational  questions such as who is really responsible for what; rather than let  it fester it into some ops-team 'we always did it like that' fudge.

@_date: 2008-03-17 00:24:26
@_author: Dirk-Willem van Gulik 
@_subject: [mm] delegating SSL certificates 
I think you are hitting a key point here. In a way - a CA (or some sub- CA) is less of an authority and more of a, ideally, somewhat  consistent organizational realm.
And at the same time we need to learn to, or be weaned away from, the  hardened shell perimeter ideas, that of a single super reliable root -  and start to see a CA as something like one of the Kerberos KDC's we  trust, just a NIS+ server we like, etc.

@_date: 2008-11-20 10:14:47
@_author: Dirk-Willem van Gulik 
@_subject: Raw RSA binary string and public key 'detection' 
Been looking at the Telnic (dev.telnic.org) effort.
In essence; NAPTR dns records which contain private details such as a  phone number. These are encrypted against the public keys of your  friends (so if you have 20 friends and 3 phone numbers visible to all  friends - you need 20 subdomains x 3 NAPTR entries under your 'master').
Aside from the practicality of this - given a raw RSA encrypted block  and a list of public keys - is there any risk that someone could  establish which of those public keys may have been used to create that  block ? I.e. something which would be done in bulk for large  populations; so the use of large tables and what not is quite warranted.

@_date: 2008-09-17 16:02:47
@_author: Dirk-Willem van Gulik 
@_subject: once more, with feeling. 
> ... discussion on CA/cert acceptance hurdles in the UI ....
I am just wondering if we need a dose of PGP-style reality here.
We're really seeing 3 or 4 levels of SSL/TLS happening here - and whilst
they all appear use the same technology - the assurances, UI,  regimen, 'investment' and user expectations are way different:
A)	Symbolic Locks (think bicycle locks in Amsterdam, or the little
B)	Some sort of assurance that you are talking to whom you think you
C)	Fair assurance that you are talking with whom you think
D)	Proper TLS; where both each end of the connection has a well
Unfortunately there is currently no way for the server to indicate any
of this; or the user to indicate what his or her expectations are.
So my take is that it is pretty much impossible to get the UI to do
the right thing - until it has this information* - and even then
you have a fair chunk of education left to do :).
But without it - the entire discussion is moot.
As to technical options to accomplish this - it would not be hard
to *_socialise_* a few small technical hints: i.e if it is a
straight  self-signed server, certificate, with minimal data - assume
A; case C is easy; and in case 'D' one would care enough to have
a proper set-up.
That just leaves case B - and distinguishing it from a failed C.  And
that is hard. Especially as a messy B should not compromise a C.
So I guess that needs some very clear marker from the site owner. Which
could be as simple as insisting on things like an funky DN, a CN with
the FQDN set to something like 'ad-hoc', a concept that a certificate
with just a CN, but no other O, OU, L or C fields.
And obviously one could try to boil the ocean; write a small RFC
detailing some OID to put in the certificate for case A & B :) - and
include the fewlines of openssl in the document to make your own
'B' certificate.
Key would not be the technical aspect - but socialising it with enough
webmaster folks** that there is enough of a mass to tempt them
browser boys. And that is the going to be the very hard part :)
*)  I strongly think that the current plug-ins which check if a
     certificates fingerprint is the same from multiple vantage
     points around the internet is really quite orthogonal to this
     issue. So no solace there.
**) And capitalise on the fact that they need to recreate their       as most folks seem to stick to the default 365 days.

@_date: 2009-07-15 00:05:11
@_author: Dirk-Willem van Gulik 
@_subject: HSM outage causes root CA key loss 
Unfortunately those code paths seem rarely traveled/tested between implementations and even within a single implementations fraught with caveats; so one often ends up with a (sub) CA in the same chain as the cert one wants to revoke.
 > Any other problems? Maybe something with key rollover or
 > interoperability?
Aye - and there is another area which is even less traveled than above.

@_date: 2013-12-22 22:58:02
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] RSA is dead. 
If you (or a small team) are good enough to write crypto code that has no side channels, no timing issues across the branches (or power surges twiddling coils in what seems to a fashionable manner) - then you darn well should be able to squeeze in a little channel of your own. Defence & building is always harder than a single offence or pointed destruction.
I doubt that this is a technical issue; it is a social and geopolitical one. Having some french, german and russian folks agree with their American and Chinese brethren on something is a good start.

@_date: 2013-12-23 17:05:44
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] RSA is dead. 
Op 23 dec. 2013, om 09:40 heeft Ralf Senderek  het volgende geschreven:
After thinking this over a bit - I am wondering though if the backdoor tells the whole story. It may be good to consider this in the context of
which shows that as software ages (open source or closed source) the "properties extrinsic to the software play a much greater role in the rate of vulnerability discovery than do intrinsic properties such as software quality?. And that due to a difference in their early lives; open sources ends up gradually faring better - and longer.
So if we assume that crypto code, by its nature, once implemented, is quite stable - and if we assume that the early period after the first release, open source sees (as this article argues) more stable/reliable fixes; and we add the assumption that groups of developers who are not in cahoots/from competing interests/cultures/etc are likely/desirable - then one could conclude that open source low level crypto libraries are about as ?good? as we, as an industry, know how to get.
Dw. * Abstract: Work on security vulnerabilities in software has primarily focused on three points in the software life-cycle: (1) finding and removing software defects, (2) patching or hardening software after vulnerabilities have been discovered, and (3) measuring the rate of vulnerability exploitation. This paper examines an earlier period in the software vulnerability life-cycle, starting from the release date of a version through to the disclosure of the fourth vulnerability, with a particular focus on the time from release until the very first disclosed vulnerability.
Analysis of software vulnerability data, including up to a decade of data for several versions of the most popular operating systems, server applications and user applications (both open and closed source), shows that properties extrinsic to the software play a much greater role in the rate of vulnerability discovery than do intrinsic properties such as software quality. This leads us to the observation that (at least in the first phase of a product's existence), software vulnerabilities have different properties from software defects.
We show that the length of the period after the release of a software product (or version) and before the discovery of the first vulnerability (the 'Honeymoon' period) is primarily a function of familiarity with the system. In addition, we demonstrate that legacy code resulting from code re-use is a major contributor to both the rate of vulnerability discovery and the numbers of vulnerabilities found; this has significant implications for software engineering principles and practice.

@_date: 2013-10-01 09:29:49
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: NIST 
Op 30 sep. 2013, om 05:12 heeft Christoph Anton Mitterer  het volgende geschreven:
Do keep in mind that in this case the crux is not around SHA-3 as a specification/algorithm - but about the number of bits one should use.
One aspect in all this is into what engineering culture standards (such as those created by NIST) finally land. Is it in one which is a bit insecure and just does the absolute minimum; or is it in one where practitioners have certain gut-feels - and take them as absolute minimums ?
I do note that in crypto (possibly driven by the perceived expense of too many bits) we tend to very carefully observe the various bit lengths found in 800-78-3, 800-131A , etc etc. And rarely go much beyond it*.
While in a lot of other fields - it is very common for 'run of the mill' constructions; such as when calculating a floor, wooden support beam, a joist, to take the various standards and liberally apply safety factors. A factor 10 or 20x too strong is quite common *especially* in 'consumer' constructions.  It is only when one does large/complex engineering works that you take the time to really calculate strength; and even then - a factor 2 or 3 is still very common; and barely raises an eyebrow with a cost conscious customer. So perhaps we need to look at those NIST et.al. standards in crypto and do the same - take them as a absolute minimum; but by default and routinely not feel guilty when we add a 10x or more. And at the same time evoke a certain 'feeling' of strength with our users. A supporting column can just 'look' right or too thin; a BMW car door can just make that right sound on closing***. And :) :) people like (paying for/owning) tools that look fit for purpose :) :) :).
*) and yes; compute power may have been an issue - but rarely is these days; I have a hard time measuring symmetric AES on outbound packet flows relative to all other stuff.
**) and yes; compute, interaction/UI/UX & joules may be a worry - but at the same time - CPU's have have gotten faster and clever UI's can background things or good engineers can device async/queues and what not.

@_date: 2013-10-01 18:27:54
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
Op 1 okt. 2013, om 17:59 heeft Jerry Leichter  het volgende geschreven:
Actually - do we ? I picked this example as it is one of those where this 'we know' falls apart on closer examination. Wood varies a lot; and our ratings are very rough. We drill holes through it; use hugely varying ways to glue/weld/etc. And we liberally apply safety factors everywhere; and a lot of 'otherwise it does not feel right' throughout. And in all fairness - while you can get a bunch of engineers to agree that 'it is strong enough' - they'd argue endlessly and have 'it depends' sort of answers when you ask them "how strong is it 'really'" ?
So I think you are hitting the crux of the matter - the material, like most, we work with, is not that easy to gauge. But then when we consider your example of DES:
with hindsight we can conclude that despite all this - despite all the various instutitions and interests conspiring, fighting and collaborating roughly yielded us a fair level of safety for a fair number of years - and that is roughly what we got. Sure - that relied on 'odd' things; like the s-boxes getting strengthened behind the scenes, the EFF stressing that a hardware device was 'now' cheap enough. But by and large - these where more or less done 'on time'. So I think we roughly got the minimum about right with DES. The thing which facinates/strikes me as odd - is that that is then exactly what we all implemented. Not more. Not less. No safety; no nothing. Just a bit of hand waving to how complex it all is; how hard it is to predict; so we listen to NIST* et.al. and that is it then.
*Despite* the fact that, as you so eloquently argue, the material we work with is notoriously unpredictable, finnicky and has many an uncontrolled unknown.
And any failures or issues come back to haunt us, not NIST et.al.
Agreed - and perhaps develop some routine practices around which way you layer; i.e. what is best wrapped inside which; and where do you (avoid) padding; or get the most out of IVs.
Very good point (I did not consider the PKI's at all when I wrote above.)
*: s/NIST/your local applicable standards body or politically correct regulator/g.

@_date: 2013-09-06 09:29:33
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Is ECC suspicious? 
Op 6 sep. 2013, om 01:09 heeft "Perry E. Metzger"  het volgende geschreven:
Given the use, including that of the wider security/intelligence community, I'd expect any issues to be more with very specific curves (either tweaked to be that way; or through soft means promoted/pushed/suggested those who by happenstance have an issue) that with the ECC as an algorithm/technology class. As anything deeper than a curve would assume very aligned/top-down control and little political entropy. Not something which 'just the' signal intelligence community could easily enforce on the other cats.

@_date: 2013-09-06 09:18:34
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Keeping backups (was Re: Separating concerns 
Would be interested & interesting. Been doing the same thing with on-chipcard generated public keys to to the 'reverse' - be able to wipe a part of your off-site backup store by cutting up the secret. So I think there is a general case - and I've got a gut feeling that when propably analysed some of the usual assumptions around KDFs do not quite hold (as in effect one can often cause a lot of known plaintext to be passed in).
Op 3 sep. 2013, om 17:02 heeft Phillip Hallam-Baker  het volgende geschreven:

@_date: 2013-09-15 13:48:59
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Security is a total system problem (was Re: 
Op 13 sep. 2013, om 21:23 heeft Perry E. Metzger  het volgende geschreven:
While most documents on Swift its move from something very akin to OTP (called BKE) seem no longer to be on the internet; the documents:
should give you a good introduction; and outline quite clearly what organisational issues they where (and to this day stil are) in essence trying to solve. I found them quite good readings - with a lot of (often) implicit governance requirements which have wider applicability.  And in all fairness - quite a good example of an 'open' PKi in that specific setting if you postulate you trust SWIFT only so-so as a fair/honest broker of information - yet want to keep it out of the actual money path. A separation of roles/duties which some of the internet PKI's severly lack.

@_date: 2013-09-20 10:36:19
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Cryptographic mailto: URI 
Op 19 sep. 2013, om 19:15 heeft Phillip Hallam-Baker  het volgende geschreven:
We've been experimenting with much the same. With two twists. Basic principle is the same. We use:
-	:
as to keep it short. ID is currently a ; namespace is a 2-3 char identifier. We then construct with this a 'hardcoded' zone name:
which is to have a (signed) entry for in DNS:
which is in fact a first-come, first-served secure dynamic dns updatable zone containing the public key.
Which once created allows only updating to those (still) having the private key of the public key that signed the initial claim of that . We assume that loss of a private key means one simply abandonds that entry in that namespace; and create anew; after which you update your handles in XMPP/messaging land (or in Phillip his example; Linked-In land). Part of the reason is that we thus allow id's which are tied to more anonymous/floating identifiers.
So the two twists we've made (which are not necessarily a good idea!) is that the  is really the public key its sha1 (as we're limited to RSASHA1 only throughout); and secondly we hardcode the postfixing 'fqdn-in-some-domain' you add after the .. And we're also still somewhat in look-aside validation sort of land - with respect to trust of the fqdn.tld (which is why it is currently hardcoded).
And secondly - we're clearly not protecting the the identifier we add-in without any more revealing communication. We assume a subsequent check of the public key in SIG as a followup.

@_date: 2013-09-23 10:09:28
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Cryptographic mailto: URI 
Op 20 sep. 2013, om 14:55 heeft Phillip Hallam-Baker  het volgende geschreven:
Most likely. The aim was not so much to secure an entry - but to provide a sufficiently solid bread-crum trail to the information which could be used to do so; to be able to use both 'trust on first contact' -or- a trust chain; and to provide 'low cost' yet very robust pillars that can be managed by 'untrusted' parties. Or in other words - the design focused more on a workable trust infrastructure with the governance pushed as close to the (end) user as possible; at the expense of some 'absolute default' trust (absolute  as in the sort of trust you'd get by default from 'some deity/governement/big-mega-crop says I am good/interacting with a legal entity).

@_date: 2014-06-09 06:40:20
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Aggregate signatures 
Firstly - a million private keys  is a very large number - even in todays internet day and age - it is hard to find a PKI environment that large (but for a few; such as  build-in certs on certain classes of mobile phones, the various medical cards, passports).   So getting that going - i.e. enough keys - is going to be hard.
Having said that - the current PKCS scheme (e.g. as used in S/MIME)  is not that inefficient; it is a fairly compact record of the signature with a modicum of metadata. So if you assume you are going to track at least who signed \& when - it is not a bad start. It is well below a 100 bytes for a simple signature; with over 80% taken up by the actual signature, the time stamps, the sha signed and the keyids.  You can get very close to optimum if you leave out the S/MIME Capabilities block.
And as ASN1/S-mime parsers are quite fast and forgiving - it is very easy to experiment with this.
If you are looking at combining multiple pools of people who have signed; and for some reason concatenating the them ?flat? is not an option - check out the bibtex below. We found it fairly easy to implement; but in the end settled on simply concatenating PKCS records; as it was compact; and we gained nothing from nesting/overlapping, etc (our usecase was a test with massive signing by the populous of what ?they had observed? at some point - ssl observatorium style).
author = {Micali, Silvio and Ohta, Kazuo and Reyzin, Leonid},
title = {Accountable-subgroup Multisignatures: Extended Abstract},
booktitle = {Proceedings of the 8th ACM Conference on Computer and Communications Security},
series = {CCS '01},
year = {2001},
isbn = {1-58113-385-5},
location = {Philadelphia, PA, USA},
pages = {245--254},
numpages = {10},
url = {
doi = {10.1145/501983.502017},
acmid = {502017},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {digital signature, multisignature},
author = {Okamoto, Tatsuaki},
title = {A Digital Multisignature Scheme Using Bijective Public-key Cryptosystems},
journal = {ACM Trans. Comput. Syst.},
issue_date = {Nov. 1988},
volume = {6},
number = {4},
month = nov,
year = {1988},
issn = {0734-2071},
pages = {432--441},
numpages = {10},
url = {
doi = {10.1145/48012.48246},
acmid = {48246},
publisher = {ACM},
address = {New York, NY, USA},
}    title = {Aggregate and Verifiably Encrypted Signatures from Bilinear Maps},
   author = {Dan Boneh and Craig Gentry and Ben Lynn and Hovav Shacham},
   howpublished = {Cryptology ePrint Archive, Report 2002/175},
   year = {2002},

@_date: 2014-06-20 16:30:22
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] "Is FIPS 140-2 Actively harmful to software?" 
Op 20 jun. 2014, om 15:11 heeft Ben Laurie  het volgende geschreven:
Arguably it got worse and slower.  And yes, It is very easy to rally behind this type of sentiment; the stupidity; the inefficiency of good design processes done by committee and the meagre output of their output; especially given the immense volume and quality of individual inputs. If there ever was a competition for a crap one with substandard governance - FIPS would do well in that race!
However I?d caution agains going too far and de-facto/industry wise killing it by voting with our feet.
Without FIPS (or a similar standard), no matter how low or bad, we loose ?aim?. And we?re suddenly in a world where the ?how good is it? is subject to scrutiny; questioning; and where the organizations around us are exposed to the fact that a lot of this is about sound, yet subjective, engineering judgement and trust in persons. And hence all sort of forces and adverse processes shake loose. And in the end; it is not sound engineering that wins - but power and what that power wants.
Part of the the reason for speaking up right now is driven by the various parliamentary inquiries around tunnel safety happening in here in the Netherlands. A few fairly critical and complex tunnels where designed (well) against contemporary international tunnel safety standards. They where commissioned according to these (high*) standards. In the aftermath of the Mont Blanc tunnel accident the various international standards for tunnel safety were reconsidered and revised. This led to a perceived absence of standards during the execution; and hence a top down `we never compromise on safety? sort of pressure. And the then predictable fallout on timeline, public perception, budget. And in summary in an endless cycle reminiscent of The Very Hungry Caterpillar; where a politician cannot be (ever) be re-assured by the engineers adding a safety feature; as it is not their reassurance he seeks - but the grandstanding one gets during the process of seeking and the show of power that ?demands? the costly extra.
What was interesting was that during these enquiries the lack of a standard (no matter how low or high) led to situations where even the very best engineers where forced to go on the book that they would never ?compromise?. Forgetting the core tenet of their profession - to build the best/safest *within* the confines of reality, budget, possibility, time or whatever other constraint.
In my day to day job, I, and my customers, are highly dependent on the various tokens, talismans and good blessings of these standards. No matter how crap - it is better than nothing - and provides helpful abstractions behind with a professional can re-mediate what is needed w.r.t. quality; the fact that the situation is not quite that what is covered by the rule, etc. And loss of *that* is what I fear in this post-Snowden world. That we collectively kill FIPS, NIST et.al. ? and thus invite a whole raft of powers and subversion into our profession that are *stronger* and ultimately not good for security**. So yes - 140-2 may be harmful to some patients - but it does help securing the herd.
*:  Keep in mind that the Netherlands is _flat_; tunnes do not go through mountains but are a few meters under the surface.
**: And yes - I am sure one can think of some lovely psy-ops/subversion/complot theory circular arguments here :)

@_date: 2014-06-20 16:50:22
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] GeekCrypt: A Secure Fork of TrueCrypt 
Op 20 jun. 2014, om 15:21 heeft ?????????  het volgende geschreven:
A possibly effective way of testing this would be to simply ignore license and alleged trademark; and continue very publicly and openly as a clean fork with full provenance and the original name. And see who makes what claims; and how these are backed up.
If I where a betting man - I?d place my cards on the noise of some very silent cheering on from unknown quarters,

@_date: 2014-06-21 15:55:58
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] "Is FIPS 140-2 Actively harmful to software?" 
Op 20 jun. 2014, om 18:34 heeft ianG  het volgende geschreven:
Actually - while I used a government example; to illustrate the politics - it was the large (commercial) customers I was mostly thinking off. In my experience government situations are somewhat more isolated form this as they toe specific rules and regulations; which are not as easily changed or ignored. And the politics there is much the same.

@_date: 2016-08-19 09:53:31
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Phishing Attacks - Alice, HAL and Bob 
Similar examples abound in nuclear nonproliferation research (and day to day practice!). Examples are intentionally scratching (with a steel wire brush) or splattering (with solder or metal welding blobs) the bolts closing a container and comparing photographs. The search term "safeguards" together with tamper proof and variations thereof, or the annual research progress reports of the secretariats of the international treaties(below), may be helpful when researching this generally very mature and robust field.  A field that may be of interest to this community - as it has state level actors and nations at the core of its threat model. Rather than consider these rather late in the game - as is common in the IT space. And due to the diplomatic nature of robust international treaties - reports back rather transparent on what (sophisticated) state actors are doing to keep each other collectively in check, what works and what failed. As a result -most papers are very engineering oriented and more reports from the field than theoretical. Dw.

@_date: 2017-02-17 15:33:17
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] HSMs or Intel SGX? Which is harder to hack? 
While 10k is a bit much - it is pretty common in some industries to have in the mid 1000’s in something called simbanks, poolGSM or simtrays; typically 128 or 256 cards; often fitting by two per 1U enclosure. While usually used for large GSM gateways or complex dialout (or spoofing/gatewaying things like  bulk WhatsApp / Signal bridges) - most models are quite happy with typical PKCS style simcards and a doddle to integrate with OpenSSL or OpenSC.
It is quite useful if you are doing things like encrypting/signing against some key in backup scenarios; with daily or `per retention policy’ key sets; which you then swap/take offsite on a weekly or so basis - but you do not want key/card PKI swap protocols daily or too regularly. Yet the auditor or regulator wants a single ‘non duplicatable’ key.

@_date: 2017-02-20 11:17:44
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] HSMs or Intel SGX? Which is harder to hack? 
Hmmm.. do not tell that to the cruise ships, hotel's in the Alps, remote factories, dead normal corporate phone installs in the 2nd and 3rd world (and 1st world countries with a painful incumbent telco hoarding BRI lines) or what not.  Or international B2B trade/merchant supporting banks that have to do 2FA in countries where mosts of its myriad MVO's are in essence so numerous and foreign so that direct SMC connections are too complex (e.g. no SMPP v3.4) or legally impossible to set up without a domestic presence (UCP/EMI, CIMD2).
And given this world of Something as a Service - is it not our legitimate professional duty to move slippery things like WhatsApp messaging into the cloud & nicely centralised - WAaaS is your trusted man in the middle! Assuming they are in cahoots with WhatsApp or whomever you are fooling - and not overly interested in simply selling MB's.  I find it surprising what tiny MVO's get away with - despite their somewhat conflicting business models with their upstream. I guess the remains of ancient regulation oversight and modern competition watchdog oversight of incumbents does keep some playing fields messy but fair.

@_date: 2017-01-27 14:05:25
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] HSM's to be required for Code Signing 
While I totally agree with the remainder of your points below — I am not sure that the statement that ``L2 HSMs or equivalent’’ at this level of complexity are expensive and hard to find.
Nor ar expensive devices the norm.
Just about any basic USB cryto stick or smartcard with simple USB reader will do; most exceed FIPS104-2 Level 2 and you can buy a handful (for test, deployment and production) for less than a 100$ - including a separate PIN keyboard if so desired.  Heck - most laptops (though the macbooks have lost them) these days come with a ‘free’ TPM chip certified.
The real issue is here— on the config & software management; the finicky scripts and the time&labour waste this drivers. But that is a chicken and egg problem and getting better. I now regularly encounter companies that have integrated such in their Jenkins/Hudson build chain without much ado (and, not coincidentally with MS their advice to move to HSMs - usually after some event or other).

@_date: 2017-01-27 22:37:38
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] HSM's to be required for Code Signing 
I beg to differ. I very regularly encounter situations in the field where  ISV their signing keys for run of the mill software to be deployed on typical end devices at customers (home and especially in the enterprise) is specifically targeted and copied. And as some security vendors are quite slack with their whitelisting (anything signed by the same key as the previous release is auto added without vetting who sent it in) - this is an issue.
Keep in mind that with 'agile' the 'path to the app store' or to an update site is sometimes exercised weekly, sometimes even more often - and terribly automated.
So making it routine to keep the signing keys for standard end user software on chipcards/usb tokens --EVEN-- if these are pin-less or with a pin hardcoded in a script right next to it and even if the chipcard is always plugged in; is already a significant improvement. As it is the *copy*ing that is currently quite key.
And on the positive side - I found that introducing a modicum of PIN keypad steps - e.g. a a dirt cheap low end ACR reader - is generally easy and welcomed as a process thing. People are quickly accustomed to having this somewhat formal and mind-focusing step of entering 'their' pin to approve 'the' release for auto upload to some app store. And organisationally welcome it.

@_date: 2017-01-30 11:30:25
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] HSM's to be required for Code 
Agreed. And the current APIs make things like signing a hash/blob really rather robust and cross tool compatible. So we do something rather much simpler (and this was driven not so much by security but by the need to reduce audit/compliance costs) to allow very low organisational impact of the signing of binaries - with conversely a fairly strong governance role for a human (which we really do not want to have too much unfettered access to the enterprise signing key):
Going back to code signing (in an agile/playstore/appstore world):
- We have introduced the concept of naming the final ‘ready for rollout’ release always by its sha256 — thus making it harder to guess or ‘assume’ a +1 version number indicates ‘they prolly did a new release; it smells newer, so lets push it through’ thing.
- The HSM issues signs CSRs/issues chipcards to persons in the release manager role.
- End users (release managers) use dead normal PKI (chipcards) in to sign (the hash of) a file in their standard windows/mac (s/mime) environment & tools.
- The HSM will sign any hash that it is offered provided it is signed by a key it has issued itself.  It ‘valid from’ date is 6 hours in the future during normal working days (the pre-seed and organisational processes take some 24 hours or more)
- On the older systems we use a simple counter (part of the serial); for the newer systems we copied the log proofs of the Certificate Transparency project.
- The end user gets a message from the HSM which he or she needs for the further governance process around rollot.
Most of this works well - the one issue we have is that the HSM is really rather exposed/too smart.
But it does solve the audit trail issue (at the expense of security).

@_date: 2017-01-31 15:40:32
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] [FORGED] Re: HSM's to be required for 
In this context - code signing - why would that be wrong ? If you have the common situation that some sort of governance process sees a piece of code ultimately declared fit for distribution; and this is tied to a release manager (or a cabal thereof) — why would it be inappropriate for a HSM to simply be the yes man. I.e. sign the executable hash if the release manager requests it to do so - with only a modicum of counting or audit to keep everyone honest and detecting something ‘extra’ signed within days or weeks.
As in the code signing case - it is the fact that you do not want the signing key to sit on every developers laptop; the threats w.r.t. the binary are often tackled elsewhere/are not part of what an HSM can really help with.
Or am I missing something ?

@_date: 2017-07-27 10:37:06
@_author: Dirk-Willem van Gulik 
@_subject: [Cryptography] Anyone interested in a cheap security module for 
You may want to have a quick look at `nuclear safeguard’ techniques for managing enclosures (Tamper detection for safeguards’, ’treaty monitoring'. While never perfect - it is fairly well understood and documented how `hard’ techniques such as (solder) splatter and steel-brush scratching are; and unlike the semi-clear glitter nail polish - they do not suffer from the parallax and shade issue that make automatic verification hard.
