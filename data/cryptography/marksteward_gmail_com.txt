
@_date: 2015-07-25 21:00:51
@_author: Mark Steward 
@_subject: [Cryptography] Whitening Algorithm 
has had a more important impact than tthe Turbid code, IMO.  However, this
particular section just quibbles about semantics of the words "hash
function" and "whitener".   Turbid uses a "hash function" on the output,
and stubbornly refuses to call this a whitener.
I don't quite get this concern. As I understand it, a whitener is a
signal-processing function, with the sole purpose of ensuring that an
output signal isn't repetitive. The idea of a whitener being "insecure",
mentioned in the original post, is meaningless, as it's outside its scope.
The only bias that's relevant to a whitener is DC bias.
So cryptographic hashes and CSPRNGs are both whiteners and
cryptographically secure, but the reverse is not true. And a whitener
needn't compress if entropy is low.
Is there some convention of terminology I've missed, or is whitening the
wrong word here?

@_date: 2016-11-26 13:04:18
@_author: Mark Steward 
@_subject: [Cryptography] Use of RDRAND in Haskell's TLS RNG? 
Links below taken from
Here's a diagram which shows what we're offered:
Arnold is saying that if we had access to the output of "Hardware Entropy
Source" it might be possible to verify the quality of that data, and to get
confidence that the intervening steps aren't subverted by default. As it
is, we have a black box, and there's nothing that prevents some secret
trigger wiring the DRBG input to a counter.
The black box does its own testing which is exposed by the carry flag:
The "Online Entropy Health Tests" have a 256*256bit buffer of entropy,
which is used to sanity check the input and return an error, but which
isn't exposed outside of test processors. This also means the DRNG will by
design fail and return 0 for an uncontrollable subset of inputs.
There's some more detail in
(search for "mostly stuck at 1" for an interesting point).
On Sat, Nov 26, 2016 at 5:41 AM, Viktor Dukhovni

@_date: 2016-11-29 00:48:22
@_author: Mark Steward 
@_subject: [Cryptography] OpenSSL and random 
I agree with your first three paragraphs, but your suggestions from that
point are the concern of the OS, not a library.
OpenSSL should call getrandom/getentropy/CryptGenRandom/SecRandom only. It
should not by default try to manage its own randomness pool because that
breaks silently. If necessary, clients could opt into an interface that
does this if they really need the performance.
On systems that don't support the above functions, it should refuse to
compile. The only way to make it compile would then be flags like
--with-dev-urandom, --with-dev-hwrng, --with-no-system-entropy or similar,
and they should not be defaults.
The controversy we perceive is manufactured by people who want backwards
compatibility on platforms that don't provide the right interface. Nobody
should be writing new code that tries to do magic with /dev/random or
command line operators, not software.

@_date: 2016-11-29 13:23:15
@_author: Mark Steward 
@_subject: [Cryptography] OpenSSL and random 
Are you aware that the getrandom/etc interfaces have just this blocking
Sure, if an OS decides to fix /dev/urandom so it blocks, then people
compiling for that platform can add --with-dev-urandom-its-safe-really. But
there's no way other than flags to know if you're on such a system, so if
you do any lobbying, please make it to allow both /dev/random and

@_date: 2017-07-02 22:46:07
@_author: Mark Steward 
@_subject: [Cryptography] OpenSSL CSPRNG work 
I think Watson Ladd's point will be missed so to call it out again: in the
context of this discussion, arc4random is a placeholder for ChaCha20 or
newer replacement, as it is in OpenBSD 5.5+. It doesn't mean RC4.

@_date: 2017-07-03 12:47:24
@_author: Mark Steward 
@_subject: [Cryptography] OpenSSL CSPRNG work 
Relevant man pages for OpenBSD and Linux:
FreeBSD's latest commit is "this is a bandaid that allows us to work on
switching to a more modern PRNG":

@_date: 2017-07-06 14:42:56
@_author: Mark Steward 
@_subject: [Cryptography] OpenSSL CSPRNG work 
I'm interested in what it will be needed for in the future. Why would glibc
need large amounts of good quality random shortly after first boot, in a
scenario where the owner can't provide randomness in advance?
If good randomness is really becoming critical to early startup, does it
make sense to treat it like a broken filesystem and explicitly halt?

@_date: 2017-03-01 17:26:11
@_author: Mark Steward 
@_subject: [Cryptography] Google announces practical SHA-1 collision attack 
It's all in the report PDF [1]:
faster than the second attack
physical locations...
reasonable to assume
a 2.3 GHz Xeon
four days to run on
take using a
of the same order.
If you invest in dedicated hardware you'd probably be able to provide a
hash collision service right now. The estimated global Bitcoin hash rate[2]
is currently 3-4 * 10^18 SHA-256 hashes per second, while the estimated
work for this collision is 9 * 10^18 SHA-1 hashes in total.
[1] [2]

@_date: 2017-03-01 18:29:09
@_author: Mark Steward 
@_subject: [Cryptography] Google announces practical SHA-1 collision attack 
We do, it's all in the report and referenced papers.
Performing the 110 GPU hours stage again might give you a different-looking
second block, but wouldn't change the chosen prefix or first block. The
non-linear path sounds like what you're referring to, and is dependent on

@_date: 2017-03-02 01:35:39
@_author: Mark Steward 
@_subject: [Cryptography] [FORGED] Re: Google announces practical SHA-1 
Yep, my reading is that you'd need to repeat all the work of crafting the
path, optimising, finding a suitable first block, crafting the second path,
optimising again, and then crunching to get a second block, for each
different document.
The first block isn't a one-off for a given document (they found another
suitable first block) but there's no point repeating that work if you only
want to find more collisions. The second block is the more expensive one,
though, so it's not like they fall out like gumballs.
I realise that USD 110k is a headline number - they point out that the
expected time to find a second-stage collision is 2.5 times what it took.
But even if you're really unlucky, and the first stage once converted to
GPU takes as much processing power as the second stage, we'd still only be
looking at an average of USD 550k of processing time per prefix on a
universally available resource.
I think the report makes it clear that it's a chosen-prefix attack, and
while Web PKI is less vulnerable these days, are people outside that
ecosystem as stringent about not signing subverted data? And even a
badly-designed repository might be an app store with automated validation,
or someone's reimplementation of a docker registry.

@_date: 2017-03-08 23:13:55
@_author: Mark Steward 
@_subject: [Cryptography] encrypting bcrypt hashes 
For a decent chance at unique salts, a good rule of thumb is the square of
the expected number of hashes. So if they have a million customers, use a
40-bit salt or longer. This won't protect against someone trying 1234
against all salts in the whole DB and knowing 10% will match, but it
maximises the work required to do that.
As a tedious side note, if you're using a key/pepper, you can avoid
worrying about the length of the salt by adding in the sanitised user ID
for guaranteed uniqueness. Might be an option if 16 bits is hard to change
for some reason.
But, the dirty dirty truth is that with public implementations of good
If you haven't already, I'd also check whether the security team didn't
mean just encrypting the DB at rest - the stolen backup scenario is a quick
win and easy to reason about. An attacker who can execute DB queries can
likely replace a hash with their own, and someone who gets hold of the
pepper will likely also have any key used for encrypting rows.
If you do recommend changing the hash, you need to consider the migration
path, which either involves cracking everyone's PIN, or wrapping the
current hash with another hashing step that introduces the pepper/longer
salt. As long as you use a pepper, I'd say it's safe to set the number of
rounds relatively low, although you might instead want to match the inner
one to avoid making it easy for someone who has the pepper. (I assume your
10s to do a bcrypt was just an example because there's no point burning
cycles on a 4-digit PIN - they're not valuable like passwords once cracked.)
This is straying a little from your original question, but my priority for
any system like this would be to make sure rate limiting is enforced. If
possible, it should be moved to an isolated server which just validates
PINs (and resets them with stronger authentication). This server can then
do account lockout after a very small number of tries, which would provide
a far better payoff than touching the hash. If the system's exposed to the
web, add a captcha, rate-limit authentication attempts by IP, and block
known IP anonymisation services. If you can, e.g. if the PIN reset process
is email-based, just rely on that and stop using PINs altogether.

@_date: 2017-03-11 16:53:34
@_author: Mark Steward 
@_subject: [Cryptography] encrypting bcrypt hashes 
I assumed Robin would be saying "best practice is X", and so tried to
keep my points general. There are two main issues that salts address:
1. Identical hashes, e.g. doing frequency analysis and guessing that
the most common one is "1234" or "password1". This includes eyeballing
when shoulder surfing (probably the most realistic threat in Robin's
case), and matching hashes from different systems. Any salt with a
sufficiently low probability of collisions will mitigate this attack,
but common unique keys (numeric user ID or email address) allow for
matching hashes across systems.
2. Precomputation attacks, e.g. a rainbow table of sha1 hashes. In
this case, a repeatable scheme for generating the salts is a problem,
because it allows for the work to be amortised across multiple hash
databases by doing the calculations once. Obviously bcrypt has the
variable work factor which makes rainbow tables less worthwhile, but
if you use defaults (e.g. python or ruby's 12) it's a threat to
consider. As I mentioned, if you use a pepper it masks the
predictability of the unique value so there's no feasible way to
Anyway, no bcrypt library I'm aware of recommends generating your own
salt, so my assumption here is that there's something weird going on
that limits what they can do. Unless they've misunderstood the
question and they're actually doing 16 rounds, not using 16 bits.

@_date: 2017-03-14 11:07:20
@_author: Mark Steward 
@_subject: [Cryptography] encrypting bcrypt hashes 
Something needs to be able to read that file, so there's not much
difference to a peppered hash, and rate limiting at the data layer is much
less useful for security than at the application layer.
You also still need to salt or pepper, as permuting doesn't hide
Also a single file would be opened by a very short list of processes.
Access control lists apply.  Even advisory access control can be used to
trigger alerts.
Also the number of active "open" states can also be watched.
So the OS services also come to play.
  T o m    M i t c h e l l
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2017-03-29 18:19:43
@_author: Mark Steward 
@_subject: [Cryptography] "Perpetual Encryption" 
Unpredictable data that's sent over a secure channel is still
unpredictable. Or are you saying it's difficult to set up a secure
channel without good entropy?
I'm not massively familiar with the systems that do this, but a cloud
provider is going to have a secure backplane for poking VMs, so I
imagine they'd reuse that.

@_date: 2018-05-01 00:39:45
@_author: Mark Steward 
@_subject: [Cryptography] Data erasure by erasure of a salt 
============================== START ==============================
On Mon, 30 Apr 2018, 22:39 Phillip Hallam-Baker, I don't know what DARE's goals are, or why you'd need to erase the body of
what's described as a message more efficiently than erasing the message
itself, but it sounds like you want this salt to act like a key. So why not
just store a "message body" key in a new EDS, and erase that sequence
instead? That way no implementer will get confused about the mixed purpose
of the salt or have to reason about whether it's safe.
You appear to be talking about hashes only. Where does Shor's algorithm
come into it?

@_date: 2018-06-05 00:45:01
@_author: Mark Steward 
@_subject: [Cryptography] Linear B 
Not only that, but Ventris had been working earnestly on the tablets
since 1951: June 4th was just when he circulated his 20th Work Note,
where he laid out tentative evidence of correspondences with Greek.
The groundwork for decoding the script was done almost 5 years
earlier, when Alice Kober (who isn't famed outside her field) showed
possible evidence of inflection.
Also, none of this has anything to do with cryptography. Can't these
birthday posts go in an iCal feed or something?

@_date: 2019-01-05 19:55:39
@_author: Mark Steward 
@_subject: [Cryptography] Blockchain without proof of work 
So that's effectively just HMAC(rand(117), m), truncated to 120 bits
(i.e. a birthday complexity of 60 bits). What purpose does the
obfuscation serve?
Is that this code?
  That link is to some bizarre functionality to "compress" the output by
adding the number of leading zero bytes to the versionID, which
further reduces the hash to 117 bits, and allows fingerprints from two
different versions to collide.
Your convenient Validate function isn't constant time:
  And throughout this library you've wrapped all the crypto functions in
a way that obscure their nature and leads to typos:

@_date: 2019-01-06 14:56:33
@_author: Mark Steward 
@_subject: [Cryptography] Blockchain without proof of work 
I don't mean "why use an HMAC", I mean why take 512 bits of random,
truncate them to 117 bits (by prefixing 8 constant bits and calling
P), and then stretch the output and pretend it's 512 bits? Why then
prefix content type unless you're anticipating reusing keys? And why
truncate the final output to 117 bits again, and format it like it's
something to be entered by hand, when a simple HMAC would suffice?
There must be a reason you've chosen this inscrutable structure.
I can't make sense of what you're trying to say here. The initial
zeroes are part of the hash, not leading zeroes from prime numbers or
similar. If you removed this suspicious and buggy functionality, would
that break anything?
Checking shortened fingerprints is an antipattern, as demonstrated by
GPG short key collisions. If humans need to enter hashes by hand,
something's gone very wrong already.
Are you talking about the patent from 1998? I don't see how that can
help with hash comparison.

@_date: 2019-05-01 23:08:52
@_author: Mark Steward 
@_subject: [Cryptography] Paper Link: 
1. Not related to cryptography.
2. Is this the same paper as  ?

@_date: 2019-05-03 17:51:29
@_author: Mark Steward 
@_subject: [Cryptography] Paper Link: 
Sure, some off-topic things are of general interest to the
cryptography community. However, my objection is that Cheshire's
article doesn't touch on topics a cryptographer might have experience
of, such as statistical analysis, but does make false claims about
areas they're unlikely to, including comparative linguistics, medical
history and medieval languages. His approach has been politely
rubbished by people who've become aware of it[1][2], and spamming this
list with a link to a paid-for journal is the behaviour of a crank at
Assuming it's the paper he's shared previously, he makes the nonsense
claim that a late dialect of Latin arose out of geographically
disparate substrate languages (this is the opposite to how languages
develop). To prove this, he makes a series of phonologically
impossible connections, and overfits his chosen solution about
homeopathy to it. It's is as much cryptography as Flat Earth theory is
geology, or Pizzagate is journalism.
I know it's not reasonable for moderators to make a judgement on this
sort of thing from a link to a paywall, but the VM has a long history
of attracting dabblers and charlatans who have convinced themselves of
their unique solution, and a constant stream of media attention
contributes to this. The cryptographic world won't miss out by being
in the second wave of hearing about the decipherment of the VM, once
it's been reviewed by experts in the field.
[1] [2]
