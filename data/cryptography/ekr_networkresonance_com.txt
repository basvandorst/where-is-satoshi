
@_date: 2007-12-20 12:30:47
@_author: Eric Rescorla 
@_subject: Good to see the FBI follows procedures 
Ryan Singel reports that despite the rather lax standards required for
wiretaps, some FBI agents seem to have decided that they could skip
    The revelation is the second this year showing that FBI employees
    bypassed court order requirements for phone records. In July, the
    FBI and the Justice Department Inspector General revealed the
    existence of a joint investigation into an FBI counter-terrorism
    office, after an audit found that the Communications Analysis Unit
    sent more than 700 fake emergency letters to phone companies
    seeking call records. An Inspector General spokeswoman declined to
    provide the status of that investigation, citing agency policy.
    The June 2006 e-mail (.pdf) was buried in more than 600-pages of
    FBI documents obtained by the Electronic Frontier Foundation, in a
    Freedom of Information Act lawsuit.
    The message was sent to an employee in the FBI's Operational
    Technology Division by a technical surveillance specialist at the
    FBI's Minneapolis field office -- both names were redacted from
    the documents. The e-mail describes widespread attempts to bypass
    court order requirements for cellphone data in the Minneapolis
    office.
    Remarkably, when the technical agent began refusing to cooperate,
    other agents began calling telephone carriers directly, posing as
    the technical agent to get customer cellphone records.
    Federal law prohibits phone companies from revealing customer
    information unless given a court order, or in the case of an
    emergency involving physical danger.
Singel's report is at:
   You can read the actual document:
   It's worth noting that a lot of what's going on here is device
and call tracking, not content capture, so even if you have end-to-end
crypto in your handset, it's only of modest value.

@_date: 2008-08-08 08:06:25
@_author: Eric Rescorla 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
At Fri, 8 Aug 2008 11:50:59 +0100,
Isn't this a good argument for blacklisting the keys on the client

@_date: 2008-08-08 09:57:30
@_author: Eric Rescorla 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
At Fri, 8 Aug 2008 17:31:15 +0100,
It's easy to compute all the public keys that will be generated
by the broken PRNG. The clients could embed that list and refuse
to accept any certificate containing one of them. So, this
is distinct from CRLs in that it doesn't require knowing which servers have which cert...

@_date: 2008-08-08 11:20:15
@_author: Eric Rescorla 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
At Fri, 08 Aug 2008 10:43:53 -0700,
Why do you say a couple of megabytes? 99% of the value would be
1024-bit RSA keys. There are ~32,000 such keys. If you devote an
80-bit hash to each one (which is easily large enough to give you a
vanishingly small false positive probability; you could probably get
away with 64 bits), that's 320KB.  Given that the smallest Firefox
build (Windows) is 7.1 MB, this doesn't sound like a nonstarter to me
at all, especially since the browser could download it in the
Yes, there are a number of approaches to more efficient CRL
checking, I think that's a separate issue.

@_date: 2008-08-08 13:33:18
@_author: Eric Rescorla 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
At Fri, 8 Aug 2008 15:52:07 -0400 (EDT),
I don't believe your math is correct here. Or rather, it would
be correct if there was only one bad key.
Remember, there are N bad keys and you're using a b-bit hash,
which has 2^b distinct values. If you put N' entries in the
hash table, the probability that a new key will have the
same digest as one of them is N'/(2^b). If b is sufficiently
large to make collisions rare, then N'=~N and we get To be concrete, we have 2^15 distinct keys, so, the
probability of a false positive becomes (2^15)/(2^b)=2^(b-15).
To get that probability below 1 billion, b+15 >= 30, so
you need about 45 bits. I chose 64 because it seemed to me
that a false positive probability of 2^{-48} or so was better.

@_date: 2008-08-18 09:24:33
@_author: Eric Rescorla 
@_subject: Voting machine security 
At Fri, 15 Aug 2008 11:57:38 -0400,
Without directly addressing the question of the quality of Diebold's
offerings, I actually don't think the criticism implied here is
entirely fair. If you're going to have voting machines, even precinct
count optical scanners (and because of the complexity of US elections,
hand counting is quite expensive), you likely want to machine
tabulate, and that means an EMS. Though you certainly should make
serious attempts to keep the EMS from coming in contact with outside
data (see [HRS+08] for some discussion of how difficult this actually
is), there is always some chance that there will be some
contact. Generic AV probably isn't that great at detecting or stopping
this, but it may well be better than nothing, and it's certainly an
arguable point.
More discussion at:
[HRS+08] J.A. Halderman, E. Rescorla, H. Shacham, and D. Wagner. ?You
Go to Elections with the Voting System You Have: Stop-Gap Mitigations
for Deployed Voting Systems.? In D. Dill and T. Kohno, eds.,
Proceedings of EVT 2008. USENIX/ACCURATE, July 2008.

@_date: 2008-08-20 10:31:17
@_author: Eric Rescorla 
@_subject: [p2p-hackers] IETF rejects Obfuscated TCP 
At Tue, 19 Aug 2008 20:57:33 -0700,
May I ask what you're trying to accomplish? Recall that TLS doesn't
start until a TCP connection has been established, so there's
aready a proof of the round trip.
That said, a mechanism of this type has already been described
for DTLS (RFC 4347), so no new invention would be needed.

@_date: 2008-08-20 12:28:59
@_author: Eric Rescorla 
@_subject: [p2p-hackers] IETF rejects Obfuscated TCP 
At Wed, 20 Aug 2008 11:59:48 -0700,
Well, as I stated in the original discussion on obfuscated TCP (on
TCPM), I'm not convinced that the latency problem is that severe, and
if it is there are a number of potential performance improvements one
could make to TLS before one started screwing around with TCP.

@_date: 2008-08-20 14:23:26
@_author: Eric Rescorla 
@_subject: [p2p-hackers] IETF rejects Obfuscated TCP 
At Wed, 20 Aug 2008 13:27:50 -0700,
Indeed. I'm not on p2p-hackers, so I'm reading this on cryptography at .
That's probably a reasonably accurate summary of my position.
I actually am not sure I agree with this assessment of "look little
like TLS". I haven't spent that much time on this particular
issue, but most of the schemes I've seen for optimizing out TLS round trips (e.g., FastTrack) are actually quite minor modifications to TLS.
Well, maybe, maybe not. Remember that if you're doing session
caching, the client and a server have an opportunity do do
discovery in the first handshake.

@_date: 2008-08-21 20:01:22
@_author: Eric Rescorla 
@_subject: Some notes the Debian OpenSSL PRNG bug and DHE 
Some colleagues (Hovav Shacham, Brandon Enright, Scott Yikel, and
Stefan Savage) and I have been doing some followup work on the Debian
OpenSSL PRNG bug. Perry suggested that some cryptography readers
might be interested in our preliminary analysis of the DHE angle,
which can be found here:
Also, Hovav gave a WIP on this topic at USENIX Security. The slides are at:

@_date: 2008-08-27 08:19:36
@_author: Eric Rescorla 
@_subject: Decimal encryption 
At Wed, 27 Aug 2008 17:05:44 +0200,
There are a set of techniques that allow you to encrypt elements of
arbitrary sets back onto that set. The original paper on this is:
John Black and Phillip Rogaway. Ciphers with arbitrary ?nite domains. In CT-RSA, pages 114?130, 2002. For a modern proposal to make this a NIST mode, see:
Full Disclosure: Terence Spies, the author of the FFSEM proposal,
works for Voltage, Voltage has a product based on this technology.
and I'm on Voltage's TAB and have done some work for them.

@_date: 2008-08-27 13:34:50
@_author: Eric Rescorla 
@_subject: Decimal encryption 
At Wed, 27 Aug 2008 16:10:51 -0400 (EDT),
Hmm... I'm not sure I recognize the difference between encryption
scheme and cipher. Can you elaborate?
I suppose it depends what you mean by "small" and "large".
A lot of the relevant values are things like SSNs, CCNs, etc.
which fall in the 10-20 digit category, where the Luby-Rackoff
approach is efficient. As I understand the situation, the
cycle following approach is efficient as long as the set
is reasonably close to the L-R block size. As far as dictionary attacks go, for any small domain permutation
you have to worry about table construction attacks. The only defense I know of is randomized encryption which defeats the
non-expansion requirement.
WRT to the security of the L-R construction, Spies claims that
I believe that Patarin's 2004 result [0] is relevant here, but
I'm not qualified to evaluate it. Anyway, the reference I provided
earlier [1] provides a summary of the claimed security properties
of L-R + Cycle Following.
[0] Jacques Patarin. Security of random feistel schemes with 5 or more rounds. In Matthew K. Franklin, editor, CRYPTO, volume 3152 of Lecture Notes in Computer Science, pages 106?122. Springer, 2004. [1]

@_date: 2008-08-27 22:40:20
@_author: Eric Rescorla 
@_subject: Decimal encryption 
At Thu, 28 Aug 2008 17:32:10 +1200,
[Description of reduced-range stream cipher elided]
There's noting inherently wrong with this mechanism, but like all
stream ciphers, it can't be used if you want to encrypt multiple
independent values, e.g., credit cards in a database--without
a randomizer (which implies expansion) you have the usual two-time
pad problems. A B-R style block cipher can, albeit with lookup
table issues.

@_date: 2008-12-30 17:02:35
@_author: Eric Rescorla 
@_subject: MD5 considered harmful today 
At Tue, 30 Dec 2008 11:51:06 -0800 (PST),
VeriSign says that they have already fixed RapidSSL:
   Q: How will VeriSign mitigate this problem?
   A: VeriSign has removed this vulnerability. As of shortly before this
   posting, the attack laid out this morning in Berlin cannot be
   successful against any RapidSSL certificate nor any other SSL
   Certificate that VeriSign sells under any brand.
   Q: Does that mean VeriSign has discontinued use of MD5?
   A: We have been in the process of phasing out the MD5 hashing
   algorithm for a long time now. MD5 is not in use in most VeriSign
   certificates for most applications, and until this morning our roadmap
   had us discontinuing the last use of MD5 in our customers'
   certificates before the end of January, 2009. Today's presentation
   showed how to combine MD5 collision attacks with some other clever
   bits of hacking to create a false certificate. We have discontinued
   using MD5 when we issue RapidSSL certificates, and we've confirmed
   that all other SSL Certificates we sell are not vulnerable to this
   attack. We'll continue on our path to discontinue MD5 in all end
   entity certificates by the end of January, 2009.
Incidentally, I most of the CAs names in Slide 19 are VeriSign
brands. In particular RapidSSL, RSA, Thawte, and Verisign.co.jp are
and I believe that FreeSSL is as well.

@_date: 2008-02-01 07:41:48
@_author: Eric Rescorla 
@_subject: Gutmann Soundwave Therapy 
At Fri, 01 Feb 2008 18:42:03 +1000,
DTLS: RFC 4347.

@_date: 2008-02-01 07:41:48
@_author: Eric Rescorla 
@_subject: Gutmann Soundwave Therapy 
At Fri, 01 Feb 2008 18:42:03 +1000,
DTLS: RFC 4347.

@_date: 2008-02-03 16:56:48
@_author: Eric Rescorla 
@_subject: Gutmann Soundwave Therapy 
At Sun, 03 Feb 2008 12:51:25 +1000,
For those who haven't already made up their minds, the situation with
VoIP and TCP (SSL doesn't really change the situation) is actually a
bit more complicated than this.
1. VoIP over TCP
If you have a reasonably fast loss-free channel (this isn't that
uncommon) then it doesn't actually make an enormous amount of
difference whether you're running TCP or UDP, especially if you're
running a high-bandwidth codec like G.711. It helps to turn off the
Nagle algorithm, of course, since it reduces the amount of buffering
in the sending TCP stack.
That said, any significant amount of packet loss does tend to create
some pretty significant artifacts, since you need to stall the
receiving TCP while you wait for the retransmit.  So, as a practical
matter nearly all interactive VoIP systems use UDP and some kind of
packet loss concealment (interpolation, etc.).
That's not to say that SSL/TLS is totally innocent here. The designers
of SSL/TLS *could* have chosen to design a protocol which would work
over datagram transport as well as stream transport, but they didn't.
DTLS (RFC 4347) is such a protocol. That said, if you compare DTLS to
TLS, there is a small amount of additional complexity in DTLS, so it's
arguable that it was a good design choice to go for the sweet spot of
stream transport, since that's what SSL was really intended for.
2. VoIP over DTLS
As Perry indicated in another message, you can certainly run VoIP
over DTLS, which removes the buffering and retransmit issues James is alluding to. Similarly, you could run VoIP over IPsec
(AH/ESP). However, for performance reasons, this is not the favored
approach inside IETF.
The relevant issue here is packet size. Say you're running a low bandwidth codec like G.729 at 8 kbps. If you're operating at
the commonly used 50 pps, then each packet is 160 bits == 20 bytes.
The total overhead of the IP, UDP, and RTP headers is 40 bytes,
so you're sending 60 byte packets. - If you use DTLS with AES in CBC mode, you have the 4 byte DTLS
  header, plus a 16 byte IV, plus 10 bytes of MAC (in truncated MAC
  mode), plus 2 bytes of padding to bring you up to the AES block
  boundary: DTLS adds 32 bytes of overhead, increasing packet
  size by over 50%. The IPsec situation is similar.
- If you use CTR mode and use the RTP header to form the initial
  CTR state, you can remove all the overhead but the MAC itself,
  reducing the overhead down to 10 bytes with only 17% packet
  expansion (this is how SRTP works)
Note that some (but not all) of the gain from SRTP can be obtained
by swapping CTR for CBC. But you're still getting an advantage
from being willing to overload the RTP header and that's harder
to optimize out (though Nagendra Modadugu and I spent some time
thinking about this).
I don't propose to get into an extended debate about whether it is
better to use SRTP or to use generic DTLS. That debate has already
happened in IETF and SRTP is what the VoIP vendors are doing. However,
the good news here is that you can use DTLS to key SRTP
(draft-ietf-avt-dtls-srtp), so there's no need to invent a new
key management scheme.

@_date: 2008-02-04 06:56:42
@_author: Eric Rescorla 
@_subject: Gutmann Soundwave Therapy 
At Mon, 4 Feb 2008 09:33:37 -0500 (EST),
In fact, 32-bit authentication tags are a feature of
SRTP (RFC 3711). Not sending a MAC on every packet has difficult interactions with
packet loss. If you do the naive thing and every N packets send a MAC
covering the previous N packets, then if you lose even one of those
packets you can't verify the MAC. But since some packet loss is
normal, an attacker can cover their tracks simply by removing one out
of every N packets.
Since (by definition) you don't have a copy of the packet you've lost,
you need a MAC that survives that--and is still compact. This makes
life rather more complicated. I'm not up on the most recent lossy
MACing literature, but I'm unaware of any computationally efficient
technique which has a MAC of the same size with a similar security
level. (There's an inefficient technique of having the MAC cover
all 2^50 combinations of packet loss, but that's both prohibitively
expensive and loses you significant security.)
Which there are, as indicated above and in my previous message.

@_date: 2008-02-06 14:09:24
@_author: Eric Rescorla 
@_subject: Gutmann Soundwave Therapy 
At Mon, 04 Feb 2008 14:29:50 +1000,
This paragraph sure is confused.
1. IPsec most certainly is not a successor to SSL. On
   the contrary, IPsec predates SSL.
2. TLS doesn't require you to carry around strong secrets.
   I refer you to TLS-SRP [RFC 5054]
3. For that matter, even if you ignore SRP, TLS supports
   usage models which never require you to carry around
   strong secrets: you preconfigure the server's public
   key and send a password over the TLS channel. Since
   this is the interface SSH uses, the claim that humans
   won't do it is manifestly untrue.

@_date: 2008-02-07 09:50:58
@_author: Eric Rescorla 
@_subject: Gutmann Soundwave Therapy 
At Thu, 7 Feb 2008 10:34:42 -0500 (EST),
So, this issue has been addressed in the broadcast signature context
where you do a two-stage hash-and-sign reduction (cf. [PG01]), but
when this only really works because hashes are a lot more efficient
than signatures. I don't see why it helps with MACs.
This basically doesn't work for VoIP, where latency is a real issue.
[PG01] Philippe Golle, Nagendra Modadugu: Authenticating Streamed Data in the Presence of
Random Packet Loss. NDSS 2001

@_date: 2008-02-07 13:24:54
@_author: Eric Rescorla 
@_subject: Gutmann Soundwave Therapy 
At Thu, 7 Feb 2008 14:42:36 -0500 (EST),
Well, since there's a much simpler procedure accept ~5-10% overhead, this doesn't seem like a particularly attractive design.

@_date: 2008-01-30 07:10:13
@_author: Eric Rescorla 
@_subject: Dutch Transport Card Broken 
At Wed, 30 Jan 2008 09:04:37 +1000,
I can't believe I'm getting into this with James.
Ignoring the technical question of "broken", I know of no evidence
whatsoever that round trip latency is in any way a limiting factor for
people to use SSL/TLS.  I've heard of people resisting using SSL for
performance concerns, but they're almost always about the RSA
operation on the server (and hence the cost of server hardware).
If you have some evidence I'd be interested in hearing it.

@_date: 2008-01-30 09:03:27
@_author: Eric Rescorla 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
At Wed, 30 Jan 2008 11:25:04 +0100,
Huh? What are you claiming the problem with sending client certificates
in plaintext is (as if anyone uses client certificates anyway)? That the phisher gets to see the client's identity? So what?
It doesn't let them impersonate the client to anyone. Certificates
shouldn't contain sensitive information anyway.
No it isn't more secure. This gets discussed on the TLS mailing list occasionally, but the
arguments for making this change aren't very convincing. If you have
an actual credible security argument you should post it to
tls at ietf.org.
Whether this is true or not depends critically on the base rate
of errors in packets delivered to TCP by the IP layer, since
the rate of errors delivered to SSL is 1/256th of those delivered
to the TCP layer. Since link layer checksums are very common,
as a practical matter errored packets getting delivered to protocols
above TCP is quite rare.

@_date: 2008-01-30 10:06:14
@_author: Eric Rescorla 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
At Wed, 30 Jan 2008 17:59:51 -0000,
You're right. It's 16 bit, isn't it. I plead it being early in the morning. I think my point now applies even moreso :)
Right, so this now depends on the error model...

@_date: 2008-01-30 21:44:18
@_author: Eric Rescorla 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
At Thu, 31 Jan 2008 03:04:00 +0100,
I don't find this at all convincing. There are a variety of different
threat vectors here:
1. Phishing.
2. Pharming (DNS spoofing).
3. Passive attacks.
In the case of phishing, the fact that the client sends its certificates
in the clear is totally irrelevant, since the client would simply send
its identity encrypted under the server's certificate. The only
fix for this alleged privacy leak in the phishing context is for
the client to refuse to deliver his certificate to anyone but people
who present valid certs that he otherwise trusts.
Now, this is potentially an attack if the attacker is passive but
on-path, either via pharming or via subverting some router, but
I'm unaware of any evidence that this is used as a certificate
disclosure attack vector.
No, if it were *convenient* people would use it. I know of absolutely
zero evidence (nor have you presented any) that people choose not
to use certs because of this kind of privacy issue--but I know
of plenty that they find getting certs way too inconvenient.
Validated email addresses are not exactly hard to obtain.
If those applications do not force the client to do proof of possession
of the private key, then they are fatally broken. It's not our job
to fix them.
No, it just leaks the password to the phishing server. Yeah, that's totally
a lot better.
Because the arguments they present are handwavy and unconvincing, just like
It's an open list. Feel free to make these arguments.
I would certainly find practical examples more convincing than the ones
you've presented.
There's already a solution: double handshake. You do an ordinary
handshake with server auth only and then you do a second handshake
with client auth. This hides the certificate perfectly well.  Yes, you
have to do two private key ops on the server, but if this issue is as
important as you say, this is a tradeoff you should be happy to make.
I've pointed this out on the TLS mailing list a number of times, but
maybe you missed it.
Fundamentally, this *is* the fix. Even if SSL guaranteeed that nobody
but the person you were handshaking with got the certificate, this
is still incredibly brittle because any random server can ask you
for your cert and users can't be trusted not to hand them over.
The basic premise of certs is that they're public info. If you
want to carry private data around in them then you should encrypt
that data.
If you have a connection with a .01 BER, then you need to run some sort
of error correction over the link, not complain that TCP doesn't solve
your problem. As a thought experiment, consider that a .01 BER used
with a standard 1500-byte MTU means that nearly every TCP packet will
contain at least one error. If the TCP checksum caught all such errors
and dropped the packets, the effect on the TCP congestion control would
be catastrophic in terms of throughput. TCP was not designed to operate
correctly in settings with this kind of error rate.
More to the point, SSL/SSH are doing you a favor here: they're telling
you about bit errors that would otherwise be undetected corruption in
the file you moved around. The fix for this is to use client software
that can resume.

@_date: 2008-07-10 10:17:54
@_author: Eric Rescorla 
@_subject: how bad is IPETEE? 
At Thu, 10 Jul 2008 18:10:27 +0200,
This is the first I have heard of this.
That said, some initial observations:
- It's worth asking why, if you're doing per-connection keying,
  it makes sense to do this at the IP layer rather than the
  TCP/UDP layer. - Why not simply use TLS or DTLS?
- The uh, novel nature of the cryptographic mechanisms is
  pretty scary. Salsa-20? AES-CBC with implicit IV?
  A completely new cryptographic handshake? Why not use
  IPsec?
- A related idea was proposed a while back (by Lars Eggert,
  I believe). See S 6.2.3.1 of:

@_date: 2008-07-15 17:42:56
@_author: Eric Rescorla 
@_subject: how bad is IPETEE? 
At Tue, 15 Jul 2008 18:33:10 -0400 (EDT),
I also have a followup post at:

@_date: 2008-07-23 18:45:47
@_author: Eric Rescorla 
@_subject: The PKC-only application security model ... 
At Wed, 23 Jul 2008 17:32:02 -0500,
DTLS-SRTP uses a similar technique: certificates solely as a key carrier authenticated by an out-of-band exchange.

@_date: 2008-06-29 12:31:26
@_author: Eric Rescorla 
@_subject: Using a MAC in addition to symmetric encryption 
At Fri, 27 Jun 2008 07:52:59 -0700 (PDT),
Encryption doesn't necessarily provide integrity.
Consider the case of a stream cipher like RC4, where you have
a function RC4(K) which generates a string of bytes from the
key K.
The encryption function is then:
Ciphertext[i] = RC4(K)[i] XOR Plaintext[i]
It should be apparent that an attacker can make targeted
modifications to the plaintext. Say he knows that plaintext
byte i is 'A' and he wants it to be 'B', he just changed
Ciphertext[i]' = Ciphertext[i] XOR 'A' XOR 'B'. Mission

@_date: 2008-05-04 20:43:20
@_author: Eric Rescorla 
@_subject: OpenSparc -- the open source chip (except for the crypto parts) 
At Sun, 04 May 2008 20:14:42 -0400,
Without taking a position on the security of open source vs. closed
source (which strikes me as an open question), I agree with Perry
that deciding whether a given piece of software has back doors is
not really possible for a nontrivial piece of software. Note that
this is a very different problem from finding a single vulnerability
or answering specific (small) questions about the code [0].
[0] That said, I don't think that determining whether a nontrivial
piece of software security vulnerabilities is difficult. The
answer is "yes".

@_date: 2008-05-22 09:54:20
@_author: Eric Rescorla 
@_subject: blacklisting the bad ssh keys? 
At Wed, 14 May 2008 19:52:58 -0400,
I've been having a similar thought. This also probably applies to SSL
keys, given the rather lack attitude that most clients have about
checking CRLS.

@_date: 2008-09-01 13:49:17
@_author: Eric Rescorla 
@_subject: [OpenID] rfc2817: https vs http 
At Mon, 1 Sep 2008 21:00:55 +0100,
Even without an active attacker, this is a problem if there is
sensitive information in the request, since that will generally
be transmitted prior to discovering the server can upgrade.
Session caches are often dialed this low, but it's not really necessary
in most applications. First, a session cache entry isn't really that
big. It easily fits into 100 bytes on the server, so you can serve
a million concurrent user for a measly 100M. Second, you can use
CSSC/Tickets [RFC5077] to offload all the information onto the client.

@_date: 2008-09-01 17:32:56
@_author: Eric Rescorla 
@_subject: [OpenID] rfc2817: https vs http 
At Mon, 1 Sep 2008 21:56:52 +0100,
Agreed. I thought we were contemplating protocol changes in
any case, so I figured having clients just use a longer session
cache (5 minutes is silly for a client anyway, since the amount
of memory consumed on the client is miniscule) wasn't much
of an obstacle.
True enough, though that's the common case right now.
Except that CSSC actually looks better when client certs are used, since
you can offload the entire cert storage to the client, so you get
more memory savings.

@_date: 2008-09-21 12:56:05
@_author: Eric Rescorla 
@_subject: once more, with feeling. 
At Sat, 20 Sep 2008 15:55:12 -0400,
This is precisely the issue.
There are any number of cryptographic techniques that would allow
clients and servers to authenticate to each other in a phishing
resistant fashion, but they all depend on ensuring that the
*client* has access to the password and that the attacker can't
convince the user to type their password into some dialog
that the attacker controls. That's the challenging technical
issue, but it's UI, not cryptographic.

@_date: 2009-04-30 14:37:18
@_author: Eric Rescorla 
@_subject: SHA-1 collisions now at 2^{52}? 
McDonald, Hawkes and Pieprzyk claim that they have reduced the collision
strength of SHA-1 to 2^{52}.
Slides here:
Thanks to Paul Hoffman for pointing me to this.

@_date: 2009-01-23 09:23:05
@_author: Eric Rescorla 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
At Tue, 20 Jan 2009 17:57:09 +1300,
Ordinarily I wouldn't bother to respond to Peter's curmudgeon act, but
since I was obviously heavily involved with TLS 1.2, I think a bit
of context is in order.
Nearly all the changes to TLS between 1.1 and 1.2 were specifically designed
to accomodate new digest algorithms throughout the protocol. For those
of you who aren't TLS experts, TLS had MD5 and SHA-1 wired all throughout
the protocol and we had to arrange to strip them out, plus find a way
to signal that you were willing to support the newer algorithms. To
avoid this becoming a huge pile of hacks, we had to restructure some of
the less orthogonal negotiation mechanisms. The other major (and totally
optional) change was the addition of combined cipher modes like GCM.
That change was made primarily because we were in there and there was
some demand for those modes. So, no, I don't consider these changes
"gratuitous", though of course they are incompatible. Yes, there were
simpler things we could have done, such as just specifying a new set of
fixed digest algorithms to replace MD5 and SHA-1, but I and others felt
that this was unwise from a futureproofing perspective.
Yes, the changes between TLS 1.1 and TLS 1.2 are about as big as those
between SSL and TLS. I'm not particularly happy about that either, but
it's what we felt was necessary to do a principled job.

@_date: 2009-01-24 09:51:34
@_author: Eric Rescorla 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
At Sat, 24 Jan 2009 14:55:15 +1300,
I agree that given the current set of attacks on SHA-1 and MD5,
there was no existing attack on the protocol. However, that doesn't
mean that improvements in analysis wouldn't lead to such attacks
and so the general feeling of the community was to err on the
side of safety. No doubt if we hadn't done so, there would be
people screaming about how TLS still used MD5. Indeed, that's
how this thread started. So, once again, I don't share your
opinions about these changes being gratuitous.
Moreover, the bulk of the changes weren't to the PRF. That's actually
quite a trivial change to implement, but rather to have accurate
signalling about what combinations of hashes and signatures
implementations could support--something that was painfully
non-orthogonal in SSLv3 and earlier versions of TLS. Again,
one could argue that we could have hacked around this and indeed the original Bellovin-Rescorla paper described a number of such
hacks, but the general feeling of the TLS WG was that it was
more important to get it right.
Which we did--including having the very discussion we are having
now--and concluded that the course of action we took was the right
one. You're of course free to weigh the evidence yourself and come to
a different conclusion, and even to hold the opinion that those who
agree with you are complete fools, but it's simply not accurate to
imply, as you do here, that we didn't think about it.

@_date: 2009-05-02 09:58:39
@_author: Eric Rescorla 
@_subject: SHA-1 collisions now at 2^{52}? 
At Sat, 02 May 2009 21:53:40 +1200,
Again, I don't want to get into a long argument with peter about TLS 1.1 vs.
TLS 1.2, but TLS 1.2 also defines an extension that lets the client tell
the server that it would take a SHA-256 certificate. Absent that, it's
not clear how the server would know. Of course, you could use that extension with 1.1 and maybe that's what the
market will decide...

@_date: 2009-05-02 12:57:14
@_author: Eric Rescorla 
@_subject: SHA-1 collisions now at 2^{52}? 
At Sat, 2 May 2009 15:00:36 -0400,
Without suggesting that collision-resistance isn't an important property,
I'd observe that we don't have anything like a reduction proof of
full TLS, or, AFAIK, any of the major security protocols in production
use. Really, we don't even have a good analysis of the implications
of relaxing any of the (soft) assumptions people have made about
the security of various primitives (though see [1] and [2] for some
handwaving analysis).
It's not clear this should make you feel any better when a primitive is
weakened, but then you probably shouldn't have felt that great to start
[1]  [2]

@_date: 2009-11-12 13:18:52
@_author: Eric Rescorla 
@_subject: TLS break  
At Tue, 10 Nov 2009 20:11:50 -0500,
Is the relevant silicon really this unprogrammable?
