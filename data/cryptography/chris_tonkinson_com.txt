
@_date: 2015-02-25 13:39:46
@_author: Chris Tonkinson 
@_subject: [Cryptography] Layering Web Encryption? 
I'm not a security researcher, pen tester, red/blue teamer, formal
infosec consultant, or a cryptographer. I am a foil-donning web
technologist who enthusiastically consumes a lot of information from the
infosec community. Basically I'm a busch league security and privacy
advocate. A crypto groupie, if you will.
So please forgive my ignorance, naivete, and lack of historical perspective.
TLS is weakened because most popular platforms (an intentionally broad
term) get preloaded with hundreds of default root certs, and no one
knows how many of those are fronts for the SAA ("Some Alphabet Agency")
or aren't, but have been compromised by same.
Gemalto's SIM keys got nabbed by the SSA, so trusting any opacity
provided by the cellular protocols goes out the window.
The list goes on, but data in transport is a pretty popular target. It
gets me thinking - could something experimental be jimmied up using "off
the shelf" components by taking a leaf out of the TOR book?
For the sake of argument, set aside usability, performance, and resource
requirements (collectively "logistics") for a moment.
What if we were to take a leaf out of TORs book, and layer "reverse" PKI
(with e.g. PGP) inside of TLS for HTTPS?
Suppose my UA has access to a locally generated keypair. Could be a
pre-generated and [relatively] long-lived keypair, or it could be
transient, surviving a single request-response cycle - doesn't matter.
Upon completion of the TLS handshake, the first request from my UA to
the server would include the public key for this pair. The response,
then, would be encrypted to this public key.
Threat model: Again, we're assuming that the client and server are not
compromised. This is simply a defense-in-depth play against
eavesdropping. For example, suppose a flaw in TLS is exposed, suppose a
services private key gets loose (by incompetence, malice, or coercion).
Is it stupid to make a distinction (with regards to threat analysis)
between a company being forced to hand over a private key (a la Lavabit)
and a company actively infiltrated? Another way to ask that is: are
there practical limitations to what can be done with an NSL?
Has this idea been attempted before? Remember, I'm young, dumb, and
naive. I've looked around, but with the keywords I'm searching on the
results are badly googlewashed.
It's my understanding that PFS is widely implemented where the server is
generating the ephemeral keys. What I'm proposing /looks/ different than
PFS, but would it fundamentally offer additional hardness?
I've used a site or two which accept keypairs for authentication instead
of passwords, but that's not really what I'm talking about here
(although clearly related, I see the two concepts as orthogonal).

@_date: 2015-02-26 13:38:42
@_author: Chris Tonkinson 
@_subject: [Cryptography] Layering Web Encryption? 
You're right, and thinking further down that road, such a system would
obviate PFS anyway - if I've learned correctly, PFS was designed simply
to separate the keys used for authentication from the keys used for
message encryption such that a compromise of the former would not
directly endanger the latter. Handing responsibility of key management
(for encryption purposes) to the client means that encryption key
compromises are necessarily per-user.
Such a scheme would have rendered the Lavabit NSL drama effectively
moot, as an example. No longer would encryption key requests for a
single user or small group of users of some service necessitate security
become broken for other "unaffected" users of said service.
Someone pointed me towards RFC 6091 but my read of it would only allow
OpenPGP keys /instead/ of X.509 - it does not appear to shift the
encryption private key to the client.
Assuming this is even a desirable pipe dream to have - am I wrong that
it would, on the whole, improve the robustness of encryption for
services over the current PKI model?
Chris Tonkinson
  "Lead, follow, or get out of the way."
  -Thomas Paine

@_date: 2015-06-17 14:07:37
@_author: Chris Tonkinson 
@_subject: [Cryptography] password fatigue; was: Lastpass 
SQRL[1] seems an early, if promising, mechanism that I would bet on over
No shared secrets, out of band, hard against spoofing, crypto looks like
it was done right, and it's something I could explain to .
[1]: Chris Tonkinson
  "Lead, follow, or get out of the way."
  -Thomas Paine

@_date: 2015-11-24 12:56:15
@_author: Chris Tonkinson 
@_subject: [Cryptography] Dells are shipping with a rogue root level CA 
Does anyone have any data on the prevalence of the most popular CAs, or
tools to audit relative use of each CA for a given client?
I'd bet folding money that out of the hundreds of default CAs on most
operating systems, a dozen (or fewer) account for 80% of all endpoints
being connected to. In which case A) the others can be deleted and B) we
can safely assume those with money and motive have set about
compromising the remainder.
Wouldn't it be funny (for some reasonably twisted definition of the word
"funny") to learn that for example that the IdenTrust chain was
compromised by some state actor(s) - thus making Let's Encrypt a very
well intentioned charade of lulz.
Chris Tonkinson
"Lead, follow, or get out of the way."
-Thomas Paine

@_date: 2015-09-24 13:11:25
@_author: Chris Tonkinson 
@_subject: [Cryptography] VW/EPA tests as crypto protocols ? 
This is the core issue. We have long accepted that nothing can be
trusted if you don't have source. With the source, of course you have no
_absolute_ guarantees, but without it you don't even have a starting
point. I can't see how adding crypto to an otherwise untrusted system
moves the needle.
  Seems to me like the only shot is the manufacturer providing source to
the testing agency, who can then build and install the firmware on
"trusted" (whatever that means) hardware (i.e. sans 3rd party DCO/JIT
interference). Behavioral observation then becomes a perfectly viable
means of analysis (whether on the dyno or on a road test) because you
have a statistical control group.

@_date: 2016-02-26 07:23:10
@_author: Chris Tonkinson 
@_subject: [Cryptography] Response to "I don't have anything to hide" 
"Okay, then will you unlock your phone and let me ferret around?"
We all have secrets, even if we don't think of them that way. This
simple request causes the mind - like a reflex hammer to the knee - to
start kicking to the surface all the various information that wasn't
even previously recognized as explicitly "private."
It works because you're putting the bogeyman (yourself) RIGHT there in
the same physical room. It realizes the privacy threat.
PS: Sometimes this isn't enough, though. But all you need to do is take
the phone and say loudly and clearly, "Okay... text messages... ..."
Chris Tonkinson
  "Lead, follow, or get out of the way."
  -Thomas Paine

@_date: 2016-11-29 07:36:34
@_author: Chris Tonkinson 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
I wonder if some Simpleâ„¢ device could be created based on a combination
of battery, capacitor, and timer to smooth the "curves" of consumption
for a household (or on a smaller scale for specific appliances),
rendering this type of analysis ineffectual.
-Chris Tonkinson

@_date: 2016-11-29 15:31:46
@_author: Chris Tonkinson 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
In this case "smoothing" was a poor choice of words, as it doesn't
necessarily have to mean "make more linear;" instead it simply means
"hide the variability."
  Suppose you charge a battery in anticipation of required energy usage
for some application. Charge it at regular intervals, and at a constant
rate. Overall power usage remains the same - but start adding multiple
appliances (e.g. an entire home) and the combinatorics of overall energy
consumption should prevent detailed analysis.
  Six months later "power laundering" devices will be outlawed :)
-Chris Tonkinson
