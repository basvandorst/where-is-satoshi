
@_date: 2006-11-02 10:42:29
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Can you keep a secret? This encrypted drive can... 
Ah, okay. The notes I jotted down from MacIver's talk at HITB in
Malaysia indicate he said it was on by default in the upper versions,
but I could well have written it down incorrectly. Thanks for the

@_date: 2006-10-12 14:00:13
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: TPM & disk crypto 
We're shipping LinuxBIOS on the One Laptop per Child machines.
I came up with a scheme that lets us do a "secure BIOS" without a TPM;
bypassing it without a PLCC would be extremely difficult. I'm not yet
certain if we'll end up shipping a PLCC socket on the final hardware,
but if not, I suspect you'd be hard-pressed to do much to the BIOS
protection even with physical access, short of un-soldering and
re-soldering a different SPI flash chip to the motherboard. That was
explicitly not part of my threat model.

@_date: 2006-10-12 14:04:37
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: TPM & disk crypto 
You're missing the marketing value of saying "this piece of hardware,
that you probably wouldn't otherwise want in your machine since it makes
sure that the machine can be trusted /against/ you, is great! Because it
protects you against trojans! And everyone wants to be safe from
trojans, right?".
The Microsoft guy presenting BitLocker at HITB last month mentioned
this, but glossed over it without explaining. He did seem to indicate
that they had some solution, but didn't provide details, IIRC.

@_date: 2006-10-12 14:31:02
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: TPM & disk crypto 
What does "prove" mean here? Does having a hash of the system state for
visual inspection before boot do it?

@_date: 2006-10-31 18:50:20
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Can you keep a secret? This encrypted drive can... 
Notably, none of the three articles mention Vista's BitLocker, which
provides FDE in software and establishes trust via a TPM chip. (For
those who haven't heard about it, BitLocker also uses a clever diffuser
that Niels Ferguson designed specifically for the FDE scenario.)
The problem I see with hardware FDE is the same one that prompted
Poul-Henning Kamp to design GBDE some time back: the "lose a password,
game over" model doesn't work in corporate environments. People forget
passwords all the time. They don't see this as an irrecoverable failure;
it's something that the IT people are supposed to be able to fix with a
wave of their tricorder. Once that assumption flies out the window, the
cost of a lost password becomes so high that it's more convenient to
disable the encryption altogether.
On the other hand, Vista is shipping with BitLocker enabled by default
in the upper editions (Enterprise or somesuch), and doesn't rely on
passwords at all; it actually brings the user, without any interaction,
to the standard Windows login prompt, where the user can reach for a
smart card, or use a fingerprint reader, or do any other kind of
authentication Windows supports. Optionally, a hardware token or USB key
can be required during boot, and those can be made rekeyable by the IT
department, if I understood one of the engineers who worked on it correctly.
Seagate's technical solution isn't compatible with the social problem
it's trying to solve. I think Microsoft's is, surprisingly enough.
As a sidenote, I wonder if Seagate will release full details and code
for their FDE (and AES) implementation, or if we're supposed to take the
"no backdoors" clause on faith, as we do with TPMs.

@_date: 2006-10-31 22:41:58
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Can you keep a secret? This encrypted drive can... 
============================== START ==============================
Here's the relevant excerpt of the Elephant paper [0]:
"A typical desktop machine today has a 3 GHz P4 CPU and a hard disk that
can read at about 50 MB/s. That means that the CPU has 60 clock cycles
for each byte that the disk reads. Laptops have slower CPUs, often
around the 1 GHz mark. Laptop disks are also slower but not by nearly as
much. (For example, the Seagate Momentus 5400.2 laptop drive can read
data at almost 50 MB/s.) Our data shows that laptops tend to have fewer
CPU clock cycles per byte read from disk, down to 40 or even 30 cycles
per byte. We cannot predict what the CPU/disk speed ratio will be for
the actual hardware that BitLocker will run on, but these numbers are
the best guidelines we have.
If decryption is slower than the peak data rate of the disk, the CPU
becomes the bottleneck when reading large amounts of data. This is very
noticeable, both because of the reduced performance and because of the
reduced responsiveness of the UI when all CPU time is being used to
decrypt data.2 Therefore, decryption, including all overhead, must be
faster than the disk to get an acceptable user experience.
BitLocker is carefully designed to overlap the reading of data from disk
with the decryption of previously read data. This is only possible to a
limited extent, and when the disk ?nishes reading the data, the CPU
still has to decrypt (some of) the data. Thus the decryption time
increases the latency of the disk request and reduces performance
accordingly. This obviously argues for a fast decryption algorithm.
A software implementation of AES runs in around 20?25 cycles per byte on
a P4 class CPU.  (Synthetic benchmarks can achieve somewhat higher
speeds, but they exclude various overheads encountered in real system
implementations.) Other overhead adds around 5 cycles per byte for a
total of 25?30 cycles per byte.
Based on this data, our performance analysis concluded that a single
pass of AES, for example using AES in CBC mode, would have acceptable
performance. An algorithm twice as slow as AES (45?55 cycles/byte) would
be on the edge of being unacceptable, and a high-risk choice given the
many uncertainties in the analysis. Anything slower than that would be
I don't think so. The key thing to recognize is that BitLocker, in its
least secure setting (no hardware tokens or USB keys), still improves
security dramatically, while requiring no setup whatsoever. Hardware FDE
does approximately the same thing security-wise, not nearly as flexibly,
and requiring a lot of up-front setup (and that's assuming your TPM does
rekeyable hardware tokens at all). And if we've learned anything from
the negligible global uptake of encrypted e-mail and FDE suites such as
PGP Drive, it's that security only works is if it can be engaged without
requiring anyone -- that's the user, the system administrator, and all
the way up to the CIO -- to think. The exceptions are exceedingly rare.
But maybe I'm just a cynic.
[0] Ferguson, Niels. AES-CBS+Elephant diffuser, A Disk Encryption
Algorithm for Windows Vista.

@_date: 2006-09-11 06:13:07
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: secure key storage APIs 
please merge with my previous message; I hit 'send' by mistake.
Also, the following are of general interest:
Henson S., `Netscape certificate database info`:
 Henson S., `Netscape key database format`:

@_date: 2006-09-11 06:06:19
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: secure key storage APIs 
Take a look at the GNOME Keyring:
  In addition, various frontends exists to GnuPG, e.g. KGPG. It's not yet
clear, but I might have to write something from scratch to satisfy our
needs at OLPC (

@_date: 2007-04-20 12:27:17
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: More info in my AES128-CBC question 
We don't let a bunch of random people design airbags. How on earth is it
a good idea to let a random bunch of people design crypto protocols? Is
this the same bunch of people that will be shocked, just SHOCKED when
someone demonstrates that their design is idiotic and doesn't protect
anyone or anything?
No, really, that people with "very little security experience" feel
comfortable doing this kind of work just boggles my mind. Please
congratulate everyone involved, and remind them to always use their PPTP
VPN over their WEP-protected wireless.

@_date: 2007-08-17 04:02:34
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: New DoD encryption mandate 
How so? If your computer goes bad, you need a *backup*. That's  entirely orthogonal to the drive encryption problem. Bitlocker uses  the TPM to provide assurance that your drive -- really, volume -- is  locked to your computer, and that the early boot environment hasn't  been messed with. When either check fails, you use the BitLocker  recovery password (either on a USB stick or entered manually) to  recover your data. This holds in the event that you take your drive  out and stick it in a different machine. In other words, the TPM is  not a single point of failure, so I don't understand why you think  you care about TPM backup/restore/transfer.
Security is never free, but in 2007, we can afford the cycles. What's  a better use for them? Drawing semi-transparent stained glass window  Ivan Krsti?  |

@_date: 2007-08-19 10:19:47
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: New DoD encryption mandate 
I still don't follow. BitLocker explicitly includes a (optionally  file-based) recovery password. If you want central management, why  not centrally manage _that_?
The reason the TPM is used to wrap the BitLocker key is not because  people don't want the key to be available outside of hardware -- at  least I've never heard of that requirement going hand in hand with  central key backup/migrate. Instead, TPM key wrapping is used so the  early-boot checks can be enforced. I don't see how a hardware-only  key that you can migrate to another TPM centrally is any more secure  than keeping a key in hardware but falling back on a centrally- managed spare for enabling data migration.
Ivan Krsti?  |

@_date: 2007-08-19 20:14:08
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: New DoD encryption mandate 
Your argument just went from "TPMs are bad for volume encryption with  BitLocker because they can't be centrally managed" to "Microsoft  should provide tools to centrally manage key recovery files because I  find doing it myself too hard". Which are you actually arguing? I've  tried to show you that the first argument is _wrong_; the second  argument has nothing to do with TPMs. You have a choice when it comes  to how you approach the recovery keyfile problem. You can build tools  for it, or any company that perceives a market need can do so.
Ivan Krsti?  |

@_date: 2007-12-30 18:48:13
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Question on export issues  
Not Libya. See 15 C.F.R ?740Spir[0], country group E: Cuba, Iran,  North Korea, Sudan, Syria.
Interestingly, 15 C.F.R. ?746.8[1] also lists Rwanda: "an embargo  applies to the sale or supply to Rwanda of arms and related mat?riel  of all types and regardless of origin, including weapons and  ammunition." I am not a lawyer, and cannot tell whether this applies  to encryption.
We've recently had to jump through the BIS crypto export hoops at  OLPC. Our systems both ship with crypto built-in and, due to their  Fedora underpinnings, allow end-user installation of various crypto  libraries -- all open-source -- through our servers. It was a  nightmare; the regulations and paperwork appear to be designed for the  use case of individual applications that utilize a handful of  primitives and attempt to keep the user from examining or modifying  the utilized crypto. Trying to fit a Linux distribution into this  model proved, er, challenging. (We also found that projects that we  expected would know the drill cold, such as Fedora and Mozilla, were  actually not very familiar with the processes involved.)
[0] [1] Ivan Krsti?  |

@_date: 2007-12-30 20:41:31
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Death of antivirus software imminent 
My, that sounds awfully familiar:
I note that, come the January OLPC software update, I will be using my  XO laptop for all my e-banking and related needs. It provides a  drastically more secure platform for doing so than any mainstream  computer I know exists.
Ivan Krsti?  |

@_date: 2007-12-31 17:46:44
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Question on export issues 
Here's one relevant excerpt from an internal e-mail exchange, as  written up by a colleague:
"1) Encryption is a dual-use technology under the Wassenaar Agreement.
This means that it is illegal to export products containing
cryptographic technology without first satisfying the requirements of
the EAR (the export regulations).
2) There are several ways to satisfy the requirements of the EAR. Of
particular interest are the "Technologies and Software - Unrestricted"
(TSU) licensing exception, the "Encryption commodities and software"
(ENC) licensing exception, and the "mass market encryption" designation.
3) Our software contains both "Open Cryptographic Interfaces" and is
designed to be cryptographically extended by the end user. These two
features prohibit us from qualifying for either the 'ENC' licensing
exception or the mass-market encryption "No License Required" (NLR)
4) Essentially all open source projects use the TSU licensing exception.
5) Essentially none of them publish the details of their experience of
the process of satisfying the export control requirements.
6) I have not been able to locate any example responses to the
Encryption Questionnaire against which I can judge what level of detail
is required and how the 'third party components' question (no. 8) was
We encountered other hassles. I intend to ask our legal intern, who  did a phenomenal job rounding this all up, to write up the process in  some detail.
Ivan Krsti?  |

@_date: 2007-02-03 11:19:53
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: man in the middle, SSL 
There's nothing new or interesting about this; SSL MITM tools have been
around for a long time. When you're connecting to a website via SSL, you
have no out of band knowledge of the certificate that the server is
supposed to use (e.g. you can't query DNS and get the certificate
fingerprint). SSL clients generally do three checks on the server cert:
they verify it's still valid on today's date, that the name in the cert
matches the server you're connecting to, and that you trust the CA that
issued the cert.
An SSL MITM proxy can trivially satisfy two of those three checks. If an
attacker had sufficiently strong incentive and a specific target site,
presumably he could satisfy the third as well (get a "trusted" CA to
sign a bogus cert for the server in question -- remember Microsoft from
a few years back).
So yes, in the general case, the web browser will notice the MITM, and
inform the user that two checks pass and one fails. And almost all users
will hit "continue" and not care, because they don't understand SSL or
the risks involved. They shouldn't have to, either; it's for this reason
that I think SSL is just altogether broken in the way we use it on the
web. It passes the technical requirements, but utterly fails at being a
usable security technology.

@_date: 2007-02-03 16:18:53
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: man in the middle, SSL 
[I prefer to keep discussions on-list where possible. CCing the list.]
Right. I was talking about the kind of MITM where an attacker is
physically between your machine and the SSL destination, such as sitting
on your network's egress. MOYM (man on your machine) attacks are a bit
of a lost cause with most modern OS environments, though I've been
working pretty hard to try and change that on the One Laptop per Child

@_date: 2007-02-07 11:13:36
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: One Laptop per Child security 
Earlier today, I publicly released the architecture-level specification
for Bitfrost, the security platform on the One Laptop per Child machines:
   This is a complete but non-technical spec, with its technical complement
scheduled for release sometime in late March (there's a pile of crypto
powering various choice bits of the system). Comments are very much invited.

@_date: 2007-02-08 09:34:49
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: One Laptop per Child security 
Hi, Steve. Thanks for your thoughts; comments inline.
The "no firewalls" thing is really a journalistic misrepresentation.
There are no *personal* firewalls, in the
keep-popping-up-messages-and-prompts sense. P_NET filtering, described
in the spec, is implemented exactly by using a firewall -- standard
Linux netfilter. Because each program executes in a VM of its own,
enforcing network access policies on it becomes very simple: it's a
matter of choosing to NAT or not NAT packets from/to its virtual IP,
with any applicable restrictions.
But it's no longer something the user has to know or care about, which
has been one of my fanatical focuses in designing Bitfrost. I firmly
believe this is how most security systems should be designed regardless
of the target audience, but with 6 year olds in the mix, it's no longer
a belief or convenience, it's an absolute necessity.
Is this a general comment, or are you talking about some particular
crypto authentication on the OLPC?
Is it really a big deal if a worm spreads to every OLPC laptop, but
can't do anything particularly malicious once it's there?
If you said "spreading," I'd have a different answer. But let's talk
about the worm succeeding. It "succeeded" in bringing down the Internet
because it -- accidentally, from what we know -- kept creating running
copies even on previously infected machines. Eventually there were too
many processes, and the machines buckled under the DoS. The Morris worm
amounted to a self-propagating forkbomb.
Bitfrost would keep the Morris worm from "succeeding" in any interesting
sense. Assuming the worm managed to spread despite the other
protections, once it landed on a user's machine and the processes
started multiplying, they'd just get throttled back -- to no more than
10% CPU use -- for the combined lot of them -- if the user doesn't have
the worm's window in the foreground of the UI. (What window? Exactly.)
Decoupling user permissions from process permissions and integrating
explicit assent into dealing with the user's documents get you a long,
long way towards a usable and reasonably secure system, I think. If I'm
wrong, I'll have 10 million reasons to not sleep next year.

@_date: 2007-02-08 12:23:40
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: One Laptop per Child security 
Hi Nico,
It really does help to read at least the introduction to the document in
question before hitting 'reply' to an e-mail :)
Here are two of the four guiding principles for Bitfrost, stated in the
first chapter of the spec:
Summary and other principles: (borrowed directly from the full spec).
The browser is an environment, which makes it an edge case. Even so,
Bitfrost provides guarantees on what happens if you take over the
browser: it's very hard to violate the user's privacy, you can't harm
the machine in any way, you can't get unauthorized access to the user's
documents. From a systems security point of view, that's all I could
hope for. Security within the browser cannot lie in the scope of the
spec. (Not to say that I don't care about it, though -- I'm meeting with
Mozilla's CSO later today to talk about what we can do to make the
browsing experience more secure.)

@_date: 2007-02-08 13:03:27
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: One Laptop per Child security 
Hi Paul,
Sort of. The worm would still be subject to connection rate and
bandwidth throttling, so the laptops are not _that_ useful as a DDoS
launchpad. But it's all a big hypothetical scenario, because finding
invariants to infect across all OLPC systems is likely to prove
extremely difficult; only applications that the user sometimes runs
generally listen on a port and act as a server. There aren't going to be
unprotected, constantly-running servers to exploit.

@_date: 2007-02-08 18:17:46
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: One Laptop per Child security 
[Perry -- this is a very interesting discussion, but please feel free to
tell us to bugger off to the OLPC security list if you find it too
If an application wants to do something for which _it_ didn't request
permission ahead of time, it fails. The difficulty is in creating the
permission set with the proper mutual exclusions, and in such a way that
it's very hard to request a permission set required to do something
malicious. At the same time, it has to be easy for most applications to
request the permissions they need to get their work done. I've tried to
strike a decent balance.
Think high-level systrace, with each application providing the policy at
install time, and the user being able to amend it at any time.
Protecting the browser is not in the scope of _system_ security. I'm
working on it separately, and want to see how to make it better, but to
the system security platform, a browser is just another application. To
that end, if the entire application is compromised, Bitfrost provides
very strong assurances about what an attacker can('t) do to the rest of
the system.
No, the platform is too low in the security stack to have any idea about
what tabs and sites are. It sees a process, or some number of processes,
which are the browser.

@_date: 2007-02-08 18:26:13
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: One Laptop per Child security 
I don't follow. How do you hop from one browser to another, if you want
to use one as your spread vector? Browsers don't accept inbound connections.

@_date: 2007-02-09 09:48:25
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: One Laptop per Child security 
The systems are similar in their desire to offer no-frills protection,
but I think the similarities end there. If I had been trying to simply
lock the machines down, as is the essence of Cheswick's proposal, my
task would have been extremely simple. The resulting security model
would also have gone against everything OLPC's educational principles
stand for.
I think you'll find that moving (even mentally) from "protection by not
running untrusted code" to "usable protection _while_ running untrusted
code" involves a few trips through a labyrinth sitting on top of a mine
field, with the exit guarded by a killer rabbit. It's also certainly
possible I'm not smart enough, and other people find this to be an
easier problem.

@_date: 2007-02-13 17:00:35
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Failure of PKI in messaging 
This is, in my experience, exactly right. I'm trying to take some steps
for the better on the OLPC: all e-mails and IMs will be signed
transparently and by default, with the possibility of being encrypted by
default in countries where it's not a problem. This'll help with privacy
and message integrity, but it's not designed to stop phishing or
Phishing is less of an immediate problem for us, as there's little
incentive to phish 6-year olds in developing countries. But it will be a
problem eventually, and by then, it might be extremely difficult to
introduce sweeping changes in the security and HCI model to remedy the
One tremendous advantage we have now with OLPC is the ability to ignore
backwards compatibility for a number of things, so if we had a really
good model for dealing with phishing and the like -- even if it required
new assumptions or approaches -- we could probably do it. So maybe it's
time (for us, perhaps) to organize a workshop on this? Is there a better
way to do it?

@_date: 2007-01-08 05:05:40
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: (Short) Intro and question 
Read Shamir's original paper:
    and the Wikipedia page:

@_date: 2007-01-20 19:43:40
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: MS responds to Gutmann's Vista paper 
Aside from admitting to increased CPU utilization, which seemed pretty
incontestable anyway, they're disputing [0] many of the points made in
the original paper [1]. Ignoring the hand-wavy arguments, I find most
interesting their claims that a) there will be no move away from unified
drivers, b) that HFS doesn't depend on, and therefore won't impact, open
source drivers, and c) that video quality is degraded only for specific
premium content rather than globally. Assuming all three are true, this
would downgrade the Vista content protection system from
"cataclysmically braindead" to merely "extremely braindead" -- a welcome
downgrade, given all of Peter's other points.
[1]

@_date: 2007-01-20 19:54:43
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: MS responds to Gutmann's Vista paper 
[Perry -- had a clause in there that made no sense; I shouldn't send
mail minutes after waking up. Please discard previous mail and send
along this one.]
[Moderator's note: Too late, sorry. --Perry]
Aside from admitting to increased CPU utilization, which seemed pretty
incontestable anyway, they're disputing [0] many of the points made in
the original paper [1]. Ignoring the hand-wavy arguments, I find most
interesting their claims that a) there will be no move away from unified
drivers, b) that HFS doesn't depend on driver-related video chip
features, and therefore won't impact (the creation of) open source
drivers, and c) that video quality is degraded only for specific premium
content rather than globally. Assuming all three are true, this would
downgrade the Vista content protection system from "cataclysmically
braindead" to merely "extremely braindead" -- a welcome downgrade, given
all of Peter's other points.
[1]

@_date: 2007-01-23 20:22:38
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: more on NIST hash competition 
I'm completely unfamiliar with the way NIST operates, but I've been
wondering for years why they haven't organized this competition already.
Do we have a list veteran who can shed some light on why it took them
this long? My curiosity demands to know.

@_date: 2007-07-16 22:25:19
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: improving ssh 
None of these are crypto issues. The OpenSSH dev list (http://  would almost certainly lend itself to a  more productive discussion of these concerns. Cheers,
Ivan Krsti?  |

@_date: 2007-06-12 03:39:42
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Free Rootkit with Every New Intel Machine 
It appears Active Management is a setting that can be disabled normally
from the BIOS, like with TPMs today:
I couldn't find a conclusive statement one way or the other, but I
expect it'll also be turned off by default for consumer machines. That
still leaves a slew of open questions, but makes it less initially
alarming, I'd say.

@_date: 2007-06-21 14:40:09
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Blackberries insecure? 
Doesn't this run into the common problem of "supposedly it's secure, but
they're not offering the source", just like with e.g. Skype, TPM RNGs,
all commercial hardware security modules that I'm aware of, etc?
Personally, I found a SymbianOS phone with a full keyboard that's
lighter, thinner and more stylish than the Blackberry, runs Python and
exposes most of the phone functionality to it through a set of APIs, and
is happy to grab my mail via IMAP+SSL. With an unlimited data plan, who
cares if it's pull instead of push e-mail?

@_date: 2007-06-22 23:39:01
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Blackberries insecure? 
[Perry -- I have no connection to Nokia whatsoever and am thrilled with
the phone in question, but the message below sounds like an
advertisement so please reject from the list if inappropriate.]
[Moderator's note: this is off topic, but there were a couple of "what
is that phone" messages to the list so clearly enough readers want to
know where to get a phone that runs real ssl and ssh. No followups,
please -- the list has been off topic enough lately already. --Perry]
Nokia E61i, an update of the E61:
        It's not available directly from service providers in the states who
only sell the E62, which is a crippled E61. It has wifi, Bluetooth,
takes additional microSD storage, exposes its drive (and SD card) as a
standard USB hard drive, has a decent music player and built-in zooming
web browser, runs Acrobat reader and Opera, can sync with Google
calendar with a third party program, runs putty as an ssh client,
supports viewing Office documents and has all the other features you'd
expect from a business phone (e.g. timed profiles and phone ACLs --
instead of turning off or muting your phone at night, you can, for
instance, specify that only certain people can call you.)

@_date: 2007-06-23 00:03:23
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Free Rootkit with Every New Intel Machine 
Right, but I think people's fears about Active Management are mostly
related to personal machines. If you're using a work-issued laptop,
you're already more or less at the complete mercy of your IT admins. AMT
gives them the ability to make the chokehold they already have over your
machine stronger.
The really troubling question that I see is how we can ascertain that
AMT can't be enabled remotely on an arbitrary machine. Let the
conspiracy theories begin.

@_date: 2007-06-23 16:32:33
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Free Rootkit with Every New Intel Machine 
Of the 25 business laptop models that HP offers on its site right now,
only 5 don't have a TPM installed.

@_date: 2007-06-28 20:08:15
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Quantum Cryptography 
I wrote a reply agreeing violently with your sentiments, and then  realized I sent the same e-mail to this list two years ago:
"I have to agree with Perry on this one: I simply can't see a compelling
reason for the push currently being given to ridiculously overpriced
implementations of what started off as a lab toy, and what offers - in
all seriousness - almost no practical benefits over the proper use of
conventional techniques. Besides, any of the ultrasecret applications
that *might* (I remain very skeptical) call for such a level of
confidentiality - things like military communication or diplomatic
message exchange between a country and its ambassadors - are all too
likely to be out of the range currently offered by these QC setups (last
I read, if I'm not mistaken, it was about 50 km or ~30 miles). Fine, the
range might improve - but I doubt that the amount of money and hassle
required to set these up will."
  -- from Later in the thread, I opined that:
"[t]he way I see this is that there are two options: consumers can  the security of their data to physics they don't understand, or
mathematics they don't understand. One of the fundamental differences is
that the former *no one* understands, and its price reflects that. With
the latter, well - quite a few people understand the math behind crypto,
and silicon is cheap these days. So what are people waiting for? Why
doesn't everyone concerned for their link security have a pair of cheap
strong crypto devices at both ends?"
I can't say I understand this fascination with photons for any  practical cryptographic purpose any better now than I did back then,  but I'm certainly more amused by it. May I coin "quantum  craptography" as a better expansion of the abbreviation QC?
Ivan Krsti?  | GPG: 0x147C722D

@_date: 2007-06-30 12:46:29
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Quantum Cryptography 
The problem I have with QC is that, as others have amply pointed out,  there is a lot of bathwater but not much of a baby to speak of. If  someone created a protocol that does a DH exchange at the beginning  and then throws away the secret and performs the rest of the  communication in plaintext, we'd hardly call the resulting system a  "cryptographic protocol". Really, we'd be hesitant to use any form of  the word cryptography in the description.
"QC", however, does something exactly analogous: it performs a  quantum key exchange and then falls back on classical primitives.  It's at best confusing, fallacious and disingenuous to refer to such  setups as quantum cryptography, though I understand "classical  encryption with quantum key exchange" has less of a marketable ring  to it.
So, by all means, let the QKD and related research continue. It's  interesting, it's cool, it's *important* work. But when the folks  behind it are talking to those of us who understand and work with  cryptography every day, they need to do a much better job at not  letting their own imprecise and almost deceitful terminology paint  themselves in a corner and trigger our snakeoil detectors. I deeply  support Jon's proposal of renaming the whole thing "quantum secrecy",  in which case I'd get off my snark horse and show more respect for  the whole thing.
Ivan Krsti?  | GPG: 0x147C722D

@_date: 2007-05-02 12:50:24
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: 128 bit number T-shirt? 
But all the artwork is just ugly numbers in a monospace font. Someone
needs to rope in a designer to make a tastefully designed shirt with my
favorite new color scheme, called 'append c0':
    Original by O. Day can be found at  by searching
for 'append c0' (Flash needed).

@_date: 2007-05-20 12:44:22
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: 0wned .gov machines (was Re: Russian cyberwar against Estonia?) 
I think it's anything but surprising. There's only so much you can do to
significantly improve systems security if you're unwilling to break
backwards compatibility -- many of the fundamental premises of desktop
security are fatally flawed, chief among them the idea that all programs
execute with the full privileges of the executing user.
One Laptop per Child is breaking application backwards compatibility for
a number of reasons, one of which is security. As a result, I'm
earnestly hoping that our systems security platform, Bitfrost[0], will
be an improvement on the scale you're talking about. But time will tell.
(Sidenote: I'm giving a keynote at AusCERT tomorrow about exactly this,
titled 'Everything you know about desktop security is wrong, or: How I
Learned to Stop Worrying and Love the Virtual Machine'. Any list members
who are at the conference should mail me if they want to play with an
OLPC laptop and commiserate about desktop security over beer.)
[0] Summary at  with full spec at

@_date: 2007-05-22 12:20:30
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: Russian cyberwar against Estonia? 
Some years back, I was on the receiving end of this type of scenario
bringing down connectivity for a small European country, and it was a
larger one than Estonia.
Out of curiosity, does anyone have information on how fat Estonia's
external pipes are?

@_date: 2007-05-23 00:48:29
@_author: =?UTF-8?B?SXZhbiBLcnN0acSH?= 
@_subject: 307 digit number factored 
That can't happen until we make sure you can trust DNS, which in turn
can't happen until we get a concrete proposal that has clearly defined
goals and isn't braindead. As has been amply pointed out, it's not clear
that DNSSEC will cut it anytime soon.
(These days, the complaints even come with illustrations:

@_date: 2007-10-04 05:25:37
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
Precisely. If you're keeping secrets from your nosy siblings and  coworkers, hardware FDE is more than adequate. If you have reason to  believe someone skilled and resourceful might really want your data,  you almost certainly have no business using a blackbox encryption  system operating in a way that's not publicly documented -- even if  the system is buzzword-compliant -- and implemented by a company  (hard disk vendor) where crypto is about as far from their core  competency as you can get.
Ivan Krsti?  |

@_date: 2007-10-30 10:54:56
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Full Disk Encryption solutions selected for US Government use 
Right -- I was unaware that Windows actually had any real (pre-boot)  FDE solutions before about the time of BitLocker. But I only  peripherally have any idea about Windows crypto solutions, so I  wouldn't be surprised if I'm wrong. Cheers,
Ivan Krsti?  |

@_date: 2007-09-07 16:16:50
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
Plain AES-CBC is not a great choice for FDE. You can do whatever  you'd like to the bits of a given block at the cost of garbling the  previous block, which makes binaries a plausible target. Given the  size of modern OSes, it might even be an easy one.
Ivan Krsti?  |

@_date: 2007-09-16 12:35:20
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: using SRAM state as a source of randomness 
If you care about your randomness, you don't want to be making the  assumption that a source is random because "it sometimes looks that  way, sort of". You want to be using a source that's assumed random  because, as far as you know, it's very hard for it to be any other way.
Clearly, SRAM state falls into the former category, and there are  lots and lots of variables keeping it firmly outside the latter. This  means the usual wisdom applies: if you really need the extra entropy,  mix some of these SRAM state bits into your pool, but make sure  you're also feeding the pool from at least one source about whose  randomness you can reason strongly.
Ivan Krsti?  |

@_date: 2007-09-20 08:08:32
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Scare tactic? 
If the affected software is doing DH with a malicious/compromised  peer, the peer can make it arrive at a predictable secret -- which  would be known to some passive listener. But hey, if the peer is  malicious or compromised to begin with, it could just as well do DH  normally and explicitly send the secret to the listener when it's  done. Not much to see here.
Ivan Krsti?  |

@_date: 2008-04-27 03:40:50
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: "Designing and implementing malicious hardware" 
I was reminded of the same contest[0]. The winning date-agnostic  entry[1] was by Micha? Zalewski[2], and is nothing short of evil. I  spotted the problem after staring at the code intensely for about a  half hour, knowing in advance it was there. Had I not known, I don't  think I'd have found it.
[0] [1] [2] Ivan Krsti?  |

@_date: 2008-04-29 02:15:12
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: defending against evil in all layers of hardware and software 
I think you just described all of security.
Ivan Krsti?  |

@_date: 2008-04-29 02:18:11
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: defending against evil in all layers of hardware and software 
The OLPC XO-1 laptop has an open-source bootloader (Open Firmware)  which checks the operating system signature before passing control to  Ivan Krsti?  |

@_date: 2008-12-26 01:35:43
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: two bits of light holiday reading 
Jonathan Zittrain's[0] latest book, 'The Future of the Internet and  How to Stop It', is available as a free PDF licensed under CC-BY-NC-SA:
While not dealing with cryptography per se, it does focus on the wider  implications of the worsening situation in modern computer security,  and what it means for the new computing platforms we're seeing now and  in the future. Zittrain is one of the foremost cyberlaw thinkers on  the planet; given a number of discussions on this list, I thought the  book would be of interest to subscribers.
[0] The DC-based Center for Strategic and International Studies recently  released a report titled 'Securing Cyberspace for the 44th Presidency'  written by a number of influential authors:
Of most interest to this list, the report suggests going on the  offensive with regard to identity management, proposing to restrict  bonuses and awards of US federal agencies not using strong digital  credentials for employees in sufficient numbers (logical pp. 61-65).  Maybe, uh, it'll work this time around?
Ivan Krsti?  |

@_date: 2008-02-04 05:54:06
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: TLS-SRP & TLS-PSK support in browsers (Re: Dutch Transport Card Broken) 
I don't know about other browsers, but Mozilla's CSO-type is Window  Snyder who I'd easily describe as a pretty top-notch "security person".
Ivan Krsti?  |

@_date: 2008-02-04 06:25:14
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Gutmann Soundwave Therapy 
I think this misses the point. Security is different.
In 2008, I can learn to build pretty good suspension bridges by  learning the state of the art of bridge-building. After that, as long  as I live, I run almost no risk of Newtonian mechanics being shown to  be wrong for any value of wrong that would make me go "well, wow, I no  longer understand how to build bridges".
In other words, people who build bridges these days can give you a  convincing presentation, based on solid physics and a highly-complete  threat model (soil erosion, material failure, etc) that their bridge  will do its job. They can say "this bridge will work because it  satisfies well-understood and reasonably immutable laws of nature".
People who attempt to build secure systems have no ultimately well- understood (let alone immutable!) requirements to design against. A  good approximation is "a secure system is one that survives all  relevant attacks that people in our field have come up with thus far",  but it's clear that a system successfully meeting that goal can simply  cease to meet it any given day. Thus unlike with bridges, you  fundamentally can't evaluate the quality of a security system you  built if you're unfamiliar with the state of the art of _attacks_  against security systems, and you can't become familiar with those  unless you realize that these attacks have each brought down a system  previously considered impregnable. And if by the time you've gone  through dozens of broken systems and their corresponding attacks you  still think you're smart enough to write a new system by yourself,  you're either very brave or very daft.
Neither of those mean you're a bad person, but both mean you shouldn't  be designing security systems.
Ivan Krsti?  |

@_date: 2008-02-21 23:13:56
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: cold boot attacks on disk encryption 
Er, what do TPMs have to do with this at all? TPMs are not tamper- proof hardware FDE devices. They're somewhat tamper-proof (in  practice, I wouldn't depend on it) non-volatile storage for small  amounts of sensitive data, such as encryption keys. But as long as  it's software that's driving your FD encryption, you need to have your  keys in RAM.
So, either:
* The TPM is used in 'basic' mode, where its only purpose is to
   provide a measure of tamper-resistance to the boot path, and as
   long as no boot-time tampering is detected, the FDE key will be
   loaded into RAM automatically,
* The TPM requires explicit authentication (e.g. by password or
   smart card) before releasing the key, in which case a successful
   authentication will load the FDE key in RAM.
If the machine is running and the FDE in use -- which is the entire  premise behind this attack -- both TPM use cases are just as  vulnerable. TPMs are a red herring in this discussion, unless the FDE  was actually offloading the crypto operations to it. This is not a  supported mode of operation for any widely-deployed FDE system that  I'm familiar with.
So, is anyone else as amused as I am that Apple can release an EFI  firmware update to zeroize MacBook Air memory at boot-time, turning  the heretofore widely-decried inability to upgrade that laptop's RAM

@_date: 2008-01-03 07:20:01
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Death of antivirus software imminent 
It's not, and despite the press handwaving about hypervisor rootkits  being the death of all security as we know it, this attack is largely  uninteresting in practice. Repeat after me: it's not a real problem,  and it's unlikely to become a real problem.
A walkthrough with pretty pictures, courtesy of the Matasano folk:
Ivan Krsti?  |

@_date: 2008-01-05 19:33:43
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Question on export issues 
Our outside counsel -- specializing in this area -- thought this was  insufficient. That said, thanks for all the feedback in the thread --  I'll pass the information back and try to figure out what the  difficulties were, posting here if anything interesting becomes  Ivan Krsti?  |

@_date: 2008-01-07 08:16:47
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Death of antivirus software imminent 
I don't think this is really being said. In fact, I've been pretty  concretely saying "here's an OS not designed from scratch, but with  certain pieces modified, that's likely to be extremely resistant to  viruses, malware and other pests", in regard to the OS being designed  for the OLPC. We're still implementing large chunks of the security  system, but my spec[0] has been public for a year, our security  working group contains a number of people from this list, and no one  so far has claimed that this design won't successfully resist most --  though not all -- classes of attacks we've seen or can presently  imagine seeing in the desktop security realm.
[0] Ivan Krsti?  |

@_date: 2008-01-29 14:59:12
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Dutch Transport Card Broken 
I'm beginning to suspect that more often than not, this nonsense is a  result of market forces rather than idiot technologists. In my  experience, senior decision-maker types outside of the computer  industry (and even within it, but perhaps a tad less so) are  sufficiently non-technical as to never have heard of Kerckhoffs'  principle -- and to disbelieve it when they do, since it opposes their  intuition of what makes for secure systems. Various companies (or  departments) then emerge peddling their home-grown crypto and  trumpeting the fact that it's proprietary as a feature, commonly going  hand in hand with stupidly large key sizes.
Some number of these muppets approached me over the last couple of  years offering to donate a free license for their excellent products.  I used to be more polite about it, but nowadays I ask that they Google  the famous Gutmann Sound Wave Therapy[0] and mail me afterwards.
I've never heard back.
[0] Last paragraph, Ivan Krsti?  |

@_date: 2008-01-31 19:29:43
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Gutmann Soundwave Therapy 
The wider point of Peter's writeup -- and of the therapy -- is that  developers working on security tools should _know_ they're working in  a notoriously, infamously hard field where the odds are  _overwhelmingly_ against them if they choose to engineer new solutions.
With such understanding, no competent developer should ever set out to  build new cryptosystems unless he can explain, point by point, why his  needs cannot be met by existing, vetted systems. That explanation  should ideally be made public for dissection by the community.
Ivan Krsti?  |

@_date: 2008-07-01 23:53:11
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: The wisdom of the ill informed 
As a data point, the largest bank in Croatia used to mail customers  pre-printed TAN lists. Some number of years ago, they switched to (non- SecurID) tokens which require a 4-digit PIN to turn on, and then  provide two functions: a login OTP and a challenge/response system for  authorizing individual transactions. Your username is simply the  token's serial number, though it's not clear if these are in fact  Ivan Krsti?  |

@_date: 2008-07-30 14:55:33
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: On the "randomness" of DNS 
I boggled a bit at the abuse of simple descriptive statistics, too.  For those interested in actual statistical tests of randomness,  there's a good literature survey at .
Ivan Krsti?  |

@_date: 2008-06-01 11:36:55
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Protection mail at rest 
I doubt there'll ever be much demand. The tinfoil hat crowd will be  bothered by the n-1 hops (and however many Narus boxes in between)  being traversed unencrypted, while most everyone else seemingly  doesn't care and uses GMail/Hotmail/YahooMail, forfeiting any  expectation of privacy right from the start.
The easiest thing for people who _do_ care is still running their own  mail server. The emergence of reasonably priced VM hosting providers  (e.g. slicehost.com) makes it fairly uncomplicated, modulo initial  Ivan Krsti?  |

@_date: 2008-06-11 23:38:09
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: A call for aid in cracking a 1024-bit malware key 
Exactly right. After Storm, I don't think anyone reasonable still  believes that there's no talent in the black hat community. So even if  this particular piece of malware has implementation issues, the next  version won't. And then what?
Focusing on the crypto is just missing the point entirely, although I  suppose it grabs headlines. But the problem at hand has nothing to do  with crypto, and  everything to do with the fact that our desktop  security systems are fundamentally broken[0]. There is _no_ _reason_  that a piece of malware executing silently in the background should  have access to the user's files without interaction or approval from  the user. And you can't maliciously encrypt files you can't access.
We know how to build systems that are both drastically more secure and  more usable than the ones in use today[1]. I wonder if a proliferation  of headline-grabbing threats like cryptographic ransomware will help  overcome the OS vendor inertia.
[0] See first half of . Note: I'm no longer affiliated with OLPC.
[1] E.g. , , Ivan Krsti?  |

@_date: 2008-06-11 23:38:09
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: A call for aid in cracking a 1024-bit malware key 
Exactly right. After Storm, I don't think anyone reasonable still  believes that there's no talent in the black hat community. So even if  this particular piece of malware has implementation issues, the next  version won't. And then what?
Focusing on the crypto is just missing the point entirely, although I  suppose it grabs headlines. But the problem at hand has nothing to do  with crypto, and  everything to do with the fact that our desktop  security systems are fundamentally broken[0]. There is _no_ _reason_  that a piece of malware executing silently in the background should  have access to the user's files without interaction or approval from  the user. And you can't maliciously encrypt files you can't access.
We know how to build systems that are both drastically more secure and  more usable than the ones in use today[1]. I wonder if a proliferation  of headline-grabbing threats like cryptographic ransomware will help  overcome the OS vendor inertia.
[0] See first half of . Note: I'm no longer affiliated with OLPC.
[1] E.g. , , Ivan Krsti?  |

@_date: 2008-06-30 21:38:49
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: The wisdom of the ill informed 
How security non-experts screwed up security in systems like WEP and  PPTP is no mystery to me. How, on the other hand, a real expert at  _anything_ feels comfortable entering another hard technical field  without screaming for assistance is something I don't get at all.
That a roomful of network experts designing 802.11 didn't hold hands  and all together chant "bring us a good cryptographer" with such  maniacal monophony as to rival any Gregorian choir makes me highly  suspicious about their supposed expertise with _networks_.
Ivan Krsti?  |

@_date: 2008-03-29 17:46:47
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: presentations about encrypted storage 
On Mar 28, 2008, at 5:48 PM, travis+ml-cryptography at subspacefield.org  On a similar note, list readers might enjoy the detailed writeup of  Tahoe, the secure distributed erasure-coded filesystem built by Zooko  and the folks at allmydata.org:
Perry forwarded the Tahoe 0.9 announcement to the list, but it didn't  include a link to this writeup, which might not have existed at the  time. As an unrelated bonus and since it doesn't merit a separate  post, here's a (well-sung!) crypto take on Harry Belafonte's Banana  Boat Song:
Ivan Krsti?  |

@_date: 2008-03-30 05:17:52
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: [p2p-hackers] convergent encryption reconsidered 
How is this conceptually different from classic dictionary attacks,  and why does e.g. running the file through PBKDF2 and using the result  for convergence not address your concern(s)?
Ivan Krsti?  |

@_date: 2008-03-30 17:13:07
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: [p2p-hackers] convergent encryption reconsidered 
Unless I'm misunderstanding Zooko's writeup, he's worried about an  attacker going from a partially-known plaintext (e.g. a form bank  letter) to a completely-known plaintext by repeating the following  1. take partially known plaintext
2. make a guess, randomly or more intelligently where possible,
    about the unknown parts
3. take the current integrated partial+guessed plaintext, hash
    to obtain convergence key
4. verify whether that key exists in the storage index
5. if yes, you've found the full plaintext. if not, repeat from '2'.
That's a brute force search. If your convergence key, instead of being  a simple file hash, is obtained through a deterministic but  computationally expensive function such as PBKDF2 (or the OpenBSD  bcrypt, etc), then step 3 makes an exhaustive search prohibitive in  most cases while not interfering with normal filesystem operation.  What am I missing?
Ivan Krsti?  |

@_date: 2008-03-31 06:47:47
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: [p2p-hackers] convergent encryption reconsidered -- salting and key-strengthening 
Tahoe doesn't run this service either. I can't use it to make guesses  at any of the values you mentioned. I can use it to make guesses at  whole documents incorporating such values, which is in most cases a  highly non-trivial distinction.
To make such guesses, I need to account for at least:
- file formats, since an e-mail message has a different on-disk
   representation depending on the recipient's e-mail client,
- temporal and transport variance, as PDF documents generally
   incorporate a generation timestamp, and e-mail messages include
   routing headers (with timestamps!),
- document modifications due to variables other than the one(s) being
   guessed, e.g. names, e-mail addresses, customized unsubscribe links.
I would be interested to see an actual real-world example of how a  document would fall to this attack. It strikes me as a cute threat in  theory, but uninteresting in practice.
Sometimes, under highly peculiar circumstances, etc.
FWIW, I have discussed this threat verbally with colleagues when I was  asked for possible designs for OLPC's server-based automatic backup  system. I dismissed it at the time as 'not a real-world concern'. I  might even have it in my notes, but those weren't published, so it's  Yeah, sorry, I wasn't being clear. I should've just said "a key  strengthening function" rather than naming anything in particular.
Adding, say, 5 seconds of computation to the time it takes to store a  file is likely to be lost as noise in comparison with the actual  network upload time, while still making an attacker's life  _dramatically_ harder than now.
Again, is there a real-world example of the kind of data or documents  that would show this to be a serious problem? While it's technically  true that you're targeting all the users in parallel when brute  forcing, note that if you're not actually hyper-targeting your attack,  you need to brute force _all_ the variables I mention above in  parallel, except in pathological cases -- and those, if you know of  some, would be interesting for the discussion.
The OpenBSD eksblowfish/bcrypt design can't be bitsliced and generally  doesn't lend itself well to large speedups in hardware, by design.
Ivan Krsti?  |

@_date: 2008-03-31 06:59:04
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: [p2p-hackers] convergent encryption reconsidered 
This isn't a good design. It's incompatible with Tahoe's present  architecture, introduces a single point of failure, centralizes the  otherwise by-design decentralized filesystem, and presents a simple  way to mount denial of service attacks. Finally, since the  decentralization in Tahoe is part of its security design (storage  servers aren't trusted), you run into the usual quis custodiet ipsos  custodes problem with the ticket-issuing server that the present  system nicely avoids.
Ivan Krsti?  |

@_date: 2008-05-02 20:27:14
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: New result in predicate encryption: disjunction support 
This is fairly interesting: AFAIK the first generalization of  predicate encryption to support disjunctions. I find the result mostly  interesting mathematically, since I expect we won't be seeing  predicate encryption in widespread use anytime soon due to complexity  and regulatory concerns. --IK
"Predicate Encryption Supporting Disjunctions, Polynomial Equations,  and Inner Products"
Jonathan Katz and Amit Sahai and Brent Waters
Preprint: Abstract: Predicate encryption is a new paradigm generalizing, among  other things, identity-based encryption. In a predicate encryption  scheme, secret keys correspond to predicates and ciphertexts are  associated with attributes; the secret key SK_f corresponding to the  predicate f can be used to decrypt a ciphertext associated with  attribute I if and only if f(I)=1. Constructions of such schemes are  currently known for relatively few classes of predicates.
We construct such a scheme for predicates corresponding to the  evaluation of inner products over N (for some large integer N). This,  in turn, enables constructions in which predicates correspond to the  evaluation of disjunctions, polynomials, CNF/DNF formulae, or  threshold predicates (among others). Besides serving as what we feel  is a significant step forward in the theory of predicate encryption,  our results lead to a number of applications that are interesting in  their own right.
Ivan Krsti?  |

@_date: 2008-05-26 02:27:48
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: The perils of security tools 
Not a direct answer to your question, but somewhat relevant as context  is Michal Zalewski's analysis of TCP/IP sequence number predictability  across operating systems:
It's several years out of date, however.
Ivan Krsti?  |

@_date: 2008-11-29 21:51:18
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: e-gold and e-go1d 
============================== START ==============================
The definition of lookalike glyphs depends on the choice of font and  variant, and Unicode wraps the whole problem in a lovely layer of  hell. If I had to do this, I'd investigate rendering both strings in  the (same) target font and then quantifying the amount of overlap in  the bitmaps, as e.g. SWORD does for TLDs:
The above is proprietary; NIST's Paul Black has Python code available  for a slightly enhanced Levenshtein distance:
Ivan Krsti?  |

@_date: 2009-02-01 23:53:40
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Obama's secure PDA 
As a postscript, it appears this type of proxy is exactly what's been  set up:
     "To minimize the risk, the government technology gurus
      have made it impossible to forward e-mail messages from
      the president or to send him attachments, people
      informed about the precautions say."
      -- Ivan Krsti?  |

@_date: 2009-02-17 20:36:40
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: how to properly secure non-ssl logins (php + ajax) 
What's the threat model?
That you're hashing the username suggests you're worried about  eavesdroppers identifying the user at login time. But without SSL,  it'll almost certainly be trivial for an eavesdropper to identify the  user _after_ they login. What's the threat model?
It is incorrect to rely on a bijection between IPs and users.
What you're calling a system hash is usually referred to as salt.
This is a completely broken approach, and prohibitive for applications  with more than a handful of users.
I suggest you start by trying to write down a clear, brief and  coherent threat model. Once that's done, you can solicit feedback  until you're satisfied with the definition of what you're trying to  build. Once you can focus on implementation, I suggest looking at  things like bcrypt, PBKDF2, and SRP as background reading.
Ivan Krsti?  |

@_date: 2009-01-26 02:49:31
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Obama's secure PDA 
As I'm sure many of you've heard by now, after some initial hesitation  due to legal requirements regarding the preservation of presidential  records, Mr. Obama has been allowed to continue using a wireless e- mail device after assuming the presidency. There are still conflicting  reports about whether the hardware is an altered RIM BlackBerry or a  different device, though the most likely contender for the latter  option appears to be the General Dynamics Sect?ra Edge, which features  a "trusted [secondary] display" and two buttons used to switch between  classified and unclassified operation. Some details from Declan  Manufacturer site and (not very detailed) specs:
I know next to nothing about the state of the art of secure cell  devices; do list members have any (public) knowledge or informed  speculation about the mechanism behind the unclassified/classified  switches? Are we talking two entire separate CPUs with a mutex-shared  screen/keyboard? Or just offload of classified processing to a  separate on-chip security domain (ala ARM TrustZone)? Similarly, the  manufacturer lists separate class/unclass memory chips and separate  class/unclass USB ports. Are these sitting on two physically separate  Finally, any idea why the Sect?ra is certified up to Top Secret for  voice but only up to Secret for e-mail? (That is, what are the  differing requirements?)
Ivan Krsti?  |

@_date: 2009-01-29 23:17:57
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Obama's secure PDA 
Multiple responses inline:
See sections 'Secure Speech Processing' and 'Interoperability' of . The standard suites are used, as one would expect.
This isn't the case; AES is approved for Top Secret with 192- or 256- bit keys, per .
I've thought about this, but I don't buy it. I'm a heavy user of  wireless e-mail, but I use it as nothing more than a SMTP-addressable  SMS service without a length limit. In other words, people can send me  messages from a computer and not just from a mobile handset (true in  the other direction, too), and I can read and write more than 160  characters at a time.
I'd find mobile e-mail just as useful if it went through a proxy that  stripped out _everything_ that's not plaintext. I open attachments on  my phone about once in a blue moon, and wouldn't miss the ability if  it were gone.
Ivan Krsti?  |

@_date: 2009-06-28 13:05:23
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: password safes for mac 
System applications and non-broken 3rd party applications on OS X  store credentials in Keychain, which is a system facility for keeping  secrets. Your user keychain is encrypted with your login password, and  items in it have application-level ACLs ("this credential can only be  read by these applications"). The definition of "application" for the  purpose of Keychain ACLs is derived from OS X code signing, so if  someone tampers with one of your apps on disk, the resulting  application won't get access to Keychain until you explicitly approve  You can inspect and modify your keychain with the Keychain Access  application, which also allows you to add your own items.
Ivan Krsti?  |

@_date: 2009-03-03 17:37:40
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
In terms of fairly widely used software, yes, TrueCrypt offers hidden  I asked the same original question on this list in 2004, and some  other software is mentioned in the replies:
Ivan Krsti?  |

@_date: 2009-03-03 18:00:34
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
Why do you think it'd be obvious to you and me that a disk has  multiple encrypted views? Contempt carries a burden of proof. If the  guy has two encrypted volumes, one with a bunch of hardcore adult porn  and the other with a bunch of kiddie porn, how does his unlocking the  first one give you a 'preponderance of evidence' that he's obstructing  justice or disobeying the court? It becomes a he-said-she-said with  the CBP agent, your word against his.
Ivan Krsti?  |

@_date: 2009-03-03 21:33:23
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
You miss the point.
Re-read the link I provided that explains how TrueCrypt implements  hidden volumes. A hidden TrueCrypt volume is *completely  indistinguishable* from empty space in a regular TrueCrypt volume.  That's what makes it hidden!
As I implied in the 2004 message in the context of political  dissidents, a good use for hidden volumes isn't to distract your  prosecutor with kittens and sunsets. That's just plain stupid,  regardless of whether you're dealing with a US judge or someone whose  preferred method of communication involves a pair of pliers and a  The idea is to present an alternative but *plausible* set of  information that's far less incriminating than the real deal, such as  only mildly illegal material or legal material that the owner would  still plausibly wish to keep secret for social reasons. I gave you a  concrete example: hardcore or fetish porn (legal, but plausibly not  the kind of thing whose possession you wish to advertise) provided to  investigators to mask a secret volume with kiddie porn.
If you give me the benefit of the doubt for having a reasonable  general grasp of the legal system and not thinking the judge is an  automaton or an idiot, can you explain to me how you think the judge  can meet the burden of proof for contempt in this instance? Surely you  don't wish to say that anyone using encryption can be held in contempt  on the _chance_ they're not divulging all the information; what, then,  is the other explanation?
Ivan Krsti?  |

@_date: 2009-10-26 23:19:08
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Security of Mac Keychain, File Vault 
Shrug. He doesn't explain what 'broken' means to him or under what  threat model, and dammit, security without a threat model is like  motherhood without apple pie. I can "easily break" a bank vault by  putting an MP5 to the head of the guy with the key, but that's hardly  the vault's fault, now is it?
Ivan Krsti?  |

@_date: 2009-09-14 23:57:49
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Bringing Tahoe ideas to HTTP 
What you're proposing amounts to a great deal of complex and  complicated cryptography. If it were implemented tomorrow, it would  take years for the most serious of implementation errors to get weeded  out, and some years thereafter for proper interoperability in corner  cases. In the meantime, mobile device makers would track you down for  the express purpose of breaking into your house at night to pee in  your Cheerios, as retaliation for making them explain to their  customers why their mobile web browsing is either half the speed it  used to be, or not as secure as on the desktop, with no particularly  explicable upside.
It bugs the hell out of me when smart, technical people spend time and  effort devising solutions in search of problems. You need to *start*  with the sorts of vulnerabilities you want to do away with, or the  kinds of new applications you can build that current security systems  don't address, and *then* work your way to solutions that enable those  use cases.
It's okay to do it in reverse order in the academia, but you seem to  be talking about real-world systems. And in real-world systems, you  don't get to play Jeopardy with cryptography.
Ivan Krsti?  |

@_date: 2009-09-16 13:44:55
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: Bringing Tahoe ideas to HTTP 
Yes, and I'd be happy to opine on that as soon as someone told me what  those important problems are.
Ivan Krsti?  |

@_date: 2009-09-22 00:18:30
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: FileVault on other than home directories on MacOS? 
FileVault is essentially just the name for a plain encrypted disk  image which happens to have some voodoo associated with it to get  pivoted in as your homedir at login. This to say, you can make  arbitrarily many encrypted disk images with Disk Utility and use them  as individual encrypted (non-homedir) folders. If you're asking  whether you can turn on encryption for existing system folders, the  answer is no; HFS+ itself offers no encryption facilities.
TrueCrypt is a fine solution and indeed very helpful if you need cross- platform encrypted volumes; it lets you trivially make an encrypted  USB key you can use on Linux, Windows and OS X. If you're *just*  talking about OS X, I don't believe TrueCrypt offers any advantages  over encrypted disk images unless you're big on conspiracy theories.
Ivan Krsti?  |

@_date: 2009-09-23 19:30:15
@_author: =?UTF-8?Q?Ivan_Krsti=C4=87?= 
@_subject: FileVault on other than home directories on MacOS? 
Unlike FileVault whose keys (have to) persist in memory for the  duration of the login session, individual encrypted disk images are  mounted on demand and their keys destroyed from memory on unmount.
XTS certainly doesn't provide cryptographic integrity. It provides  different ciphertext malleability characteristics than CBC, in that  you can only randomize an arbitrary 16-byte block of plaintext instead  of being able to flip an arbitrary bit (and screw up the previous  block). However, this comes with other costs inherent to seekable  narrow-block encryption, so I think it's hard to argue XTS provides  "more" integrity than CBC. Or were you referring to something else?
Ivan Krsti?  |
