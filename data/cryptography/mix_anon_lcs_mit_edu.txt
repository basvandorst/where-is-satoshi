
@_date: 2001-07-09 21:00:15
@_author: lcs Mixmaster Remailer 
@_subject: Zero-Knowledge proofs for valid decryption !! 
The problem can be reduced to the following: Given ElGamal ciphertext
E(m), reveal m and prove that it is the plaintext, without revealing
the private key s.  This is a subset of the problem above for the case
of 1 element, so if the problem above is solvable, this is.  And we can
show that if we can solve this, we can solve the above:
Choose another random value t and compute ( g^t * g^r, h^t * h^r * m ),
for each of m_1, m_2, m_3.  Then publish these values in a random order
(independent of the random order of the displayed m plaintexts).
Now we do a cut and choose.  The challenger picks 0 or 1 at random.  If 0
we will show that these are re-encryptions of the original ciphertexts.
If 1 we will show that these are encryptions of the claimed plaintexts.
For the 0 case, reveal t and the random order.  The challenger can verify
that the values are computed as claimed (multiplying the first terms by
g^t and the second by h^t and see if they match the claimed values).
For the 1 case, reveal the mapping between these new values and the
claimed plaintexts.  Now we have a set of ElGamal encryptions of the
plaintexts, using t+r as the exponent.  The prover doesn't know t+r,
but he can decrypt them using his private key s just as for any other
ElGamal encryption.  All he has to do is to solve the problem above of
showing that a plaintext corresponds to an ElGamal ciphertext, without
revealing his private key.
Repeat the cut and choose k times for a security level of 2^k.  This can
also be done non-interactively by standard procedures originating from
the Schnorr signature.  Thus the two problems are shown to be equivalent.
Now, as for proving validity of ElGamal decryption.  Let E(M) = (A, B)
where A = g^r and B = h^r * m.  We want to show that there is a value s
(which we won't reveal but where we have published h = g^s) such that
m = B / A^s.
Rearrange this to A^s = B / m.  In effect we want to show that the
discrete log of B/m to the base A equals the discrete log of h to the
base g.  This is a well known problem.  We do the Schnorr proof of
knowledge of a discrete log simultaneously on g^s = h and A^s = B/m,
as follows:
Choose a random value u and publish C = g^u and D = A^u.  Challenger
gives a random x.  Prover responds with y = (u + sx).  Verifier checks
the following:
g^y = g^u * (g^s)^x = C * h^x
A^y = A^u * (A^s)^x = D * (B/m)^x
If both equalities hold for the left and right terms, the proof is
Again, the Schnorr heuristic can be used to make these proofs

@_date: 2001-07-10 04:20:35
@_author: lcs Mixmaster Remailer 
@_subject: FW: Zero-Knowledge proofs for valid decryption !! 
Do you use cut and choose with an intermediate permutation, showing
that it either maps to the one or to the other?
Cut and choose in this way goes back to the very earliest work on ZK
proofs; it is the classic way to show in ZK that two graphs are identical.
Interesting point, that this problem arises very naturally in the case
of mix-nets.  They want to prove that they are operating correctly so
want to show that their outputs are the decryptions of their inputs
without revealing the correspondence.  Probably that's what motivated
the problem from the questioner?  Note to people asking questions,
as payment for the hard work of your responders you should give some
background about why your question is interesting.
I guess in this case, you'd have say (A, B, C) mapping to (1, 2, 3) and
you'd prove something like:
    (A->1  OR  A->2  OR  A->3)
AND (B->1  OR  B->2  OR  B->3)
AND (C->1  OR  C->2  OR  C->3)
This could be faster than cut and choose for small permutations, depending
on the security factor.  Unlike cut and choose the size of the proof does
not depend on the security parameter.
It seems that with cut and choose, the size of the proof is linear in the
number of texts being permuted, and linear in the security factor.  So that
does not sound too bad, although of course if you have thousands of texts
then it could get out of hand.
An interesting point with regard to the security parameter when dealing
with the Schnorr heuristic to make them non-interactive:  Often the
security parameter can be much lower in an interactive proof than in
the non-interactive form.
In an interactive proof you will probably be happy with a security
parameter of 20 bits, corresponding to 1 chance in a million of successful
cheating by the prover.  Or even 10 bits for 1 chance in a thousand may
be acceptable if the punishment for cheating is significant.  Few cheaters
would try it if they have a .999 chance of being caught and punished.
However when we turn these into non-interactive proofs using the Schnorr
heuristic (pre-commit to all values, hash them and use that to produce the
challenge bits), the equation changes.  Instead of probability of being
caught, the security parameter now represents the work necessary to find
a hash value that lets you cheat.  A security parameter of 10 means the
server needs to try 1024 times on the average to find a set of values that
satisfy the proof even though he is cheating.  A parameter of 20 means
that the server needs to try a million values to find some that work.
If the protocol is acceptably efficient in one iteration, iterating
it a thousand or even a million times may well be an acceptable cost
for a server if that allows it to cheat undetectably.  So when using
non-interactive proofs, verifiers probably will demand security parameters
of at least 40, 60 or even 80 bits.  This makes the proofs correspondingly
more expensive.

@_date: 2001-07-10 06:00:30
@_author: lcs Mixmaster Remailer 
@_subject: Zero-Knowledge proofs for valid decryption !! 
Some corrections and clarifications:
Actually this should be a different t for each ciphertext, otherwise g^t
can be figured out and the order revealed.  Also, it should be different
t values for each iteration of the cut and choose.
Although the problem statement assumed you don't know the r exponent for
the ElGamal encryption, maybe in some cases it could be made available,
embedded in the plaintext (typically r can be much smaller than m so
there may be room for it).  Then, decrypting the message would reveal r.
This allows for a greatly simplified cut and choose for the case 1,
where the mapping between the intermediate values and the claimed ElGamal
decryptions must be done.  The prover just reveals t + r mod (p-1) for
each element (this leaks no information about r), and this allows an
easy verification that the intermediate values are ElGamal encryptions
of the claimed plaintexts.  There is no need for the discrete log proof.

@_date: 2001-07-12 17:40:24
@_author: lcs Mixmaster Remailer 
@_subject: pseudonymous decentralized marketplace 
There is a lot of work in the field on auction protocols.  See the
excellent list of links at
However I don't think most of these deal with the issue of payment, they
assume some kind of pre-existing infrastructure for that.  Mostly they
are worried about collecting bids and revealing only the highest bidder.
Not knowing the issuer isn't a problem: you presumably have some way
of reaching him like a remailer reply block or a broadcast channel
where he listens.  The problem is that it doesn't really make sense to
anonymously redeem currency which is based on physical interactions.
If someone's currency is redeemable for them painting your house, you're
going to meet the painter.
If the currency is based on goods and services, then if the issuer is
anonymous, the goods/services must be such that they can be delivered
anonymously.  They could be customized information goods: Alice will write
you a porn novel customized for your kinks; Bob will produce a painting
from a photograph.  Or some physical goods could work, small items which
could be sent through the mail with reasonable anonymity for the sender
(although not for the receiver).
An alternative to the multitude of individualized currencies is a single
electronic money, managed in a distributed way.  Wei Dai's b-money,
 uses distributed servers
which each keep track of how much money each nym has, producing a global
consensus.  Or you could use any of the e-cash systems out there and
distribute the bank functions with secret sharing so that people work
cooperatively to manage currency exchanges.
But let's step out of the fantasy world for a moment.  What people
really want is to be able to use their existing money in the auction.
They don't want to be juggling exchange rates between BobBucks and
DorisDollars and a hundred other currencies.
The problem is that there aren't any very good ways of paying for goods
anonymously using ordinary money, and of course the governments are
working hard to keep it that way.
You might be able to use a multi-stage system.  Convert your dollars
to e-gold ( which although not anonymous is at
least somewhat pseudonymous.  Use your e-gold to buy e-cash, then trade
in your e-cash for new untraceable bills anonymously.  These should
be clean for use in an auction.  Let there be several cash issuers so
there is no single point of failure.  That will satisfy your customers'
needs much better than a heap of ideosyncratic currencies.

@_date: 2001-07-28 02:00:02
@_author: lcs Mixmaster Remailer 
@_subject: Criminalizing crypto criticism 
Not true.  Look closely at
 (note that
the final colon is part of the URL).
   No person shall circumvent a technological measure that effectively
   controls access to a work protected under this title.
This is the basic provision which outlaws circumvention.
   PERMISSIBLE ACTS OF ENCRYPTION RESEARCH- Notwithstanding the provisions
   of subsection (a)(1)(A), it is not a violation of that subsection for
   a person to circumvent a technological measure as applied to a copy,
   phonorecord, performance, or display of a published work in the course
   of an act of good faith encryption research if--
      [Various provisions, including making a good faith effort to get
       permission]
And this is the provision which allows encryption research even when that
involves circumvention.
Neither of these addresses publication.  This is possibly covered in
the following:
   No person shall manufacture, import, offer to the public, provide,
   or otherwise traffic in any technology, product, service, device,
   component, or part thereof, that--
      (A) is primarily designed or produced for the purpose of
      circumventing a technological measure that effectively controls
      access to a work protected under this title;
      (B) has only limited commercially significant purpose or use other
      than to circumvent a technological measure that effectively controls
      access to a work protected under this title; or
      (C) is marketed by that person or another acting in concert with
      that person with that person's knowledge for use in circumventing
      a technological measure that effectively controls access to a work
      protected under this title.
It is not at all clear that publishing a research result relating to a
cryptographic problem in a copyright protecting technology would fall
into any of these categories.  First, such a publication is clearly not a
"product, service, device, component, or part thereof".  Conceivably it
could be a "technology" although most cryptographic papers are a long
way from an actual technology.
Second, the primary purpose of such a publication is not to enable
circumvention, but to advance the state of the art in science.  Hence it
is not covered by provision (a)(2)(A), and not by (B) or (C) either.
Nevertheless if publication were to be interpreted as being covered by
this provision, there is a further exception in 1201(g):
   USE OF TECHNOLOGICAL MEANS FOR RESEARCH ACTIVITIES- Notwithstanding
   the provisions of subsection (a)(2), it is not a violation of that
   subsection for a person to--
      (A) develop and employ technological means to circumvent a
      technological measure for the sole purpose of that person performing
      the acts of good faith encryption research described in paragraph
      (2); and
      (B) provide the technological means to another person with whom he
      or she is working collaboratively for the purpose of conducting the
      acts of good faith encryption research described in paragraph (2)
      or for the purpose of having that other person verify his or her
      acts of good faith encryption research described in paragraph (2).
Again, this appears to be interpreted in the context of (A)(2) forbidding
the actual construction of devices which are are developed, employed,
and distributed.  Even if we interpret (A)(2) to include cryptographic
publications, however, the provision still applies.  Note in particular
the language in (B) which allows another person to verify the act of
good faith encryption research.  This is one of the main purposes of
publication, to allow verification of the results by others.
Hence publications which show cryptographic holes in deployed encryption
systems are exempt.  This provision also allows the distribution of
circumvention software for legitimate research purposes.
Note too the additional provision:
   Nothing in this section shall enlarge or diminish any rights of
   free speech or the press for activities using consumer electronics,
   telecommunications, or computing products.
Clearly publication of cryptographic results is a fundamental part of
free speech and will not be infringed by the DMCA.
Much of the hysteria regarding the DMCA's supposed ability to quash free
speech by cryptographic researchers is being whipped up by opponents
to the DMCA who are misrepresenting the DMCA in a calculated fashion in
order to promote opposition.  Consider two recent cases.
Dmitry Sklyarov of Russia has been arrested for violating the DMCA.
Many DMCA opponents initially claimed that he had been arrested for
discussing problems in Adobe's ebook software.  This claim was false and
has been largely abandoned now, but it has served its pupose of giving
the impression that DMCA will criminalize publication.
Princeton Professor Edward Felten and his research team were prevented
from presenting their results regarding flaws in SDMI Information
Hiding Workshop, based on a letter from the Recording Industry Association
of America which claimed that such publication would violate the DMCA.
In this case, the RIAA was mistaken about the application of the DMCA,
as the above analysis makes clear.  In fact the RIAA takes that same
position now, as seen in
The decision to pull out of the conference was made jointly by Felten,
his team, and conference organizers.  If they made the decision based
on fears of the DMCA, their decision was mistaken.
Again, anti-DMCA forces have used this case as an example of how the DMCA
supposedly prevents free speech.  In fact it is more an example of how
the misinformation spread by DMCA opponents is preventing free speech.
Had the true facts about the DMCA been widely known and disseminated,
Felten et al would have presented their paper and the RIAA's letter
would have been seen at the empty threat it was.  (Yes, lawyers issue
letters with empty threats and bluffs all the time.  It's called the
real world, folks.)
There are many problems with the DMCA, but opponents will serve their
cause best by being honest and straightforward about what the measure
does and does not do.

@_date: 2001-06-13 17:40:07
@_author: lcs Mixmaster Remailer 
@_subject: The summer of OAEP 
These are some of the papers to be presented at Crypto 2001 in August[1]:
   A Chosen Ciphertext Attack On RSA Optimal Asymmetric Encryption
   Padding (OAEP) as Standardized In PKCS    James Manger
   OAEP Reconsidered
   Victor Shoup
   RSA--OAEP is Secure Under the RSA Assumption
   Eiichiro Fujisaki, Tatsuaki Okamoto, David Pointcheval and Jacques
   Stern
   Simplified OAEP for the RSA and Rabin Functions
   Dan Boneh
Shoup's abstract[2] reads:
   The OAEP encryption scheme was introduced by Bellare and Rogaway at
   Eurocrypt '94.  It converts any trapdoor permutation scheme into a
   public-key encryption scheme.  OAEP is widely believed to provide
   resistance against adaptive chosen ciphertext attack.  The main
   justification for this belief is a supposed proof of security in the
   random oracle model, assuming the underlying trapdoor permutation
   scheme is one way.
   This paper shows conclusively that this justification is invalid.
   First, it observes that there appears to be a non-trivial gap in
   the OAEP security proof.  Second, it proves that this gap cannot
   be filled, in the sense that there can be no standard "black box"
   security reduction for OAEP.  This is done by proving that there
   exists an oracle relative to which the general OAEP scheme is insecure.
   The paper also presents a new scheme OAEP+ along with a complete
   proof of security in the random oracle model.  OAEP+ is essentially
   just as efficient as OAEP, and even has a tighter security reduction.
   It should be stressed that these results do not imply that a particular
   instantiation of OAEP, such as RSA-OAEP, is insecure.  They simply
   undermine the original justification for its security.  In fact,
   it turns out - essentially by accident, rather than by design -
   that RSA-OAEP is secure in the random oracle model; however this
   fact relies on special algebraic properties of the RSA function,
   and not on the security of the general OAEP scheme.
The Fujisaki, et al abstract[3] reads:
   Recently Victor Shoup noted that there is a gap in the widely-believed
   security result of OAEP against adaptive chosen-ciphertext
   attacks. Moreover, he showed that, presumably, OAEP cannot be
   proven secure from the one-wayness of the underlying trapdoor
   permutation. This paper establishes another result on the security of
   OAEP. It proves that OAEP offers semantic security against adaptive
   chosen-ciphertext attacks, in the random oracle model, under the
   partial-domain one-wayness of the underlying permutation. Therefore,
   this uses a formally stronger assumption. Nevertheless, since
   partial-domain one-wayness of the RSA function is equivalent to its
   (full-domain) one-wayness, it follows that the security of RSA-OAEP
   can actually be proven under the sole RSA assumption, although the
   reduction is not tight.
[1] [2] [3]

@_date: 2001-06-22 18:40:09
@_author: lcs Mixmaster Remailer 
@_subject: crypto flaw in secure mail standards 
Don Davis writes,
The only thing protected in a signed message is that portion signed.
Alice needs to say, "Bob, the deal is off."
Actually this is not enough.  Suppose Alice sends this, or equivalently
suppose we use an encryption scheme similar to what David Hopwood
describes where the inner signed portion includes the outer key.
There can still be trouble.  Suppose at some later time Alice and Bob
negotiate a new contract, and Bob wants to get out of it.  He pulls out
this old message of Alice's and stamps a new date on it, claiming that
it was with regard to their new contract negotiation.  He says that
Alice withdrew from the contract so he is not liable for any penalties.
Again the problem is that only what is signed is protected.  If the date
is not signed, it is not protected.  So the protocol has to include the
date in the signature.  (Actually I think most email encryption protocols
do this, but the point is that the formal description of what is signed
may not show that.)  Only what is signed is protected.
Even the date may not be enough.  Suppose Alice and Bob are separately
negotiating two different contracts, using a threaded mail reader
which uses Reply-To: or some similar fields in the mail header so
that exchanges with regard to one contract are shown separately from
exchanges with regard to the other.  Then Alice might send, "Bob, the
deal is off," including a date in the signature, and expect it to apply
just to the deal being negotiated in that thread, because that's how her
mail software shows it.  However Bob can take the message and claim that
it applied to the other thread.
In this case, other context that was in the minds of Alice and Bob is
not being covered by the signature.  This is really the general form of
the issue being discussed.  What is in the minds of the participants,
what assumptions are they making that are not being written down?
This is why we have lawyers and contracts and fine print.  These
institutions and practices are the result of centuries of people weaseling
out of contracts in various ways.
It is mistaken to think that we can solve this problem by a little
cryptographic legerdemain involving copying a field from the outer
encryption envelope into the inner signature.  That does not begin to
cover all of the things that can go wrong.
The only real solution is to use the advice and experience of the
legal system when negotiating a contract which will bind the parties.
Make sure everything is written down and sign a document which is as
clear, specific and free of ambiguity as possible.
It's not a cryptographic issue, and failures of this kind are not
cryptographic failures.  Cryptography can't read the minds of the
parties involved and know that all of their assumptions are included in
the signed portion.  The real solution is for the communicants to take
the responsibility to put everything there that is needed.  Only what
is signed is protected.

@_date: 2001-06-22 21:40:17
@_author: lcs Mixmaster Remailer 
@_subject: crypto flaw in secure mail standards 
That's right, and maybe some other mail headers ought to be included too.
We've all seen messages where the Subject header determines the context
of the message.  Imagine that Alice sends a message with "Subject: Milk
spoils if left out too long" and the body says, "... and I've seen it
happen, too."  Then she sends that signed, and some mischievous person
changes it to "Subject: The boss wears women's underwear" and we have
a signed message from Alice saying "... and I've seen it happen, too."
Poor Alice, she can't catch a break.

@_date: 2001-06-24 22:00:47
@_author: lcs Mixmaster Remailer 
@_subject: crypto flaw in secure mail standards 
David Wagner wrote (on sci.crypt):
I agree that something like this is the best solution.  In particular it
is much better than what was actually proposed in the paper, which was
to put the encryption key into the signature, or the signature key into
the encrypt, or to sign or encrypt twice.  Those solutions advance the
illusion that this is a cryptographic problem related to sign+encrypt,
when it is not.  (Others have observed that the same kinds of problems
arise even if the message is not encrypted at all.)  It is a confusion
about what is protected specifically in an email environment, or perhaps
it is a failure to protect some information that could or should be
protected.  More on this below.
Adding To:, etc. to the signature is the best solution in an email
environment.  As other discussions have noted, there are other fields
which could be important as well, such as Subject, Keywords, References,
In-Reply-To, etc..  In fact some have proposed that the entire set of
email headers should be protected by the signature.  This produces the
least ambiguity and possibility of error.
One cost in the context of this solution is that on the sending side the
software may have to be restructured somewhat.  Presently it is likely
that signature and encryption are done before the message is formatted
for transmission.  Many of the mail headers may be stamped on only at
that last point.  The software may have to be rearranged to make sure
that everything is available at an earlier point in the processing.
Granted, this is more of a problem in the context of retrofitting an
existing system.  It might be argued that this problem should have been
recognized from the beginning and secure email been designed to protect
the mail headers all along.
The other cost happens on the receiving side: what to do when the
protected headers don't match the outer ones?  Is this worth raising a
red flag over?  Or perhaps should the inner ones silently overwrite the
outer ones?
It might be that a certain amount of mismatch commonly occurs.
Mail headers are far from sacrosanct, and gateways, mail exploders and
forwarders do sometimes rewrite them.  If we raise a red flag every time
then people will learn to just ignore the warnings.  If we silently
overwrite then we might lose some of the advantages of the rewriting
which is done (for example mailing lists sometimes rewrite Subject to
tag it with the name of the list, to move a "Re" past the list name, etc.)
These issues can probably be solved but they require some thought and
care in implementing this proposed new capability.
Okay, but again, we are talking about confusion here.  The real problem in
these examples is a mismatch between user's expectations and/or beliefs,
and what the software actually does.  The proposed solution, especially
the crypto-only one, is to partially change the software so that it
slightly more closely approximates user's mistaken beliefs.  However this
is only a partial fix and still leaves the fundamental problem in place.
Actually the problem has not been diagnosed correctly.  The issue is
not just that people will mistakenly believe that the software protects
the recipient identity.  The more important problem is that the software
fails to routinely protect the recipient identity (and other information).
Here is how the important problem manifests itself: Alice is a manager,
and before leaving on vacation she sends mail to Bob, her subordinate,
saying, "I got the go-ahead from the VP.  We are to put the plan we
discussed into action immediately.  I'll expect to see a full status
report when I return in a week."  She comes back a week later and Bob
didn't do anything!  "Didn't you get my email?"  "Sure, but I wasn't
sure it was legitimate."  "But didn't you see I signed it?"  "Yeah,
but I couldn't be sure you sent it to me.  It might have been meant for
someone else and redirected to me."
In the real problem, the failure is that the software did not routinely
protect the fact that Bob was the recipient.  Hence he could not go on the
assumption that he was the legitimate receiver, and Alice's intention was
not met.  The difference from the earlier examples is that in those cases,
someone mistakenly thought the recipient was protected.  In this example,
someone correctly thought the recipient was not protected.  That is why
the problem is more important and fundamental, in that it does not rely
on persistent misunderstandings, but rather the problem is that the
default behavior of the software did not represent the sender's intention.
This real problem will remain in place even once people have learned that
the fake one is not an issue.  The only solution at present is to
manually copy the relevant header information into the message.  David
is right that a better fix is to do so automatically.
But again, let us not be misled into thinking it is a cryptographic
failure with a cryptographic fix.  It is actually a problem that is very
specific to email, and the fix is specific to the email environment.
The problem is that the sender has no easy way to protect relevant email
header information, and so the fix needs to be to provide a way to do so.
This will require some redesign of email software and of how it interfaces
to encryption.  The sender side needs to figure out the headers before
it goes to encrypt/sign, and the receiver side needs to be prepared to
do something reasonable when the inner headers don't match the outer ones.
BTW, adding this capability would also allow for greater privacy
protection of messages as well.  The failure to encrypt Subject lines
is something that people have complained about for years.  Even the
recipient data could be hidden until the mail got to the receiving
mail server, which could decrypt an outer envelope to discover the
to hide the source of the mail from outsiders, but put a true From:
line in the inner envelope so that the recipient sees who it is from.
There are many additional advantages to being able to put mail headers
inside encryption/signature wrappers in a transparent way.
