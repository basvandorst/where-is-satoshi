
@_date: 2008-02-02 13:13:02
@_author: Guus Sliepen 
@_subject: Gutmann Soundwave Therapy 
Yes, there are a few reasons why people use tinc instead of IPsec. Those
people who tried both tell me tinc is much easier to set up. Tinc
tunnels over UDP and/or TCP. This allows it to work in situations where
IPsec would not, for example behind (masquerading) firewalls.  Tinc does
not need fixed IP addresses at endpoints; endpoints can have more than
one IP address, or hostnames, so it even works when one has dynamic DNS.
With tinc, you can set up VPNs with more than 2 nodes, not by
configuring more tunnels, but just by specifying endpoints. Tinc itself
will handle the packet routing. It tries to set up a full mesh, but it
has a built-in routing protocol, not unlike OSPF, that can route packets
via intermediate nodes if that is necessary. As a side effect it
provides some redundancy.

@_date: 2008-01-31 16:07:03
@_author: Guus Sliepen 
@_subject: Gutmann Soundwave Therapy 
As one of the main developers of tinc, I have been at the receiving end
of Gutmann's therapy, or "drive-by shooting" as I experienced it at that
Peter sent us his write-up up via private email a few days before he
posted it to this list (which got it on Slashdot). I had little time to
think about the issues he mentioned before his write-up became public.
When it did, I (and others too) felt attacked in a cruel way. Peter
ignored all the reasons *why* we used the kind of crypto we did at
that moment, compared it to a very high standard, and made it feel like
every thing we didn't do or didn't do as well as SSL made our crypto
worthless. We had some other people sending us security reviews of tinc, Jerome
Etienne for example. With them, we never had that feeling of being
"attacked". The conversations we had with them encouraged us to improve
Peter's write-up was the reason I subscribed to this cryptography
mailing list. After a while the anger/hurt feelings I had disappeared.
I knew then that Peter was right in his arguments. Nowadays I can look
at Peter's write-up more objectively and I can see that it is not as
ad-hominem as it felt back then, although the whole soundwave paragraph
still sounds very childish ;)
When tinc 2.0 will ever come out (unfortunately I don't have a lot of
time to work on it these days), it will probably use the GnuTLS library
and authenticate and connect daemons with TLS. For performance reasons,
you want to tunnel network packets via UDP instead of TCP, so hopefully
there is a working DTLS implementation as well then.
I hope that in the future, if you see an application doing something
wrong, you don't immediately give the developers the soundwave therapy.
Be a little bit more gentle and try to find out why it was written that
way in the first place. It will create a lot more understanding and
willingness from the developers to fix the problems.
Also, from experimenting with a version of tinc that uses TLS, I can
tell you that it not the perfect solution for our problem. The main
issue I see with SSL and TLS is with the credentials. Both X.509 and
OpenPGP are focussed on URLs or email addresses. It is not clear to me
how to store other information (like which subnets a node on the VPN is
authorised to use) in such credentials in a nice way, other than
shoehorning it into a CN (X.509) or uid (OpenPGP) field. Certificate
chain verification is something that often goes wrong; some SSL libraries do
not offer that functionality, or only do it when an application
explicitly requests it. With OpenPGP you can have a web of trust, but
how do you make use of it in an automated way? I expect that the next
round of penis-shaped soundwave therapy will not be focussed on
whether or not an application uses SSL, but on how it (mis)uses SSL.

@_date: 2008-01-31 22:49:53
@_author: Guus Sliepen 
@_subject: Gutmann Soundwave Therapy 
Please understand the following:
I am not defending the use of our less-than-SSL crypto in tinc. But
there are reasons why we implemented it the way we did at that time. It
doesn't matter whether these reasons were bad or good. The result of
ignoring the why, and "attacking" others by pointing out everything they
do wrong in your perspective (even though your perspective is perfectly
right), and then finishing off the way Peter did, which is easily
perceived as an insult if you are on the receiving end of it, does not
encourage others to fix the problems, but rather puts others in
defensive mode.
Are you out to help others, or just to look down on them? If it's the
first, then please make others accept your help by just formulating
things in a more friendly way (although a patch with a fix would soften
up things as well). If it's the latter, please continue just as you are
doing now.
Now some (good and/or bad) reasons why we ended up with our
lesser-than-SSL crypto, in no particular order:
- SSL was not perceived at that time as a solution for our problem.
- We were application writers, not security specialists. We had to
  encrypt traffic, we did the best to our knowledge at that time.
- I had read Schneier's Applied Cryptography from front to end a few
  times. It made me feel I knew everything about crypto. Even Bruce
  admits he thought at that time he had put everything a programmer
  needed to know about crypto in that book. It doesn't mention SSL.
- We needed to tunnel data over UDP, with UDP semantics. SSL requires a
  reliable stream. Therefore, we had to use something other that SSL to
  tunnel data.
- It was fun to come up with a full duplex authentication scheme using
  RSA. More fun than using someone elses stuff.
- Because we could.
- We were Free Software developers who did it in our spare time for fun,
  we were not a company that sells it as one of its products.
It seems that you haven't read the rest of my email, or you would not
have written that sentence. I am enlightened now :)

@_date: 2010-08-01 15:07:46
@_author: Guus Sliepen 
@_subject: Five Theses on Security Protocols 
My threat model is practice.
I assume Perry assumed that you have some pre-established trust relationship
with the online database. However, I do not see myself having much of those.
Yes, my browser comes preloaded with a set of root certificates, but Verisign
is as much a third party to me as any SSL protected website I want to visit.
Anyway, suppose we do all trust Verisign. Then everybody needs its public key
on their computers to safely communicate with it. How is this public key
distributed? Just like those preloaded root certs in the browser? What if their
key gets compromised? How do we revoke that key and get a new one? We still
have all the same problems with the public key of our root of trust as we have
with long-lived certificates. Perry says we should do online checks in such a
case. So which online database can tell us if Verisign's public key is still
good? Do we need multiple trusted online databases who can vouch for each
other, and hope not all of them fail simultaneously?
Another issue with online verification is the increase in traffic. Would
Verisign like it if they get queried for a significant fraction of all the SSL
connections that are made by all users in the world?

@_date: 2010-07-31 19:30:06
@_author: Guus Sliepen 
@_subject: Five Theses on Security Protocols 
But, if you query an online database, how do you authenticate its answer? If
you use a key for that or SSL certificate, I see a chicken-and-egg problem.

@_date: 2010-07-31 19:25:50
@_author: Guus Sliepen 
@_subject: init.d/urandom : saving random-seed 
I do not think replaying a "stale" seed file at boot is any worse than not
replaying that file.  The real issue is how to ensure a fresh seed file.
However, looking at Debian's /etc/init.d/urandom, right after writing the seed
file to /dev/urandom, it immediately creates a new one by reading from the
freshly seeded /dev/urandom again. There is a comment right above that section
in the script: "Hm, why is the saved pool re-created at boot? [pere
2009-09-03]". Of course that is to ensure there is always a fresh seed file,
even if the system crashes and cannot writte a new seed file at shutdown time.

@_date: 2014-04-25 12:56:53
@_author: Guus Sliepen 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
For tinc (a VPN daemon), I've been working on a simplified version of TLS[1], that
is specifically targeted at peer-to-peer communication, where both peers have
each other's public key beforehand. This removes the whole X.509 certificate
mess from the protocol. It also does not support any cipher suite negotiation,
instead it always uses a fixed suite (the current implementation[2] uses
One can either exchange public keys manually, or one peer can generate an
invitation URL which contains the address of that peer, a hash of that peer's
public key and a secret nonce. The URL can be given to an invitee, which can
then contact the first peer, verify that that peer's public key is correct,
send its own key, establish a connection using the above mentioned
protocol, and then send the secret nonce. If the nonce is correct, the
first peer can store the invitee's public key permanently. Of course, one
must take care the invitation URL is not leaked before the invitee has
had a chance to use it.
[1] [1]

@_date: 2014-04-26 06:47:36
@_author: Guus Sliepen 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
It doesn't differ much from SSH after you remove all the cipher suite
negotiation and all but the public key authentication methods from that.

@_date: 2014-05-09 10:23:12
@_author: Guus Sliepen 
@_subject: [Cryptography] How to lock registers with GCC? 
This would only work if you could convince all programs and the operating
system itself to not use that register by changing the platform ABI. Otherwise,
whenever your application calls a library routine or a context switch happens,
that register will be saved on the stack and will thus end up in memory after

@_date: 2014-05-15 10:24:01
@_author: Guus Sliepen 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
Usually when one says "pre-shared key" one means a key for a symmetric
cipher. However, the problem with those is that they are supposed to be
kept secret, and that means it is hard to pre-share them over public
communication channels. Conversely, when one mentions asymmetric keys it
is usually associated with a PKI. In case of VPNs, I would argue that
the best solution is to have pre-shared public keys; it is much easier
to exchange those over public communication channels, and if you use
ephemeral Diffie-Hellman key exchange signed with those public keys, you
get PFS, something that is not possible with pre-shared symmetric keys.

@_date: 2014-05-15 15:01:52
@_author: Guus Sliepen 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
I don't believe it is as hard. The problem with the shared secret is
that you absolutely need to keep it secret. That requirement is gone
when you exchange public keys. If two people know each other and can
recognize each other's voices, then you can exchange the public key via
telephone, or just email them to each other and read out the fingerprint
to each other over the phone.
You are right, I myself just fell into the trap of conflating pre-shared
keys with only specific use cases (like in OpenVPN where it is only used
for static keys).

@_date: 2015-11-10 09:42:56
@_author: Guus Sliepen 
@_subject: [Cryptography] Cryptogit 
What do you mean with "data"? Does that include all metadata? Including
the very filenames (which can be the hash of the contents)? Maybe even
the file sizes? If not, the cloud provider can probably get useful
information out of it.

@_date: 2015-09-02 20:51:07
@_author: Guus Sliepen 
@_subject: [Cryptography] Checking for the inadvertent use of test keys 
You could algorithmically Google the key and warn when the number of
hits is too high.

@_date: 2015-09-23 09:16:40
@_author: Guus Sliepen 
@_subject: [Cryptography] Non-Authenticated Key Agreement 
A one-time pad is only a one-time pad if you use it once. You are using
them twice in your protocol.
An eavesdropper can see d', d'' and d'''. Using your equation for E, the
eavesdropper can easily calculate:
d' xor d'' = kb
d'' xor d''' = ka
d' xor d'' xor d''' = d

@_date: 2018-06-16 21:54:49
@_author: Guus Sliepen 
@_subject: [Cryptography] How to make rowhammer less likely 
You don't need to know what is in RAM or what it will be changed to for
rowhammer to result in a viable exploit. For example, one of the
exploits changed page table entries such that memory that was previously
marked as inaccessible to an unprivileged user was made accessible. As
long as you only need to toggle a few bits, no amount of encryption will
help you.
The only proper protection, apart from designing your RAM chips so that
row hammer has no effect on the contents of the actual memory cells, is
to cryptographically authenticate the contents of the RAM. However, if
you detect tampering, what can you possibly do? The system is
compromised, the only thing you can do is halt or reboot, which is not
Apart from that, there is a huge cost involved in
encrypting/authenticating RAM at full speed. If you look at a Core
i7-8700K for example, it can do AES encryption at speeds of around 11
GB/s. It probably uses a large fraction of its TDP to achieve that (say
~50 Watt). However, according to the specs it has a memory bandwidth of
41.6 GB/s. So you'd need almost 200 Watt to do just the AES encryption
for the memory. It is much simpler and cheaper to just increase the RAM
refresh rate, use ECC, and monitor performance counters to detect
excessive cache flushes generated by a single program.
