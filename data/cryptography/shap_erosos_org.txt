
@_date: 2002-11-02 11:54:36
@_author: Jonathan S. Shapiro 
@_subject: Windows 2000 declared secure 
Jim Hughes raises some good questions. Let me take them in turn:
The word "moderate" here is very unfortunate. In reading such
statements, one needs to understand a bit of subtext. The Common
Criteria community is very concerned about the possibility that people
will perceive assurance as impossibly difficult. In consequence, there
has been a tendency to a form of "grade inflation." The effectiveness of
the levels is modestly exaggerated, and the importance of going for
higher levels is grossly understated.
One unfortunate consequence is that NSA has seen no need to publish
guidelines on performing higher-level evaluations, because their has
been no demand.
I think the best way to understand "moderate" in this context is to read
it as "low". When "moderate" became the preferred term for this level,
machines were not routinely connected to the internet.
This is indeed a contradiction. If you go back and look at some of the
documents on the Microsoft web, you'll see that they added a few items
in addition to CAPP. I haven't gone through them in detail, but my guess
is that these additions were intended to augment CAPP just enough to
make a minimal EAL4 evaluation outcome permissable.
Actually, the gap is significant and meaningful. In an EAL3 evaluation
it is basically sufficient to show that you have a systematic QA process
in place and that you are using it. No substantive examination of the
design documents occurs.
With EAL4, the evaluators examine the design documents. The look at the
overall comprehensiveness of the design docs and check whether those
docs actually address the requirements of the protection profile.
To achieve EAL4 you actually need to have a design.

@_date: 2002-11-02 12:10:57
@_author: Jonathan S. Shapiro 
@_subject: Windows 2000 declared secure 
Ron's description is correct, but may lead to a slight misunderstanding.
As he says, the protection profile specifies the functional
requirements, while the EAL# specifies assurance. To be a little more
pedantic, the EAL# specifies the *assurance* requirements. When we say
that a system has been rated "EAL4" we are saying that the evaluation
has met a collection of evaluation requirements that are packaged
together in the Common Criteria under the heading of EAL4.
You may occasionally see people talk about "EAL4+" or "EAL4 Augmented"
(or, as in the Microsoft case, "CAPP augmented", where CAPP can be
replaced by any protection profile). In the case of EAL this means
that additional evaluation requirements were met beyond those of EAL4.
In the case of a protection profile, it means that additional functional
requirements were included.
One cannot altogether separate the evaluation requirements from the
functional requirements. In certain areas where we have a lot of
historical knowledge, the evaluation requirements become fairly precise.
For example, there are evaluation requirements on how to evaluate a
login authentication system. These have the side effect of implicitly
requiring that the corresponding functional requirements have been met.
When CAPP was designed, the authors specified that the highest assurance
level that the CAPP functional requirements could support was EAL3. This
may have subsequently been revised, but somebody should definitely
invite a clarification on this from NIAP (the accrediting body for
evaluation groups) on this point.
Having looked at CAPP again, it is unclear to me how an EAL4 evaluation
result could properly have been issued. This could well be my
misunderstanding, so don't jump to any conclusions yet. The answer could
very well lie in the protection profile augmentations the Microsoft did,
which I have not examined.

@_date: 2002-11-02 15:12:51
@_author: Jonathan S. Shapiro 
@_subject: Windows 2000 declared secure 
Apologies once again for the length of my reply. The issues are both
complicated and political. I also need to preface this by saying that I
am an active participant in the dialog around this issue. My usual role
is poking sharp sticks into people's eyes, so please read what I have to
say skeptically.
Context: There are international mutual-recognition treaties covering
EAL4 and below, so if you get an EAL4 evaluation in Germany, it's
accepted as binding in the US. Above EAL4 there is no mutual
recognition. From talking to various assurance evaluators (current and
former) and also to people within NSA, the alleged rationale behind this
is in two parts:
(1) There is a perception that commercial products won't
    seek higher evaluation, so there has been no real pressure
    to push the treaties beyond this.
(2) There is a perception that products seeking assurance
    above EAL4 are likely to be targeted primarily at military
    and/or sensitive applications. No country wants to be in the
    position of being treaty-obligated to accept assurance from
    another country about militarily sensitive materials.
Given that an EAL4 certification can fairly be characterized as "nowhere
near good enough for serious commercial use today", I think it is fair
to harshly criticize these rationales as rather thin rationalizations.
I am (ahem) cynical. I suspect that the absence of treaty agreement may
also have something to do with the fact that as of today the NSA has not
published procedural guidelines for anything above EAL4. In fact, they
have not finished writing them. Brian Snow (NSA), who has the mandate
for publication of such guidelines in the U.S., is in a fairly absurd
position. On the one hand he goes around telling everybody "it's
important to do higher assurance", but on the other hand the current
state of affairs (which is his responsibility) makes this impossible.
There is another subtext. One agenda of the evaluation community is to
get people in the habit of doing evaluations before they raise the
stakes. In order for this strategy to work, products have to pass the
evaluations. The de facto effect is a desire not to set too high a bar.
I personally disagree with this strategy, but even if I did I would
argue that EAL4 is not a barrier to any current commodity operating
system, and the US national interest is not served so long as the best
standards are inadequate for daily commercial use. World interests
aren't served either, but the NSA mandate stops with the US.
When pressed, Brian Snow says that until somebody wants to actually do a
higher level evaluation, NSA cannot justify the expense of doing the
higher level guidelines, but that they could proceed with a higher
evaluation today using the older guidelines that were applied under
TCSEC. This is probably true, but it is not clear whether such an
evaluation would have any commercial value, because the quality of the
resulting evaluation is not characterized by a published standard of
practice. I am publicly on record as saying that EROS will attempt EAL7
evaluation as soon as possible after NSA published appropriate
evaluation guidelines.
This is one of the issues that I use sharp sticks on. Brian usually
takes them in the eye, and I think is privately glad that somebody is
agitating over this issue. More specifically, I have stated publicly
that the single greatest impediment to a successful EAL7 evaluation for
EROS is the absence of relevant guidelines. Without those guidelines, we
can neither sensibly prepare for evaluation nor know what the result
would mean. A lot of people out there who do secure OS work know about
our stuff and our formal verification work and find these statements
quite threatening. They know that (a) EROS can probably do it, and (b)
most of them cannot. In fairness, I should add that the conventional
approach to this has been for the customer to pay for the evaluation,
and Hopkins certainly isn't going to do this. Until this changes, I can
pretty much guarantee that no open source OS will go through a
high-level evaluation. Brian and I have talked intermittently about how
to solve this, and I think we have a strategy worked out for when the
time comes.
So the current state of affairs is that for levels above EAL4 the
evaluation must be performed with participants from the government of
the host country, and has no standing outside of the host country. I
suspect that someone achieving a successful EAL5 evaluation in the US
could claim EAL4 elsewhere under the treaties, but a US-achieved EAL5
would not qualify a product to be submitted on, say, a German military
solicitation requiring an EAL5 certification.
Note that the current policies have a curious effect. Companies pursue
evaluation primarily for the marketing benefit of the certification. The
minute they step from EAL4 to EAL5, they suddenly need to spend millions
of dollars **per country** and the marketing payoff stops. A consequence
is that higher levels of assurance work are not cost effective on the
development end. The de facto effect is to ensure that there is a strong
economic disincentive to make a truly secure operating system widely
available to the public sector. Given the historical export policies of
the US, the fact that secure systems are still considered sensitive by
the armed services, and the fact that B2 or better systems may still be
export controlled under ITAR (their status is ambiguous at present), one
must question whether this outcome is an accident or an intentional
result of undisclosed policy decisions by various groups within the U.S.
Whatever policy NSA thinks is a good idea, the impact on the U.S.
commercial sector is very clear. Until there is a unified incentive
structure resulting in the construction of widely available secure
systems, both U.S. and world businesses will continue to be largely
bare-ass naked where security is concerned. Further, it follows from
this that the U.S. civilian sector is vulnerable to attack in the event
of an extended military action. It has long been recognized that the
civilian sector is *vital* for provisioning and supply in any extended
military action (i.e. longer than one week).
In consequence, I would go so far as to argue that the current ITAR
policy is actively *contrary* to U.S. interests in both the commercial
and military sectors. Paul Karger has gone further, suggesting that "...
the current state of civilian sector computer security and the ITAR
regulations represents a clear and present danger to the security
interests of the United States."
For myself, I prefer a slighly less confrontational approach. My answer
generally goes something like: Well, we've been operating under the
current policy for 35 years, and we're pretty much naked. If you want
the civilian sector to be even modestly more secure, perhaps
criminalizing the open sale of secure systems isn't the way to go. All
other things being equal, it is a legitemate national security goal to
prevent our enemies from having this technology. The cost of the current
policy is that we are more vulnerable than they are, because we rely
utterly on computers in our civilian infrastructure, and most of our
enemies do not. The current policy is a knife at our own throats.
So finally, Adam was really asking "what do we do about it?" The key, I
think, is to recognize that international treaties don't matter. If a
reputable group of recognized computer scientists were to publish a well
thought out set of evaluation criteria for higher level evaluation, NSA
would have little political choice but to adopt them -- perhaps with
modification. Similarly, performing a successful evaluation against
these criteria using publicly contributed resources would disenfranchise
the people who say "real security is too hard". Both activities would
have to be done in a way that was very much beyond reproach. In part,
this means that it needs to be done in an open source way -- that is,
*all* of the process documentation and such needs to be publicly
Enough said for now, but I will hopefully have more to say on this
within the next few months.

@_date: 2002-11-02 20:36:04
@_author: Jonathan S. Shapiro 
@_subject: Windows 2000 declared secure 
Yes, but that's not what I said. You are right that people running
businesses consider EAL4 systems good enough to deploy. However, there
is ample empirical evidence that they are wrong. These systems are
routinely hacked by script kiddies. My statement concerned objective
reality, not the wishful thinking of the people doing the deployment.
This needs to be looked at carefully to understand what is going on.
First, the Navy has many applications that aren't the least bit
sensitive. For these, Win/NT may be a fine solution.
In addition, the Navy has also deployed Win/NT into some potentially
sensitive tactical applications. In these cases, Win/NT has *always*
been deployed onto a secure network that is physically isolated from the
rest of the ship systems. This has the effect of rendering the
environment non-hostile. In a non-hostile environment, Win/NT may be a
fine solution.
This is inaccurate. There are *lots* of people demanding that security
be fixed. The problem is that all of them are customers, and in a
monopoly environment the customers don't carry any great amount of
weight. Until there is a viable commercial alternative to Windows
(preferably several), secure or otherwise, this is a commercial
non-issue. While I understand the basis for the ruling and reluctantly
agree that it was a legally sound decision, security will be a casualty
of Colleen Kollar-Kotelly's decision in the near term.
True, but the documentation can be generated retroactively. The fact is
that several UNIX systems *have* passed EAL4. With sufficient work,
Linux could do so too.
I haven't looked at SELinux in detail, but evaluation of SElinux wasn't
a design goal, and I have heard skepticism about whether it could
evaluate successfully from within NSA. In any case, any evaluation of
SElinux would have to begin by cleaning up the baseline Linux system for
I think you are probably right. At the level of "higher is better"
people understand it. Since nothing higher than EAL4 is widely
available, that's not a very useful level of differentiation in
Since the cost of the EAL4->EAL5 jump is O($1M) and several years, and
since Linux/UNIX probably can't actually get there, do you really think
I disagree. The problem is even more fundamental than that. The problem
today is the absence of liability for the consequences of bad software.
Once liability goes into place, CC becomes the industry-accepted
standard of diligent practice. Until then it's just a way of killing

@_date: 2002-11-02 23:52:36
@_author: Jonathan S. Shapiro 
@_subject: Windows 2000 declared secure 
Not so far as I know, but it could probably get there with some amount
of work if it isn't already.
This is sort of what I mean about EAL4 not being good enough. The state
of affairs at present is that a whole bunch of known-breakable OS's are
nonetheless certifiable and being touted as secure...

@_date: 2002-11-04 05:54:54
@_author: Jonathan S. Shapiro 
@_subject: [e-lang] Re: Windows 2000 declared secure 
Full disclosure alert: David and I have worked together on pulling
together some stronger protection profiles.
David and I disagree on the importance of this.
It is certainly true that in current commodity OS's, the sticking point
for evaluation has been the networking features of the system. I'm
unclear on whether these problems mostly have to do with the networking
stack per se or with the functionality that is layered above them. For
example, I'm not aware of evaluation failures based on bad TCP/IP
implementations. I'm aware of quite a number based on cruddy remote file
system designs. David: since you have done these evaluations, can you
expand on where the problem is? That is: at what layer in the network
system do things tend to go wrong? Would you expect systems like QNX,
where networking support is implemented in user-mode code, to do better?
Anyway, the reason I disagree with David's statement:
Networking is the practical bottleneck for current commodity systems,
but at higher levels of assurance (EAL5+) it becomes necessary to look
at issues of resource denial of service in the operating system. At this
point I believe that the process, storage, and memory management
subsystems of current systems would struggle because of "free rider"
problems in their architectures. Similarly, one runs into a lot of
problems with system call design. Based on some of the higher assurance
PP work David and I have done I would expect him to agree, and I'll be
interested to see if he doesn't. :-)
So it's good to talk about the network stack, but let's not make the
mistake of thinking that the rest of it is a solved problem.
I'm not convinced of this. Ignoring security for a moment, I think we
could reuse existing TCP/IP implementations without great difficulties,
and we probably will do so. The main problems I see in any networking
implementation are (a) ensuring that respective connections stay
separated and (b) ensuring that one flow cannot impede another. The
first is very straightforward to do by going with any of several
user-mode TCP solutions. These work by isolating the streams early and
processing different streams in different protection domains. The second
is a non-problem in practice, because any interference in the network
stack is overwhelmed by interference on the wire itself. Interference on
the wire is beyond the scope of the operating system.
David: this has gotten a bit afield of e-lang. I'ld suggest answering
the "what layer is the bottleneck" question here and taking up the rest
on eros-arch.

@_date: 2002-11-04 06:38:25
@_author: Jonathan S. Shapiro 
@_subject: Windows 2000 declared secure 
I'm answering this publicly, because there is a surprise in the answer.
Funny you should ask that. First, I need to correct my original
statement: one needs both evaluation criteria and an effective
requirement set for a secure OS. The Common Criteria evaluation process
needs to be augmented with quantitative tests on the actual software
artifact, but it's actually pretty good.
Requirements, on the other hand, is a tough problem. David Chizmadia and
I started pulling together a draft higher-assurance OS protection
profile for a class we taught at Hopkins. It was drafted in tremendous
haste, and we focused selectively on the portions of CC we would cover
in class, but it may provide some sense of how hard this is to actually
Sorry about the formatting errors - it's an automatically generated
document that needs cleanup.
The difficulty in drafting a PP like this is avoid specifying solutions.
A PP is supposed to be a requirements document. Unfortunately, you get
into quandries. Some of the requirements we think are important can be
done in capability systems but not in non-capability systems (at least
based on published verifications to date). It becomes tempting at that
point to introduce requirements that can *only* be done by capability
Also, much is present only by reading between the lines. An annotated
document is needed in order to really make any headway on understanding
what is implied by some of the requirements.
Having read a number of existing protection profiles, I have to say that
people have done quite well on this. There *is* some unneeded bulk, but
this is primarily due to conventions that yield consistently styled
documents. Once you understand how to read one PP you can read pretty
much any PP. A modest amount of size expansion is a reasonable price to

@_date: 2003-10-05 11:03:59
@_author: Jonathan S. Shapiro 
@_subject: [e-lang] Re: Protocol implementation errors 
I agree that ASN.1 is statically checkable, and that this is an
important property.
However, ASN.1 is notoriously hard to parse, which leads to errors.
I do wonder if we shouldn't design a format that captures the best of
both worlds...
