
@_date: 2010-08-02 12:25:10
@_author: Nicolas Williams 
@_subject: GSM eavesdropping 
Well, to be fair, there is much content to be accessed insecurely for
the simple reason that there may be no way to authenticate a peer.  For
much of the web this is the case.
For example, if I'm listening to music on an Internet radio station, I
could care less about authenticating the server (unless it needs to
authenticate me, in which case I'll want mutual authentication).  Same
thing if I'm reading a randmon blog entry or a random news story.
By analogy to the off-line world, we authenticate business partners, but
in asymmetric broadcast-type media, authentication is very weak and only
of the broadcaster to the receiver.  If we authenticate broadcasters at
all, we do it by such weak methods as recognizing logos, broadcast
frequencies, etcetera.
In other words, context matters.  And the user has to understand the
context.  This also means that the UI matters.  I hate to demand any
expertise of the user, but it seems unavoidable.  By analogy to the
off-line world, con-jobs happen, and they happen because victims are
naive, inexperienced, ill, senile, etcetera.  We can no more protect the
innocent at all times online as off, not without their help.
"There should be one mode, and it should be secure" is a good idea, but
it's not as universally applicable as one might like.  *sadness*
SMTP and IMAP, then, definitely require secure modes.  So does LDAP,
even though it's used to access -mostly- public data, and so is more
like broadcast media.  NNTP must not even bother with a secure mode ;)
Another problem you might add to the list is tunneling.  Firewalls have
led us to build every app as a web or HTTP application, and to tunnel
all the others over port 80.  This makes the relevant context harder, if
not impossible to resolve without the user's help.
HTTP, sadly, needs an insecure mode.

@_date: 2010-08-02 12:46:17
@_author: Nicolas Williams 
@_subject: GSM eavesdropping 
How should we measure success?  Every user on the Internet uses TLS
(SSL) on a daily basis.  None uses IPsec for anything other than VPN
(the three people who use IPsec for end-to-end protection on the
Internet are too few to count).
By that measure TLS has been so much more successful than IPsec as to
prove the point.
Of course, TLS hasn't been successful in the sense that we care about
most.  TLS has had no impact on how users authenticate (we still send
usernames and passwords) to servers, and the way TLS authenticates
servers to users turns out to be very weak (because of the plethora of
CAs, and because transitive trust isn't all that strong).
DNSSEC will help immensely, no doubt, and mostly by giving us a single
root CA.
But note that the one bit you're talking about is necessarily a part of
a resolver API, thus proving my point :)
The only way we can avoid having such an API requirement is by ensuring
that all zones are signed and all resolvers always validate RRs.  An API
is required in part because we won't get there from day one (that day
was decades ago).
The same logic applies to IPsec.  Suppose we'd deployed IPsec and DNSSEC
back in 1983... then we might have many, many apps that rely on those
protocols unknowingly, and that might be just fine...
...but we grow technologies organically, therefore we'll never have a
situation where the necessary infrastructure gets deployed in a secure
mode from the get-go.  This necessarily means that applications need
APIs by which to cause and/or determine whether secure modes are in

@_date: 2010-08-02 15:46:24
@_author: Nicolas Williams 
@_subject: GSM eavesdropping 
That's... extreme.  There are many things that will not be encrypted,
starting with the DNS itself, and also most public contents (because
their purveyors won't want to pay for the crypto; sad but true).
No, but you claimed that APIs weren't a major issue.  I believe they are.
You missed the point.  The point was: do not design security solutions
without designing their interfaces.
IPsec has no user-/sysadmin-/developer-friendly interfaces -> IPsec is
not used.  DNS has interfaces -> when DNSSEC comes along we can extend
those intefaces.
Note that IPsec could have had trivial APIs -- trivial by comparison to
the IPsec configuration interfaces that operating systems typically
have.  For example, there's a proposal in the IETF apps area for an API
that creates connections to named servers, hiding all the details of
name resolution, IPv4/v6/v4-mapped-v6 addressing.  Such an API could
trivially have a bit by which the app can request cryptographic
protection (via IPsec, TLS, whatever can be negotiated).  Optional
complexity could be added to deal with subtleties of the secure
transport (e.g., what cipher suites do you want, if not the default).
But back in the day APIs were seen as not really in scope, so IPsec
never got them, so IPsec has been underused (and rightly so).
No objection there.

@_date: 2010-08-02 16:20:01
@_author: Nicolas Williams 
@_subject: Five Theses on Security Protocols 
But users have to help you establish the context.  Have you ever been
prompted about invalid certs when navigating to pages where you couldn't
have cared less about the server's ID?  On the web, when does security
matter?  When you fill in a field on a form?  Maybe you're just
submitting an anonymous comment somewhere.  But certainly not just when
making payments.
I believe the user has to be involved somewhat.  The decisions the user
has to make need to be simple, real simple (e.g., never about whether to
accept a defective cert).  But you can't treat the user as a total
ignoramus unless you're also willing to severely constrain what the user
can do (so that you can then assume that everything the user is doing
requires, say, mutual authentication with peer servers).

@_date: 2010-08-15 23:33:09
@_author: Nicolas Williams 
@_subject: Has there been a change in US banking regulations recently? 
For purely internal systems Kerberos is really the way to go, mostly
because it's so easy to deploy nowadays.
TLS-PSK is not a useful way of building any but the smallest networks,
and for two reasons: a) there's no agreed PBKDF and password salting
mechanisms, so passwords are out, b) there's no enrolment mechanism, so
PSK setup is completely ad-hoc.

@_date: 2010-08-26 01:06:56
@_author: Nicolas Williams 
@_subject: towards https everywhere and strict transport security 
It'd help amortize the cost of round-trips if we used HTTP/1.1
pipelining more.  Just as we could amortize the cost of public key
crypto by making more use of TLS session resumption, including session
resumption without server-side state [RFC4507].
And if only end-to-end IPsec with connection latching [RFC5660] had been
deployed years ago we could further amortize crypto context setup.
We need solutions, but abandoning security isn't really a good solution.
The second part is a correct description of the current state of
affairs.  I don't buy the first part (see below).
Authentication and key exchange are generally going to require 1.5 round
trips at least, which is to say, really, 2.
Yes, Kerberos AP exchanges happen in 1 round trip, but at the cost of
requiring a persistent replay cache (and also there's the non-trivial
TGS exchanges as well).  Replay caches historically have killed
performance, though they don't have to[0], but still, there's the need
for either a persistent replay cache backing store or a trade-off w.r.t.
startup time and clients with slow clocks[0], and even then you need to
worry about large (>1s) clock adjustments.
So, really, as a rule of thumb, budget 2 round trips for all crypto
setup.  That leaves us with amortization and piggy-backing as ways to
make up for that hefty up-front cost.
See draft-williams-tls-app-sasl-opt-04.txt [1], a variant of false
start, which alleviates the latter.  See also draft-bmoeller-tls-
falsestart-00.txt [2].
Back to layering...
If abstractions are leaky, maybe we should consider purposeful
abstraction leaking/piercing.
There's no reason that we couldn't piggy-back one layer's initial message
(and in some cases more) on a lower layer connection setup message
exchange -- provide much care is taken in doing so.
That's what PROT_READY in the GSS-API is for, that's one use for GSS-API
channel binding (see SASL/GS2 [RFC5801] for one example).  It's what TLS
"false start" proposals are about...  draft-williams-tls-app-sasl-opt-04
gets an up to 1.5 round-trip optimization for applications over TLS.
We could apply the same principle to TCP... (Shades of the old, failed?
transaction TCP [RFC1644] proposal from the mid `90s, I know.  Shades
also of TCP-AO and other more recent proposals perhaps as well.)
But there is a gotcha: the upper layer must be aware of the early
message send/delivery semantics.  For example, early messages may not
have been protected by the lower layer, with protection not confirmed
till the lower layer succeeds, which means... for example, that the
upper layer must not commit much in the way of resources until the lower
layer completes (e.g., so as to avoid DoS attacks).
I'm not saying that piercing layers is to be done cavalierly.  Rather,
that we should consider this approach, carefully.  I don't really see
better solutions (amortization won't always help).
[0] Turns out that there is a way to optimize replay caches greatly, so
    that an fsync(2) is not needed on every transaction, or even most.
    This is an optimization that turned out to be quite simple to
    implement (with much commentary), but took a long time to think
    through.  Writing a test program and then using it to test the
    implementation's correctness was the lion's share of the
    implementation work.
    You can see it here:
        Diffs:
        RFE (though IIRC the description is wrong/out of date):
    [1] [2]

@_date: 2010-08-26 11:21:35
@_author: Nicolas Williams 
@_subject: questions about RNGs and FIPS 140 
Would it be possible to combine a FIPS 140-2 PRNG with a TRNG such that
testing and certification could be feasible?
I'm thinking of a system where a deterministic (seeded) RNG and
non-deterministic RNG are used to generate a seed for a deterministic
RNG, which is then used for the remained of the system's operation until
next boot or next re-seed.  That is, the seed for the run-time PRNG
would be a safe combination (say, XOR) of the outputs of a FIPS 140-2
PRNG and non-certifiable TNG.
factory_prng = new PRNG(factory_seed, sequence_number, datetime);
        trng = new TRNG(device_path);
runtime_prng = new PRNG(factory_prng.gen(seed_size) ^ trng.gen(seed_size), 0, 0);
One could then test and certify the deterministic RNG and show that the
non-deterministic RNG cannot destroy the security of the system (thus
the non-deterministic RNG would not require testing, much less
To me it seems obvious that the TRNG in the above scheme cannot
negatively affect the security of the system (given a sufficiently large
seed anyways).

@_date: 2010-08-27 12:58:56
@_author: Nicolas Williams 
@_subject: questions about RNGs and FIPS 140 
If the issue is that determinism is necessary during certification
testing, then it should be possible to switch off the TRNG.  If the
issue is that FIPS is braindead, well, then we're at layer 9.
(One would think that gambling systems would be required to have a TRNG
on/off switch that would be set to off for testing, then set to on, then
resin poured on it, at the end of testing, to cause it to stay on.  That
way there'd be no risk of seeds being stolen because normal operation
would render possession of those seeds useless... without also attacking
the TRNG physically.  The TRNG design should be such that physical
attacks on it would be noticeable by bystanders and physical security
monitoring.  Yes, I know, a determined engineer working at a gambling
equipment manufacturer could probably find other ways to trojan the
system anyways.)

@_date: 2010-07-12 13:04:20
@_author: Nicolas Williams 
@_subject: Intel to also add RNG 
You need an entropy pool anyways.  Adding entropy (from the CPU's RNG,
from hopefully-random event timings, ...) and non-entropy (from a flawed
HW RNG, from sadly-not-random event timings, ...) to the pool results in
having enough entropy (once enough entropy has been added to begin
with).  You'll want multiple entropy sources no matter what, to deal
with HW RNG failures for example.
BTW, SPARC CPUs have shipped with on-board HW RNGs; Intel is hardly

@_date: 2010-07-23 14:45:43
@_author: Nicolas Williams 
@_subject: What if you had a very good patent lawyer... 
If you have children at home you could just point a webcam at their
gameroom, or, depending on how obsessive compulsive their guardians are
regarding cleanliness, anywhere in their homes.  Of course, they won't
be there all the time, and their guardians will sometimes cleanup, which
means that such a generator will tend to be biased, which means you need
an entropy extractor and entropy pool (but you knew you needed those
anyways).  Even so, I believe that such an entropy generator will
generally produce better entropy than a geiger counter, at least when
it's operational.
I wouldn't put it past any PTO, especially the USPTO, to issue a patent
on gathering entropy from a webcam pointed at tiny, human entropy
generators.  But IANAL.

@_date: 2010-07-27 17:01:18
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI 
But isn't that the problem, that "SNI had to be added therefore it isn't
everywhere therefore site operators don't trust its presence therefore
SNI is irrelevant"?
Do we have any information as to which browsers in significant current
use don't support SNI?  Hopefully at some point site operators could
declare that browsers that don't support SNI will not be supported.

@_date: 2010-07-27 19:52:55
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI 
Yet browser SNI support is what matters regarding adoption.  No hosting
service will provision services such that SNI is required if too much of
the browser installed base does not support it.
Of course server support is a requirement in order to get SNI deployed,
but that's much less of an issue than client support.
Thanks for pointing out IE6 though.

@_date: 2010-07-28 07:30:41
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI 
My preference would be for doing something like SCRAM (and other
SASL/GSS mechanisms) with channel binding (using tls-server-end-point CB
type).  It has the effect that the server can confirm that the
certificate seen by the client is the correct one -- whereas the server
cannot do that in the "SSL pinning" approach.  It'd have other major
benefits as well.
The problem is: there's no standard way to do this in web browser
applications.  Worse, there's not even any prototypes.
I also like the Moonshot approach.
Better yet: use DNSSEC and publish TLS EE certs in the DNS.

@_date: 2010-07-28 07:44:04
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
Solutions at higher layers might have a better chance of getting
deployed.  No, I'm not suggesting that we replace TLS and HTTPS with
application-layer crypto over HTTP, not entirely anyways.  I am
suggesting that we use what little TLS does give us in ways that don't
require changing TLS much or at all.
Application-layer authentication with tls-server-end-point channel
bindings seems like a feasible candidate.  This too would require
changes on clients and servers, which makes it not-that-likely to get
implemented and deployed, but not changes at the TLS layer (other than
an API by which to extract a TLS connection's server cert).  It could be
deployed incrementally such that users who can use it get better
security.  Then if the market gives a damn about security, it might get
closer to fully deployed in our lifetimes.
The assumption here is that improvements at the TLS and PKI layers occur
with enormous latency.  If this were true at all layers then we could
just give up, or aim to fix not just today's problems, but tomorrow's, a
decade or three from now (ha).  It'd be nice if that assumption were not
true at all.

@_date: 2010-07-28 09:30:22
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
PKI alone is certainly not the answer to all our problems.
Infrastructure (whether of a pk variety or otherwise) and transitive
trust probably have to be part of the answer for scalability reasons,
even if transitive trust is a distasteful concept.  However, we need to
be able to build direct trust relationships, otherwise we'll just have a
house of transitive trust cards.  Again, think of the the SSH leap-of-
faith and "SSL pinning" concepts, but don't constrain yourselves purely
to pk technology.

@_date: 2010-07-28 09:57:21
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
Kerberos too lacks revocation, and it also makes up for it with short
ticket lifetimes.
OCSP Responses are much like a PKI equivalent of Kerberos tickets.  All
you need to do to revoke a principal with OCSP is to remove it from the
Responder's database or mark it revoked.  To revoke an individual
certificate you need only mark a date for the given subject such that no
cert issued prior to it will be considered valid.
An OCSP Responder implementation could be based on checking a real CRL
or checking a database of known subjects (principals).  Whichever is
likely to be smaller over time is best, though the latter is just
simpler to administer (since you don't need to know the subject public
key nor the issuer&serial, nor the actual TBSCertificate in order to
revoke, just the subject name and current date and time).
The SSH ad-hoc pubkey model is a public key pre-sharing (for user keys)
and pre-sharing and/or leap-of-faith (for host keys) model.  It doesn't
scale without infrastructure.  Add infrastructure and you're back to a
PKI-like model (maybe with no hierarchy, but still).

@_date: 2010-07-28 10:05:25
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
And PKINIT today also allows for rp-only user certs if you want them.
They must be certificates, but they needn't carry any useful data beyond
the subject public key, and the KDC must know the {principal,
cert|pubkey} associations.
This is true time you have rp-only certs or certs that carry less
information than the rp will require.  The latter almost always true.
The account can be local to each rp, however, or centralized -- that's
up to the relying parties.
Agreed.  Certificates should, as much as possible, be rp-only.
Exactly.  OCSP can work in that manner.  CRLs cannot.  In terms of
administration updating an account record is much simpler than updating
a CRL (because much less information needs to be available for the
former than for the latter).
Are you arguing for Kerberos for Internet-scale deployment?  Or simply
for PKI with rp-only certs and OCSP?  Or other "federated"
authentication mechanism?  Or all of the above?  :)

@_date: 2010-07-28 10:20:46
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
Well, OK.  But PKI no longer means that, not with bridges and what not
in the picture.
Indeed.  They must first establish a direct trust relationship.  They
might leverage transitive trust to bootstrap direct trust if doing so
makes the process easier (which it almost certainly does, and which we
use in the off-line world all the time using pieces of paper or plastic
issued by various authorities, such as "drivers' licenses", "passports",
We are.  Perhaps I hadn't made my point obvious enough: transitive trust
is necessary, but primarily as a method of bootstrapping direct trust
relationships.  I really should have used that specific formulation.

@_date: 2010-07-28 10:50:52
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
No, they really are semantically equivalent.  In Kerberos (traditional,
pre-PKINIT Kerberos) the long-term credential is {principal name,
long-term secret key} or {principal name, password}, and the temporary
credential is the Kerberos Ticket.  In PKI+OCSP the long-term credential
is {certificate, private key}, and the temporary credentials is
{certificate, private key, fresh OCSP Response}.
Both, Kerberos and PKI+OCSP replace a long-term credential with a
short-lived, temporary credential authenticating the same principal.
Yes, but it's still "morally equivalent" to Kerberos as described above,
but with PK instead of KDCs and shared secret keys.
Also, PKI+OCSP is somewhat less dependent on online infrastructure than
Kerberos because: a) just one OCSP Response will do[*], vs. a multitude
of service Tickets, b) OCSP Responders don't need access to the CA's
private key, whereas the KDCs do need access to the TGS keys.  Also,
OCSP Responses can be cached by the network, whereas Kerberos Tickets
cannot be (since they are useless[**] without the corresponding session
[*]  It helps to have protocols where subjects can send OCSP responses
     for their own certs to their peers.  It also helps to have
     protocols where client subjects can get OCSP Responses for their
     own certs from their peers and then re-use those Responses later.
[**] I'm ignoring user-to-user authentication here.

@_date: 2010-07-28 11:02:29
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
Sorry, but this is wrong.  The OCSP protocol itself really is an online
certificate status protocol.  Responder implementations may well be
based on checking CRLs, but they aren't required to be.
Don't be confused by the fact that OCSP borrows some elements from CRLs.

@_date: 2010-07-28 11:23:16
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
Also, requiring OCSP will probably take less effort than switching from
PKI to Kerberos.  In other words: eveything sucks.

@_date: 2010-07-28 11:43:55
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
You should be more specific.  I'm looking at RFC2560 and I don't see
OCSP Responses allow the Responder to assert:
 - A time at which the given cert was known to be valid (thisUpdate;
   REQUIRED).
   Relying parties are free to impose a "freshness" requirement (e.g.,
   thisUpdate must be no more than 5 minutes in the past).
   Perhaps you're concerned that protocols that allow for carrying OCSP
   Responses don't provide a way for peers to indicate what their
   freshness requirements are?
 - A time after which the given OCSP Response is not to be considered
   valid (nextUpdate, which is OPTIONAL).
 - The certificate's status (certStatus, one of good, revoked, unknown;
   REQUIRED).
How is responding "certStatus=good, thisUpdate="
not a "yes response to a query about the validity of a certificate"?
What am I missing?
OCSP gives you that.  Seriously.  In fact, an OCSP Responder either must
not respond or it must give you at least {certStatus, thisUpdate}
information about a cert.  Yes, certStatus can be "unknown", but a
Responder that regularly asserts certStatus=unknown would be a rather
useless responder.
And why would a relying party need to know internal details of the OCSP
Manufactured cert attack?  If you can mint certs without having the CA's
private key then who cares about OCSP.  If you can do it only as a
result of hash collisions, well, switch hashes.  Let's not confuse hash
collision issues with whether OCSP does what it's advertised to do.

@_date: 2010-07-28 11:20:52
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
Whether PKI can run w/o OCSP is up to the relying parties.  Today,
because OCSP is an afterthought, they have little choice.

@_date: 2010-07-28 12:38:10
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
Precise and concise language in a fast moving thread with participants
with diverse backgrounds is going to be hard to come by.  Better to quit
than hold out for that (unless you enjoy being disappointed).  I'm
hardly the only "sinner" here on that score.
"up to the relying parties" means "up to the browsers", where users-as-
relying-parties are concerned.  That also means "getting software
updated", which to some degree means "getting my mom to do stuff she
doesn't and shouldn't have to know how".  It shouldn't mean "getting my
mom to enable OCSP" -- that would be hopeless.
"up to the relying parties" means "up to the server" as well, since
servers too are relying-parties.
Again, if everything is too hard, why do we bother even talking about
any of this?  ETOOHARD cannot usefully be a retort to every suggestion.

@_date: 2010-07-28 13:49:58
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
Hear, hear!  But... great for corporate networks, not quite for
Internet-scale, but a great example of how we can make progress when we
want to.
IPsec is a great example of another kind of failure: lack of APIs.
Applying protection to individual packets without regard to larger
context is not terribly useful.  Apps have no idea what's going on, if
anything, in terms of IPsec protection.  Worse, the way in which IPsec
access control is handled means that typically many nodes can claim any
given IP address, which dilutes the protection provided by IPsec as the
number of such nodes goes up.  Just having a way to ask that a TCP
connection's packets all be protected by IPsec, end-to-end, with similar
SA pairs (i.e., with same peers, same transforms) would have been a
great API to have years ago.
The lack of APIs has effectively relegated IPsec to the world of VPN.

@_date: 2010-07-28 20:09:29
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
The protocol allows for more than simple proxy checking of CRLs.  What
implementations do is another matter (which matters, of course, but be
sure to know what you're condemning, the implementations or the
protocol, as they're not the same thing).
This is a rather astounding misunderstanding of the protocol.  An
OCSPResponse does contain unauthenticated plaintext[*], but that
plaintext says nothing about the status of the given certificates -- it
only says whether the OCSP Responder was able to handle the request.  If
a Responder is not able to handle requests it should respond in some
way, and it may well not be able to authenticate the error response,
thus the status of the responder is unauthenticated, quite distinctly
from the status of the certificate, which is authenticated.  Obviously
only successful responses are useful.
The status of a certificate (see SingleResponse ASN.1 type) most
certainly is covered by the signature: SingleResponse is part of
ResponseData, which is the type of tbsResponseData, which is what the
signature covers.
Don't take my word for it, nor that paper's author's.  Read the RFC and
decide for yourself.
[*] It's not generally possible to avoid unauthenticated plaintext
    completely in cryptographic protocols.  The meaning of a given bit
    of unauthenticated plaintext must be taken into account when
    analyzing a cryptographic protocol.

@_date: 2010-07-29 11:44:29
@_author: Nicolas Williams 
@_subject: A mighty fortress is our PKI, Part II 
A DoS attack on OCSP clients (which is all this really is) should either
cause the clients to fallback on CRLs or to fail the larger operation
(TLS handshake, whatever) altogether.  The latter makes this just a DoS.
The former makes this less than a DoS.
The real risk would be OCSP clients that don't bother with CRLs if OCSP
Responder can't respond successfully, but which proceed anyways af if
peers' certs are valid.  If there exist such clients, don't blame OCSP.

@_date: 2010-07-29 15:31:08
@_author: Nicolas Williams 
@_subject: Persisting /dev/random state across reboots 
If the entropy pool has other, reasonable/fast sources of entropy at
boot time, then seeding the entropy pool at boot time with a seed
generated at shutdown time is harmless (assuming a good enough entropy
pool design).  Else, then this approach can be a good idea (see below).
The idea is to get enough entropy into the entropy pool as fast as
possible at boot time, faster than the system's entropy sources might
otherwise allow.
The security of a system that works this way depends critically on
several things: a) no one reads the seed between the time it's generated
and the time it's used to seed the entropy pool, b) the seed cannot be
used twice accidentally, c) the system can cope with crashes (i.e., no
seed at boot) such as by blocking reads of /dev/random and even
treats the seed as entropy from any other source and applies the normal
mixing procedure to it, e) there is a way to turn off this chaining of
entropy across boots.  (Have I missed anything?)
(a) can't really be ensured.  But one could be sufficiently confident
that (a) is true that one would want to enable this.  (d) means that
every additional bit of entropy obtained from other sources at boot time
will make it harder for an attacker that managed to read this seed to
successfully mount any attacks on you.  (e) would be for the paranoid;
for most users, most of the time, chaining entropy across reboots is
probably a very good idea.  But most importantly, on-CPU RNGs should
make this totally pointless (see previous RNG-on-CPU threads).

@_date: 2010-07-31 19:28:14
@_author: Nicolas Williams 
@_subject: Five Theses on Security Protocols 
6. Enrolment must be simple.
I didn't see anything about transitive trust.  My rule regarding that:
7. Transitive trust, if used at all, should be used to bootstrap
   non-transitive trust (see "enrolment must be simple") or should be
   limited to scales where transitive trust is likely to work (e.g.,
   corporate scale).

@_date: 2010-10-07 19:04:54
@_author: Nicolas Williams 
@_subject: English 19-year-old jailed for refusal to disclose decryption key 
There is no trick, not really.  If decryption results in plaintext much
shorter than the ciphertext -much shorter than can be explained by the
presence of a MAC- then it'd be fair to assume that you're pulling this
"trick".  The law could easily deal with this.
Plausible deniability with respect to crypto technology used is not
really any different than plausible deniability with respect to
knowledge of actual keys.  Moreover, possession of software that can do
"double encryption" could be considered probable cause that your files
are likely to be encrypted with it.
Repeat after me: cryptography cannot protect citizens from their states.

@_date: 2010-10-08 16:13:13
@_author: Nicolas Williams 
@_subject: Photos of an FBI tracking device found by a suspect 
If you left a wallet in someone's car, isn't it still yours?  And isn't
that so even if you left it there on purpose (e.g., to test a person's
character)?  But this is not the same situation, of course, since the
item left behind is an active device.
If your planting of the device violates the target's rights you might
(or might not) lose ownership of the device, along with other penalties.
The FBI is a state actor though, so the rules that apply in this case
are different than in the case of a tracking device planted by a private
investigator, and those might be different than the rules that would
apply if the device's owner is a private actor not even licensed as a
IOW: ask a lawyer.  But I strongly suspect that the answer in this case
is "the FBI still owns the device", and "the question is not moot" (as
it might be if the device had stopped working then fallen off the car
(e.g., after hitting a number of nasty potholes).  I mean, I seriously
doubt that relevant laws would be written as to grant the subject
ownership of devices planted as part of a legal surveillance of them,
and though it's possible that judge-made law would conclude differently,
I doubt that judges would make such law.

@_date: 2010-10-08 16:47:49
@_author: Nicolas Williams 
@_subject: Photos of an FBI tracking device found by a suspect 
I covered that, didn't I?
Indeed, but I'm pretty sure the FBI wouldn't lose that question.  If the
surveillance subject said "it's mine now" they could probably arrest
him, and the legal question can get settled later, possibly in a
protracted appeals battle that would likely ultimately favor the FBI

@_date: 2010-09-01 10:42:26
@_author: Nicolas Williams 
@_subject: questions about RNGs and FIPS 140 
BTW, FIPS-140-2 is reasonable regarding RNGs: there are no approved
non-deterministic RNGs, and but non-deterministic RNGs may be used to
seed a deterministic RNG.  There are a few problems though:
a) nothing in the standard says anything about re-seeding nor seeding in
   the absence of TRNGs,
b) the standard speaks of "nondeterministic RNGs approved for use in
   classified applications" without referencing what such RNGs exist
   (and specifically stating that there are on approved
   non-deterministic RNGs),
c) Annex C (where approved RNGs are listed) is still a Draft.
On the plus side, one of the approved RNGs listed in the draft Annex C
(DRBG Special Publication 800-90) specifically addresses the entropy
pool concept, periodic reseeding with entropy from a non-deterministic
RNG (or from a chain of RNGs anchored by a non-deterministic RNG).
X9.31 uses two seeds, one a date/time vector, the other a proper seed
vector.  X9.31 is in the FIPS-140-2 draft Annex C.
I would argue that if what you say is true then it derives from the
standard being underspecified.  In other words: what the standard says
(and doesn't) does matter, very much.  If different labs interpret
critical portions of the standard in significantly different ways, and
in some cases in ways that reduce security, then clearly the standard is
in need of updating.
The spec ought to describe acceptable PRNG seeding in the absence of
TRNGs (e.g., use a factory seed plus date/time and/or an atomically
incremented counter that is stored persistently), it should cover
virtual machines, and it should cover RNGs that are entropy pools
constructed out of TRNGs and PRNGs.

@_date: 2010-09-08 12:21:01
@_author: Nicolas Williams 
@_subject: Hashing algorithm needed 
I understand why you're doing this, but it's not really any better than
sending the password to the server in the first place via a POST from an
HTML form (where the GET and POST of the form happen over HTTPS).  The
reason there's no real difference is that the script comes from the
server, so it could do anything at all (and besides, you'll end up with
a password equivalent at some point if all you do is hash the password,
but read on).
And since you'd still be teaching your users to type passwords into web
page elements, you'd still leave your users susceptible to phishing.
Still, if this is what really you want, then I recommend that you use
SCRAM (RFC5802).  SCRAM uses HMAC-SHA-1.  You can find implementations
of SHA-1 in JavaScript; implementing SCRAM given a JavaScript SHA-1
implementation isn't hard.
Note that if mechanisms like SCRAM were provided by the browser, then
it'd safe (indeed, good!) to use them.  Implementing them in a server-
provided script doesn't provide anywhere near as much security as
implementing them natively in the browser (or in a browser plug-in/
If you can afford to develop a browser add-on, then I recommend you
implement SCRAM there.  The key is to make it possible for users to
distinguish web page elements from UI elements of the browser/ add-on --
this is hard.
We calls those random elements "nonces".  SCRAM has those.  Browsers
provide a random() method.
SCRAM is rather simple.
I'm not sure what you mean here.  I think you mean that the verifier
shouldn't be the password nor a password equivalent, in which case
you're completely correct.  SCRAM has that, though the server obtains
enough information, the first time that the user authenticates, to keep
a password equivalent for later use.  Also, SCRAM is susceptible to
off-line password dictionary attacks.  SCRAM is best used over TLS
(HTTPS), with channel binding (see below), to defeat passive attacks and
to make MITM attacks harder to mount without the user noticing.
"Little code" does not imply "fast".  Nor does "much code" imply "slow".
If you don't understand this then you have bigger problems than not
being into cryptography.  You should want "little code" so that
development and maintenance are cheap, not so it runs fast.
You should definitely want to secure the connection.  If you don't then
your users will be subject to MITM attacks.  (But then, your users will
be vulnerable to phishing attacks anyways, since they'll be used to
typing passwords into spoofable web page elements.)
Well, you did the right thing in coming to such a list.  You should have
done more reasearch, but it's not a big deal that you didn't, because as
you can see, the real problem is that we don't have a good solution for
you (that is, the browsers don't provide what you really need).
I don't understand: why not use HTTPS [with server certs]?  Granted,
you'd still depend on a "PKI" with so many root CAs as to be nearly
useless.  But even so, HTTPS is much better than nothing.  And yes, TLS
(SSL) is at a lower layer, but that's not a real problem.  Moreover,
SCRAM provides for "channel binding", which allows you to bind the TLS
channel into the SCRAM authentication, which in turn helps the weak PKI

@_date: 2010-09-14 18:26:54
@_author: Nicolas Williams 
@_subject: Hashing algorithm needed 
I'll note that Ben's proposal is in the same category as mine (which
was, to remind you, implement SCRAM in JavaScript and use that, with
channel binding using tls-server-end-point CB type).
It's in the same category because it has the same flaw, which I'd
pointed out earlier: if the JS is delivered by "normal" means (i.e., by
the server), then the script can't be used to authenticate the server.
And if you've authenticated the server vi HTTPS (TLS) then you might as
well just POST the username&password to the server, since the server
could just as well send you a script that does just that.
This approach works only if you deliver the script in some out-of-band
manner, such as via a browser plug-in/add-on (hopefully signed [by a
trustworthy trusted third party]).
