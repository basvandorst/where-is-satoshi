
@_date: 2001-06-22 15:00:33
@_author: Jeffrey I. Schiller 
@_subject: crypto flaw in secure mail standards 
In fact there are many applications where the separation of the
signing operation from the encryption operation are useful and
Encryption provides a different service then the underlying
signature. It protects the document from being read by unintended
recipients. The signature can provide proof later that the sender did
in fact sign the message.
It is always the case that one must be careful what one writes in
e-mail, for once delivered to the recipient, the sender looses control
of the document.  In fact this threat even exists in paper mail. If
Alice sends Bob a "The deal is off" letter, but doesn't mark the
letter with enough context, Bob can always physically forward the
letter to a third party and claim it is from Alice.
I believe it is important that message signatures outlive the
message's encryption layer. If I receive a signed/encrypted message. I
will loose the ability to decrypt it if I loose my private key (or
intentionally destroy it to prevent its future compromise). However if
I remove the encryption and store the message signed (perhaps
protected by other mechanisms in my mail store), I can always verify
the signature as long as I have access to the sender's certificate
chain. No secrets have to be saved.
Btw. I don't believe S/MIME has timestamps in its signature
format. PGP does. PGP also implements a "for her eyes only" feature
that only permits an encrypted message to be displayed, but not saved
in a file. Now of course a sufficiently clever person can circumvent
this protection. I am now wondering how hard it would be to circumvent
this feature *and* keep the original message signature (of course if
you have the PGP source code, you can do this).
However, having said all this, Don has a point. There may be a class
of message where you want to prove that you originated it *only to the
original sender*.  If he has a way to do that, it sounds like a good
But there isn't a flaw in secure e-mail, just a missing service.

@_date: 2001-06-23 11:51:51
@_author: Jeffrey I. Schiller 
@_subject: crypto flaw in secure mail standards 
Ah. This is why I always replicate the Subject field (and other important)
fields in message that I sign for posterity (such as IESG action requests).

@_date: 2002-06-22 14:40:00
@_author: Jeffrey I. Schiller 
@_subject: DOJ proposes US data-rentention law. 
Of course the anti-spam people are telling ISP's to block port 25 and
require end-users to forward their e-mail through the ISP owned mail
I've always had the fear that in the clammer to get rid of spam we
would wind up building a centralized mail routing system, the spy's

@_date: 2002-10-27 16:07:46
@_author: Jeffrey I. Schiller 
@_subject: M-209 for sale on EBay 
Auction closes in about 4 hours and no one has bid...

@_date: 2003-06-11 16:10:21
@_author: Jeffrey I. Schiller 
@_subject: The real problem that https has conspicuously failed to fix 
Folks, this isn't an https (or even http) problem. It is a tough user interface issue. Note: The form posting goes to  which doesn't remotely look like paypal.com!
To make matters worse, there are plenty of businesses that send you leg imitate email that comes from a "random" looking place. Just today I received one from MIT's Alumni Association, but the actual source was something like m0.email-foobar.com (or something). Obviously the Alumni Association outsources the sending of the mail to some third party company. So even if we came up with some fancy was of saying "This form doesn't post to the same place this page came from [never mind that the original of an e-mail form is ill defined]" won't help.
I also received this scam mail. There were only two hints of badness (besides the obvious request for personal info that paypal shouldn't need) one was the form posting and the other was the "Received-by" line which my mail system put on the message which showed its original at a suspicious place (I believe in Japan, but I may have remembered wrong, it didn't look right at the time).
This is a social problem. Technical measures can help, but won't solve it, I am afraid.

@_date: 2003-06-11 16:11:59
@_author: Jeffrey I. Schiller 
@_subject: The real problem that https has conspicuously failed to fix 
Oh, and btw, the form posting URL in my message wasn't even https, it was just http. So all the futzing in the world with https wouldn't help!

@_date: 2003-06-12 15:24:19
@_author: Jeffrey I. Schiller 
@_subject: The real problem that https has conspicuously failed to fix 
Yep, I deployed such a PKI here at MIT back in 1996. Today every student and most faculty and staff have certificates.
It really does work, but unfortunately the support for them in the common browsers is quirky enough that we have our support fun! I can understand why commercial sites shy away.
I have also been involved in efforts to get U.S. Higher Education to start deploying client certificates. The big problem there is that public key encryption appears to require more then the amount of clue that most computer administrators seem to have, so education is a real

@_date: 2005-07-20 23:52:19
@_author: Jeffrey I. Schiller 
@_subject: ID "theft" -- so what? 
Btw. There are credit card issuers (AT&T Universal is one) that permits
you to create a virtual one-time use credit card (with a time limit and
$$ limit if you want).
So when I shop at a merchant I don't want to trust, I open another
browser window and go to my issuers website and obtain a one-time card
number and use it at the merchant site. I can usually see immediately
after the purchase that the card has been used (on the issuers website)
so I know the merchant is checking the card in real time.
Apparently there is wallet software that will do this in a more
automated fashion, but it isn't available for my platform (non-Windows).

@_date: 2006-05-01 11:26:04
@_author: Jeffrey I. Schiller 
@_subject: Disk Encryption (was: Re: PGP "master keys") 
I use the following approach to encrypting my disks.
I use an encrypted loopback device. The version of losetup I use
permits me to store the disk key in a PGP encrypted file and decrypt
it (with gpg) when needed. I made many backups of the both my personal
keyring and the file with the encrypted loop key. So the only "secret"
I have to remember is the passphrase on my normal PGP key, which I am
not liekly to forget.
Of course there is a trade-off here. If my PGP key is compromised, my
disk encryption is at risk (if the encrypted disk key file is
compromised as well).
                        -Jeff
P.S. If you run a reasonably modern Linux system, and have more then
one system, you can use "drbd" to implement software mirroring between
the two systems. Clever use of openvpn and encrypted loopback devices
can do this securely as well.
Jeffrey I. Schiller
MIT Network Manager
Information Services and Technology
Massachusetts Institute of Technology
77 Massachusetts Avenue  Room W92-190
Cambridge, MA 02139-4307
617.253.0161 - Voice
jis at mit.edu

@_date: 2009-02-16 22:50:30
@_author: Jeffrey I. Schiller 
@_subject: how to properly secure non-ssl logins (php + ajax) 
I think you are close, but are probably doing way too much work.
First let's define a function HMAC_MD. HMAC is defined in RFC2104
and represents the current best current practice for using a hash to
"sign" a data value. It takes:
  result = hmac_md(key, value)
You can use hmac with MD5, SHA1, SHA256... whatever. You will likely
find libraries that already implement this in various languages.
Below "SHA" means SHA1, SHA256, your choice.
We'll assume each user has a password which is stored on the
server. For a bit of extra security I would have the server store it
as a SHA hash of the actual password.)
For authentication you do a challenge response.
   Server                         Client
    nonce           ====>
                    <===        username, hmac_md(sha(password), nonce)
The trick is to ensure that the nonce is not re-used. There are
several ways to do this. One way is to store it in a table:
  crate table nonces (
       nonce varchar(128),   # Probably enough
       ts  timestamp,
       used Boolean )
When the server gets the reply it looks up the user's "sha(password)"
which is stored in the user account table. It then verifies that the
nonce value is in the nonces table and that used is False. It then
verifies that the timestamp is "fresh" (you can decide this). Upon
use, the nonces table is updated to set used to True. A second login
attempt would require a separate nonce. Once a nonce is no longer
"fresh" it can be purged from the nonces table (so you don't have to
store these forever). Obviously the server computes
hmac_md(sha(password), nonce) and verifies it is the value received
from the client.
There are a copy of gotchas here. The biggest is how you initially
setup the shared secret (aka the password). Without public key
operations there is no good way to create accounts (unless this is
done administratively, effectively "off line"). SSL of course can
solve this (but you don't want to use SSL). You can also attempt to
implement RSA in javascript and PHP (well, I'm sure routines exist for
PHP). You can then download a public key in your javascript code for
account registration. The user's browser can then compute
sha(password) and send it encrypted in the public key (or encrypted in
a data encrypting key which is encrypted in a public key).
I don't know how amenable javascript is to doing RSA. Years ago (when
computers were much slower) I wrote a Java Applet that did RSA in the
applet for account registration at MIT. It wasn't very fast, but it
was good enough for a one-time registration applet. Heh heh, we still
use it today!
Now of course I really cannot end this message without throwing in the
obvious caution that without SSL your authentication is pretty
weak. Even though you have not exposed the user's password, once
logged in PHP uses a session cookie. This cookie, although of limited
lifetime, is now available to the eavesdropper to steak and abuse. I'm
not even sure that PHP ensures that a cookie is coming from the same
IP address it was issued to (and in fact you cannot usually implement
such a restriction because some environments [aka large NATs and other
crud] can result in a legitimate user's traffic coming from different
IP addresses even within the same web session!).
And of course all of your data is also exposed, both for viewing and
for modification in flight.
Last I checked, SSL certificates could be had for the $20/year range,
so I don't see how that is cost prohibitive!
Modern hardware also does SSL pretty darn fast. You really have to
have a very high traffic site before it becomes a problem. There
actually aren't that many high traffic sites out there. Most
organizations may think their sites are high traffic, but they rarely
                        -Jeff
Jeffrey I. Schiller
MIT Network Manager
Information Services and Technology
Massachusetts Institute of Technology
77 Massachusetts Avenue  Room W92-190
Cambridge, MA 02139-4307
617.253.0161 - Voice
jis at mit.edu

@_date: 2009-07-14 11:57:53
@_author: Jeffrey I. Schiller 
@_subject: HSM outage causes root CA key loss 
It is exactly for this reason that when we generated the root key for
the U.S. Higher Education PKI we did it outside of an HSM and then
loaded it into two HSMs. The "raw" key was then manually secret shared
accross five CD's (three being the quorum) which were distributed to
five individuals for safe keeping. Because CD's have 700 Mb of storage
and the share secret is tiny, literally thousands of copies of it were
written on each CD along with the source code of the secret sharing
software (written in Python).
In theory every few years we are supposed to take out the CD's and
verify that they can be read. It's probably time to do that now :-)
Because of prior experience with a SafeKeyper(tm) (a very large HSM),
I learned that when the only copy of your key is in an HSM, the HSM
vendor really owns you key, or at least they own you!

@_date: 2009-11-02 17:36:07
@_author: Jeffrey I. Schiller 
@_subject: Security of Mac Keychain, Filevault 
I would not (do not) trust the iPhone (or iPod Touch) to protect a
high value password. Or more to the point I would change any such
password if my iPhone went unaccounted for.
In the case of the Mac Keychain and Filevault, if implemented
correctly, the security hinges on a secret that you know. Pick a good
secret (high entropy) and you are good. Pick a poor one, well...
However the iPhone?s keychain is not encrypted in a password. Instead
it is encrypted in a key derived from the hardware. The iPhone
Dev-Team, the folks who regularly jail break the iPhone, seem to have
little problem deriving keys from the phone! Note: Setting a phone
lock password doesn?t prevent me from accessing the phone using the
various jail breaking tools. Presumably once I have control of the
phone, I have access to any of the keys on it.

@_date: 2010-08-02 10:51:41
@_author: Jeffrey Schiller 
@_subject: Is this the first ever practically-deployed use of a threshold 
Hash: SHA1
OK. I'm being a bit lazy but...
I've read through the ceremony script and all that, but I have a
simple question which the script documents didn't really answer:
Does the root KSK exist in a form that doesn't require the HSM to
re-join, or more to the point if the manufacturer of the HSM fails, is
it possible to re-join the key and load it into a different vendor's
In other words, is the value that is split the "raw" key, or is it in
some proprietary format or encrypted in some vendor internal key?
Back in the day we used an RSA SafeKeyper to store the IPRA key (there
is a bit of history, we even had a key ceremony with Vint Cerf in
attendance). This was the early to mid '90s.
The SafeKeyper had an internal tamper key that was used to encrypt all
exported backups (in addition to the threshold secrets required). If
the box failed, you could order one with the same internal tamper
key. However you could not obtain the tamper key and you therefore
could not choose to switch HSM vendors.
                        -Jeff

@_date: 2013-10-19 17:22:55
@_author: Jeffrey I. Schiller 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
That is a value judgment, one where you let security be more important
than anything else. That is a mistake.
There are plenty of applications where it is better to have things
work then to have them not work in the name of security. Consider an
embedded controller running a critical resource (like your heart
pacemaker). It is better to have it fail by using poor entropy then to
fail completely and leave you dead.
For example I just invoked the ?node? command (node.js), saw the
interactive prompt and then exited. Looking at strace output reveals
that it read from /dev/urandom. I suspect there are a lot of programs
that read from /dev/urandom that are not particularly security
sensitive, but people would be annoyed (or worse) if they hung.
There are always trade-offs to be made. I remember years ago hearing a
story about a discussion between crypto geeks and air force pilots
(could be navy pilots) discussing whether or not their radio systems
should permit in-the-clear communications in the event of failure to
sync up the crypto. The crypto geeks argued that no communication
should be permitted. The pilots said something like ?If there is
someone flying 6 inches off my wingtip, I WANT TO BE ABLE TO TALK TO
I would be in favor of having /dev/urandom block iff we define a
sysctl (or similar) flag that specifies if it should and the default
should be don?t block. System designers can then decide whether or not
to set the flag (presumably prior to any use of /dev/urandom).
                        -Jeff
Jeffrey I. Schiller
Information Services and Technology
Massachusetts Institute of Technology
77 Massachusetts Avenue  Room E17-110A, 32-392
Cambridge, MA 02139-4307
617.910.0259 - Voice
jis at mit.edu

@_date: 2013-09-02 18:04:43
@_author: Jeffrey I. Schiller 
@_subject: [Cryptography] Google's Public Key Size (was Re: NSA and 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Btw. As a random side-note. Google switched to 2048 bit RSA keys on
their search engine. However my connection to mail.google.com is using
a NIST p256r1 ECC key in its certificate.
- -Jeff

@_date: 2013-09-07 10:05:22
@_author: Jeffrey I. Schiller 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Don?t be. There is no magic there. From what I can tell, there are two
different issues with public key.
1. Weaknesses in the math.
2. Fragility in use.
The NSA (or other national actors) may well have found a mathematical
weakness in any of the public key ciphers (frankly they may have found
a weakness in symmetric ciphers as well). Frankly, we just don?t know
here. Do we trust RSA more then Diffie-Hellman or any of the Elliptic
Curve techniques? Who knows. We can make our keys bigger and hope for
the best.
As for fragility. Generating random numbers is *hard*, particularly on
a day to day basis. When you generate a keypair with GPG/PGP it
prompts you to type in random keystrokes and move the mouse etc., all
in an attempt to gather as much entropy as possible. This is a pain,
but it makes sense for one-lived keys. People would not put up with
this if you had to do this for each session key. Fragile public key
systems (such as Elgamal and all of the variants of DSA) require
randomness at signature time. The consequence for failure is
catastrophic. Most systems need session keys, but the consequence for
failure in session key generation is the compromise of the
message. The consequence for failure in signature generation in a
fragile public key system is compromise of the long term key!
I wrote about this in NDSS 1991.... I cannot find an on-line reference
to it though.
Then if you are a software developer, you have the harder problem of
not being able to control the environment your software will run on,
particularly as it applies to the availability of entropy.
So my advice.
Use RSA, choose a key as long as your paranoia. Like all systems, you
will need entropy to generate keys, but you won?t need entropy to use
it for encryption or for signatures.
- -Jeff
Jeffrey I. Schiller
Information Services and Technology
Massachusetts Institute of Technology
77 Massachusetts Avenue  Room E17-110A, 32-392
Cambridge, MA 02139-4307
617.910.0259 - Voice
jis at mit.edu

@_date: 2013-09-07 10:20:52
@_author: Jeffrey I. Schiller 
@_subject: [Cryptography] Protecting Private Keys 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
While we worry about symmetric vs. public key ciphers, we should not
forget the risk of compromise of our long-term keys. How are they
One of the most obvious ways to compromise a cryptographic system is
to get the keys. This is a particular risk in TLS/SSL when PFS is not
used. Consider a large scale site (read: Google, Facebook, etc.) that
uses SSL. The private keys of the relevant certificates needs to be
literally on hundreds if not thousands of systems. Chances are they
are not encrypted on those systems so those systems can auto-restart
without human intervention. Those systems also break
periodically. What happens to the broken pieces, say a broken hard
If one of these private keys is compromised, all pre-recorded traffic
can now be decrypted, as long as PFS was not used (and as we know, it
is rarely used).
Encrypted email is also at great risk because we have no PFS in any of
these systems. Our private keys tend to last a long time (just look at
the age of my private key!).
If I was the NSA, I would be scavenging broken hardware from
?interesting? venues and purchasing computers for sale in interesting
locations. I would be particularly interested in stolen computers, as
they have likely not been wiped.
The bottom line here is that the NSA has upped the game (and probably
did so quite a while ago, but we are just learning about it now). This
means that commercial organizations that truly want to protect their
customers from the NSA, and other national actors whom I am sure are
just as skilled and probably more brazen, need to up their game, by a
- -Jeff
P.S. I am very careful about which devices my private key touches and
what happens to it when I am through with it.

@_date: 2013-09-07 16:06:02
@_author: Jeffrey I. Schiller 
@_subject: [Cryptography] Protecting Private Keys 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Years ago when key escrow and the Clipper was still on the table, I
developed an attack on the key escrow agents. It worked like this:
 1. Approach facility, knock on door.
 2. To the person who answers: ?Here is $1 Million, take a walk.?
 3. To anyone else encountered: ?Here is $1 Million, go to the
    bathroom.?
 4. ... (you get the idea).
The fact that the keys would fit on an exabyte tape made exfiltrating
them pretty easy.
A few SSL private keys take even less space.
I have a lot of respect for how Google runs its operation. However it
wouldn?t be that hard to arrange for an agent to get a job there
(there are very smart people at NSA, and Google likes hiring smart
people :-) ) for the purpose to obtaining keys.
Of course, this is all speculation...
                        -Jeff
Jeffrey I. Schiller
Information Services and Technology
Massachusetts Institute of Technology
77 Massachusetts Avenue  Room E17-110A, 32-392
Cambridge, MA 02139-4307
617.910.0259 - Voice
jis at mit.edu

@_date: 2013-09-07 19:52:44
@_author: Jeffrey I. Schiller 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
I?m sorry, but I cannot let this go unchallenged. I was there, I saw
it. For those who don?t know, I was the IESG Security Area Director
from 1994 - 2003. (by myself until 1998 after which we had two co-AD?s
in the Security Area). During this timeframe we formed the TLS working
group, the PGP working group and IPv6 became a Draft Standard. Scott
Bradner and I decided that security should be mandatory in IPv6, in
the hope that we could drive more adoption.
The IETF was (and probably still is) a bunch of hard working
individuals who strive to create useful technology for the
Internet. In particular IETF contributors are in theory individual
contributors and not representatives of their employers. Of course
this is the theory and practice is a bit ?noisier? but the bulk of
participant I worked with were honest hard working individuals.
Security fails on the Internet for three important reasons, that have
nothing to do with the IETF or the technology per-se (except for point
 1.  There is little market for ?the good stuff?. When people see that
     they have to provide a password to login, they figure they are
     safe... In general the consuming public cannot tell the
     difference between ?good stuff? and snake oil. So when presented
     with a $100 ?good? solution or a $10 bunch of snake oil, guess
     what gets bought.
 2.  Security is *hard*, it is a negative deliverable. You do not know
     when you have it, you only know when you have lost it (via
     compromise). It is therefore hard to show return on investment
     with security. It is hard to assign a value to something not
     happening.
 2a. Most people don?t really care until they have been personally
     bitten. A lot of people only purchase a burglar alarm after they
     have been burglarized. Although people are more security aware
     today, that is a relatively recent development.
 3.  As engineers we have totally and completely failed to deliver
     products that people can use. I point out e-mail encryption as a
     key example. With today?s solutions you need to understand PK and
     PKI at some level in order to use it. That is likely requiring a
     driver to understand the internal combustion engine before they
     can drive their car. The real world doesn?t work that way.
No government conspiracy required. We have seen the enemy and it is...
                        -Jeff
Jeffrey I. Schiller
Information Services and Technology
Massachusetts Institute of Technology
77 Massachusetts Avenue  Room E17-110A, 32-392
Cambridge, MA 02139-4307
617.910.0259 - Voice
jis at mit.edu

@_date: 2013-09-08 21:23:33
@_author: Jeffrey I. Schiller 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Speaking as one of the Security Area Directors at the time...
I have to disagree with your implication that the NSA intentionally
fouled the IPSEC working group. There were a lot of people working to
foul it up! I also don?t believe that the folks who participated,
including the folks from the NSA, were working to weaken the
standard. I suspect that the effort to interfere in standards started
later then the IPSEC work. If the NSA was attempting to thwart IETF
security standards, I would have expected to also see bad things in
the TLS working group and the PGP working group. There is no sign of
their interference there.
The real (or at least the first) problem with the IPSEC working group
was that we had a good and simple solution, Photuris. However the
document editor on the standard decided to claim it (Photuris) as his
intellectual property and that others couldn?t recommend changes
without his approval. This effectively made Photuris toxic in the
working group and we had to move on to other solutions. This is one of
the events that lead to the IETF?s ?Note Well? document and clear
policy on the IP associated with contributions. Then there was the
ISAKMP (yes, an NSA proposal) vs. SKIP. As Security AD, I eventually
had to choose between those two standards because the working group
could not generate consensus. I believed strongly enough that we
needed an IPSEC solution so I decided to choose (as I promised the
working group I would do if they failed to!). I chose ISAKMP. I posted
a message with my rationale to the IPSEC mailing list, I?m sure it is
still in the archives. I believe that was in 1996 (I still have a copy
somewhere in my personal archives).
At no point was I contacted by the NSA or any agent of any government
in an attempt to influence my decision. Folks can choose to believe
this statement, or not.
IPSEC in general did not have significant traction on the Internet in
general. It eventually gained traction in an important niche, namely
VPNs, but that evolved later.
IPSEC isn?t useful unless all of the end-points that need to
communicate implement it. Implementations need to be in the OS (for
all practical purposes).  OS vendors at the time were not particularly
interested in encryption of network traffic.
The folks who were interested were the browser folks. They were very
interested in enabling e-commerce, and that required
encryption. However they wanted the encryption layer someplace where
they could be sure it existed. An encryption solution was not useful
to them if it couldn?t be relied upon to be there. If the OS the user
had didn?t have an IPSEC layer, they were sunk. So they needed their
own layer. Thus the Netscape guys did SSL, and Microsoft did PCT and
in the IETF we were able to get them to work together to create
TLS. This was a *big deal*. We shortly had one deployed interoperable
encryption standard usable on the web.
If I was the NSA and I wanted to foul up encryption on the Internet,
the TLS group is where the action was. Yet from where I sit, I didn?t
see any such interference.
If we believe the Edward Snowden documents, the NSA at some point
started to interfere with international standards relating to
encryption. But I don?t believe they were in this business in the
1990?s at the IETF.
                        -Jeff

@_date: 2013-09-09 14:48:56
@_author: Jeffrey I. Schiller 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
Just to throw in my two cents...
In the early 1990?s I wanted to roll out an encrypted e-mail solution
for the MIT Community (I was the Network Manager and responsible for
the mail system). We already had our Kerberos Authentication system
(of which I am one of the authors, so I have a special fondness for
it). It would do a fine job of helping people exchange session keys
for mail and everyone at MIT has a Kerberos ID (and therefore would
permit communication between everyone in the community).
However, as Network Manager, I was also the person who would see legal
requests for access to email and other related data. Whomever ran the
Kerberos KDC would be in a position to retrieve any necessary keys to
decrypt any encrypted message. Which meant that whomever ran the KDC
could be compelled to turn over the necessary keys. In fact my fear
was that a clueless law enforcement organization would just take the
whole KDC with a search warrant, thus compromising everyone?s
security. Today they may well also use a search warrant to take the
whole KDC, but not because they are clueless...
The desire to offer privacy protection that I, as the administrator,
could not defeat is what motivated me to look into public key systems
and eventually participate in the Internet?s Privacy Enhanced Mail
(PEM) efforts. By using public key algorithms, correspondents are
protected from the prying eyes of even the folks who run the system.
I don?t believe you can do this without using some form of public key
                        -Jeff
Jeffrey I. Schiller
Information Services and Technology
Massachusetts Institute of Technology
77 Massachusetts Avenue  Room E17-110A, 32-392
Cambridge, MA 02139-4307
617.910.0259 - Voice
jis at mit.edu

@_date: 2016-07-03 11:47:57
@_author: Jeffrey Schiller 
@_subject: [Cryptography] Android Full Disk Encryption Broken - Extracting 
Hash: SHA1
If you look at the exploit you will see it is a simple case of failing
to check array/string bounds. A fairly standard hazard in C code. This
kind of mistake doesn’t require complex code, though it is more likely
in complex code.
What concerns me more is the prevalence of “hidden” processors showing
up on our systems. From the TrustZone to cell phone base band
processors to Intel’s Enterprise Management Engine. All of these have
complete access to our systems, run unpublished, un-audited code and
in many cases cannot be upgraded! The Ultimate Root Kit you may not be
able to remove without throwing away your hardware *and* waiting an
arbitrary period of time for new hardware to come out with the problem
solved (and new ones provided).
- -Jeff

@_date: 2017-12-23 23:24:05
@_author: Jeffrey Schiller 
@_subject: [Cryptography] Bitcoin, fork you very much 
If China has more then 51% of the hashing power, it could simply block the
bitcoin network. This would create a network partition. One blockchain
would grow inside China while one would grow outside China. If China has
more hashing power, its blockchain would likely grow longer (deeper) then
the one outside.
Then it removes the block and the partition heals. Suddenly the inside
China blockchain is definitive, because it is deeper, and the blocks on the
chain outside China (from the time of the partition) are orphaned. Wammo,
all of the transactions in those blocks are invalidated! Now THAT would be
