
@_date: 2002-12-16 17:54:44
@_author: David Howe 
@_subject: Micropayments, redux 
at Monday, December 16, 2002 5:19 PM, R. A. Hettinga
 was seen to say:
Indeed so, yes - however, statistical payments only work if there are a
lot of them - when you dip below the single unit (100,000 hits that
provide a peppercorn) then you have a statistical chance of either
getting a full $100 or nothing at all - when your outlay is definitely
due every month regardless of if you get paid or not. This would
encourage aggregation - pooling peppercorns amongst several sites and
splitting the income in proportion to the peppercorns collected - but
given enough aggregation, that is no different than the frequent current
setup where you gain "membership" of a multi-provider site and the fees
(minus a handling fee of course) are split in proportion to hits amongst
the content providers. There is also a fairly high processing overhead -
for every hundred bucks (on average) you get, you have to verify 100,000
digital signatures and present each one for fullfillment (possibly
repeatedly unless the validator knows up front which one will be
redeemable and which 99,999 will not)
Honestly I can't imagine the pain of this being worth paying a patent
usage fee for.

@_date: 2002-11-09 18:28:22
@_author: Dave Howe 
@_subject: Did you *really* zeroize that key? 
Given the nature of this problem, perhaps a *better* solution would be to
work on getting the spec updated to include a "security-sensitive"
declaration for variables in c/c++? such variables could be held in such a
way that they (where the os permits)
a) are never swapped to disk
b) are automagically wiped with three passes of pseudo-random data when
c) are in a "security data" area of memory that can't be accessed by
programs not owning the data there
d) are register variables when possible (for security, not speed)
the "always wipe when the variable is discarded" functionality shouldn't be
that hard to impliment, and would remove the only real reason we don't want
optimisation for those variables - that we want to be able to blank them.
not sure a  Leave_This_Intact_You_Bastard is the right solution
though :)

@_date: 2003-12-14 14:55:22
@_author: Dave Howe 
@_subject: CryptoPhone source and CryptoPhone for Windows released 
Glad to see it - however, I have a couple of minor queries about the
licencing (skipping the bits about agreeing to forfeit rights explicitly
granted by law - which obvously are worthless) :-
As it is almost impossible to compare two binaries from a modern compiler -
would it be possible for this section to be amended to allow personal use of
the self-compiled binary - obviously, without permission to redistribute.
Also, review of code is seldom a solitary activity - I assume quoting
sections of code is ok for the purposes of collaborative review, and if so,
could this be explicitly stated in future licences? and where do we report
anything we find to? the Security@ address?
and as an aside - while I understand the main focus of your work being over
public carrier (as that is the target market for your handheld devices), are
there any future plans to include VoIP capability (which as more mobile
devices become web-enabled would obviously be advantagious for long-distance
telephony, and is common on pcs now)

@_date: 2003-12-14 14:41:38
@_author: Dave Howe 
@_subject: example: secure computing kernel needed 
I think PC banking is an argument *against* Secure Computing as currently
proposed - there is no way to discover if there is a nasty "running" in
protected memory or removing it if there is.

@_date: 2003-12-14 15:03:39
@_author: Dave Howe 
@_subject: PKI root signing ceremony, etc. 
Looks good. A group I am involved with followed though similar steps a few
years ago - using openssl and batch files.
These days there is a very nice oss/free gui tool which makes the whole
process a whole lot easier - check out:

@_date: 2003-12-14 15:05:47
@_author: Dave Howe 
@_subject: Swipe-Free Credit Cards Tested 
Here in the UK there is a second, slightly more sinister motive; a CC
receipt signed by a customer places the liability on the provider, while a
"Customer not present" transaction places it on the retailler. guess which
one a pin-code card falls under?

@_date: 2003-12-14 18:46:13
@_author: Dave Howe 
@_subject: PKI root signing ceremony, etc. 
*shrug* it doesn't retroactively enforce the safety net - but that's ok,
most MS products don't either :)
note what it is saying here is that if you *have* a cert signed by a non-CA
key/cert pair, it will still display the chain - not that you can use a
non-ca key/cert pair to sign with (which is another issue; writing software
to sign using non-ca key/cert pairs is trivial though)
XCA enforces the basic constraint for keysigning, just is more lax while
displaying chains.
nor is there any with OpenSSL - there is revocation list management (which
is more than some commercial CA software in this area provides, and more
than Thawte even bothers to offer :)
Key management and auditing is pretty much external to the actual software
regardless of which solution you use I would have thought. Your rituals are
equally applicable to xca - just the nature of the tool (a pretty gui rather
than a command line exe, script and some config files) has changed.
two level independent CA is possible, by having more than one XCA database.
the location of the database can be specified to be on removable media
(which simplifies things quite a bit :)
assuming you have two databases (a:\master.db and c:\level1.db) just create
two shortcuts to xca with each db passed as a command line parameter - or if
you want to keep *both* on more reliable removable media (say, a thumbdrive)
you could arrange for the autorun.ini on each to automagically launch XCA
when inserted into a usb slot, running xca directly from the thumbdrive (so
no footprint at all on the machine) - this is trival to do with a little bit
of vbscript or batchfile scripting
you could also (if it makes you feel more secure) use Openssl for the root
certificate (which after all doesn't see much use) and XCA for day-to-day
issuing of keys, but there seems little or no reason to do so.
Personally, I keep my XCA databases in scramdisks.

@_date: 2003-12-15 14:34:14
@_author: Dave Howe 
@_subject: PKI root signing ceremony, etc. 
I meant in this context - certainly, a well designed CA package would
enforce security and audit trailing (I can easily visualise one that uses
a composite (split) access key n of m, and could probably code up such a
tool in a day or so) but Rich's original design had no audit or key
management other than that imposed externally on the (essentially
flatfile) stucture of Openssl command line tools.
*nods* and that is probably as secure as any other method, and a *lot*
more secure than a "safe" exe running on insecure hardware.

@_date: 2003-02-22 00:13:36
@_author: Dave Howe 
@_subject: AES-128 keys unique for fixed plaintext/ciphertext pair? 
This is not necessarily the case. Beyond the Unicity distance it is possible
to determine the unique plaintext for each cyphertext. if the unicity
distance for AES is one block or less, then you can uniquely determine the
plaintext matching the cyphertext - even if two keys could possibly generate
the same mapping for that unique plaintext to cyphertext pair.
AFAIK, shannon doesn't mention *how* you resolve the mapping, just that it
exists. as a Known Plaintext attack usually cannot trivially obtain the key,
I don't know how a theoretical "shannon" attack could be expected to yield a
key in addition to the plaintext.

@_date: 2003-02-22 00:25:09
@_author: Dave Howe 
@_subject: AES-128 keys unique for fixed plaintext/ciphertext pair? 
Hmm. another simpler theory to remove Shannon from the discussion.
assume that the original assertion is correct - that for each plaintext p
and each cyphertext c there exists only one key k that is valid to map
encrypt(p,k)=c. In this case, for each possible cyphertext c, *every*
possible plaintext p is a valid translation given a unique key k. for that
reason, the uniary distance for encrypt() must be larger than one block - as
it is self evidently not possible to map *any* c to a unique p without
knowledge of the key.
For that reason, Shannon cannot be applied to a single block of encrypt(),
and can be safely ignored :)

@_date: 2003-01-16 16:26:32
@_author: David Howe 
@_subject: Question regarding group management of documents 
TBH, I wouldn't bother.
use a server to store the documents, set folder permissions per group,
use some sort of lan encryption to protect the data in transit. Novell
is probably the best at this, but almost any file server will do.
Of course we now start into the lan encryption arguments :)

@_date: 2003-01-31 11:25:38
@_author: David Howe 
@_subject: Sovereignty issues and Palladium/TCPA 
at Friday, January 31, 2003 2:18 AM, Peter Gutmann
 was seen to say:
And indeed - download patches silently to change the "disable"
functionality to "email anything interesting directly to the CIA"

@_date: 2003-06-04 12:02:23
@_author: Dave Howe 
@_subject: Maybe It's Snake Oil All the Way Down 
For that matter, our system here discards the CC after use (the pre-auth
step with the merchant bank agent gives us back a "fulfillment handle" that
can only be used to fulfill or cancel that individual transaction - but of
course Amazon *want* to keep your CC details so they can do their
fast-checkout patented thingy.

@_date: 2003-06-04 09:08:56
@_author: Dave Howe 
@_subject: Maybe It's Snake Oil All the Way Down 
As a minor aside - most laptops can manage pgpfone using only onboard
hardware these days, either using an integrated modem or (via infrared) a
mobile phone.....

@_date: 2003-06-07 19:05:53
@_author: Dave Howe 
@_subject: Maybe It's Snake Oil All the Way Down 
Nope. issuing certs to someone is trivial from both a server and a user
endpoint - the user just gets a "click here to request your key" and hits ok
on a few dialog boxes; the server simply hosts some pretty off-the-shelf
Not so much that as have a much bigger security issue. Maintaining keys
securely would then become a task for the client, and while keeping a
written password secret is something most people can handle the concept of,
keeping a block of computer data safe from random trojans while exporting it
to be transported between machines is much, much harder.
Of course, you *could* generate the key entirely locally on the server,
protecting it with a HTTPS download, and protect it with the enduser's
password (not sure how secure the PKCS password is - if it isn't, then use
some self-decoding-exe like the 7z one) but that still wouldn't force the
end user to do more than hit "import" and have it stored insecurely on their
client machine.
its surprisingly reliable and easy - particuarly if your end users are just
using the MS keystore, which requires them to do no more than double-click
the pkcs file and hit "next" a few times.

@_date: 2003-06-07 19:08:53
@_author: Dave Howe 
@_subject: Quantum crypto, from BBC 
For limited applications, yes
QC in the form usually found in recent tests is actually quite simple.
The sender generates some good random binary data (from an unknown source,
doesn't really matter) and sends it encoded in the polarization of a photon
(one of four states - so two bits are needed at this point per photon; the
first encodes a choice of axes (horizontal+vertical or the diagonals) and
the second an orientation (so for example a 0 could be represented by
horizontal and 1 by vertical, or if the diagonal filter is in use, 0 by a \
and 1 by a /) )
The recipient filters the photons using a random choice of filter - and
transmits the choice of filter back to the sender. From this, the sender
will know if the recipient received the photon encoded properly or not - a
vertical filter would "see" a photon for a vertically encoded 1, not see one
for a horizontally encoded 0, and have a chance to see either a \ or a / but
if it is a decent filter, would not see them at all; the same idea rotated
45 degrees applies to the diagonal filter.
The sender then tells the recipient which filters he got right. Both now
have a set of bits that they alone know, are completely randomly generated,
and can be used as a key for conventional crypto (or if it is important
enough, OTP)
photon path - usually a fiberoptic, so that you can predetermine the
reference axes at both ends of the cable. even a free-air path is usually
too vunerable to distortion and/or photon loss, so is unsuitable.  So, for
the limited case where you can create a single, unbroken optic path between
two sites, and maintain it in a state where it can't be broken by a third
party for a literal mitm attack, it is a perfectly feasable scheme for
transmitting keys. Not likely to replace a trusted courier with a dozen
cheap CDR burnt with keydata in the near future though

@_date: 2003-06-08 23:43:29
@_author: Dave Howe 
@_subject: An attack on paypal 
HTTPS works just fine.
The problem is - people are broken.
At the very least, verisign should say "ok so '..go1d..' is a valid server
address, but doesn't it look suspiously similar to this '..gold..' site over
here?" for  - but really, if users are going to
fill in random webforms sent by email, they aren't going to be safe under
any circumstances; the thing could send by unsecured http to any site on the
planet, then redirect to the real gold site for a generic "transaction
completed" or even "failed" screen
A world where a random paypal hack like this one doesn't work is the same as
the world where there is no point sending out a Nigerian as you will never
make a penny on it - and yet, Nigerian is still profitable for the con

@_date: 2003-06-09 02:09:30
@_author: Dave Howe 
@_subject: An attack on paypal 
The problem is here, we are blaming the protective device for not being able
to protect against the deliberate use of an attack that bypasses, not
challenges it - by exploiting the gullibility or tendency to take the path
of least resistance of the user.
The real weakness in HTTPS is the tendency of certificates signed by Big
Name CAs to be automagically trusted - even if you have never visited that
site before.  yes, you can fix this almost immediately by untrusting the
root certificate - but then you have to manually verify each and every site
at least once, and possibly every time if you don't mark the cert as
"trusted" for future reference.
To blame HTTPS for an attack where the user fills in a web form received via
html-rendering email (no https involved at all) is more than a little unfair
I am not aware of one (not that that means much, given I am a novice in this
Even PKI relies on something close to a shared secret - a *trustworthy* copy
of the public key, matching a secret copy of the private key. In x509, this
trustworthyness is established by an Ultimately Trusted CA; in pgp, by the
Web Of Trust, in a chain leading back to your own key; in SSH, by your
placing of the public key into your home dir manually (using some other form
of authentication to presumably gain access)
in each of these cases, the private key will almost invariably be protected
by a passphrase; at best, you can have a single passphrase (or even single
private key) to cover all bases.. but that just makes that secret all the
more valuable.
That is pretty much because defence occupies the position of the interior -
attackers will almost invariably attack weak points, not strong ones. It is
easy to log and calculate how many attacks happen on weak points, but
impossible to calculate how many attacks *would* have happened had the
system not been in place to protect against such attacks, so the attackers
moved onto easier targets.
It makes little sense to try and break one https connection (even at 40 bit)
if by breaking into the server you get that information, hundreds of others
(until discovered) and possibly thousands of others inadvisedly stored
unprotected in a database.
Which again matches well to the Nigerian analogy. Everyone *knows* that
handing over your bank details is a Bad Thing - yet they still do it.

@_date: 2003-06-10 17:32:25
@_author: Dave Howe 
@_subject: The real problem that https has conspicuously failed to fix 
or just show the verified name in the status bar
use a specific font that makes vaguely similar characters wildly different -
use an ornate script font for numbers, with a sans font for letters, and
symbols in a "grey" halftone bold. as long as 1 can't look like i or l and 0
is wildly different from O, a lot of "fake" sites will stand out

@_date: 2003-06-11 15:00:07
@_author: Dave Howe 
@_subject: An attack on paypal 
I imagine if there exists a  site for purposes of
fraud, it won't be using a self-signed cert. Of course it is possible that
the attackers are using http:// instead, but more people are likely to
notice that.
I don't think any currently can be - but regardless, an attacker wishing to
run a fraudulent https site must have a certificate acceptable to the
majority of browsers without changing settings - That currently is the big
name CAs and nobody else.

@_date: 2003-06-18 15:24:19
@_author: Dave Howe 
@_subject: Pre-cursor to Non-Secret Encryption 
However the concept seems familiar enough - unless I am missing something, a
PRNG (n for noise rather than number this time) in sync with a similar PRNG
at the recipient end is mixed with the plaintext signal to give a
cryptotext; the matching unit subtracts the same values from the received
signal to give the original plaintext.  If it were digital we would probably
xor it :)

@_date: 2003-03-06 17:49:50
@_author: David Howe 
@_subject: Scientists question electronic voting 
at Thursday, March 06, 2003 5:02 PM, Ed Gerck  was seen
to say:
as has been pointed out repeatedly - either you have some way to "bin"
the receipt and start over, or it is worthless (and merely confirms you
made a bad vote without giving you any opportunity to correct it)
That given, you could vote once for each party, take your photograph,
void the vote (and receipt) for each one, and then vote the way you
originally intended to :)

@_date: 2003-03-07 16:12:42
@_author: David Howe 
@_subject: Scientists question electronic voting 
This may be the case in france - but in england, every vote slip has a
unique number which is recorded against the voter id number on the
original voter card. any given vote *can* be traced back to the voter
that used it.

@_date: 2003-03-31 22:04:49
@_author: Dave Howe 
@_subject: Russia Intercepts US Military Communications? 
Possibly someone was bribable - presumably the CoW need to share the same
frequencies and keys, so....

@_date: 2003-11-17 12:45:18
@_author: Dave Howe 
@_subject: Partition Encryptor 
Does anyone know of a version where this work has been done?

@_date: 2003-11-26 09:37:04
@_author: Dave Howe 
@_subject: Cryptophone locks out snoopers 
I see the source release has been put back... again.

@_date: 2003-10-01 19:30:06
@_author: Dave Howe 
@_subject: Monoculture 
ok then "yes" :)
What it comes down to is a browser will trust any certificate either
a) explicitly marked as trusted or
b) signed by a root CA in its root certificate store
so the correct procedure for (a) is for bob to delete eve's root
certificate from his root store.
for (b) he can either explicitly mark Alice's cert as accepted, or
(technically more interesting) if he trusts her as "introducer" add her
root cert - which is the same thing if she self-signed her cert - to his
root store, so that *any* cert she signs is accepted.

@_date: 2003-10-02 12:27:08
@_author: Dave Howe 
@_subject: Monoculture 
To me it seems more like a academic community - particularly the way many
can't handle the concept of "good enough" but look for theoretically
perfect solutions that may be unworkable in the Real World.  And yes, I
*am* an outsider - I dabble a little, and I am a programmer, but I am the
first to admit my math skills are nowhere near adequate to make any
meaningful contribution to the field.
It seems to me there is no more a cryptography guild than a linux guild -
yes, you get advocates who foam at the mouth if you say the wrong thing,
but the majority seem more interested in getting it to work.  From my POV
as a programmer, "learning the field" consists of identifying the
available building blocks (hash, symmetric, asymmetric), standards
(openpgp, x509, ssl, ssh, ipsec) and prior implimentations (paying
particular attention to what had to be patched due to discovered
vunerablities, so as to avoid the same errors in my own code)
It also seems the crypto community is very open to questions, very hostile
to statements - so often knowing how to phrase something to them is as
important as the content of the question. Stating "I am doing $FOO" will
not be as productive as "If I were to do $FOO what vunerabilities would
that introduce?" - remembering that any good advice you get back for free
would have probably cost you weeks of study or possibly thousands of
dollars trying to obtain a security certification for your solution later
Just ignore any posts of "because it isn't done that way" unless they give
a good reason why your way isn't better (note "as good" isn't good
enough - you always need a good reason to stray from a tested and known
path, and it is often worth putting up with a few minor inconveniences to
stay on it)
Oh - and make sure you can recognise a good reason when you see it ::)
I would certainly expect a house builder to know how to lay bricks - but
if he insisted on designing the house too, I would expect him to know how
to do that (and not just start putting up walls and hoping it will all
work out later.
Design requires a fair understanding of what you are designing and what
the capabilities and limitations of the "materials" are - this is why SAs
get paid more than their programming teams (not that I like that given I
am a programmer not a SA).  If you aren't willing to learn how to do that,
you can still follow someone else's design - or take a modular approach
and just drop pre-built units (normally libraries) into those parts of the
code that need them. Libraries can be surprisingly good - if the designer
put in enough effort, they can have sufficient inline M/C for the
timing-critical parts that they are noticably more efficient than
implimenting your own code in a medium or high level language.
That does tend to happen - in any community, you get those who get used to
being authorities, and react badly to being challenged. At least in this
community most of them have the sense to back down when proved wrong :)
Indeed so - that is why using a prebuilt standard (or better yet, a
library) as your base is such a good idea. However, a lot of programmers
don't like doing that because
they feel it is either "cheating" or means all their hard work is going to
be dismissed as "just an implimentation of someone else's idea" rather
than something original and novel.  However, the odds of someone "rolling
their own" protocol getting something more efficient or effective as work
that has already been done are low - and if the package you put together
is sufficently good, no users will care it uses SSH (protocol) for comms
or someone else's AES library for the symmetric component - but network
admins will feel comfortable with a known standard protocol and whoever
maintains your package (normally you) will usually sleep better at night
knowing that people are stress-testing those essential components, and if
any faults are found, you just have to download the fix and recompile
rather than find and fix the problem yourself (particularly as a break in
a popular library will make it to bugtraq while your program may *never*
make it above the horizon for serious security investigators - while
hackers may well target it if it is in use at a specific site they have an
interest in)
And they will turn up on bugtraq or in the cryptogram doghouse - not that
that will matter to them, given they are probably making lots of money and
if they have any sense, all the rights will be held by a limited company
(so when the lawsuits start rolling in, they can dump the shell and start
over with more insecure crap someplace else)
they could always start issuing security packs as "upgrades" of course.
another useful revenue stream :)
Indeed so. however, if a programmer isn't willing to put the effort into
writing *secure* code, how can be be willing to put the effort into
writing his own comms/crypto code (instead of just dropping in a library
and forgetting it?)
Or use decent crypto up front from a library, and if the software takes
off, look at optimizing the code for a later release.
its an evolutionary thing. ten years ago, you could get away with dumping
an insecure product onto the marketplace - few users would be on the
internet, and even those who were would find few people on there to worry
them.  You just can't get away with that today - the second a new product
is released, a thousand bored teenage hackers will have a warez copy of it
wondering how to earn kudos or steal money by abusing it.
Most ecosystems see the same thing - to start with, predators are poor
hunters, but prey are easy targets. As prey gets better at avoiding
capture, so predators get better at trapping them; all remain in balance,
with each improvement in defense matched by an improvement in attack by
the hunters, and vice versa.  But drop one of the early prey into the same
area, ten generations later, and they wouldn't manage to take more than a
few steps before they died - conversely, drop an outdated hunter into the
area and it would starve or become a scavenger on other people's kills
(that is not a bad analogy for a Skript Kiddie btw :)
The question is - in the current much, much more hostile environment of
the internet, how good is "good enough"?
look upon it as the burglar alarm principle - most home security isn't
really that good, but is "good enough". If you have lights on, a visible
burglar alarm and security lights, and the house three doors down has
lights out, no visible alarm and a window ajar - it doesn't matter that
your house is far from impregnable - that you have unshuttered glass
windows, possibly even older less secure window catches without locks -
just that it is a hardened target compared to the other choices an
attacker has.  Even if your solution isn't fort knox, it can still be
"good enough" relative to the value of your traffic and the likely
attackers.  Ok, it costs little extra for "good enough" to be upgraded to
very good indeed, but as long as it is good enough you can manage to make
your way along for a while and enter the arms race just like the rest of
us :)
How about "how much improvement did you get over SSL from your
implementation, and what security risks did it introduce?"
CIPE is a good example of such a tradeoff - they don't have any protection
from UDP replay attacks - provided you can identify which packets are UDP
of interest to you and resend them. Their CRC is also fairly weak, (but is
inside the crypto envelope) and there are other tradeoffs, all listed in
the documentation.  As a replacement for IPSEC it is a no-hoper - and that
is fine, as they don't *want* to be a replacement for IPSec - they are a
lighter, more convenient tunnelling protocol, more bandwidth efficient and
noticably easier to set up. If you are using UDP for something
security-critical, you want to take a good look at *why* rather than
blaming a non-udp-safe tunnel (provided you *know* the tunnel is not
UDP-safe in advance)
One I have seen a lot is reference to a telephone conversation with the
authors, where they admitted they didn't know about Microsoft's Automated
patch download system.
all that springs to mind is a query as to how many people actually *use*
that - I know I don't trust it as far as I can throw it. Microsoft's
patches have a nasty habit of:
1) requiring the original CD to be inserted
2) overwriting security patches already applied with older, insecure
versions (there were a couple of "two of three" situations between service
packs on NT where you could install any two of three patches - each backed
out one of the others, and there was *no* correct order that would give
you all patches applied; you were required to copy the effected dlls from
the first patch away safe, copy them back after the last patch, then
regsvr32 the things into compliance. luckily, the next service pack
overwrote all three patches with a common update)
3) actually breaking existing functionality (for a competitors' package of
course) by patching something apparently unrelated (I am sure there will
be a few shudders at the mention of NT4 SP6 pre-6a)
I don't let any patches *near* a production server until they test out
lean in a test environment - preferably from a static CD copy so I can be
sure I get the same version on the production server as the test.
As an analogy "ok we built this car with no brakes; so far we are doing
fine just switching off the engine and coasting to a stop, and if the
market tells us brakes are important we will add them"
It is surely better to be warned about the lack of brakes by an interested
observer (no matter how condescending it sounds) than to wait for the
fatalities and *then* think about adding them?
Indeed. really, crypto needs to be more accessable - there is a *lot* of
cross-referenced information out there, mostly in forms where you
gradually glean a snippet of knowledge (shared between those posting these
pages) here and there until you have enough base knowledge to understand
what the web of interconnected and often back-patting pages actually mean.
Perhaps a "basic crypto for programmers - how to use crypto and how to
decide when crypto is needful" book or website is a good idea. I am
probably not up to writing one though, or I would :)
SSL is a nice catchall wrapper - ok, its overkill in most cases, but that
is the price for flexability. I am not so happy it is biassed towards
X509, as that is very much linked to the business models of CAs and
standards organisations...

@_date: 2003-10-02 14:19:52
@_author: Dave Howe 
@_subject: Monoculture 
And RMS didn't want to write a grep tool/compiler/editor/whatever - he
wanted to write hurd. however, he recognised that hurd needed to be *built
on* a solid foundation of tools and resources; most people have never
heard of hurd, but use directly or indirectly something in the gnu toolbox
every day (mostly without knowing it)
if you build a decent TLS library, then build a VPN daemon to use that
library, you have contributed both a daemon and a TLS library, and
thousands of people may well use the TLS library without needing or
wanting a VPN daemon (given a TLS library is of much more general use than
a vpn daemon)

@_date: 2003-10-02 16:58:27
@_author: Dave Howe 
@_subject: Monoculture 
Alice can be her own CA if she wishes to - all you need is a copy of
Openssl or, if you like having gui interfaces, XCA
( both of which are free.
she can so inform MSIE - marking the key as trusted the first time she
"sees" it in IE, or importing the CA key from openssl/xca
she creates her own ssl server key, then either manually imports it into
IE (simply a case of double-clicking it!) or marks it as trusted the first
time she connects to her ssl server.

@_date: 2003-10-07 18:49:36
@_author: Dave Howe 
@_subject: NCipher Takes Hardware Security To Network Level 
Indeed so.
"What do you do to prevent ordinary users from abusing access to the
"we don't allow them on - only admins can use this machine"
"but ordinary users will *have* to use this machine"
"yes, but they will be admins while they do it"
"oh, ok then"

@_date: 2003-10-10 09:51:37
@_author: Dave Howe 
@_subject: Easy VPNs? 
spot on.
also correct
what you are missing is joining the dots. the VPN part requires that a
server process be running that "intercepts" packets destined for the
remote end of the VPN (usually a virtual network card or ip stack shim).
That says nothing about how the data gets from *that* intercept server to
the matching server at the receiving end - the transport method.
IPSec uses an assortment of custom ip types and standard tcp/udp
connections. "ssl" vpn uses an ssl encrypted tcp/ip connection, but there
is no reason why the two intercept servers couldn't talk to each other
over (for example) a ssh tunnel, zebedee, or whatever else takes its
author's fancy.
In practice, you want the tunnel to have low overhead, so udp is often
used; tcp however traverses nat and pat servers much more easily and the
additional convenience of ssh transport (being an existing, established
standard that uses only a single port and that firewalls - and their
admins - are already familiar with) may be of more value than the more
complex and less well understood (and damned hard to get though anything,
including firewalls) IPSec.
so as I say - think of vpn as two components - intercept (the virtual
network functionality) and transport (a secure, authenticated,
encapsulated communications standard) and how vpn over *anything* becomes
more clear.

@_date: 2003-10-12 01:28:10
@_author: Dave Howe 
@_subject: Easy VPNs? 
Exactly so, yes - however, the mechanics of doing so (and the protocols
used) *are* the vpn scheme - it would be possible to imagine a generic
routing shim which could be told "for network xx.xx.xx.xx use external
daemon yyyy" where yyyy could be ipsec, ssl or ssh tunnels - and the actual
routing shim could be very small indeed - as most of the hard work would be
taken care of by the external daemon. however, each vpn standard would have
to have its own daemon - and interoperate with other implimentations of that
type of vpn
its a bit like arguing which type of car is "best" - none is, they all have
their good and bad features, and you should choose the one best suited for
the tasks you are going to use it for.

@_date: 2003-10-13 09:58:04
@_author: Dave Howe 
@_subject: Open Source (was Simple SSL/TLS - Some Questions) 
There seems to be a fair amount of confusion over what a "SSL VPN" really
is - there are several examples of such that are true VPN clients - but
the big commercial push seems to be the ASP model - converting
*everything* to be web-delivered, and calling the resulting HTTPS site
"Thin Client SSL VPN" but in fact they mean "Web browser accessable
website with some normally non-web apps on it"

@_date: 2003-10-13 09:59:39
@_author: Dave Howe 
@_subject: new list to discuss VPN 
anything wrong with using the existing list at VPN at lists.shmoo.com ?

@_date: 2003-10-15 10:46:23
@_author: Dave Howe 
@_subject: Test of BIOS Spyware 
They won't even try - I am under the impression this is for use as a
"black bag" job, possibly even remotely; they can target the machine with
a specific update for the currently running OS.

@_date: 2003-09-19 10:17:37
@_author: Dave Howe 
@_subject: Simple inner transposition steganography 
Oh, I wouldn't be too sure about that.
as the order of the letters can be itself a binary channel, you could
probably obtain 3-4 bits of channel space per word for an *additional*
message that can be decoded by comparing the correct letter order to the
"encoded" letter order. obviously , this means going though the entire
letter as a machine-assisted "spellcheck" as the odds of getting an
accurate machine decode are low (the spellchecker is going to miss most of
the contextual cues humans would use to decode the text)
it has two functions.
it makes mechanical recognition of the content much, much more difficult
it provides a covert channel for the real message.

@_date: 2003-09-19 13:16:48
@_author: Dave Howe 
@_subject: quantum hype 
As I understand it, there are four possible "rotations" for the photon
( call them '\' '|' '/' and '-' ) so two choices for a filter (straight or
slant). a straight filter can reliably tell '|' and '-' apart, but '\' and
'/' are going to be unreliable; a slant filter can read '\' or '/' but not
'|' or '-'
if Mallory can guess the correct filter to use, he can reproduce the bit
to bob; if he guesses wrongly, he can still send a random bit to bob, who
will (if he uses the right filter) further randomly interpret that and
either get the right or wrong answer (50/50 chance)
of course if Mallory *is* Mallory, and not Eve, he is mounting a
Man-in-the-middle attack, so can conveniently negotiate key a with alice,
key b with bob, and do the usual :) quantum channels are just as sensitive
to Mitm as any other; without a non-interruptable (if insecure) channel no
key negotiation protocol is ever going to work.
  QC allows you to negotiate a one-time-pad between two nodes joined by an
unbroken optical link
it says nothing about the identity of the two nodes, and relies on the
optical link being unbroken (a mitm breaks the link, turning it into two
independent QC channels that happen to be both to Mallory)
  QC really needs an insecure but unbroken link. if that is achievable,
then the crypto is OTP and unbreakable (much better than DH). if it is not
achievable (and I would doubt that it is) then the key negotiation is
broken and the crypto worthless.
  The incidence should be low - in fact, there are no good reasons to use
the QC channel for actual data exchange at all - use normal insecure
channels for actual data transfer, protected by the negotiated OTP key. We
then have to correct for wrongly read bits from the QC channel, and there
you will have difficulty adding EC codes (given any individual bit may be
in error) and transmitting hashes of (or worse yet, EC for) the
known-received bits insecurely would compromise the OTP key at least a
I must admit my signal-processing knowledge is weak - maybe another
regular could propose a scheme that would work. to define the problem:
GIVEN a transmission line with approximately 50% bit loss, but for which
you know which bits were received, and a less than 10% error rate (say) in
the received bits, how do you detect and discard/correct the bad bits? I
assume there is something in FEC for very unreliable lines like this....
QC is a hype-only technology - it relies on a unbroken line impervious to
MitM, and there ain't no such beast.
.> Tell me if I got anything wrong.
without Mitm, it is impossible to evesdrop the photons used for key
even assuming you can detect a photon without distorting it in any way
(rotation or attenuation) then the *only* known way to detect the
polarization of a photon is to push it though a filter and see if it comes
out the other side. this is the "strong problem" on which QC relies; if
that fell, then QC would be worthless.
also sprach David Wagner I can't think of a single instance of one suitable to QC.
the usual definition is a broadcast channel - send once read many - where
anyone can read it, but the original sender can discover *fast* any
changes as the sender is also a receiver and can verify the sent data from
several places. QC relies on only a single quanta of energy being sent, so
obviously two people can't receive the same copy (and therefore the sender
can't verify his own transmission)
almost none. while OTP has no even theoretical attacks, QC is not otp (
you are negotiating a key, and are therefore transmitting a key protected
by a "hard problem" - admittedly one in physics rather than maths, but the
drawbacks seem to outweigh the advantages.
also sprach Arnold G. Reinhold  [2003.09.14.0536
not a problem - 160 gb hard drives are inexpensive, you don't send one,
you send four; if one fails, you transparently switch to the next
Indeed. OTP *always* breaks down to the key distribution problem - you
have to get your key from point a to point b before point b can talk to
point a
one guy with a briefcase containing four hotswap drives is a lot easier to
secure than a 200 mile fiberoptic though.
nothing stopping you using symmetric crypto to protect the keydisk if you
want to.
no. its the "underlieing hard problem" for QC. If there is a solution to
any of the Hard Problems, nobody knows about them.
cryptography is 90% paranoia - you *have* enemies, and don't know about
them. if you had none at all, you wouldn't bother with crypto (as nobody
would ever look at your data even accidentally). It doesn't matter if your
enemy is a random ISP tech who likes browsing email spools, or a spook
curious as to why you spend so much time sending encyrpted messages....
that is a FEC problem.
as I understand it, a QC key negotiation goes as follows:
host a generates 2 x 'n' random bits
host a encodes its 'n' dibits with one bit determining 90% of rotation and
the other 45% as polarizations of single photons and transmits them to
host b
host b generates 'n' random bits
host b encodes its 'n' bits as filters (either 0 or 45% rotation) for the
'n' received photons
host b transmits its 'n' bits plaintext to host a
host a xors the 45% rotation bits it used with the rotation bits from host
b to give it a "bad bit list"
host a removes bits from the 90% rotation bitset if they are set in the
"bad bit list"
host a transmits plaintext to host b the "bad bit list"
host b also removes the bad bits
approximately half the bits in the "bad bit list" would be set, leaving
approximately 'n'/2 bits for otp key material. (EC is a further problem I
have not seen addressed)
as you can see, evesdropping the individual photons is a hard problem, and
evesdropping the rotation list from host b and the bad bit list from host
a is worthless without the photons (and the rotation list is transmitted
*only* after the photons have already been processed by host b)
evesdropping *destroys* the data by removing 50% of the photons almost at
random. that is the quantum bit of the process - only a single photon is
sent, so it can only be processed (read) by one host; reading the photon
destroys its value, and the random element ensures it is incorrectly read
50% of the time.
DoS is breaking the transmission link - and a physical attack on the media
(or the equipment at either end) would be required
I admit to not entirely following the logic behind Quantum Cryptography
but if I am understanding the popularization version - it is using quantum
entanglement to run a atomic-level process simultaniously on a large
number of random cases (alternate dimensions?) and identify just the
case(s) that actually get the "right answer" by forcing the virtual
reactions to "interfere" with the reaction in this reality so that it
becomes the answer that works (a bit like how a single photon, fired at a
dual slit card in front of a screen, will land in accordance with the
interference pattern you would get from photons travelling *both* possible
paths though the slit card).
Compare with molecular computing, where you run the math as a chemical
reaction on a huge number of different molecules (one per possible answer)
, with the reaction that works altering the molecule representing the
answer so that it can be isolated and identified.

@_date: 2003-09-19 17:58:05
@_author: Dave Howe 
@_subject: quantum hype 
I think it is more a question of style - a classic "passive" Eve can't
exist in terms of QC key exchange, as eve/mallory *must* read the photons
or no interception at all can take place - therefore, even eve must
generate a new photon to send to bob.
If the intercept agent is Eve, she will attempt to reproduce as nearly as
possible the original photon to send to bob. she will get this wrong 25%
of the time.
if the intercept agent is Mallory, he will generate his own, known good
photons to send to bob, unrelated to what he has detected.
If Eve can intercept also the filter list from bob to april, she is now in
a fix - she now knows which ones she got different to bob, but doesn't
know how many bob got wrong. however, being eve she passes this on to
april, and correctly relays the "bad bit" message back to bob. bob now has
an approximately 25% error block which is detectable. Nothing changes if
the two lists are out-of-band and therefore untouchable.
If Mallory *can't* intercept the filter and bad bit lists he is in much
more trouble - his photon list to bob bore no relation to alice's, so
purely in terms of random chance he will have a 50% error block
If Mallory *can* intercept the fillter and bad bit lists he is in an
better situation - he can send his own filter list to alice, and negotiate
a set of bits with her; by selectively causing "bad luck" for bob, he can
tune the bad bit list(based on bob's filter list) to give an identical set
of bits. As the mallory-bob filter match is approximately 50%, and bob
will have to additionally "kill" a further 50% of the "correct" answers in
order to make the two bitsets match, bob will have a filter match rate of
about 25% which is again statistically significant
If Mallory *can* intercept the filter/bad block conversation and *further*
is sure he can intercept the message traffic too, he can simply negotiate
a separate bit list with bob; statistically, the key exchange will look
fine, but of course Mallory will also have to decode and re-encode the
traffic between alice and bob, or it will all go horribly wrong.

@_date: 2003-09-21 17:04:20
@_author: Dave Howe 
@_subject: quantum hype 
Peter Fairbrother may well be in possession of a break for the QC hard
problem - his last post stated there was a way to "clone" photons with
high accuracy in retention of their polarization (at the cost of a
irrelevent increase in wavelength) so that Mallory could test photons with
BOTH filters, determining the value of the bit (from the correct filter
which would show a strong bias to the correct bit value) and the
orientation (given the incorrect filter would be roughly 50/50)
Hmm. normally, the agent attempting to intercept your traffic is termed
the attacker; I don't know many attackers that aren't enemies :)
 mails i send to this other chick (i have no
I suspect my wife might not like it if I had one :)
but not against you accidentally leaving the plaintext window open, or
your system having stored a draft of the plaintext someplace.
endpoint security is typically much, much harder than transmission
security (despite key exchange not being an issue) simply because so many
standard machines and software is orientated towards data loss prevention,
not security.
indeed. perhaps "interceptor" rather than enemy would be closer?
I am (as usual) standing on the shoulders of giants; I am simply repeating
my understanding of what they said trying to dumb it down to my miserable
level :)
correct - it is a key negotiation method, not an actual transmission
no, the provable security of OTP is a given. the security of QC comes from
not being able to determine the polarization of a photon without pushing
it though a filter and seeing if it fits :)
destroying photons would mean breaking (diverting the flow of photons
down) the channel, so there is no real distinction.
indeed. not only akin, but actually a case of :)
in fact, you would be better served using another channel (or channels)
for actual data, and keeping the optical channel for key negotiation only.
a successful MiTM attack relies on controlling *all* the communications
between alice and bob. if there are multiple channels, and even one is
missed, alice and bob can determine there was a middleman involved and the
attack breaks down. Ideal for transmitting the actual data would be (say)
a broadcast medium; alice can check her own trasmissions, and bob can read
and in general terms, always assume mailing lists are not only archived,
but read avidly by the enemies I have and you haven't got ;)

@_date: 2003-09-28 17:41:33
@_author: Dave Howe 
@_subject: quantum hype 
has anyone with better number theory / probability skills than me taken a
stab at exactly *how* accurate cloning would have to be (and how many
clones you would need) to determine accurately both the bit and filter
values for a quantum key exchange photon? for a single pass (5/6 photons
output) it feels like the odds are stacked against getting a clean
reading; for two passes (25/36) it feels even worse.
how accurate would cloning need to be to get a better than 1/3 failure

@_date: 2004-04-03 23:49:15
@_author: Dave Howe 
@_subject: Do Cryptographers burn? 
Sometimes they blush hard enough to ignite, if that helps :)
  This is universally true though - nobody can live long enough to work
though the theory and practical of almost anything - consider for example a
classic (no computer engine or breaking control) automobile. You would need
to understand every part of chemical theory that relates to petroleum
fractions and additives commonly found in car fuel; thermodynamic, materials
and physical theory and engineering design that relates to the functions of
the engine and its mechanical coupling to the drive wheels; the
differential, the gearing, the steering, the breaking, the materials that
form the tyres, the ergonomic design of the seating area, vision angles
though the windshield, glass (materials) theory for the material that forms
the windshield (toughness, resistance to random impacts, refraction though
the medium), the materials of the road surface and how they behave under
different conditions of wet, dry, temperature... and that is just the
generic stuff. once you get down to a specific instance, you have to decide
if your instance of car meets the theoretical data you learnt on a abstract
car, and if the instance of road you are driving on meets similar data you
have on abstract driving surfaces.
  Even those who work in that field can take decades to reach the point they
could design one component of a modern automobile - the engine, the gearbox,
the chassis and so on. It would be insane to learn all that if you just
wanted to drive to work in the mornings....
  At a basic level, you have to define basic functions in terms that an
expert can verify and say "yes, that is a truism" - then you can drop them
into more complex systems in different patterns, not knowing if the system
will work but able to rely on the components to perform within their design
parameters. the same is true of cryptography; an accepted algo will have
been hammered on and peer reviewed by dozens of people - and as even a minor
predictability under extreme conditions using a simplified form of an algo
is worth writing up a paper on, there is a world of pre-established work to
review and verify for even the most ambitious would-be-cryptoanalyst to cut
his teeth on (and use as training examples to apply similar techniques to
algos that have not yet had that attack publically attempted on them)
  So,if the basic level for a mathematician is the maths within the
algorithm; the basic level for a programmer is the algorithm itself, as a
process to produce cryptotext from plain, or plaintext from crypto.
Normally, a programmer won't worry about verifying the algo - he will accept
that as part of the design he is to impliment, and if he has a choice of
several suitable algos, will simply impliment them all as alternative
  Programmers love to re-use code though - it saves a *lot* of work, and as
you become familiar with and improve the code you can feed back changes to
earlier software, improving its efficiency "for free". Of course for this to
work well, the code must be independent of the body of the software, have
clearly defined interfaces (so that you can't mess up an earlier
implimentation when improving a later one, by forgetting a "side effect" you
earlier relied on but don't need any more) and indeed act as a basic
component itself - forming a subprogram that you hand data to and receive
data back from as a "black box" operation. Another strength of doing your
crypto as such a "library" of pre-written code is that you can test and
"prove" it independently of your main program - you can hand your crypto
library to your peers for their review, you can encourage its use (thus
ensuring good crypto in a wide range of software, improving compatability,
and not incidentally improving your peer reputation :) and generally
maintain your library as a product in its own right.
  At the end of the chain is a programmer who doesn't want to know about how
the algo works, would rather not have to know the details of how to make it
work, but likes the idea of being able to write something like
use MyFirstCryptoLibrary;
ask user for message store in [messagedata]
ask user for key store in [key]
DoCrypto(chosenalgo,[key],[messagedata]) store in [encrypted message]
ask user for destination store in [EmailToName]
SendEmailTo([EmailToName],[encrypted message])
and have it work..... and indeed, until the average programmer *can* use a
library that easily to include decent crypto in his product, the majority of
the products out there will be either not supporting crypto at all, or doing
it badly.
I can claim to have read about a hundred. That is not enough to even get on
this mailing list if I had to do it by reputation - but I am not a
mathematician any more than I need to be to be a programmer, and I am not a
programmer these days any more than I need to be to administer my servers.
Yes, I can. I tried it and it is bloody hard :)
I know what you mean though, and if you were the leading expert in number
theory *and* had read and understood every paper ever published, you still
wouldn't know - because someone in the NSA, or russia, or some chinese
school where they don't know what a computer is, could have had an inspired
moment and found an easy solution everyone else has missed. All you can say
is "all the current experts say they don't know any way to do this that is
easy, so it is probably hard"
yes. but it requires at least some of them to be trustworthy - certainly not
all. There would have to be a universal worldwide conspiracy to conceal the
breakthough if it were at all obvious from the "state of the art" - so while
a fundimental breakthough in one restricted investigation might happen only
once in a century, so could be concealed, it would only take that once to
happen to someone who would rather publish than make it a military secret
for it to be common knowledge.
Parallel discoveries do happen, and fairly often; even something as complex
as the FFT was only re-discovered (when it was originally found, there was
no electronics industry to impliment it, so it was just a mathematical curio
and forgotten)
If you mean he gave a false assurance of the security of a product for a
friend - why would he do that? I can't think of any of my friends who would
want me to tell them sofware was secure if it wasn't.
I suppose that depends on his integrity and how much his reputation and
skill would be worth to his employers if it became known that he gave false
assurances - and it would only be a matter of time before some other
cryptoanalyst found the fault he found and ignored.

@_date: 2004-04-04 23:43:29
@_author: Dave Howe 
@_subject: Do Cryptographers burn? 
certainly possible - if he didn't know (or deliberately ignored) that it had
been written in 1988 :)
How much of it is *still* new or at least hard to find in the literature?
how much of it would be known *today* out of hand by someone who was
familiar with the state of the art?  If the university had instructed him to
take a look at your work in that context, he may well not have found
anything new or novel in there - because your work had since been
duplicated, and after 16  years I would expect it to have been duplicated
several times.  If he had been instructed to find pre-1987 published work
that duplicated yours, that would be different - but I would assume the
university neglected that direction while instructing him.
We have the same problem with expert witnesses in court here in the uk -
after a while, prosecutors learn which experts can be relied on to give the
answer they want rather than admit it is a matter of opinion and either case
could be correct - such experts get a lot more work from the prosecution for
their "unbiassed" opinions than those which gave an "unbiassed" opinion the
prosecution didn't like (it isn't unknown for the prosecution to approach
three or four experts and take the most favourable return to court)
no, it isn't.
it is about someone deliberately choosing to concentrate on the worst
aspects of a 16 year old dissertation (almost certainly, that it is 16 years
out of date) and ignoring the context. I am sure if I paid 100 experts to
evaluate *anything* I could find at least one I liked the resulting report
I am not too surprised either - for the reasons I have detailed above. I
know it is hard to have fought this way though the legal system to find the
university has tried to throw money at the problem to make it go away - but
it happens, and I can only assume you will eventually prove it in court.
what you have here is a legal problem with some individuals, that their
employer has chosen to back against a student, and in doing so bent any or
all rules it could to win. This says little about the individual who wrote
the new examination and more about your opponents in the university's legal
team.  BTW is there any way you can find out how many "experts" were asked
to evaluate your work before they found one whose answer they liked?

@_date: 2004-08-11 11:56:44
@_author: Dave Howe 
@_subject: How a Digital Signature Works 
And which will guarantee to... erm... *try* not to sell the same certificate to someone else, or to at least notice if they do (provided it has a famous name on it like "microsoft" of course)
and what is "new" about MS's signed executable support? its been around long enough...

@_date: 2004-07-03 19:22:56
@_author: Dave Howe 
@_subject: Question on the state of the security industry (second half not 
Well if nothing else, it is impossible for my bank to send me anything I would believe via email now....
To take this even slightly more on-topic - does anyone here have a bank capable of authenticating themselves to you when they ring you?
I have had four phone calls from my bank this year, all of which start out by asking me to identify myself to them. When I point out that they must know who I am - as they just phoned me - and that I have no way of knowing who they are, they are completely lost (probably takes them away from the little paper script pinned to their desk)

@_date: 2004-07-05 02:48:02
@_author: Dave Howe 
@_subject: Use cash machines as little as possible 
That's odd - given a deliberate policy of encouraging Cash Machine use over the last few years, as Cash Machine costs+fraud still come to less than the running costs of sufficient local branches to allow you to obtain *Your* money back from them when needed....

@_date: 2004-06-01 18:29:20
@_author: Dave Howe 
@_subject: Yahoo releases internet standard draft for using DNS as public 
No - it means you might want to consider a system that guarantees end-to-end encryption - not just "first link, then maybe if it feels like it"
That doesn't mean TLS is worthless - on the contrary, it adds an additional layer of both user authentication and session encryption that are both beneficial - but that *relying* on it to protect your messages is overoptimistic at best, dangerous at worst.
In limited circumstances it could well be enough - say, if your mailserver *is* yours, and hands off directly to the recipient's mail server which you know is accessed by either ssl-secured pop3, https, or some other secure access method (or unencrypted, but via a local lan link of course) - but for the majority of users this isn't going to be possible; more and more ISPs frown on even their business customers using direct outbound SMTP, and few sites are willing or able to accept mail using the alternate port for TLS.
You should do it - but you shouldn't expect it to do any good; in the long term, pushing for TLS support from your ISP, giving them grief (within limits of course) to ensure opportunistic TLS outbound, and so forth, will increase the security of the system as a whole. but at the moment reliance is a step too far.
Many ISPs accept TLS inbound, but don't specify it outbound. there is no value to them in doing so - its transparent to the user either way, adds additional load to the local server, and the occasions they get asked about it are so rare they can safely ignore it.
Certainly possible - but of course that implies using SSL during the collection too.....
Indeed so, yes. however, as I say - just because it is a step forward towards a completely end-to-end secure link, it is worth doing - even a little extra security for free is worth having - but if it is important enough to *need* encryption, it is important enough to ensure end-to-end encryption is used.
I must admit to being impressed by how functional EnigMime for thunderbird is in this regard - I can specify per-destination-user that encryption will aways be used, and its type - and have it "just work"

@_date: 2004-06-01 21:31:05
@_author: Dave Howe 
@_subject: Yahoo releases internet standard draft for using DNS as public 
No, there are plenty that you can rely on to protect your message while still in transit.
If you can ensure that the only possible points of vulnerability are at the two endpoints, then you and your correspondent take control of your security - it won't be perfect, as you point out - but you won't be reliant on the goodwill and efforts of some third party whose most economic option is to accidentally or deliberately neglect TLS between your local smart host and your correspondent's email spooler, or indeed, to supply minimal security to the email spools at smarthost or destination.
Secure systems exist - but are rarely worth the effort involved.
Many PDAs can handle PGP or S/Mime traffic these days - certainly, you could offload your message (already encrypted) to flash media, insert into sending host, receive (from email spool) at the destination and transfer to flash media, then insert into decoding PDA.  To compromise either PDA would require access - so if you keep it about your person (and within sight when you bathe), you should be safe against anything but a midnight intrusion with sleeping gas....
But regardless - the level of defence required is proportional to the likely threat.  It is entirely possible that it would be worthwhile for some hacker to compromise a router between your ISP's mail server and your correspondent's spool, or that spool itself. It is less likely that it would be worth someone's while to break into your home with exquisite timing and tracelessly alter software on your trusted airgapped machine while you shower (and if that *is* your threat model, I envy the income you must get to justify being in such a position or bow to the value of your information to some repressive regime)
Indeed so.
Again, true. I suspect we differ in what we consider an acceptable risk - I don't consider any setup where the security of the channel is against the best interests of the people controlling that channel acceptable - especially where I have no way to discover if that channel was compromised.
I have what I hope is an acceptably secure system at home - and I also hope my correspondents do likewise. If our messages are compromised (not that they contain anything worth stealing) then it is my fault or theirs - not an admin at the isp, or some minimum-wage employee on a helpdesk bribed to let someone take a peak at my mailspool. This extra security comes free, gratis, not a penny does it cost - beyond the effort of learning how to use it - and while I was used to hotkeying my way into the current window, my recent switch to Enigmail means I don't even have to do that. Why would I settle for less?
And indeed I had a conversation with someone who was interested in a "secure" mailing list only a few days ago. I suggested he not bother and   just set up a HTTPS website with any one of a dozen BBoard systems and local certificate support - because that was free and all the complexity (and most of the vulnerabilites) are at the server side - while setting up a secure email burster would be almost impossible and would rely on not only training the end users, but ensuring they have the right software installed.

@_date: 2004-05-17 17:37:08
@_author: Dave Howe 
@_subject: Vulnerability in the WinZip implimentation of AES? 
Abstract: WinZip is a popular compression utility for Microsoft Windows
computers, the latest version of which is advertised as having
"easy-to-use AES encryption to protect your sensitive data." We exhibit
several attacks against WinZip's new encryption method, dubbed "AE-2" or
"Advanced Encryption, version two." We then discuss secure alternatives.
Since at a high level the underlying WinZip encryption method appears
secure (the core is exactly Encrypt-then-Authenticate using AES-CTR and
HMAC-SHA1), and since one of our attacks was made possible because of the
way that WinZip Computing, Inc.~decided to fix a different security
problem with its previous encryption method AE-1, our attacks further
underscore the subtlety of designing cryptographically secure software.

@_date: 2004-05-31 19:56:26
@_author: Dave Howe 
@_subject: Yahoo releases internet standard draft for using DNS as public 
I wouldn't say PGP/MIME (as opposed to pgp inline) was a widely enough used standard to be considered one of two options - pgp (both methods) certainly, but not pgp/mime exclusively.

@_date: 2004-05-31 20:04:46
@_author: Dave Howe 
@_subject: Yahoo releases internet standard draft for using DNS as public 
TLS for SMTP is a nice, efficient way to encrypt the channel. However, it offers little or no assurance that your mail will *stay* encrypted all the way to the recipients.
Most of us (including me most of the time) are in the position of using their ISPs or Employer's smarthost to relay email to its final destination; in fact, most employers (and many ISPs) actually enforce this, redirecting or blocking port 25 traffic.
If my employer or isp accept TLS traffic from me, but then turn around and send that completely unprotected to my final recipient, I have no way of preventing or even knowing that.
Sendmail's documentation certainly used to warn this was the case - probably still does :)
Agreed.  In cases of spoofing, there could of course be an issue - but lets be honest here; when was the last time a mailing list regular *anywhere* lost reputation because someone posted spam or trollishness to the list in their name?
I am not saying that doesn't happen - but it is rare, and usually the real poster points out the difference in header data that would indicate that email came from a source other than him.

@_date: 2004-05-31 20:17:59
@_author: Dave Howe 
@_subject: A National ID 
Just watch how the british do it - then don't do it that way.
I am still trying to figure out how over a decade of terrorist bombings in mainland UK didn't justify introducing a national ID card - but the americans wanting biometric passports for visitors does.

@_date: 2004-05-31 20:20:59
@_author: Dave Howe 
@_subject: Software Helps Rights Groups Protect Sensitive Information 
I might be missing something here but - exactly how does a system insecure enough that interested governments can crack it help protect people who are releasing information concealed by those governments?

@_date: 2004-10-05 17:32:07
@_author: Dave Howe 
@_subject: IBM's original S-Boxes for DES? 
More accurately, they didn't protect against linear cryptanalysis - there is no way to know if they knew about it and either didn't want to make changes to protect against that (they weakened the key, so may have wished to keep *some* attacks viable against it to weaken it still further), had to choose (against *either* differential or linear, as they didn't know how to protect against both) or simply the people doing the eval on DES didn't know, as it was rated above their clearance level.
   We only have a single event to go from (that DES was indeed protected against one not the other) so can't really judge motivation or knowledge.

@_date: 2004-10-06 17:04:49
@_author: Dave Howe 
@_subject: Quantum cryptography gets "practical" 
Nope, finally strugged to the end to find a section pointing out that it does *not* prevent mitm attacks.
Anyone seen a paper on a scheme that does?

@_date: 2004-09-20 22:22:15
@_author: Dave Howe 
@_subject: They Said It Couldn't Be Done 
I must admit I am surprised a new law is needed.
Under the Help America Vote Act 2002 electronic voting machines appear to have the following audit requirement:
    TITLE III--UNIFORM AND NONDISCRIMINATORY ELECTION TECHNOLOGY AND
                       ADMINISTRATION REQUIREMENTS
                        Subtitle A--Requirements
SEC. 301. <> VOTING SYSTEMS STANDARDS.
    (a) Requirements.--Each voting system used in an election for
Federal office shall meet the following requirements:
            (2) Audit capacity.--
                    (A) In general.--The voting system shall produce a
                record with an audit capacity for such system.
                    (B) Manual audit capacity.--
                          (i) The voting system shall produce a
                      permanent paper record with a manual audit
                      capacity for such system.
                          (ii) The voting system shall provide the voter
                      with an opportunity to change the ballot or
                      correct any error before the permanent paper
                      record is produced.
                          (iii) The paper record produced under
                      subparagraph (A) shall be available as an official
                      record for any recount conducted with respect to
                      any election in which the system is used.
(taken from  )
So unless there is a amendment to that law (that I am obviously unaware of) it isn't up to individual States to add this as an additional requirement - its already required. perhaps someone could enlighten me?

@_date: 2005-04-02 17:14:18
@_author: Dave Howe 
@_subject: aid worker stego 
Depends on what you want to avoid.
Best solution for software is dual-use - 7-zip for file encryption, standard s/mime capable email software (such as thunderbird or even outlook express) for pki. However, encrypted emails are *always* going to stick out like a sore thumb if intercepted, and even the output of most stego packages will look suspect (unless your aid worker is in the habit of sending large numbers of digital photos by email. This could be arranged - get him to take new, original photos of what he sees while doing his work, use them exactly once for stego, then keep the stegoed versions around on the hd so that any comparison later will show the "original" version identical to the intercepted email version.
Probably the best overall solution to this would be a bootable mini-cd; a mini-linux distro would give a gui, and still leave room for conventional encryption packages, stego packages and the user's secret/public keyring, leave no trace on the HD at all (no matter how good the forensic package), can be hidden in a wallet amongst credit cards, and can be distroyed trivially by simply scratching off the printed surface with the back of a key or against a rough surface such as a wall or stone paving slab (ie, drop it face down, then stand on it and move foot back and forth until you have an oblong of worthless plastic and a slightly messy walkway)
assuming stego, you could load digicam photos (either via a driver on the minicd or via windows, whichever you happen to be using at the time) not long after they were taken, for later stego purposes, and the space they use on the digicam reused for more photos before the first set were used for stego (or again, if in a hurry, just remove and discard the sd card from the cam)

@_date: 2005-08-07 21:10:51
@_author: Dave Howe 
@_subject: solving the wrong problem 
I disagree - "one picket fence" gives a clear impression of a protective device that is hardened at but one point - leaving the rest insecure. "nonsense fence" doesn't give any real image.

@_date: 2005-08-26 22:02:01
@_author: Dave Howe 
@_subject: Another entry in the internet security hall of shame.... 
For the one task mentioned - transmitting the username/password pair to the server - TLS is completely appropriate.  However, hash based verification would seem to be more secure, require no encryption overhead on the channel at all, and really connections and crypto should be primarily P2P (and not server relayed) anyhow.
 > It's a chat message - it should be
yeah. you have a unencrypted interchange point - the server. There are aspects to that which make it both a good and bad thing, mostly bad. for example you allow interception at the server (may be a requirement for an american based company, but still bad), and you provide a single point of failure for hackers (very bad)
Most of the good aspects revolve around only having to support one client cert you can embed in your own client (or make available on your website) and not an entire PKI infrastructure.

@_date: 2005-08-27 18:26:13
@_author: Dave Howe 
@_subject: e2e all the way (Re: Another entry in the internet security hall 
Almost certainly though, the authorities of whatever government holds a VoIP hub are going to start insisting that traffic is interceptable at that hub. of course with SIP, unless you are proxying both ends, you are doing direct client-to-client links anyhow (so any crypto must be e2e, by definition); again however, unless there is some sort of PK retention in place, mitm attacks and attacks on the initial key negotiation are possible.

@_date: 2005-08-28 19:54:03
@_author: Dave Howe 
@_subject: Another entry in the internet security hall of shame.... 
Indeed. The main problem with TLS is lack of PKI support; in principle, this isn't true - TLS uses X509 certs, just like any other SSL based protocol - but in practice, everyone uses self signed certificates and nobody checks them or even caches them to see if they change.
   So - interesting idea time. what if....
1) Talk strongly authenticated *all* connections, even p2p ones, using a GoogleMail master certificate and a Googletalk.Googlemail single-use certificate to authenticate the GoogleMail server.
2) Google got into the CA business; namely, all GoogleMail owners suddenly found they could send and receive S/Mime messages from their googlemail accounts, using a certificate that "just appeared" and was signed by the GoogleMail master cert. Given the GoogleMail user base, this could make GoogleMail a defacto CA in 3) This certificate was downloaded to your GoogleTalk client on login, and NEVER cached locally
   Ok, from a Security Professional's POV this would be a horror - certificates all generated by the CA (with no guarantees they aren't available to third parties) but it *would* bootstrap X509 into common usage, and takeup of s/mime certificates was always the bottleneck for getting encrypted mail to go mainstream (PGP has the same problem, but in addition has the WoT issues and up to recently actual obtaining of the software to contend with)
   I can only hope that if this *is* in the gameplan, that the certificates be marked "autogenerated" so that in the longer term a more conventional, clientside-generated certificate can be used instead.

@_date: 2005-08-29 14:08:24
@_author: Dave Howe 
@_subject: Another entry in the internet security hall of shame.... 
So, the solution to nobody using the existing (but adequate) solution is another existing (but barely implimented and also unused) solution?

@_date: 2005-08-29 16:27:27
@_author: Dave Howe 
@_subject: Another entry in the internet security hall of shame.... 
Indeed so - however, if Google makes it "just work" then there will be a large swathe of people out there wondering "what does this DIGITAL SIGNATURE" button do in gmail?" plus a smaller subset who have google talk and can perform secure e2e voip using x509 certs that they don't even know they have.
   Its not ideal, but its not a bad thing either - a little more security, using a known method, without any individual user having to know or care how it works (and lets face facts here, no solution that requires an end user to get his finger out and do something without being forced to, no matter how trivial the task is, ever had a decent update)

@_date: 2005-02-17 10:49:29
@_author: Dave Howe 
@_subject: SHA1 broken? 
> I believe you are incorrect in this statement. It is a matter of public
   Its fine assuming that moore's law will hold forever, but without that you can't really extrapolate a future tech curve. with *todays* technology, you would have to spend an appreciable fraction of the national budget to get a one-per-year "break", not that anything that has been hashed with sha-1 can be considered breakable (but that would allow you to (for example) forge a digital signature given an example)
   This of course assumes that the "break" doesn't match the criteria from the previous breaks by the same team - ie, that you *can* create a collision, but you have little or no control over the plaintext for the colliding elements - there is no way to know as the paper hasn't been published yet.

@_date: 2005-02-19 15:53:53
@_author: Dave Howe 
@_subject: SHA1 broken? 
I wasn't aware that FPGA technology had improved that much if any - feel free to correct my misapprehension in that area though :)

@_date: 2005-02-19 21:23:31
@_author: Dave Howe 
@_subject: SHA1 broken? 
Indeed so. however, the argument "in 1998, a FPGA machine broke a DES key in 72 hours, therefore TODAY..." assumes that (a) the problems are comparable, and (b) that moores law has been applied to FPGAs as well as    I am unaware of any massive improvement (certainly to the scale of the comparable improvement in CPUs) in FPGAs, and the ones I looked at a a few days ago while researching this question seemed to have pretty much the same spec sheet as the ones I looked at back then. However, I am not a gate array techie, and most of my experience with them has been small (two-three chip) devices at very long intervals, purely for my own interest. It is possible there has been a quantum leap foward in FPGA tech or some substitute tech that can perform massively parallel calculations, on larger block sizes and hence more operations, at a noticably faster rate than the DES cracker could back then.
Schneier apparently believes there has been - but is simply applying moore's law to the machine from back then, and that may not be true unless he knows something I don't (I assume he knows lots of things I don't, but of course he may not have thought this one though :)

@_date: 2005-11-04 14:30:33
@_author: Dave Howe 
@_subject: [Clips] Sony to Help Remove its DRM Rootkit 
Unfortunately, this is an exaggeration of what Sony have agreed to do - they
have issued an installable which removes the filename cloaking component while
leaving the rest (primarily, the cd rom driver chain "filters" in place. It is
still not possible to remove these other than manually (and yes, the system as a
whole still uses up cpu and memory for no benefit other than for sony (and even
then, its a trivial hack to prevent the DRM from installing in the first place -
just disable autorun, which anyone halfway paranoid does anyhow)
  Mind you, sony seem to have added another wrinkle to this story with their new
DRM - which is aimed, not at preventing p2p copies, but at isolating Sony CDs
from itunes....

@_date: 2005-09-12 20:43:43
@_author: Dave Howe 
@_subject: Is there any future for smartcards? 
TBH I don't think the smartcard approach will work - really, everything needed
to verify what you are signing or encrypting needs to be within your secure
boundary, so the only sensible approach is for a mobile-sized cryptographic
device to be autonomous, but accept *dumb* storage cards for reading and
writing; that dumb card can then be used to transfer a unsigned document to the
cryptographic device, which when inserted uses a relay or switch to assume
control of the keyboard and screen; person wishing a digital signature stores
the document to be signed onto the card; signer inserts into his device, uses
the device's display to assure himself this is really what he wants to sign and
then keys his access code. The device then produces a digital signature
certificate (possibly deliberately adding some harmless salt value to the end
before signing, which is noted in the detached certificate's details) and copies
that to the dumb card, retaining a copy for the user's own records.
  by using a switch controlled by the cryptographic module, the display can be
then used by an alternate system when not in use - for example, a mobile phone -
while providing an airgap between the secure module and the insecure (and yes,
this would mean if you received a contract via email, you would have to write it
to a card, remove that card from a slot, insert it into a different slot, then
check it. I can't see how the system can be expected to work otherwise....)

@_date: 2006-02-04 22:26:49
@_author: Dave Howe 
@_subject: Hiding data on 3.5" using "40 track mode" 
It would have to be a guess.
  Back in the 5 1/2" days, we would frequently use a disk on both standard and
1.2mb drives; on the 1.2s, the head was literally half the width of a "standard"
5.25" drive, so you got the occasional problem due to this.
  For "virgin" disks, reading a file written on a 1.2 on a standard was no
problem; writing *any* disk on a standard always worked
  After a bit of use though, a interesting but predictable problem emerged - if
you wrote a file on a standard, then overwrote that file on a 1.2, then only
half the track (the lowest half) would be overwritten; the other half would
retain its original data, and a standard drive attempting to read back the data
would in fact read unreliably.
  Applying this to the problem would seem to suggest that, if you format a
standard 1.44 floppy as a 720, only *alternate* tracks are actually formatted,
and the intervening tracks are left blank.
  If you wrote and installed a special driver, you could read and write those
*alternate* tracks independently of the "formatted" tracks; even in a classic
720 3 1/2" drive, the worst you could expect would be an unreliable read, and
the best would be that you would get a reliable read from the "real" tracks,
ignoring the interleaved alternates. Of course, reading this floppy on a normal
1.44mb drive would show nothing wrong, and read it as being a perfectly usable
720K floppy. of course, *why* you would want to do that is another issue.
  Oh - before I forget, I was thinking about covert channels and cds a few days
ago and realised there is already one - CDs support a special mode called "CD+G"
- this is used making "karaoke" cds to support the video data stream; the vast
majority of pc drives cannot read this data - there are exceptions of course.
however, karaoke players (and many low-end dvd players) CAN, and by design
display them on the screen of the playback device.  This is pretty much STO, but
could conceal a message trivially that normal examination of the cd would not
reveal, but which the recipient could display (again, trivially) using nothing
more than a tv set and cheap mass-produced DVD player.
  Needless to say, you could always write or read data from the low bits of the
audio too, provided you got a reliable read of that data... the software to do
that could be considered suspicous though, while a cd that has a short text
message imbedded in track  of a 20 track audio collection would be harder to
detect (but of course for even vague security would have to be treated as a steg
channel and encrypted in addition, with something decodable by hand like a book

@_date: 2006-02-10 20:04:44
@_author: Dave Howe 
@_subject: Hiding data on 3.5" using "40 track mode" 
The InfoTool reading from this is also unreliable - I have several DVD drives
that report CD+G compatability, but on actual test don't return CD+G (they DO
return CD-TEXT properly though, so that might be an assumption InfoTool makes,
or simply are capable of ripping that data in "raw" dumps, but not as part of a
streaming read)
  The canonical playback tool for CD+G under windows is WinCDG (really
imaginative name there) although several other tools, KaraFun for example, also
offer support.
WinCDG's website offers a compatability list as follows:
  TBH I wasn't envisioning using it for anything else - you could of course use
text colour-matched to the background (note for people not familiar with the
format - its colour palette is user-definable, and there is no restriction on
having two "colours" with the same displayed RGB; in fact, one common method
given the low bitrate of the channel is to write an image in the background
colour, then swap the palette to make it suddenly appear; this is considered
pretty advanced tweaking though given COTS packages like Dart or Karaoke Builder
don't have this as an option) but really I was thinking that, if (say) track 12
on a cd had a cd+g video track on it, anyone using that cd on a conventional
audio player or pc drive would see only standard audio, but use on a cheap and
unsuspicious DVD player would show a text message onto the TV screen; obviously,
for further security this could be encrypted with a method suitable for plain
text or a stream of numbers.
  Any security would be though obscurity to a certain extent - but how many
people here were familiar with even the *existence* of CD+G before I brought it
up - never mind that  many low-end DVD players (including most portable ones)
were capable of displaying the format?  I can imagine many otherwise imaginative
investigators carefully ripping and comparing the audio to known sources /
statistical analysis to try and detect a steganographically hidden volume,
totally oblivious to the data hidden in timing bits on the disk - which could be
trivially displayed using $30 worth of DVD player.
  If it could be relied on that your recipient had one of the capable drives,
you could of course further conceal this data - on a commercial CD+G, a large
fraction of the bandwidth often goes unused - given the whole point is to
highlight words in sync with the music. you could make use of this space by
encoding to some of the unused bits of the stream, then use freely available
software to extract the graphics stream to a .CDG file; extracting the "hidden"
additional data from the file would then be a trivial task for any halfway
competent programmer.  However, this is probably technological overkill, and
reduces the simple elegance of this channel.

@_date: 2006-02-16 15:10:08
@_author: Dave Howe 
@_subject: the return of key escrow? 
The old XBox didn't encrypt the data on the hard drive - instead, it used a
password on the drive firmware that almost all modern hard drives support (your
home pc's drive almost certainly supports the same thing, even if your bios doesn't)
Defeating the password requires one of:
a) obtaining the password
b) replacing the drive bios or controller
c) using an already unlocked drive
d) defeating the os on a running system to allow writes to the drive
all known xbox hacks used method c) or d) - using a game to bypass the write
protection, or disconnecting the ide cable after the drive was unlocked and
using a standard usb>>ide adaptor to write to the drive.

@_date: 2006-01-28 16:58:41
@_author: Dave Howe 
@_subject: thoughts on one time pads 
Yeah, I know. just unsure how effective blanking is on cd-rw for (say) a pattern
that has been in residence for two years, but now must be unrecoverable.
for most, scratching off the carrier substrate is usually enough - I *might* be
persuaded some trace remains on the plastic disc afterwards, but I can't imagine
anyone recovering from a disk that had been
a) scraped clean then
b) thrown into a blast furnace containing liquid iron, or even a small home smelter.
However, I am more interested in methods to destroy just a single track at a
time, and I doubt you could deface the disk reliably *and* still retain read
abilty on the remaining tracks.

@_date: 2006-01-28 17:26:40
@_author: Dave Howe 
@_subject: a crypto wiki 
There is also the wiki crypto wikibook, which is sorta a co-production and
shares a lot of text with the wiki crypto entries. The idea is to get a slightly
more "fixed" view of the pages, which can then be published in paper form.

@_date: 2006-01-28 17:38:31
@_author: Dave Howe 
@_subject: thoughts on one time pads 
Yeah. tbh for good security, you should move your OTP keys into a secure
storage device (asssuming you have one more secure than the cd-r) as soon as
possible then destroy the entire disk. I can envisage a tamper-proof storage
device that accepts an upload of raw key data, and stores 1gb of it in battery
backed dynamic ram, which will blank reasonably effectively if the power is removed.
  But for most people, I imagine a CD-R is probably much, much easier to arrange
physical security for than any other storage they may have access to, and both
cheaper and easier to destroy after one use (easiest way to ensure data can't be
retrieved) than say a USB storage dongle.

@_date: 2006-01-28 17:40:12
@_author: Dave Howe 
@_subject: thoughts on one time pads 
you tried just scraping the data carrier paint off with a knife?

@_date: 2006-01-28 17:42:35
@_author: Dave Howe 
@_subject: [pgut001@cs.auckland.ac.nz: Re: thoughts on one time pads] 
Not sure what the data surface is made from but - surely a suitable organic
solvent could remove the "paint" into suspension leaving a clear plastic disc
and no trace of organized data?

@_date: 2007-05-27 13:13:07
@_author: Dave Howe 
@_subject: A crazy thought? 
Awareness of the failure models of various PKI solutions is an important part of
using and designing uses for them. There are many, many failure models for the
current x509/Certification Authority model used by ssl.
(everyone already familiar with the failure modes should probably hit "next
message" now, unless they want to double check I am not giving out bad advice;
this email is going to get rather long :)
Consider the following steps. I will predefine three actors here -
[SITE] which for email is the *recipient*, for web traffic is the server owner.
[USER] which is the mail sender and/or site user - originator of protected data.
[CA] which is the certificate authority
1. [CA] generates and stores securely a private key
  This is a once-in-a-decade event, but even so, there are failure modes. One
  possible mode is to use political pressure (or just bad coding) to force one
  of the two primes used in RSA to be either fixed or from a very small subset
  of possible primes (aka "canned primes"). As you can imagine, finding the
  private key becomes near trivial if you know one of the two primes in
  advance... We can move onto the security of the key later.
2. [CA] generates and stores a public certificate using the private key
  This at least is without any real issues (except security of the private key
  of course). In practice, this would be the same operation as (1) but need not
  be.
3. [CA] transmits the public key verifiably to the end recipients
  This is actually more complex than it sounds - I would guess 99% of the keys
  everyone has on their machine (if not 100%) were supplied to them with the
  browser, or in the case of IE, preinstalled on the machine. The vast majority
  of users have no idea how to even display those keys, never mind check them.
  To verify, ask yourself this question. For each web browser or email package
  installed to your machine,
  a) Where are root keys stored?
  b) How do I view them?
  c) Where is the public key or hash I should check?
  d) where do I obtain a known-good copy of that so I can verify it?
  The answers to some of those might surprise you (for instance, IE stores its
  root certs unprotected in the registry, and your AD administrator can override
  them at will; IE keys are used by almost everything supplied by microsoft,
  including execution digital signatures and email - Outlook or OE). All are
  trivially over-ridable by an attacker with write access to your machine.
4. [SITE] Generates and stores securely a private key
  Pretty much the same provisos apply here as did for the CA. Do you know and
  can you trust your key generation software? IIS for instance relies on a tool
  supplied my microsoft for the purpose; Apache usually suggests OpenSSL, email
  clients usually use their associated web browser for an interactive generation
  of both key and CSR while connected to the CA's website. However as another
  exercise - for each, where (and how) is the private key stored and protected?
5. [SITE] Generates and forwards to the CA a certificate signing request (CSR)
  Modulo the usual private key concerns, this is usually trouble-free (and
  again, is usually a combined step with key generation)
6. [CA] Receives and (for a payment) signs the CSR with its private key.
  This is where things get interesting. The certificate generated at this stage
  may or may not use exact copies of the data in the CSR; It may or may not be
  signed directly by the CA master key (for many CA's, their master key is kept
  offline in a bank vault and used to sign an intermediate key which is used for
  actual CSRs. In fact, it may sign *multiple* intermediate keys, for a number
  of good reasons (which we won't go into at this stage) but which also
  introduce another possible attack vector for a TLA with the power to force a
  CA of his choice (or someone with access to a private key there) to do
  selected tasks.
  Several potential attacks require that this transmission to the CA be
  intercepted and fulfilled by someone other than the CA themselves.
  Conventional wisdom says that there is little or no risk caused by site
  certificate substitution, and to a great extent this is correct - other than
  the possible forcing of the symmetric encryption method to one breakable by
  the TLA, there is little or no benefit to such a substitution.
7. [CA] Transmits signed certificate to the site
  Attacks possible at stage (6) also occur here - the transaction isn't complete
  until you have your certificate safely on your machine.
8. [SITE] Installs certificate into appropriate software, along with any
          intermediate certificates needed
  I am not aware of any attacks at this stage; willing to be enlightened
  though...
9. [SITE] transmits its shiny new certificate to the user
  This is an important stage, and one where the vast majority of MITM attacks
  take place. For web services, this is the https handshake; for email, the
  vector is typically sending a signed message to the user (but of course you
  can just send the key if you want, assuming the user knows how to import a key
  directly)
  If you are gnashing your teeth right now and saying but THAT'S THE PART I
  NEEDED TO KNOW - WHY IS HE GLOSSING OVER IT LIKE THAT! bear with me - I will
  come back to signatures once I have finished discussing the more general case
  (encryption)
  Normally, in order for future MITM intercepts to be readable (without
  compromising the SITE private key) the attacker must replace the proffered
  certificate with one of his own, so he can read the traffic.
  Alternately, an attacker with control over the user's machine can simply
  substitute the imported certificate in the user's profile with one of his own
  creation.
10. [USER] Establishes a symmetric key for use during the transmittal
  For web traffic, that would be an interactive process with the site (or more
  accurately, whomever you are speaking to who holds the private key matching
  the certificate you have). For email, that would be a local generation process
  in accordance with the supported methods outlined in the certificate.
11. User encodes and transmits the data
  Perhaps obviously, this would be a two-way conversation for a website, a
single transaction for an email.
But of course we are more concerned with digital signatures. To digitally sign
an email, the following elements take place:
1. [SITE] calcuates a cryptographically secure hash from the document
  An important question at this stage is - what constitutes the document? For
  many email systems, this is the body text of the email, excluding any
  attachments or inline graphics.
2. [SITE] encrypts this with his private key
  We will gloss over the padding and similar aspects of this, as they are not
  relevant to the problem.
3. [SITE] appends the encrypted checksum to the message.
  In S/MIME, the sender's certificate is often bundled as well; this makes
  signatures a convenient way to convey your certificate to an end user.
4. [SITE] transmits the message to the recipient
  For a MITM attack, this is usually where the attack takes place. Note if the
  message is, in addition to the signature, encrypted to the recipient, the MITM
  attacker must first have either compromised the recipient's private key or
  replaced the sender's copy of the recipient's certificate with its own.
5. [USER] recalculates the hash value of the document
  Obviously, this must match the value in the signature. Note that one
  theoretical attack is to substitute in the message a document which contains
  differing text, but which has the same hash as the original document. While no
  known attack can do this, there is a weaker form of the same principle (two
  documents, both generated by the same attacker, which have the same hash)
  which can be a viable attack in certain scenarios)
6. [USER] Validates the site's key(s) against the CA key(s) it holds
  Obviously, this is where substitition of the CA's key (or creation of a "new"
  CA specifically to be added to user's machines) bears its fruit.
7. [USER] uses public key from certificate to verify hash values match.
NONE of this is specific to email - "Document" could as easily be a PDF, and the
"message" (bundle of Document, signature, certificate, and any other related
items) sent as a zipfile with detached signature inside as a PDF (which has tags
to incorporate a digital signature) or other stucture, by post, hand or file
transfer. The important element is that the user is in receipt of a bundle, some
or all of which are hashed, and that that hash matches one that is encrypted
using a private key the user believes (due to the mechanisms available to him)
belongs to the user.
Ok, now we have that framework in place, we can more clearly outline the attacks
against such a system.
a) Case: Document is not signed
  1) Subcase: Fake seal attack
    For this attack, it is required only that the attacker affix to the document
    text or images that imply or falsely state that the document is digitally
    signed; as an alternate, the document could include a scanned image of the
    sender's physical (pen and ink) signature, possibly even by the sender's
    intention.
    Belief that a scanned image of a pen signature constitutes a "electronic
    signature" is fairly common, and in fact outside of our own tight
    mathematical meaning, could be correct.  Most legal jurisdictions make no
    distinction, and in those jurisdictions, typing "I SIGN THIS" on the end of
    a text file is as legally binding as the formal X509 procedure, provided you
    can prove it was done by the "signer" - the act of signing demonstrates
    intent to be bound by a document, the actual procedure is irrelevant; that
    is why an illiterate 'X' on a document before two witnesses is as fully
    binding as a sworn oath.
    Equally, it is possible both the recipient and the signer implemented such
    an electronic document in good faith, but it is not binding in the
    jurisdiction whose law the document will be interpretted in. It is also
    possible that one or the other of the parties has (after the fact, and
    wishing to escape a contract) done some jurisdiction shopping to arrange for
    this to be true.
b) Case: Document is part signed
  1) Subcase: bad encapsulation
    As has already been discussed, it is possible that only part of the
    perceived whole (for instance, a html email which references an attached or
    remote image which is not itself part of the hash, although the reference
    is) is subject to change after the fact, which alters the displayed document
    in ways hard to explain to a non-technical jury, and which in any case would
    render the document invalid due to this flaw (regardless of what the
    original said)
  2) Subcase: Dynamic content
    This is a more subtle attack, but one subject to technical analysis;
    technically, this is merely a special case of the first subcase, in that it
    introduces a dependency on some element outside the scope of the signature;
    the distinction (if there is one) is that there is some interpreted element
    within the Document which is aware of its environment, and makes changes to
    the rendering of that document should it find itself in an environment other
    than the one in effect when first signed - an example would be a document
    which checks the current date upon the machine it is running and, after a
    certain time has elapsed (three months say) makes changes in the displayed
    text so as to alter the meaning of the document in its author's favour.
    This is a powerful attack, in that it requires no access to the recipient's
    copy of the document after the signature is affixed, nor does it introduce a
    dependency on an external element (such as a remote website) which may not
    be present at all at some point, thus revealing to the recipient (possibly
    at a point inconvenient to the author) that some elements of the document
    lie outside of the scope of the signature.
    It is however also a risky attack, as competent analysis would show the
    rendering mechanism for what it is, a deliberate attempt to cause the
    displayed form of the document to change in the author's favour after the
    signature was affixed, to induce the recipient to accept as signed a
    document they would otherwise not so accept (i.e. fraud; there could be an
    argument made that they should have checked the document before signatures
    were affixed, but I suspect a reasonable jury would conclude that checking
    for digital "invisible ink" would require a level of technical competence
    far beyond the norm. To reduce the risk for the attacker, a platform (such
    as pdf with certain additions directly sponsored by adobe) could be chosen
    where the rendering is deliberately obscured from the recipient by a closed
    source module, the defeating of which is a criminal act in the USA.
c) Case: Document is signed with fake key
  1) Subcase: Fake CA
    An important prerequisite for this attack is that the recipient have on
    their equipment a ca "root" certificate not genuinely issued by a commonly
    accepted CA.  The exact mechanism here could vary, but possible vectors
    could be:
    * Compromise of browser vendor (ie, key supplied with browser)
    * Compromise of host by virus or other code vector
    * Compromise of host by user (social attack, inducing user to accept the
      root key by their own actions)
    * Compromise of host by direct action (ie, AD policy or simply modifying the
      key registry while the user is away from the machine)
    The effect of the attack, perhaps obviously, is that an attacker-generated
    certificate would be accepted as valid by the recipient; one possible
    realization of the attack would be to remove the key, leaving the recipient
    with a document which no longer verifies as signed (and hence, which is
    invalid or at least indistinguishable from one created by the recipient
    themselves)
  2) Subcase: Compromised CA
    In this case, the key verification chain is valid but was not issued
    knowingly by the CA or its agents; this could be done by having a
    confederate issue the certificate, issue an intermediary (ie, a certificate
    which can be then used to sign other certificates) or disclose the private
    key for the master or intermediate used by that confederate in the course of
    his work, so that valid (but not legitimate) certificates can be issued.
    Additionally, it is possible that social engineering caused an otherwise
    uncompromised employee to issue a key to someone not entitled to it -
    typically, a CA will verify identity by email exchange - if you respond
    appropriately to a testprobe email (and your payment clears) the certificate
    is issued. Note all CAs have no liability in this regard - they could issue
    keys routinely to anyone who asks, and there would be no legal impact
    (although I guess a lot of people would then remove the root CA key from
    their machines, making certs issued by that CA worthless - if they found
    out, and if they knew how)
  3) Subcase: Co-operating CA
    In the case of a TLA, they may well be able to command direct compliance
    from the CA they use to validate this attack - this is structurally
    different from the previous subcase only in that any attempt to validate the
    key by out-of-band methods with the CA would meet acknowledgement that the
    key was valid (as opposed to examples of the above where queries as to
    issuance of a certificate could lead to its cancellation and possibly legal
    or internal action against the compromised employee) - ie, as far as the CA
    will tell you, the issuance was "good" and the key is genuine.
d) Case: Document is signed with real key
  1) Subcase: Hash compromise
    As has previously been discussed, it is possible by the mechanisms of
    hashing that there exist two documents, both in the control of the same
    individual, which when hashed yield the same value. Hence that individual
    could induce the signer to sign the first document (which contains terms
    favourable to the signer) then transfer that signature to the *second*
    document (which contains terms unfavourable to the signer) which is then
    "signed"
    Successful use of the second document would usually require that the first
    be discarded by the signer (which may or may not happen), that the first be
    more valuable to the signer than the cost of the second (as revealing the
    collision would almost certainly invalidate both documents) and in any case
    require that the signer or his representative be able to extract the hash
    value of both documents (possibly all documents the signer has ever signed,
    just to locate the first document) and successfully explain to a court why
    the hash collision was almost certainly a deliberate act and not a strange
    twist of fate (good luck with that; while the odds of a collision are worse
    than that of winning the lottery, *someone* wins the lottery every week; its
    only a matter of time before someone, somewhere in the world signs purely by
    accident two documents that have the same hash, and it *could* have been
    you)
    A smart investigator will probably not even consider hash collision as a
    possibility until all other avenues are exhausted; even then, he may not be
    able to locate the first document if its terms have already been fulfilled
    and it is "expired" in the eyes of its recipient.
2) Subcase: Process compromise
    For this to be an attack, the signer must be induced to sign something
    either without reading, or in the belief he is signing something different;
    a variation would be the case where he is induced to sign two items in close
    succession, in the belief he is only signing one.  Automated signing systems
    could be vulnerable to such attacks depending on design; contactless
    identity systems such as are frequently proposed for national identity or
    passport schemes are another such group - by having a medium range
    transceiver, it could be possible in some designs for a random passerby in
    the street to trigger your contactless card while still in your wallet and
    cause it to sign something you have not seen.
    Similarly in the uk, credit card transactions are protected by "chip and
    pin"  - the mechanism is not disclosed for this, but it is thought to be a
    digital signature system using a dedicated cryptochip, unlocked by the pin.
    One known attack on this system is a relay attack - a confederate in a food
    retailer presents for settlement a modest food bill, and offers a card
    reader so the customer may insert his card and key his PIN to pay for the
    meal.  Unknown to the customer, the attacker is standing in *another*
    retailer, this time for something of high resale value - a jewellers, say -
    and is currently admiring something many times the cost of the meal - a ring
    for several hundred dollars.
    The attacker inserts into the retailler's similar card reading device a card
    which looks legitimate, but in fact is a short-range transceiver to a larger
    more powerful device in the attacker's pocket. this relays to another device
    at the food outlet, which is embedded in the card reader being presented to
    the customer. As the customer enters his PIN, the digits are relayed to the
    attacker as a lcd display on the second device; he reads this, and enters
    them onto the device belonging to the retailer. The retailer's device then
    authorizes the transaction, by PIN, against the customer's card some yards
    away - it all checks out, so the transaction goes though and the attacker is
    now the happy owner of an expensive and high-resale-value object - and the
    customer is now the unhappy recipient of a large bill for an object he did
    not purchase (and which when he discovers it on his statement at the end of
    the month, will probably not be able to relate to a meal he ate which does
    not appear on his statement at all). The bank of course says their system is
    infallible, so it *must* have been a valid transaction and refuses to refund
    the money.
    Note this is *not* a theoretical attack - people have been caught doing
    this, hence the great detail of the method I was able to show.
3) Subcase: key compromise
    By contrast, this is a much simpler attack. By compromising the owner's
    ztorage of the key, the attacker is able to obtain access - either directly
    (by using the key while the legitimate owner is not in direct physical
    possession of the device) or indirectly (by extracting the key and using it
    on hardware of the attacker's choosing)
    A common example of the former is where other household residents or thieves
    obtain physical possession of a token (eg - a credit card) and its
    associated unlock code (sadly, many people still keep a slip with a PIN in
    the same wallet as their cards; in addition, for remote use the usual PIN is
    a three digit code *printed on the back of the card* but this is not
    directly relevant as no on-card pki is currently party to a remote
    transaction; users typically do not have the hardware to access a physical
    token like a chip-and-pin card at home)
Anyhow, I hope some or all of this is of assistance the next time your lecturer
claims PKI is infallible :)

@_date: 2007-11-02 18:46:59
@_author: Dave Howe 
@_subject: Hushmail in U.S. v. Tyler Stumbo 
Seconded. the java applet is effectively a mail client, a copy of gpg, and a copy of the secret keyring; the public keys are looked up on the server though, and I suspect/assume that the messages are no more or less secure at the hushmail side than your own pgp mail would be on a isp imap server (i.e., you could get traffic information trivially just by looking, but message content would require being lucky with the keyphrase or active co-operation from hushmail to give you a "gimmicked" client the next time you log in that reveals that information.

@_date: 2007-11-02 18:58:31
@_author: Dave Howe 
@_subject: Hushmail in U.S. v. Tyler Stumbo 
For an earlier case where the defendents used Hushmail, we have:
Posted in July by Declan McCullagh of Politech fame....
I suspect we are just seeing the same invasive keylogging techniques trickling down to steroid abuse as have been previously used for more high profile drug barons....

@_date: 2007-10-08 16:58:08
@_author: Dave Howe 
@_subject: Trillian Secure IM 
Had a look, but it seems to me they said they wouldn't fix it unless there was an actual, active exploit for it, and my guess would be even then they would just make cosmetic changes to stop that particular instance of an exploit from working..

@_date: 2007-10-24 08:28:05
@_author: Dave Howe 
@_subject: Fingerprint Firefox Plugin? 
Never needed one. The hoops involved aren't THAT large, at least in
the version I use - click the padlock icon in the right hand side of the
navigation (address/url) box, then the "view" button on the page that
you can manually approve certificates of course, however there are a few tools I find useful.
this one remembers which certificates were (mistakenly) presented by which domains, so it won't ask you again. it also does something similar to allow already-expired certs to function.
the author has a blog here where he discusses aspects of the tool and related technologies:
currently he is blogging about a recently checked-in patch that will add similar functionality natively to Firefox, and changes to a host's cert that makes it redundant for Thunderbird.

@_date: 2007-09-15 19:36:17
@_author: Dave Howe 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
If I had to guess, I would suggest they were using the ATA "secure" hd password api, and really providing security rather than the firmware-lock usually associated with such passwords. That would allow you to retrofit it to a lot of laptops which already use that functionality, in a plug-and-play manner.

@_date: 2008-01-23 20:23:59
@_author: Dave Howe 
@_subject: patent of the day 
Interesting. he patented E4M, then two years old or so...

@_date: 2008-01-30 19:04:59
@_author: Dave Howe 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
TBH I can't see the problem - the unix philosophy of doing one thing
well, and chaining simple tools to make complex ones, works well here.
we have:
TCP - well understood, has crude integrity and reliability checks built
in, works reasonably well at converting a bunch of packets leaving and
arriving via your network connection into something vaguely like a
stream point-to-point connection. Provided by every ISP across the
planet, problems at this level can be handed off to experienced network
engineers who will at least understand the problem.
SSL - Cludge thrown together by a browser manufacturer, probably to
create a market for a bunch of companies who generated two prime numbers
and now sell the answers to simple math queries involving the numbers.
However, works reasonably well, has some crude authentication of the
server built in (via the aformentioned bunch of companies) which at
least limits potential hackers to those whose money the bunch of
companies will accept ;)
   Again, works well in its domain, but requires a reasonably reliable
channel to talk over, and a message to carry. Effectively turns an
unencrypted channel into an encrypted one, Would work as well over a
serial link as a tcp link (modulo the domain name check in the cert)
HTTP - pretty basic file transfer protocol, with limited scope for
negotiation, but designed largely to move text files from a server to a
client. requires transport, can use tcp, ssl-over-tcp, serial, whatever
your server will listen on and your client request on.
add them together and you get HTTPS. leave out the SSL, and you get HTTP
as-normally-spoke, so the SSL and HTTP are pretty much drop in modules.
you could define HTTPG (HTTP over a security protocol other than SSL)
and if a browser could support it, both TCP and HTTP would still be
happy. you could also define HTTPS-over-adis-lamp and provided the
operators were sufficiently accurate, securely download your web page
from a server on a nearby hilltop after dark by replacing the TCP layer :)

@_date: 2008-06-03 21:47:01
@_author: Dave Howe 
@_subject: Can we copy trust? 
Up until recently, you could buy a cert for one domain, use *it* to issue a cert for another domain, and the major web browsers wouldn't kick at the traces provided you sent both certs in the ssl handshake.
Thankfully, they fixed that before *too* many phishers figured it out.

@_date: 2008-06-10 23:41:56
@_author: Dave Howe 
@_subject: Ransomware 
The key size would imply PKI; that being true, then the ransom may be for a session key (specific per machine) rather than the master key it is unwrapped with.

@_date: 2008-06-11 19:13:25
@_author: Dave Howe 
@_subject: Ransomware 
Sure. however, if the virus (once infecting the machine) generated a random session key, symmetric-encrypted the files, then encrypted the session key with the public key as part of the "ransom note" then that would allow a single public key to be used to issue multiple ransom demands, without the unlocking of any one machine revealing the "master key" that could unlock all of them.
giving away your entire extortion capability to the first person to pay up doesn't seem sane, if you could as easily make each machine a unique

@_date: 2008-03-15 22:41:15
@_author: Dave Howe 
@_subject: delegating SSL certificates 
Sorta. TLS gets along with self signed just fine though, and obviously you can choose to accept a root or unsigned cert on a per-client basis.
sure. for IE its just a registry key, trivial to push out using login scripts etc.
buying a intermediate cert from an existing CA? buying a "wildcard" cert   for your domain, and using the same wildcard cert on all nodes?
at one point, you could use *any* cert to sign another cert; IE didn't bother checking. I believe they have fixed that now.

@_date: 2008-03-19 18:41:08
@_author: Dave Howe 
@_subject: delegating SSL certificates 
I have found that just adding the cert to the local keystore had pretty much the same effect. There is a nice addon for Thunderbird/Firefox (which will apparently be a native ability in v3 of the latter) called "remember mismatched domains" that lets you suppress an error for a specific cert/domain mismatch.

@_date: 2008-03-22 08:41:07
@_author: Dave Howe 
@_subject: How is DNSSEC 
DNSSEC is "working fine" as a technology. However, it is worth remembering that it works based on digitally signing an entire zone - the state of the world being what it is, most people prohibit xfer so any other technology that would allow a zonewalk is not going to be as far as I can tell, this is a basic design flaw, so isn't going to be rectified anytime soon.

@_date: 2008-10-27 22:03:54
@_author: Dave Howe 
@_subject: combining entropy 
unless you have a possible case where (say) for any given pool,
alternate bits are predictable; XORing all 'n' pools would still give a
maximum entropy of 50%, as the XOR of all 'n' predictable bits is
using a hash which performs error diffusion, I would expect that 'n'
equal to 3 would give a suitable combined stream in that case (assuming
the 50% of random bits *are* random of course) 2 is possibly good
enough, but I would probably over-engineer at 3, in case one pool went

@_date: 2008-09-09 23:21:52
@_author: Dave Howe 
@_subject: once more, with feeling. 
One thing that concerns me is that in the new release of firefox, there
appears to be NO way to get to a site that has a bad certificate (or
self signed certificate) other than overriding the warning permanently -
no "ok let me see it, I have seen the warning and want to look just this
once" that the "remember mismatched domains" plugin for 2.x gave you.

@_date: 2008-09-11 01:27:31
@_author: Dave Howe 
@_subject: once more, with feeling. 
True enough, but the "clickthru bandits" will just see a button that
reads to them "make this error go away" then next time will forget they
did it - and will take the fact that they went straight into the site to
mean the problem was "fixed" or simply not remember there ever was a
In the meantime, a choice I *used to have* is now taken from me, in the
interests of selling more EV certificates.

@_date: 2009-03-02 19:44:55
@_author: Dave Howe 
@_subject: X.509 certificate overview + status 
odd. the openssl installations I am familiar with came with example
config files that were perfectly functional, took me about ten minutes
to figure out what needed doing purely from the man pages and the
example config.
if ten minutes is too long, just go with xca
( which does it all in a nice,
pretty gui for you. A few distros (suse, for example) also have a gui
for certificate issuing in their central admin tool.

@_date: 2009-09-07 15:26:58
@_author: Dave Howe 
@_subject: Source for Skype Trojan released 
Not really. more generically, you could call it a "VoIP trojan" or even
"Audio monitoring trojan" - presumably a more advanced version could
listen to the mic stream even when the VoIP application is not in use,
in order to obtain information.
However, in context, this was designed to be used for law enforcement to
"bug" a skype VoIP session, so the name reflects the design goal; yes,
it is a more generalized attack than that, but not in intent or
(presumed) usage.

@_date: 2014-12-03 18:43:42
@_author: Dave Howe 
@_subject: [Cryptography] Why Alexander Hanff won't be using "Let's 
Why would it matter? It's not as if the TLAs can't already spoof
commercial certificates; access to a specific CA signing key isn't going
to make that any harder or easier, as the session is still encrypted
with the server's own key (not the CA key) - so without an active MitM
attack there is no more or less danger depending on who signed the CSR.

@_date: 2015-02-21 14:09:24
@_author: Dave Howe 
@_subject: [Cryptography] Lenovo laptops with preloaded adware and an evil 
You are overthinking it.
It probably went more like this:
 &  & :
  Stick this software on your consumer builds and we will pay you; sure
it will annoy your customers but hey, free money!
: Sure, sounds good to us

@_date: 2015-03-17 18:47:43
@_author: Dave Howe 
@_subject: [Cryptography] Kali Linux security is a joke! 
Not seeing why that would matter? Each repo has a hash table of all the
packages within it, and that hash table is gnupg signed. If you attempt
to alter a package, it would no longer match the hash table, and if you
alter the hash table, it will no longer validate against the detached
signature. The tools *do* check those, and alert if they don't match.
The protection is end-to-end, not on the transport.

@_date: 2015-03-17 19:04:48
@_author: Dave Howe 
@_subject: [Cryptography] Kali Linux security is a joke! 
Sort of. Certainly, nothing new should be using it, as it is getting
close to the end of its useful lifetime, and it is quite practical to
create two hash targets with the same hash now (collision attack). Not
so sure about a preimage attack on something the size of an iso, but no
doubt that will come in time.
debian package file itself has multiple hashes, including sha256, so is
probably secure for at least our lifetimes :)
