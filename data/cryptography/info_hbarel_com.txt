
@_date: 2003-08-14 14:39:22
@_author: Hagai Bar-El 
@_subject: A new paper: When To Use Biometrics 
I would like to bring to your attention a short paper I published, called "When To Use Biometrics". This paper discusses biometrics reliance on cryptographic mechanisms making them harder to deploy securely in many Abstract:	
Full Paper:	
A short recorded lecture about the topic is available in: Hagai Bar-El - Information Security Analyst
Tel.: 972-8-9354152  Fax.: 972-8-9354152
E-mail: info at hbarel.com  Web:

@_date: 2003-02-23 12:40:56
@_author: Hagai Bar-El 
@_subject: question about rsa encryption 
Hello Scott,
Sorry for the delayed response.
As mentioned in the other postings, there are several technical problems with doing the RSA encryption in its most simple fashion by exponentiation and MOD calculation alone. However, in addition to all that was said, please note the following two general problems with such an approach, which apply not just to RSA but to any other asymmetric encryption when done directly on the plaintext:
First, when encrypting a plain-text block as it is, with no random (or otherwise variable) padding, you are actually performing encryption in an ECB mode. The ECB (and other) modes of operation are known in block-cipher contexts, but the problems related to using ECB are reflected well when you perform simple block-by-block encryption using an asymmetric cipher as well. Of course, RSA uses block sizes that are much larger than the "regular" 64-bit or 128-bit block sizes, so code-book attacks are much harder to mount in comparison to code-book attacks on DES-ECB, but are still possible. So, simple block-by-block encryption using RSA (or any other asymmetric cipher), leads to the same vulnerabilities that are caused by simple block-by-block encryption with DES or other block ciphers, especially when it comes to code-book attacks.
Second, there is a big inherent quality of all asymmetric ciphers which is that encryption can be simulated (by an opponent). Here is a brief explanation: When using symmetric encryption, an opponent who does not have the key cannot simulate neither correct decryption nor correct encryption, which means that he has no way (assuming the cryptographic algorithm is strong) to guess the plain-text unless he can guess the key. The only possible avenue of attack is therefore by brute-forcing the key. With "simple" asymmetric encryption, however, the encryption process can be simulated (repeated) by the opponent, hence he can obtain knowledge of the plaintext either by brute-forcing the key or by brute-forcing the plaintext, which might often be easier to do (for example, if the plaintext is one of known choices, or can otherwise be guessed). So, if you encrypt plaintext that may be guessed easily, the attacker can simply mount a brute-force attack on the plaintext to find what it is.
Again, please note that these two are true not just for RSA, but for any other asymmetric cipher if implemented without salting (or otherwise wisely manipulating) the plaintext.
Hope this helps.
Hagai Bar-El - Information Security Analyst
Tel.: 972-8-9354152  Fax.: 972-8-9354152
E-mail: info at hbarel.com  Web:

@_date: 2003-03-11 10:55:14
@_author: Hagai Bar-El 
@_subject: double shot of snake oil, good conclusion 
I am in full agreement with your opinion. I do not think security is an "all or nothing" property, and I do think that mechanisms can be considered effective even if they do not protect against attackers with some level of skill or motivation. After all, there is no complete security and security is, and has always been, considered as "perceived assurance".
I do not think that a fact that a mechanism can be somehow circumvented makes it useless. "Keepng the honest people honest" is a good enough legitimation for a mechanism to exist as well as "moving the bar higher". However, the only problem I can see in this case is the opening of a possibility of a false sense of security. Security mechanisms do not have to be perfect, but their perceived strength by their users shall be set right.
For this I personally think that the mechanism is great and useful, but should be presented by Microsoft accordingly, hence: as a useful security-related feature, not as a complete bullet-proof protection tool.
Hagai Bar-El - Information Security Analyst
Tel.: 972-8-9354152  Fax.: 972-8-9354152
E-mail: info at hbarel.com  Web:

@_date: 2003-03-20 14:56:33
@_author: Hagai Bar-El 
@_subject: Diffie-Hellman 128 bit 
You can find good explanation for the rationale behind Diffie-Hellman parameters as well as general precautions for implementation in a good paper called "Security Issues in the Diffie-Hellman Key Agreement Protocol"
You can find it in: Hagai Bar-El - Information Security Analyst
Tel.: 972-8-9354152  Fax.: 972-8-9354152
E-mail: info at hbarel.com  Web:

@_date: 2005-08-03 16:58:13
@_author: Hagai Bar-El 
@_subject: Standardization and renewability 
Dear Colleagues,
I am currently in the process of writing a short position paper about standardization of broadcast renewability schemes. Along with the usual challenges that need to be addressed when defining renewability methods (methods that allow a system to survive successful attacks, basically by changing itself throughout its lifecycle), I am trying to tackle what I consider to be the biggest problem of standardizing a renewability scheme, which is that evolving a standard is too slow and cumbersome of a process to be incorporated into another process that is all about prompt response. Simply put, if a broadcast mechanism is broken there is no time for the standardization committee to re-define it - too much content will be lost by the time the job is done.
Up till now I could come up with three approaches to solve this problem:
1. Limit renewability to keying.
2. Generalize the scheme (like the SPDC concept, or MPEG IPMP), more or less by making the standard part general, with non-standard "profiles".
3. Standardize sets of key management methods at once, so to have spares for immediate switching.
If any one of you has any other approach towards solving this issue I will be glad if he posts it on the list. Also, if any one of you would like to get a copy of this paper when it's done, please let me know by e-mailing me directly.
Hagai Bar-El - Information Security Analyst
T/F: 972-8-9354152 Web:

@_date: 2005-06-04 11:58:56
@_author: Hagai Bar-El 
@_subject: Opinion on Israeli espionage plot 
In the following link is an opinion about the espionage act discovered in Israel a week ago.
In short: This case is probably one of dozens, but the only one that was discovered probably due to three non-typical mistakes that were done.
Hagai Bar-El - Information Security Analyst
T/F: 972-8-9354152 Web:

@_date: 2005-10-20 17:06:08
@_author: Hagai Bar-El 
@_subject: Practical Security Mailing List 
I would like to notify you all of a new mailing list forum which I opened. It is called "Practical Security" and is aimed at discussing security measures in the context of real problems in real projects. It has a much narrower scope than the Cryptography mailing list and by no means intends to replace it or to compete with it.
 From the mailing list info page:
This forum discusses applications of cryptographic protocols as well as other security techniques, such as (but not limited to) methods for authentication, data protection, reverse-engineering protection, denial-of-service protection, and digital rights management. The forum also discusses implementation pitfalls to avoid. This forum does not discuss theoretical and/or mathematical aspects of cryptography. Neither does the forum discuss particular vulnerabilities of commercial products, such as what one may find in BugTraq.
Joining this mailing list is especially recommended to professionals who design security systems and to application designers who are also responsible for the security aspects of their products.
I confess that at the moment of writing the list has just a few participants, but I project that it will grow much larger.
To subscribe visit  or send a blank message to practicalsecurity-subscribe at hbarel.com.

@_date: 2005-10-26 21:43:04
@_author: Hagai Bar-El 
@_subject: [PracticalSecurity] Anonymity - great technology but 
m>
I agree with what you say, especially regarding the frustration with TOR, but I am not sure it contradicts the message I tried to lay out in my post.
Secure browsing is one instance of anonymity applications, which, as I mentioned, is used. I completely agree that technology may not be mature enough for this other instance of anonymity applications, which is anonymous file sharing. My point was that there is a lot of anonymity-related technology that is not used, especially in the field of finance; I did not claim that there are technological solutions available for each and every anonymity problem out there. I apologize if this spirit was not communicated well.
It's not that we have everything - it's that we don't use most of what we do have, although we once spent a lot of efforts designing it.

@_date: 2007-04-02 16:24:23
@_author: Hagai Bar-El 
@_subject: Governance of anonymous financial services 
Putting the crypto capabilities aside for a moment, what is the purpose
of auditing an anonymous legal entity?
Auditing, as I see it, can be used to serve two systems:
When I take my hard earned money and deposit it with the local branch of
ABC bank, I do it while relying on two things:
assures me that this branch having this nice red "ABC" logo, is the same
ABC Bank that all my friends use, along with millions of others, and so
far, they haven't been fooled and their money hasn't yet been stolen.
accompanied by some auditing I trust, even if the bank is completely
anonymous. In the optimal installation you try to achieve the auditor I
trust will be able to tell me: "This bank, that you do not know where it
is, and so don't I, has the backing for the currency it has in
circulation." I will also be able to tell it's the same bank my friends use.
bank takes my hard earned money and refuses to give it back to me, the
*human* manager of the bank will be put in *physical* handcuffs and
taken to a physical prison, where he cannot physically exercise his
freedoms, such as go to a pub, see his kids, etc. No web-site extortion,
no reduction of virtual credibility points, not even bad publicity;
jail. Real jail, with non-chosen roommates and bad meals. I want to know
that the enforcement system that the bank is subject to is one that can
lead to real jail before I trust a web-site with my real money. This is
along the lines of the baseball bat that Ian mentioned.
auditing, but there is no chain connecting the digital world (as
intrinsically-enforced as it would be), and the physical world, that
offers better enforcement means, better matching my money's worth.
The enforcement that is offered by the legal system is tied to the
physical world and thus requires identifiability and personal (flesh --
not username) accountability. You can have a system do without it; have
only intrinsic enforcement without tying to the physical world, but I
believe its enforcement will never be strong enough to win the trust of
the masses when it comes to hard earned money.
At the end of the day, say everything works perfectly by your model, and
the intrinsic system can prove that there is a coin of gold for every $x
in circulation. How does the user know that he will ever see the sums he
put in circulation. He has a receipt, of course, but a receipt is just a
bunch of bits. These bits may prove to a third party that justice is
with the user, but what will link this justice back to money if the
bank's owner doesn't feel like paying?
I know this is not completely related to the questions you presented,
but more to the rationale of the entire system. I am just trying to
understand this better.

@_date: 2007-04-06 18:48:35
@_author: Hagai Bar-El 
@_subject: DNSSEC to be strangled at birth. 
I guess it's mostly a matter of the expectations that non-US nations
have from DNSSEC in the first place.
If I understand this correctly, the situation as it would be once DHS
has the keys will be no different than what it is today. The US will be
able to spoof DNS responses that are resolved within its cloud. To forge
a DNS response you need not only to be able to sign as a DNS server, but
you also need to be (on the path of) the DNS server that is asked. This
is not different than the situation as it is today, and non-US countries
still use the Internet.
The question is whether or not these non-US countries ever expected
DNSSEC to solve their problems with US national surveillance. I have no
facts, but I believe that they never did. After all, there is some
master key somewhere and this master key is kept by someone (I am not
sure if key splitting was ever considered). As far as national
intelligence is concerned, there is no difference between having the
keys held by a ".org" or by a ".gov". The keys are in some nation's
jurisdiction and are thus subject to subpoenas that are enabled by some
government with its own legal system that the community has no control
over. Be it the US, or the EU, or anyone else.
DNSSEC, I think, comes to solve the problem of hackers who fake DNS
responses to phish for your credit card details; not against national
espionage. And; If you don't expect -- you are not disappointed...

@_date: 2007-04-21 20:33:51
@_author: Hagai Bar-El 
@_subject: More info in my AES128-CBC question 
Hello all,
Relating to the anger at the "random bunch of people [who] design crypto
What Aram wrote is "many of the attendees have very little security
experience", not: "there are no attendees with security experience".
There are people at the relevant OMA group who know enough about
security, but just like in the real world -- they are outnumbered by
plain "feature-set" people, and thus have to come up with very clear
arguments to get their way.
Aram figured fixed IV's is generally a bad idea, and probably so did
others at OMA, but since the security people have to build a case and
not just say "well, it's generally not a good idea", a more descriptive
explanation of possible attacks (a "justification") was sought for.
Now to the subject matter:
I do not know the protocol in question, but in a nutshell: Generally,
CBC with a fixed IV (be it zero or any other value) is to be avoided for
the reason described in previous posts. In some circumstances this
restriction may be relaxed, such as:
(1) if the first unknown (to the attacker) block _always_ follows (not
necessarily immediately) a session-specific block (a block that is not
likely to repeat for the same key, such as a message-id). For example,
if every encrypted structure starts with an id that never repeats among
structures, and all "security-wise meaningful" blocks follow it, you are
_probably_ safe.
(2) if the key is never re-used among structures you encrypt.
AND (3) If you don't care about replacement attacks on the (1 to i)
blocks that will result only in a (possibly-undetected) corruption when
decrypting the i+1 block (rather than two blocks, with a varying and
non-attacker-changeable). For example: If Message  and Message  are
encrypted with the same key, you can take blocks 1,2,3,..,i of Message
 and paste them in Message  and only block i+1 will decrypt badly.
If you had protected (attacker unchangeable) and varying IV's, block 1
would have decrypted badly too, for whatever it's worth.
(Comment: block 1 can be any higher index, as long as there are no
earlier blocks that differ between the messages.)
As the others stressed: the implication of these conditions/limitations,
as well as others which I may have not spotted, depend on the protocol...
P.S. Aram, as you know, I am signed on the OMA NDA, so you can send me
the protocol. If other members here are signed on the OMA NDA, I guess
it could be useful if you notified Aram in a private message, so you can
get your copy and examine it too.

@_date: 2007-04-23 11:30:13
@_author: Hagai Bar-El 
@_subject: More info in my AES128-CBC question 
Hello David,
The group is not "reluctant" to listen, but it does expect to hear firm
reasoning, so the security consideration weights properly among other,
as important, considerations. Security gurus A' say A, Performance gurus
B' say B, which may partially conflict with A, and UI gurus C' say C. If
the product is broken then it's dead, but also if the product is slow
and annoys people, and also if average people can't use it for UI
reasons. It's easy to make a product that is never used, even if it's
secure. When we look at things, we see them as secure/insecure, but the
market and the economy sees a more complex picture where security is
very important, but is one important factor along with other important
factors that influence the design decision.
As long as security comes for no cost -- sure, why not. However, when
security comes at a cost that may make the product less useful, A' need
to convince (A' U B' U C') that they should have their way.
As long as what the Doctor says costs you very little (in terms of risk
and/or money), you follow his advice blindly because challenging it will
cost you more. When the doctor tells you that you need a heart surgery

@_date: 2007-04-25 17:20:30
@_author: Hagai Bar-El 
@_subject: More info in my AES128-CBC question 
Hello Nico,
Is there anything wrong with changing the integrity key every message as
means for preventing cut-and-paste attacks between messages or against
taking messages out of their order? It may not be the most efficient
way; adding a message counter to the HMAC does make more sense, but is
there a problem with the way Aram uses now? (I don't see any.)
What problem does this (chaining IV from message to message) introduce
in our case?
It seems as Aram uses a different IV for each message encrypted with
CBC. I am not sure I see a requirement for randomness here. As far as I
can tell, this IV can be a simple index number or something as
predictable, as long as it does not repeat within the same key scope.
I don't understand the difference between a confounder and an IV in
terms of bits on the wire. After all, in both cases the confounder or IV
need to be passed to the other side, unless they are implicitly known.

@_date: 2007-08-23 14:21:23
@_author: Hagai Bar-El 
@_subject: Good news on crypto patents: 
Hello James,
The case you quoted seems to apply only for punitive damages. If this is
the case then I'm afraid the impact of this ruling will be to a lesser
extent than you hope...
When you infringe a patent, its owner is likely to sue you for
compensatory damages, claiming that you caused him lack of income, loss
of customers, etc. IIUC, punitive damages generally apply only where
compensatory damages are deemed an inadequate remedy or where some
deterrence effect is required.
With or without punitive damages added to the ruling against you,
compensatory damages alone can end up being a large enough stack of cash
to discourage you from infringing a patent, as long as you suspect its
owner may actually have a case.
P.S. IANAL, of course.

@_date: 2007-05-05 09:30:07
@_author: Hagai Bar-El 
@_subject: phone encryption technology becoming popular in Italy 
I know these devices.
You are right. The source code you get cannot be used for full
assurance, because you don't get everything required to build an image
and replace the existent one with it. The source you get allows you to
check and be convinced that the code has no software bugs that were not
intended by the vendor. It does not aim to assure you against malicious
attempts by the vendor to introduce back-doors into the product.
So, you are "secure", just not against everything... It's still more
than you get with completely closed-source devices, let alone with ones
that implement proprietary crypto...
And, of course, the source code is probably published also because the
marketing guys (probably) said that people skilled in the art will
appreciate this feature when evaluating this product against others.

@_date: 2007-05-10 16:40:58
@_author: Hagai Bar-El 
@_subject: Enterprise Right Management vs. Traditional Encryption Tools 
The "encryption tools" function according to simple, well understood,
and more-or-less enforceable security models. Their assumptions are well
understood and, most importantly, match the environments they run on.
They solve a simple problem, and solve it effectively.
Rights management solutions have complex security models, and run in
environments that do not always satisfy the assumptions. They aim at
providing complex functionality, but they often (always?) fail to
deliver due to their over-complexity and unrealistic assumptions.
If your security needs can be met by the simple functional model of the
"encryption tools", then you will prefer to enjoy the assurance and the
reasonable robustness they provide, which is the most desirable feature
after all.

@_date: 2007-10-29 21:56:58
@_author: Hagai Bar-El 
@_subject: Full Disk Encryption solutions selected for US Government use 
Are there at all any open source FDE products for Win32?

@_date: 2007-10-30 11:12:38
@_author: Hagai Bar-El 
@_subject: Full Disk Encryption solutions selected for US Government use 
A great product, but not an FDE one.
It encrypts contents of logical drives into container files. You still
have to worry about temp files, swap files, hibernation files, tampering
with the OS when you're away, etc.
FDE typically authenticates pre-OS-boot and supports the encryption of
the full disk, including the OS, applications, system storage areas, etc.

@_date: 2007-10-30 18:39:59
@_author: Hagai Bar-El 
@_subject: Full Disk Encryption solutions selected for US Government use 
IIRC, none of the products on this list is open source.

@_date: 2007-09-13 00:43:33
@_author: Hagai Bar-El 
@_subject: Another Snake Oil Candidate 
I think there is a difference between a product that is susceptible to
an attack and the pure distilled 100% natural snake oil, as we usually
define it.
Indeed, the encrypted USB token is susceptible to sniffing of the
password on the PC where it is entered. But in my opinion this is not
the type of flaw that snake oils the product, because:
1. It's a limitation that also exists in the state of the art products
of its type. That is, nobody could ever do better (I think).
2. It therefore does not reflect complete lack of understanding on the
developer's side...
So perhaps it's not pure snake oil but just a product with an attack
vector; most products have at least one.
Actually, this product is (almost) the first one that I saw which
actually bothers to deal with the brute-force attack vector, which does
exist in many other similar products. So it's not perfect, and I would
certainly not bet my life on it, probably not even my life's data, but
it's reasonable.

@_date: 2007-09-13 20:10:57
@_author: Hagai Bar-El 
@_subject: Another Snake Oil Candidate 
Just like any term, it can have many interpretations.
However, the most useful definition is the one that you can find at
 and which quite
accurately reflects what the people who first brought this term into use
used it for.

@_date: 2008-02-08 09:46:12
@_author: Hagai Bar-El 
@_subject: Open source FDE for Win32 
Finally, an open source FDE (Full Disk Encryption) for Win32. It is the first one I am aware of:
TC is not a new player, but starting February 5th (version 5) it also provides FDE.
Didn't get to try it yet.

@_date: 2008-02-11 14:43:42
@_author: Hagai Bar-El 
@_subject: Open source FDE for Win32 
Actually, there is one major (but temporary) limitation to TC5: It does not process too well partitions that are not the system partition, but which share the same physical drive as the system partition, if you elect to encrypt the entire drive.
That is, if you decide to encrypt a whole physical drive that stores both C: (system) and D: (another partition), you are going to face a situation in which your D: partition is logically gone (until you re-decrypt the whole thing back). Next version will fix it, the team

@_date: 2008-02-14 12:38:15
@_author: Hagai Bar-El 
@_subject: Open source FDE for Win32 
Hello Dave,
Encrypting blocks only when they are used can be risky in terms of false sense of security. There is basically no way for you to tell what is left out there.
Encrypting the drive while the system is live is what TC currently does. Encryption runs in the background while you can do other things (though much slower).

@_date: 2008-03-18 12:17:26
@_author: Hagai Bar-El 
@_subject: Firewire threat to FDE 
As if the latest research (which showed that RAM contents can be recovered after power-down) was not enough, it seems as Firewire ports can form yet an easier attack vector into FDE-locked laptops.
Windows hacked in seconds via Firewire
IIUC, the tool mentioned only bypasses the Win32 unlock screen, but given the free access to RAM, exploit code that digs out FDE keys is a matter of very little extra work.
This is nothing new. The concept was presented a couple of years ago, but I haven't seen most FDE enthusiasts disable their Firewire ports yet.
It is not *their* fault, but being a company that pretends to take users' security seriously, and being at a position that allows them to block this attack vector elegantly, I would have gone that extra half-mile rather than come up with excuses why not to fix it. All they need to do is make sure (through a user-controlled but default-on feature) that when the workstation is locked, new Firewire or PCMCIA devices cannot be introduced. That hard?
