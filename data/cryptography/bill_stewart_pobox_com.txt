
@_date: 2001-04-02 18:06:23
@_author: Bill Stewart 
@_subject: PRE-ANNOUNCE: San Francisco Cypherpunks, 4/7, 1pm, Downtown 
This is a pre-announcement for the Saturday April 7 Cypherpunks Meeting in San Francisco.
This is the FIRST Saturday of the month, because the RSA conference will be
the following week and many usual suspects from out of town will be around.
The meeting will start at 1pm, and will be followed by dinner afterwards.
Agenda: The primary agenda is discussion of the work people are doing,
projects, things you're playing with, current events in crypto and privacy.
If you'd like to give a talk, please contact Bill or DDT.
We're still confirming the location, but it will either be at Moscone Center,
where the conference is being held, or within two blocks, at AT&T 795 Folsom St.,
or at the Thirsty Bear Tavern on Howard.  All of these are 5-10 minutes walk
from Caltrain and BART.
A follow-on announcement will give the definite location.

@_date: 2001-04-06 11:59:22
@_author: Bill Stewart 
@_subject: ANNOUNCE: San Francisco Cypherpunks, 4/7, 1pm, Moscone Center 
Saturday April 7 Cypherpunks Meeting in San Francisco.
The meeting will be at Moscone Center North,
The room number will be finalized in a couple of hours,
and we'll post signs at the door as well as sending out mail.
This is the FIRST Saturday of the month, because the RSA conference will be
the following week and many usual suspects from out of town will be around.
The meeting will start at 1pm, and will be followed by dinner afterwards.
Agenda: The primary agenda is discussion of the work people are doing,
projects, things you're playing with, current events in crypto and privacy.
If you'd like to give a talk, please contact Bill or DDT.
 From BART or MUNI:
 From Caltrain:
Driving: 4th st goes South, 3rd goes North, Howard goes West.
Parking: Official Parking Map

@_date: 2001-04-06 18:33:57
@_author: Bill Stewart 
@_subject: ANNOUNCE*N: San Francisco Cypherpunks, 4/7, 1pm, Moscone 
Saturday April 7 Cypherpunks Meeting in San Francisco.
The meeting will be at Moscone Center North, in Room 122.
Go in the door, take the escalators downstairs.
We've been told that we shouldn't need badges to get to the room
(and they're still setting up the exhibit floor),
but if that turns out to be incorrect, check with the registration desk
and ask for Kellie.    Bill's cellphone is +1-415-307-7119,
but cellphone reception on Moscone is normally poor to non-existent :-)
This is the FIRST Saturday of the month, because the RSA conference will be
the following week and many usual suspects from out of town will be around.
The meeting will start at 1pm, and will be followed by dinner afterwards.
Agenda: The primary agenda is discussion of the work people are doing,
projects, things you're playing with, current events in crypto and privacy.
Several people have said they'd like to talk; please contact Bill or DDT.
 From BART or MUNI:
 From Caltrain:
Driving: 4th st goes South, 3rd goes North, Howard goes West.
Parking: Official Parking Map

@_date: 2001-04-21 15:12:50
@_author: Bill Stewart 
@_subject: Requesting feedback on patched RC4-variant 
In general, if you're not an expert (:), it's worth not messing with the
core parts of algorithms to prevent an attack when you don't undertand the You mutilated it in ways that don't introduce major new strengths.
RC4 has two basic rules for using it securely
- Use long enough keys.
- Never EVER reuse a key.
The basic things wrong with the use of RC4 in several broken
commercial environments (e.g. 802.11 WEP, MS PPTP) include
- keys too short - 40 bits is trivial.  128 bits is fine.
- things that give away information about the keys.  32 bits is worse than 40.
- reusing keys.  Things like using the same key for both directions of
         a conversation, or always restarting at the beginning when you lose sync,
         or generating the key in a way that a given pair of users always
         uses the same key are easy popular ways to violate this.
- having other ways to guess the key - the original MS PPTP used leftover
         password handling code that made it easy to steal the key.

@_date: 2001-08-09 02:07:57
@_author: Bill Stewart 
@_subject: ANNOUNCE CYPHERPUNKS Saturday, Aug 11, 1-5pm, Stanford 
SF Bay Area Cypherpunks August 2001 Physical Meeting Announcement
General Info
DATE:   Saturday 11 August 2001
TIME:   1:00 - 5:00 PM (Pacific Time)
PLACE:  Tressider Student Union Courtyard,
         Stanford University Campus
         Palo Alto, California, USA
    "Our agenda is a widely-held secret."
As usual, this is an Open Meeting on US Soil, and everyone's invited.
Some events and topics that have been happening recently
include Sklyarov, Defcon, Worms From The Borg, and New FBI directors.
PGP is ten years old!  Several of us were at Phil Z's talk.
The 802.11 WEP Wireless Encryption Protocol has been cracked
even more thoroughly.  The Fedz couldn't crack Nicky Scarfo's PGP key,
but they could steal his passphrase by cracking his computer.
    The Stanford meeting location will be familiar to those who've been to our
    outdoor summer meetings before, but for those who haven't been, it's on the
    Stanford University campus (in Palo Alto, California), at the end of
    Santa Theresa, at the tables outside Tressider Union, just west of
    Dinkelspiel Auditorium.
    We meet at the tables on the West side of the building, inside the
    horseshoe "U" formed by the Tresidder building. Ask anyone on campus
    where "Tresidder" or the "Student Union" is and they'll help you find it.
    If the weather is bad, we'll meet inside.
    Food and beverages are available at the cafe inside Tresidder.
    Location Maps:
          (zoomed detail view):
     Printable Stanford Map (407k).
    GPS Coordinates: 37d23:40 N 122d04:49 W
    If you get lost on the way, you can try calling:
      +1.415.307.7119 (Bill)
If you have questions, comments or last-minute agenda requests, please contact the
meeting organizers:
     Bill Stewart bill.stewart at pobox.com
     Dave Del Torto ddt at cryptorights.org

@_date: 2001-08-29 23:25:01
@_author: Bill Stewart 
@_subject: Stealth Computing Abuses TCP Checksums 
A group of researchers at Notre Dame figured out how to use the
TCP Checksum calculations to get other computers to do number-crunching for The article has the amount of great mathematical depth you'd expect from CNN :-)
But it does say that the paper will be published in "Nature" this week.
It's a really cool hack, though not especially efficient for real work.
Of course, the Slashdot discussion follows typical structure -
there's an interesting technical suggestion (ICMP checksums may be usable
and are probably more efficient than TCP), some trolls and flamers,
the obligatory "Imagine a Beowulf Cluster of those!" comment,
and some speculation about the potential legalities and other uses for it.

@_date: 2001-12-06 01:53:40
@_author: Bill Stewart 
@_subject: ANNOUNCE: SF Cypherpunks, Saturday, 12/8, U.C.SANTA CRUZ, 
SF Bay Area Cypherpunks meeting, 8 December 01, U.C.Santa Cruz, College VIII Room 240, 12:30-5:30
We're meeting Way Down South in the land of Boletus edulus mushrooms
and Monarch Butterflies*, which are both in season, and Banana Slugs.
It's an open public meeting on US soil, everyone's invited,
and it's another month where the Second Saturday showed up early,
so it's this Saturday.
* Eric Blossom will be giving a talk and demo on Software Defined Radios. *
An anonymous cypherpunk may allegedly be discussing development status
of unnamed anonymity products or more reasons for anonymity.
Several less anonymous cypherpunks will be discussing
tools to build, or rebuild, or build differently -
what lessons have we learned from PGP for the next product?
What's a practical toolset for a human rights organization?
Now that the list has been Officially Declared Dead (stego-mpegs at 11:00),
harassed by flooded machine rooms and mailing list glitches,
we've been taunted by some science-fiction authors,
finally probably been published by others, and been dissed by several
Intellectual Property judges, and informed that civil liberties
and due process are pre-millenial relics, we've got some slack
to re-evaluate the cypherpunks movement.  What technologies
should we be looking at?  What needs building next?
What succeeded?  What failed?  What synergies do we need to exploit?
We'll also be discussing schedules for February's meeting,
since The RSA Tradeshow will be the 18th-22nd in San Jose.
If you're an out-of-towner expecting to be here for the show,
please send some mail if you know if you'll be around the
weekend before (Presidents Day) or after the show.
======= Directions and Transportation ======
Kristen Tsolis has reserved a room for Saturday, 12/8 from 12:30~5:30.
UCSC College VIII Room 240.
While UCSC is a mere 30 minutes from Silicon Valley,
it's tough to get to from SF without a car,
so Bill Stewart will be meeting several Usual Suspects at
Mountain View Caltrain at 12:13pm (train leaves SF at 11:00.)
Look for the burgundy-colored Chevy van, or for Bill :-)
The Caltrain schedule (  )
Drop email to bill.stewart at pobox.com if you want to be waited for.
UCSC can be a maze to the uninitiated, so you will want to print this map.
The meeting space at UCSC is clearly marked:
here are some more maps:
To get to UCSC, take US 280 or CA 101 to US 880 or CA 17 south. Take CA 17
south to Santa Cruz, then CA 1 north to Bay St. Turn right on Bay which will
take you to the base of campus. One can also come south from San Francisco
on CA 1 to Bay.
At the base of campus, take a left onto Empire Grade, which will take you to
the West Entrance. Take that right onto Heller, and then take a right on
Koshland into the College Eight Lower Parking Lot. There's no need to pay
for parking on weekends, and as long as you don't park in a 24 hour space,
you won't get a ticket. If you need assistance with handicapped parking,
please email kristen at pobox.com.
Walk up the stairways between the College Eight dorms until you reach the
top flight of stairs. When you are facing the top parking lot, turn right
towards Room 240.
The cafe there will be closed for Christmas Break, so bring your coffee and
victuals with you.
*Natural Bridges State Park: Bill Stewart's Cellphone is +1-415-307-7119, if you're lost and he's not.

@_date: 2001-12-06 02:04:45
@_author: Bill Stewart 
@_subject: FreeSWAN Release 1.93 ships! 
From Claudia Schmeing 's summary:
1.  Release 1.93 ships!
     ===================
     1 post Dec 3
     A number of small improvements have been added to this release, which was
shipped on-time.
Some highlights:
* Diffie-Hellman group 5 is now the first group proposed.
* Two cases where fragmentation is needed will be handled better, thanks
   to these two changes
        The code that decides whether to send an ICMP complaint back about
        a packet which had to be fragmented, but couldn't be, has gotten
        smart enough that we now feel comfortable enabling it by default.
   and
        IKE (UDP/500) packets which were large enough to be fragmented used
        to be mishandled, with some of the fragments failing to bypass IPsec
        tunnels properly.  This has been fixed; our thanks to Hans Schultz.
* If Pluto gets more than one RSA key from DNS, it will now try each key.
   This will help when a system administrator replaces a key.
* There is preliminary support for building RPMs.
* SMP support is better.
* The team has eliminated a vulnerability that might permit a denial of    attack.
     We are in the process of chasing down a couple of significant bugs (which
     have been there since at least 1.92 and possibly earlier), and we *might*
     ship another release quite shortly if we nail them down and fix them.  If
     we don't, we won't.  Barring that possibility, the next release is planned
     for the end of January; a more precise date will be announced shortly.

@_date: 2001-12-10 23:57:30
@_author: Bill Stewart 
@_subject: Customer Acts Odd? U.S. Wants to Know 
Suspicious?  Those are simply *routine* in the telecom and computer businesses :-)
You'd think that they'd find it suspicious of customers *did* read all the closely, in great detail.  It's less common now after the dot-com crash
than during the heat of tulip-bulb mania, but if customers really understood technology
there'd be less need for data sales people to bring along systems engineers
to wave their hands and tell them what to think, or for companies to hire
lots of customer support people to explain how to reset the coffee-cup holders on PCs,
or for trade rags and internet sites to keep hyping new trends.
Meanwhile, the technologies and economics are constantly changing in the so even if a customer or vendor understood what they were doing three months ago,
that doesn't mean they still understand it today.
Now, I don't sell missiles or grenade launchers, but computer encryption are part of my stock in trade - they're letting customers move from dedicated
private lines and semi-shared frame relay and ATM networks to shared Internet connections
and still get the privacy and security they got from the more expensive and tools for cracking computer security devices are also routine commercial product,
just like pressure gauges for checking car tires or chemical emissions detectors for
car exhaust.

@_date: 2001-12-28 14:21:20
@_author: Bill Stewart 
@_subject: CFP: PKI research workshop 
SST is the SuperSonic Transport; I think the term was specific
to US attempts to build something like the Concorde, but it may have
been more generic.  Among other problems (making it work, sonic booms,
economics in general), use of fast airplanes in non-military airspace
was limited by the capabilities of the air-traffic control systems,
which couldn't really handle airplanes that fast.
It's much easier to build supersonic airplanes for the military,
where you're not concerned about price per passenger-mile.
Except for airports and amusement parks, the only place I've seen
a monorail is in Seattle.  (I'm counting Las Vegas as an amusement park :-)
Airports similarly don't follow normal economic rules,
because they can often scam money out of government authorities,
who will often do stuff because it Looks Cool.
There may be economic niches where monorails make sense
(streets that are too narrow to add pillars for conventional
elevated railways, perhaps), but they're pretty limited.
Until recently I was the Regional ATM Specialist for
one of the offshoots of The Phone Company that did the
PicturePhones at the World's Fair back in the 60s :-)
Web cams are widely available, but they're still not how
most people make their phone calls, and it did take
30-40 years before they finally became economical.
ATM also has a fairly wide economic niche, though routers
have caught up with the big end of the performance curve,
and it always was too complex to win at the desktop end.
PKIs are quite simple and low cost to implement -
the problems are finding a way to make them widely useful.
Unfortunately, that hasn't matched most PKI companies'
business plans that promised World Domination to their VCs :-)
And even among the people who adopt crypto because it Looks Cool,
the last time I looked through the Web Of Trust on the PGP keyservers,
most keys were either unsigned or only signed by a couple of people,
not enough to build a big connected graph.
                         Bill

@_date: 2001-12-28 14:47:29
@_author: Bill Stewart 
@_subject: Stegdetect 0.4 released and results from USENET search 
And Perry replied:
Back in the old days, it was easy - Usenet messages carried a
bang-path route to the original sender.  You could forge parts of it
easily enough, as the Kremvax hoax demonstrated,
but the only real untraceability was because there were lots of
pre-Honey-Danber UUCP sites which would accept incoming messages
from unknown senders.  These days, most of them are gone -
you're really depending on how long sites keep logfiles.
[Moderator's note: That's not the point. You can post without any
authentication via many web sites, or over the net via accounts you
can get with little or no identification in a dozen countries, which
you can log in to anonymously from web cafes, airport kiosks,
etc. around the world. If you decide not to be found, you won't be
found. --Perry]
Reader anonymity depends a lot on how many people actually read A.A.M,
and on how many sites keep NNTP logs - it probably a lot fewer readers
than the largest binary porn spam groups, but a lot also depends on
how many small ISPs around the world still spool their own news
rather than buying access from news services.  It's certainly harder
to trace than senders.
So tracing a single transmission may be hard, but tracing an ongoing pattern
is easier, unless there's a trusted Usenet site in some
country where you don't have jurisdiction problems.
That means that A.A.M + PGP is fine for an occasional
"Attack at Dawn" message, but not necessarily for routine traffic.
So it helps to add an extra step - posting the anonymous message
through a web2news gateway through an anonymizer,
or a mail2news gateway from a webmail account from a cybercafe,
or mail2news through an open relay somewhere in the world
(since open relays are usually people who haven't bothered
configuring their mail systems, and are less likely to keep logs
unless that's the default, plus you can spread your messages
among lots of different relays.)

@_date: 2001-06-08 22:48:22
@_author: Bill Stewart 
@_subject: SF Bay Area Cypherpunks, June 9, 2001, San Francisco [REMINDER 
[Mailing these sorts of announcements to me the day before, when I'm
possibly gone for the weekend, is a way not to get the announcement
out on time. :(  --Perry]
See for SF, Toronto, & Bangalore Cypherpunks announcements.
SF Bay Area Cypherpunks June 2001 Physical Meeting Announcement
General Info:
DATE:   Saturday 9 June 2001
TIME:   12 - 6 PM (Pacific Time)
PROBABLE LOCATION:  AT&T, 795 Folsom St. 3rd Floor, SF - 4th & Folsom
"Our agenda is a widely-held secret."
As usual, this is an Open Meeting on US Soil, and everyone's invited.
The meeting starts informally at noon, with presentations starting at 1:00,
and typically is followed by dinner.
Marilyn Davis   - presentation / review of
Black Unicorn - The black market for Cocaine in the United States,
Dave Del Torto - CryptoRights: HIGHFIRE in Guatemala
Hugh Daniel - Linux-Ipsec Installation - FreeSWAN 1.9 is now doing
Lab Tour - Bill Stewart's department test/demo lab has
AT&T's office at 795 Folsom Street is a shared building.
The meeting is on the 3rd Floor, and the elevator and door require
an access card, so we'll have someone running around letting folks in,
and phone numbers posted at the guard desk for you to call us.
Bill Stewart's cell phone is +1-415-307-7119.
Coffee will be provided, and there's a deli a block away on Folsom,
and various other restaurants nearby.
Caltrain - Caltrain runs roughly hourly on Saturdays.  The schedule is posted at
 Bart - Powell station is near 4th St - walk down to Folsom, turn left, you're there.
Driving - From the Penninsula - take 280 North, or 101 to 280 North,

@_date: 2001-06-13 00:31:39
@_author: Bill Stewart 
@_subject: tapping undersea fibers? 
I'm not particularly convinced of this -
there's OC12 hardware available now (622Mbps, aka 12 T3s plus overhead),
but most telco fibers run at multiples of OC48 or OC192
(48 or 192 T3s, aka 2.4 or 10 Gbps.)  Some cables run small numbers of
wavelengths - often 8-16 of one of those two speeds,
but some of the newer fiber technology can run 80 or 160 wavelengths
if you want to buy the electronics to put on the ends.
As a telco, your end users may be able to encrypt their data streams
fast enough, if they care, but you're not going to.
It costs way too much, and there's no demand.
And as Lenny mentions - politicians, intelligence agencies, etc.,
aren't stopped by telco-provided encryption,
because what a telco can encrypt, a bureaucrat can tell them to decrypt.

@_date: 2001-06-17 16:25:03
@_author: Bill Stewart 
@_subject: WAS: Thermal Imaging Decision Applicable to TEMPEST? 
The average person's equipment could be eavesdropped relatively
easily if somebody wanted to.  I remember once seeing the
screen from my laptop displayed on a near television set -
the sync was all wrong, but the characters were relatively readable,
and somebody who wanted to mount a real TEMPEST attack
could easily do so.  Reading data off the CPU is becoming
harder as CPU speeds go up, but if you can grab the
keyboard and display signals, that's usually good enough.
This kind of interference is not supposed to happen, of course,
but if you read the FCC information included with most computers,
it'll generally say that they're intended for office use, not home,
and a bit about who to complain to if somebody's PC bothers your TV.
As home computers become more common, and more powerful,
there may be tighter restrictions on emissions,
though perhaps the upcoming digital TV technology is
less affected by it.
The main difference between crypto attacks and TEMPEST attacks
is that crypto attacks can affect your communications from a distance,
while TEMPEST attacks require the attacker to be nearby,
or at least to put an eavesdropping device nearby.
That doesn't mean they can't be in a van out on the street
(depending on your equipment and theirs),
but it's an attack that needs individual targeting of
suspicious people or places with relatively expensive equipment
rather than a Carnivore-like attack that can stay in one place
and hoover up data wholesale from lots of people;
the difference in cost of the attack also means that
TEMPEST scanning probably will be mainly used with warrants
against people strongly suspected of actual law-breaking,
as opposed to internet eavesdropping on the general public
and on people who are politically unpopular but not necessarily criminal.

@_date: 2001-05-10 11:16:54
@_author: Bill Stewart 
@_subject: SF Bay Area Cypherpunks 5/12/01 Meeting - Stanford 
SF Bay Area Cypherpunks May 2001 Physical Meeting Announcement
General Info
DATE:   Saturday 12 May 2001
TIME:   1:00 - 5:00 PM (Pacific Time)
PLACE:  Tressider Student Union Courtyard,
         Stanford University Campus
         Palo Alto, California, USA
    "Our agenda is a widely-held secret."
At Noon, we mill around for a bit: the organized program begins about 1:00 pm.
As usual, this is an Open Meeting on US Soil, and everyone's invited.
Agenda -
   Open Discussions:
   Eric Hughes's Bulk Signature Method - using hash chains to reduce
         the computation required for individual digital signatures.
    The Stanford meeting location will be familiar to those who've been to our
    outdoor summer meetings before, but for those who haven't been, it's on the
    Stanford University campus (in Palo Alto, California), at the end of
    Santa Theresa, at the tables outside Tressider Union, just west of
    Dinkelspiel Auditorium.
    We meet at the tables on the West side of the building, inside the
    horseshoe "U" formed by the Tresidder building. Ask anyone on campus
    where "Tressider" or the "Student Union" is and they'll help you find it.
    If the weather is bad, we'll meet inside.
    Food and beverages are available at the cafe inside Tresidder.
    Location Maps:
          (zoomed detail view):
     Printable Stanford Map (407k).
    GPS Coordinates:
      ??.???? N ???.???? W  (anyone know? someone bring a GPS unit...)
    If you get lost on the way, you can try calling:
      +1.415.307.7119 (Bill)
If you have questions, comments or last-minute agenda requests, please contact the
meeting organizers:
     Bill Stewart bill.stewart at pobox.com
     Dave Del Torto ddt at cryptorights.org

@_date: 2001-05-29 01:31:18
@_author: Bill Stewart 
@_subject: NSA tapping undersea fibers? 
Sure - install the tap when the cable is first being installed,
before there's real traffic on it.  Exactly how to do this will be
influenced by the monitoring going on as the cable is installed,
but there are probably times when nobody's watching the bits directly.

@_date: 2001-11-02 21:40:33
@_author: Bill Stewart 
@_subject: Wed 7 Nov Stanford - Provos talks on Detecting Steganogaphic 
Niels Provos will be talking at Stanford on Wednesday,
just a few hours before the EFF BOF at the Linux shindig in Oakland.
Does anybody have a picture of a Peter Honeyman related shirt to
auction off on E-Bay with appropriate embedded content?  :-)
---------- Forwarded message ----------
Fnord-content: low, with scattered Elvis later in the evening
          4:15PM, Wednesday, November 07, 2001
     NEC Auditorium, Gates Computer Science Building B03
Topic:		Detecting Steganographic Content on the Internet
Speaker:	Niels Provos
About the talk:
Steganography is used to hide the occurrence of communication.
Recent suggestions in US newspapers indicate that terrorists use
steganography to communicate in secret with their accomplices. In
particular, images on the Internet were mentioned as the
communication medium. While the newspaper articles sounded very
dire, none substantiated these rumors.
To determine whether there is steganographic content on the
Internet, this talk presents a detection framework that includes
tools to retrieve images from the world wide web and
automatically detect whether they might contain steganographic
content. To ascertain that hidden messages exist in images, the
detection framework includes a distributed computing framework
for launching dictionary attacks hosted on a cluster of loosely
coupled workstations. We have analyzed two million images
downloaded from eBay auctions but have not been able to find a
single hidden message.
[see the abstract at  for
a list of resouces and related news articles. -dra]
About the speaker:
Niels Provos is a Ph.D. candidate at the Center for Information
Technology Integration of the University of Michigan. His
research interests are focused around computer security.
Contact information:
Niels Provos
CITI, University of Michigan
535 W. William Street, 3rd floor
Ann Arbor, MI
GPS: 42.2775 N, 83.754167 W.
734 764 5207
provos at citi.umich.edu
Thanks to the Computer Forum for support.  The Computer Forum
is the industrial affiliate program for the Computer Science
Department and the Computer Systems Laboratory. Contact Suzanne
Bentley, bentley at cs.stanford.edu, if your company is interested
in participation.

@_date: 2001-10-01 00:36:42
@_author: Bill Stewart 
@_subject: New encryption technology closes WLAN security loopholes 
The basic howto is "ignore 802.11 - pretend it's just an ethernet
that anybody can plug in to, and do whatever flavor of ipsec you like."
Getting slightly more serious, the two issues you need to resolve are
eavesdropping and authorization.  Any ipsec system takes care of the
eavesdropping problem; the harder part is deciding how to do authorization.
If you're trying to keep the system open for public use,
but also keep your intranet private, you've got a more complex problem.
One interesting issue with radio networks is Man-in-the-middle attacks,
because nobody can intercept a request and forward it
faster than you can receive it directly, unless there are
distances that are too far for the two parties to reach each other
but still let the MITM contact both.

@_date: 2001-10-02 09:41:51
@_author: Bill Stewart 
@_subject: Best practices/HOWTO for key storage in small office/home  
I>
Sounds like you're starting to reinvent the I-Button.
(Dallas semiconductor's product - uses a small computer chip
and an infrared link attached to a watch battery.)
But, yeah, the USB memory things are cute, at least if you're
using machines new enough to have USB ports.
If your threat model includes people rifling through your office
looking for stuff, you're probably toast anyway,
but you can always do a secret-sharing thing.
If you do want off-site storage for your keys,
secret-sharing is especially important.

@_date: 2001-10-03 03:01:37
@_author: Bill Stewart 
@_subject: Best practices/HOWTO for key storage in small office/home  
Yes, I spaced on that, must have been thinking of something else :-)  Sorry.
Anyway, to partially redeem my gaffe, the web site for
Dallas Semiconductor who makes the things is  ,
and  and
are where some of the good data lives.

@_date: 2001-10-06 14:44:13
@_author: Bill Stewart 
@_subject: AGAINST ID CARDS 
[Moderator's note: we are rapidly getting off topic again. --Perry]
The US doesn't require you to have one.
If you want to leave the US by airplane, and sometimes by boat,
the airline or boat will often require one,
depending on the country you're going to.
If you want to enter the US through a formally controlled location
(e.g. an airport or bridge, as opposed to walking into Montana
or Arizona),  La Migra wants to see if your papers are in order,
though how in order they need to be depends on where you're
coming from - the amount they're legally able to control
American citizens is less than the control they have over foreigners,
though of course the trick to that is demonstrating to them
that you're an American.

@_date: 2001-10-08 21:59:20
@_author: Bill Stewart 
@_subject: AGAINST ID CARDS 
It's a really, *really* bad idea.
It's politically much easier to successfully oppose an obviously bad thing,
like National ID cards and other internal pass laws,
than to successfully oppose incremental changes in existing systems.
And forcing states to use uniform practices means that you
can't find a place to have a driver's license merely
indicate your driving skills, as opposed to hundreds of other uses.
For instance, collecting SSNs for driver's licenses,
which makes it possible to correlate drivers databases with
most other databases in the country, was done back in the 80s,
and in many states the SSN is printed on the DL or IS the DL number.
(The Federal Privacy Act had little effect on this process -
it's just a law, so future laws can easily change it, and did so.)
Another big change in DL policies was the requirement for
citizenship papers to get permission to drive.
Here in California that was largely done to prevent the
clear and present danger of people speaking Spanish while driving,
and many other states have jumped on the harassing-immigrants bandwagon.
Since many jobs need driver's licences (or at least transportation),
immigrants now have a major financial incentive to get them,
so the price and supply of corruption in motor vehicle departments
has gone up substantially.  Before this, the main people who needed
high-quality driver's licenses were convicted bad drivers
who were trying to dodge the system, and that was easier to stop.
(There was also a demand for fake ID for underage drinkers,
but low-quality fakes are fine for that, and they don't need to be
Driver's licenses have increasingly become tools of social control -
the common excuse is "deadbeat dads", and in many states
conviction for drug possession offenses also gets them suspended.
Until 9/11, you could still routinely travel without government ID,
though many airlines have a policy of training their people to lie
about "no, that's always been the policy".
ACLU Cards with pictures would have helped that - don't leave home
without one - but I doubt we'll have that freedom again for a while.
New Jersey, BTW, encodes lots of information in the DL number -
the S8235 at the beginning of mine was a Soundex for "Stewart",
the 5 digits at the end encoded birthdate and I think
race or eye color, and some of the middle six digits may have also
encoded that, though some were just serial numbers.
It provides some security against licenses forged by
people who don't know the rules.
         [They're also listed in plaintext.  The forms let you
         update your address, but not most of the personal data,
         so my weight still shows what I weighed when I was 22.]
As long as there's a driver's license number printed on the card,
it's a unique ID for database lookups attached to your name.
If the other certifications are encrypted, that means that
*you* don't know what they say, but cops who run the card
through a computer lookup will - and cops will *have* to
run the card through a computer lookup to use them,
whereas now they can just look at them if they want.
If you could get a card that just had your picture and the
certifications, and not your name or address,
that might be an improvement, but it ain't gonna happen.
And meanwhile, in many states you've got some flexibility about
whether the license lists the address where you get snailmail
or the address where you sleep or the address where you own land.
Expect any uniform standards to erase that.
What can the ability to do database lookups do?
Well, if the signatures indicate that you're black,
or a Registered Republican Voter, or a Welfare Recipient,
or a Registered Drug Offender, it's much easier for
anybody who wants to target you do do so.
If the databases are only accessible to authorized users,
that increases the demand for bribable authorized users,
especially if the expanded set of uses expands the set of
authorized users.  It's possible to keep the different sets
of information separate, if there's the technical skill
and political will to do so, but there's little enough of the former
and none of the latter among the kinds of people who'd
make the requirements for that kind of system.
                 Bill Stewart

@_date: 2001-10-25 17:41:31
@_author: Bill Stewart 
@_subject: Dilbert Random Number Generator 
Dilbert's been visiting the Trolls In Accounting,
who have been spitting all over his data.
Now he's on a tour, and the troll is showing him their random number generator.

@_date: 2001-10-29 18:17:30
@_author: Bill Stewart 
@_subject: Speaker Wanted - This Wednesday, Pulver Conference - Presence 
(Forwarded for brad at templetons.com )
This is Brad Templeton from the EFF.  This Wednesday I'm moderating a
panel at Jeff Pulver's semi-annual conference on Presence and Instant
Messaging.   It's a smallish (couple of hundred) conference where you'll
see most of the commercial players in instant messaging, with the very
notable exception of AOL.
However, having attended this conference I have found that most of the
people there pay little attention to issues of security and privacy in
the IM world.  Sometimes for real reasons (most IM is forced by NAT and
firewalls to be routed through central servers) but often times simply
because they haven't bothered.
The panel I am moderating is on these topics of Presence and Instant
Messaging, and due to various circumstances, right now I have only 2
other speakers on it, who will speak about the privacy and security work
being done by two standards bodies, the PAM formum, and the IETF SIP working
group.  I have my own talk on the design and political issues, but I can
move a lot of that into my plenary talk later in the day where I want to
get those issues out.
In particular I am interested in technologically interesting projects or
research to allow privacy, encryption and anonymity in instant messaging,
and also in presence data and location-aware devices.  (Part of the
conference is also on location aware services, E911 manadated location-aware
phones etc.)
So I apologize for not asking until today, but if you have done any work
in these areas you would like to talk about briefly, I could have a slot
for you, and get you free attendance at this normally $2,000 conference.
Last time Lenny Foner gave a great talk on his work.
The conference info is at  and my session is
This Wedesday, Oct 31, at 9:45am.  It is at the Marriott in Santa Clara.
Sorry as well for posting without regularly reading cypherpunks, but I
need to keep my email load down.

@_date: 2001-09-06 20:06:01
@_author: Bill Stewart 
@_subject: Cypherpunks 9/8/01 - GOLDEN GATE PARK - EFF Music Share-In 
See for SF, Toronto, Seattle, & Bangalore Cypherpunks announcements.
SF Bay Area Cypherpunks September 2001 Physical Meeting Announcement
General Info:
DATE:   Saturday 8 September 2001
TIME:   1 - 6 PM (Pacific Time)
Location: Golden Gate Park, corner of Haight & Stanyan
"Our agenda is a widely-held secret."
As usual, this is an Open Meeting on US Soil, and everyone's invited.
The Cypherpunks Secret Cabal Meeting starts at 1:00,
so bring blankets, lunch, tape recorders, drums, etc.
The slightly-better-hidden agenda is at  or
It's the east end of the main part of the park (not counting the Panhandle.)
    Music Share-in Festival in Golden Gate Park
   Hosted by Wavy Gravy and John Perry Barlow
    EFF Music Share In
    Saturday, September 8, 2001, 2pm-5pm PT
    Golden Gate Park (corner of Haight & Stanyan)
    Join the Electronic Frontier Foundation and ten Independent bands for
    an afternoon of music supporting artists' rights. All bands performing
    grant permission for their Share - In performances to be recorded and
    shared with friends under EFF's Open Audio License. Tapers are
    encouraged and welcome.
    Ten bands will play in two stage areas in the meadow. Hosting the main
    stage are Wavy Gravy and EFF co-founder John Perry Barlow. Musicians
    performing at the event include singer/songwriter Adrian West, the
    jazzy Alex Buccat Quartet featuring Sanaz, folk/pop band Atticus
    Scout, high-altitude bluegrass string band Hot Buttered Rum, soulful
    solo performer Michael Musika, the political satirists of The Planning
    Commission, Berkeley-based party band Shady Lady, classical Indian
    instrumentalists Srini and Raja, acoustic rock performer Vanessa Lowe,
    and singer/songwriter Wendy Haynes.
    Come with friends and family! Hear great music, feast on Ben and
    Jerry's ice cream and support a great cause. Best of all, It's FREE!
    There will also be booths, t-shirts and CDs. Visit our website at:
          for more information or call +1 415-436-9333 x101
Directions: East end of the main body of the park.

@_date: 2001-09-09 00:36:44
@_author: Bill Stewart 
@_subject: Sen. Hollings plans to introduce DMCA sequel: The SSSCA  
No, you're allowed to own old PCs, though probably not to resell them.
What you can't do is reformat the hard drive, or disconnect the old one
when you buy a new one, or uninstall any software that might have
copy protection capabilities.  Lack of scienter may or may not get you
off the hook for the $500,000 fine for uninstalling software that
you didn't realize had the Hollings/Stevens code installed.

@_date: 2001-09-09 22:47:04
@_author: Bill Stewart 
@_subject: Sen. Hollings plans to introduce DMCA sequel: The SSSCA 
Only if the free operating system hasn't developed a
and paid the US government for certification,
and the machine had a pre-Hollings OS on it.
If an older machine didn't have an approved operating system on it,
or had the copy protection built into the hardware,
you could install the free OS there, but if there's already a copy of
Monopoly-Enforcing Operating System there, you can't uninstall that,
because you'd get the $500000 fine for disabling it.
         (Boy, that's a *lot* more expensive that the $2000 fine for
         disabling smoke detectors in an airplane lavatory.
         I guess copying music is more of a threat to public safety
         than airplane fires caused by smoking in the can.)
You *probably* could use Partition Magic to let you install
the free operating system in one partition while leaving the
Monopoly-Enforcing Operating System in its original partition,
but I'm not sure if you'd be allowed to boot it after you do.
You could also install Linux using a umsdos file system,
which stores Linux as files on the Microsoft file system,
but I'm not sure if you'd be allowed to boot it or not.

@_date: 2001-09-09 23:56:22
@_author: Bill Stewart 
@_subject: Compression side channel 
G3 is a single table - it's the standard used for most fax machines,
with 100x200 or 200x200 resolution.
Not sure about G4, which has higher resolution,
but I think that's the case for it also.

@_date: 2001-09-06 20:06:01
@_author: Bill Stewart 
@_subject: Cypherpunks 9/8/01 - GOLDEN GATE PARK - EFF Music Share-In 
See for SF, Toronto, Seattle, & Bangalore Cypherpunks announcements.
SF Bay Area Cypherpunks September 2001 Physical Meeting Announcement
General Info:
DATE:   Saturday 8 September 2001
TIME:   1 - 6 PM (Pacific Time)
Location: Golden Gate Park, corner of Haight & Stanyan
"Our agenda is a widely-held secret."
As usual, this is an Open Meeting on US Soil, and everyone's invited.
The Cypherpunks Secret Cabal Meeting starts at 1:00,
so bring blankets, lunch, tape recorders, drums, etc.
The slightly-better-hidden agenda is at  or
It's the east end of the main part of the park (not counting the Panhandle.)
    Music Share-in Festival in Golden Gate Park
   Hosted by Wavy Gravy and John Perry Barlow
    EFF Music Share In
    Saturday, September 8, 2001, 2pm-5pm PT
    Golden Gate Park (corner of Haight & Stanyan)
    Join the Electronic Frontier Foundation and ten Independent bands for
    an afternoon of music supporting artists' rights. All bands performing
    grant permission for their Share - In performances to be recorded and
    shared with friends under EFF's Open Audio License. Tapers are
    encouraged and welcome.
    Ten bands will play in two stage areas in the meadow. Hosting the main
    stage are Wavy Gravy and EFF co-founder John Perry Barlow. Musicians
    performing at the event include singer/songwriter Adrian West, the
    jazzy Alex Buccat Quartet featuring Sanaz, folk/pop band Atticus
    Scout, high-altitude bluegrass string band Hot Buttered Rum, soulful
    solo performer Michael Musika, the political satirists of The Planning
    Commission, Berkeley-based party band Shady Lady, classical Indian
    instrumentalists Srini and Raja, acoustic rock performer Vanessa Lowe,
    and singer/songwriter Wendy Haynes.
    Come with friends and family! Hear great music, feast on Ben and
    Jerry's ice cream and support a great cause. Best of all, It's FREE!
    There will also be booths, t-shirts and CDs. Visit our website at:
          for more information or call +1 415-436-9333 x101
Directions: East end of the main body of the park.

@_date: 2001-09-09 00:36:44
@_author: Bill Stewart 
@_subject: Sen. Hollings plans to introduce DMCA sequel: The SSSCA  
No, you're allowed to own old PCs, though probably not to resell them.
What you can't do is reformat the hard drive, or disconnect the old one
when you buy a new one, or uninstall any software that might have
copy protection capabilities.  Lack of scienter may or may not get you
off the hook for the $500,000 fine for uninstalling software that
you didn't realize had the Hollings/Stevens code installed.

@_date: 2001-09-09 22:47:04
@_author: Bill Stewart 
@_subject: Sen. Hollings plans to introduce DMCA sequel: The SSSCA 
Only if the free operating system hasn't developed a
and paid the US government for certification,
and the machine had a pre-Hollings OS on it.
If an older machine didn't have an approved operating system on it,
or had the copy protection built into the hardware,
you could install the free OS there, but if there's already a copy of
Monopoly-Enforcing Operating System there, you can't uninstall that,
because you'd get the $500000 fine for disabling it.
         (Boy, that's a *lot* more expensive that the $2000 fine for
         disabling smoke detectors in an airplane lavatory.
         I guess copying music is more of a threat to public safety
         than airplane fires caused by smoking in the can.)
You *probably* could use Partition Magic to let you install
the free operating system in one partition while leaving the
Monopoly-Enforcing Operating System in its original partition,
but I'm not sure if you'd be allowed to boot it after you do.
You could also install Linux using a umsdos file system,
which stores Linux as files on the Microsoft file system,
but I'm not sure if you'd be allowed to boot it or not.

@_date: 2001-09-09 23:56:22
@_author: Bill Stewart 
@_subject: Compression side channel 
G3 is a single table - it's the standard used for most fax machines,
with 100x200 or 200x200 resolution.
Not sure about G4, which has higher resolution,
but I think that's the case for it also.

@_date: 2001-09-15 22:22:23
@_author: Bill Stewart 
@_subject: NYC events and cell phones 
Interesting.  For the most part, TDMA encryption in the US isn't turned on;
my Nokia phone always starts off calls by telling me
"Voice Privacy Not Active", even though the encryption is even lamer than
the GSM encryption.

@_date: 2001-09-17 14:37:41
@_author: Bill Stewart 
@_subject: How to ban crypto?  
Obviously this means that the stego-mongers are sufficiently good :-)
It's not clear that EBay would be the right place to put stego,
though I suppose it's an interesting idea.
The popular method people discuss is Usenet porn spam;
another obvious approach is webcams, since they're
typically going to have pictures that aren't broadcast everywhere.

@_date: 2001-09-18 20:18:21
@_author: Bill Stewart 
@_subject: Field slide attacks and how to avoid them. 
But XDR is so BORING compared to a REAL standard like ASN.1!
It doesn't have infinite possibilies for object definitions
requiring help from standards committees, multiple incompatible
data representations with different kinds of ambiguity,
or ugly API packages that are too large to believe that the
implementers debugged them adequately.  That's just no fun at all!
         (I realize it doesn't do everything in the world,
         or have all the power, expressiveness, or bit-twiddling
         that ASN.1 or even PGP/OpenPGP data formats have,
         but there's a lot to be said for something that's minimal and works.)

@_date: 2001-09-20 18:06:33
@_author: Bill Stewart 
@_subject: chip-level randomness? 
Using the Intel hardware RNG to seed /dev/random at startup
provides valuable help for some problems I've had under Linux.
I suspect other Unix-like systems have similar problems.
It should be done VERY early in the boot process,
just in case anything else needs randomness.
When you first boot a new machine, e.g. after installing a new
operating system or disk, the system tries to start the daemons
like sshd before there's been an opportunity for user input,
so there's no real randomness in /dev/random except for
a few bits from disk drive motion.  If the system realizes this,
some of those daemons may stall, which is much more annoying at boot;
if not, they'll start with inadequate entropy, which is very bad.
Some machines can get out of this by sampling /dev/audio,
but machines without sound cards can't do this.
Similarly, if the ethernet drivers have been started,
it's possible to get some entropy from the timing
as well as the content, though many people don't trust this,
and the cards may not always be present, especially on dialup machines.
But using the Inter chipset RNG if it's present takes care of the problem.
                 Bill Stewart

@_date: 2001-09-30 01:16:38
@_author: Bill Stewart 
@_subject: New encryption technology closes WLAN security loopholes 
Depends on the environment, and on your willingness to pay.
Using the Nortel Contivity software on Windows is really straightforward,
as long as you're only using passwords for authentication and not
fancy stuff like SecureID tokens.  The client end is just a
typical Windows-Installer thing that you feed a couple of parameters,
and the server end is a box that you need to administer.
I don't know that they've integrated it with any 802.11 systems yet -
you probably need a separate base station.
More to the point, if you've got a laptop with an 802.11 card in it,
and you plug it into the LAN in a building where you don't have 802.11,
then you're a potential security risk (though windows usually doesn't
do much in the way of routing, so the 802.11 is mostly a client thing.)

@_date: 2002-04-26 01:16:04
@_author: Bill Stewart 
@_subject: Lucky's 1024-bit post [was: RE: objectivity and factoring 
*Something* has to be the weakest link; calls for balance really come down to
"If Algorithm A is already the stronger part of the system,
why should I waste extra time/work strengthening it instead of Algorithm B?".
It doesn't hurt to make parts of the system stronger than necessary,
unless there are other costs like limiting the sizes of the other keys
that can fit in a UDP packet or whatever.   And making the AES algorithm
use longer-than-needed keys gives you some extra insurance against
mathematical breakthroughs or other sorts of discovered weaknesses.
The important issue about whether you can use X-bit block cyphers with
Y-bit public-key cyphers is whether Y bits of PK can give you X good key bits.
For Diffie-Hellman, the conventional wisdom seems to be that
Y bits of public key gives you Y/2 bits of usable keying material,
which means that 1024-bit DH is good enough for 256-bit AES.
For RSA, I think you can protect almost up to pubkeylength bits of message,
since the key generation happens separately from the public-key parts,
but you're definitely into overkill range.
So the question falls back to "Is 1024 bits long enough?".

@_date: 2002-08-28 23:00:16
@_author: Bill Stewart 
@_subject: Palladium and malware 
Hey, that's clever.  If the Palladium and/or TCPA stuff is designed
generally enough that anybody can use it, then certainly
malware authors can do so just about as well as copy-protection-ware
authors or spyware authors can.  (If it's designed so that
only Officially Licensed Trusted Developers can have the keys they need,
then malware authors will have to write their code the old-fashioned way.)
The more interesting question, I suspect, is how much access a
TCPA or Palladium program has to the surrounding environment -
is it a platform that makes it easy for the consumer to trust programs
written to run on it not to mess up their machines,
or is it *only* to let authors trust the machines not to
examine or change their programs?

@_date: 2002-12-09 00:57:11
@_author: Bill Stewart 
@_subject: DBCs now issued by DMT 
There are two main reasons honest people start banks -
- either they want to make a profit / gain control / etc.
- or else they want to get banking services with some
         predictability they're not finding in the commercial market,
         e.g. in the US, this is a Credit Union,
         or in many cultures, this is some family or private
         group that lends money to each other.

@_date: 2002-02-04 10:20:58
@_author: Bill Stewart 
@_subject: Welome to the Internet, here's your private key 
> From: 	Jaap-Henk Hoepman[SMTP:hoepman at cs.utwente.nl]
 >
 > It's worse: it's even accepted practice among certain security
 > specialists. One of them involved in the development of a CA service
 > once told me that they intended the CA to generate the key pair.
 > After regaining consciousness I asked him why he thought
 > violating one of the main principles of public key
 > cryptography was a good idea. His answer basically ran as follows:
 > if the CA is going to be liable, they want to be sure the key is strong
 > and not compromised. He said that the PC platform of an ordinary user
 > simply wasn't secure/trusted enough to generate keys on.
 > The system might not generate `good enough' randomness,
 > or might have been compromised by a trojan.
If the system is compromised by a trojan, then the user is
already toast, and storing the private key on the machine
is just as dangerous as generating it there.
Giving the user a smartcard to run everything on,
as Peter Trei suggested, is a partial fix, though a sufficiently
targeted trojan may be able to trick the smartcard into
signing or decrypting things that it shouldn't.
Randomness quality could be a genuine issue.  The solution to that
is not to give the user the key - it's to give the user a string
of officially strong random numbers and have them type that in
to the key generator along with waving their mouse and
other randomness generation techniques, and the risks from
compromise if somebody eavesdrops on the transmission of the
random number are much less serious than eavesdropping on the key.
There are special cases where the user's machine doesn't have
the CPU horsepower to generate a key - PCs are fine,
but perhaps Palm Pilots and similar handhelds are too slow
(though a typical slow 33MHz 68000 or Dragonball is faster
than the 8086/80286 MSDOS machines that PGP originally ran on.)
Cash machines may be too slow, but they normally run symmetric crypto.
A smartcard-only system probably _is_ too limited to generate keys,
but that's the only realistic case I see.

@_date: 2002-02-09 18:52:40
@_author: Bill Stewart 
@_subject: Welome to the Internet, here's your private key 
There are three different cases
- Active malicious tampering by the user
- Inadequate key generation capabilities on the user's machine,
         e.g. weak randomness, too little memory, too slow CPU
- User's machine is compromised by some untrustable third party.
In the third case, you were toast anyway.
In the first case, what can malice accomplish that's different for a
         user-generated key as opposed to a CA-generated key?
         The malicious user could already give away his private key,
         and giving the CA a key generated by someone else to certify
         is pretty much equivalent to giving away the key.
The second case appears to be the interesting one.  There may be limited
         environments where the user's system doesn't have enough CPU or RAM
         (though someone else replied that even smartcards are often smart          but certainly for anything as smart as a Palm3,
         it's basically just a one-time startup delay.
         The way to fix inadequate randomness is not to have the CA generate the key,
         it's to have the CA generate a bunch of randomness and
         send it to the user's system to input it in the key generation          If you're worried that the user might not bother to enter the
         randomness into the CA-supplied key generation program,
         have the program check that the user entered enough characters,
         or even use a checksum on the user-entered characters.
         If you're worried about Man In The Middle attacks on the
         CA-supplied randomness, you could digitally sign it, though
         that's a bit long-winded for user-typed strings
         unless you use Elliptic Curves or some similar short-signature
         method or use an HMAC or something.
Are there any other cases in which the CA needs to generate the key
for legitimate reasons, as opposed to because the CA wants access to
the user's private key for later purposes?

@_date: 2002-02-13 01:54:51
@_author: Bill Stewart 
@_subject: Announce: San Francisco Cypherpunks, Sat 2/16/02, 6pm - 225 
This announcement will be at and is being sent to several cypherpunks-related mailing lists.
The San Francisco Bay Area Cypherpunks Meeting will be
Saturday, February 16, 2002, at Don Ramon's Restaurant, 225 11th St, San As usual, this is an open public meeting on US soil.
Everyone's invited, including non-US-citizens, and several suspected Canadians
will be present :-)
Our agenda is a widely-held secret.
Predicted topics include Intrepid Traveller Bill Scannell's trip to Cuba,
discussion of the crypto and data-sharing presentations from Codecon,
potentially a couple of projects that were too late for Codecon,
and generally what everybody's been doing and working on.
The unusual time and place are because the Codecon conference will be a block away at the DNA Lounge  Friday-Sunday and the RSA conference will be at the San Jose Convention Center the following week.
A number of cypherpunks will be speaking at Codecon (See people.html and The RSA Conference appears to have decided to protect their agenda through you can obtain PDFs of the agenda from their website if you have Multimedia Flash :-)
Codecon is a low-priced conference; RSA has high-priced talks, low-priced and the usual vendor parties.
=================== DIRECTIONS AND PARKING ====================================
Don Ramon's Restaurant - Look for Usual Suspects, probably upstairs.
Directions: 	225 11th St. is a block north of the DNA Lounge,
 From the South Bay:
 From the East Bay:
onto 11th.
By Public Transit:
and Hyde),
Parking is easy for once:  Ample public parking is available at the Costco parking lot,

@_date: 2002-01-09 09:41:35
@_author: Bill Stewart 
@_subject: Cypherpunks 011202 at Stanford:  Corrected - it's January 12, 
Several people have suggested that I shouldn't edit these things
when I'm not awake; sorry about that :-)
See  for corrected Anyway, the meeting is definitely Saturday, January 12, 2002,
at Stanford in the coffeehouse in Tresidder.
And we'll be planning for the February 16th meeting,
which will be during Codecon and just before RSA.
If you get lost, or have questions, comments or last-minute agenda
requests, please contact your friendly meeting organizers:
  Dave Del Torto    Cell: +1.415.730.3583
  Bill Stewart     Cell: +1.415.307.7119

@_date: 2002-01-09 01:07:10
@_author: Bill Stewart 
@_subject: Cypherpunks 011202 at Stanford: Anti-Terrorism & Security 
See  for subscription help and
  Cypherpunks meeting announcements from around the world.
SF Bay Area Cypherpunks
January 2002 Physical Meeting Announcement
GENERAL INFO:
   DATE:  Saturday 13 October 2001
   TIME:  1-5 PM (Pacific Time)
  PLACE:  Tressider Student Union
          Stanford University Campus
          Palo Alto, California, USA
Instead of our usual outdoor location, we'll be meeting inside the
coffeehouse adjacent to the courtyard.
"Our agenda is a widely-held secret."
As usual, this is an Open Meeting on US Soil, and everyone's invited.
One of the main topics of discussion will be planning for
March's meeting, which will be on the THIRD Saturday of the month,
just before the RSA tradeshow,  ,
and approximately simultaneous with Codecon
which is Bram's conference about actual running code,
primarily focused on crypto and peer-to-peer applications.
Known foreigners suspected to be in town include Ian Goldberg.
Collateral Damage -
    The Stanford meeting location will be familiar to those who've been to our
    outdoor summer meetings before, but for those who haven't been, it's on the
    Stanford University campus (in Palo Alto, California), at the end of
    Santa Theresa, at the tables outside Tressider Union, just west of
    Dinkelspiel Auditorium.
    We'll meet inside the coffee store adjacent to the courtyard.
    Food/beverages are available at the cafe and mini-market inside.
    Location Maps:
    Tressider Union (overview):
          Tressider Union (zoomed detail view):
          Printable Stanford Map (407k).
          GPS Coordinates: 37d23:40 N 122d04:49 W
If you get lost, or have questions, comments or last-minute agenda
requests, please contact your friendly meeting organizers:
  Dave Del Torto    Cell: +1.415.730.3583
  Bill Stewart     Cell: +1.415.307.7119

@_date: 2002-01-15 00:42:56
@_author: Bill Stewart 
@_subject: [PLANNING FEB CPUNKS]  Who's going to be in the Bay Area in 
The RSA Conference will be in San Jose the week of Feb 18-22.
As usual, that means a lot of cypherpunks will be in town,
and we move the meeting to whichever weekend works best.
This year, that's Saturday the 16th, and it's Presidents' Day Weekend.
It's also Codecon 2002   , a conference on
peer-to-peer, crypto, and similar applications,
designed for presentations about actual working code.
The conference will be at the DNA Lounge, 375 11th St, San Francisco.
The not-totally-firm plans are to have the cypherpunks meeting
at Codecon on Saturday afternoon (the conference is Friday-Sunday).
Bram (the conference organizer) will probably be able to comp us attendance
(the full conference is $50), but he needs to do a schedule.
Some of the crypto projects being talked about include Cryptomail
and Zooko talking about Mojo Nation derivatives.
Who's going to be in town that weekend?
Would you like to speak at the Cypherpunks meeting,
either as an organized talk or as a works-in-progress session?

@_date: 2002-01-24 23:11:44
@_author: Bill Stewart 
@_subject: RSA Attacks - Talk at Stanford - 1/28/2002 4PM (fwd) 
Looks like an interesting talk!
---------- Forwarded message ----------
                        Algebraic Cryptanalysis
                             Glenn Durfee
                    Department of Computer Science
                          Stanford University
                        Gates Building, Room 498
                        Monday, Jan. 28th, 2002
                           4:00 PM - 5:00 PM
In this talk we study the security of the widely-used RSA public key
cryptosystem.  RSA is used in the SSL protocol for security on the
Internet, and the SET protocol used by Visa for secure credit card
transactions.  This talk outlines several cryptanalytic results on the RSA
public key cryptosystem and variants.  We obtain our results using tools
from the theory of integer lattices.
We begin by introducing a novel algorithm for the factorization of a
class of integers related closely to RSA moduli, showing a new class
of integers can be efficiently factored.  We go on to introduce
new attacks on the RSA public key cryptosystem which take advantage of
partial knowledge of a user's secret key, showing that in low public
exponent RSA, leaking the quarter least significant bits of the secret key
is sufficient to compromise RSA.  Similar results (though not as strong)
hold for larger values of the public key.  Next we describe a new attack on
the RSA public key cryptosystem when a short secret exponent is used,
extending previous bounds for short secret exponent vulnerability.  Lastly,
we describe the Sun-Yang-Laih RSA key generation schemes, and introduce
attacks to break two out of three of these schemes.

@_date: 2002-01-27 22:45:22
@_author: Bill Stewart 
@_subject: Attacks using Pure Text (Was: Re: Results, not Resolutions) 
Email viruses were not impossible with text-only email.
ASCII text is probably much safer today than it was 20 years ago,
because there are far more systems that try to render it,
and almost all of them do less interpretation than they did back then,
when we usually read email on "dumb terminals", preferably the
smartest dumb terminals we could find.  Before everything standardized on ANSI,
lots of terminals, particularly the HP 262x series and the DEC VT100s,
had features that would let you hand escape sequences to the terminal
that would not only change fonts, move the cursor, clear the screen, etc.,
but could also program function keys and execute function keys.
So it was possible to send somebody email that would cause their terminal
to transmit a limited number of characters to the computer as if the
user had typed them, which opened a variety of security holes.
Also, one of the "talk" programs would write directly to another user's
terminal if the permissions were set to the default world-writable.
There was an article in the SF Chron or Oakland Trib in spring 1979
saying that "hackers at Berkeley" had broken the security of
"the Unix, a computer made by DEC", which was really about one of these
escape-sequence exploits, probably for VT100s.  It was tough to do much,
but if you guessed what mail reader the person was using,
you could fake keystrokes for "exit mail, run something dangerous",
especially if you first sent the victim a file using UUCP.
I don't think anybody built a virus this way, since we weren't
really virus-aware at the time, but some people probably sent
password-stealers this way.
And it was easy to do a "shut down or hose up the victim's terminal" attack.
Unfortunately, the escape sequence for bold-face on one popular terminal
would hose up another popular terminal, so it wasn't always deliberate -
there were often flames on Usenet about people posting formatted articles
(commonly recipes on rec.cooking) with dangerous escape sequences in them.
A much cruder denial-of-service attack was to send +++ or other
modem-control characters, which could disconnect a Hayes-style modem.
These days, almost all of the terminal emulation programs
either just run totally dumb text, or run some subset implementation
of ANSI or the very similar DEC VT100, and most of those emulators
haven't bothered implementing the fancier features.
Another text-only attack was magic sequences for text editors like vi
(and perhaps emacs?) which would look for option-setting commands
in the beginning or end lines of files.  The purpose was to allow
comments in C code that would turn on C-related editor options,
comments in Lisp code that would turn on lisp-related options, etc.
This was eventually realized to be a security risk, so
"nomodelines" became the default in vi.
Of course, the most successful text-only attack was the "Good Times" virus,
which worked by infecting the wetware of the operator :-)
Yup.  Designing code for hostile and bogus input was about the
third lesson in CS100, after "Comment everything" and "The One True Indent and well before anything fancier than arrays and loops.
But enough code doesn't do that that it's important to use
operating system protections as well.

@_date: 2002-07-03 22:54:43
@_author: Bill Stewart 
@_subject: Ross's TCPA paper 
It can?  I thought that DMA was there to let you avoid
bothering the CPU.  The Alternate NIC card would need to have a
CPU of its own to do a good job of this, but that's not hard.
There's also the difficulty that, while it might be good at DRM,
it might or might not be good at letting users write programs
that are good at security.  It's certainly never been a Microsoft specialty.

@_date: 2002-06-28 09:51:09
@_author: Bill Stewart 
@_subject: DOJ proposes US data-rentention law.  
[more examples of expensiveness deleted; fibre channel, etc.]
You're not making appropriate technology choices,
so your costs are off by a factor of 5-10.
IDE is just fine, especially in RAID configurations,
because if you're making a scalable system, you can use as many spindles
as you need, and you don't need to run fully mirrored systems - RAID5 is fine.
Almost any technology you get can run 5MB/sec, which is T3 speeds,
so that RAID5 system can keep up with an OC3 with no problem.
Disk drive prices here in the US are about $1/GB for IDE.
The problem is that's about 200 seconds of T3 time, so your 5 100GB drives
will last about a day before you take them offline for tape backup.
The real constraints become how fast you can copy to tape,
i.e. how many tape drives you need to buy, and what fraction of data you keep.
If it's 1%, you can afford it - adding $5/day = $150/month per T3 is just Keeping 10% of the bits - $50/day = $1500/month/T3 -
is a non-trivial fraction of your cost, so you have to go for tape.
Fibre channels are useful for cutting-edge databases on mainframes,
and have the entertaining property that they can go 10-20km,
so you've got more choices for offsite backup, but GigE is fine here.
Make sure you also keep a couple of legacy media devices so you can
give the government the records they want in FIPS-specified formats,
such as Hollerith cards and 9-track tape.....

@_date: 2002-03-25 20:25:28
@_author: Bill Stewart 
@_subject: 40 teraflops (fwd) 
Unfortunately, the article that Bob Hettinga excerpted from the
South China Morning Post is a pay-only article.
 <- Japanese government site.
 <- Good page
 <- The ES center
 <- Pictures.
Here are a couple of articles from 2000 about how cool the machine will be:
  <- NEC press release
   <- Some technical detail
Cool lecture by Jack Dongarra (a name you should know)
overview of high-performance computing.  Spring 2002 CS594 UTenn.
"Most Important Slide" is the pointer to The other reference site for this stuff:  Article about Google doing work on parallel projects

@_date: 2002-03-25 23:39:21
@_author: Bill Stewart 
@_subject: 1024-bit RSA keys in danger of compromise 
While SSL implementations are mostly 1024 bits these days,
aren't PGP Diffie-Hellman keys usually 1536 bits?

@_date: 2002-05-09 18:46:25
@_author: Bill Stewart 
@_subject: Bay Area Cypherpunks - Claremont Hotel, Saturday May 11, 2002, 
See for San Francisco and other Cypherpunks announcements.
Because of mailing list problems, I'm sending this to the cryptography list
as well as meetingpunks and cypherpunks; sorry about any duplications.

@_date: 2002-05-30 00:37:47
@_author: Bill Stewart 
@_subject: FC: Hollywood wants to plug "analog hole," regulate A-D 
om>
If you don't see the fnords, they won't eat you....
         (ok, that's more of a cypherpunks remark :-)
Watermarked background music as recording prevention, billboards and
buttons with watermarks on them for digital camera repellent,
all pretty unlikely to actually work,
but that doesn't mean that laws won't imply that they must.
"These aren't the cypherpunks you're looking for..."

@_date: 2002-11-15 23:24:06
@_author: Bill Stewart 
@_subject: Public Key Addressing? 
Abstract: Maybe he's saying that phone calls could be implemented
like remailers or onion routers, or at least like ipsec tunnels,
where the contents of the call are kept separate from the
signalling information, so the ISPs only see what they need to.
I can think of a couple of things, some of which I even understand :-)
Please excuse the brief explanation of telephony terms first:
There have been several popular approaches to telephone signalling
over the years, which have different security levels against
eavesdropping and manipulation by different users
- Step-by-step transmits the signalling along with the call,
         and each piece of equipment uses a digit to route the
         audio channel for the call to the next piece of equipment,
         but ignores everything else except call tear-down signals.
         (Nobody does this any more....)  Phone Phreaks liked this.
         Eavesdroppers can listen to future signalling and audio.
- Stored-program-control in-band signalling sends the call setup
         information in the same channel as the call (either as
         audio tones or electrical dial pulses, or "robbed bits" in the US),
         but the first switch receives all the digits,
         makes some decision about where to send the call,
         and if the next step is a stored-program switch,
         sends the (possibly translated) signalling information
         to the next switch, followed by the audio call.
         (If the next step is a phone, it sends ring tones,
         and if the next step is step-by-step, it sends
         individual step signals at a standard speed.)
         Phone Phreaks liked this also!
- Common-channel signalling sends call-setup instructions along
         a data network, which tells the control interfaces of
         voice switches to connect an audio channel.
         This obviously requires stored-program-control switches.
         Phone phreaks didn't like this unless they were really expert.
         Signalling System 7 (SS7), CCIS, and CCS were versions of this.
         Most modern telephone company switches work this way.
- ISDN has signalling protocols that use data carried along with a
         group of audio-or-user-data channels.  (1 or 2 data + 2, 23 or 30          In telephone company networks, ISDN is commonly used as an
         interface from the user to the telephone company,
         which uses common-channel signalling to complete the call
         to its destgination (or at least to the last intelligent
         common-channel signalling switch in the path,
         then either ISDN or in-band audio or step-by-step,
         depending on how obsolete the phone switches at the destination are.)
         In customer-owned networks, such as business PBXs,
         the trunks between switches might also be ISDN,
         which would carry the signalling in the data channels
         in the same group as the voice channels.
Another digression - in US wiretapping law, a "pen register" is
a device that detects the signalling information on a customer's
telephone line, and records the signalling but not the audio.
(Originally, this used moving pens and paper to show the electrical
impulses from pulse dials.)  Unfortunately, US courts decided that
pen registers don't record private information, because the user
is telling the telephone company who they want to talk to,
which is therefore "public" information, so it should not receive
the same legal protection as wiretaps that actually listen to the
speech part of a telephone call.  Another unfortunate consequence
is that every time somebody develops a new technology for
eavesdropping or wiretapping, the police try to claim that it is
like a pen register, not a real wiretap, and every time somebody
develops a new communication medium, the police try to claim that
it's not like a private telephone call that has some legal protection,
or a person-to-person conversation or personal papers that have
more legal protection, but instead is only like radio which is public,
or like the parts of a telephone system that only need a pen register,
not a real wiretap.
So here is my guess about what the professor might mean:
- In a normal telephone call, the caller tells the phone company
         what telephone number he wants to call, and everybody
         who helps set up the call can see that caller and called person,
         even if they are only in the middle and not connected to
         either the caller or the called person.  Also, eavesdroppers
         who can see one part of the signalling know everything.
         (Similarly, with unencrypted email, everybody who carries it
         can see the origin and destination in the message body,
         though some equipment only sees the destination.)
- If you wanted to, you could build a telephone system where
         the signalling used public-key crypto, where the
         address used to send call setup information to a
         switch is different from the addressing that that switch
         sends to the next switch, so each piece only knows the
         next hop and not the whole path, but unlike the old
         step-by-step switches, eavesdroppers who compromise
         one switch or one trunk can't see the unencrypted
         signalling information, and therefore don't know
         which call they're tapping.  Furthermore, the forward
         direction of a phone call can be isolated from the
         reverse direction of a call, so eavesdroppers only see
         half a phone call.  This makes it much harder
         to use wholesale wiretaps to look for Usual Suspects,
         and means that wiretapping somebody's line may tell you
         when they receive a phone call but not who it's from.

@_date: 2002-10-01 16:36:51
@_author: Bill Stewart 
@_subject: Real-world steganography 
Traditional digital telephone signalling uses a "robbed-bit" method that
steals the low-order bit from every sixth voice sample to carry information
like whether the line is busy or idle or wants to set up a connection.
(That's why you only get 56kbps and not 64kbps in some US formats,
since it doesn't want to keep track of which low bits got robbed.)
In a sense both of these are steganography, because they're trying to
hide the data channel from the audio listener by being low level noise
in ways that equipment that isn't looking for it won't notice.
That's not really much different from encoding Secret Data in the LSB
of uncompressed graphics or audio - it's about the second-crudest
form of the stuff, and if you think there are Attackers trying to
decide if you're using stego, you need more sophisticated stego -
at minimum, encoding the stegotext so it looks like random noise,
or encoding the stegotext with statistics resembling the
real noise patterns, or whatever.  The definition of "hidden writing"
doesn't specify how hard you tried to hide it or how hard the
Attacker is looking - you need to Bring Your Own Threat Model.
Since I don't speak Audiophile Engineering / Human perceptual modelspeak,
which the paper was written in, I wasn't able to figure out where the
HDCD stuff hides the extra bits.  Are they really there (in the CDROM's
error-correction bits or something)?  It sounded like they were either
saying that they make part-time use of the one LSB bit to somehow encode
the LSB and 4 more bits, which sounded really unlikely given that there
weren't any equations there about the compression models, or else that they
had some perceptual model and were using that to make a better choice of LSB
than a simple 50% cut-off of the A-to-D converter (more absolute distortion,
but better-sounding distortion.)  Or did I miss the implications of the
reference to oversampling and the real difference is that HDCD disks
really have more pixels on the disk with only the LSB different,
so a conventional reader reads it fine but needs the ECC to get the LSB?
A separate question is - "so is there some internet-accessible list of
disks using HDCD, or do I just have to look at the labels for a logo?"

@_date: 2002-10-02 00:22:07
@_author: Bill Stewart 
@_subject: What email encryption is actually in use? 
I'm running Win2000 in "You're Not The Administrator" mode.
Since somebody else is root and I'm not, the fact that
my network admins could eavesdrop on my link traffic
isn't a big deal, especially when they set up my PC's software.
And if I do pretend to trust my machine against some insiders,
I can use SSH, SSL, and PGP to reduce risks from others...
Also, STARTTLS can reduce eavesdropping at Alice's ABC.COM.
If your organization is an ISP, the risks are letting them
handle your email at all (especially with currently proposed
mandatory eavesdropping laws), and STARTTLS provides a
mechanism for direct delivery that isn't as likely to be blocked
by anti-spamming restrictions on port 25.
Now to get some email *clients* using it.
On the other hand, if your recipient is at a big corporation,
they're highly likely to be using a big shared MS Exchange server,
or some standards-based equivalent, so the game's over on that end
before you even start.  Take the STARTTLS and run with it...
Defense in depth is important for real security.
STARTTLS can be a link-encryption solution,
but it can also be part of a layered solution,
and if you don't bother with end-to-end,
it's a really good start, and isolates your risks.
It also offers you some possibility of doing certificate management
to reduce the risk of man-in-the-middle attacks from
outside your organization, and does reduce some traffic analysis.
If your goal is to encrypt 20% of the net by Christmas,
STARTTLS will get a lot closer to that than a perfect system.
Similarly, IPSEC using the shared key "open secret"
would have been a much-faster-deployed form of opportunistic
encryption than the FreeSWAN project's more complex form
that wants some control over DNS that most users don't have.
In the absence of a real Public Key Infrastructure,
neither is totally man-in-the-middle-proof,
so if the Feds are targeting *you* it's clearly not enough,
but reducing mass-quantity fishing expeditions increases
our security and reduces the Echelon potential -
especially if 90% of the encrypted material is
routine corporate email, mailing lists, Usenet drivel, etc.
You can protect most of the path if your firewalls don't interfere,
and more if your recipients' don't.

@_date: 2002-10-03 16:49:06
@_author: Bill Stewart 
@_subject: Gaelic Code Talkers 
There's at least one Celtic-related code story from Bletchley Park,
though its not a Gaelic or code-talker one.
One of the intelligence honchos was referred to as "C"
rather than by name (a practice later picked up by James Bond stories.)
One Scottish worker there didn't follow the practice,
and was chewed out for it, and replied along the lines of
"Well, Mr Menzies, if you don't want people to refer to you by
your family name, you shouldn't be wearing a kilt in your family tartan"....
(I think the source was Robin Winks's book....)

@_date: 2002-09-23 22:35:53
@_author: Bill Stewart 
@_subject: unforgeable optical tokens? 
But if you're trying to use the card in
two-players-competing mode, as opposed to just
"I've got a card you don't have" mode,
how do you decide who wins?
Where are they on the roshambo scale of

@_date: 2002-09-28 09:56:46
@_author: Bill Stewart 
@_subject: RSA's RC5-64 Secret Key Challenge has been solved. 
That might make this a good time to attack the 64-bit version,
at least if there's been enough cryptanalysis done for the
attack to be realistic.

@_date: 2003-04-04 17:10:02
@_author: Bill Stewart 
@_subject: Logging of Web Usage 
Also, until recently, there was the problem that storing a hash value
for every IP address took 8-10 bytes * 2**32, and the resulting 32-40GB
was an annoyingly large storage quantity, requiring a deck of Exabyte tapes
or corporate-budget quantities of disk drive, which also meant that
sorting the results was also awkward.  These days, disk drive prices
are $1/GB at Fry's for 3.5" IDE drives, so there's no reason not to have
120GB on your desk top.
This does mean that if you're keeping hashed logs you should probably
use some sort of keyed hash - even if you don't change the keys often,
you've at least prevented pre-computed dictionary attacks over the
entire IPv4 address space, and the key should be long enough (e.g. 128 bit)
so that dictionary attacks on the "IP addresses of Usual Suspects"
also can't be precomputed.
A related question is keeping lists of public information,
e.g. don't-spam lists, in some form that isn't readily abusable,
such as hashed addresses.  The possible namespace there is much larger,
but the actual namespace isn't likely to be more than a couple of billion,
in spite of the number of spammers selling their lists of 9 billion names.
There's the question of how exact a match do you need -
if mail is for alice+tag1 at example.com, you'd ideally like to be able to check
alice+tag1 at example.com, alice at example.com, and which makes the lookup process more complex.

@_date: 2003-04-09 00:20:21
@_author: Bill Stewart 
@_subject: Swiss ISPs Required to Log and Store Email for Six Months 
SWISS ISPS MUST LOG AND STORE CONSUMERS' EMAIL DATA
As of April 1, Swiss ISPs will have to keep a log for six
months of all the emails sent by their customers.  Experts
criticize the measure, saying it will be both difficult and
costly to implement.
The law was passed in January 2002, and ISPs had until April 1 to implement.
Does anybody know if this only applies to email providers,
or exactly what kinds of email providers,
or if it also requires ISPs who provide IP transport to eavesdrop it?
What about businesses providing email for their employees and other users?
How much of the Swiss email business will be driven out of the country,
either to US email providers or European providers like Wanadoo and Tiscali?
And does anybody know if they have to keep _all_ the spam?
Or is keeping one copy of each enough?
Or can they give their customers _some_ privacy protection by
always giving the authorities all of the spam in addition to
whatever they really wanted?

@_date: 2003-04-09 11:38:36
@_author: Bill Stewart 
@_subject: Trusted Computing Group trying to be TCPA follow-on [eetimes] 
New group aims to secure PCs, PDAs, cell phones
By Rick Merritt, EE Times
April 8, 2003 (2:20 p.m. EST)
URL: SAN MATEO, Calif. ? Fifteen companies announced Tuesday [April 8] they have formed the Trusted Computing Group, an industry initiative to define and promote a specification for security in PCs, servers, PDAs and cellphones.
The group essentially reboots the efforts of the now-disbanded PC-centric Trusted Computing Platform Alliance (TCPA), this time including participation from Nokia and consumer electronics companies such as Sony and Philips.
The Trusted Computing Group (TCG) expects to release a specification for PC security before the end of the year. A spec for cell phones, however, could be as much as two years away.
Founding members of the TCG are carryovers from the earlier 190-member TCPA effort. They include AMD, Hewlett-Packard, IBM, Intel and Microsoft. Contributing members include Atmel, Infineon, National Semiconductor, Nokia, Philips, Phoenix Technologies, Sony, ST Microelectronics, VeriSign and Wave Systems.
The TCPA defined a trusted platform module (TPM), a basic device with encryption and secure memory capabilities to oversee PC security. However the TPM 1.1 chips now shipping from companies such as Atmel, Infineon and National Semiconductor have not been widely adopted to date and do not conform to concepts for a secure PC execution mode recently defined by Microsoft under a program it called Palladium.
The TCG is defining a specification for a 1.2 version TPM and a software stack that will work with the Palladium architecture Microsoft developed in collaboration with Intel Corp. and Advanced Micro Devices. Microsoft will detail this approach publicly for the first time at the Windows Hardware Engineering Conference in May.
Microsoft's implementation, which it now calls the Next Generation Secure Computing Base (NGSCB), will require new logic in several PC components including processors, chip sets, graphics processors and I/O devices. Indeed, the concept for a secure operating mode is so broad Microsoft will devote an entire track at WinHEC ? about 18 hours of content ? to describing it.
Microsoft has not said, however, when it will ship software that complies with NGSCB. Industry watchers expect that code will appear late next year or early in 2005 in the next major version of Windows, dubbed Longhorn.
The security scheme will work in conjunction with processor functions Intel Corp. calls Le Grande Technology and has embedded in its next-generation Pentium processor dubbed Prescott, expected to ship later this year. AMD will also support the PC security concepts in its processors though it has not indicated when.
The TPM 1.2 modules will include a new session encryption interface and secure state counters that prevent replay security attacks, said Stephen Heil, a technical evangelist for security at Microsoft. The TCG has separate working groups defining those modules, a security software stack and particular needs for both servers and PDAs. The TCG is about to launch a working group to define a specification for secure cellphones, an effort that could take 18 to 24 months. Nokia is expected to be a key contributor to that group in addition to other members still being recruited by the TCG.
?I would expect to see our membership broaden to include many of the players required for that effort,? said Geoffrey Strongin, a security specialist at AMD.
Jim Ward, chair of TCG and a security specialist with IBM, said the group would like to create other specifications for platforms such as set-top boxes and video game consoles though no active efforts are currently underway. ?We are looking to develop a broad specification that can be used by a broad set of products,? he said.
?The industry is coming together,? said John Hull, director of marketing for advanced PC products at National Semiconductor.
?We are thoroughly convinced that the future of the PC rests on three legs: networking, security and manageability. You will have to have all three to play in PCs going forward,? he added.
Hull said he expects TPM module makers will update their products to comply with the new security spec when Prescott processors roll out this fall. Further in the future, the modules could be integrated into existing PC components such as SuperI/O parts that provide legacy support for serial, parallel, keyboard and floppy controllers.
?IBM is about the only company in production with systems using the [standalone] TPM 1.1 devices as far as I know,? said Hull.
Ward said IBM has shipped millions of TPM devices in its PC systems. An HP spokesman said the company has not yet shipped systems with the modules which typically cost about $5.
?We have to increase the rate of adoption. That's why integration with Super I/O makes a lot of sense. We think this will be a checkbox item going forward,? Hull added.
As a legally incorporated group, the TCG will enforce reasonable and non-discriminatory licensing of any intellectual property in the spec and define a mechanism to certify compliance to it. The group is also expected to take a more pro-active approach than its predecessor to addressing controversial issues about privacy and digital rights raised by the PC security effort.

@_date: 2003-04-10 11:33:11
@_author: Bill Stewart 
@_subject: Intel RNG still available? 
It's more like looking for a car with anti-lock braking or
passenger-side airbags (if those features hadn't caught on).
Carl wasn't looking for those chips just because they're chips,
he was looking for the feature, and that was the only implementation of them.

@_date: 2003-08-22 02:44:26
@_author: Bill Stewart 
@_subject: PRNG design document? 
Go look at "Yarrow",
and also the discussions about /dev/random and /dev/urandom
(or at least their documentation.)
As far as "definitive", that depends a lot on what you're
trying to accomplish by designing a new system.

@_date: 2003-12-12 10:32:16
@_author: Bill Stewart 
@_subject: Revision of US Crypto Export Controls 
It's nice to see that, five+ years after the DES crack and
         a month after the RSA-576 challenge was broken
         (and rather longer since 512-bit cracks),
         and as spread-spectrum phones and data cards are under $50
         and wireless security has become a major industry concern,
that our government still cares enough to protect us by
limiting export of those technologies so the Commies don't get them...
I guess the FreeS/WAN project still needs to stay outside the US.
         Bill Stewart

@_date: 2003-12-14 12:21:45
@_author: Bill Stewart 
@_subject: example: secure computing kernel needed 
Agreed.  It's a better argument for booting from a known CDROM distribution.

@_date: 2003-12-20 14:36:34
@_author: Bill Stewart 
@_subject: Difference between TCPA-Hardware and a smart card (was:  
Of course, at this point the assertion that a smart card
(that doesn't also have independent user I/O)
costs enough to care about is pretty bogus.
Dumb smartcards are cost-effective enough to use them
to carry $5 in telephone minutes.
The real constraint is that you're unlikely to have
more than one card reader in a machine,
so multifunction cards provide the opportunity to
run multiple applications without switching cards in and out,
but that only works if the application vendors cooperate.
For instance, you may have some encrypted session application
that needs to have your card stay in the machine during the session
(e.g. VOIP, or secure login, SSH-like things, remote file system access),
and you may want to pay for something using your bank smartcard
during the session.  That's not likely to work out,
because the secure session software vendors are
unlikely to have a relationship with your bank that lets
both of them trust each other with their information,
compared to the simpliciy of having multiple cards.

@_date: 2003-12-28 23:13:56
@_author: Bill Stewart 
@_subject: Microsoft publicly announces Penny Black PoW postage 
Once nice thing about memory-bound functions is that,
while spammers could build custom hardware farms in Florida or China,
a large amount of spam is delivered by hijacked PCs or abused relays/proxies,
which run on standard PC hardware, not custom, so it'll still be slow.
Penny Black or any other system that involves tweaking the email protocols
gets a one-time win in blocking spam, because older badly-administered
mail relays won't be running the new system - if their administrators
upgrade them to support the new features, hopefully that will turn off
any relay capabilities.  That doesn't apply to cracked zombie machines,
since the crackers can install whatever features they need,
but at least all of those Korean cable-modem boxes won't run it.

@_date: 2003-12-30 19:11:47
@_author: Bill Stewart 
@_subject: [camram-spam] Re: Microsoft publicly announces Penny Black 
> [what about mailing lists]
Obviously you'd have to whitelist anybody's list you're joining
if you don't want your spam filters to robo-discard it.
The reason it's partly a cryptographic problem is forgeries.
Once everybody starts whitelisting, spammers are going to
start forging headers to pretend to come from big mailing lists
and popular machines and authors, so now you'll not only
need to whitelist Dave Farber or Declan McCullough if you read their lists,
or Bob Hettinga if you're Tim (:-), you'll need to verify the
signature so that you can discard the forgeries that
pretend to be from them.
You'll also see spammers increasingly _joining_ large mailing lists,
so that they can get around members-only features.
At least one large mailing list farm on which I've joined a list
used a Turing-test GIF to make automated list joining difficult,
and Yahoo limits the number of Yahoogroups you can join in a day,
but that's the kind of job which you hire groups of Indians
or other English-speaking third-world-wagers to do for you.

@_date: 2003-02-08 15:26:53
@_author: Bill Stewart 
@_subject: Columbia crypto box 
Mom, can I borrow the keys to the Space Shuttle?
 From a cryptographic perspective,
a "physical key" is just a ROM containing some bits,
or else a smart-card containing some bits it doesn't tell you directly,
but either way the only thing magic about the physical container
is whether the operator needs to know the bits or not.
These days nobody *has* a better cryptosystem than you do.
They might have a cheaper one or a faster one,
but for ten years the public's been able to get free planet-sized-computer-proof crypto,
and if you don't like it, you can switch from 3DES and 1024-bit RSA to
5DES and/or 4096-bit RSA.
That doesn't mean that the space shuttle has that quality crypto
for its critical operational communications - its computers were antique
compared to commercial-off-the-shelf-non-radiation-hardened-non-shock-proofed PCs,
so it could be running on really lame 60s NSA hardware crypto.
The tradeoff with that kind of equipment was using good key hygiene
(doesn't matter too much if the key gets stolen as long as you know,
and as long as you can wait for the guy with the briefcase handcuffed to his wrist),
but also using Obscurity to make cryptanalysis difficult.
So it's possible that they're running some crypto that's lame enough that
if somebody recovers it, they'll be able to crack the algorithms,
which might let them crack the keys for some other shuttle,
or it's possible that it will let them learn enough about old NSA crypto
and maybe the KGB can decode some old messages from somebody,
which might still have some value to somebody (learning 60s/70s military It'd be lame, but it's possible.

@_date: 2003-02-15 01:17:12
@_author: Bill Stewart 
@_subject: Columbia crypto box 
But to further toot Peter's horn here (:-), before Peter's discovery,
or maybe some work by Biham (?) around that time,
at least as far as the public literature knew,
DES key scheduling was substantially slower than the S-box phases of DES,
so not only were general-purpose-computer attacks Moore'sLawfully slower,
but add another factor of 10 or so, and customer hardware crackers
would also need to burn resources on both parts of the algorithm
and therefore take at least twice as much ASIC space unless
extremely carefully managed.  So while modern technology has
made it severely useless, and while it was crippled back then,
it was at least not _as_ crippled as it looks from today's viewpoint.

@_date: 2003-01-01 22:38:39
@_author: Bill Stewart 
@_subject: Implementation guides for DH? 
At 03:07 PM 01/01/2003 -0800, Zulfikar Ramzan replied to Adam:
The Photuris keying system (RFC2522) also has some
good insight into Diffie-Hellman implementation issues,
including a lot of emphasis on who picks what parameters
(initiator vs. responder) to reduce threats,
guidelines for acceptable parameters, and the
cookie exchange that reduces spoofing attacks.
Stiglic's paper goes into a lot of explanation about
some issues of safe parameters, particularly recommendations
for sufficiently safe primes.  Much of the discussion on the net
about prime safety for DH has been about whether safe primes
are necessary or not worth the bother, and at least with the
current methods for factoring, it's believed they aren't needed.
(One catch, of course, is that the best factoring method
10 or 50 years from now may be affected by safe vs. unsafe primes.)
At least in the initial Photuris versions, there were some
standard choices of primes that everybody used,
so it made sense to pick Sophie-Germain primes anyway.
Stiglic also refers to use of cookie puzzles such as hashcash
to further reduce the risk of swamp-the-responder attacks
by letting the responder force the initiator to do work
taking arbitrary amounts of time before the responder
needs to do any exponentiation work, which can let the responder
manage its total workload, with much more impact on an attacker
(or a slashdotting) than on non-malicious users.

@_date: 2003-01-09 11:07:19
@_author: Bill Stewart 
@_subject: DeCSS, crypto, (regions removed??!) 
That's an interesting change - a couple of years ago,
friends from Sweden told me that the standard was to
strictly sell only region-enforcing DVD players
and then charge a bit extra for installing the
region-free mod chips that everybody bought.
I guess they've stopped bothering with the games by now.

@_date: 2003-01-09 19:09:37
@_author: Bill Stewart 
@_subject: DeCSS, crypto, law, and economics 
In the case of medicinal drugs (as opposed to recreational),
the legal barriers to development and sale of new drugs
have raised the cost to about $500-800 million,
as well as adding a significant delay to availability dates,
and there are fairly convincing arguments that those have
at least as large a negative effect.  It certainly focuses
drug development in directions that can sustain big-hit
marketing campaigns, plus a small amount that's covered by
orphan-disease-drug loopholes.
It's fairly well-known that far more people died from
regulation-caused delays in deployment of several heart-attack drugs
than from active damage by failures such as misuse of thalidomide,
though some people still believe that we're better off because
the regulators also prevented wide deployment of
SideEffectOMycin and DidntWorkATol.
But back to the DVD issue - it's not an issue of public safety;
this stuff is just television.  While I'm not particularly convinced that
copyright and patent legislation actually accomplishes the goals of
advancing science and the arts, or that the time periods that those
protections give exactly count as "limited", it's certainly important
to have "Fair Use" protections for what the public can do with the
information.  On the other hand, legislating against DRM because
it prevents the public from exercising fair use seems wrong
(especially because I prefer technical means of protection for
that kind of material than legal protections),
though legislation that bans public attempts to work around DRM
also seems wrong as well, and failing to ban it just means that
people who want to build DRM systems will just have to do a better job of it.

@_date: 2003-01-26 12:06:43
@_author: Bill Stewart 
@_subject: JILT: New Rules for Anonymous Electronic Transactions? An 
There's some interesting discussion about the ability of the
Dutch legal culture to provide useful tools for regulating transactions
in anonymous or semi-anonymous environments - if you can't find somebody,
can you speak of enforcing contracts, etc.  Not surprisingly,
this has been discussed extensively by the Cypherpunks and other people
exploring applications for cryptographically-protected communications.
Some of the standard references are Tim May's "Cyphernomicon" paper (on the Orson Scott Card's novel "Ender's Game", and Vernor Vinge's story "True Names".
(As the JILT paper says, systems like this may be quite complex to actually
implement in practice, and fiction provides a good tool for exploring the
social implications without doing the difficult detail work.)
I do want to comment on the concept of pseudonymity and semi-anonymity.
The paper appears to be using a definition in which a Trusted Third Party
provides a pseudonym service, which knows the True Name behind each pseudonym
and can provide it when required for a limited number situations,
such as collecting unpaid debts or prosecuting ThoughtCrime,
but otherwise the pseudonym is adequate for many activities,
and the user can protect his privacy and conduct various activities
under different pseudonyms without them being linked to each other
or to his True Name.    Unfortunately, the definitions of ThoughtCrime
have been radically expanded in recent years, primarily due to
"intellectual property" concerns from the music and movie publishers and
the Church of Scientology, so the usefulness of these pseudonyms has
decreased, even for pure communications applications without the
anonymous digital payment systems that can enable anonymous business.
An alternative definition of pseudonymity, which is more common in the
Cypherpunks discussions, is the use of a persistent identity,
verified by digital signatures, which permits the development of
reputations without the need for True Names.  The types of businesses
that can be supported in this environment are more limited,
because there's no way to throw somebody in jail if they default,
but much of European merchant law evolved without this ability.
For some applications, "Reputation Capital" provides enough protection -
a name that's used for months or years of good transactions
or writing good essays or making good investment recommendations
has a value that will be lost if it's abused,
but for other applications, escrow services substantially increase
the types and values of transactions that are possible.
Escrow can be used on a per-transaction basis, or the escrow service
may be part of establishing a pseudonym, providing an amount of money
that can be seized in a dispute resolution process
without needing the True Name of the pseudonym-holder.
Pseudonymity is becoming increasingly common in practice.
AOL "screen names" were primarily intended to
allow multiple family members to share an account, but are also
useful for protecting privacy, especially of children in chat rooms.
There's no explicit requirement for a True Name, though most accounts
use credit cards which do provide some tracing ability,
but the depth of credit checking performed by AOL is
"did their credit card company approve paying for their service this month",
rather than "how big a transaction can their assets cover" or
"where do they sleep, in case the police want to arrest them".
Yahoo Mail and Hotmail systems are relatively untraceable, however.
EBay accounts have an organized reputation capital system,
allowing buyers and sellers to rate whether the other party has
met their obligations, and to allow prospective buyers and sellers
to see the ratings and estimate whether they'll be defrauded or not.
Unfortunately, EBay recently bought Paypal, so the privacy of
Paypal users is no longer protected by the separation between
the auction system and the payment system, since Paypal uses
credit cards and therefore semi-traceable identities to pay people.
Julf Helsingius's original Anonymous Remailer was originally intended
to provide the stronger form of pseudonymity, but unfortunately
he was forced to reveal the information he had about a user
(because of the intellectual property Throughtcrime problem),
though in fact that identity was another disposable email address.

@_date: 2003-01-28 01:03:19
@_author: Bill Stewart 
@_subject: [IP] Master Key Copying Revealed (Matt Blaze of ATT Labs) 
Defense in depth is certainly important for physical security,
for serial attacks as well as parallel attacks.
A long long time ago, in a phone company far far away,
about two floors down from where Matt Blaze was working,
I ran the computers and some other operations
for a workroom that did classified government processing.
The higher-security data lived in safes when we weren't actively using it,
as did any classified backup magtapes.  (Computers were still big then,
and the removable disk packs were roughly 14" diameter, 8" high, 250MB.)
The TEMPEST room they lived in didn't have locks on it,
just annoyingly unreliable electrical airlock doors.
It lived inside a room that had several inches of sheetrock and wiremesh walls,
and a door that had two locks - a classified-rated Sergeant & Greenleaf
mechanical combination lock, which we used when the room was unattended,
and an electronic-pushbutton combination lock which was enough when
the room wasn't attended by a guard at the front desk,
plus there were motion-detector alarms set when it wasn't attended.
Army Reg 380-380 didn't require that the room be impregnable to
people with sawzalls and dynamite - just that it be hard to break into,
and extremely hard to break into without leaving an obvious mess,
and a guard schedule appropriate for the level of difficulty breaking in.
One of the screws holding the S&G lock to the doorframe came loose
and jammed the lock.  We had to call a locksmith to drill it out,
and it took him about the required two hours to do it.
(If there'd been an emergency, we'd have sawzalled the door.)
The electronic lock jammed a couple of times, and it wasn't hard to
jimmy the door enough with a fireman's prybar to use a screwdriver to
open the latch, but we let the guards know before we started.
The real security problem was when somebody built another secure lab
next door, with what was supposed to be a high-spookiness-quality alarm system;
it took a long time to figure out that most of the false alarms were from
the guards' walkie-talkies causing electrical interference,
and got them instructed not to press talk in that hallway unless
there was something seriously suspicious going on...
and got them instructed to call the other guy, not me, if there was an alarm :-)

@_date: 2003-05-31 22:22:39
@_author: Bill Stewart 
@_subject: "PGP Encryption Proves Powerful" 
And Phil was quoted as saying
 > "Does PGP have a back door? The answer is no, it does not,"
 > he said. "If the device is running PGP it will not be possible
 > to break it with cryptanalysis alone."
But in fact that's incorrect.  PGP doesn't have back doors,
but it has two major weaknesses, which are weak user-chosen passphrases,
combined with a secret key file format that makes it easy to
verify whether a key has been guessed correctly,
and human-rememberable passphrases, combined with
rubber-hose cryptanalysis and a captured agent.
If you're doing good operational security, and the
Red Brigades probably are, your passphrases have good enough entropy
that they're hard to crack, but if they got sloppy,
and someone wants to feed all the information that's known about them
to pgpcrack, it's possible that they'll find something.
It's less likely than VENONA succeeding, because the importance
of good passphrases was known, and unlike one-time pads there's
no operational need to occasionally get sloppy under time pressure.
I'm not aware of a PGP port to the Psion, but at least the
Psion 3/3a/3c generation were 8086-like processors,
and there was a C compiler ported to them,
so perhaps somebody ported one of the earlier PGPs.
(There was an old HP palmtop that ran genuine MS-DOS,
unlike the Psion's more interesting operating system,
and you could probably run PGP on that directly.)

@_date: 2003-06-03 10:26:09
@_author: Bill Stewart 
@_subject: Maybe It's Snake Oil All the Way Down 
The catch, of course, is that most cryptosystems are only useful
if they're widely deployed.  Learning from mistakes is good,
but endangering large numbers of users in the process is bad.
By contrast, learning cryptanalysis doesn't have this weakness -
if you can't crack somebody else's code, no problem,
(with obvious exceptions for people who need to learn cryptanalysis
quickly in wartime or whatever, or undertrained cryptanalysts who are
hired by people who are learning cryptography by making mistakes...)
Even ROT-13's not too bad unless somebody tries to crack it,
though some people who've spent way too much time with it
can just read the stuff by recognizing it as an alternate font :-)
Somebody else followed up by mentioning that, while GSM's
privacy encryption is cracked, their authentication encryption isn't,
and they aren't getting massively attacked.
I thought the state of the art at this point was that the
authentication is also crackable, but it's currently enough work that
nobody's or almost nobody's bothering, because governments can get what
they want by telling phone companies to give them the information,
and regular criminals can get the equivalent of cracking GSM authentication
by stealing mobile phones more easily than by hiring cryptanalysts,
and unlike satellite TV smartcard cracking, nobody's figured out any
potential market opportunities for widespread cracked GSM.

@_date: 2003-06-03 11:27:16
@_author: Bill Stewart 
@_subject: New vs Old (was Snake Oil) 
Much of this is in the PGP FAQ Unfortunately, consistent support for the command-line options
suffered for a while, though it was pretty obvious that
Phil wasn't a Unix developer and it wasn't easy to make
PGP support other programs in general.
There were three basic problems
- The IDEA and RSA algorithms were patented, and it's one thing to
ignore or violate patents for an in-your-face human rights campaign,
but another thing entirely for a product you're trying to commercialize
or for an open-source reimplementation you're trying to GPL (the GPG.)
In the case of IDEA, they had friendly non-commercial-use permissions,
but that didn't help PGP Inc.  The RSAREF licenses, which were pretty much
done to let RSA keep some practical control over the algorithm,
also helped a bit, and of course the patent has now expired.
- MD5 appears to be somewhat broken, based on Hans Dobbertin's work.
While that doesn't necessarily affect the way it's used in PGP,
it's pretty shaky, and SHA-1 is an adequate replacement.
The 2.x data formats didn't let you replace MD5, so you have to
use newer versions of PGP formats to do it.
- The 2.x generation of PGP data formats was broken and exploitable,
because it was careless about which fields were covered by
signatures and because the ugly bit-twiddly data formats
were too busy saving a bit here or there to provide good boundaries
between fields, so it's possible to do things like forge key signatures.
Because of that, you need to switch to newer data formats anyway,
which means switching to newer versions of PGP, which preferred
the other algorithms for patent reasons (though they were extensible.)
It's basically El Gamal, using the DSS for signatures.
Details in the FAQ are at
CAST is discussed in RFC2144 and other places.
SHA-1 was extensively discussed, because the NSA released SHA and then
oopsed and followed it with SHA-1.  There's been some analysis that
hints at possible attacks on SHA, or at least suggests that the
changes that made it SHA-1 do look like they make it stronger.
A big difference between MD5 and SHA-1 is that SHA-1 hashes are 160 bits,
which are of course the wrong size for data structures built for 128 bits,
and are more resistant to birthday attacks (where applicable,
which they don't seem to be in PGP), and are almost but not quite
long enough for 3DES keying, so some programs probably sleaze that a bit.

@_date: 2003-06-03 11:38:21
@_author: Bill Stewart 
@_subject: "PGP Encryption Proves Powerful" 
Eh?  Password guessing certainly is.
Looks like it's still in active development,
mainly for the Psion 5 series - they've even got
X Windows running on them, as well as PGP.

@_date: 2003-06-03 11:55:00
@_author: Bill Stewart 
@_subject: New vs Old (was Snake Oil) 
Actually, they switched to letting the user choose algorithms,
with CAST as the default but others such as 3DES available.
One of the compatibility issues is that people have written
patches for GPG that implement IDEA, so some users' systems support it
and others don't.  On the other hand, that mainly bothers the
people who've picked "only accept IDEA" for their symmetric algorithms.

@_date: 2003-06-03 15:01:51
@_author: Bill Stewart 
@_subject: Maybe It's Snake Oil All the Way Down 
For transmitting credit card numbers on web forms,
I'd be surprised if there were 1% of the servers that *don't* use SSL/TLS.
Virtually all deployed browsers support SSL, except a few
special-purpose versions.  The web servers supporting
almost all of the web support SSL if they have keys installed.
While many of them haven't bothered paying money for certified keys
or doing self-signed keys, I'd be surprised if it's really
as low as 1%.  What's your source for that figure?
While only a small fraction of web pages, and a much smaller
fraction of web bits transmitted, use SSL, that's appropriate,
because most web pages are material the publisher wants the public to see,
so eavesdropping isn't particularly part of the threat model,
and even integrity protection is seldom a realistic worry.
(By contrast, eavesdropping protection and integrity protection
are critical to telnet-like applications, so SSH is a big win.)
It's nice to have routine web traffic encrypted,
so that non-routine traffic doesn't stand out,
and so that traffic analysis is much harder,
but there is a significant CPU hit from the public-key phase,
which affects the number of pages per hour that can be served.
Corporate intranet web traffic carried across the public internet
sometimes uses SSL, but usually uses IPSEC because that also supports email.
In addition to web browsing and email submission,
there's an emerging market for SSL-based VPNs appliances.
Neoteris is one of the pioneers, and Aventail and some others are players.
The intention is that you can get "clientless" (browser-based)
support for intranet web browsing and email,
and lightweight client support for telnet,
while only having to buy an overpriced server box.
(And the box doesn't even need crypto accelerator help,
because the public-key phase only gets used for login,
while most sessions are long enough that this amortizes quickly.)

@_date: 2003-06-09 23:42:24
@_author: Bill Stewart 
@_subject: Quantum crypto, from BBC 
I hadn't seen this particular implementation of it discussed here
before your posting, but as John points out, the topic has been discussed.
It's somewhat cool, but not particularly useful.
Quantum computers that can actually do factoring of usefully
large numbers would have a major impact on the whole crypto field.
But quantum cryptography for sending messages
is seldom any more useful than sending an occasional courier
with a briefcase handcuffed to his arm,
which probably costs a lot less than stringing fiber.
It's also not very useful for preventing traffic analysis :-)

@_date: 2003-06-13 16:32:12
@_author: Bill Stewart 
@_subject: An attack on paypal 
Unfortunately, that doesn't help you against wetware attacks -
the "paypa1.com" and "e-g0ld.com" web sites can have valid certs,
and your browser is unlikely to notice that they're different
from the certs sites "paypal.com" and "e-gold.com"
because they've got different domain names.
So it won't notice that the certs have changed, because they haven't,
they're just the new certs for the new websites.
And client-side certs won't help, because the bogus sites
can happily accept them or ignore them.
An e-gold-specific or paypal-specific client can tell,
because it can remember that it's trying to see the real thing,
but the browser can't tell, except by bugging you about
"Hi, this is a new site that's giving us a new cert" placebo box.

@_date: 2003-06-28 13:06:03
@_author: Bill Stewart 
@_subject: Attacking networks using DHCP, DNS - probably kills DNSSEC 
Somebody did an interesting attack on a cable network's customers.
They cracked the cable company's DHCP server, got it to provide a
"Connection-specific DNS suffic" pointing to a machine they owned,
and also told it to use their DNS server.
This meant that when your machine wanted to look up yahoo.com,
it would look up yahoo.com.attackersdomain.com instead.
This looks like it has the ability to work around DNSSEC.
Somebody trying to verify that they'd correctly reached yahoo.com
would instead verify that they'd correctly reached
yahoo.com.attackersdomain.com, which can provide all the signatures
it needs to make this convincing.
So if you're depending on DNSSEC to secure your IPSEC connection,
do make sure your DNS server doesn't have a suffix of echelon.nsa.gov...
"... It turns out, Charter Communications' DHCP servers were
infiltrated and were providing p5115.tdko.com as the
'Connection-specific DNS suffix', causing all non-hardened Windows
(whatever that means in a Windows context) machines to get lookups
from a hijacked subdomain DNS server which simply responded to every
query with a set of 3 addresses (66.220.17.45, 66.220.17.46,
On these IPs were some phantom services. There were proxying Web
servers (presumably collecting cookies and username/password combos),
as well as an ssh server where the perpetrators were most likely
hoping people would simply say 'yes' to the key differences and enter
in their username/password..."
Hmm, my cable ISP was down this morning.  Maybe coincidence.

@_date: 2003-06-29 14:19:51
@_author: Bill Stewart 
@_subject: Attacking networks using DHCP, DNS - probably kills DNSSEC  
I thought about that, and I think this is an exception,
because this attack tricks your machine into using the
trust chain yahoo.com.attackersdomain.com., which it controls,
instead of the trust chain yahoo.com., which DNSSEC protects adequately.
So you're getting a trustable answer to the wrong query.
I'm less sure of the implementation issues of the
"Connection-specific DNS suffix", and I've seen conflicting documentation.
If the resolver looks up "domain.suffix" before "domain",
then the attacker's DNS doesn't need to control the DNS access,
and only needs to provide the attacker's certificates,
but if the resolver looks up "domain" before "domain.suffix",
then the attacker also needs to make sure that the lookup of "domain" fails,
which is most easily done by telling the DHCP client to use
the attacker's DNS server along with telling it the suffix.
(That doesn't add any extra work to the attack, but does make it
a bit easier to trace the attacker after the fact;
if you're not replacing the attacker's DNS server entry,
then all you need is a legitimate-looking server for
"*.attackersdomain.com".  In either case, somebody who can
pull off this kind of an attack probably uses a compromised machine
to run the DNS server on anyway.)
DNSSEC seems to do a pretty thorough job of making sure that
if you look up the correct domain name, you'll get the correct answer,
in spite of attackers trying to prevent it.
But this attack tricks you into looking up the wrong domain name,
and DNSSEC makes sure that you get the correct answer for the wrong name,
which isn't the result you want.

@_date: 2003-06-29 19:17:18
@_author: Bill Stewart 
@_subject: Attacking networks using DHCP, DNS - probably kills DNSSEC 
That doesn't happen.  (Well, it could, but as you point out,
it's not a successful attack methodology, because DNSSEC was designed
to correctly take care of this.)
The DNS suffix business is designed so that your laptop tries
to use "yahoo.com.attackersdomain.com", either before "yahoo.com"
or after unsuccessfully trying "yahoo.com", depending on implementation.
It may be bad judgement, but it's designed to support intranet sites
for domains that want their web browsers and email to let you
refer to "marketing" as opposed to "marketing.webservers.example.com",
and Netscape-derived browsers support it as well as IE.
I agree with you and Steve that this would be a Really Bad Idea.
The only way to make it secure is to use an authenticated DHCP,
which means you have to put authentication keys in somehow,
plus you need a reasonable response for handling authentication failures,
which means you need a user interface as well.
It's also the wrong scope, since the DNSSEC is global information,
not connection-oriented information, so it's not really DHCP's job.

@_date: 2003-03-07 10:40:37
@_author: Bill Stewart 
@_subject: Proven Primes 
Well, it's harder in that to find a prime or SG prime,
you need to try the probable prime test on bunch of candidates until one With the Java BigInteger probable prime package, can you specify what it uses for primality (i.e. the probability is 2**-N or 4**-N, what's N?)

@_date: 2003-03-07 15:16:41
@_author: Bill Stewart 
@_subject: Scientists question electronic voting 
No, legal authorization is only required to do so _legally_.
We're talking about different threat models here,
since we're talking about stuffing ballot-boxes and bribing people -
what does it take to get the information without getting caught?
Can it be traced in real time, or after the fact, or both,
and how much is the voter's cooperation required?
How long is the data stored after the election?
(For instance, if the election isn't close enough to be contested
within N days, do they burn all the ballots?)
The two usual scenarios are
- Real-time: "Thank you for your receipt, here's your bottle of whiskey,
         and the Democratic Party invites you to vote again this afternoon!"
- Later: "Mr. Smith, we've been auditing the ballots and we see that
         you voted for Emmanuel Goldstein.  We're taking you in for therapy."

@_date: 2003-03-08 13:24:41
@_author: Bill Stewart 
@_subject: Scientists question electronic voting 
> This is a perfect example of what I'm complaining about:  You're holding
 > electronic voting to a much higher standard than you are paper ballots.
If it's going to replace paper ballots, it needs to offer advantages
that make up for its disadvantages, and if it gives us the opportunity to
make a significantly better system, might as well try to do that too.
The two main disadvantages of paper systems are slow speed and cost of Problems with speed are really problems with lack of patience :-)
But electronic systems have the major disadvantage that unless you have
some kind of independently auditable record created at the time of voting,
there's no way to tell that the system hasn't been set to cheat,
whereas most of the easy ways to cheat paper and lever-machine systems
are obvious, and can either be prevented by watching the materials
at the right times, or audited by counting the holes and hanging chads
and unused supplies afterwards.
The primary complaint everybody had with Florida's paper ballot system
was that the layout was confusing,
making it hard to tell if you were voting for Gore or Buchanan,
and any of you who've never seen a confusing layout on a computer interface
can let me know....
Well, of course they can, if they want; they can also go back to
strange women lying in ponds distributing swords for all I care...
But the context of the discussion isn't whether the system will do
the things it's supposed to when nobody's trying to cheat,
and if they've got different rules, they've got different ways to cheat.
What's the traditional bribe for a vote in the UK?

@_date: 2003-03-10 23:43:28
@_author: Bill Stewart 
@_subject: Active Countermeasures Against Tempest Attacks 
And while some of the signal processing jobs need to scale with the target as computer clock speeds get faster, the leakage gets higher and
therefore shielding becomes harder and leakage gets higher.
Most of the older shielding systems can do fine with the 70 MHz monitor speeds,
but the 3 GHz CPU clock speed is more leaky.  Millimeter wavelengths are
_much_ more annoying.
Back when most of the energy lived at a few MHz, it was easy to make enclosures
that had air vents that didn't leak useful amounts of signal.  It's harder So take your scuba gear into your Faraday cage with you :-)
Basically, if you've got a serious threat of TEMPEST attacks,
you've got serious problems anyway...

@_date: 2003-03-13 22:12:36
@_author: Bill Stewart 
@_subject: Diffie-Hellman 128 bit 
Google for "Odlyzko Diffie Hellman" and look at the various papers.
Unless you're talking about elliptic curve versions of Diffie Hellman
(and even then 128 bits probably isn't enough), 128 is way too weak.
DH is similar in strength to RSA, so don't think about using less than 1024,
and realistically go for 2048 or more.

@_date: 2003-03-13 22:32:46
@_author: Bill Stewart 
@_subject: Brumley & Boneh timing attack on OpenSSL 
From Slashdot: David Brumley and Dan Boneh write:
"Timing attacks are usually used to attack weak computing devices such as We show that timing attacks apply to general software systems.
Specifically, we devise a timing attack against OpenSSL.
Our experiments show that we can extract private keys from a
OpenSSL-based server such as Apache with mod_SSL and stunnel
running on a machine in the local network. Our results demonstrate that
timing attacks against widely deployed network servers are practical.
Subsequently, software should implement defenses against timing attacks.
Our paper can be found at Stanford's Applied Crypto Group.
  "
Schmoo Group response on cryptonomicon.net
Apparently OpenSSL has code to prevent the timing attack,
but it's often not compiled in (I'm not sure how much that's for
performance reasons as opposed to general ignorance?)
They also comment (as did somebody on Slashdot) that
"this is distinct from the timing attack described in the paper
by Canvel, Hiltgen, Vaudenay, and Vuagnoux last month."
That one's an implementation problem and hard to exploit.

@_date: 2003-03-15 14:47:59
@_author: Bill Stewart 
@_subject: Face-Recognition Technology Improves 
750,000 * 100 = 75,000,000 usually (:-), which sounds more credible.
No idea how many of those are unique passengers, but there are probably
a lot of frequent business travellers going through there many times.
They're probably not independent, but they'll be influenced by lighting,
precise viewing angles, etc., so they're probably nowhere near 100% correlated either.
There could be some positive feedback, if they keep photographs of near Another mechanism they could use is the set of names of people expected
to fly in and out of the airport, but of course that only works for people
who use their real names on airline tickets - it's better for tracking
Green Party members than for tracking Carlos the Jackal.

@_date: 2003-03-16 00:16:35
@_author: Bill Stewart 
@_subject: Microsoft: Palladium will not limit what you can run 
Anish asked for references to Palladium.
Using a search engine to find things with "palladium cryptography or "palladium cypherpunks" will find a bunch of pointers to articles,
some of them organized usefully.
But is the Xbox running Nag-Scab or whatever Palladium was renamed?
Or is it running something of its own, perhaps using some similar components?
It doesn't need to be below cost; Walmart was selling machines
with capabilities fairly similar to the Xbox for less,
and they certainly don't do anything below cost.
(This was the ~$200 Linux PCs.)  Now, the amortized development cost
of those PCs is probably less than that of X-box,
and they were a bit less compact hardware (though Xbox is pretty
much of a porker compared to most of the other gamer boxes),
and of course the "cost" of the Xbox might include some amortized
cost of developing whichever Windows variation it uses,
while Walmart didn't have that cost.

@_date: 2003-03-16 11:11:40
@_author: Bill Stewart 
@_subject: Face-Recognition Technology Improves 
But there are two sides to the problem -
recording the images of the people you're looking for,
and viewing the crowd to try to find matches.
You're right that airport security gates are probably a pretty good
consistent place to view the crowd, but getting the target images
is a different problem - some of the Usual Suspects may have police mugshots,
but for most of them it's unlikely that you've gotten them to sit down
while you take a whole-face geometry scan to get the fingerprint.

@_date: 2003-03-22 12:25:58
@_author: Bill Stewart 
@_subject: Brumley & Boneh timing attack on OpenSSL (fwd) 
If it's not meant to be a high-performance server, then slowing it down
another 20% by doing RSA timing things is probably fine for most uses,
and either using compiler flags or (better) friendlier options of some sort
to turn off the timing resistance is probably the better choice.
I'm not sure how flexible things need to be - real applications of the
openssl code include non-server things like certificate generation,
and probably some reasonable fraction of the RSA or DH calculations
don't need to be timing-protected, but many of them are also things
that aren't CPU-consumption-critical either.

@_date: 2003-03-25 03:06:39
@_author: Bill Stewart 
@_subject: Who's afraid of Mallory Wolf? 
One of the major reasons for this, of course,
is the requirement for certificates,
which give at least some vague level of authentication
that you're talking to the site you wanted,
as well as some much vaguer level of authentication
that the web site might correspond to some actual business
that at least had enough capital to buy a cert.
Sure, there are a variety of subtle and entertaining ways
to pull of MITM attacks, but one crude and obvious one
is to forge either an entire site or at least the parts of it
that ask for your credit card number,
and use something like DNS hacking or minor name misspellings
to get people to visit your site instead of the real one.
If you need to forward some of the requests on to the real site,
that's a bit more work, and makes you easier to trace,
so if you can be a MITM without bothering with the back half, great.
And of course the cruder and more obvious attack was to
create a site for a company that wasn't actually on the web yet,
so nobody's watching the site, and then fly-by-night out of there.
Is it perfect?  No, but it does tend to raise the bar on attacks
to the point that keeps out lots of the anklebiters
and makes it more effective to attack a badly-administered server
instead of forging a better-administered server.
Oh, and it also let merchants who desperately wanted the public
to trust them enough to give them credit card numbers
tell their potential customers "See, we've got *cryptography*!"
instead of "See, we've got servers sitting exposed to the net",
which is a social engineering problem,  and also let them say
"See, the certificates let you know you're talking to the
REAL Example Inc. instead a some faker putting up example.com."
Because the real economics is whether you can get customers to show up.
         (Well, ok, and whether you can make money if they do show up :-)

@_date: 2003-03-25 12:22:40
@_author: Bill Stewart 
@_subject: Who's afraid of Mallory Wolf? 
I get the impression that we're talking at cross-purposes here,
with at least two different discussions.  Let's look at several cases:
1 - Sites that have SSL and Expensive Certs that need them and need MITM 1a - 	These sites, but with other security holes making it easy to break in.
1b - 	These sites, broken by SSL bugs or browser bugs
2 - Sites that have SSL and Expensive Certs that don't need them,
3 - Sites that don't have SSL today because it's too annoying,
4 - Sites that don't need crypto.
Some people are arguing "Many Sites with SSL Certs are Type 2, Not Type 1"
Some people are arguing "There are lots of Type 3, so we should support them
One of the big reasons for DNSSEC was MITM protection,
at least before virtual hosting took over,
because it gave you a way to trust that the IP address you used
was the correct IP address for the domain name you wanted,
so you were probably talking to the right machine.
Of course that doesn't get you ARP-spoofing protection,
or eavesdropping protection unless you also use it as a crypto key
or at least a signature key for DH parts,
and doesn't protect you against other users on your machine
(but a shared machine doesn't have much protection anyway,
at least from root, so that was already part of your threat model,
and that's another 1-vs-1a variant, like the heavy-duty lock on your
apartment building front door when your own apartment door has a wimpy lock.)

@_date: 2003-03-28 16:09:12
@_author: Bill Stewart 
@_subject: Run a remailer, go to jail?  
It looked to me like it was the cable TV industry trying to ban
possession or sale of illegal cable descramblers as well as
connection-sharing things like NAT, but it was a bit hard to tell
how much of the language was new as opposed to older,
so this may have been extending existing cable descrambler laws
to also cover 802.11 or Napsterizing your Tivo.
I don't think that banning remailers or crypto was the intent,
but the cable industry has never been above using nuclear weaponry
to discourage cable service theft, regardless of collateral damage.

@_date: 2003-05-04 01:24:02
@_author: Bill Stewart 
@_subject: The Pure Crypto Project's Hash Function 
Back when we were having fun doing minimum-length crypto implementations
  like RSA-in-minus-3-lines-of-perl,
suitable for T-shirts and tattoos and coke cans and email signatures,
it was probably possible to put together a one-page cryptosystem
implementing PGP-like functionality (but not compatibility, of course),
capable of being faxed to anybody.
The most likely function to be difficult was the prime number generation everything else is known small (except of course for perl itself :-)
Extreme Smallness is mainly a hack, though it was politically important in its day.
         (By the way, there's a typo in  )
The version on the web page is slightly different than this one.
Comment 1 - YOW!  BLAZINGLY SLOW!  One modexp per character?
Comment 2 - I've read your explanation of why this should be a keyed hash,
and I'm not convinced that's generally applicable or useful.
There are times it's nice to have a pure hash function,
though I suppose you can somewhat achieve that by using H0==constant.
(It's not very pretty if the constant is 0 or 1, though,
and your "19s" may not percolate fast if the first few input characters are It's also not clear whether the Public Key Modulus you're using
is the modulus of the sender or recipient of a message,
or what to do if you're signing something and encrypting it.
Comment 3 - Is the Modexp implementation you're using dependent on the
first parameter being less than the prime?
If so, you've got a high probability of overflow and need to do
(mod(Hi+Ho), Prime) instead of (Hi+H0).
Comment 4 - The output isn't evenly distributed.  It's always < Prime.
I don't have a handy bignum calculator, and while I assume your prime is
close to 256 bits long, I don't see where you got it, so unless it's
very close to 2**256-1, it'll have artifacts.

@_date: 2003-05-05 00:07:53
@_author: Bill Stewart 
@_subject: pgp-in-50-lines-of-perl? (Re: The Pure Crypto Project's 
It's all sitting on  ,
including the RSA key generator which I don't remember having noticed.
Personally, I'd go with rc5 instead of IDEA, or even RC4,
and use much simpler data formats (crypto parameters in hex or decimal,
stuff separated by white space or maybe even newlines.)
There are too many PGP formats out there to bet on compatibility,
and Phil's various compacted integers were all ugly.
Admittedly, if somebody does have even more too much time on their hands,
even one-way compatibility with even one version would have major hack value,
but I'd lean toward cleanliness myself.
Personally I've always disliked the mixture of perl+dc, but it probably works
faster than the pure-perl version, as well as being smaller.
The 4-line LISP and Python versions are quite clean and readable :-)

@_date: 2003-05-11 16:36:45
@_author: Bill Stewart 
@_subject: faster modexp()? cipheractive 
I haven't downloaded and seen whether you need to disassemble the
free crippleware to figure out what it's really doing,
but my friend John Doe tried unsuccessfully to do so,
and perhaps a human will respond to the log messages tomorrow.
It wants some kind of public key, probably a raw hex RSA key.
Two obvious methods for them to use are
- some interesting mathematical breakthrough like Montgomery Multiplication only faster
         (ok, how to make such a breakthrough isn't obvious,
         but what to do with it if you had one is.)
- no new math, just building a modexp library that uses
         vector processing features on Intel-like chips like SSE / SSE2 / etc.

@_date: 2003-05-12 23:14:36
@_author: Bill Stewart 
@_subject: A Trial Balloon to Ban Email?  
For *you* to get something of value, there needs to be a payment system,
and the sender needs to be willing to spend money to talk to you.
There are environments in which that holds, but they're mostly specialized.
Hashcash doesn't change the economics of spam as much by imposing a
direct cost on the sender (since the amortized cost of less than an
hour's CPU time is pretty low unless you're buying lots of it),
but by limiting the rate at which a single machine can send mail.
60 seconds of CPU time per message means 1440 messages/day/CPU,
as opposed to tens of thousands per hour, which limits the rate at which
suckers can be located and money extracted from them, e.g. the ex-spammer
on Slashdot the other day would be making $5/week instead of $1000/day.
Also, spammers have a problem that they get detected and shut down,
so slowing down the rate they can transmit decreases the number of messages
that they can send before they get shut down.
For large-volume senders, the cost is measurable -
a $100 CPU over 1 year is ~30 cents/day, or about 0.02 cents/message,
which is a higher than the current costs of spam,
but for people who aren't buying CPUs just to max them out on email,
the CPU amortization is mostly a sunk cost.

@_date: 2003-05-19 11:12:17
@_author: Bill Stewart 
@_subject: using PoW + filters to avoid false positives (Re: Re: A 
Steve Bellovin pointed out that spammers who use open relays and
open proxies will happily burn those CPUs doing proof-of-work
as well as burning their bandwidth multiplying spam.
That's not necessarily a _bad_ thing, if it gets the attention of
the people running the relay/proxy machines (:-)
But it's a basic problem with link-based proof-of-work like START_TLS
as opposed to end-to-end proof-of-work mechanisms in the message itself.
If you do link-based, the pnly last relay site needs to do the work,
so the spammer can steal CPU from lots of machines without burning his own.
If you do message-based proof-of-work, it's much harder to get a proxy
or relay to do the work, as opposed to using the spammer's own machine.
START_TLS and other link-based mechanisms _do_ have the benefit of
harassing dialup and DSL spammers, who are using their own CPUs without relays,
so it at least gets rid of some of the ankle-biters and forces spammers
to abuse relays and proxies, which may be easier to identify
(especially because they're using START_TLS...)
This has the side benefit that it cuts down on the use of dial/dsl blacklists,
which are one of the extremely annoying sources of collateral damage
in the anti-spam world.

@_date: 2003-05-29 01:33:18
@_author: Bill Stewart 
@_subject: Nullsoft's WASTE communication system 
- Overview
 - Security section
 - Network design
 - Slashdot discusssion
Nullsoft, who did Winamp and Gnutella, just released a package called W A S T E
which does encrypted communications within small groups of people.
It doesn't appear to have had outside analysis of its security yet,
but they do invite it, and they say it needs some work.

@_date: 2003-11-27 23:14:34
@_author: Bill Stewart 
@_subject: Open Source Embedded SSL - (License and Memory) 
[Moderator's note: I'd really like to shut down the "What license?"
debate --Perry]
That's an obvious call for a BSD / C-News style license
- You're free to copy it but leave our copyright notice in.
- You acknowledge that you got it for free and that any consequences,
         no matter how horrible, of what you do with it are not our - You're free to change it, but only if you include a notice that you changed it.
- Maybe something about you must either distribute the licensed source code
         for no more than a copying/handling charge or else a pointer to the original.

@_date: 2003-11-27 23:24:29
@_author: Bill Stewart 
@_subject: Open Source Embedded SSL - Export Questions 
============================== START ==============================
Well, to be more precise,
RC4 has restrictions on the ways you can use it that
make its crypto strength fail very badly if you violate them,
and because it's an XOR stream cypher there are sometimes
things you can't do with it that you could do with a block cypher.
RC4 does also have the historical problem that people sometimes
decide to use it with 40-bit keys because they can...
OTOH, of course being a block cypher isn't enough to guarantee
either strength or usefulness, e.g. bass-o-matic.

@_date: 2003-09-07 17:24:28
@_author: Bill Stewart 
@_subject: Is cryptography where security took the wrong branch? 
and James Donald and Lynn Wheeler also brought up the issues
of who's certifying what, True Names, etc.
SSL certs are really addressing (I won't say "solving", exactly)
two different problems -
- Whether the communication session you're setting up with
- Whether Example.com is slightly more likely to be run by Example Inc.,
DNSSEC (or something like it) takes care of the first problem,
without the intervening step of requiring True Names.
It doesn't help the second problem, and DNS doesn't either,
which is one reason that ICANN is so insistent on getting True Names
for whois records and forcing registrars to get them as well.
It's possible to get some uncertified human-readable information
about a domain name from its whois records.
It's possible to get more human-readable information from SSL certs,
and in some cases that information might be certified in a meaningful way,
but in other cases it's not, and browsers aren't typically very good at
telling you that information unless you try hard to get it,
and when they do nag users about it, users usually ignore it.
But it's not always even useful information - Bad Example might have
a cert from trustcenter.de because they take Visa cards at their spa,
but you may be on their _other_ web site that's selling cheap knockoffs of whatever the Example Inc. you were trying to deal with sells.
Your browser isn't smart enough to know that.
While DNSSEC mostly follows a hierarchical model, that doesn't mean
that you couldn't get some user-friendly or browser-friendly
certification model that does provide multi-homed values for
rating information about web sites - Consumer Reports or the
Better Business Bureau or whatever could do signed statements
about domain names without building it into DNS or SSL.

@_date: 2003-09-08 14:36:42
@_author: Bill Stewart 
@_subject: Code breakers crack GSM cellphone encryption 
> and all GSM calls travel through the POTS land line system in the clear,
 > where they are subject to warranted wiretaps.
Some governments are more concerned about using warrants
than others are.  Sometimes the ones that are concerned about them
also have police agencies that like to avoid using them.
Some phone companies are pickier about paperwork than others.
Some phone companies are faster about responding than others.
Having governments that are officially less concerned about warrants
is often correlated with having monopoly phone companies,
which is often correlated with slow bureaucratic response -
they may be extremely happy to help out the police,
but that doesn't mean it doesn't take 18 steps to accomplish it.
Landline-based wiretaps work best if you know the phone number;
over-the-air systems can be more flexible about picking up
any phone nearby, so if you see your target pick up a phone,
but don't know its phone number, they're more convenient.
And in landline-tapping environments, clever law-evaders
can usually acquire the equipment to keep switching phones.

@_date: 2003-09-08 18:00:37
@_author: Bill Stewart 
@_subject: Digital cash and campaign finance reform 
Steve - The whole thing is a crock, and the problems aren't technical.
None of the proposed users of the system have any desire to use it,
except perhaps as a front for other activities,
and the people who'd want them to make them use it are just meddlers.
It's funny how any time you bring up the First Amendment
in the context of tobacco advertising or internet pornography,
they say "Oh, no, it's not about that, it's about *political* speech",
but if you bring it up in the context of actual political speech,
well then, oh, no, the First Amendment is about not arresting
ranters on soapboxes in the park, or letting people print newspapers
as long as there's official identifying information about the printer,
but it's *certainly* not about actually letting people fund *electoral*
speech, because elections are *way* too important to let unapproved
members of the *public* influence the outcomes....
The couple of papers that Michael Froomkin referenced are
pretty much the canonical references to the approach you're talking about,
but just because there are academics proposing it doesn't mean
it isn't still a total crock.
Now, if you're talking about *real* campaign finance reform,
as in permitting people to engage in free speech even if it requires
money to transmit that speech to their intended recipients,
fully anonymous digital cash is useful for that, in the obvious ways,
and payer-anonymous payee-disclosing digital cash has its uses as well,
if you like to be able to trace the people you're paying,
and anonymous and pseudonymous publishing are also obviously useful,
and then of course there's Blacknet if you want the real info on candidates.
You don't need 100% technical guarantees of anonymity for most political work; the public can usually guess that "Paid for by Californians for Motherhood and Apple Pie" is probably the prison guards' union, or the major opponent of the candidate that the negative TV ad was about, or whatever,
but unless there's a lawsuit or actual investigative reporter, nobody's going to bother tracking them down.
Unfortunately, softmoney.com got snapped up a few years ago;
I'd been planning to set it up as a site for donating your two cents to
John McCain, when he was ranting about banning it.
"paid for by Californians Against Bogus Campaign Financing Regulations,
John Doe  Treasurer"

@_date: 2003-09-13 20:40:36
@_author: Bill Stewart 
@_subject: quantum hype 
It's very much a question of threat model.
If anonymity and traffic analysis protection are essential
to your operations, a system that lets wiretappers
follow a piece of fiber to your co-conspirators
may not be the best security out there :-)

@_date: 2003-09-29 09:51:20
@_author: Bill Stewart 
@_subject: New authentication protocol, was Re: Tinc's response to 'Linux's answer to MS-PPTP' 
By "name of the tinc daemon", do you mean identification information?
That data should be encrypted, and therefore in step 2.
(Alternatively, if you just mean "tincd version 1.2.3.4", that's fine.
You can't encrypt the DH keyparts using RSA unless you first exchange
RSA public key information, which the server can't do without knowing
who the client is (the client presumably knows who the server is,
so you _could_ have the client send the key encrypted to annoy MITMs.)
To make the protocol generally useful for privacy protection,
you shouldn't exchange this information unencrypted.
So do a Diffie-Hellman exchange first, then exchange any other information,
including RSA signatures on the DH keyparts.

@_date: 2003-09-29 10:10:01
@_author: Bill Stewart 
@_subject: New authentication protocol, was Re: Tinc's response to 'Linux's answer to MS-PPTP' 
You need to validate the DH keyparts even if you're
corresponding with the person you thought you were.
This is true whether you're using signatures, encryption, or neither.

@_date: 2004-08-14 17:44:16
@_author: Bill Stewart 
@_subject: Cryptome on ABC Evening News? 
Speaking unofficially for the telecom industry,
we're really happy to have the site there
showing pictures of cable landings, antennas, etc.
I've seen them used in internal training about submarine cables
and I think we've probably used them in talks to customers as well.
Separately, of course, we have bureaucrats who don't want to
publish the addresses of telecom POPs, ignoring the fact
that you can't buy physically diverse access to a location
if you don't know where it is, and also ignoring the fact
that 90% of a certain large 3-1/2-letter-acronym long distance carrier's
POPs are in the same buildings as the local telcos
so everybody knows where they are anyway,
even though everybody's forgotten the derivation of V&H coordinates...
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-08-21 20:10:06
@_author: Bill Stewart 
@_subject: First quantum crypto bank transfer 
I agree that it doesn't look useful, but "lawful intercept" is harder,
if you're defining that as "undetected eavesdropping with
possible cooperation of the telco in the middle",
because quantum crypto needs end-to-end fiber so there's
nothing the telco can help with except installing dark fiber,
and the quantum crypto lets you detect eavesdroppers.
On the other hand, at least in the US and probably in Germany,
if the government wants the records of a bank's transactions,
all they need is the locally-proper paperwork demanding the data,
which is a threat model that quantum crypto doesn't help with,
especially since the costs of that attack are much lower than
tapping quantum fiber transactions.
An intermediate level of weakness is detection of who
the bank is communicating with.  In the case of quantum crypto,
it's simple - just follow the fiber to the other end.
But banks are a semi-special case for this threat also,
because you know that a bank's headquarters will talk to
other buildings belonging to that bank, so it's no information leak...

@_date: 2004-08-23 21:58:26
@_author: Bill Stewart 
@_subject: First quantum crypto bank transfer 
Yes.  That's part of one definition of "doesn't look useful".
It would be possible to use it as link encryption,
giving up the benefits of end-to-end in return for better scaling,
but you could still make all the relaying happen in the
user organization's facilities, rather than in a telco building
that's outside the user organization's control.
(Just because something isn't very useful doesn't mean you can't
at least try to do the job semi-correctly...)
That's at least interesting, though I don't see why you'd take
the experiment out of the lab without a really well-defined
benefit to the end user (unless you've got a research grant.)
I'm surprised to hear that _any_ quantum key distribution variant
is available commercially, given the costs of dedicating fiber
and the effectiveness of current mathematical crypto
or the alternative approach of couriers with briefcases and handcuffs.
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-12-22 15:52:53
@_author: Bill Stewart 
@_subject: Cryptography Research wants piracy speed bump on HD DVDs 
If you're in a profit-making business of pirating DVDs for money,
then having your $100 DVD burner stop being able to play DVDs
from a given studio is just a business expense.
But if you're a typical hobbyist pirate,
file-sharing your DVDs for free to other people
who are sharing their pirated DVDs,
rather than spending $2 to rent them at Blockbuster,
then it's probably really annoying,
and you're probably out of business with that DVD burner,
though your other $39 DVD player can play them just fine.
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-07-26 19:07:08
@_author: Bill Stewart 
@_subject: Using crypto against Phishing, Spoofing and Spamming... 
At least until a few years ago, and probably still today,
it was easy to get a non-anonymous account in the US using fake ID.
The "Know Your Customer" laws and other anti-terrorism fallout
may have encouraged banks to check SSNs a bit more carefully,
but as long as the person whose identity you're stealing
doesn't have horrendously bad or good credit,
it's probably still not hard.
If it costs you $100 in fake ID to get the account set up,
and you can burn the phish for $1000, then you win.
But credit cards are probably more common and certainly easier to use.
Buy laptops or other fungible goods, and sell them on eBay.

@_date: 2004-06-02 14:01:46
@_author: Bill Stewart 
@_subject: The future of security 
Unfortunately, that won't work for me.
My email address is at pobox.com, the mail forwarding service
where the main proponent of SPF works,
but my SMTP service is whichever ISP I'm currently connected through
(DSL, dial, work, whatever) - which isn't under pobox's control.
So my incoming mail can recognize SPFs and block forgeries,
but my outgoing mail can't use them,
unless pobox changes their business model to provide outgoing SMTP relay
for their customers, doubling their bandwidth needs.

@_date: 2004-06-04 15:20:59
@_author: Bill Stewart 
@_subject: Chalabi Reportedly Told Iran That U.S. Had Code 
And just in case some of the Iranians hadn't gotten the message,
the Feds' press release should make sure they know...

@_date: 2004-06-22 11:11:33
@_author: Bill Stewart 
@_subject: cryptograph(y|er) jokes? 
Yes, but if I told you I'd have to kill you....
(oh, wait, you said good jokes.)

@_date: 2004-05-08 21:44:27
@_author: Bill Stewart 
@_subject: Can Skype be wiretapped by the authorities? 
Also no guarantee that it's not implemented sufficiently incompetently
that the Authorities can't crack it if they want.  Somebody else's message
confirmed that there's a competence problem, though there may not be exploits.
Skype uses a supernode structure to implement reflector service,
so it doesn't have the same centralization problems.
They don't document it well enough to know if it's possible to
wiretap a message by using a corrupt supernode as MITM, but perhaps.
It's frustrating that they use proprietary protocols for everything.
Their audio codec, however, is developed by a reputable company
(brain spacing out on their name, but I'd seen them before.)
Most of that company's codec designs are intended for boring
telephony-style 4khz mono audio, 64kbps uncompressed,
something small compressed, with really good loss/noise resistence,
rather than doing 7kHz or 11kHz audio or stereo sound,
but I don't know which codecs they've chosen.

@_date: 2004-10-20 22:44:58
@_author: Bill Stewart 
@_subject: Printers betray document secrets 
It turns out that their techniques aren't all that useful.
Changing laser printer cartridges changes the results.
You might find that two documents were printed
by the same printer, but it doesn't give you the
options for tracking it down that manual typewriters did.
And the differences don't identify a specific printer
in a way that can be tracked, e.g. identifying a serial number
that could be looked up from warranty records.
It's not clear that they work at all with inkjet printers,
and changing ink cartridges is even more common than
changing laser printer cartridges.  If you're sloppy,
you've probably got a bunch of partly-used cartridges around,
so even if you want to print out a bunch of ransom notes
or whatever, you don't even have to go to Kinko's
to get them to be different.
If printer makers want to build in watermarking to
make everything they print traceable, the way many of them
check for documents that look like money and don't print them,
they could hide patterns that survive cartridge changes
(would you notice a few inverted pixels on a 600x600dpi printout?)
But even then, inkjet printers are dirt cheap;
when they're on sale, they're essentially a free enclosure
in a box of overpriced printer cartridges,
so even of the printer wants to rat out the user and
it's not easy to change the serial number PROM,
you can just replace the printer.
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-10-26 18:51:10
@_author: Bill Stewart 
@_subject: Are new passports [an] identity-theft risk? 
The questions would then be, what frequency do these
There's an excellent RFID reference article at
RFIDs run at a variety of frequencies,
including 128 kHz, 13.56MHz, 915 MHz, 2.45GHz,
which are the common ISM bands that lots of other things run in,
such as cordless phones, WiFi, Microwave ovens, etc.,
which means that detecting readers may be tough.
It doesn't take a lot of power to power them;
not sure what it takes to fry them.
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-09-02 00:54:55
@_author: Bill Stewart 
@_subject: ?splints for broken hash functions 
This approach and the "cache Block 1 until the end" approach
are both special-case versions of "maintain more state" attacks.
This special case maintains 2*(size of hash output) bits of state.
The "cache block 1" case maintains
         (size of hash output) + (size of block 1) bits of state,
but doesn't change the (size of block 1) bits between cycles.
         (Also, if you're going to do that, could you maintain
         (hash(Block1)) bits between cycles instead of the raw bits?)
They both have some obvious simplicity to them,
but I'm not convinced that simplicity actually helps,
compared to other ways of getting more state.
Perhaps the effective state of the 2-IV version is
twice the size of the basic hash, perhaps it's less.
My intuition is that more mixing might be better,
and probably isn't worse, but I could easily be wrong.

@_date: 2004-09-02 01:36:04
@_author: Bill Stewart 
@_subject: Compression theory reference? 
It's a sad situation when you have to get a non-technical
judge to resolve academic conflicts like this,
but it's your head that you're banging against the wall, not mine.
If you want to appeal to authority, there's the FAQ,
which of course requires explaining the Usenet FAQ traditions;
perhaps you can find Lempel, Ziv, or Welch?
In reality, you could show an algorithm for which any input
gets at most _one_ bit longer, rather than arbitrarily longer.
And of course most of the compression algorithms work because
real data almost always has structure which reduces the entropy.
My information theory books from grad school have
long vanished into some closet, and were written
just about the time LZ came out so they mainly discuss
Huffman coding in the discrete-message sections,
but you should be able to find a modern book on the topic.
Matt Crawford's inductive argument is very strong -
it gives you a constructive way to say that
"for any integer N, I can give a proof for that N",
starting at 1 and working your way up,
showing that if there's a lossless coding that doesn't make
any messages of length N any longer, then it doesn't make any any shorter,
so it's not a compression method, just a permutation.
The "You could compress any message down to 1 bit"
argument is a great throwaway line, but it isn't rigorously valid.
(And if it were, you might as well compress down to zero bits while you're at it.)
The problem is that for most lossless compression algorithms,
some strings will get shorter (maybe even much shorter),
but some will stay the same length,
so even if you had a hypothetical "never gets longer"
compression algorithm, you can't guarantee that your
starting message would be one that got shorter as opposed to staying the same,
so you can't say that all messages would compress to zero.
If your judge doesn't like inductions that count up,
or your academic opponents insist on examining methods that count down,
Bear's argument gets you most of the way there,
by emphasizing the 1-1 mapping aspect, but you could easily get tangled.
(To do this properly, you need to do n and 2**n, but I'll use 10 for There are 1024 10-bit messages, and only 512 9-bit messages,
so something obviously happened to the >=512 that didn't compress to 9 bits.
Maybe 512 of them didn't compress further and stayed as 10-bit;
almost certainly some of them became 8 bits or shorter.
At least one message didn't get shorter, because
         (2**10 - 1) = 2**9 + 2**8 + 2**7 ... + 2**1
So if you want to recurse downwards through repeated compression,
you need to be sure your mapping keeps track of the ones that
didn't compress the first time (maybe they'll compress the second time?),
the ones that compressed by one bit,
and the ones that compressed by more than one bit,
and avoid wandering around in a maze of twisty little passages.
So working your way up is probably cleaner.
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-09-02 01:50:44
@_author: Bill Stewart 
@_subject: "Approximate" hashes 
Check out Vipul's Razor, which uses an approach similar to this.
You'll find information at Cloudmark and on Sourceforge.
There are several different kinds of differences to work around -
- damage in transit, as noted, though it's the least of your worries
         in spite of Unicode, MS Codesets, and 8-bit-uncleanness
- different mail headers getting added or subtracted or mimed
         (Some people include relevant parts in their message indexes, some - deliberate differences introduced in the message to discourage detection,
         ranging from the simple "Dear Alice"/"Dear Bob" to
         removal addresses than encode each spam victim's info,
         to different random word-scramble that's also there to
         discourage Bayesian spam-detectors.
         This one's really common these days, especially as mail systems
         have decreased the number of users they'll send to
         in a given SMTP session / envelope because of spamming -
         if you can only spam 5-10 recipients per TCP session,
         might as well make each session somewhat different
         so you only get hit by local detectors, not global indexers.
Vipul's Razor and related approaches try to calculate a unique id
for each message so that if a human detects that a message is spam,
the id can be published so everybody else trashes it.
This usually needs more than one human rating something as spam
to prevent abuse, and there's some tuning, but it's a good start.

@_date: 2004-09-10 22:54:09
@_author: Bill Stewart 
@_subject: potential new IETF WG on anonymous IPSec 
I read the draft, and I don't see how it offers any improvement
over draft-ietf-ipsec-internet-key-00.txt or Gilmore's proposal touse "open secret" as a not-very-secret pre-shared secret
that anybody who wants to can accept.
It does introduce some lower-horsepower alternatives for
authenticating less than the entire packet, and suggests
using AH which I thought was getting rather deprecated these days,
but another way to reduce horsepower needs is to use AES instead of 3DES.
Also, the author's document discusses protecting BGP to prevent
some of the recent denial-of-service attacks,
and asks for confirmation about the assertion in a message
on the IPSEC mailing list suggesting
    "E.g., it is not feasible for BGP routers to be configured with the
    appropriate certificate authorities of hundreds of thousands of peers".
Routers typically use BGP to peer with a small number of partners,
though some big ISP gateway routers might peer with a few hundred.
(A typical enterprise router would have 2-3 peers if it does BGP.)
If a router wants to learn full internet routes from its peers,
it might learn 1-200,000, but that's not the number of direct connections
that it has - it's information it learns using those connections.
And the peers don't have to be configured "rapidly without external assistance" -
you typically set up the peering link when you're setting up the
connection between an ISP and a customer or a pair of ISPs,
and if you want to use a CA mechanism to certify X.509 certs,
you can set up that information at the same time.
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-09-13 12:00:19
@_author: Bill Stewart 
@_subject: potential new IETF WG on anonymous IPSec 
Actually, FreeSWAN's "Opportunistic Encryption" meant
"if you've got IP traffic for somebody,
see if they can do encryption with you and use it if you can."
Because Gilmore wanted to make sure encryption was always done securely,
their implementation used a common PKI - DNSSEC and inverse DNS -
which has the advantage that a security gateway can use it when
all it knows is the IP address of the destination (which is typically the but the severe disadvantage that very few people have control
over that DNS space and also that an IP address may belong to more than one There's a significant policy question there - if you don't have
a common PKI of some sort, is it worthwhile encrypting anyway,
protecting against passive eavesdroppers but not MITM,
or is that a false sense of security because the people who
most need security are the people most likely to have a government
annoyed enough at them to do the work of running a MITM attack?
Encryption against passive eavesdroppers makes password-stealing
and traffic analysis harder, so it's probably worth the risk,
but that wasn't the choice that FreeSWAM made.
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-09-16 16:57:39
@_author: Bill Stewart 
@_subject: public-key: the wrong model for email? 
I don't understand the threat model here.  The usual models are
- Key too short - Obvious to the sender
- Recipient's machine is compromised
         - Not obvious to sender, but not fixable by email program
- Recipient is stupid and careless
         - Often obvious to sender, but not fixable by email program
- Recipient's Public Key generator system generates weak keys
         - Hard for sender to detect and work around
         - Usually requires extra work by recipient to obtain
         compromised software, unless mandated by Corporate IT Droids
         - Recipient can reduce risk by using open source software
- Recipient's Public Key generator mails copy of private key to          - Indistinguishable from previous case
- Recipient's Client Software mails copy of session key to ashcroft.kgbvax.gop
         - Indistinguishable from previous case
- Recipient's Email Client forwards incoming mail message plaintext
         disguised as bouncegrams or viruses.
         - Indistinguishable from previous case.
- Recipient's Secret Key is recipient's dog's name spelled backwards,
         written on yellow sticky note pasted next to open window,
         under the big mirror with a good view of recipient's keyboard and          - Not a software problem
- Recipient's Computer Disk automatically backed up to optical storage at night
         - No sense subpoenaing cyphertext when you can subpoena plaintext.
You're focusing on a relatively niche threat model,
unless there's some operational aspect here I'm missing.
If you wanted to do something fancy, you could insist that the
recipient send the sender a Diffie-Hellmann Half-Key,
which you use to generate a session key that you use for message encryption,
and transmit your DH half-key along with the encrypted message
for the sender to decrypt.  It's still subject to most of the same threats
as the RSA-like public-key model, though maybe it's a bit easier
to detect weak Diffie-Hellmann keys.  However, unless you want to
force the recipient to change their client interface,
the easier place to implement something is in their SMTP client,
and the obvious way to do that is some variant on SSL-SMTP.
If you _still_ want more control, set up a web server,
and instead of sending your actual secret message, send
Encrypt ( Key=Alice, Message="
         ----- BEGIN PGP SIGNED MESSAGE
         Alice - I've sent you an encrypted message at
                                  This URL will self-destruct in 5 business days.
                         - Bob
         ----- END PGP SIGNED MESSAGE
         ")
However, if Alice was using a compromised email client,
she could just as easily be using a compromised browser.

@_date: 2004-09-17 10:00:09
@_author: Bill Stewart 
@_subject: How to implement a self-destructing message. 
That's been done, by "Disappearing Inc".
  says they're now owned by Omniva.
The proprietor gave a talk at a Cypherpunks meeting some years ago,
after they'd done a big Scannelly splash in USA Today.
He started out by identifying the problem he was trying to solve,
which is for routine document destruction -
a cooperating sender and receiver want to know
that their message will disappear after some time
if neither of them tries to make other copies or work around the system;
the problem of making a truly non-copyable system is snake oil
that he wasn't going to try to sell.
The system creates a session key and a cookie,
which it sends to a policy server,
encrypts the message with the session key,
and includes the cookie and encrypted message in the email.
The recipient's mail client handles and stores the encrypted message,
and when the recipient wants to read it,
he runs a Disappearing Inc. crypto client which
sends the cookie to the policy server, gets the session key,
and decrypts the mail in a viewer program.
After whatever timeout the sender specifies,
the policy server deletes the key and cookie,
so the recipient can no longer decrypt the message.
Originally the business model was that Disappearing Inc.
ran the policy server, and it was accessible using https or whatever,
but they later also started selling servers to customers.
The system obviously doesn't stop the recipient from
screen-scraping the message (don't remember if it supported cut&paste),
but it's designed for the Ollie North problem
         "What do you mean the email system backs up all messages
         on optical disk?  I thought I deleted the evidence!"
or the business equivalent (anti-trust suit wants all your
correspondence from the last 17 years.)
It's not a perfect system - courts can order the policy server
not to delete any data, for instance - but any data that
has been deleted before then has really been deleted,
assuming the policy server's disk isn't also backed up on optical.
And Ed Gerck gets to know that his message was transmitted
with adequate encryption under control of the sender.
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-09-27 17:08:49
@_author: Bill Stewart 
@_subject: An interesting "new" computer security problem 
Unless it's been radically updated in the decade or so since I last read it,
don't you need the book with the Red cover as well?  And maybe the purple one,
or whatever color the multi-level database stuff was?
Bill Stewart  bill.stewart at pobox.com

@_date: 2004-09-27 23:00:10
@_author: Bill Stewart 
@_subject: Linux-based wireless mesh suite adds crypto engine support 
In the past, there have been two main problems with the Via crypto sets
- availability of convenient software
- sufficient documentation and really transparent provable details
         so that users could trust and verify that the hardware and software
         were doing what they claimed to be doing and
         weren't doing anything evil that they didn't admit to,
         such as including backdoors or bad random number generators.
For typical applications, this is probably fine,
though I haven't looked at Via's licenses to see if they can
easily be used with a GPL license or if they need LGPL+Weaselwords or worse.
The hard part is trust - Cryptography Research did a study last year
about the quality of the random number generator, and found that you
get about 0.75 bits of entropy per output bit, or 0.99 if you do
Von Neumann whitening, so it's fine for feeding your crypto-based whitener.
But their report indicates that they were mainly working from
design documentation and testing actual equipment,
so their tests doesn't show what the RNG does if you execute
         SET MSR UNDOCUMENTED_EVIL_WIRETAP_MODE
first, much less what happens to the AES keying info or IVs.
Disclaimer:  I'd be really surprised if UNDOCUMENTED_EVIL_WIRETAP_MODE exists -
the folks who built the crypto features in say good pro-privacy things,
and I'm inclined to trust them.  I'm much less sure about the
nonexistence of OBSCURE_BUGGY_RNG_CONDITION_MODE.
It's very hard to test for these things when you've got complete documentation,
even if Ken Thompson wasn't helping write your compilers.
                 Bill Stewart

@_date: 2004-09-30 13:43:10
@_author: Bill Stewart 
@_subject: Linux-based wireless mesh suite adds crypto engine support 
> Tinfoil-hat mode.
Agreed, but some people want to be thorough, or pedantic, or paranoid.
A somewhat simpler backdoor could be used in block chaining modes.
Occasionally output the data you're leaking instead of one or a few blocks
of cyphertext, and the CBC will glitch on it and then resync a few blocks in many environments the application layer will correct for it,
e.g. IPSEC will lose a few packets, TCP will timeout and retransmit,
and 3 seconds later it's as if nothing happened except that
the private keypart has been leaked for the passive eavesdropper.
Bill Stewart  bill.stewart at pobox.com

@_date: 2005-04-08 22:17:46
@_author: Bill Stewart 
@_subject: how email encryption should work 
I see a couple of problems with your proposal.
I'm not sure I like your external trusted mail-server assumptions,
but they're probably good enough for many people,
and other people will have better comments about them.
Your plan is really designed for a small number of addresses per sender,
as opposed to a quasi-infinite set of tagged addresses.
It's becoming pretty common for anti-spam reasons
to give different recipients different mail addresses like
         tag at mydomain.com (or tag at mysubdomain.domain.com) or
         myname+tag at domain.com
so you can track and whitelist/blacklist people you communicate with,
and some ISPs automagically translate between the two formats.
Building a user interface that does that unobtrusively
is probably a hard problem, or at least not a well-solved one,
and building a cryptosystem that assumes a small number of
addresses per user could make that style of mailer harder.
A good user interface probably has some version of petname support,
though, so there's some commonality with key handling.
On the other hand, if you assume that most people will get domains,
whether 2LD or 3LD or other subdomain,
you could do a model that says that a user gets one key per domain,
so you could think about hanging the keys off DNS.
That may not be the right choice (do you want your email addresses
to be easily correlated, and cracking/stealing one address's key
to reveal the keys you use for everybody else?  Or does the domain
pretty much imply that to the skilled recipient anyway so who cares?)
And of course it gets into the whole squabble about DNSSEC,
and why its deployment failed, and whether it was trying to do
a perfect job and therefore less scalable than a mostly-good-enough job,
or at least into the politics of those questions if not the technology.
The related problem is what to do if you *do* want different keys
for different recipients; you could do that with different subdomains,
or you could do a non-DNS approach.
- Is (sender+recipient+timestamp+message) the right thing to sign?
The Subject: line is in the mail headers, but it's probably
something that should be part of the message.
I'm not sure about some various X-headers.
And of course the From: line includes both the email address
and the sender's name, and the sender's name may be different
for different recipients (in some sense, it may be the
recipient's petname for the sender.)
- Also, if you're attaching a key strictly to the email address,
what happens to old signatures if you move email addresses?
I suppose that's part of the point of getting your own domain name,
so you can avoid having to change contact addresses when you change ISPs,
but if you're using a new email address, how do you forward the signature?
One option is to do what you can do in Crypto Kong,
where you send a message from old-address signed by old-address,
saying that you'll be using new address and new key,
but that seems a bit awkward, since you need a convenient way to
include the new keys for people who whitelist you or who you
only want to send encrypted mail to.
         Thanks; Bill Stewart

@_date: 2005-12-07 19:21:35
@_author: Bill Stewart 
@_subject: [Clips] Banks Seek Better Online-Security Tools  
I've used it for about a decade at my credit union,
and I've had my paychecks deposited directly for decades.
There are things I absolutely won't do,
like have a debit card attached to the account,
or have companies authorized to take money out directly,
or have electronic checks of various sorts taken out of the account.
Normally I don't do email with them (though nobody appears to have
noticed them as a phishing target), but I did have one time
I had to ask about a transaction, and they do that by email,
so I was able to trust the responses.
But for basic services where I tell them what to send to whom,
it's reliable, appears to be at least as secure as
the other risks to the account, and it means that the
basic payments I need to make every month happen automatically,
so I only have to pay attention to the occasional variable transaction.
I've also used account-based electronic gold services,
but only transactionally, so at most they end up with a couple dollars
worth of exchange-rate breakage in them, and there are some
non-account-based services that I've also used.
I won't use e-gold - not that their website is obviously insecure,
but for a while there was so much e-gold phishing that
I set my filters to automatically discard anything purporting
to be from them, which might interfere with doing real business.
On the other hand, they don't appear to state a policy of
always digitally signing all transactions, so I'm a bit concerned
beyond the more blatant phishing risks.
                 Thanks; Bill Stewart

@_date: 2005-12-09 15:39:04
@_author: Bill Stewart 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
Usability is a hard problem, and security is a really broad field.
PGP, for instance, did a pretty good job of security a decade ago,
given Phil's threat models, (ignoring a few algorithm problems
that were mostly related to trying to skimp on bits
and the subsequent weaknesses in MD5),
but the usability was pretty rough back then,
and version compatibility has gotten enough worse that
Hugh Daniel and I can no longer reliably communicate with PGP.
But even if we both drop back to GPG on text files,
and use remailers run by friends on Tor nodes run by random strangers,
KGB-proof security would require protection against
black-bag jobs on Hugh's keyboards and duping employees
at my company's IT department into weakening my Windows XP configuration.
(For cost-effectiveness and avoidance of detection,
I'd recommend the latter strategy, probably by selling them
some new nifty administration tool or Instant Messaging client :-)
The real security issue for your mother is threat models.
If your mom isn't using a Mac or administering her own Linux box,
then her biggest security threat is that she's computing
on a box made of Swiss cheese (though XP does seem to be
noticeably better than Win95/98/ME) and probably using a browser
that's happy to accept random software installed by spammers
and phishers, and if she's not using webmail,
she's probably running a mail client that happily displays
clickable links to phishing sites purporting to be eBay or her bank.
And that's mostly independent of whether she can trustably
send email to other members of the Ladies' Sewing Circle and
Terrorist Society without the Feds reading it,
which is the kind of problem PGP was trying to solve,
because her bank and eBay don't cryptographically sign their mail.
Popularity of a product is critical to its security;
you don't gain anonymity if the Feds can recognize that
you're one of the dozen users of a given application.
Your mom can use Skype, but nobody she knows uses Crypto Kong,
and I only know a few people who use PGP to email their mom.
But some of the Instant Messaging systems use crypto;
too bad that they're continually trying to be incompatible
with each other to gain market share.

@_date: 2005-12-17 22:05:29
@_author: Bill Stewart 
@_subject: crypto for the average programmer 
This is in fact one reason that ASN.1 exploits
have been so wide-ranging when they've happened.
ASN.1 is a horrendously ugly mess, even uglier than PGP,
so almost everybody uses an existing library instead of
rolling their own or writing a new library for other users.
Major bugs aren't discovered often,
but everybody's pretty much using the same C code,
whether for SNMP or X.509 or whatever.
I don't know how many of the Java et al. versions
have rewritten it natively as opposed to importing
C libraries, which is probably more convenient.

@_date: 2005-12-18 14:58:30
@_author: Bill Stewart 
@_subject: A small editorial about recent events. 
One of the NYT articles also said that the
President's lawyers gave him an opinion saying that the
post-9/11 resolutions gave him the authority to do this.
If the resolutions actually did that, then that could
supersede the previous laws that made it criminal.
But this wasn't the only domestic spying story in the news this week.
NBC reports that the Defense Department is back to
CONINTELPRO-style spying on Americans,
specifically anti-war groups and campaigns against military recruiting,
especially suspicious groups associating with Quakers.
And the EU parliament just voted on massive data collection laws,
requiring ISPs, telcos, and mobile phone companies to
collect and retain information in ways that would have
previously violated EU privacy laws.
That's one of the big problems with protections based on laws -
they're only good until the politicians change the laws.
Constitutional protections are somewhat more durable,
but can still be changed either by Amendments or by
significant changes in court interpretations,
such as the Drugs and Terrorism Exceptions to the Bill of Rights
and the expansion of the Commerce Clause to cover almost everything.
One of the Bush Administration's innovations has been
White House legal opinions telling the President that
the courts ought to approve various powers or practices,
so there's therefore no need to actually take them to court,
whether it's wiretapping or "extraordinary rendition" or
defining "torture" to exclude anything done by US forces.
We'll see if he gets away with it this time -
he needs to be stopped.

@_date: 2005-12-21 19:11:41
@_author: Bill Stewart 
@_subject: another feature RNGs could provide 
The groups-are-bad problem applies to the
mapping between keys and plaintext-cyphertext bijections,
not the mapping between plaintext and cyphertext.
You're trying to avoid the situation where
         E(x,key1) == E( E(x,key2), key3) for all x
The mapping between plaintext and cyphertext doesn't need to be 1-1 1-n mappings from 1 plaintext to multiple cyphertexts
can work fine for many applications,
but have the practicality problem that the cyphertext is
longer than the plaintext, and there aren't many
applications where you really want the expansion.

@_date: 2005-01-04 19:18:54
@_author: Bill Stewart 
@_subject: Banks Test ID Device for Online Security 
Yup.  It's the little keychain frob that gives you a string of numbers,
updated every 30 seconds or so, which stays roughly in sync with a server,
so you can use them as one-time passwords
instead of storing a password that's good for a long term.
So if the phisher cons you into handing over your information,
they've got to rip you off in nearly-real-time with a MITM game
instead of getting a password they can reuse, sell, etc.
That's still a serious risk for a bank,
since the scammer can use it to log in to the web site
and then do a bunch of transactions quickly;
it's less vulnerable if the bank insists on a new SecurID hit for
every dangerous transaction, but that's too annoying for most customers.
Bill Stewart  bill.stewart at pobox.com

@_date: 2005-01-08 23:14:31
@_author: Bill Stewart 
@_subject: "The Reader of Gentlemen's Mail", by David Kahn 
My wife was channel-surfing and ran across David Kahn talking about his recent book
"The Reader of Gentlemen's Mail: Herbert O. Yardley and the Birth of American Codebreaking".
ISBN 0300098464 , Yale University Press, March 2004
Amazon's page has a couple of good detailed reviews
Bill Stewart  bill.stewart at pobox.com

@_date: 2005-07-12 14:48:02
@_author: Bill Stewart 
@_subject: the limits of crypto and authentication 
On the other hand, only a short time before that,
Apple's iMac created a whole marketing revolution
and set of spinoff products and revitalized the company
by coming out with a semi-transparent blue-green case
that effectively packaged the Reality Distortion Field,
and they were able to maintain the effect over several years
by the radical introduction of several other semi-transparent colors.
It'd be nice if good crypto and authentication methods
could create a market for improved products,
but hey, if blue-green translucent dancing pigs gets customers,
the marketing people have done _their_ job.

@_date: 2005-07-15 16:47:20
@_author: Bill Stewart 
@_subject: the limits of crypto and authentication 
By now you've probably seen Lucky's party announcement,
but they actually expire next week.
17-year and 20-year patent lifetimes are *way* too long.

@_date: 2005-06-06 02:43:44
@_author: Bill Stewart 
@_subject: Papers about "Algorithm hiding" ? 
Of course they have it -
the problem is having crypto in a way that's not suspicious,
and "suspicious" is highly dependent on your threat model.
For instance, Microsoft Word has crypto -
it's lousy crypto, which isn't directly relevant here,
but it's a utility that people view as normal,
while PGP is inherently suspicious-looking.
No reason that OpenOffice couldn't have crypto that's actually reasonable The "rename the binaries" strategy is probably more reliable than cyphersaber etc.

@_date: 2005-06-23 13:33:23
@_author: Bill Stewart 
@_subject: AES cache timing attack 
Would switching to triple-AES (or double-AES) or something help?
Yeah, it's ugly, and AES was supposed to let us get away from triple-DES,
but maybe running one AES with the original key and
the other session with the inverse of the key would
interfere with timing attacks?

@_date: 2005-03-15 13:13:14
@_author: Bill Stewart 
@_subject: Encryption plugins for gaim 
AOL says that the ToS bits are only for things like chatrooms;
user-to-user AIM traffic doesn't even go through their servers.
That doesn't mean they can't eavesdrop on it if they want to,
or that they don't have mechanisms for automating MITM,
so you may very well want to use encryption,
but at least in the normal case your traffic is relatively private.

@_date: 2005-11-09 18:54:08
@_author: Bill Stewart 
@_subject: RSA-640 factored 
The most important thing it tells us is that the workload for
cracking RSA-768 has definitely moved from
"No, Never!" to "Well, Hardly Ever", so in case anybody was still
thinking about using 768-bit or shorter keys,
they should now know better.  The fact that it only took 80 boxes 5 months
to crack 640-bit means that an attacker with an NSA-sized budget
is definitely a threat to 768-bit keys,
even if they're not necessarily commercially cost-effective to crack.
Separately, Shamir's work on various crypto-magical factorization machines
has also meant that 1024-bit keys aren't safe from organizations
with large science budgets.
         Bill Stewart

@_date: 2005-11-22 01:02:24
@_author: Bill Stewart 
@_subject: "ISAKMP" flaws? 
No, it was still Phil's old heavily-used petard,
worked over by various other people from PGP 3.0 and PGP Inc.
Jon was going for backwards compatibility in the OpenPGP specs.
He may have cleaned up the specs a bit,
and fixed some of the security holes from VL-integer exploits,
but unfortunately OpenPGP retained almost all the old ugliness.
I was always grumpy about the impossibility of doing stealth easily
in the native PGP formats and the fact that the OpenPGP code
fossilized it.  For political reasons I'd have also liked
PGP to have had an optional very simple format so you could
fit it into one page of Perl or equivalent to go with the
RSA in 4 lines of Perl or lisp.

@_date: 2006-04-28 23:05:57
@_author: Bill Stewart 
@_subject: VoIP and phishing 
There are two sides to the voice phishing here -
- getting the target to call a phone number you've emailed him
- using cheap voice calls to call the target with your offer.
VOIP doesn't affect the former case much,
since the target is paying for the call,
but it does separate callee geography from phone numbers,
so you can use a plausible phone number (e.g. New York)
that's directed to a location with cheap criminal labor,
without the effort that used to be required to set up
FX numbers or expensive international private lines
or locate your call center in the target's country or state.
I've received one Nigerian 419 phone call, a few years back,
which used a Deaf Relay Operator to relay the call from
the scammer, and apparently they used to be heavy abusers of that service.
VOIP also makes that more practical, and somebody's coined
the term "spit" to refer to Spam over IP Telephony.
But phone calls are cheap enough that labor is the
dominant cost of the calls.  I receive frequent
offers to refinance my mortgage or get credit cards
that use presumably-standard phone banks, usually calling
from India and claiming to be US banks.
For all I know, they really are legitimate rude bankers
instead of scammers, but I don't care either way.
VOIP may have replaced voice over frame as the transmission medium,
but it's often an enabling technology for the telco rather than
voice over internet to the end user.
I've been at a lot of telecom trade shows recently,
and vendors have been showing off session border controllers
and various security devices and presence servers,
and while there are lots of tools to let the recipient
indicate whether he's accepting calls or not,
there doesn't seem to be much out there to detect and
reject unwanted calls wholesale.  Most of what I've seen
that's somewhat in that direction are buddy-list tools that
let your spouse/boss/etc. reach you directly and divert other
callers to voice mail or whatever, but within a year or two
we'll start needing to get more sophisticated filters the
way we do with email.

@_date: 2006-08-15 10:37:20
@_author: Bill Stewart 
@_subject: Hamiltonian path as protection against DOS. 
Crypto is usually about economics and scalability.
If you're doing this for DOS/DDOS prevention,
you don't need the NP-completeness perfection you get from
Hamiltonian paths or similar problems - SHA is fine,
or any other hash that's quick to verify and
hard to reverse.  Even MD5 is probably still ok...
Calculating any of the hashes probably takes less time than
handling the packets does.
It's almost certainly better for you if they harass you by
sending you bogus SHA pieces that you can process quickly
than bogus DH pieces that take you a while,
and if it's not too distributed an attack,
you can also blacklist senders IP addresses.
At present I'm skeptical about the need for
that kind of protection - a simple UDP or TCP handshake
and maybe a Photuris cookie are enough to
take care of most forgery attacks
and let you blacklist hostile senders.
But malware writers are tenacious bastards,
and perhaps there are or will be applications where
this sort of protection could be useful -
merely insisting that attackers use _your_ protocol
is probably enough to cut down on 99.99% of attacks
unless you get the protocol widely adopted.

@_date: 2006-12-10 12:58:07
@_author: Bill Stewart 
@_subject: cellphones as room bugs 
Cell phones already compress voice, to reduce spectrum needs,
and that's done in hardware rather than wasting CPU.
If the phone's design is sufficiently general, it can easily grab
the compressed voice bits and store them in memory instead of transmitting
(assuming there's enough memory, which isn't necessarily the case.)
Voice compression rates are typically 5.6 - 6.5kbps, or 13 on some GSM flavors,
and you may gain a bit from silence suppression depending on
whether the microphone can adequately hear the other speaker.
If the phone doesn't have data networking features,
or only has the slow types (CDPD, etc.) used to handle text messages,
there's probably no big advantage to doing this.
But if you've got faster data service, say 50-60kbps or the newer
~~200-300kbps stuff, then you can transmit faster than real-time speech,
and if you can buffer enough data, say 1 MB for 20 minutes of talk time,
you might save some battery.

@_date: 2006-02-04 23:04:41
@_author: Bill Stewart 
@_subject: EDP (entropy distribution protocol), userland PRNG design 
One-time pads are expensive protocols to use properly -
the operational costs of generating easily-disposable media,
putting couriers with briefcases handcuffed to their arms onto airplanes,
shredder costs when trashing the CD/DVD/etc., /dev/thermite for the PCs,
and all the other things that you need to do for a real OTP threat model
add up to real money after a while.
If you can afford that, you can afford to spend $100 for an
external sound card or USB hardware random generator dongle or whatever
or a PC case with more slots in it.

@_date: 2006-01-04 21:03:09
@_author: Bill Stewart 
@_subject: [coderman@gmail.com: Re: [dave@farber.net: [IP] more on AP 
Strikes me as a fairly silly project, except for the fun of coding it.
There are a number of protocols like EKE, SPEKE, A-EKE, etc.
that let you combine a shared password with public-key encryption
for extra strength - a crude variant would be to encrypt your
Diffie-Hellmann keyparts with AES for the key exchange,
so there's nothing that can be conveniently attacked when the
hypothetical Quantum Computer comes online.
There's still a risk of compromising your keys if
the KGB blackbags your machine, so you might want to
change keys annually or monthly or whatever,
but your OTPs are at risk just as a password would be.
And long before Quantum Computers become strong enough to crack
2048-bit public key algorithms at a price that makes the
KGB want to waste its resources on you, there'll be
more convenient ways to blackbag machines, whether it's
including extra features in the OS through the audio CD player
or putting a video camera in your ceiling.

@_date: 2006-02-28 23:58:25
@_author: Bill Stewart 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
Keyservers are a peripheral issue in PGP -
important for convenience and for quick distribution of revocation lists,
but they're very strongly just a tool for convenience.
Security through Inconvenience is one flipside of Security through Obscurity, I suppose...
If you've got a threat model that includes traffic analysis,
then either you and your unindicted co-conspirators
need to find other ways to exchange keys,
like printing them on business cards,
or find a keyserver that lets you suck down all the keys
so it's not obvious which key you're looking for,
or start using Tor to access the keyservers.
Or you could try using the Google Keyserver -
   just because there isn't one
doesn't mean you can't type in "9E94 4513 3983 5F70"
or 9383DE06   or   bob at bob.com "PGP Key"
and see what's in Google's cache.

@_date: 2006-02-28 23:35:18
@_author: Bill Stewart 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use 
At 01:42 PM 2/26/2006, someone alleging to be Trevor Perrin replied to some The short-fingerprint handle for long keys and the
troubles of fetching long keys conveniently and reliably are a
major problem with PGP, S/MIME, and just about anything else
that uses RSA or El Gamal or other algorithms that require long keys,
and therefore you need keyservers or other awkward mechanisms
in addition to needing some validation technique for the keys.
Elliptic Curve Crypto makes it possible to use keys that are
short enough to hand around like fingerprints -
print them on business cards, use them in email signature lines, etc.
James Donald's Crypto Kong was an interesting experiment in
user interfaces for ECC crypto and in how users interact with each other,
and while there were things I didn't like about it,
the encryption and signed-message formats were short and sweet and unobtrusive,
and could be used just about as well for other user models.
The real question with ECC, other than patents, which don't seem to
interfere too much right now and will gradually go away,
is how long the keys need to be, and how long they can be trusted.
~~160-bit keys were short enough to be convenient.
256-bit is probably about the limit - I've seen some discussion
of 512-bit keys, and at that point you're pushed into
message formats that make it inconvenient to exchange keys again.
Is there a consensus view about what keylengths are reliable?
                 Thanks; Bill Stewart

@_date: 2006-03-10 02:38:54
@_author: Bill Stewart 
@_subject: bounded storage model - why is R organized as 2-d array? 
Unless you're using your Linksys for file-sharing between machines at home,
you're not likely to be encrypting more than about 6 Mbps
(or whatever DSL and Cable Modem do these days in better cities.)
I'd trust RC4-used-correctly before trusting Tri-Strata,
if there weren't so much bad history of people misusing RC4...

@_date: 2006-11-05 02:10:28
@_author: Bill Stewart 
@_subject: Cypherpunks make the OED :-) 
James Gleick's NYT article on the OED mentions "cypherpunk"
among the words recently added to the dictionary.
The page requires registration to access, though there are enough
popular pseudonyms that have done so; I don't know if any of the
"cypherpunks/somepassword" combinations still work;
I've been using one of the no-response email systems for my login.
I don't have a subscription to the online dictionary to
see what they said about it.

@_date: 2006-10-23 15:46:38
@_author: Bill Stewart 
@_subject: Spammer using Graphical Steganography 
Spammers have been including images in their email to evade anti-spammers.
Anti-spammers have been using OCR to identify spammy words in images.
Spammers have recently come up with tricks to work around OCRs,
by doing steganography with animated GIF images.
One approach they're taking is to build the real image progressively,
first drawing a background, then drawing parts of the image
(one spammer uses transparent pixels to do parts of it, showing dark parts of background),
then waiting a long time and drawing a blank page in case anything's checking the final image.
Spammers dodging OCR with .gif 'cut-and-paste'
By Paul McNamara on Fri, 10/20/2006 - 2:11pm
Spammers have begun slipping their junk past optical character recognition (OCR) software through a variety of animated .gif "cut-and-paste" techniques, says John Graham-Cumming, an anti-spam activist who maintains The Spammers' Compendium and also founded Electric Cloud.
On blog posts this week -- here and here

@_date: 2006-09-21 00:34:43
@_author: Bill Stewart 
@_subject: Public Key Cryptography 30th Anniversary Event - 10/26, 
Celebrating 30 years of Public Key Cryptography (PKC)
Join the Computer History Museum for a special public event celebrating 30
years of public key cryptography. This memorable evening celebration will
honor the inventors, the inventions, the milestones, and the future of PKC.
The program is moderated by Steven Levy, author of Crypto and senior editor
Newsweek, and includes Ray Ozzie, Whitfield Diffie, Martin Hellman, Jim
Bidzos, Dan Boneh, Brian Snow, and John Markoff.  All will share their
opinions on the state of the industry today and an audience question and
answer session will complete the evening.
Go to
 to register for this exclusive
celebration.  Space is limited, so register
Please join us on October 26th for this networking reception and panel
presentation. Mark your calendar now, and visit
 to register for this celebration.
Space is limited, so register today.
s p o n s o r e d  b y  Voltage Security and RSA:
You are currently part of the Lecture announcement list of the Computer
History Museum. To unsubscribe, please reply to this message with the word
"remove" in the subject line.

@_date: 2007-12-28 17:35:14
@_author: Bill Stewart 
@_subject: 2008: The year of hack the vote? 
> Let's not do this or we'll have to talk about JF Kennedy
 > who, at least, bought his votes with real money.
That's because Democrats had become more professional,
and the tradition of buying votes with whiskey
only works for the retail level, not wholesale.
The primary threats of electronic voting machines aren't
to the individual voter,
who can slightly increase the chances of getting
his/her vote counted accurately by insisting on paper ballots,
but to the aggregate vote count, which can be hacked
if the precinct has _any_ electronic machines.
The big problem in Ohio appears to have been Denial of Service -
not that there weren't lots of other problems,
but electronic voting systems have sufficient complexity that
an elections department can arrange to have enough
missing parts or supplies or passwords or powercords or whatever
in demographically appropriate precincts so that the
results get skewed even without Other Technical Means.
Some of the black inner-city precincts had two-hour lines
(on a rainy day), while white Republican-leaning precincts
had all the equipment they needed.
(Also, if you're saying "only an idiot would use it"
and ask how gambling sites exist, the answer is that
only idiots gamble...   As Ed Gerck pointed out,
risk in e-commerce can be managed and amortized into the price,
but that doesn't work for voting.)

@_date: 2007-01-19 00:11:40
@_author: Bill Stewart 
@_subject: Private Key Generation from Passwords/phrases 
One of the roots of the problem is that for many applications,
i is a well-defined event and P(i) is a fixed value (for i) ,
but for many other applications,
i might not be a well-defined event, and/or
P(i) is really a conditional probability, P(i|other-stuff-you-know),
and it's hard to tell whether that's
usefully different from the non-conditional P(i).
One case where this comes up is key generation with entropy pools -
you take a bunch of hopefully-kinda-independent,
hopefully-identically-distributed variables generated
by processes that are complicated enough to look random,
make some estimates of their probability distributions
and hence of their entropy, and add the estimates together,
after prewhitening the samples to make any correlation
harder to exploit.  This gives you N bits of entropy,
and you take M bits of it to use as a key,
again possibly with some hash functions to make
calculations more difficult.
So how many bits of entropy are left?
You can be conservative and call it N-M,
assuming that if somebody were clever enough to take
the M bits key sample they could validate the rest
with only N-M calls to an oracle,
or you could be wildly optimistic and call it N,
assuming that the conditional probabilities of the
remaining pool are still the same given that you know the M bits,
because there's no way to use them to validate anything,
and if you've done a good enough job of designing your
pool management functions the reality is probably
closer to the wildly optimistic case,
unless somebody finds an efficient way to invert your hash functions,
at which point the conditional probabilities are actually
different if you know the M key bits than if you don't.
Another entropy example was the Venona decryptions -
people banging "randomly" on typewriters didn't actually produce
independent or identically distributed letters,
so the conditional probabilities didn't actually match
the assumed ones, so the entropy estimates were wrong,
and human language plaintext being what it is,
they really needed the 1-bit-per-bit of key entropy.
It's much tougher to exploit than OTPs used more than once,
but it's a start.
But hey, nobody's going to guess that your password
is your dog's name spelled backwards, or think of using
a list of a few million obvious passwords as input to
the key-generation function.

@_date: 2007-01-19 01:06:14
@_author: Bill Stewart 
@_subject: It's a Presidential Mandate, Feds use it. How come you are 
m>
As far as "Full Disk Encryption"'s usefulness as a term goes,
I'd distinguish between several different kinds of applications
for encrypting the contents of a disk
1 - The disk drive or maybe disk controller card (RAID, SCSI, etc.)
2 - The operating system's driver software
3 - The operating system's file system driver software
4 - Utility software encrypts/decrypts bits written to/from directories.
5 - Application software encrypts/decrypts contents of files.
Obviously if you're trying to protect against KGB-skilled attacks
on stolen/confiscated hardware, you'd like to have the swap partition
encrypted as well as any user data partitions, though you may not care
whether your read-only utility software was protected
(e.g. your Knoppix disk or vanilla shared /usr/ or whatever.)
Whether you implement that in the disk controller or OS is really
a matter of convenience and user support economics -
if you're a small conspiracy you may want to roll your own,
but if you're a corporate IT shop, you've probably got economic issues
that affect whether you customize the OS (more) or the disks or both
and it's the operational processes that will trip you up.
On the other hand, if you're trying to protect against
lower-skilled attackers, e.g. laptop thieves who are reselling
disks to the Nigerians and other hardware on eBay,
you want to protect your file systems,
but probably don't need to protect your swap.
It's certainly nice to do that, of course, and might be a Good Thing
for Linux and ***BSD to include in their standard swap drivers,
but hopefully your file system drivers would keep their keys
in non-swappable memory, and most other things get overwritten
often enough that attackers not using electron microscopes
probably won't bother with them much.  In most OS's,
swap isn't persistent across system reboots,
so you can actually generate a new key on the fly every time
and not bother the user about entering it, unlike regular filesystems
or full-disk-encryption systems.
Of course, if the KGB *is* after you, they may black-bag your PC
before they confiscate it - if there's a key-logger chip
added to your keyboard or a camera mounted in your ceiling light,
it may not matter how cool your FDE is.

@_date: 2007-01-23 17:50:27
@_author: Bill Stewart 
@_subject: Private Key Generation from Passwords/phrases 
Different decade, different threat models, different scales.
It was probably pretty rare to have more than a
couple of hundred users on a PDP-11,
but even at 60-70 you're in birthday-collision range with a 12-bit salt.
But a website could easily have a million users in its password files,
and some systems like Yahoo and Hotmail have hundreds of millions,
though obviously they're not all separate Unix userids.
Sometimes it matters if they get stolen, sometimes not -
I don't care if someone discovers that
my New York Times web password is "password",
but I'd be really annoyed if my online banking password got cracked.
Salt is designed to address a couple of threats
- Pre-computing password dictionaries for attacking wimpy passwords
         These become harder to do online, pushing a dictionary of
         e.g. a million words to 4 billion, or ~32GB,
         an unreasonably large database for ~1975 crackers,
         though obviously you could use a manageable stack of tapes.
         Today that fits in my iPod, though it's still impractical
         to store an unsalted full-56-bit DES password dictionary.
- Detecting password collisions within systems, and between systems
         Testing a known password against 4096 salts
         took a long time at 0.5 MIPS, but it's faster at 4000 MHz.
         Large systems will have internal collisions,
         and the web makes it even more likely that somebody
         will have logins on insecure systems
         that might have the same password as their "secure" logins.
- Annoying then-hypothetical hardware DES crackers
         That's still useful against some designs today,
         though many designs, especially software,
         are table-driven in ways that aren't annoyed much.
There are probably times that salt is useful, and that password files
using hashes are useful, but I'd think that if you're going to do that
today you might as well use 64 or preferably 128 bits of salt,
and of course you might want a hash other than MD5 or SHA-1.

@_date: 2007-07-11 08:59:32
@_author: Bill Stewart 
@_subject: How the Greek cellphone network was tapped. 
Of course they do, at least in the US,
where the mobile phones are generally carrier-specific,
often locked, and generally don't have open designs.
In particular, they're not usually designed to let the
data applications get at the voice compression ASICs,
but they usually don't have enough CPU to compress voice in Java
if they can get at the voice stream at all.
Some of the PDA phones are more flexible, and I'd expect
OpenMoko to be much more flexible.
They're getting better about it, but the transmission characteristics
from most of the data protocols aren't designed for voice,
unless you're willing to do push-to-talk or equivalent.
So ironically, if you want to get good latency for 5.3kbps voice,
you'll want the fastest data protocols.
HSDPA's latency is 100-200ms, and upstream is 100+ kbps -
you could probably run uncompressed voice which is about 80kbps,
since latency's less of a problem.
(EDGE has upstream of 40-60kbps, but latency is 350+
so the more compressed protocols aren't going to behave.
I don't have the 1xRTT numbers handy, but I think they're similar.)

@_date: 2007-07-18 15:43:01
@_author: Bill Stewart 
@_subject: How the Greek cellphone network was tapped. 
> With current CPUs and audio codecs you can get
 > decent voice quality over 9600bps.
Yes and no.  There are lots of 8kbps codecs, and some 6.5 and 5.3kbps codecs,
all off which give acceptable voice quality if transmission's ok.
(And you can reduce average transmission rates by 40-50% with silence However, that's the raw codec rate - if you're taking the VOIP packets,
wrapping them in RTP, UDP, and IP headers, and then transmitting them on
a layer 2 protocol with as little overhead as PPP or Frame,
the 8kbps becomes more like 26 kbps (Ethernet and ATM are worse,
and DSL is ATM underneath - I'm not sure what the cellular carriers do for The problem is that the Voice-stream data packets are extremely small -
the same headers don't add much overhead percentage when you're using 1500-byte data packets.
In some environments you can do header compression to save about half the but in general you can't.  The Asterisk IP PBX has a trunking protocol that you use one set of RTP/UDP/IP headers to carry multiple streams of voice so you can connect two locations together for close to the raw protocol speeds,
but that's not likely to apply to a mobile phone situation.
The other way to avoid the VOIP overhead is to use one of the old
voice-over-data designs that uses point-to-point async or sync connections
without an IP layer (e.g. raw modems.)  That lets you send voice for
much closer to the 9600 bps (depending on sync protocol, async stop-bits, etc.)

@_date: 2007-06-29 20:52:17
@_author: Bill Stewart 
@_subject: Quantum Cryptography 
"Kickbacks" would be the usual American term.
"Never attribute to malice what can be adequately explained by incompetence."
Quantum Crypto is shiny new technology, complete with dancing pigs.
And once you've invested the research and development costs into building it,
of course you want to sell it to anybody who could use it.
So what kind of threat models does it address, and what does that
say about the kinds of customers who'd want it?
- It doesn't protect against traffic analysis,
         because the eavesdropper can follow the fiber routes
         and see who you're connected to.
- It potentially provides perfect forward secrecy a long time
         into the future against attackers who can eavesdrop on you now
         and save all the bits they want.
         That's mainly useful for military applications - most commercial
         applications don't require secrecy for more than a few years,
         and most criminal activities can't use it because of the
         traffic analysis threat.   Maybe banks?
- It doesn't protect against Auditors getting your data.
         So maybe it's not useful for banks.
         That's really too bad, because except for the military,
         the main kinds of customers that need to spend lots of money
         on extra-shiny security equipment are doing so to distract Auditors,
         but it does let you tell the auditors you'd done everything you could.
- The Quantum Key Distribution versions only protect keys, not data,
         so it doesn't protect you against cracking symmetric-key algorithms.
         It does provide some protection against Zero-Day attacks on
         public-key crypto-systems, but wrapping your key exchange
         in a layer of symmetric-key crypto can do that also.
         And if you're the military, you can revert to the traditional
         armed couriers with briefcases handcuffed to their arms method.

@_date: 2007-05-01 20:37:02
@_author: Bill Stewart 
@_subject: 128 bit number T-shirt? 
"Large Integers are Not A Crime" :-)
On the other hand, isn't the key really an MD5 hash of some haiku about
         OK, so we know that
         DVD-CSS was
         Just Not Good Enough

@_date: 2007-05-21 11:19:28
@_author: Bill Stewart 
@_subject: Russian cyberwar against Estonia? 
There are three likely suspects
- the actual Russian government (or some faction thereof)
- Russian Mafia for whatever reasons (might not be distinct from a faction of the government,
         and usually if the Mafia's involved they're polite enough to
         send a note demanding money or something.)
- Some teenage hacker who got annoyed at some other teenage hacker
         because they got into an argument on WoW or Myspace
         and decided to DDOS him (usually attacks like that
         don't take down much more than a small ISP or a university,
         but like "D00d, you're so 0wn3d, I can take down ur whole *country*" :-)
The latter isn't as far-fetched as it sounds (well, ok a bit...)

@_date: 2007-10-11 21:50:06
@_author: Bill Stewart 
@_subject: Trillian Secure IM 
Sun's "Secure NFS" product from the 1980s had 192-bit Diffie-Hellman,
and a comment in one of the O'Reilly NFS books says that
         "However, by 1990, advances in RISC processors produced
         workstation machines that could, by brute force,
         derive the private key from any public key in under a day."
but that in 1987 there were still a lot of Motorola 68010 machines
that took several minutes to generate keys so they didn't want it longer.
I'm guessing that a 1990 RISC machine was around 50 MIPS,
so it's maybe 1/100 the speed of a modern single-core CPU.
128-bit DH sounds like as good a decision as using 40-bit RC4 keys would be

@_date: 2007-09-03 01:59:46
@_author: Bill Stewart 
@_subject: World's most powerful supercomputer goes online 
There have been a number of half-years that Seti at Home was faster than
the top machines in the top500 list (counting by bogomips, not real LINPAK),
and most of the times I've checked, it's been at least in the top 10.
Some of the stats can be found at top500.org and
(though good SETI at Home stats have been harder to get in recent years,
partly for organizational or presentational reasons,
and partly because it's spun off a bunch of other mass-computing programs.)

@_date: 2008-02-10 13:25:49
@_author: Bill Stewart 
@_subject: Toshiba shows 2Mbps hardware RNG 
One obvious application I can think of is Diffie-Hellman session key generation
for web or email servers that handle lots of sessions.
Sure, you _could_ use PRNGs to generate the keys, with real RNG now and then,
but a fast RNG can help protect you against one popular threat model, which is "auditors".

@_date: 2008-01-19 10:55:52
@_author: Bill Stewart 
@_subject: Botnets on Unix 
Of course there've been Unix botnets, though most of them
were a few years ago and not as tightly integrated as the current ones
(or as the Morris worm, which was in 1988.)
Stacheldraht was a DDOS tool from ~1999 running in Linux and Solaris;
it was related to Trinoo and Tribe Flood Network which had similar features,
but I'm not sure what OS those ran on.
says there were several thousand machines running it.
I found it running on a RedHat 6 machine in my lab a few years back,
chatting away with a university machine in Sweden.
It had broken in through a wu-ftpd hole, so it was appropriate
that the next time somebody broke into that machine the
botnet controller was from Washington University.
Another attack looked like it was from MIT, but Jeff Schiller said
it was actually from somebody in Japan that had byte order problems
in the target IP address, so it was probably a Sparc machine.
In contrast, nobody ever bothered the Win95 machine on the same DSL circuit,
but it wasn't running any servers.
Both of them were running on 60-75 MHz Pentium hardware.

@_date: 2008-01-20 13:03:06
@_author: Bill Stewart 
@_subject: Changes in Russian licensing of cryptraghical tools 
I would have guessed the opposite - it's designed to prevent
customized encryption solutions that actually work,
but not to prevent mass-market products.
Since you don't need a license for totally inadequate crypto,
you can still sell snake-oil customized for your users.

@_date: 2008-07-30 16:48:14
@_author: Bill Stewart 
@_subject: On the "randomness" of DNS 
Random number quality is contextual.
In this case, for 95-99% of the market, the real test is between
         "Patched" "Badly Broken Not patched yet" "Didn't need patching",
and if you'd prefer the term "Best we can do until DNSSEC"
instead of "GREAT" I won't be the one to argue with you.
There are some other possible conditions, like
         "Rolled their own with open source, badly"
or      "Maliciously subtle malware DNS resolver".
The latter is way too much work compared to cruder approaches
(like targeting queries directly to your evil DNS server).
The former is not too common, though it probably exists,
but once most systems get patched,
it may not be a big enough target to interest crackers.

@_date: 2008-10-28 15:27:05
@_author: Bill Stewart 
@_subject: combining entropy 
In the case of malicious members who can snoop the inputs,
Mal can get any result he wants if the combining function is XOR
(or, with slightly more work, if it's a non-cryptographic checksum.)
But if your combining function is a cryptographic hash,
it's computationally difficult to do.
However, even a hash isn't always enough - consider the case
where the application of the random numbers only uses k of the N bits,
and the attacker has enough time to try out 2**k (waving hands roughly here)
different cases.  So you may still need to design your protocols carefully.

@_date: 2008-10-29 23:30:27
@_author: Bill Stewart 
@_subject: the skein hash function 
Eugen Leitl and Stephan Somogyi  wrote
about the Skein hash function announcement.
 > One thing I noticed on a first read-through was
a discussion of speed for ASICs vs. general CPUs.
Their implementation on CPUs was about 4 Gbps/core,
and their estimate of ASIC speed was about 5 Gbps
using about 80K gates worth of ASIC,
and their hash-tree mode makes parallelization efficient.
Their conclusion was that ASICs don't give you
much of a speedup, but may save power or cost.
A quick google-look at ASICs showed a number
in the range of 300K-20M gates,
so hash-trees could probably get speedups of up to 20-100x
if you can keep from becoming input-speed-bound.
The 300K chips were about $6, 5M at $50 and 350MHz,
which is somewhat faster than the Skein team estimate,
and some of the denser chips didn't mention price
but were starting to use 45nm technology.
So if Skein becomes popular, ASIC accelerator hardware
may be practical for higher-speed applications.

@_date: 2009-01-30 17:37:33
@_author: Bill Stewart 
@_subject: Proof of Work -> atmospheric carbon 
There are good botnets and bad botnets.
Good ones ask you if you want to join, bad ones don't.
Good ones are typically things like SETI at home, Folding at home,
Great Internet Mersenne Prime Search,  DES crackers, etc.,
and if you've got something good to do, people will help.
People usually only set up the bad ones
if they want to do something bad - it may be interesting the
first time they do it, like a new flavor of DDOS,
but it's not usually doing the world any favors.

@_date: 2009-07-28 23:23:36
@_author: Bill Stewart 
@_subject: XML signature HMAC truncation authentication bypass 
Depends - if you're only replacing it with SHA-1, it's probably not And if you're breaking things anyway, might as well replace most of the
bit-twiddling variable-length number field types with 32-bit-word-aligned but nobody listened to me rant about that a decade ago :-)

@_date: 2009-10-19 12:13:21
@_author: Bill Stewart 
@_subject: Possibly questionable security decisions in DNS root management 
Verification speed for the root or TLD keys doesn't need to be fast, because you'll be caching them.
Verification speed for every random 2LD.gTLD or 3TLD.2TLD.ccTLD can be but there are lots of 2LDs that are also important to sign securely.
I don't care whether my disposable Yahoo mail account login connections are signed securely,
but I care a lot about whether I'm really connecting to my bank or not.

@_date: 2009-10-24 16:38:32
@_author: Bill Stewart 
@_subject: Possibly questionable security decisions in DNS root management 
I thought it was also that DSA had covert channels,
but I also don't see why that's as relevant here,
and I share Dave's skepticism about threat models.
It's unlikely that DNSSEC will let you do anything any more heinous
than Dan Kaminsky's streaming-video-over-DNS hacks have already done.
There are two obvious places that data can be leaked -
the initial key signature process, and the DNS client/server process.
If the people who certify the root or TLDs can't be trusted,
the number of those people is small enough that they can simply
send the secret data to their unindicted co-conspirators
without all the trouble of hiding it in a covert channel on a very public DNS server.
And if Bad Guys have compromised the software used in a DNS server,
while they could be subtle and hide data in DSA signatures of DNS records,
it would be much easier to just send it as data if the query
has the evil bit set or asks for covertchannel1.com or whatever.
There's plenty of room in the formats even without DSA.

@_date: 2010-08-16 16:35:47
@_author: Bill Stewart 
@_subject: 2048-bit RSA keys 
With today's best-of-breed algorithms and hardware designs,
there isn't enough money in the economy to build a machine
that comes close to making a scratch in the surface of
that kind of energy consumption, whether for factoring or
for simple destruction.
Basically, 2048's safe with current hardware
until we get some radical breakthrough
like P==NP or useful quantum computers,
and if we develop hardware radical enough to
use a significant fraction of the solar output,
we'll probably find it much easier to eavesdrop
on the computers we're trying to attack than to
crack the crypto.

@_date: 2010-07-30 15:08:22
@_author: Bill Stewart 
@_subject: A mighty fortress is our PKI, Part II 
Unfortunately, there _are_ ways that it can scale adequately.
Bank of America has ~50 million customers,
so J. Random Spammer sends out 500 million emails saying
"Bank of America is updating our security procedures,
please click on the following link to update your browser."
It's more efficient for BofA to send out the message themselves,
only to actual subscribers, with the actual keys,
helping to train them to accept phishing mail in the process,
but apparently even doing it the hard way scales well enough for some people to make money.

@_date: 2010-08-31 23:27:39
@_author: Bill Stewart 
@_subject: RSA question 
In a typical RSA encryption application, the message that's encrypted with RSA is a secret session key used by a symmetric-key algorithm, so it's going to be 112/128/192/256 bits of pure randomness, which then get used with 3DES or AES to encrypt the actual message.   It's possible that under some conditions, trying to brute-force the RSA is more efficient than simply brute-forcing the symmetric key, or that you might be able to use it to help that process (e.g. if AESDecrypt(Cyphertext, Symmetric Key Kn) produces ASCII, you could check whether RSA(Pubkey, Symmetric Key Kn) gives you the RSA cyphertext.  But usually it's not very helpful.
On the other hand, if you're using RSA to encrypt the actual end-user message, and that message is from a small restricted set, it's a different Or if you're using RSA to encrypt a Symmetric Key, but that key is a hash of a passphrase instead of pure random bits, then maybe you could brute-force the passphrase.

@_date: 2010-09-28 12:06:59
@_author: Bill Stewart 
@_subject: Haystack (helping "dissidents"?) 
cryptography at metzdowd.com
They do tell you what level of attack you're trying to block.
There's "spammers trying to crack your system for money",
but then there's "a national government that doesn't like you",
though I suppose it's possible that if you're not annoying
one of the top ten governments, you might get a larger attack by annoying

@_date: 2010-09-28 12:17:34
@_author: Bill Stewart 
@_subject: Stanford 10/7/2010 -- Lessons from the Haystack Affair 
Potentially interesting lecture if you're in the Bay Area

@_date: 2013-08-26 18:30:48
@_author: Bill Stewart 
@_subject: [Cryptography] Using Raspberry Pis 
Meanwhile, while Phill may have spent $25 for a USB Ethernet, I frequently see them on sale for $10 and sometimes $5.

@_date: 2013-12-04 18:46:04
@_author: Bill Stewart 
@_subject: [Cryptography] Kindle as crypto hardware 
HDMI means you can plug the Pi into a newer television or monitor, if you're not paranoid about those, and you can plug in a vanilla USB keyboard.
There isn't persistent memory on the board; the OS is installed on a removable SD flash card, so if you need to shred anything it's the $5 flash.
As much as I like the Arduino for controlling blinky-lights and thermostats, it's not the platform you want to use for number-crunching.
It's an 8-bit CPU running at 20 MHz, so generating ECC keys will take unacceptably long.  Spend the extra $10 for the Pi, which is at least a 700 MHz 32-bit chip.  And don't go buying that NSArrduino clone board, which has a chip marked "ATmega328" that's actually an ARM emulation with a radio transmitter.
Both CPUs are under $5, and if you're willing to use a serial display, you could get one of the few PDIP ARM chips so you can plug the chip into a socket and have nothing with memory in it remaining on the board.
But it's probably safe enough and a lot less labor to just get a cheap phone or Kindle that already has all the parts.

@_date: 2013-12-06 09:20:42
@_author: Bill Stewart 
@_subject: [Cryptography] Email is securable within a coterie [was: Email 
Simple.  Just install VMware Player, then download a Linux ISO, create a virtual machine, update Linux a few times, and install Linux Mixmaster :-)
And yeah, original-architecture Usenet was better for this kind of application than the current dejanews.

@_date: 2013-12-07 20:18:51
@_author: Bill Stewart 
@_subject: [Cryptography] Kindle as crypto hardware 
Sorry, hoped it would be obvious that that was a joke.
Not totally impossible that they could have done such a thing, if they actually wanted to,
because there are a few PDIP-packaged ARM chips, or they're rumored to have their own chip fabbing,
there's plenty of spare horsepower, and the average hobbyist wouldn't notice as long as the pinouts were right.
My real worry about such things is getting the 3.3v part when I'm expecting a 5v part.

@_date: 2013-11-01 23:33:05
@_author: Bill Stewart 
@_subject: [Cryptography] What's a Plausible Attack On Random Number 
It's slightly backwards as far as timing goes - if you're trying to run a pure client, you normally have physical input from the user and access to a sound card before running anything that needs to generate encryption keys, so you don't really need it, and if you're running a server, you almost always want a fixed IP address rather than a random one from the DHCP pool, so you're probably not going to ask for DHCP.  Also, if you're starting a brand-new-out-of-the-box server, it doesn't matter if it takes a few minutes before there's enough entropy to generate keys, because it's new, while the case where you care most about startup time is restarting a previously running server that was shut down, so you would have saved a seed by then.  I guess that Cloud World may have occasion to care about how long it takes to provision a brand-new server from a canned image, and need to generate an ssh key so a user can log in to update the rest of their software, because they're paying by the millisecond, but are they likely to use DHCP as opposed to having Chef/Puppet give them an address?

@_date: 2013-11-04 17:48:09
@_author: Bill Stewart 
@_subject: [Cryptography] DNSSEC = completely unnecessary? 
SSH isn't HTTPS.  Nor are SFTP, SCP, etc.
IPSEC isn't HTTPS.
Outbound Email isn't HTTPS, even if it's sometimes TLS.
Inbound SMTP often isn't even TLS, but sometimes you want to check where it came from.
DNS isn't HTTPS, but sometimes you want to trust it, or if you're Dan Kaminsky you might want to tunnel ssh and video over it.
NFS isn't HTTPS, and sometimes you want to use DNS with it.
Printer protocols often aren't HTTPS.
There really are protocols that don't look like HTTP variants, but use DNS.  And DNSSEC has theoretically been around a long time, even though in practice it got delayed for years and we did SSL/TLS instead.
DNSSEC doesn't protect you against exactly the same threats that SSL/TLS CAs do - it does a better job of confirming that you're talking to example.com when you think you are.  Some CAs try to do a better job of telling you that example.com belongs to The Example Corporation, as opposed to examp1e.com (note the numeral "1") which belongs to Scammers Inc., but you've got to be good at restricting which CAs you believe.

@_date: 2013-11-08 17:19:05
@_author: Bill Stewart 
@_subject: [Cryptography] randomness +- entropy 
Most smartphones have wifi, and can tell you things like signal strength and noise levels on different channels, even if they don't show you the cellular signals.  It's probably not a rapidly-changing signal, but it's going to have some entropy (and if there's not enough noise, go microwave some coffee.)  There's also typically an accelerometer, and even dumb phones almost all have cameras.
But unfortunately, that $29 cable modem or dsl router isn't going to have any spare hardware, even a 5-cent photocell, so it's network noise only unless there's wifi.

@_date: 2013-11-12 11:49:11
@_author: Bill Stewart 
@_subject: [Cryptography] [cryptography] NIST Randomness Beacon 
I thought it was at BellCore by then?  Stu Haber, IIRC.
Of course, that presupposes the existence of news sources widely distributed in dead-tree form with classified ads, so it may not be a sustainable business model :-)

@_date: 2013-11-12 17:54:21
@_author: Bill Stewart 
@_subject: [Cryptography] randomness +- entropy 
Most applications can wait.  Some of them could wait, but currently don't.
But what applications are there that really do need to run early?
The one potential example I can think of is hard drive encryption -
it definitely needs good (pseudo)randomness,
and needs to start pretty early in the boot process
so other applications can have a file system to write to,
and I'd prefer not to have a system that starts out
writing unencrypted/badlyencrypted data and then updates it,
though I suppose you don't typically have any user data that early.
(BTW, does an encrypted disk drive provide any useful seed material for future boots?)
Are there any network processes that need crypto before running?
Applications like sshd and https obviously do, so you need administration, but they probably don't need to be ready early.

@_date: 2013-11-12 18:56:58
@_author: Bill Stewart 
@_subject: [Cryptography] NIST should publish Suite A 
Huh?  Of course they would.
Half* the NSA's job is to crack communications, half of it's to protect them.
The people whose job is to protect codes have a responsibility to their customers
to make sure that the code-crackers can't crack them,
not only because the customers might insist on it,
but because good operational security includes considering threat models like
"somebody in the NSA is a mole" or "somebody hired contractors as sysadmins",
and following appropriate least-privilege policies, two-person rules, etc.
Perhaps the crackers' business model also includes having some "Suite A-Prime" gear
for people they want to attack while telling them it's Suite A gear,
but that's not really the same case at "no reason to be concerned."
(*Ok, sometimes "half" == 99%.)

@_date: 2013-11-12 20:03:53
@_author: Bill Stewart 
@_subject: [Cryptography] Looking for feedback on new Java crypto library 
If you don't like the salt monoculture from always using pi at the beginning,
you can pick e, or sqrt(2), or other popularly irrational numbers.
You could even get fancy and pick pi-offset-by-"your-version-number"-digits,
which is probably also obviously not cooked.

@_date: 2013-11-13 14:17:27
@_author: Bill Stewart 
@_subject: [Cryptography] randomness +- entropy 
The only time it's an issue is the first boot for a new system;
after that you're reusing the same key.
The question is whether that key is entirely user-entered,
or whether it includes some kind of RNG as well.
(OTOH, if it's handled entirely by the BIOS and not the OS,
then it's not a Linux problem.)

@_date: 2013-11-23 13:18:48
@_author: Bill Stewart 
@_subject: [Cryptography] Dark Mail Alliance specs? 
It's about user interfaces and key management.
If you want to send encrypted email to Alice,
you need her keys, so there needs to be a key fetching UI somewhere,
and you need to have your mail system associate Alice's keys with her email address,
and have it do something appropriate if you're sending one message to multiple recipients,
especially if you have keys for Alice but not Bob, or if a recipient is a mailing list,
and if you want to send signed email, you need to have a way to get your keys to the recipient,
and ideally you'd like to have a way to validate those keys, though even first-use is a start.
If you do build a key management system, it needs to be able to feed into the email
James Donald's Crypto Kong did an interesting job of unintrusive key handling;
using ECC meant that the key was short enough to fit in a couple lines of base64 text.
At $DAYJOB, we're using the Voltage Secure Mail plugin for Outlook,
which provides a Send Secure button in addition to the regular Send button,
integrates with the Exchange system's Global Address List,
and lets recipients who don't use it fetch messages from an https URL.
And almost nobody uses it either :-)
You also need to do something appropriate for webmail systems.

@_date: 2013-09-30 21:36:27
@_author: Bill Stewart 
@_subject: [Cryptography] TLS2 
Unfortunately, you have to be able to comprehend all of the failure modes and attacks on ASN.1.
The object descriptions themselves are a bit bloaty, with their main weakness being that either
you have to get permission to attach your data into the official tree,
or else do a vendor-specific branch, but they're not all that broken.
It's the data representations that map them into binary strings that are a
wretched hive of scum and villainy, particularly because you can't depend on a
bit string being able to map back into any well-defined ASN.1 object
or even any limited size of ASN.1 object that won't smash your stack or heap.
The industry's been bitten before by a widely available open source library
that turned out to be vulnerable to maliciously crafted binary strings
that could be passed around as SNMP traps or other ASN.1-using messages.
Similarly, PGP's most serious security bugs were related to
variable-length binary representations that were trying to steal bits
to maximize data compression at the risk of ambiguity.
Scrounging a few bits here and there just isn't worth it.

@_date: 2013-10-06 21:01:38
@_author: Bill Stewart 
@_subject: [Cryptography] AES-256- More NIST-y? paranoia 
So you're essentially saying that AES would be stronger if it had a different key schedule?
You've doubled the cost of key scheduling, but usually that's more like
one-time than per-packet.  If the hash is complex, you might have
also doubled the cost of silicon for embedded apps, which is more of a problem.
I'd expect that the point of related-key attacks is to find weaknesses
in key scheduling that are exposed by deliberately NOT using random keys
when the protocol's authors wanted you to use them.

@_date: 2013-10-19 14:40:14
@_author: Bill Stewart 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
I'd kind of expect that "Zero entropy is assessed" is supposed to mean
"NOT giving the illusion of entropy", but that doesn't mean users will do that :-)
And sure, you need more entropy than that against a KGB-style attacker
(which, with another 10-20 years of Moore's law, means any script kiddie),
but at least it's protecting you against the
"all the VMs generate the same primes for their RSA key" problem,
which protects you against a whole class of attacks.
Demanding user action is really tough in a VM that hasn't connected to users yet;
anything you do is either going to go across a network or ask the host,
so you need an entropy gathering mechanism that can work with that.
If nothing else you can do something cheap like grab N = lowest 8-16 bits of uandom,
run the urandom N times, grabbing timestamp entropy each time,
hoping to get a few more bits of real sloppiness.

@_date: 2013-10-21 15:24:53
@_author: Bill Stewart 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Real-world cryptanalysis can't break mathematical-cryptography OTP.
But real-world cryptography can use sometimes-more-than-One-Time Pads, and not-independent-identically-distributed random pads, and not-destroyed-after-use pads, and real-world cryptanalysis can sometimes break those.

@_date: 2013-10-29 15:03:45
@_author: Bill Stewart 
@_subject: [Cryptography] DSL modems - how would we detect wholesale 
DSL modems normally don't have a lot of spare CPU horsepower,
and if you have old-style DSL
(as opposed to fiber, or U-Verse DSL-to-the-box, or cable modem)
there's not a lot of spare upstream bandwidth for them to abuse.
And it would cost them a lot to do all the processing to handle the data,
which isn't going to happen in a price-sensitive consumer business.
If they're trying to specifically wiretap *you*, that's a different case,
so if a large van marked "TPC" comes up to your door and
asks to replace your cable modem with a faster one, be suspicious :-)
It's annoying to us in the business as well;
that stuff is a pain to debug except from a DSLAM.
You should probably be doing that anyway (at least with a
consumer firewall appliance, if not a Linux/BSD/DD-WRT box.
And in many case, the broadband provider isn't including a switch,
or only offers that for an extra fee with managed Wifi, and you can do better.)
That lets you upgrade the wifi yourself, if you use wifi,
and gives you some vague chance of security if you want to have a
LAN-attached printer or file server supporting your machines at home,
and it also gives you the ability to have separate guest wifi.
         Thanks; Bill Stewart
Disclaimer: This is only my personal opinion, not the opinion of
my current or former employers, TPC, Big Cable, etc.

@_date: 2013-10-29 15:09:06
@_author: Bill Stewart 
@_subject: [Cryptography] Randomness from network hardware? 
I'd be surprised if most hardware or drivers makes that visible,
especially since "ethernet" is full-duplex with switches
rather than half-duplex with CSMA/CD these days.
It's not something you'd normally want the CPU to know.
Maybe some wifi gear makes it more visible,
but if you had deeply debuggable wifi there'd be a lot more sources
of random noise available.

@_date: 2013-09-03 18:09:15
@_author: Bill Stewart 
@_subject: [Cryptography] IPv6 and IPSEC 
For IPv4, that's a relatively normal way to do things,
though if example.com is commercial,
smtp.example.com might actually be a load-balanced bunch of servers in xx.yy.zz.0/24
instead of just one machine, or they might be hidden behind NAT.
But with IPv6 privacy extensions, a single machine might be using
pseudorandomly-generated addresses in a /64 subnet,
so you'd have to do some kind of wildcarding to represent it as a single name.
Also, "residential" vs. "commercial" is a much fuzzier boundary for IPv6;
an IPv6 machine might be a VM tunnelling to Hurricane Electric over IPv4,
or tunnelled from a residence to a DSL ISP that can only do telco DSL at IPv4.

@_date: 2013-09-03 20:05:35
@_author: Bill Stewart 
@_subject: [Cryptography] FIPS, NIST and ITAR questions 
PRNG is not necessarily a cryptographically strong term.  But isn't counter-mode hash likely to be ok?
         Counter = seed;
         while (counter++) Output(Hash(counter));
                 // or as somebody said Output(Hash(seed||counter||seed));
                 // and you probably need to pad it to be long enough for the hash to be happy.
Obviously if somebody discovers the seed the whole thing is toast.
And you can turn the PRNG into a stream cypher by doing plaintext[x] xor PRNG[x], with the usual limitations.
None of that has any bearing on ITAR, of course.

@_date: 2013-09-07 10:12:53
@_author: Bill Stewart 
@_subject: [Cryptography] In the face of "cooperative" end-points, 
Depends a lot on how cooperative they are.  It's much easier to get a subpoena/secret-order/etc. for "business records" that a company keeps, which may include the long-term key, than to get one for transient session keys that their software doesn't keep.  Doesn't mean they can't do it, but it's probably much easier to get an order to produce plaintext, especially for a company like a bank or email service where the plaintext is something they would be keeping, at least briefly, as a business record anyway.
Unlikely - the economics are still strongly against that.  Keeping a fleet of key cracking machines to grab long-term private keys from high-value targets might make sense, but each long-term key gets used to protect thousands or millions of transient session keys.  If they have 1024-bit RSA crackers at all, unless there's been a radical breakthrough in factoring, they're still not fast.
I've always preferred RSA-signed Diffie-Hellmann to encrypted session-key transfer when it's practical.  The long-term keys only get used for signatures, so if they're compromised they can only be used to impersonate the endpoints, not to read previous sessions, and under less-than-NSA versions of due process, it's a lot easier to argue in court against a police agency that wants to impersonate you than one that wants a copy of a transaction.

@_date: 2013-09-07 11:07:39
@_author: Bill Stewart 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
Public-key crypto requires learning math, and math is hard (or at least ECC math is hard, and even prime-number-group math has some interesting tricks in it.)
Symmetric-key crypto is easy in a black-box sense, because most algorithms come with rules that say "You need to do this and not do that", yet the original PPTP did half a dozen things wrong with RC4 even though the only rule is "never use the same state twice."
But if you want to look inside the black box, most of what's there is a lot of bit-twiddling, maybe in a Feistel network, and while you can follow the bits around and see what changes, there can still be surprises like the discovery of differential cryptanalysis.
Public-key crypto lets you use math to do the analysis, but [vast over-simplification] symmetric-key mostly lets you play around and decide if it's messy enough that you can't follow the bits.
But there are other traps that affect people with either kind of system.  Once PGP got past the Bass-o-matic stage, the biggest security problems were mostly things like variable-precision numbers that were trying so hard to save bits that you could trick the program into interpreting them differently and accepting bogus information.  Fortunately we'd never have problems like that today (yes, ASN.1 BER/DER, I'm looking at you....), and nobody ever forgets to check array bounds (harder in modern languages than in C or Fortran, but still quite possible), or fails to validate input before using it (SQL injections), etc.

@_date: 2013-09-07 20:57:05
@_author: Bill Stewart 
@_subject: [Cryptography] Bruce Schneier has gotten seriously spooked 
More to the point, spike a popular download with remote-execution malware,
and download spiked patches for important binaries,
so the not-a-collection-target's browser uses known keys
(the opposite of the "fortify" patch that made 40-bit Mozilla do 128-bit),
and the disk encryption software broadcasts its keys or stashes them in plaintext

@_date: 2013-09-10 11:52:43
@_author: Bill Stewart 
@_subject: [Cryptography] The One True Cipher Suite 
The reason you need to be able to support more than one cipher suite is so that you've got a mechanism for removing one if it's discovered to be weak in the future, and for adding a new one if none of your remaining suites are still strong.
If there are thousands of ciphers in use, it's generally easier for the attacker to get people to use one of the weak ones
than to attack a large fraction of the not-currently-known-to-be-weak ones.
The big problem PGP ran into with compatibility wasn't so much because of cipher suites (after Bass-O-Matic was replaced),
though avoiding the IDEA patent became important after violating the RSA patent wasn't a problem,
but because it did too much bit-twiddling to use variable-length fields and was sloppy about boundaries,
which made it easy to exploit.

@_date: 2013-09-10 12:56:16
@_author: Bill Stewart 
@_subject: [Cryptography] People should turn on PFS in TLS (was Re: Fwd: 
I thought the normal operating mode for PFS is that there's an initial session key exchange (typically RSA) and authentication,
which is used to set up an encrypted session, and within that session there's a DH or ECDH key exchange to set up an ephemeral session key,
and then that session key is used for the rest of the session.
If so, even if the NSA has broken ECDH, they presumably need to see both Alice and Bob's keyparts to use their break,
which they can only do if they've cracked the outer session (possibly after the fact.)
So you're not going to leak any additional plaintext by doing ECDH compared to sending the same plaintext without it.
Yep.  It's definitely the fun kind of backdoor to use.

@_date: 2013-09-11 11:40:47
@_author: Bill Stewart 
@_subject: [Cryptography] People should turn on PFS in TLS (was Re: Fwd: 
I wouldn't mind if it had been called Pretty Good Forward Secrecy instead, but it really is a lot better than regular public key.
The main difference is that cracking PFS requires breaking every single key exchange before the attack using cryptanalysis, while cracking the RSA or ECC outer layer can be done by compromising the stored private key, which is far easier to do using subpoenas or malware or rubber hoses than cryptanalysis.
(Of course, any messages that were saved by the sender or recipient can still be cracked by non-cryptanalytic techniques as well, but that's a separate problem.)

@_date: 2013-09-14 15:14:02
@_author: Bill Stewart 
@_subject: [Cryptography] Thoughts on hardware randomness sources 
More to the point, the servers in the data centers aren't going to let you plug things in to them, especially if you're just renting a virtual machine or cloud minutes and don't get to connect to the real hardware at all (which also means you're not going to be able to use disk drive timing.)
A tablet computer has lots of sensors in it; even turning the cameras on at boot time and hashing the raw pixels should give you a reasonable chunk of entropy; you're not going to turn your virtual machine upside down and shake it like an Etch-A-Sketch.
I realize it's possible for somebody to try to manipulate this, but I've always assumed that ethernet packet timing ought to give you some entropy even so, and even though with virtual machines you may only get quantized versions of interrupt times.  Startup processes are probably going to include pinging a router and a name server, or at least they could if you wanted.

@_date: 2013-09-14 15:46:42
@_author: Bill Stewart 
@_subject: [Cryptography] real random numbers 
No. You're misunderstanding what people mean by "radioactive" RNGs.
(Quantum, fine; I don't use the term when talking about RNGs, because
I don't know what it means in that context, and I took enough quantum physics
in college many decades ago to know that most people who use the term
use it to mean "handwavy stuff I don't understand", so I won't argue with
you about whether it's different from thermal noise.)
Radioactive RNGs consist of a radiation source with a large number of
unstable nuclei and a particle detector that detects their decay events.
The events occur at some average rate, based on the decay rate per nucleus
and the number of nuclei, but the timing for "when the next atom
feels like decaying" is entirely unpredictable, so you get a Poisson process.

@_date: 2014-02-01 12:38:11
@_author: Bill Stewart 
@_subject: [Cryptography] cheap sources of entropy 
Definitely not.  If you're on a VM, you have 0..n virtual disk drives, which the hypervisor simulates from a datastore pool and maybe some cache.  You don't get any access to the real device, even though the hardware drivers look like they're talking to a disk.
Most shared servers that are running virtual machines images don't have physical sound cards, and they may have a few shareable USB ports but they typically won't have video cameras plugged into them.  There might be a sound card built into the chipset, but you typically don't have access to it.  For instance, when I look at the Virtual Machine Settings for my VMware box at work, it doesn't even have the option for attaching a virtual sound card to the VM.
The exception is cases like VMware Player running on your desktop, which probably can access most of your actual hardware, or virtual machines running on mobile phones(because yeah, that's a thing these days), which may have lots of toys handy, but your typical web server running on an Amazon cloud instance isn't going to have any of those things available.  You're probably also not going to be able to log in to the VM's console and wave a mouse around (and doing an X Windows session isn't going to happen until after ssh has already been initialized.)
Even network events are pretty sparse on a vSwitch, compared to the constant blather that real ethernet ports typically see.  There isn't all that spanning tree noise, maybe you get some ARP broadcasts, but only from your other VMs on the same server cluster, vanilla users don't have the permissions to set the vSwitch port to promiscuous receive.
"If you don't like the noise, go make some of your own", i.e. you'll have to start sending out traffic to known or unknown places and using low-level timing of the responses (and even that's not going to be as independent as you'd like, since it'll be correlated with the granularity of when the hypervisor gives you some CPU cycles), and of course all of that traffic is theoretically independently observable, not that that's too credible a threat.

@_date: 2014-02-02 22:22:24
@_author: Bill Stewart 
@_subject: [Cryptography] cheap sources of entropy 
I'm not too worried about the "every now and then" case.  It's an issue, but it's one that gives you time to watch lots of fairly random stuff before you need a result.  Even CPU randomness is probably enough.
I'm mainly worried about the "new virtual machine, cloned from a standard image" case,
which needs to set up ssh keys, ssl keys, and seed /dev/random before it's ready to deal with the rest of the world
in ways that would give it some more entropy to work with.

@_date: 2014-02-05 22:25:03
@_author: Bill Stewart 
@_subject: [Cryptography] who cares about actual randomness? 
Poker's a special case, because it's less about manipulating the cards
and more about predicting the behaviour of the other players.
(Or maybe it's less about predicting the cards and more about manipulating the players, but that's only if you're good at it, which they say I'm not.)
There's the usual quote from Von Neumann that anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin.  (But then, sin and poker are activities that are seldom found in the same place... )
My standard assumption for when you care, other than for seeding PRNGs, is One-Time Pads.
Are you willing to send the next Venona message collection with your unguessable numbers?
(Yeah, these days, you probably are, because we've got enough crypto algorithms that are
strong enough to resist both bit-twiddling and mathematical attacks,
and at least for the next few decades I'm guessing that quantum computers are going to be
less of a realistic possibility than getting widely-deployed trustable HWRNGs.)
For poker, there are protocols for jointly picking mutually unguessable numbers (e.g. Diffie-Hellman variants), of course.  For servers, if the players we can't trust are Intel and the NSA, even though they've been telling us they're sitting on opposite sides of the table, then the comment that seeding PRNGs on virtual machines is actually a provisioning problem is a good one, and I do like the "cloud VMs connect to a known-friendly server to get random seed material" approach.

@_date: 2014-02-15 22:32:08
@_author: Bill Stewart 
@_subject: [Cryptography] Unified resource on Random Number Generation 
As always, anything I've written on the net is fair game, with or without attribution,
though it I said something egregiously stupid, please at least give me a heads up if you're quoting me with attribution :-)

@_date: 2014-02-16 19:31:41
@_author: Bill Stewart 
@_subject: [Cryptography] BitCoin bug reported 
> Why would you pay more for a bitcoin than the cost to mine one yourself?
Several possible cases:
- You want a bitcoin NOW, and mining with just your GPU will take too long
- You only want a fractional bitcoin, and it's cheaper to buy the fraction than to mine a whole bitcoin.
         (E.g. you want to buy $50 of "research chemicals" on SilkRoad3.0,
         and bitcoins are selling for $500-1000 this week, requiring $2000 of electricity with your GPU.)
Of course you can send the recipient a structure it hasn't been compiled to understand.
It won't understand it, but maybe your objective is to get it to misunderstand.
(And yeah, PER is probably the safest version of that hive of scum and villainy known as ASN.1,
or at least it's less unsafe than DER or BER.)

@_date: 2014-02-16 19:40:02
@_author: Bill Stewart 
@_subject: [Cryptography] The ultimate random source 
For entropy generation, dice have the limitation that physics is going to typically force them into alignment, at least with the flat surface on the bottom and possibly horizontally with each other, as opposed to the much more random positioning of the candies which a camera can take advantage of.
Also, Phill's method means you get to eat the candy when you're done, at least if they're chocolate, though it's somewhat counterbalanced by the failure mode that somebody eats the candy before you've got all the random numbers you need.

@_date: 2014-02-19 15:00:04
@_author: Bill Stewart 
@_subject: [Cryptography] The ultimate random source 
You certainly don't want a good camera; what you need is a really dumb one.  (Unfortunately, dumb and cheap aren't always synonymous these days, since it may be cheaper to use commodity silicon that already compensates for whatever you were hoping not to have compensated for.)
Can't use Fox News, it's just always the same blather :-) (Ok, obvious cheap shot, and MSNBC runs reruns of Maddow and other shows a couple of times a day.)
Can't use CNN, because the 24-hour news cycle means the same stories get run pretty much the same way multiple times, though the different text crawls may not be in sync with the news.
Can't just point the camera out the window, even in foggy San Francisco, because it gets dark at night, and because your data center probably doesn't have windows.
Even auditing is difficult; a bit difficulty with USB as a connection method means it's easy to replace your camera with a video player.

@_date: 2014-01-10 22:39:58
@_author: Bill Stewart 
@_subject: [Cryptography] Dumb idea: open-source hardware USB key for 
Ian Goldberg and others argued some years ago that you need to have
a display and keypad on the device, so you don't have to trust the computer
not to steal keys from the users (his solution was a Palm Pilot,
but a simple 2x16 LCD and some buttons will do.)
You'll need an independent power supply (even if it's just a wall-wart USB charger)
to help prevent some of the power-analysis attacks that smart cards are vulnerable to.
Depending on how paranoid you want to be, you may want the USB interface
to be on a separate chip, such as the fairly dumb FTDI chips used in the earlier Arduinos,
so that you're only handling data on the USB, not full programming,
and can restrict your paranoia to your JTAG interface.
Or you could choose to be a good bit less paranoid and
provide the programs on an SD card the way Raspberry Pi does instead of JTAG,
if your FPGA can read that (natively or with help from an AVR

@_date: 2014-01-15 17:11:31
@_author: Bill Stewart 
@_subject: [Cryptography] [cryptography] Boing Boing pushing an RSA 
If you have a PRNG or DRBG, compromised or not, you don't have a OTP, you have a stream cypher of whatever quality level, subject to mathematical attack.  Maybe it's a good stream cypher, like BBS with a seed you protected well, maybe it's the random() function in your ROM's BASIC interpreter, maybe you're doing good tradecraft to handle distribution and use of the pseudorandom bits or maybe you're not, but it's not a one-time pad.
Compromised on-chip hardware randomness generators, giving you a stream that claims to be thermal noise but is actually DES(clock,NSAkey)?  Yeah, that's something you thought was a legitimate OTP, just like you thought the pad you generated by flipping coins (not knowing there was a KGB Ceiling Cat Camera Watching You) was a legitimate OTP.  But for that attack you blame Intel, not RSA.

@_date: 2014-01-15 22:26:37
@_author: Bill Stewart 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference  boycott 
Ignoring Phill's perfectly reasonable main point, what's wrong with 3DES?
Sure, it's clunky, takes lots of bit-twiddling, is a good bit slower and larger than AES, and only gives you ~112 bits of security for your 168 bits of keys, but is there anything wrong with it other than being not as good as some of the alternatives?  (Ok, and maybe a bit of power analysis risk, depending on your implementation.)  It's not like MD5 where there are theoretical attacks that make it much weaker?

@_date: 2014-01-27 22:23:54
@_author: Bill Stewart 
@_subject: [Cryptography] cheap sources of entropy 
It's clearly into bike shed territory, thus the endless discussion.
We've all got ideas about the problem and how to fix it, or how it's or at least how somebody else's solution to it is clearly wrong wrong wrong,
unlike the coffee case where we'd have all agreed on a good-enough solution
         ("But I don't like coffee!" "Fine, we'll also order donuts and tea." "Ok, whatever.")
I'd be tempted to take the Intel "NSA Inside" RNG, hash each 32 bits down to 1,
hash it in with any other available entropy, and call it a day.
Probably simple parity calculation is as good as fancier hashes for that,
but hash in the system clock if you'd like.
Maybe use 128 bits instead of 32 if you don't have any other saved entropy.

@_date: 2014-01-29 15:30:06
@_author: Bill Stewart 
@_subject: [Cryptography] cheap sources of entropy 
A digital thermostat typically has a 10 or 12 bit A/D converter,
at least if it's an Internet of Things home-type thermostat.
Not much thermal noise available there.
But one entropy source, however well-defended, means that if
there's a problem you can't defend against, it's toast.
Being well-monitored means that a RNG bug when setting your SSH key gets
         "kernel panic in /dev/random at line 32767 - core dumped"
printed neatly on the console DECwriter,
which is probably better than setting it to "00000000" or "NaN"
because at least it failed securely,
while if you've got multiple sources of mediocre entropy,
your boot time takes a few seconds or minutes longer but works.
