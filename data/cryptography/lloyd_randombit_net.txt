
@_date: 2003-10-03 05:13:34
@_author: Jack Lloyd 
@_subject: DH with shared secret 
This was just something that popped into my head a while back, and I was
wondering if this works like I think it does. And who came up with it
before me, because it's was too obvious. It's just that I've never heard of
something alone these lines before.
Basically, you share some secret with someone else (call it S).  Then you
do a standard issue DH exchange, but instead of the shared key being
g^(xy), it's g^(xyS)
My impression is that, unless you know S, you can't do a succesfull MITM attack on the exchange. Additionaly, AFAICT, it provides PFS, since if someone later recovers S, there's still that nasty DH exchange to deal with. Of course after S is known MITM becomes possible.
Given the recent climate around here, I'll add that I'm not planning on
using this for anything (I only use TLS, I swear! :P), I just thought it
was an semi-interesting idea.

@_date: 2004-06-14 13:31:37
@_author: Jack Lloyd 
@_subject: Passwords can sit on disk for years 
Sure there are. In fact there was a discussion (either here or cypherpunks)
maybe a year or two ago about how Visual C++ has exactly that problem with
memset. Consider the following:
void foo()
   char buffer[1024];
   /* do something */
   memset(buffer, 0, 1024);
   return;
As far as the compiler can tell, that memset has no effect, because as soon as
it returns from the function the stack will go away, so whatever value it may
or may not have doesn't matter (basically - there is no way for you to tell if
that memset executed or not). Since it has no effect, why bother executing it?
It's just a waste of time.
That's because languages are defined in terms of side-effects that are visible
to the program - not in terms of side effects visible to some external
entity. The fact that someone messing around with swap can tell if that memset
executed or not is not something C cares about.

@_date: 2004-05-23 13:34:29
@_author: Jack Lloyd 
@_subject: SSL accel cards 
Does anyone know of an SSL acceleration card that actually works under
Linux/*BSD? I've been looking at vendor web pages (AEP, Rainbow, etc), and
while they all claim to support Linux, Googling around all I find are people
saying "Where can I get drivers? The ones  shipped only work on RedHat
5.2 with a 2.0.36 kernel." (or some similar 4-6 year old system), and certainly
they don't (gasp) make updated versions available for download. Because someone
might... what, steal the driver? Anyway...
What I'm specifically looking for is a PCI card that can do fast modexp, and
that I can program against on a Linux/*BSD box. Onboard DES/AES/SHA-1/whatever
would be fun to play with but not extremely important.

@_date: 2004-05-26 13:15:56
@_author: Jack Lloyd 
@_subject: Very scary... 
Browsing around in bookstore this afternoon, I came across 'Cryptography for
Dummies'. Yikes. It was suggested to general approval that the book should open
up to a single page with DON'T in a large font.
The TOC on the site doesn't have the full, horrible details - the book tells
you how to do things like roll your own protocols/formats. At least it doesn't
go into cipher design...

@_date: 2004-11-30 12:22:36
@_author: Jack Lloyd 
@_subject: SSL/TLS passive sniffing 
Looking at my logs, about 95% of all STARTTLS connections are
DHE-RSA-AES256-SHA; I'm guessing this is because most STARTTLS-enabled SMTP
servers (ie Postfix, Sendmail, Qmail) use OpenSSL, and recent versions of
OpenSSL have DHE-RSA-AES256-SHA as the top preference cipher by default.
I suspect you'd see about the same results for any other SSL service that's not
HTTP. I'm surprised to see that SSLv2 connection at the bottom... considering
that STARTTLS didn't exist until, well, TLS, I wonder what logic went into
supporting only SSLv2.
OpenSSL just calls them differently depending on the ciphers in use (an
artifact of the specifications, I think).

@_date: 2004-11-30 14:41:40
@_author: Jack Lloyd 
@_subject: SSL/TLS passive sniffing 
Based on unique hosts, about 5% used TLS for at least one connection (I didn't
do a full comparison, but eyballing it, it looked like if they used TLS at all,
they always used it). Based on connections made to the mail server, it's about
2.5%. Meaning that hosts that don't use STARTTLS send more mail (at least to
the system in question). I suspect that is accounted for by mailing list hosts
and spambots.
Source here was the logs for this month from a host with ~130 users. Since
Victor stated that his counts were just for today, he obviously has a much
larger sample set than I do, so I would be curious how his results compare.

@_date: 2005-12-12 10:54:23
@_author: Jack Lloyd 
@_subject: another feature RNGs could provide 
Use can use the Bear or Lion constructions to form 2^{arbitrary} bit block
ciphers quite easily.

@_date: 2005-12-15 17:12:50
@_author: Jack Lloyd 
@_subject: Looking for fast KASUMI implementation 
Define fast - KASUMI is based heavily on MISTY1. In fact, during a fast scan of
the KASUMI spec, I couldn't see anywhere obvious where it different from MISTY1
at all. As far as I know, I'm the only person who has even tried writing fast
code for MISTY1, and the result is quite dog-slow compared to most other common
ciphers (to pull some numbers out of the air: around 4.3 MB/sec on an 800 MHz
Athlon, compared with 9.4 MB/sec from AES-128 and 15 MB/sec from 16-round
RC5). Obviously you can do better on a faster processor (and I'm sure there are
some cycles yet to be squeezed out of my MISTY1 code - there are many who can
hand-optimize better than I), but I don't think MISTY1 (or KASUMI) will ever be
very fast in software.
Would a FPGA work instead? That seems like your best bet to me.

@_date: 2005-12-16 22:33:46
@_author: Jack Lloyd 
@_subject: crypto for the average programmer 
Last I checked, public key operations in OpenSSL were significantly faster
using the GNU MP engine - so "just as good" is perhaps not entirely
accurate. OpenSSL's BN library is still very fast compared to many other MPI
implementations, of course.

@_date: 2005-12-23 12:33:47
@_author: Jack Lloyd 
@_subject: Standard ways of PKCS #8 encryption without PKCS #5? 
Does anyone know of any 'standard' [*] ways of encrypting private keys in the
usual PKCS  format without using password-based encryption? It is obviously
not hard to do, as you can stick whatever you like into the encryptionAlgorithm
field, so it would be easy to specify an plain encryption algorithm OID
(aes256-cbc, or whatever) plus an IV (and possibly a key check value and/or
some optional key label fields). I'm sure this is not the first time someone
has needed such a thing - any references would be useful.
[*]: Standard in this case being "at least one implementation/spec has it, and
(preferably) it is reasonably secure/sane"
   Jack

@_date: 2005-12-27 20:59:33
@_author: Jack Lloyd 
@_subject: crypto for the average programmer 
Thank you for the correction. My statement was primarily on the basis of some
benchmarks I ran at the time I wrote some backend code in Botan to dump crypto
operations to GNU MP and/or OpenSSL when available, and at the time GNU MP
outperformed OpenSSL by a fairly large margin on x86 and Alpha machines (up to
50% on large RSA private key operations; as the keys got smaller the
performance difference reduced, down to basically nothing at 512 bit
keys). However I have since checked my changelogs and realized I must have run
those tests almost two years ago now (which surprised me a bit!), so I'm sure
those results are not particularly reflective of current performance. I'll have
to revisit this and see how things stack up these days on the platforms I care

@_date: 2005-02-06 01:08:34
@_author: Jack Lloyd 
@_subject: Is 3DES Broken? 
That would make for a pretty poor cipher, considering that flipping a plaintext
bit would only change one half of the ciphertext block (assuming I'm not
misinterpreting your suggestion).
Something along the lines of DEAL should suffice for this, using the block
ciphers as round functions in a Feistel cipher. A bit slow, but it seems like a
plausible solution.

@_date: 2005-02-19 00:25:55
@_author: Jack Lloyd 
@_subject: SHA-1 results available 
No real details, just collisions for 80 round SHA-0 (which I just confirmed)
and 58 round SHA-1 (which I haven't bothered with), plus the now famous work
factor estimate of 2^69 for full SHA-1.
As usual, "Technical details will be provided in a forthcoming paper." I'm not
holding my breath.

@_date: 2005-11-10 11:13:00
@_author: Jack Lloyd 
@_subject: Pseudorandom Number Generator in Ansi X9.17 
Asides from the relatively small internal state, and the state compromise
extension problems noted by Schneier, Wagner, et al, X9.17/X9.31 are AFAIK good
PRNGs. It is very trivial to use AES instead of 3DES (just swap out the
algorithms, and change the size of the various internal values to match the
128-bit block size), and you get a larger keyspace, larger internal state, and
faster operation, so I'd say doing so is a complete win.
Technically, X9.17 has been withdrawn by ANSI, but X9.31 contains the exact
same PRNG in Appenxix A.2.4. ANSI still requires 2-key 3DES, but NIST allows
the use of 3-key 3DES or of AES with any keylength instead.

@_date: 2005-11-17 21:15:42
@_author: Jack Lloyd 
@_subject: the effects of a spy 
SHA-* also look very much like the already existing and public MD4 and MD5... I
would be very willing to bet that the NSA's classified hash functions (I assume
it has some, though to be honest I have only ever seen information about block
ciphers) look nothing like SHA. Perhaps their analysis tools apply well to the
ones that they build internally, but did not to an MDx-style hash, and they did
not want to release a design based on some clever design technique of theirs
that the public didn't know about; when SHA was released, Clipper and the
export controls were still in full swing, so it seems pretty plausible that the
NSA wanted to limit how many goodies it gave away.

@_date: 2005-11-29 11:08:35
@_author: Jack Lloyd 
@_subject: Encryption using password-derived keys 
The basic scenario I'm looking at is encrypting some data using a
password-derived key (using PBKDF2 with sane salt sizes and iteration
counts). I am not sure if what I'm doing is sound practice or just pointless
overengineering and wanted to get a sanity check.
My inclination is to use the PBKDF2 output as a key encryption key, rather than
using it to directly key the cipher (with the key used for the cipher itself
being created by a good PRNG). For some reason the idea of using it directly
makes me nervous, but not in a way I can articulate, leading me to suspect I'm
worried over nothing.
So, assuming using it as a KEK makes sense: At first I thought to use XOR to
combine the two keys, but realized that could lead to related key attacks (by
just flipping bits in the field containing the encrypted key). That is probably
not a problem with good algorithms, but, then again, why take the chance; so I
was thinking instead using NIST's AES-wrap (or perhaps a less weirdly designed
variant of it that uses HMAC for integrity checking and AES in CBC mode for
Am I thinking about this far harder than I should?

@_date: 2005-10-12 11:56:32
@_author: Jack Lloyd 
@_subject: EDP (entropy distribution protocol), userland PRNG design 
I can't say I a fan of the idea of having multiple ways of mixing entropy into
the system. In particular, the idea of producing output by XORing your PRNGs
output with the output of a semi-public RNG seems like a bad idea to me,
because an attacker can easily control those values by taking over the web
server or modifying packets in the network, and if they can somehow predict
your PRNG outputs then they will be able to actually control the final output.
The difference between knowing and controlling the PRNG output is a big deal
when you're using it for something like DSA.
I prefer a multi-stage design, as described by various people smarter than I
  source(s) --> mixer --> pool --> extractor --> X9.31
Take the sources, mix it into an entropy pool and then use an extraction
function to derive values from the pool. Then use the values of that to seed a
X9.31 PRNG and produce the final output with that (with the DT values also
being generated by the extractor function). That helps make sure that even if
you make a mistake with the extractor and/or mixer function you still have some
level of protection. For example, even if an attacker can correctly guess every
16th bit of your extractor function, it will still be very difficult for them
to guess the final PRNG outputs. I've found that it is much easier to think
about the two functions as distinct, so you can reason about what specific
properties you want or need the mixer and extractor to have, and it also makes
it simpler to replace one or the other to make different security/speed
I believe most common hardware RNGs produce data at fairly high rates, often
over 100 kbytes per second. If you have one of those you'll be able to get much
more entropy from that than you will out of regular system sources, especially
as the entropy of those samples usually decreases pretty strongly after the
first sample or two, while the HWRNG keeps producing entropy at the same rate.
Instead of treating the two entropy sources as somehow different in your mixing
strategy, just use the HWRNG for most of the inputs, but every tenth sample (or
whatever), instead use the hash of all the random-looking system data you can
get ahold of. Only doing it occasionally means there is a reasonable chance
that sufficient changes have happend to the system since the sample worthwhile
in terms of entropy gained, and doing a large block of it all at once prevents
iterative guessing attacks if an attacker can control your HWRNG outputs but
not your system statistics.
Encrypting the output using keys generated by the PRNG is a good idea, but you
presented it in a somewhat confusing way, in that it sounded almost like you
were doing message transfer. Then I realized you're not actually doing that at
all, just a postprocessing (or preprocessing, in the case of the recipient)
operation using a randomly keyed block cipher (which the X9.31 RNG would also
provide nicely). At not point do the two sides actually exchange messages, so
in this situation, your mention of key distribution is somewhat misleading. If
you want to try to keep the entropy values sent from the box with the HWRNG to
the client a secret from people on the network, just open up a TLS session. TLS
is cheap if you use session resumption, and with self-signed certificates or
anonymous DH there is no key distribution. It makes bootstrapping a little more
difficult, but presumably the client can get at least some entropy via the
traditional means currently available on common platforms.
You could also just solve the problem you mention directly, and try to find a
cheaper HWRNG design. I know people who have built them for a few dollars worth
of stuff at Radio Shack, and apparently VIA, Intel, and AMD have all found them
cheap enough at various times to ship them included in components they've built
at little or no extra cost. You can buy a PCI board with a low-end Hifn crypto
chip on it for less than $80 online.

@_date: 2005-10-18 19:49:17
@_author: Jack Lloyd 
@_subject: EDP (entropy distribution protocol), userland PRNG design 
Peter Gutmann has several good papers on RNG design, as have some folks
currently or formerly associated with Counterpane (ie Wagner, Kelsey, Hall,
...). It is worth reading their analysis papers as well as their design papers,
especially the ones that cover fielded PRNG designs.
Of course. I was just pointing out that there are many that do produce at that
rate. Since you weren't specific, I assumed it was a COTS hardware RNG.
That does not seem very difficult: just sample all of them. As long as your
PRNG is good, an attacker won't be able to do anything by only controlling a
subset of them.
Sorry, I should have been a little more clear. That 1/10 split was only
supposed to be an example. You would presumably determine the appropriate
sample rate based on an analysis of the system statistics. It is just as you
mentioned, "oversampling won't help you generate random bits any faster; you
will get more bits but no more randomness." You should sample each possible
source so as to reach some maximum; presumably you either want to maximize
total entropy over time, or total entropy over bits sampled, or maybe total
entropy over # of samples. In any case, it's highly likely that alternating
between reading 160 bits from a good HWRNG and the SHA1 hash of the output of
`ps` is not going to produce any such maxiumum.
The point of my suggestion was not that you implement those specific steps, but
that you desing your PRNG so that it can make the best use of an arbitrary
number of entropy sources with various (known or estimated) distributions. This
ties in well with the previous point about using multiple HWRNGs.
But that is all you are moving - entropy. As best as I could tell from your
original proposal, the two sides never actually shared a key. So while one side
was encrypting stuff and the other side was decrypting, at no point were they
actually exchanging information.
However, I don't see how you are protecting the confidentiality of the data at
all in your current design. I was not suggesting TLS as an alternative, but as
a method of achieving what you (apparently?) meant to do. However, if you could
perhaps clarify what you meant with regards to encrypting the data that is
transferred, that might help - I may well have simply misread you. In
particular, how do the two sides agree on an initial key?  I'm afraid I don't
see how it is possible for two parties to use the same key starting out with no
shared knowledge and without any public key operations.
Thanks for the link - I only knew about the Soekris boards.

@_date: 2005-10-26 11:37:49
@_author: Jack Lloyd 
@_subject: [smb@cs.columbia.edu: Skype security evaluation] 
I just reread those sections and I still don't see anything about RSA
encryption padding either. 3.2.2 just has some useless factoids about the RSA
implementation (but neglects to mention important implementation points, like
if blinding is used, or if signatures are verified before being
released). 3.2.3 describes the signature padding, but makes no mention of the
encryption padding, or even that a padding method is used for encryption.

@_date: 2006-02-01 13:16:27
@_author: Jack Lloyd 
@_subject: CD shredders, was Re: thoughts on one time pads 
If you packaged up your OTP material into blocks using an all-or-nothing
transform you could probably be certain that this would suffice, as long as the
blocks you used were large enough that it was at least statistically probable
that 'enough' bits of each block were destroyed or made unreadable. I believe
specifically you'd want to make sure that 2^n is an infeasible amount of work,
where n is the minimum number of bits that will be lost from any block by the
destruction process. This seems to generalize nicely, for example if an entire
CDs worth of material was processed as a single block under an all-or-nothing
transform, just snapping the disk in half might suffice to prevent any
(computationally feasible) data recovery [though it would be quite annoying in
practice, since you'd have to process the entire disk to read even a single bit
from it]

@_date: 2006-02-08 11:53:56
@_author: Jack Lloyd 
@_subject: general defensive crypto coding principles 
This seems like an interesting choice - Bellare and Namprempre have a paper on
this [worth reading IMO;  which
suggests that this method (which they term Encrypt-and-MAC) has problems in
terms of information leakage. An obvious example occurs when using a
deterministic authentication scheme like HMAC - an attacker can with high
probability detect duplicate plaintexts by looking for identical tags. They
also show that using a MAC on the ciphertext is a secure construction in a
fairly broad set of cases.
Hmm.. though I believe in the case of using public key signatures rather than a
MAC, one would want to sign before encrypting, since otherwise an attacker
could take another parties message, strip off the signature and add their own
without detection (unless the message itself included source information that
the receiver could check against). I can imagine some bizarre key management
systems where something like this attack might also work using a shared-key
MAC, though it seems the best solution then would be to fix your key

@_date: 2006-02-09 01:13:56
@_author: Jack Lloyd 
@_subject: general defensive crypto coding principles 
Looking at the definitions in the paper, I think it is pretty clear that that
was their intent. The scheme definitions in section 4 make no provisions for
initialization vectors or any kind of parameterization, so I'm assuming that
they assumed the encryption function will include all that as part of the
output, meaning it will be included as part of the MAC.

@_date: 2006-02-11 13:14:29
@_author: Jack Lloyd 
@_subject: general defensive crypto coding principles 
I would expect that typically implementors would be following a published
standard, which would (well, one would hope) have had expert cryptographers
check it over sometime prior to publication. If your typical application
programmer is just coming up with their own crypto protocol, I personally don't
consider it to be a valid concern because they will with overwhelming odds
completely botch it in any case, and usually in a much less subtle way than
(Actually offhand I can't think of a single non-cryptographer-designed crypto
protocol I've seen that wasn't fundamentally broken, often in a fairly obvious
way. I could believe there have been a few, but the odds seem very much against

@_date: 2006-02-13 11:25:44
@_author: Jack Lloyd 
@_subject: general defensive crypto coding principles 
I'm also the author of a crypto toolkit, and I'll admit I've been involved in
creating custom security protocols more than once myself. I'm well aware that
this is a legitimate need.
I think the source of our different views on this is a result of expectations
with regards to what your average programmer is capable of in terms of secure
protocol design. I have done reviews on probably a dozen or so products that
had a custom crypto component of one sort or another, and there were often
really trivial problems (typically the well-known and well-documented ones that
people have been getting wrong for decades).
At this point I'm generally of the opinion that there are maybe 5% of
programmers who will be careful enough to get it right, and the rest will get
it spectacularly wrong because they won't bother to do anything more than
perhaps skim Applied Cryptography. So, if you're going to mandate just one
technique for everyone, you're better off (IMO) using something that is a bit
trickier but has better optimal bounds, because the 5% will still probably get
it right (and their protocols will be better off for it) and the rest are too
busy getting it wrong in other ways to bother implementing the authenticated
encryption mode incorrectly.
In short, I find it extremely optimistic to think that there is any substantial
population of programmers who could correctly design and implement a
non-trivial and secure crypto protocol without taking a reasonable amount of
time with the existing body of knowledge.

@_date: 2006-01-03 14:10:40
@_author: Jack Lloyd 
@_subject: OpenSSL BIGNUM vs. GMP 
Some relevant and recent data: in some tests I ran this weekend (GMP 4.1.2,
OpenSSL 0.9.8a, Athlon/gcc/Linux) RSA operations using GMP were somewhat faster
than ones using OpenSSL even when blinding was used with both (typical
performance boost was 15-20%).
I'm assume "both of which are needed" should have been "at least one of which
is needed"? AFAIK blinding alone can protect against all (publicly known)
timing attacks; am I wrong about this?

@_date: 2006-01-03 18:01:07
@_author: Jack Lloyd 
@_subject: OpenSSL BIGNUM vs. GMP 
Thanks for the link! Does OpenSSL defend against this attack? I suspect writing
fast modexp code that will (in the paper's words) "avoid any data-dependent or
key-dependent memory access or code path patterns" would be quite non-trivial,
so I would be interested to see how that is implemented. I did a quick scan
through 0.9.8a's crypto/bn but didn't see anything that looked likely, but
OpenSSL is big, so I could easily be missing it. :)
That's an good point - probably compiling both OpenSSL and GNU MP with no
assembly code would be a more interesting comparison, from an algorithm
However, I think you are confusing two different goals here. I'm guessing that
you want an analysis of GNU MP vs OpenSSL so you can figure out how to make
OpenSSL faster. For that, an algorithm-based analysis is obviously much more
useful. I mostly care about which is faster, now, on the platforms I care
about, and it doesn't really matter why one is faster. For example, if GNU MP
has a faster modexp implementation than OpenSSL on an Athlon because the GNU MP
developers sold their souls to the devil [*] in exchange for some really good
hand-tuned Athlon asm, that's cool with me -- as long as it's fast.
[*] I make no claims that the GNU MP developers have actually been involved in
    any unholy bargains involving souls for code.

@_date: 2006-01-26 14:24:30
@_author: Jack Lloyd 
@_subject: thoughts on one time pads 
Your use case above suggests that you are still willing to trust conventional
ciphers to be secure, so, practically speaking, what is the difference between:
Key  128 bits of one time pad
Key  AES_{masterkey}(counter++)
I'm not an "expert", but the reason I'd call it a bad idea (versus just not
worth the effort, which is all the AES/OTP comparison is suggesting) is it
introduces a need for synchronization, and that can be a hard thing to do
between arbitrary parties on a network.
I don't think attacks are the problem, so much as susceptibility to errors. To
even get started, you need a CD of truly random bits, which is fairly
non-trival to do on many platforms (and it's difficult to tests if your bits
are actaully random or just look that way). More importantly, the key
management issues seem annoying and highly prone to catastrophic failure. For
example, I send you a message using the first N bits of the pad, my machine
crashes, I restore from backup (or a filesystem checkpoint), and then my index
into the pad is reset back to the start. Then I resend a second message using
the same pad bits. Problem.
I think your characterization of the possible attacks is pretty fair. But
compare the OTP failure mode "access to it would compromise past and future
communications", to the failure mode of, say, RSA authenticated DH key
exchange, which provides PFS and requires an active attack in order to attack
communications even after the key is compromised. Is OTP so much more secure
than a simple PK-based key exchange that it is worth even this single tradeoff
(not to mention the initial key exchange hassles and the need to store
megabytes of pad with anyone I might want to talk to)?
That sounds prone to a man in the middle attack; what is to stop someone from
taking your authentication packet with the N bits of unguessable pad, cause
your connection to drop and then authenticating as you using the pad you sent
You could probably do a challenge-response authentication based on pad bits
pretty easily, however, though doing it in a way that doesn't require a secure
hash might be a little trickier.
There are some attacks against WEP along those lines (they used RC4 to encrypt
the checksum, instead of a one time pad, but it would end up about the same, I
would think). Using HMAC keyed with pad bits seems a lot more sane to me...
I think that this question needs to be asked at all points to one of the flaws
of OTP from a practical standpoint.

@_date: 2006-07-02 11:21:27
@_author: Jack Lloyd 
@_subject: EDP (entropy distribution protocol), userland PRNG design 
Yes. IIRC, same thing, just in a different standard. (And I have a
copy of X9.31, while I've never even read X9.17)

@_date: 2006-03-22 23:30:56
@_author: Jack Lloyd 
@_subject: Entropy Definition (was Re: passphrases with more than 160 bits of entropy) 
He did give a formula for the entropy of a source; however the caculation is
based on the probabilties of each symbol appearing. Unless you know those, you
can't actually apply the formula. So it is computable in theory, just not in
pratice for any source that is at all interesting.
A random oracle, by definition, produces a completely random output. However,
since random oracles don't actually exist that does not seem to be a terribly
interesting thing to be measuring the entropy of.
Bits are usually the most intuitive/useful unit.
I have a vague feeling this question requires a deeper answer than I'm able to
No, because there are no additional secrets. Knowledge of the password is all
you need to rederive the final output, thus clearly there is no additional
information (ie, entropy) in the output that was not in the original password.
This ignores the salt, iteration count, and the specification of the algorithm
itself, but those are all (usually) public. So they contribute to the entropy,
they do not contribute to the conditional entropy, which is what we are usually
interested in when thinking about entropy and crypto.
Yes. Let's say the contents of tommorrow's NY Times has n bits of entropy (we
probably can't actually calculate n, but we know it is a finite and fixed
value). And the LA Times from the same day will also have some amount of
entropy (call it n'). However, the entropy of the two papers combined would
(probably) not be n+n', but some number x st min(n,n') <= x <= n+n', because
the two papers will report on many of the same issues, carry some of the same
AP stories, and so forth. This redundant information doesn't increase the
entropy (reading the same AP story in a second newspaper wouldn't give you any
new information).
A book you may find interesting is "Elements of Information Theory" by Cover &

@_date: 2006-11-20 10:13:10
@_author: Jack Lloyd 
@_subject: EAX and CCM code 
There are some vectors in the EAX paper, which were generated by
These vectors were, IIRC, confirmed by a second independent implementation.

@_date: 2006-09-18 11:27:23
@_author: Jack Lloyd 
@_subject: A note on vendor reaction speed to the e=3 problem 
Botan does the same thing for (deterministic) encodings - mostly
because I wrote a decoder for PKCS v1.5, realized it probably had
bugs I wouldn't figure out until too late, and this way the worst
thing that can happen is a valid signature is rejected due to having
some unexpected but legal encoding. Default deny and all that.
Anyway, it's a lot easier to write that way - my PSS verification code
is probably around twice the length of the PSS generation code, due to
the need to check every stupid little thing.

@_date: 2007-04-05 10:05:02
@_author: Jack Lloyd 
@_subject: DNSSEC to be strangled at birth. 
How is this any different from plain-old-DNS? Except that now the
number of attackers is limited to one - instead of worrying about the
US or China or UK or India or Russia or whoever falsifying DNS
records, you just have to worry about the US. And if/when you catch
them at it, you know exactly who did it.

@_date: 2007-08-20 09:19:53
@_author: Jack Lloyd 
@_subject: New DoD encryption mandate 
The basic algorithms don't but you can easily enough use multiple CPUs
with a hash tree or hash list. I'd also guess that in many cases you'd
want to hash many files, which offers easy parallelism by spawning a
pool of threads that work off a series of files. If you can afford a
patent license for PMAC, that would work as well.

@_date: 2007-08-31 12:40:55
@_author: Jack Lloyd 
@_subject: World's most powerful supercomputer goes online 
The Steam survey is going to overestimate the power of the average
machine because it is only sampling machines which are capable of
playing Half-Life 2 (or other equally resource intensive games). The
recommended machine for Half-Life 2 is a 2.4 GHz CPU with 512 Mbytes
RAM. No surprise that most of the machines surveyed hit that minimum.
As for "most powerful supercomputer" - that ignores that the
interconnect used (the Internet) is going to be 2 to 4 orders of
magnitude slower in bandwidth and latency than that used in any modern

@_date: 2007-12-13 14:22:47
@_author: Jack Lloyd 
@_subject: More on in-memory zeroisation 
GCC on x86-64 (-O2) compiles this function to the same machine code
regardless of the value of ZEROIZE:
 int sensitive(int key)
   {
   char buf[16];
   int result = 0;
   size_t j;
   for(j = 0; j != sizeof(buf); j++)
      buf[j] = key + j;
   for(j = 0; j != sizeof(buf); j++)
      result += buf[j];
 ZEROIZE
   (memset)(buf, 0, sizeof(buf));
   return result;
   }
Even if (memset) must refer to a function with external linkage (an
analysis I find dubious), there is nothing stopping the compiler from
doing IPA/whole program optimization - especially with a very basic
function like memset (in the code above, if buf is declared volatile,
GCC does do the memset: but it does it by moving immediate zero values
directly to the memory locations, not by actually jumping to any
external function).
  Jack

@_date: 2007-12-28 10:05:23
@_author: Jack Lloyd 
@_subject: 2008: The year of hack the vote? 
The only reason this 'must' be true is because an anonymous and secure
payment system is a terror which thankfully our federal governments
and central banks protect us from. While Amazon and others obviously
like being able to build customer profiles of everyone, I don't doubt
that they would be perfectly willing to accept an anonymous payment as
long as the money is good (and, of course, that the transaction costs
are no more than a credit card and/or the order flow is sufficient
that it is worth building support for it).

@_date: 2007-05-12 16:05:17
@_author: Jack Lloyd 
@_subject: no surprise - Sun fails to open source the crypto part of Java 
I believe at least some versions of Java used RSADSI's JSAFE for the
low-level crypto code, which would explain why that portion of it
wasn't included.

@_date: 2007-10-05 10:48:20
@_author: Jack Lloyd 
@_subject: Retailers try to push data responsibilities back to banks 
Amazingly, Tizor Systems does PCI reviews (actually they entirely seem
to do C&A work), and I'm sure Prat would prefer to see the PCI gravy
train stay around. (I don't know the current state of the industry,
but when I was working in a consulting group 2004-2005, PCI reviews
were our most profitable engagement type by a large margin - and
non-technical enough that you can put a person with a few months of
security training on them and they'll do fine).

@_date: 2007-10-26 10:12:12
@_author: Jack Lloyd 
@_subject: Password vs data entropy 
If E(key) >= E(text), why not use a one time pad?
Entropy != economic value

@_date: 2008-04-16 11:16:02
@_author: Jack Lloyd 
@_subject: Double Encryption Q 
This would certainly cause problems in if "particular mode" == OFB or
counter, since (if you also reuse the IVs), you could have E(zA) == A.
If you use a different (independent, unrelated) key/IV, then the
existence of a weakness in this scheme would seem to provide evidence
of an attack on AES, regardless of mode choice.

@_date: 2008-04-23 12:18:03
@_author: Jack Lloyd 
@_subject: Cruising the stacks and finding stuff 
I think one point worth making is that we probably don't really know
how to make a cipher that is secure to, say, 2^512 operations (or
2^1024 or 2^4096 or whatever). For instance if you took Serpent or AES
or Twofish and modified it to support 512-bit keys, I don't believe
the resulting cipher would actually be secure to 2^512
operations... to guess completely at random, I'd say they would be
more like 2^300 or so. (Have any block ciphers with 256-bit
block/512-bit key been proposed/studied? I have not been following FSE
and similar conferences of late)
Making a cipher that uses an N bit key but is only secure to 2^M
operations with M<N is, firstly, considered broken in many circles, as
well as being inefficient (why generate/transmit/store 512 bit keys
when it only provides the security of a ~300 bit (or whatever) key
used with a perfect algorithm aka ideal cipher - why not use the
better cipher and save the bits).

@_date: 2008-04-29 11:27:38
@_author: Jack Lloyd 
@_subject: SSL and Malicious Hardware/Software 
Most places I have worked (all in the US) explicitly required consent
to more or less arbitrary amounts of monitoring as a condition of

@_date: 2008-12-05 16:00:01
@_author: Jack Lloyd 
@_subject: CPRNGs are still an issue. 
I think the situation is even worse outside of the major projects (the
OS kernels crypto implementations and the main crypto libraries). I
think outside of those, nobody is even really looking. For instance -
This afternoon I took a look at a C++ library called JUCE which offers
(among a pile of other things) RSA and Blowfish. However it turns out
that all of the RSA keys are generated with an LCRNG (lrand48,
basically) seeded with the time in milliseconds.
  Also I found GNU Classpath has a PRNG that does something similiar,
though at least it has the decency to use SHA-1 instead of an LCRNG.
Unfortunately this is the same PRNG class that is used to generate
RSA/DSA private keys and DSA's k values, and it is not even possible
(AFAICT) for an application developer to add additional seed data in.
These are trivially obvious mistakes that have been known (at least in
the security community, though clearly not everywhere) for a decade
plus, at least since Goldberg and Wagner broke Netscape, and, like
classic buffer overflows and SQL injection, new code making the same
mistakes keeps getting written.

@_date: 2008-12-28 23:49:06
@_author: Jack Lloyd 
@_subject: very high speed hardware RNG 
I've been thinking that much better than a chipset addition (which is
only accessible by the OS kernel in most environments) would be a
simple ring-3 (or equivalent) accessible instruction that writes 32 or
64 bits of randomness from a per-core hardware RNG, something like
; write 32 bits of entropy from the hardware RNG to eax register
rdrandom %eax
Which would allow user applications to access a good hardware RNG
directly, in addition to allowing the OS to read bits to seed the
system PRNG (/dev/random, CryptoGenRandom, or similar)
I think the JVM in particular could benefit from such an extension, as
the abstractions it puts into place otherwise prevent most of the
methods one might use to gather high-quality entropy for a PRNG seed.

@_date: 2008-12-30 13:37:10
@_author: Jack Lloyd 
@_subject: very high speed hardware RNG 
Well, maybe it has. Or maybe it was just not competently implemented,
or perhaps it has a failure mode that was not accounted for. The
design might be perfect but the physical implementation that happens
to be in your computer has a manufacturing flaw such that if the CPU
core voltage is slightly low and the ambient temperature is above 95F,
the raw output becomes biased from a uniform distribution in a subtle
way - how do you detect something like that? I personally would not
trust the direct output of any physical hardware source for anything,
precisely because you cannot measure it, or test for failures, in any
meaningful way. That does not mean it is not a useful thing to have.
We already have this problem with rdtsc and equivalent cycle counter
reading instructions. ISTR that some architectures allow the kernel to
forbid access to the cycle counter - if so, similar techniques could
be used for a rdrandom instruction. For those that don't, the
non-reproducability ship has already sailed (think of rdtsc as a
rdrandom that has a very bad probability distribution).
Reproducability is sometimes a virtue, but sometimes not. I recall
discussions last year, I believe on this list, about how to design a
PRNG that was able to safely deal with VM state rollbacks. A
user-accessible RNG instruction would easily alleviate this problem.
Except when it doesnt exist - in which case most Java software seems
to default to things like seeding a PRNG with the timestamp, because
the other alternatives that are feasible in Java, like interleaving
counter reads among multiple threads, are slow, difficult to implement
correctly, and even more difficult to test.

@_date: 2008-02-21 15:13:30
@_author: Jack Lloyd 
@_subject: cold boot attacks on disk encryption 
While they did have some success with recovering an entire AES key
schedule uncorrupted, it seems important to note that the simplistic
nature of the AES and DES key schedules allowed them to recover the
entire original key even after the state had been somewhat degraded
with only moderate amounts of work. A cipher with a better key
schedule (Blowfish or Serpent, for instance) would seem to offer some
defense here.

@_date: 2008-07-09 13:22:32
@_author: Jack Lloyd 
@_subject: Kaminsky finds DNS exploit 
Taking a brief look at what changed in bind, it seems primarily to
involve randomizing the query port, matching both the port and
transaction id instead of just the id, and using RC4 to generate the
transactions ids instead of a pair of very sketchy-looking
(cryptographically speaking) RNGs based on an LCRNG design via Knuth.
Perhaps there is something subtle here that is more dangerous than the
well known problems, and all these source port randomization and
transaction id randomization fixes are just a smokescreen of sorts for
a fix for something Dan found.
Securosis claims [1] "The good news is that due to the nature of this
problem, it is extremely difficult to determine the vulnerability
merely by analyzing the patches", and Dan claims something similar,
offering to share the stage at Defcon with anyone who finds the
bug [2]
A statement from the MaraDNS author [3]:
MaraDNS is immune to the new cache poisoning attack.  MaraDNS has
always been immune to this attack.  Ditto with Deadwood (indeed,
people can use MaraDNS or Deadwood on the loopback interface to
protect their machines from this attack).
OK, basically, this is an old problem DJB wrote about well over seven
years ago.  The solution is to randomize both the query ID and the
source port; MaraDNS/Deadwood do this (and have been doing this since
around the time of their first public releases that could resolve DNS
queries) using a cryptographically strong random number generator
(MaraDNS uses an AES variant; Deadwood uses the 32-bit version of
Radio Gatun).
(But CERT has no reply in their advisory from MaraDNS, so I'm not sure
if this statement was made on the basis of just what is publically
known, or if he was in fact in on the vendor notify list).
[1] [2] [3]

@_date: 2008-07-10 09:59:36
@_author: Jack Lloyd 
@_subject: Kaminsky finds DNS exploit 
I came across a plausible sounding theory about this.
Quoting from So I have a theory on what it is that Dan Kaminsky may have discovered
that is broken with DNS (it was already _so_ broken, what else could be
Basically it has to do with ICMP packets (spoofed ICMP unreachables sent
in response to DNS packets the attacker can't see, but can guess - thanks
to non-random port selection).
The biggest problem with spoofing DNS at the moment is that you need
to silence the real nameservers in order to get your fake replies in.
For an ICMP response to be valid, it must contain the IP header of the
packet it is a reponse too, but it also must contain 64bits of the data
payload. The reason for requiring 64bits of the payload is to prevent
people from spoofing ICMP replies to packets they have not received. In
the case of a DNS packet, that payload is the first 64 bits of the UDP
What is in the first 64bits of the UDP header? The source and destination
ports of the DNS servers. If these are easily predictable then you can
spoof an ICMP unreachable response to a dns query or reply without
actually receiving it.
If you can spoof ICMP; You can prevent the recursor from communicating
with the real nameserver. This will make it very very easy to spoof DNS as
it removes the biggest hurdle; that of silencing the real nameservers. It
only takes about 2min on a 10mbit/s connection to run through all 65536
possible sequence numbers so if you can prevent the recursor from talking
to the real nameservers it really is easy as pie.

@_date: 2008-06-29 15:41:44
@_author: Jack Lloyd 
@_subject: Why doesn't Sun release the crypto module of the OpenSPARC? 
The calculus on AES may change in the nearish future: Intel is adding
AES instructions in upcoming processors, and AMD is adding another set
of instructions in SSE5 to assist AES implementations. AMD claims a 5x
speedup for AES using SSE5 versus plain x86-64 instructions [2], I
have not yet seen performance estimates for the Intel instructions.
[1]: [2]:

@_date: 2008-03-20 10:05:52
@_author: Jack Lloyd 
@_subject: Protection for quasi-offline memory nabbing 
Or as a non-patented alternative one could use the Bear/Lion
constructions [1], which can encrypt arbitrary size blocks at
reasonably good speeds (depending on the performance characteristics
of the stream cipher and hash function they are instantiated with).
[1]

@_date: 2008-05-05 10:20:06
@_author: Jack Lloyd 
@_subject: Comments on SP800-108 
As a standard, this is specification is a disaster. Just from a quick
read, I see the following:
"However, alternative orders for the input data fields may be used for
a KDF."
"with a length specified by the function, an algorithm, or a protocol
which uses T as an input."
"In feedback mode, the output of the PRF is computed using the result
of the previous iteration and, optionally, using a counter as the
iteration variable(s)."
With sufficient options, all implementations are non-interoperable. I
think you've managed to reach that point here. As an implementor, my
instinct is to stay well away from this entire mess and just use IEEE
1363's KDF2, which is:
  - simple enough that anyone can implement it easily and without
     interop difficulties, or requiring protocol negotiations (and
     then the implementor has to do the negotiation properly - which
     opens up new avenues for security holes)
  - secure enough that it "doesn't matter" (ie, that the likelyhood
     that a security flaw in the KDF is the critical problem is far
     lower than a security flaw elsewhere in the system)
My recommendation: choose something that will work for nearly
everyone, and mandate it directly. For instance, why make the counter
length configurable? In 99% of implementations, the thing that will
make sense is a 32-bit counter (to paraphrase the famous if apocryphal
Bill Gates quote, 4 gigabytes of keying material should be enough for
anybody), but by refusing to mandate this behavior, you force every
implementor and application designer to choose something and then
negotiate on the off chance that some other length was chosen, or that
the other side is using variable length encodings - something which is
allowed by the spec, as best as I can tell, and which opens up some
pretty big (at least theoretical) holes.
I have no comments about the actual security aspects of it; it looks
fine to my eye, but given the interoperability issues listed above I
don't plan on implementing any of these KDFs anyway, so I can't say I
much care whether they are actually secure or not. I would advise you
to remember that crypto does not exist in a vacuum, and should help,
not hinder, the overall security of a system.
  Jack Lloyd

@_date: 2008-05-06 13:53:49
@_author: Jack Lloyd 
@_subject: User interface, security, and "simplicity" 
Is there any reason (in principle) that IPsec/IKE could not be done
entirely in userspace / application space, though?

@_date: 2008-10-24 13:50:07
@_author: Jack Lloyd 
@_subject: Who cares about side-channel attacks? 
I have little experience on the embedded crypto side but I do maintain
a crypto library that has some non-zero number of users on general
desktop and server machines.
Basic protections ala your point 2 are provided and enabled by default
(blinding, and checking private key operations for consistency with
the public, to prevent the really easy attacks). There used to be a
toggle to disable blinding, which as far as I know was never used - or
at least nobody complained when I removed the toggle.
To my memory nobody has ever asked about what SCA measures are or are
not enabled, or how to toggle them, though I do have a FAQ entry about
it, so perhaps people who really wanted serious side-channel
resistence just read that FAQ and moved on to another implementation
without ever bothering to contact me - certainly there are some
self-selection problems with my sampling.
When FlexSecure wrote Botan's ECC implementation for BSI, they
implemented a number of anti-timing attack countermeasures - but they
were being paid to care about that, so this is probably not a valid

@_date: 2008-10-24 16:12:32
@_author: Jack Lloyd 
@_subject: combining entropy 
I do not think one means the other here.
An omniscient malicious RNG source seems quite unlikely in most threat
models. However that is a very different statement from saying that
lacking such an attacker, you can safely assume your 'pools of
entropy' (to quote the original question) are independent in the
information-theoretic sense.
Say you execute (on a Linux machine) two commands, like ifconfig -a
and netstat -s (which print ASCII text with statistics about network
interfaces and network protocols, resp), capturing the output as two
of your entropy sources.
Both have some amount of entropy (perhaps zero if an attacker is on
the machine and runs his commands at the same time as yours - and
perhaps quite a bit more if the local machine happens to be safe). But
they are certainly not statistically independent!  Information in one
will be somewhat reflected in the other (packet counters), and of
course at the macro level all your inputs have high bit unset, so if
you combined via XOR your output will have at best .875 bits of
entropy per bit.
To address IanG's question more directly, my first thought would be to
use something like the design Hugo Krawczyk describes in "On
Extract-then-Expand Key Derivation Functions and an HMAC-based KDF"
( or one of the related
PRNG designs he references. Then use the output of the HMAC PRF to
feed the DT vector of an X9.31 PRNG (using block cipher du jour), a
trick AFAIK invented by Peter Gutmann which has always seemed like a
good worst-case-scenario trick to me (for instance, if the code for
the hash's compression function is miscompiled), though at the cost of
extra code/design complexity (and thus points of failure) - as always
there are tradeoffs to make.
-Jack (IANAC)

@_date: 2008-10-24 18:40:25
@_author: Jack Lloyd 
@_subject: combining entropy 
Perhaps our seeming disagreement is due to a differing interpretation
of 'trusted'. I took it to mean that at least one pool had a
min-entropy above some security bound. You appear to have taken it to
mean that it will be uniform random?

@_date: 2008-09-01 16:18:15
@_author: Jack Lloyd 
@_subject: 512-bit discrete logarithms, in practice 
How difficult is it to compute discrete logarithms modulo a 512-bit
prime p of the form 2*q+1, q prime? I have had no luck finding recent
DL results, as it seems factoring is the preferred
benchmark/target. The DL algorithms seem to be have roughly the same
runtimes as factoring, but this is only getting me to order of
magnitude estimates.
These estimates suggest 512 bits is feasible, based on recent
factoring results, but I'm not sure if that means it is feasible with
a handful of modern processors, or if I need to go acquire a
supercomputer and/or a few hundred thousand zombie PCs before trying
this. I am really trying to solve a series of DH key exchanges,
however I am not aware of any algorithms specifically for DH (though
references would be welcomed).
Can anyone point me to recent DL results, or have any experiences
trying to break ~512 bit DH exchanges?
  Jack

@_date: 2009-08-18 08:04:02
@_author: Jack Lloyd 
@_subject: 512 bit RSA key used for TI 83+ auth cracked 
It seems the TI-83+ operating system is protected using some form of
code signing scheme using a 512 bit RSA key. That key has now been
Which apparently will allow custom operating systems to run on the
While this certainly is not the first 512 bit RSA moduli to be
factored, this may be the first one that was performed (publicly, at
least) with the goal of breaking an existing system, rather than
simply demostrating progress in algorithms and hardware.
Interestingly, it was reportedly done with only a single machine, over
the course of 73 days.
Details on the computation are lower down in the thread:
How did I do this? With the best tools I could find for the job. The
best algorithm for factoring really large general numbers (i.e.,
numbers without any special properties) is the general number field
sieve. The best currently-available implementation of the GNFS
consists of a combination of the GGNFS and Msieve projects. It's
really the guys behind these tools who deserve the credit for making
this possible. While it does take a bit of work to get the tools set
up correctly, most of what I did was sitting around waiting for it to
finish, and every once in a while, telling the script to try another
filtering run. smile.gif
Some fun statistics:
- The factorization took, in total, about 1745 hours, or a bit less
  than 73 days, of computation. (I've actually been working on this
  since early March; I had a couple of false starts and haven't been
  able to run the software continously.)
- My CPU, for reference, is a dual-core Athlon64 at 1900 MHz.
- The sieving database was 4.9 gigabytes and contained just over 51
  million relations.
- During the "filtering" phase, Msieve was using about 2.5 gigabytes of RAM.
- The final processing involved finding the null space of a 5.4
  million x 5.4 million matrix.

@_date: 2009-08-19 12:05:20
@_author: Jack Lloyd 
@_subject: [tahoe-dev] Tahoe-LAFS key management, part 2: Tahoe-LAFS is 
OT trivia: The idea actually predates either monotone or git; opencm
( was using a similiar technique for VCS
access control a year or two prior to monotone's first release. AFAIK
Graydon Hoare (the original monotone designer) came up with the
technique independently of the opencm design. I'm actually not certain
that opencm originated the technique, either; all I can say for
certain is that it was using it prior to monotone or git.

@_date: 2009-02-12 14:40:08
@_author: Jack Lloyd 
@_subject: Property RIghts in Keys 
That only certain persons can revoke or reissue a certificate is a
matter of mathematics, not legal restrictions.
Say I have discovered a marvelous method of easily factoring RSA keys,
which unfortunately the margin of this emacs buffer is too small to
contain, and I then go out, factor GeoTrust's CA key and issue a new
Am I now infringing on GeoTrust's IP rights? Or have, rather, I made
myself a co-owner in said rights on this particular key?
Have I broken any law? If not, should what I have done be illegal?

@_date: 2009-07-02 14:37:31
@_author: Jack Lloyd 
@_subject: What will happen to your crypto keys when you die? 
This method would not work terribly well for data at rest. Copy the
ciphertext, start the brute force process, and two months later you
get out everything, regardless of the fact that in the meantime the
data was reencrypted.

@_date: 2009-07-22 00:30:04
@_author: Jack Lloyd 
@_subject: Fast MAC algorithms? 
I'm getting the impression that key agility is important here, so one
MAC that comes to mind is CMAC with a block cipher with a fast key
schedule like Serpent. (If for some reason you really wanted to do
something to make secuity auditors squirm you could even cut Serpent
down to 16 rounds which would increase the message processing rate by
about 2x and also speed up the key schedule. This seems like asking
for it to me, though.)
Another plausible answer might be Skein - it directly supports keying
and nonces (so you don't have to take the per-message overhead of the
extra hash as with HMAC), and has very good bulk throughput on 64-bit

@_date: 2009-07-24 15:07:22
@_author: Jack Lloyd 
@_subject: NIST announces SHA-3 round 2 candidates 
A report summarizing NIST's selection of these candidates will be
forthcoming. A year is allocated for the public review of these
algorithms, and the Second SHA-3 Candidate Conference is being planned
for August 23-24, 2010, after Crypto 2010.
Making the cut:
  BLAKE
  Blue Midnight Wish
  CubeHash
  ECHO
  Fugue
  Grostl
  Hamsi
  JH
  Keccak
  Luffa
  Shabal
  SHAvite-3
  SIMD
  Skein

@_date: 2009-06-17 01:16:25
@_author: Jack Lloyd 
@_subject: Popular explanation of fully homomorphic encryption wanted 
Google located for me a set of slides and audio for a talk given by
the author on this paper:

@_date: 2009-05-22 11:06:23
@_author: Jack Lloyd 
@_subject: Distinguisher and Related-Key Attack on the Full AES-256 
Alex Biryukov, Dmitry Khovratovich, and Ivica Nikolic gave a talk at
the Eurocrypt rump session, 'Distinguisher and Related-Key Attack on
the Full AES-256', with the full paper accepted to Crypto.
Slides from Eurocrypt are here:
The q-multicollisions attack they describe may be a practical way of
breaking a hash function based on AES. So this could have some
interesting ramifications to SHA-3 candidates which use the AES round
function; I'm not sufficiently familiar with those designs yet for it
to be clear one way or another if they would in fact be vulnerable.
(via zooko's blog)

@_date: 2009-11-11 11:32:08
@_author: Jack Lloyd 
@_subject: hedging our bets -- in case SHA-256 turns out to be insecure 
If performance is really an issue one could code a combined H1/H2
function which would interleave the operations, which would prevent
needing two passes (which _is_ really important since memory and disk
latencies are usually the biggest factor in performance). Direct
interleaving would also offer better ILP.
But even updating both hashes at the same time would prevent needing
two full passes; something like the code below would offer much better
cache utilization, and would not be at all difficult to implement:
while data_left:
  block = input.read_one_block()
  h1.compress(block)
  h2.compress(block)
If it was really important, choosing a nonstandard H2 could offer even
better performance; for instance let H1=SHA-256 and H2=SHA-~256, where
SHA-~256 is precisely SHA-256 but with all of its constants bitwise
inverted. One could compute both functions in parallel using SIMD
(SSE2, ARM's NEON, etc) [and they could share the message expansion,
which is quite costly in SHA-2]. It's not clear from a quick read of
the paper Zooko referenced ("On the Strength of the Concatenated Hash
Combiner when All the Hash Functions are Weak") if this would actually
meet the requirements of "sufficiently different" for the results
there to apply, though.
One trouble with this construction that Zooko's does not have is that
it can fail even if H1 is collision resistant due to an inner
The GOST hash does use the sum of input blocks (as the final input to
the compression function) but it has a number of other components; it
is actually quite slow compared to modern hashes.

@_date: 2009-10-15 00:39:07
@_author: Jack Lloyd 
@_subject: Possibly questionable security decisions in DNS root management 
Even plain DSA would be much more space efficient on the signature
side - a DSA key with p=2048 bits, q=256 bits is much stronger than a
1024 bit RSA key, and the signatures would be half the size. And NIST
allows (2048,224) DSA parameters as well, if saving an extra 8 bytes
is really that important.
Given that they are attempted to optimize for minimal packet size, the
choice of RSA for signatures actually seems quite bizarre.

@_date: 2009-10-19 12:15:26
@_author: Jack Lloyd 
@_subject: Possibly questionable security decisions in DNS root management 
True, but TCP and UDP are also full of covert channels. And if you are
worried that your signing software or hardware is compromised and
leaking key bits, you have larger problems, no matter what algorithm
you use; for instance, with RSA, the signer could intentionally
miscalculate 1 in 2^32 signatures, which would immediately leak the
entire private key to someone who knew to watch for it. (I would have
said that using PSS also introduces a covert channel, but it appears
DNSSEC is using the scheme from PKCS1 v1.5.)
And, for that matter, one can make DSA deterministic by choosing the k
values to be HMAC-SHA256(key, H(m)) - this will cause the k values to
be repeated, but only if the message itself repeats (which is fine,
since seeing a repeated message/signature pair is harmless), or if one
can induce collisions on HMAC with an unknown key (which seems a
profoundly more difficult problem than breaking RSA or DSA).
As far as I know even now nobody has proven that breaking RSA is
equivalent to factoring; there are results that suggest it, for
instance [ shows there is no 'generic'
attack that can break RSA without factoring - meaning such an the
attack would have to examine the bit representation of the modulus.  A
full proof of equivalence still seems to be an open problem.
If for some reason one really wanted to ensure their public key
primitives reduces to a hard problem, it would have made much more
sense to use Rabin-Williams, which does have a provable reduction to

@_date: 2009-09-04 16:14:19
@_author: Jack Lloyd 
@_subject: RNG using AES CTR as encryption algorithm 
NIST SP 800-38A "Recommendation for Block Cipher Modes of Operation"
contains a set of AES/CTR test vectors in Appendix F.5

@_date: 2010-04-21 18:58:19
@_author: Jack Lloyd 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
Numerous PK schemes based on coding theory or the shortest vector
problem are available. None of them are vulnerable to Shor's
algorithm. Any of them can be implemented in software and do not
require point to point links.
The introduction to "Post Quantum Cryptography" may be informative:

@_date: 2010-07-12 13:13:10
@_author: Jack Lloyd 
@_subject: Intel to also add RNG 
I think it's important to make the distinction between trusting Intel
not to have made it actively malicious, and trusting them to have
gotten it perfectly correct in such a way that it cannot fail.
Fortunately, the second problem, that it is a well-intentioned but
perhaps slightly flawed RNG [*], could be easily alleviated by feeding
the output into a software CSPRNG (X9.31, a FIPS 186-3 design, take
your pick I guess). And the first could be solved by also feeding your
CSPRNG with anything that you would have fed it with in the absense of
the hardware RNG - in that case, you're at least no worse off than you
were before. (Unless your PRNG's security can be negatively affected
by non-random or maliciously chosen inputs, in which case you've got
larger problems).
[*] Even if it were perfectly designed, it seems plausible to me that
manufacturing defects and/or any number of runtime problems (age,
overheating, bad voltage control, cosmic rays, dirty power, etc, etc)
might cause subtle failures/biases that might be difficult to detect
reliably; I would personally be dubious of using any hardware RNGs
output directly for this reason.

@_date: 2010-07-27 20:44:43
@_author: Jack Lloyd 
@_subject: A mighty fortress is our PKI 
Already exists:
 - JS, displays a nice
dialog telling the user why they should upgrade and links to download
a new IE, Firefox, Chrome, etc.
 - Drupal (CMS) plugin
 - if you're feeling malicious, just include
the one line JavaScript that will make IE6 crash, maybe eventually the
user will figure it out. (Or maybe not).
Or a block of pretty much plain old HTML:
Ultimately though, the only thing that's going to get some people off
IE6 is the machines they are running it off of finally dying, either
due to hardware failure or being so badly owned by worms that the
machine becomes inoperable, at which point it goes into the trash
and they buy a new one.

@_date: 2010-07-28 10:53:52
@_author: Jack Lloyd 
@_subject: A mighty fortress is our PKI, Part II 
With a sufficiently fine grained authorization model inside the OS,
there is no reason in principle that something like attribute
certificates couldn't work - RealTek would have a code signing cert
only valid for drivers that talked to network cards with specific PCI
vendors IDs, and UI tools that talked to that driver - the signature
on the worm binary in question would be valid, but the worm would not
be given the permissions it wants to actually do its thing. (Eg, when
was the last time you had a network driver that needed to access an
MSSQL db). Windows is not that OS. (Neither is Linux or BSD of
course). It looks like Singularity has some features which could
support this sort of model [1].
This is not to suggest this is at all an easy course of action to
take; my point is just that it's possible to do much better here
without having to alter anyone's incentives: the CAs still collect
their rent, and RealTek's drivers still work. Fixing the OS is
probably easier than somehow fixing PKI to do what we'd nominally want
it to do here (though actually revoking the cert would have been a
good start) or modifying the obvious incentives.
[1]

@_date: 2010-07-28 11:21:21
@_author: Jack Lloyd 
@_subject: deliberately crashing ancient computers (was: Re: A mighty 
Personally I'm not planning on doing anything one way or another to
encourage or discourage people using IE6. In the spectram of social
badness, I'd view using IE6 roughly on par with using heroin - a bad
idea that mostly hurts oneself with some limited (albeit real)
negative externalities. As with using drug rehabilitation versus
prison sentences to reduce use, the real solution to IE6 is education
and assistance for those who want it, not punishment. Some will, for
whatever reason, choose to ignore said educational/assistance efforts,
and eventually will take the consequences of their actions without any
antics by you or I.
And certainly I have better things to do with my time than crash a
decade-old browser.
  Jack

@_date: 2010-10-06 11:15:51
@_author: Jack Lloyd 
@_subject: Formal notice given of rearrangement of deck chairs on RMS 
_If_ Mozilla and the other browser vendors actually go through with
removing all <2048 bit CA certs (which I doubt will happen because I
suspect most CAs will completely ignore this), it would have one
tangible benefit:
(Some of, though unfortunately not nearly all) the old CA certificates
that have been floating around since the dawn of time (ie the mid-late
90s), often with poor chains of custody through multiple iterations of
bankruptcies, firesale auctions, mergers, acquisitions, and so on,
will die around 2015 instead of their current expirations of
2020-2038. Sadly this will only kill about 1/3 of the 124 (!!)
trusted roots Mozilla includes by default.

@_date: 2010-09-03 10:29:35
@_author: Jack Lloyd 
@_subject: Merkle Signature Scheme is the most secure signature scheme 
A recent result relevant to this is
"Practical consequences of the aberration of narrow-pipe hash designs
from ideal random functions", Klima and Gligoroski
Which shows that narrow-pipe designs have a huge null space for
messages which are exactly as big as the compression function input
size. For instance hashing inputs that are multiples of 512 bits,
SHA-256 will only produce about 63% of the possible 2^256
outputs. This could be quite relevant to a Merkle scheme since
typically the input will be a set of hash outputs; if the internal
block size and the output length are not coprime, one would easily
encounter this limitation. It could probably be hacked around by using
padding on the inputs (eg the input to each Merkle hash is N subtree
hashes plus as many zero bytes as required to make the input length a
prime number of bytes), but that definitely sets of some bogosity
alarms in my mind.
One point I am uncertain on is if wide-pipe hashes like Blue Midnight
Wish or SHA-384 suffer the same levels of entropy loss as narrow-pipe
designs (outside of the case described in the referenced paper, which
is specific to narrow pipes).

@_date: 2010-09-30 21:09:18
@_author: Jack Lloyd 
@_subject: 2048 bits, damn the electrons! [rt@openssl.org: [openssl.org 
It would not require changing the standard, since the only way to tell
that my RSA modulus N is a factor of 4 primes rather than 2 primes is
to, well, factor it. And if one can do that there are bigger issues,
of course.
However multi-prime RSA is patented in the US; by Compaq (now HP) I
believe? US patent 7231040, applied for in 1998, so in force for at
least 5 more years if not more. I don't know if there are patents on
this in non-US locales.

@_date: 2013-09-02 18:06:04
@_author: Jack Lloyd 
@_subject: [Cryptography] NSA and cryptanalysis 
Suite B is specified for 128 and 192 bit security levels, with the 192
bit level using ECC-384, SHA-384, and AES-256. So it seems like if
there is a hint to be drawn from the Suite B params, it's about
Not to mention that our entire PKI system (as well as TLS < 1.2, ie
the versions actually supported in browsers) rely on the security of
SHA-1, an algorithm which has a public 2**68 (IIRC) collision attack
and which was phased out by NIST years ago.
Fortunately now TLS 1.2 is finally being forced into most browsers
thanks to BEAST, Lucky13, RC4 breaks, etc but still we're bound to see
some major problems on the PKI side when a practical chosen prefix
SHA-1 collision is found, as I expect at least a few widely used CAs
have still not adopted randomized serial numbers and will have the MD5
experience all over again.
Worth noting that NIST has announced plans to create AEAD modes based
on Keccak. It will be interesting to see how quickly AES-GCM is phased
out of Suite B once that occurs.

@_date: 2013-09-06 14:41:32
@_author: Jack Lloyd 
@_subject: [Cryptography] Suite B after today's news 
OCB parallelizes very well in software and I see no reason it would
not also do so in hardware; each block of both the plaintext and
associated data can be processed independently of the others, and all
of OCB's operations (xor, GF(2^128) doubling, Grey codes) seem like
they would be well suited to a fast hardware implementation. And
actually McGrew and Viega's original 2003 paper on GCM specifically
mentions that OCB "scales to high speeds in hardware", though they do
not provide references to specific results.

@_date: 2015-07-06 13:26:50
@_author: Jack Lloyd 
@_subject: [Cryptography] Best AES candidate broken 
Serpent uses sboxes, but ones intentionally designed to be implemented
using bitslicing rather than table lookups. I'm not aware of any
non-toy Serpent implementation that actually does 4->4 bit lookups,
rather than evaluating all 16 lookups in parallel using bitwise operations
whose sequence does not depend on any secret data. Do you?
  Jack
