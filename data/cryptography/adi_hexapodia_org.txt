
@_date: 2003-04-09 15:58:09
@_author: Andy Isaacson 
@_subject: Intel RNG still available? 
It sounds to me like going to a car dealer and demanding an automobile
made with steel mined in Minnesota.  Perhaps they exist, but the
salesperson has absolutely no reason to have such detailed information
about the product they sell.
Since OpenBSD has kernel support for the Intel 8xx RNG, searching the
web for dmesg output is informative.  My laptop says
pchb0 at pci0 dev 0 function 0 "Intel 82815 Hub" rev 0x11: rng active, 7Kb/sec
Googling for 'Intel hub "rng active"' found examples of i810, i815,
i820, i840, and i850 hardware that activate the RNG.
It certainly appears that "the entire stock" was not shipped to IBM, as
dozens of other vendors have systems incorporating these chipsets.
The OpenBSD source code claims that the 810, 810e, 815, 820, 840, 850,
and 860 all provide the RNG.  The conspicuous missing entry on the list
is the 845, which appears on all the Intel-chipset Pentium 4
motherboards currently available from my local whitebox shop.
OpenBSD also has code to support the AMD768 RNG, but google does not
show any instances of this being used in the wild.

@_date: 2003-06-25 10:53:29
@_author: Andy Isaacson 
@_subject: New toy: SSLbar 
I doubt the truth of this statement.  Certainly, the back door was only
published after the source was opened.  But, just as Matt Blaze found
out when he published his attack on pin-and-tumbler locks, fields other
than computer security do not have a culture of public disclosure.  In
all likelihood the Interbase back door was discovered and carefully
promulgated among the gray- and black-hat communities interested in that
Closed-source is not much of a guarantee in the face of a determined
attacker.  Or in the face of a large number of capable, interconnected,
curious hackers (in the traditional sense of the word).

@_date: 2004-04-13 12:52:45
@_author: Andy Isaacson 
@_subject: [Mac_crypto] Apple should use SHA! (or stronger) to authenticate software releases 
You and Nicko are discussing different attacks.
One attack is "Find two patches which have the same MD5".  This falls to
a birthday-paradox attack with 2^64 work, and is somewhat easier if the
patch format includes a random tail.  (The collision attack needs 64
bits of controllable input in the message.)  Short of a compromise of the
developer's machine, it's hard to see how this type of hash collision can
be leveraged into getting a malicious patch distributed as genuine.
Another attack is "Submit a carefully sculpted change through normal
channels which results in the new patch having an attacker-determined
hash value".  The work factor is somewhat difficult to estimate, but is
probably a significant multiple higher than 2^64, primarily due to the
more-complex iterator due to having to emulate the workflow of the
developer when computing hash values.  In this attack, the assumption is
that the attacker submits a diff (a very innocuous one, but with a
special structure), which is integrated, and the result is a (binary)
patch which is signed by the developer.  The attacker was able to craft
the diff so as to cause MD5(patchA) to match MD5(patchB) and then
distributes patchB with the signature from patchA.
This second attack is made infeasible by simply appending 64 bits of
randomness to the patch before signing it.  Since the attacker could not
possibly know those bits, so his work required increases by a *power* (I
believe -- haven't done the math carefully) of 64.
These are straightforward extensions of Van Oorschot & Wiener's 1994
paper "Parallel Collision Search with Application to Hash Functions and
Discrete Logarithms".
The obvious conclusion is that nobody should be using MD5 any more;
follow the OpenBSD project's lead and distribute SHA1 alongside your MD5
distribution.  Or SHA-256 if you're really paranoid.
I don't see how this is any different from the generic source validation

@_date: 2004-12-24 12:56:37
@_author: Andy Isaacson 
@_subject: SSL/TLS passive sniffing 
That's basically what /dev/urandom does, no?  (Except that it has the
undesirable side-effect of depleting the entropy estimate maintained
inside the kernel.)
On my PIII/666 running 2.4.26, I get 1.4 MB/sec from /dev/urandom.
Seems plenty fast enough to me.  (Fast, of course, being orthogonal to
I'm baffled by the post you reference:
Andrew Suffield writes on Mon, 20 Dec 2004 06:11:08 -
I *think* what that says is "generating a session key based on entropy
from /dev/urandom is security-equivalent to no encryption
Which is so obviously false that I can't imagine that I'm not
misreading.  I will grant that *if* an attacker can reconstruct the
state of the entropy pool (which in theory is possible if the attacker
can gather N bits of information about the outputs, but would require a
significant advance over the state of the art in cryptanalysis of the
hash function, and probably about 2^N work) then a key generated from it
is insecure.  But the difficulty of extracting that much information
about the entropy pool is enormous, and the challenge of reconstructing
the state, given that information, is ... large.
It would be less work to build a SQUID [1] and snoop the operation of
your ALU from the white van parked across the street from the data
So, I agree with you - while it would be preferable to generate session
keys using the most conservative entropy estimates, it's a perfectly
reasonable engineering compromise to use /dev/urandom.  I'd rather have
Good Enough encryption, universally deployed, than fall for the Purity of
Essence^H^H^H^H^H^H^HRandomness whackos' claims that "Everyone must plug
a Geiger counter into their serial port or We're All Going To Die".
BTW, the Linux kernel guys are actively working on improving the
security of /dev/*random and could benefit from experienced
cryptographers willing to review work and make suggestions.  Check out
the linux-kernel archives for the past few months for subjects
mentioning /dev/urandom and /dev/random.
[1] Superconducting QUantum Interference Device, the Gibsonian gizmo
    used by the dolphin in _Johnny Mnemonic_ to extract "80 *Gigabytes*!"
    of information from the courier's brain-mounted memory module.

@_date: 2005-02-15 18:56:05
@_author: Andy Isaacson 
@_subject: SHA-1 broken, says Schneier 
# SHA-1 has been broken. Not a reduced-round version. Not a simplified
# version. The real thing.
# # The research team of Xiaoyun Wang, Yiqun Lisa Yin, and Hongbo Yu (mostly
# from Shandong University in China) have been quietly circulating a paper
# announcing their results:
# #     * collisions in the the full SHA-1 in 2**69 hash operations, much
#     * less than the brute-force attack of 2**80 operations based on the
#     * hash length.
# #     * collisions in SHA-0 in 2**39 operations.
# #     * collisions in 58-round SHA-1 in 2**33 operations.
# # This attack builds on previous attacks on SHA-0 and SHA-1, and is a
# major, major cryptanalytic result. This pretty much puts a bullet into
# SHA-1 as a hash function for digital signatures (although it doesn't
# affect applications such as HMAC).
# # The paper isn't generally available yet. At this point I can't tell if
# the attack is real, but the paper looks good and this is a reputable
# research team.
This appears to be the same research team that published the MD5
collision technique back in August.

@_date: 2013-11-10 00:54:01
@_author: Andy Isaacson 
@_subject: [Cryptography] NIST Randomness Beacon 
WARNING:
    DO NOT USE BEACON GENERATED
    VALUES AS SECRET
    CRYPTOGRAPHIC KEYS.
The Beacon is a potentially useful service.  Folks have implemented
similar semantics by, for example, hashing the DJIA closing value of a
given date (see NIST's implementation, of course, makes them a trusted third party to
any security critical applications of this oracle.  I'd be more
comfortable with a cryptographic hash of an unpredictable but publicly
determined value; however, it's hard to find one that has as much
entropy as the Beacon.
For example, suppose you use the low bits of the bitcoin blockchain
hash.  An attacker with 10% of the hash power could probabilistically
attack such a system by chosing blocks with a specific value in those
bits; furthermore, the miners might know the relevant value earlier than
other users of the system.

@_date: 2014-08-17 15:06:58
@_author: Andy Isaacson 
@_subject: [Cryptography] [cryptography] Question About Best Practices for 
I'm a significant proponent of open source, and the benefits you
enumerate here are definitely true.  Open source can be helpful in
reviewing code, in grokking developer intent, in providing a hash-chain
guarantee of code lineage, in providing change history and justification
when reviewing new releases of a previously audited program, and in
fostering positive engineering practices.
However --
Your "proprietary program" strawman is full of holes.
The intellectual labor of decompiling a program delivered as a binary is
not especially large compared to the labor required to do a thorough
systematic review.  Given IDA Pro and a non-obfuscated Win32 or Linux
app, people I trust say the decompilation process is on the order of
10%-20% of the total effort of a review.
Binary patches are not great by any means, but they are definitely a
feasible method of deploying fixes, and this method works and is well
tested in the real world.  Some kinds of deployments basically require
binary patching, no matter what the underlying source management
technology.  (The Linux Ksplice project provides one prominent example.)
Backdoors are an enormous problem for both open source and
binary-distribution codebases, and claiming that open source will save
you from backdoors ignores the reality of the situation.  Just to start,
"Building Reliable Voting Machine Software", Ka-Ping Yee
page 148 of  provides a sobering
assessment of the difficulty of finding intentionally inserted bugs in
open source software.

@_date: 2015-01-13 17:56:32
@_author: Andy Isaacson 
@_subject: [Cryptography] open hardware as a defence against state-level 
The LowRISC project aims to build a complete open SoC based on the
RISC-V architecture and get chips fabbed.
