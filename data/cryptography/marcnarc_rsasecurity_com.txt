
@_date: 2001-06-25 11:26:06
@_author: Marc Branchaud 
@_subject: Zero Knowledge Identity Proofs 
I'm not hep to the identification scheme literature, but I'll just a note
that in Dimitrios's scheme, Alice can't just sign the challenge, but must
also include Dave's signature in her signature.  That is, Alice must sign all
of {S_dave(challenge), challenge}, not just the challenge by itself.  And
Dave has to verify that both the challenge and his signature were signed by
Alice.  Otherwise, Bob could just masquerade Dave's challenge.

@_date: 2001-06-26 16:00:26
@_author: Marc Branchaud 
@_subject: Zero Knowledge Identity Proofs 
Well, I can't be sure that I'm not misunderstanding something either.  For
the most part, I agree with Dimitrios that challenges with proof of origin
are part of the solution to Mafia Fraud attacks.  My main point is that I
don't think simply signing the challenge is enough.
Let me try to restate things symbolically.  Nominally, in the naive case,
Dave would present Alice with a challenge, X, and Alice would transform &
return the challenge: X'.  This, as we know, is vulnerable to the Mafia
What I believe Dimitrios is proposing is for Dave to present both the
challenge and a signature on the challenge: {X, S_dave(X)}.  Then, Alice
would verify that the signature corresponds to the person she thinks she's
talking to, and if so she can return the transformed challenge X'.
I'm essentially contending that Dave needs to verify that Alice did indeed
see the challenge & signature he presented.  Consider Mafia Fraud against the
above scenario.  Dave presents {X, S_dave(X)} to Carol, who forwards it to
Bob.  Now, Bob can re-sign the challenge himself, and present {X, S_bob(X)}
to Alice.  Alice will happily verify that the challenge comes from Bob, and
return X' to Bob, who then passes it to Carol & then on to Dave.   The fraud
is successful, because Dave can't tell that Alice saw Bob's signature on the
challenge and not his own.
So the X' that Alice computes must be a function f(X, S_dave(X)) on both the
challenge and the signature.  (If, in the naive case, X'=S_alice(X), then to
truly prevent the fraud we need X'=S_alice(X,S_dave(X)).)  Now the fraud
fails because Alice would compute X'=f(X, S_bob(X)), and so Dave (not Alice)
would detect the fraud.
So it's not enough for Dave to simply sign the challenge & for Alice to
verify that signature.  Alice must prove to Dave that she saw his signature
and not somebody else's.
BTW, without giving it any thought, I believe this scheme is safe against
replay attacks (because Dave generates a new challenge every time).  Does
anybody have any thoughts about that?

@_date: 2001-10-18 14:56:51
@_author: Marc Branchaud 
@_subject: limits of watermarking (Re: First Steganographic Image in theWild) 
This analogy doesn't quite hold.
Copy protection need only be broken once for the protection to be disabled
for a particular piece of work.  Also, once the scheme is known for one piece
of work, it is extremely easy to break the scheme for other pieces, and in
particular to write an application that will do so.
With crypto's bar-raising, OTOH, breaking one instance, like an SSL stream or
an AES key, does not break all other uses of SSL or AES.  In particular, SSL
& AES will provide the same degree of protection for any other communication
of the same data between the same or other parties.  Also, good crypto
schemes are already widely known and designed explicitly so that knowledge of
the scheme does not break the scheme.

@_date: 2002-08-22 17:22:06
@_author: Marc Branchaud 
@_subject: the underground software vulnerability marketplace and its hazards 
I agree that such pressure is pretty reprehensible.  As others in this
thread have said, it's your decision how you want to publish the
information.  People should respect that decision.
I agree with that to a certain extent.  However, we (RSA) recently had
to release patches to several versions of Xcert's old Sentry CA because
of the OpenSSL fixes.  I do not know how our customers would have been
helped by having the source.
First, I want to point out that Xcert's use of OpenSSL was entirely in
agreement with OpenSSL's license.  The fact that we built closed-source
product atop OpenSSL was playing the game properly, as far as the rules
were laid out.  (If you think OpenSSL's users should behave differently,
change the license!)
Even if we gave our customers our source code, we had made a few changes
to the OpenSSL code for use in Sentry CA.  Mostly to deal with things
like PKCS and ECC (we used OpenSSL for crypto, some ASN.1 and SSL).
So patches don't necessarily apply perfectly cleanly (though these ones
did).  It seems unreasonable for us to expect our customers to make the
appropriate changes themselves.  (We even had to make our own patch for
a particularly early version of Sentry CA that used a verison of OpenSSL
that did not get a patch from openssl.org.  There's nothing like money
to bring out the whore in all of us...)
Also, one of the selling points of Sentry CA was that it's thoroughly
tested.  We had to make sure that the patches didn't break the product.
 Again, we can't really expect our customers to do that themselves.
Now, I'm a big fan of open-source software, and am very sympathetic to
its ideas in many ways.  All I'm trying to point out is that the issues
aren't necessarily so black-and-white.  We certainly could have
benefitted from advanced notice of the flaws, but I personally think
that "vendors" shouldn't get first dibs at any patches.  That said, I
don't really know what we could've done with the news while waiting for
OpenSSL's patches to come out.  So the way things happened is probably
the fairest outcome possible.  It was a rough couple of weeks for us,
though, getting our own fixes together while OpenSSL was sitting pretty.
 Customers don't seem to like _knowing_ they're vulnerable, for some
(I speak for myself, and these opinions are my own, and I might even be
lying about everything.)

@_date: 2002-02-07 10:56:09
@_author: Marc Branchaud 
@_subject: SSO (was Re: biometrics) 
In most SSO schemes, the password is only used to authenticate to a single
domain, and (a token attesting to) the fact that the authentication succeded
is passed around to other domains.  The authenticating domain is typically
akin to the user's "home" domain (as opposed to the user just logging into
some arbitrary domain) so the password isn't widely shared.  Most of these
schemes are web-based, and users that first surf to a non-home domain are
redirected (as tranparently as possible) to their local domain for
authentication, and something like an authentication "ticket" is encoded in a
cookie or in a return-redirecting URL.

@_date: 2002-07-03 09:42:42
@_author: Marc Branchaud 
@_subject: MS DRMOS Palladium -- The Trojan Horse OS 
By patenting the DRMOS, only M$ will be allowed to create such a beast (OK, they could license the patent without restrictions -- pardon me while I pick myself up off the floor).  This means that the rest of the planet's OSes will have nothing even approaching DRM functionality, because nobody wants to be sued by M$.
That's good, but OTOH other OSes will not build anything approaching secure computing either, for the same reason.
I expect M$ OSes to provide both secure computing as well as the DRM nightmare outlined in Stallman's story.  I also expect all other OSes to provide neither secure computing nor DRM.
Software patents.  Gotta love em!

@_date: 2002-11-06 09:50:34
@_author: Marc Branchaud 
@_subject: patent free(?) anonymous credential system pre-print 
Absolutely.  Which is precisely why we need an extension to patent
If it's good enough for copyright...

@_date: 2002-11-06 15:20:54
@_author: Marc Branchaud 
@_subject: Did you *really* zeroize that key? 
If I use
is the pointer volatile or is the memory it points to volatile?  What
does the standard say?  Obviously, I want to memory to be treated as

@_date: 2002-10-17 10:22:57
@_author: Marc Branchaud 
@_subject: QuizID? 
Any thoughts on this device?  At first glance, it doesn't seem
particularly impressive...
Lovely idea of two-factor authentication:
   The user then enters their user name (something they know) and the
   8-digit Quizid passcode (something they have) into the login screen
   of their application.
BBC NEWS | Technology | Handy future for online security
Excerpt from the BBC article:
   Users are issued with a card and a personal code, based on a set of
   colour keys on the card. Each time they wish to conduct a secure
   transaction, they punch in the colour code and a random number is
   generated.

@_date: 2002-09-20 10:50:00
@_author: Marc Branchaud 
@_subject: unforgeable optical tokens? 
According to the article at  :
   ?We have about a terabit ? a one followed by twelve zeros ? of
   information contained in a penny?s worth of material,? said
   Gershenfeld.
   ...
   In practice, the combination of laser light inputs and resulting
   speckle pattern outputs for each token could be stored on a secure
   database. The token could then be read at a terminal that queries
   the database and authenticates the token?s identity.
I don't know just how practical this would be, in practice...
BTW, I think the Science article cited in the above article & on Pappu's
web site is available to Science subscribers (of which I'm not) at
(The above URL may have been munged...)

@_date: 2003-04-02 11:51:17
@_author: Marc Branchaud 
@_subject: TPM coming to Canada 
Do you have a pointer to that second study?
I haven't fully read this paper, but a quick glance leads me to believe
that it's fairly balanced.  Consider:
 - Section 4, "Circumvention", ends with "As will be discussed in
greater detail in our second Study, the motives for circumventing TPMs
articulated above suggest that a policy choice that would result in
anti-circumvention laws should be approached with great caution."
 - Section 5.2, "The Policy Implications of DRMs", has the following
passage: "However, the degree of control that publishers will obtain
over works in a digital environment could also result in attempts to
apply and enforce copyright in ways never previously contemplated by
Canadian copyright law. For example, it might allow copyright holders to
exclude various forms of public access to a digital work. This very real
possibility could entirely undermine the delicate balance between
private rights and the public interest that copyright law seeks to achieve."
 - Section 6, "The Future of TPMs", discusses two general approaches
"thought to assist in minimizing the threat of circumvention" --
technical and legal.  The brief technical discussion points out the
shortcomings we all know.  The even briefer legal discussion refers to
the second study, saying the legal approach "is fraught with other
So I'm not sure I agree with your pessimistic assessment of the paper,
though I'm very keen to see that second study.

@_date: 2003-06-30 15:51:55
@_author: Marc Branchaud 
@_subject: Mozilla tool to self-verify HTTPS site 
I'll reserve judgement about the significance of SSLBar, but I couldn't agree more with the above point.  The only way to use non-X.509 certs with TLS 1.0 is by rather clunkily extending the ciphersuites to also identify some kind of certificate type.
IMO, this fact has significantly contributed to the lack of adoption of PGP, SPKI, and alternative PKIs on the Internet.
TLS's new extension mechanism can help address this (see draft-ietf-tls-openpgp-keys), but it'll be a while before extension support is common.

@_date: 2003-03-25 09:53:46
@_author: Marc Branchaud 
@_subject: Brumley & Boneh timing attack on OpenSSL 
The way I understand the attack, you have to throw a million
specially-chosen guesses at the server, which it will blindly attempt to
decrypt and use.  Basically, you're getting the server to decrypt chosen
ciphertext for you.
I don't see how the attack can apply to signatures, where the server
itself is formatting the data to be signed.  Unless the server is just
directly signing (RSA-encrypting) arbitrary client-supplied data, but
that's a no-no anyway.
This is slightly more than theoretical, as OCSP servers do nothing but
emit signed responses.  An OCSP client can only indirectly influence
some of the data that a server signs, and so it seems very difficult to
pull off the attack.

@_date: 2004-08-12 13:34:09
@_author: Marc Branchaud 
@_subject: Any TLS server key compromises? 
I've been wondering, has a TLS server (or client, for that matter) key ever actually been compromised?  I don't think I've ever heard of one.
I'm thinking of two possible avenues for compromise, and ignoring insider attacks.  One is through defects in the protocol itself or its implementation.  The other would be through a compromise of the server host (e.g. a buffer overflow in Apache) that allows the attacker to copy the TLS server's private key from the file system.
It seems to me that in-the-wild attacks on the protocol or its implementation are unheard of.
OTOH, we hear about server break-ins all the time.  However, one never hears about these break-ins leading to a compromise of the server's key.
Perhaps the server's private key isn't a really useful target?  Although posession of the key makes it easy to spoof a secure server, actually doing that spoofing requires a secondary attack, like phishing or an active attack on the Internet, to redirect a user to the false server.
So have there ever been any actual TLS private key compromises (through any non-insider attack)?
If TLS private keys aren't attractive enough a target for them to be compromised even when the opportunity presents itself (as I'm assuming it has), then to what extent do these keys really need to be protected?
