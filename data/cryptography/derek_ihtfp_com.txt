
@_date: 2002-04-16 17:47:49
@_author: Derek Atkins 
@_subject: Schneier on Bernstein factoring machine 
I see no contradiction at all.  Bruce believe that Lucky is one of
"those paranoid enough" that "should have upgraded years ago".  In
other words, Bruce is surprised that Lucky didn't already upgrade to a
key larger than 1024 bits, due to his "paranoia".
No offense meant, Lucky...

@_date: 2002-04-17 10:51:21
@_author: Derek Atkins 
@_subject: Schneier on Bernstein factoring machine 
I think it's really about degree.  I don't agree that having a
non-empty threat model implies you a paranoid.
You could have a threat model of "I don't want my sister or parents to
read this" which is very different than "I don't want the NSA or KGB
to read this".  I would certainly call both of these statements a
"non-empty threat model".  I would certainly call the latter threat
model "paranoid"; I would NOT call the former threat model paranoid --
I would call it a "normal teenager" :)

@_date: 2002-08-10 12:49:40
@_author: Derek Atkins 
@_subject: adding noise blob to data before signing 
Blinding?  Padding?  It depends on what you are trying to accomplish.
It depends on the signature algorithm.  With RSA you can sign any
message "directly" if said message is smaller than the public key size
(N).  DSA, however, requires the use of a hash.
Note that, in the grand scheme of things, performing the public key
operation is significantly slower than performing the hash, so it
really doesn't hurt you computationally to perform the hash.  OTOH,
your signature strength still depends on the strength of your hash.

@_date: 2002-08-10 15:38:30
@_author: Derek Atkins 
@_subject: adding noise blob to data before signing 
Let me be clear: I implied (but clearly I should have been explicit)
that PKCS padding should be used, not "raw" RSA.  The problem with
raw RSA is that you can combine multiple encryptions into new
encryptions.  Using PKCS padding inside the RSA signature foils the
multiplication attack.  So, sure, your message is can only be
N-(sizeof(pkcs bits, not N bits.  However you still do not
need a hash.

@_date: 2002-08-10 15:51:26
@_author: Derek Atkins 
@_subject: responding to claims about TCPA 
Who owns the key?  If you bought the smartcard, you generated the key
yourself on the smartcard, and you control it, then it is probably
benefitting you.  If the smartcard came preprogrammed with a
certificate from the manufacturer, then I would say that it is
protecting the third party from you.
The difference is proving that you are being honest to someone else
vs. an application proving to YOU that it is being honest.  Again, it
is a question of ownership.  There is the DRM side (you proving to
someone else that you are being honest) vs. Virus Protection (an
application proving to _you_ that it is being honest).

@_date: 2002-08-15 23:21:45
@_author: Derek Atkins 
@_subject: get a grip on what TCPA is for 
Note that this is not the only interesting question
to be solved.  It is one question, certainly the major
question that Da Mouse wants to be answered, but far
from the only one.
Ok, I qualify here as "stepping in those moccasins", so let me
continue my analysis.
True, however I have yet to believe that this is a credible
threat.  Perhaps I am naive, but I do believe that a majority
of people are honest, and honest people are going to do the
honest thing.  Do I listen to digital music?  Sure, but I
still go out and buy the CD.
Um, this is NOT the same problem.  In fact, this is completely
different.  Yes, you still need the TPM to do this, however the
requirements over the TPM are completely different.  To solve this
problem I only need a TPM where *I* can control the keys, and have it
watch over itself.  I could still run Linux or whatever OS I wanted,
because the goal here is for me to certify my own software running on
my own machine.
In fact I don't even need a TPM to detect tampering.  All I need is to
have a boot-CD with md5sum and have it burn the md5sum values of all
files onto another CDROM...  Then I can detect tampering by again
booting off the CDROM and running the tests again.
A TPM that *I* control just makes it more real-time.  You can enforce
restrictions that no changes are made to the OS.  But the manufacturer
needs no control over this.  They don't need the keys.  They don't
need certificates.
Actually, as I think about this, you can do this today with
"non-resetable" BIOS and Bootup passwords and "encrypted" disk drives
(where the disk key is also stored in the BIOS).  Someone with
physical access would need to be able to read out the BIOS settings or
obtain my BIOS passwords to do anything.  You don't need a TPM for
this, you just need resiliant BIOS nvram.  Then the machine is useless
without the passwords.
So, what does the TPM buy _ME_ when running my own machine?

@_date: 2002-08-20 10:40:43
@_author: Derek Atkins 
@_subject: SEC weighing civil injunction against RSA 
SEC may sue RSA over records
By Bloomberg News, 8/20/2002
B EDFORD - RSA Security Inc. said the Securities and Exchange
Commission may file suit following an investigation into how the
company disclosed a change in accounting and stock sales by executives
last year.
The SEC's staff told the computer-security company last month that it
may seek permission from the commission to file a lawsuit against the
company and some of its officers, RSA said in a quarterly report to
the SEC last week. The company, which denies wrongdoing, in April said
it was the subject of an SEC investigation. RSA changed its accounting
in the first quarter of 2001 to recognize revenue when products are
shipped to distributors, rather than when the goods reach
customers. The company didn't disclose the change, which boosted
first-quarter revenue by $1.74 million, until more than a month after
reporting results, when it filed a quarterly report with the SEC.
This story ran on page C3 of the Boston Globe on 8/20/2002.  ?
Copyright 2002 Globe Newspaper Company.

@_date: 2002-08-30 19:48:15
@_author: Derek Atkins 
@_subject: Palladium and malware 
"application/shell" anyone?  (Yes, some Mail-readers actually
implement this!)

@_date: 2002-12-08 17:18:31
@_author: Derek Atkins 
@_subject: DOS attack on WPA 802.11? 
The answer is multi-fold.
1) The 802.11i standard wont be finished for a while.
2) There is an apparent Market Requirement for something better than
   WEP __NOW__.
3) The WPA can only change their "requirements" once per year, so even
   if 802.11i were ready in 3 months, it would still take another year
   until it hit the WPA conformance requirements.  But they wanted to
   make some changes _now_ in order to get "better" security into next
   year's product line.
In other words, the answer is due to layers 8 and 9, and nothing

@_date: 2002-01-28 12:41:32
@_author: Derek Atkins 
@_subject: [linux-elitists] Re: Looking back ten years: Another Cypherpunksfailure (fwd) 
There are other problems with using IPsec for VoIP..  In many cases
you are sending a large number of rather small packets of data.  In
this case, the extra overhead of ESP can potentially double the size
of your data.  In certain cases (such as cablemodem networks) this
implies that using IPsec effectively halves the number of active
VoIP sessions that a carrier can handle.

@_date: 2002-01-28 17:04:03
@_author: Derek Atkins 
@_subject: Fingerprints (was: Re: biometrics) 
Keep in mind that this is the _creation_ of the database entry.  Yes,
you want the data in the database to be as completely accurate as
possible.  Later, when they only have partial prints, they can perform
a lookups of partial data using the complete database.  I think the
same would be true of mass-produced fingerprint scanners.
So long as the backend-database has a full, complete data set,
a partial read on the verification step can still match.
The question is: what would be the rate of false-positive (or
false-negative) readings?

@_date: 2002-01-28 17:43:34
@_author: Derek Atkins 
@_subject: [linux-elitists] Re: Looking back ten years: Another Cypherpunksfailure (fwd) 
8-bit u-law (standard telephone quality) is 56kb/sec.  20ms at that
rate is 140 bits (I guess you assumed 64kb/sec to get 160 bits?).
However, many audio codecs in common use (e.g. G7.11) output a
bit-rate much smaller than 8-bit u-law, to the point were we're really
talking about 20-30 bytes of data for that same 20ms of audio.  Yes,
we're talking 8-12kb/sec codecs.  This means that in order to send 20
bytes of data you're already adding 60 bytes (or a factor-of-three
increase), not to mention the extra 22 (or more) for ESP.
The other thing to keep in mind is that IP+UDP+RTP can be compressed
using standard header-compression techniques, which pretty much
eliminates most of that extra overhead.  So, maybe your
factor-of-three increase that we're seeing above is now reduced to a
factor-of-one increase.  The problem is that if you use ESP then your
UDP and RTP headers are now encrypted within the ESP, thereby
destroying your chance for any kind of header compression.

@_date: 2002-01-29 10:40:53
@_author: Derek Atkins 
@_subject: [linux-elitists] Re: Looking back ten years: Another Cypherpunksfailure (fwd) 
Actually, this was chosen only to protect signalling, not the
actual VoIP data.  If you read the spec carefully you will notice
that the RTP stream is NOT using IPsec for data protection.

@_date: 2002-07-23 09:56:01
@_author: Derek Atkins 
@_subject: building a true RNG (was: Quantum Computing ...) 
I can give you a number of examples:  MD5, SHA-1, ....
More mixing is never bad in an RNG..  See RFC1750.
I think they probably meant cryptographic strength, but I
don't know what was going through their minds.  What
do people mean by "authentification"?  That's not even
a real world but I see it all the time.  To me, I think
people just don't know the right term to use so they
just put down something that sounds right to them, regardless
of its correctness.

@_date: 2002-06-24 10:34:52
@_author: Derek Atkins 
@_subject: Ross's TCPA paper 
I, for one, can vouch for the fact that TCPA could absolutely
be applied to a DRM application.  In a previous life I actually
designed a DRM system (the company has since gone under).  In
our research and development in '96-98, we decided that you need
at least some trusted hardware at the client to perform any DRM,
but if you _did_ have some _minimal_ trusted hardware, that would
provide a large hook to a fairly secure DRM system.
Check the archives of, IIRC, coderpunks... I started a thread entitled
The Black Box Problem.  The issue is that in a DRM system you (the
content provider) wants to verify the operation of the client, even
though the client is not under your control.  We developed an online
interactive protocol with a sandbox environment to protect content,
but it would certainly be possible for someone to crack it.  Our
threat model was that we didn't want people to be able to use a hacked
client against our distributation system.
We discovered that if we had some trusted hardware that had a few key
functions (I don't recall the few key functions offhand, but it was
more than just encrypt and decrypt) we could increase the
effectiveness of the DRM system astoundingly.  We thought about using
cryptodongles, but the Black Box problem still applies.  The trusted
hardware must be a core piece of the client machine for this to work.
Like everything else in the technical world, TPCA is a tool..  It is
neither good nor bad; that distinction comes in how us humans apply
the technology.

@_date: 2002-09-21 09:24:49
@_author: Derek Atkins 
@_subject: unforgeable optical tokens? 
This isn't security -- this is a small-form-factor physical ROM.  This
"read-only data crystal".  The fact that they cannot be duplicated
easily just means that you cannot use these tokens for real data
storage.  Imagine if they _were_ replicable..  Imagine keeping a
terabyte of backup data on one of these tokens!
PS: My Master's degree is from the Media Lab, so I can vouch for the
fact that reasonable work is done there ... ;)

@_date: 2003-04-01 16:47:27
@_author: Derek Atkins 
@_subject: Run a remailer, go to jail? 
I'll see if I can get there.  I'm not sure I can.  But I know a
number of other MIT-types who are considering going.  If I can
go I'll try to keep notes.  If I can't go, then hopefully someone
else can take some notes.

@_date: 2003-04-16 13:36:11
@_author: Derek Atkins 
@_subject: DMCA Crypto Software 
Gee, this looks a lot like the work I did at Arepa, er, Into Networks
back on '98-99.  Indeed, I've already got a patent on a similar
technology (although I have no clue who owns the patent nowadays).  We
were using the technology to protect software and stream it to users
machines off the net.  Unfortunately the company closed down last

@_date: 2003-04-21 17:07:16
@_author: Derek Atkins 
@_subject: DRM technology and policy 
I'm not sure which comments you are referring..  My statement
was that you cannot perform DRM in a purely software solution;
you need some level of hardware assistance to get any level
of assurance as a content provider.  The only proof that I
maintained was that you couldn't create a perfect DRM solution
using only software (which was our constraint at the time).
I don't see any illogic in that (except perhaps by some
readers who wanted to read more into it).
I agree that DRM is a good thing -- I'd love to use a DRM
system to protect my medical and financial information.
So, where do we go from here?  You suggest....
Ok, let's start from the beginning.  Let's be engineer here.
What are the requirements of such a system.  Let's get DEEP
into details.  What are the constraints?  What is the threat model?
I don't think we've seen a good requirements document (from
either side) that details the issues, concerns, and wants
from a DRM system.  They all start with the a priori solution
("DRM Good" or "DRM Bad") and work backwards.  Let's work forwards
and see where it takes us, and let's leave the fear behind.
Fear is a powerful thing.  The Big Guys are afraid of losing their
money/power; the little guys are afraid of losing their freedoms
(freedom to steal/copy?  I'm not so sure).  So, where is the
balance of protecting the rights of the content producers and
protecting the fair-use by the consumers?
Is this necessarily a problem that _can_ be solved with technology?
And if it can, is it necessarily one that should?
PS: Ok, who wants to pay me to think about this??  Or do you
feel entitled to get my ramblings for free?  ;-)

@_date: 2003-04-22 16:22:51
@_author: Derek Atkins 
@_subject: DRM technology and policy 
The problem is that the current business models recoup this
cost by requiring payment on the assumption of a scarce resource.
You are correct that Copyright has nothing to do with it; it's
the current (flawed?) business models.  However, I don't think
the MPAA or RIAA are willing to change their business models
anytime soon.
So I'll re-ask my question, John..  What do you see as the
requirements of a DRM system?  Clearly allowing a content creator to
get paid for their work is part of the picture (but it is not the
whole picture)..

@_date: 2003-04-24 10:32:29
@_author: Derek Atkins 
@_subject: DRM technology and policy 
You may agree with him, but you've missed his point.
There *IS* still a moral obligation to pay the "artist" (creator of a
work).  Carsten's point was that the artist was only obtaining a small
percentage of the amount normally charged, and it was the distributor
making most of the money.
This about it this way: if never got paid for their work, what incentive would they have to
continue making music?  While musicians (and I know a few personally,
including grammy-award winning artists) do usually feel the need to
create music (sort of how programmers feel the need to write
programs), if they cannot make a living, feed themselves and their
family, then most likely they will find another avenue.
I agree completely that the proposed DRM systems exist solely to
continue the existing (IMHO broken) business model of the Big
Distributor.  The Internet gives us the opportunity to shift the power
from the distributor back to the artist.  But that does not relinquish
us from the moral obligation to pay the artist.
Adam, I don't know exactly what you do for a living, but would you
continue to do it if people morally felt that they should not pay you
for doing it?
Sure, the LICENSES are unlimited, but the LICENSES here are what map
directly to the digital world!  The thing that you are ignoring is
marginal cost.
The marginal cost of copying a book is significant.  Paper _IS_ a
limited resource.  There are a finite number of trees that can be
harvested and turned into paper.  There is a finite, non-zero cost per
sheet of paper (approx $0.01 retail per 8.5x11 inch 20# sheet, but
certainly less than that in bulk).  Ink, as well, has a cost
associated with it (and again, I believe it IS a finite resource -- it
takes time and effort to create the ink from its natural (or
unnatural) substances.
Similarly, the fixed-costs of the book-duplicating machine is
extremely signifant.  I don't know many people who have a printing
press in their basement (let alone access to one elsewhere).  Both the
availability of the technology as well as the marginal cost make it
extremely uneconomical to copy a book.  Why would someone go pay
$100,000 for a machine to duplicate a book they can buy for only $10.
Also the space constraints are high.  Storage of the duplicating
machine, paper supplies, and ink for duplicating a bunch of books is
rather large.  Also, the quality of a copy is usually diminished,
unless you take the time to reverse engineeer back to the source.  A
xerox is "worse" than an original master copy, and after N generations
the copies become effectively worthless.
None of this is true for digital media.
What's changed is that the marginal cost of duplication of a digital
work is SIGNIFICANTLY lower (near zero!).  The cost of duplicating a
CD is about $500 fixed cost plus about $0.30/copy.  And that assumes
you're duplicating onto CD and not using the network.  The space
requirements of a comuter and a bunch of CD or DVD media is tiny.  And
the quality of a copy is exactly the same as the quality of the
original, so an N-th generation copy is indistinguishible from a
1st-gen copy.
So the economics (and aesthetics) of making copies of digital media is
significantly changed from older, analog media.  Which returns us to
my thesis that the current business models don't work.
Something has to give.

@_date: 2003-04-24 14:49:26
@_author: Derek Atkins 
@_subject: DRM technology and policy 
No, but when I know I'm better than those amateurs...  "you get
what you pay for".  There is no way I could perform as well as
some bands that I like.  Similarly, there is no way they could
program as well as I could.
So, when I'm doing work *I* get to choose whether I'm working for
free or working for hire.  It's _my_ choice.  And if I choose
to ask for payment for my work, you can choose to go elsewhere,
or you can choose to pay me.  However, just because you pay me
does not necessarily give you the right to redistribute my work
for free behind my back.
I'm not just talking about software.  Indeed, I'm _not_ talking about
software.  I'm talking about art, music, literature...
Note that I'm not talking about the industry.  I'm not talking about
MPAA or RIAA.  I'm talking about the individual artists; I'm talking
about Pink Floyds, Jewels, Neil Youngs, Mozarts, and Nickel Creeks of
the world.

@_date: 2003-04-27 11:03:43
@_author: Derek Atkins 
@_subject: DRM technology and policy 
This is indeed the end goal for which I'm driving.
Agreed.  Barrier of entry should remain zero (or as close to zero as

@_date: 2003-01-24 15:17:22
@_author: Derek Atkins 
@_subject: [IP] Master Key Copying Revealed (Matt Blaze of ATT Labs) 
Having taken apart Medeco's before, I have to agree with Matt that
this attack would work fine on old-style medecos with a groove for the
the turn-bar.  This means the twist is the same at all pin heights for
any particular pin.
There is, however, a newer medeco design that uses a drill-hole
instead of a groove.  With that design you can have the pin twist be
different at different pin-heights (by putting the drill-hole at a
different twist-angle).  I don't think this attack would work quite
as easily on this design.

@_date: 2003-01-24 15:47:28
@_author: Derek Atkins 
@_subject: [IP] Master Key Copying Revealed (Matt Blaze of ATT Labs) 
The fact that the hole is on the bottom pin is not important.  What is
important is that the hole at the change-key height does not need to
be at the same angular position as the hole at the master-key height.
It's hard to draw ascii art to show what I mean, but because the twist
holes are at a particular height when the key is inserted, you can
certainly see how at different heights the holes can be in different

@_date: 2003-01-28 09:27:35
@_author: Derek Atkins 
@_subject: EU Privacy Authorities Seek Changes in Microsoft 'Passport' 
Single Signon by ITSELF is not a bad technology.  But it very much
depends on the architecture and implementation.  A Globally
Centralized SSO system like Passport certainly has problems as you
suggest.  A locally centralized SSO system like Kerberos is less
of an issue.  A Federated SSO system like Shibboleth is much better.
It all depends on your threat model.  Don't destroy SSO just because
some company decided to "do it wrong".

@_date: 2003-06-05 20:30:54
@_author: Derek Atkins 
@_subject: Maybe It's Snake Oil All the Way Down 
Actually, the ASN.1 part is a major factor in the X.509
interoperability problems.  Different cert vendors include different
extensions, or different encodings.  They put different information
into different parts of the certificate (or indeed the same
information into different parts).  Does the FQDN for a server cert
belong in the DN or some extension?  What about the email address for
a user cert?
That's a different problem (namely that the "big guys" like RSA
Security, Microsoft, and Verisign don't sell PGP-enabled software or
PGP certificates).  PGP's problem is an integration problem, making
it easy to use for non-techies.  That has been the barrier to entry
for PGP.
This is only part of the problem... It is not all of it.  Indeed the
cost (both in money, time, and headache) has always been a barrier to
entry.  I don't believe that market or political forces are the largest
problem with X.509....  I will certainly agree that the cost is a
major impediment.
The question is:  how do we convince M$ and Netscape to include something
else in their software?  If it's not supported in IE, then it wont be
available to the vast majority of users out there.

@_date: 2003-06-05 20:54:21
@_author: Derek Atkins 
@_subject: Maybe It's Snake Oil All the Way Down 
Except some CAs make certs that can only work as an SSL server and not
an SSL client, or don't work with certain verifiers, or can't be
parsed right, or have the "commit-bit" set on some extensions.  It's
been a major pain in a problem that I'm working on -- not all vendor's
certs work properly.

@_date: 2003-06-16 21:50:38
@_author: Derek Atkins 
@_subject: Sessions 
This is what a backend database is for. ;)
-derek, who just implemented something like this for one of his clients

@_date: 2003-06-22 13:33:00
@_author: Derek Atkins 
@_subject: authentication and ESP 
you really don't want to open this can of worms....  I suggest you
go read the archives of the IPsec mailing list over the last 9
years.  That should give you some clue into the depth of the
can you plan to open...

@_date: 2003-03-07 13:42:46
@_author: Derek Atkins 
@_subject: Delta CAPPS-2 watch: decrypt boarding passes! 
I've not seen ANY airport that didn't have this initial check,
although generally it is "boarding pass, printed ticket, or printed
itinerary".  This is actually one of the "written rules" (as opposed
to some of those lovely unwritten rules that TSA seems to like

@_date: 2003-03-14 13:53:15
@_author: Derek Atkins 
@_subject: Diffie-Hellman 128 bit 
I'm sorry to inform you, but a brute-force attack on a 128-bit prime
is simple to mount.  I don't think I can estimate the length of time
to attack a prime of this length, but it wouldn't be very long.
Consider that 425 bits is only about 4KMY (Kilo-MIP-Years) -- with
todays 2KM+ processors you're probably talking about a week or less to
crack it.  Also, there aren't THAT many "strong" 128-bit primes.
If you're using these numbers for real data (even if ephemeral), I
would suggest using at least 512-bit ephemeral DH Primes..  But then
you need some way to securely AGREE upon the ephemeral prime.
How do you intend to prevent an attacker from forcing you to agree to
a prime that it's already solved?

@_date: 2003-03-15 09:01:36
@_author: Derek Atkins 
@_subject: Face-Recognition Technology Improves 
Were there really 750 Million Passengers flying through ATL???  That
number seems a bit high...
Also, I'm not convinced that multiple trials for a single individual
are independent.  Indeed, one could easily assume that multiple trials
for a single individual are highly correlated -- if the machine isn't
going to recognize the person on the first try it's highly unliklely
it will recognize the person on subsequent tries.  It's not like there
is a positive feedback mechanism.
Therefore, a better question would be how many UNIQUE passengers flew
threw ATL, and then take 1% of that for the number of false positives.
I think it's safe to assume that the 99% accuracy for false-positives
is over the population, not over the number of trials.

@_date: 2003-03-15 18:55:00
@_author: Derek Atkins 
@_subject: Face-Recognition Technology Improves 
Ok Ok ok.  I'm sorry for trying to do math on only 6 hours sleep
before a flight.  I mis-counted 0's.  I'm sorry.

@_date: 2003-03-26 17:50:47
@_author: Derek Atkins 
@_subject: meet in the middle attacks 
Note that SSH is vulnerable to a Man in the Middle attack (not meet in
the middle -- that is an attack on 2DES where you attack from the
input and output and then "meet in the middle").  In particular SSH is
vulnerable if you do NOT have the long-term server key cached on the
That notwithstanding, I think that Ian is just upset about
paying for an SSL Cert and wants a way to setup an SSL/TLS server
without paying homage to one of the Big Three (or is it down
to Big One at this point?).  Ignore the fact that he could
use self-signed certs and be as secure as SSH.

@_date: 2003-05-02 11:24:18
@_author: Derek Atkins 
@_subject: eWeek: Cryptography Guru Paul Kocher Speaks Out 
But wait.  Based on your assumption, each user's data will differ from
an unmarked version by 1 bit and that one bit is different for each
person.  Sure, you can't have partial bits, but you CAN have bit
probabilities!  So you find that all but those four marked bits match
with probability 1, but each of these four marked bits matches a
distribution of .25/.75.  That means you now know with certainty 75%
what the proper bit setting is to make it an unmarked copy.
Let's look at bit0 (which is the ID bit for user 0).  Let's assume the
bit is 0 for all users but user 1.  Even if you use pure averaging
across 4 users, you'll have three users with a 0 and one user with a
1, so on average the bit is .25 which rounds to 0.
So, I think you can do much better than "flip a coin" -- and the more
users you can get to collude, the better you can do in finding those
bits and removing them.
Yes, if you add more bits per person, then you have a higher chance of
two colluders sharing a bit.  Let's assume you still have 4 colluders,
and 2 of them share a particular bit.  That means you have a 50/50
probability on that bit, so you don't have a good distribution.
However, the more colluders you add, the more likely you are to get a
good distrbution that tends towards the unmodified data.

@_date: 2003-05-13 09:06:18
@_author: Derek Atkins 
@_subject: A Trial Balloon to Ban Email? 
The same way you know you have the right answer with certain other
hard problems -- you choose a problem that's one-way hard.  For
example: factoring.  Factoring a large number is hard.  Verifying you
have the right answer is easy (you just multiply the factors and see
if you've got the right answer).  So, just choose from the class of
self-verifying problems.
OTOH, I still think a micro-payment postage system is a better idea.
The sender puts a micro-payment into the mail header to pay the
recipient to accept/read the message.  For non-spam, the receipient
doesn't need to cash the payment (or can just return it to the
sander).  For spam, the receipient collects the money (thereby costing
the spammer real $$$ to send spam, if most receipients actually
collect).  The only remaining architectural problem is how to handle
mailing lits.

@_date: 2003-05-17 13:26:45
@_author: Derek Atkins 
@_subject: Payments as an answer to spam 
That's not sufficient.  Spammers regularly forge email addresses.
I've received spam apparently from people I know, but it's clearly not
from them.  So, just using white lists on the "From: " address is not
sufficient.  You still need some content filtering (either via a coin,
a signature, or something easily-verified).

@_date: 2003-10-01 13:10:04
@_author: Derek Atkins 
@_subject: New authentication protocol, was Re: Tinc's response to "Linux's answer to MS-PPTP" 
You can't get rid of the distinction.  You will always have a "client"
and a "server" -- however you may just rename it "Initiator" and
"Responder" to make it sound more peer-like, but it's just the same
emperor in different clothes.  The only real distinction between a
_pure_ client-server protocol and a peer-to-peer protocol is that the
latter is generally reversible where the former is not.  By
"reversible" I mean that either party could be the initiator and
either could be the responder.
HOWEVER, during the run of a protocol it behooves you to label the
parties, and "client/server" is just as valid a naming as
"initiator/responder".  IPsec (IKE) is clearly peer/peer.  Even with
TLS the protocol is reversible if you perform the name mappings and
assume both ends have certificates.
So, I urge you to be careful with trying to get rid of a distinction
that really has little meaning in most protocols.

@_date: 2014-02-28 14:12:19
@_author: Derek Atkins 
@_subject: [Cryptography] GOTO Considered Harmful 
Sorry, Patrick, but your code doesn't work, either.  Indeed, your code can
be made to return success by having 'failed' turned on at the beginning. Then you'll hit the line:
    failed ||= ((err = SSLHashSHA1.final(&hashCtx, &hashOut)) != 0);
Which will most likely set err to OK (because, honestly, SHA1 final never
fails.  Then it will fall though to:
    return err;
Eh viola, no error code returned.
A better approach would be a set of:
do {
  ...
} while (0);
sections.  E.g.
  do {
     if ((err = ReadyHash(&SSLHashMD5, &hashCtx)) != 0) break;
     ...
  while (0);
  if (!err) err = ReadyHash(&SSLHashSHA1, &hashCtx);
  if (!err) ....
This way you will always make sure you return an error, and you are
guaranteed to return the first error you hit.
Or drop the code and use C++ exceptions ;)

@_date: 2014-01-21 13:48:21
@_author: Derek Atkins 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
The RFC does not specify, because protocol-wise both are valid.  You could
do either sign-then-encrypt or encrypt-then-sign, and PGP validators
should handle either order of packet nesting.  The more appropriate
question would be: what do the various OpenPGP implementations do by
default, and that I cannot answer for you
-derek, former OpenPGP-WG Chair

@_date: 2014-09-03 13:47:16
@_author: Derek Atkins 
@_subject: [Cryptography] Are there Key Server for non-PGP systems? 
You're mixing things incorrectly.  Ed25519 is a specific ECC curve, but
you could use that curve in PGP, X.509, SSH, or plenty of other protocols.
 Ed25519 is completely orthogonal to PGP Keyservers.
So what exactly are you asking?  Are you asking if there are Ed25519 PGP
Keys that could be available via HKP?  Or are you asking if there are
X.509 (non-PGP) Key Servers?  Or are you asking how you could use Ed25519?

@_date: 2014-09-18 08:44:16
@_author: Derek Atkins 
@_subject: [Cryptography] [cryptography] Email encryption for the wider 
(Henry Augustus Chamberlain's message of "Wed, 17 Sep 2014 21:48:58
 +0200")
You are correct in your observation, however I would argue your
conclusion is still wrong. After having worked on secure email for many
of the past 22 years personally, I can assure you that the issue is
absolutely usability.  However the issue is a combination of key
management and integration, and not with "naming".
There is absolutely no way my mom could send me an email to
  It's just not going to happen.  There's no way she
could type it in.  There's no way she could remember it.  Sure, once it
gets into her address book she doesn't need to remember it again,
however how does it *get* into her address book?
I'll also note that this is the idea behind HIP, and was also the basis
behind (IIRC) SPKI.  "The Key is the ID".  It works great for machines.
It doesn't work well for people.
Quick, without looking it up anywhere, what's your PGP Key ID?
Now, without looking it up, what's your email address?
I don't know about you but I can rattle off my email address over the
phone very quickly.  No way could I rattle off a keyID and make sure the
other person has it and, more importantly, can type it correctly.
That's not the problem.  The problem is that most users out there are
using gmail, or aol, or yahoo, or... *gasp*  Outlook!  Enigmail doesn't
help any of those users.
Here's the issue:  The main email software vendors integrated S/MIME
into their applications.  It already exists in Outlook, Mail.App, and
probably most every major email system.  However S/MIME sucks from a key
management perspective exactly because "getting certificates is hard."
PGP is nice in that anyone can effectively click a button and viola,
they have a certificate.  However none of the mail systems support PGP
*THAT* is the problem that needs to be solved.  You need to convince
every MUA out there to make generating keys (and/or a certificate) as
easy as PGP, and also make encryption the default.  Indeed, you need to
get to a point where the MUA would pop up a dialog saying "You are about
to send email unencrypted.  Anyone (like the NSA) could read this.  Are
you sure?  y/N"
I recommend you go get Microsoft and Apple on board first.
Good Luck,

@_date: 2015-08-26 20:36:31
@_author: Derek Atkins 
@_subject: [Cryptography] 3DES security? 
2-key or 3-key 3DES?  Generally 3DES implies 2-key EDE, which equates to
112-bit security.  3-Key 3DES uses more key bits, but my recollection is
that it doesn't significantly increase the security..  So I would treat
3DES as 112-bit security.  To date, the best known attack against DES is
brute force.
The REAL issue with 3DES is that it's still only a 64-bit block size so
you have a 1 in 2^64 chance of randomly guessing the mapping from a
plaintext block to a cipher block, regardless of the keys.  Of course you
need to repeat this mapping on every block, so it doesn't necessarily buy
you anything.

@_date: 2015-08-27 10:05:30
@_author: Derek Atkins 
@_subject: [Cryptography] 3DES security? 
The MITM attacks are why 3-key DES isn't much better than 2-key DES, and
also why EDE is preferred over EEE.  The reduction from 112 to 108 is
something I didn't know about, so thank you for that reference.

@_date: 2017-02-23 10:55:05
@_author: Derek Atkins 
@_subject: [Cryptography] Google announces concrete SHA-1 collision 
Just just came to my attention!  I think this is (hopefully) the final
nail in the SHA-1 coffin?

@_date: 2018-08-09 12:57:59
@_author: Derek Atkins 
@_subject: [Cryptography] PGP -- Can someone help me understand something? 
Hi Matt,
Well, the no should have been added with a postscript saying that it COULD
if you had enough computation to perform the required operations to break
the cryptosystem.
Thinking about cryptography in terms of basic algebra doesn't work,
because the system isn't linear.  You cannot model a system like AES using
only a single variable.  Well, okay, you can say AES(Key, PlainText) =
Ciphertext and then ASSUME that this is the same as solving 10 + x = 50. But it's not.
Specifically, a system like AES is designed such that knowing the
plaintext and ciphertext does NOT provide a way to find the key.  It does
provide you a way to VERIFY that you've found the right key, but it
doesn't help you having to search through all 2^128 (or 2^256) possible
AES keys to find the one that matches.
If you had a cryptosystem that could be broken by a single
plaintext/ciphertext pair it would not be considered very strong.
Hope this helps.

@_date: 2018-10-31 16:49:41
@_author: Derek Atkins 
@_subject: [Cryptography] hash size 
Hi James,
You are correct, an N-bit hash provides N-bit security against preimage
and second-preimage attacks.   It only provides N/2-bit security against
collisions.  It's safe to use a 128-bit hash if you are ABSOLUTELY SURE
that you will NEVER have a use case where you could have a collision-based
attack.  But finding those rare use-cases are rare.  Worse, you'll have to
explain to everyone, over-and-over, why you're not succeptible to
collision attacks.  And then after you're done explaining, the next person
will come up and ask again.
Worse, a 256-bit hash is pretty fast, so it's unclear what you're actually
buying yourself with a 128-bit hash.

@_date: 2020-11-15 21:36:40
@_author: Derek Atkins 
@_subject: [Cryptography] Satoshi Nakamoto Email Timestamps Disambiguation 
If you send me the specific date and message ids I can look in my personal archive and give you email header data tomorrow. Of course that won't give you actual sender timezone, just apparent times.
Sent using my mobile device. Please excuse any typos.

@_date: 2020-11-16 10:40:00
@_author: Derek Atkins 
@_subject: [Cryptography] Satoshi Nakamoto Email Timestamps Disambiguation 
The original Satoshi email has a "Date" header of Sat, 01 Nov 2008
02:10:00 +0800.  It was received by metzdowd.com at Fri, 31 Oct 2008
14:20:34 -0400 (EDT), then forwarded witihin metzdowd at Sat,  1 Nov 2008
19:15:33 -0400 (EDT).  This leaves a 10-minute "window" from the "Date" to
the first "Received", which lends credence to that timestamp.  The delay
from Oct 31 14:20 to Nov 1 19:15 is, most likely, a moderation delay.
Here is a snippet of the full email header (I left out the deliveries to
me, but the next header is the delivery from metzdowd to me at 19:15 EDT):
Received: by green.metzdowd.com (Postfix, from userid 1101)
Delivered-To: cryptography at metzdowd.com
Received: from hacklheber.piermont.com (hacklheber.piermont.com
Received: from snark.piermont.com (localhost [127.0.0.1])
Received: by snark.piermont.com (Postfix, from userid 1000)
Received: from mail.anonymousspeech.com (anonymousspeech.com
Received: from server123 ([124.217.253.42]) by anonymousspeech.com with
MailEnable ESMTP; Sat, 01 Nov 2008 02:20:18 +0800
X-Mailer: Chilkat Software Inc (
X-Priority: 3 (Normal)
