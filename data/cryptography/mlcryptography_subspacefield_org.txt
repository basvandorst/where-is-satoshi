
@_date: 2007-04-17 00:34:26
@_author: Travis H. 
@_subject: crypto component services - is there a market? 
So back when I was reading about secure logging I thought it'd be
a fun service to offer, but it doesn't seem like a "product" that
the average business would be interested in; it seems more like
something that would be a component of a larger system, or used by
other systems.
Same with digital timestamping.
Does anyone think there is a market for these "point solutions"?

@_date: 2007-04-25 15:32:43
@_author: Travis H. 
@_subject: open source disk crypto update 
Forgive me as this isn't as technical as the usual posts, but I
find it interesting nonetheless.
OpenBSD has, for some time, supported encrypted swap.
Just recently I discovered Debian default installs now support
encrypted root (/boot still needs to be decrypted).
Presumably we are moving back the end of the attack surface; with
encrypted root, one must attack /boot or the BIOS.  What is the limit?
I think a simple evolution would be to make /boot and/or /root on
removable media (e.g. CD-ROM or USB drive) so that one could take it
with you.  Of course if someone reflashes your BIOS you are still
hosed, but it appears that there's no way to completely eliminate
that kind of threat without taking the whole system with you.

@_date: 2007-04-25 21:15:33
@_author: Travis H. 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
Haven't read this yet, but will... and may have comments.
Without reading it, I do have some comments.
At least one authentication protocol failed because it was possible
to strip off a signature then re-use an encrypted blob (e.g. with
one's own signature on it).  So they are malleable.
In _many_ poorly-designed systems it becomes possible to use a system
as a signature oracle to sign arbitrary things.  Smartcards with a
hostile PC are just one of these cases.
One must be very careful what a signature is supposed to attest.
Also there's a semantic issue; am I attesting to the plaintext,
or the ciphertext?  It's possible the difference could be important.
Do we sign letters, or sign envelopes?  If I sign an envelope
containing a letter, I deprive you of much of the evidentiary
value that a signed letter would carry; you cannot easily prove
to someone what I signed without revealing your decryption key(s).
With encrypt-then-authenticate, one can check authentication, and
if it fails, avoid decryption - while in theory this could avoid
DoS, in practice the authentication is more costly than decryption.
In my reading on information-theoretic security, I found that if one
does encryption around the authentication, then one can prevent the
opponent from learning anything about the message.  Specifically, if
Enc(x) is a one-time-pad, then one can use very efficient and
ostensibly unsecure hash functions such as a selection from the
universal hash family ax + b (mod n) for one's integrity and
authentication, and (for certain restrictions on a, b, and n, and
under the assumption of secrecy of a and b) one can have
_information-theoretic security for authentication and integrity_.
That is, no matter how many messages sent, no matter how many CPU
cycles the opponent has available, the opponent can learn nothing new.
I've been discussing and developing a prototype system that aims to
provide information-theoretic security (and at worst, conventional
computational security) for low-bandwidth purposes (i.e. email or IM),
and I will post details here when I have them in a relatively stable
form, for those who are interested.

@_date: 2007-04-25 22:58:01
@_author: Travis H. 
@_subject: More info in my AES128-CBC question 
Not true.  Since we are comparing confounders to IVs, let's make identical
assumptions; that the value is somehow agreed upon in advance.
Then, one need not send it; the receiver can compute C_(i-1) = E_k(confounder)
without actually having it sent to him, and from there
continue decryption with P_i = C_(i-1) xor D_k(C_i) and so on.
I don't fully understand what it means to have IVs chained across
contiguous (?) messages, as in CBC mode each ciphertext block forms
the "IV" of the block after it, effectively; basically an IV is just
C_0 for some stream.

@_date: 2007-04-25 23:20:17
@_author: Travis H. 
@_subject: Why CBC?  What is wrong with n-bit CFB? 
I've always wondered this about the lesser-used modes.  What's special
about CBC?
With CFB in particular, I think 8-bit CFB is stupid (one full block
encryption per byte processed - rather computationally expensive), but
n-bit CFB seems just as useful as CBC, if not more so.  Specifically,
I can start sendings bits of C_(i-1) = IV xor P_(i-1) as soon as I
feel like it, even before all of P_(i-1) is in, and it uses the same
number or less crypts than CBC.  Futhermore, it can be used to encrypt
"in place" like CBC but without any special "ciphertext stealing" or
other processing.  Of course I assume that integrity is handled by a
completely seperate mechanism that includes redundancy; anything less
is snake oil.
For that matter, error extension doesn't seem to be an issue to me in
most cases.  Error handling should be done via a seperate layer that
adds redundancy to the ciphertext prior to transmission (and can do
error correction, not just detection).  If any error is so bad that it
defeats this layer, I want to know about it (and will find out via yet
another layer, an integrity/authenticity layer); it could also be a
malicious attack, and unless there is bad sunspot or EMP activity the
seperation of duties allows me to distinguish between the two.  The
exception I can see is if retransmission or delay is unacceptable and
it is better to get a garbled message than none at all.  This may be
the case with human spies in occupied territory, or perhaps for
emergency messages to a deep space probe, or such.  Still, this is the
Internet age and transmission errors are increasingly handled by the
lower layers.  Is anyone actually doing crypto with plaintext that is
interpreted by humans (so they can detect and deal with garbles) over
radio any more?  Not many among us here I suspect.
That having been said, I can't see much in favor of OFB over CTR mode.

@_date: 2007-04-25 23:23:03
@_author: Travis H. 
@_subject: truncating MACs for confidentiality, was Re: Public key encrypt-then-sign or sign-then-encrypt? 
One more thing to consider; if you pick a reasonable MAC with twice
the security factor you need, then truncate the output to half the
size, I believe you get both confidentiality and
integrity/authentication guarantees of the desired strength.

@_date: 2007-08-07 07:58:39
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: magnifying unpredictability and common subexpressions 
So I'm looking for a minimum cost transformation with _only_ the
following characteristic:
Given a set of m input bits X, produce a set of n output bits Y such
that knowledge of some subset of X and Y gives a minimum knowledge of
the remainder (of Y if that makes it simple, but of X would be nice).
This is not unlike the "all-or-nothing" package transform proposed
by Rivest; the basic idea is that you have to know all of X in order
to know anything about Y - sort of.
My first iteration is as follows:
Let ^ represent xor.
Let p be the exclusive or of all bits of x (i.e. the parity).
Let Y = f(X), where f(x) = p ^ x
Basically, each bit of Y is the xor of every _other_ bit of x
(x was actually xored into p, so by xoring again, it cancels out)
However, my problem is that no matter how few bits of X you know, you
only have to guess one bit, p, in order to know the bits of Y that
correspond to the bits you know of X.
Let me be concrete; suppose that I know only bits 0 of X and bit
0 of Y.  I can then compute p, and from that I can use any further
knowledge of bits of X to compute corresponding bits of Y.
Note that p = x[0] ^ y[0].
Then if I know x[1], I can reveal y[1] = p ^ x[1].
And so forth.
Obviously I need something more complex.  The problem seems to be that
the equations for every bit y depend only on x and p; that is, if we
know x, we only have to guess p once for the whole array.
In a way, this reminds me of an idea I had earlier, whereby this
variable p is what I call a common subexpression, a key which unlocks
the equation, a sort of trapdoor.
Suppose I had written Y = f(X) as follows:
y[0] = x[1] ^ x[2] ^ x[3] ^ x[4]
y[1] = x[0] ^ x[2] ^ x[3] ^ x[4]
y[2] = x[0] ^ x[1] ^ x[3] ^ x[4]
A novice may have not have realized that each bit of y depends _only_
on x ^ p, and that knowing or guessing p would reveal every bit of Y
for each known bit of X, without having to know any other bit of X.
Now, what I sometimes wonder is whether the equations and tables in
things like DES or SHA-1 are not similar... a table allows for several
boolean logic representations, and depending on which you pick for
each output bit, it may be possible that a common subexpression like p
falls out of the equations, minimizing the amount of unknowns, or
the amount of compute power necessary to brute-force it.
For a Feistel cipher like DES, one might pick different boolean logic
representations in different rounds, to minimize the complexity of
the equations you get at the end.
This is why I don't try to design ciphers.  I could possibly come up
with some complicated-looking tables and equations, but I'd have no
assurance that a simple common subexpression did not exist.
Do I need to resort to a conventional hash like SHA-1?  I am not
convinced that it is necessary, or that I'd have any more assurance
from SHA-1 than I'd have with a randomly-generated set of equations.
Does it have to be random?  Isn't there a regular structure I could
exploit here?  It seems like there should be!
Randomly-generated equations remind me a bit of the following AI Koan:
In the days when Sussman was a novice, Minsky once came to him as he
sat hacking at the PDP-6.
"What are you doing?", asked Minsky.
"I am training a randomly wired neural net to play Tic-Tac-Toe",
Sussman replied.
"Why is the net wired randomly?", asked Minsky.
"I do not want it to have any preconceptions of how to play", Sussman
Minsky then shut his eyes.
"Why do you close your eyes?", Sussman asked his teacher.
"So that the room will be empty."
At that moment, Sussman was enlightened.

@_date: 2007-08-30 20:43:59
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: debunking snake oil 
I think it might be fun to start up a collection of snake oil
cryptographic methods and cryptanalytic attacks against them.  It
would be more fun for me than crossword puzzles, and educational for
all the would-be cryptographers.
I'd like to start with the really simple stuff; classical
cryptography, systems with clean and obvious "breaks".  Although I
find the magazine entertaining to read, I'm finding that 2600 Magazine
is a particularly good source of this brand of snake oil.
So, when you find a particularly obnoxious dilettante going on about
his bone-headed unbreakable scheme, please forward it to me and I'll
see about breaking it, and then publish the schemes and the results on
a web site for publicly "educating" them.  Honestly, there's probably
no better way to educate people than to see schemes submitted and
broken, and I'm not sure there's a good site for it, although there
are plenty of books.  Unfortunately, these types won't be bothered to
buy books since they already know everything.
If you have a break of some scheme you wish to contribute, please
do forward me a URL and I'll link to it.
Perhaps this should be a wiki?
I'm revamping my web site, so the crypto wiki has been down
temporarily but will be back up.

@_date: 2007-12-17 10:38:59
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: crypto class design 
So... supposing I was going to design a crypto library for use within
a financial organization, which mostly deals with credit card numbers
and bank accounts, and wanted to create an API for use by developers,
does anyone have any advice on it?
It doesn't have to be terribly complete, but it does have to be
relatively easy to use correctly (i.e. securely).
I was thinking of something like this:
class crypto_api
    ...
    // developers call these based on what they're trying to do
    // these routines simply call crypto_logic layer
    Buffer encrypt_credit_card(Buffer credit_card_number, key_t key);
    Buffer encrypt_bank_account(Buffer bank_account, key_t key);
    Buffer encrypt_other(Buffer buffer, key_t key);
    ...
class crypto_logic
    ...
    algo_default = ALGO_AES256CBC;
    // encrypt with a given algorithm
    Buffer encrypt(Buffer buffer, key_t key, algo_t aid = algo_default);
    // calls different routines in crypto_implementation layer depending on algorithm used
    Buffer decrypt(Buffer buffer, key_t key);
    ...
class crypto_glue
    ...
    // calls routines in libraries such as OpenSSL
    // mostly wrappers that translate between our data types and theirs
    Buffer aes256cbc-encrypt(...);
    Buffer aes256cbc-decrypt(...);
    ...
The general idea is that crypto_api provides domain-specific APIs that
are easy for anyone to understand, that the logic layer allows for the
selection of different algorithms, and the glue layer is basically a
translation layer to underlying libraries.
It is very important that the API remain stable, because the code
base is large and owned by various groups.
One thing that I'm wondering is how to indicate (e.g.) the overhead in
terms of padding, or whatever, for various algorithms... or if it
matters.  The old code had some really disturbing practices like
assuming that the output buffer was 16 octets bigger, and stuff like
that... scary.
Intend to skim the OpenSSL design and Gutmann's "Design of a
Cryptographic Security Architecture" for ideas.

@_date: 2007-12-20 11:04:00
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: crypto class design 
The problem is that client code assumes that there is a fixed (constant)
relationship between the size of the output and the size of the input,
and does its own memory allocation for the output, and uses pointers.
This makes it difficult to change that relationship safely; I
basically have to track down and change all the calling code, which
may be near-impossible.
I think the right solution in this case is to pass objects and not
pointers, unless performance dictates otherwise.
But, are there similar assumptions implicit in the calling code which
I can avoid through proper design, now?
That having been said, your suggestion for a data type for this
purpose, with semantically-useful subdivisions, is an interesting one;
thank you (and everyone else who gave suggestions!)

@_date: 2007-02-01 15:01:00
@_author: Travis H. 
@_subject: deriving multiple keys from one passphrase 
Hey, quick question.
If one wants to have multiple keys, but for ease-of-use considerations
want to only have the user enter one, is there a preferred way to
derive multiple keys that, while not independent, are "computationally
I was thinking of hashing the passphrase with a unique string for each
one; is this sufficient?  If sufficient, is a cryptographically strong
hash necessary?
I got a clarification about the "use CRCs to process passphrase" idea
someone mentioned.  The salient bit is that he was using several CRCs
(not sure if it's random or carefully chosen), and each one is run on
the passphrase, and the output of all of them concatenated to
initialize a PRNG seed.  The passphrase and seed are both secret, so
according to him there's no need to use a cryptographically strong
hash, and CRCs have a well-understood mathematical basis.
I presume this would be insufficient for deriving independent keys,
but perhaps there is a way to do that with careful selection of the
CRC polys?

@_date: 2007-02-05 06:39:35
@_author: Travis H. 
@_subject: OTP, was Re: data under one key, was Re: analysis and implementation of LRW 
For long-term storage, you are correct, OTP at best gives you secret
splitting.  However, if people can get at your stored data, you have
an insider or poor security (network or OS).  Either way, this is not
necessarily a crypto problem.  The system should use conventional
crypto to deal with the data remanance problem, but others have
alleged this is bad or unnecessary or both; I haven't seen it proven
either way.  In any case, keeping the opponent off your systems is
less of a crypto problem than a simple access control problem.
It was my inference that this data must be transmitted around via some
not-very-secure channels, and so the link could be primed by
exchanging key material via registered mail, courier, or whatever
method they felt comfortable with for communicating paper documents
_now_, or whatever system they would use with key material in any
other proposed system.  The advantage isn't magical so much as
practical; you don't have to transmit the pad material every time you
wish to send a message.  You do have to store it securely (see above).
You should compose it with a conventional system, for the best of both
Of course any system can be used incorrectly; disclosing a key or
choosing a bad one can break security in most systems.  So you already
have a requirement for unpredictability and secure storage and
confidential transmission of key material (in the case of symmetric
crypto).  The OTP is the only "cipher" I know of that hasn't had any
cryptanalytic success against it for over 70 years, and offers a
proof. [1]
As an aside, it would be interesting to compare data capacity/density
and networking speeds to see if it is getting harder or easier to use
OTP to secure a network link.
[1] Cipher meaning discrete symbol-to-symbol encoding.  OTP's proof
does rely on a good RNG.  I am fully aware that unpredictability is
just as slippery a topic as resistance to cryptanalysis, both being
universal statements that can only be proved by a counterexample, but
that is an engineering or philosophical problem.  By securely
combining it with a CSPRNG you get the least predictable of the pair.
Everyone in reliable computing understands that you don't want single
points of failure.  If someone proposed that they were going to deploy
a system - any system - that could stay up for 70 years, and it didn't
have any form of backup or redundancy, and no proof that it wouldn't
wear down over 70 years (e.g. it has moving parts, transistors, etc.),
they'd be ridiculed.
And yet every time OTP comes up among cryptographers, the opposite
When it comes to analysis, absence of evidence is not evidence of
I think that any long-term data storage solution would have to accept two
1) The shelf life is a complete unknown.  By the time we know it, we will
be using different media, so don't hold your breath.
2) The best way to assure being able to read the data is to seal up a
seperate instance of the hardware, and to use documented formats so
you know how to interpret them.  Use some redundancy, too, with
tolerance of the kind of errors the media is expected to see.
3) Institutionalize a data refresh policy; have a procedure for
reading the old data off old media, correcting errors, and writing it
to new media (see below).
The trend seems to be that I/O capacity is going up much faster than
I/O bandwidth is increasing, and there doesn't seem to be a
fundamental limitation in the near future, so the data is "cooling"
rapidly and will continue to do so (in storage jargon, temperature is
related to how often the data is read or written).
Further, tape is virtually dead, and it looks like disk-to-disk is the
most pragmatic replacement.  That actually simplifies things; you can
migrate the data off disks before they near their lifespan in an
automated way (plug in new computer, transfer data over direct network
connection, drink coffee).  Or even more simply, stagger your primary
and backup storage machines, so that 1/2 way through the MTTF of the
drive, you have a new machine with a new set of drives as the backup,
do one backup and swap roles.  Now your data refresh and backup are
handled with the same mechanism.
At least, that's what I'm doing.  YMMV.

@_date: 2007-02-05 21:08:07
@_author: Travis H. 
@_subject: Entropy of other languages 
I seem to recall Shannon did some experiments which showed that with a
human as your probability oracle, it's roughly 1-2 bits per letter.
Many of his papers are online last time I looked, but some of his
experimental results are harder to locate online.
IIRC, it turned out that Egyptian heiroglyphs were actually syllabic,
like Mesopotamian, so no fun there.  Mayan, on the other hand, remains
an enigma.  I read not long ago that they also had a way of recording
stories on bundles of knotted string, like the end of a mop.

@_date: 2007-02-07 19:19:55
@_author: Travis H. 
@_subject: Entropy of other languages 
Do you remember how he got from the "upper bound on processing time"
to anything other than a completely uniform distribution of symbols?
Seems to me a flat distribution has the minimal upper bound on
information content per symbol for a given amount of information!

@_date: 2007-02-07 20:59:06
@_author: Travis H. 
@_subject: Entropy of other languages 
says:
In 2002 the regiment arrived in Bosnia as part of SFOR, a NATO-led
force intended to ensure peace and stability reigns supreme in the
Balkan nation. During their deployment HM the Queen Mother died. A
number of officers of the Welsh Guards stood in vigil around the Queen
Mother's coffin which was lying in state in Westminster Hall, one of a
number of regiments to do so. The regiment returned home from their
deployment to Bosnia later in the year.
That's all I could find in a 10 minute search...

@_date: 2007-02-09 20:12:02
@_author: Travis H. 
@_subject: interesting and thought provoking resources on quantum crypto 
You know, you shouldn't use the Internet to ask people to do your
homework for you... ;-) j/k
Well, this company sells quantum cryptography devices:
On the other side, any link collection on quantum _cryptanalysis_
wouldn't be complete without Shor:
I went to one of his lectures at my university, and it was one of
those experiences where you know they're speaking English, but it's
just not communicating information to you.  Usually this means one of
two things; either they are trying to fool you, or you are the fool.
I'm convinced it was the latter. I know an EPR pair from a quantum
decoy, but I still have no idea what the angles on his graphs had to
do with QC and superposition.
Lots of good papers on his electronic publications list:
He points to this wiki:
This page is about the watershed paper:
And this page attempts to illustrate it:

@_date: 2007-01-20 18:41:34
@_author: Travis H. 
@_subject: Private Key Generation from Passwords/phrases 
Yes; in textbooks, the author is usually kind enough to give a
complete description of the source; in cryptanalysis, you're usually
looking at the output and making inferences about the source, and
thus, the entropy.
Actually, my reading of a book on Venona said they captured some
unused OTP on microfilm, but weren't able to use the non-randomness of
the source to decrypt anything.  Someone here mentioned that the
entropy of the plaintext and the OTP have to merely add to 1 to
prevent decryption; the OTP does not necessarily have to provide it
all.  Shannon's estimates were that English prose carries about 1 bit
per symbol.
There were some decrypts of material; the official explanation is that
they recovered a partial codebook and discovered some OTP re-use (the
KGB encoded then superenciphered it).
BTW, dictionary attacks can probably be effectively resisted by
making the hashes of passwords twice as big, and using a random value
concatenated with the password before hashing, and storing it alongside
the hash (it's like crypt(3) salting, but more so).  If the password is
important to keep from disclosure beyond the needs of this security
system, one could even truncate the output of the hash to half its size,
so that there's multiple preimages; since you doubled the hash size to
begin with, you end up with the same security factor against guessing,
I believe.

@_date: 2007-01-21 01:55:05
@_author: Travis H. 
@_subject: Private Key Generation from Passwords/phrases 
I probably wasn't clear, you bring out my realization that there
are a number of unwritten assumptions going on here.
Well, I can't disagree, since I also approved of truncating it to
its original size, but I wouldn't want to induce collisions by
making the salted input space much larger than the output space,
or else the work factor goes down for the attacker, right?
I'll have to look at that.
Well, birthday paradox here, but what you say is true.  IIRC, standard
cracker practice back when tftp'ing password files was popular was to
pool them all and sort by salt, then computing the most common salts
and the most common passwords.
Really?  What about rainbow tables?  I heard recently that there was a
relatively complete MD5 rainbow table online with an ajax/js interface
for searching it.  Unless I'm missing something obvious, this basically
eliminates the advantage of hashing unsalted passwords with MD5 to null.
I look favorably on the formats that allow you to iterate a OWF over
the password N times, and that store N in the entry.  That way, if the
costs of running the algorithm go down, you can just increase the
number of times it has been run on every entry in the file without
requiring any interaction from end-users.  This kind of scaling with
the world is needed, because cryptanalysis isn't a stagnant field, and
Moore's Law still holds, and I find the idea of having to change
between incompatible systems just to keep the same level of security,
and on someone else's schedule, to be undesirable.

@_date: 2007-01-22 18:41:43
@_author: Travis H. 
@_subject: analysis and implementation of LRW 
Interesting... reference?
Might look into CMC or EME:

@_date: 2007-01-23 20:47:26
@_author: Travis H. 
@_subject: OT: SSL certificate chain problems 
This is not really typical of the traffic on this list, hence the OT.
I send it because I think this is one of the few places where I'll
find some people with deep understanding of SSL certs.
Recently I had an issue where Google checkout would not accept an
SSL certificate because Apache didn't present the entire hierarchy,
just the site certificate itself.  The CA was Thawte.  What Google
said was that many browsers supply missing certs as needed, but
apparently their software did not.
The fix would seem to be easy; just put the right CA root cert in the
SSLCACertFile directive. or point to the directory with SSLCACertPath.
However, I've tried over and over with various root CA certs
downloaded from Thawte, and with one intermediate CA cert, and various
combinations thereof, but with no sucess.
The troubleshooting command line Google gave us was:
openssl s_client -connect  -showcerts < /dev/null
This is not really typical of the traffic on this list, hence the OT.
I send it because I think this is one of the few places where I'll
find some people with deep understanding of SSL certs.
Recently I had an issue where Google checkout would not accept an
SSL certificate because Apache didn't present the entire hierarchy,
just the site certificate itself.  The CA was Thawte.  What Google
said was that many browsers supply missing certs as needed, but
apparently their software did not.
The fix would seem to be easy; just put the right CA root cert in the
SSLCACertFile directive. or point to the directory with SSLCACertPath.
However, I've tried over and over with various root CA certs
downloaded from Thawte, and with one intermediate CA cert, and various
combinations thereof, but with no sucess.
The troubleshooting command line Google gave us was:
openssl s_client -connect  -showcerts < /dev/null
Which shows:
depth=0 /C=US/ST=California/L=Los Angeles/O=Company, LLC/OU=COMPANY, LLC/CN=
verify error:num=20:unable to get local issuer certificate
verify return:1
depth=0 /C=US/ST=California/L=Los Angeles/O=Company, LLC/OU=COMPANY, LLC/CN=
verify error:num=27:certificate not trusted
verify return:1
depth=0 /C=US/ST=California/L=Los Angeles/O=Company, LLC/OU=COMPANY, LLC/CN=
verify error:num=21:unable to verify the first certificate
verify return:1
Certificate chain
 0 s:/C=US/ST=California/L=Los Angeles/O=Company, LLC/OU=COMPANY, LLC/CN=
   i:/C=ZA/O=Thawte Consulting (Pty) Ltd./CN=Thawte SGC CA
-----BEGIN CERTIFICATE-----
-----END CERTIFICATE-----
Server certificate
subject=/C=US/ST=California/L=Los Angeles/O=Company, LLC/OU=COMPANY, LLC/CN=
issuer=/C=ZA/O=Thawte Consulting (Pty) Ltd./CN=Thawte SGC CA
No client certificate CA names sent
SSL handshake has read 1396 bytes and written 340 bytes
New, TLSv1/SSLv3, Cipher is DHE-RSA-AES256-SHA
Server public key is 1024 bit
Compression: NONE
Expansion: NONE
    Protocol  : TLSv1
    Cipher    : DHE-RSA-AES256-SHA
    Session-ID: 0DD3301C8B8AF7BD3706A991475B22580AA32FCF85A141D753E2F051A691ED86
    Session-ID-ctx:
    Master-Key: ...
    Key-Arg   : None
    Start Time: 1169584627
    Timeout   : 300 (sec)
    Verify return code: 21 (unable to verify the first certificate)
I can't seem to get that certificate chain to have any contents other
than what you see above, no matter what I do, and hence can't get rid
of the Verify return code: 21... does anyone have any advice on what
to do next?  URLs or references to other mailing lists welcome.

@_date: 2007-01-24 18:54:13
@_author: Travis H. 
@_subject: block cipher modes and collisions 
The wikipedia page on the IEEE SISWG debate about LRW says:
"[A] general security requirement for any block cipher, regardless of
mode of operation, is that no block cipher should be used to encrypt
any more data, without changing the key, when the probability of a
collision becomes not negligible (see also birthday paradox)."
They must mean output collisions, rather than multiple preimages,
but I think some modes will have collisions at a rate which depends
on the plaintext (LRW being the obvious example)... but I've never
heard of this security requirement before.  Excepting the Handbook
of Applied Cryptography, which I need to read, does anyone have
another reference for this requirement, or others like it?
I suppose that NIST might have published something like that
in the various publications about block cipher modes, but don't
know where to look exactly...

@_date: 2007-01-27 21:08:34
@_author: Travis H. 
@_subject: data under one key, was Re: analysis and implementation of LRW 
In case anyone else couldn't parse this, he means "the amount of
encrypted material necessary to break the key would be large" or
"the size of a lookup table would be large" or something like
That's longer than computers have been available, and also longer
than modern cryptography has existed.  The only way I would propose
to be able to stay secure that long is either:
1) use a random key as large as the plaintext (one-time-pad)
2) prevent the ciphertext from leaking
   (quantum crypto, spread-spectrum communication, steganography)
Even then, I doubt Lloyd's would insure it.  Anyone who claims to know
what the state of the art will be like in 70+ years is a fool.  I
would be cautious about extrapolating more than five years.
The problem is not the amount of data under one key; that's easy
enough, generate random keys for every n bits of plaintext and encrypt
them with a meta-key, creating a two-level hierarchy.  You calculate a
information-theoretic bound on n by computing the entropy of the
plaintext and the unicity distance of the cipher.  Note that the data
(keys) encrypted directly with the meta-key is completely random, so
the unicity distance is infinite.  Furthermore, one can't easily
brute-force the meta-key by trying the decrypted normal keys on the
ciphertext because all the plaintext under one key equivocates because
it is smaller than the unicity distance.  I'm not sure how it
compounds when the meta-key encrypts multiple keys, I'd have to look
into that.  In any case, you can create a deeper and deeper hierarchy
as you go along.
This bound is the limit for information-theoretic, or unconditional
security.  Shannon proved that a system with these characteristics is
unbreakable.  If you don't know what the entropy of the plaintext is,
you have to use a one-time pad.  The unicity distance of DES, last
time I looked, was so low that one might as well use a one-time pad.
With computational security, you can fudge a little by trying to
calculate how much data you can safely encrypt under one key.
However, I believe this value can only go down over time, as new
cryptanalytic attacks are developed against the cipher.
Another method is to derive many data keys from bits of a larger
meta-key in a way that is computationally infeasible.  However, every
time you hear "computationally infeasible", remember that it is an
argument of ignorance; we don't know an efficient way to break it,
yet, or if someone does they aren't talking.
You can also make this argument more "scientific" by extrapolating
future attacks and computational advances from trends (Moore's Law
et. al.) - see "Rules of Thumb in Data Engineering" from Microsoft;
it's on the storagemojo.com blog and well worth reading.
Furthermore, you should provide a mechanism for the crypto to be
changed transparently as technology progresses; an installed base is
forever, but computational security is not.  Permitting multiple
security configurations is complex, but I don't think anything short
of OTP can give an absolute assurance of confidentiality when the
opponent has access to the plaintext.
Another simple solution, the belt-and-suspenders method, is to
superencrypt the ciphertext with a structurally different cipher.
This basically makes the plaintext fed to the top-level cipher
computationally indistinguishable from random data, and so the unicity
distance of the top-level cipher is infinite according to
computational security of the lower-level cipher.  I'm mixing
terminology here, but the net result is that you're guaranteed that
the combination is as secure as either alone, and in most cases a
weakness in one cipher will not be a weakness in the other (this
is because of the "structurally independent" assumption).
You get the same effect by sending an encrypted file over an encrypted
network connection (unless the file is converted to base64 or
something prior to transmission), assuming that the opponent is not an
insider with access to decrypted network traffic.
Some assumptions to consider are:
What problem(s) are we trying to solve, and why?
Can we set up a secure distribution network for key material?
Who is the opponent?  How many years will they remain interested in a
captured record?
What is the budget?
Who are the users?  How competent are they?  How much can we educate them?
How will we fix bugs or update it?
What are the security priorities?
(usability, confidentiality, authenticity, integrity, availability,
identification, authorization, repudiation)
When the system fails, does it fail-safe or fail unsafe?  What is
the backup method when it fails?  Can the main system be forced to
fail by the opponent?
What are the legal and economic considerations?  That is, are the
people who can best secure the system also the ones with the financial
liability?  If the patient is the beneficiary of the confidentiality,
do they have any control over which system they use, or do they have
any ability to make sure the system is secure?  Who bears the cost of
the system?  Ultimately, a patient should be able to choose between
priorities; if my drug allergies were stored on the system, and I had
a heart attack and passed out, confidentiality and self-authorization
would not be my primary concern.  It's easy to imagine other scenarios
with other priorities.
In my experience, the last consideration (legal and economic) is the
most common reason why systems fail.  Compare the security of voting
systems versus the security of slot machines and you'll see exactly
how economics and self-interest trumps everything else.
What you want to do is terribly difficult to do with any assurance,
unless you're willing to spend a lot of money on it.  I would
recommend figuring out what you're trying to do, then hiring some
consultants; cryptographers, systems analysts, penetration testers,
professional engineeers on reliability, and so on.  Brainstorm.
Propose ideas and shoot them down.  If your funds are limited,
publication on the web, trade magazines, and a public email list plus
referendum may be the best way to get free design critiques.  Since
"all bugs are shallow to one set of eyes", so too most weaknesses are
obvious to some brain, and most failures are predictable by someone.
The closer they are to the problem domain, the more valuable they are,
but even stopped clocks are right twice a day.
I'm thinking about unconditional security, and will write up a
proposed design soon.  I'll send it around when it's ready for public

@_date: 2007-01-28 13:33:30
@_author: Travis H. 
@_subject: length-extension and Merkle-Damgard hashes 
So I was reading this:
It seems to me the length-extension attack (given one collision, it's
easy to create others) is not the only one, though it's obviously a
big concern to those who rely on it.
This attack thanks to Schneier:
If the ideal hash function is a random mapping, Merkle-Damgard hashes
which don't use a finalization function have the following property:
If h(m0||m1||...mk) = H, then h(m0||m1||...mk||x) = h(H||x) where the
elements of m are the same size as the block size of the hash, and x
is an arbitrary string.  Note that encoding the length at the end
permits an attack for some x, but I think this is difficult or
impossible if the length is prepended.

@_date: 2007-06-05 19:00:51
@_author: Travis H. 
@_subject: luks disk encryption benchmarks 
I just did some performance testing on a file server (debian 4.0) and
thought I'd share the figures, both raw and using the luks
cryptosystem described here:
Here's the specs:
AMD Athlon 64 x2 3600+ (1800MHz)
2GB 800MHz DDR2 ECC DRAM
Asus M2N32WS motherboard
3ware 9650SE SATA RAID controller (PCI Express) in PCI Express x16 slot
4 Seagate SATA-II 500GB 7200 RPM drives with NCQ in RAID 10 configuration
16kB stripe size
Debian 4.0 stable (etch)
# time dd if=/dev/zero of=/dev/sdb bs=1024k count=1000
1000+0 records in
1000+0 records out
1048576000 bytes (1.0 GB) copied, 23.0923 seconds, 45.4 MB/s
real    0m23.094s
user    0m0.000s
sys     0m4.508s
Now here demonstrates the luks cryptsetup overhead:
# time dd if=/dev/zero of=/dev/mapper/bulk bs=1024k count=1000
1000+0 records in
1000+0 records out
1048576000 bytes (1.0 GB) copied, 31.0872 seconds, 33.7 MB/s
real    0m31.089s
user    0m0.004s
sys     0m14.053s
So, with write-caching disabled, performance is fairly close.
Then I enabled write-caching and got this:
# time dd if=/dev/zero of=/dev/sdb bs=1024k count=1000
1000+0 records in
1000+0 records out
1048576000 bytes (1.0 GB) copied, 3.08291 seconds, 340 MB/s
real    0m3.126s
user    0m0.000s
sys     0m1.996s
That seems to reflect that it isn't really going to disk.
I'm surprised the controller has that much RAM on it,
really... so I ran this:
# time dd if=/dev/zero of=/dev/sdb bs=1024k count=4000
4000+0 records in
4000+0 records out
4194304000 bytes (4.2 GB) copied, 81.0223 seconds, 51.8 MB/s
real    1m21.024s
user    0m0.004s
sys     0m19.197s
Now here's the overhead with encryption:
# time dd if=/dev/zero of=/dev/mapper/bulk bs=1024k count=4000
4000+0 records in
4000+0 records out
4194304000 bytes (4.2 GB) copied, 151.202 seconds, 27.7 MB/s
real    2m31.227s
user    0m0.008s
sys     1m29.318s
Based on this, it looks like one of two things is happening:
Write cache is 2GB and encryption cancels it out
Encryption reduces bandwidth by about a factor of 2 with write-caching enabled.
Now, for these filesystem tests I just used the default ext3... it does use
a journal, which will slow down writes, but this should give ballpark figures:
Here are the filesystem-level benchmarks without encryption (using LVM to make the filesystem 4G or so):
Version  1.03       ------Sequential Output------ --Sequential Input- --Random-
                    -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
machine            4G 54305  96 84213  14 37749   8 52767  94 119217  13 436.6   0
                    ------Sequential Create------ --------Random Create--------
                    -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                 16  5175  99 +++++ +++ +++++ +++  5131  99 +++++ +++ 14419  99
Here's the filesystem-level performance with encryption (again, with LVM on top of the encryption, file system 10G):
Version  1.03       ------Sequential Output------ --Sequential Input- --Random-
                    -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
machine            4G 36692  98 79380  71 28544   6 50631  91 74157   9 464.5   0
                    ------Sequential Create------ --------Random Create--------
                    -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                 16  5344  99 +++++ +++ +++++ +++  5261  99 +++++ +++ 16060  99
This presents a more interesting picture; it appears that for work on
actual files, the overhead is pretty modest... with all but
character-at-a-time input, it's not worth worrying about.
My hunch is that over NFS, even with gigabit ethernet, there will be no measurable
difference between encrypted and non-encrypted storage.

@_date: 2007-06-13 00:27:08
@_author: Travis H. 
@_subject: luks disk encryption benchmarks 
raw over NFS:
Version  1.03       ------Sequential Output------ --Sequential Input- --Random-
                    -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
nfsclient        4G 16756  61 40475  21 12033   9 15669  85 15564   6 445.8   3
                    ------Sequential Create------ --------Random Create--------
                    -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                 16  2329  12  8480  32  4185  22  1857  10  9742  27  3692  18
crypt over NFS:
Version  1.03       ------Sequential Output------ --Sequential Input- --Random-
                    -Per Chr- --Block-- -Rewrite- -Per Chr- --Block-- --Seeks--
Machine        Size K/sec %CP K/sec %CP K/sec %CP K/sec %CP K/sec %CP  /sec %CP
nfsclient        4G 16416  61 33488  13 10666   9 14084  73 16143   7 392.7   3
                    ------Sequential Create------ --------Random Create--------
                    -Create-- --Read--- -Delete-- -Create-- --Read--- -Delete--
              files  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP  /sec %CP
                 16  2218  12  7444  25  4248  20  2288  12  9401  28  3575  15
So... yeah, pretty minimal - IMHO, not worth worrying about.

@_date: 2007-03-08 17:21:02
@_author: Travis H. 
@_subject: explanation of security classification schemes 
This is probably the most lucid coverage of the topic I've seen:

@_date: 2007-05-09 01:13:36
@_author: Travis H. 
@_subject: More info in my AES128-CBC question 
Hmm, what about IPSec?  Aren't most of the cipher suites used there
CBC mode?  If it doesn't key each flow seperately, and the opponent
has the ability to generate traffic over the link, which isn't
unreasonable, then this would seem feasible.  And then there's openvpn,
which uses SSL for the point-to-point link, thus probably vulnerable,
more vulnerable than a browser.  I am also aware of SSL being used
many places other than browsers and openvpn.

@_date: 2007-05-09 10:36:30
@_author: Travis H. 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
This reminds me a bit of a suggestion I once heard for protocol
designers that the messages of the various steps of the protocol
include a step number or something like it to prevent cut-and-paste
attacks (presumably each message has some redundancy to protect the
integrity/authenticity as well, like a running hash covering all the
previous messages (in this direction)).
I wonder if something similar couldn't be done with digital
signatures, where the input is padded with data that indicates the
semantics of the signature; not unlike the forms which say "by signing
here I agree that..."
This also makes it very difficult for the opponent to do any kind
of chosen-plaintext trickery since the plaintext will be framed
with this data that the opponent does not control, but that is
also true with other padding options and such.

@_date: 2007-05-09 17:22:02
@_author: Travis H. 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
This appears to simplify to:
(G^b * G^x)^(a+y) = (G^(b+x))^(a+y) = G^((b+x)(a+y))
This doesn't appear to be anything like the latest rev of the OTR protocol:
Apparently they key exchange is now a variant of the SIGMA protocol,
and relies upon the implementation to disclose MAC keys automagically
as the related session keys are destroyed/expired.
Apparently this fixes an identity-binding flaw:
And this illustrates a subtlety:
Contrast this to sign-then-encrypt, where Mallory could decrypt, then
forward to Alice.  Compare with encrypt-then-sign.
But it brings up an interesting point; that when a party relays a
piece of data it may not be equivalent to receiving it directly; that
is, authenticity may not be transitive.
Put another way, maybe it's not the information that matters, but who
says it.  The New York Times may say that someone did XYZ, but that's
not entirely the same as the person admitting it under oath.  In
international politics, many believe that admitting to having
performed some provocative action can be more provocative than
actually the action itself, even if everyone already knows who is
responsible.  If you believe this, I suppose the official lie can be
said to serve the interest of both sides, as the government receiving
the provocation can allow the story to go unchallenged, and probably
not be forced into taking an overt retaliatory action.  Thus it
preserves their options, and avoids forcing them into what could be a
disastrous confrontation.  If they are too weak to confront the
provocateur, they aren't likely to shout this from the rooftops.

@_date: 2007-05-09 18:00:47
@_author: Travis H. 
@_subject: More info in my AES128-CBC question 
There's many ways to deal with it if you're willing to do more crypts
per block.  For example, you could derive an independent key and use
that to encrypt a counter for IVs... becoming a cryptographically
strong permutation... that'd work as long as you didn't send so many
IVs that you ran through most of the cycle (the last value in the
cycle is 100% predictable).

@_date: 2007-05-09 18:12:23
@_author: Travis H. 
@_subject: More info in my AES128-CBC question 
Well, it depends on if you key per-flow or just once for the link.  If
the latter, and you have the ability to create traffic over the link,
and there's a 1-for-1 correspondence between plaintext and encrypted
packets, then you have a problem.
Scenarios include:
Private wifi network, you are sending packets at a customer from
unprivileged node on internet; you want known plaintext for the key
used to secure the wifi traffic, or you want the contents of his
Target is VPN'ed into corporate headquarters, you are sending packets
at them (or you send them email, they download it from their mail server)

@_date: 2007-05-09 21:15:47
@_author: Travis H. 
@_subject: phone encryption technology becoming popular in Italy 
If the chips had more than a single layer, or even if they were single layer,
it's probably possible to hide some functionality.  I've heard of devices that
are capable of displaying the current flowing through the conductive regions
of the chip (electrons move just a little too fast to follow, about 1/4 the
speed of light in copper) but that's an awfully labor-intensive way to check
that everything is working to spec... it's probably cheaper to build it
And then with respect to the non-crypto issues; are you going to cut open
every capacitor on the red signal path to check for, say, miniature FM
I'm reminded a bit of the US embassy in Moscow, where (using neutron
scanners) they found bugs in the girders that were the same density as
the steel, and so invisible to X-rays... in the end, they learned that
the only way to avoid these kinds of surprises was to use only their
own building materials and labor.
Earlier in this list tamper-resistant hardware was mentioned... the
downside of that is that unless you're the manufacturer, your attempts
to verify that it doesn't have any surprises look a whole lot like
the kind of tampering it is designed to resist...
It seems like this is a deep rabbit hole with no obvious end.
Probably the best one could hope for is to avoid targeted attacks,
where the opponent knows you are getting something and has it
customized for you.  Widespread (indiscriminate) compromisation is
probably impractical to detect. If you're a nation, or particularly
wealthy, then perhaps you can do it all yourself, but for high-tech
devices that can get very expensive.  History is littered with examples
where countries tried to create a domestic source for some strategic
good and failed miserably.
Incidentally, on my web page I have some pictures and code for a HWRNG
that an associate built (I wrote the software); he made a limited run
of 10 or so, but if anyone wants the schematics, you'll want to send a
SASE to Brad Martin at  (the plans are not in an
easy-to-email form and this method filters out all but serious
inquiries).  It is actually a pretty neat device, battery powered to
avoid 60Hz signal injection (you can use a wall wart if you want to
though, the filters are good) and even enters a power-saving mode when
not in use.  My software (written for Linux and BSD) supports a mode
where it allows the device to power down when /dev/random is above a
"high water mark", and automatically powers it up when it drops below
it.  One person called it "the most over-engineered RNG I have ever
seen".  I think the cost to build one is about $100-200, but Brad
spent $30k of unbillable time on this personal project, mostly on the
design.  It's a shame to see that only used on 10 units.
There are, incidentally, some open-source hardware web sites, where
they have schematics for various chips and cores... although you can't
just etch your own silicon, there are shops that do all of that for
you; you just email them the layouts and send them the money, and
they can do a small run of chips for reasonable prices.

@_date: 2007-05-17 19:49:01
@_author: Travis H. 
@_subject: kernel-level key management subsystem 
Ignoring special-purpose hardware, does anyone have thoughts on what
the requirements for a kernel-level key management subsystem should be?

@_date: 2007-05-23 19:21:21
@_author: Travis H. 
@_subject: crypto maxims 
I have posted my ideas on defensive use of crypto here:
This is not about cipher design, it's more about protocol design
and implementation.
Everyone here is welcome to edit it as they see fit; questions and
answers, discussion - the goal is education, so all of those are

@_date: 2007-11-05 00:01:41
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: Hushmail in U.S. v. Tyler Stumbo 
I probably shouldn't say anything about this, but whoever made this
PDF failed to properly redact the personal information in  just
like the NYT failed to do with the names of the people who helped the
US in Iran.
I can simply switch desktops and see the numbers underneath before the
rectangles are drawn over them (possibly on another layer).  Actually
the box on  seems to work, possibly because it is larger, or was
done differently.
You would think that they would store the minimum or none, so that
they didn't have to answer such requests.  In the US, companies can
require compensation for resources spent filling these requests, but
many do not for fear of increased scrutiny by law enforcement.
I have been around when my department at a Usenet server had to fill
these kinds of requests on posts from people selling GHB or something
like that.  They pretty much write their subpoenas as wide as
possible, pretty much "any record you have about..." and then they
give you every relevant piece of identifying information they have.  I
think you have to swear under penalty that you got them everything.
Sorry bro....
IIRC, there were laws passed in Europe dictating minimum retention
times for ISPs and such.  They may have been passed in Canada and the
US as well.  I guess the legal theory is that when a business offers
services to the public they give up some rights over private property.
Probably they did the minimum work to comply, which means that the
CDs are either mostly empty, or full of unrelated data.
It appears he used IP addresses gathered from My guess is that Hushmail has had subpoenas before and had to develop
and install a modified java applet which captures the passphrase when
the user enters it.  With that and the stored keys, it can decrypt all
the stored communications.
If that's true, I wouldn't expect them to trumpet it, since it would
mostly negate their value proposition.

@_date: 2007-11-08 13:49:30
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
Network latency is important, and will only become more so, since
light won't go faster in a given medium, and we can't do better than
c, ever.
PROPOSED SOLUTION:
Refactor protocol to minimize number of interlocked steps.
Specifically, reduce the number of messages.
Identify data which must be transmitted, and identify their
dependencies.  Send data on first outbound message to peer after all
its dependencies are available (i.e. on the step after it is
received).  Each transmission is a sweep of one level of the
dependency tree, starting at the root and working downward.
PREVIOUS WORK:
Three messages is the proven minimum for mutual authentication.  Last
two messages all depend on the previous message, so minimum handshake
time is 1.5 RTTs.
First examine SSL with Mutual Auth, which is detailed here:
Here is a refactored version of the important messages:
C->S: hello, RNc, client cert, enc_S(client_cert)
S->C: server cert
C->S: enc_S(PMS)
Providing the datum as soon as its dependencies are satisfied is
well-studied in processor design.
One may have extra messages, but they are implementation artifacts,
completely irrelevant to the cryptography.
Network protocol libraries advance through time monotonically and thus
are analogous to LR(1) language parsers which parse from left to right
and are only able to look at the next token (message); perhaps we can
apply what we already know about them to create unambiguous crypto
handshakes with respectable error handling.
Sending one layer of the dependency tree at once is like a synchronous
circuit; one could also fire off messages as soon the data becomes
available, like an asynchronous circuit, which may reduce overall time
of the handshake due to computation by the endpoints.  However, it is
an implementation detail, not important to this analysis.
OPEN QUESTIONS:
When would a handshake require more?  Is there such a thing, in any
extant ZKS or PFS systems?

@_date: 2007-11-09 12:35:10
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: Caffe Latte attack cracks WEP from clients in 6 mins 
The Caffe Latte attack debunks the age old myth that to crack WEP, the
attacker needs to be in the RF vicinity of the authorized network,
with at least one functional AP up and running. We demonstrate that it
is possible to retrieve the WEP key from an isolated Client - the
Client can be on the Moon! - using a new technique called "AP-less WEP
Cracking". With this discovery Pen-testers will realize that a hacker
no longer needs to drive up to a parking lot to crack
WEP. Corporations still stuck with using WEP, will realize that their
WEP keys can be cracked while one of their employees is transiting
through an airport, having a cup of coffee, or is catching some sleep
in a hotel room. Interestingly, Caffe Latte also has a great impact on
the way Honey-pots work today and takes them to the next level of
At its core, the attack uses various behavioral characteristics of the
Windows Wireless stack along with already known flaws in WEP to pull
off this feat! We have considered all combinations of network
configurations and shown how it is possible to retrieve the WEP key in
matter of less than 6 minutes in each case. We exploit the shared key
authentication flaw and the message modification flaw in 802.11 WEP,
to send a flood of encrypted ARP requests to the isolated Client. The
Client replies to these requests with a barrage of encrypted ARP
responses. We use these ARP responses and plug them into the PTW
cryptographic attack and recover the WEP key in less than 6
minutes. It is important to note that though our talk will center on
wireless Clients which run a Windows operating system, the core idea
presented can be easily used to find similar attacks for other
operating systems.

@_date: 2007-11-12 11:43:10
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: cryptanalysis of RNG of Windows OS 
Interesting-looking paper from some guys in Israel:
We analyzed the security of the algorithm and found a non-trivial
attack: given the internal state of the generator, the previous state
can be computed in O(2^23) work (this is an attack on the
forward-security of the generator, an O(1) attack on backward security
is trivial). The attack on forward-security demonstrates that the
design of the generator is flawed, since it is well known how to
prevent such attacks.
The generator is run in user mode rather than in kernel mode, and
therefore it is easy to access its state even without administrator
The implication of these findings is that a buffer overflow attack or
a similar attack can be used to learn a single state of the generator,
which can then be used to predict all random values, such as SSL keys,
used by a process in all its past and future operation. This attack is
more severe and more efficient than known attacks, in which an
attacker can only learn SSL keys if it is controlling the attacked
machine at the time the keys are used.

@_date: 2007-11-14 13:45:37
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
So, this is a good place to attempt to use this method.
Data to be sent:
1) supported capabilities on the client
2) supported capabilities on the server
3) negotiated capabilities
1) No dependencies (first message from client to server)
2) No dependencies (first message from server to client)
3) Depends on  and 3 messages
1-1.5 RTTs (one if there's a simultaneous open, which is rare)
So unless I'm missing something, we're still at 3 messages.
I would like to point out that TCP-based protocols have the latency
disadvantage of having to do a 3-way handshake before transferring any
data.  If you were to design a new IP protocol, you could do the key
exchange within the handshake, which would save 3 messages, but may be
vulnerable to a resource-consumption attack on the CPU.
I wonder if we here could develop a handshake that was
cryptographically secure, resistant to CPU DoS now, and would be
possible to adjust as we get faster at doing crypto operations to
reduce latency even further.  Basically an easy knob for balancing
high latency and DoS resistance vs. crypto overhead and low latency.
It should be adjustable on either end without altering the other.

@_date: 2007-11-29 12:34:19
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
One could theoretically send all of the permutations prior to
negotiation.  However, there would be a bandwidth penalty, a privacy
penalty (any listener knows all cryptographic identities), and a
possible security penalty (if any of the supported methods are
undesirably weak).
However, if you only have strong ciphers and don't care about
cryptographic identity protection, it could be useful.
Note that all these weaknesses already exist, as they could be
triggered by communicating with a less-capable client, or one
controlled by an adversary.  Whether or not it matters depends on some
contextual details.
Schneier suggests keeping a running MAC over the entire datastream,
the state of which is sent with each logical message.  I think that's
a simple and safe way to do it, and so there's no extra messages
involved.  You always check the MAC first, before operating on the
data, and you abort whenever you receive one with a message with an
invalid MAC.  The MAC with each message attests to the integrity of
all data ever sent over that connection, period.
The obvious way - doing a specific step just to verify the handshake -
is the kind of code-centric thinking that I'm trying to avoid.  I'm
having trouble finding the right words for it.  Basically an encrypted
network protocol is a language in which a transmission is
syntactically correct if and only if all the security properties hold.
In some ways current protocols are like a poorly-written language
whose parser that needs a seperator character between statements
instead of being able to detect the syntax error when it starts
processing the following statement.  Basically it lacks even a single
symbol look-ahead.

@_date: 2007-10-04 14:37:21
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: Undocumented Bypass in PGP Whole Disk Encryption 
Interesting quote:
Jon Callas, CTO and CSO of PGP Corp., responded that this [previously
undocumented] feature was required by unnamed customers and that
competing products have similar functionality.

@_date: 2007-10-04 15:08:57
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: ECC vs. D/H or RSA 
Does anyone have information on:
1) The ECAES weakness that led to ECIES
2) Any known weaknesses of ECIES
3) Relative performance figures between ECC routines like ECIES
   and D/H (or possibly RSA, though IES is based on EC-DH)
I can generate the last if these figures are not available.
BTW, I noticed that the latest OpenSSL has some EC functions,
including EC-DH IIRC.  It does not have ECAES or ECIES though.

@_date: 2007-10-08 17:33:59
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: kernel-level key management subsystem 
Protect keys in kernel land rather than userland.
Allows for things like e.g.
1) marking memory unpageable (avoiding swap hazard)
2) relocating the data to different physical pages to prevent
   burn-in
3) secure wiping
4) providing a common system for storing and protecting them
   rather than doing it in each individual application
5) allowing for them to be shared securely among processes (like
   ssh-agent and gpg-agent)
6) provide protection against userland snooping
   programs (gdb anyone?)

@_date: 2007-10-09 17:11:08
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: 307 digit number factored 
They already expired.
Some EC primitives in the latest OpenSSL.
But why assume short ECC keys are stronger than long RSA?
AFAIK, the only advantage of ECC is that the keys are shorter.
The disadvantage is that it isn't as well studied.
Although every time I read up on ECC, I understand it, and then within
a few days I don't remember anything about it.  I think they teflon
coated those ideas somehow, because they don't stick.
Why can't they do something like El-Gamal?
I'm not comfortable with RSA somehow.  It seems fundamentally more
complicated to me than DLP, and it's hard to get right - look at how
many things there are in the PKCS for it.

@_date: 2007-10-09 16:54:51
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: kernel-level key management subsystem 
Good stuff.
I was hoping perhaps to stimulate a discussion on just these sorts of issues.
There's a bit of interrelated stuff here; you can start with requirements,
postulate some mechanisms, think about implications of their implementation,
which leads to refining requirements.  It's sure to be a learning experience.
Maybe this isn't the best place to do that, but it seems to me that this group
would be one of the best for ironing out the details, and would have a vested
interest in any such management interface not suck.
Ideally I'd like to be able to develop something for, say, Linux, and possibly
integrate it with your open-source co-processor stuff.
Maybe that's a good question: what are the idioms in key management?
Is there any similar work already that I could read up on?
Where can I read up on current HSM functionality, offerings, features, etc.?
  "Computers are useless; they can only give answers."
   -- Pablo Picasso

@_date: 2007-10-29 14:24:23
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: password strengthening: salt vs. IVs 
So back in the bad old days when hashing was DES encryption of the
zero vector with a fixed key, someone came up with salt as a password
strengthening mechanism.
I'm not quite sure why it was called salt.
It perturbed the S-boxes in DES IIRC, but essentially it was a known
bit of text that was an input to the algorithm that varied between
entries, like an IV does with encryption.
If there isn't already a term for this, I'm going to call this
general concept "individuation", or possibly "uniquification".
Nowadays with strong hash algorithms, but rainbow tables and
low-entropy passwords as the threat, I'm wondering what the best
practice is.
I was thinking of simply prepending a block of text to each passphrase
prior to hashing, and storing it with the hash - similar to salts in
passwd entries.
It should have at least as much entropy as the hash output, maybe a
little more in case there's collisions.  If it were uniformly random,
you could simply XOR it with the passphrase prior to hashing and save
yourself some cycles, right?
Would it be appropriate to call this salt, an IV, or some new term?

@_date: 2008-04-13 14:20:56
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: Pi, randomness, entropy, unpredictability 
I've been working on the "randomness and unpredictability" this morning
instead of doing my taxes, and found these links:
The section on randomness, entropy, etc. is here:
The formatting on the PDF is better:
Currently the section begins on page 72.
Please tell me what you think.

@_date: 2008-04-21 17:57:53
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: quantum cryptography broken? 
Quantum cryptography broken
KurzweilAI.net, April 20, 2008
Two Swedish scientsts, Jorgen Cederlof, now of Google, and Jan-Ake
Larsson of Link In a paper published in IEEE Trans. Inf Theory, 54:
1735-1741 (2008), they point out that an eavesdropper could gain
partial knowledge on the key in quantum cryptography that may have an
effect on the security of the authentication in the later round.
By accessing the quantum channel used in quantum cryptography, the
attacker can change the message to be authenticated (since the message
is influenced by attacker-initiated events on the quantum
channel). This, combined with partial knowledge of the key
(transmitted on the quantum channel), creates a potential security
gap, they suggest.
Their proposed solution: simply transmit an extra exchange of a small
amount of random bits on the classical (Internet) channel.

@_date: 2008-02-25 16:01:43
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: delegating SSL certificates 
So at the company I work for, most of the internal systems have
expired SSL certs, or self-signed certs.  Obviously this is bad.
I know that if we had IT put our root cert in the browsers, that we
could then generate our own SSL certs.
Are there any options that don't involve adding a new root CA?
I would think this would be rather common, and I may have heard about
certs that had authority to sign other certs in some circumstances...

@_date: 2008-03-28 16:48:08
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: presentations about encrypted storage 
I've got two presentations I've given on encrypted storage technologies here:
There's also a book I'm writing, if anyone is interested.

@_date: 2009-02-13 20:08:34
@_author: Travis 
@_subject: preparing a web 2.0 crypto talk 
I've been working on a presenation for the local OWASP chapter, and here it is:
I'd like suggestions on how to stretch this talk out a bit.  I would particularly
like good examples of real web apps that have done crypto wrong - and how.
Unfortunately, I found this talk, Cryptography for Pen Testers, after
writing mine:
It has a lot of similar material, but I think his talk is much better
because it goes into how it would actually be attacked.  He also must
have powerpoint-fu whereas I'm using lyx....
Any opinions?

@_date: 2009-02-24 13:45:55
@_author: Travis 
@_subject: peer review of presentation requested 
Hello all,
I'm working on a presentation about cryptography to give to the Open
Web Application Security Project (OWASP).  The reason why I'm giving
it is that I've seen web developers doing crypto a lot lately, and
they seem to be making some naive mistakes, like using ECB mode for
multi-block structures, using encryption when they should be using
MACs, and that kind of stuff.
I had originally intended to make the entire presentation on web
security failures, but found it time-consuming to locate information
about web-specific vulnerabilities...  they just aren't documented
well because they're usually in the application layer for a single
company, and so generally not shared widely.  So, I've thrown in some
non-web examples of application developers trying to invent their own
crypto and getting it wrong (LANMAN hashes, for example).
Anyway, I'd like some cryptographers to review my presentation to make
sure that I am giving solid advice.
In addition, I'm curious about:
Which hashes are currently vulnerable to length-extension attacks.  If
I recall Bruce Schneier's book "Practical Cryptography" correctly, he
stated that even SHA-1 was vulnerable.  Do any hashes in the SHA-2
family have protection against length extension?
Is it sufficient to have a one-way finalization function in your
Merkle-Damgaard hash construction to prevent length extension attacks?

@_date: 2009-02-24 18:35:32
@_author: Travis 
@_subject: peer review of presentation requested 
Agreed on this end.  However, these are web security people, not mere
web developers.  They are very sharp on complicated issues like web
security, and just today one of them was joking about how one web
developer thought that hidden fields in forms are immutable.
Hmm, interesting thought.  I was hoping to present the multiple
failures (by smart people) as a way to convince them of the need to
use existing algorithms rather than try to design their own.
This actually touches on something I've noticed.  With a
locally-executing application, the operating system provides
abstractions like user IDs and file permissions that an application
developer gets "for free", and by and large they are making effective
use of them.  However, in the web application or web services world,
nearly everyone* is doing things like user account management from
scratch, and they're making the same sort of mistakes over and over
[*] There are possible exceptions in web application frameworks
like Zope.  Some of these systems may already provide security
features and abstractions that can be used by web developers.
Strong agreement.
I'm not so sure; it seems that, for better or worse, web developers
are doing these things, and they're doing them wrong.
Hopefully this presentation will deliver two messages; one, that
cryptography and cryptographic protocols are insanely hard to get
right, and two, that they should use some relatively standard
mechanisms for implementing their crypto, like AES256-CBC (for
confidentiality) and SHA-2-HMAC (for integrity protection).
But I suppose it could backfire, if people came away with the notion
that _now_ they are educated enough on crypto to make informed
decisions about new combinations.  Maybe I should make a point of
telling them that this is not the case.

@_date: 2009-02-27 15:26:45
@_author: Travis 
@_subject: X.509 certificate overview + status 
============================== START ==============================
Recently I set up certificates for my server's SSL, SMTP, IMAP, XMPP,
and OpenVPN services.  Actually, I created my own CA for some of the
certificates, and in other cases I used self-signed.  It took me
substantially more time than I had anticipated, and I'm left with
feelings of unease.
It seems the way to do this revolves around openssl, but while I was
able to find instructions*, they were cookbook-style, and didn't
really give me as complete an understanding as I had hoped.
[*] I experimented with tinyca2, which appears only to create certificates
with passphrases, which is obnoxious.  Only some applications
(e.g. dovecot) allow you to specify passphrases, and in most cases the
config file with the passphrase is protected the same way as the key
itself, using filesystem permissions, making it pointless.
However, I still have problems with dovecot.  Whenever I connect to
IMAPS, it complains that the certificate is for '' (empty string), and
I'm not sure what I did wrong in the certificate creation.
In other cases, such as openvpn, there are some scripts there
(easy-rsa) which take care of it for you.
I couldn't, in particular, find comprehensive information on the
openssl.cnf file, particularly the v3 extensions.
In some cases, such as OpenBSD's isakmpd, I had to abandon my plans
completely because they had requirements that the certificates have
some fields (subjectAltName, I think) that weren't well documented.
I can't remember exactly if I couldn't create this field, or merely
didn't know what to put in it.
However, in this case, the main problem I found was that the Linux
port of isakmpd was not reliable, and nearly impossible to debug.  It
just would work 50% of the time, and not the other 50%.  OpenBSD's
isakmpd is pretty sexy - it detects NAT traversal and automagically
encapsulates in UDP - but apart from the Linux reliability issue, I
also had issues with multiple tunnels going through the same NAT/fw
box that was itself running IPSec.  Whereas by contrast, OpenVPN
handles that situation well, and has support for MS-Windows should I
ever want it.
Further, trying to dig into ASN.1 was extremely difficult.  The specs
are full of obtuse language, using terms like "object" without
defining them first.  Are there any tools that will dump certificates
in human-readable formats?  I would really like something that could
take a PEM file of a cert and display it in XML or something of the
Although I have it all working, I am considering redoing all the work,
hopefully all under one CA cert that I control.  But I'm not sure if
that's wise.
I'm plowing through the O'Reilly OpenSSL book, but are there other
resources out there that could help me, or others like me?

@_date: 2009-07-17 12:34:01
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: Intercepting Microsoft wireless keyboard communications 
FWIW, it is likely sending keyboard scan codes:
It doesn't send the actual characters typed, because games and the
like need to know when keys are depressed and released, not just what
letter was typed.
Here's an overview of keyboard input under Linux:

@_date: 2009-07-17 13:37:43
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: work factor calculation for brute-forcing crypto 
Hi folks,
Assume for a moment that we have a random number generator which is
non-uniform, and we are using it to generate a key.
What I'd like to do is characterize the work factor involved in
brute-force search of the key space, assuming that the adversary
has knowledge of the characteristics of the random number generator?
The algorithm for this is simple:
Let the array X represent the probabilities of the outcomes of the
random number generator, sorted by probability, with x[0] being the
probability of the most probable value.
Then, for a given fraction of the messages n (0 < n <= 1):
i = 0
m = 0
while (m + x[i]) < n:
    m = m + x[i]
    i = i + 1
return (i - 1) + (n - m) / (m + x[i])
This return value represents the average number of decryption attempts
required to guess the right key.  If one wanted to round up, one could
just return i instead of the last expression above, because the second
term is always in (0, 1]
I'm curious if there's a way to express this calculation as a
mathematical formula, rather than an algorithm, but right now I'm just
blanking on how I could do it.

@_date: 2009-06-10 18:19:53
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
Reading really old email, but have new information to add.
There was an interesting article in 2600 recently about ATA drive
It's in Volume 26, Number 1 (Spring 2009).  Sorry that I don't have an
electronic copy.
The relevant bit of it is that there are two keys.  One key is for the
user, and one (IIRC, it is called a master key) is set by the factory.
IIRC, there was a court case recently where law enforcement was able
to read the contents of a locked disk, contrary to the vendor's claims
that nobody, even them, would be able to do so.  The man in question
had his drives sized by the FBI and they read the drives, uncovering
emails between the man and his lawyer.  He was suing the manufacturer
for false advertising.
Here are the links from the 2600 article:
hdparm -security-erase-enhanced in Linux

@_date: 2009-06-11 11:37:16
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: padding attack vs. PKCS7 
Towards the end of this rather offbeat blog post they describe a
rather clever attack which is possible when the application provides
error messages (i.e. is an error oracle) for PKCS7 padding in e.g. AES
CBC-encrypted web authenticators that allows an adversary to attack
the crypto one octet at a time.

@_date: 2009-03-13 14:16:15
@_author: Travis 
@_subject: CSPRNG algorithms 
I have never seen a good catalog of computationally-strong
pseudo-random number generators.  It seems that everyone tries to roll
their own in whatever application they are using, and I bet there's a
lot of waste and inefficiency and re-inventing the wheel involved.
If this true, or is there a survey somewhere?  If not, would people
like to help me create one by emailing me references to extant PRNG

@_date: 2010-08-05 10:09:37
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: phpwn: PHP cookie PRNG flawed (Netscape redux) 
Hey, another PRNG is broken.  Raise your hand if you're surprised.

@_date: 2010-08-25 13:37:16
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: questions about RNGs and FIPS 140 
Hey all,
Looking for feedback on this section on RNGs:
Equations are broken in HTML, but clear in PDF:
I am aware the Renyi entropy link is broken.
I also wanted to double-check these answers before I included them:
1) Is Linux /dev/{u,}random FIPS 140 certified?
No, because FIPS 140-2 does not allow TRNGs (what they call non-deterministic).
I couldn't tell if FIPS 140-1 allowed it, but FIPS 140-2 supersedes FIPS 140-1.
I assume they don't allow non-determinism because it makes the system harder
to test/certify, not because it's less secure.
2) Is CryptGenRandom certified?
Yes - is that because they have a deterministic mode?  Wikipeda makes it sound
like this closed-design system seeds from system timings and other stuff, which
would seem to make it non-deterministic as far as FIPS 140 testing is concerned.
3) Is determinism a good idea?
See Debian OpenSSL fiasco.  I have heard Nevada gaming commission
regulations require non-determinism for obvious reasons.
4) What about VMs?
Rolling back a deterministic RNG on those systems gives the same
values unless/until you re-seed with something new to this iteration.
Do those sound right?

@_date: 2010-08-26 08:14:26
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: questions about RNGs and FIPS 140 
That brings up an interesting question... if you have a source of
unpredictable values in the first place, why use a CSPRNG? ;-)
Actually, I know I'm being snarky; I'm aware that they're handy for
"stretching" your random bits, if you don't have enough for the task.
I suppose some people feel they're also handy for whitening them, so
that if they're not entirely random, the structure isn't completely
obvious from the output alone, but I think that's probably a separate
property that needs to be evaluated independent of the others.
Last I checked Linux /dev/{u,}random uses SHA-1 hash over the pool,
which suggests they had this in mind.  However, it also makes using it
very slow for wiping disks or any other high-bandwidth tasks, at least
when compared to something like Yarrow.
I heard from a colleague that /dev/urandom exists on Android, but
standard Linux /dev/urandom, but we're not really sure.  Presumably
they dumped /dev/random because there just weren't enough sources of
unpredicability on that platform.  I'd like to hear from anyone who
knows details.
Also, please do check out the links about RNGs on the aformentioned
page.  Seth Hardy's /dev/erandom looks very interesting, and has
languished in relative obscurity for nearly a decade.
I'll take the rest of my comments to this list:

@_date: 2010-08-26 09:31:40
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: questions about RNGs and FIPS 140 
On closer reading, I guess that's true.  Annex C, "Approved Random
Number Generators", claims that no TRNGs have been approved, but
that's not the same as saying that they are specifically excluded.

@_date: 2010-09-02 08:49:07
@_author: travis+ml-cryptography@subspacefield.org 
@_subject: RSA question 
As of 2003, RSA said:
1024 bit RSA ~= 80 bit symmetric
2048 bit RSA ~= 112 bit symmetric
3072 bit RSA ~= 128 bit symmetric
So PK is usually weaker than the symmetric part of a hybrid scheme.
I hear that NIST Key Mgmt guideline (SP 800-57) suggests that the RSA
key size equivalent to a 256 bit symmetric key is roughly 15360 bits.
I haven't actually checked this reference, so I don't know how they
got such a big number; caveat emptor.
I have no idea what the state of, say, AES brute forcing is, so I
don't know the ratio from AES key size to ideal symmetric cipher key
sizes.  I'm guessing it's pretty close to 1, but would love to hear
if it's not.
