
@_date: 2007-04-06 10:49:07
@_author: Nicolas Williams 
@_subject: DNSSEC to be strangled at birth. 
Think of the DNSSEC root as the root CA of a universal PKI (finally).
The root CA of any PKI can act as an MITM between any pair of peers in
that PKI, no matter how many intervening CAs there may be between the
root and each peer.
The problem with wanting the DNSSEC root keys for facilitating MITM
attacks is that people are likely to notice, and secrecy is typically
something that an MITM attacker wants.  To avoid detection the MITM
would have to get between the target client and all of DNS; and that's
difficult because typically clients get DNS cache service from their
immediate network service provider -- which cache the MITM does not want
to pollute, so as to avoid discovery...
Which means that the MITM would need the cooperation of the client's
provider in many/most cases (a political problem) in order to be able to
quickly get in the middle so close to a leaf node (a technical problem).
Then there's the need to scale this -- if you can only use this MITM
capability occasionally, what's the point?  And what targets would DHS
have that it could subvert in this way but not in other, simpler ways?
Criminals?  Not likely (besides, isn't that DoJ's job?).  Spies?  Less
likely.  Clients abroad?  Less likely still.  Dumb spies/criminals?
Well, there'd be other ways to attack those.
IMO, DHS gets too little real value from having the DNSSEC root keys in
terms of MITM attack capability.
And it will not get much value in terms of DoS attacks on, say, ccTLDs

@_date: 2007-04-19 16:51:50
@_author: Nicolas Williams 
@_subject: AES128-CBC Question 
Kerberos V calls this a "confounder" (a block of randomly selected bits
that is prepended to plaintext prior to encryption).

@_date: 2007-04-23 10:11:11
@_author: Nicolas Williams 
@_subject: More info in my AES128-CBC question 
You don't necessarily have to change the integrity protection key for
every message.  One thing this says is that the protocol involves an
ordered stream of messages.
It does.  You can get by without a random IV by using CBC analogously to
how you use counter modes and cipher streams in general.  The key thing
is to avoid key and IV/counter re-use.  For a protocol where ordered
delivery of messages is expected/ required this is easy to achieve.
Derive the key and/or counter/IV from a message sequence number and do
it in such a way that you either cannot repeat them or are very, very
unlikely to repeat them and you're fine.
But be careful.  Simply chaining the IV from message to message will
create problems (see SSH).
What is the concern with using random IVs/confounders anyways?  The need
for an entropy source?  If so keep in mind that a PRNG will be
sufficient for generating the IVs/confounders and that you'll generally
need some source of entropy for at least some protocol elements (e.g.,

@_date: 2007-04-24 18:18:43
@_author: Nicolas Williams 
@_subject: More info in my AES128-CBC question 
Or construct your MAC so that there is a sequence number in it.
E.g., SSHv2 uses HMAC without changing the integrity key.
If deriving a new key is slower than adding a sequence number into the
input of HMAC (which it most likely is) then you're likely to prefer the
If there isn't a good reason for rejecting what I suggest then one might
worry that changing the integrity key on every message (but not the
confidentiality key?) is something that a non-expert might do and that
there may be other problems with this protocol.  Much experience has
been gained with other protocols in these areas; do leverage it.
As long as it doesn't repeat.  Also, if it's not random then make that
IV the first block of plaintext (with a fixed IV) -- that is, use a
confounder, and make sure it doesn't repeat.
Fallacious responses, those.
A legitimate response w.r.t. confounders might be "but that wastes a
cipher block's worth of bits on the wire," which it certainly does, and
if you're really hard pressed for bandwidth and use mostly small
messages then you'd mind the confounder.  But I see no reason not to use
a random or pseudo-random IV -- a device that can do crypto can and
should have a decent PRNG (and a true, if low-bandwidth RNG to seed it).

@_date: 2007-04-25 17:28:08
@_author: Nicolas Williams 
@_subject: Public key encrypt-then-sign or sign-then-encrypt? 
Instinctively sign-then-encrypt offers privacy protection: only the
intended receipient can verify the signature.

@_date: 2007-04-25 17:42:44
@_author: Nicolas Williams 
@_subject: More info in my AES128-CBC question 
See RFC4251:
   Additionally, another CBC mode attack may be mitigated through the
   insertion of packets containing SSH_MSG_IGNORE.  Without this
   technique, a specific attack may be successful.  For this attack
   (commonly known as the Rogaway attack [ROGAWAY], [DAI], [BELLARE]) to
   work, the attacker would need to know the Initialization Vector (IV)
   of the next block that is going to be encrypted.  In CBC mode that is
   the output of the encryption of the previous block.  If the attacker
   does not have any way to see the packet yet (i.e., it is in the
   internal buffers of the SSH implementation or even in the kernel),
   then this attack will not work.  If the last packet has been sent out
   to the network (i.e., the attacker has access to it), then he can use
   the attack.
I think you should really consider the SSHv2 experience and add a
confounder.  The confounder plaintext block need not be random or
pseudo-random, just non-repeating.
A confounder is an extra block of random plaintext that is prepended to
a message prior to encryption with a block cipher in CBC (or CTS) mode;
the resulting extra block of ciphertext must also be sent to the peer.
An IV is a cipher block size's worth of bits that is XORed into the
first plaintext block when encrypting/decrypting; if you somehow agree
upon an IV to use and so does not take up any bits on the wire.  If the
IV chained across continguous messages as in SSHv2 then you have a
problem (see above).  If it's constant then you have a problem that you
can solve by deriving per-message keys or by generating a pseudo-random
IV from a sequence number.
Since the protocol describe generates per-message integrity keys I
imagine that it might generate per-message confidentiality keys as well,
in which case the IV issue goes away.

@_date: 2007-04-26 08:33:59
@_author: Nicolas Williams 
@_subject: More info in my AES128-CBC question 
The term "confounder" as used in Kerberos V is as I described.
The last ciphertext block of one message is the IV for the next.

@_date: 2007-04-27 16:30:21
@_author: Nicolas Williams 
@_subject: More info in my AES128-CBC question 
SSH_MSG_IGNORE messages carry [random] data.
Effectively what the RFC is calling for is a confounder.

@_date: 2007-02-07 12:44:30
@_author: Nicolas Williams 
@_subject: Entropy of other languages 
Er, no, Mayan has been decoded:
The knotted string system was an Inca writing system, IIRC.

@_date: 2007-02-08 12:42:49
@_author: Nicolas Williams 
@_subject: One Laptop per Child security 
If this means pop-up dialogs for every little thing an application wants
to do then the result may well be further training users to click 'OK'.
The more complex the application, the harder it is for the user to
evaluate all its access requests (if nothing else due to lack of
As for browsers, you'd have to make sure that every window/tab/frame is
treated as a separate application, and even then that probably wouldn't
be enough.  Remember, the browser is a sort of operating system itself

@_date: 2007-02-08 15:09:41
@_author: Nicolas Williams 
@_subject: One Laptop per Child security 
The text you quote doesn't answer the question; the rest of the wiki
frontpage says little more.  It tends to make me think that if an
application wants to do something that I've not enabled it to do ahead
of time then it fails.  Failure is incovenient.  So as near as I can
tell from the text you quote BitFrost sets its convenience/security
parameters differently than other OSes, but there's nothing truly Earth
shatteringly new there.  Now, if it's a new OS presumably you start from
scratch in terms of applications, so you get to have usable profiles for
all of them initially, and maybe _that_ is what is truly new.
I'm imagining BitFrost as something like OpenBSD's systrace facility + a
small number of well-profiled apps.  If this is a good analogy, please
confirm it.  If it isn't and there is another similarly simple analogy,
then tell me what it is -- simple analogies, imprecise though they might
be, can help provide a good starting point to understand something new.
In a world where web-based applications are all the applications you
need, this attitude towards the browser leaves BitFrost with a big hole
in it.
I think you have to think of each site as a separate application, and
profile that, if I understood BitFrost correctly.  And that seems

@_date: 2007-02-09 10:40:29
@_author: Nicolas Williams 
@_subject: One Laptop per Child security 
This is a good summary -- the analogy that I asked for.
It doesn't sound so new either though.  Labelled OSes and trusted
desktops allow as much.  My employer makes this stuff (much, if not all
of it FOSS), and there have been some very impressive blog posts showing
how you can have applications, including browsers, running in different
"VMs," with some VMs VPNed into a private network, and some not.

@_date: 2007-02-15 10:56:56
@_author: Nicolas Williams 
@_subject: Failure of PKI in messaging 
As mobile devices improve in compute/memory/display/input capabilities
the distinction between texting/IM/e-mail will get blurred, and at the
same time mobiles will become more and more tempting vehicle for
securing transactions.
E.g., I use the GMail J2ME app on my cell phone and it's almost as good
as SMS in some ways and better in others (plus I forward some e-mails to
SMS so that this app need not be running all the time).  I can even pay
via paypal using my phone, supposedly -- I've not tried it.
Just as we laugh when we recall 1980s cell phones (ha!) the next
generation will laugh at the best of our current crop of mobile devices,
never mind the more basic ones.

@_date: 2007-07-16 16:49:43
@_author: Nicolas Williams 
@_subject: improving ssh 
Doesn't this belong on the old SSHv2 WG's mailing list?
The SSHv2 protocol or OpenSSH (an implementation of SSHv1 and SSHv2)?
Do you think that implementations of the protocol should implement this?
(From what you say below I think your answer is "yes."  Which brings up
the questions "why?" and "how?")
SSH servers could integrate features like this without needing firewall
Unfortunately SSH implementations tend to depend on accurate client and
server software version strings in order to work around bugs.
Anyways, security by obscurity doesn't help.
What are those?
Are they requests with an empty username?  The only SSHv2 userauth
methods that support that are the GSS ones, and that's a good feature
(it allows the server to derive the username from the client's principal
Currently the only way to do this is to configure SSH servers to support
only SSHv2 and only the gss-* key exchange algorithms (see RFC4462,
section 2).  There exist implementations that support this.
To get rid of the "host authenticates itself first" attitude for all
non-GSS-based SSHv2 userauth methods will require radical changes to the
protocol and deployment transitions.
The server has to answer with something.  Silence is still an answer.
So is closing the TCP connection.
Coding to firewall APIs is even less portable (heck, not all OSes have
firewall APIs).

@_date: 2007-06-21 12:03:15
@_author: Nicolas Williams 
@_subject: Why self describing data formats: 
ASN.1 is not an encoding, and not all its encodings are self-describing.
Specifically, PER is a compact encoding such that a PER encoding of some
data cannot be decoded without access to the ASN.1 module(s) that
describes the data types in question.
Yes, it's a nit.
Then there's XDR -- which can be thought of as a subset of ASN.1 and a
four-octet aligned version of PER (XDR being both, a syntax and an
Supposedly it is (or was thought to be) easier to write encoders/
decoders for TLV encodings (BER, DER, CER) and S-expressions, but I
don't believe it (though I certainly believe that it was thought to be
easier): rpcgen is a simple enough program, for example.
TLV encodings tend to quite redundant, in a way that seems dangerous: a
lazy programmer can (and many have) write code that fails to validate
parts of an encoding and mostly get away with it (until the then
inevitable subsequent buffer overflow, of course).
Of course, code generators and libraries for self-describing and non-
self-describing encodings alike are not necessarily bug free (have any
been?) but at least they have the virtue that they are automatic tools
that consume a formal language, thus limiting the number of lazy
programmers involved and the number of different ways in which they can
screw up (and they leave their consumers off the hook, to a point).
I agree.  The redundancy of TLV encodings, XML, etcetera, is
unnecessary.  Note though that I'm only talking about serialization
formats for data in protocols; XML, I understand, was intended for
_documents_, and it does seem quite appropriate for that, and so it can
be expected that there should be a place for it in Internet protocols in
transferring pieces of documents.

@_date: 2007-06-21 12:10:33
@_author: Nicolas Williams 
@_subject: Why self describing data formats: 
Maybe.  But there's quite a lot to be said for standards which lead to
widespread availability of tools implementing them, both, open source
and otherwise.
One of the arguments we've heard for why ASN.1 sucks is the lack of
tools, particularly open source ones, for ASN.1 and its encodings.
Nowadays there is one GPL ASN.1 compiler and libraries: SNACC.  (I'm not
sure if it's output is unencumbered, like bison, or what, but that's
important to a large number of developers who don't want to be forced to
license under GPL, and there's not any full-featured ASN.1 compilers and
libraries licensed under the BSD or BSD-like licenses.)
The situation is markedly different with XML.  Even if you don't like
XML, or its redundancy (as an encoding, but then, see FastInfoSet, a
PER-based encoding of XML), it has that going for it: tool availability.

@_date: 2007-06-21 12:11:34
@_author: Nicolas Williams 
@_subject: Why self describing data formats: 
Nonsense.  ASN.1's PER encoding does not prevent extensibility.

@_date: 2007-06-23 12:26:20
@_author: Nicolas Williams 
@_subject: Why self describing data formats: 
If only it were so easy.  As we discovered in the IETF KRB WG you can't
expect that just because the protocol uses a TLV encoding (DER) you can
just add items to sequences (structures) or choices (discriminated
unions) willy nilly: code generated by a compiler might choke because
formally the protocol didn't allow extensibility and the compiler did
the Right Thing.  Extensibility of this sort requires that one be
explicit about it in the original spec.
I doubt it: you can have schemas without self-describing encodings
(again, PER, XDR, are examples of non-self-describing encodings for
ASN.1 and XDR, respectively).  Schemas can be good while self-describing
encodings can be bad...

@_date: 2007-06-26 12:10:03
@_author: Nicolas Williams 
@_subject: Quantum Cryptography 
This relates back to the inutility of QKD as follows: when physical
exchanges are required you cannot run such exchanges end-to-end over an
Internet -- the middle boxes (routers, etc...) get in the way of the
physical exchange.
This too is a *fundamental* difference between QKD and classical
That difference makes QKD useless in *today's* Internet.
IF we had a quantum authentication facility then we could build
hop-by-hop authentication to build an Internet out of QKD and QA
(quantum authentication).  That's a *big* condition, and the change in
security models is tremendous, and for the worse: since the trust chains
get enormously enlarged.
IMO, QKD's ability to discover passive eavesdroppers is not even
interesting (except from an intellectual p.o.v.) given: its inability to
detect MITMs, its inability to operate end-to-end across across middle
boxes, while classical crypto provides protection against eavesdroppers
*and* MITMs both *and* supports end-to-end operation across middle

@_date: 2007-06-26 13:18:28
@_author: Nicolas Williams 
@_subject: Quantum Cryptography 
Noone claimed that it isn't -- the claim is that there is no quantum
authentication, so QKD has to be paired with classical crypto in order
to defeat MITMs, which renders it worthless (because if you'll rely on
classical crypto then you might as well only use classical crypto as QKD
doesn't add any security that classical crypto, which you still have to
use, doesn't already).
The real killer for QKD is that it doesn't work end-to-end across middle
boxes like routers.  And as if that weren't enough there's the
exhorbitant cost of QKD kit.
Everyone who's commented has agreed that authentication is to be done
classically as there is no quantum authentication yet.
But I can imagine how quantum authentication might be done: generate an
entangled pair at one end of the connection, physically carry half of it
to the other end, and then run a QKD exchange that depends on the two
ends having half of the same entangled particle or photon pair.  I'm no
quantum physicist, so I can't tell how workable that would be at the
physics-wise, but such a scheme would be analogous to pre-sharing
symmetric keys in classical crypto.  Of course, you'd have to do this
physical pre-sharing step every time you restart the connection after
having run out of pre-shared entabled pair halfs; ouch.
The end-to-end across middle boxes issue kills this argument about
protection against speculative brokenness of public key cryptography.
All but the smallest networks depend on middle boxes.
Quantum cryptography will be useful when:
 - it can be deployed in an end-to-end fashion across middle boxes
 OR
 - we adopt hop-by-hop methods of building end-to-end authentication
And, of course, quantum kit has got to be affordable, but let's assume
that economies of scale will be achieved once quantum crypto becomes
Critical breaks of public key crypto will NOT be sufficient to drive
adoption of quantum crypto: we can still build networks out of symmetric
key crypto (and hash/MAC functions) only if need be (with pre-shared
keying, Kerberos, and generally Needham-Schroeder).
But the only real practical issue, for Internet-scale deployment, is the
end-to-end issue.  Even for intranet-scale deployments, actually.
Which legal issue?

@_date: 2007-06-26 14:49:22
@_author: Nicolas Williams 
@_subject: ad hoc IPsec or similiar 
That's pretty funny, actually, although I don't quite agree with the
substance (surprise!)  :)
Seriously, for those who merely want unauthenticated IPsec, MITMs and
all, then yes, agreeing on a globally shared secret would suffice.
For all the other aspects of BTNS (IPsec connection latching [and
channel binding], IPsec APIs, leap-of-faith IPsec) agreeing on a
globally shared secret does not come close to being sufficient.

@_date: 2007-06-26 15:26:20
@_author: Nicolas Williams 
@_subject: ad hoc IPsec or similiar 
I strongly dislike the WG's name.  Suffice it to say that it was not my
idea :); it created a lot of controversy at the time, though perhaps
that controversy helped sell the idea ("why would you want this silly,
insecure stuff?" "because it enables this other actually secure stuff").

@_date: 2007-06-27 16:53:34
@_author: Nicolas Williams 
@_subject: Quantum Cryptography 
I don't mind using "classical" here.  I don't think Newtonian physics
(classical) is "bad" -- it works great at every day human scales.
Heh!  Indeed: with classical (or non-quantum, or standard, or...) crypto
eavesdroppers are passive attackers and passive attackers cannot mount
DoS attacks (oh, I suppose that wiretapping can cause some slightly
noticeable interference in some cases, but usually that's no DoS), but
in QKD passive attackers become active attackers.
But it gets worse!  To eavesdrop on a QKD link requires much the same
effort (splice the fiber) as to be an MITM on a QKD link, so why would
any attacker choose to eavesdrop and be detected instead of being an
MITM, go undeteceted and get the cleartext they're after?  Right, they
wouldn't.  Attackers aren't stupid, and an attacker that can splice your
fibers can probably afford the QKD HW they need to mount an MITM attack.
So, really, you need authentication.  And, really, you need end-to-end,
not hop-by-hop authentication and data confidentiality + integrity
This reminds me of Feynman's presentation of Quantum Electro Dynamics,
which finished with "QED."  Has it now been sufficiently established
that QKD is not useful that whenever it rears its head we can point
folks at archives of these threads and not spill anymore ink?

@_date: 2007-05-04 09:50:30
@_author: Nicolas Williams 
@_subject: Was a mistake made in the design of AACS? 
Wait, are you saying that people copy rented DVDs onto DVD media?  Or
that they _extract_ the content?
There's a big difference: there's no need to crack the DVD DRM system to
do the former, but there is for the latter.
I expect the same to be true for HD-DVDs, unless the readers themselves
perform one-way transformations on the content and the readers are
tamper-resistant enough that DMCA protection for them as access control
devices can be claimed.
So?  If breaking AACS has nothing to do with disk-to-disk copies then I
don't see how the coming market for HD players/writers is going to
affect that kind of piracy.  Or analog hole piracy.  Let's face it: DRM
only stops anyone from trying to make fair use of content (e.g.,
sampling) -- pirates might as well not even know that DRM is there,
unless you can create scarcity of media for the pirates (blank media
taxes), but that's harder than you think when in a couple of years
someone can be manufacturing blank media in some far off place that's
politically hard to reach.
Well, there's an idea: use different physical media formats for
entertainment and non-entertainment content (meaning, content created by
MPAA members vs. not) and don't sell writable media nor devices capable
of writing it for the former, not to the public, keeping very tight
controls on the specs and supplies.  Then finding, say, a Disney movie
on an HD-DVD of the data format would instantly imply that it's pirated.

@_date: 2007-05-09 17:51:35
@_author: Nicolas Williams 
@_subject: More info in my AES128-CBC question 
But if the key doesn't change between messages then this makes the IV of
the second block constant and if any plaintext repeats in the first
block of plaintext then you have a problem.

@_date: 2007-05-12 13:58:44
@_author: Nicolas Williams 
@_subject: no surprise - Sun fails to open source the crypto part of Java 
Were you not surprised because you knew that said source is encumbered,
or because you think Sun has some nefarious motive to not open source
that code?
If the latter then keep in mind that you can find plenty of crypto code
in OpenSolaris, which, unless you think the CDDL does not qualify as
open source, is open source.  I've no first hand knowledge, but I
suspect that the news story you quoted from is correct: the code is
encumbered and Sun couldn't get the copyright holders to permit release
under the GPL in time for the release of Java source under the GPL.

@_date: 2007-05-14 19:51:19
@_author: Nicolas Williams 
@_subject: no surprise - Sun fails to open source the crypto part of Java 
"crypto with a hole" (i.e., a framework where anyone can plug anyone
else's crypto) is what was seen as bad.
The requirement for having providers signed by a vendor's key certified
by Sun was to make sure that only providers from suppliers not from,
say, North Korea etc., can be loaded by the pluggable frameworks.  As
far as I know the process for getting a certificate for this is no more
burdensome to any third parties, whether open source communities or
otherwise, than is needed to meet the legal requirements then, and
since, in force.
Of course, IANAL and I don't represent Sun, and you are free not to
believe me and try getting a certificate as described in Chapter 8 of
the Solaris Security Developers Guide for Solaris 10, which you can find
Comments should probably be sent to security-discuss at opensolaris.org.

@_date: 2007-05-15 11:19:57
@_author: Nicolas Williams 
@_subject: no surprise - Sun fails to open source the crypto part of Java 
If we ignore politics, and if we ignore TPMs, yes.  Those are big
I'm not sure I understand the significance of the above.  I'm sure that
there are better lists to ask about the prospects for evolution here.
That's not due to luck.
Save it from what exactly?
By whom?  The code is GPLed -- you're free to hack on it.  OpenSolaris
is CDDLed and you're free to hack on that too.
Sun may or may not be subject to more relaxed export rules as a result
of open sourcing these things.  I don't know, IANAL.  The point is that
Sun may not be able to do in the products it ships what the community
can do with the source code.
Ah, but you're free to: the code is GPLed and you can figure out what to
do to make the crypto framework not require provider signing.
Also, the provider surely can't be missing due to export rules -- the
C/assemler equivalents in Solaris are open source.

@_date: 2007-11-12 17:00:27
@_author: Nicolas Williams 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
Kerberos V manages in one round-trip.  And it could do one round-trip
without a replay cache if it used ephemeral-ephemeral DH to exchange
sub-session keys.  (OTOH, high performance, secure replay caches are
difficult to implement, ultimately being limited by the number of write
to persistent storage ops that the system can manage.)
I think you might want to say that "three messages is the minimum for
mutual authentication with neither a replay cache nor a trusted third
party negotiating a key for use during the authentication exchanges."
Or something along those lines.
Of course, you might claim that the TGS exchanges should be added to the
number of messages needed for AP exchanges, but if you re-authenticate
often then you amortize the cost of the TGS exchanges over many AP
I think first and foremost we need authentication protocols to be
secure, while at the same time being algorithm agile.  I think you can
generally manage that in 1.5 round-trips optimistically, more when
optimistic negotiation fails.  And you can do better if you have
something like a KDC that can do negotiation out of band.

@_date: 2008-04-16 10:15:49
@_author: Nicolas Williams 
@_subject: how to read information from RFID equipped credit cards 
Cell phones have that.
The bigger problem is pairing with the local POS (or whatever), which is
where NFC comes in -- the "obvious" thing to do here is to make this
pairing not-really-wireless (e.g., the cell phone could scan a barcode
from the POS, or the POS could scan a barcode displayed by the cell
phone, or both, or any number of variants of this).
Right, it's got to be wireless :)

@_date: 2008-08-08 13:47:01
@_author: Nicolas Williams 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
The PKIX moral equivalent of Kerberos V tickets would be OCSP Responses.
I understand most current browsers support OCSP.
No doubt.

@_date: 2008-08-08 14:33:10
@_author: Nicolas Williams 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
You could store {, } and check matches for false positives
by generating a key with the corresponding seed and then checking for an
exact match -- slow, but rare.  This way you could choose your false
positive rate / table size comfort zone and vary the size of the hash

@_date: 2008-08-08 15:08:57
@_author: Nicolas Williams 
@_subject: OpenID/Debian PRNG/DNS Cache poisoning advisory 
Not that long ago nothing supported OCSP.  If all that's left (ha) is
the CAs then we're in good shape.  (OCSP services can be added without
modifying a CA -- just issue the OCSP Responders their certs and let
them use CRLs are their source of revocation information.)

@_date: 2008-12-05 15:53:25
@_author: Nicolas Williams 
@_subject: Quantum direct communication: secrecy without key distribution 
[I'm guessing that nobody here wants yet another "quatum crypto is snake
oil, no it's not, yes it is, though it has a bright future, no it's not,
..." thread.]
That's not the most serious, obvious flaw in quantum cryptography.
The most obvious flaw is that when we're talking fiber optics the
eavesdropper might as well be a man in the middle, and so...  well, see
the list archive.

@_date: 2008-12-16 12:08:00
@_author: Nicolas Williams 
@_subject: Why the poor uptake of encrypted email? 
The subject is "[w]hy the poor uptake of encrypted email?".
Alec's answer shows that "encrypted email" when at rest is not easy to
Providing a suitable e-mail security solution for the masses strikes me
as more important than providing anonymity to the few people who want or
need it.  Not that you can't have both, unless you want everyone to use
PGP or S/MIME as a way to hide anonymized traffic from non-anonymized

@_date: 2008-12-17 14:35:26
@_author: Nicolas Williams 
@_subject: CPRNGs are still an issue. 
But do beware of becoming something of a luddite w.r.t. entropy sources.
If you can mix seeds into your entropy pool without destroying the
entropy of your pool (and we agree that you can) while adding some of
any entropy in your seeds (and we agree that you can), then why not?
Yes, I saw your other message.  Testing entropy pools and sources is
hard if you want real entropy.  One way to test the pool and its mixing
function is to add and use a hook for supplying test vectors instead of
real entropy for each source.  But to test the operational system, if it
has real entropy sources, is harder.  So you might as well add in a
fixed, manufacture-time seed + time/counter-based salting, as you
suggested.  And you'll still want to test the result, but you can only
apply statistical analysis to the outputs to decide if they're
Having no entropy sources is not a good option for systems where the
threat model requires good entropy sources (e.g., if you want PFS to
prevent compromise of an end-point from compromising pre-compromise
communications).  IMO it's not wise to trivially reject an "all of the
above" approach to entropy gathering.

@_date: 2008-12-18 15:35:44
@_author: Nicolas Williams 
@_subject: Why the poor uptake of encrypted email? 
That's also true for e-mail where the only encryption is in the
transport.  Except that you tend to store your e-mails and not your
phone calls, of course.  But you could always encrypt your filesystem
and not your e-mail itself, and that way avoid all the portability
issues that Alec brought up.

@_date: 2008-02-01 10:56:58
@_author: Nicolas Williams 
@_subject: Gutmann Soundwave Therapy 
I agree wholeheartedly.  I'm trying to fix this too.  But for web stuff,
IPsec won't have a chance for a long time, maybe never.

@_date: 2008-02-01 11:05:38
@_author: Nicolas Williams 
@_subject: Dutch Transport Card Broken 
What, specifically, are you proposing?  Running the web over UDP?
That's the only alternative that I can see short of modifying TCP or
IPsec.  I doubt any of those three will take the web world by storm, but
HTTP over DTLS over UDP would have to be least unlikely, and even then,
I strongly doubt it.
I think we'll just have to deal with those round-trips.  As long as
there be plenty of other, cheaper or more practical ways to improve web
app performance, that's all we're likely to see pursued.

@_date: 2008-02-01 14:28:57
@_author: Nicolas Williams 
@_subject: Dutch Transport Card Broken 
And on top of that web site designers don't want browser dialogs for
HTTP/TLS authentication.

@_date: 2008-02-02 13:07:44
@_author: Nicolas Williams 
@_subject: Dutch Transport Card Broken 
To be fair, the "handbrake" in SFTP isn't -- the clients and servers
should be using async I/O and support interleaving the transfers of many
files concurrently, which should allow the peers to exchange data as
fast as it can be read from disk.
The same is true of NFS, and keep in mind that SFTP is more of a remote
filesystem protocol than a file transfer protocol.
But nobody writes archivers that work asynchronously (or which are
threaded, since, e.g., close(2) has no async equivalent, and is required
to be synchronous in the NFS case).  And nobody writes SFTP clients and
server that work asynchronously.  But, we could, and we should.
And the handbrake in the SSHv2 connection protocol has its rationale as
well (namely to allow interactive sessions to be responsive).  As
described in Peter's paper, it can be turned off, effectively.  It's
most useful when mixing interactive sessions and X11 display forwarding
(and port forwarding which don't involve bulk data transfers).  It's
most useless when doing bulk transfers.  So use separate connections for
bulk transfers.

@_date: 2008-02-04 01:20:59
@_author: Nicolas Williams 
@_subject: Dutch Transport Card Broken 
In the beginning most pages were simple enough that to speak of
"transactional protocol" is almost an exageration.  Web techonologies
grew organically.  Solutions to the various resulting problems will, I
bet, also grow organically.
A complete revamping is probably not in the cards.  But if one should be
then it should not surprise you that I'm all in favor of piercing
abstraction layers.  User authentication should happen that the
application layer, and session crypto should happen at the transport
layer, with everything cryptographically bound up.  In any case we
should re-use what we know works (e.g., ESP/AH for transport session
crypto, IKEv2/TLS/DTLS for key exchange, ...).
Sounds a bit like SCTP, with crypto thrown in.
I thought it was the latency cause by unnecessary round-trips and
expensive key exchange crypto that motivated your proposal.  The cost of
session crypto is probably not as noticeable as that of the latency of
key exchange and authentication.

@_date: 2008-02-04 16:28:10
@_author: Nicolas Williams 
@_subject: Dutch Transport Card Broken 
Proposing something new won't help make that available sooner than SCTP
if that something new, like SCTP, must be implemented in kernel-land.
This is what session resumption is all about, and now that we have a way
to do it without server-side state (RFC4507) there should be no more
If the latency of multiple key exchanges is the issue then we should
push for deployment of RFC4507 before we go push for a brand new
transport protocol.
If I understand what you mean then the ticket in RFC4507 is just that.

@_date: 2008-01-29 15:37:26
@_author: Nicolas Williams 
@_subject: two-person login? 
I think you missed John's point, which is that two-person *login* says
*nothing* about what happens once logged in -- logging in enables
arbitrary subsequent transactions that may not require two people to
What if one of the persons leaves the other alone to do whatever they
wish with the system?  Or are the two persons chained to each other?
(And even then, there's no guarantee that they are both conscious at the
same time, that no third person shows up and knocks them out *after*
they've logged in, ...)
When you force two people to participate on a *per-transaction* basis
then you probably get both of them to pay attention, though such schemes
might not scale to thousands, or even hundreds of transactions per-team,

@_date: 2008-01-31 16:46:52
@_author: Nicolas Williams 
@_subject: Dutch Transport Card Broken 
I don't have one that exists today and is practical.  But we can
certainly imagine possible ways to improve this situation: move parts of
TLS into TCP and/or IPsec.  There are proposals that come close enough
to this (see the last IETF SAAG meeting's proceedings, see the IETF BTNS
WG) that it's not too farfetched, but for web stuff I just don't think
they're remotely likely.
Prior to the advent of AJAX-like web design patterns the most noticeable
latency in web apps was in the server (for dynamic content) and the
client (re-rendering the whole page on every click).  Applying GUI
lessons to the web (asynchrony!  callbacks/closures!) fixed that.
TLS was not to blame.
TLS probably still isn't to blame for whatever latency users might be
annoyed by in web apps.
It's *much* easier to look for improvements in the app layer first given
that web app updates are much easier to deploy than TLS (which in turn
is much easier to deploy than changes to TCP or IPsec).

@_date: 2008-07-10 13:22:07
@_author: Nicolas Williams 
@_subject: how bad is IPETEE? 
I did miss it.  Thanks for the link.  I don't think in-band key exchange
is desirable here, but, you never know what will triumph in the
Connection latching, which is the BTNS WG equivalent of 'IPETEE', but
much simpler, is in the IESG's hands now.

@_date: 2008-07-10 15:26:06
@_author: Nicolas Williams 
@_subject: how bad is IPETEE? 
Indeed.  But it's as quiet as the old list :/
Seriously, the work of the BTNS WG is, IMO, crucial to the use of IPsec
as an end-to-end solution (as opposed to as a VPN solution, for which
IPsec is already pretty darned good).  If you care, then please
participate, or even better, implement.
That anyone is working on IPETEE indicates that end-to-end IPsec
solutions are desired.  The in-band nature of the IPETEE key exchange
indicates, to me, a dislike of IKE, or perhaps unawareness of BTNS WG
(man, the WG's name doesn't reflect very well what it does), or perhaps
a misunderstanding of IPsec.

@_date: 2008-07-11 12:15:20
@_author: Nicolas Williams 
@_subject: how bad is IPETEE? 
Note that this is not all that bad because many apps can do
authentication at the application layer, and if you add channel binding
then you can leave session crypto to IPsec while avoiding MITMs (they
get flushed by channel binding).
This is the premise of BTNS + connection latching.  W/o channel binding
it's better than nothing, though not much.  W/ channel binding it should
be much easier to deploy (beyond software updates) than plain IPsec with
similar security guarantees.

@_date: 2008-07-23 20:37:36
@_author: Nicolas Williams 
@_subject: The PKC-only application security model ... 
Advice on how to generate self-signed certs for this purpose would be
good for an FYI, or even a BCP.  I don't think we need extensions to any
protocols that support PKI to support bare PK (though some protocols
have both, e.g., IKE).

@_date: 2008-06-30 11:50:37
@_author: Nicolas Williams 
@_subject: The wisdom of the ill informed 
Putting aside the fact that cryptographers aren't custodians of
anything, it's all about social institutions.
There are well-attended conferences, papers published online and in many
journals, etcetera.  So it's not so difficult for people who don't know
anything about security and crypto to eventually figure out who does, in
the process also learning who else knows who the experts are.
For example, in the IETF there's an institutional structure that makes
finding out who to ask relatively simple.  Large corporations tend to
have some experts in house, even if they are only expert in finding the
real experts.
We (society) have new experts joining the field, with very low barriers
to entry (financial and political barriers to entry are minimal -- it's
all about brain power), and diversity amongst the existing experts.
There's no major personal gain to be had, besides fame, and too much
diversity and openness for anyone to have a prayer of manipulating the
field undetected for too long.
When it comes to expertise in crypto, Quis custodiet ipsos custodes
seems like a relatively simple problem.  I'm sure it's much, much more
difficult a problem for, say, police departments, financial
organizations, intelligence organizations, etc...

@_date: 2008-06-30 14:08:05
@_author: Nicolas Williams 
@_subject: The wisdom of the ill informed 
What does that have to do with anything?  Expert != knowledge cast in
The above does not really refute what I wrote.  It takes effort to
figure out who's an expert.  But I believe that the situation w.r.t.
crypto is similar to that in science (cold fusion frauds were identified
rather quickly, were they not?) and better than in medicine (precisely
because there is not much commercial incentive to fraud here; there is
incentive for intelligence organizations to interfere, I suppose, but
here the risk of getting caught is high and the potential cost of
getting caught high as well).
I thought we were talking about cryptographers, not marketing
departments, market dynamics, ...  If you want to include the latter in
"custodes" then there is a clear custody hierarchy: the community of
experts in the field is above individual implementors.  Thus we have
reports of snake oil on this list, on various blogs, etc...
So we're back to "quis custodiet ipsos custodes?"  Excluding marketing
here is the right thing to do (see above).  Which brings us back to my
In my experience market realities have much more to do with what gets
deployed than the current state of the art does; never mind who the
experts are.  "We'd love to deploy technology X, but in our
heterogeneous network only one quarter of the vendors support X, and
only if we upgrade  systems, which requires QA testing,
which..." -- surely you've run into that sort of situation, amongst
others.  Legacy, broken code dwarfs snake oil in terms of deployment;
legacy != snake oil -- we're allowed to learn, as you yourself point

@_date: 2008-05-06 14:05:24
@_author: Nicolas Williams 
@_subject: User interface, security, and "simplicity" 
"Connection latching" and "connection-oriented" IPsec APIs can address
this problem.
Solaris, and at least one other IPsec implementation (OpenSwan?  I
forget) makes sure that all packets for any one TCP connection (or UDP
"connection") are protected (or bypassed) the same way during their
lifetime.  "The same way" -> by similar SAs, that is, SAs with the same
algorithms, same peers, and various other parameters.
A WGLC is about to start in the IETF BTNS WG on an I-D that describes

@_date: 2008-11-17 15:54:28
@_author: Nicolas Williams 
@_subject: Bitcoin P2P e-cash paper 
How do identities help?  It's supposed to be anonymous cash, right?  And
say you identify a double spender after the fact, then what?  Perhaps
you're looking at a disposable ID.  Or perhaps you can't chase them
Double spend detection needs to be real-time or near real-time.

@_date: 2008-09-09 15:23:09
@_author: nico 
@_subject: Let's be paranoid about CSS (cascaded style sheet) as an 
As the service provider you have little choice but to assume local
security on the client side IF you want to allow clients that you don't
control (and you don't really have a choice about _that_; most SPs don't
I don't see how to mitigate all possible attacks you can imagine that
involve a compromised client.
You could say the same thing about AJAX, ...  This train left the
station long ago, and I was on it then along with everyone else.

@_date: 2008-09-10 14:42:19
@_author: Nicolas Williams 
@_subject: once more, with feeling. 
Or maybe there's a civil liability law issue that causes the market to
fail in this instance.

@_date: 2008-09-23 12:14:47
@_author: Nicolas Williams 
@_subject: once more, with feeling. 
I've a hard time believing that this is the major obstacle.  We all use
credit cards all the time -- apparently that's as good a "strong binding
between [credit] cards and true names" and as the government needs.  (If
not then throw in cameras at many intersections and along freeways, add
in license plate OCR, and you can tie things together easily enough.
Wasn't that a worry in another recent thread here?)
More likely there are other problems.
First, there's a business model problem.  Every one wants in: the cell
phone manufacturer, the software developer, the network operators, and
the banks.  With everyone wanting a cut of every transaction done
through cell phones the result would likely be too expensive to compete
with credit cards, even after accounting for the cost of credit card
fraud.  Credit card fraud and online security, in any case, are pretty
low on the list of banking troubles these past few weeks, and not
without reason!
Second, there's going to be standard issues.
Third the nfc technology has to be commoditized.
Fourth there's cost of doing an initial rollout of the POS nfc
terminals and building momentum for the product.  Once momentum is there
you're done.  And there's risk too -- if you fail you lose your
Touble is: what happens if the user's cell phone is stolen?

@_date: 2009-08-25 13:36:46
@_author: Nicolas Williams 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management, part 2: Tahoe-LAFS is like encrypted git) 
Many good replies have been given already.  Here's a few more reasons to
want "pluggability" in the protocol:
 - Yes, we "want to design the protocol once and be done with" the hard
   parts of the design problem that we can reasonably expect to have to
   do only once.  Having to do things only once is not just "cool".
 - Pluggability at the protocol layer enable pluggability in the
   implementations.  A pluggable design does not imply open plug-in
   interfaces, but a pluggable design does imply highly localized
   development of new plug-ins.
 - It's a good idea to promote careful thought about the future,
   precisely what designing a pluggable protocol does and requires.
   We may get it wrong (e.g., the SSHv2 alg nego protocol has quirks,
   some of which were discovered when we worked on RFC4462), but the
   result is likely to be much better than not putting much or any such
   thought into it.
If the protocol designers and the implementors get their respective
designs right, the best case scenario is that switching from one
cryptographic algorithm to another requires less effort in the pluggable
case than in the non-pluggable case.  Specifically, specification and
implementation of new crypto algs can be localized -- no existing
specification nor code need change!  Yes, new SW must still get
deployed, and that's pretty hard, but it helps to make it easier to
develop that SW.

@_date: 2009-02-12 09:54:29
@_author: Nicolas Williams 
@_subject: Property RIghts in Keys 
Private and secret keys had better be property.  Public keys are...
well, *public*, and CA public keys really, really had better be public,
so I'm as perplexed as you.
Most likely this is just a case of lawyers gone wild.  Too bad a TV show
or DVD product based on that idea wouldn't be successful.
Really, really wild lawyers.  (Or maybe not so wild, in the U.S.,
depending on what happens in the Lori Drew case.)

@_date: 2009-01-20 15:58:42
@_author: Nicolas Williams 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
As Jeff Hutzelman suggested recently, inspired by the SSHv2 CBC mode
vulnerability, hash algorithm agility for PKI really means having more
than one signature, each using a different hash, in each certificate;
this enlarges certificates.  Alternatively, it needs to be possible to
select what certificate to present to a peer based on an algorithm
negotiation; this tends to mean adding round-trips to our protocols.

@_date: 2009-01-26 16:19:45
@_author: Nicolas Williams 
@_subject: Obama's secure PDA 
[OT for this list, I know.]
It seems that the President's lawyers believe that IM is covered by the
Presidential Records Act and shouldn't be used in the White House:
One possible workaround might be to allow WH staff to _receive_ IMs, and
follow twitting from outside the WH, but not respond to any of it except
by phone.  (Even phone calls, though not recorded, are dangerous to the
WH since there is a record of calls made and taken.)
Of course, if there's nothing to hide, then, why not just use IM and be
done?  The legal advice seems sounds, but it's just advice.  Obama and
his staff could easily use and archive IMs and avoid embarrassment by,
well, keeping discussions above board.

@_date: 2009-01-28 17:52:37
@_author: Nicolas Williams 
@_subject: Proof of Work -> atmospheric carbon 
For some definition of "digital coin."
An alternative design where all coins are double-spend checked against
on-line infrastructure belonging to the issuer don't have this
constraint.  Though they have different properties.  For example,
anonymity might then depend on trusting mixmaster-type networks to
exchange coins the issuer knows you have for coins that the issuer
doesn't know you have, but that might make anonymity entirely
impractical.  But then, how practical are POW coins anyways?
I suspect most people in the formal sectors of most economies would
gladly live with digital credit/bank cards most of the time and to heck
with digital coins.

@_date: 2009-01-30 18:26:30
@_author: Nicolas Williams 
@_subject: full-disk subversion standards released 
Plus: that's a lot of code to read!  A single person can't hope to
understand the tens of millions of lines of code that make up the
software (and firmware, and hardware!) that they use every day on a
single system.  Note: that's not to say that open source doesn't have
advantages over proprietary source.

@_date: 2009-07-01 13:06:05
@_author: Nicolas Williams 
@_subject: password safes for mac 
Indeed.  IIRC, the Mac keychain uses your login password as its passphrase
by default, which means that to keep your keychain unlocked requires
either keeping the password around (bad), keeping the keys in cleartext
around (worse?), or prompting for the password/passphrase every time
they are needed (unusable).
This applies to ssh-agent, the GNOME keychain, etcetera.  It also
applies to distributed authentication systems with password-based
options, like Kerberos.
ISTM that keeping the password around (preferably in mlocked memory,
and, to be sure, with swap encrypted with ephemeral keys) is probably
the better solution.  Of course, the keys themselves have to be handled
with care too.

@_date: 2009-07-01 13:10:35
@_author: Nicolas Williams 
@_subject: password safes for mac 
I should add that a hardware token/smartcard, would be even better, but
the same issue arises: keep it logged in, or prompt for the PIN every
time it's needed?  If you keep it logged in then an attacker who
compromises the system will get to use the token, which I bet in
practice is only moderately less bad than compromising the keys

@_date: 2009-07-14 16:23:21
@_author: Nicolas Williams 
@_subject: HSM outage causes root CA key loss 
Not a security problem?  Well, if you have a way to do authenticated
trust anchor distribution that doesn't depend on the lost CA, then sure,
it's not a security problem.  But that's just not likely, or at least
there's no standard for authenticated TA distribution, yet.  If you can
do unauthenticated TA distribution without much trouble (as opposed to
by, say, having to physically visit every host), then chances are you
have no security to begin with.
If there was such a standard you'd want to make real sure that you have
separate keys for TA distribution than for your CA, with similar
physical and other security safeguards.
This goes to show that we do need a TA distribution protocol (not for
the web, mind you), and it needs to use PKI -- a distinct, but related
PKI.  As long as both sets of hardware tokens don't die simultaneously,
then you'll be OK.  Add multiple CAs for TA distro and you get more
The only other ways are: distribute the new CA certs, and/or use OCSP
(which must use a different cert than the CA).  OCSP is the better
answer, if you can get all apps to use it.

@_date: 2009-07-21 19:15:02
@_author: Nicolas Williams 
@_subject: Fast MAC algorithms? 
I've an application that is performance sensitive, which can re-key very
often (say, every 15 minutes, or more often still), and where no MAC is
accepted after 2 key changes.  In one case the entity generating a MAC
is also the only entity validating the MAC (but the MAC does go on the
wire).  I'm interested in any MAC algorithms which are fast, and it
doesn't matter how strong they are, as long as they meet some reasonable
lower bound on work factor to forge a MAC or recover the key, say 2^64,
given current cryptanalysis, plus a comfort factor.
On the other hand, practical MAC forgery / key recovery attacks would
completely break the security of this application.  So stronger MACs
would have to be available as well, as a performance vs. security
Key length is not an issue.  Having to confound the MAC by adding a
nonce is an acceptable and desirable requirement.  MAC and nonce length
are also not an issue (128-bits is acceptable).  Implementation of any
MAC algorithms for this application must be in software; parallelization
is not really an option.  Algorithm agility is also not a problem, and
certainly desirable.
I see many MAC algorithms out there: HMAC, NMAC, OMAC, PMAC, CBC-MAC,
UMAC, ...  And, of course, AEAD ciphers that can be used for
authentication only, (AES-GCM, AES-CCM, Helix/Phelix, ...).  What I'm
interested in is a comprehensive table showing relative strength under
current cryptanalysis and relative performance.  I suspect there's no
such thing, sadly.  UMAC and HMAC-SHA-1 seem like obvious default
I also see papers like "Differential-Linear Attacks against the Stream
Cipher Phelix", by Wu and Preneel.  Wu and Preneel declare Phelix to be
insecure because if you violate the requirement that nonces not be
reused then the key can be recovered rather easily.  Helix seems to be
stronger than Phelix in this regard, even though the opposite was
intended.  That makes Phelix and Helix seem likely to be in for further
weakening.  For uses such as mine (see above), such weaknesses are fine

@_date: 2009-07-22 00:43:28
@_author: Nicolas Williams 
@_subject: Fast MAC algorithms? 
Oh, I agree in general.  As far as new apps and standards work I'd make
HMAC-SHA-256 or AES, in an AEAD cipher mode, REQUIRED to implement and
the default.
But that's not what I'm looking for here.  I'm looking for the fastest
MACs, with extreme security considerations (e.g., "warning, warning!
must rekey every 10 minutes") being possibly OK, depending on just how
extreme -- the sort of algorithm that one would not make REQUIRED to
implement, but which nonetheless one might use in some environments
simply because it's fast.
For example, many people use arcfour in SSHv2 over AES because arcfour
is faster than AES.  The SSHv2 AES-based ciphers ought to be RTI and
default choice, IMO, but that doesn't mean arcfour should not be
In the crypto world one never designs weak-but-fast algorithms on
purpose, only strong-and-preferably-fast ones.  And when an algorithm is
successfully attacked it's usually deprecated, put in the ash heap of
history.  But there is a place for weak-but-fast algos, as long as
they're not too weak.  Any weak-but-fast algos we might have now tend to
be old algos that turned out to be weaker than designed to be, and new
ones tend to be slower because resistance against new attacks tends to
require more computation.  I realized this would make my question seem a
bit pointless, but hoped I might get a surprising answer :(

@_date: 2009-07-23 10:45:25
@_author: Nicolas Williams 
@_subject: Fast MAC algorithms? 
How much NIC hardware does both, ESP/AH and TCP offload?  My guess: not
much.  A shame, that.
Once you've gotten a packet off the NIC to do ESP/AH processing, you've
lost the opportunity to use TOE.

@_date: 2009-06-30 11:26:06
@_author: Nicolas Williams 
@_subject: password safes for mac 
============================== START ==============================
Suppose a user's Kerberos credentials are about to expire.  What to do?
If Kerberos TGT renewable lifetime is set long enough then chances are
very good that the user will have to unlock their screen sometime within
a few hours of TGT expiration.  But what if TGT renewable lifetime is
set very short?  Or if the user doesn't lock then unlock their screen in
time?  You have to prompt the user.  But this could be an asynchronous
prompt coming from deep within the kernel (think secure NFS) -- not
impossible, but certainly tricky to implement.  And what if the user
were not using a graphical login (stop thinking Mac all the time :)?
You can't do async prompts on text-based consoles (though you can do
async warnings).
You can see where the temptation to cache the user's password comes
The password can't be cached in encrypted form either (it could be
cached in string2key() form, but that's password-equivalent).  It could
be cached in scrambled form, or encrypted with a key that's stored in
cleartext or in a hardware token (think TPM), but ultimately it'd be
extractable by any sufficiently privileged process.  In any case, the
password must not end up in cleartext on unencrypted swap, and
preferably not on swap at all.
FWIW, Solaris doesn't cache the user's password.

@_date: 2009-11-02 10:39:43
@_author: Nicolas Williams 
@_subject: Truncating SHA2 hashes vs shortening a MAC for ZFS Crypto 
[Not speaking for Darren...]  No, the requirement to use a strong hash
remains, but since the hash would be there primarily for protection
against errors, I don't the requirement for a strong hash is really
Users won't actually get the data keys, only the data key wrapping keys.
Users who can read the disk and find the wrapped keys and know the
wrapping keys can find the actual data keys, of course, but add in a
host key that the user can't read and now the user cannot recover their
data keys.  One goal is to protect a system against its users, but
another is to protect user data against maliciou modification by anyone
else.  A MAC provides the first kind of protection if the user can't
access the data keys, and a MAC provides the second kind of protection
if the data keys can be kept secret.
I think we have to assume that an attacker can write to any part of the
pool, including the Merkle tree roots.  It'd be odd to assume that the
attacker can write anywhere but there -- there's nothing to make it so!
I.e., we have to at least authenticate the Merkle tree roots.  That
still means depending on collision resistance of the hash function for
security.  If we authenticate every block we don't have that dependence
(I'll come back to this).
The interesting thing here is that we want the hash _and_ the MAC, not
just the MAC.  The reason is that we want block pointers (which include
the {IV, MAC, hash} for the block being pointed to) to be visible to the
layer below the filesystem, so that we can scrub/resilver and evacuate
devices from a pool (meaning: re-write all the block pointers point to
blocks on the evacuated devices so that they point elsewhere) even
without having the data keys at hand (more on this below).
We could MAC the Merkle tree roots alone, thus alleviating the space
situation in the block pointer structure (and also saving precious CPU
cycles).  But interestingly we wouldn't alleviate it that much!  We need
to store a 96-bit IV, and if we don't MAC every block then we'll want
the strongest hash we can use, so we'll need at least another 256 bits,
for a total of 352 bits of the 384 that we have to play with.  Whereas
if we MAC every block we might store a 96-bit IV, a 128-bit
authentication tag and 160-bit hash, using all 384 bits.
You get more collision resistance from an N-bit MAC than from a hash of
the same length.  That's because in the MAC case the forger can't check
the forgery without knowing the key, while in the hash case the attacker
can verify that some contents collides with another's hash.  In the MAC
case an attacker that hasn't broken the MAC/key must wait until the
system reads the modified block(s) to determine if his/her guess was
correct.  So a 128-bit MAC provides more protection than a 160-bit hash,
and about as much as a 256-bit hash.  If we remove the MAC then the hash
has to grow longer to compensate, thus the space gained by not including
the MAC is minimal, possibly zero.
If we MAC every block then we don't need the hash function for security
purposes: its main role would still be to provide integrity protection
against errors for scrubbing and resilvering when keys are unavailable.
The hash would continue to provide end-to-end integrity protection
against errors.  The hash would add _some_ security value though: not
only must an attacker seeking to modify data forge the right MAC for the
new contents, they must also find a hash collision (and they must do
this all the way up the Merkle tree).
For dedup you want to compare block contents on hash equality.  That's
what ZFS will do.  That defeats your attack on dedup.
The block address can't be used: a blkptr_t actually stores 1-3 actual
block addresses, but these can change if a block is relocated.
I think the notion that all encrypted/authenticated filesystems need not
be logged in in order to perform certain pool operations is both, very
useful and rather odd.  Odd because once a filesystem is logged in, an
all-powerful administrator could either learn its keys or, if the system
were using a token to avoid this, the admin could abuse those keys --
the sysadmin remains so powerful that trying to protect users against
the sysadmin seems like a waste of resources.  But the ability to
perform some pool operations without having the keys is still useful:
the sysadmin is a user, after all, and might not be around.  Think of a
SAN operator reconfiguring pools without having to have the keys to the
datasets on those pools.

@_date: 2009-11-03 12:21:08
@_author: Nicolas Williams 
@_subject: Truncating SHA2 hashes vs shortening a MAC for ZFS Crypto 
Exactly.  I proposed to Darren that he MAC only the Merkle tree roots,
and he rejected that as too big a change at this point.  That leaves him
with the MAC/hash size trade-off.  Therefore my recommendation then is
to truncate only the hash.  Yes, that means that you'll want to enable
dedup block match verification.
Note that blocks can be relocated when dataset keys are not available,
which means the IV cannot be constructed from block addresses, for
Interesting.  If ZFS could make sure no blocks exist in a pool from more
than 2^64-1 transactions ago[*], then the txg + a 32-bit per-transaction
block write counter would suffice.  That way Darren would have to store
just 32 bits of the IV.  That way he'd have 352 bits to work with, and
then it'd be possible to have a 128-bit authentication tag and a 224-bit
And if later Darren is able to switch to MACing the Merkle roots then
he'd have 352 bits for a hash.
[*] Transactions happen a fairly low rate of about a one every few
    seconds.  At that rate 2^64 transactions means over a trillion years
    before the txg wraps (half a trillion if the rate is 1/sec).
    Therefore ZFS does not need a cleaner service to re-write really old
    blocks.
    If 32 bits for per-transaction block write counters is too low, then
    transaction rate could increase (and arguably would have to
    anyways); even with the fastest flash 2^32 IOPS seems a long way
    away, and there should be enough CPU to jack up the transaction rate
    by then to compensate.  Let's suppose that we end up with a txg
    per-microsecond: then we get down to a still comfy (though starting
    to push it) 584,542 years before we wrap.

@_date: 2009-11-03 13:36:08
@_author: Nicolas Williams 
@_subject: Truncating SHA2 hashes vs shortening a MAC for ZFS Crypto 
Not really.  You can change or not change keys, and still, txg+32-bit
counter will give you enough.
Heh.  txg + 32-bit counter == 96-bit IVs sounds like the way to go.

@_date: 2009-11-23 16:35:07
@_author: Nicolas Williams 
@_subject: TLS break 
Not to sound like a broken record, and not to plug work I've done[*],
but IMO the best tool to apply to this situation, both, to understand
the problem, produce solutions, and to analyze proposed solutions, is
"channel binding" [0].
Channel binding should be considered whenever one combines two (or more)
two-peer end-to-end security protocols.
In this case two instances of the same protocol are combined, with an
outer/old TLS connection and an inner/new connection negotiated with the
protection of the outer one.  That last part, "negotiated with the
protection of the outer one" may have led people to believe that the
combination technique was safe.  However, applying channel binding as an
analysis technique would have made it clear that that technique was
vulnerable to MITM attacks.
What channel binding does not give you as an analysis technique is
exploit ideas beyond "try being an MITM".
The nice thing about channel binding is that it allows you to avoid
having to analyze the combined protocols in order to understand whether
the combination is safe.  As a design technique all you need to do is
this: a) design a cryptographically secure "name" for an estabilished
"channel" of the outer protocol, b) design a cryptographically secure
facility in the inner protocol for veryfying that the applications at
both ends observe the same outer channel, c) feed (a) to (b), and if the
two protocols are secure and (a) and (b) are secure then you'll have a
secure combination.
[*] I've written an RFC on the topic, but the idea isn't mine -- it
    goes as far back as 1992 in IETF RFCs.  I'm not promoting channel
    binding because I had anything to do with it, but because it's a
    useful technique in combining certain cryptographic protocols that I
    think should be more widely understood and applied.
[0] On the Use of Channel Bindings to Secure Channels, RFC5056.

@_date: 2009-10-19 10:24:40
@_author: Nicolas Williams 
@_subject: Possibly questionable security decisions in DNS root management 
Getting DNSSEC deployed with sufficiently large KSKs should be priority If 90 days for the 1024-bit ZSKs is too long, that can always be
reduced, or the ZSK keylength be increased -- we too can squeeze factors
of 10 from various places.  In the early days of DNSSEC deployment the
opportunities for causing damage by breaking a ZSK will be relatively
meager.  We have time to get this right; this issue does not strike me
as urgent.
OTOH, will we be able to detect breaks?  A clever attacker will use
breaks in very subtle ways.  A ZSK break would be bad, but something
that could be dealt with, *if* we knew it'd happened.  The potential
difficulty of detecting attacks is probably the best reason for seeking
stronger keys well ahead of time.

@_date: 2009-09-04 14:58:10
@_author: Nicolas Williams 
@_subject: RNG using AES CTR as encryption algorithm 
They are trivially constructed from the test vectors for AES in ECB
mode (just as counter mode is trivially constructed from ECB mode).

@_date: 2009-09-04 15:09:23
@_author: Nicolas Williams 
@_subject: Client Certificate UI for Chrome? 
Well, if you're willing to reserve screen real estate, keyboard key
combinations, and so on, with said reserved screen space used to
indicate unambiguously the nature of other things displayed, and
reserved input combinations used to trigger trusted software paths, then
yes, you can solve that problem.  That's the premise of "trusted
desktops", at any rate.  There are caveats, like just how large the TCB
becomes (including parts of the browser), the complexity of the trusted
information to be presented to users versus the limited amount of screen
real estate available to convey it, the need to train users to
understand the concept of trusted desktops, no fullscreen apps can be
allowed, accessibility issues, it all falls apart if the TCB is
compromised, ...

@_date: 2009-09-30 11:42:40
@_author: Nicolas Williams 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management, part 2: Tahoe-LAFS is like encrypted git) 
"AES-128 in CBC mode with a unique IV made from /dev/urandom" is
manifestly not the issue of the day.  The issue is hash function
strength.  So when would you worry about MD5?  SHA-1?  By your own
admission MD5 has already been fatally wounded and SHA-1 is headed
that way.
We don't have a decade to replace MD5.  We've had a long time to replace
MD5, and even SHA-1 already, but we haven't done it yet.  The reason is
simple: there's more to it than you've stated.  Specifically, for
example, you ignored protocol update development (you assumed 1 new
protocol per-year, but this says nothing about how long it takes to,
say, update TLS) and deployment issues completely, and you supposed that
software development happens at a consistent, fast clip throughout.
Software development and deployment are usually constrained by legacy
and customer behavior, as well as resource availability, all of which
varies enormously.  Protocol upgrade development, for example, is harder
than you might think (I'm guessing though, since you didn't address that
issue).  Complexity exists outside protocol.  This is why we must plan
ahead and make reasonable trade-offs.  Devising protocols that make
upgrade easier is important, supposing that they actually help with the
deployment issues (cue your argument that they do not).
I'm OK with making up numbers for the sake of argument.  But you have to
make up all the relevent numbers.  Then we can plug in real data where
we have it, argue about the other numbers, ...
We don't have crystal balls.  We don't really know what's in store for
AES, for example.  Conservative design says we should have a way to
deploy alternatives in a reasonably short period of time.
You and Peter are clearly biased against TLS 1.2 specifically, and
algorithm negotiation generally.  It's also clear that you're outside
the IETF consensus on both matters _for now_.  IMO you'll need to make
better arguments, or wait enough time to be proven right by events, in
order to change that consensus.

@_date: 2010-03-16 11:45:08
@_author: Nicolas Williams 
@_subject: 1024 bit RSA cracked? 
My initial reaction from reading only the abstract and parts of the
introduction is that the authors are talking about attacking hardware
that implements RSA (say, a cell phone) by injecting faults into the
system via the power supply of the device.
This isn't really applicable to server hardware in a data center (where
the power, presumably, will be conditioned and physical security will be
provided, also presumably) but this attack is definitely applicable to
portable devices -- laptops, mobiles, smartcards.
They're not the first ones to show that!  Side-channel attacks have been
around for a while now.  It's not just the algorithms, but the machine
executing them and its physical characteristics that matter.

@_date: 2010-03-23 10:42:38
@_author: Nicolas Williams 
@_subject: "Against Rekeying" 
I fully agree with EKR on this: if you're using block ciphers with
128-bit block sizes in suitable modes and with suitably strong key
exchange, then there's really no need to ever (for a definition of
"ever" relative to common "connection" lifetimes for whatever protocols
you have in mind, such as months) re-key for cryptographic reasons.
There may be reasons for re-keying, but the commonly given one that a
given key gets weak over time from use (meaning the attacker can gather
ciphertexts) and just the passage of time (during which an attacker
might brute force it) does not apply to modern crypto.
Ensuring that a protocol that uses modern crypto also supports re-keying
only complicates the protocol, which adds to the potential for bugs.
Consider SSHv2: popular implementations of the server do privilege
separation, but after successful login there's the potential for having
to do re-keys that require privilege (e.g., if you're using SSHv2 w/
GSS-API key exchange), which complicates privilege separation.  But for
that wrinkle the only post-login privsep complications are: logout
processing (auditing, ...), and utmpx processing (if you want tty
channels to appear in w(1) output; this could always be handled in ways
that are not specific to sshd).  What a pain!  (OTOH, the ability
delegate fresh GSS credentials via re-keying is useful.)

@_date: 2010-03-23 14:51:41
@_author: Nicolas Williams 
@_subject: "Against Rekeying" 
I forgot to mention that I was referring to session keys for on-the-wire
protocols.  For data storage I think re-keying is easier to justify.
Also, there is a strong argument for changing ephemeral session keys for
long sessions, made by Charlie Kaufman on EKRs blog post: to limit
disclosure of earlier ciphertexts resulting from future compromises.
However, I think that argument can be answered by changing session keys
without re-keying in the SSHv2 and TLS re-negotiation senses.  (Changing
session keys in such a way would not be trivial, but it may well be
simpler than the alternative.  I've only got, in my mind, a sketch of
how it'd work.)

@_date: 2010-03-25 11:07:55
@_author: Nicolas Williams 
@_subject: "Against Rekeying" 
It would have sufficed to bind the new and old channels.  In fact, that
is pretty much the actual solution.
Channel binding is one tool that simplifies the design and analysis of
composable secure protocols.  Had channel binding been used to analyze
TLS re-negotiation earlier the bug would have been obvious earlier as
well.  Proof of that last statement is in the pudding: Martin Rex
independently found the bug when reasoning about channel binding to TLS
channels in the face of re-negotiation; once he started down that path
he found the vulnerability promptly.
(There are several champions of the channel binding technique who could
and should have noticed the TLS bug earlier.  I myself simply took the
security of TLS for granted; I should have been more skeptical.  I
suspect that what happened, ultimately, is that TLS re-negotiation was
an afterthought, barely mentioned in the TLS 1.2 RFC and barely used,
therefore many experts were simply not conscious enough of its existence
to care.  Martin was quite conscious of it while also analyzing a
tangential channel binding proposal.)

@_date: 2010-03-26 12:02:35
@_author: Nicolas Williams 
@_subject: "Against Rekeying" 
I made much the same point, but just so we're clear, SSHv2 re-keying has
been interoperating widely since 2005.  (I was at Connectathon, and
while the details of Cthon testing are proprietary, I can generalize and
tell you that interop in this area was very good.)

@_date: 2010-03-26 18:44:59
@_author: Nicolas Williams 
@_subject: "Against Rekeying" 
Several key ones, including SunSSH.  I'd have to go ask permission in
order to disclose, since Connectathon results are private, IIRC.  Also,
it's been five years, so some of the information has fallen off my
