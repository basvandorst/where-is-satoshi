
@_date: 2001-11-21 13:31:16
@_author: Kent Borg 
@_subject: Shades of FV's Nathaniel Borenstein: Carnivore's "Magic Lantern" 
I can imagine an arms race between the Feds and anti-virus-types, that
is until the anti-virus programs are strong-armed one way or the other
into backing down.  I am certain that will happen, either behind the
scenes or by public law.
I think you are toast if you are sitting at a PC and the Feds ~really~
want to catch your keystrokes.  That is, if the Feds are acting
competently.  They might be coy with their good keyloggers to keep
samizdat word of their details from getting out.  They might save the
good stuff for important targets.
Alternatively, to move to a physical analogy, instead of leaving a
telltale thread on your door and trying to spot intruders that way,
you might instead invest in good locks in the first place.  That is,
to use a reasonably secure operating system.  At risk of starting an
OS war, a well managed Linux box is going to be pretty secure.
Or, for a practical example, I am typing this on a Linux notebook that
mostly is obscured behind firewalls.  If I keep damn Javascript OFF
and don't launch viruses that might be sent to me, and don't reuse
passwords between here and an unsecure computer, I think they are
going to have a very hard time cracking in without my knowing.
This could change, however, if the son-of-DMCA passes; it outlaws
Linux (and all other open source software).
-kb, the Kent who points out that even Linux can be broken if the Feds
manage to embed their spyware in the BIOS.

@_date: 2002-01-10 08:49:51
@_author: Kent Borg 
@_subject: Hackers Targeting Home Computers 
But that is an annoying limitation to begin with--and not just for
people trying to be the next Yahoo.
One of the things that makes the internet is cool that an arbitrary
packet can be sent from one arbitrary IP address to another arbitrary
IP address.  ISPs with "no servers" requirements mostly reduce the
internet to "you may browse the web".  There is a difference between
the internet and the world wide web!, we need to keep reminding
ourselves of that and explaining it to those who don't know.
I run my own "server" and most of what happens there is an e-mail
server and an sshd that I log into.  By running my own e-mail server I
can have e-mail selectively forward to my Palm VII, I can have my
numeric pager poked to let me know my Palm has e-mail.  If I couldn't
run my own server I would have to poll someone else's, and I couldn't
control my own addresses (my wife does personal e-mail through that
box too).
As manufacturers start to assume that RJ-45 jacks that connect to the
internet are common, there are all kinds of cool things that become
possible, but many would technically be servers.  Hell, we currently
have remote Oregon Scientific thermometers at home.  I think it would
be neat to have them connected to the internet.  That way I could look
at them from work--but also from the living room via my Palm VII.
If one thinks of the internet as a universal digital connection
between "stuff" the ability to run "servers" is crucial.
-kb, the Kent who is in favor of policing bad behavior, but who
opposes bans on flexibility in an attempt to prevent bad behavior.

@_date: 2013-12-04 09:03:31
@_author: Kent Borg 
@_subject: [Cryptography] Kindle as crypto hardware 
I recently bought a crazy cheap Android phone from a company in China (Hong Kong?): geekbuying.com
The phone I bought has since fallen to under a $100.
It came with only the open source apps that are part of Android (no maps, for example, which is fine with me) and only a couple other custom apps, I have installed very little more, and with the radios off, it looks like I have over a month of idle battery life.  Even this is only charging the battery to 90% to try to conserve its total life span.
I have never put a SIM in either of its dual slots. I have never directly connected it to the internet.  (This policy was before Snowden and Schneier stuff publicized such precautions, but it made sense to me.)
Unfortunately, when I counted the number of different passwords I have to enter to sync and back up its data, it is a lot, too many for a civilian.  But the result is I don't think it is the weak link in my password scheme.
To use it requires my entering a longish password to unlock the phone and another longish password to decrypt the key database. This is cumbersome on a little screen, but it is portable, much smaller than a Kindle, and the smaller screen is probably more suited to use in public. I added it to the bag I use as a purse and have with me mostly always. I don't have full control over its software, but one likely could for a lot less effort than breaking into a Kindle.  (The manufacturer likely isn't going to fight you as Amazon would.)  Instead I rely on keeping it mostly incommunicado.
Aren't there some explicitly open source phones finally popping up? They might be a cleaner starting point.

@_date: 2013-12-05 08:57:32
@_author: Kent Borg 
@_subject: [Cryptography] Kindle as crypto hardware 
I was thinking the question was about a personal gizmo for keeping keys and passwords. But Pandora looks pretty nice as a way to do larger key management ceremonies. In addition to 512MG internal flash (enough for a trim OS and programs) there are dual SD slots, so you could even do secret splitting fun stuff.
There is touch screen, and also a real USB port, you could keep a wired mouse in your evidence bag and you get at least that level of entropy. Or plug some other entropy generating device into the USB port. It has an internal mic and a mic/headphone jack...put a vintage transistor radio between stations and cat the mic to /dev/random...
If one is getting so elaborate as using evidence bags and locking in safes, the price of this hardware doesn't look so high.
A note on evidence bags: make sure your device can't be operated through the bag! Put a Kindle in a plastic bag with big clear panels? Bad idea.
Use an opaque paper bag that you wrap tight before sealing (if there is a product that works that way). Be extra paranoid and put that in a plastic evidence bag, they can be vacuum packed. Make your foe defeat two different technologies in close proximity, just in case their techniques for one will be evident on the other?
The clamshell design of the Pandora, if held tight in a small bag, would be extra security. The Pandora battery is removable, taking it out before sealing it up tight would further disable it while sealed up.
Depending on what you are up to, worry about EMI and cameras and acoustics and slight-of-hand and other attacks in your ceremony room.
P.S. Is putting electronics in an evidence bag in your Chinese hotel room a good way to get it stolen? (And to plant a "barium enema", and maybe even get arrested for good measure?)

@_date: 2013-12-13 14:37:07
@_author: Kent Borg 
@_subject: [Cryptography] Fwd: [IP] 'We cannot trust' Intel and Via's 
It might make even two bad inputs good. If rdrand has a backdoor it still needs to leak state to its master.  XORing in something way noisy might be annoying to the masters.

@_date: 2013-12-22 18:31:32
@_author: Kent Borg 
@_subject: [Cryptography] RSA is dead. 
The NSA should do that.
If the NSA were doing their job, if they really looked that the landscape and wondered where the risks are...THEY would be doing this code review.  (They probably are.)  And publishing the results.  (They are not.)  And suggesting good fixes.  (I can dream...)
Cyber threats are a place where defense really can work.  It is such a shame the US government chose to militarize the internet instead of making it safer for everyone.  Safer for everyone, they are too jealous for that.

@_date: 2013-12-22 21:55:51
@_author: Kent Borg 
@_subject: [Cryptography] Fwd: [IP] RSA Response to Media Claims Regarding NSA 
From Dave Farber's IP list.  Stunning.  Just stunning.
(c/o Jericho)
RSA Response to Media Claims Regarding NSA Relationship
December 22, 2013
Recent press coverage has asserted that RSA entered into a ?secret contract? with the NSA to incorporate a known flawed random number generator into its BSAFE encryption libraries.  We categorically deny this allegation.
We have worked with the NSA, both as a vendor and an active member of the security community. We have never kept this relationship a secret and in fact have openly publicized it. Our explicit goal has always been to strengthen commercial and government security.
Key points about our use of Dual EC DRBG in BSAFE are as follows:
         ? We made the decision to use Dual EC DRBG as the default in BSAFE toolkits in 2004, in the context of an industry-wide effort to develop newer, stronger methods of encryption. At that time, the NSA had a trusted role in the community-wide effort to strengthen, not weaken,          ? This algorithm is only one of multiple choices available within BSAFE toolkits, and users have always been free to choose whichever one best suits their needs.
         ? We continued using the algorithm as an option within BSAFE toolkits as it gained acceptance as a NIST standard and because of its value in FIPS compliance. When concern surfaced around the algorithm in 2007, we continued to rely upon NIST as the arbiter of that discussion.
         ? When NIST issued new guidance recommending no further use of this algorithm in September 2013, we adhered to that guidance, communicated that recommendation to customers and discussed the change openly in the media.
RSA, as a security company, never divulges details of customer engagements, but we also categorically state that we have never entered into any contract or engaged in any project with the intention of weakening RSA?s products, or introducing potential ?backdoors? into our products for anyone?s use.
Just because i'm near the punchbowl doesn't mean I'm also drinking from it.
Archives  Modify Your Subscription | Unsubscribe Now

@_date: 2013-12-23 08:40:12
@_author: Kent Borg 
@_subject: [Cryptography] Fwd: [IP] RSA Response to Media Claims Regarding 
No, they didn't say that.  They said didn't "incorporate a known flawed random number generator", they also said that they don't reveal their contract details.
My translation of their statement:
  - We are outraged our name has been smeared.
  - We were following a trend, back when we assumed the NSA worked for   - We only changed the default, trouble-makers looking to get fired could still use a different RNG.
  - It was the FIPS standard, so even when folks pointed out its flaws, we hid behind NIST guidence.
  - When NIST change their tune we told customers to go figure out how change the default in their deployed Bsafe fobs and we started working on this carefully worded press release.
  - We won't comment on the $10 million.
  - We were too stupid to have an opinion about Dual EC DRBG, we didn't know it had any problems.  Just because we have legendary initials as our name doesn't change that we are just ignorant businessmen, honest, we don't know any better.
-kb, the Kent who hopes he wasn't too brutal in his translation.

@_date: 2013-12-23 09:10:39
@_author: Kent Borg 
@_subject: [Cryptography] Passwords are dying - get over it 
People love to say passwords are dead, but any alternate proposals they might suggest always seem worse to me.
Google seems to have the biggest head of steam by trying to become the single sign-in for everything else, and then, because they are so important they can force you to carry a Bsafe fob, or something like that.  Actually, they probably won't go for a fob...
Instead Google is working hard to know everything about me, and that is key to their security solution: they will know I am legit when I log in because they will know it is me because they have been following me.  Or something like that, they don't exactly know how it will work, but they are getting good at recognizing login patterns and being confident I am me based how and where I login.
I can cache in my head the passwords I use frequently. And when I need a more obscure one, I look it up, in the records I keep of all my passwords.  Exactly how to keep those records and how to maintain any endpoint security is the hard part about my approach and not something that is easy to recommend to others.
A pencil and a little paper notebook that should be carefully protected, obfuscate the contents in some simple way--that is the best I can suggest for civilians.  (And don't bring the whole notebook when traveling internationally, maybe leave it with someone trusted whom you can phone.)

@_date: 2013-12-23 11:14:33
@_author: Kent Borg 
@_subject: [Cryptography] Passwords are dying - get over it 
I never use a private ssh key for personal interactive logins. Which means I nearly never use ssh private keys, only when I need automated logins and that needs to be done very carefully.
Using a private key has three problems I see:
1. Another opportunity for an attacker: the key file.
2. Now I need to manage all the places I store key files.
3. The passphrase protecting the private key needs to be much stronger than does a password because there is a limit on how fast a password can be checked because the server will throttle attempts. Yes, you are talking about key strengthening, but I still want a lot of real entropy in my base passphrase, just in case the strengthening isn't so good.  Something worth 128-bits of entropy is a pain to remember and type.  But a password can be pretty short and still good (for example, 4-digit ATM P.S.  Passwords can be pretty easy to type, or have lots of entropy in them: but then they get long and hard to type without errors--and hard to remember.  For example, this has 128-bits of entropy in it (as it was mechanically and created out of 128-bits of /dev/urandom by a reversible Remembering a series of three randomly chosen words is easy, there always seems to be a meaning that can be associated with them, but to "curve fit" an idea through many such random words is hard.  And typing with only bullet characters as feed back is error-prone.

@_date: 2013-12-23 12:00:34
@_author: Kent Borg 
@_subject: [Cryptography] HSBC's Password Approach: Impressive 
I have an account with one of HSBC's banks and in my case their password use is pretty impressive.  (I don't know how it varies around the world with different instances of HSBC.)
1. They chose the password, not me. (So not duplicated elsewhere, at least not initially.)  Short, alpha-numeric.
2. When I login, they want my account number.  Their Javascript doesn't allow pasting, I used to use X11 middle-click pasting but one day they decided I was a specific piece of Windows malware and locked me out until I had my computer professionally cleaned. I managed to talk them out of that for my Linux machine--but I don't middle click any more.  (I actually ended up talking to someone pretty real.)  They are watching their attacks, maintaining a security model on each customer.
4. They want the answer to a security question (effectively a password I have chosen).
5. They want their password--but only a few positions, they show a form, graying out boxes for positions they are not interested in.
In their model they are keeping track of when they have used which character positions (when a keyboard sniffer might have discovered a position).  They seem to settle on the same character positions for a long time, until something interesting happens (such as logging in with a smart phone app), then they shift them.  I bet their HTML doesn't obviously reveal which positions they are requesting, to make the sniffing harder.
They are being pretty clever to make up for terribly endpoint security.

@_date: 2013-12-24 12:41:33
@_author: Kent Borg 
@_subject: [Cryptography] Tarnished Reputation, Sad 
Just noticed a new posting on the bugtraq mailing list.  Nothing odd in that, but it caught my eye because it was from EMC, parent of disgraced RSA. ("EMC Replication Manager Unquoted File Path Enumeration Sad to see.  Someone apparently is doing the right thing and fixing security hole.  On Christmas Eve.  But when I see it I don't admire it.  I'm not sure what my reaction is, it is decidedly mixed.  But seeing those letters, it just tastes bad.  Unfair.  Sad.

@_date: 2013-12-25 08:45:27
@_author: Kent Borg 
@_subject: [Cryptography] Passwords are dying - get over it 
My problem is the "think of" part, I want a password that has been built from random data, not something I dreamed up.  If the phrase really is memorable, it might be from The Lord of The Rings, and so part of a cracker list. (Your example appears not to be.) If it is something you made up and no one could anticipate, will it be memorable enough? Will you mess up a comma or preposition?
My solution is to have good *passwords* but realize they can be short. Encryption keys, however, are a different beast that must be far longer, so I try to have fewer I have to remember, mostly just the one I use to encrypt all the others. How many encryption keys do most normal people have?

@_date: 2013-11-03 10:22:24
@_author: Kent Borg 
@_subject: [Cryptography] What's a Plausible Attack On Random Number 
I kind of like the idea of RNGs sharing data, if one is following the "more sources is safer"-approach, it seems it can't hurt. (Subliminal channel?? Other system consequences?)
But there is an irony here: aren't most of the DHCP servers out there little embedded NAT boxes running in homes? RNGs at risk for not having much entropy shortly after boot...
Just make sure you don't put all your eggs in any one entropy source...
-kb, the Kent who used to callect entropy samples from Linux machines he encountered, but who eventually lost interest, as he wasn't actually doing anything with this data, just hoarding it.

@_date: 2013-11-03 16:09:07
@_author: Kent Borg 
@_subject: [Cryptography] What's a Plausible Attack On Random Number 
Yaron Sheffer suggested:
Starting to sound so neighborly: whenever you think a neighbor could maybe use some entropy, offer a little.  (To be mixed with other sources!)

@_date: 2013-11-04 14:21:15
@_author: Kent Borg 
@_subject: [Cryptography] /dev/random is not robust 
I think some lessons here are:
  1. Worry about operating with low initial entropy, including blocking usually non-blocking RNG output until some configurable amount entropy has maybe been collected.
  2. Look for local sources of entropy, and look again every few years as technology changes:
    - disk turbulence might have been good once maybe not so much anymore;
    - interrupt timing might have been an iffy source earlier, but now with much faster system clocks holds more promise;
    - hw sources like rdrand are becoming more common, but maybe not trusted, mix with other sources;
    - uninitialized RAM contents might have been worth some entropy once but it seems not so with recent technology.
  3. Even non-entropy data that is unique or might vary (MAC addresses, serial numbers, version numbers, time) makes an attacker's life harder and are worth mixing in.
A manufactured-in starting seed seems more like  than  (is it kept secret?, was it honest and high quality to begin with?), but still worth using if a manufacturer can afford to include it.

@_date: 2013-11-06 07:59:11
@_author: Kent Borg 
@_subject: [Cryptography] randomness +- entropy 
I still suggest adding a *mechanism* to block urandom before it has any entropy.  And if you can sneak in defaults that mostly no one notices but still help many...cool.
Those who don't like such a change, those who look deep enough to notice the change, can set their defaults to something suitable for them.  (Leave helpful comments in the code for those who might find editing a couple constants in their private kernel sources easier than managing custom kernel parameters.)
But please add a mechanism as soon as possible, even if it is defaulted to off.
RNGs should try very hard to not fail silently and emit bad data.

@_date: 2013-11-06 09:38:35
@_author: Kent Borg 
@_subject: [Cryptography] Ah, The Circles of Life 
I saw a tweet by Bruce Schneier about elliptic curve cryptography, recommending an article on Ars Technica.
I start reading it, am reminded of the mysteriously chosen parameters of the NIST RNG, and that I read about how to choose such things in a public and honest way.
And that for makes me wonder about pi, but in hex.  (Can't remember the question before, but all things are new to me at least once.) So I google "pi in hex".
And the page I go to begins:
Ah, the circles of life.  (Or, possibly the incestuous nature of life.)
-kb, the Kent who needs to get back to the Ars article now.

@_date: 2013-11-06 14:20:19
@_author: Kent Borg 
@_subject: [Cryptography] Ah, The Circles of Life 
Yes, only when they are.
-kb, the Kent who was only noting that some free association starting from Schneier can easily lead back to Schneier.
P.S.  I didn't say where the article was:

@_date: 2013-10-01 12:04:06
@_author: Kent Borg 
@_subject: [Cryptography] Why is  emailing me my password? 
I noticed the password would be mailed in the clear when I signed up, but even if I had not, I would not have been bothered to later discover it.  What is the harm?  The sensitivity of this password is extremely limited.  That is, unless you are someone who recycles one password in other places.  You wouldn't do that, though, would you?

@_date: 2013-10-17 13:05:52
@_author: Kent Borg 
@_subject: [Cryptography] /dev/random is not robust 
There are certainly larger system issues, and anyone doing auto-provisioning of servers and generating keys before any entropy has accumulated could get burned.  Though to be fair to /dev/random, isn't this a larger Linux distribution issue?  Don't automatically generate keys on first boot.  RNGs that need seed data should not be run empty.
But is this something that /dev/urandom might do better?  Should blocking be added to /dev/urandom immediately after boot until some reasonable threshold has been reached at least once?  Or on first boot are common distributions restoring a bad seed file and /dev/random can't tell?  Arrgh, I am starting to think that the RNG is the wrong place to fix it.
Should RNGs attempt to detect uninitialized states and refuse to run?

@_date: 2013-10-20 12:54:28
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
The RNG should be configurable to block.
In the case of Linux's urandom Ted suggested blocking on bits-in and time, which ever comes first.  The question of defaults becomes key.
I suggest that the kernel's default values for these two parameters should be small enough that nearly no existing user is harmed by the change, yet many could benefit from not running on empty immediately after boot.
One question I have is who are typical first users of urandom after boot?  (That is, who will notice if the delay in seconds or bits is too large, what are they doing, when are they doing it?)
At the larger system level, these parameters could be set explicitly according to what that system is doing, how it is designed, etc.

@_date: 2013-10-21 14:28:22
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Also, the universe is of limited size and life expectancy: the "resources and time" bit really matters once the numbers get big.
In isolation of a larger analysis (of the threat and the definition of the system boundaries being defended) there are still useful things to say. Such as ROT-13 is extremely weak, DES medium weak, AES-256 likely very much stronger, OTP completely strong.
But the system boundaries matter. I don't hold AES-256 responsible for protecting the secrecy of the key, though that matters in a larger system (try memorizing and accurately entering 256-bits, it ain't easy).  Similarly, I don't hold OTP responsible for key generation nor key distribution, though those do become extremely important when designing the larger system.
One has to look at the larger system if one wants to draw conclusions about the security of the larger system (and so on for the system larger than that, and the one larger than that).  But components can still be examined, at each level, weaknesses found, improvements made.
In the case of and RNG (as with much of crypto), failures can be silent.  It makes sense to build into an RNG the ability to refuse to work absent any seed (or entropy, as the case may be).  It makes sense to make this facility have parameters that can be tuned by those using it when carefully building a larger system.  It further makes sense to choose defaults that give those larger designers as much help as possible, hurt as little as possible, and try to reduce the "fail silently" property to fewer cases and lesser severity.
If the RNG also mixes in locally unique information that isn't particularly secret (MAC addresses, time, etc.), as long as it doesn't hurt, I conclude it doesn't hurt and it is worth doing. Even if you don't know what the larger system is, it helps.  A little like a crypto angorithm having more rounds, it usually helps.
The refusal to look at the component without first being served your cookies and milk is pedandic silliness.  Like refusing to reduce the failure rate of your bolts, nor examine their strength, because it is the fault of the bridge builder for not doing the entire analysis and using enough bolts.  Yes, the bridge builder should do his/er job.  But it is still worth talking about bridges independent of any specific structure.  It is still worth studying bolts independent of specific Similarly, reducing the silent failure modes of RNGs, and making residual failures less fatal, is worthwhile.

@_date: 2013-10-22 07:35:19
@_author: Kent Borg 
@_subject: [Cryptography] [RNG]   on RNGs, VM state, rollback, etc. 
I used to like that idea. After all, even though power-on contents of RAM isn't completely random it is also not completely predictable. Some unique bits in there if not rich entropy.
Unfortunately, since I had my brainstorm, RAM technology seems to have changed and in my observation recent RAM comes up nearly all zeros. At least once Linux is up (and I don't think Linux has taken the time to zero things).
Another problem: it takes time to read all that RAM, so one wouldn't want to actually wait before finishing booting.

@_date: 2013-10-22 07:48:47
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
And the system boundaries matter: OTP itself cannot be broken. Period.  AES-256 itself (maybe) cannot be broken before the universe dies.  However *both* are vulnerable if used insecurely in a larger system.  And OTP has particularly large practical problems.
But it is still worth understanding the properties of such primatives.  As it is worth talking about the properties of a larger system built out of them.  And *that* system in turn might be used in an insecure way by the still larger system that is built from it.
Saying "everything can be broken" because at some point someone will make a mistake isn't very useful.  At various points it *is* possible to have security and one should understand those details so we can better avoid the "someone will make a mistake" boo-boo.
My point: RNGs are still worth talking about, even in isolation, everybody quit saying "oh, there is no point, every system can be broken".

@_date: 2013-10-22 08:39:53
@_author: Kent Borg 
@_subject: [Cryptography] "Death Note" elimination for hashes 
Maybe.  But manufacturers like selling a whole new phone maybe more than they like putting effort and support costs into giving away a free upgrade.  (Doing an upgrade is harder than a fresh installation, so many possible starting points, so slow to test each, so little reward for the job well done.)
And consumers don't necessarily think it is a benefit to have a phone that seems to be working changed at the risk of it not working.  Plus, many of them expect to buy a new phone shortly anyway.
In the case of Android, it is Google that has a clear interest in the health of the whole ecosystem, including secure phones.  And they have been recently struggling with improving the upgrade paths.  Moving their secret sauce from AOSP into Google Play Services gives them more control along these lines, as it makes it more closed source.

@_date: 2013-10-24 12:04:10
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
A warning here: when mixing in different sources, you want to make sure they are different or it might make matters worse.
In recent versions of Linux's urandom the Intel CPU random HW is NOT independent of urandom output; CPU HW random bits are XOR-ed in just before they are output.
If you mix them Intel random bits again you are making a complex system that is hard to analyze, and so not necessarily an improvement.  Using some different and independent HW source?  Cool.

@_date: 2013-10-28 14:42:34
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Knowing "packet timing" isn't good enough.  It is the interrupt timing that matters, and even that isn't good enough, at least not in the case of a fast CPU with a GHz+ system clock: you have to know the value of a fast counter at the moment that it is sampled as part of servicing the The clock the attacker needs to know doesn't even exist outside the chip in question.  An attacker needs to infer very precise phase angles here, or a bit or more of entropy will slip through on that interrupt.
And you expect to measure this via malware running on a cheap printer plugged into feet of ethernet cable plus an ethernet switch plus more cabling between it and the computer that gets the interrupt?  The malware might make an estimation of interrupt timing, but it can't get down to the last LSB of that clock at the moment when the CPU gets around to reading it.
We are talking not just an off-chip measurement of a signal that doesn't exist off-chip, we are talking about doing it from outside the box, when the box isn't trying to cooperate.
Making timing measurments precisely is hard to do in the best possible and most carefully engineered circumstances.

@_date: 2013-10-31 10:31:48
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
You make a good point: If an attacker can feed crafted data as an "it can't hurt" entropy source, and if the attacker can draw entropy out, it is possible to break the entropy accounting, making it think there is more entropy there than there really is.  (Fair summary?)
This then turns the attacker's problem into breaking the hashing or encryption that is at the heart of the RNG.
But the problem isn't the extra entropy sources, it is broken accounting.
I want lots of entropy sources.  It makes the attacker's task more difficult.  Even if the attacker's job maybe starts out impossible, I like making it harder.
Linux tries hard to not credit "can't hurt" sources.  It doesn't even credit the reading of a stored pool at boot.
-kb, the Kent who doesn't like entropy accounting to begin with, it just feels like we are fooling outselves.

@_date: 2013-10-31 14:11:36
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
Yes, but not centralized, approved, and documented with the NSA.
For example, at a low-credit rate, it includes a rather diffuse and hard to characterize source: "interrupts".

@_date: 2013-09-08 20:34:55
@_author: Kent Borg 
@_subject: [Cryptography] Techniques for malevolent crypto hardware 
I don't see the big worry about how hard it is to generate random numbers unless:
  a) You need them super fast (because you are Google, trying to secure your very high-speed long lines), or
  b) You are some embedded device that is impoverished for both sources of entropy and non-volatile storage, and you need good random bits the moment you boot.
On everything in between, there are sources of entropy. Collect them, hash then together and use them to feed some good cryptography.  If you seem short of entropy, look for more in your hardware manual. Hash in any local unique information. Hash in everything you can find! (If the NSA knows every single bit you are hashing in, no harm, hash them in anyway, but...if the NSA has misunderestimated  any one of your bits...then you scored a bit! Repeat as necessary.)
I am thinking pure HW RNGs are more sinful than pure SW RNGs, because real world entropy is colored and hardware is the wrong place to fix that. So don't buy HW RNGs, buy HW entropy sources (or find them in your current HW) and feed them into a good hybrid RNG.
On a modern multi-GHz CPU the exact LSB of your highspeed system counters, when the interrupt hits your service routine, has uncertainty that is quite real once the you push the NSA a few centimeters from your CPU or SoC.  Just sit around until you have a few network packets and you can have some real entropy. Wait longer for more entropy.
In case you did notice, I am a fan of hybrid HW/SW RNGs.
P.S.  Entropy pools that are only saved on orderly shutdowns are risking crash-and-playback attacks. Save regularly, or something like that.
P.P.S. Don't try to estimate entropy, it is a fool's errand, get as much as you can (within reason) and feed it into some good cryptography.
P.P.P.S. Have an independent RNG? If it *is* independent, no harm in XORing it in.

@_date: 2013-09-08 22:06:31
@_author: Kent Borg 
@_subject: [Cryptography] Techniques for malevolent crypto hardware 
I overstated it.
Good random numbers are crucial, and like any cryptography, exact details matter.  Programmers are constantly making embarrassing mistakes.  (The recent Android RNG bug, was that Sun, Oracle, or Google?)
But there is no special reason to worry about corrupted HW RNGs because one should not be using them as-is, there are better ways to get good random data, ways not obvious to a naive civilian, but still well known.
Snowden reassured us when he said that good cryptography is still good cryptography.  If that includes both hashes and cyphers, then the fundamental components of sensible hybrid RNGs are sound.
Much more worrisome is whether Manchurian Circuits have been added to any hardware, no matter its admitted purpose, just waiting to be activated.

@_date: 2013-09-09 09:17:20
@_author: Kent Borg 
@_subject: [Cryptography] Techniques for malevolent crypto hardware 
Your three cases left off an important one: Not bothering to seed the PRNG at all.  I think the Java/Android cryptographic (!) library bug that just came up was an instance of that.
I think the root of the problem is that programs are written, and bugs squashed, until the program works. Maybe throw some additional testing at it if we are being thorough, but then business pressures and boredom says ship it.
That won't catch a PRNG that wasn't seeded, nor a hashed password that wasn't salted, the unprotected URL, the SQL injection path, buffer overflow, etc.
Computer security is design, implementation, and skepticism.  But unless you can sell it with a buzzword...

@_date: 2013-09-12 10:41:46
@_author: Kent Borg 
@_subject: [Cryptography] Finding Entropy Isn't That Hard 
I agree that things like consumer NAT boxes have a tricky problem, and anything that needs high bandwidth random data, but otherwise routers and servers are not as bad off as people say.  At least in the case of modern servers that are running enough of an OS to include a good entropy-pool RGN (like Linux's urandom*).
These boxes have GHz-plus clocks, so fast that the "box" doesn't have that clock, it only exists on-chip.  It is multiplied up from a lower frequency external crystal oscillator by an analog PLL which is also on-chip.  This fastest clock is commonly used to drive an on-chip counter.  These chips also have interrupts from the outside world.  There is real entropy in the interaction between the two.
What is that value of that counter when the interrupt is serviced? I assert there is entropy in the LSB of that value.  A GHz-plus clock is running just too fast for someone meters (or kilometers) away to know its exact value.  And every time the observer might get the LSB wrong, a bit of entropy got by: Use that data to stir an entropy pool.
How do we know it is hard to know the value of a GHz-plus counter? Because of the engineering problems suffered by people trying to build fast systems.  Clock distribution is difficult--there is a reason that high speed clock doesn't exist off-chip, the skew becomes great.  Even on-chip clock distribution is tricky and requires careful layout rules when designing the chip.  And even on this fast chip, the uses of the fastest clock are limited and any functions that will work on a slower clock will get a slower clock. Clock distribution is hard.  Hard within a large IC, hard on a circuit board, hard between circuit boards, hard between boxes, hard between equipment racks, hard between buildings...how far away is this nefarious observer, the one who you worry might be able to infer the LSB?  I think more than a few cm is too far away and if you don't have security at that radius, you don't have [* Until Linux kernel 3.6 the person maintaining urandom was busily turning off interrupts as a source of entropy, I think because he didn't know how much entropy he was getting so better not to get it at all (huh?).  In 3.6 this was changed to use all interrupts as entropy sources, which is good.  This means earlier kernels aren't so good--though I notice that Ubuntu's kernel has the 3.6 improvement in their version of 3.2, so individual distributions will vary.]

@_date: 2013-09-12 11:52:20
@_author: Kent Borg 
@_subject: [Cryptography] Finding Entropy Isn't That Hard 
Not that more sources is bad.  A new trustworthy HW entropy source would be good.  Even a suspect rdrand is worth XORing in (as Linux does on the machine I am using right now).
But if you thirst for more entropy keep looking in your current hardware, server boxes are particularly good hunting grounds for a few more dribs of entropy:
  - current RPM of all the fans (the proverbial entropy-starved server can have a lot of fans)
  - temperatures
  - voltages
  - disk ("SMART") statistics (temperatures and error counts, multiplied by the number of disks)
These are all things that could wear out or go wrong, which means they need monitoring because...you can't otherwise know what they are.  Cool, that's a decent definition of entropy.  Sample them regularly and hash them into your entropy pool.  Not a lot of bandwidth there, but if your RNG does a good job of hiding its internal state, and you are mixing in a dozen more bits here and a dozen more bits there...pretty soon you have made the attacker's job a lot harder.
Maybe not as sexy as a lavalamp or radioactive gizmos, but more practical and available now.

@_date: 2013-09-13 12:18:02
@_author: Kent Borg 
@_subject: [Cryptography] Finding Entropy Isn't That Hard 
Within limits.  Mixing the entropy pool on Linux takes work and battery Looking at some random Android kernel source code (git commit c73c9662) it looks like add_interrupt_randomness() is happening for every interrupt (your Android device's kernel may vary), so there is probably plenty of entropy.  And add_interrupt_randomness() throttles to only feed the randomness once a second, not wasting our time or battery.
Don't carry moral obligation beyond what is reasonable!

@_date: 2013-09-14 17:38:24
@_author: Kent Borg 
@_subject: [Cryptography] real random numbers 
I see "theoretical" the enemy of the "good" here.
The term "squish" is entertaining, but be careful that once you paint away with your broad brush that you don't dismiss engineering realities that matter.
I can see there is an appeal to entropy sources that you can work back to some quantum origin, but even they will fail horribly if you don't build a larger system that is secure, and secure at some non-trivial radius.  (How much Tempest-hardening are you going to do?)
And once we have built such vaguely secure systems, why reject entropy sources within those systems, merely because they you think they look like "squish"?  If there is a random component, why toss it out?  You seem to respect using hashing to condition and stretch entropy--though why any existing hash shouldn't also fall to your "squish" generalization, I don't know.  It seems that you would reject using a coin toss as a source of entropy because coins are not perfectly fair and there are biases in their results.  So?  You respect hashing, why not clean the output with a good hash?
You dismiss "things like clock skew", but when I start to imagine ways to defeat interrupt timing as an entropy source, your Johnson noise source also fails: by the time the adversary has enough information about what is going on inside the GHz-plus box to infer precise clock phase, precise interrupt timing, and how fast the CPU responds...they have also tapped into the code that is counting your Johnson.
There are a lot of installed machines that can get useful entropy from existing sources, and it seems you would have the man who is dying of thirst die, because the water isn't pure enough.
Certainly, if hardware manufacturers want to put dedicated entropy sources in machines, I approve, and I am even going to use rdrand as *part* of my random numbers, but in the mean time, give the poor servers a sip of entropy.  (And bravo to Linux distributions that overruled the purist Linux maintainer who thought no entropy was better than poorly audited entropy, we are a lot more secure because of them.)

@_date: 2013-09-15 13:35:57
@_author: Kent Borg 
@_subject: [Cryptography] real random numbers 
Yes, the time I was part of designing a physical RNG product (for use in real gambling, for real money) we made sure to not only sweep up all the entropy sources we could, and not only mixed in fixed information such as MAC addresses to further make different machines different, our manufacturing procedures included pre-seeding the stored pool with data from Linux computer that had a mouse and keyboard and lots of human input.
We did not try to do entropy accounting, but did worry about having enough.
We also were going way overboard on security thinking, far exceeding regulatory requirements for any jurisdiction we looked at.  I don't know if it every shipped to a customer, but we got all the approvals necessary so it could have...
I do agree that, though a Linux box might make keys on its first boot, it should be used interactively first, and then generate keys.
Again Ubuntu (at least a "desktop" install) doesn't include sshd by default, you have to decide to install it, and at that point, if there is a human setting up things with a keyboard and mouse, there should be a lot of entropy.  Ubuntu "server" installations might be different, and I would be very worried about automatic provisioning of server machines in bulk.

@_date: 2013-09-15 06:49:25
@_author: Kent Borg 
@_subject: [Cryptography] real random numbers 
Maybe don't.
When Bruce Schneier last put his hand to designing an RNG he concluded that estimating entropy is doomed. I don't think he would object to some coarse order-of-magnitude confirmation that there is entropy coming in, but I think trying to meter entropy-in against entropy-out will either leave you starved or fooled.

@_date: 2013-09-16 12:06:10
@_author: Kent Borg 
@_subject: [Cryptography] Broken RNG Generating Taiwanese Citizen Digital 
Broken RNG-time again: In looking 2.2 million certificates, researchers found reused primes in 103 of them.
News story: Original paper:

@_date: 2013-09-18 15:27:42
@_author: Kent Borg 
@_subject: [Cryptography] Gilmore response to NSA mathematician's "make 
You foreigners actually have a really big vote here.  All those US internet companies want your business, and as you get no protections, in the current scheme, not even lip-service, you should look for alternatives.  As you do, this puts pressure on the US internet companies, and they have the economic clout to put pressure on Feinstein and Polosi and all the others.
Sad that economic clout matters so much, but voters in the US are astoundingly ignorant of reality (pick a topic--other than sports and celebrity gossip--and we are ignorant), and so many can't be bothered to vote.  We kind of get the government we deserve.  Do what you can to save us, please.

@_date: 2014-08-15 09:42:43
@_author: Kent Borg 
@_subject: [Cryptography] Open Source Sandboxes to Enforce Security on 
Designing in end-to-end encryption is a good idea, but just because there is a claim that some product employs end-to-end encryption, why should any customer believe it?
With open source programs there is a go-check-for-yourself response that, though it might not be practical, does pose a risk of discovery to those who might want to try to quietly inject a backdoor.
But that doesn't do any good in assuring that a proprietary product is in anyway secure.
Is there any work going on to build an open/closed hybrid, where a the closed source portion of the code is in a restricted sandbox that can't talk to the outside world, except through limited facilities provided by the open source portion, a part that is susceptible to go-check-for-yourself auditing?
One doesn't have to worry as much about what product Foo is doing if we encrypt all its communication with a key that Foo doesn't know. Sure, Foo might implement a covert channel, but if we don't let it talk to untrusted endpoints, so what? Don't think of it as a covert channel, think of it as a proprietary feature that makes Foo's voice quality better than the competition's.
Individual products might release portions of their source code to try to demonstrate how wholesome they are, but some standardization would be Recent Linux kernels have seccomp filters that can restrict and filter system calls, and that sounds useful, but is rather incomplete. The open source portions of Android made an attempt at implementing permission lists on app sandboxes, but it is full of holes.
Are their other Usual Suspects are in this space?
-kb, the Kent who has been musing over a product idea and but who is wondering how it could possibly be considered trustworthy.

@_date: 2014-08-19 14:31:17
@_author: Kent Borg 
@_subject: [Cryptography] Open Source Sandboxes to Enforce Security on 
Indeed, important point.
The larger system is a tricky problem, doing a proprietary product that is effectively penned into a verifiable open source enforced censorship cage. Without also giving away the proprietary bits.
Thanks for all the answers,

@_date: 2014-12-05 15:37:57
@_author: Kent Borg 
@_subject: [Cryptography] cost-watch - the cost of the Target breach 
News like this should change the political, and therefore technical, landscape: hardheaded business folk should start screaming that we have a problem with computer systems being insecure, and that the government should do something about it.  (Make things more secure, that is, not less.)  Silicon Valley-types tend to understand but will Joe-average-board-members see the connection and start making phone calls?
-kb, the Kent whose opinion doesn't matter because he is naive or ignorant or doesn't love his country or doesn't have enough money to buy the results he wants.

@_date: 2014-02-08 12:52:50
@_author: Kent Borg 
@_subject: [Cryptography] RAM memories as one source of entropy 
Reading plain-old DRAM at power up seemed like a good idea to me, and I have done it years ago on the "can't hurt" theory, but on recent hardware it looks like CPU reads from DRAM right after boot are almost entirely zeros.  Something has changed in the technology, there used to be lots of patterning when I did that.
That doesn't mean that there might not be other ways to get interesting entropy from DRAM, just that is doesn't seem to be free for the reading in recent hardware; you might have to do some hardware engineering to do it, at which point there have got to be better ways to add some entropy-yielding hardware to your design.
-kb, the Kent who doesn't know about SRAM.

@_date: 2014-01-04 10:55:21
@_author: Kent Borg 
@_subject: [Cryptography] nuclear arming codes 
Very cool, but it requires a photo of what the nail polish is supposed to look like. A secure photo. Don't trust your regular cell phone with this, sounds like a job for the off-line "phone" you carry. You do carry one, right?

@_date: 2014-01-13 14:16:25
@_author: Kent Borg 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
Two points.
First, RSA knew--or certainly should have known--that they were in the business of selling security, yet they failed in that.  Worse, thewy failed spectacularly and sold something not just broken, but something with a backdoor specifically designed to defeat security. As you well know, this is serious business.
I don't think the suits knew what they were doing, I think they were just chasing money, they didn't ask too many questions that might get in the way of that money.  Businessmen do that.  We all know (suits, too), security doesn't sell, buzzwords sell.  They sold the buzzwords without the security.  Nearly everyone does it to some degree.  They did it worse, they were in a position of trust.
If we can't make selling security pay, we can maybe make selling insecurity cost.  There are a lot of other suits watching this, seeing how RSA fairs.  I want them to see something gruesome, something that worries them.  (The same way I want a banker or two who nearly dumped us into DEPRESSION to go to jail, so others will think twice.)
Second, I don't see a political groundswell to change what the NSA does.   A very cynical public has learned things only a few of us cranks imagined (and didn't full believe), but they are shrugging their shoulders, and wondering about their meal and sports entertainment.
The only political force I see with any real interest and clout are American high tech businesses.  They need motivation and ammunition. RSA is a little fish, and they are likely going to die, and that is appropriate.  Their name once-valuable is dirt, and it isn't even the name of a prestigious tech conference--right?? Little companies have to do a lot of "just going along with the flow", we need to change this flow.  We need an example even someone from marketing can understand.
At my day job this morning, I asked a meddlesome question at a meeting. The nerds in the room reacted like the cynical public.  The marketing person looked up and started thinking.  The graphic and gory example of RSA made this possible.  If they get away with it because they didn't know what they were doing...this lesson will be lost.

@_date: 2014-01-13 15:26:23
@_author: Kent Borg 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
How bad can it be?  This breach is about as bad as I can imagine. Someone technical at RSA must have raised an eyebrow--too bad s/he didn't persist more.  The most charitable guess is that management didn't want to know.
At least not inappropriate collateral damage.  Is this one conference such an irreplaceable jewel that is has to continue? Could something better be created in the vacuum?
The name "RSA" is important here.
We have a proud example in Lavabit, and I would hope that if we saw a resume with Lavabit on it we would be impressed.  What will we think when we see a resume with RSA on it?  I think RSA should be the clear counter example.  Letting the RSA Conference continue with pride doesn't seem to underline this as firmly as I would like.
Jeeze, I feel like such an old geezer to say: "I remember when 'RSA' was a proud name that left me in awe!"
How important *is* this conference?  I admit I have never attended...

@_date: 2014-01-13 16:01:33
@_author: Kent Borg 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
I'm not very impressed with the IP security industry ("Firewalls, anti-virus software, latest Service Packs--okay, we are set."--seems to be the dominant attitude I see...).  Leaving them navel gazing for a year wondering what they should do now...doesn't seem that bad to me.  Forgive me for over generalizing here.
On the other side, will the alternative security conference I am imaging pop up anyway?  Can RSA be allowed to wither for a couple years in the It seems it will go on--it hasn't been canceled and would be expensive to cancel so it won't.  There will be a lot of noise, the boycott folks will make a big point--but not manage to cancel it. There will be some empty sessions.  If Colbert cancels that will be big news and help make the point of what a damaged brand "RSA" is, if he doesn't cancel I predict Colbert will skewer RSA in his performance and make them wish he had canceled.  They get further burned either way.  Hmmm.

@_date: 2014-01-15 09:15:23
@_author: Kent Borg 
@_subject: [Cryptography] [cryptography] Boing Boing pushing an RSA 
Huh?  How can this be?
OTP has always ranged from difficult to impractical to securely deploy, and the larger system where OTP is used will offer targets for attack, but one-time-pads themselves are compromised??

@_date: 2014-01-15 11:28:47
@_author: Kent Borg 
@_subject: [Cryptography] [cryptography] Boing Boing pushing an RSA 
Which is completely different.
-kb, the Kent who doesn't want to see people crying that, say, AES-256 has been compromised either--not unless it has.

@_date: 2014-01-16 08:48:12
@_author: Kent Borg 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
I want everyone to see blood (figuratively), and be afraid.  For their jobs, for their reputations.
Every few minutes some other business has a data breach, and it seems their big worry is always publicity ("Can we kill a messenger?").  Let's up the stakes.  I want to see a little operant conditioning, apply some pain to mistakes, and see people trying to avoid being part of blunders.
Security doesn't sell, let's at least make security blunders cost.
RSA needs to be seen as having paid dearly for their very bad mistake.  People in corporations need to be able to invoke "RSA" and have others shudder.  I don't care if others have also done bad things, I want RSA made an example.  How much worse could they have behaved?  Make an example of them.
How much money did EMC pay for RSA?  I want EMC (and others) to see that a purchase can be destroyed if they misbehave and just cash the big check.  Did EMC managers encourage them to be profitable, praise them for the nice haul?  I think we can assume "yes".  Did EMC put /any/ real effort into policing RSA's integrity?  We don't know, but I guess "not really"; clearly it was not enough.  Make EMC pay for that.
Security doesn't sell.  At least make security blunders cost.

@_date: 2014-01-17 08:14:20
@_author: Kent Borg 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
Go start one.  I'll wait.
How'd it go?  Did the world beat a path to your door, asking how they could help?
What?  No one noticed?  Crickets?
It has been well publicized that RSA failed.  They need to be publicly burned.  That publicity makes is easier, and more important, for them to be burned.  (That's a nice accident, doesn't always work out that way.)
Go ahead and come up with ways the world could be made better.  But triage them against practical reality.
-kb, the Kent who doesn't use Skype.

@_date: 2014-01-21 08:34:56
@_author: Kent Borg 
@_subject: [Cryptography] one-time pads 
For quick destruction of data I like the idea of using full disk encryption (implemented by the computer not the disk drive).
When the mob/swat-team tops the walls, kill the power on the attached computer. Sure, RAM will hold keys for a time, so kill the power to the warm RAM many seconds before the invaders can reach it with their freeze The key to decrypt the disk needs to be stored somewhere, but can imagine a USB flash drive mounted in a device that includes a mechanism for crushing the flash chip. Heck, maybe the power also runs through this mechanism, too: hit the red button on it and the RAM goes dark as the key is crushed. As I think about it, I think I would have the destruction mechanism hold dual USB drives running redundantly, tiny flash devices like to die for no good reason.
Also, there need to be passphrases known to humans to access the keys on the USB drive.
A lot can be stored there. All for cheap, with quick destruction. TBs of disk data and GBs of flash data. The weak link, as always, is the larger system. The software running on this computer, the hardware, what is connected to it, the security of the room where it sits, the procedures the humans do or don't follow, etc.
The specific problem of destruction seems pretty easy, as many narrow problems are. Ah, but building the larger system that is secure, so hard.
P. S. Years ago there was a Doonesbury cartoon where Duke was running a drug dealing business and talking to a customer on the phone. He asked the customer for his account number (to type into an Apple II I seem to recall). The customer is aghast that he is keeping records, but he dismisses the worry, saying he can destroy the data in seconds and he has already looked up the customer's data.
I guess an old 5-1/4 inch floppy can be destroyed pretty quickly if one is prepared. Drop it in a container of solvent. (Doesn't work so well for a large stack of floppies.) Stinkier and more dangerous than the crusher idea above: progress!

@_date: 2014-01-22 09:07:08
@_author: Kent Borg 
@_subject: [Cryptography] Fwd: [IP] RSA Response to Media Claims Regarding 
When the NSA breaks into a machine over the internet they probably use a series of hops, but for the last hop in, what kind of IP address do you suppose they choose?  Possibly a Chinese IP address?

@_date: 2014-01-22 09:13:11
@_author: Kent Borg 
@_subject: [Cryptography] RSA is dead. 
Data point: I still have my old "Cyber Rights Now!" t-shirt, with a raised fist clutching lighting bolts on one side, and on the other side an observing eye and apology from the NSA about being behind schedule for 1984.
At least with some of us, their reputation was terrible by 1984.

@_date: 2014-06-11 20:49:12
@_author: Kent Borg 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
I have a question, I think it is about concatenated encryption and convolved keys, but I am not sure. It is the sort of question that lots of people should be asking these days, so forgive me it lots of people have, I have been behind in my reading.
Alice lives on the far end of a single DSL line, and produces data on a regular basis, she encrypts it with a key only she knows, and she sends it to Bob.
Bob lives in the cloud (and so has lots of bandwidth), but Bob is in the cloud, and therefore is only partially trusted, so he is given no ability to directly decrypt the data. There is also lot of data accumulated, he doesn't can't store unique copies for each client.
Charley is a client, one of many (Charley-1, Charley-2, Charley-3, etc., clients can come and go), he lives in a smart phone, say. He asks Bob for a specific piece of data, Bob encrypts it with a Charley-1-specific key and sends it off.
Charley-1 decrypts the data with a key that Bob does not know.
If Alice discovers Charley-1 is compromised, she can instruct Bob to delete Charley-1-specific data, destroying his ability to read data from Bob. Alice probably knows everyone's keys, but Bob and Charley do not know each other's keys, and again only Alice knows her key.
If Charley-1 and Bob collude, the system is, unfortunately, broken, but that seems unavoidable.
An attempt to restate the question:
  Is there a way to encrypt once with key A, super-encrypt with key B1 (not knowing any other keys), and finally decrypt with key C1 (not knowing any other keys)?  Or, super-encrypt with key B2, then decrypt with key C2?
In some respect this is a satellite TV problem subscription problem, with an on-demand component.
Is there a canonical answer here? Is it a stupid question?
-kb, the Kent who Googled some on this but the closest PDF seemed to want to know all the Charlies in advance, and was too encrypted a paper for him to really understand anyway.

@_date: 2014-06-12 10:31:33
@_author: Kent Borg 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
Dang, that makes sense.
But, as I am trying to "secure" data in the cloud, instead of just throwing up my hands, maybe I want to use an inferior algorithm that *is* a group...? Nah, then I am getting close to inventing my own crypto I'll have to think about my problem definition more, dig through my memory of available crypto primitives, and see if I can find another But people should be asking related questions more. The cloud is a cool thing, yet end-to-end encryption is the responsible approach, and there is a contradiction in the two.
Thanks for all the answers,
-kb, the Kent who will have to keep his eye open for progress in homomorphic encryption.

@_date: 2014-06-12 22:20:11
@_author: Kent Borg 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
Very interesting! I don't understand it yet, and there are different proposals, but my need isn't immediate, so I have some time to try to figure it out.
Unfortunate that this is so obscure, with apparently only a few people working on it. No where near like having a well debugged library I could just start using. This is topical stuff, or at least should be.
P.S. Hey! Amazon, Google, and other cloud providers: This is important! Are you working on this?

@_date: 2014-06-13 10:37:47
@_author: Kent Borg 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
Yes, I saw that, including "This library and the bibliography have not been actively maintained.", hence my ranting that this should be active and maturing, not dusty academic material that grinds to a halt as the original researchers move on to paying jobs.

@_date: 2014-06-13 18:19:51
@_author: Kent Borg 
@_subject: [Cryptography] End-to-End, One-to-Many, Encryption Question 
But the crypto world eschews algorithms that are a group. So how would one land upon an algorithm that is secure *but* for the feature/misfeature of being a group?
But if no one is working out the other kinks that will be there. Picking one turns into something close to designing ones own crypto, doesn't it? Any recommendations?
-kb, the Kent who reminds himself that not encrypting and trusting the cloud is somewhat fewer effective bits.

@_date: 2014-03-05 08:14:16
@_author: Kent Borg 
@_subject: [Cryptography] BitCoin bug reported 
> BitCoin is super deflationary, the value of goods relative to BitCoin has dropped to 1% of
 > their original value in a year. In an economy like that, anyone spending money is an idiot
 > because their money will be worth much more in a short period of time.
Indeed, were bitcoin the basis of an economy--were it to completely replace all other currencies. But what makes you think that will happen?
I think it is more accurate to think of bitcoin as just a (rather odd) financial instrument. Berkshire Hathaway could be called deflationary, too. But our economy hasn't collapsed on a cross of BRK.A.

@_date: 2014-09-24 22:42:53
@_author: Kent Borg 
@_subject: [Cryptography] Of writing down passwords 
That is cool. Trusting the creation of the card is a question, but a really cool idea in general.

@_date: 2014-09-25 08:21:45
@_author: Kent Borg 
@_subject: [Cryptography] Of writing down passwords 
I used to use a Palm Pilot, but they were getting rare and thus my unit being closer to being a single-point-of-failure, so I my current scheme includes an off-brand Android phone that I have never put a SIM card into (it has two slots, too!), have never let connect to the internet. I do let the phone occasionally be an isolated wireless access point that I ssh over to backup its encrypted data...
The phone was pretty cheap from geekbuying.com, supposedly even water resistant. And with nearly no software installed on it and all radios turned off the idle time is stunning. I try not to charge it above 90% (preserve battery life that way?), yet it seems I have a month of idle capacity, though I tend to charge it every week to ten-days.
The rest of my password scheme is less solid, but this end of it is pretty good. Too bad entering a decent key on a phone screen is such a pain.

@_date: 2015-04-26 17:51:37
@_author: Kent Borg 
@_subject: [Cryptography] Shamir Reveals Sisyphus Algorithm 
A frustrating article that leaves me with the reaction of "And...?". Something tells me that Shamir's keynote was more interesting.  Are their any good reports on it?
Standard Rants, with a Fresh New analogy:
It is as though we are on a ship that is taking on prodigious amounts of water, we have massive pumps running full time, this article seems like we are being told that it is silly to think a bilge should be bone dry.
Yes, the best ships will always have some water leaking in, but we currently have things so badly designed that passengers and crew going about their daily routine keep opening hatches below the waterline. We need some lifeboat drills, to point out to the everyone they are on a ship, and the water must be kept out. And we need ships that are actually designed to float.
Sure, let's not spend our time worrying too much whether a standard model valve--which works great--could be made more perfect. We haven't begun to install those valves correctly. Let's not also think that bigger pumps will bail us out, even though the commercial security industry seems fixated on selling us bigger and better pumps.

@_date: 2015-02-01 11:56:22
@_author: Kent Borg 
@_subject: [Cryptography] best practices considered bad term 
The term "best practices" suggests following some meretricious standard without being obligated to name any specific standard--let alone defend any choice. It temps with the promise of a standard so good it will fix things, while suppressing further discussion.
Standards are good. But even with good crypto standards to choose from (AES-265, SHA-512 both seem good circa 2015), we have to understand and define each larger problem where we might use them, and real systems are too complex to precisely understand and define, let alone have standard Just as we have never managed to standardize the analog world to be safe from fraud, we can't standardize secure computer systems of any size. In both cases the enemy is crafty and the enemy is among us--I suggest the enemy is always within the boundaries of any large system. We can be work to safer or less safe, more or less stupid, get results more or less like building with toothpicks, but the battle will ever continue.
Yes, in addition to specific standards, there is an evolving body of knowledge--there are known stupid and smart ways to do things (whether to salt password hashes, for example)--but one still has to understand and build a larger system, and buzzwords like "best practices" suggest a shortcut to a complete solution, and that is bad.
-kb, the Kent who doesn't even want to think on more clever stupidities like ISO-9000.

@_date: 2015-02-02 08:11:01
@_author: Kent Borg 
@_subject: [Cryptography] best practices considered bad term 
The National Electric Code benefits from dealing with a well defined problem. Frustrating as I presume it can be, it is still a reasonable thing to try to standardize.
But when precisely defining the problem is the bulk of the task--as I think is true of all programming--standards like the NEC can only work at a micro-level (e.g., AES) and won't secure the entire system. (Process standards, however, could offer some hope, though I assume only

@_date: 2015-02-02 20:02:56
@_author: Kent Borg 
@_subject: [Cryptography] best practices considered bad term 
Admit we are in a wild-west era--say so--tell businesses that there are no magic bullets, they need to be cautious, worried, and skeptical buyers. Give is a few decades (!) and things will maybe calm down some.
Promote open source software: cheaper, less need to be buzzword-compliant, more hope of being well implemented.
Maybe lobby the US government to understand that the US is arguably the most cyber-dependent economy, that more secure computer systems are a net gain for the US; that they should quit promoting and cherishing There are some standards being developed, for example regarding credit card systems, they will continue to evolve as money continues to be lost, so stagnation is less a problem there.
But we have had a major revolution in high tech and con men will come to these new fertile fields. We are in for some bumpy years here, no matter what we say, so let's be honest about that to warn people. Council caution, maybe not computerize and network everything as fast as possible. (Online voting? No! Paper is great stuff.)
-kb, the Kent who drives an extremely manual car, because he know about

@_date: 2015-02-04 09:07:42
@_author: Kent Borg 
@_subject: [Cryptography] crypto standards and principles 
Sounds fishy; an extra bit or two of the key could be used to select among key methods and make things much stronger! Seems too good an idea to pass up, why don't we do that? Why is AES-256 not, say, AES-260 with 4-bits used to select among different algorithm variations?

@_date: 2015-02-05 08:55:47
@_author: Kent Borg 
@_subject: [Cryptography] best practices considered bad term 
One piece of advice I would offer to, say, Anthem Health Insurance: It is not possible to secure your current system. Period.
You need to assemble a new system with security in mind; the starting assumption has to be that everything by default is excluded unless it is necessary, and can be securely included. Possibly you can include some existing components that you can't fully trust, but you might have to wall them off into a very restricted pen, with a lot of intrusion detection.
I am not opposed to all use of firewalls: To use a firewall and intrusion detection-type monitoring to create a quarantine of some untrusted component is very powerful. It is when people pretend that a single firewall can create a safe zone for general purpose frolicking with Skype and Internet Explorer and Outlook and Acrobat and any piece of Javascript anyone wants to put on any webpage anywhere--that is when I shake my head and say they are doomed.
Big Organization keeps trying to secure millions of customer records with the latest firewall, virus protection, and up-to-date service packs, and they are always failing.
And the bring-your-own-devices trend that companies are using to save money? Doomed. End-point security is possibly the hardest part of securing a larger system, and putting it in the hands of your employees' teenage kids isn't always the best way. (Though some of those kids will be better than most IT departments.)
This is getting pretty far off the topic of cryptography, but maybe that is the point. AES, good as it is, doesn't solve anything unless it is part of a larger system that is coherent and well built. And we know a lot more about why that is hard than we do about how to do it right.

@_date: 2015-02-06 18:10:25
@_author: Kent Borg 
@_subject: [Cryptography] best practices considered bad term 
Sure, collect it, write books about it, improve upon it, make it better, make it more complete, toss out stupid bits, badmouth broken things, praise good things, argue, win and lose arguments, repeat all that.
But "best practices" has a seductive sound suggesting "I'll take that!", and be done.
Any sentence that uses the term would be better off striking it and substituting words that have actual meaning.
Ah, but then one would have to stop and figure out what one is trying to do...damn! Can't I just ask for Wholesome Apple Pie and be done?
Where is the bedrock in the analog world's anti-fraud industry? Ain't no such thing. Bad guys keep innovating. And computers--moving fast--provide so many new and /juicy/ opportunities for nimble bad guys. In the real world we all need to know about fraud, starting with traditional bedtime stories for children. Computers are part of the real world now.
People want to use modern computer tools but don't want learn about the properties or risks of those tools; they want to delegate to some affordable expert, someone who won't rock any boats, who will sell them a load of "best practices".
-kb, the Kent who is sorry to say that, though civilians won't have to learn esoteric design properties of block cyphers, they are actually going to have to learn about larger systems and security because they, and details of their behavior, are key components of those systems.

@_date: 2015-02-09 08:34:04
@_author: Kent Borg 
@_subject: [Cryptography] What do we mean by Secure? 
There is that--your engineering could be great.
But there are a couple of crucial differences.
First, exactly where you draw the boundary of your system matters. For example, your system might be perfect until the user chooses the password "password". If your system boundary includes the choice of that password, then it is crap. If your responsibility stops short of that poor choice, then your system might be perfect.
Lucky you! You sold a perfect system, wipe your hands, walk away counting your bucks. Your customer, however, might think there is a bottom-line problem. The millions of credit card holders might also have a complaint and rage why can't "they" build a secure system?
"I thought you said it was just an engineering problem. What kind of terrible engineer are you?", they might ask.
I don't think orderly engineering domains have that squirrelly property, I don't think they will invisibly shift from good to bad due to some invisible, external event. It is like open pails of gasoline can suddenly appear everywhere, surrounded by lit candles--but invisibly and not giving off any fumes.
The second difference is that, unlike orderly data and predictably charged electrons, you have active, clever, adaptive, and malicious foes who are looking for holes in your design and implementation--and they are trying to shift the system boundaries to create new holes--trying to make a shift that destroys your otherwise your perfect security.
Not only can open pails of gasoline be invisible, you have foes who are trying to sneak them into your hallway!.
Those two properties make computer security very different from "just another engineering domain". We are trying to "stop crime" here. We know a lot about it, we have some solid tools, but we don't have complete solutions and are fools to think we could.
If you exclude the humans who use your system as part of the system you are cheating, you are not selling a system, you are selling a limited component, and if you don't admit it is just a component, it probably has poorly defined interfaces and functions. If you do include humans in the system then you are being honest, and have some hope of building a decent system, but are doomed to build a system that can never be perfectly secure because the enemy is inside the system.
In the case of computer security, at the moment, our attempts to stop computer crime are made of toothpicks. Though it will never be perfect, we are extra non-perfect right now, for those wanting to bail an ocean we are in a golden age, there is plenty of work to do.
P.S. Does anyone ever do security analysis that specifies the boundaries and the vulnerabilities near those boundaries? Seems basic, I have written such things for my own benefit, but don't know that I have seen anyone else do so.

@_date: 2015-02-09 09:16:58
@_author: Kent Borg 
@_subject: [Cryptography] What do we mean by Secure? 
I am sure BMW made a lot of stupid mistakes, and most of us would know better about many of them. Spotting mistakes among many is easy. But to make a secure, connected car, where all the right people have access and none of the wrong people have access is hard. (Who are all these different people? When is some individual the right person and when does he become the wrong person?) It just takes one teensie, little, gigantic hole and it is broken.
It really *is* a hard thing to build a secure connected car. No one has done it, and until we can hash out contradictory expectations about what the proper properties of this car are, it will remain impossible. (Does this car have an app? Oh, hell, now the boundaries of the system BMW has to defend probably just exploded. Does the AAA have access? Do the cops have access? Does your mechanic have access? Does the authorized BMW mechanic have access? Does some BMW engineer have access? Does the engine computer port have access? Does the handsfree bluetooth gizmo have access? Do the CAN-connected brakelights have access? Does the finance company have access? What are the security questions to recover access for the owner?)
Could BMW do better, could avoid a ton of stupid mistakes? Certainly they could. But they have to care about security and hire some people who know and not insist on selling a broken thing just because they can make millions doing so and they can't let Lexus get there first and everyone expects security problems anyway.
Handing BMW a binder labeled "best practices" would not solve their problems, but like the no-one-got-fired security trio (corporate firewall, current antivirus software, and current service packs) it might make them think they have solved their problems.
AES-256 and SHA1 are great, and assembling them sensibly into a larger program is tricky but very doable. Assembling that into a product that can remotely unlock your car doors--but only in the right circumstances--is a mess. (Yes, "Soooooo Hard.")

@_date: 2015-02-10 14:38:02
@_author: Kent Borg 
@_subject: [Cryptography] What do we mean by Secure? 
And now, with technology, we expect new features that are not addressed in that century of precedent.
Customers will want it to be better, will have both vague and specific wishes, but won't have thought through the whole system. Companies like BMW will rush to add wiz-bang features, apparently without thinking through the whole system either.
Considering the "demands" of consumers and the demands of marketing are fuzzy as hell, and not thought through, this can't be solved as an engineering problem.
The result will be a terribly insecure system, until an awful lot of dust has settled.
Unfortunately, the prudent car company that doesn't rush dangerous features to market will be at a disadvantage looking old fashioned in the face of companies that do.

@_date: 2015-02-17 16:42:49
@_author: Kent Borg 
@_subject: [Cryptography] Passwords: Perfect, except for being Flawed 
On NPR this morning I heard a nice mangling of the old Churchill line, saying that passwords are the worst authentication possible, except for all the other systems. It occurs to me there is something deep in that.
Passwords have serious problems, but they are bit like the problems with one-time-pads: cumbersome--but otherwise perfect.
There is never going to be a generalized crack of the "password system". Even with some fancy Quantum Cryptography, passwords are not going to suffer a catastrophic failure. Flawed as they are in practice, passwords are a solid tool in principle.
All the alternatives risk failure ranging from major to gigantic. All the alternative systems are complicated and brittle. Passwords are simple. Distributed. Robust.
Our use of passwords, on the other hand, is terrible. But all the alternatives to passwords are worse.
We should quit trying to craft fragile replacements and instead resign ourselves to cleaning up our act: quit reusing password the same passwords on different sites, pick good passwords, write them down our passwords, but otherwise keep them secret*.
* Including not running spyware on our machines and not typing password Z into phishing site X.
And then tell the world to do the same.
Passwords are a fundamentally good system, but for their cumbersome details. All the alternatives are worse, and I think for rather fundamental reasons.

@_date: 2015-02-18 11:50:12
@_author: Kent Borg 
@_subject: [Cryptography] Passwords: Perfect, except for being Flawed 
In responses I have seen so far, all the alternate proposals are complex and centralized. Some don't scale well or are walled-garden only. And all require that complex systems be implemented carefully and run competently. All require that lots of other stuff work right and lots of humans do their jobs well. Maybe Apple Pay can do it, maybe. I believe RSA once did a good job, but with changing ownership and management, they became incompetent and all their token seeds were stolen. And anything that claims to be "universal" (U2F) looks both over ambitious and a juicy target, and temporary. (USB? How many more years before this "universal" standard expires and legacy devices abandoned?)
Passwords, however, are simple. Yes, they depend on lots of people understanding what they are doing and being careful, but their design does not introduce immense complexity.
In our culture we have spent a lot of effort over the centuries trying to teach our kids not to take candy from a stranger. Times have changed, and we have fallen badly behind in dealing with new fraud opportunities offered by technology. As in ages past, humans are functioning in the thick of the system are still part of the security of that system, and therefore they still need to be taught to be savvy.
Though we can always engineer a more terrible system that encourages users to behave more stupidly, the badly designed system is not the only foe here, there are bad guys out there who are also trying to get users to do stupid things, and we will never engineer a solution to that. The human users have to participate in the system security and not behave like naive children.
Phishing is the big worry people trot out. But phishing is really just recognizing who is the stranger whom you should not trust. We are at really infantile level here: don't take candy from a stranger! Do we really think a better fob system is going to fix that? God, what a ripe time to be a crook.
Technological solutions alone are certainly going to make some folks a lot of money: over and over again, because it isn't going to work the first time, nor the next time...and repeat. As long as users who are part of the system keep behaving stupidly, we are going to be doomed. Yes, as long as we build terrible systems we are also doomed; I know users and systems will never be perfect, but each has to at least try, try a little! Saying users will be stupid and moving on is like saying our 3-year-old drivers don't know they should drive on the proper side of the road--hell these baby drivers don't really understand the steering wheel--so build better airbags!*
* Driverless cars, I hear you say. Fine. Steal my metaphor. Except we don't expect a lot of people trying to sabotage our driverless cars. Instead we have active and clever foes here.
My realization is that we blame passwords for things that have nothing to do with passwords' faults, and we propose solutions that require far bigger systems be built, and run flawlessly--and won't fix things.
Passwords themselves have some really nice properties. Indeed, they only work for responsible and disciplined adults (which in computer security terms, circa 2015, are vanishingly few), but the alternatives are not only wildly more complex, they will also keep blowing up in our faces if we think we can engineer around infantile users given both power and Vast numbers of our population know amazing amounts of minutia about their favorite spectator sports, but we think we can run a computerized world with them knowing nothing about how to spot phishing scams. Instead we are going to engineer our way out of it. Sure.
What can engineers do about it? Quit saying we mustn't write down our passwords. Quit making us change our passwords on a 90-day schedule. And quit overselling engineered solutions.

@_date: 2015-02-18 12:21:05
@_author: Kent Borg 
@_subject: [Cryptography] Passwords: Perfect, except for being Flawed 
A side note on spyware: HSBC Canada has a clever way to do passwords.
First, they don't let the customer choose the password, they assign it. The password is short and at each login they only ask for a few specific characters of the password. They watch login patterns and can change which characters they ask for. They know whether a given character has been revealed and in what circumstances. I think they correlate what transactions are made with login details, too.
They also have a security question--that is effectively a user chosen They don't pair a customer-chosen username with the password and security question, rather they use an account number. So neither of those two components is well known to attackers.
I had my account locked once because the X-windows middle-button paste I did for my account number looked like some MS Windows virus. The day I made a different payment from my usual pattern they shut things down. When I called they told me I had to have a specific Windows virus removed form my (Linux!) computer before they would turn it back on. Okay, but their credit, when I explained, they escalated me to someone smarter and he understood. I type the account number manually now.
Yes, a highly engineered solution--but human behavior is part of that engineering. It is password based, and, from what I can see out here, it is the most secure online account I have of any sort.
The human is part of the security system.

@_date: 2015-02-18 14:14:45
@_author: Kent Borg 
@_subject: [Cryptography] Passwords: Perfect, except for being Flawed 
USB is also a protocol, and it, too, uses the word "universal".
Whenever anything makes really big claims, best be skeptical. "Universal" seems a big claim. I was using USB as a familiar example that is not universal, and tarring them both with the same hubris of claiming too much.
-kb, the Kent who was using an RS-232 port today.

@_date: 2015-02-25 15:26:14
@_author: Kent Borg 
@_subject: [Cryptography] trojans in your printers 
I also keep my printer turned off when I am not using it, and I honestly don't use it much. Sure, it can still be against me while it is on, but it is dark and unresponsive almost always--that should frustrate many attacks and uses.

@_date: 2015-01-26 12:50:41
@_author: Kent Borg 
@_subject: [Cryptography] random numbers on virtual machines? 
If I may carp: "best practice" is a horrible term.
For what circumstances? At what cost? Measured how?
If "best practice" is removed from the question, you would have to decide on something more useful to put there. If you really want the best way you have to specify more, if you want an interesting discussion then you don't just want the best way you want bad ways, too, including discussions of what makes the bad!
Sorry, you pushed one of my buttons.

@_date: 2015-01-28 14:10:39
@_author: Kent Borg 
@_subject: [Cryptography] Introduction to EC that is actually an 
I've always thought one of the best ways to learn something is to be scheduled to teach it: it focuses the mind, to anticipate every question and be sure I have a ready answer.
Good luck!

@_date: 2015-01-30 14:49:50
@_author: Kent Borg 
@_subject: [Cryptography] Wrong uses of filesystem encryption 
Again, that horrible term! Says who? Measured how? Accomplishing what?
What is the boundary of the system you are defending? Is this a single laptop, used by one person? Or is this a server? Does one person need access or a group? What happens when that person is run over by an unexpected truck or a member of the group quits in a huff?
What about backups? How do you do your backups? Are they encrypted? What does your recovery plan look like on that day you need your backups? Do you need file-by-file encryption? Or do you need whole filesystem encryption? (Do you need to hide the names and sizes of the files or just the contents?) Maybe you do both.
Why are you doing this, what are you afraid of? Something simple, like disposing of old disks by destroying the encryption key instead of having to destroy the platters? Or is this expected to keep the prying eyes of the Chinese off your data next you visit China? What if someone tries to compel disclosure of the key? The foreign cop? The thug who carjacks you? The US border guard standing between you and home? The TSA agent? A US federal court order?
In the simple laptop example, I hear the first thing the smart cops do when they break down your door is plug a mouse-wiggler into your computer, to keep the screen saver from locking them out.
Say many ways to screw up,

@_date: 2015-01-31 20:40:11
@_author: Kent Borg 
@_subject: [Cryptography] best practices considered bad term 
I love that history. Thanks.
Yes, but that is a large list that requires a lot of thought to expand into practice.
And don't pretend everything is so harmonious as all that. There are still disagreements about whether we should frequently change passwords or not; whether to write down passwords or not; whether passwords are any good or not; whether firewalls are good (they cut off lots of bad packets) or not (they make people think insecure networks are safe).
On NPR the other day I heard a host blah-blah the standard list of everyone-knows security advice, but I heartily disagreed: change passwords she said but no mention of not reusing passwords. And we wonder how Central Command can have its Twitter and You Tube accounts both hacked on the very *same* day!?
The little thing of not reusing passwords is really a gigantic thing--extremely vanishingly small numbers of people actually do that.
This stuff is still full of controversy. (But thanks for the SAP story.)
-kb, the Kent who asserts firewalls have been terrible for security--that they should only be installed secretly, as a safety net, because otherwise people let their computers and data run around naked, thinking they are safely behind The Firewall.

@_date: 2015-03-01 10:20:53
@_author: Kent Borg 
@_subject: [Cryptography] trojans in your printers 
In my particular case, it is a hard switch--but I have an old printer. Good point.

@_date: 2015-11-18 19:58:34
@_author: Kent Borg 
@_subject: [Cryptography] The vultures circle... 
Ari Shapiro did one of the stories. No Robert Siegal, he, but he's learning, and he did press kinda well in that interview, he was trying, for a general audience program and all.
On this side of the battle, we all seem to have a preference for familiar "soft targets":
- Encryption,
- Bill of Rights,
- Muslims.
Off topic, I got into two arguments recently on Twitter about refugees. One ended with "Get out of our country you Muslim loving piece of shit.".
The other grudgingly conceded, roughly: Okay, let in some women and children. I conclude there is hope! But the battle will require a years of fighting.
(Did you know that motorcars were used in the Paris attacks? These 'cars are a boon to underworld criminals.)
-kb, the Kent from a state with a GOP governor who is playing into Daesh's hands: Massachusetts!

@_date: 2016-08-06 10:37:00
@_author: Kent Borg 
@_subject: [Cryptography] Generating random values in a particular range 
God, there must be plenty of prior art on this. I think I almost have some in materials I generated for a class I taught at the Boston Computer Society back in the late '80s--except I used the first technique and then explained it was biased, probably never wrote down the second.
-kb, the software engineer Kent who is proud to have no patents in his name because software patents are basically all crap, except now-expired RSA and maybe a few others.

@_date: 2016-08-23 19:02:08
@_author: Kent Borg 
@_subject: [Cryptography] "NSA-linked Cisco exploit poses bigger threat 
I'm looking for a chance to learn Rust. (Even makes writing multi-thread programs sensible projects.)

@_date: 2016-08-24 17:48:28
@_author: Kent Borg 
@_subject: [Cryptography] "NSA-linked Cisco exploit poses bigger threat 
It was quite clever of C to make pointers and arrays and strings all the same, it was efficient and elegant, but it brought dangers. Critics have always been dismissed, with the implication that they are not Real    "We are adults, we program carefully, this won't be a problem."
Except it has not worked. That clever unity of pointers and arrays and strings is still burning us, both in very old code and in new.
Arguing that any reaction is pointless, that it will always be possible to write bugs, is kind of like arguing that it will always be possible to crash an airplane. Okay, what's the point? All efforts are futile?
   "Lecture the programmers harder. Don't make mistakes!"
Disclaimer: The following might contain mistakes.
 From what I understand Rust manages to be as small and fast as C,  yet as safe as Python/Java, even suitable for systems programming.
   "Wait, safe *and* I can write device drivers?"
Not quite. If you have to do unsafe things (directly manipulate a pointer, touch hardware, etc), you have to do that in a block of code that is marked "unsafe". Be really careful in there, be ready to defend to your colleagues both the details of your unsafe code, and that the unsafe block need be there at all.
Where every line of a C program is dangerous, in Rust you can grep for them all.
Yes, Rust has an odd syntax for a C programmer.
The compiler is also very picky, figuring out how to make it happy can apparently be frustrating, but once you do there are whole classes of bugs that won't be there.
Possibly the most onerous thing about Rust is it obligates the programmer to specify ownership of all allocated data. Passing data to a function? Okay, but are you passing ownership of that data or are you just lending it? This has to be explicit. The benefits, however, are great: use after free or before allocation is no longer a problem, and a bunch of bugs endemic to multithreaded code also go away. So though Rust requires programs to be explicit about ownership, the programmer then no longer has to implement all that error-prone data-locking by hand.
To make array bounds checking fast Rust offers higher level access mechanisms, similar to Python's slices: If the programmer doesn't manage array indexes by hand, then Rust doesn't need to runtime check them! (Rust compiler trusts its own code generation.) What if you have an access pattern that you can't efficiently express in Rust? Okay, maybe just pay the bounds-checking cost, or maybe you need a small block of unsafe code: Be careful in that handful of lines. Be as careful as you should always be in C. Examine your unsafe block, have it reviewed, test it. Be skeptical.
Most of Rust's safety comes from compile-time static analysis (that's why the compiler is annoying). This means Rust is fast, and its runtime code can be (depending on what libraries you use) very nearly as small as that of C. Far smaller than Java, and I think even smaller than C++. Oh, and there is no garbage collector, seems the compile time approach works and there is no need. And though Rust might be a little bizarre, is it not as bizarre as something like Erlang!
We have a crisis. Our software is riddled with low-level bugs and it is only getting worse. I don't know whether Rust will be successful, but it seems quite clear that programmers are not capable of handling C's clever pointer/array/string-unity. What other languages are suitable for "I need every drop of performance and control", yet are this safe? Serious question. A question we should be asking.
Forgive me for going on so long with something that is not strictly crypto-related, but Rust is new technical ground for most of us, and crypto code also has these low-level bugs. Rust might help.

@_date: 2016-08-25 20:13:59
@_author: Kent Borg 
@_subject: [Cryptography] "NSA-linked Cisco exploit poses bigger threat 
Ancient fun-fact: Years ago there was an article in Byte magazine describing how a useful subset of C could be directly assembled into 68000 code. Not compiled, assembled.
C is a stunning assembly language. When those wild-eyed nerds at AT&T decided to write Unix not in assembly but in C (where was management!?), it was radical. But C was up to (down to?) the task, it was pioneering then and is still doing useful things decades later: From the fastest supercomputers to some pretty slim microcontrollers (plus a hell of a lot of Android devices) multitudes of computers run a Linux kernel compiled from the *same* C source code, with almost no assembly. Big-endian, little-endian: no matter. Different word lengths: no matter.
That is one impressive cross-platform assembly language!
Unfortunately, C is also a dangerous language that mortal programmers cannot reliably wield.
-kb, the Kent who knows he is pressing his luck on a moderated cryptography mailing list, but C deserves a lot of respect, as it also deserves to be efficiently sent into a dignified retirement.

@_date: 2016-08-26 14:48:38
@_author: Kent Borg 
@_subject: [Cryptography] programming languages and the people who (don't) 
was "NSA-linked Cisco exploit poses bigger threat than previously thought"
Doing Unix on a little PDP-11 was near magic. Just finding a modern memory part that is as small as the total memory in Dennis Ritchie's machine has probably been impossible for quite a few years now.
I said Rust has a small runtime. How small? A subtle question. Looking at  it looks like a nearly honest, minimal "Hello, world" running on top of Linux can be 5360-bytes, 32-bytes bigger than the matching C case, a reasonable build that uses Rust's IO and not a direct system call bloats to 160KiB, and a naive build with debugging info starts at 650KiB. Every library seems to assume a megabyte of RAM is nothing these days...
So for a Fitbit, baremetal assembly (aka C) is probably necessary, but those cases get pretty rare: I've seen an SD card that, in addition to being GBs of flash storage, runs Linux, casually on the side, to manage wifi hardware that also fits inside the SD card.
It is still important that crypto code be callable as efficient libraries. One wouldn't want to, say, instantiate an entire Python environment every time the caller starts a new hash or encryption. And it seems a good idea to program pretty close to the metal to head off timing attacks, not let keys drift off into garbage collection land, etc.

@_date: 2016-08-27 10:49:41
@_author: Kent Borg 
@_subject: [Cryptography] Say 'unguessable' not random 
That reminds me of how one of my bank accounts does it: I have an 8-character alphanumeric password that they chose for me.
This might seem like a too-short password to some, so let me continue, and annoy some of you further...
When I login they only ask for a few of the characters.
I am guessing they couple this with a significant tracking of my behavior: my IP address, my client versions, time of day and week, whether I have logged in recently, what my transactions were while logged in, whether I have the cookie they gave me last time, number of failed logins and the details surrounding those attempts, etc. Okay, the probably don't track all of those but I bet they have thought about all of those and they are on the list of security features they might add.
The "username" is not my standard (and very guessable) "kentborg"*, it is an account number, but not the bank account number, the number on my ATM card. My old ATM card (the one lost, that I left in a machine and walked away one stupid day).
   * I use "kentborg" mostly everywhere, so it is well known,
     and that was a problem for my brokerage account: someone
     was trying to break in. My password was high-quality, so I
     wasn't very worried, but the brokers were and kept making me
     change my password--too many failed attempts. So I changed
     the username, too, it is now also a high-quality "password".
     Problem seems solved. Good, I want to retire some day, rather
     not have that money stolen.
And they are watching other stuff. One day my account locked me out and when I phoned I was told I had some specific MS Windows malware and I needed to have an expert clean my computer before they would turn my online account on again.
This was odd, because I am on Linux. But I think I know what happened: they don't allow pasting into the account field but I got around that with the center-click paste feature in X windows. Their security monitoring detected that and IDed it as some specific malware.  The human I talked to on the phone was insistent that I needed to have an expert fix my MS Windows machine, but when I said it didn't apply to me, I was easily escalated to someone more knowledgeable who understood what I was talking about and turned on my account again.
But back to the overall password approach they use, I bet there will be disagreement, but I think it is excellent. It has a lot of really cool features. It forces the customer to write down the password (which is a good thing even though there is plenty of obsolete religious dogma that screams in opposition). It is very resistant to spyware. It has escalation options that don't rely on "security questions"**: I have not recorded the pattern, but they can know when they have asked for each password character and can keep one in reserve. It has very few driveby login attempts to worry about because the account number is pretty dang secret. It is non-standard enough (single character fields, one for every character of the password, but most are dummy, fill in the1st, 5th, and 6th...or something like that) that automated password entry from some buggy password utility probably won't work so they avoid being attacked at that integration--the html might also be rather scrambled so the entry fields are hard to automatically ID and the instructions might be just graphics (raising hell with screen reader software).
    ** I get asked a security question *every* time I login because
     I always login from a fresh browser context which doesn't
     have their cookie.
I have had this account for a few years and they did change my password once, the old one was only 6-characters. I am guessing 6 was plenty big for their basic design, but it didn't have the safety margin of being able to withhold some character for emergencies, and let some other character age out far enough to assume spyware probably doesn't know it.
-kb, the Kent who hopes he hasn't posted this description before and would be boring people.

@_date: 2016-12-22 18:38:05
@_author: Kent Borg 
@_subject: [Cryptography] USB hardware token for $2?? 
That device is still gnawing at me! It seems so useful, or at least like it should be so useful. But it has me suffering over endpoint security. It could secure sensitive information for me. The display looks so valuable to get information out, but what about getting information in? How does it know I am me?
A perennial question resurfaces: what is the smallest little computer device with a slightly, kinda reasonably usable keyboard?
For a password safe, for portable purposes, I have an Android phone that I have never allowed to see a SIM and be a phone, nor even be on the internet. But oh, horrors, it is terrible for entering encryption keys! Not too bad for a password (the two are different: passwords can be short, encryption keys/passphrases need to be crazy long! They are very I can type a practiced, pretty-mostly nasty-long passphrase on a real keyboard, repeatedly during the course of the day, with little effort. But how secure is that? I use decent hygiene on that device, but it is not sterile. I would like something I *can* keep sterile, small enough to have on me, but with far more usable passphrase entry than a cheap Android phone I keep incommunicado.

@_date: 2016-12-22 20:14:29
@_author: Kent Borg 
@_subject: [Cryptography] Photojournalists & filmmakers want cameras, 
Two thoughts:
  1. Be careful about demanding for robust "authenticity" features, they are in conflict with anonymity and otherwise can document too much. Sometimes we have something to say and we don't care if we can prove the picture is "authentic" via a digital trail, don't force an indelible provenance and sequence on every photo.
  2. XKCD  is a distraction. Being caught with an encrypted mobile phone isn't incriminating, it is common. If encrypted cameras were the norm, same thing. Let the owners of the cameras have the choice of how to deal with this, don't say they can't handle it. There are journalists and citizen journalists dying everyday over these issues, some would die before revealing a source (and then being killed anyway), many of the ones who are still alive know a lot about operational security, we shouldn't second guess them. They might mumble protests before decrypting the SD card in the camera, while keeping the sensitive card in their mumbling mouths.  (See item

@_date: 2016-12-23 07:47:40
@_author: Kent Borg 
@_subject: [Cryptography] USB hardware token for $2?? 
That starts to get really interesting. Almost a USB keylogger, but turned to the forces of good.

@_date: 2016-12-23 15:57:44
@_author: Kent Borg 
@_subject: [Cryptography] USB hardware token for $2?? 
Hell, yes.
Indeed, you have me imagining running it off a battery.

@_date: 2016-12-27 12:32:29
@_author: Kent Borg 
@_subject: [Cryptography] where shall we put the random-seed? 
Not just those scripts. Not every boot is preceded by an orderly shutdown. Once the pool is amply supplied, the seed should be written. And maybe on a regular basis after that.
-kb, the Kent who starts up his laptop more frequently than he shuts it down, because the OS isn't flawless.

@_date: 2016-01-01 15:01:04
@_author: Kent Borg 
@_subject: [Cryptography] Alice, Bob, Eve, Mallory, Maxwell ??? 
I kind of Like Maxwell, though his Demon (if I understand it) is smarter than noise, maybe suggests backdoored noise...save him for bad RNGs.
How about Claude? As in Shannon, in some sense the source of all noise. (Before him we still hoped it could go away.)
If there isn't, there needs to be.

@_date: 2016-01-20 13:47:40
@_author: Kent Borg 
@_subject: [Cryptography] TRNG related review: rngd and /dev/random 
The kernel cannot make a perfect RNG, there are system issues that are bigger than just the kernel's responsibility. The kernel needs to do the best job it can but...
A few years ago the Linux urandom maintainer seemed to be turning off every entropy source he could because none of them were well enough characterized for him. Crazy! (Then Ted took over again, thank God.)
It is important to have some entropy making its way in, but there is a logical extreme here to avoid: don't discard all your entropy just because none of it is perfect.
Heck: give me a backdoored RNG (the new NSA one!), and give me another backdoored RNG (what is Intel's old RNG opcode?), and I'll mix them together--maybe use the CPU temperature to control how the two backdoored RNGs slide across each other in time. And let me mix in the timestamp counter at every interrupt and let me mix in the most recent value of the Dow Jones Industrial Average and a few books off Project Gutenberg. And keep the attackers out of my box and a few meters away---and I will have a great RNG.
It is important to know the RNG isn't spitting disguised zeros, and that is hard. But mixing in complete crap--with something good--should not be a problem. Don't excise everything that you can't prove is perfect.
Someone on this list liked to dismiss stuff as "squish". I say go ahead and put in lots of squish. I know I would rather crack a simple RNG with only a few inputs that can be well characterized than a chaotic RNG with tons of inputs I would have to track. Mix in an interrupt from the fan's RPM sensor and let a door slam a couple times on a windy day--and as an attacker I am up a creek because I don't know what dozen-ish bits got tossed in when and I can't get enough clear RNG output before the internal state further drifts from my tracking.
"Oh, hell, turn this one over to the exploit boys who can just e-mail a damn infected spreadsheet and quit trying to do it the hard way."
Just making sure your RNG isn't flat out broken is really, really important and not so easy. Making sure it is perfect is a distraction.

@_date: 2016-07-08 20:44:59
@_author: Kent Borg 
@_subject: [Cryptography] What to put in a new cryptography course 
This sounds like a related question I was musing over recently: What would a course in cryptography for bankers look like?
I assume they know a lot of system stuff. From defining system boundaries to input validation to really simple checksums (the double entries balancing to zero). Further assume the bankers aren't programming their systems, but are in charge of them--they employ techies. They need to make sense at a high level.
Not that this is a unique position for just bankers, rather they seem an interesting proxy for a lot of folk in the world.
An analogy: I understand internal combustion engines--roughly.  I am not a mechanic but I can maybe sniff out whether my mechanic is telling me something sensible. The world needs to be able to sniff out whether they crypto they are being sold might be snake oil.

@_date: 2016-07-13 12:36:17
@_author: Kent Borg 
@_subject: [Cryptography] The Laws (was the principles) of secure 
Uh, oh! You invite me to rant about one of my pet peeves by including a trigger-word pair of mine in your very title: "systems" and "secure".
It seems to me that no one is ever honest about system security, starting by not being honest with themselves.
The problem is that you might design a *perfectly* secure system, yet attackers can still break in. How? By shifting system boundaries. We might say this started with social engineering and has progressed to spyware that sniffs passwords from users' computers.
So where is the pervasive dishonestly I casually assert? In not specifying system boundaries, and further, not offering any analysis of what risks exist regarding the details of those boundaries.
Many of the laws in your list hint around this, but I think it needs to be explicit. One has to understand what is being secured before you can secure it. And as you define the "what" that you are defending, I think you also need to defend and explain your choices: why you consider some aspects inside your system but not others? And this needs to be clear to the users of the system. (And if the users are naive consumers?, the problem is particularly difficult and, I think, important. Consider password managers and the false sense of security that is due to explode in lots of users faces...)
A specific example. I have a strange sense of fun, and a few years ago,  just for fun, I implemented an encrypted Python dictionary (intended to be used on top of persistent storage, such as Python's shelve, or maybe a cloud service). And it was secure!
Except, very aware of Kerckhoffs's Principle (even if I can't pronounce nor remember the name), I tried hard to examine what I had done, and wrote up for myself a technical analysis. A significant part of this was specifying vulnerabilities. Because even if I have made no mistakes, there were still weaknesses! I don't remember all the issues, but the obvious one off the top of my head is essentially traffic analysis. I included padding parameters so this could be mitigated, somewhat, and that was worth discussion. I forget what else I found, but in a key/value dictionary, I didn't just encrypt the values, but I also encrypted the keys, and doing that while implementing all the things a Python dictionary can do, is tricky, it involved tradeoffs, and those are important to understand. (I do remember I didn't get as far doing a multiuser version--as layering on top of a cloud service begs for--but that is when things get seriously difficult.  Unfortunately, the idea of specifying vulnerabilities--in a system that doesn't *have* any "known vulnerabilities"--isn't a common practice that I could copy, rather it just seemed like good engineering to me; it was something I needed to invent.
I assume this is not really my invention, that others have done so far better than have I, but why it is damn obscure? It shouldn't be!
Maybe include a law that says designers and users have to understand the "secure system's" boundaries.
Okay, I'll shut up now. Thank you for your patience.
-kb, the Boston-area Kent who also happens to be out of work...if the curious want to peek at his resume, they are cordially invited:

@_date: 2016-07-13 20:04:17
@_author: Kent Borg 
@_subject: [Cryptography] The Laws (was the principles) of secure 
Quite entertaining, if completely cynical, list.
Only if the computer doing the guessing can quickly validate all those Doesn't sound lie a password. I think you mean an encryption key passphrase. (Or a password on a system that is so insecure that your password isn't the weak link.)
Passwords and encryption keys are different.

@_date: 2016-07-17 12:38:48
@_author: Kent Borg 
@_subject: [Cryptography] The Laws (was the principles) of secure 
Very interesting. (I like "open design" as a simple term-of-art, gotta start over-using that.)
What I think is still missing among the interesting details of the trees is the idea of being explicit about the forest and understanding its definition and boundaries.
Seems a bit like talking about tactics and strategies of war, without explicitly discussing particulars of lines of control. (I don't remember Sun Tsu addressing the five-fold-nature-of-battle-lines, was it there?) Leaving this as an individual exercise for your officers and soldiers seems inefficient. Similarly, leaving this unspoken in terms of computer security seems lacking.
-kb, the Kent who has never been in the military and freely admits he is tossing out a metaphor he doesn't understand.
P.S. Heck, if nothing else the scene in the old war movie with big map, a contained buzz of quiet activity including calm subordinates using rakes to adjust tiny model armies and armadas, is such a powerful visual. What with all the movies involving cyber-intrigue these days, Hollywood needs this metaphor to make us better entertainment. I'm getting sick of meaningless monospaced ASCII whizzing by too fast indicating "important computer stuff you wouldn't understand".
P.P.S. My earlier rant on this, if anyone missed it and doesn't know what I am talking about:

@_date: 2016-07-27 10:18:09
@_author: Kent Borg 
@_subject: [Cryptography] LastPass Broken (and Fixed) 
I seem to remember saying something recently about how users are going to be dismayed when these password managers start blowing up in their It looks like an autofill browser feature in Lastpass could be tricked into autofilling all your passwords to a malicious web page.
Why would anyone sensible think such a tight integration with malicious code could ever be secure? Okay, so this one has been fixed. This one...
There is no way to build a secure system if you don't pay attention to the system boundaries. And a password manager that blends its boundaries with every website you ever visit is asking for trouble. But it's convenient, and convenience sells.
-kb, the Kent who is busily studying for a Google interview; so if you want to hire him better move fast:

@_date: 2016-06-27 09:00:21
@_author: Kent Borg 
@_subject: [Cryptography] RFC: block cipher randomization 
I like it is simple enough that even I can understand it. And even I can criticize it!
The argument that is can't hurt is nice. But I am not sure I buy it because it unpredictably changes the amount of data going through, it changes the number of blocks that need to be encrypted; that will ripple up to higher layers, possibly breaking things there. Might cause programmers to craft broken variants on otherwise good encryption modes.
What about doing a fixed expansion, sprinkle exactly N-bytes of random stuff in pseudorandom locations? That will still keep it from being a drop-in can't-hurt idea, but seems less dangerous.

@_date: 2016-05-08 18:33:24
@_author: Kent Borg 
@_subject: [Cryptography] russian spies using steganography? 
Maybe because the NSA watches everything that goes into and out of bit.ly.
I have a different question: Shouldn't steganography always be preceded with an encryption that outputs something indistinguishable from noise? (That is, no file format that frames the "secure" part.) Don't expect the steganography to obscure perfectly well, help it out by feeding it input that looks much like noise!

@_date: 2016-05-08 21:18:45
@_author: Kent Borg 
@_subject: [Cryptography] russian spies using steganography? 
A steganographic channel I have long thought is under appreciated is spam. I guess the flaw here is the real senders of spam seem to be pretty few (I see it come in in batches, some one person pushed a button, I see the results, not a lot of little mom-and-pop retail spam senders). Also, unfortunately to the spies, gmail does such a good job of filtering spam that who sees all that spam anymore?
Twitter also seems an interesting one-to-many channel. But I guess that depends on Twittter not letting the TLAs into their network, and not letting  them carefully monitor all the comings and goings.
-kb, the Kent runs his own e-mail server, so all his spam does make it all the way to his computer--he doesn't know how the rest live in the luxury of gmail.
P.S. I am convinced there are only a few big spammers,  "Who will rid me of this troublesome priest?", is a quote that comes to mind...

@_date: 2016-05-08 21:51:33
@_author: Kent Borg 
@_subject: [Cryptography] russian spies using steganography? 
Another problem with  shortened URLs is that where regular URLs might be thought of as a sparse address space (though /very/ non-uniform) shortened URLs are  very dense address spaces. Try one that is real, then increment and see what you get. Some juicy stuff is stashed in there.
-kb, the Kent who actually did some let's-explore-the-space playing years before he (last week-ish) saw--and appreciated--the story on the security risk there.

@_date: 2016-05-21 12:55:31
@_author: Kent Borg 
@_subject: [Cryptography] Entropy Needed for SSH Keys? 
Embedded devices are frequently starved for entropy, and frequently want to generate SSH keys on first boot when the entropy might be in particularly short supply.
How much entropy does modern openssh key generation need?
In a case I am playing with I want my own 512-bits of entropy after the ssh keys are generated. If I can come up with a nice plump 4096-bits at boot (common pool size these days for Linux urandom), and then generate the ssh keys, how many bits will be left over?
This might be an elementary question, but embedded people are always getting this stuff terribly wrong, so my excuse is that a little repetition is good.

@_date: 2016-05-22 21:18:10
@_author: Kent Borg 
@_subject: [Cryptography] Entropy Needed for SSH Keys? 
Dammit, I can neither remember nor find that quote about how using a deterministic process to make up random numbers is against nature, or grace, or the universe. Like I say, I can't find it.
That agrees with another answer I got, but the worrywart in me frowns on putting so much faith in the perfection of SHA-1 (to pick a random version of Linux's drivers/char/random.c). Especially when it can be so easy to stir the pot and make a guessing observer's life a theoretical hell and not just a practical hell.
You hedge. Why? If the crypto is good, if it hides the pool state, what's the problem? At how many bits of draw does it become a problem? And why then? Why the hedge?
Another response I got also referred me to  but it looks completely experimental, watching keys degrade as the system is starved of entropy.
Let me try my own experiment:
   # strace ssh-keygen -t rsa
Lot of output, only one mention of the string "random":
   [...]
   open("/dev/urandom", O_RDONLY|O_NOCTTY|O_NONBLOCK) = 3
   fstat(3, {st_mode=S_IFCHR|0666, st_rdev=makedev(1, 9), ...}) = 0
   poll([{fd=3, events=POLLIN}], 1, 10)    = 1 ([{fd=3, revents=POLLIN}])
   read(3, "\255J\373\231\323\256\251^\314\207MqkC\332\222^\352\275\307\373\351bM\267\273\260$G\232\301\r", 32) = 32
   close(3)                                = 0
   [...]
(Was I supposed to say "dsa"? Okay...tried that too, same result.)
Looks to me like it read 256-bits. I would have expected it would have read more, just to waste if nothing else.
No where near using up 4096-bits (if "using up" even is real). Maybe do both DSA and RSA? It still would only "use" 1/8 of a 4096-bit pool.

@_date: 2016-05-23 12:51:18
@_author: Kent Borg 
@_subject: [Cryptography] Entropy Needed for SSH Keys? 
Hear, hear!
I have long argued that an important consideration is the distance at which your foe is forced to observe.
Consider the timing of a network interrupt.
A CPU's system clock doesn't even exist outside the CPU chip (clean GHz-plus clock distribution is hard). So these digital chips go to the extra effort of including an analog PLL to multiply up from a far lower external oscillator that itself is fed only a very short distance to one of the chip leads. So if it is a fast Intel-ish chip, an observer just a few inches away will have a hard task to know what the Time Stamp Counter's LSB will be at the instant the CPU reads it. And as the observer's distance increases, low-order bits become unknowable--to that observer. An observer at a couple meters is worse off than an observer hovering over the CPU, and observer just at the other end of my last-mile DSL link (millisecond-order latency) is going to be in the dark about a lot of low order bits in the TSC. That observer likely can estimate a little beyond the number of high-order zeros in the TSC (ie, When building an RNG, merely putting it in a big metal box--say, the size of a computer--accomplishes a lot.
Unfortunately, Arm chips don't have counters running as fast a TSC, so you get far less ignorance per interrupt per meter-to-which-you-can-push-off-your-foe. But this ignorance is still significant, if not entropy.

@_date: 2016-05-24 10:05:16
@_author: Kent Borg 
@_subject: [Cryptography] Entropy Needed for SSH Keys? 
I like that. Not a lot of bits, but some.
Assume there is no jitter. Just consider that the TSC is running at over For an observer to know what value the CPU will read, that observer will have to know not only how the CPU might jitter (and let's assume zero), but also the observer needs to know the state of the clock. Not just how many ticks have gone by (hard already), but exactly *where* the edge of those ticks are or an LSB value will slip by. The observer needs precise phase information.
Isn't this essentially an exercise in clean distribution of a crappy clock? That clock only exists over the space of a few millimeters--but enough span that the "correct" phase information starts out ambiguous.
Tracking a good clock is hard (the right answer is a win), tracking a crappy clock is harder (gotta know the specific wrong answer). GPS is designed to be as accurate as possible, yet its time distribution accuracy at best is nanoseconds. Frequency accuracy (an easier problem) is still only 10-times better via GPS. But an observer of my TSC needs to do still better, tracking a crappy clock, without my cooperation, from how far away?
Thought experiment: Best-case design a system that can precisely track phase of a 2GHz CPU clock over a distance of meters. A clock that is referenced to a crystal that is not temperature compensated, multiplied up by a PLL that is designed only to be good enough, and then intentionally made worse with a spread-spectrum smear varying the frequency. Spend millions if you have to, be big and bulky, but track that clock edge.
How confident are you that it can be done at all? And if it can be done, to a distance of how many meters?
Now do it covertly and cheaply.

@_date: 2016-05-27 10:12:28
@_author: Kent Borg 
@_subject: [Cryptography] Entropy Needed for SSH Keys? 
Sorry, I am talking about measuring against external interrupts.
I guess I am promoting that old trick of beating two clocks against each other. But I am impressed that one clock (in the case of Intel chips) is pretty special: it is running very fast, it is physically small (does not even exist beyond a span of a few mm), it is designed to be only mostly regular and not particularly stable. It drives a counter that can be sampled in response to an interrupt. As a bonus, this interrupt servicing is itself very complex--but I don't trust that either.
The other clock (interrupt) has to be much slower: The CPU is mostly for doing other work and doesn't want to spend all its time servicing interrupts, and it is physically incapable of servicing interrupts at anything very close to its internal clock speed.
It also seems important here that the TSC is running fast. We aren't talking lots of big fat nanoseconds here, we are interested in the precise phase on a sub-nanosecond period. I don't think we have to pine for sloppy mechanical stuff like keyboard and mouse activity, I think any interrupt from any other subsystem will do--let's fudge it and say "subsystem with its own crystal". Certainly anything so external as a network interrupt is great.
Is there a term for how far a photon can travel in a clock period? Well, whatever that might be called, if the physical distance of a second clock is on-order that far away--inches in this case--it feels like the problem changes. It seems there is real entropy in the analog aspects inside the CPU and there are theoretical problems with how well that could ever be communicated to a distance, and similar problems with how well it could ever be correlated at a distance.
Or am I being overly impressed by how a fast 2GHz is?
-kb, the Kent who remembers kilocycles.

@_date: 2016-11-12 21:31:20
@_author: Kent Borg 
@_subject: [Cryptography] would email encryption have saved Hillary 
Endpoints are the final weak link.
But! Even if the computer of the person on the other end is really secure, that person is part of the system, part of whether the larger system is secure.
Secure from what? Against whom? Working for whom?
There is always a further endpoint, there is always more system off the end of this system (which was not well defined to begin with).
Also, I thought Eastasia was our friend!?
-kb, the Kent who is not a cynic, the Kent who insists that there are many miles improvements before we get close to Manning and Snowden and Philby being our bottom-line worries.
P.S. I have a nice job starting at the end of the month, so it is too late for you folk. So there. You had your chance.
P.P.S. I am also worried for Snowden. It was pointed out that Putin has no need for him now. Part of Snowden's motivation was worry of what would happen of a less benign president than Obama took power. Has that happened? If Obama can't pardon him, maybe he can lift the pressure and let him (oops!) escape to a better refuge.

@_date: 2016-11-22 10:25:50
@_author: Kent Borg 
@_subject: [Cryptography] combining lots of lousy RNGs ... or not 
Your definition of squishy is, shall we say, rather squishy. Any candidate source that is neither perfectly good nor perfectly bad, you call squishy. Why do you waffle? Why won't you definitively tell me whether the source is good or bad? Because you don't know! What *do* you know? You know that you can't predict its output, otherwise you would declare it "reliably predictable". Well, if you can't predict it, then it is useful, for XOR-ing it in will remove you from the population of observers who could predict the next random draw.
Get off the "squishy" hobby horse and hop on the "correlated" hobby horse: Much more useful would be if you were pedantic on whether candidate sources might be correlated with other sources. Because XOR-ing one more source can be *very* bad--if it is correlated with a previous source (e.g., some beautiful quantum-derived bit stream, and an inversion of the same bit stream).
What would you call a backdoored RNG from the NSA? I think you would say "reliably predictable", but I would say "useful"!
Give me the NSA's backdoored RNG, give me a Chinese backdoored RNG, give me a Russian backdoored RNG. The more the merrier!
All "reliably predictable", but I XOR-them together and (assuming an observer can deal with sync issues), they are quite predictable to...very probably no one.
To put icing on the cake, I then XOR in some "squishy" local noise source. Maybe something that is very knowable to a local observer (who can see my lava lamp in the window), but as long as it isn't also know to that mythical cabal who has the keys to all those backdoored RNGs, the population that can predict my next random draw goes to zero.
Thought experiment: Is a streamcipher of a counter "reliably predictable" or "reliably unpredictable"? I guess you would call "squishy", because the key *could* be known. I would say the category "squishy" is meaningless, rather this hinges on on very concrete things: whether the cipher is good, and whether the key actually is known. (My taste is for local secrets to change. It unnerves me that if that local key is static.)
The goal isn't to have some perfect head-of-a-pin output, the goal is to get the number savvy observers ever closer to zero; the goal is to make the last holdouts work so hard acquiring my local RNG state information that they might just as well have rooted my computer in the first place because it would have been far easier, cheaper, and more resistant to detection. (The goal is also to worry about whether local software is actually using this valuable random data and not ignoring it.)
-kb, the Kent who doesn't care whether his RNG produces random data, he just cares that no one can back out all the "squish" and predict the next draw.

@_date: 2016-11-23 11:40:31
@_author: Kent Borg 
@_subject: [Cryptography] NIST Updates Password Recommendations: WOW! 
I haven't read the actual NIST publication yet, but the TL;DR from Sophos ( has some nice stuff in it. Such as saying quit forcing users to change passwords for no reason, and don't use SMS as a two-factor device.
I hope people read it--I have it in my queue. Looks like a lot of longstanding dogma gets finally gets thrown under the bus.
The full NIST version: Their github (!) sources: -kb, the Kent who doesn't know whether they say to write down passwords with paper and pencil.

@_date: 2016-11-23 17:17:53
@_author: Kent Borg 
@_subject: [Cryptography] combining lots of lousy RNGs ... or not 
In a sense each entropy source needs to be consider others almost as adversaries, to be sure they are independent.

@_date: 2016-11-27 12:02:44
@_author: Kent Borg 
@_subject: [Cryptography] Is Ron right on randomness 
I just now went to your web page for SC4-HSM. I hadn't seen it before. Very interesting! Cool, even. You have my mind mulling over some of the possibilities. Being fully programmable, having a display, two user buttons, and maybe even a dang secure place to lock away secrets, all in a little and cheap USB fob, the possibilities are quite attractive.
-kb, the Kent whose a quick Google search suggests it could maybe even be programmed in Rust for less chance of being vulnerable to buffer overflow attacks, etc.

@_date: 2016-10-01 19:09:33
@_author: Kent Borg 
@_subject: [Cryptography] Use Linux for its security 
From what I understand of Rust... it pays for its safety in time, but in compile-time, not run-time.
Tricky!! Seriously, they seem to be doing some clever stuff here.
They pay in compile time, combined with such things as requiring the programmer say whether the data being passed to a function is being (1) given away, (2) a shared read-only reference, or (3) a writable reference but on a loan that will be returned. This is stuff programmers already worry about at a lower level, by telling Rust more about what is going on, it can enforce data safety for us--at compile time. It makes the rustc more annoying than cc, but in exchange for less debugging and fewer low-level bugs leaking through.
In Rust data can be writable or it can be shared, but not both, at least not at the same time.
Much of programming is getting straight who allocates data, who looks at it, who touches it (plus coordinating when do the lookers and touchers do these things), who frees it, and does anyone try to touch or look at it after it has been freed. Not only is this a lot of the work of programming, it is implicit and scattered all over the place. It makes multithreaded code hellish to maintain beyond its first optimistic writing.
By forcing programmers to be explicit about ownership Rust can then enforce that ownership.
If I call a function and pass ownership of some object to that function, Rust can see that at compile time, so if I then try to access it after that point a static analysis can detect that and blow up at compile-time not run-time.
Similarly, if I pass a shared reference to some data Rust will enforce that as read-only data everywhere until all the shared references go out of scope, at which point the original owner owns it again, free and clear. And if no one owns it anymore it gets immediately reclaimed, without explicit freeing nor waiting for garbage collection.
I don't fully understand how Rust comes up with a compile-time solution to know when blah-blah allocated data is squirreled away in some other data structure and when it is not, but apparently it can.
As for bounds checking, something that sure sounds like a run-time cost, the Rust approach is try get the programmer to say what access is needed, but at a higher level. For example, there is a slice syntax that is a bit like Python. If that fills the bill then there will be *zero* runtime cost for bounds checking because Rusts trusts its own code generation, it trusts its own index arithmetic, so it runs at full speed. No extra checking required. (And are we really going to miss writing "for (i=0, i<len; i++) ..." over and over again?)
But what if there is an access pattern that cannot be efficiently expressed in Rust, what if you really need to do some run-time index calculation that hops all over the place?
A couple options.
How much data are you accessing? Is this a one-off access? Then pay the price, let Rust do the bounds checking, it's a service.
Or, what if it really is a hot little loop but chaotic as hell? Then maybe you need an unsafe block with maybe a whole dozen lines of code in it. Okay, but that is still a win. But...reconsider whether you really need an unsafe block there, look at your code carefully, test it carefully, and have it reviewed carefully. Frown hard over that unsafe code.
Instead of every line of the C program being unsafe, in Rust you can grep for the unsafe code. Being really careful is easier to do with a dozen lines of code than with thousands or millions. That's why Rust is a suitable language for low-level systems programming. Every line of Linux kernel C sources is unsafe, but only a small minority are doing something inherently unsafe, only a small minority would need be marked unsafe were it written in something like Rust.
I think there is an odd trick going on here: by giving programmers higher-level features Rust designers have figured out how to better know in advance what the hell will be going on. They somehow designed the language to make it possible to move abstractions closer in time, move them into compile time, where they can be bolted down safely.
I don't understand this well enough to grok the corner cases that must be there where this falls down, but apparently it mostly doesn't. I guess language design has progressed; I guess computer science is still -kb, the Kent whose Rust understanding is admittedly incomplete.

@_date: 2016-10-31 12:38:58
@_author: Kent Borg 
@_subject: [Cryptography] Nundrum cipher = hypothetical WWII cipher 
============================== START ==============================
Very cool. If anyone ever goes to the effort of building an "authentic" one (or just making a detailed design), it would be quite fun to see that "could have been"-artifact.

@_date: 2016-09-02 17:02:20
@_author: Kent Borg 
@_subject: [Cryptography] New approach needed to IT, 
Story from the very belt-way sounding "fedscoop": First two paragraphs:
Amazing that this could be news. But it is.
Just look at each new retailer with a credit card break in. We laugh at Target for not heeding the intrusion warnings they had. Yes, they deserve ridicule for that. But what about the folks who make a PoS system that is apparently just a PoS? Why are they still in business?
Another quote:
I feel like he was cribbing from my recent rant on how we need to understand and specify our system boundaries. I also feel like this is off-topic for a cryptography list--at least from the old cypherpunk perspective that writing good crypto code will solve our security problems. But what good is the best RNG if someone trying to use it doesn't wire it up right? What good is the best cypher if someone trying to use it can't manage the keying and use a sensible cypher mode? What good is any of this if input isn't sanitized and attackers can get directly to the backing database? (
A lot of clever people have done great crypto work, and it seems we now have a good set of powerful primitives. Snowden confirms that good crypto works. And there might be some great crypto buried in Fancy New Product, but if that product is otherwise riddled with security blunders, what good is it?
Crypto people are practiced at thinking in security terms, but the people building insecure systems left and right are not. I know we have plenty of opinions and are familiar with no one else being much interested in them, but I wonder whether things might be shifting. Is it time to make a different kind of noise?
If the budding, young, somewhat-technical manager in charge of building some new website, or app-plus-cloud product asked "How do I manage this so we will not be broken into and make the news?", do we have anything to say beyond "Hire people who know what they are doing and sternly tell then not to fuck up."? If the NIST guy, Ron Ross, asks a similar question, do we have anything better than "Don't let the NSA hand you backdoored RNGs."?  (He probably agrees with us on that.)
Is it time to elbow aside "agile programming" in favor of some new buzzword-compatible philosophy that pushes people toward not committing so many security fuck-ups? Make it simple enough to summarize in a short paragraph, but real, something to have seminars about, something that can work if it gets a chance to command significant mindshare. Something the somewhat technical manager can grab onto. Is there currently something out there like I describe that could use more promotion? Someone on this list maybe makes a pile of money writing a popular business bestseller that Important Executives can mostly finish on a long plane flight?
Someone tell me we might ever get to the point that building a secure system* could become an even slightly common occurrence.
-kb, the Kent who is still unemployed and so helpfully, and shamelessly, posts a link to his resume for any who might be interested * What the hell does "secure system" mean? I say you gotta define what you mean, as part of defining the system boundaries: Say what you are defending and against what. Say what you are not defending, say what attacks you can't fend off.

@_date: 2016-09-08 12:25:40
@_author: Kent Borg 
@_subject: [Cryptography] Secure erasure in C. 
How about something like this?
   unsigned long secure_erase(void *buf, size_t len)
   {
     size_t index;
     unsigned long total = 0;
     srandom(time());
     for (index=0; index<len; index++) {
       ((char*)buf)[index] = (char)random();
     }
     for (index=0; index<len; index++) {
       total += ((char*)buf)[random() % len];
     }
     return total;
   }
Convince the compiler that you are interested in the return value, and doesn't it have to do the work? Maybe the second loop could be shortened to a single random array access. Faster would be to do wide accesses, maybe some unwinding, but that's more work to write. And too much such work might give too many clues to the compiler.
The optimizer isn't so perverse as to reverse engineer random(), is it?
I like using random (-ish) data for things like testing disk speed or network speed or RAM bandwidth, because zero is a common thing to cheat about, some subsystem recognizes what you are doing and agrees to pretend the data is now zero, effectively doing some really efficient compression. As memory subsytems get more and more like disks, they might start doing these tricks, too. And as has been mentioned, with virtualization sneaking in without always telling you, you aren't just doing battle with the optimizer; your zeros might get deduplicated with other's while your real data lives on, sitting there, itself trying to be deduplicated with completely unrelated data belonging to completely unrelated customers.
I want to avoid what I like to call The Mikado Rule.
As Koko said in Gilbert and Sullivan's The Mikado:
    It's like this: When your Majesty says, "Let a thing be done," it's
    as good as done  practically, it is done  because your Majesty's
    will is law. Your Majesty says, "Kill a gentleman," and a gentleman
    is to be killed. Consequently, that gentleman is as good as dead 
    practically, he is dead  and if he is dead, why not say so?
The argument was good enough in the very silly world of The Mikado, and it is also the general approach to efficient modern computing.
Using random (-ish) data is a way to force the work.
-kb, the Kent who won't make a gruesome and current Syria analogy to photographic evidence and Bashar al-Assad.

@_date: 2016-09-08 18:45:06
@_author: Kent Borg 
@_subject: [Cryptography] [Crypto-practicum] Secure erasure in C. 
Along with the CPU and the network and ...
Our Man Flint! I am so old I remember the movie. But I don't immediately spot the flash connection.
I guess I still like the overwrite with random (-ish) data. If you had reason to trust that buffer in the first place, why not trust it to accept the overwritten data? Seems a way to get the compiler to do what it is told: tell it something complicated.

@_date: 2016-09-08 23:06:46
@_author: Kent Borg 
@_subject: [Cryptography] New approach needed to IT, 
But he might be an ally. What if, through a stroke of lightning, *you* suddenly got an important job a NIST, how quickly do you want to get fired or suffer a general mutiny? What if you decided to enlist some external help to turn the tide? Maybe it would be nice if someone offered some help.
I don't know the man, but from the story I read, he might be a good guy, maybe he thinks being screwed by the NSA on the RNG was a bad thing, too. I don't know, but I am inclined to give him a benefit of the the What if we did happen upon a good guy, what should we do?

@_date: 2016-09-09 15:22:39
@_author: Kent Borg 
@_subject: [Cryptography] Secure erasure 
Most of the "secure erase can't work" in this thread seems equivalent to "memory can't be trusted". Indeed, there is a lot of reason to mistrust hardware. Okay then, do you dare do any cryptography at all in your hardware? If so (big if), then how to do a secure erase becomes a sensible question.
Whether the hardware is trustworthy maybe isn't completely binary, systems like to cheat for efficiency sake and not because they are evil, which is why I like writing something more interesting than than just zeros. Give the hardware more to chew on to try to get it to actually do the chewing.
Cute picture, and though it might be a security fail, it might not be a legal fail. A little like locking just a screen door: it won't stop a forced entry but it turns it from something that might be no offense at all into "breaking and entering", possibly a full crime. Legal deterrence does have value.
Trespass, similarly, can turn on whether notice is given. People like to tear down no trespassing signs and say they didn't know. Tearing down this would take a little time and probably hit a dollar threshold designed to elevate the vandalism offense. And having a path might be pretty clever, a way to lead would-be trespassers to the prominent notice, without littering signs every few meters--each then easy to remove and again claim "Oh, I didn't know."

@_date: 2016-09-10 12:00:44
@_author: Kent Borg 
@_subject: [Cryptography] Secure erasure 
Very good points. These questions are interesting to think through, but absent a threat model, how do you decide?
Well...how DO you decide? If one is building some crypto component, how can the final threat model possibly be known? Um, gotta make some guesses.
Okay, once you make those guesses (let's call them "assumptions"--sounds classier), shouldn't they be captured? So when someone gets to the point of applying your component as part of building a larger system, when a threat model is closer to being knowable, the consequences of those assumptions could be worked through?
[Pretend I here repeated my recent rant about needing to define system Once you make some assumption about threat model, you are also baking in vulnerabilities (being vulnerable to the threat models you can't, or choose not to, defend against). Shouldn't these vulnerabilities be documented by defining what is inside your system and defended, and what is outside and so the responsibility of the larger system using it? And at the next higher level up, when someone builds that bigger system incorporating your component, shouldn't someone also document the system boundaries and threat model assumptions made at the level? Does this ever happen? I know we say RTFM, read the millions of lines of source code too...
At each subsystem level there will be configuration options that the larger system needs to get the right behavior; these are dangling bits that the subsystem necessarily can't control, yet it requires they *be* sensibly controlled. They should be handed off carefully, but I don't see that happening.
As we build systems it seems like there is a whole stack of security assumptions being made but not documented nor otherwise coordinated. How could we ever hope to build secure systems that way? Oh, wait, we don't come close to building secure systems.
This approach seems doomed to fail. That's why it does.

@_date: 2016-09-13 12:19:16
@_author: Kent Borg 
@_subject: [Cryptography] Secure erasure 
That is wonderful.
The idea that it isn't the locks that are defective but how they are mis-installed in the door (and the door mis-installed in the wall, and the wall mis-installed...) reminds me of an ancient quip, which Wikiquote tells me is Weinberg's Second Law:
     If builders built buildings the way programmers wrote programs,
     then the first woodpecker that came along would destroy civilization.
That was a long time ago. Since that was coined things have only gotten worse as we choke on complexity (OPM didn't even know what servers it had), and now we are automating the creation of more complexity. With Docker and Kubernetes enormous packages can be efficiently poured into scads of virtual computers with a few clicks. Even if people knew how to deploy the crypto bits, they don't know what is in the rest of their systems, there is no way all of those subsystems are ever composed in any sensible way. Not to mention all the buffer-overflows pre-written for us inside all those subsystems.
Once upon a time, long ago, I was on a team of three programmers and we programmed up everything it took to do one of the first computerized scanning electron microscopes. (It was a cool machine, it could look at things like mayonnaise. A scanning electron microscope...looking at a mushy insulator!) Sure, we bought an RTOS and maybe a TIFF library, but everything else was homemade. The result was a naturally lean system*, we knew what was in it, a sane basis for making a secure system. (In that pre-internet era it was well air-gapped and naturally dang secure.)
* It had to be lean, computer power wasn't infinite back then. Today my Pebble watch (the lean smartwatch) probably has a more powerful CPU and about the same RAM as did that 68000 VME system.
But that was 30-years ago. Time passes, and there has been a qualitative Now we build systems by gathering up the most "powerful" (aka featuritis plagued) subsystems we have heard of, tinker with config files, write some code until we can get the monstrosity to do things, and hire a "designer" to make it look flashy. And not just web stuff, have you looked at the size of that "clean slate" project AOSP (the open source parts of Android)? It takes hours to compile, on a fast machine. Millions of lines of dangerous code.
KISS is only receding, and with it any hope of crafting secure systems. It has to be possible to do something about this, because I think I see more woodpeckers gathering.
What difference does the crypto make in these circumstances?

@_date: 2016-09-13 14:14:44
@_author: Kent Borg 
@_subject: [Cryptography] Secure erasure in C. 
I've worked on a Big/Little SoC: they have hardware that automagically maintains cache coherency between different clusters and different cores. I forget the details, and they are detailed, but I seem to remember that in Linux a lot of cache management macros turn to no-ops. Another example of your data multiplying out there, or at least multiplying on-chip.

@_date: 2016-09-13 20:27:34
@_author: Kent Borg 
@_subject: [Cryptography] Secure erasure 
Yes! Security and reliability are closely wrapped in each other. We need one to get the other.
Hard to do, but if we define the component boundaries, there is a possibility of carefully composing them into a larger system that has some hope. Even Target's PoS system *might* have been secure, had it been on an isolated network, but they didn't know if that be so, and they probably still don't know.
A religious faith in firewalls and intrusion detection systems distracts everyone. We heard a lot about Target ignoring their intrusion detection system, but did we hear much about their PoS system being a PoS?
When we can neither trust the chips nor trust UPS to deliver them without further tampering, there are lots of holes, but the way we build systems adds more.
-kb, the Kent who repeats Jerry Leichter: "Security is a *system*

@_date: 2016-09-17 14:36:34
@_author: Kent Borg 
@_subject: [Cryptography] Ada vs Rust vs safer C 
[Jamey: A thread on the moderated Cryptography List is talking about the dangers of C, and Rust comes up, and I am now mentioning your Corrode project--so I added you to the CC. Hope that's okay. The thread might be getting long-in-the tooth, so this might just end up being an FYI. -kb]
There is at least one (seems active) project, "Corrode", to automagically convert C code to Rust.
   The developer, Jamey Sharp, seems to think it could be useful. From my ignorant position I fear the output is going to range from horrible to won't-compile. Maybe it would be a good starting point in porting old code. Turning its output into "real" Rust code could be a lot of work, but it might easier than starting from scratch: a way of checking you have reproduced all the feature points (and figured out which of them are actually bugs to be discarded).
If one of the "features" of C is its latent bugs, then, though a mechanical translation might eliminate segfaults, it seems the bugs will still be in any faithful translation. Maybe the biggest benefit would see where the C code is too groady to translate at all--might be a lot of code.

@_date: 2016-09-18 14:04:48
@_author: Kent Borg 
@_subject: [Cryptography] Recommendations for short AES passphrases 
I finally saw Citizenfour, and the voiceover at the beginning said to assume that a they can try a trillion keys a second. That would be the US government, ~3-years ago, in a case where they are really pissed. Other cases would be slower.
Looking at hashcat speeds ( on an 8-GPU system (pretty affordable for many values of "medium"), is a lot slower, but dang impressive. The comments say the PBKDF2 numbers are all 1,000-rounds, I don't know which matches your proposal.

@_date: 2016-09-18 15:38:38
@_author: Kent Borg 
@_subject: [Cryptography] Recommendations in lieu of short AES passphrases 
I have some disagreements:
- Password managers are a bad idea. They become an all-eggs-in-one-basket, single-point-of-failure. Why should we trust them to be both competently written and honestly written? Even if they are perfect, what about some local malware that compromises the machine accessing them? Was it Lastpass that was recently broken? Why will that be the last vulnerability? My advice: Write down passwords on physical paper, obfuscate them slightly, obfuscate what accounts they are for, keep that paper safe! Frequently copy new entries to a second backup piece of paper which you store apart from the first. (Don't trust photocopies to backup your password list, unless you have an obsolete analog copier.)
- Two-factor authentication is trendy but not always good. You don't distinguish between two-factor as a password recovery mechanism and two-factor as a supplementary measure. I have a bank that insists on sending me an SMS every time I login, because I always delete their cookie. Fine with me--as a supplemental measure, but cellphone numbers are easy to hijack. As a recovery mechanism SMS becomes a gaping hole: bad guy ports your number and recovers your password. Similarly, you don't distinguish between different kinds of two-factor gizmos and how hard they might be to hijack (cellphone vs. physical fob token with changing numbers). However, RSA had a complete breach of their tokens a few years ago--I don't really trust any of them.
- You don't clearly distinguish between passwords vs. encryption keys. Passwords don't need to be very strong, they are supplied to some login-mechanism that should throttle how fast attempts can be made. 32-bits of entropy (e.g., quebec-natural-group or cabaret-mystery-export) can be easy to remember and easy to type, yet plenty strong for any decently set up system. And if the system is not decently set up? Then there are probably a lot easier ways in than brute-forcing your password. And if the hashed version is acquired? So what! If you don't recycle passwords, it only means the crackers might log in as you, to a machine that it seems they already have access to. So what. Change that password, or quit using that insecure service. Encryption keys, however, are a completely different beast! They should be dang long. A very important distinction! A key like 62b-72c98-60a3-4ce0-b1a4-2abd0-ca14bc5 is pretty impossible to remember but not impossible to carefully type, and pretty much a necessary length for a secure encryption key.
Some possibly missing points:
- Some accounts are more important than others. Accounts that involve money are obvious, but also e-mail accounts that would be part of a password recovery mechanism for other accounts (such as the ones that involve money). Also be careful with accounts used as login mechanisms for unrelated services ("Login it with Google or Facebook!"--I recommend not doing that when possible.). These more important accounts don't need better passwords, but they do need better care on your part to protect them.
- For important financial accounts that allow you to pick your own username, pick a password-quality username (world-project-flash) in addition to a password-quality password (shrink-digital-disco). Now there should be no risk of being locked out because of too many failed logins from some cracker, and it makes a rogue password recovery harder.
- Don't give your password to anyone or anything other than the account you are going to use it for. Don't type it on the computer in the hotel lobby. If it is important don't type it on your friend's computer. Don't type it into the wrong account, don't type it into a link you clicked on in an e-mail. Ios and Android devices that are connected to the internet and used for all that cool stuff they can do...are not a good place to type important passwords, they are too big a target for malware. Don't use wireless keyboards and mice. Segregate your reckless and buggy computer activities from important passwords: Consider keeping a computer that you maintain very conservatively and only type important passwords on it; don't install any software on that computer that you don't have to--don't stick into it random Windows device driver disks for random silly gizmos that you don't need. Don't have your kids installing unnecessary software on your conservative computer. If you go really crazy about maintaining a separate, secure computer...then maybe use a password manager--an offline password manager, no cloud stuff. A simple password manager that doesn't automatically type passwords for you--you don't want automatic things happening with your passwords, automatic things go wrong, automatic things are dangerous.
- Changing passwords. There is religious doctrine out there that passwords should be frequently changed. I think it is worth saying that, unless you give the password to someone, unless you have reason to think it was stolen, unless some stupid admin requires you change it, there is no need.
- Passwords are important. Pretty much your whole life sits behind passwords, it is worth taking care regarding passwords.
- Trying to hide something off-the-grid isn't as easy as you might think: Just because *you* don't set up an online account for your retirement funds doesn't mean there isn't one still sitting there, ready for an attacker set up. First time setups (mother's maiden name...) are not as secure as a decent password. Set up all your accounts.
About the burden of not recycling passwords:
As far as I can tell, everyone thinks it is a bad idea to recycle passwords, but almost everyone does it anyway. A shame. Yes, it requires some discipline to record all those passwords, but it isn't so cumbersome once you are up and running. If you have easy-to-remember and easy-to-type passwords (farmer-turtle-sardine) you will quickly learn all the ones you frequently use, and then you just type them in when needed. The only time you have to refer to your records is for obscure accounts you don't use often, which means not that often. I refer to my password records just a few times a week, because mostly I know the passwords I use.
-kb, the Kent who disagrees with a lot of people on these topics.

@_date: 2016-09-18 17:43:08
@_author: Kent Borg 
@_subject: [Cryptography] Recommendations in lieu of short AES passphrases 
I do think it is possible to use an electronic password manager, but I also think it is really hard to do well, and really risky for a normal person to attempt. One false move, and while you sleep a Russian mobster on the other side of the planet can destroy you.
In contrast, physically writing down passwords is pretty simple, and hard to mess up on an invisible technicality. We are pretty familiar with physically protecting things--far better than we are with protecting data. A written record isn't as flashy, but it has an attack surface that is tiny, very local, something a normal person has experience with, something it is possible for a regular person to judge and reason about. For those among us who long ago learned they can't go a week without losing a wallet or car keys, they might then also figure out some important passwords should not be carried around on a daily basis, either. By being in the physical domain, these are all things normal people can reason about.
But whether some particular buzzword-compliant password manager that has a 4-star rating is a good or bad choice, because it does or does not use a good ZK design, is not something normals can judge.
Certainly there is the argument that users are bad about passwords, because they clearly are! But this isn't going to be fixed with some magic technical solution.
We expect regular people to have some horse sense to avoid getting ripped off in the physical world (we start teaching how as toddlers), but in virtual worlds techies like to throw up their hands, chant 2fa, and tell us to start ordering retina scanners.
People are going to have to learn a little. No way around it. I don't think Joe Average needs to become a STEM wizard (I hate that fad), but I do think Joe has to learn a little. Starting with "don't recycle passwords", "write them down", and some diceware-style advice for how to choose decent passwords.
I don't think that is a horribly ambitious idea, I don't see any simpler approaches, and I think it would accomplish a lot.

@_date: 2016-09-19 08:39:02
@_author: Kent Borg 
@_subject: [Cryptography] Recommendations in lieu of short AES passphrases 
That's because I largely agree with you.
The reason I then repeated some of your points was to answer the objection "It's too complicated, getting too long." There is plenty to say, but that 19-word sentence you quote is pretty dang short, yet describes a *big* improvement on the typical case.
I do admit a fudge in my count of 19-words: "some diceware-style advice" is honestly more than just 4-words of content. But it doesn't take too much explanation to get across the idea of don't just "dream up" passwords but take some unpredictable input from the real world and incorporate it into your passwords.
There are certainly dangling issues those 19-words don't address, but because they put problem into the physical domain, regular people will be able to reason about them and add some sane elaborations on their own. Tell people to keep their list of passwords safe? Sure, but that's also the kind of thing they can be reasonably expected to figure out No, the 19-words don't address encryption keys being different passwords, but I don't recommend normal people encrypt their passwords with a password manager anyway, and regular people don't do much other encryption. Probably they should, but the point is there is some low hanging fruit here that doesn't have to be that complicated. Simple is good. My choice of 19-words isn't exclusive nor possessing special magic, they are just an example. But they are simple, and if followed, would work pretty well.
-kb, the Kent who insists complexity is the chronic enemy of security.

@_date: 2016-09-21 13:17:33
@_author: Kent Borg 
@_subject: [Cryptography] Ada vs Rust vs safer C 
That's certainly an old tradition: fix it in the documentation.
Reminds me of a very popular current technique: can't decide right way to do something?, make it configurable. Maybe it can be tracked back to the NSA, maybe they somehow planted this "design pattern": Complexity is the enemy of security, so we gotta find more ways for people to add more add complexity.

@_date: 2016-09-24 19:00:29
@_author: Kent Borg 
@_subject: [Cryptography] Threat Model: Bluetooth tracking beacons 
My Android phone gives the impression it has (about) three Bluetooth modes:
1) Off.
2) Discoverable.
3) On, but not discoverable.
What does  mean? Not pairable, but still exposed?
I long ago read that Bluetooth is encrypted (as if that necessarily means something real). I was vaguely assuming that if my phone is talking to my smartwatch it was doing so encrypted, and though someone might do some analog fingerprinting of the radio, or correlate with more public cell radio IDs, the Bluetooth didn't say who it is except when it is in "discoverable" mode.
Um, so there is a durable MAC address-like value that IDs my watch and phone, and can be observed as I come into and go out of range? That's no ...for an additional 2500-something-pages. (Okay, not all about privacy, because Bluetooth is big, but a privacy gotcha could be hidden anywhere--nearly three-thousand total pages in the public spec sounds like a complex system.)
So does that mean the common Bluetooth devices (iphones, Androids, Fitbits, battery-hungry smartwatches, Pebble smartwatches, audio devices...) do that privacy stuff or not? (And does it work?)
-kb, the Kent who continues to be fret that our systems are both so complex that we don't know what they do, and that the details at all of the system boundaries are so poorly defined that no one could know what they do.

@_date: 2016-09-29 09:33:49
@_author: Kent Borg 
@_subject: [Cryptography] Use Linux for its security 
Good point.
But Linus Torvalds seems to think that security is well handled by ( writing good code in the first place, and ( letting the distributions patch whatever vulnerabilities might fall through. There has been some hard work to improve Linux security (such as grsecurity) but it doesn't get much encouragement. Linux is too busy moving forward as best it can--conquering the world--to worry about such cruft.
Those efforts don't have enough mindshare for me to have noticed them. At least nothing beyond  above.
The situation is bad.
There is a trade-off between the constructive power that can be built of complexity (features!), and the dangers that will be camouflaged in that complexity. The incentives to build features are quite real, but there is no back-pressure asking whether any given feature is worth the added complexity. Complexity isn't seen to be a liability, it is seen as an Has anyone ever been fired for adding some big useful feature? How about for removing one?
The costs of complexity are real, but they aren't felt directly. A bit like pouring untreated waste in a river: the benefits are mine, but costs are someone else's.
-kb, the Kent who thinks computer security might somehow be jiu jitsu-ed into a needed counter-pressure.

@_date: 2016-09-29 11:10:23
@_author: Kent Borg 
@_subject: [Cryptography] Complexity as an Asset vs. Liability 
"Complexity isn't seen to be a liability, it is seen as an asset." But there are exceptions.
This morning I was reading about Qubes (Linux distribution that makes it easy, at the GUI level, to isolate different activities in different Xen VMs, including protecting the OS itself).
In their FAQ they brag:
Bragging about how few lines-of-code?!
Yes! Simplicity as a feature.
Reading about why Qubes isn't multiuser, they seem to have suffered greatly over establishing system boundaries; there wasn't a way for both non-privileged users to control Xen and to protect those non-privileged users from each other.
-kb, the Kent who can't help but think their job in building this larger secure system would be so much easier if the subsystems they are wrangling were designed to have clean (and defined!) system boundaries.

@_date: 2017-12-14 09:48:05
@_author: Kent Borg 
@_subject: [Cryptography] zeromq/libsodium/elliptic question: are shared keys 
Context: I am looking at using Zero MQ in a project. It has security features using libsodium's elliptic curve public key cryptography.
Question: Is it okay for Alice and Bob to communicate with each other using a single shared public/private elliptic key pair? Experimentally it seems to work, but does it introduce any security holes? (Beyond the obvious that keys can't be individually deployed and revoked when they are not individually issued.)
Motivation: Alice and Bob are in the same household, they trust each other. They are, um, liberal, Charlie might be joining, too, they will trust him, too. When he does join they would rather not do a bunch of two-way key distribution. Also, there might be more than one instance of Alice (and of Bob and Charlie), and the Alices (and Bobs and Charlies) want to be able to talk to among themselves. They are willing to rekey the entire household if need be. And if later they need more resolution of who trusts whom they can start issuing some unique keys then. But in the meantime, does sharing keys open up any vulnerabilities?

@_date: 2017-01-01 12:42:52
@_author: Kent Borg 
@_subject: [Cryptography] Smart electricity meters can be dangerously 
One thing smart meters are used for is to manage peak load: maybe you agree to have your AC cycled off occasionally and get an rate break in exchange. (You still get cooling, but it cycles on a schedule that helps manage total load.)

@_date: 2017-07-06 18:54:31
@_author: Kent Borg 
@_subject: [Cryptography] Moths, Evolution, and RNGs 
Whatever the seasonal moths are that are out in Boston right now: I see RNGs. They have very erratic flight paths, I presume to be unpredictable to prevent birds from intercepting their flight. They also aren't around long each year, so before birds can learn or evolve a strategy for catching them, they are gone again. I remember last year seeing birds trying to catch them, but failing, and losing interest.
-kb, the Kent who is wondering what sort of chaotic and noisy circuitry they use as an RNG.
P.S. Spraying them with kitchen degreaser--something that usually works marvelously to instantly kill most bugs--maybe only makes their flight a bit faster. Mostly they don't seem to know they are as-good-as-dead, and they keep harassing me.

@_date: 2017-07-08 16:02:48
@_author: Kent Borg 
@_subject: [Cryptography] Applied Steganography: Do Moths Do CDMA-based 
[There is probably literature on this but wild speculation can be fun.]
I think chaotic moth flight is not so dissimilar to purposive bee flight. A bee will follow a predicable zig-zag, mapping the edge of plume of perfume from an upwind flower. I think these moths are doing something similar, but modulated by a PRNG function. As with CDMA radio, these bugs are communicating with each other, they want to find each other, they are using plumes of pheromones to communicate, but with this extra chaotic signal mixed in, so as with CDMA radio communications, they need to sync up with each other, and they do seem to do so: there will be several in an area, and then there will be none, and awhile later several again.
The other day at work I saw one parked on the office window: I looked closely, and it had big comb-like antennae. Looked like high-gain rigs, to quickly measure presence and absence of interesting molecules, as it rapidly darts about in flight.
These moths seem to function well when presented with solid objects, they and the plumes can't go through solid objects, and they don't bang into them. But when confronted with a screen covering an open window, they get messed up, they get stuck, their PRNG modulated plume following algorithm says to go that way but they can't. They look like they are trying to get in the house, but I think the screen has simply exposed a weakness in their strategy.
The birds have noticed, they are now hunting up against the kitchen window and storm door, I occasionally hear them bang into the wall or door as they go in for a snatch--each time I hope they got it. There is bird shit under the roof, on a table that normally never gets any. And I am pleased.
Trying to drag this a /bit/ on topic, if these bugs are navigating the world in a sensible (if effectively slow) manner, mapped through a PRNG modulation, it needs to be pretty simple. Not just to generate, but more so to demodulate it, so these simple creatures can accomplish their larger navigation goals, and really impressively, agree with other moths on compatible modulation phases. They get to use dedicated circuitry, but they still do this in such a way that vastly more intelligent birds can't decode it, and instead have to prey in places where the moth's design breaks down. Like up against my kitchen wall.
Disclaimer: Long ago I read in Scientific American (or was it Science News?) that butterflies, flighty as they are, do follow scent plumes to seek food. So I am not being that original.
My possible insight would be that they don't do this to find stationary food (I don't know that they even can eat in this stage of their lives), rather they do this to find similarly moving mates. (Probably same-sex, too. A CDMA-modulated cloud of one gender probably attracts the other gender better than a lone chaotic moth could.) They need to be predictable (enough) to each other, but still random to predators. Can they really adjust their PRNGs to correlate and roughly group themselves? How the heck do they do that?
I am impressed that these bugs show no caution as I try to kill them, as though they are on suicide missions, or maybe they feel invulnerable cloaked behind their stego navigation.
-kb, the interdisciplinary Kent who can mix casual nature watching with kinda up-to-date radio communications and cryptography.
P.S. As the afternoon goes on the birds are banging into the house more gently. I think they are perfecting their technique. Smart birds. I left a fan on out there, I was sitting in front of it earlier. I think that is further messing with the moths' design and helping the birds.

@_date: 2017-06-07 16:33:09
@_author: Kent Borg 
@_subject: [Cryptography] stego mechanism used in real life (presumably), 
Stego or not, this sounds like a useful utility for cheating students: Rewrite plagiarized material so as to be harder to catch. Not a perfect solution, but a salvo in the arms race that must be going on in that realm.
-kb, the Kent who doesn't hang out in that world anymore.

@_date: 2017-09-05 14:38:33
@_author: Kent Borg 
@_subject: [Cryptography] Finding Nemo's random seed 
And presumably the folks writing the rendering software /did/ know this. The older rendering software knew how to keep track of its RNG state, so it could re-render frames without positions changing. It is common to re-render 3D scenes and fragments of scenes as components are added, tweaked, lighting changed, eventually better quality output generated, etc. The sea grass that Nemo is swimming through had better not jump from one rendering to another. Someone was very aware of this.
But it seems that wasn't explicit in the "source code" that they preserved for Finding Nemo. And somehow programmers are better at writing functions for importing data than they are for exporting data...
Similarly for any Monte Carlo simulation: frequently one wants to be able to rerun different version of the code on previous "random" data.

@_date: 2018-08-09 13:36:31
@_author: Kent Borg 
@_subject: [Cryptography] PGP -- Can someone help me understand something? 
For simple equations, sure. But have you ever been confronted with an equation you could not solve?
Some problems are easier than others. Your example is addition, which is simple. More complicated would be multiplication. Worse would be exponentiation. Worse still would be a nasty combination of the above, with lots of other functions included. There are plenty of "natural" math equations that have not been solved.
Cryptography design is the art of conspiring to come up with contrived equations that are as hard as possible to solve. Equations that are so nasty as to make brute force is the best known way to solve them.
Part of how this is done is to make these algorithms (the "equation" is so complicated it has to be described in many steps) as chaotic as Consider a block cypher that encrypts 128-bits at a time. Change just one of these inputs bits and the encrypted output block will change completely: about half of the output bits will flip. Change just one bit in the key and the same thing will happen: the output will change entirely. By being so chaotic the idea is to make it impossible for the person analyzing it to know whether s/he getting closer or not.
To appreciate how hard this can be, try designing your own encryption algorithm. How would you break it? Okay, make it harder. Can you still break it? Steal some ideas from public algorithms, that should slow you A warning: It is pretty easy to design an encryption algorithm that is too hard for the designer to break. But that doesn't mean others won't find it easier. Don't trust your own encryption designs to be worth anything beyond stumping you. Assume that those who have spent decades studying this stuff understand things you don't.
Good encryption algorithms need to be looked at (looked at hard) by a lot of clever people working hard to find flaws.
Does this mean there isn't some clever solution just around the corner that will crack the AES algorithm? No. Maybe you can find it. If you do you will be way famous.
But probably not: Some very clever people have done their best to make this as difficult as possible.

@_date: 2018-08-10 10:13:38
@_author: Kent Borg 
@_subject: [Cryptography] PGP -- Can someone help me understand something? 
Other answers are also going into details of public key cryptography. But you don't need to.
Plain old symmetric algorithms (good ones, such as AES) resist known-plaintext attacks. They are very specifically designed to do so: Give someone plaintext and matching AES cyphertext and it is NOT feasible for that person to deduce the key.
P.S. Remember, public key cryptography is slow and cumbersome. It is NOT used to encrypt big messages. It is used to encrypt little messages, such as an AES key that was used for the rest of the message.

@_date: 2018-08-10 18:18:09
@_author: Kent Borg 
@_subject: [Cryptography] PGP -- Can someone help me understand something? 
But resistance to plaintext attacks has nothing to do with public-key cryptography one-way functions.

@_date: 2018-08-11 11:13:22
@_author: Kent Borg 
@_subject: [Cryptography] PGP -- Can someone help me understand something? 
I guess I made my point wrong. The original question asked why, knowing a cypher text and plain text, it isn't trivial to deduce the key.
This strength is a property of a robust conventional symmetric cypher, and almost ALL encrypted data is encrypted with symmetric cyphers, not with public key cyphers. Explaining that factoring is harder than multiplication doesn't explain why the key can't be deduced for symmetric cypher, rather it seems to muddy the waters.

@_date: 2018-01-11 10:11:22
@_author: Kent Borg 
@_subject: [Cryptography] Caches considered harmful 
One of the key properties of computers, one we take for granted and don't spend much time contemplating, is their predictability. We originally named them "computers" because their ability to compute--as in do arithmetic--was so impressive when compared to humans' ability to do the same.
With early computers there was no risk that they would replace humans in most endeavors because computers and humans are good at completely different things. But time passes.
We are now building and applying computers in mushy ways where they are no longer predictable, no longer deterministic. The two big examples of this, circa 2018, are (1) the magic tricks that are possible with neural networks and related self-tuning software, and (2) and all the self-tuning-usually-helps strategies that make a modern CPUs so much faster than a 68000.
Now, this isn't to say that the neural-inspired, speculative magic are all bad, just that we are trading away a key property of computers without making a conscious choice to do so: dogged predictability is a virtue. Seems we are trying to make them as fallible as we are, making them in our own image, without appreciating the implicit decision we are -kb, the Kent who wants autopilots and MRI machines and cryptography programs and mortgage balances and door locks to be doggedly predictable.

@_date: 2018-07-30 17:18:32
@_author: Kent Borg 
@_subject: [Cryptography] how to encrypt for the very long term? 
I think you have to ask yourself what failures you are most afraid of.
The two obvious ones:
 1) The wrong person gets access to your unencrypted data.
 2) The right person cannot get access to your encrypted data.
Which would be worse for your case?  might be harder than you think.
Possibly technological change will slow down about now, but I wouldn't count on it. Which means more than twenty-years is truly a long time. I would be very worried about software needed to access your data not existing or not runnable on existing hardware or not still being compatible with old data formats.
I would also worry about bit-rot in whatever media you use to store your data. And I would worry about working hardware still existing for your media, and still supported by existing drivers, to read your physical media.
Obviously I would worry about keeping passphrases secure AND not forgotten for twenty-years.
Finally, I would worry about the right person knowing how to recover your encrypted data in twenty-years. Being too obscure might be an ironic way to lose your data. (How motivated and resourced and interested in the data is this person in twenty-years?)
I would not be worried that AES-256 is going to be broken. Superencrypting with some other algorithm wouldn't hurt (providing keys and passphrases are completely unrelated!), but it might not help. (Remember, there is no such thing as double-DES. Because it is no stronger than single-DES!) Superencryption is trickier than you might guess, and it would certainly make recovery procedures harder.
I would recommend the most standard, and most likely to stay living, software I could, and that is probably gnupg, running on Linux, using other standard Linux (nee Unix) tools (split!). Some version of something Unix-like will still exist in twenty years, and gnupg and other classic tools will likely run on it. Who cares if gnupg doesn't do key-extension as well as you want, I don't think you should trust key extension: I think you need really good passphases, which means lots of real entropy going into their generation and encoded in a long string independent of the defensible minimum entropy (remember, an encryption passphrase is different from a login password--completely different).
Mostly, I would redefine the problem if I could. Why is anyone interested in this data in twenty-years or more? Why has someone preserved and kept secure any passphrase for so long?? Presumably because there is some institutional interest in this data. If so, secure the data carefully now, but delegate responsibility for maintaining it to said institutional interest: Copying to new media before the old bits die or become too obsolete, re-encrypting in new formats before the old formats die or being too obsolete. Regularly revisit these issues to make sure they still have access to this important data.
The hardest part of this problem is *not* the encryption itself. (It mostly never is.) All the surrounding issues are the hard parts.

@_date: 2018-03-31 18:19:33
@_author: Kent Borg 
@_subject: [Cryptography] Password entry protocols 
Spoof from whole cloth, or relaying in the middle?
I have seen various attempts at customizing what each specific user sees on password web pages, as a crude form of information exchange, but I think I have also seen each of them abandoned. And I bet no user raised a question when each was abandoned. ("But I was expecting to see the same little inkblot picture, and it's gone today! Quick, call the bank!" Yeah, sure.)
The most suspicious thing I have maybe done was complain to a bank that their domain registration was secret and not becoming of a brick-and-mortar institution--but I looked around and all small banks seem to think it is a good idea to make their domain registrations look like hijacked domains. As a way to prevent hijacking, I think. Ironic.
That's what phishing is based on.
But we are not allowed to educate the user to be more savvy for that is blaming the user. Rather we train the user to accept phishing more attempts by initiating legitimate transactions in a way which is indistinguishable from evil phishing e-mails. (That kind of user education is okay.)
HSBC Canada used to have a neat password design where they issued a random password (so no inbound password reuse) and they only asked for a specific few characters of the password each login. So the user never revealed the entire password any given login. Combined with fingerprinting of logins, they could change up what positions they asked for. But they abandoned that after a few years. I guess someone new was hired. (I'll quit periodically repeating this at some point, I'm sure I Come to think of it, the way I do security questions (not give real answers, and keep careful notes) does have a two-way key exchange property: if Bank XYQ asks me the name of my elementary school but I have no record of a made up elementary school for that account, that stops the "key exchange", for I have no answer. Unfortunately the remedy at that point is for me to give even more information as part of a password recovery process.
Google's approach seems to be to fingerprint our logins as a way to try to detect fakes--or detect Eve. But how to we detect fake Googles? No, we aren't allowed to do any user education--that would let crappy web sites off the hook and therefore be blaming the user.
But I guess I have been ranting. Back to one of your points: if Eve can sit in the middle she can do what she pretty much whatever she wants.
-kb, the Kent who will shutup now.

@_date: 2018-05-03 10:38:43
@_author: Kent Borg 
@_subject: [Cryptography] Security weakness in iCloud keychain 
Sounds like they built a very complex system and in that either they messed up, or it is confusing enough that the user (you) messed up.
Complex systems are hard to get right. Trusting the passwords for one's entire life to such a system seems a bad idea, but that's the current trend, everybody's doing it, every expert (that I have seen) is recommending it.
This isn't going to end well.
-kb, the Kent who recommends simple solutions, simple enough that the user can fully understand it, paper and pencil if necessary.

@_date: 2018-05-04 10:19:19
@_author: Kent Borg 
@_subject: [Cryptography] Security weakness in iCloud keychain 
Exactly my point.
Apple is about as mainstream as you can get, you aren't an idiot, and I don't think you did something wildly outside the envelope, yet you are having these problems.
Password management software is software, therefore it WILL have bugs--there is no way to avoid that. Password management software is also extremely sensitive, it holds, by definition, the most sensitive computer information possible: the "nuclear codes" to your life. This is a problem. Your choice should be very careful, this isn't just the latest game everyone is playing so you download it, too.
Password management needs to be as simple as possible. Any password management software needs as few automatic convenience features as possible, with the smallest and cleanest system boundary as possible--so there will be some hope of securing it.
Competitive marketing features are an enemy here. It needs to come from a trusted source whose motivation is your security not the whim of the current marketing and management of some company. It needs to come from smart programmers who are paranoid about security holes and buffer overflows and carefully sanitized input, etc. (Oh, and *leaks* of your passwords aren't the only risk. *Loss* of your passwords is not a great thing to happen to you, either.)
And once you select this mythical conservative program, you need hardware and an OS on which to run it. End-point security is really hard, if some spyware manages to get on your machine and target your password management software, you are toast.
Picking secure software and running it on a secure machine is something very, very few people are capable of, getting it wrong in this case has serious consequences, therefore most people should not do this. Most people should manage passwords with paper and pencil. But that's not sexy and high tech, and the experts all disagree with me.
A breach that exposes your Twitter password is not such a big thing for you. Twitter is pretty competent, yet this still happened to them. A breach that exposes every password in someone's life (or many persons lives) is rather worse those persons. This is going to happen.
To appropriate an old clich: We have a fad of everyone getting elaborate and fragile "baskets"--of just a few designs--and putting all their "eggs" in these baskets. This is not going to end well.
But the experts all say I am wrong.
-kb, the Kent who is shouting into the wind.

@_date: 2018-05-07 15:14:50
@_author: Kent Borg 
@_subject: [Cryptography] Security weakness in iCloud keychain 
But high-entropy passwords are not necessary.
High-entropy is only needed for encryption keys passphrases. (And they are very hard to remember).
The two are very different.

@_date: 2018-05-08 10:23:29
@_author: Kent Borg 
@_subject: [Cryptography] Security weakness in iCloud keychain 
Hear, hear!
There is a lot of well-justified frustration around authentication, and passwords are *everywhere*. They are always involved in whatever the problem is, always seen near the crime, implicated by proximity.
So conventional wisdom is that passwords are bad. Anything that purports to replace passwords (including password manager software auto-typing them, effectively turning into a sort of randomly-specced authentication agent), has an automatic bias in favor of it: Passwords are bad, alternatives must be better. But the alternatives are all rather bigger systems, that on further thought have a lot of places to hide really big In replacing passwords: First do no harm.
I have hundreds of passwords (everyone does, I am merely rare in that mine are unique), for wildly disparate systems. Any "this will replace passwords!" needs replace all that, and make matters better.

@_date: 2018-05-08 15:01:36
@_author: Kent Borg 
@_subject: [Cryptography] Security weakness in iCloud keychain 
Let me see, how have I used passwords today?
 - unlock my phone
 - unlock my laptop
 - password over ssh to a remote machine
 - sudo password on the account above
 - password over ssh to a shared account at work
 - sudo password on the above account
 - password over ssh to a shared account on an "appliance"
 - wanting to click on a web link in an e-mail, but it will prompt me for a password and I never do things in that order, I manually log into that website (looking up the password because that one I do not memorize) to get a valid cookie and then I followed the link.
Six different passwords in the above.
With your tidy solution ("That's it. We're done here."), how many different passwords would I have typed so far today?

@_date: 2018-05-08 17:30:56
@_author: Kent Borg 
@_subject: [Cryptography] Security weakness in iCloud keychain 
At the end you answer a key question: You would still have me entering passwords, but where my example had me entering a half dozen different passwords, you say I would enter just one.
You aren't getting rid of passwords, you are just coming up with a way to make recycling a single grand master password safe.
Or, safer. It seems you are only aiming to solve the problem of some website leaking plaintext of a recycled password.
But back to One Master Password: I don't want that.
Two immediate reasons:
 - I don't trust all the devices and keyboards in my life with such a powerful password. I don't trust that they are honest, I don't trust they are competent.
 - I currently don't much worry about shoulder-surfing, most passwords I enter aren't that important, but there are a few which are, and then I do worry who is behind me and whether there could be a camera above me.
Granted, the immediate utility of a Russian mobster learning this password is limited, but still a not something I welcome.
A related question: Would there ever be a case where this master password you imagine would actually be an encryption key? That is, would I have to worry about encrypted copy of any data leaking into a parallel key attack? If so, the master password would have to be a nasty one with lots of entropy in it.
I see other problems, but this seems a good start.

@_date: 2019-08-13 16:19:07
@_author: Kent Borg 
@_subject: [Cryptography] generated passphrases 
I have a simple largely homebrew solution using mnencode. I downloaded my copy a long time ago, but I think it is the same as It is a program that converts data to words (and the companion mndecode converts back). It is like base64 but more pronounceable output. And because it is a two-way thing--nothing added nothing lost--whatever entropy you feed in is in the output.
I use it to generate passwords by (roughly*) feeding a few bytes from Linux's /dev/urandom into it. Presto: turn high quality random bits into something memorable.
$ head -c 4 /dev/random | mnencode
 ?Wordlist ver 0.7 - EXPECT INCOMPATIBLE CHANGES
 ?artist-equal-cricket
$ head -c 4 /dev/random | mnencode
 ?Wordlist ver 0.7 - EXPECT INCOMPATIBLE CHANGES
 ?eric-panic-visitor
$ head -c 4 /dev/random | mnencode
 ?Wordlist ver 0.7 - EXPECT INCOMPATIBLE CHANGES
 ?orient-empire-final
$ head -c 4 /dev/random | mnencode
 ?Wordlist ver 0.7 - EXPECT INCOMPATIBLE CHANGES
 ?costume-harvard-charlie
Those are high quality passwords with 32-bits of real entropy each.
     ?* Actually, I use it in combination with a Python program I wrote
    to generate somewhat more complicated passwords. For example
    sometimes systems will silently truncate passwords at, say,
    8-characters. So that last one might actually end up being
    "costume-", which isn't so good. So I recommend prepending some hex
    digits. If some stupid system truncates "7csaturn-accent-vatican" at
    8-characters it will still be "7csaturn" which isn't a horrible
    password.
The difference between a login password and an encryption passphrase is gigantic and mostly ignored. I am so glad to see people underlining this Encryption passphrases are /really/ hard to reliably remember (and quite hard to blindly type accurately without a keyboard echo).
In the examples above it is easy to "curve fit" an idea through three words, and use it to help remember the password. But when it gets longer the "curve" gets bumpy and arbitrary. The following is 128-bits of entropy, and a monster to remember and type:
    artist-equal-cricket-eric-panic-visitor-orient-empire-final-costume-harvard-charlie
And get wrong a word form ("visit" vs "visitor") or confuse your Brit sports ("rugby" vs "cricket") and you are locked out.
But in a real sentence it is even easier to mess up a plural or tense or preposition. (Or was it: "But in real sentences it's even easier to mess up plurals or tense or a preposition.")
Passphrases are hard. That's the key reason I think ssh keys are almost always a bad idea: the key file isn't going to be protected with a decent passphrase because decent passphrases are really hard. Whereas an ssh password like "3d97critic-develop-winter" has over 47-bits of entropy; if the sshd has any rate limiting it will take years of continuous hammering to have a 50-50 chance of getting in.
The fact that an ssh key will survive even more years of the same hammering doesn't see so valuable if:
a) The computer it is protecting doesn't have that long a lifetime.
b) The at-rest key file, were it to be acquired by the Bad Guys, can be attacked at arbitrary speeds and might succumb far sooner.
If you had an important passphrase that you needed to type from memory what would I recommend?
- It's okay to have internal structure to the passphrase to make it easier to deal with: some numbers here, some words there, some punctuation or capitalization mixed in. But don't tell anyone what that structure is, keep it secret--which means don't use it anywhere else.
- Make the passphrase long. Even if the components are all low entropy (dictionary words) the whole thing being longer and in a unknown format makes cracking much harder.
- Put significant real entropy in it. (That is, choices you did /not/ make but were made by some high quality RNG.)
If the passphrase length implies 150-bits of entropy (about 23 printable ASCII characters), with a format unknown to your attacker, and has, say, 70-bits of real entropy in it...I think that's pretty dang good. At over twenty characters it can't be raw brute forced, someone needs to guess the internal format and then brute force within that constraint. If they don't know the structure of the passphrase they need to not only brute force 70-bits of entropy, they need to brute force all the different ways you might have formatted those 70-something bits of entropy. That sounds hard. How juicy a target /are/ you?

@_date: 2019-08-14 20:36:27
@_author: Kent Borg 
@_subject: [Cryptography] generated passphrases 
Something I have played with manually is nonsense words, pronounceable syllables, strung together. (Notably, something like a feature I think the old pwgen had.) It might be a way to cram more entropy into human Pick a random consonant, pick a random vowel, pick another random consonant...? Follow out rules to make it pronounceable. It doesn't need to be a very long string so build up significant entropy.
But not enough for a good passphrase.
Next approach: take the above pronounceable nonsense "word" and mix in some other stuff. Random capitaliZAtion someplaCe, extra symbols here, a pair of digits there, etc. If the starting "word" is in some sense sensible then the abuse layered on top can be recognized as a separate layer to be remembered.
The cognitive load ends up being two-part: the fake word, and the mangling of the "word" layered on top.
It still isn't easy to do big entropy, the it can maybe get pretty good, and the total length gets long enough that if the internal structure isn't known to the attacker (Have you noticed my being a bit vague...?) the brute force search space is still horrible.
Maybe if well done you could get someone to memorize one well crafted passphrase...? Maybe only 100-low-something-bits. (Significantly easier than 128-bits! Those extra two-dozen-ish bits are hard.) But don't expect people to remember many such. (Another scary topic.)
I think key stretching is a great idea...that I don't want to depend on. The idea of devising incremental, necessarily serial work, that will necessarily take lots of time even of a well-financed foe, yet still cheap enough to do on a little battery while I wait? A nice idea, but I remain skeptical. (And ignorant, I admit.)
Give me defensible entropy: counting bits going into how the passphrase was generated, not after-the-fact estimates by an ignorant observer.
But that's hard. Hence my point at the top.
Because provably-large yet not-too-much work is a hard hair to split.
And because passwords!, everyone knows passwords are the worst. Annoying, not sexy, about to be replaced any moment now--for decades now about to be replaced any moment now. And don't you know you just have the just chant "2FA"--SecureID, SMS, doesn't matter the details--to solve everything?

@_date: 2019-08-15 08:45:54
@_author: Kent Borg 
@_subject: [Cryptography] generated passphrases 
And not a very easy solution.
But then the entropy per character goes down and it has to get longer. Also, human sentences are flexible things. Use a contraction or not and the human meaning doesn't really change but as a passphrase the two are different. Unless some algorithm boils the two versions of the sentence to the same thing...meaning the entropy per character would fall even Passphrases for quality encryption are hard.

@_date: 2019-02-27 20:11:53
@_author: Kent Borg 
@_subject: [Cryptography] In the event of my death, master password 
My advice? Change how we manage passwords. (No, I'm not ambitious...)
First, don't recycle passwords between different sites. Okay, I just lost 99.8% of my audience.
Second, people should write down their passwords on paper. All analogue, no electronic-anything involved (because you can't trust that stuff is working for you, and can't trust it is competent). There goes 0.1%...
 - Keep a backup by copying by hand, and regularly updating the backup. And now I have lost the remaining 0.1%. (No photocopies, they are computers these days and can't be trusted.)
 - Protect that paper as though it were important--treat it like cash money. For frequently used passwords you will learn them and won't need to refer to the paper, it's not that bad.
 - If some passwords are more critical than others put them on a different piece of paper and treat it like a /lot/ of cash (i.e., don't carry it around with you).
Now the recovery question is much simpler: Tell your airs where the backups are kept. (Put that in information in a sealed envelope, if you would like.)
-kb, the Kent who is terrified of end-point security.

@_date: 2019-01-29 12:46:26
@_author: Kent Borg 
@_subject: [Cryptography] Introducing the world's worst hash function 
I remember that, but I am not sure from where. Did Linux or Sun Unix once do something similar??
As for ugly patching, a linker is quite dynamic yet acceptable these days. For delays bigger than a subroutine call it seems that a little bit of dynamic in just one place could then be merely linked to. But then modern caching makes most inherent timing so non-deterministic.
-kb, the Kent, who on seeing the merdeMerdeHash() code in almost compilable C, wonders what it would look like in Rust.

@_date: 2020-04-04 15:35:11
@_author: Kent Borg 
@_subject: [Cryptography] Dumb Question about Pair-Wise Authentication 
So I am starting work on a personal little project that involves two copies of a simple little server (written in Rust!). Each copy will be e-mailing automated requests to its partner. It is nothing very critical and I am not a juicy target, it will be obscure, so I don't need to secure it...or maybe I secure it a little.
The "right" way to do this would be to sign each request, right? The other side uses a public key to verify the request.
But I'm lazy, every infrequent time I look at the man pages for any of the standard public key software my head hurts and I don't trust I am doing it right.
Can't I do it much more simply? This is a pair-wise data syncing problem, it can only every be for a pair of machines, I don't have the key distribution problems that public key signatures solve. So why can't I just have a shared secret?
When I want to send a message I do a hash of the message plus the secret, and append that hash. On receipt I strip the hash, do a new hash of the message plus the secret and compare the result. So simple. What is wrong with it? Seems radical.
There must even be a name for this.
-kb, the Kent who is sensibly afraid of inventing security protocols.

@_date: 2020-04-05 15:46:49
@_author: Kent Borg 
@_subject: [Cryptography] Dumb Question about Pair-Wise Authentication 
I received kind several replies off-list, thought I should summarize on-list: I should use HMAC, to make length extension attacks harder.
Seems to me my simple minded hashing approach /would/ be okay but for the fact that crytographic hashes aren't as perfect as one might want to assume*, and length extension attacks are a consequence of these algorithms being designed to be efficient to implement, a consequence of them being incremental.
-kb, the Kent who notes that HMAC also has the virtue of being fairly simple, making it likely to be implemented and deployed correctly.
* Though Wikipedia says SHA-3 of is not susceptible to this attack on

@_date: 2020-12-02 14:52:48
@_author: Kent Borg 
@_subject: [Cryptography] Happy birthday, John Wallis! 
According to Wikipedia, his math study was erratic because "mathematics, at that time with us, were scarce looked on as academical studies, but rather mechanical".
Interesting to consider.
-kb, the Kent who notes that these days most people consider math as very academical, but /otherwise/ pointless.

@_date: 2020-12-11 17:05:58
@_author: Kent Borg 
@_subject: [Cryptography] Zodiac Killer's 340 Cipher Broken 
-kb, the Kent who likes the mispelling detail of "PARADICE".

@_date: 2020-12-11 20:36:44
@_author: Kent Borg 
@_subject: [Cryptography] The Military Wants to Hide Covert Messages in 
I suggest hiding spread-spectrum messages in ship screw and engine noises.
For close in communications, I suppose it depends on what other noises are available to snuggle up to. Better not try this when and where dolphins and whales aren't.
Though as the article suggests, to imitate natural sonar pings (not communications) might be a nicer option. Sure, might not be perfect if they want to ping at a depth and time and location where dolphins and friends aren't, but that applies to secret communications, too, and when blind and not wanting to be a colliding international incident in non-international waters, it could still be a better option than some industrial-strength/industrial-profile sonar ping.
Hmmm, something tells me the US Navy has a collection of different magnitude and waveform pings when the really need to look but don't want be caught trying.
The real stuff must be pretty interesting stuff.
-kb, the Kent who is a fan of spread spectrum.

@_date: 2020-03-04 13:28:35
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
I would think that is a big part of why we started down this path.
Why have we persisted? I figured is a combination of:
- Some guy at the dawn of (computer) time saying "change passwords" (and he regrets it to this day, I forget his name),
- Computer people (whether they know it or not) being deeply traditional,
- Computer users being deeply superstitious and afraid, and
- Few people willing to foolishly spend personal political capital to tilt at conventional wisdom. ("We have been using Best Practices here, what kind of practices are /you/ proposing?")
-kb, the Kent who periodically rails against the conventional wisdom that ssh keys are better than ssh passwords, because he is a fool who insists fools are occasionally right.

@_date: 2020-03-05 00:11:26
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
To be fair, the cases where ssh keys are most appropriate are automated connections, where a plaintext key is needed.
My gripe is that a login password is completely different from an encryption passphrase. The former can be pretty thin and still be secure*, but the former needs to be pretty implausibly high entropy, almost impossible to remember and reliably type blindly.
An ssh key needs to be protected as the encryption key that it is.
* If the server checks the password at a limited rate AND passwords are not recycled between accounts or otherwise freely given to one's foes.

@_date: 2020-03-05 11:23:39
@_author: Kent Borg 
@_subject: [Cryptography] Proper Entropy Source 
[I should have sent this sooner. Might be too stale, if moderators kill it I'll not object.]
When looking for entropy, sample every input one can from the real world. And if one if looking for entropy that is unknown to a distant foe, sample local things. In addition, do it at a moment that is unknown to that distant foe. Maybe when a human physically plugs it in--another case of sampling something local, a human.
For a project I worked on that wanted entropy I sampled every voltage and temperature I could find, every serial number I could find, I sampled fan RPMs, I hashed startup contents of DRAM (this was a vintage when these parts did not initialize to zeros). I also initialized the stored pool from a mouse-equipped computer at "manufacturing" time. I regularly saved the pool in a cron job (to minimize a reboot after a crash replaying from a previous state). This was also a time when the Linux urandom maintainer was busily turning off all interrupt timing as entropy sources, on some damn purity grounds (stupid!), so I compiled a custom kernel turning them back on.
In the case of AC power, sure, at a gross level it will be the same phase--across a very large region. But the powerlines are an antenna and each outlet is getting different local reception, so there is going to be local information there that is not available elsewhere. That looks tasty if I'm looking for entropy. (Always hash accordingly.)
Doing detailed sampling of the AC is expensive, but measuring phase could be pretty cheap...and, exactly when an embedded device is plugged in (and the phase when it first gets around to measuring it) isn't something that is easy for a remote foe to learn. Hell, it isn't easy for a really sophisticated near foe to learn. Phase, based on, say, millisecond-quality measurement, seems valuable; there are obvious ways to attack it, but oh my God, they are expensive. If one is designing a cheap device manufactured in volume scale will not be on the side of the We should quit being so pure about "entropy" and be pleased for any world matters for RNGs, implementation matters (stupid things like, are your entropy sources not wired up in the first place?, or are you giving away your pool somehow?), and physical dimensions matter: If your attacker can't get closer than some minimum range, and there is going to be local information that is hard for the attacker to know (speed of light, lossy "signal lines", and inelastic mechanics are your friends). Will there be phase jitter in an on-chip, multi-GHz, pseudo-spread-spectrum, analog PLL? Yes! Looks as good as "entropy" to me: at least if ones foes are forced to be more than a few mm away, and if they aren't that far away? You have far bigger problems.
RNGs are an engineering problem. That means theory applied to practical

@_date: 2020-03-05 23:53:36
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
I've only created self-signed certificates...and I have always picked a date far further into the future than the computer in question would still be functioning.
A good reason, a bad reason, and a pedantic reason:
1) Your appearance changes over time, so a new photo is smart,
2) To raise money--not renewals without a new photo are sometimes allowed, and
3) When the rule says the credential is not valid then it is not valid (makes for simpler, more robust protocols to have fewer special cases, and to heck with common sense*).
Like rules about "authentication words" that carry over to new circumstances and persist for years: an original reason (new photo, test vision, verify address, etc.) find a new motivation (revenue).
* Interesting to look at "common sense" might seem like an agile as a both a attack vector and an agile response. Drop your phone in the airplane toilet, not realize it is your own, report it to the flight attendant as suspicious and that can start a procedure that cannot be stopped. "Oh, I realize that was MY phone. No biggie." "Sorry, we already set the transponder to 7500, we now have to follow the protocol.".

@_date: 2020-11-17 17:45:51
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
Allow me to be controversial: We should be badly worried by password First, why should we trust that the user's machine that it is running on is secure? People get infected by malware all the time.
Second, why should we trust that password manager software is somehow immune to having bugs?
 ?o Don't recycle passwords for different purposes. (Though everyone does, worth repeating again?)
Back to the controversy:
It is completely unreasonable to expect users to remember a zillion unique passwords. They have to record them somewhere. So how to do that?
- Loudly tell users it is okay to write down passwords. There is an article of religious faith that needs to be overturned here, people need to be understand it IS okay to write down passwords. (And, once someone writes down an important password, take very good care of that paper. Pretend it is a hundred dollar bill if that helps focus the mind.)
- However passwords are to be recorded, the more off-line, and the simpler and more manual, the better. Offline and simple and manual will reduce both the number of bugs and the reduce severity of the consequences.
Personally I do use a password manager?but I use it very little, and it is very manual. (No auto-pasteing of passwords when some software infers I would like that.) Most of the time I need a password I type. (Diabolically simple!) Without looking it up, because I remember my frequently used passwords, because they are frequently used. I only look up a password when I need one I don't remember.
But I run my password manager on a Linux machine that I am very conservative about what other software runs on it; I wouldn't *think* of trusting my regular Android cellphone with my password records.
These last points start to get pretty subtle, which is why most people should write down passwords on paper, with NO electronic technology involved. Wanna backup? Do not take picture of your passwords list with your cellphone, don't photocopy it with anything that is also online. Best keep two copies of your list in two places. After you add a new password to one list, later update the other copy.
Yes, passwords are a mess. alas the magic bullets proposed all make it worse, so people need to be taught how to do the work to manage them better, and people like us can't agree. (See controversy above.)

@_date: 2020-11-18 09:04:25
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
But readable password hashes have gone away. Passwords are only readable on systems that are already quite broken. (Any old Unix systems still running are quite broken.) To set password policy based this case is all If the target system has already been broken into, correct. But if one has to brute force through a login program? 2^60 is more than plenty!
If I have done my math correctly, to be certain of breaking in in 100-years, one would have to get the login to test passwords for you at over a 6 MHz rate that entire time. Appropriately faster to get in appropriately sooner.
Only the crappiest systems will have no login throttling and if they are that crappy they will respond far slower than that because they are?.crappy.
This gets me to an oft ignored point: passwords (something that has to be tested against some authority) are completely different from encryption passphrases (which, given ciphertext, can be tested in parallel and at arbitrary speeds).
Rules for passwords need to be completely different from those for encryption passphrases. In that case, you are correct: "there is simply no ENCRYPTION PASSPHRASE that is long enough to be secure that is short enough to be memorable".

@_date: 2020-11-18 09:17:09
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
No, paper is still better than an all-eggs-in-one-handy-basket approach.
For the manual case a key logger still needs to catch each being password used. Much less juicy target. Much harder problem for the attacker.

@_date: 2020-11-19 11:56:04
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
You are optimizing for a very specific case:
(1) A site uses password hashes,
(2) for passwords that are allowed to be long,
(3) and are honored in their entire length*,
(4) is broken into and they don't tell me,
(5) the breakin doesn't include general admin powers but just supplies that one file,
(6) the attacker bothers to crack the hash for my password, and
(7) it does any good for the attacker to have that password.
* Even Linux is willing to let you use long passwords where anything past 8-characters are quietly ignored?if you set things up wrong. I've twice discovered this where I didn't set it up that way, a system installation script did.
If I don't recycle passwords, getting all the way to  lets the attacker impersonate me only on this one iffy site, which the attacker already has some backdoor access to. By insisting on unmanageably long passwords for everything, you do avoid this one narrow circumstance.
But there are a lot of ways for people to get security wrong, by the time they let their password data leak you need to assume things are very broken.
What makes you think there is any hashing going on at random site?
I have a large collection of plain-text passwords that have publicly leaked, where did I get those? That doesn't smell like hashing to me. Why do so many sites have password length and severe password content restrictions? That doesn't smell like hashing to me.
As long as my password even approaches a couple dozen-ish bits of real entropy, if I haven't given away copies (by recycling), my password is not going to be the weak link.
Do you have an ATM card? Well, if someone finds a way into your bank's computers that isn't via your PIN, then it didn't happen because your PIN was too short. And if you have to change your PIN as part of the cleanup, your new one doesn't have to be any longer than was your old one. The PIN wasn't the problem.
By telling people that every password has to be unmanageably long, you are effectively discouraging people from using difficult passphrases when it really does matter: for encryption.

@_date: 2020-11-20 12:19:57
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
Down that road lies a lot of territory?
Whether, say, passwords are even required! Didn't T-Mobile recently have a problem where once logged in a user could change an account number in the URL and access a different account? Isn't S3 data routinely discovered sitting around unprotected?
Regulating around password storage feels like a narrow concern.
There are *so* many ways to build an insecure system, and there is *so* little regulation about the building of these systems. First, can we regulate our way out of this insecure mess? If we can, is this really where to start?

@_date: 2020-11-20 13:36:36
@_author: Kent Borg 
@_subject: [Cryptography] Possible reason why password usage rules are 
Might be a start.
Though self-certification of what? Sounds like ISO standards or something. (I hope there isn't a "best practices" requirement of changing passwords every 30-days in there.)
Things are a mess, even some bad standards might be useful. Maybe for things such as just prompting people to survey to know what their systems consist of.

@_date: 2020-09-03 15:31:06
@_author: Kent Borg 
@_subject: [Cryptography] Really good ideas, harsh reality, 
Naively encrypted digitized voice is supposed to be particularly vulnerable to variable rate codecs. I think I read if presented it to the human ear, it can significantly demodulate and decode it.
