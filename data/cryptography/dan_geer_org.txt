
@_date: 2004-10-22 12:27:51
@_author: dan@geer.org 
@_subject: Financial identity is *dangerous*? (was re: Fake companies, real money)  
I'm pretty sure that you are answering the question
"Why did Microsoft buy Connectix?"[1]  -- the answer
was not, in other words, to screw Mac OS X users
but to break the conundrum Ballmer finds himself
in where the road forks towards (1) fix the security
problem but lose backward compatibility, or (2) keep
the backward compatibility but never fix the problem.
His Board would prefer (2), the annuity of locked-in
users, but it forces a bet that software liability
never happens.  Fixing the problem, for which the
calls grow more strident daily, puts the desktop
platform into play even more than it is now as
it asks the users (who, having lost compatibility,
thus have nothing to lose) to marry Redmond a
second time.  A VM-cures-all strategy is then
an attempt to avoid having to choose between (1)
and (2) by breaking backward compatibility for
new things but bridging the old things with a
magic box that both preserves the annuity revenue
stream from locked-in users while it keeps the
liability bar at bay.
Or so I think.
[1]

@_date: 2004-10-24 09:35:30
@_author: dan@geer.org 
@_subject: Financial identity is *dangerous*? (was re: Fake companies, real money)  
No need to buy a company just to use its
product in your development shop.
Please insert additional coins.

@_date: 2004-10-26 23:07:25
@_author: dan@geer.org 
@_subject: Financial identity is *dangerous*? (was re: Fake companies, real money)  
This is what I love about the Internet -- ask a question
and get silence but make a false claim and you get all the
advice you can possibly eat.
OK, I (quite happily) stand corrected about why Microsoft
bought Connectix --  it was cheaper given their extensive
dependence on the Virtual PC product, including redistribution
to outside parties.  That's fascinating, actually.
Now the reason I brought this up was it seemed like a Heaven-
sent bit of circumstantial evidence[1] to inference about a
larger business strategy question.  That question still stands,
but I'll have to look harder for corroborating evidence.
--dan, on the road
[1] "Some circumstantial evidence is very strong, like finding a trout in the milk." -- Henry David Thoreau

@_date: 2004-09-21 17:36:46
@_author: dan@geer.org 
@_subject: Academics locked out by tight visa controls  
Lynn (or anyone) -- I have a small question of
history, viz., when Rome was in its heyday what
sort of rules and so forth did it have about
citizens versus non-citizens in the city?  This
is not to start a long thread, or so I hope, but
if there is a lesson of history rather than
speculation perhaps this would be a good moment
to call for it to be remembered.  Modify the "Rome" to any place else if the lesson thus
improves in predictive value.

@_date: 2005-04-06 11:06:25
@_author: dan@geer.org 
@_subject: philosophical cum practical point 
Please critique, if you will, this line of reasoning:
All other things being equal, integrating cryptographic
communication protocols into client-server or peer-to-peer
products with existing end-point vulnerabilities tends
to increase total enterprise vulnerability.
By "all other things being equal" I am trying to
diplomatically reflect my experience to date that
not only is, say, key management hard but ensuring
that overburdened systems administrations staffs
continuously do the right thing with it has near
zero probability.  The SSL experience sort of sets a
lower bound for automaticity and low/no end-user skill
requirement corroborated by Alma Whitten's classic
paper[1] and other similar findings.  In perhaps the
most awkward and commonplace sense, I find myself
dealing with development teams that (rightly) believe
applications of cryptography are well understood but
then make the naive leap that they themselves either
already well understand those applications of
cryptography or that such understanding is an
assignable task to randomly selected team members
irrespective of background.
Perhaps I am only elaborating Spaf's remark[2] about
armored cars by restating it as an operational rule
for when development teams are permitted to add
crypto in their comm protocols -- when they have
damped out their end-user vulnerabilities.
Put one additional way, the guy who adds crypto
to his data stream risks becoming the most critical
server in the data center.
Whitten A & Tygar JD, "Why Johnny Can't Encrypt: A Usability
Evaluation of PGP 5.0," Proceedings of the 8th USENIX Security
Symposium, August 23-36, 1999, Washington, D.C., pp 169-184.
Using encryption on the Internet is the equivalent of arranging
an armoured car to deliver credit card information from someone
living in a cardboard box to someone living on a park bench.
          -- Gene Spafford, Purdue University.

@_date: 2005-08-05 18:21:41
@_author: dan@geer.org 
@_subject: [Clips] Does Phil Zimmermann need a clue on VoIP?  
This seems, ah, relevant to today's discussion...
FCC Requires Certain Broadband and VoIP Providers to Accommodate Wiretaps
Order Strikes Balance Between Law Enforcement, Innovation
Washington, D.C. - Responding to a petition from the Department of Justice, the Federal Bureau of Investigation, and the Drug Enforcement Agency, the Commission determined that providers of certain broadband and interconnected voice over Internet Protocol (VoIP) services must be prepared to accommodate law enforcement wiretaps, the Federal Communications Commission ruled today.
The Commission found that these services can essentially replace conventional telecommunications services currently subject to wiretap rules, including circuit-switched voice service and dial-up Internet access. As replacements, the new services are covered by the Communications Assistance for Law Enforcement Act, or CALEA, which requires the Commission to preserve the ability of law enforcement agencies to conduct court-ordered wiretaps in the face of technological change.
The Order is limited to facilities-based broadband Internet access service providers and VoIP providers that offer services permitting users to receive calls from, and place calls to, the public switched telephone network.  These VoIP providers are called interconnected VoIP providers.
The Commission found that the definition of "telecommunications carrier" in CALEA is broader than the definition of that term in the Communications Act and can encompass providers of services that are not classified as telecommunications services under the Communications Act.  CALEA contains a provision that authorizes the Commission to deem an entity a telecommunications carrier if the Commission "finds that such service is a replacement for a substantial portion of the local telephone exchange."
Because broadband Internet and interconnected VoIP providers need a reasonable amount of time to come into compliance with all relevant CALEA requirements, the Commission established a deadline of 18 months from the effective date of this Order, by which time newly covered entities and providers of newly covered services must be in full compliance.  The Commission also adopted a Further Notice of Proposed Rulemaking that will seek more information about whether certain classes or categories of facilities-based broadband Internet access providers - notably small and rural providers and providers of broadband networks for educational and research institutions - should be exempt from CALEA.
The Commission's action is the first critical step to apply CALEA obligations to new technologies and services that are increasingly used as a substitute for conventional services.  The Order strikes an appropriate balance between fostering competitive broadband and advanced services deployment and technological innovation on one hand, and meeting the needs of the law enforcement community on the

@_date: 2005-08-12 16:21:30
@_author: dan@geer.org 
@_subject: knotty problems 
[ arguably cryptanalysis-like ]
Computer analysis provides Incan string theory
    * 19:00 11 August 2005
    * NewScientist.com news service
    * Will Knight
Computer analysis reveals that information is
collated from some Khipu into high level ones
The mystery surrounding a cryptic string-based communication system
used by ancient Incan administrators may at last be unravelling,
thanks to computer analysis of hundreds of different knotted bundles.
The discovery provides a tantalising glimpse of bureaucracy in the
Andean empire and may, for the first time, also reveal an Incan
word written in string.
Woven from cotton, llama or alpaca wool, the mysterious string
bundles - known as Khipu - consist of a single strand from which
dangle up to thousands of subsidiary strings, each featuring a
bewildering array of knots. Of the 600 or so Khipu that have been
found, most date from between 1400 AD and 1500 AD. However, a few
are thought to be about 1000 years old.
Spanish colonial documents suggest that Khipu were in some way used
to keep records and communicate messages. Yet how the cords were
used to convey useful information has puzzled generations of experts.
Now, anthropologist Gary Urton and mathematician Carrie Brezine at
Harvard University, Massachusetts, US, think they may have begun
unravelling the knotty code. The pair built a searchable database
containing key information about Khipu strings, such as the number
and position of subsidiary strings and the number and position of
knots tied in them.
The pair then used this database to search for similarities between
21 Khipus discovered in 1956 at the key Incan administrative base
of Puruchuco, near modern day Lima in Peru. Superficial similarities
suggested that the Khipu could be connected but the database revealed
a crucial mathematical bond - the data represented by subsidiary
strands on some of Khipu could be combined to create the strands
found on more complex ones.
This suggests the Khipu were used to collate information from
different parts of the empire, which stretched for more than 5500
kilometres.  Brezine used the mathematical software package Mathematica
to scour the database for other mathematical links - and found
"Local accountants would forward information on accomplished tasks
upward through the hierarchy, with information at each successive
level representing the summation of accounts from the levels below,"
Urton says. "This communication was used to record the information
deemed most important to the state, which often included accounting
and other data related to censuses, finances and the military."
And Urton and Brezine go a step further. Given that the Puruchuco
strings may represent collations of data different regions, they
suggest that a characteristic figure-of-eight knot found on all of
the 21 Puruchuco strings may represent the place itself. If so, it
would be the first word to ever be extracted from an Incan Khipu.
Completely deciphering the Khipu may never be possible, Urton says,
but further analysis of the Khipu database might reveal other details
of life. New archaeological discoveries could also throw up some
more surprises, Urton told New Scientist.

@_date: 2005-08-22 09:30:20
@_author: dan@geer.org 
@_subject: online MD5 crack database  
This website has a large database of MD5 hashes of common passwords:
    Presumably, as storage continues to get cheaper, this sort of thing
 will only become easier.
 ......
 None of this is new -- I'm just noting that the trend continues apace.
 In 1985 I was told by an MIT professor with DoD
connections and a clearance that certainly no
later than 1979 the folks at Fort Meade had every
possible BSD password indexed by its /etc/passwd
representation.  Reversing a password meant to
simply look up the /etc/password text on-disk to
see what tape it was on and to then read that

@_date: 2005-08-22 12:41:59
@_author: dan@geer.org 
@_subject: online MD5 crack database  
I should (apparently) add that at the time I did
not know enough to ask relevant questions, but
it was tossed off in such a way as to sound like
that if I did know anything I'd realize the speaker
was telling me something obvious so since it didn't
seem obvious to me then I must not know anything.
Hadn't thought about it since until I saw Perry's
[ Imagine the math professor who having said "It is
obvious that..." steps back from the board for
two full minutes before continuing "... yes, it
is obvious that..." and you have the feel for the
setting two decades ago when I heard the claim. ]

@_date: 2005-12-02 23:05:29
@_author: dan@geer.org 
@_subject: [Clips] Banks Seek Better Online-Security Tools  
You know, I'd wonder how many people on this
list use or have used online banking.  To start the ball rolling, I have not and won't.
Cryptography is nothing more than a mathematical framework for
discussing the implications of various paranoid delusions.
    -- Don Alvarez

@_date: 2005-12-23 10:11:43
@_author: dan@geer.org 
@_subject: A small editorial about recent events.  
You know, as a security person, I say all the
time that the greatest threat is internal threat,
not external threat.  In my day job, I/we make
surveillance tools to prevent data threat from
materializing, and to quench it if it does anyhow.
I tell clients all day every day that when the opponent can attack location independently, and
likely without self identification, your only
choice is pre-emption, which requires intell,
which requires surveillance, which requires
listening posts.
And I'm just talking about intellectual property
in the Fortune 1000, not the freaking country.
--dan, who doesn't like reality any more

@_date: 2005-12-23 20:40:31
@_author: dan@geer.org 
@_subject: A small editorial about recent events.  
> You know, as a security person, I say all the time that the greatest
 > threat is internal threat, not external threat.  In my day job, I/we
 > make surveillance tools to prevent data threat from materializing, and
 > to quench it if it does anyhow.  I tell clients all day every day that
 > when the opponent can attack location independently, and likely
 > without self identification, your only choice is pre-emption, which
 > requires intell, which requires surveillance, which requires listening
 > posts.
  Are you saying we need to carefully surveil our government and pre-empt
 it from attacking us, or that our government should carefully surveil us
 and pre-empt us from attacking it?
  > And I'm just talking about intellectual property in the Fortune 1000,
 > not the freaking country.
  Let's hope society as a whole never resembles life inside the Fortune
 1000 too closely.
   IF ( I believe what I tell my customers )
THEN ( it applies more broadly than them )
That's all.  I do believe what I tell them,
and I am certain it is a fundamental truth
rather than an advertising slogan.  As such,
I should (and do) snap to attention and salute
it when it appears in other guises in other venues.
As to whether you should surveil the government
or the other way around, David Brin's book,
_The Transparent Society_, and the mountains of commentary it has spawned probably answer the question better than I ever will.
As to society looking like the Fortune 1000,
I (also) agree that I'd rather it did not,
but I look at globalized competition, the
first-world's populace that beyond all else wants to be protected/taken care of, and
a planet where jihadists and sociopaths have
an increasing edge, and I ask myself why I
shouldn't imagine that the Fortune 1000 are
not anomalies but avatars, that they are merely
the first to adopt what we will soon demand
as a societal entitlement?  The more crowded
we get the more controls we have to have to
keep the jihadists and sociopaths in their
place, the populace protected, and so forth.
The Internet is a crowded place in that sense;
everyone is your next door neighbor.
Personally, I am working on my farming skills
as fast as I can and do, in truth, intend to
drop out of sight / get off the grid.  What
some may interpret as apologies for the first
or second estate are, at least as I mean them,
nothing but an attempt at Real Politik.  Hope
I'm wrong, but I don't bet against my intuition.
Probably a rat hole,

@_date: 2005-02-22 00:49:55
@_author: dan@geer.org 
@_subject: SHA-1 cracked  
> ... a team has found collisions in full SHA-1.  It's
 > probably not a practical threat today, since it takes
 > 2^69 operations to do it ...
In the perspective of scale department, there
are approximately 2^60 individual insects on
this planet, of which 2^50 are ants.

@_date: 2005-07-09 17:38:33
@_author: dan@geer.org 
@_subject: Why Blockbuster looks at your ID.  
I consulted an oracle at a major third party
processor.  He said the number is more like
64-67 basis points, that you have to be very
precise about your definitions, i.e., very
precise about what goes in the numerator and
what goes in the denominator.  For example, if a dishonored transaction is the merchant's
fault and the merchant has to foot the bill
then the card association has not had a fraud
loss.  I doubt it is actually germane to this
list, but I can go back to said oracle if
BTW, if you ever have the opportunity to hear
Frank Abagnale's discussion of check forgery
by all means do so.

@_date: 2005-07-09 18:24:22
@_author: dan@geer.org 
@_subject: the limits of crypto and authentication  
>>It would seem simple to thwart such a trojan with strong authentication
 >>simply by requiring a second one-time passcode to validate the
 >>transaction itself in addition to the session.
 >>
 >
 > How does the user know which transaction is really being authenticated?
  You send the pass code in an SMS to the user's mobile phone, together
 with some information on the transaction.  (If the SMS delay is a
 problem, use a computer-generated phone call.)  The pass code is then
 entered by the user to authorize the transaction.
[ Disclaimer -- I advise this company ]
Take a look at Boojum Mobile -- it is
precisely the idea of using the cell
phone as an out-of-band chanel for an
in-band transaction.
[ Disclaimer -- I advise this company ]

@_date: 2005-07-09 18:31:42
@_author: dan@geer.org 
@_subject: the limits of crypto and authentication  
I think that the cost of two-factor authentication will plummet in the
 face of the volumes offered by e-banking.
Would you or anyone here care to analyze
what I am presuming is the market failure
of Amex Blue in the sense of its chipcard
and reader combo?

@_date: 2005-07-11 22:04:49
@_author: dan@geer.org 
@_subject: the limits of crypto and authentication  
Well, whether you like the cell phone as
the out-of-band second-factor, you can now
unlock your front door with it...

@_date: 2005-06-01 10:07:59
@_author: dan@geer.org 
@_subject: Digital signatures have a big problem with meaning  
In the end, the digital signature was just crypto
 candy...
On the one hand a digital signature should matter more
the bigger the transaction that it protects.  On the
other hand, the bigger the transaction the lower the
probability that it is between strangers who have no
other leverage for recourse.
And, of course, proving anything by way of dueling experts doesn't provide much predictability in a jury
system, e.g., OJ Simpson.

@_date: 2005-06-08 16:19:06
@_author: dan@geer.org 
@_subject: de-identification 
Ladies and Gentlemen,
I'd like to come up to speed on the state of the
art in de-identification (~=anonymization) of data
especially monitoring data (firewall/hids logs, say).
A little googling suggests that this is an academic
subspeciality as well as a word with many interpretations.
If someone here can point me at the mother lode of insight, I would be most grateful.

@_date: 2005-06-10 16:51:11
@_author: dan@geer.org 
@_subject: encrypted tapes  
If you have no other choice, pick keys for the next five years,
 changing every six months, print them on a piece of paper, and put it
 in several safe deposit boxes. Hardcode the keys in the backup
 scripts. When your building burns to the ground, you can get the tapes
 back from Iron Mountain and the keys from the safe deposit box.
 Assuming I even understand the problem,
this is, in fact, one of the wonderful
uses of split-key (threshold) crypto;
including scale-down to the individual
split K as 2-of-3 quorum
   (1) smartcard
   (2) laptop
   (3) corp server
encrypt disk using K (or another key protected by K, of course)
situations handled
   (a) Dan offline inside Faraday cage, use frags 1,2 to do work
   (b) fire Dan / confiscate laptop, use frags 2,3 to read disk
   (c) Dan leaves laptop in cab, use frags 1,3 to recover from backup
We can (for backup tapes) make 2-of-N
splits.  This would allow each tape
of a multi-volume tape set to be
"partially" encrypted in a different
fragment which nevertheless could have
its encryption "completed" by the common
fragment held centrally thus making each
tape a different cryptanalysis problem
for the attacker but without the apparent
key management overhead for the good guys.
As one fragment of a quorum can be set in
advance, that fragment could be common to
several otherwise non-communicating sets
of tapes and thus be the one retained in
that central, good-guy location.
And so forth.
Disclaimer: I am a good enough mathematician
to know how bad a mathematician I really am
so, in the usual Internet practice, a flood
corrections/denunciations will doubtless
now commence.
Geer DE & Yung M : Threshold Cryptography for the Masses,
Proceedings, Sixth International Financial Cryptography Conference,
Southampton, Bermuda, 11-14 March 2002.

@_date: 2005-06-17 10:48:36
@_author: dan@geer.org 
@_subject: de-identification  
>
 >Ladies and Gentlemen,
 >
 >I'd like to come up to speed on the state of the
 >art in de-identification (~=anonymization) of data
 >especially monitoring data (firewall/hids logs, say).
 >A little googling suggests that this is an academic
 >subspeciality as well as a word with many interpretations.
 >If someone here can point me at the mother lode of  >insight, I would be most grateful.
 >
  What's your threat model?  It's proved to be a very hard problem to  solve, since there are all sorts of other channels -- application data,  timing data (the remote fingerprinting paper mentioned this one), etc.
Steve, et al.,
My threat model is how can I have a convincing
technical solution that, in turn, gets your average
corporate general counsel to permit sharing various
kinds of logs with similar firms.  The Patriot Act
(2001,Bush), PDD 63 (1998,Clinton), and various other
intervening bits of legislation say that threat and
vulnerability information shared between like private
sector firms is (1) exempt from Anti-Trust (even
where security is a competitive feature) and (2)
exempt from FOIA (even where such sharing is under
government aegis).  Nevertheless no corporate general
counsel will permit such sharing.  From where a GC
sits, the risk is clear, near-term and direct to the
firm while any benefit is diffuse and distant, and
no GC believes any laws' words until the courts, as
unacknowledged legislators, get a whack at it and
that being so no GC wants to be the test case.
Ipso facto, I (we) need a way to ensure that log
data can be shared between firms in ways that do
not identify the source firm so that, in turn, I can stand up and say that the risk as seen from
the GC's point of view has been technically put
to bed.  I don't imagine for a minute that even
that argument will be trivial, but a technical
solution is necessary even if insufficient.
My real aim is, of course, the characterization of macro-scale risk to critical infrastructure.
In the hypothesis-generation stage of such an
effort I need to take field observations that
could easily go any of three ways:
 (1) All the players see the same scans, the same
     automated attacks, the same over-pressure;
 (2) All the players see entirely different scans,
     entirely different automated attacks, entirely
     different over-pressures; or
 (3) One of the players stands apart from the others
     and whereas the corpus of that industrial      sector sees the same scans, the same automated
     attacks, the same over-pressure there is one
     player whose experience is different.
This is information that no firm can get on its
own, so uniqueness of value is a given and amongst
rational players unarguable.  What I need is to
break the logjam over being the first to share.
The only alternative is to take the biased samples
that are available inside managed security providers
and confidential consulting firms and pool that data,
thus anonymizing it, within a single corporate shell.
This is second best and tends to have little motive
power of its own, though I/we proved it can be done[1]
as has Qualys[2], inter alia.
Clear enough?

@_date: 2005-06-24 10:47:41
@_author: dan@geer.org 
@_subject: WYTM - "but what if it was true?"  
What do you tell people to do?
Defense in depth, as always.  As an officer at
Verdasys, data-offload is something we block
by simply installing rules like "Only these
two trusted applications can initiate outbound
HTTP" where the word "trusted" means checksummed
and the choice of HTTP represents the most common
mechanism for spyware, say, to do the offload
of purloined information.  Put differently, if there 5,000 diseases but only two symptoms,
then symptomatic relief is the more cost-effective
approach rather than cure.  In this case, why do
I care if I have spyware if it can't talk to its
distant master?  (Why do I care if I have a tumor
if angiostatin keeps it forever smaller than 1mm
in diameter?)  Of course, there are details, and,
of course, I am willing to discuss them at far
greater length.

@_date: 2005-06-24 17:25:10
@_author: dan@geer.org 
@_subject: WYTM - "but what if it was true?" 
Dan--
     I had something much more complicated, but it comes down to.
     You trust Internet Explorer.
     Spyware considers Internet Explorer crunchy, and good with ketchup.
     Any questions?
     A little less snarkily, Spyware can trivially use what MS refers to
 as a Browser Helper Object (BHO) to alter all traffic on any web page.
 Inserting a 1x1 iframe in the corner of whatever, that does nothing but
 transmit upstream data via HTTP image GETs, is trivial.  And if HTTP is
 a bit too protected -- there's *always* DNS ;).  gethostbyname indeed.
 P.S.  Imagine for a moment it was profitable to give people cancer.  No,
 not just a pesky side effect, but kind of the idea.  Angiostatin
 wouldn't stand a chance.
If you are insisting that there is always
a way and that, therefore, the situation is
permanently hopeless such that the smart
ones are getting the hell out of the
Internet, I can go with that, but then
we (you and I) would both be guilty of
letting the best be the enemy of the good.
  However, I/we routinely disable all use of
  BHOs, prevent mod of any entity as chosen
  by filename extension, checksum, or filesystem
  location, and whitelist applications, to name
  a _few_.  For the genuinely paranoid, regular
  (like every few hours) reboot to a new VM is
  also enforceable and recommended, especially
  if you care about attacks that are purely
  in-memory and which do not leave behind any
  payload such as to aid an attacker on his/her
  proposed second visit.  If you indeed are an
  "I don't need no stinkin' payload" sort of
  guy, like the folks who eschew carrying matches
  because you can always light a fire rubbing
  two sticks together, make me a suggestion;
  I love free consulting.
"Internet Explorer is the most dangerous program ever written."
  -- Rik Farrow to Scott Charney during the audience grilling stage of

@_date: 2005-06-29 13:00:16
@_author: dan@geer.org 
@_subject: WYTM - "but what if it was true?"  
...
 The personal ATM appliance should be difficult to tamper with and should
 accept only a single set of accounts (so that stolen pin numbers are not
 portable)...
My personal guess is that the general purpose
computer is ultimately a goner -- it will later,
if not sooner, be legally treated much like having
a swimming pool if not a 50 caliber.  ("Honest people
don't need a compiler or admin privilege" is already
true in the corporate arena...)  Either that, or
network-admittance will become the focus of authority
and liability (also already true in corporate arenas).
Probably a rat hole,

@_date: 2005-03-25 16:28:28
@_author: dan@geer.org 
@_subject: NSA warned Bush it needed to monitor networks  
I think a bigger issue here is a sort of rational (to the bureaucrat) risk a
 versity: if he declassifies something and it turns out he's leaked somethin
 g valuable (in the eyes of his boss), he's in trouble.  As long as there's  no cost to stamping "secret" or "FOUO" on every document his office produce
 s, this is safer for him than any other course of action.   Along with this
 , going through a document to make sure there's nothing secret in there is  a lot more work than just classifying it.  The same logic works in the priv
 ate world--how much of the stuff you've seen under NDA was genuinely going  to cause a problem to the company that produced it, if someone just posted  it to their website?
Exactly correct.  It is the same reason that
no corporate general counsel will allow data
on successful intrusions to be shared; the downside risk is well understood and the upside
benefit is vague, delayed, and does not accrue
to the releasing party.  Cf. mandatory reporting of communicable diseases
where, presumably, few patients or private docs
would ever voluntarily report that there's a
case of Plague in the house were it not for
compelled disclosure.[1]
sample state list, to which you can add gunshot wounds
Acquired Immunodeficiency Syndrome (AIDS)
Chlamydial Infections
Colorado Tick Fever
Encephalitis (post-infectious, arthropod-borne, and unspecified)
Food-borne Illness, including food poisoning
Gonococcal Ophthalmia Neonatorum
Granuloma Inguinale
Hemophilus Influenza, Invasive Disease (all serotypes)
Hepatitis A
Hepatitis B, cases and carriers
Hepatitis, other Viral: Type C
Lymphogranuloma Venereum
Meningitis, Aseptic and Bacterial
Pelvic Inflammatory Disease
Rabies (Human and Animal)
Relapsing Fever (tick-borne and louse borne)
Rheumatic Fever
Rocky Mountain Spotted Fever
Rubella, Congenital Syndrome
Staphylococcal Diseases
Toxic Shock Syndrome
Yellow Fever

@_date: 2005-10-20 11:42:19
@_author: dan@geer.org 
@_subject: [Clips] Read two biometrics, get worse results - how it works  
RAH, et al.,
It is true that one can combine two diagnostic
tests to a worse effect than either alone, but
it is not a foredrawn conclusion.  To take a
medical example, you screen first with a cheap
test that has low/no false negatives then for the
remaining positives you screen with a potentially
more expensive test that has low/no false positives.
There is a whole health policy & management
literature on this.  I reproduce the barest
precis of same below, assuming the reader can
manage to view it in a fixed width font while
respecting my hard carriage returns as writ.
  cheat sheet on terminology of medical diagnostic testing
              \  the true situation
               \
                \    +       -
                 +-------+-------+---
       |       |
               + |   a   |   b   |  a+b
what the         |       |       |
diagnostic       +-------+-------+---
test returns     |       |       |
               - |   c   |   d   |  c+d
       |       |
                 +-------+-------+---
       |       |
  a+c  |  b+d  |   t
   true positives
          a = positive testers who have disease
   true negatives
          d = negative testers who are without disease
   false positives
          b = positive testers who are without disease
   false negatives
          c = negative testers who have disease
   prevalence
          (a+c)/t = fraction of population that has disease
   sensitivity
          a/(a+c) = what fraction of those with disease test positive
   specificity
          d/(b+d) = what fraction of those without disease test negative
   predictive value positive
          a/(a+b) = what fraction of positive tests have disease
   predictive value negative
          a/(a+b) = what fraction of negative tests are without disease
   Notes:
   Information retrieval people know sensitivity as "recall" and
   predictive value positive as "precision."
   Screening with a cheap test with high sensitivity then an expensive
   test with high specificity is often the best (most cost effective)
   strategy.

@_date: 2005-09-20 20:21:26
@_author: dan@geer.org 
@_subject: Defending users of unprotected login pages with TrustBar 0.4.9.93  
Dare I say that the best must not be the enemy of the good?

@_date: 2005-09-28 07:09:11
@_author: dan@geer.org 
@_subject: PKI too confusing to prevent phishing, part 28  
>
 >Talking about users as being able only to hold one bit continues an  >unfortunate attitude that, if only users weren't so dumb/careless/whatever,
 >we wouldn't have all these security problems.
  This is an important point.
In November, 2003, the Computing Research Association,
and the NSF held a sequestered workshop in Virginia
to ascertain what "Grand Challenges" should drive
the NSF funding priorities for the ensuing ten years.
You can see more on this here[1], but one of the four
Grand Challenges was that there be enough advances
that one did not have to be an expert to be safe.

@_date: 2006-04-27 07:23:05
@_author: dan@geer.org 
@_subject: History and definition of the term 'principal'?  
I was manager of development for Project Athena beginning
in 1985.  Amongst our projects was Kerberos, and, as you
know, it was a direct implementation of Needham-Schroeder.
Schroeder had been Jerome Saltzer's Ph.D. student and Saltzer was the MIT faculty member in charge of the
technical side of Athena, and to whom I reported.  The
word "principal" was solidly in place from the moment
the Kerberos work began, and comes directly from the
work of Saltzer and Schroeder.  At least as early as
1975 the term "principal" was in use in their work;
see [1] for my own earliest reference.  I suspect it
was in place at Project MAC and might thus have some
lineage with Multics, but now I am speculating.
Needham is sadly gone, but Schroeder and Saltzer are
still with us.  If it is worth my pursuit of the matter
I'll make the time for it, but I now forget why this
was asked.  If it is curiousity, perhaps the canoe is
now far enough upriver.  If it is a patent claim or the
like and one needs to find the exact wet spot in the
ground that the river starts, well, let me know.
[1] Proceedings of the IEEE. Vol. 63, No. 9 (September 1975), pp.
1278-1308; Manuscript received October 11, 1974; revised April 17,
1975. Copyright 1975 by J. H. Saltzer.  The authors are with Project
MAC and the Department of Electrical Engineering and Computer Science,
Massachusetts Institute of Technology Cambridge, Mass. 02139.

@_date: 2006-12-16 18:40:02
@_author: dan@geer.org 
@_subject: ATM vulnerability 
I hesitate to use the syllable "crypto" in describing this paper,
but those who have not seen it may find it interesting.
Or profitable.

@_date: 2006-12-20 11:44:29
@_author: dan@geer.org 
@_subject: news story - Jailed ID thieves thwart cops with crypto 
Jailed ID thieves thwart cops with crypto
By Tom Espiner
Story last modified Tue Dec 19 06:46:45 PST 2006   Three men have been jailed in the U.K. for their part in a massive
  data theft operation.
  One of the accused ringleaders of the gang, Anton Dolgov--also
  known as Gelonkin--was sentenced to six years at London's Harrow
  Crown Court on Wednesday for his part in the theft of millions
  of dollars from victims in countries including the U.K. and the
  U.S.
  The ID thieves used stolen credit card numbers and created false
  identities to buy high-end electronics and other goods, which
  they then resold on eBay, prosecutors said.
  The gang pleaded guilty to conspiracy to defraud, obtain services
  by deception, acquire, use and possess criminal property, and
  conceal, disguise, convert, transfer or remove criminal property.
  One of the gang members, Aleksei Kostap, was also found guilty
  of perverting the course of justice, and was sentenced to four
  years' imprisonment.
  When the gang's premises were raided by the members of the Serious
  and Organised Crime Agency (SOCA), Kostap was handcuffed with his
  hands in front of his body. He managed to leap up and flick an
  electrical switch that wiped databases that could have contained
  records of the gang's activities stretching back more than 10
  years, SOCA said.
  Kostap's action also triggered intricate layers of encryption on
  the gang's computer systems, which SOCA's experts were unable to
  crack, the court heard.
  SOCA was not prepared to discuss what encryption was used or why
  it was unable to decrypt it, as such information would enable
  other criminals to use the same methods.
  According to the Crown Prosecution Service (CPS), which confirmed
  that Kostap had activated the encryption after being arrested,
  it would take 400 computers 12 years to crack the code.
  Because much data was inaccessible to the police, it is not known
  how much the criminals profited from their operation, but it is
  believed that they made millions of dollars. Police were able to
  find evidence of 750,000 pounds ($1.46 million) worth of transactions
  between 2003 and 2006, but the gang had been operating since the
  mid-'90s.
  "The true scale of the gang's crimes will probably never be known,"
  said a representative for the CPS.
  Identify theft is a growing problem worldwide. Figures released
  by Sainsbury's Bank last week found that more than 4 million
  British citizens have suffered financial losses through ID fraud.
  And last year, in the U.S, identity theft for the third straight
  year topped the list of fraud complaints reported to the Federal
  Trade Commission. Consumers filed more than 255,000 identity theft
  reports to the FTC in 2005, accounting for more than a third of
  all complaints the agency received.
  Police became aware of the gang after a reported break-in at the
  gang's base of operations. When they raided the premises they
  found the gang hard at work at their computers and arrested them.
  "They were very busy when they were arrested," the CPS said.
  The gang used fake identities, and falsified and forged passports
  to open bank and PayPal accounts, and sent the goods they purchased
  to residential addresses for later sale. They had already requested
  the mail be redirected from the addresses. Goods including
  Manchester United strips and cameras, which have a high resale
  value, were then auctioned on eBay.
  The CPS told ZDNet UK, CNET News.com's sister site, that the gang
  also had data containing registries of births and deaths, local
  tax documents and electoral registration applications, and that
  they had 120 different checkbooks in their possession.
  "Fraud was their bread and butter," the CPS representative said.
  There is an outstanding arrest warrant for another member of the
  gang, believed to be a ringleader. Known as Mr. Kaljusaar, police
  have evidence of his involvement but as yet have no idea who or
  where he actually is, the CPS said.
  After the break-in at the gang's premises, the police became aware
  of an outstanding international arrest warrant for Gelonkin/Dolgov
  in the name of Anthony Peyton, which had been issued after the
  arrest of gang member Andreas Furhmann by Spanish authorities.
  Another gang member, Romanos Vasiliauskas, was jailed for 18
  months on Thursday.

@_date: 2006-02-24 10:45:30
@_author: dan@geer.org 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use  
> >> Usability should by now be recognized as the key issue for security -
 > >> namely, if users can't use it, it doesn't actually work.
% man gpg | wc -l
% man gpg | grep dry
-n, --dry-run   Don't make any changes (this is not completely implemented).
I rest my case.

@_date: 2006-01-28 18:55:26
@_author: dan@geer.org 
@_subject: thoughts on one time pads  
In our office, we have a shredder that happily
takes CDs and is designed to do so.  It is noisy
and cost >$500.

@_date: 2006-07-11 14:14:36
@_author: dan@geer.org 
@_subject: Interesting bit of a quote  
I can corroborate the quote in that much of SarbOx and
other recent regs very nearly have a guilty unless proven
innocent quality, that banks (especially) and others are
called upon to prove a negative: X {could,did} not happen.
California SB1386 roughly says the same thing: If you cannot
prove that personal information was not spilled, then you
have to act as if it was.  About twenty states have followed
California's lead.  The surveillance requirements of both
SEC imposed-regulation and NYSE self-regulation seem always
to expand.  One of my (Verdasys) own customers failed a
SarbOx audit (by a big four accounting firm) because it
could not, in advance, *prove* that those who could change
the software (sysadmins) were unable in any way to change
the financial numbers and, in parallel, *prove* those who
could change the financial numbers (CFO & reports) were
unable to change the software environment.
Jeffrey Ritter, partner in the "electronic" practice at
(big-name) D.C. law firm Kirkpatrick & Lockhart gave the major address at the annual meeting of the Cyber Security
Industry Alliance recently.  In it he said that what he
and his firm tell their (big-name) clients is this:
and he did not mean this in the "paths to invisibility"
sense but rather that you have liability unless you can
prove that you don't.
While one can say that this has always been true or that
the insider has always been the real threat, or whatever
variation you like, as a consultant for nearly two decades
the burgeoning "prove a negative" focus feels unprecedented
to me.  And it is not just our field -- today's Boston
newspaper has the State of Massachusetts' building inspectors
being suspended en masse' for refusing en masse' to accept
GPS position tracking as a newly imposed job requirement.
By next summer, every animal in the country is supposed to
be chipped and the owner's home address recorded in GPS
form (google for NAIS) with a requirement to file with
USDA any off premises transportation (taking the kids'
heifer to the the 4H show included).
The great distinction: A conservative is a socialist who worships order.
A liberal is a socialist who worships safety.                         -- Victor Milan', 1999

@_date: 2006-07-11 21:00:47
@_author: dan@geer.org 
@_subject: Interesting bit of a quote  
You're talking about entirely different stuff, Lynn,
but you are correct that data fusion at IRS and everywhere
else is aided and abetted by substantially increased record
keeping requirements.  Remember, Poindexter's TIA thing did
*not* posit new information sources, just fusing existing
sources and that alone blew it up politically.  As a security
matter relevant here, we can't protect un-fused data so
fused data is indeed probably worse.
On the "prove-a-negative" area, every time I say this in
front of CISO-level audiences I get nodding assent.  Ain't
making it up, in other words.  Innocent until proven
guilty seems now to be true in criminal matters; guilty
until proven innocent holds sway in the civil arena.
On the idea that our version of it is just one of many
versions of the same phenomenon in all fields, not just
the crypto-security one, today (literally) I was ordered
by the State of Rhode Island to install smoke and fire
detectors with direct tie-in to the Fire Department in
my farm's riding arena (a steel frame building with dirt
floor and three doors big enough for a semi).  Why?  Because
the regulators couldn't figure out whether I was a place of
assembly or not so, therefore, I must be a place of assembly
and my next hearing is whether I need sprinklers.  Mind you,
klaxons & strobes, now required, guarantee killing any
non-expert riders who are in the ring when they go off, but since the regulators themselves cannot prove to themselves that they don't have to impose the same requirements as a movie theater, to protect their own
asses it is me that has to now prove to them that I am
not covered -- which appears to mean getting the Legislature
to specifically exempt riding arenas since if that
Legislature is silent the regulators will assume the
worst and that means their ass versus mine.
The core issue here is thus runaway positive feedback loops.
When you hold regulators (fire inspectors, financial auditors,
whatever) liable for not having proven that their clients
cannot have anything wrong (which is why Arthur Anderson
went out of business, e.g.), then you get prove-a-negative
from the regulators and auditors -- madness on the same
scale as tulip mania or the defenestration of Prague.

@_date: 2006-07-11 21:08:14
@_author: dan@geer.org 
@_subject: Interesting bit of a quote  
>I can corroborate the quote in that much of SarbOx and
 >other recent regs very nearly have a guilty unless proven
 >innocent quality, that banks (especially) and others are
 >called upon to prove a negative: X {could,did} not happen.
 >California SB1386 roughly says the same thing: If you cannot
 >prove that personal information was not spilled, then you
 >have to act as if it was.
  No, it doesn't.  I think you've got it backwards.  That's not what SB1386
 says.  SB1386 says that if a company conducts business in Caliornia and
 has a system that includes personal information stored in unencrypted from
 and if that company discovers or is notified of a breach of the security
 that system, then the company must notify any California resident whose
 unencrypted personal information was, or is reasonably believed to have
 been, acquired by an unauthorized person. [*]
 Been with a reasonable number of General Counsels
on this sort of thing.  Maybe you can blame them
and not SB1386 for saying that if you cannot prove
the data didn't spill then it is better corporate
risk management to act as if it did spill.  All I know
is that the GCs, or for that matter the newspapers,
are full of stories about, say, buying credit-watch
services for everyone who could conceivably be at
any non-zero risk.  "Conceivably at non-zero risk"
maps to "prove a negative" at least as I mean it here.
This may be, in other words, de facto versus de jure
and your interpretation may be the correct one.  It
doesn't seem so to me, but YMMV.
And, yes, SarbOx is worse.

@_date: 2006-05-04 10:27:47
@_author: dan@geer.org 
@_subject: fyi: Deniable File System - Rubberhose 
OK, I'll say it.  This site:
  makes me visualize tinfoil hats.

@_date: 2006-05-08 10:25:39
@_author: dan@geer.org 
@_subject: MetriCon 1.0 
Security Metrics
Three of us put together a discussion group; it's grown to 150
over the course of a year.  We've now decided to hold an official
Workshop.  See
If security metrics are your game, this will be the place.

@_date: 2006-05-12 09:17:47
@_author: dan@geer.org 
@_subject: NSA knows who you've called.  
And a personal note to you all:
  Let me again remind people that if you do not inform your elected
 representatives of your displeasure with this sort of thing,
 eventually you will not be in a position to inform them of your
 displeasure with this sort of thing.
 While I agree with you, the public does not,
so far as I can tell, find itself willing to
risk insecurity for the benefit of preserving
privacy, as this article in today's Boston
Globe would tend to confirm.
   Most put security ahead of privacy
   (By Bruce Mohl, Globe Staff)
   Mark Jellison, a Verizon customer in Quincy, isn't fazed that his
   phone company may have turned over his calling records and those of
   millions of others to the National Security Agency as part of an
   effort to thwart terrorism.

@_date: 2006-05-12 15:06:09
@_author: dan@geer.org 
@_subject: NSA knows who you've called.  
Probably because most Americans believe they are being spied on
 anyways.  (And have for a very long time.)
 Au contraire', it is precisely what, for example,
my spouse would say: "I live a decent life and have
nothing to hide."
As this and all security-related lists are composed
of people who are off-center when it comes to risk,
it is us what be the outliers in the distribution
and in no way are our various paranoias widely shared.
Not trying to debate the hive mind, etc.,

@_date: 2006-05-12 16:11:30
@_author: dan@geer.org 
@_subject: NSA knows who you've called.  
...
 Or to teach pollsters to ask the correct questions.
 ...
Mr. Owen is dead-on.  Speaking as someone who has had
a formal education in statistics including the design
of survey instruments, I will say that of all the ways
in which it is possible for the dishonest to skew the
results of quantitative analysis, survey design is hands
down the most vulnerable.  You want the numbers to come
out your way?  Sure, you can manipulate any data set of
numbers to lean the direction you want them to lean,
but if you control the survey instrument used to collect
the raw data in the first place you 0wn the analysis
in ways that re-analysis by others cannot erase.
Case in point: Allowing those who care about Issue XYZ
to self-select whether to take your survey guarantees
overweighting the tails of your distribution and in
ways that you may not be able to see (such as organized
survey takers who talk to each other).  Sort of like
an Internet-mailing-list, no?

@_date: 2006-05-12 19:58:09
@_author: dan@geer.org 
@_subject: NSA knows who you've called.  
You and I are in agreement, but how do we get
the seemingly (to us) plain truth across to
others?  I've been trying for a good while now,
reaching a point where I'd almost wish for a
crisis of some sort as persuasiveness is not
We are probably well off-topic for this list.

@_date: 2006-05-12 20:21:22
@_author: dan@geer.org 
@_subject: NSA knows who you've called.  
I guess the big question is one of trust.  I cannot see why people
 trust the Bush administration.  Any time they have been given power
 they have abused it or used it to destroy their rivals.
 I don't think this has anything to do with
any particular administration.  As Gilmore
would say now (hi, John), don't give any
government a power you would not want a despot to have. What's on my car

@_date: 2006-05-22 12:49:39
@_author: dan@geer.org 
@_subject: Phil Zimmerman and voice encryption; a Skype problem?  
.............................. -- that leaves open the possibility of a
 protocol change that implemented some sort of Clipper-like functionality.
 A silent change like that would be *very* ominous.
 I'm reminded of Adi Shamir's 2004 Turing Award Lecture
* Absolutely secure systems do not exist
* To halve your vulnerability, you have to double your expenditure
* Cryptography is typically bypassed, not penetrated

@_date: 2006-10-02 23:24:28
@_author: dan@geer.org 
@_subject: obituary 
Mildred Hayes, 78; decoded Russian messages for NSA
By Joe Holley, Washington Post  |  October 1, 2006
WASHINGTON -- Mildred Louise Hayes, a retired Russian-language
cryptologist with the National Security Agency, died of respiratory
failure Sept. 23 at her home in Gulfport, Miss. She was 78.
The former resident of Fairfax Station, Va., had lived in Gulfport
since 2005.
At the National Security Agency, Ms. Hayes was involved with Venona,
a computer-created code name for a small, very secret program set
up to examine Soviet diplomatic communications. Established in 1943,
Venona soon expanded its message traffic to include espionage
efforts. The Central Intelligence Agency finally unveiled the project
in 1995, 15 years after it ended, hailing it as one of the most
significant counterespionage accomplishments of the Cold War.
Over the years, the program uncovered information about Soviet
efforts to acquire information about US atomic bomb research and
the Manhattan Project and about Soviet spy networks in the United
States. It led to the unmasking of Klaus Fuchs, the German-born
scientist convicted of spying for the Soviets; Julius and Ethel
Rosenberg, who were executed for espionage in 1953; and British
intelligence officer Kim Philby, who after defecting to Moscow in
1963 admitted that he had been a Soviet spy for two decades.
Ms. Hayes was one of the dozens of language teachers and professors,
many of them young women, who were recruited by the US Army's Signal
Intelligence Service, forerunner to the National Security Agency,
to come to Washington and work as code breakers after the Japanese
attack on Pearl Harbor. Based at the headquarters of Signal
Intelligence at Arlington Hall in Northern Virginia, the Venona
cryptanalysts sifted through thousands and thousands of encrypted
cable messages from the Soviet Union.
Ms. Hayes, who was recruited for the program in 1952, was born in
Cisco, Texas. Her father died when she was 6, and when her mother
remarried, her stepfather decided he didn't want to raise the girl
and her sister, only their little brother. An aunt and uncle in
Little Rock took in the two girls.
She grew up in Little Rock and received a bachelor's degree in
languages from Arkansas State University in 1944. She received a
master's degree in Russian language and linguistics from George
Washington University in 1980.
Her marriage to Paul Hayes ended in divorce. Ms. Hayes leaves a
daughter, Sharon Hayes of Gulfport, and a brother.

@_date: 2006-09-14 11:25:11
@_author: dan@geer.org 
@_subject: Why the exponent 3 error happened:  
ASN.1 provided additional redundant information, making
 possible unexpected data layouts that should not
 normally happen.  It had too much expressive power, too
 much flexibility.  It could express cases that one does
 not expect to deal with, could flex in more ways than
 one's software is likely to be written for.
 Sir,  There is a lesson here as important as
Fred Brook's "Adding people to a late project
makes it later" and I urge you to put this in
some form of "print" at your earliest capability.
No, not urge but rather beg.
P.S., If needing further examples, take a shot at
the fattest, sittingest duck -- the PERL credo:
"There's more than one way to do it."

@_date: 2007-04-05 11:48:12
@_author: dan@geer.org 
@_subject: DNSSEC to be strangled at birth.  
For the purposes of discussion,
(1) Why should I care whether "Iran or China" sign up?
(2) Who should hold the keys instead of the only powerful
    military under democratic control?
    (a) The utterly porous United Nations?
    (b) The members of this mailing list, channeling
    for the late, lamented Jon Postel?
    (c) The Identrus bank consortium ("we have your
    money, why not your keys?") in all its threshhold
    crypto glory?
    (d) The International Telecommunication Union?
    (e) Other: _____________________________
Hoping for a risk-analytic model rather than an
all-countries-are-created-equal position statement.

@_date: 2007-04-29 14:48:00
@_author: dan@geer.org 
@_subject: Cryptome cut off by NTT/Verio  
[Moderator's note: I'm forwarding this one message, but I will
 not be forwarding any further messages on what regulations ISPs
 should or should not be subject to -- that is beyond the scope of the
 mailing list. --Perry]
Perry, et al.,
"If I ran the zoo", then I would give the big ISPs this choice:
(1) You accept common carrier designation,
which means you are not responsible for your content but you have to charge the
same for transporting X bits independent
of what those bits are.
(2) You can charge whatever you want to
charge, e.g., get into the premium movie
distribution business, but you are not
a common carrier and you are responsible
for the content you carry.
Note that what they want is the good
parts of both (we can charge what we
like and it is never our fault).
 Slightly off topic, but not deeply. Many of you are familiar with
 John Young's "Cryptome" web site. Apparently NTT/Verio has suddenly
 (after many years) decided that Cryptome violates the ISP's AUP,
 though they haven't made it particularly clear why.
  The following link will work for at least a few days I imagine:

@_date: 2007-08-17 10:30:16
@_author: dan@geer.org 
@_subject: Skype new IT protection measure  
We've heard it so many times: "There's nothing to worry about."
 Now, Skype adds a new IT protection measure -- "love":
    "The Skype system has not crashed or been victim of a cyber
   attack. We love our customers too much to let that happen."
 ---------- Forwarded message ----------
Hi all!
On SecurityLab.ru forum an exploit code was published by an anonymous
user.  Reportedly it must have caused Skype massive disconnections
The PoC uses standard Skype client to call to a specific number.
This call causes denial of service of current Skype server and
forces Skype to reconnect to another server. The new server also
"freezes" and so on ... the entire network.
Liks: PoC: Best regards,
Valery Marchuk
Full-Disclosure - We believe in it.
Charter: Hosted and sponsored by Secunia -

@_date: 2007-08-22 20:09:56
@_author: dan@geer.org 
@_subject: curiousity question 
Would any of you care to advance an opinion of Harold Gans?
[ "Who?" is not an opinion, and I am not asking for anyone
to go do research. ]
Offlist or on, as you prefer.

@_date: 2007-08-23 12:40:41
@_author: dan@geer.org 
@_subject: interesting paper on the economics of security  
This lemon-car analogy is interesting.
One sidebar that might be worked into the argument is the
apparently widespread side-line business where a car is
auctioned on eBay but before the sale is consumated the
buyer engages a mechanic to check the car out pre-sale.
The car and the mechanic are generally remote from the
buyer but local to each other, and the mechanic is paid
by the prospective buyer.  The prospective buyer does not
know the mechanic and is instead relying on some (to me)
unknown combination of eBay endorsement and personal
reputation.  Note that all of what I just said is hearsay,
though my office-mate says that he has bought three cars
by this method.  It almost causes me to say "relying party"
out loud...
If this idea is a rathole, then my fault and my apology.

@_date: 2007-12-03 18:14:35
@_author: dan@geer.org 
@_subject: PlayStation 3 predicts next US president  
If on the one hand, the correct procedure is sign-encrypt-sign,
then why, on the other hand, is the parallel not sign-hash-sign ?
Donald T. Davis, "Defective Sign & Encrypt in S/MIME, PKCS MOSS, PEM,
PGP, and XML.", Proc. Usenix Tech. Conf. 2001 (Boston, Mass., June
25-30, 2001), pp. 65-78.(180 Kbytes) (PDF, 200 Kbytes) (HTML, 80 Kbytes)
Summary of the paper.
Abstract: Simple Sign & Encrypt, by itself, is not very secure. Cryptographers
know this well, but application programmers and standards authors still
tend to put too much trust in simple Sign-and-Encrypt. In fact, every
secure e-mail protocol, old and new, has codified na??ve Sign &
Encrypt as acceptable security practice. S/MIME, PKCS PGP, OpenPGP,
PEM, and MOSS all suffer from this flaw. Similarly, the secure document
protocols PKCS XML- Signature, and XML-Encryption suffer from the
same flaw. Na??ve Sign & Encrypt appears only in file-security and
mail-security applications, but this narrow scope is becoming more
important to the rapidly-growing class of commercial users. With file-
and mail-encryption seeing widespread use, and with flawed encryption in
play, we can expect widespread exposures.
In this paper, we analyze the na??ve Sign & Encrypt flaw, we
review the defective sign/encrypt standards, and we describe a
comprehensive set of simple repairs. The various repairs all have a
common feature: when signing and encryption are combined, the inner
crypto layer must somehow depend on the outer layer, so as to reveal any
tampering with the outer layer.

@_date: 2007-12-26 09:54:23
@_author: dan@geer.org 
@_subject: 2008: The year of hack the vote?  
May I point out that if voting systems have a level
of flaw that says only an idiot would use them, then
how can you explain electronic commerce, FaceBook,
or gambling sites?  More people use just those three
than will *ever* vote.

@_date: 2007-12-26 11:49:31
@_author: dan@geer.org 
@_subject: 2008: The year of hack the vote?  
There is every reason to believe that the 2000 presidential
 election was stolen.  A fair/honest/lawful election would
 have made Al Gore the 43rd president.
 Let's not do this or we'll have to talk about JF Kennedy
who, at least, bought his votes with real money.

@_date: 2007-12-26 16:34:55
@_author: dan@geer.org 
@_subject: 2008: The year of hack the vote?  
>  More people use just those three
 > than will *ever* vote.
 More people under 40, certainly.  But in '04 there were 36 million  people over 65, most of whom are eligible to vote.  You know a lot of  70-year old e-gamblers or FaceBook members?
I don't but my many over-70 relatives all have
some sort of e-mail now, many from AOL where
we know from history the price of buying the
AOL screenames in bulk from an insider was at
the rate of $0.001/name.
Quoting my friend Marcus Ranum, the Internet
will remain as insecure as it can and still
apparently function.  Why should voting be
We are approaching a rat hole...

@_date: 2007-12-30 00:06:35
@_author: dan@geer.org 
@_subject: Question on export issues  
What are the rules these days on crypto exports.  Is a review
 still required?  If so, what gets rejected?
 The following is a recent interaction with specialty
export counsel, though somewhat modified as I detoxed
it from base64 to ASCII plaintext and from infinite
line length to fixed line length.
When you file, you have immediate permission to export
to, essentially, the anglophone democracies and western
Europe.  If you have heard nothing in 30 days elapsed
time, you are then free to export generally but you will
never be permitted to export to the embargoed country
list (Cuba, Iran, Sudan, Syria, North Korea, and Libya).
A. BIS Checklist of Questions:
1. Does your product perform "cryptography", or otherwise
contain any parts or components that are capable of performing
any of the following "information security" functions?
(Mark with an "X" all that apply)
a.  _____  encryption
b.  _____  decryption only (no encryption)
c.  _____  key management / public key infrastructure (PKI)
d.  _____  authentication (e.g., password protection, digital signatures)
e.  _____  copy protection
f.  _____  anti-virus protection
g.  _____  other  (please explain) : ___________________________________
h.  _____  NONE / NOT APPLICABLE
2. For items with encryption, decryption and/or key management
functions (1.a, 1.b, 1.c above):
a. What symmetric algorithms and key lengths (e.g., 56-bit
DES, 112 / 168-bit Triple-DES, 128 / 256-bit AES / Rijndael) are
implemented or supported?
b. What asymmetric algorithms and key lengths (e.g., 512-bit
RSA / Diffie-Hellman, 1024 / 2048-bit RSA / Diffie-Hellman) are
implemented or supported?
c. What encryption protocols (e.g., SSL, SSH, IPSEC or PKCS
standards) are implemented or supported?
d. What type of data is encrypted?
B. BIS Review Requirements for Form 748-P.  If any inquiry
is not applicable, please state "N/A."
(a) State the name of the encryption item being submitted for review.
 i. Enter the name of the manufacturer of the software.
 ii. Provide a brief technical description of the basic purpose
 to be served by the encryption;
 iii. Provide a brief description of the type of encryption used
 in the software; e.g., 168-bit Triple DES for xyz purpose, and
 1024-bit RSA for abc purpose.
(b) You would also need to provide brochures or other
documentation as well as specifications related to the software,
relevant product descriptions, architecture specifications and,
if required by BIS, source code.  You must also indicate whether
there have been any prior reviews of the product, if such
reviews are applicable to the current submission.  In addition,
you must provide the following information in a cover letter
accompanying your review request:
 (1) Description of all the symmetric and asymmetric encryption
 algorithms and key lengths and how the algorithms are used.
 Specify which encryption modes are supported (e.g., cipher
 feedback mode or cipher block chaining mode).
 (2) State the key management algorithms, including modulus
 sizes, that are supported.
 (3) For products with proprietary algorithms, include a textual
 description and the source code of the algorithm.
 (4) Describe the pre-processing methods (e.g., data compression
 or data interleaving) that are applied to the plaintext data
 prior to encryption.
 (5) Describe the post-processing methods (e.g., packetization,
 encapsulation) that are applied to the cipher text data after
 encryption.
 (6) State the communication protocols (e.g., X.25, Telnet or
 TCP) and encryption protocols (e.g., SSL, IPSEC or PKCS
 standards) that are supported.
 (7) Describe the encryption-related Application Programming
 Interfaces (APIs) that are implemented and/or supported.
 Explain which interfaces are for internal (private) and/or
 external (public) use.
 (8) Describe the cryptographic functionality that is provided
 by third-party hardware or software encryption components (if
 any).  Identify the manufacturers of the hardware or software
 components, including specific part numbers and version
 information as needed to describe the product.  Describe whether
 the encryption software components (if any) are statically or
 dynamically linked.
 (9) For commodities or software using Java byte code, describe
 the techniques (including obfuscation, private access modifiers
 or final classes) that are used to protect against decompilation
 and misuse.
 (10) State how the product is written to preclude user
 modification of the encryption algorithms, key management and
 key space.
 (11) For products which incorporate an open cryptographic
 interface as defined in part 772 of the EAR, describe the Open
 Cryptographic Interface.
 (12) We must provide sufficient information for BIS to
 determine whether the software qualifies for "mass market"
 consideration.  The regulations offer examples of items that
 qualify.  Please comment on the applicability of any of these
 examples to your software product and how you plan to market it,
 and approximately how many units will be sold per month:
 "general purpose" operating systems and desktop applications
 (e.g., e-mail, browsers, games, word processing, database,
 financial applications or utilities) designed for, bundled with,
 or pre-loaded on single CPU computers, laptops, or hand-held
 devices; commodities and software for client Internet appliances
 and client wireless LAN devices; home use networking commodities
 and software (e.g., personal firewalls, cable modems for
 personal computers, and consumer set top boxes); portable or
 mobile civil telecommunications commodities and software (e.g.,
 personal data assistants (PDAs), radios, or cellular products);
 and commodities and software exported via free or anonymous
 downloads."

@_date: 2007-06-27 12:39:09
@_author: dan@geer.org 
@_subject: The bank fraud blame game  
[ This may well be OT; I leave that to the moderator. ]
 As always, banks look for ways to shift the risk of
 fraud to someone - anyone - else.  The New Zealand
 banks have come up with some interesting wrinkles on
 this process.
 This is *not* a power play by banks, the Trilateral Commission,
or the Gnomes of Zurich.  It is the first echo of a financial
thunderclap.  As, oddly, I said only yesterday, I think that
big ticket Internet transactions have become inadvisable
and will become more so.  I honestly think that the party
could be over for e-commerce, with eBay Motors as its
Now what I think I know and what I am about to say are all
based on hearsay.  It is surely wrong in part, but until I
am corrected in public it is true enough for lemonade
The story begins with E-Trade's 10-Q filing of 17 November,
which filing is at [1] and elsewhere.  In that 10-Q, we have
this paragraph:
In other words, remote exploitation of individual customer's
computers, doubtless many of them home machines and the
laptops of road warriors, eventually lead to a loss for
E-Trade that was material enough to appear on the 10-Q.
This is not a pump&dump scheme where rubes are snookered
into buying some worthless stock.  No, it is the actual
entry of trades into legitimate trading systems by
legitimate users, only with the special case that those
users are actually the alien malware using the captured
credentials of the legitimate user and entering the trades
from the legitimate users' legitimate machine.  As I
understand it, some of this malware is clever enough to
piggyback sessions that are opened by the legitimate user
using the much vaunted 2-factor authentication; thus proving
that 2-factor auth is a mere palliative.
As you are well aware, stealing data is now and everywhere
the name of the game, and "we" have lots of supporting
evidence that such theft is fully professionalized.  As one
example, the APWG has already shown that phishing e-mails
are transmitted in a pattern that suggests the transmitters
are enjoying a conventional 5-day work week, and there are
many other examples.  Mike D'Anseglio, Security Program
Director at Microsoft, said two interesting things in the
last six months: (1) that 2/3rds of all PCs have "unwanted"
software running on them and (2) that state-of-the-art
attack tools cannot be eliminated without a clean install
from the raw iron up.
Well, ironically due to SOx, as the loss amounts get bigger

@_date: 2007-03-20 20:14:26
@_author: Dan Geer 
@_subject: virtualization as a threat to RNG 
Quoting from a discussion of threat posed by software virtualization as found in Symantec's ISTR:xi, released today:

@_date: 2007-05-21 10:55:11
@_author: dan@geer.org 
@_subject: 0wned .gov machines (was Re: Russian cyberwar against Estonia?)  
A while ago, I did a rough calculation that made
me state that 15-30% of all machines are no longer
under the sole control of their owner.  In the
intervening months, I got some hate mail on this,
but in those same intervening months Vint Cerf
said 40%, Microsoft said 2/3rds, and IDC said 3/4ths.
Whatever it is, it is >> 0.
And, of course, definitions matter.  I don't think
that 0wned is a binary variable any more; there are
degrees of 0wned-ness with a wide range between the
optimist ("I replaced` the only program that was
trojaned") to the pessimist ("Any compromise of any
sub-component makes the entire edifice untrustable").

@_date: 2007-10-31 19:48:33
@_author: dan@geer.org 
@_subject: Commercial CAPTCHA-breakers for sale  
The complexity of some the captchas shown on this web-site
 made me think. We have gone to such extents to prevent
 against spammers. When we should be prosecuting and hanging
 the spammers.   Remember
 "Men are not hanged for stealing horses, but that horses may
 not be stolen" George Savile
 I stand ready to organize a massive conspiracy to execute all conspiracy theorists.
Are you with me?

@_date: 2008-08-04 15:00:45
@_author: dan@geer.org 
@_subject: Strength in Complexity?  
With the caveat that I am reading mail in reverse order (i.e., panic-mode), I do have
to say one thing and it isn't even to mount a
stirring defense of Kerberos, which does not
need defending anyhow...
The design space for practical network security
has always been:
   I'm OK
   You're OK
   The Internet is a problem
A gathering storm of compromised machines, now
variously estimated in the 30-70% range depending
on with whom you are talking, means that the situation is now:
   I'm OK, I think
   I have to assume that you are 0wned
   The Internet might make this worse
Put differently, network security has now come
close to Spaf's famous line about netsec in the
absence of host security being assured delivery
of gold bars from a guy living in a cardboard box
to a guy sleeping on a park bench.
BTW, it is probably time to turn off your software's
autoupdate feature.
Likely off-topic,

@_date: 2008-08-09 13:11:20
@_author: dan@geer.org 
@_subject: another proprietary symmetric cipher ? 
yet another proprietary symmetric cipher ?
Encryption Security Solutions provides unprecedented encryption
security, efficiency, and performance for business applications ensuring
critical information is secure.
Encryption Security Solutions, LLC (ES??) has developed an
innovative, proprietary symmetrical encryption algorithm (JUMBLE) for
commercial applications. This algorithm provides an end-to-end or site
solution, for use by individuals or across an enterprise environment.
Using the newly developed and proprietary JUMBLE encryption engine
allows ES?? to provide multiple encryption solutions for all
digital data formats, including real-time streaming high definition
digital video. The JUMBLE engine can be integrated directly in the
client, at the web server, application server, or database layer. This
unique software solution goes beyond current platforms that contain such
things as centralized cryptographic processing, key management, policy
management, and security administration because it does not rely on
human procedure-based security practices. JUMBLE provides unprecedented
advantages in security, scalability and manageability.

@_date: 2008-08-18 16:28:21
@_author: dan@geer.org 
@_subject: Voting machine security  
>(and because of the complexity of US elections,
 >hand counting is quite expensive)
  This is quite disputable. Further, hand vs. machine counting is core  to the way we think about the security of the voting system.
 The keynote talk for the USENIX Security Symposium was       Dr. Strangevote or: How I Learned to Stop Worrying
      and Love the Paper Ballot
      Debra Bowen, California Secretary of State and her talk had one slide only.  I do not have the
slide, but I can reproduce it.  It was a photo of
the tail end of her car and on it a bumper sticker.
That bumper sticker read
      PREVENT UNWANTED PRESIDENCIES
      MAKE VOTE COUNTING A HAND JOB
In no other state could a Constitutional Officer
get away with such a bumper sticker, but...

@_date: 2008-08-27 07:10:51
@_author: dan@geer.org 
@_subject: road toll transponder hacked 
Bill Frantz writes, in part:
 In the San Francisco Bay Area, they are using the transponder codes
 to measure how fast traffic is moving from place to place. They
 post the times to various destinations on the electric signs when
 there are no Amber alerts or other more important things to
 display. It is quite convenient, and they promise they don't use it
 to track people's trips.
Look for general tracking to appear everywhere.
Fast declining gasoline tax revenues will be
replaced with per-mile usage fees, i.e., every
major road becomes a toll road.  Most likely
first in will be California and/or Oregon.
The relationship to this list may then be thin
excepting that the collection and handling of
such data remains of substantial interest.  Of
course, everyone who carries a cell phone has
already decided that convenience trumps security,
at least the kind of security that says "they
can't misuse what they ain't got."

@_date: 2008-08-27 16:36:52
@_author: dan@geer.org 
@_subject: road toll transponder hacked 
> Personally, I don't want to have a history of my travel stored in any
 > database. Right now, purchasing a one-time CharlieTicket is a 30 cent
 > surcharge per ride, but it is the only way to take the subway in Boston
 > without creating a travel history. Privacy in public transportation
 > should be equally accessible to all citizens, regardless of financial
 > resources.
I suspect that you, as do I, pay for as many things
in cash as humanly possible though, of course, we are
well past the point at which paying for an airline
ticket, say, in cash does anything more than make
you even more inspected than you would be if you
used credit.
That said, the 30c surcharge for having no record
kept for riding the subway is at once a "price" for
privacy that is at least expressed in the coin of
the realm and, at the same time, not a guarantee,
just a side effect.  If the MBTA general manager
were to say "For 30c more, we promise to forget
you were a passenger" he would be out of a job in
the morning at the Governor's demand and there'd
be wide agitation against the idea that better off
people get privacy when poor folks don't.  Do you
suppose that we can, just possibly, make privacy
into a class warfare issue?
We sort of do that already in that the people
who make privacy law, legislature and executive
alike, are afforded precisely zero privacy by
both the courts and the press.  As such, one has
to be a truly addled optimist to imagine that
those who have no privacy are nevertheless willing
to grant you more privacy than they have, unless
they are somehow nostalgic for what they themselves
lost in becoming a member of government.  Me, I
think that the loss of privacy required to become
part of government is a sieve for not caring about
such issues because, if you did care, you wouldn't
go into government in the first place.

@_date: 2008-08-27 22:27:29
@_author: dan@geer.org 
@_subject: road toll transponder hacked  
"Steven M. Bellovin" writes, in part:
 There's a limit to how far they can go with that, because of the fear
 of people abandoning the transponders.
  As for usage-based driving -- the first question is the political will
 to do so.
  Finally, the transponders may not matter much longer; OCR on license
 plates is getting that good.
 I don't think whether it is a transponder or not
actually matters, Steve, since, as you say, OCR
of the license plates makes whether a transponder
is in place totally irrelevant.
As to public resistance -- look at the revenue
coming in to, say, Chicago from the red-light
cameras and tell me that this won't spread.
Similarly, per-mile road-use pricing will be
all about revenue enhancement but it will be
painted DHS-faireness-green ("So as to fairly
fund the maintainance of this State's critical
infrastructure, this Act converts the funding
mechanisms over to a fairer road-use policy
but, at the same time, it leaves in place the
State gasoline tax, thereby penalizing the
people who continue to drive gas guzzlers").
Which leads back to the recording of travel
and the handling of those recordings.  When
New Jersey signed up with EZ-Pass it required
the company involved to retain toll records
for ten years (as an aid to law enforcement).
Since that is the same company in lots of
states even if it is called something else
(like FastLane in Massachusetts), the rational
thing for the company to do is to just keep
everything forever.  With disk prices falling
as they are, keeping everything is cheaper
than careful selective deletion, that's for

@_date: 2008-12-05 19:06:01
@_author: dan@geer.org 
@_subject: Quantum direct communication: secrecy without key distribution  
>  > The most obvious flaw is that when we're talking fiber optics the
 > eavesdropper might as well be a man in the middle, and so...  well, see
 > the list archive.
 > ...possibly OT...
well-placed but UNCORROBORATED informant sez that
day before yesterday (3 dec):
5 hours of CheckFree traffic redirected and likely
captured in full
half of IP addresses for CheckFree left in place, half
re-directed to Ukraine, i.e., partial MITM entirely
at the routing protocol layer
as is so often the case, slight amateurish fuckup at
the Ukrainian end raised the alarm -- would not otherwise
have been found for days
[the important part] it appears that in the last few hours
a method has been ?found/?released that makes possible the
MITM completely transparent with all traffic forwarded on
as if there was just an extra hop in the path; MITM via an
effective attack on routing protocols, per se, would be no joke

@_date: 2008-12-09 22:15:56
@_author: dan@geer.org 
@_subject: AES HDD encryption was XOR 
The computing power of the microprocessor is still under
 32 powers of 2 from its inception, naive extrapolation
 to the next 32 powers of 2 is unwise.
Well taken, indeed.
But what I am myself interested in is the relationship
of the three main up-curves, Moore's for CPU horsepower
per unit of money, and its two un-named siblings for
storage and for bandwidth.  As I read the tea-leaves,
storage is doubling at perhaps a 12-month rate while
bandwidth is faster still.  Yes, these are laboratory
figures, but the lab is where the action is.
This tells me, I think, that the future of computing
is ever more data-rich but, at the same time, that
that data-richness is eclipsed by ever-increasing
Suppose the doubling times are 18/12/9; then a decade
is two orders of magnitude for CPU, three for storage,
and four for bandwith.  I do not see how this does not
radically alter the economically optimal computing
infrastructure or, for that matter, the nature of the
problems we here are collectively paid to solve.
This is, of course, all irrelevant if and when the
Singularity occurs.  Kurzweil's guess of 2035 is
27 years away, which is to say 18 powers of two out,
not 32.  Perhaps relevant to this list, imagine that
the research described here:
was of two programs creating not music but a cipher.
Thinking out loud,
[ just for amusement, 2008 world production of wheat
  and rice would each cover 53 squares, with maize
  coming in at 51 squares ]

@_date: 2008-02-03 23:16:55
@_author: dan@geer.org 
@_subject: Interesting editorial comment on "security" vs. privacy  
Earlier this week, I heard Dr. Donald Kerr, Principal
Deputy Director, ODNI, say that the greatest challenge
of the next (U.S.) administration would be a fundamental
re-thinking of the inter-relation of security & privacy.

@_date: 2008-02-06 20:49:45
@_author: dan@geer.org 
@_subject: Gutmann Soundwave Therapy  
> Amateurs talk about algorithms.  Professionals talk about economics.
That would be
  Amateurs study cryptography; professionals study economics.
  -- Allan Schiffman, 2 July 04
Quotationally yours,

@_date: 2008-01-03 11:52:21
@_author: dan@geer.org 
@_subject: Death of antivirus software imminent  
> however, another interpretation is that the defenders
 > have chosen extremely poor position to defend ... and are
 > therefor at enormous disadvantage. it may be necessary
 > to change the paradigm (and/or find the high ground)
 > in order to successfully defend.
First, it is evident that the malware writers have
reached a level of sophistication where stealth is
more attractive than persistence, i.e., prey are
sufficiently abundant that it does not matter if your
code survives reboot -- you can always get a new
machine soon enough.  Second, as soon as one of these
guys figures out how to hook the memory manager
(which may already have happened), then the ability
to find the otherwise in-core-only malware goes away
as your act of scanning memory will be seen by the
now-corrupted memory manager and the malware will be
thus relocated as you search such that you are
playing blindman's bluff without knowing that you
are.  Third, targetted malware does not defeat the AV
paradigm technically, rather it defeats the business
model as no AV company can afford to craft, test, and
distribute signatures for any malware that does not
already have, say, 50,000 victims.  Fourth, under
so-called Service-Oriented-Architecture, there is no
one anywhere who knows where all the moving parts
The aspect of this that is directly relevant to this
list is that while "we" have labored to make network
comms safe in an unsafe transmission medium, the
world has now reached the point where the odds favor
the hypothesis that whomever you are talking to is
themselves already 0wned, i.e., it does not matter if
the comms are clean when the opponent already owns
your counterparty.
I blogged on this recently (guest for Ryan Naraine)
and it made the top of Slashdot.  Apologies for
boring those who've already seen it.

@_date: 2008-01-06 17:48:26
@_author: dan@geer.org 
@_subject: Death of antivirus software imminent  
Alexander Klimov writes, in part:
 It sounds like: we cannot make secure OS because it is too
 large -- let us don't bother to make a smaller secure OS,
 just add some more software and hardware to an existent
 system and then it will be secure. Sounds like a fairytale :-)
As yet another variation on the theme "complexity is the
enemy of security," consider patches.  Patches tend to
add complexity to the code they patch, viz., it is the
rare patch indeed that simply elides some non-working
Taking as our metric the venerable McCabe score:
   v(G) = e - n + 2
where e and n are the number of edges and nodes in the
control flow graph, and where you are in trouble when
v(G)>10 in a single module, the simplest patch adds two
edges and one node, i.e., v'(G)=v(G)+1, and that minimum
obtains only for patches with no conditional branches in
the patch.
If someone wanted to have fun, it would be to examine
what fraction of patches are themselves re-patched at
a later date -- as in Fred Brooks' famous dictum in
_The Mythical Man Month_ where, in paraphrase, he said
that you should stop patching when the probability of
fixing a known problem is no longer substantially
greater than the probability of simultaneously creating
an unknown problem.
Yet security patches are a special case: no vendor can
obey Brooks' Law, and so they will inevitably over-run
the boundary condition where the known flaw the new
patch patches is no longer likely to be substantially
more probable than the inadvertent introduction of an
unknown flaw at the same time.  As such, I would guess
that the more often an application receives security
patches the less secure it is, at least at the limit.

@_date: 2008-01-07 10:35:00
@_author: dan@geer.org 
@_subject: Death of antivirus software imminent  
It is always possible that I misunderstand the McCabe
score which may come from the fact that so many build
environments compute it along with producing the binary,
i.e., independent of human eyeballs.  If complexity
scoring requires human eyeballs or the presence of the
designer's flow charts, then will we ever get meaningful
numbers (sans artificial intelilgence) for code we did
not write ourselves?  [...yes, this parallels the many
arguments about how can you trust crypto code you didn't
write, either...]
If McCabe scoring is your area, do you agree with the
rule that a McCabe score of <10 is essential -- an argument
that I am quoting from some NASA spec I read a while ago
and can dig up again if that turns out to be necessary.
Always ready for re-education, but wary of the best
being the enemy of the good,

@_date: 2008-01-21 10:27:46
@_author: dan@geer.org 
@_subject: 2008: The year of hack the vote?  
Well, for all of you who want to prove that hacking
the vote is easy, here's your chance to do something:
[ ObDebate: is a winner-take-all state more or less
attractive to vote hacking? ]

@_date: 2008-01-21 10:36:27
@_author: dan@geer.org 
@_subject: DRM Helps Sink Another Content Distribution Project  
So, what is Apple doing for its brand-new iTunes movie rental thing?
1/3rd of the way into Jobs' song-and-dance

@_date: 2008-01-21 10:36:27
@_author: dan@geer.org 
@_subject: DRM Helps Sink Another Content Distribution Project  
So, what is Apple doing for its brand-new iTunes movie rental thing?
1/3rd of the way into Jobs' song-and-dance

@_date: 2008-01-23 09:29:57
@_author: dan@geer.org 
@_subject: patent of the day  
>  > I wonder whether this was research to see how hard it
 > was to get the PTO to grant an absurd patent.
 > Get Simson's opinion, please.  It is not insane to
patent something so that you can control its use
and to do so for reasons other than wanting to
lay about in the Caribbean/Vegas.
As to prior art, consider "A Revocable Backup System,"
by Boneh and Lipton, 6th USENIX Security Symposium,
presented 25 July 1996.  (see [1] below)
BTW, I can personally attest that the USPTO makes
both Type I (false positive) errors (in granting
patents that should not be classified as useful
and unobvious) *and* Type II (false negative)
errors (when confronted with something sufficiently
unobvious that they find it impossible to understand
that it is either unobvious or useful much less

@_date: 2008-06-15 14:20:23
@_author: dan@geer.org 
@_subject: reminder of upcoming deadline  
MetriCon 3.0 agenda at this URL
  Workshop is limited attendance though some small number
of requests can still be granted; send same by e-mail to
  metricon3 at securitymetrics.org

@_date: 2008-06-21 19:26:42
@_author: dan@geer.org 
@_subject: [Beowulf] Re: "hobbyists"  
I think that's a wise decision. Skype is a giant black
 box.  Fabrice Desclaux published a fair amount of
 cryptanalysis papers about Skype, each one more
 frightening than the previous ([1], [2] and [3]) My read on Skype is that they are doing a world
leading job when it comes to avoiding vulnerabilities,
better, indeed than the operating systems on which
they run.
One could call it a design weakness that to interface with the plain old telephone system there has to be
a knowable, fixed in-the-clear peering to the POTS.
If I am a state actor or equivalent, I do not need
to bother myself with breaking VoIP crypto -- I just
insert some tool into the peering point where the
Skype caller reverts to the ordinary.
Yes, a state may be interested in two parties each
of whom has a Skype instance and thus the demodulation
for POTS does not occur, but two such parties, if
they really care, would do their own end-to-end
protections even if it is a simple as speaking
All hail Saltzer, Reed, and Clark.

@_date: 2008-06-30 13:44:56
@_author: dan@geer.org 
@_subject: The wisdom of the ill informed  
...
 Not so fast. Bank PINs are usually just 4 numeric characters long and  yet they are considered /safe/ even for web access to the account  (where a physical card is not required).
  Why? Because after 4 tries the access is blocked for your IP number  (in some cases after 3 tries).
 ...
So I hold the PIN constant and vary the bank account number.

@_date: 2008-05-06 06:48:35
@_author: dan@geer.org 
@_subject: reminder of upcoming deadline 
Call for Participation
MetriCon 3.0
Third Workshop on Security Metrics
Tuesday, 29 July 2008, San Jose, California
Security metrics -- an idea whose time has come. No matter whether you read the technical or the business press, there is a desire for converting security from a world of adjectives to a world of numbers. The question is, of course, how exactly to do that. The advantage of starting early is, as ever, harder problems but a clearer field though it is very nearly too late to start early. MetriCon is where hard progress is made and harder problems brought forward.
The MetriCon Workshops offer lively, practical discussion in the area of security metrics. It is a, if not the, forum for quantifiable approaches and results to problems afflicting information security today, with a bias towards practical, specific implementations. Topics and presentations will be selected for their potential to stimulate discussion in the Workshop. Past events are detailed here [1] and here [2]; see, especially, the meeting Digests on those pages.
MetriCon 3.0 will be a one-day event, Tuesday, July 29, 2008, in San Jose, California, USA. The Workshop begins first thing in the morning, meals are taken in the meeting room, and work/discussion extends into the evening. As this is a workshop, attendance is by invitation (and limited to 60 participants). Participants are expected to "come with findings," to "come with problems," or, better still, both. Participants should be willing to discuss what they have and need, i.e., to address the group in some fashion, formally or not. Preference will naturally be given to the authors of position papers/presentations who have actual work in progress.
Presenters will each have a short 10-15 minutes to present his or her idea, followed by a another 10-15 minutes of discussion. If you would like to propose a panel or a group of related presentations on different approaches to the same problem, then please do so. Also consistent with a Workshop format, the Program Committee will be steered by what sorts of proposals come in response to this Call.
Goals and Topics
Our goal is to stimulate discussion of, and thinking about, security metrics and to do so in ways that lead to realistic, early results of lasting value. Potential attendees are invited to submit position papers to be shared with all, with or without discussion on the day of the Workshop. Such position papers are expected to address security metrics in one of the following categories:
Benchmarking of security technologies
Empirical studies in specific subject matter areas
Financial planning
Long-term trend analysis and forecasts
Metrics definitions that can be operationalized
Security and risk modeling including calibrations
Tools, technologies, tips, and tricks
Visualization methods both for insight and lay audiences
Data and analyses emerging from ongoing metrics efforts
Other novel areas where security metrics may apply
Practical implementations, real world case studies, and detailed models will be preferred over broader models or general ideas.
How to Participate
Submit a short position paper or description of work done or ongoing. Your submission must be brief -- no longer than five (5) paragraphs or presentation slides. Author names and affiliations should appear first in or on the submission. Submissions may be in PDF, PowerPoint, HTML, or plaintext email and must be submitted to metricon3 AT securitymetrics.org. These requests to participate are due no later than noon GMT, Monday, May 12, 2008 (a hard deadline).
The Program Committee will invite both attendees and presenters. Participants of either sort will be notified of acceptance quickly -- by June 2, 2008. Presenters who want hardcopy materials to be distributed at the Workshop must provide originals of those materials to the Program Committee by July 21, 2008. All slides, position papers, and what-not will be made available to all participants at the Workshop. No formal academic proceedings are intended, but a digest of the meeting will be prepared and distributed to participants and the general public. (Digests for previous MetriCon meetings are on the past event pages mentioned above.) Plagiarism is dishonest, and the organizers of this Workshop will take appropriate action if dishonesty of this sort is found. Submission of recent, previously published work as well as simultaneous submissions to multiple venues is entirely acceptable, but only if you disclose this in your proposal.
MetriCon 3.0 will be co-located with the 17th USENIX Security Symposium at the Fairmont Hotel in San Jose, California.
$225 all-inclusive of meeting space, materials preparation, and meals for the day.
Important Dates
Requests to participate: by May 12, 2008
Notification of acceptance: by June 2, 2008
Materials for distribution: by July 21, 2008
Workshop Organizers
Dan Geer, Geer Risk Services, Chair
Bob Blakley, The Burton Group
Fred Cohen, Fred Cohen & Associates & California Sciences Institute
Dan Conway, Indiana University
Lloyd Ellam, Iceberg Networks
Andrew Jaquith, The Yankee Group
Elizabeth Nichols, PlexLogic
Gunnar Peterson, Arctec Group
Bryan Ware, Digital Sandbox
Christine Whalley, Pfizer
1 2

@_date: 2008-05-27 10:39:47
@_author: dan@geer.org 
@_subject: not crypto, but fraud detection + additional  
I don't know what the policy is in Ireland, but here in the USA  there is no stop loss on debit cards so the banks are not  obligated to make good on fraudulent withdrawals. There is also a legal distinction between a personal
credit card and a corporate card in terms of the regulated upper bound on the losses due to a stolen
card and fraudulent charges on it, though the credit
companies tend never to stand on their right to not
rescind fraudulent charges on non-personal cards.
Factoid: Had the $50 stop-loss limit been indexed for
inflation, then it would today be $300.  (1968-present)

@_date: 2008-11-09 14:56:27
@_author: dan@geer.org 
@_subject: voting by m of n digital signature?  
Is there a way of constructing a digital signature so
 that the signature proves that at least m possessors of
 secret keys corresponding to n public keys signed, for n
 a dozen or less, without revealing how many more than m,
 or which ones signed?
 quorum threshhold crypto; if Avishai Wool or Moti Yung
or Yvo Desmedt or Yair Frankel or...  are here on this
list, they should answer
a *tiny* contribution on my part

@_date: 2008-09-09 11:42:57
@_author: dan@geer.org 
@_subject: once more, with feeling. 
Peter Gutmann writes, in part:
 ... - the rate-limiting step is the fact that
 the crooks simply can't use all the stolen identities
 they have, not any security measures that may be present.
 ...
To my knowledge, you are correct.  It seems that the
price of stolen credentials (on the black market) is
falling, which, as with the street price of heroin, would
tend to indicate that the opposition is winning.
I have a slide for this somewhere (not on this machine)
and will dig it up if needed, but the disparity between
actual crime and a naive estimate of the opportunity for
crime seems to be widening.  If correct, then such a
disparity would either indicate that our countermeasures
are winning -or- the predators are leaving prey on the
field.  I'm sadly of the opinion that it is the latter.
In their Internet Security Threat Report, Symantec used
to publish the number of bots detected.  The last one of
those I have at hand showed a leveling out of the number
found de novo per unit interval (per month).  Again, this
permits two interpretations; on the one hand, we are winning
in that we are preventing the problem from worsening while
on the other hand it can be read to mean that as fast as
we remove bots from hosts that other hosts are botted
and, as such, the supply of bots being stable implies
that it is easy enough to replace them that the lost of
an individual host does not slow down our opposition.
What does (in the Symantec graphs) vary is the variance
of in-and-out-flow, but not the fraction that are botted.
This would tend to strengthen the argument that any
periodic sweep of bots off networks is compensated
for relatively quickly.  In public health, widely
varying incidence (new infection rate) but stable
prevalence (infected fraction) tends to indicate
a high degree of infectability and not a particularly
effective immune response.  We see this in a way in
the AIDS data -- every advance in treatability seems
to be followed by increases in risky behavior while
prevalence remains to a degree stable.
This idea of replacement of cured machines by infected
machines seems corroborated in a different way as well.
The opposition seems to have lately decided that the
advantages of stealth outway the advantages of persistence,
which is to say that in-core-only infection is now the
preferred mechanism and not writing to disk so as to
preserve infected status through a reboot cycle.  If
this is correct, then it signals that the opposition
can replace machines lost through reboot easily enough
that the availability of penetrated machines can be
better enhanced through making infections harder to
find (latent, in medical parlance) than through making
a once penetrated machine stay penetrated as to do the
latter you have to expose yourself to periodic clean-up
of that which is persistent (on disk).
For anyone looking ahead, the interaction between this
phenomenon (if it is indeed a phenomenon) and the growing
role of virtual machines should be of intense interest.
Inferentially yours,

@_date: 2008-09-10 11:32:06
@_author: dan@geer.org 
@_subject: street prices for digital goods?  
David Molnar writes, in part:
 Dan Geer's comment about the street price of
 heroin as a metric for success has me thinking -
 are people tracking the street prices of digital
 underground goods over time?
This material is in fact tracked but not so publicly
reported.  You named the obvious sources, but no one
to my knowledge publishes regularly.
I previously committed myself to doing this annually,
and am about to convince myself to go quarterly.  See
    for what I am (lightheartedly) talking about.

@_date: 2008-09-10 12:40:02
@_author: dan@geer.org 
@_subject: street prices for digital goods?  
Sigh...  typing in a moving vehicle.  This is
the right URL, verified by cut&paste.

@_date: 2008-09-11 09:18:05
@_author: dan@geer.org 
@_subject: street prices for digital goods?  
>
 > >Dan Geer's comment about the street price of heroin as a metric for
 > >success has me thinking - are people tracking the street prices of
 > >digital underground goods over time?
 >
 > I've been (very informally) tracking it for awhile, and for generic
 > data (non- Platinum credit cards, PPal accounts, and so on) it's
 > essentially too cheap to meter, you often have to buy the stuff in
 > blocks (10, 20, 50 at a time) to make it worth the sellers while.
  At such cheap prices, it must be close to the point where it would
 be worth it for the the card issuers to buy the numbers as a loss
 mitigation measure.
 I have had a guy who wished to remain nameless
claim that he makes a fine living breaking into
the machines of black-market card sellers and
copying the card numbers they have for sale.
He then (he says) takes those card numbers to
the issuing banks and sells those numbers to the
banks so that the banks can prophylactically
cancel the soon-to-be-affected cards.  He claimed
to get 50c/card.  All hearsay...

@_date: 2009-02-09 11:36:06
@_author: dan@geer.org 
@_subject: anyone know "Morris Code"? 
Does anyone know what the "Morris Code" is inside
Peachinc's "mobile ticketing" appliance/kiosk is?
Reference URL (video advert) at
UK patent, but for the reading mechanism only, at
As always, the phrase "proprietary coding readable
only by us" caught my ear.

@_date: 2009-01-20 17:16:22
@_author: dan@geer.org 
@_subject: [heise online UK] Secure deletion: a single overwrite will do it  
Peter Gutmann has responded
(see the "Further Epilogue" section well down the page)

@_date: 2009-01-24 23:07:17
@_author: dan@geer.org 
@_subject: Bitcoin v0.1 released  
Some people tell me that the 0wned machines are among the most
 secure on the network because botnet operators work hard to
 keep others from compromising "their" machines. I could see the
 operators moving toward being legitimate security firms,
 protecting computers against compromise in exchange for some of
 the proof of work (POW) money.
I'm one of those people.  Quoting from my speech of 1/20:
Rest of text upon request.  Incidentally, I *highly* recommend
Daniel Suarez's _Daemon_; trust me as to its relevance.  Try
this for a non-fiction taste:

@_date: 2009-07-08 20:46:28
@_author: dan@geer.org 
@_subject: Weakness in Social Security Numbers Is Found  
I don't honestly think that this is new, but even
if it is, a 9-digit random number has a 44% chance
of being a valid SSN (442 million issued to date).
Similarly, with Chase and Citi each at about 100M
cards issued, and the 16-digit card number having
7 of those digits fixed-in-advance, a 16-digit
random number has a 10% chance of being a valid
card number.  Amex cards are 15-digits and there
are 50M in play, so a random 15-digit number has
a 50% chance of being a valid card number.  As such,
an attacker is better off holding the password
constant and cycling through account numbers than holding the account number constant and cycling
through password guesses.
Yes, these are approximations for the purpose of
argument, but I don't see what the big deal is for
the "All The News That's Fit to Print" paper in
learning that there ain't much entropy in SSNs.
Hell, my brother and I have sequential numbers.

@_date: 2009-07-21 18:45:07
@_author: dan@geer.org 
@_subject: New Technology to Make Digital Data Disappear, on Purpose  
> The pieces of the key, small numbers, tend to =93erode=94 over time as
 > they gradually fall out of use. To make keys erode, or timeout, Vanish
 > takes advantage of the structure of a peer-to-peer file system. Such
 > networks are based on millions of personal computers whose Internet
 > addresses change as they come and go from the network.
One would imagine that as IPv6 rolls out, the need
for DHCP goes to zero excepting for mobile devices
attaching to public (not carrier) nets.  Yes?

@_date: 2009-07-28 09:41:50
@_author: dan@geer.org 
@_subject: The latest Flash vulnerability and monoculture  
I think this is one of those circumstances where
if you can get the criminal to go to the house
next door you've won and that is all the winning
you can do.  That everyone else uses Famous Vendor
Software Latest Version and you don't is your win.
Now it would be entirely ironic if the complexity
of something (think ASN.1) caused a single working
open source version (think ASN.1 compiler) to eclipse
all other versions just because the complexity has
made it too hard to go forward.  As Mike O'Dell used
to say, left to themselves, competent engineers will
deliver the most complex code they can debug.  This
may apply to the world at large.

@_date: 2009-05-03 16:57:59
@_author: dan@geer.org 
@_subject: Has any public CA ever had their certificate revoked?  
No, but a few years ago I looked at all the certs in IE
and Netscape and found that about 30% of them were from
companies that were at that time no longer in existence.
The expiries on those where-are-they-now certs were often
as not three decades into the future.
N.B., if you are willing to take "no longer baked into
the browser" as effectively revocation, there is a
retrospective clerical job that might be a fun project
if you had some graduate student labor to assign.

@_date: 2009-05-06 21:54:17
@_author: dan@geer.org 
@_subject: MetriCon 4.0 
On behalf of the program committee, may I please direct
your attention to your possible participation MetriCon 4.0.
The MetriCon 4.0 Workshop will be held on Tuesday, August 11,
2009, in Montreal, Quebec, co-located with the USENIX Security
Symposium. All who are interested in participating should
review the formal Call for Participation and, as it says, soon
communicate via email to the MetriCon 4.0 program committee.
As with all MetriCon events, MetriCon 4.0 is by invitation
with both invitations for attendance-only and for attendance
with presentation possible. Please be in touch. The theme of
this episode is The Importance of Context.  This workshop
series is intense, and is focused on progress rather than
claims of first discovery.  See
Dan Geer

@_date: 2009-11-10 20:11:50
@_author: dan@geer.org 
@_subject: TLS break  
This is the first attack against TLS that I consider to be
 the real deal. To really fix it is going to require a change to
 all affected clients and servers. Fortunately, Eric Rescorla
 has a protocol extension that appears to do the job.

@_date: 2009-11-11 10:53:44
@_author: dan@geer.org 
@_subject: Crypto dongles to secure online transactions  
Imagine a couple of hundred million devices with updatable
 firmware on them, and one or more rogue updates in the wild.
So should or should not an embedded system have a remote
management interface?  If it does not, then a late discovered
flaw cannot be fixed without visiting all the embedded systems
which is likely to be infeasible both because some will be where
you cannot again go and there will be too many of them anyway.
If it does have a remote management interface, the opponent of
skill focuses on that and, once a break is achieved, will use
those self-same management functions to ensure that not only
does he retain control over the long interval but, as well, you
will be unlikely to know that he is there.
This leads to a proposal on what to do about the future:
Embedded systems, if having no remote management interface and
thus out of reach, are a life form and as the purpose of life is
to end, an embedded system without a remote management interface
must be so designed as to be certain to die no later than some
fixed time.  Conversely, an embedded system with a remote
management interface must be sufficiently self-protecting that
it is capable of refusing a command.
Long live HAL,

@_date: 2009-10-01 11:52:21
@_author: dan@geer.org 
@_subject: [Barker, Elaine B.] NIST Publication Announcements  
> It is also completely impossible to prove you've deleted a
 > record. Someone who can read the record can always make a copy
 > of it. Cryptography can't fix the DRM problem.
If, and only if, the document lives solely within an
airtight surveillance system, then it is possible to
prove deletion.  Put differently, only within airtight
surveillance will the absence of evidence be the
evidence of absence.
In factually, if not politically, correct terms, the
Electronic Health Record is the surest path to a
surveillance state, but I digress.

@_date: 2010-04-23 16:36:03
@_author: dan@geer.org 
@_subject: random but not by chance 
Random Numbers -- But Not By Chance
   April 2010
   Researchers have devised a new kind of random number
   generator, for encrypted communications and other uses,
   that is cryptographically secure, inherently private
   and - most importantly - certified random by laws of
   physics.
article cut there as there both a diagram and a video

@_date: 2010-08-11 01:04:06
@_author: dan@geer.org 
@_subject: "Cars hacked through wireless tire sensors"  
Unlike the work earlier this year, these attacks are more of a   nuisance than any real danger; the tire sensors only send a message   every 60-90 seconds, giving attackers little opportunity to compromise   systems or cause any real damage. Nonetheless, both pieces of research   demonstrate that these in-car computers have been designed with   ineffective security measures.
 Of course, in a place where surveillance infrastructure
is already capitalized (think London), adding the ability
to track bluetooth tire sensors would be so easy... and
self-initializing at the toll stations where the license
plates are read and correlation between plate number and
current radio fingerprint trivially recorded.

@_date: 2010-08-17 23:10:34
@_author: dan@geer.org 
@_subject: Haystack  
>  > Based on those statements, I'm going to speculate that the client
 > connects to a static list of innocuous-looking proxies and that they
 > are relying on keeping those proxies secret.
 > Hmm, what is the chance that the static ones redirect to
other proxies (some of which might even be unwitting)?
Probably too out there.

@_date: 2010-08-26 06:38:19
@_author: dan@geer.org 
@_subject: towards https everywhere and strict transport security (was: Has there been a change in US banking regulations recently?)  
>  > as previously mentioned, somewhere back behind everything else ... there
 > is strong financial motivation in the sale of the SSL domain name digital
 > certificates.
 > While I am *not* arguing that point, per se, if having a
better solution would require, or would have required, no
more investment than the accumulated profits in the sale
of SSL domain name certs, we could have solved this by now.

@_date: 2010-07-27 15:14:43
@_author: dan@geer.org 
@_subject: A mighty fortress is our PKI  
> False metrics are rampant in the security industry. We really need
 > to do something about them. I propose that we make fun of them.
You might consider joining us in D.C. on 10 August at
--dan, program committee

@_date: 2010-07-28 00:58:09
@_author: dan@geer.org 
@_subject: A mighty fortress is our PKI  
>  > Wow, I was just going to recommend Dan's book, "Security Metrics."
 > It is actually Andy Jaquith's book, I only wrote the intro.
In the meantime, though, couple of years ago I did a tutorial
on security metrics which you may find useful

@_date: 2010-07-28 22:34:50
@_author: dan@geer.org 
@_subject: A slight modification of my comments on PKI.  
The design goal for any security system is that the number of
failures is small but non-zero, i.e., N>0.  If the number of
failures is zero, there is no way to disambiguate good luck
from spending too much.  Calibration requires differing outcomes.
Regulatory compliance, on the other hand, stipulates N==0 failures
and is thus neither calibratable nor cost effective.  Whether
the cure is worse than the disease is an exercise for the reader.

@_date: 2010-03-25 08:58:33
@_author: dan@geer.org 
@_subject: Law Enforcement Appliance Subverts SSL  
"At a recent wiretapping convention however, security researcher Chris =
 Soghoian discovered that a small company was marketing internet spying =
 boxes to the feds designed to intercept those communications, without =
 breaking the encryption, by using forged security certificates, instead =
 of the real ones that websites use to verify secure connections. To use =
 the appliance, the government would need to acquire a forged certificate =
  from any one of more than 100 trusted Certificate Authorities."
 I rather like Cormac Herley's paper:
    So Long, And No Thanks for the Externalities:
  The Rational Rejection of Security Advice by Users
which I cite here for this line:
  It is hard to blame users for not being interested in SSL
  and certificates when (as far as we can determine) 100% of
  all certificate errors seen by users are false positives.

@_date: 2013-12-03 22:27:38
@_author: dan@geer.org 
@_subject: [Cryptography] useful data on PFS 
I just stumbled across Netcraft's bulletin from June, which I don't think has been previously mentioned here

@_date: 2013-12-10 19:11:37
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] Which encryption chips are 
>     * (TS//SI//REL TO USA, FVEY) Complete enabling for [XXXXXX]  > encryption chips used in Virtual Private Network and Web encryption  > devices. [CCP_00009].
For this to be an explicit line item in that document, it
has to be special.  The two classes of "special" that occur
to me are (1) XXXXXX has a near monopoly (like Broadcom
does in its sector) or (2) XXXXXX is uniquely vulnerable to
blackmail (a merchant with an export control problem, say).
But in related news:
Engineers abandon encryption chips after Snowden leaks

@_date: 2013-12-19 20:35:36
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] NIST Randomness Beacon 
After all that discussion of the randomness beacon, it belatedly
occurs to me to ask if anyone has ever applied, even for fun, any
of the various tests for randomness to the transmissions from the
various shortwave "numbers stations."

@_date: 2013-12-23 09:01:46
@_author: dan@geer.org 
@_subject: [Cryptography] [IP] 'We cannot trust' Intel and Via's 
Bill Cox writes, in part:
 Anyway, it's a nice thought that RISC CPUs might provide more trust
 due to their simplicity, but given the complexity of modern RISC
 architectures like ARM, forget it.  There's no modern CPU of any
 reasonable performance that isn't too complicated to easily audit.
 There's a lot of room for back doors that no one would ever find,
 RISC or CISC, IMO.
No doubt true.  No doubt.
There must be a {rule of thumb, nomogram, proportionality constant}
relating the build-up of complexity and the build-up of occult risk,
mustn't there?  Machines beat human chess (and other game) players
not by being smarter but by grinding a solution out.  One wonders
if AI doesn't eventually have the power to find back doors that no
human could ever find.  Then what?

@_date: 2013-12-23 13:34:41
@_author: dan@geer.org 
@_subject: [Cryptography] RSA is dead. 
> What the recent revelations really show is that the NSA is abjectly
 > incompetent at its real job which is making America safe. They have
 > failed to protect the confidentiality of US government secrets.
 > They were pwned by a 29 year old contractor.
It is said that the most important legacy for an executive
is what did not happen on their watch.  In a complexifying
world, the list of things that did not happen (the numerator)
becomes as inestimable as the list of things that could
have happened (the denominator), thus reducing  conversations
on a given legacy to the listing of anecdotes.
In the meantime, what do you think of the Russians going
back to typewriters?  To be crisp, on a scale from paranoid
fantasy (0) to unshakeable genius (100), where would you
place the mark?

@_date: 2013-07-09 22:20:06
@_author: dan@geer.org 
@_subject: [Cryptography] dead man switch [was: Re: Snowden "fabricated 
============================== START ==============================
for a novel treatment of a dead man switch, read _Daemon_ by Leinad Zeruas
botnet that uses MainStreamMedia news feeds as a covert channel
insofar as the MSM cannot help themselves but to publicize nasty
events that the botnet is itself capable of causing, thus allowing
the botnet to know collectively what each part of it is doing and
that without a C&C channel other than the repurposed MSM; the fun
begins when the botnet reads the obituary of a certain person

@_date: 2013-11-13 15:41:21
@_author: dan@geer.org 
@_subject: [Cryptography] randomness +- entropy 
Taking a single paragraph of a single note out of context,
This is not an altogether new problem in the sense that what to do
about boot-time versus security for the always-in-demand production
environment goes at least as far back (in my humble experience) as
the stash file for the key distribution center under Kerberos.
web.mit.edu/kerberos/krb5-devel/doc/basic/stash_file_def.html [*]
In other words, make and document a decision about which cost you'd
rather bear and get on with it.
[*] The stash file is a local copy of the master key that resides
in encrypted form on the KDC's local disk. The stash file is used
to authenticate the KDC to itself automatically before starting the
kadmind and krb5kdc daemons (e.g., as part of the machine's boot
sequence). The stash file, like the keytab file, is a potential
point-of-entry for a break-in and, if compromised, would allow
unrestricted access to the Kerberos database. If you choose to
install a stash file, it should be readable only by root, and should
exist only on the KDC's local disk. The file should not be part of
any backup of the machine, unless access to the backup data is
secured as tightly as access to the master password itself.
If you choose not to install a stash file, the KDC will prompt you
for the master key each time it starts up. This means that the KDC
will not be able to start automatically, such as after a system

@_date: 2013-11-19 20:02:41
@_author: dan@geer.org 
@_subject: [Cryptography] HTTP should be deprecated. 
Though seeing what addresses you look at can tell them a lot of
 that, even if they can't read the content.
 quoting my own sorry ass and all the lameness that implies,
    We have known for some time that traffic analysis is more
    powerful than content analysis.  If I know everything about to
    whom you communicate including when, where, with what inter-message
    latency and at what length, then I know you.  If all I have is
    the undated, unaddressed text of your messages, then I am an
    archaeologist, not a case officer.  The soothing mendacity of
    proxies for the President saying "It's only metadata" relies
    on the ignorance of the listener.

@_date: 2013-11-19 22:09:46
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] NIST Randomness Beacon 
1| >In fact, a team at (I think) Bell Labs came up with a "digital 1| >notary" service that did exactly this, in an efficient way.
2| I thought it was at BellCore by then?  Stu Haber, IIRC.

@_date: 2013-11-21 21:51:26
@_author: dan@geer.org 
@_subject: [Cryptography] Cryptolocker 
I can say that this did hit an accounting firm that I know well.
The encryption of all of their files ten days before the 10/15
tax deadline was nearly fatal and, yes, it nailed the backups.
I believe the toehold was a poisoned PDF from a client.

@_date: 2013-11-26 19:47:06
@_author: dan@geer.org 
@_subject: [Cryptography] Explaining PK to grandma 
> > Yes, "signature" is an unfortunate term. "Seal" would have been better.
 > ...
 > I like seal.
The term of art in postal mail is "sealed against inspection"
and it matters rather a lot.  In the U.S., the Postal Service
has its own police force -- not even the Treasury can still
say that.

@_date: 2013-11-30 22:14:13
@_author: dan@geer.org 
@_subject: [Cryptography] Explaining PK to grandma 
============================== START ==============================
 > The NSA can't compromise every endpoint without being noticed.
  For defending against NSA, we don't really have to prevent active  attacks.  We merely have to make it reasonably feasible for the  seriously sophisticated paranoid to have a chance of detecting active  attacks.
  If very powerful adversary gets observed observing, it loses, since the  information is valuable to its adversaries.
  The guy in Nigeria, on the other hand, will have no hesitation in  committing active attacks and will not much worry even if a very large  proportion of them get detected.
Absolutely correct.

@_date: 2013-10-01 08:56:11
@_author: dan@geer.org 
@_subject: [Cryptography] NIST about to weaken SHA3? 
excerpting, we have
 >  > Weaker in ways that the NSA has examined, and the people that chose
 > the winning design have not.
 Viktor Dukhovni replies:
 >  > Just because they're after you, doesn't mean they're controlling
 > your brain with radio waves.  Don't let FUD cloud your judgement.
As "we" (here) are fond of saying, anything can be broken,
therefore the question at hand is "Who can break what at
this strength?"  This question does not have a time-invariant
answer, and, in any case, as Adi Shamir so adequately said,
"Cryptography is typically bypassed, not penetrated."[*]
Nevertheless, the value of scepticism is profound; it is
the chastity of the intellect.

@_date: 2013-10-03 11:59:54
@_author: dan@geer.org 
@_subject: [Cryptography] encoding formats should not be committee'ized 
> For those not familiar with TL1, "supposed to be readable" here means
 > "encoded in ASCII rather than binary".  It's about as readable as
 > EDIFACT and HL7.
The (U.S.) medical records system that started at the Veterans'
Administration and has now spread to all but all parts of the
U.S. Federal government that handle electronic health records is
ASCII encoded, and readable.  Called "The Blue Button,"[1] there
is even an HL7->Blue Button file converter.[2]
Score one for human readable.
[1] [2]

@_date: 2013-09-30 12:28:37
@_author: dan@geer.org 
@_subject: [Cryptography] TLS2 
>
 > Why not do the requirements, then ask for competing proposals?
 > Choose 1.  It worked for NIST and committees didn't work for anyone.
If there is anything I've learned about "the Internet" it is that
if you ask a difficult question you will get very little in the
way of answers you can trust a priori.  However, if you make a false
claim, then people will come out of the woodwork to tell you that
"You are a doofus and here is why."  Ergo, the way to ask a question
is to make a false claim the summed corrections to which contain the
answer to the question you wanted to ask.
We now return you to your program already in progress,

@_date: 2014-04-16 19:44:33
@_author: dan@geer.org 
@_subject: [Cryptography] I don't get it. 
As for probable causes:
 - underfunding;
 - ever-changing requirements, as the users will imagine new
 possibilities as the project matures;
 - managers/customers thinking that software *development* is a sort of
 conveyorbelt, just replace a programmer with the next and the work will
 continue;
You know, yours is a point worth repeating; it affects software
projects as it affects armies: mission creep.
Would it be worthwhile to banter about various analogies here?
Clinical trials of new pharmaceuticals where efficacy and safety
get conjoined evaluation?  Jet engines where an "airworthiness"
certificate is not for the engine but for what we here would call
the build environment?  Probably been done so point me at something
to read, but a gauntlet that precludes mission creep might be a
useful construct.  I've certainly been involved in failed software
projects involving mission creep (especially when a weak-willed
and/or maniacal CEO listens to salesmen who say "If we only had X,
then I'd be able to double my quota!").
On the other hand, we're headed into a rat-hole...

@_date: 2014-04-16 23:05:59
@_author: dan@geer.org 
@_subject: [Cryptography] Heartbleed and fundamental crypto programming 
W.r.t. programmatic code analysis, false positives, and so forth
Heartbleed and Static Analysis
A New Development for Coverity and Heartbleed
both due to John Regehr, Univ of Utah

@_date: 2014-04-30 08:27:31
@_author: dan@geer.org 
@_subject: [Cryptography] New slogan for the NSA 
> "We're the NSA.  We hear you."
  RSA put out a poster with that on it 20 years ago.
  :-)
Bob, do you have a copy of "If you want to reach us, call your Mother" ?

@_date: 2014-08-12 22:23:35
@_author: dan@geer.org 
@_subject: [Cryptography] A post-spy world 
John Young
 "We are moving toward a post-spy world, according to the guy that  runs the CIA's venture capital arm."
FWIW, I don't run In-Q-Tel, In-Q-Tel isn't a venture firm, and I
don't recall saying "post-spy" at all.  Full text of the speech is
at geer.tinho.net/geer.blackhat.6viii14.txt, see for yourselves.
In the meantime, tell me if PPD-28 would be satisfied were an
artificial semi-intelligence doing the searches rather than humans.
What if surveillance data was mined not by people who could go to
jail but by self-modifying programs that co-evolve with the subject
of the surveillance.  Tell me that "the more complex the decision
the more surely it will be left to humans" is a long-term guiding
ethic.  Opine on whether "algorithmic regulation" aimed at a single
individual needs be visible to that individual if due process is
to be preserved.  Perhaps also read "We Are All Intelligence Agents
Now", the final technical talk at last February's RSA Conference;
see geer.tinho.net/geer.rsa.28ii14.txt .
Still got no Clearance...

@_date: 2014-08-26 07:03:00
@_author: dan@geer.org 
@_subject: [Cryptography] Encryption opinion 
I think the most effective class of phishing attacks right now in  fact can easily be beaten.    This is the message that purports to be from someone with whom you  have a pre-existing security relationship: your bank, your ISP,  a business from which you buy things online, or your email provider,  or whatever.  As a side note, the state of Massachusetts has just moved to toll
roads without toll takers, using license plate cameras instead to
send you a bill for a few dollars.  I've not been on any of those
roads, but I've gotten three e-mailed bills in the last two weeks
that to the unskeptical eye look fully legitimate, which also
indicates that the phishers know that my geolocation makes driving
such roads plausible.
You may not buy from Company XYZ, but everybody is a client of their
respective government...

@_date: 2014-08-27 21:13:37
@_author: dan@geer.org 
@_subject: [Cryptography] toll bills, was Encryption opinion 
So, Jerry, you are saying that EZ-Pass is two factor auth but where
the two factors are one from column A and one from column B.

@_date: 2014-08-29 22:02:02
@_author: dan@geer.org 
@_subject: [Cryptography] digital currency is currency - Ecuador 
[possibly OT except for the question "What is a digital currency?"]
ECUADOR HERALDS DIGITAL CURRENCY PLANS
BY GONZALO SOLANO ASSOCIATED PRESS
QUITO, Ecuador (AP) -- Ecuador is planning to create what it calls
the world's first digital currency issued by a central bank, which
some analysts believe could be a first step toward abandoning the
country's existing currency, the U.S. dollar.
The electronic money, which Central Bank officials say they expect
will start circulating in December, does not have a name and officials
would not disclose technical details, though they said it would not
be a crypto-currency like Bitcoin. The amount of the new currency
created would depend on demand.
Deputy director Gustavo Solorzano said it is to exist in tandem
with the greenback and, by law, be backed by `'liquid assets." It
would be geared toward the 2.8 million Ecuadoreans - 40 percent of
participants in the economy - too poor to afford traditional banking,
officials say.
Initially, it will be able to make and receive payments on cellphones,
Solorzano said. Such mobile payments schemes are especially popular
in African nations including Kenya and Tanzania, where they are
privately run.
The new currency was approved, and stateless crypto-currencies such
as Bitcoin simultaneously banned, by Ecuador's National Assembly
last month.
Leftist President Rafael Correa has said the project's only problem
is that it has taken this long, defending it against `'pseudo-analysts
who have appeared in the media trying to smear (it)." He denies any
plan to replace the U.S. dollar, which Ecuador set as its currency
in 2000 after a crippling banking crisis.
The official in charge of the new currency, Fausto Valencia, said
the software is already used in Paraguay by cellphone companies.
He said it is not like Bitcoin, whose advantage is in its technical
underpinnings: Only a limited amount of Bitcoin can be minted.
Without that safeguard, economists have warned, a government could
theoretically create as much as it wants, risking inflation.
Nathalie Reinelt, an emerging payments analyst with the U.S.-based
Aite Group, said she does not understand any other motivation for
creating such a currency than to allow Ecuador to increase its money
supply and, essentially, devalue its U.S. dollar holdings.
`'It is far too early to know how they are thinking of making the
electronic money work," said analyst Juan Lorenzo Maldonado of
Credit Suisse LLC.
Some believe it could be a first step to abandoning the U.S. dollar,
Ecuador's currency since January 2000. Correa denies it puts
dollarization in peril.
His government has tripled social spending, and opposition lawmaker
Ramiro Aguilar says it `'has a serious fiscal liquidity problem.
It needs money ... It doesn't mint money. It has no control over
what circulates."
The state is currently $11 billion in debt, mostly to China, which
buys most of Ecuador's oil. It recently sold $2 billion in bonds
with a 7.95 percent return, as well as obtaining another $400 million
from Goldman Sachs in exchange for part of its gold reserves.
Use of the currency will be voluntary and it will not be used to
pay public employees or state contractors, according to the law.
Nor can it be used to buy financial instruments the Finance Ministry
Some question whether Ecuador's Central Bank is constitutionally
empowered to create such a currency.
`'Let's remember that the Central Bank has no autonomy, and this
could lend itself to all manner of political maneuvers," said
independent political analyst Jaime Carrera.

@_date: 2014-12-09 14:55:35
@_author: dan@geer.org 
@_subject: [Cryptography] North Korea and Sony 
"Banks Dreading Computer Hacks Call for Cyber War Council"
Bloomberg, July 8, 2014
  Wall Street's biggest trade group has proposed a government-industry
  cyber war council to stave off terrorist attacks that could trigger
  financial panic by temporarily wiping out account balances,
  according to an internal document.
  The proposal by the Securities Industry and Financial Markets
  Association calls for a committee of executives and deputy-level
  representatives from at least eight U.S. agencies including the
  Treasury Department, the National Security Agency and the Department
  of Homeland Security, all led by a senior White House official.
  The document sketches an unusually frank and pessimistic view by
  the industry of its readiness for attacks wielded by nation-states
  or terrorist groups that aim to "destroy data and machines."  It
  says the concerns are "compounded by the dependence of financial
  institutions on the electric grid," which is also vulnerable to
  physical and cyber attack.

@_date: 2014-12-10 21:19:18
@_author: dan@geer.org 
@_subject: [Cryptography] North Korea and Sony 
>"Banks Dreading Computer Hacks Call for Cyber War Council" Bloomberg,
 July 8, 2014
 >
 >
 for-cyber-war-council.html
 >
 >  It says the concerns are "compounded by the dependence of financial
 >  institutions on the electric grid," which is also vulnerable to
 >  physical and cyber attack.
  More of Michael Hayden's fear-mongering about the electric grid.
  Well, the discussion we were having was about nation-state actors,
so I'm tempted to interpret the material you provided -- with which
I am *not* arguing -- as a clear and present indicator that state
level actors seeking to damage the U.S. should act sooner rather
than later as, per your materials, the sooner they act the more
vital the electric grid is at the time they take action since said
grid will not be as vital tomorrow as it is today, etc.
Kelly Ziegler from NERC gave a 2010 USENIX talk (*) which is relevant
to this topic (even if this topic is irrelevant to a crypto list).
In the Q&A after the talk, she noted that due to the large firmware
sizes in SmartGrid meters compared to the low achievable bandwidth
for IP-over-powerline, re-flashing a fully US-deployed SmartGrid
metering infrastructure would iequire approximately one calender
year elapsed.  One might then advise the nation state actor that
unless the future includes no metering at all, it will matter little
whether generation plants go the way of the dodo and, in turn, an
investment in attack tools aimed at the distribution system, however
residual centralized generation may become, will have value.
(*) Ziegler K, "The Future of Keeping the Lights On,"

@_date: 2014-12-11 10:04:12
@_author: dan@geer.org 
@_subject: [Cryptography] North Korea and Sony 
> "Banks Dreading Computer Hacks Call for Cyber War Council"
 > Bloomberg, July 8, 2014
 >
 Are these people that clueless (which makes me even more worried about the
 vulnerability of our financial systems), or are they trying to accomplish
 something else?
I do not believe that a private company can sustainably deny
penetration by a commited state-level actor.  That then begs the
question of whether any particular sector or particular company
sees itself as a target of state-level actors.  It does not strike
me as nutty for any one of the world's twenty largest banks, taking
the current example, to think that it is now or could soon be a
target for state-level aggression.  As such, for a bank to request
state-level protections is not nutty, even if such protections are
likely to come with significant strings attached.
Or am I missing your point/question?

@_date: 2014-12-11 10:22:12
@_author: dan@geer.org 
@_subject: [Cryptography] North Korea and Sony 
Jerry, you and I are in violent agreement that there is enormous
fragility in the buildout of systems as presently deployed.
So many things come to mind, the most pithy being Mike O'Dell's
comment that "Left to themselves, creative engineers will deliver
the most complicated system they think they can debug."  The financial
services industry has proven Mike's contention at scale, viz., that
we humans can (will), in general, build systems too complex to then
operate.  Let us hope that mandated electronic health records plus
15K hospitals plus three dozen Federal agencies plus all the world's
reinsurers will not re-prove that same contention.
But as to Geithner and stress tests, my last column(*) was precisely
on that point and I did, indeed, steal directly from the financial
market experience in proposing a prescription for national-scale
"digital life."
Stress Analysis

@_date: 2014-12-13 15:07:51
@_author: dan@geer.org 
@_subject: [Cryptography] When did zero day attacks become commonplace? 
Back in the mid 1990s, the idea an attacker would hit you with a 'zero-day'
 was considered a mythical possibility. Anyone who suggested it might happen
 was scaremongering. Then within the space of a few weeks they went from
 being unheard of to routine.
  I am trying to track down when the transition occurred for a talk. I
 remember there being a sharp transition but I can't place when.
My memory says that it was 2006 plu/minus two, but I am not remembering
an event so much as an observation that once crafting exploits got
too hard to be a hobby it became a profession.  The hobbyist, paid
in bragging rights, brags thus broadcasting his knowledge.  The
professional, paid in currency and perhaps by N>1 buyers, says
nothing, thus not broadcasting his knowledge.  Surely the percentage
of attacks that are based on previously unknown avenues of attack
must rise when motivations undergo a sea change like making exploit
crafting too hard to be a hobby and/or paying for R&D out of revenue.
I'm sure someone has numbers or a way look at various records
(someone working in attack remediation, say?) and detect when it
was that the ratio of major attacks due to pedestrian vulnerabilities
to major attacks due to previously unknown ones began to change.
If there was a discontinuity, a ratio like the above would tend
to make it visible.
Thinking out loud,

@_date: 2014-12-19 13:05:38
@_author: dan@geer.org 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
> Microsoft has since around 2000 been giving the source code to
 > various large corporations and governments.  It was at least in
 > the news that they gave it to China and the FSB (ex-KGB).
I've always thought of that play as globally self-enforcing
"No warranty, express or implied."
Brilliant finesse, actually.

@_date: 2014-12-19 22:59:24
@_author: dan@geer.org 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
I think it would be very hard to find a backdoor suggested by  Norm Hardy. Modify the CPU to detect when two specific floating  point numbers are multiplied. When they are, execute the next  instruction in privileged mode.
It's my second-hand understanding that it would take perhaps 3,000
gates to implement intentional sensitivity to a pre-designed kill
packet.  The addition of 3,000 gates to any current chipset will
never be found in current hardware, e.g., the iPhone 6 has two
billion transistors on the system chip.
Others more knowledgeable welcome to correct my understanding.

@_date: 2014-12-20 21:56:31
@_author: dan@geer.org 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
>From: dan at geer.org
 >
 > | I think it would be very hard to find a backdoor suggested by  > | Norm Hardy.  Modify the CPU to detect when two specific floating  > | point numbers are multiplied.  When they are, execute the next  > | instruction in privileged mode.
 >
 >It's my second-hand understanding that it would take perhaps 3,000
 >gates to implement intentional sensitivity to a pre-designed kill
 >packet.  The addition of 3,000 gates to any current chipset will
 >never be found in current hardware, e.g., the iPhone 6 has two
 >billion transistors on the system chip.
 >
 >Others more knowledgeable welcome to correct my understanding.
  So Intel&Apple have provided PRC with netlists for their processor
 chips?
  Of course, PRC shouldn't believe them, unless they could also
 manufacture their own chips from the netlists.
You missed the point well enough that it must have been on purpose.
Nevertheless, to reword in the interest of clarity, hiding something in
hardware is, AND ALWAYS WILL BE, impossible to detect or disprove.

@_date: 2014-12-21 22:30:39
@_author: dan@geer.org 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
> Then, sample the chips, open them up, and test whether the tracks /  > layout are the same as each other?
multi-layered at 20nm line widths and 3 billion gates per chip
have a nice day

@_date: 2014-12-28 08:46:45
@_author: dan@geer.org 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
> Of course, we can't know if lower-abstraction-level exploits are
 > being mounted today - but are so well hidden that we never detect
 > them.  But the exist ence of state-of-the-art attack mechanisms
 > like Stuxnet and Darkhotel - none of which go deeper than the OS
 > - argues that if lower-level attacks are being mounted, they are
 > being mounted by the most sophisticated parties in extremely unusual
 > and specialized circumstances.
So, what should one assume w.r.t. infrastructure, e.g., should some
level of the military-industrial complex plan as if all the biggest
Cisco backbone routers contain an intentionally placed sensitivity
to a kill packet?  What would such a plan involve if not alternatives
to the Internet?
One might as well ask why we bother tracking incoming asteroids...

@_date: 2014-12-30 23:17:43
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] NSA Attacks on VPN, SSL, TLS, SSH, 
> you know what nietzsche said about the skeptics - stranglers of life force
Scepticism is the chastity of the intellect; it is shameful to give
it up too soon, or to the first comer.
                        -- George Santayana
And now that we have reached the dueling quotes stage,
it is time to move on to something productive.

@_date: 2014-02-09 23:20:37
@_author: dan@geer.org 
@_subject: [Cryptography] cheap sources of entropy 
All of this discussion about proofs, how certification is done,
the degree to which by the time something is studied to death
an assumption will have changed, etc. -- the lot of it reminds
me of nothing so much as Goodhart's Law:
   Once a social or economic indicator or other surrogate measure
   is made a target for the purpose of conducting social or economic
   policy, then it will lose the information content that would
   qualify it to play such a role.

@_date: 2014-01-08 20:25:20
@_author: dan@geer.org 
@_subject: [Cryptography] What is a secure conversation? (Was: online 
various writers variously write:
 > code, code, who's got the nuclear code? yadda yadda yadda
Steve Bellovin: Nuclear Weapons, Permissive Action Links, and the
History of Public Key Cryptography, USENIX, 2006.

@_date: 2014-01-11 10:08:28
@_author: dan@geer.org 
@_subject: [Cryptography] Dumb idea: open-source hardware USB key for 
>                         And just who is going to bring
 > the aforesaid open model upon this class of gear? So it's
 > +1 for spooks.
Yes and no.  Across the security parts of that government with
which I am familiar, the issues of which you are speaking are
deeply troubling -- they buy computers, too.  There is, indeed,
the strong mandate to use commercial off the self (COTS) goods
rather than government-only goods which, on balance, is a Very
Good Thing as perversion of the supply chain is thereby a common
enemy.  That all significant private firms are transnational is
likewise a Very Good Thing (at least in this context).  Naturally,
I have no access to whether the precise discussion taking place
in English here on these two lists is simultaneously taking place
in and around Beijing, Brussels, London, Moscow, and Tokyo, but
I would be surprised if it is not.
Put differently, all airlines share a joint interest in air safety
and none advertise that "our planes fall out of the sky less often
than theirs."  Because airplane crashes are not concealable, they
are studied and thus learned from.  Perhaps the policy you might
want to consider is mandated disclosure of computer failures
whether from attacks or from clumsiness.  Public health trumps
medical privacy should you turn up at hospital with smallpox or
the plague.  Peter Neumann's long-running RISKS digest is a small
mockup of what might well be a global need.  As with airlines and
the (US) National Transportation Safety Board, learning from events
is about all you can do once collective complexity is above that
level where further refinements of design are, at best, episodic.

@_date: 2014-01-13 19:41:08
@_author: dan@geer.org 
@_subject: [Cryptography] What is an attack, and what is not an attack? 
With your indulgence, can I speak to just this:
I'm already on the record here, both in essay form:
  A Doubt of the Benefit
  and in tutorial form (begin on page 233):
  Measuring Security
  The one sentence precis: If you are the CSO, then argue your CIO
into endorsing some semi-consensual estimate (e.g., Gartner's) of
what fraction of the total IT budget should go to security and then
spend all of it based on cost-effectiveness analysis, *not*
Keeping it brief,

@_date: 2014-01-14 22:00:07
@_author: dan@geer.org 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
Ranking Fortune 100 firms by the numbers of vulnerabilities they
have distributed times the numbers of people they have distributed
them to, RSA is an also ran.  Ranking Fortune 100 firms by the
numbers of known monetary losses attributable to their vulnerabilities,
whether direct (theft) or indirect (overtime for sysadmins), RSA
is an also ran.  Ranking Fortune 100 firms by the numbers of enemies
they have slept with, RSA is in the middle of the pack but way, way
out of contention for the laurel wreath.  Ranking Fortune 100 firms
by the attractiveness of penetrating them, RSA is top tier but
ancillary, like a sexy supporting actress -- the main objects of
desire are governments and their respective defense industrial
bases.  Ranking Fortune 100 firms by the number of times they have
made bad bets, RSA doesn't have enough money to make the kind of
bets that could wreck anybody's civil economy.  Ranking worldwide
firms by the fraction of their business that involves crimes against
nature done while sucking on their respective government's tit, RSA
doesn't come remotely close to making the A-list.
I'm not their friend, but this is a side show.

@_date: 2014-01-16 00:04:36
@_author: dan@geer.org 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
> > I'm not their friend, but this is a side show.
 >  > But, it is our side show.
Yes, and perhaps the core of the argument.
This is an open mailing list with an untold number of subscribers
so, frankly, that is the end of the discussion except to state the
central truth: If you do not want to be at risk from something,
then DO NOT DEPEND ON IT.  Would that I could share how I am in
fact living up to that maxim.

@_date: 2014-01-18 10:12:05
@_author: dan@geer.org 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
If any of ya'll attend the Cryptographers' Panel at RSA, please to
file a trip report here.

@_date: 2014-01-29 23:11:55
@_author: dan@geer.org 
@_subject: [Cryptography] cheap sources of entropy 
It was said that:
Recalibrating first principles for a moment, please.  My understanding
is that a mix of N bit streams will be truly unpredictable if any 1 of
the N bit streams is truly unpredictable.
If that is incorrect, what am I missing?  (RTFM is entirely acceptable
and even gracious if accompanied by a pointer to TFM to R.)

@_date: 2014-07-16 18:41:17
@_author: dan@geer.org 
@_subject: [Cryptography] What has Bitcoin achieved? 
A bit tangential, but see last paragraphs in this CNBC item:
Google has the potential to hit a trillion-dollar market cap in the
next 10 years, according to one technology investing leader.
Jim Breyer, founder and CEO at Breyer Capital and a partner in Accel
Partners, expects the search engine giant to join Facebook in
gobbling up smaller companies and continuing to grow rapidly.
"The environment we're in now is probably the most interesting
seismic change relative to the new companies that will be Internet
leaders," Breyer said Wednesday at the Delivering Alpha conference
presented by CNBC and Institutional Investor. "The froth in some
of the venture capital consumer Internet companies without business
models -- if they're not being bought by Google or Facebook, they're
going out of business."
The rise of the first trillion-dollar companies was one of a handful
of big ideas entertained during a tech-focused panel that also
featured Shana Fisher of High Line Venture Partners. Fisher was an
early partner in video-sharing site Vine.
She said companies that can make it easier to make videos will do
"The technology limitations just dealing with getting something
from your phone to the server is still a difficult hurdle," Fisher
said. "The sky's the limit for video."
Breyer also predicted big things for digital currencies.
He said the leader in the field may not end up being bitcoin, which
is the most prominent name now but has faced price volatility, theft
and scandal over the past year. Other providers will emerge.
"I have zero doubt in the next five to seven years that we will see
at least half a dozen multibillion dollar digital currency companies,"
he said.

@_date: 2014-06-04 21:15:21
@_author: dan@geer.org 
@_subject: [Cryptography] It's GnuTLS's turn: "Critical new bug in crypto 
> "A recently discovered bug in the GnuTLS cryptographic code library puts
 > users of Linux and hundreds of other open source packages at risk of
 > surreptitious malware attacks until they incorporate a fix developers
 > quietly pushed out late last week."
 >
 >
 This has large implications for  embedded software....
 Appliances are notoriously long lived and not profitable to maintain.
 I have numerous wifi routers that can only be used in islolation.
 I have a growing pile of phones and tablet hardware that are no
 longer getting updates from the vendor....  In some cases AT&T
 blocks Samsung from updating Samsung designed hardware.
  They are locked or closed source and closed hardware so I cannot ---.
Agreed, and on the record:
   Security of Things (speech)
      On Abandonment, IEEE S&P, July/August 2013
   The current situation is flatly untenable.

@_date: 2014-06-05 22:53:59
@_author: dan@geer.org 
@_subject: [Cryptography] To what is Anderson referring here? 
Q: Has anyone ever made money from crypto?
A: Silvio Micali

@_date: 2014-06-07 22:36:12
@_author: dan@geer.org 
@_subject: [Cryptography] DOJ Wants to Expand Authority to Break Into 
<5B4B5A92-263F-4CC7-BC1B-9444F52C8B4D
You have hit on it.  Either an ISP is a government monopoly
or it is a private component of the critical infrastructure.
In the former case, the government owns the means.  In the
latter case, the government 0wns the means.  Have you a
preference for O v 0?

@_date: 2014-06-09 23:27:27
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] Help investigate cell phone 
The order of optimality:
1. no cell phone no how
2. cell phone with battery removed
3. disinformation feed
4. faraday cage for otherwise operational phone
Film at 11,

@_date: 2014-06-10 11:36:25
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] Help investigate cell phone 
[lots of cross posting, as per original]
Stipulating that I'm not in any conceivable sense the last word on
this topic, you might find some of this
  Tradeoffs in Cyber Security
  Dan Geer, 9 October 13, UNCC
  relevant.  If short on reading time, scan down to "Marcia Hofmann."

@_date: 2014-03-05 13:29:47
@_author: dan@geer.org 
@_subject: [Cryptography] OMB Circular A-119 
This is all quotation from a newsletter on consortia generally.
I've no time today and since the fuse is short, I am just forwarding
it here and now.  De-html-ized using /usr/local/bin/lynx.
   Recently, the U.S. Office of Management and Budget (OMB) proposed
   changes to the rules that govern not only participation by agency
   personnel in standards development, but also all procurement by
   government agencies as well. These changes are far-ranging, and some
   could have a significant negative impact on consortium-developed
   standards unless the proposed changes are modified.  Public comments
   will be accepted through May 14.
   The American National Standards Institute (ANSI), coordinator of the
   U.S. standardization system, will be holding a Webinar on March 6 that
   will ouline the proposed amendments. The Webinar is free, but space is
   limited and advance registration is required, and I am forwarding that
   invitation to you below.
   Further engagement and information on these issues are available to
   ANSI members, and I will be circulating additional information, as well
   as proposed comments, to interested organizations (and OMB) as well.
   Please contact me if you would like to participate in those comments.
   Here is the Webinar invitation:
   Dear colleagues,
   On March 6, ANSI will host a webinar about the proposed revisions to
   Office of Management and Budget (OMB) [1]Circular A-119, "Federal
   Participation in the Development and Use of Voluntary Consensus
   Standards and in Conformity Assessment Activities."
   Thursday, March 6, 2014
   2 to 3:45 pm Eastern
   [2]Register here
   The webinar will focus on a number of topics, including voluntary
   consensus standards and voluntary non-consensus standards, SDO process
   issues, IPR and incorporation by reference, conformity assessment, and
   agency-related issues. Several guest facilitators from the
   standardization community - both public and private sectors - will join
   us for the dialogue.
   Due to the anticipated level of interest in this webinar, please
   register in advance. Participation will be listen-only, but there will
   be an opportunity to pose questions to the facilitators via chat.
   By way of background, earlier this month, OMB posted a Federal Register
   [3]notice inviting public comment on the revised circular. ANSI will
   develop a consensus response on behalf of the standardization
   community, and we are asking stakeholders to submit any input on the
   revision to [4]eneiman at ansi.org by Friday, March 21. We also encourage
   individual companies and organizations to submit their own comments in
   direct response to the notice. Please note that final responses must be
   submitted to the Federal Register by May 12, 2014.
   If you have any questions or concerns about this issue, please feel
   free to reach out to me at any time.
   Thank you very much for your attention.
   Best regards,
   Liz Neiman
     __________________________________________________________________
   1.    2.    3.    4. mailto:eneiman at ansi.org

@_date: 2014-03-06 19:41:56
@_author: dan@geer.org 
@_subject: [Cryptography] Bounties 
So, Jim (et al.), you say "thief" w.r.t. Bitcoin.
What odds do you give that the theft was a state-level op to
derail the Bitcoin economy, i.e., that making money was not the
object, rather, let's imagine, that this op hedges the vulnerability
of fiat currency to disintermediation.

@_date: 2014-03-07 17:03:29
@_author: dan@geer.org 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
> It really is all about the errors.  And the answer to this is style ---
 > establishing a set of practices that best works with the language you
 > are stuck with, and best allows the flow of errors.
slight detour: I remember once reading that good code
had, in round numbers, 40% of its volume in error
handling.  Can't remember where I read it, but I asked
one of the big static analysis firms if they had any
data.  They didn't, but thought that going forward
they could.  It would be an interesting figure to be
sure.  If anyone has data, I'd be pleased to hear about
it and/or hear some measure of spread for that number
across large systems in common use.

@_date: 2014-03-11 11:48:37
@_author: dan@geer.org 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
May I call your attention(s) to the upcoming Language Theoretic
Security Workshop,
   with which several of us here are already involved.

@_date: 2014-03-12 21:56:54
@_author: dan@geer.org 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Back to the conference room and the sales cycle, how many, many times
I've had some prospective customer say something like "10% performance
hit for security? That's a deal breaker!"
My answer: "Well, 10% is 2.5 months' worth of Moore's Law..."
Sometimes it worked.  Sometimes it didn't.

@_date: 2014-03-13 09:19:05
@_author: dan@geer.org 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Peter, Jerry, et al., Good points about how performance either does,
or inevitably will, matter more as time goes on, raw speedups are
not so easy to buy, and implementations are ever more deeply buried
in places you can't get to again.
Let's stipulate that you are entirely correct.  How do we react if
we are to learn the lessons of history, etc.?  Can a lack of
speedups-to-come be itself relied upon enough to factor that into
design decisions yet to be made, such as to put aside any need to
design in resistance to a sped-up future or to demand specialized
chipsets for devices that will have no remote management interface?
I am asking the "You are right, but so what?" question (with respect).

@_date: 2014-03-13 23:46:48
@_author: dan@geer.org 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
>Let's stipulate that you are entirely correct.  How do we react if
 >we are to learn the lessons of history, etc.?  Can a lack of
 >speedups-to-come be itself relied upon enough to factor that into
 >design decisions yet to be made, such as to put aside any need to
 >design in resistance to a sped-up future or to demand specialized
 >chipsets for devices that will have no remote management interface?
  First, we get no relief from the danger of exhaustive search. It=
 is trivial to parallelize.
  If we are interested in security, then we must (a) be willing
 and financially able to throw away the device, (b) be able to
 upgrade it, or (c) be willing to lose security. The cynic in me
 says we will always choose the (c), at least until we have been
 personally burned.
I agree both with the choice set and the cynicism.
If I ran the zoo, I would leave the decision on whether an embedded
system does or does not have a remote management interface to the
entity that deploys them subject to a 2-tuple of choices, to wit:
 * Embedded systems that have a remote management interface must
 be certified by their maker to be designed such that when said
 remote management interface is operated according to spec, the
 maker shall be found negligent, per se, were the management interface
 found to have been be jimmied by an attacker.
 * Embedded systems that have no remote management interface shall
 be so designed as to die without fail no later than some fixed
 time, which time is stated in advance.
This precludes, and I mean by statute, the possibility of an embedded
system being at once blamelessly immortal, unupdatable, and vulnerable.
Thank you for writing.

@_date: 2014-03-14 14:18:40
@_author: dan@geer.org 
@_subject: [Cryptography] embedding security (was ChaCha) 
All -- Sure, there are imperfections and edge conditions around the
requirements I was suggesting (management-interface XOR finite-lifetime)
for embedded devices.  As always, it is tempting to let the best
be the enemy of the good, with which I am sympathetic in emotion
but try always to discipline myself out of such temptations.  In
any case, the triad of {immortal, un-updateable, and vulnerable}
and its cross-product with Really Big Numbers of embedded systems
seems so real and so prevalent that a cold bath is surely preferable
to waiting for a sufficient disaster to make way for easy change.
(Yes, I know, Washington wisdom says to never let a good crisis go
to waste, meaning that absent a crisis the status quo ante is the
rule of the day.  All hail Rahm Emanuel, so to speak.)
In the meantime, this is an interesting paper...
Perimeter-Crossing Buses: a New Attack Surface for Embedded Systems

@_date: 2014-03-16 22:17:24
@_author: dan@geer.org 
@_subject: [Cryptography] We need a new encryption algorithm competition. 
Not sure how we got to this discussion, but to synopsize:
Ergo, we have the classic problem of governance, that there is no
more wonderful governance than that of a benevolent dictator, only
that said wonderfulness is only sustainably wonderful if you can
solve the succession problem.  (The Matrix is not the answer even
if a rising fraction of all code is machine written.)
Perhaps orthogonally,

@_date: 2014-03-17 15:13:52
@_author: dan@geer.org 
@_subject: [Cryptography] We need a new encryption algorithm competition. 
> Ergo, we have the classic problem of governance, that there is no
 > more wonderful governance than that of a benevolent dictator, only
 > that said wonderfulness is only sustainably wonderful if you can
 > solve the succession problem.
  Postel was succeeded by ICANN.  Do we take the average?
 Not the average, but rather the slope.

@_date: 2014-03-17 17:30:16
@_author: dan@geer.org 
@_subject: [Cryptography] Science of Security 
[ The deadline draws nigh --dan ]
The National Security Agency is seeking nominations for the 2013 Annual
Best Scientific Cybersecurity Paper Competition. The competition is for
scientific papers that were published between October 1, 2012, and
December 31, 2013, and that show an outstanding contribution to
cybersecurity science. Deadline for nominations is March 31, 2014.
The competition was created to stimulate research toward the development
of systems that are resilient to cyber attacks. Entries are judged on
scientific merit, the strength and significance of the work reported,
and the degree to which the papers exemplify how to perform and report
scientific research in cybersecurity.
"This competition supports the greater NSA mission to strengthen and
protect cyber space for our nation," said Dr. Michael Wertheimer, NSA
Director of Research. "It offers a great opportunity to share scientific
methods and it was a remarkable success in its first year."
The winning papers from last year are available at the Cyber-Physical
Systems website, This year's nominations will be reviewed by a panel of distinguished
experts including:
Dr. Dan Geer, In-Q-Tel
Dr. John McLean, Naval Research Laboratory
Dr. Whitfield Diffie, Cybersecurity Advisor
Professor Angela Sasse, University College London
Professor Fred Schneider, Cornell University
Mr. Phillip Venables, Goldman Sachs
Professor David Wagner, University of California at Berkeley
Dr. Jeannette Wing, Microsoft Research
Individual recommendations from the panel will be forwarded to the NSA
Research Directorate, with Dr. Wertheimer making the final decision on
awards. The contest winner and honorable mentions will be announced on
the NSA external web site,  and the winner will be invited
to present the winning paper to an audience of cybersecurity experts and
government personnel. For more information regarding the eligibility
criteria, nomination procedures, criteria for judging, and to download
the nomination forms, visit
The NSA/CSS Research Directorate creates breakthroughs in science,
technology, engineering, and mathematics. These discoveries enable NSA
to achieve and sustain intelligence advances against immediate and
emerging threats to U.S. national security. Our continuing investment in
a world-class faculty contributes to mission success, bringing the power
of science to securing our nation's future.

@_date: 2014-03-19 08:14:46
@_author: dan@geer.org 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Jerry, you wrote a longish item which ends with this memory-jog:
 Yes, performance matters.  It always has:  A system that's secure only
 as long as it operates below the data rates necessary to get the job
 it's paid to do done isn't secure in any meaningful sense.  We've been
 lulled by years of being able to make raw single-stream performance (and
 ever-increasing memory usage, and ever-growing disk usage) Someone
 Else's Problem, which miraculously Someone Else has solved for us.  Those days are over.  It's *our* problem now.
If the above is a lemon, what kind of lemonade might we make of it?
So many things come to mind.  Were the average person to stop buying
new toys that happen to come with new operating systems which happen
to allow their makers to stop upgrading that part of their customer
base that hasn't plumped for the latest gear...  (I've got a long
diatribe about taking by eminent domain widely used codebases that
are abandoned by their putative owners.)
But to your main point that technology advances that have the effect
of making cheap an absence of attentive engineering are themselves
ending -- that really might be a good thingk and a good thing we
should think about now just like now is the time to think about
cryptography post-quantum.  The paper below(*) hints at this in a
different direction, viz., that resource constraint on converting
algorithms to metal may also soonish appear.
On the materials basis of modern society T. E. Graedel1, E. M. Harper, N. T. Nassar, and Barbara K. Reck School of Forestry and Environmental Studies, Center for Industrial
Ecology, Yale University, New Haven, CT 06511 Edited by William C. Clark, Harvard University, Cambridge, MA, and
approved October 11, 2013 (received for review July 29, 2013) It is indisputable that modern life is enabled by the use of materials
in its technologies. Those technologies do many things very well,
largely because each material is used for purposes to which it is
exquisitely fitted. The result over time has been a steady increase
in product performance. We show that this materials complexity has
markedly increased in the past half-century and that elemental life
cycle analyses characterize rates of recycling and loss. A further
concern is that of possible scarcity of some of the elements as
their use increases. Should materials availability constraints
occur, the use of substitute materials comes to mind. We studied
substitution potential by generating a comprehensive summary of
potential substitutes for 62 different metals in all their major
uses and of the performance of the substitutes in those applications.
As we show herein, for a dozen different metals, the potential
substitutes for their major uses are either inadequate or appear
not to exist at all. Further, for not 1 of the 62 metals are exemplary
substitutes available for all major uses. This situation largely
decouples materials substitution from price, thereby forcing material
design changes to be primarily transformative rather than incremental.
As wealth and population increase worldwide in the next few
decades, scientists will be increasingly challenged to maintain and
improve product utility by designing new and better materials, but
doing so under potential constraints in resource availability.

@_date: 2014-03-22 08:16:29
@_author: dan@geer.org 
@_subject: [Cryptography] Tamper-evident cryptographic systems 
Perry resurrected this list after a long hiatus with the challenge to =
 develop new systems secure again such attacks.  I think we have some =
 idea how to accomplish this kind of thing.  But ... one thing we really =
 must learn from the Snowden experience is that even apparently secure =
 systems can be attacked by a well-funded, motivated attacker.  You can't =
 just introduce a new system and walk away saying "it's done".  You also =
 need an active defense.
  So ... how might one build "tamper evident cryptographic systems"?  Are =
 there collections of sensitive signals of possible attacks that can be =
 tracked to provide an early warning - even if no individual signal has a =
 sufficiently low false positive/false negative rate?  Are there ways to =
 construct "honey pots" that will attract attackers to systems specially =
 configured to notice they are there?
  Suggestions?
For me, the pinnacle goal in security engineering, the ne plus ultra,
the goal beyond which there is no other, is this:
  No Silent Failure
I, for one, would readily settle for many more failures if such
failure rate is hedged with their never being silent.  With this,
I break conclusively with Postel's Rule.

@_date: 2014-03-28 19:16:28
@_author: dan@geer.org 
@_subject: [Cryptography] The ultimate physical limits of privacy 
[ not free/cheap ]
The ultimate physical limits of privacy
Can you keep secrets safe from eavesdroppers? Yes you can, say Artur
Ekert and Renato Renner. In a Perspective article they argue that
recent developments in quantum cryptography, coupled with the fact
that we still possess free will, suggest that truly private
communication will always be possible, even in a world with access
to as yet undiscovered code-breaking technologies. The answer lies
in new insights into the nature of randomness and non-local
correlations. Thus equipped it should be possible to outsmart even
the most powerful surveillance procedures.

@_date: 2014-03-31 00:17:43
@_author: dan@geer.org 
@_subject: [Cryptography] ideas for (long) Nothing up my sleeve numbers 
Now that we are defining random numbers, may I suggest
  Randomness is complexity too deep to understand

@_date: 2014-03-31 21:19:00
@_author: dan@geer.org 
@_subject: [Cryptography] ideas for (long) Nothing up my sleeve numbers 
> Therefore, the question: What is your favourite idea for a good,
 > random-enough Nothing Up My Sleeve data with size around 2^14 bits?
 > (e.g. long, reputable, randomly looking positive integer that is less
 > than 2^(2^14))?
  If you want "nothing up my sleeve" numbers start with a source that  has long been published and do a simple repeatable manipulation to it.    For around 2^14 bits, I think you could take a long novel (say, the  Gutenberg Press copy of Fyodor Dostoyevsky's book _The Idiot_).
  Separate it into sentences.  Eliminate any duplicates.
 Take all combinations of two sentences in a deterministic sequence.  Produce a SHA256 block for each.   Then publish the code that munged the book into the bitblock,  publish the exact version of the book you used, and everybody can  verify that the bits you used are in fact derived from that book  in a straightforward way and that you didn't manipulate the text  to get any particularly-desired results. Would you like to borrow my (first edition) copy of RAND's
_One Million Random Digits_, buy your own reprint ($60 USD),
or tell me what it is that I am missing here?

@_date: 2014-11-06 22:47:59
@_author: dan@geer.org 
@_subject: [Cryptography] $750k Fine for exporting crypto 
Your note which begins
opens a can of worms for a list such as this, but if the moderator
allows, may I point out that the number of Federal crimes has grown
from three in 1790 (piracy, treason, counterfeiting) to over 5,000
today, that the trend in Federal criminal law is to criminalize
action (reus actus) without regard to intent (mens rea), and that
regulations -- which have the force of law without the nicety of a
judicial finding -- are growing at stunning rates.
Starting with the Federal Register as found at
   converting that to
   geer.tinho.net/federal.register.xls
and making the assumption that the page count in the Federal Register
has a linear relationship with the regulatory burden imposed by the
Federal government (more precisely, that the percentage of pages
that are actual regulations is relatively constant hence the trend
line is a fair representation, per se), we have, in turn, this
   geer.tinho.net/federal.register.tiff
Taking, then, the 4-year moving average of the number of new pages,
we can score Presidents (omitting Pres. Obama as his term is as yet
unended) by the compound annual growth rate (CAGR) in regulatory
burden during their time in office, first in chronologic order
FDR   19.7%
HST   -2.2%
DDE    1.3%
JFK    5.2%
LBJ    6.1%
RMN    5.8%
GRF   17.6%
JEC    7.4%
RWR   -3.6%
GHB    2.7%
WJC    3.2%
GWB    0.9%
and then sorted highest (most regulating) to lowest (least regulating)
FDR   19.7%
GRF   17.6%
JEC    7.4%
LBJ    6.1%
RMN    5.8%
JFK    5.2%
WJC    3.2%
GHB    2.7%
DDE    1.3%
GWB    0.9%
HST   -2.2%
RWR   -3.6%
This can be further collapsed to the party level where the CAGR
under Democratic Presidencies has been 6.22% and under Republican
Presidencies has been 2.63% for an overall shared CAGR of 4.53%,
meaning that had the Democrats held the Presidency for the full 78
years there would be 46.0% more regulations than now obtain while
had the Republicans held the Presidency for the full 78 years there
would be 78.6% fewer regulations than now obtain, corresponding to
an 11.5 year doubling time for total regulatory burden under
Democratic Presidencies versus a 26.7 year doubling time under
Republican Presidencies.
The entirety of the above aligns with Harvard Law Professor Harvey
Silverglate's estimate that the average American commits three
felonies a day
      In sum, selective enforcement of the putative rule base is a
structural inevitability given the observed rate of growth in that
rule base.  To return to a rule of law requires that the number of
laws be reduced.

@_date: 2014-10-10 22:11:57
@_author: dan@geer.org 
@_subject: [Cryptography] HP accidentally signs malware, 
[ public case study now in progress ]
HP accidentally signs malware, will revoke certificate
(Ars:)     Regardless of the cause, the revocation of the affected certificate
    will require HP to re-issue a large number of software packages with a
    new digital signature. While the certificate drop may not affect
    systems with the software already installed, users will be alerted to
    a bad certificate if they attempt to re-install software from original
    media. The full impact of the certificate revocation won't be known
    until after Verisign revokes the certificate on October 21, Wahlin
    said.

@_date: 2014-10-24 08:56:51
@_author: dan@geer.org 
@_subject: [Cryptography] Best internet crypto clock: hmmmmm... 
> That's fascinating!  Turning an annoyance of audio engineers and home
 > stereos into a forensic tool.
On a similar line, see  which uses
telephony background noise for near-real-time spoofing
detection, inter alia.

@_date: 2014-10-26 09:22:03
@_author: dan@geer.org 
@_subject: [Cryptography] Best internet crypto clock: hmmmmm... 
Along similar lines, small noise in image acquisition is now well
enough understood and discernible to say "This camera did take that
picture" as it does to say "This rifle did fire that bullet," which
extends to "These two pictures/bullets came from the same camera/rifle."

@_date: 2014-10-27 08:30:21
@_author: dan@geer.org 
@_subject: [Cryptography] Auditable logs? 
Where I do think this has relevance is Electronic Health Records
(EHRs).  I do not see a unitary EHR per person but rather, like
today, health records dispersed at least as broadly as the number
of providers that the patient has (your internist has some, your
cardiologist has some, your urologist...) plus the number of insurance
carriers involved plus, perhaps, regulatory overseers of the most
nannified sort.  Today this is part self-protection on the part of
the provider against the event of malpractice claims -- "Here is
the information I was furnished from the laboratory and thus my
decision was as follows."  It is also partly that in most (U.S.)
states, the medical record is the property of the provider, not the
patient.  (Ownership was legislatively swapped from patient to
provider in the middle 1970s in Massachusetts when I was myself
working in teaching hospitals on the then-novel idea of an automated
health record; such change became a generalized trend nationwide.)
In short, there is little to no likelihood of a unitary EHR for the
patient and thus it is likely that logs will have increased meaning
including in front of juries.  On the other hand, there are those
in the medical community with whom I am still in touch who believe
that in due course the ownership of the medical record will revert
to its previous form, i.e., that the patient will own it.  Whether
patients will want to have the facility of log analysis over how
their providers use their EHRs, including how those to whom their
providers outsource use their EHRs, remains unknown.  People on
this list are probably not representative of the general public in
these matters.  In any case, we have begun a natural experiment on
the importance of auditable logs though probably a slow running one.

@_date: 2014-09-09 21:54:15
@_author: dan@geer.org 
@_subject: [Cryptography] Hal Finney cryopreserved 
Last page of The Economist for 6-12 September is Finney's obituary.

@_date: 2014-09-12 22:27:17
@_author: dan@geer.org 
@_subject: [Cryptography] Encryption opinion 
As a side note, the state of Massachusetts has just moved to toll
 roads without toll takers, using license plate cameras instead to
 send you a bill for a few dollars.  I've not been on any of those
 roads, but I've gotten three e-mailed bills in the last two weeks
 that to the unskeptical eye look fully legitimate, which also
 indicates that the phishers know that my geolocation makes driving
 such roads plausible.
  You may not buy from Company XYZ, but everybody is a client of their
 respective government...
and I mostly got "Pshaw; EasyPass spam is old hat."  Yeah, maybe
for some, but then (and now) I thought that the timing of the spam
was rather better than mere random happenstance.
I just read this article
which is germane insofar that if the quality of a phish is the
plausibility of the context in which it appears, then widening data
collection materially enables ever more plausible context-generation;
just pick up
and see what you can do all by your lonesome, etc.

@_date: 2014-09-22 08:26:09
@_author: dan@geer.org 
@_subject: [Cryptography] science of security, NSA paper awards 
NSA's award for the best "science of security" paper published in
2013 was bestowed this past Thursday.  Here are the two papers
honored (the best paper first, then the honorable mention paper).
Memory Trace Oblivious Program Execution
Chang Liu, Michael Hicks, Elaine Shi
University of Maryland
Cloud computing allows users to delegate data and computation to
cloud service providers, at the cost of giving up physical control
of their computing infrastructure. An attacker (e.g., insider) with
physical access to the computing platform can perform various
physical attacks, including probing memory buses and cold-boot style
attacks. Previous work on secure (co-)processors provides hardware
support for memory encryption and prevents direct leakage of sensitive
data over the memory bus. However, an adversary snooping on the bus
can still infer sensitive information from the memory access traces.
Existing work on Oblivious RAM (ORAM) provides a solution for users
to put all data in an ORAM; and accesses to an ORAM are obfuscated
such that no information leaks through memory access traces. This
method, however, incurs significant memory access overhead. This
work is the first to leverage programming language techniques to
offer efficient memory-trace oblivious program execution, while
providing formal security guarantees. We formally define the notion
of memory-trace obliviousness, and provide a type system for verifying
that a program satisfies this property. We also describe a compiler
that transforms a program into a structurally similar one that
satisfies memory trace obliviousness. To achieve optimal efficiency,
our compiler partitions variables into several small ORAM banks
rather than one large one, without risking security. We use several
example programs to demonstrate the efficiency gains our compiler
achieves in comparison with the naive method of placing all variables
in the same ORAM.
Rethinking SSL Development in an Appified World
Sascha Fahl, Marian Harbach, Henning Perl, Markus Koetter, Matthew Smith
Distributed Computing & Security Group, Leibniz Univ, Hannover, Germany
The Secure Sockets Layer (SSL) is widely used to secure data transfers
on the Internet. Previous studies have shown that the state of
non-browser SSL code is catastrophic across a large variety of
desktop applications and libraries as well as a large selection of
Android apps, leaving users vulnerable to Man-in-the-Middle attacks
(MITMAs). To determine possible causes of SSL problems on all major
appified platforms, we extended the analysis to the walled-garden
ecosystem of iOS, analyzed software developer forums and conducted
interviews with developers of vulnerable apps. Our results show
that the root causes are not simply careless developers, but also
limitations and issues of the current SSL development paradigm.
Based on our findings, we derive a proposal to rethink the handling
of SSL in the appified world and present a set of countermeasures
to improve the handling of SSL using Android as a blueprint for
other platforms. Our countermeasures prevent developers from willfully
or accidentally breaking SSL certificate validation, offer support
for extended features such as SSL Pinning and different SSL validation
infrastructures, and protect users. We evaluated our solution against
13,500 popular Android apps and conducted developer interviews to
judge the acceptance of our approach and found that our solution
works well for all investigated apps and developers.
I was one of the judges, in case that matters to someone here.

@_date: 2014-09-23 22:09:37
@_author: dan@geer.org 
@_subject: [Cryptography] science of security, NSA paper awards 
>  > NSA's award for the best "science of security" paper published in
 > 2013 was bestowed this past Thursday.  Here are the two papers
 > honored (the best paper first, then the honorable mention paper).
   Nice!  I find it slightly ironic that the second paper was of far more
 practical use to the world ;-)
 Quoting from the call for nominations,
  Entries are judged on scientific merit, the strength and significance
  of the work reported, and the degree to which the papers exemplify
  how to perform and report scientific research in cybersecurity.
Note that this is an annual award, and if a similar calendar is used
for the 2014 competition, nominations will be due in March of 2015.
Sharpen your pencil(s).

@_date: 2014-09-25 14:58:13
@_author: dan@geer.org 
@_subject: [Cryptography] Of writing down passwords 
> > The security you get with writing passwords down is inherently  > > because it's physically written and kept in a physical location, not  > > on some electronic medium that could be cracked.
 >  > Beware of cameras! Their resolution now is so good that an attacker  > without physical access can steal all your passwords using the  > reflection in your eyes.
  Can you post a demo of that?
  Many of us have seen the Blade Runner movie scene where a photo is
 magnified to show who took it via a captured reflection.  But whenever
 I've tried something similar, the pixels are just too big and they
 fuzz out.  I wasn't aware that e.g. laptop/phone cameras had good
 enough optics and resolution to use reflections from eyes or
 eyeglasses to read handwriting that's out of view of the camera.
Lookup "PlaceRaider" -- it's three year old technolgy so project
yourself forward in time to the present...

@_date: 2014-09-25 22:47:11
@_author: dan@geer.org 
@_subject: [Cryptography] NSA versus DES etc.... was: iOS 8 
> So no, I at least don't agree with Geer's argument, no matter that it was  > well written.
  Dan isn't making that argument, and I strongly doubt he subscribes to it.
 He was hoping to provide a window into the rationale.
The argument in question is a permutation of this point:
   To prove a negative, that is to say to prove that XYZ did not happen,
   you must have a complete enumeration of everything that did happen
   as only in the presence of total surveillance is the absence of
   evidence equivalent to the evidence of absence.
I write that or something like it whenever I am commenting on
regulations that promise true love or happiness ever after if
only we were to prohibit certain happenings, icing that cake
with Dwight D. Eisenhower's words:
   If you want total security, go to prison.  There you're fed,
   clothed, given medical care and so on.  The only thing lacking
   is freedom.

@_date: 2015-04-07 18:50:36
@_author: dan@geer.org 
@_subject: [Cryptography] Fwd: OPENSSL FREAK 
Yes, the Internet of Things as it's being called is scary as hell
 because you know that software will not be updated in any organized
 way - especially when the company that sold the "thing" is out of
 business or loses a patent lawsuit or something.  Or somebody
 who makes a business model of "give away the thing, charge for the
 updates" is going to have a bunch of customers are perfectly happy
 with the way their toaster or thermostat or doorbell or whatever
 works now and don't want to pay for a software update for it,
 or whatever.
  In the absence of timely, reliable upgrades, there really does
 need to be some kind of "kill switch" to shut down discovered
 vulnerable configuration options, or those "things" will become
 the gateway for crooks to get into the rest of the owner's
 network.
I'll bite.  We don't need a kill-switch but we do need a keep-alive.
In other words (and as usual), it is all about the defaults.
Shared Risk and What to Do about It
Messaging, Malware and Mobile Anti-Abuse Working Group
Boston, Massachusetts, October 22, 2014
So perhaps mandating pre-deployed fallbacks is a bad idea entirely.
Perhaps what is needed is a way to reach out and upgrade the endpoints
when the time of necessity comes.  But today, or real soon now,
most of the places needing a remote management interface through
which you can remotely upgrade the endpoints are embedded hardware.
So let me ask a question, should or should not an embedded system
be required to have a remote management interface?  If it does not,
then a late discovered flaw cannot be fixed without visiting all
the embedded systems -- which is likely to be infeasible because
some you will be unable to find, some will be where you cannot again
go, and there will be too many of them in any case.  If it does
have a remote management interface, the opponent of skill will focus
on that and, once a break is achieved, will use those self-same
management functions to ensure that not only does he retain control
over the long interval but, as well, you will be unlikely to know
that he is there.
Perhaps what is needed is for embedded systems to be more like
humans, and I most assuredly do not mean artificially intelligent.
By "more like humans" I mean this: Embedded systems, if having no
remote management interface and thus out of reach, are a life form
and as the purpose of life is to end, an embedded system without a
remote management interface must be so designed as to be certain
to die no later than some fixed time.  Conversely, an embedded
system with a remote management interface must be sufficiently
self-protecting that it is capable of refusing a command.  Inevitable
death and purposive resistance are two aspects of the human condition
we need to replicate, not somehow imagine that to overcome them is
to improve the future.

@_date: 2015-04-09 14:13:43
@_author: dan@geer.org 
@_subject: [Cryptography] Fwd: OPENSSL FREAK 
Answering everyone and no one, here is the most succinct form that
I have yet come up with:
   Problem: Devices that are unfixable & immortal
   Solution: Mortal if unfixable || Fixable if immortal
Yes, I know, for absolutely any solution there will be opponents
the chief of which are inertia and ignorance.  So WTF else is new?
A better behavioral economist than I might now work on an insurance
scheme whereby so long as you take the updates it is the maker that
is strictly liable for all downsides, else it is you.

@_date: 2015-04-13 23:49:48
@_author: dan@geer.org 
@_subject: [Cryptography] Fwd: OPENSSL FREAK 
for all values of "solution," your choice will be a Hobson's choice
next question, please

@_date: 2015-12-01 00:19:22
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] Paris Attacks Blamed on Strong 
In dealing with high level decision makers, the best strategy is
always to provide three options and have the decision maker choose
amongst them.  Taking the American electorate as that high level
decision maker, I would find it refreshing were Brennan to present
said electorate with the choice between [1] content analysis (hence
crypto side doors and the exposure of content), [2] traffic analysis
(hence data retention at a level heretofore unseen and the cataloged
exposure of real social networks), and [3] a willing resolve to tolerate
the occasional terrorist success.  It is a choice amongst losses.

@_date: 2015-12-02 20:11:56
@_author: dan@geer.org 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
Paris Attacks and "Going Dark": Intelligence-Related Issues to Consider
Congressional Research Service, November 19, 2015 (IN10400)

@_date: 2015-12-02 20:52:33
@_author: dan@geer.org 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
The Kafkaesque Sacrifice of Encryption Security in the Name of Security
Daniel Solove
Dec 2, 2015
Proponents for allowing government officials to have backdoors to
encrypted communications need to read Franz Kafka.  Nearly a century
ago, Kafka deftly captured the irony at the heart of their argument
in his short story, "The Burrow."

@_date: 2015-12-07 22:31:43
@_author: dan@geer.org 
@_subject: [Cryptography] Anyone else seen some odd shipping delays? 
Never, ever, order a computer delivered to your identity.
Jeez, Louise.

@_date: 2015-12-24 23:32:53
@_author: dan@geer.org 
@_subject: [Cryptography] Questions about crypto that lay people want to 
<0d1f01d13c2a$677997d0$366cc770$
Point of information: I had a Federal prosecutor tell me that the
overwhelming majority of voting fraud cases taken all the way to
conviction involve absentee ballots.
As voting by mail ~= 100% absentee ballots, ...

@_date: 2015-01-14 23:32:37
@_author: dan@geer.org 
@_subject: [Cryptography] $10 USB charger steals MS keyboard strokes 
in speaking of chargers, e.g., kiosk chargers, might I suggest

@_date: 2015-01-28 18:00:03
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] Underhanded Crypto 
We will keep submissions secret until they have been judged. Once the
   contest is over, all submissions will be published. Winners will be
   announced on December 30, 2014.
Did this complete?  If it did, my searching has been inept as
I can't find it.  Sorry for the noise if noise it is.

@_date: 2015-01-30 08:11:58
@_author: dan@geer.org 
@_subject: [Cryptography] De-Anonymizing 
Whether one or another kind of data can or cannot be anonymized is
fast becoming irrelevant.  The more things you are or carry that can
be a source of good information, the less the blinding of any one of
them diminishes the overall probability that you are identifiable.
We already understand that the field advantage in attacks goes to
the offense because the offense needs only one way in whereas the
defense needs to plug every way in yet discovered.  Applying that
dynamic to privacy, the surveiller needs only one solid match but
the person that wishes to be left alone must block or forego all
data emanations.
As with crypto itself, it is easy to drift towards "making the best
be the enemy of the good."  Nevertheless, baking RFID tags in the
microwave does not, in the end, do anything if one's cellphone, one's
Bluetooth gizmos, one's iris, one's auto registration, and so forth
are each and severally collected then, to the point, correlated.
We cannot, nor should we waste effort trying to, serially forbid
collections by name or by type.  We can only sabotage the process
and, for that, I see only two paths, both of which need labor now
or never:
   (1) changing liability law so substantially as to make casual
   data acquisition more akin to stockpiling lethal chemicals the
   combination of which grows exponentially dangerous as their
   varieties increase, and
   (2) requiring the public and private sectors alike to, in every
   detail, offer their services to persons whose technical highpoint
   is Lynx with neither cookies nor remote procedure calls (read, no
   Javascript, et al.), a kind of parallel to how we now require
   structural and procedural accomodations to handicapped persons.
Both (1) and (2) are as impossible as reaching the North Star, but
they must be that by which we navigate.

@_date: 2015-03-23 21:40:26
@_author: dan@geer.org 
@_subject: [Cryptography] "Most Americans Don't Mind Being on Candid 
<55106AB0.2060505
 However, what I am not keen on - actually what I think is the threat to  the very nature of the democratic and free societies we were taught  about in school - is that the intelligence agencies then use their broad  and well-funded surveillance powers on everyone, *and then hand the data  over to the police*.
  That way lies the police state.  And for that, there is no excuse,  because we were all (*) alive and aware when the Berlin Wall came down.
  Spying on everyone is fine - for national security.  But there is a  long-standing taboo between mixing national / military affairs with  domestic / criminal affairs.
Show me the man and I'll find you the crime.
                        -- Lavrentiy Beria, NKVD
Beria is all the more correct in a surveillance society;
read Silverglate's _Three Felonies a Day_ if needing more.
The real question is who can (is able to) opt out, and what
is the social cost for doing so when we are facing a wave of
globalized, extra-territorial prosecutions for social crimes
for which the Bill of Rights is but a local ordinance.
Freedom, Security, Comfort.  Choose Two.
--dan, channeling for Demosthenes

@_date: 2015-03-26 21:32:09
@_author: dan@geer.org 
@_subject: [Cryptography] "Most Americans Don't Mind Being on Candid 
<5512336C.2010307
 > Otherwise democracy dies right alongside privacy.
Privacy, as in unrecorded solitude, is essential for the
development of a coherent sense of self and, thus, free will.
Our path now is parlous.

@_date: 2015-03-26 23:23:45
@_author: dan@geer.org 
@_subject: [Cryptography] "Most Americans Don't Mind Being on Candid 
WMD? Chem is as irrelavent as a cloudy day. Nuke policing is
 tricky yet seems to be working and still under state control. But
 it's the bio's / DNA and knowledge coming out of govt/corp/edu labs
 that pose the biggest risk to mass humanity. And nobody seems
 to have any idea how to grasp or manage that.
Read Juan Enriquez's (new) book: _Evolving Ourselves_
the subtitle of which is _How Unnatural Selection and
Nonrandom Mutation are Changing Life on Earth_.
Compare that to the core plot line in Richard Clarke's
_Breakpoint_, which was that once genetic modding
becomes doable not only will the elite think they are
better than the rest, they will be.
All states already require permanent cryobanking of
neonates' cord-blood; how soon before we start
screening it for diseases-to-be, all in the name
of universal-risk-pooling which will be oh so surely
couched in paternalistic common good (Obamacare)?

@_date: 2015-03-29 22:39:54
@_author: dan@geer.org 
@_subject: [Cryptography] OPENSSL FREAK 
Would you comment, please, on whether this means you are
accumulating complexity and, if so, at what rate?  For
comparison, ten years ago friends at MSFT Research told
me that approximately 80% of the labor cost of bringing
out a new version of Windows was backward compatibility.
(As a collector of rather a lot of Excel files, I deeply
appreciate that they all still work, for example.)

@_date: 2015-11-12 13:41:43
@_author: dan@geer.org 
@_subject: [Cryptography] Ransomware: Newest viral marketing gimmick ? 
> The critics are right that there can be no certainty that the
 > ransomware operators will make good on their promise.  And there's
 > always the possibility a programming error or law enforcement
 > takedown will allow keys to be recovered without paying the fee,
 > as was the case last year with the CryptoLocker brand.
I was told on Tuesday that some one of the current ransomware
operations did, in fact, make a mistake and cannot, in fact,
do decryption as it failed to retain the needed key.
I have no way to check this.

@_date: 2015-11-30 20:49:13
@_author: dan@geer.org 
@_subject: [Cryptography] Long-term security (was Re: ratcheting DH 
============================== START ==============================
 <20151116130507.554523da
Your design must accept that as a constraint.
See point  in

@_date: 2015-10-24 08:09:50
@_author: dan@geer.org 
@_subject: [Cryptography] Other obvious issues being ignored? 
> ...snip...
 >
 > 1.  You're saying out loud what's obvious but unacknowledged:
 > The base of your trust is not in any CA, it's in your browser's
 > code.  Whether open source or closed, browsers are way to complex
 > and change way too often to be effectively audited by any outside
 > team.  All the cryptography in the world can't protect you from
 > attack code within your browser itself.
 >
 > ...snip...
So, let me suggest that audit is headed for a brick wall.  I don't
like that, but it seems so.  The reason, as you say, is a side
effect of complexity that leads to obscurity.  But obscurity is
the malware writer's central technique and, arguably, stealing our
opponents' techniques is fair if not brilliant.  See, in other
words, DARPA's in-progress work looking at obfuscation -- original
announcement here:
which leads me to ask the general question, what does one do when
something you might soon depend upon can simply never be analyzed?
This may be on the wrong list for this discussion,

@_date: 2016-04-04 21:15:36
@_author: dan@geer.org 
@_subject: [Cryptography] Hayden on encryption v. metadata 
It was said
 Maybe it's time to start publicly calling for Nuremberg-style war crimes
 tribunals to arrest, prosecute, convict, imprison, and execute senior
 surveillance state officials?
Anyone who voluntarily uses a device whose inherent function requires
continuous connectivity has no, repeat no, reasonable expectation
of not being tracked.

@_date: 2016-04-18 08:43:59
@_author: dan@geer.org 
@_subject: [Cryptography] [cryptography] Secure universal message 
> The whole idea that you need a way to securely communicate with
 > someone who you've never had any contact with before is mainly
 > incoherent.
Similarly, the bigger the financial transaction the less likely
it is to be between entities that do not know each other.  As
such, the substantial cost of a/the PKI Registration Agent done
right yields value only for transactions amongst strangers which
is to say the smallest transactions, i.e., the RA function will
never be done right.  Unless compelled.

@_date: 2016-04-22 12:41:12
@_author: dan@geer.org 
@_subject: [Cryptography] a little bit of history 
Under the assumption that this article is true, it tells a little bit
of history that is new to me:
[one-time pads, winning wars, etc.]

@_date: 2016-01-14 23:55:27
@_author: dan@geer.org 
@_subject: [Cryptography] FTC sues for crappy crypto 
[Too many levels of quoting, so I dropped them all.]
While talking about HIPAA, remember that the I is for Insurance,
not Information, and the P is for Portability, not Privacy, plus
as a technical audience cognizant of the capacity of deduction from
large data pools, consider:
HIPAA Privacy Rule's De-Identification Standard
Have a nice day / pay your therapist in cash under an assumed name.

@_date: 2016-01-15 14:55:47
@_author: dan@geer.org 
@_subject: [Cryptography] Plan to End the Crypto War 
Continuing what is essentially now a point of information:
Using a quorumed N of M key fragmentation has two effects.
  One, no M-N actors can cause a service denial.
  Two, no M-N actors can collusively nullify protections.
The size of N and M are chosen relative to risk tolerance which is to
say policy.  Because it has been shown that key fragments can be
generated in abstentia and that they can be used sequentially, there
is no technical requirement that the merged "true" key ever exists.

@_date: 2016-01-22 20:48:10
@_author: dan@geer.org 
@_subject: [Cryptography] LANGSEC Workshop #3 deadline of Feb 3, 2016, 
In the spirit of Adi Shamir's
  "Cryptography is typically bypassed, not penetrated"
may I recommend this workshop to your consideration..
The Third Workshop on Language-Theoretic Security (LangSec) at the
IEEE CS Security & Privacy Workshops solicits contributions related
to the growing area of language-theoretic security.
LangSec's goal is to provide the strongest defense for connected
software and hardware, expressed as a practical design methodology
for handling hostile inputs. LangSec offers a coherent computer
science explanation for the current "epidemic of insecurity" and
imposes an easy-to-understand structure on the seemingly ad hoc
collection of software mistakes or design flaws. This explanation
is predicated on the connection between fundamental computability
principles and the continued recurrence of software flaws despite
numerous and diverse secure programming initiatives.
LangSec posits that the only path to trustworthy software that
safely handles untrusted inputs is treating all valid or expected
inputs as a formal language and treating the respective input-handling
routines as a recognizer for that language.
However, far from being an "Ivory Tower" theory, the LangSec approach
to systems design is primarily concerned with achieving practical
assurance: development that is rooted in fundamentally sound theory,
but is expressed in efficient and practical tools for building
software. One major objective of the workshop is to develop and
share this viewpoint with attendees and the broader systems security
community, to help establish a foundation for research based on
LangSec principles.
The overall goal of the workshop is to bring more clarity and focus
to two complementary areas: (1) practical software assurance and
(2) vulnerability analysis (identification, characterization, and
exploit development). The LangSec community views these activities
as related and highly structured engineering disciplines and seeks
to provide a forum to explore and develop this relationship.
Call for Papers is at Submission deadline is Feb 3, 2016
Program Committee:
Sergey Bratus (Dartmouth College)
Sofia Bekrar (VUPEN)
Jon Callas (Silent Circle)
Fabien Duchene (Grenoble INP, LIG Labs, IMAG)
Thomas Dullien (Google)
Dan Geer (In-Q-Tel)
David Grawrock (Intel)
Felix Lindner (Recurity Labs / Phenoelit)
Meredith L. Patterson (Nuance Communications / Upstanding Hackers, Inc.)
Erik Poll (Radboud University)
Sean W. Smith (Dartmouth College)
Gang Tan (Lehigh University)
Julien Vanegue (Bloomberg)
Samuel M. Weber (Software Engineering Institute, CMU)
Stefano Zanero (Politecnico di Milano University)
Organizing Committee:
Sergey Bratus (Dartmouth College)
Daniel 'TQ' Hirsch (P3KI GmbH)
Felix 'FX' Lindner, (Recurity Labs / Phenoelit)
Michael E. Locasto (University of Calgary)
Meredith L. Patterson (Nuance Communications / Upstanding Hackers, Inc.)
Anna Shubina (Dartmouth College)
Julien Vanegue (Bloomberg)

@_date: 2016-03-17 22:37:36
@_author: dan@geer.org 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
<20160316220043.45863d75
 Formal verification is not a panacea, will never be something we can
 use for every program, and has serious limitations, but it is already
 a really serious tool in the security world. A number of recent TLS
 vulns were found via formal methods.
Two related items, possibly old news here:
1. Kathleen Fisher, Tufts, holds what I understand to be the
world heavyweight champion belt in having put together a
formally verified control system for a quad copter.
2. I see great promise in the Language Theoretic Security effort,
spearheaded by Sergey Bratus (Dartmouth) and Meredith Patterson
(Nuance Communications / Upstanding Hackers, Inc.)

@_date: 2016-03-23 13:52:40
@_author: dan@geer.org 
@_subject: [Cryptography] Paris attackers used OTP's: One Time Phones 
I also don't recall hearing about terrorists buying iPhones a dozen
 at a time.
 Are you suggesting that having a crate of phones in the boot
of your car well be seen as damning the way having a collection
of lockpicks and prybars there is?

@_date: 2016-03-23 19:35:45
@_author: dan@geer.org 
@_subject: [Cryptography] e-mail giants / IETF 
Using TLS in Applications                                    D. Margolis
Internet-Draft                                                 M. Risher
Intended status: Standards Track                           N. Lidzborski
Expires: September 19, 2016                                    W. Chuang
                                                                 B. Long
                                                             Google, Inc
                                                         B. Ramakrishnan
                                                             Yahoo!, Inc
                                                              A. Brotman
                                                            Comcast, Inc
                                                                J. Jones
                                                          Microsoft, Inc
                                                               F. Martin
                                                                LinkedIn
                                                               K. Umbach
                                                                M. Laber
                          1&1 Mail & Media Development & Technology GmbH
                                                          March 18, 2016
                     SMTP Strict Transport Security
                       draft-margolis-smtp-sts-00
   SMTP STS is a mechanism enabling mail service providers to declare
   their ability to receive TLS-secured connections, to declare
   particular methods for certificate validation, and to request sending
   SMTP servers to report upon and/or refuse to deliver messages that
   cannot be delivered securely.

@_date: 2016-03-23 19:52:58
@_author: dan@geer.org 
@_subject: [Cryptography] Paris attackers used OTP's: One Time Phones 
I noticed that these attackers were activating the phones only just
 before they used them. Presumably they were bought for cash. They
 would have to have some way of knowing the number they had to call
 after activation so they could talk to other co-conspirators but that
 would be pretty easy to mask.
I'm waiting for a free-conference-call number to be implicated.

@_date: 2017-03-29 16:52:22
@_author: dan@geer.org 
@_subject: [Cryptography] Science of Security Award, last call 
[forwarded sans headers]
Dear Science of Security Community,
The deadline for nominating a paper to the National Security Agency's Annual Best Scientific Cybersecurity Paper Competition is Friday, March 31, 2017. Nominations can be submitted at  Please find details about the competition below.
*ABOUT THE COMPETITION*
In order to encourage the development of the scientific foundations of cybersecurity, the National Security Agency (NSA) established The Annual Best Scientific Cybersecurity Paper Competition. NSA invites nominations of papers that show an outstanding contribution to cybersecurity science. A set of Distinguished Experts will review the nominations according to the criteria below. Awardees will be invited to NSA to receive the award and present the winning paper to an audience of cybersecurity experts.
*NOMINATIONS AND ELIGIBILITY*
Papers published in peer-reviewed journals, magazines, or technical conferences are eligible for nomination. The date of the publication must be between January 1st 2016 and December 31st 2016. Nominations should include, in 500 words or less, a nomination statement describing the scientific contribution of the paper and explaining why this paper merits the award. A strong nomination statement is desired and will be used as part of the criteria when evaluating paper submissions. Nominated papers must be available in English and PDF format. Nominations must be submitted via  The nominator may not be an author or co-author of the nominated paper. If a paper includes a reviewer as a co-author it may not be considered for an award. Papers may come from any field of cybersecurity research. (Please refer to the SoS-VO discussion forum What is Security Science? A set of distinguished experts will review the submitted nominations and provide individual assessments to the NSA Research Directorate. The NSA Research Directorate will recommend awardees to the NSA Director of Research, whose decision will be final. Considerations in the evaluation of the nominated paper may include:
Scientific merit and significance of the work reported, the degree to which the paper exemplifies how to perform and report scientific research in cybersecurity.
Distinguished experts for the 5th annual competition:
Prof. L. Jean Camp, Indiana University
Dr. Robert Cunningham, Lincoln Laboratory
Dr. Whitfield Diffie, Cybersecurity Advisor
Dr. John Mclean, Naval Research Laboratory
Prof. David Wagner, University California At Berkeley
Dr. Dan Geer, In-q-tel
Prof. Angela Sasse, University College London
Prof. Stefan Savage, University Of California, San Diego
Prof. Paul Van Oorschot, University Of Carleton
Mr. Phil Venables, Goldman Sachs
Dr. Jeannette Wing, Microsoft Research
Submission Period Begins: December 15, 2016
Submission Period for Entries Ends: March 31, 2017 11:59 PM, EST.
Evaluation Process for Entries Begins: April 1, 2017
Winners Notified: By September 15, 2017
Winners Announced: Fall 2017

@_date: 2018-01-31 22:56:53
@_author: dan@geer.org 
@_subject: [Cryptography] NSA's 5th annual Science of Security paper award 
============================== START ==============================
Hello.  I am writing to help recruit nominations for NSA's 5th
Annual Best Science of Cybersecurity paper award, which covers
papers published in calendar 2017.  Nominations close at the end
of next month, March, 2018.
The exercise of trying to identify what paper provided the strongest
*scientific* contribution to the field in the past calendar year
provides an interesting perspective from which to review recently
published work and assess its significance.  I hope you'll take
advantage of this invitation to do just that.
Nominated papers are reviewed by a set of named experts, with the
final selection made by NSA's Director of Research, Dr. Deb Frincke.
The list of reviewers and all other details on the competition can
be found here:
  Past winning papers are listed here:
  And, most important, the place to submit nominations is here:
