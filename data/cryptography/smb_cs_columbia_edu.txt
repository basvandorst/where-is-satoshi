
@_date: 2004-12-08 20:38:39
@_author: Steve Bellovin 
@_subject: workshop on unwanted Internet traffic 
Readers of this list may be interesting the the SRUTI -- Steps Towards Reducing Unwanted Traffic on the Internet -- workshop.  See
 for details.

@_date: 2004-12-09 11:24:58
@_author: Steven M. Bellovin 
@_subject: workshop on unwanted Internet traffic  
In message <20041209013840.068F31AE91 at berkshire.research.att.com>, Steve Bellov
CORRECTION: it's

@_date: 2005-04-02 22:45:47
@_author: Steven M. Bellovin 
@_subject: Lauren Kohnfelder's undergraduate thesis on certificates 
I found this on Simson Garfinkel's blog (
Thank you Simson!

@_date: 2005-04-14 11:15:50
@_author: Steven M. Bellovin 
@_subject: Moore says his law won't last 
This has obvious implications for brute force attacks -- projections
based on Moore's Law are thus much too conservative.

@_date: 2005-04-21 13:49:23
@_author: Steven M. Bellovin 
@_subject: Three NIST Special Pubs for Review (Forwarded) 
There are three NIST Special Publications available for public review and SP 800-38B:
As part of NIST's ongoing effort to update and develop modes of operation for use with the AES algorithm, NIST intends to recommend either the Galois Counter Mode (GCM) or the Carter-Wegman + Counter (CWC) mode. GCM and CWC are modes for authenticated encryption with associated data, combining Counter mode confidentiality with authentication that is based on a universal hash algorithm. Both GCM and CWC are parallelizable. The submission documents specifying GCM and CWC are available through the modes home page,  NIST invites comments on these two modes, including comments on intellectual property matters, by June 1, 2005, at EncryptionModes at nist.gov.
SP 800-57, Parts 1 and 2:
Drafts of NIST Special Publication 800-57 Recommendation for Key Management, Parts 1 and 2 are available for public comment at  This Recommendation provides cryptographic key management guidance.
Part 1 provides guidance and best practices for the management of cryptographic keying material. Comments will be accepted on Part 1 until June 3, 2005. Please send comments to Key_mgmt at nist.gov, with "Comments on SP 800-57, Part 1" in the subject line.
Part 2 provides guidance on policy and security planning requirements for U.S. government agencies. Reviewers of Part 2 should note that a number of the security planning documents referenced in this part of SP 800-57 are undergoing review and revision. It is anticipated that Part 2 will be updated to reflect these revisions. Comments will be accepted on Part 2 until May 18, 2005. Please send comments to Key_mgmt at nist.gov, with "Comments on SP 800-57, Part 2" in the subject line.
Elaine Barker
100 Bureau Drive, Stop 8930
Gaithersburg, MD 20899
Phone: 301-975-2911

@_date: 2005-08-05 12:04:34
@_author: Steven M. Bellovin 
@_subject: draft paper: "Deploying a New Hash Algorithm"  
I'd have phrased it differently than Perry did.  I'd say that the attackers are often cleverer *about security* than protocol designers, because insecurity is their specialty.  Ordinary protocol desingers are good at designing those protocols, but they haven't been trained to think about security.  Here's how I put it in my talk at the IETF plenary last night:
\ns{Patterns of Thought}  \item   Serial number 1 of any new device is delivered to your enemy.
\item   You hand your packets to your enemy for delivery.
\item   Your enemy is just as smart as you are.  If we haven't seen
        a given class of attack yet, it's because it hasn't been necessary;
        simpler attacks have worked well enough.  (Besides, how do you know
        if you'll actually notice it?)

@_date: 2005-08-06 16:48:02
@_author: Steven M. Bellovin 
@_subject: cracking passwords and challenge/response 
Folks might want to look at the slides from a talk Christian Huitema gave at the Applications Area at IETF63 this past week.  Of particular interest is just how cheap it is to brute-force a passphrase these days, especially if it's just used as a cryptographic key with known plaintext (i.e., in challenge/
response protocols).

@_date: 2005-08-06 17:16:24
@_author: Steven M. Bellovin 
@_subject: solving the wrong problem  
In message <27062101.1123360215327.JavaMail.root at elwamui-lapwing.atl.sa.earthli
Tickets are an excellent use for this, because it binds the printing to a specific physical object.  The concert industry has had a problem with trying to use print-at-home tickets -- the fraudsters buy a single ticket, then print it multiple times and sell the resulting tickets to others.  One group is resorting to requiring ID at the door -- buyers will never have a physical ticket until after they're escorted inside, to eliminate the opportunity for such fraud.  (See
 for more Yes, you could do everything via an online system based on identity documents.  Apart from the privacy implications, and the problem of coping with network failures just prior to the start of a concert or game, dealing with the multiple forms of ID people carry isn't easy; it requires a fair amount of preparation and infrastructure.  As I said, people may be moving in that direction, but the article itself called the scheme "laborious"; the band's manager called it "unbelievably I don't disagree with Perry's basic statement -- that a lot of people try to solve the wrong problem.  Here, though, we have a tool.  It remainds to be determined if it's a hammer, screwdriver, or wrench, and hence what problems to apply it to.

@_date: 2005-08-17 08:37:37
@_author: Steven M. Bellovin 
@_subject: faster SHA-1 attacks?  
Shamir gave her rump session talk (and first gave a humorous presentation on why she couldn't get a visa -- she admitted to attacking U.S. government systems, and used collisions).  She is indeed claiming a 2^63 attack, and found a new path to use in the attack.  Because of the new path, there is reason to think the attack will get even better.  Shamir noted that 2^63 is within reach of a distributed Internet effort to actually find one.

@_date: 2005-08-17 08:40:19
@_author: Steven M. Bellovin 
@_subject: How many wrongs do you need to make a right?  
One can easily conceive of schemes that don't have such problems, such as simply publishing the hash of revoked certificates, or using a Bloom filter based on the hashes.
Of course, that doesn't mean that was how it was done...

@_date: 2005-08-17 12:18:21
@_author: Steven M. Bellovin 
@_subject: How many wrongs do you need to make a right?  
Details matter.  If two parties do a DH exchange before sending their certificates, it would take an active attack.  In many protocols, one party authenticates first, thereby preventing an active attack on the But any CRL scheme exposes knowledge of a compromise to a corrupt insider -- and they're often the primary party from whom you want to keep such information.

@_date: 2005-08-22 10:08:29
@_author: Steven M. Bellovin 
@_subject: online MD5 crack database  
In message <20050822133020.C03571BF906 at absinthe.tinho.net>, dan at geer.org writes
I'm sorry, I flat-out don't believe that.  For one thing, why would that have been necessary in 1979?  Unix just wasn't that important.
For another, let's do some arithmetic.
First -- I'm assuming you mean the classic Morris and Thompson scheme,
which has salts.  (That scheme was only published in 1979, but maybe Morris told people -- and NSA had tracked and used Unix from way back.)
Assume there are 100 possible characters -- the 95 printable, plus a handful of control characters.  In those days, @ and # were line kill and character erase, but that meant that ^U and ^H were available.
At 8 characters max, that gives us 100^8 possible passwords, times
4K salts.  That's about 4*10^19.  I'll neglect the indexing overhead, though it would be considerable.
Now, the largest disk drive I know of today is about 400GB, or
4*10^11.  That means you'd need 10^8 drives.  At, say, $50/drive -- very cheap, because you need to factor in the controller and CPU overhead -- that's $5*10^9.  Even by NSA's standards, that's a hefty chunk of change.
You did, however, mention tapes.  The tape drives of that era were, if I recall correctly, 9-track, 6250 bits/inch, with the largest reels being 2400'.  Assuming no interrecord gaps -- and such gaps were mandatory and consumed a noticeable amount of space -- that translates to 2400*12*6250 bytes/real, or 180*10^6.  If my arithmetic is right, that translates to 222 *billion* tapes.  Sorry; even Fort Meade isn't that big.
Oops -- I forgot that each password is 8 bytes.  Multiply all of those numbers by 8...
To figure out how long it would take to generate them, we should start with Diffie and Hellman's DES-cracker.  Yes, the set of passwords is smaller than the set of DES keys, but not by that much if you reall allow "every possible" password.  Besides, these passwords were (a) iterated 25 times, i.e., having a 25x slowdown, and (b) required custom chips because of the salt.  And all this for a system that wasn't in widespread use?
Now -- if you mean old-style passwords, of the type Morris and Thompson replaced, it becomes somewhat more plausible.  Let's restrict ourselves to 64 characters, mirroring the password styles of the day, unsalted.  That's 64^8.  It still comes to 1.5 million reels of tape, however, so I still don't believe it.

@_date: 2005-08-26 11:41:42
@_author: Steven M. Bellovin 
@_subject: Another entry in the internet security hall of shame....  
What is security?  What are you trying to protect, and against whom?
I use Jabber extensively, and I utterly rely on the SSL encryption to the server.  I sometimes use end-to-end GPG encryption, but only when I need to discuss something very private.  In general, I don't bother, because of my threat model.
The biggest threat I face, in many situations, is people eavesdropping on my wireless link, or playing ARP-spoofing games on my wired link.
SSL to the server combats that nicely.  (I run psi, because it's the only open-source client I've found that actually checks the server's certificate against a pre-configured list.  I have no idea what the default list is, since I just replace it with my own...)
I'm not particularly worried about the server end.  I and most of my Jabber correspondents use one of about four different Jabber servers.  I run one myself; the other three are also very tightly administered.  Sure, there could be a problem with any of them; given how bad typical endpoints are today, I'd guess that the servers are actually safer.
I'm not even slightly worried about eavesdropping on the backbone.  I assume NSA can do that if they really want to.  But I *know* that it's hard enough that they're not going to waste their time without a reason, and I doubt if my IM conversations are high enough on their list.  (They're pretty boring, as a rule...)
I'm much more worried about implementation bugs.  A previous version of psi had the bad habit of silently falling back to unencrypted mode if it couldn't find the local crypto library, and due to some glitches in my environment this could happen fairly easily.  I was forced to resort to firewalling the unencrypted port on my machines...  (The implementation has since been changed to make that failure much less If you don't trust your (or your correspondents') IM servers, it may be a different situation.  I haven't read Google's privacy policies for IM; if it's anything like gmail, they're using automated tools that look at your messages and add to your behavioral profile.  As Peter said, though, you can always run your own server or find one that you do trust.  The protocol itself is quite nice, and was designed with
due attention to privacy.  (Aside: the Jabber RFCs were some of the best I dealt with while I was Security AD.  They were remarkably easy to read, given their length and the complexity of the protocol.)
Do I support e2e crypto?  Of course I do!  But the cost -- not the computational cost; the management cost -- is quite high; you need to get authentic public keys for all of your correspondents.  That's beyond the ability of most people.

@_date: 2005-08-26 15:59:15
@_author: Steven M. Bellovin 
@_subject: Another entry in the internet security hall of shame....  
Yup -- documented in the Googletalk pages.
That wouldn't be a surprise at all -- a number of IM programs, including at least Gabber and Psi, keep local logs.  Given Google's core competency of retaining searchable data, one would expect them to do that.
But this underscores one of my points: communications security is fine, but the real problem is *information* security, which includes the endpoint.  (Insert here Gene Spafford's comment about the Internet, park benches, cardboard shacks, and armored cars.)

@_date: 2005-08-26 16:17:32
@_author: Steven M. Bellovin 
@_subject: e2e all the way (Re: Another entry in the internet security hall of shame....)  
On the contrary -- I did say that I support and use e2e security.  I simply said that user-to-server security solves a lot of many -- most?

@_date: 2005-08-28 10:43:58
@_author: Steven M. Bellovin 
@_subject: MD5 Collision, Visualised  
Very nice, though you need to give a scale of rounds -- how many horizontal lines per round?

@_date: 2005-12-02 16:35:41
@_author: Steven M. Bellovin 
@_subject: NSA declassifies some Vietnam-era SIGINT 
These are the documents related to the claim that NSA suppressed many of the intercepts relating to the so-called Gulf of Tonkin incident.

@_date: 2005-12-05 13:31:35
@_author: Steven M. Bellovin 
@_subject: [Clips] Banks Seek Better Online-Security Tools  
In message , Jonathan Thor
I do use it -- but never from a Windows machine.  The OS I use is probably better, but it's *definitely* a much less attractive target for malware writers.
Problems?  I did have my credit card number stolen, but almost certainly not that way.  The bank believes it was a random card number

@_date: 2005-12-07 10:31:52
@_author: Steven M. Bellovin 
@_subject: [Clips] Banks Seek Better Online-Security Tools  
In message <20051207124835.GH27159 at syjon.fantastyka.net>, "Janusz A. Urbanowicz
This is interesting -- the bank is using S/MIME?  What mail readers are common among its clientele?  How is the bank's certificate checked?

@_date: 2005-12-10 10:08:55
@_author: Steven M. Bellovin 
@_subject: secure links using classical (i.e., non-quantum) physics 
Totally Secure Classical Communication Utilizing Johnson (-like) Noise and Kirchoff's Law
Authors: Laszlo B. Kish
Comments: 14 pages; Google search terms: +totally +secure +communication
Subj-class: General Physics
Journal-ref: Manuscript featured by Science, vol. 309, p. 2148 (2005, September 30)
    An absolutely secure, fast, inexpensive, robust, maintenance-free and low-power- consumption communication is proposed. The states of the information bit are represented by two resistance values. The sender and the receiver have such resistors available and they randomly select and connect one of them to the channel at the beginning of each clock period. The thermal noise voltage and current can be observed but Kirchoff's law provides only a second-order equation. A secure bit is communicated when the actual resistance values at the sender's side and the receiver's side differ. Then the second order equation yields the two resistance values but the eavesdropper is unable to determine the actual locations of the resistors and to find out the state of the sender's bit. The receiver knows that the sender has the inverse of his bit, similarly to quantum entanglement. The eavesdropper can decode the message if, for each bits, she inject current in the wire and measures the voltage change and the current changes in the two directions. However, in this way she gets discovered by the very first bit she decodes. Instead of thermal noise, proper external noise generators should be used when the communication is not aimed to be stealth.

@_date: 2005-12-18 00:28:32
@_author: Steven M. Bellovin 
@_subject: browser vendors and CAs agreeing on high-assurance certificates 
The article is a bit long-winded and short on details, but the basic message is simple: too many CAs have engaged in a price- and cost-driven race to the bottom; there are thus too many certificates being issued that aren't really trustworthy.  A group of CAs and browser vendors have been meeting; they've agreed on a set of standards for certificates that represent more checking by the CA.  Browsers will be enhanced to display a different sort of notification -- for IE, a green address bar.

@_date: 2005-12-18 12:52:51
@_author: Steven M. Bellovin 
@_subject: browser vendors and CAs agreeing on high-assurance certificates  
The very first phishing attack I ever heard of was for paypa1.com.  As I recall, they did have a certificate.

@_date: 2005-12-18 19:55:57
@_author: Steven M. Bellovin 
@_subject: A small editorial about recent events.  
The resolution very clearly did not change the text of the law.  As you noted, it's easy to verify that.
There's ample legal precedent that says that a president can't just ignore a law he doesn't like.  One case that comes to mind is the Youngstown steel seizure case.  Truman nationalized the steel companies to head off a threatened strike.  There was a law on the books that would have let him stop the strike.  For political reasons -- the Taft-Hartley Act was passed over his veto -- he didn't want to use it.  The Supreme Court didn't buy it, even though the U.S. was at war (Korea) and steel is obviously a vital war material.  There's a good summary of the case, including most of the Court's opinion at

@_date: 2005-12-23 12:15:24
@_author: Steven M. Bellovin 
@_subject: RNG quality verification  
In message <200512231609.17767.pg at futureware.at>, Philipp =?utf-8?q?G=C3=BChrin
(I am not a RSA specialist yet, I tried to stay away from the bit-wise details It's really unsolvable, in several different ways.
First -- you just cannot tell if a single number is "random".  At best, you can look at a large selection of numbers and see if they fit certain randomness tests.  Even that isn't easy, though there are several packages that will help.  The best-known one is DIEHARD;
ask your favorite search engine for "diehard random".
However -- and it's a big "however" -- numbers that are "random enough" for statistical purposes are not necessarily good enough for cryptographic purposes.  As several people have pointed out already, there are processes involving cryptographic algorithms that produce very "random" sequences, but are in fact deterministic to someone who knows a secret.  In other words, if you don't control the generator, it's not possible to distinguish these two cases.  In fact, any cipher or hash function whose output was easily distinguishable from a true-
random source would be rejected by the cryptographic community.
Furthermore, even if the generator is good, if the machine using the certificates has been compromised it doesn't matter, because the malware can steal the secret key.  What this boils down to is that you either trust the endpoint or you don't.
Finally, even if it were possible for you to verify that p and q were "random", you *really* don't want to do that -- you *never* want to see users' secret keys, because that exposes the keys to danger and hence you to liability.
Let me make an alternative suggestion.  Pick two or three key generation packages -- as I recall, both Firefox and IE have such -- generate a lot of keys, and run them through DIEHARD.  Then warn your users to use only approved mechanisms for generating their certificate requests -- you just can't do any better.

@_date: 2005-12-28 13:46:42
@_author: Steven M. Bellovin 
@_subject: What phishers want  
No -- what phishers are after is money.  They get that today by going after shared secrets.  If banks change, they'll change.

@_date: 2005-02-02 09:35:08
@_author: Steven M. Bellovin 
@_subject: how to tell if decryption was successfull?  
There are a lot of ways to tell, but you generally have to have some idea what you're looking for.  For two examples of how to do it, see
 (or .pdf) and
 (or .pdf)

@_date: 2005-02-02 13:39:34
@_author: Steven M. Bellovin 
@_subject: Is 3DES Broken?  
No, I meant CBC -- there's a birthday paradox attack to watch out for.

@_date: 2005-02-04 13:30:59
@_author: Steven M. Bellovin 
@_subject: Dell to Add Security Chip to PCs  
I have no idea whether or not the bad guys are laughing about it, but if they are, I agree with them -- I'm very afriad that this chip will make matters worse, not better.  With one exception -- preventing the theft of very sensitive user-owned private keys -- I don't think that the TCPA chip is solving the right problems.  *Maybe* it will solve the problems of a future operating system architecture; on today's systems, it doesn't help, and probably makes matters worse.
TCPA is a way to raise the walls between programs executing in different protection spaces.  So far, so good.  Now -- tell me the last time you saw an OS flaw that directly exploited flaws in conventional memory protection or process isolation?  They're *very* rare.
The problems we see are code bugs and architectural failures.  A buffer overflow in a Web browser still compromises the browser; if the now-evil browser is capable of writing files, registry entries, etc., the user's machine is still capable of being turned into a spam engine, etc.  Sure, in some new OS there might be restrictions on what such an application can do, but you can implement those restrictions with today's hardware.  Again, the problem is in the OS architecture, not in the limitations of its hardware isolation.
I can certainly imagine an operating system that does a much better job of isolating processes.  (In fact, I've worked on such things; if you're interested, see my papers on sub-operating systems and separate IP addresses per process group.)  But I don't see that TCPA chips add much over today's memory management architectures.  Furthermore, as Dan points out, it may make things worse -- the safety of the OS depends on the userland/kernel interface, which in turn is heavily dependent on the complexity of the privileged kernel modules.  If you put too much complex code in your kernel -- and from the talks I've heard this is exactly what Microsoft is planning -- it's not going to help the situation at all.  Indeed, as Dan points out, it may make matters worse.
Microsoft's current secure coding initiative is a good idea, and from what I've seen they're doing a good job of it.  In 5 years, I wouldn't be at all surprised if the rate of simple bugs -- the buffer overflows, format string errors, race conditions, etc. -- was much lower in Windows and Office than in competing open source products.  (I would add that this gain has come at a *very* high monetary cost -- training, code reviews, etc., aren't cheap.)  The remaining danger -- and it's a big one -- is the architecture flaws, where ease of use and functionality often lead to danger.  Getting this right -- getting it easy to use *and* secure -- is the real challenge.  Nor are competing products immune; the drive to make KDE and Gnome (and for that matter MacOS X) as easy to use (well, easier to use) than Windows is likely to lead to the same downward security sprial.
I'm ranting, and this is going off-topic.  My bottom line: does this chip solve real problems that aren't solvable with today's technology?  Other than protecting keys -- and, of course, DRM -- I'm very far from convinced of it.  "The fault, dear Brutus, is not in our stars but in

@_date: 2005-02-07 15:11:41
@_author: Steven M. Bellovin 
@_subject: link-layer encryptors for Ethernet? 
Are there any commercial link-layer encryptors for Ethernet available?  I know that Xerox used to make them, way back when, but are there any current ones, able to deal with current speeds (and connectors)?

@_date: 2005-02-08 11:32:46
@_author: Steven M. Bellovin 
@_subject: link-layer encryptors for Ethernet?  
Hmm -- I thought that the Intel encrypting NIC cards were for IPsec, not link encryption.

@_date: 2005-02-08 19:36:09
@_author: Steven M. Bellovin 
@_subject: link-layer encryptors for Ethernet?  
Layer 2?  It seems to be an IPsec box.  At the least, their Administrator's Guide talks about using IP Protocol 50.

@_date: 2005-02-09 11:35:19
@_author: Steven M. Bellovin 
@_subject: link-layer encryptors for Ethernet?  
Yup.  Often, large corporations had policies requiring them, because of how frequently a transoceanic fiber would be cut and the circuits rerouted to satellite.

@_date: 2005-02-09 14:12:28
@_author: Steven M. Bellovin 
@_subject: A cool demo of how to spoof sites (also shows how TrustBar preventsthis...)  
Actually, both Trustbar and checking the certificate are "working" because the code isn't right yet -- those sections of code (in Firefox) don't understand IDN yet, and they need to.  Sure, they're catching a problem here, but they're catching the problem for those network users who are expecting and reading ASCII characters.  But think of, say, the Japanese user who would like to see that the certificate really was issued to , and instead sees the IDN encoding?  That's less than helpful -- he or she would have no way whatsoever of verifying the certificate.

@_date: 2005-02-09 21:58:56
@_author: Steven M. Bellovin 
@_subject: link-layer encryptors for Ethernet?  
Anything beginning with "KG" or "KO" is government, and not what I'm looking for.  The KG-235, which your second URL took me to, is for
TS/SCI traffic -- *way* above what I need...

@_date: 2005-02-10 18:24:46
@_author: Steven M. Bellovin 
@_subject: A cool demo of how to spoof sites (also shows how TrustBar preventsthis...)  
"Unusual CA"?  I'm not sure what a *usual* CA is.
Just for fun, I opened up the CA list that came with my copy of Firefox.  There are no fewer than 40 different entities listed, many of whom have more than one certificate.  I personally know less than half of them to be trustworthy -- and that's assuming that, say, Thawte, Thawte Consulting, and Thawte Consulting cc are all the same company and I can count that as three different ones.  I had no idea that that the U.S. Postal Service had a CA that was trusted by my browser -- and I dare say that many non-Americans wouldn't trust it at all, on the assumption that it would do whatever the U.S. government told it to do. (For such people: the relationship between the USPS and the government is complex.  Let it suffice to say that they moved from .gov to .com, and they had quasi-valid reasons for doing so.)  Baltimore is listed; last I heard, they were out of business.  Is a private root key (or the equivalent signing device) an asset that can be acquired under bankruptcy proceedings?  Almost certainly.  The following text appears in the December 2004 Shareholder Circular I found at Apart from the question of whether or not EvilHackerDudes.Org, a sub rosa
corporation, purchased that key, the fact that this CA is out of business
is certainly good cause for a bank to change its CA.  Would you like
to be the supervisor of customer service when people start calling
about this problem their browser is complaining about?  Remember that
99.99% of people have no idea what a certificate is, what a CA is, or
how to judge whether or not a given CA exercises due diligence when
issuing a cert.  One member of this mailing list, in a private exchange, noted that
he had asked his bank for their certificate's fingerprint.  My
response was that I was astonished he found someone who knew what
he was talking about.
I'm not saying your toolbar is a bad idea; in fact, I think it's a good
one.  But the problem of verifying certificates is a very deep one,
and simple answers will not solve the phishing or MITM problem.

@_date: 2005-02-15 23:29:43
@_author: Steven M. Bellovin 
@_subject: SHA-1 cracked 
According to Bruce Schneier's blog ( a team has found collisions in full SHA-1.  It's probably not a practical threat today, since it takes 2^69 operations to do it and we haven't heard claims that NSA et al. have built massively parallel hash function collision finders, but it's an impressive achievement nevertheless -- especially since it comes just a week after NIST stated that there were no successful attacks on SHA-1.

@_date: 2005-02-16 09:24:57
@_author: Steven M. Bellovin 
@_subject: SHA-1 cracked  
In message , Alexandre
As the blog entry mentions, it's it's unlikely that SHA-1 is affected.
That said, the attack merits close attention; as Schneier has noted in other contexts, attacks always get better, never worse.

@_date: 2005-02-22 11:37:40
@_author: Steven M. Bellovin 
@_subject: [IP] SHA-1 cracked?  
See which includes links to scanned copies of the book.
Note that finding a hash function collision  by brute force is
inherently harder, because it requires some communication:  two
widely-separated machines may have produced matching outputs, but
they need to know about the other one.
That said, van Oorschot and Wiener published a paper in 1994 on
how to do it.  They estimated then that an MD5-cracker could be
built for $10,000,000 with an expected runtime of 24 days.  The
SHA1 attack is a 2^69 problem; MD5 collisions are 2^64; the difference
is pretty close to the Moore's Law gain since 1994.  I haven't
followed the literature on that subject; I don't know if there are
better designs or, for that matter, if they got it wrong.
I should note, though, that this is a meaningless discussion -- no
technical details have been released about the new attack, so we
don't know how easily it parallelizes.
As for gates -- from a naive level, SHA1 has 80 rounds; DES has
16.  If you want high throughput (again, for a brute force style
of attack), you need a pipeline and replication of the core logic;
that alone would imply a 5-fold increase in the gate count.  Beyond
that, SHA1 has a 160-bit data path; DES uses a 32-bit path.  I
won't try to estimate the relative complexities of the mixing
functions at each round.

@_date: 2005-02-23 21:37:25
@_author: Steven M. Bellovin 
@_subject: [IP] One cryptographer's perspective on the SHA-1 result  
Burt Kaliski posted the following to Dave Farber's IP list.  I was about to post something similar myself.
As he quite eloquently pointed out, we have a near-monoculture of hash algorithms.  Virtually every well-known hash algorithm, with the exception of Whirlpool, is derived from MD2/MD4/MD5.  At the time SHA-0 was released, in fact, there was a great deal of speculation that NSA had copied Rivest's framework to avoid disclosing any new principles for hash function construction.
I have no idea if that's true or not.  As we all know, even NSA found SHA more problematic than they would have hoped; witness the release of SHA-1 not all that long afterwards.
When NIST released SHA256/384/512 shortly after AES, but without a public competition, the word was that they didn't have the resources to run two simultaneous large-scale, open processes.  That's a fair statement, and given the choice between an openly-chosen encryption algorithm and an openly-chosen hash function I think most of us would have made the same decision.
I don't know if there's quite the need for open process for a hash function as there was for a secrecy algorithm.  The AES process, after all, had to cope with the legacy of Clipper and key escrow, to say nothing of the 25 years of DES paranoia that was only laid to rest by the reinvention of differential cryptanalysis.  (The Deep Crack machine only confirmed another part of the paranoia, of course, but the essential parameter it exploited -- key size -- was both obviously insufficient in 1979 and obviously sufficient from the requirements of the AES competition.)  It is clear, as Burt said, that we need a large-scale effort to produce new and better hash functions.  To try to repair the MD*/SHA* family is to risk the cry of "epicycles".

@_date: 2005-01-09 21:55:44
@_author: Steven M. Bellovin 
@_subject: "The Reader of Gentlemen's Mail", by David Kahn  
In message <6.0.3.0.0.20050108230829.03c33ed8 at pop.idiom.com>, Bill Stewart writ
I have the book.  For the student of the history of cryptography, it's worth reading.  For the less dedicated, it's less worthwhile.  It's not "The Codebreakers"; it's not "The Code Book"; other than the title quote (and I assume most readers of this list know the story behind it), there are no major historical insights.
The most important insight, other than Yardley's personality, is what he was and wasn't as a cryptanalyst.  The capsule summary is that he was *not* a cryptanalytic superstar.  In that, he was in no way a peer of or a competitor to Friedman.  His primary ability was as a manager and entrepreneur -- he could sell the notion of a Black Chamber (with the notorious exception of his failure with Stimson), and he could recruit good (but not always great) people.  But he never adapted technically.  His forte was codes -- he know how to create them and how to crack them.  But the world's cryptanalytic services were also learning how to crack them with great regularity; that, as much as greater ease of use, was behind the widespread adoption of machine cryptography (Enigma, M-209, Typex, Purple, etc.) during the interwar
period.  Yardley never adapted and hence he (and his organizations) became technologically obsolete.
One of the reviews on Amazon.com noted skeptically Kahn's claim that Friedman was jealous of Yardley's success with women.  I have no idea if that's true, though moralistic revulsion may be closer.  But I wonder if the root of the personal antagonism may be more that of the technocrat for the manager...

@_date: 2005-01-11 10:58:03
@_author: Steven M. Bellovin 
@_subject: entropy depletion  
Let me raise a different issue: a PRNG might be better *in practice* because of higher assurance that it's actually working as designed at any given time.
Hardware random number generators are subject to all sorts of environmental issues, including stuck bits, independent oscillators that aren't independent, contamination by power line frequency noise, etc.  By contrast, a correct implementation of a cryptographic algorithm will always function correctly.  (Yes, there could be an undetected hardware fault.  Run it three times, on different chips....)
To me, the interesting question about, say, Yarrow is not how well it mixes in entropy, but how well it performs when there's essentially no new entropy added.  Clearly, we need something to see a PRNG, but what are the guarantees we have against what sorts of threats if there are never any new true-random inputs?  (Remember the purported escrow key generation algorithm for Clipper?  See for details.  The algorithm was later disavowed, but I've never been convinced that the disavowal was genuine.)

@_date: 2005-01-21 10:46:36
@_author: Steven M. Bellovin 
@_subject: Microsoft reuses RC4 keys in Office 
When you encrypt a file in MS Office, the program hashes the user-supplied password and an IV to produce an RC4 key.  However, if you create a second version of the document, it doesn't generate a new IV.  The consequences are obvious to readers of this list....

@_date: 2005-01-29 13:09:32
@_author: Steven M. Bellovin 
@_subject: Cryptanalytic attack on an RFID chip 
Steve Bono, Matthew Green, Adam Stubblefield, Ari Juels, Avi Rubin, and
Michael Szydlo have successfully attacked a cryptographically-enabled RFID chip made by Texas Instruments.  This chip is used in anti-theft automobile immobilizers and in the ExxonMobil SpeedPass.  You can find details at  (and a link to the draft paper),
and a New York Times article at The paper itself is very nice, and combines RF techniques, cryptanalysis, Internet sleuthing, space-time tradeoffs, and more.  There are some points I'm sure we'll be discussing at length, such as the authors' decision to withhold some of the details of their attack, the actual effective range of an RFID transponder when the attacker uses a suitable antenna, and the practical significance of the work.  But oddly enough, what struck me was TI's response: rather than attacking the researchers, they co-operated, to the extent of providing them with challenge keys to see if the technique was really that effective.  TI is to be congratulated -- such a response is all too Btw, the paper suggests carrying car keys or SpeedPasses in aluminum foil.  I suspect that a more practical form factor is a spring-loaded conductive sleeve that normally surrounds the RFID chip, but is push back either manually or on key insertion.

@_date: 2005-01-31 22:38:53
@_author: Steven M. Bellovin 
@_subject: Is 3DES Broken?  
============================== START ==============================
I'll be happy to second Perry's comment -- I've seen no evidence whatsoever to suggest that it's been broken.  But there are some applications where it's a bad choice for cryptographic reasons.
When using CBC mode, one should not encrypt more than 2^32 64-bit blocks under a given key.  That comes to ~275G bits, which means that on a GigE link running flat out you need to rekey at least every 5 minutes, which is often impractical.  Since I've seen Gigabit Ethernet cards for <US$25, this bears thinking about -- and while 10GigE is still too expensive for most people, its prices are dropping rapidly.
With 10GigE, you'd have to rekey every 27.5 seconds...
For reference purposes, with AES you'd be safe for 2^64*128 bits.  That's a Big Number of seconds.

@_date: 2005-07-05 23:26:54
@_author: Steven M. Bellovin 
@_subject: [Forwarded] RealID: How to become an unperson.  
Let me refer you to a National Academies report (I was on the committee):  Stephen T. Kent and Lynette Millett, ed. IDs -- Not That
Easy: Questions About Nationwide Identity Systems. National Academies
Press, 2002.    Briefly, the report notes that there are a very large number of questions that need to be answered about any such system before it's even possible to discuss it intelligently.

@_date: 2005-07-08 15:06:47
@_author: Steven M. Bellovin 
@_subject: the limits of crypto and authentication 
There's been a lot of discussion about how to strengthen cryptography and authentication, to get away from problems of phishing, pharming, etc.  But such approaches can take you only so far, as this link Briefly, it's a Trojan that waits for you to log int o E-Gold, checks your balance, and drains your account except for .004 grams of gold.

@_date: 2005-07-09 11:37:04
@_author: Steven M. Bellovin 
@_subject: Why Blockbuster looks at your ID.  
I very rarely rent from Blockbuster, so I may have the details wrong; I can state for sure how things work at the local video store I usually When I signed up with them, I supplied a credit card number; they retained that for contingency charges if I fail to return a video.  (Odd -- my local library doesn't do that.  But I digress.)  In return, they handed me an account-linked credential -- exactly the sort of thing that is often advocated on this list.
was one of those key ring-sized cards, and I soon lost it, probably during a wallet upgrade.  No problem -- they're happy to fall back to the secondary authentication system, to whit my drivers' license.  I show that to get access to the account, independent of how I actually pay for the rental.  In other words, they are not using my license to authenticate my credit card.  (I would add that the feeds are low enought that I almost always pay in cash; I have no idea if they even have the ability to use the stored credit card for rental fees if I don't present the card separately.  Hmm -- the account is old enough that the expiration date on my credit card has long since expired.  They've never asked me for an update.  Maybe they're using a reputation

@_date: 2005-07-09 11:45:35
@_author: Steven M. Bellovin 
@_subject: the limits of crypto and authentication  
How does the user know which transaction is really being authenticated?
(I alluded to this in a 1997 panel session talk; see
 )

@_date: 2005-07-13 22:10:21
@_author: Steven M. Bellovin 
@_subject: mother's maiden names...  
One New York bank -- long since absorbed into some megabank -- did the same thing about 30 years ago.  They gave up -- it was expensive then, and may not have solved any real problems.  (Possibly, it simply didn't
fit their real purpose of attracting more customers.)

@_date: 2005-07-21 10:11:11
@_author: Steven M. Bellovin 
@_subject: draft paper: "Deploying a New Hash Algorithm" 
Eric Rescorla and I have written a paper "Deploying a New Hash Algorithm".
A draft is available at and  .
Here's the abstract:

@_date: 2005-07-25 08:12:14
@_author: Steven M. Bellovin 
@_subject: draft paper: "Deploying a New Hash Algorithm"  
In message <4.3.2.7.1.20050725003455.0470c6f8 at mail.alten.org>, Alex Alten write
Yes, Eric and I have been talking about that, and we'll add some discussion of that to the next version of the paper.

@_date: 2005-06-01 21:05:28
@_author: Steven M. Bellovin 
@_subject: analysis of the Witty worm 
Readers of this list may be interested in an analysis of the Witty worm's spread by Kumark, Paxson, and Weaver.  An article summarizing the paper is at A tentative conclusion is that the worm was probably written by an insider at ISS....
The paper itself (there's a link in the article) has several more items of interest to this list.  Especially interesting is the effective cryptanalysis of the PRNG used by the worm.  Implicit in many of the analyses, though not a focus of the paper, is the amount of information that the authors could gather about network configurations at different sites: as we all know, traffic analysis is a powerful technique.

@_date: 2005-06-07 20:34:30
@_author: Steven M. Bellovin 
@_subject: encrypted tapes (was Re: Papers about "Algorithm hiding" ?)  
I don't completely agree.  While I suspect that laziness or lack of thought
are the primary problems, there are some real costs.  The minor one is compression: most modern tape drives compress the data before writing, and you can't compress encrypted data.  That means they'd need to compress in software before writing to the tape; that chews up CPU time that they may not have to spare on the machines in question.  (Remember that we're talking about massive amounts of data here.)
The bigger issue, though, is more subtle: keeping track of the keys is non-trivial.  These need to be backed up, too, and kept separate from (but synchronized with) the tapes.  Worse yet, they need to be kept secure.  That may mean storing the keys with a different escrow company.  A loss of either piece,the tape or the key, renders the backup useless.  Backups are not very reliable to start with.  Too few companies do regular checks on the adequacy or quality of their backups.  Most companies feel they can't afford lowering the reliability even further.
Bingo.  Especially the CEO's head -- or the CFO's head, or the general counsel's -- for some of the mistakes we've seen.  But there's no one cause.  For those who subscribe to the Wall Street Journal online, see
for a chart of recent failures to protect identity data.  Of the 10 failures for which a cause is listed, though, 4 were loss of tapes in transit.  (One was a shipment of tapes to a credit bureau.)  2 involved hacking, one was an inside job, one was a stolen laptop, and 2 were fraudulent use of logins and passwords.

@_date: 2005-06-08 18:07:17
@_author: Steven M. Bellovin 
@_subject: AmEx unprotected login site  
They're doing the wrong thing, and probably feel they have no choice.  Setting up an SSL session is expensive; most people who go to their home page do not log in, and hence do not (to Amex) require cryptographic protection.
A few years ago, I talked with someone who was setting up a system that really needed security.  Given how few pages people would visit on the site, though, he estimated that it would increase his costs by a factor of about 15.  (I didn't verify the numbers; I know from experience that he's competent and has his hear in the right place re security).

@_date: 2005-06-08 19:28:16
@_author: Steven M. Bellovin 
@_subject: AmEx unprotected login site  
There's an attack there, too -- one can divert the link to the login It's a tough problem: they want to outsource the payment processing, but don't have the infrastructure to do so properly.

@_date: 2005-06-16 09:18:53
@_author: Steven M. Bellovin 
@_subject: AES cache timing attack 
Dan Bernstein has a new cache timing attack on AES:
(This was mentioned in Bruce Schneier's CRYPTO-GRAM newsletter.)
Briefly, the attack relies on the fact that retrieving an S-box
entry from the cache is much faster than retrieving it from main
memory; this in turn leaks bits of keying material.
One of his claims is that the attack is possible because of the
characteristics of efficient software implementations of AES, and
that NIST should have realized the problem -- there are ciphers
that don't have this problem.  He also makes some suggestions to
CPU designers about steps they can take to let implementors avoid
such traps.
For years, it was a commonplace that one should not design one's
own encryption algorithms.  Some people have extended that advice
to apply to cryptographic protocols.  Dan Boneh now says he's
warning people even against doing their own implementations.

@_date: 2005-06-16 17:56:54
@_author: Steven M. Bellovin 
@_subject: de-identification  
In message <20050608201906.F3E6C1BF9AD at absinthe.tinho.net>, dan at geer.org writes
What's your threat model?  It's proved to be a very hard problem to solve, since there are all sorts of other channels -- application data, timing data (the remote fingerprinting paper mentioned this one), etc.

@_date: 2005-06-17 18:52:11
@_author: Steven M. Bellovin 
@_subject: massive data theft at MasterCard processor 
MasterCard reported the exposure of up to 40,000,000 credit card numbers at CardSystems Solutions, a third-party processor of credit card data.  CardSystems was infected with a script that targeted specific data.  In other words, this wasn't the usual carelessness, this was enemy action, and of a sophisticated nature.  See
 for the official statement.
Designing a system that deflects this sort of attack is challenging.  The right answer is smart cards that can digitally sign transactions, but that would require rolling out new readers to all the merchants.  That's doable, about once per decade -- and at least one credit card vendor (JP Morgan-Chase) is using the opportunity to push out RFID-based credit card readers instead.  So the marketing department outranks the security department -- big surprise there....

@_date: 2005-03-03 11:57:30
@_author: Steven M. Bellovin 
@_subject: FUD about CGD and GBDE  
What Thor said.
It's instructive to quote from Vol. 2 of Knuth:
And Knuth was talking about a situation without an adversary.
I don't claim that there's a flaw.  I do assert that that I haven't seen a
threat model that would justify extra complexity.
Let me go one step further.  The cryptographic literature is full of
examples of broken protocols.  My favorite is the flaw in the original
Needham-Schroeder protocol, from 1978, that went unnoticed until 1996,
when an automated tool found it.  I should add that once pointed out, the
flaw is blindingly obvious -- but it went unnoticed for 18 years, in the
oldest protocol in the open literature.  Btw, in modern terms this
protocol is 3 lines long.
One more quote, this time a remarkably prescient one from that Needham
and Schroeder:

@_date: 2005-03-04 16:36:43
@_author: Steven M. Bellovin 
@_subject: comments wanted on gbde 
A "discussion" -- I'll be polite and call it that -- has erupted on some mailing lists about gbde -- geometry-based disk encryption.  With the author's consent, I'm soliciting opinions from this group about it:
I have my own opinions, which I know some of you have seen, but on this list I'll remain silent for now to see if any consensus develops.

@_date: 2005-03-11 21:25:27
@_author: Steven M. Bellovin 
@_subject: NSA warned Bush it needed to monitor networks 
WASHINGTON (AP) -- The National Security Agency warned President
Bush in 2001 that monitoring U.S. adversaries would require a
``permanent presence'' on networks that also carry Americans'
messages that are protected from government eavesdropping.
``Make no mistake, NSA can and will perform its missions consistent
with the Fourth Amendment and all applicable laws,'' the document

@_date: 2005-03-11 21:25:27
@_author: Steven M. Bellovin 
@_subject: NSA warned Bush it needed to monitor networks 
WASHINGTON (AP) -- The National Security Agency warned President
Bush in 2001 that monitoring U.S. adversaries would require a
``permanent presence'' on networks that also carry Americans'
messages that are protected from government eavesdropping.
``Make no mistake, NSA can and will perform its missions consistent
with the Fourth Amendment and all applicable laws,'' the document

@_date: 2005-03-15 10:59:56
@_author: Steven M. Bellovin 
@_subject: Security is the bits you disable before you ship  
In message , Peter Gutmann writes
That's not new, either.  I believe it was Tony Hoare who likened this to sailors doing shore drills with life preservers, but leaving them home when they went to sea.  I think he said that in the 1970s; he said this in his Turing Award lecture:

@_date: 2005-03-16 12:02:01
@_author: Steven M. Bellovin 
@_subject: how to phase in new hash algorithms? 
We all understand the need to move to better hash algorithms than SHA1. At a minimum, people should be switching to SHA256/384/512; arguably, Whirlpool is the right way to go.  The problem is how to get there from OpenSSL 0.9.7 doesn't even include anything stronger than SHA1.  As a practical matter, this means that no one can use anything stronger in certificates, especially root certificates.  Worse yet, people can't use anything stronger for public consumption for at least five years after a stronger hash algorith is available -- we have to wait until
most older software has died off, since most machines are never
upgraded.  This means that appearance of the code in client machines is on the critical path.  I've heard that OpenSSL 0.9.8 will include stronger hashes, but there's no work in progress to backport the code to 0.9.7.  So -- what should we as a community be doing now?  There's no emergency on SHA1, but we do need to start, and soon.

@_date: 2005-03-18 22:52:04
@_author: Steven M. Bellovin 
@_subject: NSA warned Bush it needed to monitor networks  
A few days ago, I posted this:
Today, I happened to learn the URL for the document itself:
 .  There's little that strikes me as sensitive in it, other than the (redacted) budget numbers.  What's someplace between amusing and appalling is some of the other things that NSA had considered sensitive.  For example, consider this paragraph, from page 5:
That paragraph, believe it or not, was classified Secret.  For what
it's worth, the official definition of "Secret", from Executive Order
12958 ( is:
What in that paragraph could cause "serious damage"?  The notion that
NSA gives the U.S. government an edge in policy interactions, i.e.,
it may spy on foreign governments?  I'm shocked, shocked to hear that.
Then there are the paragraphs on pages 16 and 17 that describe
NSA's legislative lobbying on crypto legislation.  Those were marked
FUOO -- For Official Use Only.  DD Form 254 says
Why is that information eligible to be withheld?  Because it tells
the public that NSA is interested in legislation about crypto and
I could go on, but the topic of overclassification is well-worn.

@_date: 2005-03-20 20:30:03
@_author: Steven M. Bellovin 
@_subject: Encryption plugins for gaim  
Let me second the recommendation for jabber (though I wish the code quality of some of the components were better).  The protocol itself supports TLS for client-to-server encryption; you can also have AIM (or other IM) gateways on that server.  In many situations (i.e., wireless), it protects the most vulnerable link from eavesdropping.  While clearly not as good as end-to-end encryption, it's far better than nothing, especially in high-threat environments such as the IETF...  (Of course, I only know of one open source client -- psi -- that checks the server certificate.)  In theory, server-to-server communications can also be TLS-protected, though I don't know if any platforms support that.
On top of any other encryption, many implementations support PGP encryption between correspondents.  I don't know of any support for e2e-encrypted chat rooms.
I haven't played with OTR, nor am I convinced of the threat model.  That said, what you really need to watch out for is the transcript files on your own machine...

@_date: 2005-03-20 20:31:08
@_author: Steven M. Bellovin 
@_subject: Schneier: SHA-1 has been broken - Time for a second thought about SDLH ?  
In message , Ralf Senderek w
"Dominated"?  No, of course not.  But a hash function based on discrete log will be slow enough that no one will use it.

@_date: 2005-05-30 21:17:57
@_author: Steven M. Bellovin 
@_subject: What happened with the session fixation bug?  
First, you mean "the Web PKI", not PKI in general.
The next part of this is circular reasoning.  We don't see network sniffing for credit card numbers *because* we have SSL.  Since many of the worm-spread pieces of spyware incorporate sniffers, I'd say that part of the threat model is correct.
As for DNS hijacking -- that's what's behind "pharming" attacks.  In other words, it's a real threat, too.

@_date: 2005-05-31 14:38:39
@_author: Steven M. Bellovin 
@_subject: "SSL stops credit card sniffing" is a correlation/causality myth  
Given the prevalance of password sniffers as early as 1993, and given that credit card number sniffing is technically easier -- credit card numbers will tend to be in a single packet, and comprise a self-checking string, I stand by my statement.
Given what a small percentage of ecommerce goes to those sites, I don't think it's really noticeable.
Sure -- but setting up WEP is a nuisance.  SSL (mostly) just works.  As for your assertion that no one is listening, I'm not sure what kind of evidence you'd seek.  There's plenty of evidence that people abuse unprotected access points to gain connectivity.
Sure -- that's certainly the easy way to do it.
I meant precisely what I said and I stand by my statement.  I'm quite well aware of the difference between network sniffers and keystroke They're using cache contamination attacks, among other things.
I agre completely that virtually no one checks certificates (or even knows what they are).

@_date: 2005-05-31 16:06:38
@_author: Steven M. Bellovin 
@_subject: Citibank discloses private information to improve security  
Bank of America is adopting some new schemes that might help.  First, they're asking users to select a picture the user selected at registration time.  The theory is presumably that a phishing site won't have the right image for you.  Second, you can "register" your computer; if your account is accessed from another computer, additional authentication is demanded, thus rendering a compromised password much less useful.
I think both schemes will help; I doubt that either will stop the

@_date: 2005-11-01 11:36:38
@_author: Steven M. Bellovin 
@_subject: Symmetric ciphers as hash functions  
In message , "Trav
Given that we seem to know much more about block cipher design than hash function design, finding a hash function that is provably as strong as a block cipher is a great idea.
Have you read the Morris and Thompson paper?  If not, see
Briefly, though, the 12 bits of salt were used to permute the E-box in DES.  They limited the salt to 12 bits because there was little need for
any more.  The salt served three purposes: discouraging hardware attacks based on off-the-shelf DES chips; rendering precomputed dictionaries prohibitively expensive; and forcing an attacker to attack individually each password in a file.  If you have 500 passwords -- a lot for 1978 -- and 4K choices, the odds are high that you won't get much overlap in salt space.  Even with 15K entries, a high figure even today, you're not going
to increase the attacker's work factor by more than a few bits.  As for the dictionary size -- they felt (probably correctly) that the size expansion was already large enough that that wasn't a feasible path for the attacker.

@_date: 2005-11-07 11:16:13
@_author: Steven M. Bellovin 
@_subject: On Digital Cash-like Payment Systems  
In message , "Trav
Don't ever encrypt the same message twice that way, or you're likely to fall to a common modulus attack, I believe.

@_date: 2005-11-09 10:54:53
@_author: Steven M. Bellovin 
@_subject: How broad is the SPEKE patent.  
It certainly doesn't claim EKE, by myself and Michael Merritt, since he and I invented the field.  Of course, EKE is also patented.  SRP is patented but royalty-free.  Some of have claimed that it infringes the EKE patent; since I don't work for the EKE patent owner (Lucent), I've never tried to verify that.
Radia Perlman and Charlie Kaufman invented PDM specifically as a patent-free method.  However, the claim was made that it infringed the SPEKE patent.  Since it wasn't patented, there was no one willing to spend the money on legal fees to fight that claim, per a story I heard.
Have a look at for some history.

@_date: 2005-11-15 11:01:02
@_author: Steven M. Bellovin 
@_subject: "ISAKMP" flaws?  
Broadly speaking, they're implementation bugs.  The folks at University of Oulu are doing what developers around the world and across the industry should have been doing: they're writing test case generators that stress parsers.  So far, they've been extremely successful against IKEv1, ASN.1, SNMP, and more.  This should surprise no one and depress  is the home page for this project.

@_date: 2005-11-15 14:29:21
@_author: Steven M. Bellovin 
@_subject: "ISAKMP" flaws?  
I mostly agree with you, with one caveat: the complexity of a spec can lead to buggier implementations.  Sure, even relatively simple protocols can be implemented poorly, but complex ones have more places to go wrong.  (It's instructive, I might add, to read RFC 1025, especially the part about "dirty blows".)

@_date: 2005-11-15 16:08:50
@_author: Steven M. Bellovin 
@_subject: the effects of a spy 
Bruce Schneier's newsletter Cryptogram has the following fascinating link: It's the story of effects of a single spy who betrayed keys and encryptor designs.

@_date: 2005-11-21 11:35:28
@_author: Steven M. Bellovin 
@_subject: from the bad idea department 
Steve Gibon is now offering a "GRC's Ultra High Security
Password Generator" -- a web page that provides you with
"totally random" data in 3 formats: 64 hex digits, 63 printable
characters, or 63 alphanumerics.  The page suggests using
them for passwords, WEP and WPA, VPN shared secrets, and more.
Sigh.  First off, there are no details on just how these
"custom, high quality, cryptographic-strength" strings are
generated.  We all know there are lots of bad ways to do it.
Second, these strings are supposed to be *secret* -- why get
them from somewhere else?   if you want to see more.
(In fairness, the "Application Notes" section is listed as
"under construction".  Maybe it will contain suitable caveats
when it's finished.)

@_date: 2005-11-30 11:15:40
@_author: Steven M. Bellovin 
@_subject: the early history of NSA 
The Quest For Cryptologic Centralization and the Establishment of NSA:

@_date: 2005-10-13 21:51:08
@_author: Steven M. Bellovin 
@_subject: Venona not all decrypted?  
Have a look at  .  The one-time pad was used to superencrypt a codebook; two different codebooks were used.  Most of the successful decryptions were done by 1952; there was some additional help from a partial codebook recovered in 1953.  Here's the key section of that monograph:
Given that intelligence scrutiny of the intercepts continued until 1980,
I doubt there's any more to recover.  That said, the NSA admits of the

@_date: 2005-10-14 13:19:10
@_author: Steven M. Bellovin 
@_subject: NSA Suite B Cryptography  
Precisely.  NSA's actions here are independent of whether or not they like open source software on other criteria.  They've determined that ECC presents a better cost-benefit tradeoff.  We all understand, I think, why they're not enamored with 1024-bit RSA.  Doubling the key size means a ~8x performance hit for the signer and 4x for the verifier; they need to worry about embedded devices such as secure phones, sensors, and things like smart landmines.
Besides, they may feel that open source software isn't trustworthy enough to get near keys.  NSA isn't fond of software crypto to start with, though they're trying to adapt to it.  But they are very concerned about development methodology -- note the part about
'Testing, Evaluation and Certification of "Suite B" Products'.  (For
that matter, I'm also getting increasingly concerned about open source
development methodologies.  That, however, is a separate issue; if/when I write up something coherent, I'll post a pointer here.)
To me, the really interesting thing about that announcement was NSA's endorsement of certain algorithms and sizes.  It states that you can protect Top Secret traffic with 192-bit AES, 384-bit ECC DSA, and SHA-384.  Those numbers, especially the latter, are lower than I'd have guessed.  Note that the web page we're discussing is from Feb 2005, *after* Wang et al had successfully attacked MD5, though before the publication of their SHA-1 results.  NSA still has enough confidence in SHA-384 to rate it for Top Secret traffic.  I wonder what they're going to say at the Halloween Hash Bash....

@_date: 2005-10-15 11:05:56
@_author: Steven M. Bellovin 
@_subject: NSA Suite B Cryptography  
I strongly suspect that Certicom would sue if NSA tried that.
I think that that's a fair summary.

@_date: 2005-10-16 09:46:12
@_author: Steven M. Bellovin 
@_subject: [saag] status of SSL vs SHA-1/MD-5, etc.?  
In message <4.3.2.7.1.20051015234218.0525d718 at mail.alten.org>, Alex Alten write
The major risk that I know of is for signed objects, which generally means signed email, i.e., S/MIME and PGP.  MD5 absolutely should not be used for email, period.  The current attack on SHA-1 is probably infeasible for most attackers; that said, it would be better to have something stronger.  We'll know more about that in two weeks, after NIST's Hash Function Workshop.  As I mentioned on the cryptography list

@_date: 2005-10-16 14:24:55
@_author: Steven M. Bellovin 
@_subject: [saag] status of SSL vs SHA-1/MD-5, etc.?  
No, it wasn't comprehensive, but we looked at the major IETF protocols.

@_date: 2005-10-23 09:48:37
@_author: Steven M. Bellovin 
@_subject: Skype security evaluation 
Skype has released an external security evaluation of its product; you can find it at (Skype was also clueful enough to publish the PGP signature of the report, an excellent touch -- see The author of the report, Tom Berson, has been in this business for many
years; I have a great deal of respect for him.

@_date: 2005-10-25 18:39:47
@_author: Steven M. Bellovin 
@_subject: semi-preditcable OTPs  
In message , "Trav
Another possible answer is that it didn't matter because of how it was If you read the NSA monograph on Venona -- I posted a link a few weeks ago -- you'll see that the OTP in that case was used to superencipher a codebook, by adding the 5-digit OTP number to the 5-digit code value.  Non-random digits in such a setting are more or less irrelevant, unless there is enough of a pattern that it helps you strip off the

@_date: 2005-09-12 11:00:06
@_author: Steven M. Bellovin 
@_subject: ECC patents?  
It does if *all necessary patent rights* are owned (or licensed) by Sun.  For obvious reasons, it's remarkably hard to get someone to say that they don't have a claim on some product.

@_date: 2005-09-13 09:29:20
@_author: Steven M. Bellovin 
@_subject: Clearing sensitive in-memory data in perl  
There's an interesting tradeoff here: which is a bigger threat, crypto secrets lying around memory or buffer overflows?  What's your threat model?  For the average server, I suspect you're better off with Java, especially if you use some of its client-side security mechanisms to lock down the server.  Under some circumstances, you could do a call-out to a C module just for the crypto, but it's by no means obvious that that's a major improvement.
Again -- what is your threat model?

@_date: 2005-09-14 12:29:39
@_author: Steven M. Bellovin 
@_subject: MIT talk: Special-Purpose Hardware for Integer Factoring 
Open to the Public
DATE:    TODAY * TODAY * TODAY * WEDNESDAY, Sept. 14 2005
TIME:    4:00 p.m. - 5:30 p.m.
PLACE:   32-G575, Stata Center, 32 Vassar Street
TITLE:   Special-Purpose Hardware for Integer Factoring
SPEAKER: Eran Tromer, Weizmann Institute
Factoring of large integers is of considerable interest in
cryptography and algorithmic number theory. In the quest for
factorization of larger integers, the present bottleneck lies in the
sieving and matrix steps of the Number Field Sieve algorithm. In a
series of works, several special-purpose hardware architectures for
these steps were proposed and evaluated.
The use of custom hardware, as opposed to the traditional RAM model,
offers major benefits (beyond plain reduction of overheads): the
possibility of vast fine-grained parallelism, and the chance to
identify and exploit technological tradeoffs at the algorithmic level.
Taken together, these works have reduced the cost of factoring by many
orders of magnitude, making it feasible, for example, to factor
1024-bit integers within one year at the cost of about US$1M (as
opposed to the trillions of US$ forecasted previously). This talk will
survey these results, emphasizing the underlying general ideas.
Joint works with Adi Shamir, Arjen Lenstra, Willi Geiselmann, Rainer
Steinwandt, Hubert K?pfer, Jim Tomlinson, Wil Kortsmit, Bruce Dodson,
James Hughes and Paul Leyland.
------- End of Forwarded Message

@_date: 2005-09-14 13:06:40
@_author: Steven M. Bellovin 
@_subject: Amazon's  
It's actually an interesting tradeoff.  The older scheme, as I recall, would mail you your password; knowledge of that (say, by intercepting the email) lets you at your account, which will display the last 5 digits of your credit cards.

@_date: 2005-09-14 18:35:23
@_author: Steven M. Bellovin 
@_subject: [Colloquium] ARMSTRONG LECTURE on Quantum Crypto and Optical Networks (Forwarded) 
The Department of Electrical Engineering at Columbia University invites you
to attend
THE ARMSTRONG MEMORIAL LECTURE
Monday, September 19 - 3:00pm
Davis Auditorium (Schapiro/Host)
Host:  Professor Osgood
"Unbreakable Secret Key Distribution?
Quantum Cryptography and Optical Networks"
Matthew S. Goodman, Ph.D.,
Chief Scientist and Telcordia Fellow, Telcordia Technologies & Laboratory
for Telecommunications Sciences Red Bank, NJ and Adelphi, MD
Manifestly quantum mechanical behavior has had tremendously important
implications for the development of modern technology.  In this talk we
explore the impact of recent ideas and new approaches that quantum
information is having on future secure communications for high performance
optical networks. The talk will concentrate on quantum cryptography, which
offers the promise of unconditional security for communications, and
complements existing mathematically based cryptography, which is applied at
higher networking levels.  The talk will review the rapid progress in this
field as well as some very recent experimental results from the Telcordia
research group and its collaborations.  We will describe the impact that
this work is having on optical networking research and some early
commercial activities and will speculate on its broader commercial
Light refreshments will be served.  We look forward to seeing you there!
Colloquium mailing list
Colloquium at cs.columbia.edu

@_date: 2005-09-15 13:17:42
@_author: Steven M. Bellovin 
@_subject: ECC patents?  
We have been told.  I downloaded Certicom's 2005 annual report
On p. 11, it says

@_date: 2005-09-19 11:28:51
@_author: Steven M. Bellovin 
@_subject: Java: Helping the world build bigger idiots  
In message , Peter Gutmann writes
As opposed to the C version:
    int idx = 0;     while (true) {       displayProductInfo(prodnums[idx]);
      idx++;     }     printf("Segmentation error; core dumped\n");
If it were input, it would print "you are now 0wned"...
No, Java isn't the solution to the world's programming problems.  But
bounds-checking -- in any language! -- would be a very big help.

@_date: 2005-09-22 00:00:22
@_author: Steven M. Bellovin 
@_subject: Java: Helping the world build bigger idiots  
Not quite.  The name of the game is information security, and that's far more than crypto.  Sometimes, in fact, the two conflict.

@_date: 2005-09-26 12:42:08
@_author: Steven M. Bellovin 
@_subject: PKI too confusing to prevent phishing, part 28  
This is an important point.  When *many* people are doing the "wrong" thing, the problem isn't the people, it's the mechanism they're being asked to use.

@_date: 2006-04-08 14:31:58
@_author: Steven M. Bellovin 
@_subject: wiretapping in Europe 
There's a long AP wire story on wiretapping in Europe; see
There are a number of intriguing statements in the article.  For
example, in Italy 106,000 wiretaps were approved last year.  By
contrast, in the US there were only about about 1,700 wiretaps in 2004.
(That number does not include Foreign Intelligence Surveillance Act
wiretaps.  It is also unclear to me if the Italian number represents
calls tapped, as opposed to "court orders issued", which is what
the US number represents.)
Italian prosecutors strongly defend the need for wiretaps, but called
the recent warrantless NSA wiretaps "illegal under our judicial traditions".
A study at the Max Planck Institute said that Italy, followed by the
Netherlands, does the most wiretapping.  One of the authors said:

@_date: 2006-04-26 18:13:49
@_author: Steven M. Bellovin 
@_subject: History and definition of the term 'principal'? 
There were a number of things that Roger deserves at least some credit for
that he never claimed (such as one-way hashing of passwords), at least in
part because they were developed at the Eagle Pub.  Whether it was modesty
on his part, the fact that these things were group efforts, or the fine
IPA they serve there I don't know...

@_date: 2006-04-26 21:53:27
@_author: Steven M. Bellovin 
@_subject: PGP "master keys" 
In an article on disk encryption
( the following
paragraph appears:
What is a "master key" in this context?

@_date: 2006-04-26 22:41:12
@_author: Steven M. Bellovin 
@_subject: PGP "master keys" 
Ah -- corporate key escrow.  An overt back door for Little Brother, rather
than a covert one for Big Brother....

@_date: 2006-08-18 18:32:59
@_author: Steven M. Bellovin 
@_subject: NSA running out of electrical power 
There have been a number of news articles recently about server farms
running into power crunches.  NSA, as we all know, has lots of computers.
They're running into a power crunch, too, according to
The story doesn't say so, but I would guess they're having cooling problems,

@_date: 2006-12-03 20:43:24
@_author: Steven M. Bellovin 
@_subject: cellphones as room bugs 
On Sun, 3 Dec 2006 20:26:07 -0500
I don't recall if it's Q.931 per se, as much as the CO.  Or rather, I
know for certain that various government security agencies were quite
unhappy about ISDN phones with speakerphone capability being deployed
in sensitive sites.  The speaker button was not, as I understood it, a
hard button; it was a soft button that the switch responded to.

@_date: 2006-02-01 12:58:11
@_author: Steven M. Bellovin 
@_subject: CD shredders, was Re: thoughts on one time pads  
Again -- what is the assurance level that they do a good enough job, and against what enemy?

@_date: 2006-02-02 15:20:05
@_author: Steven M. Bellovin 
@_subject: US plans for "Information Operations" 
Note that there's a plentiful supply of black pixels included...

@_date: 2006-02-02 21:28:31
@_author: Steven M. Bellovin 
@_subject: serious threat models 
I hate to play clipping service, but this story is too important not to mention.  Many top Greek officials, including the Prime Minister, and
the U.S. embassy had their mobile phones tapped.  What makes this interesting is how it was done: software was installed on the switch that diverted calls to a prepaid phone.  Think about who could manage

@_date: 2006-02-14 13:00:33
@_author: Steven M. Bellovin 
@_subject: GnuTLS (libgrypt really) and Postfix  
Precisely.  I was preparing a post of my own, saying the same thing; you beat me to it.
We all agree that critical errors like this should be caught; the only question is at what layer the action should take place.  I'm an adherent to the Unix philosophy -- when a decision is made at a lower level, it takes away the ability of the higher level to do something different if appropriate, and this loss of flexibility is a bad thing.
As noted, the best answer is a modern language that supports exceptions.  (Sorry, SIGABRT and setjmp/longjmp just don't cut it.)  Let me suggest a C-compatible possibility: pass an extra parameter to the library routines, specifying a procedure to call if serious errors occur.  If that pointer is null, the library can abort.

@_date: 2006-02-14 16:26:35
@_author: Steven M. Bellovin 
@_subject: GnuTLS (libgrypt really) and Postfix  
It can take context-specific error recovery.  Maybe that's greying out the "encrypt" button on a large GUI.  Maybe it's paging the system administrator.  It can run 'mknod' inside the appropriate chroot partition, much as /sbin/init on some systems creates /dev/console.  It can symlink /dev/geigercounter to /dev/random.  It can load the kernel module that implements /dev/random.  It can do a lot of things that may be more appropriate than exiting.

@_date: 2006-02-15 10:52:45
@_author: Steven M. Bellovin 
@_subject: the return of key escrow? 
According to the BBC, the British government is talking to Microsoft about putting in a back door for the file encryption mechanisms.

@_date: 2006-02-21 10:24:24
@_author: Steven M. Bellovin 
@_subject: distributed password cracking a a product 
The really interesting part is the implication that there's still a lot of 40-bit crypto out there...

@_date: 2006-02-24 10:31:36
@_author: Steven M. Bellovin 
@_subject: NPR : E-Mail Encryption Rare in Everyday Use  
I assumed that that was your point, which is why I figured you were trolling.  But of course, your analogy is precisely wrong -- I can look people's addresses, physical and electronic.  People who want to engage in secure communication publish their keys.  I haven't checked Paul's home page; Ben and I both have links to our PGP keys from our web pages.
You don't.
Of course, you know even less about such things in the physical world.  But you know that, too.  So what is your point?
Certainly, usability is an issue.  It hasn't been solved because there's no market for it here; far too few people care about email encryption.  And they're right -- their email is insecure, but given the environment of the typical desktop system would crypto do any good? We've already seen tailored worms stealing corporate information; we've also seen keystroke loggers and e-theft programs that watch for a login successful screen from your financial provider.  How would encrypting email help a businessman in an environment like that?  (I know -- have a separate machine used only for encrypting and decrypting files, and use a flash drive to carry ciphertext back and forth.  Talk about usability problems....)
Yes, I can and do send encrypted email.  Statistically, I don't do it very often.  In all of last year, I sent four such messages, comprising exactly one conversation.  My effective security is locked-down hosts,
in particular the machine where sensitive inbound mail sits until I pull it down to my laptop.  This way, I don't have to trust my employer, my ISP, etc.  And I use SSL or SSH -- with checking of the far-side certificates -- for transport.

@_date: 2006-01-03 10:50:46
@_author: Steven M. Bellovin 
@_subject: French cryptography and TEMPEST protection 
Those who can read French may be interested in and The first discusses cryptographic primitives, including key and block size recommendations; the second discusses security against parasitic emanation attacks (i.e., TEMPEST).

@_date: 2006-01-06 11:05:00
@_author: Steven M. Bellovin 
@_subject: browser vendors and CAs agreeing on high-assurance certificat es  
It doesn't have to be a capability-based OS; one could easily envision a (ahem) alternate browser strategy accomplish it.  Consider, to pick a non-random example, Apache.  Apache 2.0.x (and I think 1.y, but I don't run it so I can't be sure) forks several child processes to actually serve the pages.  What if the  directives contained an optional User directive that specified the uid each virtual host should run as?  You could have different processes for different virtual hosts.
Yes, that would require more bookkeeping on the part of Apache; it would also require more (perhaps many more) processes running simultaneously.  Both of those are much smaller changes than a capability-based OS.  (Hmm -- who was it who noted that capability-
based systems were the wave of the future, and always would be?)
A final note -- multiple IP addresses is not the same as multiple machines.  Lots of hosting companies dedicate an IP address to each customer, but put them all on a single machine.

@_date: 2006-01-06 13:46:40
@_author: Steven M. Bellovin 
@_subject: phone records for sale.  
Yes, but it's also bad reporting -- the newspaper neglected to call the cell phone companies and ask what their privacy policies are.  What happened may have been 100% legal and explicitly permitted by law...
18 USC 2702(a)(3) says
18 USC 2702(c) says
See for the full text.
The first time I read that last clause, I couldn't believe it; I
actually went and looked up the legislative history.  I found that
Congress wanted to permit sale for marketing or financial reasons, but
wanted to limit the power of the government.  (The Supreme Court had
ruled previously that individuals had no expectation of privacy for
phone numbers they'd dialed, since they were being given voluntarily to
a third party -- the phone company.)
If the phone companies are not giving it out voluntarily, perhaps
they're being tricked or perhaps they have corrupt employees.  From my
experience, one way you authenticate yourself to a cell phone company is
by social security number, and those aren't exactly hard to find.  That
possibility suggests using stronger authentication, but of course that
gets in the way of customer service for the 99.99% of queries that are
legitimate.  (I've had to call my company from abroad, more than once,
on fairly urgent matters.  I had no easy access to, say, my last bill.)

@_date: 2006-01-10 14:42:44
@_author: Steven M. Bellovin 
@_subject: SIGINT and the prisoner "rendition" scandal 
Without going into the details of the purported CIA "rendition" of prisoners to other countries ("it's not torture; we're just outsourcing interrogration to places with less legal overhead"), there may be a SIGINT connection.  The following text appeared in an AP wire story today about a purported Egyptian government document:

@_date: 2006-01-11 11:38:52
@_author: Steven M. Bellovin 
@_subject: quantum chip built 
So, on a semiconductor chip roughly the size of a postage stamp, the Michigan scientists designed and built a device known as an ion trap, which allowed them to isolate individual charged atoms and manipulate their quantum states.
The new chip, which is made of gallium arsenide, should be easily scaled and mass-produced, because it's made using microlithography -- the same process that makes microchips.

@_date: 2006-01-13 11:29:05
@_author: Steven M. Bellovin 
@_subject: long-term GPG signing key  
The difficulty with 3DES's small blocksize is the 2^32 block limit when using CBC -- you start getting collisions, allowing the attacker to start building up a code book.  The amount of data is quite within reach at gigabit speeds, and gigabit Ethernet is all but standard equipment on new computers.  Mandatory arithmetic: 2^32 bytes is 2^38 bits, or ~275 * 10^9.  At 10^9 bits/sec, that's less than 5 minutes.  Even at 100M bps -- and that speed *is* standard today -- it's less than an hour's worth of transmission.  The conclusion is that if you're encrypting a LAN, you need AES or you need to rekey fairly often.

@_date: 2006-01-17 11:57:57
@_author: Steven M. Bellovin 
@_subject: standards being adopted for encrypting stored data 
"Proposed standards for protecting data on disk or tape are gathering steam
within the IEEE and could be supported in products as soon as next year,
according to proponents."

@_date: 2006-01-24 16:01:02
@_author: Steven M. Bellovin 
@_subject: NSA explains how to redact documents electronically 
One wonders how long it will be till someone finds an error...

@_date: 2006-01-25 01:53:24
@_author: Steven M. Bellovin 
@_subject: NSA explains how to redact documents electronically  
I agree.  It's also very dependent on the exact options that Microsoft and Adobe have currently implemented.  Minor changes could screw this up completely.
That's more or less what they did when they declassified Skipjack, though they may have used a real printer and scanner instead.  Some people laughed at NSA's technical ineptitude -- didn't they know how to print to PDF directly?  Others realized that NSA understood the problem at a much deeper level.

@_date: 2006-01-28 12:20:53
@_author: Steven M. Bellovin 
@_subject: thoughts on one time pads  
How high-assurance are these CD destruction methods?  I don't recall seeing any articles on CD data recovery under normal conditions, let alone these.  As always, it depends on your threat model.  (Aside: to me, the only reason for using one-time pads is because you don't trust conventional encryption algorithms.  Given that AES is rated for top secret traffic by NSA, I will assert that any enemy who has a chance of attacking it can devote considerable resources to data recovery from smashed CDs.)

@_date: 2006-07-10 12:39:22
@_author: Steven M. Bellovin 
@_subject: cryptanalysis of Galileo satellite navigation signals 
The EU Galileo navigation satellite uses a set of pseudo-random numbers to
secure access to its data.  Galileo is partially investor-funded; part of
the business model is to sell access to the data.  Some researchers at
Cornell took a different approach -- they cryptanalyzed the algorithm...
Better yet, they got an opinion from their university lawyer that the DMCA
didn't apply.  See for details.

@_date: 2006-07-29 14:48:42
@_author: Steven M. Bellovin 
@_subject: Recovering data from encrypted disks, broken CD's 
I wonder how accurate this is.  It's certainly true that some drives have
vendor passwords to unlock them.  It's hard to see how they could break
through (good) software encryption, unless the software vendor -- probably
Microsoft -- has implemented some form of key escrow, which to my
knowledge they've adamantly opposed doing.  In fact, Microsoft just
withdrew an add-on feature to provide easy-to-use encrypted folders
because corporations didn't like the lack of key recovery.

@_date: 2006-06-05 02:05:36
@_author: Steven M. Bellovin 
@_subject: Status of attacks on AES? 
On Sun, 4 Jun 2006 16:52:38 -0500, "Marcos el Ruptor"
Are there any peer-reviewed descriptions of your technique?  Right now,
all that site seems to have -- and forgive me if I've missed a link --
is a set of simple assertions about various ciphers, plus a fairly vague
background page.  Put another way, and I hate to be this blunt, is there
any reason to think your results are correct and/or meaningful?

@_date: 2006-06-08 12:17:06
@_author: Steven M. Bellovin 
@_subject: Status of attacks on AES? 
I shouldn't pursue this, but I will.  This is still proof by blatant
assertion.  It isn't "controversial" because it's not even worth thinking
about.  You've claimed that (a) you have a powerful but secret method for
analyzing ciphers, and (b) AES fails your tests.  That's nice.  Suppose I
said that when I calculated SHA-512 of the pdf version of the AES standard
mod 257 and found that it was prime (it's 5, if my script is correct), and
therefore AES was insecure. You'd laugh at me, and rightly so.
You say you have a method to evaluate ciphers.  Without full details, no
one can form their own judgment if it's valid or not.  (My "proposal"
clearly isn't valid.)  You say you've evaluated AES and other ciphers.
Without full details, we don't know if your evaluation is correct.
By contrast, see the controversy over the XSL attack an AES.  (The
Wikipedia article,  is a good
summary.)  There are claims and counterclaims, but everything is public.
Note in particular Coppersmith's claim that Courtois and Pieprzyk
overcounted the number of linearly independent equations -- their basic
method may or may not be correct -- Coppersmith himself says that the
"method has some merit, and is worth investigating" -- but they apparently
applied it incorrectly.
You should also explain why you're keeping the details secret.  The market
for new block ciphers is tiny.  No credible vendor is going to rely on a
cipher evaluated by an unproven technique.  (For that matter, the
near-universal consensus in the open community is proprietary ciphers are
generally worthless.)

@_date: 2006-06-08 14:32:01
@_author: Steven M. Bellovin 
@_subject: mailer certificate retrieval via LDAP? 
Are there any common mailers -- open source preferred but not mandatory --
that can query LDAP directories to retrieve X.509 certificates for use in
S/MIME messages?  Evolution and Thunderbird are both able to send S/MIME,
but don't seem to have any easy certificate retrieval mechanisms.

@_date: 2006-06-14 23:12:50
@_author: Steven M. Bellovin 
@_subject: Chinese WAPI protocol? 
Perhaps not.  The Clipper chip may have been patented -- see
 for details.
I also don't know what Chinese law is on the subject.

@_date: 2006-06-15 23:36:28
@_author: Steven M. Bellovin 
@_subject: Chinese WAPI protocol? 
One unspoken issue has always been whether or not the Chinese government
has deliberately sabotaged the spec, presumably for domestic espionage.
Is there any evidence of that?

@_date: 2006-06-21 14:42:08
@_author: Steven M. Bellovin 
@_subject: Greek cellular wiretapping scandal 
The Greek cellular wiretapping scandal was the subject of a front-page
article in today's Wall Street Journal.  (It's
for subscribers.)  The broad outlines of the story are familiar to anyone
who has been following the story -- a Lawful Intercept mechanism was
abused to send copies of certain calls to prepaid cell phone numbers --
but the details are interesting.
incident.  A communications expert who was working on the switch apparently
commited suicide, but this has been questioned by some.  He
The problem was discovered when some people had problems sending text
messages; the link between the two issues is unclear.
The bug itself wasn't simply a matter of turning on Lawful Intercept.
That software did exist in the switch, but everyone says it wasn't
activated and Ericsson wasn't paid for it. (Aside: Greece does have a
CALEA-like law, which means it should have been enabled.)  Vodafone denies
even knowing about such software, which strikes me as improbable.  In
addition, the attack required some other software that activated the
Lawful Intercept but hid its existence. In other words, it was a rootkit
running on a phone switch.  I have more than a passing aquaintance with
the complexity of phone switch software; doing that was *hard* for anyone,
especially anyone not a switch developer.  Installing the rogue software
quite likely involved "authorized access to Vodafone's networks".
Most suspicious, the prepaid phones that could pick up the calls
Guess what's just to the east of Laurel, MD...  On the other hand,
exposing links like that is clumsy -- could it be disinformation?  And one
of the phones monitored was from the American embassy in Athens -- or is
that the disinformation?  Or is NSA spying on the embassy?  You are in a
maze of twisty little spooks, all different.
The attack was very sophisticated, and required a great deal of arcane
knowledge.  Whoever did it had detailed knowledge of Ericsson switches,
and probably a test lab with the proper Ericsson gear.  It strongly
suggests that Ericsson and/or Vodafone insiders were involved -- my guess
is both.  But who did it, and why, remains obscure.

@_date: 2006-03-09 10:14:43
@_author: Steven M. Bellovin 
@_subject: bounded storage model - why is R organized as 2-d array? 
I think you vastly overestimate how much hardware one needs to do
something like AES.  I ran
  	dd if=/dev/zero bs=32k count=1024| openssl speed aes-128-cbc
on a 1500 Mhz Athlon.  It reported speeds of ~27.5 MBps, or 220 Mbps.
Even video isn't that fast, and that's a slow CPU by today's standards.
Also -- I don't know how large these random tables have to be, but if
they don't fit in cache the cipher will be quite slow -- memory
bandwidth hasn't increased nearly as rapidly as CPU speed; modern
machines utterly rely on their caches.

@_date: 2006-03-27 20:06:17
@_author: Steven M. Bellovin 
@_subject: Creativity and security 
On Sun, 26 Mar 2006 19:07:07 -0800, "Joseph Ashwood" There was a Dilbert strip on that about 10 years ago.  (Jan 11, 1996,
according to my saved copy, but it doesn't seem to be available via
their web archive.)  It shows Dilbert saying that he'd never buy
anything online because he doesn't want his credit card number floating
around the net.  He then hands his credit card to a waitress, who comes
back wearing a fur coat.

@_date: 2006-05-04 13:06:38
@_author: Steven M. Bellovin 
@_subject: Linux RNG paper 
On Thu, 04 May 2006 18:14:09 +0200, markus reichelt See "Space-Efficient Block Storage Integrity", Alina Oprea, Mike Reiter,
Ke Yang, NDSS 2005,
--Steven M. Bellovin,

@_date: 2006-05-08 10:01:13
@_author: Steven M. Bellovin 
@_subject: Get a boarding pass, steal someone's identity 
I read the article.  What bothers me is the focus on CAPS II, Secure
Flight, and all the other US government-mandated initiatives.  I saw
nothing in it that seemed in any way related to security.  Every one of
those database entries could have been there -- and probably were there --
for the convenience of airline passengers.  In particular, I'm referring
to the ability to check in online and print your own boarding pass.  For
business travelers who use only carry-on baggage, it's a *major*
timesaver.  I've been on flights where I had to wait 45-60 minutes (or
more) just to get my boarding pass, independent of any security screening.
Passport numbers?  I've always had to present my passport when checking in
for an international flight; the difference now is that I see what's
happening.  (Yes, US immigration is fussier about passport and customs
inspections than most other countries I've visited -- but in my personal
experience, that dates back to 1971.  It's also less fussy about
emigration -- I remember having to listen to fundamentalist religious
preaching from an Australian emigration officer some years ago.)
The real point here is carelessness with access controls.  *That's* what
we have to fight.  It's certainly better if databases don't exist; as I
said, I think that these exist because of customer demand, not government

@_date: 2006-05-08 11:15:56
@_author: Steven M. Bellovin 
@_subject: Get a boarding pass, steal someone's identity 
This is hardly either news or sensitive.  Schneier described it in
CRYPTOGRAM almost 3 years ago
( as did Eric Rescorla
( it's also
been in Slate (

@_date: 2006-05-22 10:19:05
@_author: Steven M. Bellovin 
@_subject: Phil Zimmerman and voice encryption; a Skype problem? 
There's an article in today's NY Times (for subscribers, it's at
 )
on whether Phil Zimmerman's Zfone -- an encrypted VoIP package -- will
invite government scrutiny.  There doesn't seem to be any imminent threat
in the U.S.; the one concrete example mentioned -- the British plan to
give police the power to compel individuals to disclose keys -- doesn't
threaten Zfone, because it uses Diffie-Hellman for (among other things)
perfect forward secrecy and doesn't even have any long-term keys.  (See
draft-zimmermann-avt-zrtp-01.txt for protocol details.)
The fascinating thing, though, was this sentence near the end of the
The Berson report says that Skype uses AES-256.  NSA rates that as
suitable for Top Secret traffic, so it's presumably not the cipher.
Berson analyzed a number of other possible attack scenarios; the only one
that seems to be possible is an active attack plus forged certificates.
If Berson's analysis was correct -- and we all know how hard it is to
verify cryptographic protocols -- that leaves open the possibility of a
protocol change that implemented some sort of Clipper-like functionality.
A silent change like that would be *very* ominous.

@_date: 2006-05-23 11:49:11
@_author: Steven M. Bellovin 
@_subject: Secure phones from VectroTel? 
A 4-digit PIN using EKE or its successors can be a fine thing for a voice
phone -- it's rather hard to brute-force when the other end can't keep
up...  In fact, we mentioned that in our original EKE paper.

@_date: 2006-05-30 22:03:23
@_author: Steven M. Bellovin 
@_subject: Elizabethan traffic analysis 
We tend to think of traffic analysis as a modern technique, but it's
actually quite old.  Here is a message from a spy, observing the
activities of two of (English Queen) Elizabeth I's courtiers, whom he
suspected of trying to manipulate her successor:
This was in 1602.

@_date: 2006-11-02 13:08:19
@_author: Steven M. Bellovin 
@_subject: Can you keep a secret? This encrypted drive can... 
On Thu, 02 Nov 2006 10:42:29 -0500, Ivan Krsti?
My understanding is that that was the plan, but concern about lost
passwords made them change their minds.

@_date: 2006-11-06 10:57:25
@_author: Steven M. Bellovin 
@_subject: Cypherpunks make the OED :-) 
University libraries are useful...
They are open to comments and criticisms...  One caveat: for citations,
they want *only* written works for the citation section.

@_date: 2006-11-15 19:56:39
@_author: Steven M. Bellovin 
@_subject: Citibank e-mail looks phishy 
On Tue, 14 Nov 2006 18:21:38 -0500 (EST), "Leichter, Jerry"
I wish that were true of our field...
Neumann, 1969.
One of my favorite papers is Epstein, McHugh, and Pascale's "Evolution of
a Trusted B3 Window System Prototype", because it describes an approach
that didn't work.  Such papers are all too rare.

@_date: 2006-10-10 11:38:56
@_author: Steven M. Bellovin 
@_subject: handling weak keys using random selection and CSPRNGs 
Given how rare weak keys are in modern ciphers, I assert that code to cope
with them occurring by chance will never be adequately tested, and will be
more likely to have security bugs.  In short, why bother?

@_date: 2006-10-12 17:05:55
@_author: Steven M. Bellovin 
@_subject: handling weak keys using random selection and CSPRNGs 
This is a very interesting suggestion, but I suspect people need to be
cautious about false positives.  MP3 and JPG files will, I think, have
similar entropy statistics to encrypted files; so will many compressed
For a more substantive, less hand-wavey analysis, see
which has actual file system entropy measurements.

@_date: 2006-10-17 09:42:44
@_author: Steven M. Bellovin 
@_subject: physical-layer traffic analysis 
Some folks might be interested in
 -- it's not
precisely traffic analysis, but there are enough similar techniques that I
think it's relevant to this list.

@_date: 2006-10-23 20:12:00
@_author: Steven M. Bellovin 
@_subject: Traffic Analysis References 
Very nice summary.  I'd add a few things.
First, on a topical note, Hewlett-Packard obtained call records of various
people, including members of its own board and reporters for major
publications.  In other words, there's a private sector threat.  Second,
in many cases the beauty of traffic analysis is that it can be done after
the fact.  Phone companies don't keep recordings of all conversations;
they do keep billing data.
In a legal vein, in some jurisdictions (i.e., the U.S.) traffic analysis
warrants are *much* easier to obtain than wiretaps.  Philosophically, the
distinction is because traffic analysis data (and in particular telephone
calling records) is information that was voluntarily given to a third
party, the phone company.  There is thus no expectation of privacy.
Again, this is U.S. law; your jurisdiction's law may vary.
Finally, you should cite the Zendian problem, since it's a classic
published training exercise.

@_date: 2006-10-26 13:13:14
@_author: Steven M. Bellovin 
@_subject: [Cfrg] Applications of target collisions: Pre or post-dating 
So how close are we getting to first or second preimage attacks?

@_date: 2006-10-26 14:05:17
@_author: Steven M. Bellovin 
@_subject: Are laptop search & seizures increasing use of disk crypto? 
There was a related story in Tuesday's NY Times
( for
subscribers -- and get there before Tuesday, so you don't have to pay), on
"At U.S. Borders, Laptops Have No Right to Privacy".

@_date: 2006-09-05 11:59:39
@_author: Steven M. Bellovin 
@_subject: A lack of US cryptanalytic security before Midway? 
The conventional wisdom is that the successful US cryptanalytic efforts
against Japanese naval codes was a closely-held secret.  I've just
stumbled on a source that disputes that.  In "The Unknown Battle of
Midway: The Destruction of the American Torpedo Squadrons" (Alvin Kernan,
Yale University Press, 2005), the author states:
The source for this statement isn't clear.  The author himself was an
enlisted sailor on one of the American carriers (he was an ordnanceman for
a torpedo squadron), so it may be first person knowledge.  Later in the
second paragraph, there's a footnote to Prange et al's "Miracle at
Midway", but I don't have that reference.

@_date: 2006-09-07 12:54:35
@_author: Steven M. Bellovin 
@_subject: A lack of US cryptanalytic security before Midway? 
The URL you cite does not support your claim.  It speaks of the successful
cryptanalysis of JN-25 as "one of the closest kept secrets of World War
II".  It also notes that the reporter learned of some data just from
seeing a piece of paper in a senior officer's quarters, rather than
knowning about the real source of the data, and that the Trib's headline --
"NAVY HAD WORD OF JAP PLAN TO STRIKE AT SEA" -- was not in fact justified
by what the reporter had seen and written. In other words, there was not a
factual leak of the real secret, though admittedly Japanese
counter-intelligence would likely have drawn the proper conclusion had they
seen the story.
I should note that if Kernan's account is correct, the danger to American
SIGINT efforts were far greater than were realized.  Three downed American
airmen were rescued by Japanese ships; they were then interrogated and
executed.  None of them (again, according to Kernan) had had proper
training on what they should or should not disclose.  If, indeed, the fact
of cryptanalysis was common knowledge, it was lucky indeed that the proper
questions weren't asked -- or if they were asked, they weren't answered,
even though at least one of them did give away more information than he
should have.

@_date: 2006-09-14 21:22:17
@_author: Steven M. Bellovin 
@_subject: Why the exponent 3 error happened: 
On Thu, 14 Sep 2006 17:21:28 -0400, Victor Duchovni
A software testing expert once asked me why even good test groups didn't
find more of the software holes.  I told her it was because the spec said
things like "must accept input up to 4096 bytes" rather than "must accept
input up to 4096 bytes and must detect and reject longer input strings".
I think we're seeing the same thing here -- the spec didn't say "must
reject", so people who coded to the spec fell victim.
As for the "not compatible with a well-socialized human" -- well, maybe --
I don't think normal people describe themselves as "paranoid by

@_date: 2006-09-16 23:18:55
@_author: Steven M. Bellovin 
@_subject: Fw: [Cfrg] Invitation to review Bluetooth Simple Pairing draft 
Forwarded with permission.  Begin forwarded message:
My name is Robert Hulvey and I am a Systems Engineer with Broadcom Corp.
working on Bluetooth products.  I participate in several groups within the
Bluetooth Special Interest Group (SIG) including the Core Specification
Working Group (CSWG), the Human Interface Device (HID) Working Group, and
the Bluetooth Architecture Review Board (BARB).  Within the CSWG, we have
been developing a feature called Simple Pairing to address the weaknesses
which were part of the original Bluetooth specification's pairing
mechanism. Our hope is that the new pairing method will be FIPS compliant,
and as such we would appreciate your review and feedback on whether we are
on track to achieve this goal.  "Pairing" refers to the method of
associating 2 devices so that they can communicate via the Bluetooth
wireless protocol. Note that Simple Pairing is just a first step, and does nothing to change
the Bluetooth encryption mechanism (the Massey-Rueppel stream cipher, also
known within the specification as E0).  We anticipate changing to AES in
counter-mode, similar to what WiFi currently uses, in a future version of
the specification.
The following is a link to a whitepaper which has been made publicly
available for the express purpose of encouraging outside review of the the
draft specification.  Please feel free to forward this to any other
interested parties.
Please send any feedback to the address shown in the document (
 radio-feedback at bluetooth.org), but
please also copy me at rwhulvey at broadcom.com.
Thank you for your time.
Best Regards,
Robert W. Hulvey
Principal Systems Engineer 	Broadcom Corporation
 & Wireless Group
16215 Alton Parkway
Irvine, CA 92618 	
hulvey at broadcom.com
   	
tel: mobile: 	949-926-6239
310-384-0996 	
  Add me
to your address book...	   Want a
signature like this?

@_date: 2006-09-20 10:23:25
@_author: Steven M. Bellovin 
@_subject: Did Hezbollah use SIGINT against Israel? 
That isn't supposed to be possible these days...  (I regard it as more
likely that they were doing traffic analysis and direction-finding than
actually cracking the ciphers.)

@_date: 2006-09-21 16:05:17
@_author: Steven M. Bellovin 
@_subject: Exponent 3 damage spreads... 
NIST's draft revision of FIPS 186-3 says
   (b) The exponent e shall be an odd positive integer such that
           65,537 <= e < 2**(nlen - 2*security_strength)
       where nlen is the length of the modulus n in bits.
The security_strength is the work factor for brute force attack on the
corresponding symmetric cipher or hash function, i.e., 128 for SHA-256.

@_date: 2006-09-28 23:21:08
@_author: Steven M. Bellovin 
@_subject: Circle Bank plays with two-factor authentication 
I'd like to hear why you think the scheme isn't that usable.  I disagree
with you about its security.
The question is what the threat model is.  We all know that email can be
intercepted over the wire.  We also know that that's not very common or
very easy, except for wireless hotspots.  I assert that *most* email does
not flow over such links, and that the probability of a successful
interception by someone who's staked out a hotspot is quite low.
Residential wireless?  Sure, there's a lot of it, mostly unencrypted.  If
you're a bad guy, is there any reason you should be watching for that
particular piece of email?  You don't even know who the customers of that
bank are.  (Sure, there can be targeted attacks aimed at a given
individual.  Unless you're a member of the HP board of directors or a
prominent technology journalist, that risk is low, too....)
Again -- the scheme isn't foolproof, but it's probably *good enough*.  What is their threat?  There are two obvious answers: phishing and
keystroke loggers.  It works very well against the first, and tolerably
well against the second, at least until the scheme catches on.  A phisher
has no knowledge of what challenges will appear, so that won't do much.
(OTOH, an active attacker -- one who waits for you to connect to the site,
then connects to the real bank and echoes the real challenge -- will
succeed, but an active attacker will succeed against any scheme that
doesn't involve bilateral authentication.)
As for keystroke loggers -- the bad guy would have to capture enough table
entries that they'd have a reasonable probability of seeing challenges
they'd already received.  The bad guy's strategy might be to try a lot of
logins, until the hit a lucky set, but the bank's obvious defense is to
lock people out after too many failed attempts.  Yes, that's denial of
service, but that's not the bad guy's goal here.
In short -- I think that the scheme is well-matched to the threat.  The
one thing they should have done differently is not put the username in the
same email -- you're told to safeguard the matrix, so you don't want to
send the two in the same message, where someone who has compromised the
file will get both.  I agree that a matrix you need to look at is harder
to use than, say, a password, but most two-factor schemes are going to be
somewhat difficult.

@_date: 2007-04-20 12:02:15
@_author: Steven M. Bellovin 
@_subject: More info in my AES128-CBC question 
Let me make a stronger statement.  If the standards group has "very
little security experience", they *will* get many things wrong.  They
desperately need to get several clueful individuals involved and
*listen* to them.
The WEP group made that mistake.  I use WEP in my classes as a case
study in how to do crypto wrong.

@_date: 2007-04-22 22:57:40
@_author: Steven M. Bellovin 
@_subject: More info in my AES128-CBC question 
Sure -- but remember that in general, *you don't know as much as the
expert*.  It's relatively easy to learn the basic facts; however,
learning *judgment* is a lot harder -- and that's what you're really
paying the expert for.

@_date: 2007-04-30 13:23:25
@_author: Steven M. Bellovin 
@_subject: phone encryption technology becoming popular in Italy 
According to an NY Times article
phone encryption technology is becoming popular in Italy because of
many recent incidents of conversations being published.  Sometimes, a
wiretap is being leaked; other times, it seems to be private behavior:

@_date: 2007-08-08 14:48:54
@_author: Steven M. Bellovin 
@_subject: unintended consequences? 
I recently saw a news story about a new kind of fiber optic cable from
Corning -- it has a much smaller bending radius.  (See
The problem is that when fiber is bent too sharply, the light escapes.
Of course, that's the rumored way that, umm, agencies tap fiber: they
bend it enough that some light escapes, but not too much.  That trick
won't work nearly as well with the new fiber, which is reportedly 100x
more bendable.  Does that mean that the new fiber is less tappable?

@_date: 2007-08-15 09:24:30
@_author: Steven M. Bellovin 
@_subject: New DoD encryption mandate 
According to  the US
Defense Department has mandated that all sensitive but unclassified
information on mobile devices must be encrypted in compliance with FIPS
140-2.  "Mobile devices" include laptops, PDAs, CDs, flash drives, etc.

@_date: 2007-08-18 13:45:49
@_author: Steven M. Bellovin 
@_subject: a new way to build quantum computers? 
"Ann Arbor (MI) - University of Michigan scientists have discovered a
breakthrough way to utilize light in cryptography. The new technique
can crack even complex codes in a matter of seconds. Scientists believe
this technique offers much advancement over current solutions and could
serve to foil national and personal security threats if employed."...
I'll let those who know more physics comment in detail; from reading
the article, it appears to lead to a way to construct quantum computers.

@_date: 2007-12-03 01:24:32
@_author: Steven M. Bellovin 
@_subject: Open-source PAL 
I don't think it would be fruitful.  Have a look at page 2 of
 -- it notdes
that "The system hinges on what is essentially a switch in the firing
circuit that requires the would-be user to enter a numeric code that
starts a timer for the weapon?s arming and detonation."  I don't think
that that's quite correct -- it permits arming; PALs are not in the
firing circuit, I believe -- but this section is more interesting:
"Delicate design details involve how to bury the link deep inside a
weapon to keep terrorists or enemies from disabling the safeguard."
In other words, it's easy to have a circuit that keeps the bomb from
arming; the hard part is doing so with high assurance against attacks,
and that's very design-dependent.

@_date: 2007-12-10 01:51:36
@_author: Steven M. Bellovin 
@_subject: Intercepting Microsoft wireless keyboard communications 
It's moderately complex if you're trying to conserve bandwidth (which
translates to power) and preserve a datagram model.  The latter
constraint generally rules out stream ciphers; the former rules out
things like encrypting the keystroke plus seven random bytes with a
64-bit block cipher.  Power is also an issue if your cipher uses very
much CPU time or custom hardware.
I"m sure most readers of this list can propose *some* solution.  It's
instructive, though, to consider everything that needs to go into a
full system solution, including the ability to resynchronize cipher
states and the need to avoid confusing naive users if the cat happened
to fall asleep on the space bar while the CPU was turned off.

@_date: 2007-12-10 19:49:44
@_author: Steven M. Bellovin 
@_subject: Flaws in OpenSSL FIPS Object Module 
On Mon, 10 Dec 2007 11:27:10 -0500
"Integrity" or "ability"?  We all know that finding problems in code or
architecture is *very* hard.

@_date: 2007-12-11 04:03:14
@_author: Steven M. Bellovin 
@_subject: Intercepting Microsoft wireless keyboard communications 
On Tue, 11 Dec 2007 13:49:19 +1000
Believe it or not, I thought of CFB...
Sending keep-alives will do nasties to battery lifetime, I suspect;
most of the time, you're not typing.  As for CFB -- with a 64-bit block
cipher (you want them to use DES? they're not going to think of anything
different), it will take 9 keypresses to flush the buffer.  With AES
(apparently your assumption), it will take 17 keypresses.  This isn't
exactly muggle-friendly.  Just think of the text in the instructions...
Redundancy?  I wonder how much is needed to avoid problems.  It has to
be a divisor of the cipher block size, which more or less means 8 extra
bits.  How much will that cost in battery life?

@_date: 2007-02-05 16:48:16
@_author: Steven M. Bellovin 
@_subject: Entropy of other languages 
On Sun, 04 Feb 2007 15:46:41 -0800
It should be pretty easy to do at least some experiments today --
there's a lot of online text in many different languages.  Have a look
at  for freely-available books that
one could mine for statistics.

@_date: 2007-02-07 17:53:16
@_author: Steven M. Bellovin 
@_subject: Entropy of other languages 
On Wed, 7 Feb 2007 12:44:30 -0600
An interesting web site, which also contains the following
crypto-relevant statement:
Does anyone know anything more about this use of Welsh?

@_date: 2007-02-07 21:26:41
@_author: Steven M. Bellovin 
@_subject: One Laptop per Child security 
We're digressing to general security topics here, but I'll take a
chance that our moderator will allow this through -- I do mention
That firewalls should be omitted is no surprise.  A firewall is a
device for centralized policy enforcement; it's useful when policy to
the "outside" -- whatever that is -- is different than policy for the
"inside".  If you don't have a well-defined "inside" and "outside",
they're not very useful.  However, their primary benefit comes from
keeping the bad guys away from buggy code.  That problem, I predict,
will afflict this project as well -- just because a service uses
cryptographic authentication doesn't make it immune to bugs, including
bugs before the crypto authentication has succeeded.  Even if the
crypto authentication succeeds, all it means is that some process on
the other machine has access to the credentials; it says nothing about
whether or not the human in front of that machine wants to connect.
The AV decision is more problematic.  While a good security model can
prevent system files from being overwritten, most worms use purely
user-level abilities.  It would take a fairly radical OS design to
prevent a user-level worm from spreading.  (Thought experiment: explain
what OS facilities would have prevented the 1988 Internet worm from
succeeding. My conclusion, way back when, that nothing in, say, the
Orange Book would have stopped it was a major step in my evolution as a
security researcher.  It can be done, I suspect, but only by very
stringent restrictions on application privileges.  Have you designed
such restrictions?  Now assume it's a dual-mode worm, that attacks web
servers and web browsers.)

@_date: 2007-02-08 20:10:34
@_author: Steven M. Bellovin 
@_subject: One Laptop per Child security 
On Thu, 08 Feb 2007 13:03:27 -0800
What about unprotected, frequently-running web browsers?

@_date: 2007-02-12 17:44:03
@_author: Steven M. Bellovin 
@_subject: Failure of PKI in messaging 
On Mon, 12 Feb 2007 17:03:32 -0500
Precisely.  The real problem is the human interface, where we're asking
people to suddenly notice the absence of something they're not used to
seeing in the first place.
Yes, there have been studies.  They've all been quite disappointing.
I'm working on some related material right now, with the financial
sector.  It's not an easy problem.

@_date: 2007-01-07 23:02:22
@_author: Steven M. Bellovin 
@_subject: (Short) Intro and question 
There's a vast literature on the subject.  The classic paper is "How to
Share a Secret", by Shamir, Comm. ACM 22:11, Nov 1979.  Gus Simmons
published a survey of the field about 10 years ago, but I don't have
the citation handy.  I've always been fond of "Cryptographic sealing
for information secrecy and authentication", David Gifford, Comm. ACM
25:4, April 1982, but remarkably few people seem to have heard of it --
even Simmons was surprised when I mentioned it to him.

@_date: 2007-01-10 18:31:21
@_author: Steven M. Bellovin 
@_subject: A web site that believes in crypto 
I just stumbled on a web site that strongly believes in crypto --
*everything* on the site is protected by https.  If you go there via
http, you receive a Redirect.  The site?  $ telnet  80
Trying 198.81.129.100...
Connected to Escape character is '^]'.
GET / HTTP/1.0
HTTP/1.0 301 Found Location: Connection closed by foreign host.
This has apparently been going on for a while -- see

@_date: 2007-01-13 10:26:06
@_author: Steven M. Bellovin 
@_subject: [Cryptocollectors] STU III 2500 
It appears to be a Type 2 encryptor (sensitive-but-unclassified
traffic), according to

@_date: 2007-01-14 15:31:22
@_author: Steven M. Bellovin 
@_subject: Banking Follies 
The advice may actually be correct, though of course they have a major
financial incentive to persuade you to adopt the scheme even if it
Anyway -- we're so focused in this group on the Internet that we
sometimes forget about physical world attacks.  Theft of financial data
(and financial objects, such as checks and credit cards) from physical
mailboxes (or garbage cans) is quite commonplace, and is -- according to
some -- a more significant vector for identity theft than Internet fun
and games.  The Wall Street Journal advised people to use electronic
statements for just that reason (see
also note the list at

@_date: 2007-01-16 09:32:19
@_author: Steven M. Bellovin 
@_subject: It's a Presidential Mandate, Feds use it. How come you are not 
I'll turn it around -- why should you use it?
In most situations, disk encryption is useless and probably harmful.
It's useless because you're still relying on the OS to prevent access
to the cleartext through the file system, and if the OS can do that it
can do that with an unencrypted disk.  It's harmful because you can
lose a key.  (Your web page does address that, but I'm perplexed --
what is challenge/response authentication for key recovery?)
Disk encryption, in general, is useful when the enemy has physical
access to the disk.  Laptops -- the case you describe on your page --
do fit that category; I have no quarrel with disk encryption for them.
It's more dubious for desktops and *much* more dubious for servers.
(Caveat: I'm assuming that when you dispose of systems, you run DBAN or
some such on the drives -- if not, we're back to the physical access

@_date: 2007-01-16 11:08:15
@_author: Steven M. Bellovin 
@_subject: It's a Presidential Mandate, Feds use it. How come you are  not 
On Tue, 16 Jan 2007 07:56:22 -0800
Legal access is a special case -- what is the law (and practice) in any
given country on forced access to keys?  If memory serves, Mike Godwin

@_date: 2007-01-16 11:33:46
@_author: Steven M. Bellovin 
@_subject: It's a Presidential Mandate, Feds use it. How come you are not 
On Tue, 16 Jan 2007 08:19:41 -0800
Not necessarily -- many of my systems have multiple disk drives and
file systems, some of which are on removable media.  Apart from that,
though, this is reinforcing my point -- what is the threat model?
I wouldn't call that "challenge/response", I'd call that key escrow.
Key escrow isn't a bad idea for storage encryption, but you need
*really* good authentication mechanisms for the backup channel.
Visualize this phone call to the help desk:  "Hi, I'm Pat, the CFO.
I'm in New York for the Board meeting, and my laptop blue-screened and
won't reboot -- it's not accepting my passphrase.  Help!"  Of course,
more or less by definition, Pat isn't online at that point, so the help
desk can't manipulate anything remotely.  (I should add that most
secondary authentication mechanisms I've seen are garbage, especially
when it comes to people on the road.  Since we're talking about laptops
here, that's a very serious threat.)
I don't dispute the need for FDE for (many) laptops.  But remember that
security is a systems property; it's not something you can get by
bolting on crypto.

@_date: 2007-01-16 17:03:52
@_author: Steven M. Bellovin 
@_subject: It's a Presidential Mandate, Feds use it. How come you are not 
On Tue, 16 Jan 2007 08:58:27 -0800
I don't think that that distinction is either necessary or sufficient.

@_date: 2007-01-17 14:23:07
@_author: Steven M. Bellovin 
@_subject: It's a Presidential Mandate, Feds use it. How come you are not 
On Wed, 17 Jan 2007 09:33:54 -0800
Please -- "Steve".
Does it run on NetBSD?  I don't use Windows....
My point is that I have some fairly complex operational environments.
The distinction between the "operating system" and everything else
isn't that clear.  What is part of the OS?  The kernel?  The boot
loader? (It has several parts.)  Dynamically-loaded
modules?  /sbin/init?  The shell?  My virtual machines?  The Xen
hypervisor?  (I don't yet run Xen on my laptop.  I will as soon as it
supports power management.)

@_date: 2007-01-21 00:13:09
@_author: Steven M. Bellovin 
@_subject: Private Key Generation from Passwords/phrases 
On Sat, 20 Jan 2007 18:41:34 -0600
Could you explain this?  It's late, but this makes no sense at all to
me.  Dictionary attacks work by guessing -- if the random salt is
visible to the attacker, I don't know what "more so" might mean.
Similarly, the size of the output is irrelevant; we're not talking
about cryptanalysis here.  As best I can tell, increasing the output
size and/or the salt size increases the size of a precomputed
dictionary, but that's not the only form of dictionary attack -- see M.
Bishop, ?An Application of a Fast Data Encryption Standard
Implementation,? Computing Systems 1(3) pp. 221?254 (Summer 1988), for
One sometimes sees claims that increasing the salt size is important.
That's very far from clear to me.  A collision in the salt between
two entries in the password file lets you try each guess against two
users' entries.  Since calculating the guess is the hard part,
that's a savings for the attacker.  With 4K possible salts, you'd need a
very large password file to have more than a very few collisions,
though.  It's only a benefit if the password file (or collection of
password files) is very large.
There is also some benefit if the attacker is precomputing
dictionaries, but there the size of the search space is large enough
that the salt factor isn't that important given even minimal quality

@_date: 2007-01-23 12:59:37
@_author: Steven M. Bellovin 
@_subject: Fw: NIST announces Draft Requirements and Evaluation Criteria for  
Begin forwarded message:
NIST Wants Comments on Proposed Hash Algorithm Requirements and
Evaluation Criteria
The National Institute of Standards and Technology is planning a
competition to develop one or more cryptographic hash algorithms to
augment and revise the current Secure Hash Standard (Federal
Information Processing Standard 180-2). As a first step in this
process, NIST is publishing draft minimum acceptability requirements,
submission requirements, and evaluation criteria for candidate
algorithms ( See the Federal Register Announcement on
 ), and requests public comment by
April 27, 2007.

@_date: 2007-01-23 19:46:52
@_author: Steven M. Bellovin 
@_subject: Forwarded:  Request for Comments on primality testing 
X-Mailer: QUALCOMM Windows Eudora Version 6.2.3.4
NIST received many comments when Draft FIPS 186-3 was posted for public
comment during the spring of 2006 (see Note above). Several comments
concerned the number of tests required for primality testing. In
response, NIST surveyed the latest literature available on this topic
and is providing alternatives for your consideration (see
 Please provide
comments to ebarker at nist.gov by February 23rd, 2007, inserting
_Comments on FIPS 186-3 Primality Testing_ in the subject line. NIST is
particularly interested in comments relating to the security of the new
proposal versus the values currently used in Draft FIPS 186-3.
Elaine Barker
National Institute of Standards and Technology
100 Bureau Drive, Stop 8930
Gaithersburg, MD 20899-8930

@_date: 2007-01-26 19:29:28
@_author: Steven M. Bellovin 
@_subject: Intuitive cryptography that's also practical and secure. 
Good work.  In fact, I knew days ago that you would post this...
I agree with you about intuitive cryptography.  What you're complaining
about is, in effect, "Why Johnny Can't Hash".  There was another
instance of that in today's NY Times.  In one of the court cases
stemming from the warrantless wiretapping, the Justice Department is,
in the holy name of security, effectively filing court papers with
itself -- it's depositing the "filings" in a secure facility, rather
than with the court, to protect them.  I won't go into the legal,
political, judicial, or downright bizarre aspects of this case (save to
note that one of the plaintiff's attorneys was quoted as saying
"Sometime during all of this, I went on Amazon and ordered a copy of
Kafka?s ?The Trial,? because I needed a refresher course in bizarre
legal procedures."), but one point the article mentioned is
relevant here:  how is the record preserved for a possible
appeal?  Indeed, one of the judges involved has commented on that
There's an obvious cryptographic solution, of course: publish the
hash of any such documents.  Practically speaking, it's useless.  Apart
from having to explain hash functions to lawyers, judges, members of
Congress, editorial page writers, bloggers, and talk show hosts, is
this a time you'd want to stand up before a Congressional committee and
testify that some NSA technology, i.e., SHA-512, that NIST thinks needs
replacing, is still strong enough to protect documents that concern
possible NSA misconduct?  And of course, collision attacks are
precisely the concern here.

@_date: 2007-01-28 11:52:16
@_author: Steven M. Bellovin 
@_subject: Private Key Generation from Passwords/phrases 
On Mon, 22 Jan 2007 16:57:34 -0800
Is that all in one /etc/passwd file (or the NIS equivalent)?  Or is it a
Kerberos KDC?  I note that a salt buys the defense much less in a
Kerberos environment, where capture of the KDC database lets an
attacker roam freely, and the salt simply protects other sites where
users may have used the same password.
Beyond that, 60K doesn't make that much of a difference even with a
traditional /etc/passwd file -- it's only an average factor of 15
reduction in the attacker's workload.  While that's not trivial, it's
also less than, say,  a one-character increase in average password
length.  That said, the NetBSD HMAC-SHA1 password hash, where I had
some input into the design, uses a 32-bit salt, because it's free.

@_date: 2007-01-30 21:41:08
@_author: Steven M. Bellovin 
@_subject: Intuitive cryptography that's also practical and secure. 
I don't dispute your analysis.  However, this case is not just a legal
one, it's a political issue, which is why I spoke of "editorial page
writers, bloggers, and talk show hosts".  All it will take is for
enough technically-skilled conspiracy theorists to raise the issue of
hash function collisions and NSA, and we won't hear the end of it for
decades to come.  (Did you know that President Kennedy was actually
killed by a large prime factor discovered by the CIA...?)

@_date: 2007-07-09 10:57:04
@_author: Steven M. Bellovin 
@_subject: How the Greek cellphone network was tapped. 
That's interesting -- the news just came out about Blackberry entering
the Chinese market...  See
 which (briefly) discusses
such issues.

@_date: 2007-07-19 10:10:35
@_author: Steven M. Bellovin 
@_subject: How the Greek cellphone network was tapped. 
You're an optimist.  There was the Israeli case of the tailored virus.
I haven't noticed any rush to get rid of insecure operating systems,
mailers, and word processors.  Or have a look at
and ask if that will do it.  (Department of Transportation?  Department
of Defenses, more likely, from that list of businesses...)  Today's
Wall Street Journal reported on "new" threats from ads on the Internet,
and loudly worried why ad companies and web sites weren't doing more to
filter their offerings.  But an ad is just web content, which means
that the real problem is the web browser and host OS.  Will that prompt
a switch?
We're talking about phone calls -- did all of the well-publicized
cellular eavesdropping (Prince Charles, Newt Gingrich (then a major US
politician), and more) prompt a change?  Well, there are now US laws
against that sort of phone eavesdropping gear -- a big help....
Want another example?  How many US corporations have major operations
in China?  What are the odds that the Chinese government is listening
in?  If you're uncertain, see (a) the posting on this list a few days
ago about the landing declaration about communications security devices
and yesterday's news story about email problems to China because of
apparent problems with the Great Firewall
(  None
of his seems to have affected business there.  (Nor are corporations
unaware of this; I was advising people on this close to 20 years ago.)
I agree that it will take a trigger.  I don't know what that trigger
will be, but it won't be something as simple as a proven case.  It's
hard to predict what will get enough people upset; sometimes, it's
nothing at all.  (Remember the Pentium serial number case?  Objectively,
that was a complete non-issue, but enough people got upset about it
that Intel had to back off.)
It will also have to be dead simple.  It can't happen on the POTS
network, because modem handshaking takes too long.  It can't happen on
conventional cellular unless the voice is traveling over a
clear-channel end-to-end data connection, not something that the
carrier's equipment "knows" is voice.  (There's also the question of
phone CPU access to the voice channel, per Bill Stewart's post.)  It
could happen for VoIP if done properly, as others have pointed out.  It
has to be easy to use, which means that things like PKIs are, shall we
say, obstacles.

@_date: 2007-07-21 12:56:00
@_author: Steven M. Bellovin 
@_subject: How the Greek cellphone network was tapped. 
On Sat, 21 Jul 2007 04:46:51 -0700 (PDT)
Not as I read the statute (and of course I'm not a lawyer).  Have a
look at 18 USC 2512
that the design of such device renders it primarily useful for the
So simple possession of a surreptitious interception device is illegal,
with exceptions for things like sale to law enforcement or
communications companies.
Probably -- that's not surreptitious.
The specific law I had in mind when I posted that note was the
ban on scanners capable of picking up cellular bands, as well as
decoders to convert digital cellular signals to analog.  See
and There are other provisions in the law that bar interception of
encrypted or scrambled signals, but I haven't waded through the
verbiage enough to know if they apply here.

@_date: 2007-07-21 13:48:15
@_author: Steven M. Bellovin 
@_subject: Enigma for sale on eBay 
See Bruce Schneier's blog entry
( --
it was relisted and sold for $30K.

@_date: 2007-07-30 10:50:33
@_author: Steven M. Bellovin 
@_subject: NIST documents for public review 
============================== START ==============================
X-Mailer: QUALCOMM Windows Eudora Version 6.2.3.4
NIST announces the release of draft Special Publication 800-106,
Randomized Hashing Digital Signatures. This Recommendation provides a
technique to randomize the input messages to hash functions prior to
the generation of digital signatures to strengthen security of the
digital signatures. Please submit comments to quynh.dang at nist.gov with
"Comments on Draft 800-106" in the subject line. The comment period
closes on September 17, 2007.
NIST announces the release of draft Special Publication 800-107,
Recommendation for Using Approved Hash Algorithms This Recommendation
provides guidance on using the Approved hash algorithms in digital
signatures applications, Keyed-hash Message Authentication Codes
(HMACs), key derivation functions (KDFs) and random number generators.
Please submit comments to quynh.dang at nist.gov with "Comments on Draft
800-107" in the subject line. The comment period closes on September
17, 2007.
NIST announces the release of D raft Federal Information Processing
Standard (FIPS) 198-1 Publication, The Keyed-Hash Message
Authentication Code (HMAC). The draft FIPS 198-1 is the proposed
revision of FIPS 198. The draft specifies a keyed-hash message
authentication code, a mechanism for message authentication using
cryptographic hash functions and shared secret keys. Comments will be
accepted through September 10, 2007. Comments should be forwarded to
the Computer Security Division, Information Technology Laboratory at
NIST or submitted via email to proposed198-1 at nist.gov with "Comments on
Draft 198-1" in the subject line. Click here to review the Federal
Register Notice for Draft FIPS PUB 198-1.
NIST announces the release of Draft Federal Information Processing
Standard (FIPS) 180-3 Publication, Secure Hash Standard (SHS). The
draft FIPS 180-3 is the proposed revision of FIPS 180-2. The draft
specifies five secure hash algorithms (SHAs) called SHA-1, SHA-224,
SHA-256, SHA-384 and SHA-512 which are used to condense input messages
to fixed-length messages, called message digests. These algorithms
produce 160, 256, 384, and 512-bit message digests, respectively.
Comments will be accepted through September 10, 2007. Comments should
be forwarded to the Computer Security Division, Information Technology
Laboratory at NIST or submitted via email to Proposed180-3 at nist.gov
with "Comments on Draft 180-3" in the subject line. Click here to
review the Federal Register Notice for Draft FIPS PUB 180-3.
Elaine Barker
National Institute of Standards and Technology
100 Bureau Drive, Stop 8930
Gaithersburg, MD 20899-8930

@_date: 2007-06-20 23:41:20
@_author: Steven M. Bellovin 
@_subject: Blackberries insecure? 
According to the AP (which is quoting Le Monde), "French government
defense experts have advised officials in France's corridors of power
to stop using BlackBerry, reportedly to avoid snooping by U.S.
intelligence agencies."
That's a bit puzzling.  My understanding is that email is encrypted
from the organization's (Exchange?) server to the receiving Blackberry,
and that it's not in the clear while in transit or on RIM's servers.
In fact, I found this text on Blackberry's site:
Of course, we all know there are ways that keys can be leaked.

@_date: 2007-06-25 19:48:17
@_author: Steven M. Bellovin 
@_subject: Why self describing data formats: 
The most important reason is application flexibility -- very often,
complex data structures are being passed around, and having some
format like those makes life easier.
There is some security benefit, though -- see Section 7 of Abadi
and Needham's "Prudent Engineering Practice for Cryptographic
Protocols" (1995).  (Yes, they're calling for a lot less than
full-blown ASN.1.)

@_date: 2007-06-26 21:52:46
@_author: Steven M. Bellovin 
@_subject: anti-RF window film 
A company is selling a window film that blocks most RF signals.  The
obvious application is TEMPEST-shielding.  I'm skeptical that it will
be very popular -- most sites won't want to give up Blackberry and cell

@_date: 2007-06-29 10:44:36
@_author: Steven M. Bellovin 
@_subject: Quantum Cryptography 
I'm unhappy with the tone of the discussion thus far.  It's gone far
beyond critiquing current products and is instead attacking the very
Today's cryptography is largely based on certain assumptions.  You
can't even call them axioms; they're far too weak.  Let's consider
RSA.  We *know* that no one has proven it equivalent to factoring; even
if that had been done, there is as far as I know no theoretically and
useful computational complexity bound for factoring, especially for the
average case.  Similarly, we have no proofs that discrete log is
inherently hard.  But cryptographic proofs frequently work by showing
that breaking some new construct is equivalent to solving one of these
"believed to be hard" problems.  We have a theoretically unbreakable
system -- one-time pads -- but as most of us on this list know, they're
rarely usable.
Protocols are even worse.  We can prove certain things about the
message exchanges, and we have tools to help analyze protocols.  But I
have yet to see any such mechanism that can cope with attacks that mix
protocol weaknesses with, say, number theory -- think of
Bleichenbacher's Million Message Attack (which also involved how the
protocol worked over the wire) or Simmons' Common Modulus Attack.
It's not wrong to want something better.  Sure, we think our ciphers
are secure.  The Germans thought that of Enigma and the
Geheimschreiber; the Japanese thought that of Purple.  Is AES secure?
NSA has said so publicly, but there have been technical papers
challenging that.  I've seen no technical commentary on this list on
the Warren D. Smith paper that was cited here about a week ago.
To me, QKD is indeed a very valid area for research.  It's a very
different approach; ultimately, it may prove to be useful, at least in
some circumstances.
Now -- I'm not saying that *anyone* should buy today's products.  As
has been pointed out ad infinitum, they rely on conventional
cryptographic techniques for authentication.  More seriously, they have
been subject to serious friendly attacks.  It's only recently been
mentioned prominently that the most devices don't send a single photon
per bit, and the proof of security relies on that.  There is the
limitation, possibly inherent, to a single link.  (I wonder, though,
what can be done in the future with switched optical networks.)
All that said, perhaps QKD will be useful some day.  Unauthenticated?
Diffie-Hellman is unauthenticated.  Expensive?  RSA is computationally
expensive, and in fact wasn't used very much for 10 years after its
invention.  Single link?  We still use -- and need -- link-layer
cryptography today.  Provable security?  Despite their limitations,
one-time pads are and have been used in the real world. Sometimes, the
operational and threat environments are right.  Gilmore has noted that
cryptography is a matter of economics -- and in some situations,
perhaps the economics of QKD are right.
It's very valid to criticize today's products, and it's almost
obligatory to criticize over-hyped marketing.  As I said, I don't think
today's products are useful anywhere, and the comparisons vendors draw
to conventional cryptography are at best misleading.  But let's not
throw the baby out with the bathwater.

@_date: 2007-03-12 22:33:28
@_author: Steven M. Bellovin 
@_subject: Fw: Revisions to NIST Special Publications 
Begin forwarded message:
X-Mailer: QUALCOMM Windows Eudora Version 6.2.3.4
Revisions have been made to the following NIST Special Publications,
which are available at
1.   SP 800-56A, Recommendation for Pair-Wise Key Establishment
Schemes Using Discrete Logarithm Cryptography. This revised document
is also available at The revision to this document is identified in Appendix E. It allows
the dual use of keys during certificate requests only.
2.   SP 800-57, Part 1, Recommendation for Key Management. This
revised document is also available at
 The revisions
to this document are listed in Appendix D. The latest revisions
allow the dual use of keys during certificate requests only.
3.   SP 800-90, Recommendation for Random Number Generation Using
Deterministic Random Bit Generators. This revised document is also
available at  The
revisions to this document are listed in Appendix I. These revisions
include the insertion of a step in the  Dual_EC_DRBG specification
that was inadvertently omitted that is needed for the DRBG to
provide backtracking resistance.
Elaine Barker
National Institute of Standards and Technology
100 Bureau Drive, Stop 8930
Gaithersburg, MD 20899-8930

@_date: 2007-03-23 14:59:39
@_author: Steven M. Bellovin 
@_subject: Forwarded: REMINDER - comment period on NIST's hash function 
X-Mailer: QUALCOMM Windows Eudora Version 5.1.1
NIST published a draft requirements and evaluation criteria for new
hash functions in a Federal Register notice on 1/23/2007( see
 ) . This email is a reminder that the
public comment period on these requirements and evaluation criteria
will end in five weeks on 4/27/2007. If you wish to send comments for
consideration, please send them to hash-function at nist.gov before the
deadline. In case you are not aware of it, a hash forum has been
established for dialogue on the hash function competition. An archive
of the discussions is available at
 , and
is accessible with a password. Please see
 for information about subscribing to
the forum and obtaining the password.

@_date: 2007-05-08 13:53:07
@_author: Steven M. Bellovin 
@_subject: Forwarded: Public comments on the hash algorithm requirements and 
X-Mailer: QUALCOMM Windows Eudora Version 5.1.1
Public comments on the hash algorithm requirements and evaluation
criteria (see Federal Register Notice Vol. 72, No. 14, January 23,
2007) are now available for review at
 .
For other information related to NIST's hash algorithm competition,
please visit  .

@_date: 2007-05-09 17:02:44
@_author: Steven M. Bellovin 
@_subject: More info in my AES128-CBC question 
On Wed, 9 May 2007 15:35:44 -0400
Mostly right.  RFC 2405 stated:
   Implementation note:
      Common practice is to use random data for the first IV and the
      last 8 octets of encrypted data from an encryption process as the
      IV for the next encryption process; this logically extends the CBC
      across the packets.
not as a requirement but as a hint.  On the other hand, RFC 3602 says
   The IV MUST be chosen at random, and MUST be
   unpredictable.

@_date: 2007-05-11 16:15:55
@_author: Steven M. Bellovin 
@_subject: wiretaps and encryption 
Those who remember the Crypto Wars of the 1990s will recall all of the
claims about "we won't be able to wiretap because of encryption".  In
that regard, this portion of the latest DoJ wiretap report is
The situation may be different for national security wiretaps, but of
course that's where compliance with any US anti-crypto laws are least
likely.  There was no mention of national security or terrorism-related
wiretaps in the report, possibly because they've all been done with
FISA warrants.

@_date: 2007-11-14 03:06:56
@_author: Steven M. Bellovin 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
There was a paper by Li Gong at an early CCS -- '93, I think, though it
might have been '94 -- on the number of messages different types of
authentication protocol took.  It would be a good starting point.

@_date: 2007-11-15 22:39:39
@_author: Steven M. Bellovin 
@_subject: refactoring crypto handshakes (SSL in 3 easy steps) 
On Wed, 14 Nov 2007 13:45:37 -0600
Depending on your goals, JFK has some of those properties; see

@_date: 2007-11-23 13:15:51
@_author: Steven M. Bellovin 
@_subject: Fw: [IP] Skype encryption stumps German police 
Begin forwarded message:
Begin forwarded message:
Ole J. Jacobsen
Editor and Publisher,  The Internet Protocol Journal
Cisco Systems
Tel: +1 408-527-8972   Mobile: +1 415-370-4628
E-mail: ole at cisco.com  URL: Archives: RSS Feed: Powered by Listbox:

@_date: 2007-11-27 21:46:17
@_author: Steven M. Bellovin 
@_subject: Fw: NIST announces approval of SP 800-38D specifying GCM 
Begin forwarded message:
FYI, yesterday NIST announced the approval of Special Publication
800-38D, which specifies Galois/Counter Mode (GCM), an AES mode of
operation for authenticated encryption with associated data.  GCM was
submitted to NIST by David McGrew and John Viega.  The announcement
appears on the NIST website, at  , and the URL for
the document is  .

@_date: 2007-10-02 16:37:47
@_author: Steven M. Bellovin 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
On Tue, 02 Oct 2007 15:50:27 +0200
I'd say "decrypted by the password", rather than unlocked, but that's
the right way to do it: since it permits easy password changes.  It
also lets you do things like use different AES keys for different parts
of the disk (necessary with 3DES, probably not with AES).
There was this paper on using air turbulence-induced disk timing
variations for entropy...

@_date: 2007-10-08 11:27:37
@_author: Steven M. Bellovin 
@_subject: Full Disk Encryption solutions selected for US Government use 
Out of curiousity, are any open source FDE products being evaluated?

@_date: 2007-10-08 20:17:40
@_author: Steven M. Bellovin 
@_subject: Trillian Secure IM 
On Mon, 8 Oct 2007 09:17:48 -0700
They're not required to decrypt anything unless they're providing the
keys.  The lawful intercept requirement is to deliver the ciphertext in
this case.

@_date: 2007-10-12 18:18:39
@_author: Steven M. Bellovin 
@_subject: Trillian Secure IM 
On Thu, 11 Oct 2007 21:50:06 -0700
It wasn't just brute force, it was math.
         nfscrack,   author        = {Brian A. LaMacchia and Andrew M. Odlyzko},
  journal       = {Designs, Codes, and Cryptography},
  pages         = {46--62},
  title         = {Computation of Discrete Logarithms in Prime Fields},
  volume        = {1},
  year          = {1991},
  annote        = {Describes how the authors cryptanalyzed Secure RPC.}

@_date: 2007-10-12 18:21:57
@_author: Steven M. Bellovin 
@_subject: Password hashing 
NetBSD uses iterated HMAC-SHA1, where the password is the key and the
salt is the initial plaintext.  (This is my design but not my

@_date: 2007-10-24 20:21:51
@_author: Steven M. Bellovin 
@_subject: Elcomsoft trying to patent faster GPU-based password cracker 
I hope they don't get the patent.  The idea of using a GPU for
cryptographic calculations isn't new; see, for example, "Remotely Keyed
Cryptographics: Secure Remote Display Access Using (Mostly) Untrusted
Hardware" (
Debra L. Cook, Ricardo Baratto, and Angelos D. Keromytis. In
Proceedings of the 7th International Conference on Information and
Communications Security (ICICS), pp. 363 - 375. December 2005, Beijing,
China. An older version is available as Columbia University Computer
Science Department Technical Report CUCS-050-04
December 2004.

@_date: 2007-10-30 03:43:45
@_author: Steven M. Bellovin 
@_subject: password strengthening: salt vs. IVs 
That's an IV.  I strongly suggest your read the Ritchie and Thompson
paper on the reasons for the salt.  While making sure that two
identical passwords rarely hashed to the same value, it had another
purpose: protecting against hardware attacks.  Ritchie and Thompson
assumed that there would be generic DES chips; they didn't want those
to be used in a password-cracking machine.  Accordingly, the salt was
used to permute the E-box -- not the S-boxes -- to prevent that.

@_date: 2007-09-04 19:11:07
@_author: Steven M. Bellovin 
@_subject: Neal Koblitz critiques modern cryptography. 
I interpreted it a bit differently.  In a nutshell, security is
different, for two reasons.  One is, as you note, the parameter size
issue.  There, the issue is twofold: first, that detailed analyses are
necessary, and not just worst-case bounds; second, that detailed
analyses -- though always of interest -- are a lot harder than simple
worst-case bounds.  It's the job of referees to ensure that the right
analysis appears in security papers, and not just the easy, wrong one.
The other point, though, is more subtle.  Any proof depends on your
axioms or system model.  In security, though, an attacker can often
attack via a different model.  Thus, we may have ciphers that are fine
at the 0s and 1s level but are vulnerable to things like differential
power analysis, cache timing, etc.  Even at the 0s and 1s level, did
the proof of security account for things like related-key attacks?  Mathematicians have known since Euclid that axioms are important.
Security, though, is math embedded in the real world, and that
matters.  Put another way, Euclidean geometry is completely valid as a
pure mathematical system.  But that doesn't mean it applies in a
relativistic universe.  Sure, we live far from any space-warping
masses, so we can pretend that the angles in our triangles add up to
180 degrees.  In the security world, though, the attacker will toss a
black hole at us to warp the space around our provably-secure
triangular encryptor.  Was that proof of security flawed?  Ask Riemann
or Lobachevsky.

@_date: 2007-09-06 13:43:29
@_author: Steven M. Bellovin 
@_subject: In all the talk of super computers there is not... 
On Thu, 6 Sep 2007 09:28:40 -0400 (EDT)
It's less than that.  See, for example, the bottom of the first page of
 :
The interesting question is whether or not one can effectively
enumerate candidate phrases for a guessing program.  For that problem,
punctuation and capitalization are important.

@_date: 2007-09-12 14:27:35
@_author: Steven M. Bellovin 
@_subject: Rare 17th century crypto book for auction. 
As I commented to Bruce, see what Kahn says about it:  "But the work,
while containing some cipher systems, mainly defends the occultism of

@_date: 2007-09-17 13:46:04
@_author: Steven M. Bellovin 
@_subject: open source digital cash packages 
Are there any open source digital cash packages available?  I need one
as part of another research project.

@_date: 2007-09-17 16:49:25
@_author: Steven M. Bellovin 
@_subject: using SRAM state as a source of randomness 
This is an old technique.  We could even go back to von Neumann's
scheme: look at two successive bits.  If they're equal, discard them.
Otherwise, map <0,1> to 0 and <1,0> to 1.
See the section on "Software whitening" in
 (which
was correct as of when I looked at it, a few minutes before the
timestamp on this email; check the Wiki history to be sure....).

@_date: 2007-09-19 16:46:03
@_author: Steven M. Bellovin 
@_subject: OK, shall we savage another security solution? 
If done properly -- i.e., with cryptographic protection against new
firmware or policy uploads to it -- it's immune to host or user
compromise as a way to disable the filter.

@_date: 2008-04-16 16:41:04
@_author: Steven M. Bellovin 
@_subject: Still locked up Shannon crypto work? 
I've heard that there were some patent applications with secrecy
orders. though I thought those were release by the late 1980s.

@_date: 2008-04-30 17:45:02
@_author: Steven M. Bellovin 
@_subject: privacy expectations Was: SSL and Malicious Hardware/Software 
On Wed, 30 Apr 2008 12:49:12 +0300 (IDT)
The actual opinion is much more nuanced and case-specific.  In the
first place, it demonstrated that the actual culture at that site was
very different.  In particular, the administrator testified that "it
was general policy to avoid examining e-mails and their content
because it was a 'privacy issue'."  The court might well have ruled
differently were that not the case.
Second, the court noted that the suspected misconduct was (a) for
evidence of illegal behavior, and (b) unrelated to workplace misconduct.
And the banner wasn't specific enough: "The banner in the instant case
did not provide Apellee with notice that she had no right of privacy.
Instead, the banner focused on the idea that her use of the system may
be monitored for limited purposes."
In addition, because the employer in this case was the government,
constitutional protections come into play, in a way that would not
apply to a private sector employer.  The reasoning there is complex,
especially since we're talking about the military (and soldiers have
many fewer rights than do civilians), so I won't try to summarize it;
let it suffice to say that generalizing from that case to an ordinary
workplace environment is not simple.
To sum up -- the court ruling in this particular case was very specific
to the facts of the case.  It's far from clear that it's generally

@_date: 2008-08-10 10:06:49
@_author: Steven M. Bellovin 
@_subject: Judge approves TRO to stop DEFCON presentation 
And the vulnerability assessment they prepared -- filed by the MBTA in
court, and hence a matter of public record -- is at

@_date: 2008-08-18 11:34:41
@_author: Steven M. Bellovin 
@_subject: Fw: NIST Documents Available for Review 
Begin forwarded message:
NIST revised the first drafts of Special Publication(SP) 800-106,
Randomized Hashing for Digital Signatures, and SP 800-107,
Recommendation for Applications Using Approved Hash Algorithms after
receiving great comments from many public and private individuals and
organizations. The second drafts of these two SPs have been posted at
 The deadlines for
public comments and the point-of-contact are listed with the documents. NIST also would like to announce that FIPS 198-1 has already been
approved and it is posted at

@_date: 2008-08-19 20:12:57
@_author: Steven M. Bellovin 
@_subject: "Cube" cryptanalysis? 
Greg, assorted folks noted, way back when, that Skipjack looked a lot
like a stream cipher.  Might it be vulnerable?

@_date: 2008-08-27 12:12:11
@_author: Steven M. Bellovin 
@_subject: Decimal encryption 
Do you want a stream cipher or a block cipher?  For the former, it's
easy.  Use something like rc4, which produces a sequence of keystream
bytes.  Retrieve the low-order N bits from each key stream byte, where N
is large enough for the base you're using.  If the value is greater
than or equal to the base you're using, discard that byte and try
again.  For your example, you'd use the low-order 4 bits, but discard
any bytes whose value is >= 10.  Add this value, discarding the carry,
to the digit to be encrypted.
You're running RC4 at 5/8 efficiency; unless you have a *lot* of data,
that almost certainly doesn't matter.

@_date: 2008-08-27 12:16:23
@_author: Steven M. Bellovin 
@_subject: road toll transponder hacked 
There's a limit to how far they can go with that, because of the fear
of people abandoning the transponders.  For example -- they absolutely
will not use it for automated speeding tickets on, say, the NJ
Turnpike, because if they did people would stop using their EZPasses.
Given what a high percentage of drivers use them, especially at rush
hour, they make a significant improvement in throughput and safety at
toll plazas.  On congested roads, throughput is *extremely* important.
As for usage-based driving -- the first question is the political will
to do so.  In NYC, there's been tremendous resistance to things like
tolls over the East River bridges or congestion charges for driving
into much of Manhattan during the business day -- the Mayor tried very
hard, but was unable to push it through the state legislature.  That
said, I've seen some papers on how use of these transponders has
desensitized people towards the actual tolls they pay, and hence to
toll increases.
Finally, the transponders may not matter much longer; OCR on license
plates is getting that good.  As has already been mentioned, the 407
ETR road in Toronto already relies on this to some extent; it won't be
too much longer before the human assist is all but unneeded.

@_date: 2008-08-27 16:19:58
@_author: Steven M. Bellovin 
@_subject: Decimal encryption 
Also see Debra Cook's PhD dissertation on Elastic Block Ciphers at

@_date: 2008-08-28 09:16:48
@_author: Steven M. Bellovin 
@_subject: road toll transponder hacked 
On Thu, 28 Aug 2008 10:49:20 +0200
How well does that actually work?  There were many articles in RISKS
Digest about problems with the early deployment.
And -- turning the topic back to crypto -- is there a cryptographic
solution to license plates?  Put another way, what are the legitimate
needs of various parties, and can these be satisfied in a
privacy-preserving way?  (Note: I do not regard "put a digital cash
wallet in the transponder" as a solution to the license plate problem,
since it doesn't handle the problem of toll evaders, people who aren't
members of the system, and many other things that license plates are
used for.)

@_date: 2008-08-28 11:58:24
@_author: Steven M. Bellovin 
@_subject: road toll transponder hacked 
On Thu, 28 Aug 2008 17:55:57 +0200
I confess that from a privacy perspective, I'd prefer if it didn't work
that well...

@_date: 2008-08-29 21:34:07
@_author: Steven M. Bellovin 
@_subject: Origin of the nomenclature "red-black"? 
Does anyone know where and when the use of "red" (inside networks) and
"black" (outside, encrypted networks for crypto gear) started?  I'm
especially intrigued by the use of "red", since in other military
nomenclature (in the US) blue is the usual color for US and friendly
forces and red is (for obvious geopolitical reasons) the enemy.
One hypothesis I've come up with is that the color was chosen by the
British from the so-called "all-red route" -- the web of underseas
telegraph links that touched only Britain and its colonies.  It was
named for the usual map color of the time (~100 years ago) for the
British empire.  The all-red route gave the British protection against
(some) foreign eavesdropping; it was also useful offensively, since the
1920 Official Secrets Act contained a provision requiring cable
companies to turn over copies of all telegrams to the government.
(Source: "The Invisible Weapon: Telecommunications and International
Politics, 1851-1945", by Daniel R. Headrick, Oxford University Press,

@_date: 2008-12-15 13:38:25
@_author: Steven M. Bellovin 
@_subject: CPRNGs are still an issue. 
In my copious spare time, I've entertained thoughts of writing a FIPS
181 pronounceable password generator for the iPhone, using the
accelerometer for randomness.  The thought of shaking my phone to
produce a password amuses me...

@_date: 2008-12-17 15:18:36
@_author: Steven M. Bellovin 
@_subject: CPRNGs are still an issue. 
But what is the *physical basis* for the randomness?
 (full text
at  explains why hard drive
timings are considered random; are their comparable phenomena for SSDs?
(Of course -- that's a '94 paper; hard drive technology has changed a
lot.  Would they still get the same results?)

@_date: 2008-12-27 12:33:37
@_author: Steven M. Bellovin 
@_subject: two bits of light holiday reading 
I disagree with a number of recommendations in that report; some of the
ones about identity management are high on my list.  See
 for my

@_date: 2008-12-30 11:27:24
@_author: Steven M. Bellovin 
@_subject: Fw: [saag] Further MD5 breaks: Creating a rogue CA certificate 
Begin forwarded message:
MD5 considered harmful today
Creating a rogue CA certificate
December 30, 2008
Alexander Sotirov, Marc Stevens,
Jacob Appelbaum, Arjen Lenstra, David Molnar, Dag Arne Osvik, Benne de
We have identified a vulnerability in the Internet Public Key Infrastructure (PKI) used to issue digital certificates for secure websites. As a proof of concept we executed a practical attack scenario and successfully created a rogue Certification Authority (CA) certificate trusted by all common web browsers. This certificate allows us to impersonate any website on the Internet, including banking and e-commerce sites secured using the HTTPS protocol.
Our attack takes advantage of a weakness in the MD5 cryptographic hash function that allows the construction of different messages with the same MD5 hash. This is known as an MD5 "collision". Previous work on MD5 collisions between 2004 and 2007 showed that the use of this hash function in digital signatures can lead to theoretical attack scenarios. Our current work proves that at least one attack scenario can be exploited in practice, thus exposing the security infrastructure of the web to realistic threats.
saag mailing list
saag at ietf.org

@_date: 2008-12-30 11:45:27
@_author: Steven M. Bellovin 
@_subject: very high speed hardware RNG 
Of course, every time a manufacturer has tried it, assorted people
(including many on this list) complain that it's been sabotaged by the
NSA or by alien space bats or some such.
It's not obvious to me that you're right.  In particular, we need to
consider how such an instruction would interact with a virtual machine
hypervisor.  Is it a bug or a feature that the hypervisor can't
intercept the request?  Remember that reproducibility is often a virtue.
The JVM could just as easily open /dev/urandom today.

@_date: 2008-02-01 19:58:16
@_author: Steven M. Bellovin 
@_subject: Dutch Transport Card Broken 
The big issue is prompting the user for a password in a way that no one
will confuse with a web site doing so.  Given all the effort that's
been put into making Javascript more and more powerful, and given
things like picture-in-picture attacks, I'm not optimistic.   It might
have been the right thing, once upon a time, but the horse may be too
far out of the barn by now to make it worthwhile closing the barn door.

@_date: 2008-02-06 18:43:19
@_author: Steven M. Bellovin 
@_subject: Gutmann Soundwave Therapy 
Some years ago, I did a crypto design for a potential product.  As best
we could figure it, the extra overhead for a standard mechanism versus
a custom one was greater than the profit margin for this product.

@_date: 2008-02-07 05:42:00
@_author: Steven M. Bellovin 
@_subject: Dutch Transport Card Broken 
There's another issue: initial account setup.  People will still need
to rely on certificate-checking for that.  It's a real problem at some
hotspots, where Evil Twin attacks are easy and lots of casual users are
signing up for the first time.

@_date: 2008-02-15 03:19:58
@_author: Steven M. Bellovin 
@_subject: Toshiba shows 2Mbps hardware RNG 
Leaving aside whether or not your scenarios make sense, why must this
be done via a hardware RNG?
I ran 'openssl speed aes' on a 3.4 Ghz single-core Pentium.  On 16-byte
blocks with AES-128 -- i.e., running AES in counter mode to generate
128-bit keys -- it ran at about 3.4M encryptions/second.  That's more
than two orders of magnitude better than you say is needed.  Why do I
need hardware?
Hardware RNGs are great for producing initial seeds.  They're also
great for producing new randomness to stir into the pot (i.e., via
something like Yarrow).  But they're lousy for ongoing work because
they're relatively low assurance.
As others have noted, software has a big advantage: it's
deterministic.  Once you know its working, you have much higher
assurance that it will continue to work the same way.  (Aside: I know
quite a bit about the problem of certifying complex software.  A
cryptographically strong PRNG doesn't fall into that category if you
have confidence in the algorithm.)  Remember the Clipper chip?
According to Dorothy Denning, the escrowed keys -- that is, the entire
security of the basic scheme -- was generated by several applications of
the Skipjack, the underlying block cipher -- see
 for details.  (Note:
that statement was later disavowed.  I'm not sure I believe the
disavowal; it looked secure to me.)

@_date: 2008-02-26 05:06:47
@_author: Steven M. Bellovin 
@_subject: cold boot attacks on disk encryption 
On Thu, 21 Feb 2008 13:37:20 -0800
Briefly, there's a bit in the TPM that means "there are keys present;
zero RAM when booting".  This does nothing against the guy with the
Dewar flask of liquid nitrogen, of course.

@_date: 2008-01-02 21:38:53
@_author: Steven M. Bellovin 
@_subject: Death of antivirus software imminent 
~~20 years ago, after the Internet Worm, I went and reread the Orange
Book.  I concluded, to my horror, that *nothing* in it, including an
A1-rated system, would have stopped the worm from spreading.  Being
rather new to the theoretical security game (though I'd caught my first
hackers around 1971), I asked someone older and wiser.  "Oh, no; a B2
system would have prevented it."  I asked how.  "B2 requires a thorough
search for bugs."
Worms and viruses have essentially nothing to do with the operating
system.  As long as whatever context the vulnerable application is run
in -- the mailer, the browser, the word processor, whatever -- can
write to the network or to a file, the malware can spread.
Another approach is to run such things at a lower privilege level.
(Vista does that with IE7.)  The problem is that you sometimes have to
cross the barrier; that's another way the malware can spread.
Cryptography provides authentication and integrity.  It does not
provide authorization, nor does it provide protection against bugs.
Your suggested approach -- better OS and better crypto -- is exactly
what's failed for the last 25 years.
If you included all applications as part of the OS, you'd be right --
except that it isn't possible to secure such a code base.

@_date: 2008-01-03 23:23:33
@_author: Steven M. Bellovin 
@_subject: Death of antivirus software imminent 
Right -- remember Spaf's famous line about how using strong crypto on
the Internet is like using an armored car to carry money between
someone living in a cardboard shack and someone living on a park bench?
Crypto solves certain problems very well.  Against others, it's worse
than useless -- "worse", because it blocks out friendly IDSs as well as
hostile parties.

@_date: 2008-01-04 22:54:45
@_author: Steven M. Bellovin 
@_subject: Fw: SHA-3 API 
Forwarded with permission.
This is part of a discussion of the proposed SHA-3 API for the NIST
competition.  Those interested in discussing it should subscribe to the
list; see  for
Begin forwarded message:
Dear Larry Bassham --
Since you indicated that you might be producing a revised
API for the SHA-3 submissions, here are some suggestions and
thoughts for your consideration:
(1) Make hashState totally opaque.
     In other words, eliminate the requirement to include
     a field "hashbitlen".  While an implementation presumably
     includes such a field, there is no need that I can see
     for standardizing its name and making it a requirement.
(2) Measure all input to be hashed in bytes, not bits.
     While the theoretical literature on hashing measures
     lengths in bits, in practice all data is an integral
     number of bytes.  That is, theory uses base-2, practice
     uses base-256.  I have never seen an application that
     cared about hashing an input that was not an integral
     number of bytes.
     An application that really needs bit-lengths for hashing
     can apply the "standard" transformation to the data first:
     always append a 1-bit, then enough 0-bits to make the data
     an integral number of bytes.
     I think that using a bit-length convention for the standard
     input will cause errors, as callers are likely to forget
     multiplying the input chunk length by 8.  This will cause
     the wrong result, but it will be undetectable---only 1/8 of
     the data will be hashed.  A security vulnerability will be
     created, as it will no longer be collision-resistant...
     I think the risk of application-level mistakes in this manner
     outweighs the (non-existent) need for bit-lengths on inputs.
(3) Eliminate the "offset" input to the Update function.
     First of all, it is too short, if you are going to admit
     inputs of 2**64 bits.
     But more importantly, there is no understandable need for
     such an input.
     I don't think you are contemplating giving the inputs
     out-of-order.  If this is to support parallel implementations
     somehow, you would need other functions, beyond Update, to
     combine the hash results for various portions of the input.
     Thus, the offset is merely the sum of the previous datalen
     values, and can be kept by the hash function implementation
     internally in hashState.
     Best to eliminate it.
(4) Make datalen a 64-bit input to Update.
     I think you need to "bit the 64-bit bullet" and insist that
     all C implementations support 64-bit data values, particularly
     when you have inputs that may often be larger than 2*32 bits
     (or 2**32 bytes, even).  Your SHA-1 example on page 4 of the
     proposed API breaks for long inputs.
     Having an int parameter here is another place where users may
     have errors, when they don't realize that their inputs may be
     exceeding the int length bound.  We shouldn't build in hazards
     for the unwary into the API.
(5) Make it clear what kinds of "endian-ness" should be supported.
     While the inputs are supplied as byte-strings, implementations
     may immediately copy these over into words for processing.
     What are the possibilities that an implementation needs to
     handle for endian-ness during this copying?  Big/little endian-ness
     within 16/32/64 bit words?
(6) Make it clear that threads are not allowed in reference
     implementation.
     You stated that the standard implementation should not
     make use of available parallelism on the reference platform.
Ron Rivest

@_date: 2008-01-06 17:09:43
@_author: Steven M. Bellovin 
@_subject: DRM for batteries 
Correct.  In a similar case, Lexmark sued a maker of print cartridges
under the DMCA.  Lexmark lost in the Court of Appeals and the Supreme
Court declined to hear the case.  See
 and

@_date: 2008-01-07 01:57:46
@_author: Steven M. Bellovin 
@_subject: DRM for batteries 
On Sun, 6 Jan 2008 17:23:56 -0800
It's worth reading the actual opinion of the Appeals Court.  (Legal
note: this opinion is only binding in the Sixth (U.S.) Circuit; the
Supreme Court declined to hear Lexmark's appeal, so no national
precedent was set.)  The Court had many reasons for rejecting the DMCA
part of the argument.  Among other things, they held that the
copyrighted work -- the printer software -- wasn't protected against
copying, and that the purpose of the DMCA was to protect works against
*copying*.  They held that the copyrighted code in question -- the
firmware in the printer -- was "used" by people trying to print things,
rather than by the print cartridge, and that access to the protected
work was gained by buying a printer, not by buying a print cartridge.
There are a lot more nuances than that in the opinion; I suggest that
folks read it.  For now, let it suffice to say that the DMCA bars
circumvention of mechanisms that protect copyrighted material; it does
not bar circumvention of access control mechanisms that protect other
things.  (I also fear that a clever, technically-minded lawyer could
design a print cartridge that would work around the Court's ruling.)

@_date: 2008-01-14 22:49:07
@_author: Steven M. Bellovin 
@_subject: Death of antivirus software imminent 
On Fri, 11 Jan 2008 17:32:04 -0800
You've given a wish list but you haven't explained why you think it
will happen.  The US government walked away from the issue years ago,
when the Clipper chip effort failed.  Even post-9/11, the Bush
administration chose not to revisit the question.
The real issue, though, is technical rather than political will.  CALEA
is a mandate for service providers; key escrow is a requirement on the
targets of the surveillance.  The bad guys won't co-operate...

@_date: 2008-01-15 15:37:02
@_author: Steven M. Bellovin 
@_subject: US drafting plan to allow government access to any email or Web 
I believe the proper URL is
(and as best I can tell, it doesn't require a WSJ subscription for

@_date: 2008-01-18 17:09:54
@_author: Steven M. Bellovin 
@_subject: Emissions security 
(for those of you who
don't take TEMPEST seriously)

@_date: 2008-01-23 04:21:29
@_author: Steven M. Bellovin 
@_subject: SSL/TLS and port 587 
This is old news.  But what's your threat model?
Clearly, hop-by-hop encryption, be it port 587 to your ISP's submission
server or pop3s/imaps by the recipient to his/her mail server does
nothing to protect against someone who has hacked the server.  I wrote
about that years ago; see
 (which archive.org
dates to April 1999, under my old AT&T URL), and I don't claim the
insight was novel even then.  Port 587 was defined in RFC 2476, from
1998; it specifically talks about the need for encryption.  SMTP-AUTH is
defined in RFC 2487 (Jan 1999 -- again, before my page), which
specifically warns that TLS protection of the channel isn't sufficient
against some threats.  (Aside: my page was prompted by someone on a
sensitive internal project who asked if he should encrypt his email.
After poking around a bit, I used xmessage to pop up a message on his
screen saying that there wasn't much point to encryption unless he
cleaned up a lot of other security issues...)  But note that the logic
applies about as well to end-to-end encryption, if your attacker can
hack the machine at either end.  By hack I specifically include "black
bag jobs" to plant a keystroke logger or the like.
So -- is encryption, whether hop-by-hop or end-to-end, useless?  No, of
course not.  Encrypting email submission or retrieval is very useful if
you use, say, wireless hotspots.  (Caveats and cautions here are left
as an exercise for the reader.)  End-to-end encryption guards against
rogue administrators of mail servers.  Neither protects against all
threats -- but both have their uses.
"Amateurs talk about algorithms; pros talk about economics."

@_date: 2008-01-23 15:00:50
@_author: Steven M. Bellovin 
@_subject: SSL/TLS and port 587 
On Tue, 22 Jan 2008 21:49:32 -0800
Please justify this.  Email stored at the ISP is protected in the U.S.
by the Stored Communications Act, 18 USC 2701
(  While it's not a
well-drafted piece of legislation and has been the subject of much
litigation, from the Steve Jackson Games case
( to Warshak v. United States
( I don't
see how you can say stored email isn't protected at all.

@_date: 2008-01-23 16:45:31
@_author: Steven M. Bellovin 
@_subject: SSL/TLS and port 587 
On Wed, 23 Jan 2008 08:10:01 -0800
You're confusing two concepts.  "Warrants" apply to government
behavior; terming something a "wireless wiretap" carries the clear
implication of government action.  Private action may or may not
violate the wiretap act or the Stored Communications Act, but it has
nothing to do with warrants.
Since the Councilman case took place several years before I started my
blog, it's hardly surprising that I didn't blog on it.  And it turns out
that Councilman -- see  for a
summary -- isn't very interesting any more.  The original district
court ruling, upheld by three judges of the Court of Appeals,
significantly weakened privacy protections for email.  It was indeed an
important and controversial ruling.  However, case was reheard en banc;
the full court ruled that the earlier decisions were incorrect, which
left previous interpretations of the wiretap law intact.  As far as I
can tell, it was never appealed to the Supreme Court.  (The ultimate
outcome, which isn't very interesting to this list, is discussed in
You are, of course, quite correct that ISP terms of service need to be
read carefully.

@_date: 2008-01-24 05:38:55
@_author: Steven M. Bellovin 
@_subject: Typex 
A knowledgeable colleague (but who is nevertheless not a crypto expert)
thinks he's seen something about Typex (the WW II British rotor
machine) having been cracked.  Does anyone know anything about that?  A
quick Google found nothing of the sort, but did find references showing
that it was used as late as 1970.

@_date: 2008-01-29 22:47:41
@_author: Steven M. Bellovin 
@_subject: US reforming export controls 
The Bush administration is reforming the way export controls are
administered; see
It's too soon to know if crypto will be affected; certainly, it's
something to watch.

@_date: 2008-01-30 03:51:22
@_author: Steven M. Bellovin 
@_subject: Dutch Transport Card Broken 
OPs deliberately elided.
This posting (and several others in this thread) disturb me.  Folks on
this list and its progenitors have long noted that cryptography is a
matter of economics.  That is, cryptography and security aren't
absolute goals; rather, they're tools for achieving something else.
The obvious answers in this case are "prevent fare fraud" or "make
money", and even those would suffice.  However, there are other issues
less easily monetized, such as "make the trams and buses run
A security system doesn't have to be perfect.  Rather, it has to be
good enough that you save more than you lose via the holes, including
the holes you know about up front.  Spending more than you have to is
simply bad engineering.  Speaking as an engineer, rather than as a
scientist, the real failure mode is too high a net loss.  As a
cryptographer and security guy, I'd rather there were no loss -- but
that's not real.
A transit system has to move people.  For all that the New York City
Metrocard works, it's slower than a contactless wireless system.  How
much longer will it take people to board trams with a stripe reader
than with a contactless smart card?  What is your power budget (which
affects range)?  Even leaving out the effect that delays have on
ridership, a transit system that wants to move N people needs more
units if the latency per rider is above a certain threshold.
Let's take a closer look at the New York system, since it was touted as
superior.  It's optimized for subways, not buses, which has several
implications.  (Subway ridership in New York is twice bus
ridership -- see
First, subway turnstiles are much more easily used as part of an online
system than are bus fare card readers.  The deployment started in 1994,
when cellular data simply wasn't an option, based on cost, bandwidth,
availability, and much more.  Second, on a subway you use your fare
card well in advance of boarding; there is thus little latency effect
on the system.  Third, wireless is *still* faster -- according to some
reports (
the MTA is considering replacing the current system with a wireless one.
Online systems have another issue: they require constant communication
to a high-availability server.  When that's not an option (i.e., New
York buses, or subway turnstiles when the server is down), the system
has to fall back to some other scheme.  This scheme is more restrictive,
precisely because of the fraud issue.   Back when I was in high school,
some students got bus passes.  I recall a frequent sight: those who had
boarded early moving to the back of the bus and handing their passes to
other students still waiting to board the bus.  Replay worked well
against an overloaded driver...  Metrocards don't have that failure
mode -- but the failure mode they do have is a limitation on how many
times they can be used in a short time interval.  This affects, for
example, a family of five or more trying to travel on a single card,
even on subways.  How much of this applies to the Dutch farecards?  I have no idea.  But
this group is trying to *engineer* a system without looking at costs
and other constraints.  That leads to security by checklist, an
all-too-common failing.
Systems like this have two primary failure modes -- "failure" in the
sense of losing more money (or time, or what have you) than
anticipated.  First, the designers may not have understood the
available technology and its limitations.  That was certainly the case
with WEP; I suspect it's the case here, but I don't know.  Even so, it
is far from clear that exploitation of the hole will have an economic
impact; that's as much a sociological question as a technical one.
(Maybe the incremental cost per card of better crypto is ?.01.  One
web site I found put tram ridership in Amsterdam at >1,000,000/year
( which means
that the cost might be ?10,000/year.  How many riders will try to cheat
the system?  Enough that to be an issue?  I don't know -- but that's
precisely my point; I don't know and I doubt very much that most other
posters here know.  That said, I do suspect that stronger crypto would
be economical.)
The second failure mode comes from misunderstanding the threat model.
That's why the old American AMPS cellular phones were subject to
cloning attacks.  It was *not* that the designers didn't anticipate the
problem; they understood perfectly well that something sent in the
clear over radio waves could be intercepted and replayed.  However,
they made three mistakes.  They overestimated the expertise necessary
to exploit the attack (it turned out that test gear was cheap enough
that small businesses could get into the cloning market), they
drastically underestimated how many cell phones would exist (they saw
them as toys for high-level executives and the like, which was false
even by 1990), and they didn't understand why people would want to buy
cloned phones.  (If you think it was to save money, you're just as
wrong as they were -- they assumed that that was the issue, and that
declining costs would prevent the market from taking root.  That wasn't
it at all.)  Given the petty crime rate in, say, Amsterdam, I suspect
that the designers of this system do understand the threat model,
though of course I (and/or they) could be as wrong as the AMPS
As a cryptographer, I'm amused and offended by the design error in the
Dutch system.  As an engineer, though, I want to see some cost
projections before I say how badly they're wrong.  And as an observer
of the human condition and a practical security guy, I'm curious what
the actual loss rate will be due to technical factors, as opposed to
pickpockets, turnstile jumping, and the like.
To replay the line I used a few days ago, "Amateurs talk about
algorithms; pros talk about economics."  (I was asked where that came
from.  I'm told that it's a saying but I don't know that

@_date: 2008-07-01 19:47:16
@_author: Steven M. Bellovin 
@_subject: Strength in Complexity? 
No, no one competent would deliberately opt for complexity.  However,
there's a quote I've seen attributed to Einstein to remember:
"Everything should be as simple as possible, but no simpler."
Sometimes, extra complexity is due to the need to deflect certain
attacks, such as replays and cut-and-paste.  It's quite possible that
the original, simpler design isn't resistant to some threats, either
because the designers weren't aware of them or because they felt that
they weren't credible in their environment.  Without more details than
are in the article (and I don't have the time or energy to read through
those documents), it's hard to say.  I did see one possible red flag in
the article: "the key server verifies the client request, then
encrypts, digitally signs, and escrows the key in a database".
Escrowed keys are potentially *very* dangerous, but without knowing
just what's being stored and how it's being protected, I can't say more.

@_date: 2008-07-05 14:02:24
@_author: Steven M. Bellovin 
@_subject: Upper limit? 
There are limits, but they're not particularly important.
I'll oversimplify.  Roughly speaking, a 1024-bit RSA public key is the
product of two 512-bit primes.  According to the Prime Number Theorem,
the number of primes < n is approximately n/log(n).  Actually, what we
need is the number of primes >2^511 and <2^512, but that correction
doesn't make much differences -- work through the math yourself to see
that.  Call the number of such primes P.
Now, we need two such primes.  There are therefore P^2 pairs, more than
2^1000.  The numbers are very much larger for 2048- and 4096-bit keys,
but I'll leave those as an exercise for the reader.

@_date: 2008-07-09 11:18:10
@_author: Steven M. Bellovin 
@_subject: Kaminsky finds DNS exploit 
I'm curious about the details of the attack.  Paul Vixie published the
basic idea in 1995 at Usenix Security

@_date: 2008-07-14 10:52:42
@_author: Steven M. Bellovin 
@_subject: Kaminsky finds DNS exploit 
Right.  There's a common misconception, on both security and network
operator mailing lists, that DNS servers use TCP only for zone
transfers, and that all such connection requests should be blocked.
See, for example, the NANOG thread starting at

@_date: 2008-07-29 13:07:50
@_author: Steven M. Bellovin 
@_subject: "The American Black Chamber" 
I was in my local Large Chain Bookstore last night, glancing at the
history and military history sections.  I was rather surprised to see
Yardley's "The American Black Chamber" for sale -- it's a facsimile
edition published by the Naval Institute Press.  It would have been
nice if they'd added a modern preface or afterword; even without that,
it's a good volume to have around.

@_date: 2008-07-30 13:27:56
@_author: Steven M. Bellovin 
@_subject: Fw: FIPS 198-1 announcement 
Begin forwarded message:
The National Institute of Standards and Technology (NIST) is pleased to announce approval of Federal Information Processing Standard(FIPS) Publication 198-1, The Keyed-Hash Message Authentication Code (HMAC), a revision of FIPS 198. The Federal Register Notice (FRN) of the approval is available here. The FIPS specifies a mechanism for message authentication using cryptographic hash functions in Federal
information systems.
URL to the Federal Register Notice:  URL to the FIPS Publication 198-1:

@_date: 2008-06-09 10:59:54
@_author: Steven M. Bellovin 
@_subject: A call for aid in cracking a 1024-bit malware key 
According to
some new malware is encrypting files with a 1024-bit RSA key.  Victims
are "asked" to pay a random to get their files decrypted.  So -- can
the key be factored?

@_date: 2008-06-11 16:04:39
@_author: Steven M. Bellovin 
@_subject: A call for aid in cracking a 1024-bit malware key 
To put it mildly.  They can can even set up sophisticated structures to
have lots of keys.
Let's put it like this: suppose you wanted to use all of your
cryptographic skills to do such a thing.  Do you think it could be
cracked?  I don't...
Btw -- see  for more details.

@_date: 2008-06-12 21:53:54
@_author: Steven M. Bellovin 
@_subject: Mystery on Fifth Avenue 
Off-topic, but (a) some crypto stuff, and (b) I think this group will
appreciate it:

@_date: 2008-03-15 22:30:18
@_author: Steven M. Bellovin 
@_subject: RNG for Padding 
Maybe -- but you probably have enough guessable plaintext elsewhere
that a bit more simply doesn't matter much.  See, for example, my 1997
paper "Probable Plaintext Cryptanalysis of the IP Security Protocols,"

@_date: 2008-03-20 01:56:49
@_author: Steven M. Bellovin 
@_subject: Protection for quasi-offline memory nabbing 
I've been thinking about similar issues.  It seems to me that just
destroying the key schedule is a big help -- enough bits will change in
the key that data recovery using just the damaged key is hard, per
comments in the paper itself.

@_date: 2008-03-26 17:20:21
@_author: Steven M. Bellovin 
@_subject: How is DNSSEC 
On Fri, 21 Mar 2008 08:52:07 +1000
You might want to look at RFC 3445 and draft-iab-dns-choices-05.txt.
As for DNSSEC keys -- DNSSEC is for securing the DNS.  Once you've done
that, you can put other records in the DNS, but there are some subtle
points in DNS RR design that should be heeded.

@_date: 2008-05-02 23:50:56
@_author: Steven M. Bellovin 
@_subject: SSL and Malicious Hardware/Software 
Assorted user studies suggest that most users do not notice the color
of random little windows in their browsers...

@_date: 2008-05-03 23:35:00
@_author: Steven M. Bellovin 
@_subject: User interface, security, and "simplicity" 
There's a technical/philosophical issue lurking here.  We tried to
solve it in IPsec; not only do I think we didn't succeed, I'm not at
all clear we could or should have succeeded.
IPsec operates at layer 3, where there are (generally) no user
contexts.  This makes it difficult to bind IPsec credentials to a user,
which means that it inherently can't be as simple to configure as ssh.
Put another way, when you tell an sshd whom you wish to log in as, it
consults that user's home directory and finds an authorized_keys file.
How can IPsec -- or rather, any key management daemon for IPsec -- do
that?  Per-user SPDs?  Is this packet for port 80 for user pat or user
I can envision ways around this (especially if we have an IP address
per user of a system -- I've been writing about fine-grained IP address
assignment for years), but they're inherently a lot more complex than

@_date: 2008-05-06 15:22:58
@_author: Steven M. Bellovin 
@_subject: User interface, security, and "simplicity" 
On Sun, 04 May 2008 11:22:51 +0100
The problem is more on the server end.

@_date: 2008-05-06 15:40:46
@_author: Steven M. Bellovin 
@_subject: User interface, security, and "simplicity" 
On Sat, 03 May 2008 19:50:01 -0400
So here's an interesting experiment.  Part one: Take a common IPsec
implementation -- Linux, *BSD, Windows, what have you.  Assume this
common scenario: laptop connecting to a corporate server.  Assume a
user authentication credential.  (I'd prefer that that be a public/
private key pair, for many reasons, not the least of which is the bug
in IKEv1 with main mode and shared secrets.)  Do not assume a 1:1 ratio
between laptops and internal IP address, because such servers are
frequently underprovisioned.  Challenge: design -- and implement -- a
*simple* mechanism by which the client user can set up the VPN
connection, both on the client and on the server.  This part can
happen while the client is physically on the corporate net.  Variant A:
the VPN server is a similar box to which the client has login-grade
access. Variant B: the VPN server is something like a restricted-access
Cisco box, in which case a trusted proxy is probably needed.  User
setup should be something like 'configvpn cs.columbia.edu', where I
supply my username and authenticator.  User connection should be
'startvpn cs.columbia.edu' (or, of course, the GUI equivalent); all I
supply is some sort of authenticator.  Administrator setup should be a
list of authorized users, and probably an IP address range to use
(though having the VPN server look like a DHCP relay would be cool).
Experiment part two: implement remote login (or remote IMAP, or remote
Web with per-user privileges, etc.) under similar conditions.  Recall
that being able to do this was a goal of the IPsec working group.
I think that part one is doable, though possibly the existing APIs are
incomplete.  I don't think that part two is doable, and certainly not
with high assurance.  In particular, with TLS the session key can be
negotiated between two user contexts; with IPsec/IKE, it's negotiated
between a user and a system.  (Yes, I'm oversimplifying here.)

@_date: 2008-05-13 12:45:08
@_author: Steven M. Bellovin 
@_subject: [ROS] The perils of security tools 
I was going to post something similar.  I maintain several pkgsrc
packages ( while most upstream maintainers are
happy to receive bug fixes, others range from indifferent to downright
hostile.  For example, I once reported a portability bug to a
developer: POSIX standards *require* that a certain system call reject
out-of-range arguments, and NetBSD enforces that check.  The Linux
kernel (or rather, the kernel of that time; I haven't rechecked lately)
did not.  Fine -- a minor standards issue with Linux.  But the
application I was adding to pkgsrc relied on the Linux behavior and the
developer angrily rejected my fix -- the standard was "stupid", and he
saw no reason to change his code to conform.
Usually, though, indifference is a bigger problem.  The NetBSD internal
developers' mailing list has seen numerous complaints about *major*
package developers ignoring portability and correctness fixes.  If it
isn't Linux and it isn't Windows, it doesn't matter, it seems.

@_date: 2008-05-13 12:47:53
@_author: Steven M. Bellovin 
@_subject: [ROS] The perils of security tools 
Ben: I haven't looked at the actual code in question -- are you saying
that the *only* way to add more entropy is via this pool of
uninitialized memory?  If so, is there any support in the relevant
standards that dictate that this memory MUST NOT be cleared?  I was
thinking of things like SELinux, which may (or may not) clear memory
areas before handing it to an application.

@_date: 2008-05-13 18:26:31
@_author: Steven M. Bellovin 
@_subject: [ROS] The perils of security tools 
On Tue, 13 May 2008 23:00:57 +0100
So why are are the keys so guessable?  Or did they delete other code?

@_date: 2008-05-13 18:35:24
@_author: Steven M. Bellovin 
@_subject: [ROS] The perils of security tools 
On Tue, 13 May 2008 23:27:52 +0100
Ah -- you wrote "adding memory" rather than "adding entropy", which I
found ambiguous.

@_date: 2008-05-14 19:52:58
@_author: Steven M. Bellovin 
@_subject: blacklisting the bad ssh keys? 
Given the published list of bad ssh keys due to the Debian mistake (see
 should sshd be
updated to contain a blacklist of those keys?  I suspect that a Bloom
filter would be quite compact and efficient.

@_date: 2008-05-24 23:18:43
@_author: Steven M. Bellovin 
@_subject: The perils of security tools 
On Sat, 24 May 2008 20:29:51 +0100
I believe that all open source Unix-like systems have /dev/random
and /dev/urandom; Solaris does as well.

@_date: 2008-05-31 20:27:55
@_author: Steven M. Bellovin 
@_subject: Protection mail at rest 
============================== START ==============================
On Fri, 30 May 2008 15:04:34 -0400 (EDT)
There's an option 2b that might be even more practical: an S/MIME or
PGP/MIME forwarder.  That is, have a trusted party receive your mail,
but rather than forwarding it intact encrypt it and then forward it to
your favorite IMAP provider.

@_date: 2008-11-07 13:21:56
@_author: Steven M. Bellovin 
@_subject: NIST Special Publication 800-108 Recommendation for Key  Derivation 
Dear Colleagues:
NIST Special Publication 800-108 Recommendation for Key Derivation
 Using Pseudorandom Functions is published at
 Thank you very much for your valuable comments during public comments

@_date: 2008-11-12 16:41:13
@_author: Steven M. Bellovin 
@_subject: Comment Period for FIPS 186-3: Digital Signature Standard 
User-Agent: Thunderbird 2.0.0.14 (Windows/20080421)
As stated in the Federal Register of November 12, 2008, NIST requests
final comments on FIPS 186-3, the proposed revision of FIPS 186-2, the
Digital Signature Standard. The draft defines methods for digital
signature generation that can be used for the protection of messages,
and for the verification and validation of those digital signatures
using DSA, RSA and ECDSA.
Please submit comments to ebarker at nist.gov with "Comments on Draft
186-3" in the subject line. The comment period closes on December 12,

@_date: 2008-11-26 13:34:37
@_author: Steven M. Bellovin 
@_subject: HavenCo and Sealand 
Slightly off-topic, but a cause celebre on cypherpunks some years ago

@_date: 2008-10-03 14:46:19
@_author: Steven M. Bellovin 
@_subject: "unbreakable" quantum crypto cracked by a laser 
Not surprisingly, it's attacking the implementation, not the physics --
but of course we use implementations to communicate, rather than

@_date: 2008-10-12 18:00:00
@_author: Steven M. Bellovin 
@_subject: Using GPUs to crack crypto 
Elcomsoft has a product that uses GPUs to do password-cracking on a
variety of media.  They claim a speed-up of up to 67x, depending on the
application being attacked.
(This has led to a variety of stories (see, for example,
claiming that WPA is dead. The correct answer, though, is that
passwords are dead, especially bad ones.)

@_date: 2008-10-27 17:05:06
@_author: Steven M. Bellovin 
@_subject: Cryptologic History Symposium: Call for Papers 
Forwarded with permission.
Just sending notice of our upcoming Symposium, especially if you can
present or know of a colleague who would like to do so.  Dr. Kent Sieg  The Center for Cryptologic History announces a call for papers for its
biennial Symposium on Cryptologic History.  The Symposium will occur on
15-16 October 2009 in Laurel, Maryland, at the Johns-Hopkins Applied
Physics Laboratory located in the Baltimore-Washington corridor.  The
theme for the Symposium will be "Global Perspectives on Cryptologic
History".  We will consider all proposals relating to any aspect of
cryptologic history.  The deadline for submission of proposals, to
include a minimum two-page topic prospectus, a brief source list, and a
biography, is 10 January 2009.  Selected presenters will received
notification by 1 March 2009.  For further information, contact Dr.
Kent Sieg, Symposium coordinator, at 301-688-2336 or kgsieg at nsa.gov.

@_date: 2008-10-30 14:08:35
@_author: Steven M. Bellovin 
@_subject: Who cares about side-channel attacks? 
You're forgetting the first questions you need to ask: who are your
enemies, what are you trying to protect, and what can you enemy spend?
And regardless of the answer to the last part, it's safe to assume that
your enemy would prefer to spend as little as possible.  Note that
"spend" includes not just dollars, euros, zorkmids, or linden dollars,
but also reputation if discovered, attack techniques you may or may not
want to reveal, etc.  So -- why do a side-channel attack involving, say, a million SSL
messages (see  when
that's the sort of thing that will show up in a log file, when you can
send a simple RPC query
( to
learn a private key?
But -- if you're a transit getting ready to deploy fare cards that
depend on a chip being secure, you'd better be very careful about side
channels, because those attacks can be tried offline.

@_date: 2008-10-30 17:40:56
@_author: Steven M. Bellovin 
@_subject: Fw: SHA-3 lounge 
Begin forwarded message:
This is to announce the creation of a "SHA-3 lounge", at

@_date: 2008-09-20 15:55:12
@_author: Steven M. Bellovin 
@_subject: once more, with feeling. 
Once upon a time, this would have been possible, I think.  Today,
though, the problem is the user entering their key in a box that is (a)
not remotely forgeable by a web site that isn't using the browser's
TLS-PSK mechanism; and (b) will *always* be recognized by users, even
dumb ones.  Today, sites want *pretty* login screens, with *friendly*
ways to recover your (or Palin's) password, and not just generic grey
boxes.  Then imagine the phishing page that displays an artistic but
purely imaginary "login" screen, with a message about "NEW!  Better
naviation on our login page!"
If this had been done in the beginning, before users -- and web site
designers, and browser vendors -- were mistrained, it might have
worked.  Now, though?  I'm skeptical.

@_date: 2008-09-24 20:36:47
@_author: Steven M. Bellovin 
@_subject: Fake popup study 
On Wed, 24 Sep 2008 18:52:24 -0400
Yes.  Don Norman said it quite eloquently at
 -- "If we assume that
the people who use technology are stupid ("Bubbas") then we will
continue to design poorly conceived equipment, procedures, and
software, thus leading to more and more accidents, all of which can be
blamed upon the hapless users rather than the root cause --
ill-conceived software, ill-conceived procedural requirements,
ill-conceived business practices, and ill-conceived design in general." Strong agreement.

@_date: 2008-09-24 20:52:03
@_author: Steven M. Bellovin 
@_subject: Fake popup study 
On Wed, 24 Sep 2008 20:43:53 -0400
There are no panaceas in this business.  As I told my class yesterday,
if they learn nothing else they should remember that security is a
systems property, and everything interacts.

@_date: 2009-08-13 13:48:17
@_author: Steven Bellovin 
@_subject: Kahn's "Seizing the Enigma" back in print -- with a catch 
David Kahn's "Seizing the Enigma" is back in print.  However, it's  only available from Barnes and Noble -- their publishing arm is doing  the reprint.  According to the preface, the new edition corrects minor  errors, but didn't give any details.

@_date: 2009-02-03 16:54:48
@_author: Steven M. Bellovin 
@_subject: Property RIghts in Keys 
I was reading a CPS from GeoTrust -- 91 pages of legalese! -- and came
across the following statement:
Under what legal theory might a certificate -- or a key! -- be
considered "property"?  There wouldn't seem to be enough creativity in
a certificate, let alone a key, to qualify for copyright protection.
I won't even comment on the rest of the CPS, not even such gems as
"Subscribers warrant that ... their private key is protected and that
no unauthorized person has ever had access to the Subscriber's private
key."  And just how can I tell that?

@_date: 2009-02-13 11:24:35
@_author: Steven M. Bellovin 
@_subject: NSA offering 'billions' for Skype eavesdrop solution 
Counter Terror Expo: News of a possible viable business model for P2P
VoIP network Skype emerged today, at the Counter Terror Expo in London.
An industry source disclosed that America's supersecret National
Security Agency (NSA) is offering "billions" to any firm which can
offer reliable eavesdropping on Skype IM and voice traffic.

@_date: 2009-02-14 10:36:36
@_author: Steven M. Bellovin 
@_subject: Property RIghts in Keys 
As best I can tell, the creativity was by the person who wrote their
certificate software...  Besides -- is a certificate a "literary,
dramatic, musical or artistic work"?
In any event, British law doesn't apply; the CPS states that it is to
be interpreted under Virginia, US, law.

@_date: 2009-02-19 14:45:15
@_author: Steven M. Bellovin 
@_subject: stripping https from pages 
-- we've
talked about this attack for quite a while; someone has now implemented

@_date: 2009-02-20 14:03:52
@_author: Steven M. Bellovin 
@_subject: The password-reset paradox 
Because then you need PIN resets, lost token handling, and "my token
doesn't work and I'm on a trip and my boss will kill me if I don't get
this done" resets.  I've personally had to deal with two of the three,
and it was just as insecure as password resets....

@_date: 2009-02-25 13:41:04
@_author: Steven M. Bellovin 
@_subject: Security through kittens, was Solving password problems 
It's not caching such pages; it is acting as a TCP relay for the
requests, without access to the keys.  These are utterly necessary for
some firewall architectures, for example, and generally do not represent
a security threat beyond traffic analysis.

@_date: 2009-02-25 20:53:24
@_author: Steven M. Bellovin 
@_subject: Solving password problems one at a time, Re: The password-reset 
On Sat, 21 Feb 2009 11:33:32 -0800
Up to a point.  The "most important password problem" is very much
context-dependent.  I'm not going to forget the unlock password to my
laptop, because I use it many times/day.  I regularly forget my login
password to the CS department's servers because I use it so rarely --
as best I can tell, I haven't used it in at least 15 months, because I
use public key authentication for most functions.  They've installed
some new service that will require it, though, so I suppose I need to
learn it.
However -- if you're talking about garden-variety web passwords, you're
probably correct.  For your last sentence, see my next response...
Define "automatic" and "secure".  "Self-managed" is context-dependent.
It's true for generic web authentication; it most certainly is not for
more serious ones.  The generic recovery/reset mechanisms have their
own security issues -- how secure is the back-up authentication
systems?  In most cases, the answer is "much less secure than the base
So -- why does that matter?
We've become prisoners of dogma here.  In 1979, Bob Morris and Ken
Thompson showed that passwords were guessable.  In 1979, that was
really novel.  There was a lot of good work done in the next 15 years
on that problem -- Spaf's empirical observations, Klein's '90 paper on
improving password security, Lamport's algorithm that gave rise to
S/Key, my and Mike Merritt's EKE, many others.  Guess what -- we're not
living in that world now.  We have shadow password files on Unix
systems; we have Kerberos; we have SecurID; we have SSL which rules out
the network attacks and eavesdropping that EKE was intended to counter;
etc.  We also have web-based systems whose failure modes are not nearly
the same.  Why do we think that the solutions are the same?  There was
a marvelous paper at Hotsec '07 that I resent simply because the
authors got there before me; I had (somewhat after them) come to the
same conclusions: the defenses we've built up against password failure
since '79 don't the problems of today's world.  We have to recognize
the new problems before we can solve them.  (I *think* that the paper
is at
but I'm on an airplane now and can't check...
Personally, I think this is the biggest problem when it comes to
phishing attacks.
What problem does two-factor solve?  I agree that it's helpful, but
until we know the threat we can't solve it.
As Peter Gutmann has pointed out, that has succeeded only because it
hasn't been seriously attacked.  Research results show that users are
very easily fooled by "changes" to the server.  In the scenario you
cite, all it takes -- and again, this is backed up by experimental
evidence -- is a web page saying "We've changed our login screen to
make it easier.  You no longer need to remember that meaningless
6-character string!"  Sure, no security expert would be fooled.
Virtually everyone else will be -- and again, I'm not guessing.
That is true if and only if people *notice* the absence.
And keystroke loggers?  They're a *huge* vulnerability.  You're also
ignoring the practical objects to use of certificates: storage of
certs and their private keys are difficult, with very poor usability
But usability is *the* problem, with server and client penetration a
close second.

@_date: 2009-01-10 12:50:41
@_author: Steven M. Bellovin 
@_subject: feds try to argue touch tone content needs no wiretap order 
It's very much worth reading the whole article; the author, Declan
McCullagh, does a good job with the historical background.  I'll add
one more historical tidbit: in the late 1980s, New York courts outlawed
pen register taps, because the same equipment was used to detect touch
tones as was used to record full content, and thus there was no
protection against law enforcement agents exceeding the court's
If I may wax US-legal for a moment...  According to a (U.S.) Supreme
Court decision (Katz v U.S. 389 US 347 (1967)), phone call content is
private, which therefore brings into play the full protection of the
Fourth Amendment -- judges, warrants, probable cause, etc.  However,
under a later ruling (Smith v Maryland 442 US 735 (1979)), the numbers
you call are information that is "given" to the phone company, and
hence is no longer private.  Accordingly, the Fourth Amendment does not
apply, and a much easier-to-get court order is all that's needed,
according to statute.  (I personally regard the reasoning in Smith as
convoluted and tortuous, but there have been several other, similar
rulings: data you voluntarily give to another party is no longer
considered private, so the Fourth Amendment doesn't apply.)
The legitimate (under current law) problem that law enforcement would
like to solve involves things like prepaid calling cards.  Suppose I
use one to call a terrorist friend, via some telco.  The number of the
calling card provider is available to law enforcement, under a pen
register order, per Smith and 18 USC 3121, the relevant legislation.
The telco will help law enforcement get that number.  I next dial my
account number; this is in effect a "conversation" between me and the
calling card provider.  Getting that number requires yet a different
kind of court order, I believe, but I'll skip that one for now.  I next
dial the number of my terrorist friend.  That's the number they now
want -- and per Smith, they're entitled to it, since it's a dialed
number via a telecommunications provider.  There is no doubt they could
go to that provider and ask for such a number.  However, they want to
ask the telco for it -- but the telco doesn't know what is a phone
number, what is an account number, what is a password for an online
bank account, and what is a password for an adult conference bridge.

@_date: 2009-01-17 11:24:08
@_author: Steven M. Bellovin 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
My analysis is similar to Peter's: 2-3 years for an RFC, 2-3 years for
design/code/test, 2 years average delay for the next major release of
Windows which will include it, 5 years for most of the older machines to
die off.  I've mentioned it before, but I'll point to the paper Eric Rescorla
wrote a few years ago:
 or
 .  The bottom line:
if you're running a public-facing web server, you *can't* offer a SHA-2
certificate because you have no way of knowing if the client supports
SHA-2. Fixing that requires a TLS fix; see the above timeline for that.

@_date: 2009-01-19 16:37:45
@_author: Steven M. Bellovin 
@_subject: MD5 considered harmful today, SHA-1 considered harmful tomorrow 
On Mon, 19 Jan 2009 10:45:55 +0100
So -- who supports TLS 1.2?  (Btw -- note the date of that RFC: August
2008.  That's almost exactly 3 years after ekr and I published our
paper.  Since ekr is co-chair of the TLS working group, we can assume
that that group was aware of the problem.  See what Peter and I said
about how long it takes to get any changes deployed.)

@_date: 2009-01-26 21:26:10
@_author: Steven M. Bellovin 
@_subject: Obama's secure PDA 
I actually explained (my take on) that question to my class last week.
Quite simply, voice offers one service -- voice.  Data offers many
services, and hence many venues for data-driven attacks: email (which
includes many MIME types) and probably clicking on URLs, web (which
includes HMTL, gif, jpeg, perhaps png, and almost certainly
Javascript), and perhaps data files including pdf, Word, Powerpoint,
and Excel.  Any one of those data formats is far more complex than even
compressed voice; the union of them makes me surprised it can handle
even Secret data... Note especially that HTML involves IFRAMEs and
third-party images, which means inherent cross-domain issues.

@_date: 2009-01-31 14:11:42
@_author: Steven M. Bellovin 
@_subject: Proof of Work -> atmospheric carbon 
On Fri, 30 Jan 2009 11:40:12 -0700
I asked Rob Thomas of Team Cymru this question (he and they study the
underground).  Here is his answer, posted with permission:
Botnets are routinely used as:
1. Proxies (IRC, HTTP & HTTPS)
2. To recover financial credentials, e.g. paypal, citibank, et al.
   This was the original purpose of the PSNIFF code in some of the early
Here's a code snippet from the now venerable
rBot_rxbot_041504-dcom-priv-OPTIX_MASTERPASSWORD dating back several
[ ... ]
[ ... ]
PSWORDS pswords[]={
        {":.login",BOTP},
        {":,login",BOTP},
        {":!login",BOTP},
[ ... ]
        {"paypal",HTTPP},
        {"PAYPAL",HTTPP},
        {"paypal.com",HTTPP},
        {"PAYPAL.COM",HTTPP},
        {"Set-Cookie:",HTTPP},
        {NULL,0}
[ ... ]
3. Remember they're called "boats" now, so anything is possible.  Screen
captures are becoming increasingly popular.

@_date: 2009-07-03 23:49:39
@_author: Steven M. Bellovin 
@_subject: MD6 withdrawn from SHA-3 competition 
The report is quite correct.  Rivest sent a note to NIST's hash forum
mailing list (
announcing the withdrawal.  Since a password is necessary to access the
archives (anti-spam?), I don't want to post the whole note, but Rivest
said that they couldn't improve MD6's performance to meet NIST's
criteria (at least as fast as SHA-2); the designers of MD6 felt that
they could not manage that and still achieve provable resistance to
differential attacks, and they regard the latter as very important.
Here's the essential paragraph:

@_date: 2009-07-15 17:45:26
@_author: Steven M. Bellovin 
@_subject: spyware on Blackberries 
A BlackBerry update that a United Arab Emirates service provider pushed
out to its customers contains U.S.-made spyware that would allow the
company or others to siphon and read their e-mail and text messages,
according to a researcher who examined it.
The update was billed as a ?performance enhancement patch? by the
UAE-based phone and internet service provider Etisalat, which issued
the patch for its 100,000 subscribers.

@_date: 2009-03-03 13:00:05
@_author: Steven M. Bellovin 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
I would not read too much into this ruling -- I think that this is a
special situation, and does not address the more important general
issue.  To me, this part is crucial:
In other cases, where alternative evidence is not available to the
government, and where government agents have not already had a look at
the contents, the facts (and hence perhaps the ruling) would be

@_date: 2009-03-03 14:45:17
@_author: Steven M. Bellovin 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
On Tue, 03 Mar 2009 13:53:50 -0500
Indeed.  Let me point folks at

@_date: 2009-03-04 19:18:48
@_author: Steven M. Bellovin 
@_subject: Judge orders defendant to decrypt PGP-protected laptop 
Courts very rarely issue broader rulings than they absolutely have to.
*Given the facts of this particular case* -- where Federal agents have
already seen the putatively-illegal images -- it strikes me as unlikely
there will be definitive ruling in either direction.  Let me refer folks to Orin Kerr's blog on the original ruling:
 .  I rarely agree with
Kerr; this time, after thinking about it a *lot*, I concluded he was
likely correct.  I suggest that people read his post (including all the
'click here to see more' links, which seem to require (alas)
Javascript) and the precedents cited.  It doesn't mean I agree with all
of those rulings (I don't), or that I think the courts should rule
against Boucher.  What I'm saying is that based on precedent and the
facts of this case, I think they will.
Here's a crucial factual excerpt from Kerr's blog:
Also note this text from the original ruling (at
 supporting Boucher:
The legal issue is very narrow: is entering the password "testimonial",
and thus protected?  Again: "both parties agree that the contents of the
laptop do not enjoy Fifth Amendment protection as the contents were
voluntarily prepared and are not testimonial."
Beyond that, Boucher waived his Miranda rights in writing and showed the
agent the (I assume) relevant folders.  That, coupled with the
precedents from Fisher, Hubbell, etc., make it likely, in my
non-lawyerly opinion, that the government will prevail. *But* -- I
predict that the ruling will be narrow.  It will not (I suspect and
hope) result in a ruling that the government can always compel the
production of keys.
(Philosophical aside: I've never been happy with the way the Fifth
Amendment has been interpreted.  To me, it's about freedom of
conscience, rather than freedom from bringing punishment upon oneself.
The law supports that in other situations -- the spousal exemption, the
priest-penitent privilege, etc.  This is why grants of immunity and
especially use immunity have always troubled me.  I recognize, though,
that this is not the way the law works.)
So -- I suspect that Boucher is going to lose.  The real question is
whether the ruling will be narrow, based on these facts, or whether
some judge will issue a broad ruling on witholding keys.

@_date: 2009-03-16 16:42:16
@_author: Steven M. Bellovin 
@_subject: Some old works 
While poking around Google Books, I stumbled on the following two
references that might be of interest to this list.  The first is cited
by Kahn.
\emph{The Military Telegraph During the Civil War in the United States:
With an Exposition of Ancient and Modern Means of Communication,
and of the Federal and Confederate Cipher Systems ; Also a Running
Account of the War Between the States}
By William Rattle Plum
Published by Jansen, McClurg & Company, 1882
"Secret Writing"
The Century
Published by The Century Co., 1913

@_date: 2009-03-10 23:08:17
@_author: Steven M. Bellovin 
@_subject: Legalities: NSA outsourcing spying on Americans? 
The assertion occasionally comes up that since the NSA cannot legally
eavesdrop on Americans, it outsources to the UK or one of the other
Echelon countries.  It turns out that that's forbidden, too -- see
Section 2.12 of Executive Order 12333
Now, I'm not saying that the government or the NSA always follows the
rules; I'm simply saying that that loophole is pretty obvious and is
(officially, at least) closed.

@_date: 2009-05-06 20:54:34
@_author: Steven M. Bellovin 
@_subject: 80-bit security? (Was: Re: SHA-1 collisions now at 2^{52}?) 
That's an interesting statement from a historical perspective -- is it
true?  And what does that say about our ability to predict the future,
and hence to make reasonable decisions on key length?
See, for example, the 1996 report on key lengths, by Blaze, Diffie,
Rivest, Schneier, Shimomura, Thompson, and Wiener, available at
 -- was it right?
In 1993, Brickell, Denning, Kent, Maher, and Tuchman's interim report
on Skipjack (I don't believe there was ever a final report) stated that
Skipjack (an 80-bit cipher) was likely to be secure for 30-40 years.
Was it right?
The problem with SHA-1 is not its 80-bit security, but rather that it's
not that strong.

@_date: 2009-11-01 22:32:32
@_author: Steven Bellovin 
@_subject: Security of Mac Keychain, Filevault 
Unfortunately, there's no better response here.
At time T, someone will assert that "X is insecure", and that products  exist -- commercial and freeware -- to crack it.  This person supplies  no evidence except for an incomplete list of products to support the  assertion.  What do I now know that I didn't know before?
One way to judge is by reputation.  If, say, Adi Shamir says it, I'm  very inclined to believe it, even without wading through the technical  details.  If the posting comes from a notorious crank, I'll likely  discard the message unread because cranks tend to misread technical  papers.  If it's someone I've never heard of, I have to make the  decision based on the evidence presented and what I already know.   What was the evidence here?
The article made no verifiable or falsifiable technical statements, so  there's nothing to evaluate in that respect.  I've never heard of any  freeeware to crack Filevault; given the familiarity of the readership  of this list in the aggregate with the free software world, it seems  unlikely that such software exists.  He did point to some commercial  software to attack Filevault, but it works by password guessing.  For  his business -- forensic analysis -- I suspect that that technique is  extremely useful; I doubt that anyone on this list would disagree.   But that's not the same as a flaw in MacOS.
Beyond that, we're left with *no* new information.  What basis does  this article give us to conclude that Filevault is -- or is not --  insecure?  I have no more reason to trust it or distrust it than I had  before reading that article.
A proper evaluation of Filevault would, of course, be a good idea.   But that statement is equally true after the article as before.

@_date: 2009-10-13 11:41:44
@_author: Steven Bellovin 
@_subject: Review of new book on the NSA 
There's a new book on the NSA, based largely on documents received via  Freedom of Information Act requests.  Bamford's review is at    .

@_date: 2009-10-19 18:35:22
@_author: Steven Bellovin 
@_subject: Possibly questionable security decisions in DNS root management  
The evidence that it was an intentional design feature is, to my  knowledge, slim.  More relevant to this case is why it matters: what  information is someone trying to smuggle out via the DNS?  Remember  that DNS records are (in principle) signed offline; servers are  signing *records*, not responses.  In other words, it's more like a  certificate model than the TLS model.
It's rather more complicated than that.  The issue isn't bandwidth per  se, at least not as compared with total Internet bandwidth.  Bandwidth  out of a root server site may be another matter.  Btw, the DNS as  designed 25 years ago would not scale to today's load.  There was a  crucial design mistake: DNS packets were limited to 512 bytes.  As a  result, there are 10s or 100s of millions of machines that read *only*  512 bytes.  That in turn means that there can be at most 13 root  servers.  More precisely, there can be at most 13 root names and IP  addresses.  (We could possibly have one or two more if there was just  one name that pointed to many addresses, but that would complicate  debugging the DNS.)  The DNS is working today because of anycasting;  many -- most?  all? -- of the 13 IP addresses exist at many points in  the Internet, and depend on routing system magic to avoid problems.   At that, anycasting works much better for UDP than for TCP, because it  will fail utterly if some packets in a conversation go to one  instantiation and others go elsewhere.
It is possible to have larger packets, but only if there is prior  negotiation via something called EDNS0.  At that, you still *really*  want to stay below 1500 bytes, the Ethernet MTU.  If you exceed that,  you get fragmentation, which hurts reliability.  But whatever the  negotiated maximum DNS response size, if the data exceeds that value  the server will say "response truncated; ask me via TCP".  That, in  turn, will cause massive problems.  Many hosts won't do TCP properly  and many firewalls are incorrectly configured to reject DNS over TCP.   Those problems could, in principle, be fixed.  But TCP requires a 3- way handshake to set up the connection, then a 2-packet exchange for  the data and response (more if the response won't fit in a single  packet), plus another 3 packets to tear down the connection.  It also  requires a lot of state -- and hence kernel memory -- on the server.   There are also reclamation issues if the TCP connection stops -- but  isn't torn down -- in just the proper way (where the server is in FIN- WAIT-2 state), which in turn might happen if the routing system  happens to direct some anycast packets elsewhere.
To sum up: there really are reasons why it's important to keep DNS  responses small.  I suspect we'll have to move towards elliptic curve  at some point, though there are patent issues (or perhaps patent FUD;  I have no idea) there.
Actually, no; the design then was wrong.  It looked ok from the crypto  side, but there were subtle points in the DNS design that weren't  handled properly.  I'll skip the whole saga, but it wasn't until RFC  4033-4035 came out, in March 2005, that the specs were correct.  There  are still privacy concerns about parts of DNSSEC.
There was some of that animosity, but I don't think it was the whole  That's an interesting assumption, but is it true?  In particular, is  it really that useful to tune an cracking engine to exactly one  modulus size?  A maximum size, sure, but do the cracking engines  really have trouble with slightly smaller moduli?

@_date: 2009-10-25 21:21:07
@_author: Steven Bellovin 
@_subject: Security of Mac Keychain, File Vault 
The article specifically mentions Mac Marshall for attacking  FileVault, but from the descriptions of it I can find it's just doing  password guessing.

@_date: 2009-09-02 15:13:59
@_author: Steven Bellovin 
@_subject: Client Certificate UI for Chrome? 
This returns us to the previously-unsolved UI problem: how -- with  today's users, and with something more or less like today's browsers  since that's what today's users know -- can a spoof-proof password  prompt be presented?

@_date: 2009-09-06 20:12:37
@_author: Steven Bellovin 
@_subject: Client Certificate UI for Chrome? 
Several other people made similar suggestions.  They all boil down to  the same thing, IMO -- assume that the user will recognize something  distinctive or know to do something special for special sites like  banks.  Both, to me, are unproven assumptions.  Worse yet, both the  security literature and what I've seen of user behavior strongly  suggest to me that neither scenario is true.
Peter, I'm not sure what you mean by "good enough to satisfy security  geeks" vs. "good enough for most purposes".  I'm not looking for  theoretically good enough, for any value of "theory"; my metric -- as  a card-carrying security geek -- is precisely "good enough for most  purposes".  A review of user studies of many different distinctive  markers, from yellow URL bars to green partial-URL bars to special  pictures to you-name-it shows that users either never notice the  *absence* of the distinctive feature or are fooled by a tailored  attack (see, e.g., the paper on picture-in-picture attacks).  Maybe  Camino is really better -- or maybe it just hasn't been properly  attacked yet, say by a clever flash animation or some AJAX weirdness.   Given the failure of all previous attempts -- who, amongst the  proponents of EV certificates, realized that attackers could and would  use all-green favicon.ico files to fool users -- I think the burden of  proof is on the proponents.

@_date: 2009-09-09 08:10:45
@_author: Steven M. Bellovin 
@_subject: Client Certificate UI for Chrome? 
On Wed, 09 Sep 2009 15:42:34 +1000
We conducted a small-scale controlled user study -- it didn't work.
Not quite.  I'm not saying it "cannot be improved".  I'm saying that
controlled studies thus far have demonstrated none of the proposed
methods have worked, against fairly straight-forward new attacks.  And
if we've learned one thing over the last ten years, it's that the
attackers are as good as we are at what they do.  There's money to be
made and the market has worked its wonders: there is a demand for
capable hackers, and they're making enough money to attract good people.
What I am saying is twofold.  First -- when you invent a new scheme,
do a scientific test: does it actually help?  Don't assume that because
pure reason tells you it's a good idea, it actually is in the real
world.  Second -- you may very well be right that tinkering with the
password entry mechanisms cannot succeed, because users are habituated
to many different mechanisms and to login screens that regularly change
because some VP in charge of publicity has decided that the site's web
presence looks old-fashioned and needs to be freshened.  In that case,
we have to look at entirely different approaches.  (How many different
experiments will it take to convince people that you can't make gold by
mixing chemicals together?)

@_date: 2009-09-09 11:01:51
@_author: Steven Bellovin 
@_subject: NSA intercepts led to a terrorist conviction 
"Threat Level Privacy, Crime and Security Online
NSA-Intercepted E-Mails Helped Convict Would-Be Bombers
The three men convicted in the United Kingdom on Monday of a plot to  bomb several transcontinental flights were prosecuted in part using  crucial e-mail correspondences intercepted by the U.S. National  Security Agency, according to Britain?s Channel 4.
The e-mails, several of which have been reprinted by the BBC and other  publications, contained coded messages, according to prosecutors. They  were intercepted by the NSA in 2006 but were not included in evidence  introduced in a first trial against the three last year.
 has more.

@_date: 2009-09-21 16:57:56
@_author: Steven Bellovin 
@_subject: FileVault on other than home directories on MacOS? 
Is there any way to use FileVault on MacOS except on home  directories?  I don't much want to use it on my home directory; it  doesn't play well with Time Machine (remember that availability is  also a security property); besides, different directories of mine have  different sensitivity levels.
I suppose I could install TrueCrypt (other suggestions or comments on  TrueVault?), but I prefer to minimize the amount of extra software I  have to maintain.

@_date: 2009-09-29 23:07:57
@_author: Steven Bellovin 
@_subject: [Barker, Elaine B.] NIST Publication Announcements 
I don't know if their scheme was patented in Germany.  It was in the  U.S., though I think that at least some of the patents expire within  the year.

@_date: 2010-04-22 09:09:22
@_author: Steven Bellovin 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
While I'm quite skeptical that QKD will prove of practical use, I do think it's worth investigating.  The physics are nice, and it provides an interesting and different way of thinking about cryptography.  I think that there's a non-trivial chance that it will some day give us some very different abilities, ones we haven't even thought of.  My analog is all of the strange and wondrous things our cryptographic protocols can do -- blind signatures, zero knowledge proofs, secure multiparty computation, and more -- things that weren't on the horizon just 35 years ago.  I'm reminded of a story about a comment Whit Diffie once heard from someone in the spook community about public key crypto.  "We had it first -- but we never knew what we had.  You guys have done much more with it than we ever did."  All they knew to do with public key was key distribution or key exchange; they didn't even invent digital signatures.  They had "non-secret encryption"; we had public key cryptography.
Might the same be true for QKD?  I have no idea.  I do suggest that it's worth thinking in those terms, rather than how to use it to replace conventional key distribution.  Remember that RSA's essential property is not that you can use it to set up a session key; rather, it's that you can use it to send a session key to someone with whom you don't share a secret.  Beyond Perry's other points -- and QKD is inherently point-to-point; you need n^2 connections, since you can't terminate the link-layer crypto at a router without losing your security guarantees -- it's worth reminding people that the security guarantees apply to ideal quantum systems.  If your emitter isn't ideal -- and of course it isn't -- it can (will?) emit more photons; I can play my interception games with the ones your detector doesn't need.

@_date: 2010-08-13 18:15:27
@_author: Steven Bellovin 
@_subject: new tech report on easy-to-use IPsec 
Thanks.  I'll add that the code is now up on SourceForge under a BSD license:

@_date: 2010-08-16 09:30:48
@_author: Steven Bellovin 
@_subject: Has there been a change in US banking regulations recently? 
Right -- who's your enemy?  The NSA?  The SVR?  Or garden-variety cybercrooks?
That depends on what you're protecting.  If it's the 4-digit PIN to billion-zorkmid bank accounts, they key needs to remain secure for many years, given how seldom PINs are changed.
But only slightly exaggerated...

@_date: 2010-08-17 17:08:12
@_author: Steven Bellovin 
@_subject: Has there been a change in US banking regulations recently?  
John, as you yourself have said, "cryptography is a matter of economics".  Other than a few academics, people don't factor large numbers for fun; rather, they want the plaintext or the ability to forge signatures.  Is factoring the best way to do that?  Your own numbers suggest that it is not.  You wrote "After they've built 50, which perhaps only take six months to crack a key, will YOUR key be one of the 100 keys that they crack this year?"  100 keys, perhaps multiplied by 10 for the number of countries that will share the effort, means 1000 keys/year.  How many *banks* have SSL keys?  If you want to attack one of those banks, which is *cheaper*, getting time on a rare factoring machine, or finding some other way in, such as hacking an endpoint?  For that matter, don't forget Morris' "three Bs: burglary, bribery, and blackmail".  (Aside: I was once discussing TWIRL with someone who has ties to the classified community.  When I quoted solution speeds of the we're discussing, he chortled, saying that the political fight over whose solutions were more valuable would paralyze things.)
If the threat is factoring, there are cheaper defenses than going to 1024-bit keys.  For example, every one under a given CA can issue themselves subcertificates.  For communication keys, use D-H; it's a separate solution effort for each session.  (Yes, it's cheaper if the modulus is held constant.)  Cracking the signing key won't do any good, because of perfect forward secrecy.
You don't need long keys when they're used solely for short-lived authentication -- DNSSEC comes to mind.
Now -- all that said, I agree that 2048-bit keys are a safer choice.  However, defenders have to consider economics, too, and depending on what they're protecting it may not be a smart choice.

@_date: 2010-08-17 18:24:20
@_author: Steven Bellovin 
@_subject: 2048-bit RSA keys 
It's worth quote from the paper at CRYPTO '10 on factorization of a 768-bit number:
They conclude with
They also suggest that a 3-4 year phase-out of 1024-bit moduli is the proper course.

@_date: 2010-08-23 15:35:45
@_author: Steven Bellovin 
@_subject: [IP] Malware kills 154 
And the articles I've seen do not say that the problem caused the crash.  Rather, they say that a particular, important computer was infected with malware; I saw no language (including in the Google translation of the original article at  though the translation has some crucial infelicities) that said "because of the malware, bad things happened.  It may be like the reactor computer with a virus during a large blackout -- yes, the computer was infected, but that wasn't what caused the problem.

@_date: 2010-08-23 15:37:48
@_author: Steven Bellovin 
@_subject: [IP] Malware kills 154 
To say nothing of what happens when you run a nuclear power plant on Windows:  (slightly OT, I realize, but too good to pass up).

@_date: 2010-08-24 18:44:02
@_author: Steven Bellovin 
@_subject: [IP] Malware kills 154 
What I have not seen are any statements attributed to the investigating agency that support your last conclusion: that the malware is what caused the alarm failure.  I saw a very good summary of the official findings; I'll ask permission to repost them.

@_date: 2010-08-24 20:49:25
@_author: Steven Bellovin 
@_subject: [IP] Malware kills 154 
With his permission, here is a summary of the Spanish-language article by Ivan Arce, a native speaker of Spanish.  (I misspoke when I said he read the actual report.)  Note the lack of any assertion of causality between the crash and the malware.
- The malware-infected computer was located at the HQs in Palma de
Mallorca. The plane crashed on take off from Madrid.
- The fact that the computer was infected was revealed in an internal
memo on the same day of the incident.
- The computer hosted the application used to log maintaince failure
reports. It was configured to trigger on on-screen alarm (maybe a dialog
with an "OK" button?) when it detected 3 failures of a similar kind on
the same plane
- Spainair  was known to take up to 24hs to update the system with
maintaince reports as admitted by two mechanics (I dont know the proper
english term for this) from the maint. team.
- This isn't a minor issue given that the same plane had two failures on
the prior day and another failure on the same day. The maintaince crew
was responsible for reporting failures immediately when they were
- That last failure on the same day, had prompted the pilots to abort
the take off at the head of the runway and get back to the gate when an
overheated valve was detected.
- Then the pilots forgot to activate flaps and slats.
- The plane had an onboard audible alarm to signal that condition, the
alarm did not go off.
Reading this full account is quite saddening.
So, in sum, it seems that a set of failures and errors were combined and
led to terrible consequences. In this overall picture, malware had a
very limited and small impact.

@_date: 2010-08-25 14:43:49
@_author: Steven Bellovin 
@_subject: towards https everywhere and strict transport security (was: Has there been a change in US banking regulations recently?) 
This statement is quite correct.  I know of at least one major player that was very reluctant to use SSL because of this issue; the round trips, especially on intercontinental connections, led to considerable latency, which in turn hurt the perceived responsiveness of their service.
We need to do something about the speed of light.  Is anyone working on hyperwave or subether technologies?

@_date: 2010-08-25 23:46:00
@_author: Steven Bellovin 
@_subject: questions about RNGs and FIPS 140 
It's worth noting that the issue of determinism vs. non-determinism is by no means clearcut.  You yourself state that FIPS 140-2 requires deterministic PRNGs; I think one can rest assured that the NSA had a lot of input into that spec.  The Clipper chip programming facility used a PRNG to set the unit key -- and for good reasons, not bad ones.

@_date: 2010-07-09 18:58:28
@_author: Steven Bellovin 
@_subject: Question w.r.t. AES-CBC IV 
Unless I misunderstand your point, I think that in the real world there's a very real difference in the insecurity of CBC vs CTR if the IV selection is faulty.  With CBC, there is semantic insecurity, in that one can tell if two messages have a common prefix if the IV is the same.  Furthermore, if the IV is predictable to the adversary under certain circumstances some plaintext can be recovered.
With CTR, however, there are very devastating two-message attacks if the IVs are the same; all that's necessary is some decent knowledge of some probable plaintext.

@_date: 2010-07-14 14:40:59
@_author: Steven Bellovin 
@_subject: new tech report on easy-to-use IPsec 
Folks on this list may be interested in a new tech report:
The IPsec protocol promised easy, ubiquitous encryption. That has never happened. For the most part, IPsec usage is confined to VPNs for road warriors, largely due to needless configuration complexity and incompatible implementations.  We have designed a simple VPN configuration language that hides the unwanted complexities. Virtually no options are necessary or possible. The administrator specifies the absolute minimum of information: the authorized hosts, their operating systems, and a little about the network topology; everything else, including certificate generation, is automatic. Our implementation includes a multitarget compiler, which generates implementation-specific configuration files for three different platforms; others are easy to add.
We hope to have the code up on Sourceforge soon.

@_date: 2010-07-18 07:19:18
@_author: Steven Bellovin 
@_subject: Root Zone DNSSEC Deployment Technical Status Update 
DNSSEC signatures do not need to have a long lifetime; no one cares if, in 10 years, someone can find a preimage attack against today's signed zones.  This is unlike many other uses of digital signatures, where you may have to present evidence in court about what some did or did not sign.
It's also unclear to me what the actual deployment is of stronger algorithms, or of code that will do the right thing if multiple signatures are present.

@_date: 2010-07-24 20:38:07
@_author: Steven Bellovin 
@_subject: MITM attack against WPA2-Enterprise? 
There is a claim of a flaw in WPA2-Enterprise -- see

@_date: 2010-07-26 21:42:53
@_author: Steven Bellovin 
@_subject: MITM attack against WPA2-Enterprise? 
If I understand the problem correctly, it doesn't strike me as particularly serious.  Fundamentally, it's a way for people in the same enterprise and on the same LAN to see each other's traffic.  A simple ARP-spoofing attack will do the same thing; no crypto needed.  Yes, that's a more active attack, and in theory is somewhat more noticeable.  In practice, I suspect the actual risk is about the same.

@_date: 2010-07-26 22:37:06
@_author: Steven Bellovin 
@_subject: MITM attack against WPA2-Enterprise? 
Probably...  To me, access link crypto is about access control.  WEP --
apart from the failings in RC4 and how it was used -- got that badly
wrong, because it was impossible to change keys in any rational way.
WPA2 was supposed to fix that; I'd have been happy if that were all
it did.  As others have noted, end-to-end crypto is the proper approach.

@_date: 2010-07-28 08:48:14
@_author: Steven Bellovin 
@_subject: A mighty fortress is our PKI, Part II 
There seem to be at least three different questions here: bad code (i.e., that Windows doesn't check the revocation status properly), the UI issue, and the conceptual question of what should replace the current PKI+{CRL,OCSP} model.  For the last issue, I'd note that using pki instead of PKI (i.e., many different per-realm roots, authorization certificates rather than identity certificates, etc.) doesn't help: Realtek et al. still have no better way or better incentive to revoke their own widely-used keys.

@_date: 2010-07-28 20:44:48
@_author: Steven Bellovin 
@_subject: A mighty fortress is our PKI, Part II 
When I look at this, though, little of the problem is inherent to PKI.  Rather, there are faulty communications paths.
You note that at t+2-3 days, the CA read the news.  Apart from the question of whether or not "2-3 days" is "shortly after" -- the time you suggest the next step takes place -- how should the CA or Realtek know about the problem?  Did the folks who found the offending key contact either party?  Should they have?  The AV companies are in the business of looking for malware or reports thereof; I think (though I'm not certain) that they have a sharing agreement for new samples.  (Btw -- I'm confused by your definition of "t" vs. "t-lots".  The first two scenarios appear to be "t == the published report appearing"; the third is confusing, but if you change the timeline to "t+lots" it works for "t == initial, unnoticed appearance in the wild".  Did the AV companies push something out long before the analysis showed the stolen key?)
Suppose, though, that Realtek has some Google profile set up to send them reports of malware affecting their anything.  Even leaving aside false positives, once they get the alert they should do something.  What should that something be?  Immediately revoke the key?  The initial reports I saw were not nearly specific enough to identify which key was involved.  Besides, maybe the report was not just bogus but malicious -- a DoS attack on their key.  They really need to investigate it; I don't regard 2-3 days as unreasonable to establish communications with an malware analysis company you've never heard of and which has to verify your bonafides, check it out, and verify that the allegedly malsigned code isn't something you actually released N years ago as release 5.6.7.9.9.a.b for a minor product line you've since discontinued.  At that point, a revocation request should go out; delays past that point are not justifiable.  The issue of software still accepting it, CRLs notwithstanding, is more a sign of buggy code.
The point about the communications delay is that it's inherent to anything involving the source company canceling anything -- whether it's a PKI cert, a pki cert, a self-validating URL, a KDC, or magic fairies who warn sysadmins not to trust certain software.  What's interesting here is the claim that AV companies could respond much faster.  They have three inherent advantages: they're in the business of looking for malware; they don't have to complete the analysis to see if a stolen key is involved; and they can detect problems after installation, whereas certs are checked only at installation time.  Of course, speedy action can have its own problems; see  for a recent example, but there have been others.  Note that I'm not saying that PKI is a good solution.  But it's important to factor out the different contributing factors in order to understand what needs to be fixed.  It's also important to understand the failure modes of replacements.  (To pick a bad example, Kerberos for the Internet is extremely vulnerable to compromise of the KDC, unless you use the public key variants of Kerberos.)

@_date: 2010-07-30 21:23:41
@_author: Steven Bellovin 
@_subject: Obama administration seeks warrantless access to email headers. 
Actually, no, it isn't.  Transaction record access is not afforded the same protection as content.  I'll skip the detailed legal citations; the standard now for transactional records is 'if the governmental entity offers specific and articulable facts showing that there are reasonable grounds to believe that the contents of a wire or electronic communication, or the records or other information sought, are relevant and material to an ongoing criminal investigation."  This is much less than the "probably cause" and specificity standards for full-content wiretaps, which do enjoy very strong protection.
Not in this case.  Since the target of such an order is not necessarily the suspect, the fact of the information transfer may never be introduced in open court.  Nor is there a disclosure requirement here, the way there is for full-content wiretaps.

@_date: 2010-07-31 23:14:41
@_author: Steven Bellovin 
@_subject: Is this the first ever practically-deployed use of a threshold scheme? 
There is circumstantial evidence that such schemes were deployed for U.S. nuclear weapons command and control.  I also wonder if it's used for some of the NSA's root keys -- they run very large PKIs.

@_date: 2010-07-31 23:50:19
@_author: Steven Bellovin 
@_subject: Venona 
I'm currently reading "Defend the Realm", an authorized history oF MI-5 by a historian who had access to their secret files.  The chapter on Venona has the following fascinating footnote: "The method of decryption is summarized in a number of NSA publications, among them the account by Cecil James Phillips of NSA, 'What Made Venona Possible?'  References to this account does not imply that it is corroborated by HMG or any British intelligence agency."
I've always been a bit skeptical of NSA's story of how the system was broken, which makes me wonder if there's some other reason for that disclaimer...  (Grumpy aside: I have the full text of the ebook (borrowed from the NY Public Library) on my laptop.  However, I couldn't copy and paste the quotation, even though it's obviously fair use -- the DRM software wouldn't let me...)

@_date: 2010-06-29 10:33:51
@_author: Steven Bellovin 
@_subject: A real case of malicious steganography in the wild? 
============================== START ==============================
For years, there have been unverifiable statements in the press about assorted hostile parties using steganography.  There may now be a real incident -- or at least, the FBI has stated in court documents that it happened.
According to the Justice Department ( 11 Russian nationals have been operating as deep cover agents in the US for many years.  According to Complaint  (link at the bottom of the page), a steganographic program was used.  Other Internet-era techniques allegedly employed include ad hoc WiFi networks.  (To be sure, the FBI could be wrong.  In the past, I've seen them make mistakes about that, but they're *much* more experienced now.)
It will be interesting to see how this develops in court.

@_date: 2010-03-23 22:13:20
@_author: Steven Bellovin 
@_subject: "Against Rekeying" 
I'm a bit skeptical -- I think that ekr is throwing the baby out with the bath water.  Nobody expects the Spanish Inquisition, and nobody expects linear cryptanalysis, differential cryptanalysis, hypertesseract cryptanalysis, etc.  A certain degree of skepticism about the strength of our ciphers is always a good thing -- no one has ever deployed a cipher they think their adversaries can read, but we know that lots of adversaries have read lots of "unbreakable" ciphers.
Now -- it is certainly possible to go overboard on this, and I think the IETF often has.  (Some of the advice given during the design of IPsec was quite preposterous; I even thought so then...)  But one can calculate rekeying intervals based on some fairly simple assumptions about the amount of {chosen,known,unknown} plaintex/ciphertext pairs needed and the work factor for the attack, multiplied by the probability of someone developing an attack of that complexity, and everything multiplied by Finagle's Constant.  The trick, of course, is to make the right assumptions.  But as Bruce Schneier is fond of quoting, attacks never get worse; they only get better.  Given recent research results, does anyone want to bet on the lifetime of AES?  Sure, the NSA has rated it for Top Secret traffic, but I know a fair number of people who no longer agree with that judgment.  It's safe today -- but will it be safe in 20 years?  Will my plaintext still be sensitive then?
All of that is beside the point.  The real challenge is often to design a system -- note, a *system*, not just a protocol -- that can be rekeyed *if* the long-term keys are compromised.  Once you have that, setting the time interval is a much simpler question, and a question that can be revisited over time as attacks improve.

@_date: 2010-05-17 16:47:41
@_author: Steven Bellovin 
@_subject: Commercial quantum cryptography system broken 
Not at all to my surprise, they broke it by exploiting a difference between a theoretical system and a real-world implementation.

@_date: 2010-10-08 11:29:16
@_author: Steven Bellovin 
@_subject: Photos of an FBI tracking device found by a suspect 
See  for even more disturbing aspects of the story -- they operated by intimidation (to say nothing of apparent ethnic and religious profiling).

@_date: 2010-09-04 16:32:07
@_author: Steven Bellovin 
@_subject: RSA question 
Also see RFC 3766, which comes up with comparable numbers and several types of analysis.

@_date: 2010-09-13 14:45:54
@_author: Steven Bellovin 
@_subject: Fwd: [ PRIVACY Forum ] 'Padding Oracle' Crypto Attack Affects Millions of ASP.NET Apps 
Here's what happens when you get your integrity checks wrong....
Begin forwarded message:

@_date: 2010-09-14 18:15:26
@_author: Steven Bellovin 
@_subject: Intel plans crypto-walled-garden for x86 
I've written a long blog post on this issue for the Concurring Opinions legal blog; see

@_date: 2010-09-17 16:04:36
@_author: Steven Bellovin 
@_subject: Something you have, something else you have, and, uh, something else you have 
I don't know how NZ banks do it; in the US, they use the phone number you're calling from.  Yes, it's spoofable, but most folks (a) don't know it, and (b) don't know how.
Of course, in many newer houses here there's a phone junction box *outside* the house.  So -- steal the envelope, and plug your own phone into the junction box, and away you go...

@_date: 2010-09-20 11:23:14
@_author: Steven Bellovin 
@_subject: Slides on the SHA-3 competition 
Attached on John Kelsey's slides on the status of the SHA-3 competition.  (Forwarded with permission.)
Begin forwarded message:

@_date: 2010-09-22 09:34:48
@_author: Steven Bellovin 
@_subject: ciphers with keys modifying control flow? 
Does anyone know of any ciphers where bits of keys modify the control path, rather than just data operations?  Yes, I know that that's a slippery concept, since ultimately things like addition and multiplication can be implemented with loops in the hardware or firmware.  I also suspect that it's potentially dangerous, since it might create very hard-to-spot classes of weak keys.  The closest I can think of is SIGABA, where some of the keying controlled the stepping of the other rotors.

@_date: 2010-09-24 15:47:44
@_author: Steven Bellovin 
@_subject: Certificate-stealing Trojan 
Per  there's a new Trojan out there that looks for a steals Cert_*.p12 files -- certificates with private keys.  Since the private keys are password-protected, it thoughtfully installs a keystroke logger as well....

@_date: 2010-09-30 12:02:26
@_author: Steven Bellovin 
@_subject: 2048 bits, damn the electrons! [rt@openssl.org: [openssl.org #2354] [PATCH] Increase Default RSA Key Size to 2048-bits] 
While I'm not convinced you're correct, I think that many posters here
underestimate the total cost of SSL.  A friend of mine -- a very competent
friend -- was working on a design for a somewhat sensitive website.  He
really wanted to use SSL -- but the *system* would have cost at least 12x
as much.  There were many issues, but one of them is that the average dwell
time on a web site is very few pages, which means that you have to amortize
the cost of the SSL negotiation over very little actual activity.

@_date: 2011-08-10 14:35:56
@_author: Steven Bellovin 
@_subject: [Cryptography] Crypto being blamed in the London riots. 
More precisely, Blackberry email is encrypted from the recipient's
Exchange server to the mobile device.
The scenario is corporate email; the business case is that RIM could
claim that they *couldn't* read the email; they never had it in the
clear.  However, that's only true for that service.  For personal
Blackberries, there is no corporate-owned server doing the encryption.
The service in question here, though, is Blackberry Messenger.  There
seems to be some confusion about whether or not such messages are
encrypted, and if so under what circumstances.  One link
( says that they're not, in any meaningful form.  More
authoritatively, says that they aren't.
The most authoritative source is RIM itself.  P 27 of
 confirms the CSE document.
Looking at things more abstractly, there's a very difficult key management problem for a decentralized, many-to-one encryption service.
Here, you're either in CA territory or web of trust territory.  In
this case, are the alleged perpetrators of the riots careful enough
about to which keys they're sending the organizing messages?  If
the pattern is anything like Facebook friending, I sincerely doubt

@_date: 2013-11-06 14:13:15
@_author: Steven Bellovin 
@_subject: [Cryptography] Ah, The Circles of Life 
What makes you think that purely random parameters are good?
Sometimes they aren't -- think s-boxes.

@_date: 2013-11-06 16:48:36
@_author: Steven Bellovin 
@_subject: [Cryptography] DNSSEC = completely unnecessary? 
Correct.  I showed some ways of doing very targeted DNS attacks in 1995,
based on work from 1990-1991.  "Attacks only get better; they never
get worse."  And I didn't even consider things like p0wned routers or
hosts on the LAN.

@_date: 2016-08-24 14:00:27
@_author: Steven M. Bellovin 
@_subject: [Cryptography] "NSA-linked Cisco exploit poses bigger threat 
This is the issue: C makes it hard to do the right thing.  Sure, good programmers will expend the extra effort to get it right -- Dave Presto wrote a safe string library for his upas mailer in the mid-1908s, *before* the Morris Worm.  I asked him about that once: "I didn't think I could get it right any other way."  But the fact that everyone else has had to roll their own illustrates the problem.
Sure, Java isn't a panacea.  But it does solve certain problems very

@_date: 2016-08-25 18:06:55
@_author: Steven M. Bellovin 
@_subject: [Cryptography] "NSA-linked Cisco exploit poses bigger threat 
Precisely.  I first heard more or less that line from Doug McIlroy himself;
he called C the best assembler language he'd ever used.
        --Steve Bellovin,
