
@_date: 2015-07-05 01:47:43
@_author: EddyHawk 
@_subject: [Cryptography] Best AES candidate broken 
Dear Jerry,
 Subject: Re: [Cryptography] Best AES candidate broken
 To: "Ryan Carboni"  Cc: "Crypto"  Date: Sunday, July 5, 2015, 11:01 AM
 On Jul 4,
 2015, at 4:23 PM, Ryan Carboni   fastest on software,
 and faster than Rijndael on
 hardware,
 Given that the criteria were a
 mix of security and performance, if it didn't make it to
 the final 5 and was the fastest, it must have been dinged on
 security.
 While there's plenty discussion of the 5
 algorithms that made it to the final round, I haven't
 been able to find anything on why the remaining 10,
 including Crypton, the subject of the paper at hand, were
 rejected.
Perhaps this old article can help?

@_date: 2015-07-06 03:30:07
@_author: EddyHawk 
@_subject: [Cryptography] Best AES candidate broken 
Dear Jerry,
 Subject: Re: [Cryptography] Best AES candidate broken
 To: "Ryan Carboni"  Cc: "Crypto"  Date: Sunday, July 5, 2015, 11:01 AM
 On Jul 4,
 2015, at 4:23 PM, Ryan Carboni   fastest on software,
  and faster than Rijndael on
  hardware
 Given that the criteria were a
 mix of security and performance, if it didn't make it to
 the final 5 and was the fastest, it must have been dinged on
 security.
 While there's plenty discussion of the 5
 algorithms that made it to the final round, I haven't
 been able to find anything on why the remaining 10,
 including Crypton, the subject of the paper at hand, were
 rejected.
Also, this one:
Best regards,

@_date: 2015-07-24 14:05:17
@_author: EddyHawk 
@_subject: [Cryptography] Whitening Algorithm 
Rob Seward (at Thursday, July 23, 2015, 4:50:03 AM):
use a small cryptographic sponge in duplex mode, for example
keccak[200, r=8] reduced to 6 rounds. this sponge instance has 96 bit
security, and requires only 25 bytes of memory. this is a very safe
solution, although of course a magnitude slower than yours, and also
needs a fair bit of code.
Be warned though before treating keccak the same
as any other prng:
I notice that attempting naive multiple feedbacks to keccak (as prng or some sort of ksa) will not improve its security
as one may hoped for, but may even reduce it, because
next input = current output, and then next input will be xor-ed
to current output
= zero-ed io state.
io state thus does not contribute to capacity state and
 instead the capacity state is 'drained' to regenerate io state
again, all without generating actual output. in this case, it would better to just perform multiple 'squeeze' immediately without extracting the output.

@_date: 2015-06-04 20:14:55
@_author: EddyHawk 
@_subject: [Cryptography] Introducing Chicha stream cipher 
Dear cryptography list members,
Here I propose my variant of Chacha stream cipher by D. J. Bernstein that may be stronger than the original, measured by a simple metric, without performance penalty under plain IA-32 implementations. However, certain optimizations which are considered in Chacha design, such as vectorized implementations for improved performance, are ignored here. Therefore such optimizations may or may not be applicable.
As I am not the original designer of Chacha, I can not and should not name it Chacha2. So I pick the name 'Chicha' for the modified Chacha proposed here.
Chicha is identical in every respect to Chacha except in these:
Â  -its quarterround function
Â  -its even (diagonal) round
While Chacha uses this quarterround function:
Â  a:=a+b; d:=d xor a; d:=rot32l(d,16);
Â  c:=c+d; b:=b xor c; b:=rot32l(b,12);
Â  a:=a+b; d:=d xor a; d:=rot32l(d, 8);
Â  c:=c+d; b:=b xor c; b:=rot32l(b, 7);
Chica uses this quarterround function:
Â  a:=a+d; a:=rot32l(a,17); b:=b xor a;
Â  c:=c+b; c:=rot32l(c,11); d:=d xor c;
Â  a:=a+d; a:=rot32l(a, 7); b:=b xor a;
Â  c:=c+b; c:=rot32l(c,23); d:=d xor c;
So Chicha-qrf uses 'xor rotated sum' as Salsa20's, starts with a:=a+d, and replaces rotation constants to 17,11,7,23 (all prime numbers).
And while Chacha uses this even round:
Â  chacha-qrf( 0, 5,10,15);
Â  chacha-qrf( 1, 6,11,12);
Â  chacha-qrf( 2, 7, 8,13);
Â  chacha-qrf( 3, 4, 9,14);
Chicha uses this even round:
Â  chicha-qrf( 0, 9, 6,15);
Â  chicha-qrf( 1,11, 4,14);
Â  chicha-qrf( 2, 8, 7,13);
Â  chicha-qrf( 3,10, 5,12);
How these changes improve over Chacha? I ascertain the improvement simply by measuring the randomness of its keystreams against Chacha's and Salsa20's. More specifically, I implement and/or adapt XSalsa20, XChacha, and XChicha to allow variable rounds and to apply feed-forwarding after the last chosen round, and I use randomly generated keys & IVs to produce their respective keystreams, several tenths of them and about 3 Mb each.
Then I measure their chi-square distributions using John Walker's ENT program on byte-level (ENT's default setting):
Â  Salsa20	keystreams attain goodÂ Â Â  randomness after 4 rounds
Â  Chacha keystreams attain goodÂ  randomness after 3 rounds
Â Â Â  (chi-square distribution range: 202-311)
Â  Chicha keystreams attain decent randomness after 2 rounds
Â Â Â  (chi-square distribution range: 237-666)
Afterwards, we look at the best known attack on Salsa20 & Chacha so far:
Â  Salsa20	best known attack is on 8 rounds
Â  Chacha best known attack is on 7 rounds
Note that eventhough Chicha doesn't attain good randomness after 2 rounds, suggesting that its hypothetical best attack will reach more than 6 rounds, my experiment show that Chicha does attain such randomness after hypothetical 2.25 rounds (ie, applying an additional quarterround on word 12,13,14,15 after odd round and before even round, but not after even round) which should result in hypothetical best attack on 6.25 rounds, which are still below 7 rounds.
In other words, I rely on earlier randomness of Chicha to back up its higher security claim against Chacha. So a way to disqualify Chicha as such is by showing an attack better than brute-force against Chicha on 7+ rounds.
Questions? Comments? Feedback?
Thank you for reading.
Best regards,

@_date: 2015-06-05 00:41:57
@_author: EddyHawk 
@_subject: [Cryptography] Introducing Chicha stream cipher 
Dear  DJ and members of cryptography list,
 Subject: Re: [Cryptography] Introducing Chicha stream cipher
 To: "EddyHawk"  Cc: cryptography at metzdowd.com
 Date: Friday, June 5, 2015, 4:26 AM
 Thing
  What makes you think
 Chi-Square T.O.R. is the right algorithm to test for
 randomness? I don't see the logic. It's
 not even easy to judge the output
 of that
 test because what you are looking for is the uniformity of
 the
 metric over many tests. No individual
 test tells you anything, nor is it
 sensitive
 to correlation between the data.
 In addition to base statistics like you get out
 of ent, I would look at
 things like the
 Markov-Renye min entropy test and run it over a few
 megabytes of data with group lengths > 7.
 It's described in draft
 SP800-90B. Also
 distinguishability tests (dieharder, SP800-22 etc), if
 you
 can get enough data.
 Thing  It reminds of
 meta-AES which is a lunatic cipher I dreamt up that has
 similar goals. Implement AES, but replace the
 key expansion algorithm with
 a reversible
 mode of AES that over 10 rounds is strongly
 indistinguishable
 from random, specifically
 AES-CTR. Inefficient as heck, but it works. If
 you want 256 bit keys, just make key[128:255] =
 the CTR IV rather than
 using the nasty 256
 bit key schedule of normal-AES. For this I probably
 deserve shooting.
 --------------------------------------------
Simply put, if XChacha/2 rounds keystreams are data-compressible
while XChicha/2 rounds keystreams are data-incompressible, wouldn't
it show that (X)Chicha/2 rounds has better randomness/diffusion over
(X)Chacha/2 rounds, regardless the metric used?
But yes, it alone doesn't show that Chicha has proper randomness and
it still needs further correlation/bias/whatever tests to ensure that.
For your super-AES, I suggest to replace its KSA with Anubis' KSA
and name it AESnubis  :-)
Best regards,

@_date: 2015-06-09 02:48:47
@_author: EddyHawk 
@_subject: [Cryptography] let's kill md5sum! 
Dear Zooko Wilcox-O'Hearn & cryptology list members,
The way I see it, the new *sum will need to fully accomodate both crypto &
non-crypto use, while b2sum doesn't yet achieve those by using blake2:
-non-crypto people will be more compelled to replace md5sum with b2sum
 only if blake2 is uniformly faster than md5 (ie., faster without ssse3+
 instructions)
-blake2 favors speed over attack-safety (most notably, by the removal of
 all constants for its compression function). crypto-worry people don't seem
 to like such reduced security. they may accept a few less steps, but not
 weakened compression function.
For that, I suggest modified blake2 (blake2x? blake3?) for the new *sum
-returns all/some of blake constants for compression function to satisfy
 crypto-worry users.
-introduces (double amount) finalization, like siphash's approach, say
 4 or 6 or 8 rounds for hashing & 8 or 12 or 16 rounds for finalization,
 to be uniformly faster than md5.
Blake2 is already very good, but perhaps these changes to blake2 could
increase its acceptance to all potential users.
Best regards,

@_date: 2015-06-10 06:39:30
@_author: EddyHawk 
@_subject: [Cryptography] let's kill md5sum! 
Dear Zooko Wilcox-O'Hearn and cryptology list members,
 I don't understand why this matters. BLAKE2 is faster than
 MD5 in
 software in most cases, currently. Future CPUs will probably
 further
 increase that.
I mean by 'uniformly faster than md5' that it should be faster on 32bit cpus
too, without simd thingy. implementators can't just simply replace md5sum with
b2sum and say to their non-crypto users: "btw, you will need to upgrade to
64bit cpus (& 64bit oses), preferably with more cores & also
neon/ssse3/sse4.1/avx/avx2 for this new b2sum to be faster than md5sum.
otherwise, it's slower. sorry."
At least, not until a few years more, when the cpus are all 64bit.
 BLAKE2 as currently specified already has a finalization
 step
 (preventing length-extension attacks) and is already faster
 than MD5
 (in most cases).
(Double/heavier) finalization here is meant to shift some of
the computational burden to a function only called once, not just to
resist the length extension attack:
 ----
               hashing     finalization
               ------------------------
 blake2b     : 12 rounds + shrinking                = 12+ rounds
 blake2x 8/12:  8 rounds + 12 rounds + shrinking    = 20+ rounds
 ----
so the total rounds are even higher than blake-512 while being much faster
than blake2b for bulk hashing (8 vs 12).
Anyway, these actually are my simple ideas on how to push chacha-based
hash function or blake to its utmost speed (closer to md4's if possible)
while attempting to retain its attack-safety, not to criticize blake2.
Best regards,

@_date: 2015-09-03 08:20:01
@_author: EddyHawk 
@_subject: [Cryptography] Checking for the inadvertent use of test keys 
Subject: Re: [Cryptography] Checking for the inadvertent use of test keys
 To: "cryptography at metzdowd.com"  Date: Thursday, September 3, 2015, 12:53 PM  So for now I've left things at the ad-hoc level, checking
 for ASCII strings,
 strings where value n+1 differs from value n by a small
 amount, that sort of
 thing.Â  It's not meant to be a bulletproof test, just
 something to ask the
 user "are you sure this is what's meant to be used as a
 key".
You could run a basic sorting algorithm to the key content
and count the number of swaps it performed.
If no swap or very few swaps happen, the key is probably a test key.
