
@_date: 2001-12-01 15:28:17
@_author: Werner Koch 
@_subject: wu-ftpd-2.6.2 fails GPG & PGP2 signature verifications, passes 
message of "Sat, 01 Dec 2001 03:14:11 -0800")
On Sat, 01 Dec 2001 03:14:11 -0800, Hugh Daniel said:
I don't know what you mean by this mess.  PGP >= 5 is simply not
OpenPGP compliant, even the 7.x versions seem to have a lot of
I remember a bug report for one of the last releases of wu-ftp where
the signature was also not valid.  The problem that time was that the
signature was created in textmode which wrong.  textmode should only
be used on human readable textfiles to cope with trailing whitespace
and line-ending issues.  There are many bugs in the way textmode is
treated - it even differs between the PGP 2.x versions; see rfc3156
for the ways which should be taken to overcome these problems.
You may want to do a  gpg --list-packets sigfile
to see how the message is actually composed and to track the problem
further down,   gpg --debug 1024 foo.sig foo
should be of great help, because it dumps the data which gets hashed
to some file.  The source of pgp 6.5.8 is available and you may want
to add similar debugging stuff - I am pretty sure that they hash
different things.
  Werner

@_date: 2002-12-10 18:25:12
@_author: Werner Koch 
@_subject: PGPfreeware 8.0: Not so good news for crypto newcomers 
As long as PGP Corp has the same assumption about the lifetime as you.
Recently a lot of users made a bad experience with NAI and PGP.
Nobody knows what will happen after the VC has been burnt ;-)
So please have a close look at PGP that it will always comply with the
OpenPGP standard and that it does not get away with proprietary and
undocumented extensions again.  I am confident that PGP Corp will do a
much better job than NAI in this regard.
   Werner

@_date: 2002-01-15 13:19:35
@_author: Werner Koch 
@_subject: PGP & GPG compatibility 
According to the bug reports I receive for GnuPG, it seems that even
the latest versions of PGP (7.0.3?) are still not OpenPGP compatible.
At least they still don't understand version 4 signatures on data
packets (only on keys).  I had in mind that this was fixed some time
ago, but obviously this isn't the case.
There is a problem wrt text mode signatures: no agreement was found on
what a line ending consists of.  PGP translates a CR inside a line
(well, what most non Apple programmers consider a line ending) into a
CR,LF sequence for hashing.  The proper solution is not to use
textmode signatures except for cleartext signed messages.
About two years ago we agreed on a way to implement MDC and defined
new packet types for it.  I did some tests with Hal Finney and it used
to work.  The OpenPGP draft was later changed to introduce key flags
and use one to enable MDC mode.  However, GnuPG uses MDC mode with all
ciphers of a block length other than 64 bits (i.e. Twofish and AES*).
The draft has still not been released as a new RFC so this may change
again :-(.
The flaw in the secret key protection mechanism was discussed for a
short time but it seems that nobody is willing to continue with this.
I made several suggestion on how to do it.
Interoperability tests should have happened last summer but for
unknown reasons they didn't.  It is very sad to see that after 3 years
we have not achieved to get OpenPGP into draft status :-(.
  Werner

@_date: 2002-01-15 18:32:01
@_author: Werner Koch 
@_subject: PGP & GPG compatibility 
So, you can't decrypt the attached message?  Or does this problem
only occur with another key?  I have never received a bug report
regarding such a problem.
BTW, even NAI says that PGP (before 7.0) is not OpenPGP compliant.
  Werner

@_date: 2002-01-16 10:25:11
@_author: Werner Koch 
@_subject: PGP & GPG compatibility 
On Tue, 15 Jan 2002 17:25:15 -0800, Will Price said:
Huh?  Go to the gnupg-users lists archive and search for PGP problems.
You will notice a couple of reports wrt PGP 7.0.3 - this is what I
have described.  I have not the time to dig out the messages for you
as too much of my time is already spend to cope with all those little
PGP bugs.  It is really an annoying job which does not get easier by
the "verbosity" of PGP's error messages ;-)
According to Len this was indeed fixed in 7.0 but it seems that it was
dropped in later versions.  I have not seen any message from 7.1.
RFC2440 - 5.9. Literal Data Packet (Tag 11)
   A Literal Data packet contains the body of a message; data that is
   not to be further interpreted.
So there are no conversion issues here.  Unless textmode is used -
which IMHO should be dropped entirely for clearness of protocol
layering.  But we should not discuss it here.
Not unlikely for Windows or KDE who are using UCS-2.
My feeling is that the proprietary vendors are not interested in
OpenPGP due to the fact that S/MIME does better feed the PKI cash cow.
Well the trademark PGP is a different story and probably good to sell
other products.
  Werner

@_date: 2002-01-21 09:35:24
@_author: Werner Koch 
@_subject: PGP & GPG compatibility 
Things would get much better if a PGP 2 version with support for CAST5
would get more into use.  We can't officially support IDEA for patent
reasons in GnuPG; the next release comes with a --pgp2 option to
bundle all the options needed for pgp 2 cmpatibility and furthermore
you will get a warning if a message can't be encrypted in a PGP2
compatible way.  There is a pgp 2 version by Disastry (
which support all OpenPGP defined ciphers.   Werner

@_date: 2002-01-21 09:42:45
@_author: Werner Koch 
@_subject: PGP & GPG compatibility 
BTW, there is such a gateway for OpenPGP at ftp://ftp.gnupg.org/geam/
which can also be used for org-to-end-user etc.  S/MIME support will
come soon.
  Werner

@_date: 2002-01-22 10:02:29
@_author: Werner Koch 
@_subject: PGP & GPG compatibility 
On Mon, 21 Jan 2002 20:50:22 +0000, Adam Back said:
The reason to write GnuPG were the patent problems with RSA (at that
time) and IDEA.  The GNU project is about Free Software and IDEA does
not allow the use of the software in a lot of countries.  It is not
sufficient that Ascom grants (on request) gratis licenses for private
use (there scope of private use is actual very narrow, as you are not
allowed to use the same box for any business purposes and even
charitable organisations have to pay per-user fees), the GPL does not
distinguish between private and commercial use.
See section 7 of the GPL for the reason why we can't distribute an
IDEA implementation.  Noone but Ascom and the patent laws are
disallowing the use of the IDEA module - we are just not able to
distribute it along with GPLed software and guess why we have this
loadable module feature in GnuPG.
If you want to use IDEA (instead of using a CAST5 enabled PGP 2.6)
write to Ascom and ask them to grant a royality-free and perpetual
license to use the IDEA algorithm with GPLed software.  Or even better
help to abolish all patents on algorithms and software:
 or This may be true for you and the small set of long term users.  In
general the use of PGP (well in the form of the IETF OpenPGP protocol)
has grown far beyond a small group of geeks.  There is at least one
major car vendor who demands the use of PGP enrcypted mail from all
suppliers.  If you look at the keyring anylyses at dtype.org you will
notice that there is a large user base.  keyserver admins should be
able to give some numbers to prove that PGP is actually in use.
Yes, this is indeed possible and GnuPG does it for a long time.
Because encryption interoperability with 2.6 is hampered by the IDEA
patent problem it did not made too much sense for me to put a lot of
effort into fixing some litlle annoyances related to the inability of
PGP 2 to encrypt in streaming mode.  Well, I believe David fixed most
of this while adding the --pgp2 option.
  Werner

@_date: 2002-01-22 16:41:00
@_author: Werner Koch 
@_subject: PGP & GPG compatibility 
On Tue, 22 Jan 2002 16:28:17 +0100, Gilles Gravier said:
Since version 1.0.4 all keys are created with AES as top cipher
preference.  The snapshot version 1.0.6c allows to change preferences.
If you encrypt to such a key and your application supports AES, it
will be used.
  Werner

@_date: 2002-05-22 08:55:53
@_author: Werner Koch 
@_subject: Just how bad is the Microsoft Visual C++ 6 rand function, 
Peter"'s message of "Tue, 21 May 2002 11:52:01 -0400")
On Tue, 21 May 2002 11:52:01 -0400, Trei, Peter said:
Which looks pretty standard and ISO-C compatible as long as RAND_MAX
yields 0x7fff.  Recall that rand() was never intended as a
cryptographic strong RNG - IIRC the specs say that it must produce the
same sequence of number for a given seed (set with srand()).
Ah yes, latest Posix draft:
   The rand () function shall compute a sequence of pseudo-random
   integers in the range 0 to {RAND_MAX} with a period of at least
   232.  The rand( ) function need not be reentrant. A function that
   is not required to be reentrant is not required to be thread-safe.
   The rand_r( ) function shall compute a sequence of pseudo-random
   integers in the range 0 to {RAND_MAX}. (The value of the {RAND_MAX}
   macro shall be at least 32 767.)
  Werner

@_date: 2003-06-08 21:07:49
@_author: Werner Koch 
@_subject: Nullsoft's WASTE communication system 
Encrypt/decrypt time for Libgcrypt:
Algo       ECB             CBC             CFB             CTR               ---------- --------------- --------------- --------------- ---------------
3DES        1120ms  1130ms  1140ms  1170ms  1200ms  1190ms  1410ms  1400ms
BLOWFISH     350ms   340ms   370ms   380ms   430ms   430ms   630ms   630ms
AES          290ms   310ms   340ms   360ms   410ms   410ms   620ms   620ms
AES256       400ms   410ms   440ms   470ms   510ms   510ms   730ms   720ms
There are no constraints on AES usage.
   Werner

@_date: 2003-06-18 14:27:20
@_author: Werner Koch 
@_subject: The meat with multiple PGP subkeys 
You may also want to use subkeys.pgp.net.  These are servers running
software not eating keys.
pksd used to have only a simple hack to support *one* subkey but bo
revocation for them etc.  If they encounter a key with an "unknown"
structre they start to eat packets or swap them around.
Updated pksd versions are much better and won't eat them anymore.
However due to the syncronisation they can't do much about already
garbled keys except for removing invalid parts.
I have these problems for may years now and as a workaround I use the
X-Request-PGP header to point to a valid source of my key.
There is a couple of new keyserver software actually in use but not
yet widespread enough.  subkeys.pgp.net is a goog start.
All keyserver operators should update to the new pksd or even better
use one of the modern servers.
   Werner

@_date: 2003-06-27 15:24:06
@_author: Werner Koch 
@_subject: Draft Edition of LibTomMath book 
Does the proprietary SSH still use GMP?  I know no other major crypto
apps using GMP for big number math.  A problem with GMP is that it
heavily uses alloca() and thus it is not that hard to find traces of
secrets in the core.
   Werner

@_date: 2003-03-11 22:27:07
@_author: Werner Koch 
@_subject: Encryption of data in smart cards 
Usually you don't need to encrypt data stored on a card. The files on
the card (where you store the data) are protected by ACLs or whatever
the card application provides for this.  If you want to encrypt the
data on the card, you also need to store the key on it. And well, if
you are able to read out the data, you are also able to read out the
key (more or less trivial for most mass market cards).
If you fear an eavesdropper between the box generating the data and
the actual smartcard, one uses secure messaging to protect against
this.  See your card's OS manual (or ISO 7816-8) on how to do it.
If your are talking about memory cards, you can use whatever protocol
you would use for encrypting files.
   Werner

@_date: 2003-03-13 08:32:39
@_author: Werner Koch 
@_subject: Encryption of data in smart cards 
Sorry my fault, by "read out the data" I meant to do this using a side
channel or with a hardware probe.

@_date: 2003-11-27 09:06:56
@_author: Werner Koch 
@_subject: Problems with GPG El Gamal signing keys? 
Yes, that is true.  The message was intended for the known owners of
such keys to give them extra time to revoke the keys.  However one
addresss was from killfile.org and actually a mail-news gateway ...
Yes, yes, I should have removed ElGamal signing key support back in
1998 when there was no more need for it.  I recall that some folks
begged me not to do that and I took the wrong decision.
  Werner

@_date: 2003-10-21 21:48:27
@_author: Werner Koch 
@_subject: WYTM? 
Joel N. Weber II developed PGP patches for OpenSSH:
and I am pretty sure that he has a server up somewhere.   Werner

@_date: 2004-01-08 14:45:24
@_author: Werner Koch 
@_subject: Problems with GPG El Gamal signing keys? 
On Thu, 27 Nov 2003 11:30:45 -0500, Ian Grigg said:
I don't know.
Regarding this ElGamal sign bug, the only thing I heard of were a very
few Debian developers who lost all their key signatures and have to
start again gathering new signatures from their co-Debian developers.
However there was no anger about this it sounds more like, "oops, I
shoot myself into my foot with my self-build secure thing".
  Werner

@_date: 2004-01-08 14:54:08
@_author: Werner Koch 
@_subject: Problems with GPG El Gamal signing keys? 
On Mon, 1 Dec 2003 11:20:10 -0800, Anton Stiglic said:
But duplicates the lines of code and thus introduces another source of
errors.  Its aghrd to tell what ebtter.  Given that the algorithms for
signing and encryption are really different (compared to RSA) it might
have been better to use separate source files for ElGamal-signing and
ElGamal-encryption and don't view them as similar.
Sure, that's what OpenPGP strongly suggests.  However ElGamal signing
stems from a time before OpenPGP when I tried to replace RSA by
ElGamal and keeping most of the PGP2 format (rfc1991) in place.
I don't know, please ask him.  Phong dot Nguyen at ens.fr.
  Werner

@_date: 2004-09-16 12:15:42
@_author: Werner Koch 
@_subject: pci hardware for secure crypto storage (OpenSSL/OpenBSD) 
On Wed, 15 Sep 2004 16:30:54 +0100, Ian Grigg said:
The advantage of the OpenPGP card is that is is a specification that
it is open and ready for everyone to implement.  No proprietary
strings attached as usual in the smartcard business.  So go write an
application according to the specs and it will, run with any card
compliant with the spec.  Any vendor may implement this spec on his
card.  Whether you do this on a slow 4 Euro chip or a fast 8 Euro chip
or on an iButton is up to you.  Our card is just one implementation of
the spec using an expensive chip.
  Werner

@_date: 2005-08-31 07:46:10
@_author: Werner Koch 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
On Mon, 29 Aug 2005 17:32:47 +0200, Simon Josefsson said:
5 Rabin-Miller tests using random bases are run after a passed Fermat
   Werner

@_date: 2005-12-14 12:07:48
@_author: Werner Koch 
@_subject: X.509 / PKI, PGP, and IBE Secure Email Technologies 
On Mon, 12 Dec 2005 10:59:05 -0600, Travis H said:
You need to clarify the trust model.  The OpenPGP standard does not
define any trust model at all.  The standard merely defines fatures
useful to implement a trust model.
AFAIK, PGP provides two different trust models; with GnuPG you may
also select between 4 trust models.  However this is implementation
specific and not part of the standard. The "classic" web of trust is just the commonly used one.  It is a
pity that many commonly used mail programs don't even make use of any
real trust model but use the "always" trust model.
The newer trust model "pgp" makes use of the advanced OpenPGP features
and allows implementing a hierarchical model very similar to the X.509
one.  In fact it is a superset of the X.509 model.
   Werner

@_date: 2005-01-06 10:43:32
@_author: Werner Koch 
@_subject: SSL/TLS passive sniffing 
On Wed, 5 Jan 2005 08:49:36 +0800, Enzo Michelangeli said:
It is a practical issue: Using /dev/urandom to avoid waiting for a
blocked /dev/random will let other processes wait infinitely on a
blocked /dev/random.
The Linux implementation of /dev/urandom is identical to /dev/random
but instead of blocking, (as /dev/random does on a low entropy
estimation) it continues to give output by falling back to a PRNG mode
of operation.
For services with a high demand of random it is probably better to
employ its own PRNG and reseed it from /dev/random from time to time.
   Werner

@_date: 2005-09-02 09:27:37
@_author: Werner Koch 
@_subject: Fwd: Tor security advisory: DH handshake flaw 
On Thu, 01 Sep 2005 15:04:43 +0200, Simon Josefsson said:
Oh well, if you are able to do this you have far easier ways of
compromising the security.  Tricking the RNG to issue the same number
to requests for the secret exponent of an DSA sign operation seems to
be easier.
Here it would be easier to add a backdoor to the prime certificate
check than to implement a fake RNG.
   Werner

@_date: 2005-09-12 16:34:16
@_author: Werner Koch 
@_subject: ECC patents? 
On Mon, 12 Sep 2005 11:58:14 +0300 (IDT), Alexander Klimov said:
Yes, there exists an implementation for an ECC implementation for
GnuPG.  The problem is that OpenPGP does not define ECC and thus it
does not make much sense to have it there. We have not worked on the Libgcrypt integration of that code because
there is not much need for ECC in general.  The costs advantage of ECC
smartcards is shrinking more and more and thus why should we bother to
implement the host part of ECC just for fun and try convincing the
OpenPGP WG to add ECC.
   Werner

@_date: 2006-02-11 21:23:29
@_author: Werner Koch 
@_subject: GnuTLS (libgrypt really) and Postfix 
On Sat, 11 Feb 2006 12:36:52 +0100, Simon Josefsson said:
I disagree strongly here.  Any code which detects an impossible state
or an error clearly due to a programming error by the caller should
die as soon as possible.  If you try to resolve the problem by working
around it will increase code complexity and thus error won't be
detected.  (Some systems might provide a failsafe mechanism at a top
layer; e.g. by voting between independed developed code).
Sure, for many APIs it is posssible to return an error code but this
requires that the caller properly checks error codes.  We have all seen
too many cases were return values are not checked and the process goes
ahead assuming that everything went well - this might be okay for games
but definitely not for cryptographic applications.
Libgcrypt tries to minimize these coding errors; for example there are
no error returns for the RNG - if one calls for 16 bytes of random one
can be sure that the buffer is filled with 16 bytes of random.  Now,
if the environemnt is not okay and Libgcrypt can't produce that random
- what shall we do else than abort the process.  This way the errors
will be detected before major harm might occur.
It is the same rationale why defining NDEBUG in production code is a
Bad Thing.
Against our advise Nikos rejected to implement a proper
initialization.  Libraries and threading is actually a deep problem.
It usually works well on GNU/Linux systems but this is more of
coincidence than by design.  We did quite some research on this and
experimented with different ways of automagically initializing the
thread primitives correctly; they all fail either at runtime or create
headaches when trying to write proper build rules.  The current
approach is by far the most flexible and safest.  But yes, the fact
that one library needs an initialization can't be hidden from the
application even if the application is using the lib only indirectly
Background: The problem stems from the fact that there are more than
one thread implementations available and used.  Mixing them in one
process cries for problems.  There are quite a couple of libs taking
the putatively easy approach of using pthreads.  Applications using
another thread implementaion (e.g. Pth to make auditing possible) will
then sooner or later run into grave problems.
This is known since Ted Ts'o wrote /dev/random and justified by
requirement of the Linux hackers to keep the memory use by a minimal
Linux build low.    Werner

@_date: 2006-02-12 22:25:21
@_author: Werner Koch 
@_subject: GnuTLS (libgrypt really) and Postfix 
On Sun, 12 Feb 2006 13:46:05 -0500, John Denker said:
Thus my remark about a independend failsafe system.
I strongly hope that for life critical systems nobody even things
about throwing in a bunch of general purpose libraries and declares
the task as done.  Fortunately these systems have resource constraints
so that such a solution won't come to mind anyway.
s,impossible,not foreseen/tested/coded by the developer,
Yes.  And one of the concurrent running system will take over. In
1969 this system used to be Armstrong, though.
Terminating a process is a well handled exception.  Think of hardware
failure; continue while knowing that tehre is something really weird
going on??
If you are thinking of exit please mentally translate this to assert.
Still believing one should never call assert(0) in a library?
Die as soon as you can; kill (getpid(),SIGKILL) might even be
justified in such a situation.  Try to make an attackers life as hard
as possible.  Yes, for life critical systems an attack scenario might
be different to judge and thus the design needs to be different.
Obviously I agree with Ben that that there is no way to know the
current state if something went wrong in unexpected ways.
   Werner

@_date: 2006-02-13 19:22:39
@_author: Werner Koch 
@_subject: GnuTLS (libgrypt really) and Postfix 
Actually libgcrypt exactly does this.  I have not looked at the
postfix code under question but it sounds like stderr has beend duped
to /dev/null and no log handler has been registered (e.g. to divert
logging to syslog).
   Werner

@_date: 2006-02-13 19:43:31
@_author: Werner Koch 
@_subject: GnuTLS (libgrypt really) and Postfix 
On Sun, 12 Feb 2006 23:57:42 -0000, Dave Korn said:
[ Then for what was assert invented for? ]
I agree. But the reality is not that of the text books.
Huh? According to ISO C and POSIX abort raises SIGABRT and the default
action is abnormal *process termination* - if your view is that
process termination takes away control from the main executable I
wonder how a file can control a process (unless the kernels plays
nasty games with on demand paging).
To my limited Windows experience abort() does terminate the process. I
have ported quite some Unix applications nativly to Windows and never
got in semantic problems you describe.  Anyway, Windows is strange
(atexit lists per DLL and such) but Libgcrypt is not really supported
Being in an insane state libgcrypt can't assure that this main loop
will continue to run - the stack might already be corrupted.  We don't
know and thus assert(!"fubar").
By design there can't be any error.  If there is an error something
really strange has occured, like improper chrooting.
Your joking right? I am usually quite sure that no attacker has made
it to one of the machines used for debugging. Outside in the Internet
wilderness I should then switch off all protection?  That is like
wearing a hard hat in bed and take it off at the construction site.
   Werner

@_date: 2006-02-13 19:52:23
@_author: Werner Koch 
@_subject: GnuTLS (libgrypt really) and Postfix 
On Mon, 13 Feb 2006 11:29:00 +0100, Simon Josefsson said:
Running Linux this is not possible because /dev/random is guarenteed
to be available.
I don't know where Postfix dumps the error messages from Libcrypt:
  fd = open( name, O_RDONLY );
  if( fd == -1 )
    log_fatal ("can't open %s: %s\n", name, strerror(errno) );
I guess you need to blame postfix for this.
So may I conclude that it is actually Good Thing that in this case
libgcrypt refrained from continuing to preserve the caller from false
Yes.  We discussed this already at length at more appropriate places.
I can only tell what Ted told me years ago.
   Werner

@_date: 2006-02-13 20:09:09
@_author: Werner Koch 
@_subject: GnuTLS (libgrypt really) and Postfix 
On Mon, 13 Feb 2006 03:07:26 -0500, John Denker said:
Actually the plain C similar thing is done for an internal error:
SIGABRT is raised and the top level code (or in theory any layer in
between) may catch it and try to continue.  Okay, this won't work in
practise because signal handling between independent developed code
(libraries) is guaranteed not to work correctly. And yes, we need to discuss whether whether a failed open should abort
or exit.  As of now it does an exit and not an abort() but I won't
insist on this.
For Libgcrypt's usage patterns I am still convinced that it is the
right decision.
   Werner

@_date: 2006-02-14 22:08:30
@_author: Werner Koch 
@_subject: GnuTLS (libgrypt really) and Postfix 
I agree.  However the case at hand is a bit different.  I can't
imagine how any application or upper layer will be able to recover
from that error (ENOENT when opening /dev/random).  Okay, the special
file might just be missing and a mknod would fix that ;-).  Is it the
duty of an application to fix an incomplete installation - how long
shall this be taken - this is not the Unix philosophy.
   Werner

@_date: 2006-02-15 16:18:00
@_author: Werner Koch 
@_subject: GnuTLS (libgrypt really) and Postfix 
On Tue, 14 Feb 2006 15:53:39 -0500, John Denker said:
Except that this does not work.  ERRNO gets set by most calls only on
error so if everything went fine in the "try ssome stuff" you get
random results.
   Werner

@_date: 2006-01-13 18:06:01
@_author: Werner Koch 
@_subject: long-term GPG signing key 
On Thu, 12 Jan 2006 00:48:05 -0600, Travis H said:
And it has the advantage that people will stop sending encrypted mail
to this key after the expiration date.  Comes handy if you forgot your
passphrase or lost physical access to the key.
   Werner

@_date: 2007-12-14 17:14:34
@_author: Werner Koch 
@_subject: More on in-memory zeroisation 
On Thu, 13 Dec 2007 21:11, apb at cequrux.com said:
This has the little disadvantage that you need to check the attributes
of BUF first and that you can't immediately see what the memset is used
for.  For a long time we use the macros below to document the intention
and to make sure that the compiler does not do any harm:
  /* To avoid that a compiler optimizes certain memset calls away, these
     macros may be used instead. */
   wipememory2(_ptr,_set,_len) do { \
                volatile char *_vptr=(volatile char *)(_ptr); \
                size_t _vlen=(_len); \
                while(_vlen) { *_vptr=(_set); _vptr++; _vlen--; } \
                    } while(0)
   wipememory(_ptr,_len) wipememory2(_ptr,0,_len)
   Werner

@_date: 2008-02-10 19:27:28
@_author: Werner Koch 
@_subject: TLS-SRP & TLS-PSK support in browsers (Re: Dutch Transport Card Broken) 
On Thu,  7 Feb 2008 16:37, Victor.Duchovni at MorganStanley.com said:
The last time I checked the Mozilla code they used their own crypto
stuff.  When did they switched to OpenSSL and how do they solve the
GPL/OpenSSL license incompatibility?
   Werner

@_date: 2008-01-31 21:24:23
@_author: Werner Koch 
@_subject: Fixing SSL 
On Thu, 31 Jan 2008 03:04, pg at futureware.at said:
Which has the problem that you may use any certifcate you ever created
wit cacert.org to log in.  Even certificates created for demo purposes
with published private keys.  That was the case up until a year ago; I
don't know whether this has been changed.  I was a bit surprised about
such a security flaw.
   Werner

@_date: 2008-05-28 15:56:50
@_author: Werner Koch 
@_subject: The perils of security tools 
On Wed, 28 May 2008 10:34, pg at futureware.at said:
It is not an implementaion issue but a requirement of the C standard.
To avoid buffering use
   setvbuf (fp, NULL, _IONBF, 0);
right after the fopen.
   Werner

@_date: 2009-03-03 08:58:47
@_author: Werner Koch 
@_subject: X.509 certificate overview + status 
On Mon,  2 Mar 2009 17:35, marcus.brinkmann at ruhr-uni-bochum.de said:
You may also import the certificate into GnuPG ("gpgsm --import foo")
and run "gpgsm --dump-cert" to get a human readable printout.  Example:
$ gpgsm --dump-cert 0x39F4F81B
           ID: 0x39F4F81B
          S/N: 01D8
       Issuer: CN=12R-CA 1:PN,O=Bundesnetzagentur,C=DE
      Subject: CN=TeleSec PKS SigG CA 17:PN,O=Deutsche Telekom AG,C=DE
     sha1_fpr: 13:0C:16:2D:91:68:7C:E0:AE:95:6F:11:08:34:3A:26:39:F4:F8:1B
      md5_fpr: D7:2B:65:D3:E6:5C:54:DB:B7:4A:47:49:6E:CF:36:F1
       certid: D6C0C14EE753E3D147C0827A4C8D579F130DEFD4.01D8
      keygrip: EC4EC0D13B47680C28869929D76B3357838CEC11
    notBefore: 2007-11-08 09:22:57
     notAfter: 2012-01-01 12:00:00
     hashAlgo: 1.2.840.113549.1.1.13 (sha512WithRSAEncryption)
      keyType: 2048 bit RSA
    subjKeyId: 57A001BB58498529AEE9DFAD6810FA056F5F3A9B
    authKeyId: [none]
 authKeyId.ki: 04DE9D7FDF437289BA694901F4E84928DE02196F
     keyUsage: certSign
  extKeyUsage: [none]
     policies: 1.3.36.8.1.1
  chainLength: 0
        crlDP: ldap://ldap.nrca-ds.de:389/CN=CRL,O=Bundesnetzagentur,C=DE,dc=ldap,dc=nrca-ds,dc=de?certificateRevocationList;binary?base?objectClass=cRLDistributionPoint
               issuer: none
     authInfo: 1.3.6.1.5.5.7.48.1 (ocsp)
                    subjInfo: [none]
         extn: 1.3.6.1.5.5.7.1.3 (qcStatements)  [12 octets]
         extn: 1.3.6.1.5.5.7.1.1 (authorityInfoAccess)  [62 octets]
         extn: 1.3.6.1.4.1.8301.3.5 (validityModel)  [14 octets]
CERTID and KEYGRIP are GnuPG specific.
   Werner

@_date: 2010-08-27 12:03:49
@_author: Werner Koch 
@_subject: questions about RNGs and FIPS 140 
I am nor sure whether it is already certified.  However a FIPS mode was
added to Linux featuring an FIPS approved ANSI X9.31 PRNG instead of the
   Werner

@_date: 2010-09-15 10:07:56
@_author: Werner Koch 
@_subject: Debian encouraging use of 4096 bit RSA keys 
On Tue, 14 Sep 2010 17:01, hmh at debian.org said:
We have made RSA the default in GnuPG for three reasons: First, DSA >
1024 is only supported by more recent versions of OpenPGP
implementations whereas RSA is supported for 10 years now with any sane
key size.  Second, we want to support SHA2 et al as soon as possible;
this is not possible with DSA-1024.  Third, DSA signing is fast
(DSA-3072 is about 7 times faster than RSA-4096) however verification is
much slower (~15 times).  Given that for most use cases verification is
the most prominent operation (think only of checking hundreds of key
signatures per key), this is for what we want to optimize.
OTOH, DSA vs. RSA is not the real question.  I have not seen a threat
model for DD keys.  I would claim that the best way to attack Debian's
code signing is to take over a developer's box and make use of his/her
key [1].  With ~ 1000 developers and thus at least this number of boxes and
keys this is a by far an easier way for malice actions than even to
think about how to break RSA-2048.  I doubt that this situation will
change in the next 10 years.
Right, but than you should take the primary key offline or put it on a
smart card - this removes the option to attack the primary key on the
developer's box.  And if one of the subkeys has been compromised it is
very easy to replace that subkey.     Werner
[1] An even easier way is to subvert the upstream source.

@_date: 2013-12-19 12:22:23
@_author: Werner Koch 
@_subject: [Cryptography] RSA Key Extraction via Low-Bandwidth Acoustic 
On Thu, 19 Dec 2013 01:19, anzalaya at gmail.com said:
OpenSSL seems not to be vulnerable.  The reason is that OpenSSL uses
Montgomery multiplication which protects against this concrete attack.
The attack is based on the specific way GnuPG switches between Karatsuba
and simple multiplication.
   Werner

@_date: 2014-04-16 21:58:32
@_author: Werner Koch 
@_subject: [Cryptography] I don't get it. 
switch statements without a default clause are useful to assert that all
enum values are handled.  Compilers can and do check for non-handled
values.  You do the default processing by other means.
   Werner

@_date: 2014-08-17 21:39:55
@_author: Werner Koch 
@_subject: [Cryptography] Which big-name ciphers have been broken in 
(Peter Gutmann's message of "Sun, 17 Aug 2014 15:56:56 +0000")
On Sun, 17 Aug 2014 17:56, pgut001 at cs.auckland.ac.nz said:
Just for the record: CAST5 is only used by default for symmetric only
encryption.  This is hopefully only rarely used and if so, the cipher
algorithm should have been given on the command line to match what has
been negotiated out of band with the recipient.  CAST5 used to be the
drop in replacement for IDEA.  Most of these decisions have been made by
the OpenPGP WG for PGP-2 (1992) backward compatibility.  It is hard to
kill that feature.
For normal asymmetric encryption AES is the preferred algorithm for more
than a decade.
   Werner

@_date: 2014-08-18 09:05:23
@_author: Werner Koch 
@_subject: [Cryptography] Which big-name ciphers have been broken in 
(Peter Gutmann's message of "Sun, 17 Aug 2014 19:49:09 +0000")
On Sun, 17 Aug 2014 21:49, pgut001 at cs.auckland.ac.nz said:
   Implementations MUST implement TripleDES.  Implementations SHOULD
   implement AES-128 and CAST5.  [...]
Thus you should have kept it for decryption and for being able to import
GPG generated secret keys.
It is funny that people loudly complain that RSA-2048 is not good enough
but never requested to change the default symmetric algorithm.  Well
except for a request last week where all kind of stuff should be changed
(e.g. CAST5 -> AES-256, where the latter is a MAY implement algorithm).
Thanks for your remark - I will do the switch to AES-128 for 2.1.
   Werner

@_date: 2014-01-23 16:26:08
@_author: Werner Koch 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
On Wed, 22 Jan 2014 19:56, crypto at senderek.ie said:
In addition virtually nobody uses the same key for encryption and
signing.  This is accomplished in OpenPGP using a set of keys instead of
just one key (By default a primary key for certification/signing and a
subkey for encryption).
   Werner

@_date: 2014-01-23 16:36:30
@_author: Werner Koch 
@_subject: [Cryptography] Does PGP use sign-then-encrypt or 
On Wed, 22 Jan 2014 18:57, pete at petertodd.org said:
Right, this is the de-facto standard since PGP 2.  PGP/MIME (RFC-3156)
also demands sign-then-encrypt.
In addition OpenPGP demands the use of an MDC (manipulation detection
code) which is the SHA-1 hash of the plaintext appended to the plaintext
before the encryption.  It is not the best thing one could do but it
mitigates many attacks on the CFB mode.  The MDC feature is widley
deployed since its introduction in in 2000 (GnuPG 1.0.2, PGP 7).
   Werner

@_date: 2014-07-23 15:25:11
@_author: Werner Koch 
@_subject: [Cryptography] The role of the IETF in security of the 
(Watson Ladd's message of "Tue, 22 Jul 2014 18:47:13 -0700")
On Wed, 23 Jul 2014 03:47, watsonbladd at gmail.com said:
Nope: We released several betas of gnupg 2.1 with full rfc-6637 support.
The Google folks are using this to test their JS code.  Unfortunately
the integration of Curve25519 is delayed because I planned to wait for
IETF standards.  Given that nothing happened over the last 6 months, I
now feel forced to go forward and write an OpenPGP specific I-D on how
to use Curve25519 and Ed25519 (mainly to get an algorithm ID for EdDSA).
   Werner

@_date: 2014-06-29 21:55:00
@_author: Werner Koch 
@_subject: [Cryptography] Good GPG email solution for Windows (NOT 
"Sun, 29 Jun 2014 10:29:40 +0100")
On Sun, 29 Jun 2014 11:29, brg at gladman.plus.com said:
It is just an optional feature.  We include it because it is small
compared to other GUI MUAs because we need to build and distribute the
GTK+ libraries anyway.
   Werner

@_date: 2014-09-12 10:45:29
@_author: Werner Koch 
@_subject: [Cryptography] distributing fingerprints etc. via QR codes etc. 
Well, I actually implemented
     --quick-sign-key fpr [names]
     --quick-lsign-key name
              Directly sign a key from the passphrase without any
              further user interaction.  The fpr must be the verified
              primary fingerprint of a key in the local keyring. If no
              names are given, all useful user ids are signed; with
              given [names] only useful user ids matching one of the-
              ses names are signed.  The command --quick-lsign-key marks
              the signatures as non-exportable.  If such a
              non-exportable signature already exists the
              --quick-sign-key turns it into a exportable signature.
              This command uses reasonable defaults and thus does not
              provide the full flexibility of the "sign" subcommand from
              --edit-key.  Its intended use is to help unattended signing
              using a list of verified fingerprints.
on your request.  However, backporting that whole stuff to the stable
GnuPG versions would have been too much work.
Grab a GnuPG 2.1 beta and it should be easy.
   Werner

@_date: 2014-09-14 11:41:41
@_author: Werner Koch 
@_subject: [Cryptography] distributing fingerprints etc. via QR codes etc. 
Would data like
  nonfoo://nonexistent.foo.org/sec?encoded_private_key
be a failsafe approach to avoid that a QR reader leaks a backup of a
private key via the browser?  I assume that foo.org is controlled by a
trusted party and that the subdomain does not exist.
   Werner

@_date: 2014-09-19 10:31:25
@_author: Werner Koch 
@_subject: [Cryptography] [cryptography] Email encryption for the wider 
message of "Thu, 18 Sep 2014 21:57:11 -0700")
On Fri, 19 Sep 2014 06:57, gnu at toad.com said:
The same can be achieved with a separate mail header for the key and a
local association of key and mail address for future communication
(which you need for the above scheme also).
   Werner

@_date: 2015-04-14 22:27:47
@_author: Werner Koch 
@_subject: [Cryptography] the TOFU lie - or why I want my meat... 
That proposal is by Neal Walfield, who is being employed and paid from
the donated money to work on GnuPG.  The TOFU thing is actually a major
part of Marcus' and mine STEED paper.
   Werner

@_date: 2015-04-16 11:00:14
@_author: Werner Koch 
@_subject: [Cryptography] ToFU +- SaFU 
rfc4880, 5.2.1 actually explains on how the key signatures are used.
For example:
   0x13: Positive certification of a User ID and Public-Key packet.
       The issuer of this certification has done substantial
       verification of the claim of identity.
But it also remarks
       Most OpenPGP implementations make their "key signatures" as 0x10
       certifications.  Some implementations can issue 0x11-0x13
       certifications, but few differentiate between the types.
9maybe in attempt not to be viewed as a PKI).
  5.2.3.20.  Policy URI
   [...]
   This subpacket contains a URI of a document that describes the policy
   under which the signature was issued.
   Werner

@_date: 2015-04-16 21:15:35
@_author: Werner Koch 
@_subject: [Cryptography] ToFU +- SaFU 
--sig-policy-url string
   --cert-policy-url string
   --set-policy-url string
     Use string as a Policy URL for signatures (rfc4880:5.2.3.20).  If
     you prefix it with an exclamation mark (!), the policy URL packet
     will be flagged as critical. --sig-policy-url sets a policy url for
     data signatures. --cert-policy-url sets a policy url for key
     signatures (certifications). --set-policy-url sets both.
     The same %-expandos used for notation data are available
     here as well.
   --ask-cert-level
   --no-ask-cert-level
     When making a key signature, prompt for a certification level. If
     this option is not specified, the certification level used is set
     via --default-cert-level.  See --default-cert-level for information
     on the specific levels and how they are used. --no-ask-cert-level
     disables this option. This option defaults to no.
   --default-cert-level n
     [...]
--set-policy-url since 1999, --default-cert-level since 2004.

@_date: 2015-08-06 09:43:18
@_author: Werner Koch 
@_subject: [Cryptography] More efficient and just as secure to sign 
6 Aug 2015 04:30:04 +0200")
On Thu,  6 Aug 2015 04:30, peter at cryptojedi.org said:
There is another point to consider.  When using a smartcard it is
obviously better to implement the entire signature algorithm in the
smartcard.  The whole point of using a smartcard is to better protect
the private key.
Now, smartcards have a very limited I/O bandwidth and thus it is
impossible to feed the card with large data so that the EdDSA algorithm
in the card can do its work.  You want to feed the card only with a
   Werner

@_date: 2015-01-06 11:26:42
@_author: Werner Koch 
@_subject: [Cryptography] 
=?utf-8?q?ything=3F?=
 message of "Tue, 06 Jan 2015 02:29:08 +1300")
On Mon,  5 Jan 2015 14:29, pgut001 at cs.auckland.ac.nz said:
I can't see why a file in the root of a tarball is not easy to find and
  tar xzOf openssh-6.6p1.tar.gz openssh-6.6p1/PROTOCOL | less
   Werner

@_date: 2015-10-05 20:13:15
@_author: Werner Koch 
@_subject: [Cryptography] [openpgp] OpenPGP SEIP downgrade attack 
Well, I assumed that this is the case (my "Yes") but in the next mail
Trevor explained that this is not true.  More important however is my
remark that we need to get MDC deployed so that we can issue an error
for non MDC packets instead of just a warning.
AFAIK, there are still implementations not supporting MDC and a small
number of folks loudly complaining when I removed PGP-2 support.
One of the goals of 4880bis is:
  - A symmetric encryption mechanism that offers modern message
    integrity protection (AEAD)
   Werner

@_date: 2015-10-06 08:55:47
@_author: Werner Koch 
@_subject: [Cryptography] [openpgp] OpenPGP SEIP downgrade attack 
And wait another 15 years until it has been taken up by all
implementations?  What is wrong with the planned AE mode?
   Werner

@_date: 2015-10-07 21:37:45
@_author: Werner Koch 
@_subject: [Cryptography] [openpgp] OpenPGP SEIP downgrade attack 
But raises the same problems as all data format changes.  When taking up
these trouble why got for a slow method whilst faster methods are
OCB works with all 128 bit block length ciphers and is faster than GCM.
   Werner

@_date: 2015-10-08 18:18:17
@_author: Werner Koch 
@_subject: [Cryptography] [openpgp] OpenPGP SEIP downgrade attack 
I heard of backups somewhat larger than that.  For mail it is anyway not a
problem - you sign and encrypt and you are done.  Not even a need for an
Well, for the majority of uses cases there is a gratis license grant
from Phil Rogaway for his patents.
Further daft-zauner-tls-aes-ocb-03.txt states:
   6.  Intellectual Propery Rights Issues
   Historically OCB Mode has seen difficulty with deployment and
   standardization because of pending patents and intellectual rights
   claims on OCB itself.  In preparation of this document all interested
   parties have declared they will issue IPR statements exempting use of
   OCB Mode in TLS from these claims.  Specifically - OCB Mode as
   described in this document for use in TLS - is based, and strongly
   influenced, by earlier work from Charanjit Jutla on [IAPM].
At IETF-93 this case was mentioned and it was suggested to ask for a
similar licenses exception [1,2] if we consider to use OCB for OpenPGP.
   Werner
[1] [1]

@_date: 2015-10-23 21:46:52
@_author: Werner Koch 
@_subject: [Cryptography] Other obvious issues being ignored? 
I would describe it in a mail with less hash words but that does not
change the true facts.  It is getting worse with every new release.
IMHO, the whole thing stems from an ill-attempted race to prove that gcc
produces better - in the sense of faster - code than LLVM (and to some
extend icc).  Too sad.
Given that the newer compiler versions give better warnings and thus
help to write better code, they should only be used as a mandatory lint
pass.  The actual used code should then be created by an old version with
only known bugs.
   Werner

@_date: 2015-09-30 17:09:13
@_author: Werner Koch 
@_subject: [Cryptography] Future GPG/PGP 
And GnuPG also support this since 2.1 (last November) - it is not yet in
the standard but several people started to use it and I do my commit
signatures with such a key.  Plain ECC using NIST and Brainpool curves
are also supported since 2.1 (RFC-6637).
Key creation using newer algos is hiden behind --expert for the sole
reason that it is better to first have software understanding ECC
deployed before most people start to create these keys.
   Werner

@_date: 2016-04-05 16:24:33
@_author: Werner Koch 
@_subject: [Cryptography] On the Impending Crypto Monoculture 
RFC-7253 suggests a re-keying after 2^48 blocks. I wonder who is going
to encrypt 4 Petabyte in one chunk to finds out that at the receiving
site the authentication did not validate due to a hardware introduced
bit flip.
   Werner

@_date: 2016-01-27 20:24:43
@_author: Werner Koch 
@_subject: [Cryptography] [FORGED]  cms with multiple signatures 
and GnuPG can also do it:
 fortune | gpgsm -a -u foo at example.org -u bar at example.org -s
   Werner

@_date: 2016-01-29 15:06:54
@_author: Werner Koch 
@_subject: [Cryptography] cms with multiple signatures 
It is pretty clear from the ASN.1 description.  Here is an excerpt from
RFC-5652 (but all profiles I used are identical in this regard)
The SignerInfo object has the actual signature.
   Werner

@_date: 2016-06-06 10:13:22
@_author: Werner Koch 
@_subject: [Cryptography] "Physical Key Extraction Attacks on PCs" 
Right, they bug GnuPG for quite some time with their research ;-).
Their latest attack got public in February
() due to an unexpected
publishing of the conference paper before the event.
The CACM paper mentions Enigmail and GpgOL.  The former actually has the
ability to decrypt all incoming mails in advance after the passphrase
has been given once.
   Werner

@_date: 2016-09-30 11:04:09
@_author: Werner Koch 
@_subject: [Cryptography] Privacy-enhanced OpenPGP 
parcimonie - privacy-friendly helper to refresh a GnuPG keyring
  Description-en: privacy-friendly helper to refresh a GnuPG keyring
   parcimonie is a daemon that slowly refreshes a gpg public keyring
   from a keyserver.
   .
   Its refreshes one OpenPGP key at a time; between every key update,
   parcimonie sleeps a random amount of time, long enough for the
   previously used Tor circuit to expire.
   .
   This process is meant to make it hard for an attacker to correlate
   the multiple performed key update operations.
   .
   See the included design document to learn more about the threat
   and risk models parcimonie attempts to help coping with.
Further, we plan to integrate the features of this tool into GnuPG
proper.  Current GnuPG already supports Tor and would use Tor by
default if it is running.
   Werner

@_date: 2018-05-15 11:03:59
@_author: Werner Koch 
@_subject: [Cryptography] Vulnerability found in badly broken email apps 
of "Tue, 15 May 2018 01:08:26 +0000")
On Tue, 15 May 2018 03:08, pgut001 at cs.auckland.ac.nz said:
Do you know such a mailer or do you have at least test mails?
People are always curious to see how attacks work - let's help them ;-)
   Werner

@_date: 2018-05-15 11:09:41
@_author: Werner Koch 
@_subject: [Cryptography] Table of vulnerable Efailhtml software 
For us text based folks, here is a hopefully easier to read table from
the efail paper 0.9.0, page 11.  Watch our for all these nos.
          TABLE OF VULNERABLE MAIL CLIENTS
-    = Encryption not supported
no   = Not vulnerable
yes  = Vulnerable
user = Vulnerable after user consent
-MDC = with stripped MDC, +MDC = with wrong MDC, SE = SE packets

@_date: 2018-05-16 13:57:13
@_author: Werner Koch 
@_subject: [Cryptography] Vulnerability found in badly broken email apps 
of "Wed, 16 May 2018 08:49:47 +0000")
On Wed, 16 May 2018 10:49, pgut001 at cs.auckland.ac.nz said:
Thanks.  Frankly I missed RFC-6476 when searching the index for
authenicated encryption.  Better to use a MAC than GCM.  Or well there
is RFC-8103 (ChaCha20).
Assuming that it will take a decade we could directly settle for OCB ;-)
   Werner

@_date: 2018-05-17 21:33:15
@_author: Werner Koch 
@_subject: [Cryptography] Vulnerability found in badly broken email apps 
message of "Wed, 16 May 2018 14:43:11 +0200")
On Wed, 16 May 2018 14:43, stephan.neuhaus at zhaw.ch said:
Not quite.  The MDC (Modification detection code) is used by default for
15 years or so.  If the MDC indicates tapering gpg prints appropriate
error messages and fails as you would expect.  Now it is possible to do
a rollback attack from MDC encryption to old style encryption with
negligible amount of garbled data.  gpg prints a warning in this case
because it needs to take care of legitimate use of non-MDC encryption
(mail archives or backup scripts originating from the last century which
use CAST5 or 3DES).
The pragmatically solution we implemented is to error out hard for a
missing MDC in the case of AES (or Camellia) but stick to the warning
From CAST5 and 3DES.  Clients have enough information to implement
another strategy and that is what Enigmail did yesterday.  And soon
they were bugged with complaints "I can't read my old mails anymore" or
"I can't read anymore the mails created by Obscure(tm) OpenPGP
The need for backward compatibility is a real curse but after all some
data wants to be decrypted after 20 years.  Anyway, for the next major
version of gpg we have implemented a new AEAD method and then we simply
forbid MDC.  There might be some migration steps needed by users but at
some point we need to do that.
Contrary to my first assumption I have no indication that error codes
were not checked by any client.  Thus the whole EFFail paper is about
the HTML backchannels.
Note that the above is all about OpenPGP and not about S/MIME.
   Werner

@_date: 2020-05-25 08:17:20
@_author: Werner Koch 
@_subject: [Cryptography] CMS or S/MIME test vectors 
Sorry, I don't have a good set of non-private test cases either.
But that reminds me that I am looking for CMS samples using X25519 et
al. (RFC-8410)?  OpenSSL seems not to be able to create such messages.
Before I go ahead and implement from the specs, I would very much like
to see and test against samples.
Samples of enveloped data using GCM (RFC-5084) would also be of
interest, given that Outlook will eventually support this.
   Werner

@_date: 2020-05-27 10:03:52
@_author: Werner Koch 
@_subject: [Cryptography] CMS or S/MIME test vectors 
I was not ware that GnuTLS supports CMS thus I didn't looked into this
direction.  I'll check it out.
BTW, I would also suggest to use the public key as subjectKeyIdentifier
in Ed25519 signed certificates than to use a hash of the public key.
Russ Housley mentioned that RFC-8591 (SIP-Based Messaging with S/MIME)
has an example with RSA and AEC-GCM (see A.3.2)
   Werner
