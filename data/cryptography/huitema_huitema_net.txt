
@_date: 2013-08-25 16:04:59
@_author: Christian Huitema 
@_subject: [Cryptography] Email and IM are ideal candidates for mix 
I think we can agree that the first step is to deploy home servers, and that
the first application there would  to host communication applications. Just
doing that without much other change would already provide protection
against the "silent spying" that goes on in big cloud servers.
Initial deployment of anything must provide an immediate reward to the early
adopters. You cannot rely on a network effect, and that means you can
certainly not request third parties to adopt a new protocol. So better pinch
our noses and say that, of course, we will accept SMTP mail. Probably SIP as
well, and XMPP. We just need at first to make sure that the home server is
easy to deploy and maintain. Then the adopters get the immediate reward,
"nobody can go through my mail archives without asking me."
The various P2P enhancements come next, once there already is a network of
home servers. The obvious one is a communication application that beats
traffic analysis by embedding its own "shuffling" or "onion routing." I
don't think we can run anything like that directly on a phone, it would
drain the battery way too quickly.

@_date: 2013-08-25 16:42:57
@_author: Christian Huitema 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
I studied such systems intensely, and designed some
( Using a
distributed hash table securely is really hard. The basic idea of DHT is
that information is spread on the network based on matches between the hash
of a resource identifier and the hash of a node identifier. All nodes are
effectively relying on every other node. In an open network, that is pretty
much equivalent to "relying on the goodness of strangers." You can be sure
that if our buddies at the NSA set up to watch the content of a DHT, they
will succeed.

@_date: 2013-08-25 18:04:13
@_author: Christian Huitema 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
Of course the data can be signed, encrypted, etc. But the rule of the game
is that the adversary can manufacture as many peers as they want --
something known as the Sybil attack. They can then perform various forms of
denial. For example, the connectivity of the DHT generally relies on connectivity
between nodes of similar indices. The attackers can research hashes that
fall very near the hash of the target node, add the corresponding nodes in
the DHT, and effectively place themselves in the path of DHT traffic meant
for the target node. This enables passive traffic analysis, and active
denial of service.
Another potential attack is to get node indices close to that of a popular
resource, effectively becoming the repository of record for that resource.
Again, that enables passive traffic analysis, e.g. finding who accesses a
specific resource, and also active denial of service attacks.
If the attackers can manufacture enough virtual nodes, they obtain control
of the network. They can use that passively for global traffic analysis.
They can also engineer selective disruption, inject traffic to DOS specific
nodes, and other fun games.
Bottom line, anonymous DHT are fragile.
If we want something robust, we have to forgo the mathematical elegance of
the DHT, and adopt a network structure in which nodes only connect to peers
that they trust. You could call that "networks of friends." That removes the
nice O(log N) properties of the DHT, and it becomes hard to guarantee that
all queries will converge. But the network becomes much harder to penetrate.
The old Freenet had a structure like that.

@_date: 2013-08-27 22:02:23
@_author: Christian Huitema 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
Hash: SHA1
When we designed PNRP, I was pretty adamant to avoid this business of storing other people's data. We assumed that your data would be stored locally. The cost is a bit of added synchronization cost, effectively scaling as the number of records that have to be published. But if you are looking at a P2P name server type application, there are very few such records. Basically, the less nodes rely on strangers, the better.

@_date: 2013-08-27 22:05:48
@_author: Christian Huitema 
@_subject: [Cryptography] Email and IM are ideal candidates 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
You can even use some hash compression tricks so you only need 9 or 10 characters to express the address as hash of the public key. That works very well, until you have to change the public key.

@_date: 2013-08-28 07:36:37
@_author: Christian Huitema 
@_subject: [Cryptography] Why human-readable IDs (was Re: Email and IM are 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
This is exactly the problem that Kim Cameron and I tried to solve by developing what we called "call signs." The idea is to compress the hash of the public by solving a puzzle: find the arbitrary "salt" so that the hash of the salt and the public key ends with a large enough number of zeroes. (Or 1, or any arbitrary patterns.) Publish then the "call sign" as a  fraction of the hash, say the leading bits, that is short enough to be memorized, or at least written on a napkin. Of course, you have to verify that N bits of call signs + M zeroes is long enough to provide a strong hash.
The birthday paradox tells us that collisions will happen after 2^(N/2) users in the same space. We assumed that the practical length was at most 10 characters, 50 bits, which means collisions would happen after a few million users. We mitigated that by adding a human identifier in the mix, making the call sign something like "Perry.A32-H45Z-ZE0." Now the collisions only happen in the space of "all people named Perry", which is much smaller than "everybody."
Of course, this was a Microsoft project, which Microsoft did not choose to develop. And it was patented...

@_date: 2013-12-12 08:54:01
@_author: Christian Huitema 
@_subject: [Cryptography] Size of the PGP userbase? 
There are some big There is probably more than one gap. In fact, I see five fairly big issues:
getting your own certificate, getting the right software in your mail
client, getting the certificates of your peers, managing multiple computers,
and working with web applications.
With PGP, getting a certificate translates to installing the PGP capable
software. Last time I tried it involved downloading GPG. With S-MIME, it
involves finding the well hidden security menu in Outlook, which then points
to series of certificate providers. Then, finding a provider you like,
paying the required fee, and again finding the right menu to have the
software installed in Outlook. In short, in both cases it requires jumping
through hoops.
Outlook has S-MIME built in, but if you want to use PGP you have to use a
plug-in. That means finding an adequate plug-in, paying for it, downloading
it, and making sure that it is kept up to date. With PGP, the list of peer's keys is managed in the local key ring. There
are good reasons for that, but it is a different management than the address
book. That means using different procedures to find keys, import them, etc.
I have no idea how to do that for S-MIME.
Mostly, I use Outlook. But I use Outlook on 3 different computers and on a
smartphone. If someone sends me encrypted e-mail, I currently decrypt it on
exactly one of these computers, mostly because I did not bother install the
PGP plug-in on the other ones. Even if I did, I would have to copy my
private to each of those. Then there is the little problem of mail clients. How exactly can I use one
of these without providing my private key to the service?
Some of that could be fixed rather easily. For example, it would not take
too much effort to have an S-MIME option to use self-signed certificates, or
an option to add the peers certificates to the address book entry. It would
require somehow securing the address book, but that's necessary anyhow --
why bother spoofing the key if you can spoof another field, e.g. a subtle
typo in the e-mail address? Replicating the certificate to multiple email clients probably requires some
secure storage on a server, but that can certainly be done. It will require
work, and integration with the mail client.
The web part is the hardest. I could see something like the javascript
crypto API loading the private key from a secure server, and providing a
service to the mail clients, but the details can be very hard to get right.

@_date: 2013-10-12 23:06:35
@_author: Christian Huitema 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - 
identity or memory of previous sessions, the best we can do in the inner generate an AES key for messages in each direction.
AES-CCM with their sequence number and their sending key, and keep other side.  We should get Stev Knowles explain the "skeeter" and "bubba" TCP options.
pretty much what you describe:  use Diffie Hellman in the TCP exchange to
negotiate an encryption key for the TCP session. That would actually be a very neat thing. I don't believe using TCP options
would be practical today, too many firewalls would filter them. But the same
results would be achieved with a "zero-knowledge" version of TLS. That would
make session encrypted by default.
Of course, any zero-knowledge protocol can be vulnerable to
man-in-the-middle attacks. But the applications can protect against that
with an end to end exchange. For example, if there is a shared secret, even
a lowly password, the application protocol can embed verification of the
zero-knowledge "session key" in the password verification, by combining the
session key with either the challenge or the response in a basic
challenge-response protocol. That would be pretty neat, zero-knowledge TLS, then use the password
exchange to mutually authenticate server and client while protecting against
MITM. Pretty much any site could deploy that.

@_date: 2013-10-20 10:27:53
@_author: Christian Huitema 
@_subject: [Cryptography] Mail Lists In the Post-Snowden Era 
like?  Is it inherently just an open discussion?  Or could we come up with to make it as free-flowing and easy to participate in and manage as I know of several attempts to do that, and the conclusion always seems to be
that e-mail is not the right tool for this job, and that specialized
bulletin boards are much easier to deploy.
It is pretty clear that end-to-end e-mail encryption using PGP or S-MIME
does not work for large groups. You end up having to solve the "distribution
of the key to a large group," which is a variant of "sharing a secret with a
large number of people," pretty much an oxymoron. If you want a solution
that can actually be deployed, you have to send securely to the mail
reflector, and have the mail reflector send securely to each subscriber.
That could be done, but still would not solve "anonymous posting."
It would be much easier to switch to a bulletin board format. Imagine
something like Slashdot, but with authenticated TLS access to the server.
Once a subscriber is authenticated, they get the option to post anonymously.
All subscribers can read the messages with a web interface. Clearly that
puts a lot of trust in the server, but no more trust than we put in the
current e-mail reflectors. If you place the server in a country with
appropriate privacy laws, and if the server management can be audited by
some trusted subset of the community, you should be good.

@_date: 2013-09-02 13:14:00
@_author: Christian Huitema 
@_subject: [Cryptography] NSA and cryptanalysis 
I would be very surprised if they had gotten any assistance from Microsoft.
It goes against the grain. Microsoft engineers are really indoctrinated with
the "trustworthy computing" agenda, with mandatory security training every
year, specialized design reviews, code reviews, tests and all that. Not
saying there are no bugs or oversights in Microsoft's code, but a deliberate
action like that is very unlikely. Also, It would be very difficult to keep
something like that secret for long, and the leak would have dire effects on
the company's reputation.

@_date: 2013-09-07 12:25:35
@_author: Christian Huitema 
@_subject: [Cryptography] Why prefer symmetric crypto over public 
Hash: SHA1
Another argument is ?minimal dependency.? If you use public key, you depend on both the public key algorithm, to establish the key, and the symmetric key algorithm, to protect the session. If you just use symmetric key, you depend on only one algorithm.
Of course, that means getting pair-wise shared secrets, and protecting them. Whether that?s harder or more fragile than maintaining a key ring is a matter of debate. It is probably more robust than relying on CA.

@_date: 2013-09-07 20:06:53
@_author: Christian Huitema 
@_subject: [Cryptography] Why prefer symmetric crypto over public key 
I am certainly not going to advocate Internet-scale KDC. But what if the application does not need to scale more than a "network of friends?"

@_date: 2013-09-08 14:20:59
@_author: Christian Huitema 
@_subject: [Cryptography] Market demands for security (was Re: Opening 
Bill Gates 2003 "trustworthy computing" memo is a direct proof of the
opposite. He perceived lack of security, shown by reports of worms and
viruses, as a direct threat against continued sales of Windows products. And
then he proceeded to direct the company to spend billions to improve the
matter. Say what you want about BillG, but he is pretty good at assessing
market demand.

@_date: 2013-09-08 21:22:13
@_author: Christian Huitema 
@_subject: [Cryptography] Der Spiegel: "NSA Can Spy on Smart Phone Data" 
Hash: SHA1
The high level summary is that phones contain a great deal of interesting information, that they can target IPhone and Android phone, and that after some pretty long efforts they can hack the Blackberry too. Bottom line, get a Windows Phone...

@_date: 2013-09-08 21:29:35
@_author: Christian Huitema 
@_subject: [Cryptography] Why prefer symmetric crypto over public 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1
There is however a little fly in that particular ointment. Sure, we can develop system that manage pairwise keys, store them safely, share them between several user devices. But what about PFS? Someday, the pairwise key will be compromised, and the NSA will go back to the archives to decrypt everything. We could certainly devise a variant of DH that use the pairwise key to verify the integrity of the session keys, but that brings the public key technology back in the picture. Maybe I am just ignorant, but I don't know how to get PFS using just symmetric key algorithms. Does someone know better?

@_date: 2013-09-17 23:48:40
@_author: Christian Huitema 
@_subject: [Cryptography] PRISM-Proofing and PRISM-Hardening 
Or we could make it easy to have one separate RSA key per front end, signed
using the main RSA key of the organization.

@_date: 2014-04-13 21:30:09
@_author: Christian Huitema 
@_subject: [Cryptography] Heartbleed and fundamental crypto 
It is indeed possible to implement on top of UDP a TCP-like congestion
control algorithm. One can for example run TCP itself on top of UDP. But when people say that the Internet does not like UDP, they are probably
not speaking about basic congestion control. They are concerned with series
of so-called "optimizations" that have been baked in the infrastructure over
time. Middle-boxes that know how to drop UDP packets first when congestion
happens. Firewalls that will only let TCP through, not UDP. Load balancers
that can manage TCP load balancing for a server farm, but not UDP.
But one should not be too pessimistic. There are also examples of UDP based
protocols that have been deployed at large scale. VoIP, for example, mostly
relies on UDP. Various VPN services tunnel data over UDP. Teredo tunnels
IPV6 over UDP. In fact, UDP has at least one deployment advantage of TCP: it
is much easier to cross a NAT with UDP than with TCP. Same goes for a
stateful IPv6 gateway.

@_date: 2014-04-13 22:18:41
@_author: Christian Huitema 
@_subject: [Cryptography] Preliminary review of the other 
I think that you are restating a variant of the end-to-end argument. The
Internet architecture has grown rather complex. A simple transaction like
"loading a secure web page" will involve a bunch of actors, DNS resolvers
and servers, web proxies and caches, firewalls and routers. One approach to
security is to try to secure every little link of these complex chains.
Another approach is to treat all that as a hopeless soup, and just trust an
end to end verification to make sure that the system is behaving more or
less as expected -- which is pretty much the TLS approach.
I love the end to end approach, but it has two big issues. First, if the
soup is in fact poisoned, the only current end-to-end option is to refuse to
eat it, e.g., refuse to open the web page. Much better than being poisoned,
but leaves you hungry. We would need a way to "retry getting the page using
a different set up," and we don't have that with TLS today.
The second issue is that if we only do end to end security, the TLA's can
still go sift through the soup and learn a lot about what we are doing.

@_date: 2014-04-16 19:18:25
@_author: Christian Huitema 
@_subject: [Cryptography] I don't get it. 
In the variant of C++ that we use at Microsoft, the "user types 11" scenario will absolutely be flagged by static analysis. The static analysis will learn that the array is size 10, and will complain if the program attempts to access it with an index that is not guaranteed to be in bounds. The programmer will be instructed to add bound checks.
I say "variant of C++" because we "decorate" the C++ code with SAL annotations, so that bound checking can be carried through procedure calls. At some level, you could say that the combination of C++ and SAL annotation defines a new language in which it is "possible to statically assert your code is free of memory safety errors."

@_date: 2014-04-26 18:21:20
@_author: Christian Huitema 
@_subject: [Cryptography] Heartbleed and fundamental crypto 
I remember writing a stub compiler for the language. That compiler was
contributed by Siemens to OSF DCE.
There was indeed lots of gratuitous complexity in ASN.1. Why was there a
need for SEQUENCE and SET, or a distinction between SEQUENCE OF and SET OF?
Why was there a need for both IMPLICIT and EXPLICIT tags? Why where there
three types of tag numbers? Why have two ways to encode the length of a
structure type? The worse was probably the extension method. All these extra
definitions created some joy in the tests. However, by the end of the effort
(in 1992) we had generated code that was reasonably fast and safe. After
all, it is a TLV specification, so the stub compiler could include
systematic checks for consistency, buffer overflow, etc. And we had great
fuzz testing to prove it. But the worse part of ASN.1 was the way extensions were defined. The early
definition with ANY and MACRO was bad enough, but then the table extensions
went way beyond what would make sense in a data description language. That's
really what you get when a language is defined by committee...

@_date: 2014-04-27 16:27:21
@_author: Christian Huitema 
@_subject: [Cryptography] Heartbleed and fundamental crypto 
able to
Of course, it would be very simple to develop a web service that responds to
 That would be some
overhead, but it would meet the requirement of encryption and
authentication. It would also have the advantage of looking like web
traffic, hiding the fact that this is in fact DNS traffic meant to evade
censorship.

@_date: 2014-08-04 21:02:38
@_author: Christian Huitema 
@_subject: [Cryptography] "The Visual Microphone: Passive Recovery of 
its "secure" room this way.
Very nice demo, but it requires a really high speed camera -- Nyquist and
all that. The beauty there is the "passive" part. The active version has been out
there for a long time. Point a laser at an object that could potentially
vibrate, measure the intensity of the returned light, feed the vibrations to
a loud speaker. Apart from the laser, the electronics are really
straightforward -- you could describe the capture system as a "single pixel
They use something far more sophisticated than a single pixel camera, as
explained in
 "Video
frame rates are in the range of 2kHz-20kHz, with resolutions ranging from
192x192 pixels to 700x700 pixels. Sounds were played at loud volumes ranging
from 80 dB (an actor?s stage voice) to 110 dB (comparable to a jet engine at
100 meter)... Processing each video typically took 2 to 3 hours using MATLAB
on a machine with two 3.46GHz processors and 32GB of RAM." They need a
relatively high pixel definition to retrieve the minute motions induced by
the sound waves, and they need the high frame rate to beat Nyquist. Multiply
high definition by high frame rate and you get a really large bandwidth
requirement. On the other hand, bandwidth requirement and computing requirement will only
be a problem for a limited time. Just light crypto, computer vision
algorithm only get better with time. I can foresee someone implementing the
basic filtering steps in an FPGA right inside a special purpose camera,
drastically reducing the bandwidth requirement. Somebody else will probably
use machine learning techniques to train better filters. What is a lab
curiosity now could become a viable product in a short time!

@_date: 2014-08-04 21:40:59
@_author: Christian Huitema 
@_subject: [Cryptography] "The Visual Microphone: Passive Recovery of 
show well using Yes I saw that. What they call a standard camera is in fact a rolling
shutter DLSR camera. The rolling shutter causes each line to be captured at
slightly different time. They get a "super-sampling" effect from analyzing
the movement of pixels on each line of the camera. That would absolutely not
work with a standard webcam, in which all the pixels are captured at the
same time.
loudspeaker playing speech, and took a video from a viewpoint orthogonal to
the loudspeaker-object axis, so that the motions of the bag due to the
loudspeaker would be horizontal and fronto-parallel in the camera?s image
plane. We used a Pentax K-01 with a 31mm lens. The camera recorded at 60 FPS
at a resolution of 1280?720 with an exposure time of 1/2000 seconds. By
measuring the slope of a line, we determined it to have a line delay of 16?s
and a frame delay of
5 milliseconds, so that the effective sampling rate is 61920 Hz with 30% of
the samples missing. The exposure time caps the maximum recoverable
frequency at around 2000 Hz." The technique that they describe effectively gets 1280 pixels per line and
compute their vibration on the horizontal axis. This is what they allude to
in the "viewpoint orthogonal to the loudspeaker-object axis." If the
loudspeaker had been placed in a direction perpendicular to the lines, they
would not have captured anything. Of course, that could be mitigated by
having two cameras at a 90 degrees angle. But at that point, you are
probably better off building a specialized device.

@_date: 2014-08-05 13:35:36
@_author: Christian Huitema 
@_subject: [Cryptography] "The Visual Microphone: Passive Recovery 
makes the attacker's job a bit harder and more expensive.
Yes. Also, even if the signal is hard to understand by humans, it might be
possible to use machine learning and train a recognizer directly on the
output signal...
Computer vision leads to all kind of neat applications like that.
Recognizing faces or reading license plates, obviously. Capturing heartbeat.
Classifying emotions. Finding the origin of a sound by comparing the sound
to vibrations of part of the image. Sound from images. The implications for
security can be interesting!

@_date: 2014-08-20 22:28:02
@_author: Christian Huitema 
@_subject: [Cryptography] CSPRNG for password salt 
the parts around" Not if you look at the bigger picture. There are so many cases in which
using "rand()" is problematic that our secure development guidelines just
ban it. Our developers get a simple message: if you want random numbers, use
"cryptogenrandom()," do not use "rand()." In fact, automated verification
will reject your commit if you try to slip in a banned API like "rand()" or
"strcpy()." This is much simpler than trying to explain that "rand()" is OK
in some places, but not in others, and you should do a case study...
The only exception may be scientific computations, simulations in which you
want to ensure that a known seed produces a predictable sequence of pseudo
random numbers. But then, you don't want to use rand() either, because the
period is way too short. You will probably end up with a Mersenne twister.

@_date: 2014-08-25 20:49:13
@_author: Christian Huitema 
@_subject: [Cryptography] Encryption opinion 
That particular deception is just one of the phishing techniques, in which
Alice is, for example, tricked into contacting "bankofamerikka.com" and give
out her Bank of America credentials. But the actual phishing techniques are
way more diversified. Phishers might just point the user to a web site that
they own, using social engineering to have the target overlook the URL. They
might be hacking some legitimate web site and plant a bug there. They might
just send an email attachment from a previously pwned account that the
target trusts. The technology may well ensure that Alice is indeed speaking
to the intended site, and yet phishing will still happen.

@_date: 2014-08-29 00:19:56
@_author: Christian Huitema 
@_subject: [Cryptography] Encryption opinion 
Lots of potential with that. The mouse talks to the laptop, all the while
broadcasting its presence and a unique identifier. Better yet, the phone
chats with the smart watch, providing a convenient beacon for whoever cares
to listen. And don't get me started on the FitBit...

@_date: 2014-08-28 22:06:43
@_author: Christian Huitema 
@_subject: [Cryptography] Phishing and other abuse issues [Was: Re: 
Hash: SHA1
Reminds me of the old saying about computer science problems and another layer of indirection, except in reverse this time. Take the basic example: Alice wants to work with "her bank." Computers don't quite know yet how to read minds, so we solved the problem with one layer of indirection. Alice is told that she should really connect to  Of course, that degree of indirection is executed inside Alice's brain. That leaves the door open to all kinds of attacks that target the space behind the users' eyes, to trick her into an alternative indirection, say to  or even to  Just need a page layout that is convincing enough for Alice, and she might not pay attention to the fine print at the top of the browser.
Iang calls that a MITM attack. IMHO, that's a poor choice of words, because 99.9% of the community will use MITM to designate a potential attack that inserts a hacker between Alice and  or even between Alice and  But the problem is real, and is worth addressing.
Maybe we should teach computer how to read minds. Or do some approximation with voice recognition, bookmarks, etc. But we should not just ignore the issue.

@_date: 2014-12-15 21:34:21
@_author: Christian Huitema 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
I bet you they also have access to the Linux source code.

@_date: 2014-12-29 18:52:21
@_author: Christian Huitema 
@_subject: [Cryptography] Certificates and PKI 
There is indeed a way to tune QName minimization, which is to "follow the
zone cuts." From
   To do such minimisation, the resolver needs to know the zone cut
   [RFC2181].  There is not a zone cut at every label boundary.  If we
   take the name  it is possible that there is a
   zone cut between "foo" and "bar" but not between "bar" and "example".
   So, assuming the resolver already knows the name servers of .example,
   when it receives the query "What is the AAAA record of
    it does not always know if the request should
   be sent to the name servers of bar.example or to those of example.
   [RFC2181] suggests a method to find the zone cut (section 6), so
   resolvers may try it.
Implementations could assume that algorithmically derived names like
"_._.mxhost.example.com" are in the same zone as
"mxhost.example.com." The cost of being wrong is not all that high. The
protocol ID will leak, but that can in most cases be already inferred from
the host name.

@_date: 2014-02-15 21:57:46
@_author: Christian Huitema 
@_subject: [Cryptography] Another Bitcoin issue (maybe) (was: BitCoin 
> encryption keys are often protected using the same hash algorithms that
 > mining ASICs (and FPGAs and GPUs) are designed to calculate at great
 > By repurposing the hardware that was designed for Bitcoin mining it would
 > possible to attack hashed passwords with an efficiency that wasnb
I am not sure I got the whole sentence, but should we not already assume
that "hashed passwords" can be attacked quite successfully using current
hardware, such as GPUs, maybe multiplied in a botnet. My working assumption
is that "if a human can remember the password, a computer can retrieve it
from the hash!" Not sure that we need mining hardware for that...

@_date: 2014-02-18 23:09:08
@_author: Christian Huitema 
@_subject: [Cryptography] The ultimate random source 
Hash: SHA1
If you rely on a capped camera to generate white noise, you may be out for a surprise with at least some cameras. There is a lot of filtering and processing that happens on board the camera itself, e.g. conversion from Bayer pattern to YUV or RGB, firmware that enhances the image, compression to JPEG before transmission on the USB bus, cropping and resizing on demand, etc. I would not be surprised if some cameras, when capped, just transmit a black image. The  camera is designed to produce an image that represents the scene in front of it. There are two sources of randomness that are "built in," the randomness of the scene itself, and the randomness of the position of the camera in the scene. A few degrees cause a lot of pixels to shift, a live scene has lots of varying bits. I would rather rely on that instead of making assumptions on the amount of filtering built in the firmware.

@_date: 2014-01-11 19:16:43
@_author: Christian Huitema 
@_subject: [Cryptography] Advances in homomorphic encryption 
more information that "pure" HE would, but that is an Homomorphic encryption enables computations using additions and
multiplications, but I wonder about the domain of application. Whether you
consider projection and joint in a SQL database, or map/reduce, we need to
perform comparisons. For example, we may want to find all the sales that
happened last week and compute the average profit. That requires accessing
the date field and verifying that it falls within last week's  range. I
can't see how to do that if the date is encrypted in a way that provides
semantic security.

@_date: 2014-01-12 11:38:22
@_author: Christian Huitema 
@_subject: [Cryptography] Advances in homomorphic encryption 
I don't think you can do that if the encryption provides true semantic security. In van Dijk and Gentry's proposal, encryption of is achieved by mixing the original number with a random number r, so that the encryption depends on r but the decryption does not. This ensures that the same number can be encrypted in multiple different ways. It also precludes any simple comparisons, pretty much by design.

@_date: 2014-01-19 17:04:08
@_author: Christian Huitema 
@_subject: [Cryptography] cheap sources of entropy 
The key here is to trust that the camera is not somehow subverted and does
not feed a "pseudo random" set of bits, just like any hardware that has been
modified. But then, if the camera truly delivers the pixels that it sees, I
wonder why I would rely specifically on pointing at a grey card. Simply
pointing at a landscape or an interior scene will probably provide just as
much entropy. Minute differences in the location and orientation of the
camera will cause pixels to shift. In a handheld device like a cell phone,
we can ask the user to take a series of pictures while randomly moving the
phone. Hashing  the images will certainly deliver some pretty  good input to
the entropy bucket.

@_date: 2014-07-17 18:36:14
@_author: Christian Huitema 
@_subject: [Cryptography] Steganography and bringing encryption to a piece 
Steganography on a piece of paper? A problem with the dictionary approach is that the text does not look like a normal letter. The censors may not be able to read it, but they can see that the text stands out. A phrase like "uncomplimentary threateningly. conceptually secures on pockiest" does not look like something you would place in a letter to grandma...
Speaking of grandma, my son and I were discussing encryption variants at the dinner table, and my mother chimed in. "How, I now encryption, our network used it to send messages to French underground and intelligence service contacts!" She went on to describe a variant of grille coding. Place the letters of your message at specified points in the grille, then use your imagination to fill the rest of the text so it looks like a normal letter. So, basically, they were using steganography on a piece of paper...

@_date: 2014-07-18 14:55:41
@_author: Christian Huitema 
@_subject: [Cryptography] Steganography and bringing encryption to a piece 
The made up language works for a personal diary, but it would not have solved the problem for my mother (and mostly my grandfather). They needed to send messages that would not be flagged by the censors. A language that censors did not understand was sure to draw the attention of the Gestapo!

@_date: 2014-07-18 14:55:41
@_author: Christian Huitema 
@_subject: [Cryptography] Steganography and bringing encryption to a piece 
The made up language works for a personal diary, but it would not have solved the problem for my mother (and mostly my grandfather). They needed to send messages that would not be flagged by the censors. A language that censors did not understand was sure to draw the attention of the Gestapo!

@_date: 2014-07-18 14:55:41
@_author: Christian Huitema 
@_subject: [Cryptography] Steganography and bringing encryption to a piece 
The made up language works for a personal diary, but it would not have solved the problem for my mother (and mostly my grandfather). They needed to send messages that would not be flagged by the censors. A language that censors did not understand was sure to draw the attention of the Gestapo!

@_date: 2014-07-20 17:30:22
@_author: Christian Huitema 
@_subject: [Cryptography] multi-key encryption of "meta" data 
what.  looks I have seen designs trying to achieve that with basically a drop box. Drop
an encrypted file at some random location, then arrange for the intended
recipient to get the key and the location. Of course this is merely a way to
achieve one degree of indirection, there is still a need to pass the key and
controlled by different with some kind of information and chaff There is a tradeoff between traffic analysis and the number of nodes. A
single node creates a single point of observation. Too many nodes allow for
easy correlation of who connects to what...

@_date: 2014-06-03 22:50:28
@_author: Christian Huitema 
@_subject: [Cryptography] To what is Anderson referring here? 
Two examples come to mind. RSA deployments definitely became easier after
the patent expired, and we may be witnessing a variation of that with
elliptic curves. EKE would probably be deployed more often if people were
not concerned with the patents.

@_date: 2014-06-04 22:12:18
@_author: Christian Huitema 
@_subject: [Cryptography] To what is Anderson referring here? 
I was not trying to be perverse. I remember big debates in the IETF in the
late 90's about default profiles for IPSEC/IKE, DNS SEC, etc. In all these
cases, the RSA patent issue was raised, and standards eventually settled to
some patent free option as the default. Why else do you believe we find all
these references to DSA in the 90's RFC? Check for example RFC 2535 ( the
specification of DNS SEC dating from 1999. You will see in the "KEY
Algorithm Number Specification" that RSA/MD5 [RFC 2537] is "recommended" but
DSA [RFC 2536] is "mandatory." Lots of time and energy was expanded dealing
with that...

@_date: 2014-06-28 13:14:51
@_author: Christian Huitema 
@_subject: [Cryptography] a question on consensus over algorithmic agility 
Hash: SHA1
Actually, that could be a pretty good solution for the crypto version of TCP. By nature, crypto in TCP will have to be negotiated by some kind of SYN option. The option will have to say something like "let's use TCP crypt version N." Which means that even if there is only one cypher suite defined for version N, there is still a way out, just define version N+1.
The "whole version" negotiation has the advantage of dealing with protocol bugs as well as algorithm obsolescence, without requiring support of a zoo of algorithms at any given version.

@_date: 2014-02-28 22:13:06
@_author: Christian Huitema 
@_subject: [Cryptography] The GOTO Squirrel! [was GOTO Considered Harmful] 
Of course it should have been caught. And of course you should check test
coverage, which should be near 100% for a critical procedure like that, But
this is also a story of multiple layers of protection failing one after the
other -- code style, code review, automated compiler checks, unit tests, end
to end tests... And the "goto considered harmful" should indeed be included in the coding
style. Like many others I could not help but write a small blog about it --
nes/. The "goto fail" programming style has many supporters, often using some
"CHECK_AND_FAIL()" macro. It does not generate extra instructions, it allows
for easy step by step debugging, and it does not require cascades of
indentations. But many of the issues that Dijkstra pointed out are still
there. In particular, it is very easy to get a memory leak or some other
side effect due to partial execution, much easier than if you enforce the
strict "structured programming" requirements.
Of course, not using goto does not guarantee no bug. In fact, the second
iteration of Patrick Chkoreff's "no goto" refactoring still has a bug -- it
will only output an error message if all test except the last one succeed,
instead of "if any test fails."

@_date: 2014-03-16 11:58:20
@_author: Christian Huitema 
@_subject: [Cryptography] Client certificates as a defense against MITM 
of whom has any way of identifying the other".  Sure, you might as well
allow the user to send a cert registered with some CA.  Someone in the
middle who can "open up" the SSL session being initiated can just replace
that with their own cert, and now there's no basis for trusting the the
client cert is actually bound to the user.  It seems we always end up back
at "key continuity" as the best we can do - which in the "parties initially
unknown to each other" setting seems unavoidable.
This comes down to "detecting MITM." You could indeed use client
certificates. You could also use some form of password check that is secure
against MITM, e.g. EKE. But the client authentication tends to happen
outside of the TLS exchange, because it is a somewhat complex user
interaction. What if this is the first time the client connects to the site?
What if they just start using a new device? What if they forgot their
password? If client authentication is implemented outside the TLS exchange,
what API do we have to tie the client verification to the TLS credentials
and negotiated keys?
Detection inside the second automated TLS exchange could also rely on
"re-negotiation." If the MITM attack does not happen all the time, it will
lead to renegotiation failure, and that can be detected.

@_date: 2014-03-17 21:05:09
@_author: Christian Huitema 
@_subject: [Cryptography] We need a new encryption algorithm competition. 
performance; (b)
Of course they can help the client. Just offload encryption to the cloud.

@_date: 2014-05-14 08:53:31
@_author: Christian Huitema 
@_subject: [Cryptography] Is it time for a revolution to replace TLS? 
There may be some hope there with the recent increase in number of top level
domain names. There is a single root for the DNS managed by ICANN, but we
can expect the TLD certs to become very quickly well-known and "pinned." In
theory, someone with ICANN keys could still change them, but in practice
this could be made into a very public event with lots of "societal control."
If you believe that, then we have effectively created a market for "name +
security." By registering your domain in a specific TLD, you get the
certificate management practice of that TLD. That would be a definitive
improvement on the current "hundreds of PKI authorities" model.

@_date: 2014-05-18 21:11:13
@_author: Christian Huitema 
@_subject: [Cryptography] [cryptography] Is it time for a revolution to 
"Datagram" relates to the transport of data as independent units. Louis
Pouzin coined the name as an opposition to the connection model in which a
path is first established and then a series of data packets streamed over
it, as in for example X.25 virtual circuits. As a transport concept, a datagram is pretty much "an independent unit of
transmission." There is well established design rule that for efficient
network transmission, the unit of control shall also be the unit of
transmission, otherwise you get the very inefficient behavior of resending
many packets because a single one was lost.
A web page typically does not fit in "a single unit of transmission," and
treating it as a unit of control and retransmission would be seriously
inefficient.

@_date: 2014-05-19 10:55:03
@_author: Christian Huitema 
@_subject: [Cryptography] updating a counter 
Or you could just use CRC32 or CRC64, adding a bit to the CRC checked
message instead of adding 1 to the equivalent counter. You will get to
change half the bits in the counter for each message, and you will have a
long enough non repeat period.

@_date: 2014-05-23 21:32:50
@_author: Christian Huitema 
@_subject: [Cryptography] The proper way to hash password files 
Having tripwires is fine, and I hope many systems do that. But the main
problem with these massive password breaches is password reuse. If the
attackers learn that  is using "P at ssw0rd!" on
E-Bay, chances are that he is using the same password on Amazon or Facebook.
They can start exploiting these other sites while leaving E-Bay alone. The
tripwires at E-Bay won't protect against that.

@_date: 2014-11-17 13:26:52
@_author: Christian Huitema 
@_subject: [Cryptography] FW: IAB Statement on Internet Confidentiality 
they start joyfully singing to
Do you really believe that the folks who pushed the IAB statement are not
aware of that?
Of course it is easy to be cynical. "Obscure standard outfit puts up a
statement. The spooks must be shaking in their boots." But it takes time to
update a bunch of IETF standards, and to undo what the IAB called "our
addiction to plain text." So instead of being cynical I would rather take
the statement for what it is, a step in a journey.
By the way, there were many such steps taken during last week's meeting. A
Wi-Fi network was dedicated to experimentation of MAC randomization. The
DHCP working group started discussions of privacy issues. A specific working
group starts working on DNS privacy. The work on TCP encryption progresses.
Lots of efforts on TLS profiles and deployments. All that may be going at a glacial pace, but there is something good about
glaciers. They are hard to stop.

@_date: 2014-11-17 13:26:52
@_author: Christian Huitema 
@_subject: [Cryptography] FW: IAB Statement on Internet Confidentiality 
they start joyfully singing to
Do you really believe that the folks who pushed the IAB statement are not
aware of that?
Of course it is easy to be cynical. "Obscure standard outfit puts up a
statement. The spooks must be shaking in their boots." But it takes time to
update a bunch of IETF standards, and to undo what the IAB called "our
addiction to plain text." So instead of being cynical I would rather take
the statement for what it is, a step in a journey.
By the way, there were many such steps taken during last week's meeting. A
Wi-Fi network was dedicated to experimentation of MAC randomization. The
DHCP working group started discussions of privacy issues. A specific working
group starts working on DNS privacy. The work on TCP encryption progresses.
Lots of efforts on TLS profiles and deployments. All that may be going at a glacial pace, but there is something good about
glaciers. They are hard to stop.

@_date: 2014-11-30 16:49:19
@_author: Christian Huitema 
@_subject: [Cryptography] Toxic Combination 
That would be a nice entry in the underhanded crypto contest. Given dictionary attacks, digest authentication is hardly better than plain text.
If we want a better solution, we have to implement something like AKE.

@_date: 2014-10-04 17:11:27
@_author: Christian Huitema 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic 
Actually, it is a bit more complex than that. In many applications, you have to be concerned about denial of service attacks. If an outsider can manufacture hash collisions, then you can end up with a serious issue, the hash resolution moving for example from O(1) to O(N). Think for example of a hash table going from TCP headers to TCP context, and a SYN attack amplifying the damage by picking combinations of address and ports that result in hash collisions.
That may be why in many such applications the common practice is to compute the hash using truncated MD5. Of course, this creates a maintenance problem when MD5 is deemed "unsafe" for cryptography applications, and you have to fix your code to now use SHA256...

@_date: 2014-09-21 11:17:12
@_author: Christian Huitema 
@_subject: [Cryptography] Simple non-invertible function? 
For the general case, you would have to demonstrate that for a given Encrypt
function there is no tuple (X, Y, key) such that encrypt(X,key) XOR X =
encrypt(Y,key) XOR Y.
Let's do a simple example. Assume encrypt(X,key) = X^key, i.e. a very simple
"encryption" function. Then encrypt(X,key) XOR X = key = encrypt(Y,key) XOR
Y for all (X, Y, key). So we have at least one example where the construct
does not provide a permutation.
Even for less trivial encryption functions, it would take some time to
demonstrate the absence of collisions.

@_date: 2014-09-25 14:48:49
@_author: Christian Huitema 
@_subject: [Cryptography] Of writing down passwords 
yourself forward in time to the present...
Place Raider is about 3D reconstruction from multiple pictures. John's
question was about "reading reflections on eyes or glasses." We are not
quite there yet. With a 1080p camera at 1 meter from your eyes, the eyes are
typically 30 pixels wide, and the iris 10 pixels. This is not enough to read
something. Even with the 41 Mpixels camera of the Nokia Lumia 1020, you will
get less than 150 pixels for the eyes and less than 50 for the iris. Getting
there, but not quite.
On the other hand, I was surprised when a friend took a photo of my office
with the Lumia 1020, and then showed me that he could read the handwritten
note pinned on the wall.

@_date: 2015-04-05 10:03:33
@_author: Christian Huitema 
@_subject: [Cryptography] Fwd:  OPENSSL FREAK 
Hash: SHA1
Engineering is about tradeoff. That includes balancing immediate cost and future risk. Automated kill switches negate that. They only make sense if the risk is so high that there is no possible balancing. How often have we seen that?

@_date: 2015-04-11 13:04:23
@_author: Christian Huitema 
@_subject: [Cryptography] upgrade mechanisms and policies 
There are two main reasons for creating a new protocol version: bug fixes, or performance enhancements. We do have lots of experience with bug fixes, and part of that experience is that a substantial fraction of bug fixes introduce another bug. We may debate whether the fraction is 10%, 20%, or 30%. It depends on quality controls during the making of the new version. But we can certainly not assume that the fraction is 0%. Performance enhancements have a similar track record. They may very well introduce a regression of some kind. So, yes, definitely, it can happen that sometimes after TLS/1.5 is published, we discover an issue, and realize it is actually less secure than TLS/1.4.
Assuming that the occurrence of regressions is low enough, there is always a simple fix. Instead of changing the negotiation mechanism to, for example, "prefer 1.4 to 1.5," it should be possible to simply "reissue 1.4 as 1.6." A bit of a waste in terms of numbers, but very little engineering cost.

@_date: 2015-08-02 11:28:43
@_author: Christian Huitema 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
That's what worked in previous similar scenarios, e.g. SNMP vs. CMIP, or OSPF vs. ISIS. Note that I cannot help associating IanG's message with the current state of the TCP crypto working group. And in that particular case, I don't believe there is much malice involved. The group started with a goal to "develop opportunistic encryption for all TCP connections," but quickly ran into two kinds of troubles. The first one was a need to traverse the hodge-podge of firewalls, inspectors and accelerators that we call "middle boxes." Turns out that if you want to do that, you have to leave TCP pretty much alone, and that negates most of the compelling advantages of the original "TCP Crypto" design. If you cannot secure the TCP protocol itself, you are bound to just insert a security filter on top of TCP, which brings the second issue.
We already know how to run a security filter on top of TCP. That's what SSL/TLS do. At that point, the obvious question is whether the original goal of "opportunistic encryption" is best achieved by just inserting TLS as a filter, or by developing a light weight filter that would be easier to insert -- where light weight means light weight negotiation, as the actual cost of encryption is pretty much constant in any proposal. There are bunches of arguments one way and the other, but they are all about implementation issues, not about anything drastic. For example, we don't want to encrypt twice, so any light weight filter would have to be disabled if the application actually runs TLS. We also want applications to be able to evolve from "opportunistic" to "strong" encryption, which means adding authentication. And that means either evolving a parallel authentication framework in top of the light-weight filter, or just switching to TLS. And then there is a question whether having two parallel technologies means twice more resiliency, or two times as many bugs.
So we are seeing two camps, not out of malice but because people weight different arguments differently. And yes, the only way out is to start deployments and see what happens.
By the way, there are actually three camps in the debate. The third camp is QUIC, the protocol designed at Google to subsume both TCP, TLS and the bottom layer of HTTP 2.0.

@_date: 2015-12-21 12:01:38
@_author: Christian Huitema 
@_subject: [Cryptography] Questions about crypto that lay people 
Same in Washington. Vote by mail, using machine readable forms. The coercion threat can most probably be mitigated without using fancy crypto. To work and actually change results, coercion has to affect a large enough number of votes. But large enough also means "easy to find out." The probability that "nobody speaks" decreases exponentially with the number of parties involved...
After that, it is a legal and political process, the outcome of which depends mostly on the local political culture.

@_date: 2015-02-15 18:35:36
@_author: Christian Huitema 
@_subject: [Cryptography] phishing attack again - $300m in losses? 
The spear part points to the reconnaissance of the target, usually through social networks. Reconnaissance helps a lot building context and making the bait much more tempting, because it is specially crafted for the target.
The usual finger points "between the keyboard and the chair." But obviously this is not sufficient. The classic attack operates through e-mail, and only involves a browser in a second stage, if at all. Attacks through spiked attachments do not involve a browser at all. The gaping hole there is the ease of forging an e-mail source.
Note that this is a very hard problem. For example, ensuring that the mail really comes from the source address "John Doe " would help, but would still leave open forgeries like a source set to "John Doe ". Part of the problem is indeed between the chair and the screen, and fixing that requires lots of work on the user interface.
You missed the news on the new deal, Yahoo instead of Google:  The purpose is not "browser advertisement" but "default setting for the search engine." Of course, setting the search engine results in steering search traffic and the corresponding advertisements to the highest bidder.

@_date: 2015-02-16 11:17:43
@_author: Christian Huitema 
@_subject: [Cryptography] phishing attack again - $300m in losses? 
There is actually a level of indirection between Office and the browser -- the system variable that sets default browser to the user preference. If you set that to Firefox, Firefox, not IE, will be launched when you click on a link in Office. So the integration is not quite as tight as you mention.
AI is actually not bad at making binary decisions. With proper training, it might be able to differentiate between a mail that actually comes from someone in your contact list and a spoofing attempt. Of course, this is only one of the steps in the phishing attempts.
First step is reconnaissance. The more information you make available about yourself, the easier it is to forge the convincing email that will phish you. Or to learn the various web sites that you go to and spike one for a water-holing attack. In the days of Facebook and LinkedIn and Twitter, reconnaissance is getting very easy.
Step two is generally the phishing e-mail. The goal is to make the target believe that the e-mail is legit, and have them then click on either a web link in the email, or an attachment. I said generally, because the same phishing attack could be conducted through social network if one of the target's contacts is compromised. It could also be conducted by laying a trap in a web site that the target often visits, if that site can be compromised to do the bidding of the phisher. SQL injection, for example.
Step 3 is the initial exploit that will deliver a payload to the target's computer. Great variety there. That's one of the purpose of the zero day attacks hoarded by spy agencies and by criminals. Maybe there is a virus in that PDF. Maybe the web site that the target clicked contains a spiked bit of flash. Maybe the page exploits a zero day in IE or Firefox. There are lots of possibilities. And if a virus does not do, the phisher can try to capture passwords by other means.
Remember, the initial goal is to get a beach head or two in the target organization. The phisher may try a number of targets, and only needs one of them to bite the bait. After that, the attack moves to the second stage, lateral propagation inside the corporation.
And yes, I agree with IanG that this situation is outrageous.

@_date: 2015-02-21 21:21:02
@_author: Christian Huitema 
@_subject: [Cryptography] Lenovo laptops with preloaded adware and an evil 
spheres, have ostensibly users open to other about privacy or security.
One way to look at that is that these agents are rubbing our collective
noses in our past collective mistakes. In that case, the collective mistake
is the reliance on WebPKI and its multitude of root CA, combined with the
apparent facility with which everybody and their evil twin manages to insert
their own certificate in the "root files" of our devices.
IanG in another thread expressed his outrage at the prevalence of phishing,
an outrage that many share. Again, this phishing is largely due to our past
collective mistakes, like the ease with which any midlevel hacker can fake
the origin of an email, the ease with simple SQL injection attacks can still
be used to hack websites, or the ease with which zero-day bugs in various
document parsers can be used to plant viruses on unsuspecting targets. To
name a few.
A particular example of phishing led to the recently disclosed attack on SIM
cards. But phishing was not the only past mistake there. Static shared
secrets, really? No forward secrecy? What year is this, 1994? Or 1984 maybe?
In a sense, that's a wake-up call. Stuff was kind of OK because the world
was a nice place and the business was good. Not anymore.

@_date: 2015-02-22 16:47:37
@_author: Christian Huitema 
@_subject: [Cryptography] Lenovo laptops with preloaded adware and an 
mutually authenticated connection You can use symmetric them, but in either case, someone
someone is the SIM card programmer.  just what is it that you propose to do?  unauthenticated.  Even so, probably rich white west have a rather
The real problem is the "static" part. Shared secrets may be an expedient
solution, but if the natural destiny of secrets is not eventually be shared
a little too much. Of course, there is the option of switching to a new SIM
card, but that only works if that card is not already compromised. The
reliance of pre-programmed SIM amounts to a design with a single point of
catastrophic failure.
didn't really get much interest until desk-top class machines (much much further than you might expect:  1996.  These are dates of back at least a year earlier, I worked in the field for over 30 years and somehow managed to never be
involved in the making of phone standards, so of course I can also blame
myself. We may naively believe that if more energy had be applied to the
subject we would have better designs. Or maybe not. The SIM card was a key
feature of the original GSM design, a feature very much liked because it
allowed users to change providers or devices by simply swapping a card. But
we are not in 1991 anymore, and even low end phones have enough computing
power to implement robust crypto. I am pretty sure that if we tried hard
enough we would find something.
talking about the inevitable delay world, under the administrative this is given what we now know mistake is to think it can have to be built on top.
Evolving the telco standards will take several years. On the plus side, I am
sure there are plenty of very angry people in Europe or Asia right now, so I
would expect them to be quite motivated. As for building security on top of the IMS system, there are limits. Sure,
you can probably decide to use Skype or Snapchat instead of the regular
telco service, assuming that these IP-based alternatives are reasonably
secure. But you cannot build privacy that way. The current IMS protocols
disclose the IMSI identity when establishing a connection to a tower, and
the IMSI identifies your SIM card. Even if you never use the phone or text
services, IMSI catchers like the Stingrays will find your location and be
able to "tag" the IP addresses that you use for further analysis of the
metadata. That part at least will have to change if we want to get back
privacy in the phones.

@_date: 2015-02-27 15:26:08
@_author: Christian Huitema 
@_subject: [Cryptography] trojans in your printers 
If you are that concerned with the printer, you should wrap it in tin foil
or store it in a metallic locker. Because of course it can find some Wi-Fi
connection all by itself...
As for random devices, I like the idea of having a separate subnet for the
devices, with its own SSID, address range, and no Internet connection. But
then, most of the "modern" devices require access to "the cloud." What

@_date: 2015-01-15 21:23:02
@_author: Christian Huitema 
@_subject: [Cryptography] Summary: compression before encryption 
The real question is whether the compressed file has more or less structure (or entropy) than the original text. In most cases, the compressed file has less structure, and compression before encryption makes the system more robust. If anything, the large pile of files in Utah is considerably smaller if the files have been compressed than if they were left in clear text.
There are two well-known issues, which I could sum up as "SKYPE and CRIME." In the Skype attack, the original stream of voice packets has a constant bit rate, but a compressed stream has a variable bit rate, since for example vowels compress more than consonants and silences compress more than anything. In that case, encryption after variable bit rate encryption provides information that is not be present if encryption is applied to the original constant bit rate data. Of course, there is an obvious mitigation, constant bit rate compression, which is indeed what most modern VOIP systems are doing.
In the CRIME attack, the opponent is able to insert data in the original clear text, using various forms of web trickery. Algorithms like GZIP compress better when the same strings are present several times, so each injection can be used as a predictor of the presence of similar data in the original text. If this third party injection is a concern, then the mitigation is to use a "stateless" algorithm, e.g. some form of Huffman coding where the code is derived from analysis of a pre-established thesaurus. This is why HTTP/2.0 uses the HPACK algorithm instead of GZIP.
Of course, if one is really concerned with analysis of message sizes, it is always possible to add some random padding to the compressed messages. This is obviously less efficient than vanilla compression, but probably still more efficient than foregoing compression altogether.

@_date: 2015-01-15 22:07:55
@_author: Christian Huitema 
@_subject: [Cryptography] Compression before encryption? 
compressed, then at some point it gets (s)he can send a _super-compressed_ choke any buffer/memory is a buffer overflow on steroids.  be several exponentials larger explosion of bits.
That's very easy to do with JPEG. Create a monochromatic image so it
compresses really well. Make it really large. In fact, if you don't care
about syntax checks, you can just forge a start of frame header that
specifies an enormous size, then enjoy watching programs doing a malloc of
width*height. You can also play games with chosen size values and integer
overflow. But this is hardly related to encryption. More related to the
general idea that one shall not trust data coming from unverified sources...

@_date: 2015-01-31 13:56:16
@_author: Christian Huitema 
@_subject: [Cryptography] De-Anonymizing 
That reminds me of a story from the 70's, when "electronic pass" where
starting to be introduced in enterprises. One particular insurance company
embraced it with gusto, requiring a badge read when crossing lots of doors
inside the building. Every week, the manager would get a detailed report of
where the employees had been, which corridor they crossed, even how much
time they spent in the restrooms. Unusual patterns would result in an
extended "one on one" between manager and employee.
Needless to say, said employees were not happy. So, they devised a simple
counter-measure. At the beginning of the week, they would drop all their
electronic badge in a basket, and then pick one at random.

@_date: 2015-07-12 17:20:12
@_author: Christian Huitema 
@_subject: [Cryptography] The names in "the mesh" 
Your proposed use of names derived from cryptographic keys reminds me a lot
of the work with did several years ago with PNRP. The principle was the
same, pick a master key and use a hash of that master key as a node's
identity. In our case, it was a key to an entry in a P2P mesh. Leaving aside
the specific details of the application, we got lots of feedback from our
use of identifiers of form +, very similar to:
    mmm:MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ:alice at cryptomesh.org
The main issue is that the hashes are very unwieldy. They cannot be visually
verified by the user. An attacker can generate an alternate key whose hash
looks "close enough" to the real thing, and then use MITM attack to
substitute that when the key is sent from Alice to Bob. Bob performs a
visual check, is fooled, and then the communication between Bob and Alice
can be intercepted. We explored using a "compressed hash" for verification purposes, which we
dubbed "call sign." The idea was to hash
"MB2GK-6DUF5-YGYYL-JNY5E-RWSHZ:alice at cryptomesh.org" plus some "salt",
choosing the salt so the hash ends with a large number of zeros. Let Z be
that number. We would then build the call sign from the first N bits of the
hash, and publish it as a short Base32 string. The strength of the
verification is "N+Z". For example, N=50 and Z=32 results in a 82 bit strong
password, and a 10 character string.
The point of the small string is that it can be spelled over the phone, or
copied from a card, without being too unwieldy.

@_date: 2015-06-21 13:21:00
@_author: Christian Huitema 
@_subject: [Cryptography] password fatigue;  was: Lastpass 
USB or Bluetooth would both work. You can probably implement a prototype with a phone app that stores the passwords and pushes them on demand through Bluetooth.
Not sure about the physical connection part. If the device is physically connected by USB, then you have to worry about the device itself being hacked through some maintenance API available from the PC through USB. If it is connected by radio like Bluetooth, you have to worry about Bluetooth hacks.

@_date: 2015-03-02 13:37:11
@_author: Christian Huitema 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
Yeah, that's weird. When I read that, I am reminded of the origins of X.509,
and the use of "natural names" in X.500. The idea at the time was to avoid
creation of extraneous identifiers, and just pile on enough natural
attributes to achieve uniqueness. If surname and first name do not suffice,
add a city. If that does not suffice, add a zip code... There is beauty in keeping things simple. For a user signet, why do we care
about more than the email address and the key? OK, I can see why we want to
add some management fields, such as some form of expiry date and creation
date. And maybe facilitate search. But that does not mean that the
searchable attributes shall be structured. A "common name" type of field
ought to be enough.

@_date: 2015-03-05 19:56:02
@_author: Christian Huitema 
@_subject: [Cryptography] DIME // Pending Questions // Seeking Your Input 
The DIME transmission itself appears to be a minimal form of onion routing:
the sender passes it to the sender agent, which encapsulates it. The sender
only tells the sender agent about the next step, the receiver's agent. SO
the sender agent forwards that to the receiver agent, which then passes it
to the actual receiver.
I believe we should be able to achieve something similar using a kind of
"postmaster" convention:
Inner message: from Alice at sender.net to Bob at receiver.net. Alice encrypts it,
so that bob can decrypt.
Alice places the message in an envelope, from postmaster at sender.net to
Bob at receiver.net. Alice encrypts, postmaster at receiver.net can decrypt.
Alice submits the message to postmaster at sender.net, asks postmaster to send
it to receiver.net.
Postmaster at sender.net agrees to send it, places message in an envelope from
postmaster at sender.net to postmaster at receiver.net.
Postmaster at receiver.net decrypts the outer envelopes, forward the inner
envelope to Bob.
Thinking of that as a form of onion routing allows for further extensions...
As for the signets, that may be the most interesting contribution. If done
right. If we can indeed solve distribution of user keys, then lots of good
things happen. But we have to keep it simpler than the initial DIME spec.

@_date: 2015-05-01 22:39:44
@_author: Christian Huitema 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
There have been attacks that hacked or abused CA privileges. But most of the attacks follow a simpler path -- tricking or convincing the user to add a particular CA to the root store of their device, or browser. Many corporations do that -- add the local firewall's certificate to the root store of corporate-owned machines, so they can break the encryption and encrypt the traffic at the firewall. Many schools will force a certificate like that on the student's computer, as a condition for using the school's network. Some ISP and hot spots are rumored to do it. There are of course technical solutions to detect the problem - CT, HPKP, various forms of pinning, etc. But the real issue is cultural. The practice will not stop until it is widely denounced.

@_date: 2015-05-03 15:45:23
@_author: Christian Huitema 
@_subject: [Cryptography] "Trust in digital certificate ecosystem eroding" 
Hash: SHA1
Yes. And this is indeed the right way to look at the problem. Not "does this certificate chain verifies according to the rules of WebPKI" but "can we verify that this is the certificate that the server domain intended to use." DNSSEC could be a great tool for that. If the site and the client already share a secret then channel binding could also help.
But! If the user lives in the Kingdom of Notrustistan, there is a catch. The local dictators could mandate that every computer and every phone ships with their very own version of ICANN root's key, enabling the Great Firewall of Notrustistan to spoof TLSA records and then MITM the TLS connections...

@_date: 2015-05-10 10:54:28
@_author: Christian Huitema 
@_subject: [Cryptography] Is there a good algorithm providing 
On May 10, at 6:16 AM, Peter Guttmann wrote
It depends on the application. If it uses fixed length message, e.g., 20 milliseconds of audio, then using variable length compression is very revealing. If it is subject to data injection, variable length compression enables guessing attacks. If it uses variable length messages, like web pages, then variable length compression does not reveal more than not compressing. For the latter, random padding looks tempting. But I fear that the random padding has to be statistically as large as the standard deviation between the message lengths.

@_date: 2015-05-11 16:32:18
@_author: Christian Huitema 
@_subject: [Cryptography] Is there a good algorithm providing 
At the same time, the IETF is pushing the encrypt everything agenda, and one of the big arguments is browsing privacy. You get arguments to encrypt Wikipedia to prevent censors from discovering which pages a particular user is reading. Wikipedia is public, but reading pages on homosexuality or abortion could get youths in trouble in many places. The argument goes that encryption will thwart the censors. Except of course that the encrypted traffic still reveal page lengths, compressed or not...

@_date: 2015-05-13 18:32:20
@_author: Christian Huitema 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
Reminds me of the ancient way of writing Greek.  One could think of a Feistel like construct that worked like that. One pass forward, next pass backwards, etc.  Would probably depend on a good initial vector, maybe also a trailing vector.

@_date: 2015-11-13 10:20:43
@_author: Christian Huitema 
@_subject: [Cryptography] Post Quantum Crypto 
Are we even sure about the three dimensions part? If I understand correctly, string theory postulates that there are many more than 3 dimensions.

@_date: 2015-11-15 11:52:42
@_author: Christian Huitema 
@_subject: [Cryptography] Fwd: Re:  Post Quantum Crypto 
On security, I don't know. But it certainly impacts the practicality of building quantum computers. The principle of quantum computing pushes against the borders of our current knowledge, such as the actual structure of matter and the interaction between particles. It is hardly surprising that building such devices is devilishly hard.
On the other hand, a breakthrough in theoretical physics would probably be rapidly followed by similar breakthroughs in the art of computing. But then, physicists have been trying to reconcile quantum mechanics and relativity for a long time, so we have to believe that the breakthrough will not happen tomorrow.

@_date: 2015-11-17 18:33:42
@_author: Christian Huitema 
@_subject: [Cryptography] Sadly predictable: Terrorism used as excuse to 
Actually, No. We should encrypt everything, for three big reasons: privacy, meta-data, and herd protection. These were debated quite heavily in the IETF, before arriving at the "encrypt everything" consensus.
The privacy arguments goes for protecting not just what you send, but also what you read, or who reads what. For example, a young man is not sending any particularly private information when reading a Wikipedia page about atheism from Saudi Arabia, but the knowledge that he did that is going to put him in trouble with the local morality police. We don't know what page is considered sensitive where, so better encrypt everything.
The meta-data argument is best explained with cookies. If you access a web site in plain text, the cookies are also in plain text. Anybody on the path can read them, and use that to attribute traffic to you. Of course, there are many more such examples of meta-data, and the safe solution is to just encrypt the whole traffic.
The herd protection is well known. If the only people using encryption are those who want to hide from the secret police, then of course if you use encryption you will get a visit from these folks. But if everything is encrypted, then you get "herd protection," much like when everybody is vaccinated.
We actually thought about that. It turns out that as long as you don't widely inflate the size of the exchanges, you also do not inflate power consumption all that much. The bulk of the bytes on the network are compressed video. Video compression, decompression and imaging are way more energy intensive than AES. Yes, you pay some extra cost for the initial exchange, but when you look at the global effect on the server farm or on the handset, it is actually not that much.

@_date: 2015-11-21 15:23:11
@_author: Christian Huitema 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on 
I get the reasoning, but I am not so sure of the applicability. The attack that DJB explains appears to be a known plain text attack. If I get 2^N targets to encrypt the same known plain text, then I have about 50% chance of finding one match after 2^(128-N) trials. If the plain text is not known, the odds are much worse. But if we admit that this is a known plaintext attack, we get a practicality issue. How often can the attacker predict the plaintext? Don't modern algorithm use some kind of IV to defeat such attacks?

@_date: 2015-10-26 07:07:34
@_author: Christian Huitema 
@_subject: [Cryptography] [FORGED] Re: How programming language design can 
> The problem is: Undefined behaviour is where compiler builders get to make In the sample, the compiler could perform the optimizations safely if it knew the expected range of the integer variable. If the compiler can predict the value will not overflow, the optimization is safe. Some checkers like Prefix can check that, and complain if an integer overflow is possible and not checked. I wonder whether the new C11 extensions enable that.

@_date: 2015-10-28 18:08:14
@_author: Christian Huitema 
@_subject: [Cryptography] Hiding parties identities 
I am looking at the Pre-shared key specs in RFC 4279, and in particular at
the privacy issues inherent with pre-shared key. According to 4279, the
client sends to the server a key identity so the server understands which
shared key to use in the exchange. The problem of course is that by doing so
the client reveals its own identity in a clear text message. This is
dutifully flagged in the security considerations, but no mitigation is
I can think of two kinds of mitigations. The first one is to encrypt the key
identity with a server provided key. The problem is that this is a bit
circular, as the server has to identity that identity encryption key. Also,
privacy is only achieved if the server key is shared with multiple clients,
but then it falls into the widely known secret category. The second one is to replace the key identity by a puzzle, e.g. a nonce and
the hash of the nonce and the shared key. The server tries many shared keys
until one is found to match, thus identifying the client with which the key
was shared. Bluetooth LE does a variation of that. The problem of course is
that the server load increases linearly with the number of clients, which
may be OK with small Bluetooth devices paired with a small number of peers,
but not so OK for medium to large servers.
Do you know a better way?

@_date: 2015-10-29 21:13:34
@_author: Christian Huitema 
@_subject: [Cryptography] Hiding parties identities 
If the key is unique to the user, then the 128-bit string is a unique identifier. Given enough observed traffic, unique identifiers will be tied to the user's identity. For example, if the identifier is observed on traffic originating from the user's home, it can be tied to the user. If the same identifier is later observed from a Wi-Fi hot-spot, the user will be identified. Then, all traffic originating from that IP address at the hot spot can be tied to the user.
PSK seems to be the authentication method of choice for Internet of Things. Also, it is one of the plausible options for Post-Quantum.
Yes of course. There are many leaks, and we need to plug them all.
RFC 7624 is a good start for that.

@_date: 2015-11-01 10:39:24
@_author: Christian Huitema 
@_subject: [Cryptography] [FORGED] Re: How programming language design can 
Actually, a lot can be determined at compile time. If the function's manifest specifies that an argument shall not be null, the compiler can check whether the calling program guarantees that the argument will not be null. That is done by tracing the variable through the potential execution paths, which requires annotating functions handling that variable, checking for "== NULL" tests, etc. Of course at compile time the exact values of a variable cannot be known, but a check whether a variable is guaranteed non null or not is entirely possible.
That's arguably perfectly fine, if the compiler can also check that the function will never be called with a non-null argument. Of course, that's a big if. It implies that the non-null property is exposed in the language or its extensions, and properly verified. It also requires that if the function is placed in a library, the linker does not assemble it with an application that does not honor the extensions.
By the way, the same kind of declarations tests can be used to verify array bounds, zero termination of strings, actual initialization of variables, etc. It is technically possible to extend C to do all that.

@_date: 2015-09-03 15:22:18
@_author: Christian Huitema 
@_subject: [Cryptography] Checking for the inadvertent use of test keys 
You could consider using machine learning. Get a good sized sample of test keys, an equal size sample of no test keys, constraint the learning enough so that it does not simply enumerate the test keys, and you would get a nice little classifier that would tell you whether to trigger the question.

@_date: 2015-09-21 15:32:36
@_author: Christian Huitema 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
The leakage is not so much at the individual ad level than at the auction sites were publishers and advertisers meet. When a web page load, scripts will run in the "place holder" for the app, which will trigger a real-time bid for an ad to fill the space. The bid request from the ad exchange will be submitted to maybe 15 different aggregators, and the highest bidder will get to show the ad. The sequence is defined by the "Open Real-Time Bidding" protocol, published by the Internet Advertisement Board: Each of the aggregators receiving the bid request sees the bid data: identification of the content, of the device, of the user -- device ID, location, brand, model, user ID, age, home location, interest and keywords, relevant cookies. If an agency wanted to track user activity, they could just sign a back room deal with one of these aggregators, and get all that bidding data. No need to actually publish an ad.

@_date: 2016-04-09 08:00:25
@_author: Christian Huitema 
@_subject: [Cryptography] At what point should people not use TLS? 
Bill Cox commented on that already. To reinforce his point, we see Google actively participating in the TLS WG. They also have an official position that he ad hoc security stack in QUIC will be replaced by TLS 1.3 when available.
There is some truth to the PKI link, but that is changing. For example, there are several IOT stacks that specify use of TLS with shared secrets -- definitely not linked to PKI. The rationale for using TLS rather than an ad hoc development is obvious: avoid the design errors risk with an independent design, and avoid the implementation bugs with a new from scratch implementation.

@_date: 2016-04-09 21:33:33
@_author: Christian Huitema 
@_subject: [Cryptography] At what point should people not use TLS? 
avoid the design errors risk with an independent design, and avoid the
implementation bugs with a new from scratch implementation.
bugs in TLS :-) ?
Ah Ah Ah. Of course not. This is just that if you design your own, you are
very likely to make more mistakes than whatever is left in the TLS protocol,
without the benefits of many people actively looking at the spec.

@_date: 2016-04-14 17:44:47
@_author: Christian Huitema 
@_subject: [Cryptography] Simple IoT sensor encryption ? 
Simple threat: the attacker spoofs the cheap sensor, and convinces the system that it is really freezing in the master room. Based on that input, the system cranks the boiler way up. The people sleeping in the master room end up being cooked.

@_date: 2016-04-18 14:44:42
@_author: Christian Huitema 
@_subject: [Cryptography] Is "drivers for foo" a major malware vector? 
As far as Windows is concerned, most people don't look online either. They get the driver installed on their PC by the OEM (e.g. Dell) or they get it from Windows Update. Some adventurous folks may try to get a more up-to-date driver directly from the manufacturer site (e.g. Intel). There are fewer and fewer reasons to do that as most manufacturers will just publish the latest driver on Windows Update. Going to some random third party web site looks like a really bad idea. The only plausible rationale is because the original manufacturer has gone out of business, or has abandoned the product. You would need to exercise a lot of caution. I would certainly not do that for a keyboard.

@_date: 2016-04-18 16:26:24
@_author: Christian Huitema 
@_subject: [Cryptography] Is "drivers for foo" a major malware vector? 
Yeah, I knew all that.
That's the whole point of building a "golden path" for getting drivers through Windows Updates. So that users won't have to web through the dark corners of the Internet to get crazy drivers. Positive message: "do this and you will be OK." That tends to work better than negative warnings. Also, requiring signature of driver files, which provides some traces. But then, we can get into the whole PKI argument again... I have not heard of such driver uploads causing big problems in practice. There may be lots of bait out there, but not very many phishes.
You should check the state of freeware downloads, bundling with the likes of Superfish. That's a much bigger problem that drivers.

@_date: 2016-04-26 16:49:05
@_author: Christian Huitema 
@_subject: [Cryptography] Current state of WPA2 security for IoT access ? 
There are two problems:
1) WPA2 is a pass-phrase based. Easy-to-memorize pass phrases created by and for humans can be cracked by a dictionary attacks.
2) The key used for a specific device is the hash of clear-text nonce and the shared pass-phrase. Anybody who knows the shared pass-phrase and listens to the initial exchange can derive the key.
For IOT devices, there are two simplifications. First, there is no need to be "human friendly," since you have to use some kind of automated provisioning process. Second, you are probably not very concerned with some IOT devices snooping on other IOT devices in the same network. The simplest solution is thus to use a long machine generated pass phrase for the WPA2 routers dedicated to the IOT network.
For human friendly networks, the solution is to move away from WPA2 and use an 802.1X based solution. PEAP + MSCHAPv2 using a common identity and a common pass phrase would work just fine.

@_date: 2016-08-11 09:32:22
@_author: Christian Huitema 
@_subject: [Cryptography] Public-key auth as envisaged by first-year 
Are you sure? We live in the time of big data and machine learning. It ought to be possible to train some kind of neural network with examples of timing on straight connections, and examples of timings on MITM-ed connections, and get some kind of indicator. Just another side channel.

@_date: 2016-08-22 10:34:34
@_author: Christian Huitema 
@_subject: [Cryptography] Real-world crypto/PRNG problem:  Bridge 
48 bits of state is obviously not enough for generating decks of bridge.
Given a 52 card deck, there are about 5.36E28 possible decks, 6.35E11 possible hands, and 5.16E21 possible pairs of hands. This implies that each deck can reveal more than 95 bits of information. So, clearly, one can use a deck as an oracle to guess the 48 bits of state of their PNRG. A pair of hands, such as the player and the dummy, reveals 72 bits of information, and that too is enough to get an oracle for the 48 bits of state of the PNRG. When playing bridge, a player only sees his own hand during the bidding phase, but when the bidding concludes, the hand of the highest bidder's partner is displayed on the table, becoming the "dummy". So, we can have a situation where when the game play begins, a player can look at his own hand and at the dummy, use a powerful computer, retrieve the state of the PNRG, and accurately predict the hands of the two other players. Once the PNRG stat has been predicted once, just looking at one hand is enough to re-synchronize the state the PNRG and predict the deck.
If they want to generate 72000 hands, they need at least 112 bits of state.

@_date: 2016-12-04 10:40:30
@_author: Christian Huitema 
@_subject: [Cryptography] OpenSSL and random 
seed = HMAC( fixed_secret, time() || MAC address || IP address || kernel version || ... );
Yes, that works quite well. But it is also an example of "all problems can be solved with one level of indirection". Your formula translates as, to get per-device unique keys, you don't need strong entropy, just ... a unique per device fixed secret. Don't you need some magic to initialize that for the first boot?

@_date: 2016-12-18 19:13:50
@_author: Christian Huitema 
@_subject: [Cryptography] DNSChanger in ad malware attacks home routers 
Actually, something like "DNS over TLS" (RFC 7858) would go a long way. If the devices access a trusted DNS server through a secure connection, they would be reasonably protected against misbehaving routers. But then, RFC 7858 is quite new and not widely implemented yet. If you are interested, you can check the DNS Privacy Project at And, of course, if browsing with HTTPS instead of HTTP, DNS attacks downgrade to denial of service, which is annoying but much less rewarding for the attacker. Uh, no. STUN was originally defined as "Simple Traversal of User Datagram Protocol (UDP) Through Network Address Translators (NATs)" (RFC 3489), then revised as "Session Traversal Utilities for NAT (STUN)" (RFC 5389). Ars mentions "so-called STUN server requests used in VoIP communications", which is reasonable. I assume that the malware uses STUN to establish some kind of peer-to-peer communication through NAT with other infected hosts.
Maybe devices should stop trusting routers for anything else than sending packets. We just might have to treat all networks as hostile. That's pretty much the norm for Wi-Fi hot spots, but it should probably be the norm too for home networks.

@_date: 2016-12-22 19:51:09
@_author: Christian Huitema 
@_subject: [Cryptography] Photojournalists & filmmakers want cameras, 
Seems like you fell in one of the categories that Joshua Marpet delineated: "Pressure, ranging to duress, to delete stills or video." Being a network guy, I tend to think of network based solutions. Any reason that real time streaming to a safe place would not have worked? Maybe coupled with clear text copies of some pictures on the device itself, which you could volunteer to delete before they hurt you too much?

@_date: 2016-01-01 10:09:28
@_author: Christian Huitema 
@_subject: [Cryptography] Nu supr unbrakable cripto 
If the hash function uses the MerkleDamgrd construction, isn't that going full circle? Create a hash function from a symmetric encryption algorithm, and then create a symmetric encryption algorithm from the hash function?

@_date: 2016-01-07 10:24:06
@_author: Christian Huitema 
@_subject: [Cryptography] Chaum Has a Plan to End the Crypto War 
Maybe I am just slow, but I don't see how in practice that fragmented golden key approach would be any more secure than the single golden key. It is certainly more complicated, which increases the probability of bugs and compromises. And it also provides a really big attack surface.

@_date: 2016-01-11 21:00:15
@_author: Christian Huitema 
@_subject: [Cryptography] Your fist... 
The good news is that we know how to turn on MAC Address Randomization, at least on the latest version of Windows tablets and phones: We also fixed the leakage of metadata through DHCP:  That's implemented in Windows, turned on when the Wi-Fi MAC Address is randomized.
That and a VPN should minimize what the routers see. Without the VPN, we need DNS privacy. That will come soon.
And an ad blocker, of course.

@_date: 2016-06-14 10:09:10
@_author: Christian Huitema 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
How is this negotiation different from the Two Generals' Problem? (

@_date: 2016-06-21 09:50:05
@_author: Christian Huitema 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
Sorry, but it is the other way around. The problem that you are trying to solve appears to be the same as the "two generals" problem, which is proven to not have a solution. If you want to see further work on your proposal, then you need to demonstrate first that the "fair signing" problem is not the same as the "two generals" problems.
It is also well known that one can make arbitrarily complicated attempts at solving at the two generals problems: if a simple message + ACK fails, add an ACK of ACK, etc., ad libitum. Given the general result, all these attempts ultimately fail in some obscure way. Spending time about the particular way this or that construct fails generally takes a long time, and is not particularly interesting.

@_date: 2016-03-10 14:22:05
@_author: Christian Huitema 
@_subject: [Cryptography] Would open source solve current security 
There is something more. Many of the fixes apply to previously undisclosed vulnerabilities. Pushing a fix allows users to patch their system, but it also discloses the vulnerability in unpatched systems. When a fix is out, you can expect a bunch of exploit writers to reverse engineer it, and add it to their toolkit. And then, whoever did not apply the patch is vulnerable.
One nice aspect of "patch Tuesday" is that it helps administrators. If system administrators know that a fix is coming at a specified data, they can plan ahead and make sure that there will be resource available to update systems and apply patches. So in practice, most systems get fixed shortly after the patch is out, and the risk of disclosing previously unknown bugs is somewhat mitigated.
The exception is if a bug is known and exploited in the wild. In that case, it is better to ship the fix quickly.

@_date: 2016-03-16 22:07:33
@_author: Christian Huitema 
@_subject: [Cryptography] Formal Verification (was Re: Trust & randomness 
I am not sure that formal method are such a break from the current state of the art.
Formal methods end up declaring what the code should do, using pre-conditions for the input variables and statements of invariants for the outcome. That's good, but at some level it is comparable to what can be done with the combination of static code analyzers and real time assertions. C/C++ extensions like SAL Annotations make static code analyzers really powerful. If developers use SAL honestly, the code analyzers will definitely catch have Heart Bleed or Go To Fail bugs. Adding ASSERT statements liberally expresses a lot about code intent, and will catch potential issues during a debug break.
Of course, true formal development if applicable will be somewhat better than C + SAL + ASSERT. ASSERT are too costly to be compiled in the production code. They are only activated in special debug builds, and thus can only detect issues encountered during debug runs. There are classes of bugs that are not found by static analysis. They tend to be arcane, something like "use after free during a race condition." Formal development and "annotated analysis" are different. But there are enough similarities. It is probably a continuum.

@_date: 2016-05-08 16:12:01
@_author: Christian Huitema 
@_subject: [Cryptography] russian spies using steganography? 
The "URL" variation would have the interest of minimizing the length of the message. It has some obvious drawbacks, if access to shortened URL is somehow monitored by the adversaries. But using few bits is a very good thing. Of course, the dumb way is to put the information in the least significant bit of every pixel, and that gives plenty of bits. But that is very easy to detect, in particular because it is not robust to a simple decompression/recompression. If you want that kind of robustness, you are in the domain of "robust undetectable watermarks," and the bandwidth is very limited.

@_date: 2016-11-08 15:47:04
@_author: Christian Huitema 
@_subject: [Cryptography] "we need to protect [our dox] by at least 
Arguably, something like "let's encrypt" goes a long way into removing the "slavish obsequiousness to CAs". That, and certificate transparency.

@_date: 2016-11-09 21:40:47
@_author: Christian Huitema 
@_subject: [Cryptography] protecting information ... was: we need 
Well, maybe. But thinking of security in terms of perimeter has its downsides. It is more productive to first look at "what are the assets that you want to protect." Are these documents, email, metadata, connection graphs, etc. Then, using an architecture diagram, you can look at the various interfaces in the system, and check for each one how they can be abused. Yes, people are not always smart. But then, that's what they pay for help, don't they?

@_date: 2016-11-15 11:38:57
@_author: Christian Huitema 
@_subject: [Cryptography] On the deployment of client-side certs 
That could of course be fixed, and client certificates will be sent encrypted in TLS 1.3. But there is still a huge metadata problem. In practice, how many certificates do you believe that a client will manage? Also, do you believe that individual users want to be bothered with pop ups like "example.com wants to see your identity, OK or Cancel?" If the answer are "1" and "No", then client certificates are the ultimate tracking cookie.

@_date: 2016-11-28 14:54:30
@_author: Christian Huitema 
@_subject: [Cryptography] Gaslighting ~= power droop == side channel attack 
Smart power meters could do much more than that. It turns out that various appliances can be recognized through their "power consumption signature". A quick search of "appliance recognition" turns out a variety of research papers on how to do that, as well as projects to build data bases of appliance signatures. The smart power meter of the future ought to be able to check not only when you are starting the dish washer, but what brand and what model you are using. And of course, when the utility starts doing that, they will want to teach you what to use and when.

@_date: 2016-09-07 15:07:52
@_author: Christian Huitema 
@_subject: [Cryptography] Strong DNS Names 
Yes, that's classic big problem with any scheme using fingerprints as identifiers. The lifetime of keys, and fingerprints, is typically shorter than the lifetime of identities. The classic solution is to have a degree of indirection. On the other hand, the lifetime of email addresses is also shorter than the lifetime of identities. After Alice leaves "Example Co.", he is likely to use a different address than "alice at example.com". In fact, if "Example Co." hires a new employee also called Alice, the email address will be recycled and will point to this new Alice's identity.
So maybe bundling the address and the fingerprint in a single token is just OK. At least, it has a "failsafe" property. If I send encrypted mail to the old "alice at example.com.MB2GK-6DUF5-YGYYL-JNY5E," I know that it will not be readable by the new Alice.

@_date: 2016-09-10 15:08:04
@_author: Christian Huitema 
@_subject: [Cryptography] Secure erasure in C. 
Hash: SHA1
Most of the issue seems to be with optimizers. Un-optimized C is a basic imperative language, meaning the compiler is supposed to translate the code literally. Optimized C works on a different principle, i.e. translate the code into something that provides the same result as what the programmer meant, for some definition of "same result". The good news is that mainstream compilers support something like " optimize(off)", allowing to turn off optimization for a specific code segment. Bracketing the erasure routine with such pragmas should ensure that it erases as intended, at least as far as C is concerned.

@_date: 2016-09-18 21:54:53
@_author: Christian Huitema 
@_subject: [Cryptography] Ada vs Rust vs safer C 
Small, like, say, the Windows sources?
It is not so much the size of the code base that matters as the size and complexity of individual functions. I have seen cases where Prefast was producing "false" warnings because, for example, it could not trace how a particular index was evaluated through a complex series of loops and conditional statements. In such cases, there are two options. The lazy one is to add pragmas asking Prefast to "ignore warning such and such in this part of the code". The correct option is to refactor the code, e.g. splitting the long function in a small set of easier-to-evaluate functions.

@_date: 2016-09-20 10:15:10
@_author: Christian Huitema 
@_subject: [Cryptography] Ada vs Rust vs safer C 
Yes, that's definitely a possibility.
In the cases that I am familiar with, we actually had extensive test code. But of course, one almost never gets to 100%, especially in a long complex function. One may get close to 100% of code blocks, ensuring that each line of code is executed at least once, but one cade almost never test all combinations of code paths.
That depends a lot on how the refactoring is done. For example, one simple case is to export the inner block of a loop to its own function. It makes analysis simpler, by reducing analysis of the loop to analysis of the signature of the new function, and it minimizes the risks.
In practice, developers use code reviews, tests, automated analyses, beta deployments and user feedback. The experience shows that reviews are fallible, and that tests never provide complete coverage of corner cases. The point of automated analyses, or for that matter language restrictions, is to provide some guarantees of safety. But yes, there is an obvious tradeoff. If I rewrite a piece of code so that it can be best analyzed, I increase the efficiency of analysis, which is likely to reduce vulnerabilities -- detecting stuff like Heart Bleed or Go To Fail. But I am likely to change some behavior, which is not validated by the previous beta deployments and user feedback. Prefast does not exactly belong to the category of "non-production-quality tools for analyzing programs" built by "academic or researcher, whose main objective is to write a paper or get a degree". But even production quality tools do have their limits. The more tool developers push these limits, the fewer code falls in the "too complex" category, and the easier the tradeoffs. But it is a tradeoff. On the other hand, if code has grown so complex that automated analyzers get confused, chances are that code reviewers are also confused, and that test developers struggle to get adequate coverage. So there is a tradeoff there too.

@_date: 2017-04-01 11:12:21
@_author: Christian Huitema 
@_subject: [Cryptography] escalating threats to privacy 
Actually, having a trusted first hop ISP helps a lot. The traffic going
out of that ISP will be the aggregation of the traffic of multiple
customers, which means that individual users are harder to track. Also,
in many cases, the path leads directly from the ISP to a content
distribution network such as Akamai, or to the presence point of a big
service like Google. After that, there is literally nothing to see in
"the core". And of course, the traffic should be encrypted.
Yes. The real problem is not so much the ISP as the "advertisement
funded" business model. That's what I wrote in this short note:
Congress authorized a free for all, in which ISP can gather information
about you in the same way as web sites do. This demonstrates to our
society the extreme danger of the business model pushed by Silicon
Valley in the last 20 years. A classic reductio ad absurdum. If one
company does it, it is probably not too much of a problem. But if you
allow one company to do it, you must allow all of them. And if all of
them do it, the result is patently absurd.

@_date: 2017-04-21 13:10:37
@_author: Christian Huitema 
@_subject: [Cryptography] Internet synthetic traffic generator or ad 
"Protect against traffic analysis" is a rather vague specification. What
is your threat model, exactly?
There are some threats that are mitigated by cover traffic, but many
others are not. For example, if your goal is to mask your visits to
" your generating cover traffic won't
help. The needle will still be somewhere in the bigger haystack.
Of course, one way to protect against the threat is to have lots of
cover traffic generated by *other people*. They will do random loads of
" and in a quid pro quo you will do
random loads of " The hope would be that
the censors would be befuddled, and won't know who is loading this or
that site for real or as a cover. It would be a variation of "safety in
numbers". But it will only work if there is a big enough number of
people playing that game.

@_date: 2017-12-14 11:33:43
@_author: Christian Huitema 
@_subject: [Cryptography] Privacy-preserving wireless communication? 
This is pretty much the problem that Daniel Kaiser and I set to solve in
the Privacy Extensions for DNS SD:
 Our solution
uses pairwise shared secrets, obtained via pairing. It uses obfuscated
announcements of the form . There is a
scaling issue, as the number of announcements scales with the number of
peers * number of nodes on the network. We mitigate it partially by
constraining the nonce to be a coarse version of the date, e.g., set the
nonce to the time in seconds modulo 30 minutes so peers only have to
redo the computation every 30 minutes.
The DNS SD working group would very much like to find a solution that
does not have these scaling constraints, maybe using public key
technology instead of pairwise secrets. If you have such a solution,
your contributions would be very welcome.

@_date: 2017-12-14 22:49:49
@_author: Christian Huitema 
@_subject: [Cryptography] High volume thermal entropy from an iPhone 
In fact, I am not convinced at all that the "dark frame" approach is
best. Camera vendors may very strive to make sure that the dark frame is
actually dark. And it is also very easy to play games with an almost
dark pictures, since your eyes will not notice the noise.
If I was to extract entropy from a camera, I would rather take a picture
of some reasonably complex life scene and then hash the pixels. Maybe a
picture of my office desk. It would be rather hard for the adversary to
predict the minute details of the image's pixels, as they depend not
only on the rather disorganized pattern of papers on my desk, but also
on the specific position and angle at which the picture is taken.
Unless of course the adversary has access to the picture itself...

@_date: 2017-12-31 16:03:55
@_author: Christian Huitema 
@_subject: [Cryptography] Fast handling of IP Address changes for HTTPS 
============================== START ==============================
Yes, static IP addresses are convenient when you want to run a server at
home, but there is a downside. The static IP address is a pretty good
unique identifier. It will be present in every web transaction, every
email trace, every VOIP connection. Some of us consider that a huge
privacy issue, and actually prefer services in which the ISP regularly
renumbers the connection. Not that changing IP address is sufficient to
keep your browsing private, but it is a necessary first step.

@_date: 2017-02-01 17:30:38
@_author: Christian Huitema 
@_subject: [Cryptography] Firewall penetration 
Yes. I would say, look at RTC in general. As Jerry Leichter wrote, mostly they use third-party "rendezvous" sites. Also, they mostly use UDP instead of TCP. The general strategy is to have the two stations predict the UDP port number that will appear outside the firewall/NAT, then manage to each send packets to the other in order to "open the NAT". If one packet makes it all the way, the path is open and exchanges can happen. Check for IETF specs such as ICE, STUN, TURN.
AFAIK, it works reasonably well for consumer-type connections, but still fails in a few % of the cases. For those cases, you need a relay through a server.

@_date: 2017-02-23 10:33:54
@_author: Christian Huitema 
@_subject: [Cryptography] German govt tells parents to destroy 
There is a marked difference between the Amazon Echo and the Cayla doll.
The Echo device waits for a keyword, "Alexa", and only starts sending
voice commands to Amazon after hearing that. The Cayla doll appears to
listen and send data all the time. In one case, there is clear user
intent to "talk to Alexa". In the other case, it is just an open microphone.
This came to play when the police asked Amazon to provide voice
recordings as part of a murder investigation:
 Amazon
answered that they could not.
But then, pretty much all the "natural voice" services use cloud
processing. Small devices appear to not have enough power and processing
capability to fully understand voice. When working locally, their
vocabulary is very limited, and that doesn't feel "natural". Microsoft,
Google, Amazon, Nuance, Apple, they all send the voice input to their
cloud servers. And they tend to all collect logs of voice samples to
better train their services.

@_date: 2017-01-11 07:03:43
@_author: Christian Huitema 
@_subject: [Cryptography] nytimes.com switches to https 
Well, the part about "authenticity of our content" is definitely correct. The part about "privacy of our readers", yes, it is somewhat vulnerable to attacks. But it is certainly an improvement over plain text.
The NYT folks are journalists, not protocol designers or software developers. They are doing their part, switching to HTTPS. They are not in a position to improve HTTPS -- that's a job for the IETF, browser developers, and server developers.
The good news is that the use of message length as a side channel is now widely understood. TLS 1.3 supports message padding. Researchers are exploring stuff like logarithmic rounding. It will come, even if it takes longer than we would like. And the NYT will hopefully get it when they upgrade their HTTPS software.
I agree about metadata, but I would just say "a system that leaks..." You point out the "side channel" leak through message lengths, and yes that is something that ought to be fixed as part of TLS design. But there are plenty of other metadata leaks outside of the crypto envelope. The SNI in TLS is an obvious one, but there is also IP addresses, DNS queries, list of frame sources such as ads or images in web pages, and maybe timing signals. We need to fix all that, and it will take some time. So yes, we need good crypto systems, but we also have to pay attention to the entire system design, not just the crypto.

@_date: 2017-01-11 18:16:05
@_author: Christian Huitema 
@_subject: [Cryptography] nytimes.com switches to https 
To quote from the conclusion of the Peek-a-Boo paper, "Our work paints a
pretty negative picture of the usefulness of efficient, low-level TA
countermeasures against website-fingerprinting attacks.  But pessimism need
not prevail." The work demonstrates that given enough "features", one can
train classifiers and recognize which web site is being queried. No doubt
about that. Note that the paper was about identifying web sites, such as for example
differentiating the NYT from Wikipedia. That's a very hard problem. But we
can start with simpler goals, such as differentiating one Wikipedia article
from another. Still hard, but probably not unattainable.
It will probably require padding of the "page sizes" to a small set of
standard sizes, maybe powers of two or fractional powers of two, thus
defeating the coarse grain features outlined in the Peek-a-Boo paper. That's
substantial padding, up to 100% for the power of 2, a fraction of that for
the fractional power. Will the web site publishers pay for that? Probably
not all of them.  But some might.

@_date: 2017-01-12 17:15:51
@_author: Christian Huitema 
@_subject: [Cryptography] nytimes.com switches to https 
Hash: SHA1
The "optionally multiplied by 3" series is an approximation. The fractional power equivalent is "Ceiling(2^(N/2))", which gives the same numbers up to 64, but differs slightly after that: 64, 91, 128, 182, 256, 363, 512, etc., versus 64, 96, 128, 192, 256, 384, 512, etc. Padding with the 2^(N/2) series has an overhead of (sqrt(2) - 1), about 40% instead of 50% for the multiply by 3 approximation.
Yes, that's quite true. I could not find the statistics about page size, number of images, etc., at  Looks like an interesting project that would give a good basis for the discussions. Very good point. It might be possible to do something like that with HTTP2, and even better with QUIC. Multiplex several streams over the transport connection, and use the prefetching features to get the images without showing separate bursts. Instead of padding with noise, pad with data that you may want to cache. That might even be quite efficient!

@_date: 2017-07-06 22:17:11
@_author: Christian Huitema 
@_subject: [Cryptography] OpenSSL CSPRNG work 
What is the easiest, convincing device makers to safely manage such a
seed, or convincing them to add some kind of hardware generator of

@_date: 2017-07-12 10:56:25
@_author: Christian Huitema 
@_subject: [Cryptography] [FORGED] Attackers will always win, 
We want constant-time execution in order to avoid leaking information.
Turning off optimizations is a gross way to achieve that -- it relies on
the assumption that the non-optimized code will execute in constant
time, which may or may not be true. If we want a fraction of the code to
be free of side channels, it would be much better to tell it to the
compiler. Maybe have something like " constant-time-required" in
the source code. Of course, compilers today do not understand such
instructions, and we are thus stuck with approximations like turning off
optimization or writing in assembly. But requesting support for constant
time segments seems like a reasonable feature request to compiler

@_date: 2017-03-16 19:47:40
@_author: Christian Huitema 
@_subject: [Cryptography] NSA says China's supercomputing advances put US 
A few years ago, s/China/Soviet Union/. Same pitch.
Somehow, the massive data centers built by Google, Amazon, Microsoft or
IBM do not seem to count...

@_date: 2017-03-16 19:57:00
@_author: Christian Huitema 
@_subject: [Cryptography] Crypto best practices 
I get the IV fragility part. Was just reviewing an RFC draft about
ciphers for IPSEC, with a recommendation to disallow all the current
AEAD style ciphers when manual configuration is used instead of IKEv2,
because manual configuration cannot guarantee non repeating IV. But
then, where is the alternative? How about designing a cipher-mode that
combines the robustness of CBC with the safety of AEAD? Looking at the
literature, the only reference I find is a mythical variant of Keccak,
mythical as in rumored to exist but never seen in the wild...

@_date: 2017-05-01 11:24:47
@_author: Christian Huitema 
@_subject: [Cryptography] CFB/OFB/CTR mode with HMAC for key stream 
This concept was actually used and deployed in the RADIUS Protocol (RFC
2138), when transmitting user passwords from an access point (RADIUS
client) to a Network Authentication Server (NAS): "The NAS and RADIUS
server share a secret.  That shared secret followed by the Request
Authenticator is put through a one-way MD5 hash to create a 16 octet
digest value which is xored with the password entered by the user, and
the xored result placed in the User-Password attribute in the
Access-Request packet." That was in 1997. MD5 encryption.

@_date: 2017-05-06 09:20:01
@_author: Christian Huitema 
@_subject: [Cryptography] French election attacked. 
That was the argument that eventually worked in the 90's in France: "If
we keep banning encryption , the Americans will have a field day spying
on our companies." The law banning encryption of electronic
communication dated from WW1, and so the opponents just had to maintain
status quo. But the DST and then the politicians became convinced that
keeping the ban amounted to unilateral disarmament, and the restrictions
were finally lifted. Somewhat. There is still a fair amount of red tape
So yes, "the Russians are attacking our politicians" might be an
argument for boosting defenses. Although it might also cut the other
ways, as in "we should let the police help citizens from the Russians."

@_date: 2017-11-09 18:28:15
@_author: Christian Huitema 
@_subject: [Cryptography] One Bitcoin Transaction Now Uses as Much Energy 
There are periods at which the wholesale price of electricity is
negative:  So,
imagine that you are the operator of a nuclear plant that cannot be shut
down, or of a wind farm that is just getting wind when the market is
saturated. You have free electricity, in fact negative price
electricity. It makes perfect sense to send that to a Bitcoin mining rig.

@_date: 2017-11-25 21:49:19
@_author: Christian Huitema 
@_subject: [Cryptography] Is ASN.1 still the thing? 
The problem is the combination of EXPLICIT and DEFAULT. The spec:
  version [0] EXPLICIT Version DEFAULT v1
Normally encodes something like , but in the case where V=v1, you get three plausible encodings:
1) nothing
2) 3) Arguably, sensible IDL syntaxes should not have anything like the
EXPLICIT clause. It is just overhead, and generates puzzling situations
like the one above. But then, ASN.1 used to allow
 extension-1 [1] EXPLICIT ANY
Which make for powerful constructs. Or powerful foot guns, depending how
you look at it.

@_date: 2017-10-02 13:51:48
@_author: Christian Huitema 
@_subject: [Cryptography] Is there any advantage to canonical fingerprints. 
Both the idea and the implementation are very close to the "call signs"
system that I worked on with Kim Cameron and Josh Benaloh. Too bad that
we failed to publish an academic paper, and that the best description is
in the patent -- Christian Huitema

@_date: 2017-10-18 16:14:21
@_author: Christian Huitema 
@_subject: [Cryptography] Severe flaw in all generality : key or nonce 
The interesting property would be that every bit in the encrypted
message statistically depends on all bits in the key, the nonce, and the
clear text message. Reusing the same key and nonce would only reveal
something if it was used with exactly the same message, in which case it
would just reveal that two messages were identical.
That would be in contrast with stream ciphers, in which a bit in the
encrypted message depends on the key and the nonce and the corresponding
bit in the clear text -- but no other bits.

@_date: 2017-10-19 13:19:17
@_author: Christian Huitema 
@_subject: [Cryptography] Severe flaw in all generality : key or nonce 
Thanks for the pointer. As for the performance constraints, they
certainly are practical issues when the messages are long, but there are
applications in which messages are fairly short. Take for example IPSEC:
the unit of encryption is an IP packet, which in practice is at most
1500 bytes. TLS over TCP can have messages of up to 2^14 bytes, but when
using TLS with UDP for DTLS or QUIC, the message size is again at most
1500 bytes. 1500 bytes is not all that long. I also get the need to do
two passes, one to compute the message-dependent nonce and one to
perform the encryption. That's less memory efficient than the AES-GCM
pipelining, in which the result of encryption can be directly fed into
the checksum computation. But the number of operations would be about
the same, just reverse the order: perform a keyed hash to obtain the
nonce, then perform the encryption with the nonce as IV.
So this may well be worth a try, if there was a real security benefit.

@_date: 2018-04-19 23:38:30
@_author: Christian Huitema 
@_subject: [Cryptography] The Bob Morris worm 
Well, that worked well enough for the Mirai worm in 2016. Quoting from
the Wikipedia page, Mirai scanned ranges of IP addresses and "identifies
vulnerable IoT devices using a table of more than 60 common factory
default usernames and passwords, and logs into them to infect them with
the Mirai malware." Rince and repeat...

@_date: 2018-08-01 16:36:02
@_author: Christian Huitema 
@_subject: [Cryptography] Krugman blockchain currency skepticism 
Krugman develops two arguments. The first one is that the transaction
cost of crypto-currencies is much higher than the transaction cost of
credit cards or cash. He believes that rules out daily use for paying
bills. From there, he deduces that if the crypto-currencies are not used
to pay bills, the main usage left is to stash cash, much like people
stash $50 or $100 bills, and move them occasionally while hiding them
from the Feds or other police forces.
Krugman then goes on to say that even for the "stash of cash" markets,
crypto-currencies are inferior to alternative like wads of $100 bills or
ingots of gold, because they are not "tethered" to something tangible,
like paying US taxes with $100 bills or selling shiny jewelry.
Basically, there is no intrinsic value for a Bitcoin. It is purely what
people want to pay for it, and if too few people wanted to buy it the
value could drop to zero, because it is not tethered to anything.
These two arguments are not tied to policy desires, such as enabling or
not people to exchange money with activist groups or drug lords. It
takes more than just "reading this e-mail" to refute them.

@_date: 2018-08-15 13:08:45
@_author: Christian Huitema 
@_subject: [Cryptography] Throwing dice for "random" numbers 
There is a little twist there. If you do not mark the dice, then the
experimenter will input the 12 numbers "in whatever order they see fit".
Maybe left to right, maybe nearer to further, maybe even results first,
maybe odd, maybe smaller result to larger. The choice by the operator
may be unconscious, but it is still very likely to introduce a bias,
resulting in fewer than 12*log(6) bits of entropy.

@_date: 2018-02-06 12:21:33
@_author: Christian Huitema 
@_subject: [Cryptography] How slow is pairing based crypto compared to 
There is a good discussion of the performance tradeoff for crypto and
IOT in this Internet Draft, currently in IETF last call:
 Form
the abstract:
   This memo describes challenges associated with securing resource-
   constrained smart object devices.  The memo describes a possible
   deployment model where resource-constrained devices sign message
   objects, discusses the availability of cryptographic libraries for
   small devices and presents some preliminary experiences with those
   libraries for message signing on small devices.  Lastly, the memo
   discusses trade-offs involving different types of security
   approaches.
The draft contains measurement and evaluations of libraries, including herumi.

@_date: 2018-02-12 11:51:07
@_author: Christian Huitema 
@_subject: [Cryptography] Insufficient MAC randomization 
MAC Randomization has been available in Windows 10 since December 2015.
It is not limited to probe requests, but there are lots of practical
issues that needs to be dealt with, such as not paying multiple times
for Wi-Fi in an hotel room, or playing nice with corporate Wi-Fi (see:
There is also an implementation in Linux, although I don't know the details.
Maybe. But I don't know whether the average hacker or advertiser can
afford the required equipment, and deploy it at all locations that needs
surveillance. State agencies probably can do that in a targeted manner.
In any case, just randomizing the MAC address is not enough -- see
 for a list of issues in
the Wi-Fi stack that also need to be patched, and
for another set of such issues. AFAIK, the various stacks are patching
these bugs, but YMMV.
And then, there is also the case of MAC-like identifiers used in DHCP --
see RFC 7819 ( for a list of
issues, and RFC 7844 ( for
DHCP anonymous mode. This was implemented in Windows 10, and should also
be implemented in Linux by now.

@_date: 2018-02-26 16:44:57
@_author: Christian Huitema 
@_subject: [Cryptography] [dns-operations] IP address encryption: 
The filter that they use is IPCrypt (
designed by Jean-Philippe Aumasson. It takes a 128 bit key, splits it
into 4 32 bit words, and combines it with the input as follow:
 input -> XOR(Key1) -> Permutation -> XOR(key2) ->Permutation ->
XOR(key3) -> Permutation-> XOR(key4) -> output
The permutation is effected by splitting the 32 bit word in 4 octets,
and then doing a series of rotations, additions and XOR combination of
these octets.
The design has limitations, such as not being robust to some related key
attacks, but is seems otherwise to be fairly natural.
I understand that when collecting logs they are rotating keys very
frequently, in part for that reason. In any case, the working set of IP
addresses seen by a DNS resolver is well below 4 billions. I would be
surprised if it was more than a few millions, maybe a few tens of
millions for very large providers.

@_date: 2018-01-01 11:52:04
@_author: Christian Huitema 
@_subject: [Cryptography] Fast handling of IP Address changes for HTTPS 
Yes. The point is that it is not very wise to use the same IP for
running a server and running a client.
Yes of course, you have to be worried about cookies, supercookies, and
various forms of fingerprinting. The issue there is the web model that
allows pretty much anyone to run whatever code they want in your
browser. And the protection there has more to do with ad-blockers and
tracking blockers than with network level controls.
TOR may be great, but I would like to see privacy for the masses, not
just good hiding for the few. TOR has a built-in trade-off: hiding at
the cost of increased latency through multi-hop. This is why I like IP
address randomization: it does not affect latency or bandwidth, and
could potentially be deployed massively.

@_date: 2018-06-04 19:44:13
@_author: Christian Huitema 
@_subject: [Cryptography] Odd bit of security advice 
You are missing the birthday paradox.   Encrypting a counter is a bijection that guarantees uniqueness. Truncating the encryption yields a random number that has no such guarantee.

@_date: 2018-06-06 19:39:07
@_author: Christian Huitema 
@_subject: [Cryptography] Apple Group FaceTime and end-to-end and 
I had to solve a very similar engineering problem for a chat application
on the X-box, about 10 years ago. What we did was organize the
participants in a spanning tree, picking the devices with the network
connections as nodes and the devices with the worse connections as
leaves. We controlled the branching of the tree so as to not overwhelm
the nodes. You get a structure in which each node-to-node or
leaf-to-node transmission is encrypted, but of course each member sees
the whole context. The spanning tree worked fine in practice, although
of course latency becomes a function of the diameter of the graph. I
have no idea what the folks at Apple chose to do, but yes, there are

@_date: 2018-03-26 22:00:10
@_author: Christian Huitema 
@_subject: [Cryptography] Justice Dept. Revives Push to Mandate a Way to 
I am actually very interested in practical ways to reduce metadata
leakage. At the lower layers, the big ticket items are the MAC
addresses, which we know how to randomize, the IP addresses, which
hopefully vary over time, the DNS names, for which we start seeing
encrypted transports, and the SNI in TLS, which is a very tough nut to
crack. There are other potential leaks in DHCP and systems like MDNS,
which can be plugged. I would be happy to complete my list with your
Of course, even if we did plug the obvious leaks at the lower layer,
there are other issues. The graph of connections leaks user social
networks, unless we find something like Tor for the masses. And then
there is the massive data collection done by Google and Facebook in
particular, and the advertisement industry in general...

@_date: 2018-11-18 23:20:38
@_author: Christian Huitema 
@_subject: [Cryptography] Norton Password Vault 
It may or may not work, but if you can script the access to the vault
you could try a "smart" dictionary attack. Gather the name, dates or
other numbers that were significant to the deceased, and use this set of
strings to create a dictionary of potential passwords for the vault --
mixing symbols, case shifts, variations, common words, etc.

@_date: 2018-09-01 15:38:14
@_author: Christian Huitema 
@_subject: [Cryptography] Is "perfect forward secrecy" the biggest fraud 
Straight DH could indeed be broken by quantum computers. What about DH
combined with shared secret, as in for example the PSK + (EC)DH modes of
TLS 1.3? Are those broken too?

@_date: 2018-09-03 10:44:34
@_author: Christian Huitema 
@_subject: [Cryptography] WireGuard 
There was a nation state, Iran, behind the Diginotar attack. The attack
enabled them to create fake certs for Google, so as to spy on Gmail
traffic. I would not say that all nation states exhibit "reluctance to
get caught".

@_date: 2018-09-29 21:57:06
@_author: Christian Huitema 
@_subject: [Cryptography] Did Spectre help torpedo Qualcomm? 
Except Spectre is not really a software problem. Check the paper in ACM
"C Is Not a Low-level Language"
in which David Chisnall explains the rather large distance between what
the C
programmers believe they are writing and what is actually executed. Spectre
is an attack on that interstitial layer, a layer that software does not
see with
bugs that software can hardly fix.

@_date: 2019-01-24 11:51:39
@_author: Christian Huitema 
@_subject: [Cryptography] Implementing full Internet IPv6 end-to-end 
If you want real integration with IPv6 addressing, the crypto systems
can really only use 64 bits. The top 64 bits are claimed by the routing
system, and the network providers just won't let you put something
arbitrary there. That's a big issue, because if your cryptographic proof
of ownership relies on matching 64 bits, then it is not much of a proof.
The CGA specification (RFC 3972) tried to mitigate that by introducing
the "SEC" field. It tries to make the proof harder by specifying a
number of matching zeroes. There is a tradeoff there. We wanted to
encode the number of zeroes in the address itself: we feared that doing
otherwise would make address spoofing too easy. But we were also worried
about birthday paradox issues. Each bit allocated to the SEC field is
one fewer bit available to differentiate the addresses of hosts on the
same network. The compromise was to pick a 16 bit granularity.
It order to generate the address, the defender has to do O(2^(16*SEC))
trials. In order to generate a matching address, the attacker has to
perform O(2^(61 + 16*SEC)) trials. We felt at the time that it was an OK
compromise between required load at the defender and resulting security.
I am not sure that we were right.
It turns out that there is a huge range of capabilities between Internet
hosts. On a mobile system, doing 2^32 hash trials turns out to be a very
big deal, if only because of the energy it burns. The practical limit is
probably be something like 2^16. But then, the attacker only has to do
2^77 trials to break the hash. Nation state attackers can probably do
that without breaking a sweat. They could also build rainbow tables,
which makes the problem even worse.
We also realize the privacy issues with keeping the same IPv6 address
for a long time, or with keeping the same 64 bit host identifier when a
device moves to a new location. When moving, the devices learns the IPv6
prefix of the network that it visits. The current algorithm is to
generate a new host identifier for that network by hashing the prefix
with a local secret. RFC 3972 did not envisage that. It could be
modified to require hashing the local prefix with the public key, which
would create "private CGA addresses" and would also provide some defense
against rainbow tables. But see the argument about mobile devices above:
they really don't want to wait a minute or two and burn their batteries
before getting an address and being ready to use the network.
Big static servers do not have these limitations and could perhaps spend
a lot of CPU and get a large SEC value. But these big servers also have
no problem getting a PKI certificate, and don't need CGA so much.
Bottom line, back in 2005 we had high hopes that CGA would enable all
kinds of security improvements, be it end-to-end IPSEC or secure IP
Mobility. That did not happen, and hardly anybody uses CGA today. Lots
of the work was done at Microsoft Research, but Microsoft never found a
real reason to deploy CGA in Windows. The real reason is that 64 bits is
too small for crypto.

@_date: 2019-01-24 14:08:24
@_author: Christian Huitema 
@_subject: [Cryptography] Implementing full Internet IPv6 end-to-end 
Let's first state that just being compliant with the address
architecture brings you little by itself, apart from preventing
collisions. Claiming address=X only makes sense if your peers can do a
socket call, send a packet towards X, and have a reasonable expectation
that it will arrive. In the current state of the routing, that means
that the address should be of the form "|", and that
some variation of the "prefix" needs to be known in the routing tables
all the way from source to destination. If you are connected to a
network with prefix P, the address that you give to your peers must be
of the form "X=P|H" if you want to receive data. Most final destinations
are identified by a 64 bit prefix, unique to the specific network link
on which the host is attached, which means that H is constrained to be
no more than 64 bit long.
The plausible exception would be a "network link" identified by a much
shorter prefix. In theory, you could obtain that through the current
system if you justify a large enough number of users. In practice, very
large networks do get 32 bit network prefixes.
You could claim that a network overlay like TOR qualifies as one such
big network, and it should be given a short prefix. Data sent to these
addresses would be routed to the closest overlay access point, and the
overlay would route messages to their final destination based on the
host ID. I can easily conceive a proof of concept using for example a
DHT, although a production version would have to be address issues like
DOS, Sybil attacks, frequent address changes to maintain privacy, etc.
How short the prefix should be is an interesting discussion. Just 48
bits would be a no-brainer. I can see converging an a 32 bits after some
discussion -- and that would match the 96 bits length that you mention.
Anything less would probably require a lot more discussion.
But squatting on a large portion of the address space, no, that's not
going to end well.

@_date: 2019-01-31 13:56:59
@_author: Christian Huitema 
@_subject: [Cryptography] the world's worst hash function 
Peter, your implementation being slow is one thing. But do you have a
proof that some smart implementation would not be able to fling the
merde much faster, and land on the same shit by a shorter path?

@_date: 2019-07-16 11:42:53
@_author: Christian Huitema 
@_subject: [Cryptography] Alan Turing to Be Face of 50 Pound Note 
Given that Alan Turing is famous for breaking encryption, is this a
hidden message?

@_date: 2019-05-09 22:00:00
@_author: Christian Huitema 
@_subject: [Cryptography] peering through NAT 
NAT traversal has been with us since quite a while. Two variants: the
UPNP/IGP or PMP kind, in which a devices inside the network talks to the
local router and opens a port; and the "implicit" one, pioneered for
video games by Dan Kegel at Activision. The technique was standardized
by the IETF in STUN (RFC 5389, 2003). The basic idea is to reverse
engineer how the NAT works with the help of a server behind the NAT, and
"punch a hole". These techniques are widely used by video games, voice
and video over IP, and other P2P systems.

@_date: 2019-05-10 20:06:56
@_author: Christian Huitema 
@_subject: [Cryptography] peering through NAT 
It *is* off topic, wonder why the moderators are not cutting that off
If I were king, that would have happened years ago. But you know, rough consensus and running code and all that. Perry tried to precipitate the movement with whisky shots and toasts to the universal deployment of IPv6, but that was not too successful either.  It took some time for IPv6 to ship on most platforms -- Windows only got a production ready version in 2003. In between, NAT became entrenched. Something to do with business models. NAT was giving you an immediate tangible benefit, connect several computers while paying just one ISP bill. The economic incentive were well aligned: customer shells out maybe $100 for a device, recovers the price in a few month by saving on the ISP bill. The economic incentives of IPv6 were much more "long term", to use an euphemism.
At this point, they are waiting for explicit requirements from ISP. It is getting there, because it turns out that Net 10 + Carrier Grade NAT does not work well if you have more than 16M customers. With IPv4, ISP cannot give a unique address to each of their customer premise equipment, and that makes network management very costly. Same thing is happening in big data centers.
But then, having a unique stable address/identifier for each device has some pretty nasty privacy implications. It is not hard to find privacy advocates who believe that Carrier Grade NAT is great, because it lets people hide.

@_date: 2019-11-04 22:26:34
@_author: Christian Huitema 
@_subject: [Cryptography] Very best practice for RSA key generation 
Pushing your luck, are you? Matching a list of 32K words in different
languages is going to be fraught with synonyms, homonyms and the like.
Just to take your example, "batterie" in French is a rechargeable
battery, while the Duracell battery is "une pile" -- which is also a
pile. And then, I am not sure that there are 32K commonly used words in
French, which might introduce interesting issues.

@_date: 2019-10-19 23:58:46
@_author: Christian Huitema 
@_subject: [Cryptography] Very best practice for RSA key generation 
So you are saying that because the spacing between primes varies, the
method that Phil's proposed will introduces a bias in the selection of
primes. This seems directly tied to Phil's specification:
p0 = KDF ("ZAAA-UJUY-H7TF-SFLK-CWAW-TKC4-O5HQ".FromBase32(), "P")?
p = next_prime (p0)
Suppose that instead of just stating "next_prime (p0)", the algorithm
tried a series of pseudo random numbers seeded with P0, for example:
p(i+1) = KDF(p(i),"P")
and stops at the first p(n) that appears to be prime. Would that work?

@_date: 2020-04-06 17:45:05
@_author: Christian Huitema 
@_subject: [Cryptography] Privacy post COVID 
Me neither. I leave my phone on my desk when I go outside. If I really
have to carry it, because maybe I need to call someone, then I carry it
in a Silent Pocket, and take it out only when I need to use it.
And I like the idea that the mask confuses face recognition.

@_date: 2020-12-28 17:07:25
@_author: Christian Huitema 
@_subject: [Cryptography] Am I missing something about CBDC ? 
Isn't that a "misfeature" of any form of payment that is not anonymous? The logic of surveillance capitalism is that if some data is available and has value, it will be collected and resold. Does not matter much whether the identifier in the data is a customer ID, a credit card number, or some kind of cryptographic identifier. Today, the only way out of that are is to convince politicians to make such data collection illegal, or at a minimum to put limits on data reuse and resale. We may hope that some iteration of something like GDPR will work, but given the potential flow of money from surveillance capitalists to politicians I am not holding my breath.

@_date: 2020-02-13 15:26:32
@_author: Christian Huitema 
@_subject: [Cryptography] 'The intelligence coup of the century' 
Not really. The article describes how the CIA and the German BND bought
and used a small company in Switzerland, which is hardly an indictment
of the US industry. In fact, Microsoft, RSA Security, Google, Facebook,
and Amazon (AWS) did not even exist when the CIA and BND bought Crypto
AG. If anything, the article shows that buying devices from a neutral
country is not a guarantee against interference by the CIA.

@_date: 2020-02-16 18:39:32
@_author: Christian Huitema 
@_subject: [Cryptography] SSL Certificates are expiring... 
That's exactly how the organic growth of the Internet works. A
specification is put up with a narrow scope and demonstrates that it
works well in that scope. Since it works well, it get adopted widely and
the scope of application exceeds the initial design. At which point
additional works happens until the new version meets the extended scope.
Repeat. This is true for pretty much every standard including TCP
itself, which went from working on kilobit links in the 70's to multi
Gigabit links now, and in the process acquired a bunch of features like
congestion control, selective acknowledgements, time stamps, wide
windows and many more. It is obviously true of SSL and then TLS. And it
is also true of the certificate infrastructure, with stuff like CT
grafted on top of PKI. Experience shows that standards developed that
way are really hard to replace. You would think that a shiny new feature
will ensure replacement of the old crumpy stuff by the new one, but
generally the answer is just to add a slightly less shiny replacement
feature to that old stuff.
Unless you are Google or the Chinese Communist Party, of course. Google
has managed to develop an alternative to TCP with Quic, and they could
do that because the Chrome browser and the various Google services have
a huge market share. Even so, the transition has been going on since
2013, and we might finally get a standard this summer. It takes time.
The Chinese Communist Party is trying something similar with their "New
IP" initiative, aiming at replacing the current Internet standard by one
in which the identity of every user could be verified and their
activities observed from within the network. They may succeed because in
the process hey invested huge diplomatic efforts to get votes in the
ITU, and built a pretty solid industrial base with Huawei, and they plan
working on it until 2030. But if you are not one the mega corporate
powers or one of the dominant nation states, your odds of success are
much lower.

@_date: 2020-02-18 11:42:21
@_author: Christian Huitema 
@_subject: [Cryptography] With an e2e network, 
Metadata. We kill people based on metadata?
And if you look at recent events like the OPM or the Experia hacks, the
Chinese services are just as found of metadata as the NSA.

@_date: 2020-02-18 19:32:14
@_author: Christian Huitema 
@_subject: [Cryptography] With an e2e network, 
Of course we need e2e encryption. But Alfie was wondering why the US government was concerned about Huawei providing telecommunication equipment in US-allied country. And the simplest explanation is that on-path devices are in a beautiful position to collect meta data.

@_date: 2020-02-19 11:05:51
@_author: Christian Huitema 
@_subject: [Cryptography] With an e2e network, 
Or both. And whatever hacking team manages to penetrate the routers. This is why we need metadata reduction on top of e2e encryption. SNI encryption of course, but also defense against application fingerprinting. Onion Routing for the masses would be nice too. Once we have that on top of e2e encryption, then yes we could treat the network as a compromised swamp and still maintain privacy. But today we don't.

@_date: 2020-01-12 15:31:15
@_author: Christian Huitema 
@_subject: [Cryptography] improved identification of non-targets 
I assume the Iranians were concerned that closing the airport would have
cued the Americans that there were up to something. Of course, it
appears that the American bases had plenty of time to get in the
bunkers, so closing the airport would not have changed anything in
practice. Then they also said that the flight path was over a secret
military base, and of course they had not warned anyone about the
location of that base. Little wonder that the Iranian civilians are angry...

@_date: 2020-06-30 21:55:11
@_author: Christian Huitema 
@_subject: [Cryptography] Statement from Attorney General William P., 
That is certainly how the French regulation of encryption started. It
was written during WW1, in very general terms, so as to regulate the
practice in any electronic communication. It was only overridden in the
90's, when a fraction of the French services realized that if
enterprises could not encrypt their data, then foreign powers such as
America would take advantage of that. And of course, shortly after the
bans were lifted, the French public started to hear a lot about pedophiles.
By the way, the protection of businesses is a very powerful argument on
the side of encryption. Weakening encryption now is guaranteed to make
securing these businesses harder, at a time when they are under constant
attacks from a variety of foreign powers and criminal gangs. Plus, the
defense of the businesses cannot be separated from the defense of their
employees, so the argument extends to protecting private data and
private communications, not just business data and communications.

@_date: 2020-07-10 21:31:34
@_author: Christian Huitema 
@_subject: [Cryptography] "Home router warning: They're riddled with known 
Is there a build for the rasp Pi -- or any other hardware -- that is
specially tuned for this scenario?
There are some difficult issues there. The simplest way to do back to
back router with IPv4 is to do double NAT, which is fine if you want to
break peer-to-peer applications but not so great if you want to have
local servers, or make sure audio and video conferences work, etc.
Similarly, you want to be able to distribute IPv6 addresses, and that
requires either acquiring /64 subnets from the ISP router, or faking
that with the IPv6 equivalent of proxy ARP. You also want to test and
configure DNS properly, without falling prey to the ISP's DNS, and also
without sending all your traffic logs to Google or Cloudflare over DoH.
Hence the need for a specific project. Is there one already?

@_date: 2020-07-20 18:03:01
@_author: Christian Huitema 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Paul, when you say "I don't think TLS ever saw much use either", could
you qualify the context for that lack of use? We get all kinds of
statistics showing that the majority of the web connections are now
using HTTPS, and that the TLS 1.3 version is being deployed, e.g.,
This brings us to the questions about "what did we learn" and "what
would we do now"? Of course, we learned that the NSA and others are
spying on the Internet connections. We learned that the end-to-end model
of deployment worked well for TLS and HTTPS, and also for SSH. We
learned with the Let's Encrypt initiative that automating X.509
certificate acquisition and renewal helped deployment a lot. We also
learned that there are two big issues left unaddressed: the collection
of metadata, and corporate surveillance.
Many people have been working to limit the metadata available outside of
the encryption enveloped, but there are still hard issues. For TLS, SNI
Encryption is almost ready for standardization, and that would be one
big step. The work on DNS encryption complements that. But there are
still large gaps -- for example, there seems to be no appetite to
diminish metadata in email messages, because it is used for controlling
spam. The need to control spam and malware is also used as an argument
to resist DNS encryption, and resist metadata removal in general. And
then, the IP addresses are also metadata, which only Tor seems to remove
so far.
On the other hand, focusing on this type of leaks feels a bit like the
quip about "speeding ticket at Indianapolis" in "Apocalypse Now". The
apocalypse is happening already, with the generalized surveillance
implemented by Google, Facebook and their likes. What is the good of
encrypting web connections if the other end is going to conduct a web
auction and broadcast the metadata to all auctioneers? What is the point
of focusing on little details when companies continue being funded to
acquire as much metadata as possible and sell it? What is the point of
limited collection by government agencies when they can just turn around
and get the data from resellers, like the CBP just did by buying
databases of license plate surveillance?

@_date: 2020-06-04 13:32:47
@_author: Christian Huitema 
@_subject: [Cryptography] Zoom publishes draft cryptographic design for 
That sounds like a two-edged sword. On one hand, widely used platforms
do attract a wide cast of attackers. But on the other hand, most widely
used platforms are also actively maintained and regularly updated to fix
newly discovered attacks. Using something obscure will protect against
mass-produced attacks such as phishing campaigns, but might be very
vulnerable to targeted attacks.
Yet I think there is something to that argument, because widely used
applications are often most vulnerable to nation-state compromises due
to their business model. Take the example of Skype. The early versions
of Skype were designed for end-to-end security, and law enforcement
agencies in many countries were not happy. As Skype became widely used,
it migrated from being managed by a small crew to being managed as part
of a big business. It then became much more vulnerable to pressure, and
had to find creative ways to satisfy the requests of at least some law
enforcement agencies. After Microsoft bought Skype they centralized the
handling of the call set-up, and the centralized handling made it much
easier to satisfy law enforcement requests. We are seeing the same
process happening with Zoom.
At app that just serves a small niche of users might escape these
pressures -- until of course it becomes popular enough and noticed...

@_date: 2020-03-01 08:35:03
@_author: Christian Huitema 
@_subject: [Cryptography] Recognizing faces vs. recognizing a face 
The two questions that you describe are the same problem. Take the "same person in photo" question. You have to measure false negatives, i.e., present N other pictures of the same person and see how many are not recognize. And you have also measure false positives, i.e., take N pictures of other people and see how many are falsely recognized. You need the two numbers to characterize a system.

@_date: 2020-11-16 12:28:23
@_author: Christian Huitema 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Do you mean something like QUIC, which does all of TCP and embeds TLS,
plus HTTP3, which subsumes HTTP2?

@_date: 2020-11-17 09:15:11
@_author: Christian Huitema 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Ah ah ah! Good luck with that. Consider that despite lots of investment,
a quarter of a century after being standardized IPv6 only carries maybe
30 to 50% of the Internet traffic. Wholesale replacement may happen if
some radical new technology comes along, maybe quantum networking if it
turns out to be practical. But failing that, the best that can happen is
a series of small updates.

@_date: 2020-11-17 19:48:24
@_author: Christian Huitema 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Really? Facebook and Ali-Baba are already sending a bunch of their
traffic over Quic, so it is not just Google. In fact, a sizeable
fraction of the Internet traffic runs over Quic already. Most browsers
already support Quic -- Chromium of course, but also Mozilla and Safari.
There are implemention of Quic on server platforms like Apache, NGinx,
or Litespeed, on VPNs like Akamai, Fastly or Cloudflare, and I am
missing a few. (see:
Quic is really an encrypted transport, solving the vulnerabilities
caused by TCP's clear-text header. Encrypting everything reduces
interference by network based attackers and other middle-boxes, and
allows for much simpler upgrade paths than TCP. Quic is also in many
ways cleaner than TCP, largely because it uses 64 bit packet numbers and
because it cleanly separates packet control from content control. For
example, it is much easier to implement error correction or congestion
control correctly with Quic than with TCP. That does not mean
applications that work well with TCP will rush to migrate to Quic --
that would be silly. But it does make a lot of sense for new
applications. Not to mention that lots of application run on top of HTTP
already, and they easily get QUIC/HTTP3 support.

@_date: 2020-11-22 22:49:23
@_author: Christian Huitema 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
While QUIC started as a Google project, it is being standardized in the IETF. There are several independent implementations of QUIC, by Apple, Microsoft, Mozilla, Cloudflare and many others, including mine. They are not "married to the Google code base".

@_date: 2020-11-23 09:30:27
@_author: Christian Huitema 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
It uses PicoTLS, a from-the-ground-up implementation of TLS 1.3 by Kazuho Ohu --  Picotls allows for a variety of implementation of the crypto algorithms, including libcrypto from OpenSSL, a "fusion" implementation of AES-GCM developed by Kazuho, and a "mini crypto" implementation using cifra  for most crypto and micro-ecc  for secp256r1.
As noted by Rich Saltz, different implementations use different implementations of TLS and different crypto libraries. Some use a forked branch of OpenSSL in which the API required by QUIC were added. The Microsoft implementation uses S-Channel or MiTLS from MSR. The Google implementation and some others use BoringSSL. Mozilla use their own library. Some implementations use rusttls. A few implementations allow developers to choose between OpenSSL, LibreSSL, etc.
The list of implementations is at The results of the automated interop testing set by Marten Seeman are at  The results from manual interop testing conducted periodically are at  That spreadsheet includes tabs for the interop that have been going on since 2017. Interop testing was one of the basic tools of protocol

@_date: 2020-10-01 08:49:11
@_author: Christian Huitema 
@_subject: [Cryptography] Exotic Operations in Primitive Construction 
Galois field multiply? Isn't that directly supported by some CPU? The
advantage over rotate, xor or ADD is "strong mixing". The result of the
Galois field multiply makes all output bits dependent of every input
bit. You could also get the mixing effect with multiply, then combining
result and overflow.

@_date: 2020-10-04 08:53:02
@_author: Christian Huitema 
@_subject: [Cryptography] Exotic Operations in Primitive Construction 
"Reverse a bit chain" is a classic interview question for junior
software developers. The answer has better be O(logN), as Jerry and John

@_date: 2020-10-15 08:25:48
@_author: Christian Huitema 
@_subject: [Cryptography] Secret sharing for family members 
If you are going to store it in a safe, printing on paper seems the
If you believe in nerndess, print QR codes. Otherwise, plaintext seems fine.

@_date: 2020-09-28 12:49:37
@_author: Christian Huitema 
@_subject: [Cryptography] A naming and key distribution infrastructure for 
Is that difference large enough for people to care? Peter own his domain
name until he fails to pay the rent, or until someone sues him out of
ownership. You own a mesh name until you lose control of the secret key
that certifies ownership. I am not sure which of the two events has the
highest probability. Domain name law suits do happen, but they are quite
rare if the name is as obscure as tsto.co.uk . Is
that more likely to happen than, say, a virus causing loss of the disk
memory, or a physical failure of the backup media? Ransomware attacks
show that people do lose their data quite often. In any case, both types
of events are quite rare. Not sure that actual users bother.
