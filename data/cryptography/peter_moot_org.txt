
@_date: 2015-08-31 14:28:17
@_author: Peter Fairbrother 
@_subject: [Cryptography] Does Simon effectively use the Toffoli Gate as 
The Simon function has three inputs. S1, S8 and S2, but only two outputs. There is an AND of S1 and S2.
Nor should it - reversibility in a "Fiestel function" is at best suspect.

@_date: 2015-12-22 16:16:07
@_author: Peter Fairbrother 
@_subject: [Cryptography] What is encryption good for? - was Re: Hillary on 
Well, encryption undoubtedly _is_ used by terrorists. At least occasionally, eg when they visit ATMs or do internet shopping.
Encryption may well also be used by terrorists for more direct terrorist purposes, though that use doesn't actually seem to be widespread (and those who do seem to be at the cleverer end of the spectrum, and won't be put off by a law demanding backdoors - everybody who has made even a cursory study of the field knows how to do unbreakable end-to-end However, what I am interested in, which should perhaps be emphasised a bit more,  is the use of encryption by ordinary folk who are not terrorists, for lawful purposes.
So, what is encryption good for?
Some suggestions:
internet banking
internet shopping
protection against identity theft
use by enterprises keep customer details confidential
cloud services
keep mobile calls private
modern car locks
conditional access to computers, databases etc - anything needing a password
Any more?

@_date: 2015-07-12 03:19:50
@_author: Peter Fairbrother 
@_subject: [Cryptography] Ad hoc "exceptional access" discussion at 
I am unsure what "exceptional access" means.
Is it access by exceptional people, eg the NSA can read everything, or access in exceptional circumstances, eg the UK's Cameron's "with a warrant signed personally by the Home Secretary"?
Of course to a cryptographer these are much the same thing, but politically they seem to be different.
7th principle of information security: Holes for good guys are holes for bad guys too.

@_date: 2015-07-14 07:43:25
@_author: Peter Fairbrother 
@_subject: [Cryptography] Ad hoc "exceptional access" discussion at 
Hell, they wouldn't have convinced me.
Paper was a load of rubbish and waffle. It didn't even define "exceptional access" in a meaningful way.
Result of a committee approach, I suspect.
There are at least five valid arguments against "exceptional access".
[] First: holes for "good guys" are holes for "bad guys" too.
Incidentally, this includes things like default and maintenance passwords, alarm codes, safe combinations, and so on, not just government access.
"Good guys" and "bad guys" are in quotations here, as they are used in ways which do not fit our convention - good guys defend access to information, bad guys try to obtain it.
[] Second: the costs pro and ante are wildly disproportionate - it would cost a lot more than it would be worth. Think of internet banking ..
[] Third: why should people trust those who are authorised, as they work in secret and are, by the unavoidable nature of that secrecy, unaccountable to the people?
[] Fourth: making it impossible for terrorists to communicate securely is an impossible pipedream. They can. "Exceptional access" will not stop them from doing it.
You can make it harder, but they will learn how to get around any difficulties quickly; and the cost of making it harder is not worth paying.
[] Fifth, one especially for leftpondians but still universally applicable: "exceptional access" is searching the papers of innocent people - whether or not anyone actually looks at them.
If you don't like the last bit of that sentence, then consider - The people are less secure in their persons, houses, papers and effects if an "exceptional access" backdoor exists.
More, "exceptional access" violates that right to privacy and peaceful enjoyment without probable cause - most of the people affected will be

@_date: 2015-07-14 08:12:12
@_author: Peter Fairbrother 
@_subject: [Cryptography] Super-computer project wanted 
I have a dream ... for a single-database PIR-based anonymous messaging service, based on either a variant of Cachin, Micali and Stadler's [1] or Gentry and Ramazan's [2] PIR schemes.
Both schemes however require a huge amount of computation, in the form of modular exponentiations, by the (distributed) servers.
This would not be a once-only effort, it would have to be a continuous service, so it might not be in accord with your project requirements.
However, any work designs for both software and inexpensive hardware systems which can do vast numbers of modexps, would be interesting; and might lead to a practical computationally-untraceable messaging service, for at least tweet-sized messages.
[1]  . The variant is unpublished, but I presented it in a rump session at PET2003.
[2]

@_date: 2015-07-14 08:42:36
@_author: Peter Fairbrother 
@_subject: [Cryptography] The names in "the mesh" 
It also reminds me of "mashes", which I described here a few years ago.
A mash is a truncated hash, 12 to 16 characters long, from an alphabet of 32 characters, to give 60 to 80 bits of security.
The document which is mashed is available online in an untrusted distributed directory, and contains the owner's name, two [1] public keys, the key owner's email address, a proof of work, telephone number and other details at the owner's discretion - the point is that the mash is both the identity and the address.
In order to send someone an email (or call them on the encrypted 'phone, or post them a letter etc.) at a mash you have to find out their email address - which means finding out the document, which contains their public keys. The right software, and end-to-end encryption is transparent to the user, and pretty much universal.
One variation has the mash as peter-m-GJRV-FFR5-6TTR, with the first part, peter, as the first part of the document. The -m- is constant, like an @ in an email address.
I _think_ you do not need more than 60 bits of security - taken with the proof of work, means that a tailored attack on a particular 60 bit hash is impractical.
[1] two public keys, one for authentication, one for encryption; plus signed DH forward secrecy keyparts and update information etc attached to the document but outside the hash.
And one point of mashes is that you HAVE to know the document which contains the recipient's key in order to even send them a message.

@_date: 2015-07-18 08:12:24
@_author: Peter Fairbrother 
@_subject: [Cryptography] Hypothetical WWII cipher machine. 
A smallish suggestion, perhaps one change - the device is an updated, secure rotor machine, but it has been designed so as to be defeat the methods used to break Enigma - unfortunately, it's design is also such that if it fell into Nazi hands they would know for sure that Enigma had been broken ..
Your first mistake is in the first sentence: there are 13 triangular parts, 24 boat-shaped parts (and with four input and four output contacts, there are only ten possible different varieties of each).

@_date: 2015-06-09 08:24:46
@_author: pete 
@_subject: [Cryptography] Logjam attack, state level attack 
Not all that new,  but I haven't seen any comment here.
Logjam attack, and the state-level attacks mentioned in the logjam paper. Logjam, like FREAK, degrades crypto suites, in this case TLS DH to 512-bit "export grade" crypto. It's a bit more sophisticated than FREAK, but not much.
7th principle: Holes for "good guys" are holes for bad guys too.
8th principle: In code, nothing ever really goes away.
(big nod to Jerry Leichter)
More controversial, and quite possibly more damaging, is this:
"Threats from state-level adversaries.
Millions of HTTPS, SSH, and VPN servers all use the same prime numbers for Diffie-Hellman key exchange. Practitioners believed this was safe as long as new key exchange messages were generated for every connection.
However, the first step in the number field sieve â the most efficient algorithm for breaking a Diffie-Hellman connection â is dependent only on this prime. After this first step, an attacker can quickly break individual connections.
A close reading of published NSA leaks shows that the agency's attacks on VPNs are consistent with having achieved a break [of the single, most common 1024-bit prime]."
I wonder whether the "state level threat" of breaking common 1024-bit DH primes is the "major breakthrough" which NSA told Congress about a few years ago, for which they got all that lovely extra money.
If so, the people who in 2013 were supporting the idea of replacing 2048-bit RSA with ubiquitous 1024-bit DH in order to provide FS look a bit silly ..
[ the major browsers supported 1024-bit DH but 2048-bit RSA, perhaps due to people mistakenly thinking that DH keys needed to be half the size of RSA keys - it might be interesting to see where that rumour came from.
To quote Peter Gutmann, posting here:
"It's a debate between two groups, the security practitioners, "we'd like a PFS solution as soon as we can, and given currently-deployed infrastructure DH-1024 seems to be the best bet", and the theoreticians, "only a theoretically perfect solution is acceptable, even if it takes us forever to get it"." ]
.. as the only people who could even partially break 2048-bit RSA were the major agencies (gimme the private keys sunshine, or go to jail), the same ones who could almost universally break 1024-bit DH, but without the hassle of warrants or anyone else knowing about it ..
By the way, this was just after Snowden, when Google and the like were moving to 2048-bit RSA, and other people were running around like headless chickens saying "we must do something".
NSA must have been laughing all the way to the bank.

@_date: 2015-06-09 08:36:46
@_author: pete 
@_subject: [Cryptography] Proposed US ITAR changes would require 
Proposed US ITAR changes. New regs, for comment, not yet in law or in force.
Actually, it says, for the first time explicitly, that publishing widely on the internet would be enough to put data into the public domain [000]. Sounds good?
However, there is a great big kicker: posting ITAR technical data for the first time would be an export, and you wouldn't be allowed to do it without prior authorization [17].
Reposting already-posted technical data is also making it available, and you wouldn't be allowed to do that unless the initial posting was Neither would you be allowed to sell a book or magazine or periodical, even within the US, unless it had been made available with an authorisation [23].
Phil Zimmerman's trick, publishing the source to PGP in printed form to put it in the public domain, would no longer work.
There is also some trickery about redefining software as an item, rather than as data; one effect of which is to put software which is the result of fundamental research into the control regime.
Of course, as "fundamental research" only means research done in the US by US centers of learning, or US Government funded ..
I get confused, but it would seem to me that eg if there is a crypto conference in the US with published proceedings, the publishers would need export permission for the work of foreign authors, but not the work of most US authors.
[000] "Public domain" here is not the same thing as "public domain" in copyright law. The use the same words, but they are defined completely [17] To get pernickity: data which has been made publicly available, including by widespread posting, would be exempt.
However, data which hadn't been made available with proper authorisation would not be exempt. This would apply to data which is now in the public domain too.
If you saw some posted data or data in a book, and you didn't actually know that it hadn't been released with proper authorisation, you couldn't be prosecuted for reposting it, or selling the books it was in. Though you could be prevented from doing it again, if someone told you its initial release has not been authorised.
[23] the relevant bits:
Â§ 120.11 Public domain.
(a) Except as set forth in paragraph (b) of this section, unclassified information and software are in the public domain, and are thus not technical data or software subject to the ITAR, when they have been made available to the public without restrictions upon their further dissemination such as through any of the following:
(1) Subscriptions available without restriction to any individual who desires to obtain or purchase the published information;
(2) Libraries or other public collections that are open and available to the public, and from which the public can obtain tangible or intangible (3) Unlimited distribution at a conference, meeting, seminar, trade show, or exhibition, generally accessible to the interested public;
(4) Public dissemination (i.e., unlimited distribution) in any form (e.g.,not necessarily in published form), including posting on the Internet on sites available to the public; or
(5) Submission of a written composition, manuscript or presentation to domestic or foreign co-authors, editors, or reviewers of journals, magazines, newspapers or trade publications, or to organizers of open conferences or other open gatherings, with the intention that the compositions, manuscripts, or publications will be made publicly available if accepted for publication or presentation.
(b) Technical data or software,whether or not developed with government funding, is not in the public domain if it has been made available to the public without authorization From-Mail: From-Name: 1 The Directorate of Defense Trade Controls;
(2) The Department of Defenseâs Office of Security Review;
(3) The relevant U.S. government contracting entity with authority to allow the technical data or software to be made available to the public; or
(4) Another U.S. government official with authority to allow the technical data or software to be made available to the public.
Â§ 127.1 Violations.
(6) To export, reexport, retransfer, or otherwise make available to the public technical data or software if such person has knowledge that the technical data or software was made publicly available without an authorization described in Â§ 120.11(b) of this subchapter.
ps: there is yet another ITAR change on the way about exploits and technical data concerning security and hacking tools.
see eg;

@_date: 2015-06-11 05:42:41
@_author: Peter Fairbrother 
@_subject: [Cryptography] Proposed US ITAR changes would require 
Sounds interesting,
They are basically trying to reintroduce the "born secret" principle, which in US law exists only in an unchallenged part of the Atomic Energy Act; though that concept has not been tested against First Amendment rights as the only previous case of note (United States v. The Progressive, 1979) was dropped by the Government before it reached the Supreme Court.
But it's "born again secret" as well as "born secret, again" - it applies to all previous technical data, whether widely disseminated or not.

@_date: 2015-10-04 14:50:04
@_author: Peter Fairbrother 
@_subject: [Cryptography] Edwards curves are just ellipses - and why ECC 
There is a bit more to it.
Elementary group theory:  A group is a set of elements with an associated binary operation. For it to be a group the binary operation must have three required properties: closure, inverses, associativity. As a fourth required property, one of the elements in the set must be an identity element.
Looking at closure for a start. In your construction F(a) + F(b) need not be in the domain of F, in which case G(a, b) does not exist and the construct is not a group.
By the same argument, using your method can produce an operation without In a group, the binary operation is by definition associative, ie for all a,b,c in the group set (a*b)*c = a*(b*c). The method you suggest does not necessarily produce associative operations.
In a group there must be an identity element - the method you suggest does not necessarily result in the existence of an identity element.
So, 0 out of 4 required properties - not very good. And not groups.
An example. The domain of the one-to-one function F is apple, orange, halfbrick, lead pipe. The codomain is orange, apple, leadpipe, halfbrick. The function is
o -> a
a -> o
h -> l
l -> h
and the inverse is
a -> o
o -> a
l -> h
h -> l
What does G(apple, leadpipe) equal?

@_date: 2015-10-16 23:26:43
@_author: Peter Fairbrother 
@_subject: [Cryptography] Fwd: freedom-to-tinker.com: How is NSA breaking 
Unless NSA has built asics ..
I gotta repost this, first posted here 09 June. Not so much a told-you-so (though it is :) but.. the paper seems to have been rewritten, but it's the same paper. The last part of the post is particularly apposite:
Not all that new,  but I haven't seen any comment here.
Logjam attack, and the state-level attacks mentioned in the logjam paper. Logjam, like FREAK, degrades crypto suites, in this case TLS DH to 512-bit "export grade" crypto. It's a bit more sophisticated than FREAK, but not much.
7th principle: Holes for "good guys" are holes for bad guys too.
8th principle: In code, nothing ever really goes away.
(big nod to Jerry Leichter)
More controversial, and quite possibly more damaging, is this:
"Threats from state-level adversaries.
Millions of HTTPS, SSH, and VPN servers all use the same prime numbers for Diffie-Hellman key exchange. Practitioners believed this was safe as long as new key exchange messages were generated for every connection.
However, the first step in the number field sieve — the most efficient algorithm for breaking a Diffie-Hellman connection — is dependent only on this prime. After this first step, an attacker can quickly break individual connections.
A close reading of published NSA leaks shows that the agency's attacks on VPNs are consistent with having achieved a break [of the single, most common 1024-bit prime]."
I wonder whether the "state level threat" of breaking common 1024-bit DH primes is the "major breakthrough" which NSA told Congress about a few years ago, for which they got all that lovely extra money.
If so, the people who in 2013 were supporting the idea of replacing 2048-bit RSA with ubiquitous 1024-bit DH in order to provide FS look a bit silly ..
[ the major browsers supported 1024-bit DH but 2048-bit RSA, perhaps due to people mistakenly thinking that DH keys needed to be half the size of RSA keys - it might be interesting to see where that rumour came from.
To quote Peter Gutmann, posting here:
"It's a debate between two groups, the security practitioners, "we'd like a PFS solution as soon as we can, and given currently-deployed infrastructure DH-1024 seems to be the best bet", and the theoreticians, "only a theoretically perfect solution is acceptable, even if it takes us forever to get it"." ]
.. as the only people who could even partially break 2048-bit RSA were the major agencies (gimme the private keys sunshine, or go to jail), the same ones who could almost universally break 1024-bit DH, but without the hassle of warrants or anyone else knowing about it ..
By the way, this was just after Snowden, when Google and the like were moving to 2048-bit RSA, and other people were running around like headless chickens saying "we must do something".
NSA must have been laughing all the way to the bank.

@_date: 2015-10-22 11:39:26
@_author: Peter Fairbrother 
@_subject: [Cryptography] Other obvious issues being ignored? 
While others have mentioned optimising compilers "optimising" away security measures, let's not forget object code authentication.
Most people don't compile their own code, they trust someone else to do it, and (maybe) check the signatures on the object code.
But does the object code match the source? The only way you can be sure is if the compiler can repeatedly produce the same object code - and today's compilers don't do that, for at least ten reasons which have nothing to do with security.
Jerry Leichter doubted that "having a whole separate language for writing security-related code is the right approach" - but I think eventually it must be.
Though even that would not wholly solve the silicon problem, where the processor changes the instructions..
No low-level optimising stuff like mallocs - the complier should allocate memory, and delete/release it, always, and in a secure manner, always, not the programmer. No user-generated buffers, so no buffer overflows even possible - you don't actually need user-generated fixed-size buffers. No undefined behaviour, ever.
No compiler options.
Actually, it makes for a fairly simple language, and a not-too-complex

@_date: 2015-09-14 01:55:54
@_author: Peter Fairbrother 
@_subject: [Cryptography] Comey: targeted ads => plaintext access 
hmmm - looking at the title, "targeted ads => plaintext access", I
initially thought of peeping on the Google targeted adserver traffic and looking for ads for eg dynamite.
But apparently it's not about that.
Ah, he's FBI not NSA - FBI prolly haven't thought of looking for dynamite ads yet.
No, Mr Comey, we [1] do not share the same values.
You are a nosy snooping peeping tom, and in general we try to protect people and their traffic from nosy snooping peeping toms like as you.
[1] mostly. I hesitate to speak for the open crypto community as "us", and I guess we have our share of nosy snooping peeping toms too.
That's not clear, but maybe the problem is partly your reliance on peeping on internet traffic in order to do your job; and partly your wish to peep at all internet traffic, including traffic where you have no reason to suspect the people making the traffic.
Would we accept some peeping, on a targeted level, for a good cause - probably. That seems to be the majority opinion - a little peeping is OK if it is in a good cause.
The power of peeping is such that I personally believe that it cannot be effectively controlled, and thus all peeping should be outlawed - but not all agree.
So the secondary question - how much peeping?
US 4th amendment sounds about right - internet traffic and papers are not very different. A warrant, and show cause, in each and every case.
Anything less in the way of control? No.
Capability and intent - capability to peep, and reason for peeping - are intertwined nowadays.
Because some people (NSA?) want to peep a lot, the public in the form of tech companies are introducing technological measures to stop indiscriminate peeping.
These measures are generally aimed at mass peeping, not targeted peeping, but they also stop targeted peeping.
I do not see this trend towards the technological prevention of targeted peeping decreasing, in fact I think it may accelerate.
More, the more widespread introduction of end-to-end encryption. which will stop all [2] peeping, may reach a tipping point, to where almost all comms are encrypted end-to-end - and the real bad guys, will of course be early adopters.
[2] the brits have a "show us the keys/plaintext or go to jail" law - but that would be unconstitutional in the US, and is very probably against EU human rights legislation as well.
It is applied very sparingly, less than 10 times per year on average, probably in order to avoid a EU case: and there are technological measures which, if taken, pretty much reduce its effectiveness to zero Wow, you can't have looked hard. Or in the right places, eg here. Or possibly at all.

@_date: 2015-09-14 02:17:02
@_author: Peter Fairbrother 
@_subject: [Cryptography] "Ulysses pacts": better than "warrant canaries" ? 
"binary transparency" - the digital matching of updates (your clients permit updates??! ?? you permit your clients to know each other??) - is not a Ulysses pact or a self-enforcing self-destruct button, or a replacement for warrant canaries.
These are different things.
Ulysses pacts etc are about warrants served on you, the server - binary transparency is occasionally about warrants served on your software Occasionally a warrant might be served on you, to serve your clients with a trojaned software - but binary transparency will not be something you do which will allow them to detect it, it is up to the clients to compare upgrades.
You will almost certainly be required by the warrant to do all you can to prevent the client knowing is trojaned, eg provide him with fake hashes.

@_date: 2016-04-12 18:29:28
@_author: Peter Fairbrother 
@_subject: [Cryptography] Is storing a hash of a private key a security 
I suppose you could use it test guesses of keys, but that doesn't help an attacker much.
If the hash was serious1y broken (and aren't they all??) though, then maybe you could use it to test swathes of guesses (all of which had the same hash value) at once, which might help an attacker.
Also, with the hash value stored outside the secure enclave, the hash value is then presumably public, or should be considered so.
Then an attacker doesn't need to use the secure enclave itself to do the tests, he can do them offline, so to speak.
Of course an attacker can test guesses by trying the guess in the ordinary way, but maybe testing hash values is quicker - probably so, especially if the hash might at some point be broken as to give some data about possible and impossible preimages, it would give some data about the keys.

@_date: 2016-04-21 22:19:31
@_author: Peter Fairbrother 
@_subject: [Cryptography] Security on TRIM for full-disk encrypted SSDs 
You think that an attacker knowing how much data you send doesn't affect hmmm, how many files on t'internet are 2798954788 bytes long?

@_date: 2016-04-29 01:19:59
@_author: Peter Fairbrother 
@_subject: [Cryptography] US Case: Infinite Jail Contempt for Disk Crypto, 
A quick-as-I-can note on the "All Writs Act" for non lawyers.
Long long ago the things which a Court could do were by and large limited to things which other Courts had done before; so people would mostly know what a Court would do if eg they murdered someone.
This is known as Common Law, and the principle behind it is known as "stare decisis" - the idea that all Courts will act alike, and that therefore justice is the same for all, and that people can know what the Courts will say people can and cannot do.
However if a Court came across a new situation then if it needed to it could do something new to ensure justice was done. There was no fundamental limitation on what Courts could do, only that they had a vague but general duty to follow previous precedents if they reasonably  From time to time since then people have tried to put what a Court could do into writing; these are the laws passed by Governments, which are known as Statute Law, as opposed to the previous Common Law.
However, and thankfully, the transition to Statute-only Law has never been completed, and in general Common Law is still in effect except in particular areas where Statute law has said it isn't.
The All Writs Act was simply an early attempt to put the previous Common Law idea that a Court could do whatever was necessary to ensure justice in a new situation (within some limitations) into Statute Law.
It says that a Court can issue any writs it needs to in a new situation (a "matter of first impression") - but this has always been the case, for over a thousand years.
If you repealed the All Writs Act the Courts would have slightly more power to issue writs, as the limitations in the Act would be gone.

@_date: 2016-02-16 21:28:02
@_author: Peter Fairbrother 
@_subject: [Cryptography] 
=?utf-8?q?of_Suite_B?=
No surprise there.
No FS means that NSA's attack division only have to key-break one communication in order to break all the traffic between two people; whereas with FS they have to break each communication separately.
Also, with FS they can't use a lot of their non-brute-force tricks - or indeed, $5 wrench [1] brute force tricks, only outside the US, obviously Â¬( - to obtain message keys, as the people communicating only have them for a very short time.
In another email you say:
"it's ironic that DSA is being dropped when RSA is loosing its
compelling advantage of providing key transport and server
authentication in one operation."
but it's the same forces at work again - as far as NSA's attack division goes, the compelling advantage is not going away.
Only one key used? great, that means only one key to find.
As far as producing crypto design for the world+dog goes, NSA are fscked by their dual role, both attacking and defending. They should be ignored [1]

@_date: 2016-02-19 00:12:02
@_author: Peter Fairbrother 
@_subject: [Cryptography] 
=?utf-8?q?of_Suite_B?=
Of course NSA want to attack them - otherwise how would they know what the rest of the Gubbmint are doing?  Or Gubbmint contractors?
And NSA recommended systems are used by loads of other people who have little to do with the Gubbmint.
And their recommendations are probably screwed by some really really secret considerations - eg they recommend AES but they can break it (not actually I expect, but an example of what they might be thinking).
And if they don't want to attack them, as they have the keys anyway, they still want to be able to monitor them.
The ability to monitor is more important to NSA than some small increase in security.

@_date: 2016-02-19 00:14:27
@_author: Peter Fairbrother 
@_subject: [Cryptography] Thoughts on the Apple iPhone fiasco 
Agreed. If Apple are going to claim they can't decrypt iPhones, they should make sure that they really can't decrypt them.
The problem is in the use of short 4-numeral passwords. User convenient, but not cryptographically sound unless the number of possible input attempts is limited.
Of course it is is entirely possible for Apple to make an iPhone undecryptable by themselves - if an ordinary credit card can be input-attempt-limited, and that mechanism can be practically unbreakable, why not a 'phone or other device?
The chips in cards cost less than a dollar each, in bulk.
Of course the iPhone in question is an old model,and I gather that the latest iPhones have something similar, which is supposed to be unbreakable-by-Apple -
- but I don't know as I'd trust it, as it seems Apple have been caught lying about the unbreakability of iPhones ...

@_date: 2016-07-07 11:36:20
@_author: Peter Fairbrother 
@_subject: [Cryptography] What to put in a new cryptography course 
Yep. Just restating that, 5th Principle: A more complex system has more places to attack.
Set against this, simple systems can develop brittleness where one flaw brings the whole house down, which can be especially devastating where the system is widespread or monoculturous.
Belt-and-braces defence in depth can decrease brittleness, but to be effective, each layer must be individually capable of defending the system.
At which point, people say "you don't need layer 2, layer 1 can do the job all by itself"...
Which ignores the benefits of defense-in-depth, and breaks the 9th principle: Plan for future threats.

@_date: 2016-07-12 21:30:12
@_author: Peter Fairbrother 
@_subject: [Cryptography] The Laws (was the principles) of secure information 
I've been revising the principles, and came up with this. It's an early As ever, corrections and suggestions are welcome.
Calling them Laws is perhaps a bit overreaching - but on reflection I thought that's mostly what they are, break them and the system won't be I will put the Laws up on the 'net shortly, hopefully with a link for suggestions and comments.
The Laws of secure information systems design:
Law 0: It's all about who is in control
Law 1: Someone else is after your data
Law 2: If it isn't stored it can't be stolen
Law 3: Only those you trust can betray you
Law 4: Attack methods are many, varied, ever-changing and eternal
Law 5: The entire system is subject to attack
Law 6: A more complex system has more places to attack
Law 7: Holes for good guys are holes for bad guys too
Law 8: Kerckhoffs's Principle rulez! - usually...
Law 9: A system which is hard to use will be abused or unused
law 10: Design for future threats
Law 11: Security is a Boolean
Law 12: People offering the impossible are lying
Law 13: Nothing ever really goes away
Law 15: "Schneier's law" [1] holds illimitable dominion over all... including these laws

@_date: 2016-07-13 23:57:47
@_author: Peter Fairbrother 
@_subject: [Cryptography] The Laws (was the principles) of secure 
While I agree that there are too many, these are different in a significant way -  is about trust, and betrayal and people (while considered as parts of the system) doing things they are supposed not to. The design works, the components fail.
 is about leaving openings for people within the system, openings which can be used by attackers who are not parts of the system - not just the FBI/NSA wanting backdoors, but maintenance codes, default passwords and the like. The components of the system are working in spec, the design fails.
 is much more widely applicable. It's called  because it is fundamental, more fundamental than the other laws.
So, who is in control? Parliaments, as law-making bodies?
with eg PGP, to some extent it is the user, but eg in the UK to some extend it is the Police - they can demand passwords.
For the super-duper-personal-privacy-guaranteeing system - the user? To some extent the designer?, iff he can keep user data from Gubbmint and/or the Law?
Blackberry? For ordinary users, the Canadian gubbmint (and I imagine most other gubbbmints). For enterprise users - the users? - the enterprise? - the Canadian gubbmint? - not sure.
Your non-political business design? Well, can users see other user's data?  Can users see other user's shared data? Can administrators see user's data? Can helpdesk weenies? Can the pointy-haired boss?
Can the NSA?
can probably be
Yep, I'll consider that one for inclusion.
If I told you that I'd have to kill you, of course.. :)

@_date: 2016-07-14 01:37:50
@_author: Peter Fairbrother 
@_subject: [Cryptography] The Laws (was the principles) of secure 
I was thinking about modifying  "A more complex system has more places to attack" to:
 "A larger system has more places to attack"
Larger in the sense of more complex, more complicated, with more "features" - but also larger in the sense of scale of deployment.
I have to get more about functionality and security vs functionality in somewhere as well, the present list is too skewed towards security.
Other maybes:
The security of a secret is inversely proportional to the square of the number of people who know, or can access, it.
security always favors the attacker (needs rewriting)
System design decides whether security is cheap and effective
A good system designer is better qualified to make a security choice than any user   (needs rewriting, better able to decide eg security levels, methodologies - present the average user with a list of security choices and he won't have a clue)
ignoring failure costs, the upfront and operating costs of well-designed secure systems are about the same as those of insecure ones
it _is_ a battle

@_date: 2016-07-15 19:36:58
@_author: Peter Fairbrother 
@_subject: [Cryptography] The Laws (was the principles) of secure 
is it secure
- depends on your attack model
what's an attack model?
- well, depends on who wants to get your data. If it's the nsa they can
so, is it secure
Yes but, is it secure
so, is it secure
so, is it secure?
- No
The purpose of Law 11, "Security is a Boolean", is to:
* get away from the "spend x to protect against threat y with
probability z" paradigm
- when you don't know what the threat y is.
- when you can't calculate the probability z
- when you don't know the cost of "security"
- when you don't know the cost of insecurity
- when you don't know whether it will work at all.
ie most all of the time.
And I dispute any near-linear relationship between spending and
security, unless it's spending on good system design.
"ignoring failure costs, the upfront and operating costs of
well-designed secure systems are about the same as those of insecure ones"
The purpose of Law 11, "Security is a Boolean", is also to:
* get away from the "security is protecting against threat y with
probability z" paradigm.
They may be nice paradigms in theory, but in practice ..
.. they are just about ways of estimating insecurity. They have given up
on security.
Data security is not "a sliding scale of tradeoffs towards .."
Data security is "can I, and nobody else I don't want to, get my data
when I want it?".
And far too often it's "no" when it doesn't have to be.
Take TLS with 2k DH FS where the server end isn't subject to NSLs -
that's probably secure. Ok, the server and user's computers may be
bugged or pwned - but the link itself probably can't be broken.
But as we all know there are eg MITM downgrade attacks on the link which
are possible in some cases - TLS is a very large system - but just for
that one version, we can (ignoring QC) answer the question "Is it secure
(against any possible threat)" with "Yes, we think so."
Is it really actually secure against all threats though? Well we don't
really know, it might not be.
Maybe God sees all, so nothing is secure from him. On the other hand,
maybe our data is secure in his hands.
But there is an answer to the question "Is it secure?" even if we don't
know what it is.
And that's why security is a Boolean; not a process, not a set of

@_date: 2016-07-16 20:17:58
@_author: Peter Fairbrother 
@_subject: [Cryptography] The Laws (was the principles) of secure 
Thanks, a very interesting link.
However most of my list aren't in there - I think they are somehow more fundamental, more universally applicable somehow.
Sun Tsu - The Art of War?
I don't expect to get there, but..
I'd argue, strongly, that The Art of War is an engineering tool.
Perhaps not perfect, nor universally applicable (though I have never found a situation where it is inapplicable) - but a d**n useful tool.
For my list, I'd like to see it as a tool as well - break one and you break security, follow them and you'll be secure.
Of course I'm nowhere near getting there, but that is another, perhaps the, goal.
Revised list below
-Peter Fairbrother
Revised list 16 Jul 2016:
The laws of secure information systems design:
Law 0: It's all about who is in control
Law 1: Someone else is after your data
Law 2: It can't be stolen if it isn't there
Law 3: Only those you trust can betray you
Law 4: Attack methods are many, varied, ever-changing and eternal
Law 5: The entire system is subject to attack
Law 6: A larger system has more places to attack
Law 7: Openings for good guys are openings for bad guys too
Law 8: Kerckhoffs's Principle usually rules
Law 9: A system which is hard to use will be abused or unused
law 10: Design for future threats
-------------- to be revised:
Law 15: "Schneier's law" holds illimitable dominion over all... including these laws
Part d of
a)"Anyone, from the most clueless amateur to the best cryptographer, can create an algorithm that he himself can't break. It's not even hard.
b)What is hard is creating an algorithm that no one else can break, even after years of analysis.
c) And the only way to prove that is to subject the algorithm to years of analysis by the best cryptographers around. "
d) years of analysis by the best cryptographers around helps ... but doesn't actually prove anything. For good or bad reasons the best cryptographers around might be lying about their results; there may be better cryptographers elsewhere; a really good cryptographer may have inserted an indetectable backdoor long before the best cryptographers around got to looking .. not to mention attacks against the actual, or all possible/practical, implementations, rather that attacks directly against the algorithm.
--------- bubbling under:
As system designer it's your job to make security choices, not the user's
big secrets, little secrets - treat them all the same . so an attacker can't tell the difference, and neither can you, or anybody else.
confidentiality integrity assurance
your bad security affects others
_security always favors the attacker_
defense in depth
System design decides whether security is cheap and effective
Belt-and-braces defence in depth can decrease brittleness, but to be effective, each layer must be individually capable of defending the system.
-------- unsure of their place:
Law 11: Security is a Boolean
Law 12: People offering the impossible are lying
Law 13: in code, Nothing ever really goes away

@_date: 2016-07-19 19:17:23
@_author: Peter Fairbrother 
@_subject: [Cryptography] The Laws (was the principles) of secure 
Hi Jon.
But at heart it's simple enough.
Design of secure information systems is in the first place all about who immediately controls access to the information, and later who controls other people's access to the information, and maybe who allows eg users to share information, and what information between themselves -
all of which is, who is in control of access to the information.
By access I include, as appropriate, addition, deletion, modification as well as "seeing" of information.
I was thinking of changing this (back)
  Law 0: Ultimately, it's all about who is in control
but it's ok as it is - in fact, it's the law I am happiest with.
Plus, it is a law like a physical law - the ultimate goal of a secure information system is to provide someone(s) with the means of control over adding, accessing, modifying, deleting information in or used by the system.
There is no other ultimate goal.
There may be considerations of availability, usability, etc which can and do overcome best control practice - but the whole point of having a secure system is to provide control.
Oh dear, I can see this is going to be very long!
There is a badly-expressed not-quite-law, "big secrets, little secrets - treat them all the same, so an attacker can't tell the difference,and neither can you, or anybody else."
So we should treat the "I don't care" by "he cares" quadrant the same as the "interesting" quadrant, and act as if someone else is after the data in it.
As according to the above principle the attacker isn't supposed to know what's in a quadrant, so the "I don't care" by "he doesn't care" quadrant should be empty - because he cares about everything unless he knows he shouldn't, as hoe is after something but can't tell where it is.
There is another argument about this, but I'll skip it for now. I'll just say
Law 1: Someone else is after your data
that is to say, someone else, someone you may not have considered.
Robert Morris Sr.: Never underestimate the attention, risk, money and time that an opponent will put into reading traffic.
Me: And never underestimate who your opponents are.
Well bloody yes.
The system has to have an attack model? why? a well-defined attack model?
So, if it's out of scope of some attack model, it isn't subject to attack?
I have this nice bottom land ..
You may - I don't. and Kerkchoff's Principle says we shouldn't.
Nope. That way lies defeat.
The attacker will in practice try things until he finds an attack which works (or stop attacking). He may well abandon an attack just before it would have become successful.
The order in which he tries attacks may (may - not all attackers are sane) be first the ones which he thinks are against the weakest points/where he thinks the least work is required/ which he thinks are most likely to succeed.
But our appreciation of what the weakest points are and what the attacker's appreciation is will almost certainly differ.
Now your statement above, "The attacker will do the least work to win." may be a good worst-case assumption - but that is all it is.
yes, it has to defend more places that a simpler system
Indeed. I have no argument with that. Thing is, in practice, most systems do not follow the corollary:
Something should be as complex as necessary and no more complex.
Or Occam's razor, Entia non multiplicanda praeter necesitas
*Everyone* puts holes in for the good guys.
I'm not just talking about backdoors, or default passwords, or the like: noone could get access to anything in the system unless there were holes for the good guys.
Even real passwords are holes.
Even the
But that is what they are, holes. Pretending the aren't holes because management doesn't like the idea is, well
First, that's not Kerckhoffs's principle, which is roughly : A cryptosystem should be secure even if everything about the system, except the key, is public knowledge.
That's very sensible, as an enemy might work all the rest out once, and if it weren't true that one break might compromise the whole system, but have to work out keys on a one-by-one basis.
But it doesn't always apply. If the system has two ends without variable keys, eg think Caesar cipher, an attacker not knowing how the system works might be enough to keep messages secure.
That makes no sense to me. Explain?
hmm, planning for 2048-but RSA? Planning for non-QS-susceptible crypto? in designs for new cryptosystems   (which is what the Laws are all about)?
I'll leave that one, see other postings
a slightly drunk (it's the hottest day of the year, cold beeer mmmmmmmmm

@_date: 2016-06-20 04:05:56
@_author: Peter Fairbrother 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
They are impossible.
This is known as the two generals problem:

@_date: 2016-06-24 17:27:20
@_author: Peter Fairbrother 
@_subject: [Cryptography] Proposal of a fair contract signing protocol 
No. Suppose Alice signs, but Bob hasn't signed yet.
Bob can create an enforceable contract by signing, Alice cannot.
I don't know why people are wasting time with this bollox, it is well-known to be impossible.
Moderator, please close this thread. It is now a waste of space and time.

@_date: 2016-03-09 11:47:00
@_author: Peter Fairbrother 
@_subject: [Cryptography] Director GCHQ speaks at MIT 
[1] Published alongside the speech were two newly declassified papers by James Ellis, a cryptographer at GCHQ who, in the 1970s, secretly invented public-key cryptography.
The papers, titled The Possibility of Secure Non-Secret Digital Encryption [2] and The Possibility of Secure Non-Secret Analogue Encryption [3], had remained classified for almost 50 years.
Hannigan : "For nearly 100 years we have been intimately involved in strengthening encryption."
And keeping it from the unwashed masses ..
Heck, check to see if you still have your fingers ..
[1] [2] [3]

@_date: 2017-02-09 13:26:00
@_author: Peter Fairbrother 
@_subject: [Cryptography] So please tell me. Why is my solution wrong? 
Replying to the rather rude Mr Kilcullen:
I haven't read your paper, and don't intend to. However from reading some of the other posts in this thread, I assume it is about securing a TLS connection by using a pre-chosen graphic sent from server to user There are two problems with this: first, it doesn't work in practice for human-type reasons. Peter G has given many links to this, which should be enough.
Second, there are no circumstances in which it is actually useful.
It doesn't prevent phishing: if the circumstances of an otherwise-succesful phishing attack are modified to include a graphic, the phishing site can easily log in to the real site (as it knows the real login details) obtain the graphic, then forward it to the client/user.
It doesn't protect in *any* other realistic use case either. It is totally useless.
I realise I haven't directly answered your question - as I said, I haven't read your paper, and as far as it goes it may be correct. But that's 20 minutes work, £40 plus 20% VAT = £52.
Paypal accepted.
