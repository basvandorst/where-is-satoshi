
@_date: 2001-07-12 11:09:24
@_author: Jurgen Botz 
@_subject: Crypto hardware  
Others have responded with specific products which may be what Kent
originally saw, but it occurs to me that this description also applies to crypto smart cards, USB dongles, iButtons, and other
such devices.
The idea with these devices is exactly that the secret key of a private/public key pair is stored in a tamper proof device and
never leaves this device (and the device can generate the key
pair so that the secret key need not ever have existed outside
the device).  The device performs RSA (or other public key)
encryption using its stored secret key... since in pratical
crypto applications the thing that's actually RSA encrypted is
small (a session key, auth challenge, or fingerprint) the device
need not be particularly fast and can use a low-bandwith interface
to the application.
Set up a PC with CA software and a smart card reader and put
your CA cert/key on a smart card and you have your tamperproof
CA master... the only weak link in the certificate generation
process is the CA's secret key, so that's really the only thing
you need to protect.  From a security standpoint everything
else should be as transparent as possible, so ideally you want
a box running open source software rather than a proprietary
appliance and isolate the critical part of the process to something that can be made very tamperproof and has well known
specs/intefaces... i.e. a smart card.
I've been playing with smart cards and iButtons, and I think
they are very cool.  I'm puzzled why they aren't seeing wider
use already, but I suspect/hope they will get a lot more popular
soon.  Opinions?

@_date: 2003-04-22 12:53:52
@_author: Jurgen Botz 
@_subject: DRM technology and policy 
The problem with this is that due to the nature of the Internet, or
more generically the increase in social "connectedness", once the
10% of people who can crack it have done so the will redistribute
"cracked" versions to the 90% who couldn't have done it.  And the
only way to prevent that is to attack the increased social
connectedness itself, which is part of what we're seeing with the
current round of "super-DMCA" state laws.  To make DRM work we
have to not only make them a technical obstacle for 90% of the people,
but also criminalize the other 10% and outlaw freedom of communication
and privacy to prevent that 10% from "corrupting" the 90%.
The issue isn't the viability of specific DRM schemes... it's what
would happen to the whole social framework if DMR schemes are viewed
as a necessary solution to some economic problem.  That social effect
is the creation of a new "digital dark age" as someone (Lessig?) has
put it.

@_date: 2003-03-30 14:33:11
@_author: Jurgen Botz 
@_subject: Run a remailer, go to jail? 
The cable modem provider and the DSL provider at their consumer
service level in my area both have explicit clauses in their AUP
prohibiting "sharing" of the connection by multiple machines
(I've seen various wordings, some explicitly mentioning NAT,
others explicitly mentioning 802.11).
So in that case, yes, using NAT would seem to be "intent to
I'm with Steve Bellovin, I think it's the broadband providers
who are behind this.
But the people saying glibly "good riddance NAT" (it's
tempting, I know) are missing the real point here...
this is a much greater threat to the end-to-end model of
the Internet than NAT ever was.
This proposed law would give the broadband provider
absolute power over the last mile, letting them separate
the edge from the core more than ever before.  Because now
they'll do it with the force of criminal law.  No longer
can you ignore their AUPs by just tunneling through a VPN.
You'll have to use the pipe exactly the way your provider
says you can use it.  If you don't they'll cut you off,
but if you try to trick them and just hide how you're
really using their pipe, by means of NAT, encrypted
tunnels, or other outlawed technologies... then they'll
send you to jail.
   :j

@_date: 2003-09-28 02:37:51
@_author: =?ISO-8859-1?Q?J=FCrgen_Botz?= 
@_subject: Reliance on Microsoft called risk to U.S. security 
Yes... and it isn't that the users are stupid or ignorant.  Most
of the time it's /really hard/ to be 100% sure, unambiguously,
what the pop-up dialogue is talking about.  This is for several
- Language.  It's hard to write a clear and unambiguous
   message, and since these are written by programmers they
   usually aren't even grammatically correct, never mind clear
   and unambiguous.
- Context.  The user often has multiple things going on, and
   often acts faster than the computer's stupid, slow, laggy,
   ugly GUI... now what did I do that caused this pop-up?  Was
   it my last click, or the other window that finally popped up
   from the link I clicked 2 minutes ago and which I had almost
   forgotten about?
- User mental "state".  The pop-up may ask for permission to use
   a previously entered password, but the user can't remember what
   they previously entered... was that one of my throwaway,
   non-secure passwords, or was it the PIN for my bank account?
These uncertainties cause stress.  After stressing about it for
a while the user clicks one choice only to find later that that
was the wrong one, increasing the stress level even more the
next time.  They are likely to soon give up, but even if they do
persevere in paying attention and trying to make the right choices,
the percentage of errors is going to be very high, and since a single
error can critically compromise security this means it's basically
J?rgen Botz               | While differing widely in the various
jurgen at botz.org           | little bits we know, in our infinite
 ignorance we are all equal. -Karl Popper
