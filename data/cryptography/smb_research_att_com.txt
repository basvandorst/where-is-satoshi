
@_date: 2001-04-02 17:11:45
@_author: Steven M. Bellovin 
@_subject: secure hash modes for rijndael  
I asked some NIST folks that question.  Their answer was that they didn't have the resources to run two large, public efforts simultaneously.  Hash functions induce much less public paranoia than do encryption algorithms; few people think that NSA wants to forge The reason for SHA-256 is to provide O(2^128) security, comparable to that of AES.  SHA-384 and SHA-512 are complements to the longer key lengths available with AES.  There's going to be a revised digital signature standard coming soon, partly to match the new hash functions and partly because of Bleichenbacher's attack on DSA.

@_date: 2001-04-24 18:23:48
@_author: Steven M. Bellovin 
@_subject: Requesting feedback on patched RC4-variant  
Not quite, for reasons that are illustrated by the WEP incident.
If you reuse a key with a stream cipher, the results are catastrophic.  That isn't true with, say, CBC and a block cipher.  Furthermore, the bit-twiddling attack on a stream cipher without a MAC is more serious than the corresponding attack on CBC, since the attacker can change particular bits without error propagation.
To be sure, MACs are very much needed with either cipher, but the failure modes aren't always the same.

@_date: 2001-12-13 22:43:30
@_author: Steven M. Bellovin 
@_subject: MS Patent for DRM OS  
My first reaction was to yawn -- that patent seems to be useful on insecure systems, since on a secure system you don't have to worry about running untrusted and trusted applications simultaneously.  Besides, the point of a patent is to prevent people from doing certain things, and I have no particular interest in doing digital rights But then I thought of the relationship between this patent and the SSCA, and it didn't seem funny any more.

@_date: 2001-12-17 18:31:16
@_author: Steven M. Bellovin 
@_subject: [DailyRotten] FBI requests worm-built password log  
In message , "Jay D. Dyson" w
Well, recovered stolen property is generally considered evidence.  Looking at that file provides evidence that the worm *did* steal passwords, and not just that it was capable of doing so according to some complex analysis.  (For many worms, there is often considerable uncertainly about exactly what they can and cannot do.  Besides, do you want to try to explain "decompiling" to a jury?)
Perhaps more on target, possession of those passwords does *not*, as far as I can tell, change the FBI's legal ability to, for example, read someone's email.  They'd still need a court order under your favorite statute.  At most, I suspect that they could use information in that file as evidence of improper possession of a password by one of the worm's victims.  Not good if you're the improper possessor -- but also not an extension of the FBI's abilities or authority.  The implication of the original claim was that the FBI wanted these passwords so that they could surreptiously read email without bothering with Magic Lantern or Carnivore.  Maybe -- but doing so without authorization is just as illegal with passwords as via a tailored Trojan horse.  (Well, maybe the latter would constitute a violation of 18 USC 1030, the Computer Fraud and Abuse Act.  I think the former would, too, plus it would violate 18 USC 1029:  use of a counterfeit access device.)
The only thing these passwords would do is make the entry easier.

@_date: 2001-12-20 15:12:41
@_author: Steve Bellovin 
@_subject: quantum computer factors number 
A quantum computer has been built that has actually factored a number: 15.
It's not a very interesting number from a cryptographic perspective, but it is real.

@_date: 2001-12-27 20:13:40
@_author: Steven M. Bellovin 
@_subject: (A)RC4 state leakage  
In message , Damien
Seee  for lots of references on RC4 and attacks on it.

@_date: 2001-07-27 14:13:40
@_author: Steven M. Bellovin 
@_subject: Criminalizing crypto criticism  
It's certainly not broad enough -- it protects "encryption" research, and the definition of "encryption" in the law is meant to cover just that, not "cryptography".  And the good-faith effort to get permission is really an invitation to harrassment, since you don't have to actually get permission, merely seek it.

@_date: 2001-06-05 12:57:53
@_author: Steven M. Bellovin 
@_subject: NSA tapping undersea fibers?  
In message , Peter Fairbrother wr
Until the Church Committee investigation in 1975, the NSA did this routinely.  They had arrangements with the various cable companies to give NSA copies of all international telegrams; the project was
code-named SHAMROCK.  (Source:  Bamford's new book "Body of Secrets"; there's also a lot out there on the Web that Google can find for you.)  Bamford's conclusion (I think; I'm not all the way through the book yet) is that NSA stopped doing that after the Church Committee's report.

@_date: 2001-06-06 14:00:32
@_author: Steve Bellovin 
@_subject: Felten et al. file suit 
Ed Felten and his co-authors, the EFF, and Usenix have filed suit in Federal court against the RIAA, SDMI, Verance, the U.S. Attorney-General, and others, seeking to enjoin the defendants from suing over the purported violation of the Digital Millenium Copyright Act.

@_date: 2001-06-16 00:23:25
@_author: Steve Bellovin 
@_subject: George Fabyan 
There's an amazing news story about George Fabyan that can be found at
I'd summarize it, but I don't think it compresses well semantically...
Let it suffice to say that Fabyan is the guy who founded the lab where William Friedman learned cryptography.  And the plaque on the wall that thanks Fabyan was presented by the NSA.

@_date: 2001-06-28 22:37:19
@_author: Steven M. Bellovin 
@_subject: archives?  
I'm not 100% certain what you're referring to.  However, there was considerable confusion early on about the keyboard encoding -- was 'A' mapped to 'A', etc., or was there (effectively) an unkeyed monoalphabetic substitution first.  IT turned out that it was just a straight-through mapping, but they hadn't tried that.

@_date: 2001-05-23 16:08:34
@_author: Steve Bellovin 
@_subject: NSA tapping undersea fibers? 
There's a long, fascinating article in the 23 May Wall Street Journal on how NSA is (allegedly) tapping undersea fiber optic cables.  It's not clear that this is feasible, but the article claims that the USS Jimmy Carter, a nuclear-powered sub, is undergoing a $1 billion, five-year retrofit to equip it to do the taps.  The article points out that even if they can tap the cable, there's another problem: making sense of that much data.
The article is at for those who subscribe.

@_date: 2001-11-03 14:15:33
@_author: Steven M. Bellovin 
@_subject: Proving security protocols  
Also see the National Research Council report "Trust in Cyberspace" (I served on that committee).  The section on formal methods can be found at  95
(yes, there's a blank in the URL...)

@_date: 2001-11-03 14:17:41
@_author: Steve Bellovin 
@_subject: California appeals court holds that DeCSS code is protected speech 
"SAN FRANCISCO (November 2, 2001 6:20 p.m. EST) - Publishing software
code to decrypt and copy digital movies is protected by the First
Amendment as an expression of free speech, a California appeals
court ruled.
"The state's 6th Appellate District in San Jose found Thursday that
Andrew Bunner's publishing of links to a software program called
DeCSS on his Web site represented "pure speech" protected under
the First Amendment."

@_date: 2001-11-25 11:57:48
@_author: Steven M. Bellovin 
@_subject: What's the state of the art in one-pass integrity/encryption?  
Rogaway's OCB is patent-pending -- see
Gligor and Donescu's NIST submission said that they had filed patent applications, too: And indicates that IBM has filed for patent applications on IAPM.

@_date: 2001-11-27 13:55:50
@_author: Steve Bellovin 
@_subject: private-sector keystroke logger... 
It's not just the FBI, of course.  There are press reports this morning of a new worm, Badtrans.b, that not only leaves behind a Trojan horse, it includes a keystroke logger.  Now, that particular leakage isn't a major concern, since it emails the stolen text to an account that's now been shut down, but I'm sure we can all think of other ways to export information like that.

@_date: 2001-10-01 18:24:55
@_author: Steven M. Bellovin 
@_subject: New encryption technology closes WLAN security loopholes  
Move up the stack a bit.  The way to launch a MITM attack on wireless is via ARP-spoofing.  *Maybe* the gateway will notice an ARP entry being overwritten -- but most likely, a human will not.

@_date: 2001-10-16 12:35:54
@_author: Steven M. Bellovin 
@_subject: Scarfo "keylogger", PGP  
The problem is that you're thinking like a computer scientist instead of like a lawyer...
Definitions are important in the law.  The wiretap statute (18 USC 2510
et seq,  defines
an "electronic communication" as "any transfer of signs, signals, writing, images, sounds, data, or intelligence of any nature transmitted in whole or in part by a wire, radio, electromagnetic, photoelectronic or photooptical system that affects interstate or foreign commerce, but does not include - (A) any wire or oral communication..."  ("Wire communications"
refers to telephone calls.)  Interception of such transmissions
is one of the things governed by the wiretap statute; the procedure
for getting an authorization for a tap is very cumbersome,
and is subject to numerous restrictions in both the statute and
DoJ regulations.
Access to *stored communications* -- things that aren't actually
traveling over a wire -- are governed by 18 USC 2701 et seq.,
which was added to the wiretap statute in 1986.  (That's when
electronic communications were added as well.)  The rules for
access there are much simpler.  But that section was written on
the assumption that email would only be stored on your service
bureau's machine!  In this case, it would appear that we're back to
the ordinary search and seizure statutes governing any computer records
owned by an individual.  *But* -- if they're *in the process of being
sent* -- 2511 would apply, it would be a wiretap, and it would be
hard to do.  The FBI agents who wrote that keystroke logger are
well aware of this distinction, and apparently tried to finesse
the point by ensuring that no communications (within the meaning
of the statute) were taking place when their package was operating.
I suppose that someone could make an argument to a judge that
email being composed is intended for transmission, and that it
should therefore be covered by 2511.  The government's counter will
be to cite 2703, which provides for simpler access to some email, as
evidence that Congress did not intend the same protections for
email not actually in transit.  I'd have to reread the ruling
in the Steve Jackson Games case to carry my analysis any further,
but I'll leave that to the real lawyers.

@_date: 2001-10-16 20:52:48
@_author: Steven M. Bellovin 
@_subject: Security Research (Was: Scarfo "keylogger", PGP ) 
Microsoft?  See their view of how to deal with security at
 -- I wonder if they
think it should apply to crypto research, too?
Of course, why should I be surprised at this?  Some crypto research is already banned by the DMCA; why not ban even more?

@_date: 2001-09-09 20:06:17
@_author: Steven M. Bellovin 
@_subject: Field slide attacks and how to avoid them.  
Mike Merritt and I discussed such issues in our critique of Kerberos
( or .pdf).
We recommended use of ASN.1 or equivalent to prevent it.  I demonstrated a variety of analogous cut-and-paste attacks in my critique of early versions of IPsec; the fix I suggested was strong authentication ( or

@_date: 2001-09-09 20:06:17
@_author: Steven M. Bellovin 
@_subject: Field slide attacks and how to avoid them.  
Mike Merritt and I discussed such issues in our critique of Kerberos
( or .pdf).
We recommended use of ASN.1 or equivalent to prevent it.  I demonstrated a variety of analogous cut-and-paste attacks in my critique of early versions of IPsec; the fix I suggested was strong authentication ( or

@_date: 2001-09-12 16:32:13
@_author: Steve Bellovin 
@_subject: DES cracked by teenagers? 
According to some teenagers "reportedly cracked an encryption technology called Data
Encryption Standard (DES)".  I'm skeptical, but I thought I'd toss it out.  Anyone have any details?

@_date: 2001-09-14 22:57:05
@_author: Steven M. Bellovin 
@_subject: Senate votes to permit warrantless Net-wiretaps, Carnivore use  
In message <5.0.2.1.0.20010914161852.00a9cbf0 at mail.well.com>, Declan McCullagh This is seriously misleading.  Although there are a fair number of objectionable items in the bill (the worst of which are likely unconstitutional, though you'd have to explain protocol layering to a judge to make that point clear), the bill is concerned with pen registers and trap-and-trace devices.  It does not legalize "warrantless wiretaps".  And yes, Carnivore can be used more freely under this bill, but only in its pen register mode.
There's a lot to worry about; we do ourselves a disservice by attacking the wrong things.

@_date: 2001-09-16 19:16:45
@_author: Steven M. Bellovin 
@_subject: How to ban crypto?  
In message <4.2.2.20010916164053.00da5520 at surfcity.research.att.com>, John Denk
John, you've just opened a can of worm.  A giant, economy-sized can of The basic argument is complexity.  Cryptographic software and key exchange protocols are very hard to get right even in simple cases.  If we now try to add a new feature, we have to add complexity.  Worse yet, this new feature is designed to do something that is not only brand-new, it's something that more conventional protocols and implementations are designed to avoid, at virtually all costs:  export a copy of the key.  Why do you think we can get this right?  That's the essence of why I (and many others) accept (1); for more detail, see "The Risks of Key Recovery, Key Escrow, and Trusted Third Party Encryption", at   As a postscript, I'll note that we've already had a failure associated with the key recovery mechanisms in a version of PGP; see CERT Advisory CA-2000-18,

@_date: 2001-09-21 11:24:23
@_author: Steven M. Bellovin 
@_subject: Op-ed on encryption: Privacy is no longer an argument  
Apart from anything else, Guzy misses the technical argument:  that key escrow will likely make things worse.  In a recent (post-attack) interview, I asked the reporter what would happen to escrowed keys if Robert Hansen were still at large.  As for "but lives aren't at stake"

@_date: 2001-09-24 18:31:13
@_author: Steven M. Bellovin 
@_subject: [FYI] Did Encryption Empower These Terrorists?  
Actually, I believe it's by the merchants.  Internet transactions generally count as "card not present" transactions, which means that the merchants take the risk.

@_date: 2001-09-26 13:58:07
@_author: Steven M. Bellovin 
@_subject: [FYI] Antiques man guilty of Enigma charge  
The machine in question is an Abwehr Enigma, a variant of the basic design.  (There were a fair number of variants, in fact.)

@_date: 2002-04-04 14:02:11
@_author: Steve Bellovin 
@_subject: NIST standardizes HMAC 
On April 3, NIST announced that it had issued FIPS 198, on HMAC.  See

@_date: 2002-04-04 14:02:11
@_author: Steve Bellovin 
@_subject: NIST standardizes HMAC 
On April 3, NIST announced that it had issued FIPS 198, on HMAC.  See

@_date: 2002-04-29 12:08:03
@_author: Steven M. Bellovin 
@_subject: Gartner supports HK smart ID card use  
Folks on this list might be interested in a National Research Council report on nationwide identity systems:

@_date: 2002-08-19 17:54:24
@_author: Steve Bellovin 
@_subject: SEC weighing civil injunction against RSA 
RSA, Inc., in a filing, reported that the SEC is considering seeking an injunction against it and some of its officers.  The filing did not say what the injunction was about.

@_date: 2002-02-11 18:43:49
@_author: Steven M. Bellovin 
@_subject: Where's the smart money?  
I can't speak for other countries, but the U.S. already has well-defined procedures for trading in damaged currency.  For example, if you have >3/5 of the bill, you get full value; between 2/5 and 3/5, you get half-value; below that, you get nothing.  I believe that such exchanges can be done at any bank, though I could be wrong about that.
Anyway -- I'd assume that similar procedures would be put in place for tagged bills.  Validation might inlude a waiting period to see if the tag corresponding to that serial number shows up.

@_date: 2002-01-16 09:15:21
@_author: Steve Bellovin 
@_subject: password-cracking by journalists... 
A couple of months ago, a Wall Street Journal reporter bought two
abandoned al Qaeda computers from a looter in Kabul.  Some of the
files on those machines were encrypted.  But they're dealing with
that problem:
Does anyone have any technical details on this?  (I assume that it's
a standard password-guessing approach, but it it would be nice to know
for certain.  If nothing else, are Arabic passwords easier or harder
to guess than, say, English ones?)

@_date: 2002-01-17 21:24:50
@_author: Steven M. Bellovin 
@_subject: password-cracking by journalists...  
I didn't say that they would be easier; I asked...  As for why I asked

@_date: 2002-01-19 19:38:02
@_author: Steven M. Bellovin 
@_subject: password-cracking by journalists...  
In message , Sampo
Right -- there are factors pushing in both directions, and I don't know how it balances.
Your mention of Unicode, though, brings up another point:  the encoding that's used can matter, too.  If UCS-2 or UCS-4 (16 and 31-bit encodings) are used, I believe that there are many constant bits per character.  Even UTF-8 would have that effect.

@_date: 2002-01-22 10:39:40
@_author: Steven M. Bellovin 
@_subject: password-cracking by journalists... (long, sorry)  
Another point -- the law protects "encryption" research, not "cryptographic" research.  Watermarking or DRM systems do not appear to be covered by the statute's definition of "encryption".

@_date: 2002-06-06 14:40:17
@_author: Steve Bellovin 
@_subject: Key Management Guideline Draft (fwd) 
The Key Management Guideline is under development and has been divided into three parts. Part 1 will contain General Guidance; a draft of this part is available at  NIST welcomes comments to be
submitted from the public at any time, but would prefer that comments on this part be submitted by August 15, 2002. Please submit these comments to GuidelineComments at nist.gov. The reader should be aware that the content of this document is not stable and may change during the continuing development process.
Part 2 will provide guidance for system and application owners for use in identifying appropriate organizational key management infrastructures, establishing organizational key management policies, and specifying
organizational key management practices and plans.
Part 3 is intended to provide guidance to system administrators regarding the use of cryptographic algorithms in specific applications, select products to
satisfy specific operational environments, and configure the products Elaine Barker
National Institute of Standards and Technology
100 Bureau Dr., Stop 8930
Gaithersburg, MD 20899-8930
Phone: 301-975-2911
Fax: 301-948-1233
Email: ebarker at nist.gov

@_date: 2002-06-20 15:19:08
@_author: Steven M. Bellovin 
@_subject: DOJ proposes US data-rentention law.  
This isn't clear.  The proposals I've seen call for recording "transaction data" -- i.e., the SMTP "envelope" information, plus maybe the From: line.  It does not call for retention of content.
Apart from practicality, there are constitutional issues.  Envelope data is "given" to the ISP in typical client/server email scenarios, while content is end-to-end, in that it's not processed by the ISP.  A different type of warrant is therefore needed to retrieve the latter.  The former falls under the "pen register" law (as amended by the Patriot Act), and requires a really cheap warrant.  Email content is considered a full-fledged wiretap, and requires a hard-to-get court order, with lots of notice requirements, etc.  Mandating that a third party record email in this situation, in the absence of a pre-existing
warrant citing probable cause, would be very chancy.  I don't think even the current Supreme Court would buy it.

@_date: 2002-06-21 11:42:22
@_author: Steven M. Bellovin 
@_subject: Shortcut digital signature verification failure  
That involves extra round trips, and as such isn't suitable for all

@_date: 2002-05-30 00:35:13
@_author: Steven M. Bellovin 
@_subject: FC: Hollywood wants to plug "analog hole," regulate A-D conve rters  
In other words, an ad-skipping device should skip anything not watermarked, since those are ads....
What's your threat model, and what are *all* the implications of it?

@_date: 2002-05-31 17:23:23
@_author: Steven M. Bellovin 
@_subject: Commercial quantum crypto product - news article  
In message <2F1A38DC0413D311A7310090273AD527042023F8 at dthrexch01>, "Kossmann, Bi
A fascinating article.  It raises an interesting point:  how does one validate such a system?

@_date: 2002-11-03 17:20:29
@_author: Steven M. Bellovin 
@_subject: Windows 2000 declared secure  
In message <1036287365.30537.543.camel at deskjob.eros-os.org>, "Jonathan S. Shapi
Hmm -- let me point folks at (registration at

@_date: 2002-11-07 15:55:26
@_author: Steven M. Bellovin 
@_subject: Did you *really* zeroize that key?  
In message <200211070207.PAA88426 at ruru.cs.auckland.ac.nz>, Peter Gutmann writes
Regardless of whether one uses "volatile" or a pragma, the basic point remains:  cryptographic application writers have to be aware of what a clever compiler can do, so that they know to take countermeasures.

@_date: 2002-10-02 14:56:39
@_author: Steven M. Bellovin 
@_subject: What email encryption is actually in use?  
The primary use of STARTLS for SMTP is for mail *submission*, not relaying.  That is, when clients (like Eudora) generate mail, they submit it to an ISP or organizational SMTP server.  If this server is accessible from the Internet, it should require some sort of authentication, to avoid becoming an open spam relay.  This is sometimes done by a password over a TLS-protected session.
In other words, this isn't opportunistic encryption, and doesn't run into the problem of "random smtp server has a self-signed cert".  The client should be configured to know what cert to expect.

@_date: 2002-10-02 14:58:56
@_author: Steven M. Bellovin 
@_subject: Optical analog computing?  
In message <5.1.0.14.2.20021003031603.0409fea8 at 203.30.171.11>, Greg Rose writes
If memory serves (my references are at home), the Bletchley Park crew used holes punch in large grids.  They'd overlap many sheets and see where the light made it through; that would be a good key (or candidate I don't know if you'd call that a "computer", but it was an interesting optical device.  I'm sure there have been many later applications of similar principles -- see Shamir's TWINKLE, for example, which relied on
detecting aggregate brightness over many LEDs.

@_date: 2002-10-03 21:19:20
@_author: Steve Bellovin 
@_subject: Confidentiality as a goal of old telegraph codes 
It's a truism in the crypto business that the old telegraph codes were for economy, with confidentiality against casual readers a noted and desirable goal.  But I've recently acquired two old codebooks that have stronger ambitions.
The more interesting one is Slater's Telegraph Code, since confidentiality is its only goal.  I have the 9th Edition, from 1938, but it appears to be originally from the late 1860's.  It encodes 25,000 words, including "a" and "the".  There are no sentences, phrases, etc.  Users
are told to convert the plaintext word to a number, transform the number, and convert back to a new word for transmission.  Suggested transformations include adding or subtracting a shared secret constant, permuting some of the digits of the code number, and/or regrouping the digits of a string of code numbers.  Clearly not military-grade security, even for the time, I'd guess; in addition to the rather simple transforms, it's a one-part code.
Equally interesting is the threat model.  I quote from the introduction:
It goes on to warn of the need for confidentiality in business
communications, especially when undersea telegraph lines are used.
Equally interesting is the fact that despite the common wisdom that
says that secrecy products didn't sell well, this book survived
for about 70 years -- with my edition being printed on the eve of war.
The other confidentiality code I have is "Sheahan's Telegraphic Cipher
Code", from 1892.  It was intended for use by railway labor organizers,
to keep management from knowing what they were up to.  It has about
7000 code words.
It's a more conventional telegraph code, in that it includes some
phrases.  The general confidentiality scheme is similar to Slater's,
though the only suggested transformation is adding or subtracting
a constant to the code number.  Because the plaintext is phrases,
rather than just words, there are separate code words along with the
code numbers; these words are sent, rather than the numeric values.
that times, days, and numbers do not have code numbers -- the instructions
say to send just the code words.  The compiler was worried about a
known or probable plaintext attack on the offset value used for
superencipherment.  There is also a warning against mixing plaintext
with ciphertext, "excepting the name of a person or the name of a town".
There is a cipher alphabet for spelling out words, but it, too, is not superenciphered.
Some of my other, larger code books could have been used in a similar
fashion, but there's no hint of that in the instructions.

@_date: 2002-10-10 17:50:51
@_author: Steve Bellovin 
@_subject: CFP -- IEEE Symposium on Security and Privacy 
CALL FOR PAPERS
May 11-14,2003
The Claremont Resort
Oakland, California, USA
2003 IEEE Symposium on
Security and Privacy
sponsored by
IEEE Computer Society Technical Committee on Security and Privacy
in cooperation with
The International Association for Cryptologic Research (IACR)
Symposium Committee:
General Chair: Bob Blakley (IBM Software Group - Tivoli Systems, USA) (bblakley
Vice Chair: Lee Badger (Network Associates Labs, USA)
Program Co-Chairs: Steven M.  Bellovin (AT&T Research, USA)
David A. Wagner (University of California at Berkeley, USA)
Since 1980, the IEEE Symposium on Security and Privacy has been
the premier forum for the presentation of developments in computer
security and electronic privacy, and for bringing together researchers
and practitioners in the field.
Previously unpublished papers offering novel research contributions
in any aspect of computer security or electronic privacy are
solicited for submission to the 2003 symposium. Papers may represent
advances in the theory, design, implementation, analysis, or
empirical evaluation of secure systems, either for general use or
for specific application domains. Topics of interest include, but
are not limited to, the following:
Commercial and Industrial Security Electronic Privacy
Mobile Code and Agent Security Distributed Systems Security
Network Security Anonymity
Data Integrity Access Control and Audit
Information Flow Security Verification
Viruses and Other Malicious Code Security Protocols
Authentication Biometrics
Smartcards Peer-to-Peer Security
Intrusion Detection Database Security
Language-Based Security Denial of Service
Security of Mobile Ad-Hoc Networks
Program Committee:
Martin Abadi (University of California Santa Cruz, USA)
Marc Dacier (Eurecom, France)
Drew Dean (SRI, USA)
Barbara Fox (Microsoft, USA)
Virgil Gligor (University of Maryland, USA)
Peter Gutmann (University of Auckland, New Zealand)
John Ioannidis (AT&T, USA)
Trent Jaeger (IBM, USA)
Paul Karger (IBM, USA)
Dick Kemmerer (University of California Santa Barbara, USA)
John McLean (Naval Research Laboratory, USA)
Vern Paxson (ICSI, USA)
Michael Roe (Microsoft, UK)
Avi Rubin (AT&T, USA)
John Rushby (SRI, USA)
Paul Syverson (Naval Research Laboratory, USA)
INSTRUCTIONS FOR PAPER SUBMISSIONS
Submitted papers must not substantially overlap papers that have
been published or that are simultaneously submitted to a journal
or a conference with proceedings. Papers should be in Portable
Document Format (.pdf) or Postscript (.ps), at most 15 pages
excluding the bibliography and well-marked appendices (using 11-point
font, single column format, and reasonable margins on 8.5"x11" or
A4 paper), and at most 25 pages total. We request the submissions
be in US letter paper size (not A4) if at all possible. Authors
submitting papers in PDF are urged to follow the NSF "Fastlane"
guidelines for document preparation (
 ), and to pay special
attention to unusual fonts.  Committee members are not required to
read the appendices, so the paper should be intelligible without
them. Papers should be submitted in a form suitable for anonymous
review: remove author names and affiliations from the title page,
and avoid explicit self-referencing in the text.
Instructions on electronic submission will appear shortly at
 .
For any questions, please contact the program chairs, at
oakland-chairs03 at research.att.com.
Paper submissions due: November 6, 2002
Acceptance notification: January 29, 2003
Submissions received after the submission deadline or failing to
conform to the guidelines above risk rejection without consideration
of their merits.  Authors are responsible for obtaining appropriate
clearances; authors of accepted papers will be asked to sign IEEE
copyright release forms. Where possible all further communications
to authors will be via email.
PANEL PROPOSALS
The conference may include panel sessions addressing topics of
interest to the computer security community. Proposals for panels
should be no longer than five pages in length and should include
possible panelists and an indication of which of those panelists
have confirmed participation. Please submit panel proposals by
email to oakland-chairs03 at research.att.com.
Panel proposals due: November 6, 2002
Acceptance notification: January 21, 2003
Where possible all further communications to authors will be via email.
5-MINUTE TALKS
A continuing feature of the symposium will be a session of 5-minute
talks, where attendees can present preliminary research results or
summaries of works published elsewhere. Poster presentations related
to these talks are also possible. Abstracts for 5-minute talks
should fit on one 8.5"x11" or A4 page, including the title and all
author names and affiliations. Please submit abstracts by email to
oakland-chairs03 at research.att.com.
5-minute abstracts due: March 17, 2003
Acceptance notification: March 31, 2003
Where possible all further communications to authors will be via email.

@_date: 2002-10-14 12:07:33
@_author: Steve Bellovin 
@_subject: Input requested for second edition of "Firewalls and Internet  
[slightly (but only slightly, I hope) off-topic]
We've just about finished the draft manuscript for the second
edition of "Firewalls and Internet Security" (this time by Bill
Cheswick, Steve Bellovin, and Avi Rubin).  Given the tremendous
change in the market (including both the prevalence of commercial
firewalls and widespread easy access to open source software),
we're dropping the appendix that lists useful free software; we're
replacing it by a list of important sources to monitor for word on
new holes, major patches, etc.  (We'll put up a draft table of contents on the book's web site some time this weekend.)
So -- what are your favorite mailing lists, web sites, etc., for
keeping your systems and networks secure?
(To answer the obvious question:  we don't yet know precisely when the new book will appear on the shelves.  A lot depends on how much rewriting we'll have to do in response to the technical reviews.  But some time in the spring looks to be a pretty good bet.)

@_date: 2002-10-27 13:50:46
@_author: Steve Bellovin 
@_subject: M-209 for sale on EBay 
There's an M-209 for sale on EBay:
Interestingly enough, some people are blocked "for legal reasons" from getting to it.
You can (probably) see the search entry by searching for
in the EBay search window.

@_date: 2002-09-02 21:50:13
@_author: Steven M. Bellovin 
@_subject: Quantum computers inch closer?  
Last time I asked Peter Shor about it, he said that the best known quantum algorithms for exhaustive key search for classical ciphers was O(sqrt(key size)).  (To me, that's the real reason that AES needs the option for 256-bit keys...)

@_date: 2002-09-24 15:31:46
@_author: Steven M. Bellovin 
@_subject: unforgeable optical tokens?  
In message <20020921063415.6F76030752 at lion.ninthwonder.com>, eli+ at zimbs4.srv.cs
A fair number of years ago, I saw something like this proposed for non-proliferation seals on nuclear reactors.  The scheme then (I believe I saw it in Science News) was that International Atomic Engergy Agency inspectors would use a length of randomly-twisted multi-strand fiber optic cable and use it to seal a door that they opened to verify that the reactor in question wasn't being used to build weapons.  They then shine a light in one end, and photograph the other.  When they come back, the repeat the photographic process, so that they can see if anyone has removed their seal -- say, to get at the irradiated, plutonium-containing fuel rods.

@_date: 2003-12-01 14:01:34
@_author: Steven M. Bellovin 
@_subject: Problems with GPG El Gamal signing keys?  
In message <00ea01c3b840$239179a0$5900a8c0 at p1038mobile>, "Anton Stiglic" writes
This note appeared on the IETF OpenPGP mailing list.
The paper is as yet unpublished, but the author's web page with
contact info is

@_date: 2003-12-04 17:29:32
@_author: Steve Bellovin 
@_subject: Additional Proposed Hash Function (Forwarded) 
NIST is proposing a change notice for FIPS 180-2, the Secure Hash Standard that will specify an additional hash function, SHA-224, that is based on SHA-256. The change notice is available at  NIST requests comments for the change notice by January 16, 2004. Comments should be addressed to ebarker at nist.gov.

@_date: 2003-12-06 10:14:06
@_author: Steve Bellovin 
@_subject: safety of Pohlig-Hellman with a common modulus? 
Is it safe to use Pohlig-Hellman encryption with a common modulus?  That is, I want various parties to have their own exponents, but share the same prime modulus.  In my application, a chosen plaintext attack will be possible.  (I know that RSA with common modulus is not safe.)

@_date: 2003-12-06 20:05:08
@_author: Steven M. Bellovin 
@_subject: origin of SHA 224 initial hash values  
In message <80CA5A5D-2823-11D8-94A5-00039375644C at vangelderen.org>, "Jeroen C.va
You've nailed it -- that's precisely why SHA-224 is being defined, to
match 2-key 3DES.
There's another Internet draft that's likely of interest to this group:
'Determining Strengths For Public Keys Used For Exchanging Symmetric Keys '
.  The draft is in IETF Last Call until 2 January; please email any comments to iesg at ietf.org.
Wearing my IETF Security Area Director hat,

@_date: 2003-12-07 17:39:35
@_author: Steven M. Bellovin 
@_subject: yahoo to use public key technology for anti-spam  
That isn't Carl's point.  He may very well be using a trustworthy SMTP server, via a secure tunnel.  The issue is whether he has to use a server owned by the owner of his return address.  I use a variety of email addresses, for various reasons.  I have my usual work account, some university accounts, a few personal accounts, one I reserve for EBay use, etc.  I also use several different SMTP servers to send my email.  I *always* have a secure tunnel set up; in fact, Postfix on my laptop is hard-wired to send to port 20025 on 127.0.0.1.  Of course, where that ends up will vary, but it's not in a one-to-one correspondence with the sending address I use.  The Yahoo scheme would apparently require that each email I send be routed via the domain owner's SMTP server.

@_date: 2003-12-07 18:51:39
@_author: Steven M. Bellovin 
@_subject: yahoo to use public key technology for anti-spam  
I used to do that, but I had to give up -- too often, my laptop happened to be in someone's blacklist range.  Right now, for example, it's in Comcast's IP addr space, and some people regard that as a spam But we're wandering off-topic.
Btw -- I've been told that Yahoo has not yet disclosed technical details

@_date: 2003-12-14 09:26:03
@_author: Steve Bellovin 
@_subject: NEMA rotor machine offered again on ebay 
:SS:US:1 Last time such a machine appeared, some people reported that ebay blocked their access to the listing.  That included one person in the The ebay records indicate that this machine is being offered by the same
party who sold the last one (  That one went for US$ 3605.

@_date: 2003-02-03 15:28:14
@_author: Steven M. Bellovin 
@_subject: question about rsa encryption  
Transmitting a private key under RSA encryption can have subtle failure modes.  I suggest that you use a published standard such as OAEP, from PKCS

@_date: 2003-02-08 22:01:47
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
You can find Kerchhoffs' original work at  , in French and English.

@_date: 2003-02-09 23:34:01
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
Actually, that's missing the point.  Yes, the cryptanalytic attack on RC4, especially as it's used in WEP, was impressive.  But that attack was the least important problem with WEP -- the more serious problems were protocol issues.
First, there was no key management.  This means that loss of a single unit -- a stolen laptop or a disgruntled (ex-)employee would do -- compromises the entire network, since it's impossible to rekey everything at once in an organization of any size.  For most real-world deployments, this is the most serious weakness.  Furthermore, if there were real key management, the next two problems couldn't have happened.
This was clearly avoidable.
The second most serious problem was the set of problems documented by Borisov et al. at Berkeley.  These mostly relied on the inappropriate use of a stream cipher, especially with too short an "IV".  Note that if it were possible to rekey before 2^24 packets were sent under any one key, the attacks mostly wouldn't be possible.
The cryptanalytic attack did exploit an unforeseen weakness in RC4.  But the attack was a related-key attack, and it required a noticeable amount of traffic.  If rekeying had taken place, or if the "IV" were properly mixed with the seed key, there wouldn't have been a problem To be sure, Enigma was largely broken because it wasn't being used properly.  As you say, protocol issues are the leading cause of crypto holes.  (And, as you note, programming bugs account for *far* more real-world security problems.)

@_date: 2003-02-10 15:51:50
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
In message , bear writ
That's not correct.  Each packet is encrypted with a key consisting of
, where "IV" is a 24-bit counter.  It does not use a later part of the stream; each packet starts from the beginning.
Note that with a 24-bit key, plus the difficulty of changing the key, there *will* be reuse.  It's compounded because (a) everyone has the same key, so there's lots of traffic; (b) both directions use the same key; and (c) some units, when power-cycled, always start the IV at 0, making collisions in that space more likely.
Read the Borisov et al. paper for more details on all of these points and more.

@_date: 2003-02-10 18:12:13
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
I'm not sure you're right.  While 40-50% of packets are about 40 bytes
long -- see  for some
older statistics -- most *bytes* are carried by larger packets.  From that same site, about 75% of the bytes are carried by packets over 500
bytes long.
A quick awk script suggests that given that packet size distribution, the total workload to use WEP-style encryption is about double the number of bytes.  The overhead is thus substantial -- but RC4's cost per byte is quite low, so it was probably a net win.  Other studies suggest that LAN packet size distribution is somewhat different, with more large packets; that would lower the overhead.
Note that the traffic mix on the Internet has shifted since that data was collected.  Audio and video files are large, and hence will use more large packets; that again would lower the overhead.  What's unclear is to what extent wireless device traffic differs.  Given the increasing deployment of 802.11 in the home, I suspect that there's a lot of big files going to wireless endpoints.
A block cipher is clearly a better choice here.  But there were some rational reasons for selecting RC4 (even though I think that on balance, the choice was very wrong).

@_date: 2003-02-10 19:29:27
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
I reran my script assuming that the first 1024 bytes of each packet were discarded.  It triples the cost of encryption, compared to discarding nothing.
There may be a cryptographically sound reason to discard that much, but it's not without cost.

@_date: 2003-02-10 20:01:07
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
That's a good reason...  (At that point, even with older hardware, AES might be better -- and of course, using a block cipher solves lots of other problems, too...)

@_date: 2003-02-10 23:03:11
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
Of course they couldn't have used AES.  But there are other block ciphers they could have used.  They could have used key management.  They could have added a MAC.  They could have used a longer "IV" field, with a random starting point mandated by the spec.  Or they could have put a big warning on saying "this doesn't protect you from very much".

@_date: 2003-02-10 23:10:37
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
In message <5.1.0.14.2.20030211131643.02a92418 at 203.30.171.11>, Greg Rose writes
As I said, there was some rational engineering in there...
We have a set of independent messages here.  Stream ciphers are generally intended for -- well, streams.  TLS is a good example of where I think they can be used.  They also work well with asynchronous bytes with irregular arrival time, with a requirement for very low overhead (i.e., typed characters, except for the lack of error propagation and the predictable change issue).  We have here a set of discrete blocks, with no connection between them.  While I certainly agree that a MAC is necessary even with a block cipher, it's much more critical for a stream cipher, given the ability (noted by Borisov et al.) for an attacker to change bits in the destination IP address to cause the packet to be routed to a host of the attacker's choice.  Whether or not that can be done profitably with a block cipher would
depend on the cipher's block size and the packet format.
But it may, ultimately, be a matter of taste....

@_date: 2003-02-11 10:40:51
@_author: Steven M. Bellovin 
@_subject: Columbia crypto box  
The 40-bit issue is orthogonal to the other problems with WEP.  Look at IBM's Commercial Data Masking Facility (CDMF), a way to degrade the strength of DES from 56 bits to 40 bits, while still ensuring that they didn't enable any less-expensive attack.

@_date: 2003-02-21 09:17:11
@_author: Steven M. Bellovin 
@_subject: [Bodo Moeller <bodo@openssl.org>] OpenSSL Security Advisory: Timing-based attacks on SSL/TLS with CBC encryption  
I'm struck by the similarity of this attack to Matt Blaze's master key paper.  In each case, you're guessing at one position at a time, and using the response of the security system as an oracle.  What's crucial in both cases is the one-at-a-time aspect -- that's what makes the attack linear instead of exponential.

@_date: 2003-01-07 21:45:08
@_author: Steven M. Bellovin 
@_subject: DeCSS, crypto, law, and economics  
I'm 100% certain it's happening, today.  And -- dare I suggest that the industry is being farsighted in anticipating higher bandwidth, and wants to close the barn door *before* the horse's image is "stolen"?

@_date: 2003-07-08 21:24:27
@_author: Steven M. Bellovin 
@_subject: LibTomNet [v0.01]  
[Moderator's note: I've been choking back the LibTomNet argument but I
 thought Steve's specific references here are interesting, even if the
 point has already been made. --Perry]
In message <20030707230743.64482.qmail at web41109.mail.yahoo.com>, tom st denis w
What does the ACLU have to do with it?  "Be liberal in what you accept?"
Tom, I don't know you, and I don't know what your background in crypto protocol design is.  It's an *exceedingly* subtle art.
A few months ago, I went back and reread the original Needham-Schroeder paper, from December 1978.  It is, as far as I know, the first paper in the open literature on cryptographic protocols.  In it, the authors warn that they think that this is a very difficult area, and that subtle flaws will occurs.  That's one of the more amazing instances of prescience I've seen.
Let me briefly review the history of that protocol.  As I said, it was published in December, 1978.  It had symmetric and asymmetric versions of the protocol.  The latter -- taking into account certificates, which had not yet been invented -- was only three lines long.  In August 1981,
Denning and Sacco published a paper describing a comparatively subtle flaw in the protocol; they also proposed a fix.  In 1994, Abadi and Needham described a flaw in the Denning/Sacco replacement.  (That flaw might have been described in 1987, but I'm traveling and don't have my library with me...)  In 1996, a new flaw was found in the original Needham-Schroeder asymmetric variant -- a flaw that was blindingly obvious once pointed out.
Tell me -- why should anyone trust your new protocol, given the history of one of the most-studied protocols in the field?  SSLv3 has had a lot of scrutiny.  Has yours?
That's what SSL is.

@_date: 2003-07-11 17:28:03
@_author: Steve Bellovin 
@_subject: traffic analysis of phone calls? 
Slightly off-topic, but a reminder of the sort of thing that ordinary
crypto doesn't hide.
IT Myths: Colombian drugs gang's mainframe-assisted assassinations?
Did drugs barons really use multi-million pound systems to see who
was grassing to informants...?
Colombian drug running, police raids and the assassination of
informants isn't something that has an obvious link to mainframe
technology but in the first of our series investigating IT myths
this was certainly the most intriguing.
The story has it that Colombian drugs cartels in the 1990s were
using massive mainframe computer systems to analyse telephone
billing records they had 'borrowed' from phone companies to find
out which people in their cartels were on the blower to Colombian
police and US agents.

@_date: 2003-07-28 09:50:33
@_author: Steve Bellovin 
@_subject: a thesis investigating sigint sites 
Some people on this list may be interested in
(Note: I haven't read more than Chapter 1.)

@_date: 2003-06-01 12:59:53
@_author: Steven M. Bellovin 
@_subject: [spam] Re: Nullsoft's WASTE communication system  
In message , "John Brothers"
It doesn't matter if the GPL statement wasn't inserted by the real owner of the work.  Note that the employees almost certainly do not own the "work for hire" -- it would be Nullsoft/AOL Time Warner that does.

@_date: 2003-06-03 17:32:40
@_author: Steven M. Bellovin 
@_subject: Nullsoft's WASTE communication system  
The AP wire reports that the founder of Nullsoft, Justin Frankel, plans to resign in the wake of WASTE being pulled.

@_date: 2003-06-08 21:39:12
@_author: Steven M. Bellovin 
@_subject: An attack on paypal  
In message <4.2.2.20030608173129.00a99bb0 at mail.earthlink.net>, Anne & Lynn Whee
One could argue that that's because of https...
More seriously, eavesdropping on passwords was a *very* big problem starting in late 1993.  Part of the problem was that ISPs then didn't know better than to put NOC workstations on their backbone LANs; when those were compromised, the attackers had wonderfully-placed eavesdropping stations.

@_date: 2003-06-11 16:06:55
@_author: Steven M. Bellovin 
@_subject: An attack on paypal  
In message <200306111913.h5BJDPV1004648 at gungnir.fnal.gov>, "Matt Crawford" writ
You can also use *.fnal.gov

@_date: 2003-06-11 20:07:15
@_author: Steven M. Bellovin 
@_subject: An attack on paypal  
Let me point folk at for a related issue.  To put it very briefly, *real* authentication is

@_date: 2003-06-18 11:07:56
@_author: Steven M. Bellovin 
@_subject: Pre-cursor to Non-Secret Encryption  
Can you amend that to ask for digital signature information, too?  From my research on Permissive Action Links, I think there's some chance that digital signatures were invented separately, possibly by NSA before GCHQ's non-secret encryption work.

@_date: 2003-06-20 14:28:40
@_author: Steven M. Bellovin 
@_subject: authentication and ESP  
In message <20030619174940.GA18220 at diamond.madduck.net>, martin f krafft writes
The question has been asked quite often.  The short answer is that AH protects parts of the preceeding IP header, which ESP doesn't do.  I did an analysis many years ago which showed that everything in the AH header was either unprotectable, irrelevant, or protected in some other fashion.  But the question has been re-opened, notably with regard to protecting Neighbor Discover in IPv6.

@_date: 2003-06-24 22:42:43
@_author: Steven M. Bellovin 
@_subject: New toy: SSLbar  
Please don't take this personally -- I'm speaking in general terms here, rather than casting aspersions on anyone in particular.  I've
deliberately deleted any personal names from this reply, to underscore that point.
from an unknown party?  In this very specific case, why should someone download a a plug-in that by its own description is playing around in the crypto arena.  How do we know it's not going to steal keys?  Is the Mozilla API strong enough that it can't possibly do that?  Is it implemented well enough that we trust it?  (I see that in this case, the guts of the plug-in are in Javascript.  Given how often Javascript has played a starring role in assorted security flaws, that doesn't reassure me.  But I do appreciate open source.)

@_date: 2003-06-25 09:21:21
@_author: Steven M. Bellovin 
@_subject: New toy: SSLbar  
Sounds about right...
In fact, the "come and get it" method seems to exceed the "scan and 'sploit" method of building botnets.  That is, Trojans are a very active method of infection.
Botnets communicate via IRC, among many other ways.  Sometimes, they even use encrypted channels....

@_date: 2003-06-28 23:15:45
@_author: Steven M. Bellovin 
@_subject: Attacking networks using DHCP, DNS - probably kills DNSSEC  
No, that's just not true of DNSsec.  DNSsec doesn't depend on the integrity of the connection to your DNS server; rather, the RRsets are digitally signed.  In other words, it works a lot like certificates, with a trust chain going back to a magic root key.  I'm not saying that there can't be problems with that model, but compromised DNS servers (and poisoned DNS caches) are among the major threat models it was designed to deal with.  If nothing else, the existence of caching DNS servers, which are not authoritative for the information they hand out, makes a transmission-based solution pretty useless.

@_date: 2003-06-29 21:46:49
@_author: Steven M. Bellovin 
@_subject: Attacking networks using DHCP, DNS - probably kills DNSSEC  
I can pretty much guarantee that the IETF will never standardize that, except possibly in conjunction with authenticated dhcp.

@_date: 2003-03-05 14:30:54
@_author: Steven M. Bellovin 
@_subject: Wiretap Act Does Not Cover Message 'in Storage' For Short Period (was Re: BNA's Internet Law News (ILN) - 2/27/03)  
In message , "R. A. Hettinga" wr
No, that's not waht the decision means.  Access to stored messages also requires court permission.  The (U.S.) ban on wiretapping without judicial
permission is rooted in a Supreme Court decision, Katz v. United States,
389 U.S. 347 (1967) which held that a wiretap is a search which thus required a warrant.  I don't think there's ever been any doubt that seizing a stored message required a warrant.  But in an old case (OLMSTEAD v. U.S., 277 U.S. 438 (1928))
the Court had held that the Fourth Amendment only protected material things, and therefore *not* conversations monitored via a wiretap.  That decision was overturned in Katz.
The crucial difference, from a law enforcement perspective, is how hard it is to get the requisite court order.  A stored message order is relatively easy; a wiretap order is very hard.  Note that this distinction is primarily statutory, not (as far as I know) constitutional.

@_date: 2003-03-24 13:02:37
@_author: Steven M. Bellovin 
@_subject: Who's afraid of Mallory Wolf?  
Sorry, that's flat-out false.  If nothing else, there was a large-scale MITM attack on the conference 802.11 net at the 2001 Usenix Security Spammers are hijacking BGP prefixes; see for one such incident.
Eugene Kashpureff was pleaded guilty to domain-name hijacking; used
very slightly differently, that's a MITM attack.  See
 for
I warned of the possibility of hijacking via routing attacks in 1989,
and via DNS attacks in 1995.  (See the 'papers' directory on my Web
site.)  Given that the attacks were demonstrably feasible, Netscape
would have been negligent not to design for it.  Given that such attacks
or their near cousins have actually occurred, I'd say they were right.
And yes, you're probably right that no one has stolen credit card numbers
that way.  Of course, since the defense was in place before people
had an opportunity to try, one can quite plausibly argue that Netscape
prevented the attack....

@_date: 2003-03-25 22:34:09
@_author: Steven M. Bellovin 
@_subject: Who's afraid of Mallory Wolf?  
Let me quote what the (U.S.) 2nd Circuit Court of Appeals said in the
T.J. Hooper case (60 F.2d 737, 1932):
        Indeed in most cases reasonable prudence is in face common prudence;
        but strictly it is never its measure; a whole calling may have unduly lagged
        in the adoption of new and available devices.
        It may never set its own tests, however persuasive be its usages.
        Courts must in the end say what is required; there are precautions
        so imperative that even their universal disregard will not
        excuse their omission....
        them, some did not; the most that can be urged is that they had
        not yet become general.  Certainly in such a case we need not
        pause; when some have thought a device necessary, at least we may
        say that they were right, and the others too slack.
Given that there were published warnings of *practical* MITM attacks (my papers, Radia Perlman's dissertation on secure routing, Lawrence Joncheray's paper on TCP hijacking, etc.), I have no doubt whatsoever what a (U.S.) court would have ruled if there had ever been a real attack.  Given that MITM attacks have happened, I have just about as little doubt that they would have been used to steal credit card numbers if SSL had no protection.  Look at it this way -- we've already had passowrd-eavesdropping (vintage 1993), off-the-shelf TCP hijacking code (Dug Song's package), and moderate-scale hacked machines for credit card number and account number theft (Internet cafes in Japan, about a month ago -- I'm on the train, and don't have the precise citation handy.)  Given all that, do you doubt that the hackers would have combined the easily-available pieces into a MITM attack?  I don't.
The real issue in the original post seems to be the cost of a "trusted" certificate.  I submit that there are other ways to solve that problem than abandoning a very necessary protection.

@_date: 2003-03-28 18:06:26
@_author: Steven M. Bellovin 
@_subject: Run a remailer, go to jail?  
In message , James M Galvin
The question is more complicated than that.  The full text of the Texas bill is at (I haven't found the Mass. version).  It is far from clear to me that intent to commit a crime is needed.
Section 2 of the billl, which does contain the phrase "with the intent to
harm or defraud a communication service", bars theft of service.  (I'm speaking loosely here; read it for yourself.)
Section 3 and 4 also contain that phrase; they bar possession of devices
for defrauding providers.  (The language is rather broad, and seems to bar possession even a computer or modem if you have evil intent.)
The ban on concealing origin or destination is in Sections 5 and 6.
That section does *not* have the "intent to harm" phrase.  Given that the bill is amending three consecutive sections of the state penal code (31.12, 31.13, and 31.14), and given that the first two sections have that language but the third doesn't, it's hard for me to see that evil intent is required by the proposed statute.
But it's worse than that:  the bill bars concealment of "existence or place of origin or destination of any communication" from "any lawful authority".  In other words, it would appear to outlaw many forms of cryptography or steganography.
What's unclear to me is who is behind this.  Felten thinks it's content providers trying for state-level DMCA; I think it's broadband ISPs who are afraid of 802.11 hotspots.

@_date: 2003-05-05 21:27:57
@_author: Steven M. Bellovin 
@_subject: The Pure Crypto Project's Hash Function  
Except, of course, that coding in assembler is quite demonstrably more bug-prone.  And I'm not even talking about productivity (also lower) -- bugs are a major source of security holes.
As for matching the output of the compiler -- well, it's not often that I get to cite my dissertation, but that's what I worked on >20 years ago.  See  for the

@_date: 2003-05-13 11:30:31
@_author: Steven M. Bellovin 
@_subject: economics of spam (Re: A Trial Balloon to Ban Email?)  
In message <200305130152.h4D1qC1F007097 at syn.hamachi.org>, Bill Sommerfeld write
The spammers are doing that and more.  For example, recent traffic on the NANOG list suggests that they are using false BGP advertisements on stolen address blocks to shoot and run.  (There is a proposal to stop that via cryptographic authentication of BGP advertisements, but SBGP hasn't gotten any traction with most of the operator community yet.  Just why is a subject for a separate thread.)

@_date: 2003-11-17 15:58:08
@_author: Steven M. Bellovin 
@_subject: A-B-a-b encryption  
I believe that Pohlig-Hellman with the same modulus has this property, too.  But I don't recall seeing any analysis if Pohlig-Hellman modulus reuse has the same failings as RSA with modulus reuse.

@_date: 2003-11-26 15:09:54
@_author: Steven M. Bellovin 
@_subject: Open Source Embedded SSL - Export Questions  
I understand the need to conserve space; that said, I strongly urge you to consider AES as well.  If this is for embedded systems, it will live for a long time, and I expect AES to displace 3DES in the near future.

@_date: 2003-10-01 22:22:08
@_author: Steven M. Bellovin 
@_subject: anonymous DH & MITM  
What's your threat model?  Self-signed certs are no better than ADH against MITM attacks.  Until you understand your threat model, you don't
have any grounds to make that decision.
MITM is certainly possible -- I've seen it happen.  The dsniff package includes a MITM tool, as do many other packages; at the Usenix Security conference a few years ago, someone intercepted all web-bound traffic and displayed a page "All your packets are belong to us".  Anyone on the same LAN (switched or unswitched) could have done the same.  If you're not on the same LAN, a routing attack or a DNS attack could
result in the same thing, and those are happening, too, in the wild.

@_date: 2003-10-01 22:40:14
@_author: Steven M. Bellovin 
@_subject: Monoculture  
Better yet, don't use predictable IVs; the threat is much clearer.
Perry is right -- a number of us learned the hard way about cryptographic protocol complexity.  I led the fight to remove sequence numbers from the early version of ESP, since no one could elucidate a threat model beyond "the enemy could duplicate packets".  My response was "so what -- packet duplication is always possible per the IP datagram model".  (A while back, my ISP fulfilled that part of the model; I was seeing up to 90% duplicate packets.  But I digress.)  But then I wrote a paper where I showed lots of ways to attack IPsec if you didn't have both sequence numbers and integrity protection, so I led the fight to reintroduce sequence numbers, and to make integrity protection part of ESP rather than leaving it to AH.  We all learn, even in embarrassing ways.
My first published cryptographic protocol, EKE, has had an interesting history.  One version of it is still believed secure:  encrypt both halves
of a DH exchange with a shared secret.  (Ironically enough, that was
the very first variant we came up with -- I still have the notebook where I recorded it.)  We came up with lots of variations and optimizations that all looked just fine.  We were wrong...
Someone has already alluded to the Needham-Schroeder protocol.  It's instructive to review the history of it.  The original protocol was published in 1978; it was the first cryptographic protocol in the open literature.  Presciently enough, it warned that cryptographic protocol design seemed to be a very suble art.  Three years later, Denning and Sacco showed an attack on the protocol under certain assumptions; they suggested changes.  In 1994, Abadi and Needham published a paper showing a flaw in the Denning-Sacco variant.  In 1996, Lowe published a new attack on the *original* Needham-Schroeder paper.  Translated into modern terms -- the first paper was published before certificates were invented -- the faulty protocol was only three lines long!  Three lines of protocol, in the oldest paper in the literature, and it took 18 years to find the flaw...
No, we're not a guild.  To me, "guild" has connotations of exclusivity and closed membership.  Anyone can develop their own protocols, and we're quite happy -- *if* they understand what they're doing.  That means reading the literature, understand the threats, and deciding which you need to counter and which you can ignore.  In IPsec, Steve Kent -- who has far more experience with cryptographic protocols than most of us, since he has access to, shall we say, more than just the open literature -- was a strong proponent of making integrity checks option in ESP.  Why, when I just finished saying that they're important?  Integrity checks can be expensive, and in some situations the attacks just don't apply.  The trick is to understand the tradeoffs, and *to document them*.  Leave out what you want, but tell people what you've left out, why you've left it out, and under what circumstances will that change get them into trouble.

@_date: 2003-10-03 14:52:18
@_author: Steven M. Bellovin 
@_subject: anonymous DH & MITM  
You have to be careful how you apply it; sometimes, there are attacks.  See Steven M. Bellovin and Michael Merritt, "An Attack on the Interlock
Protocol When Used for Authentication," in IEEE Transactions on
Information Theory 40:1, pp. 273-275, January 1994,
 for an example of how it's a bad protocol to use to send passwords.

@_date: 2003-10-28 09:21:05
@_author: Steve Bellovin 
@_subject: NEMA rotor machine available on EBay 
============================== START ==============================
[Moderator's apologies for how late this is... --Perry]
A NEMA rotor machine -- described in the listing as "based on Enigma", but with 10 rotors -- is listed for sale on Ebay, with bids starting at US$2390.  It's item number 2199580460.

@_date: 2003-09-19 15:59:54
@_author: Steven M. Bellovin 
@_subject: Threat models (was: quantum hype ) 
Right -- this is crucial.  *What is your threat model?*  Until you know that, you don't know how to design your crypto gear.  For example, one of the prime considerations in NSA designs is to make sure that no traffic decryption key is *ever* accessible to users of the system -- that way, those keys can't be compromised, by stupidity or espionage.  Think of it as perfect forward secrecy on steroids.
Let me strongly recommend that people read "Between Silk and Cyanide", by Leo Marks.  It's a good read, but from a professional perspective what's important is what you learn about threat models.  During World War II, Marks worked on (among other things) secure communications for resistance fighters in occupied Europe.  A naive approach to the problem would be "make sure that all of the keying material is memorizable, so that there's nothing incriminating in written form".  Indeed, that was tried -- it turned out to be the wrong answer.  If the Gestapo was interested in you, you *would* disclose your key, with high probability.  It didn't matter if there was a secret distress authenticator; they'd match what you said about that to your past traffic and see what it looked like.  By contrast, a written one-time-use key that was destroyed after encryption revealed nothing, not even which variant of the key was the distress signal.  Furthermore, the printed keys were easier to use, which made for fewer garbles when encrypting and hence fewer retransmissions.  And transmissions were *very* dangerous, because of Gestapo direction finders; anything that minimized transmission time was a major In other words, what looks at first glance to be a weaker system is actually much stronger.  There's a lot more; read the book.
Returning to the original question -- quantum key distribution has certain strengths and certain weaknesses.  Do its strengths address areas where you're actually weak?  For example, is (as John points out) the real risk that someone will steal your private key or your plaintext, rather than that someone will crack RSA?  If so, QKD isn't going to help.  Even from a purely cryptographic perspective, if you're using QKD perhaps AES is the weak point, rather than RSA, in which case a more secure mechanism for distributing AES keys won't help.
We're dealing with cryptographic systems here, and enemies don't go through security, they go around it.

@_date: 2004-04-14 08:43:03
@_author: Steve Bellovin 
@_subject: AES suitable for protecting Top Secret information 
I haven't seen this mentioned on the list, so I thought I'd toss it out.  According to  ,
AES is acceptable for protecting Top Secret data.  Here's the crucial    The design and strength of all key lengths of the AES algorithm
   (i.e., 128, 192 and 256) are sufficient to protect classified
   information up to the SECRET level. TOP SECRET information will
   require use of either the 192 or 256 key lengths.

@_date: 2004-08-09 19:10:36
@_author: Steven M. Bellovin 
@_subject: Al Qaeda crypto reportedly fails the test  
That is, of course, one of the primary goals of perfect forward secrecy

@_date: 2004-07-07 12:47:36
@_author: Steven M. Bellovin 
@_subject: Question on the state of the security industry (second half not necessarily on topic)  
In message , Jason H
In all seriousness, background investigations have been outsourced...
I had a similar experience a few years ago.  I was supposed to visit the --- agency.  Someone I had *not* been dealing with called to ask for my social security number and birthdate.  I declined, on the grounds that I had no idea who he was.  "But if I'm not legitimate, how do I know you're going to visit tomorrow?"  My reply was "you're from --- and you don't think people can learn things they're not supposed
to know?"
He was livid -- "if you don't tell me, you can't visit".  I told him that that was fine with me, and he should get my usual contact to call me.  "But he's unavailable today!".  I indicated that I was still unconcerned -- and 10 minutes later, this unavailable person called On the other hand, when my broker called last week and asked for some confidential info, he was very understanding and co-operative when I declined to give out that information over the phone when he had called me.  So it's not completely hopeless.

@_date: 2004-07-09 19:26:09
@_author: Steven M. Bellovin 
@_subject: EZ Pass and the fast lane ....  
There are, in fact, toll roads that try to do that; see, for example,
But it's not foolproof; see
(the original seems to have expired, hence the reference to the Google

@_date: 2004-07-19 15:54:21
@_author: Steven M. Bellovin 
@_subject: Using crypto against Phishing, Spoofing and Spamming...  
I think that Eric is 100% correct here: it doesn't happen because it's a low-probability attack, because most sites do use SSL.
I think that people are forgetting just how serious the password capture attacks were in 1993-94.  The eavesdropping machines were on backbones of major ISPs; a *lot* of passwords were captured.  Furthermore, the technology has improved -- have you looked at dsniff lately, with the ARP-based active attack capability?  And credit cards are much easier to grab -- they're probably sent in one packet, instead of several, and the number is a self-checking string of digits.
It's also worth remembering that an SSL-like solution -- cryptographically protecting the transmission of credit card number, instead of digitally signing a funds transfer authorization linked to some account -- was more or less the only thing possible at the time.  The Internet as a medium of commerce was too new for the banks to have developed something SET-like, and there wasn't an overwhelmingly-dominant client platform at the time for which custom software could be developed.  (Remember that Windows 95 was the first version with an integral TCP/IP stack.)  *All* that Netscape could deploy was something that lived in just the browser and Web server.  SET itself failed because the incentives were never there -- consumers didn't perceive any benefit to installing funky software, and merchants weren't given much incentive to encourage it.

@_date: 2004-06-02 15:17:44
@_author: Steven M. Bellovin 
@_subject: SMTP over TLS  
This gets to the real question:  what is the threat model?  Who is trying to do things to your email, and what resources can you bring to Someone serious who's targeting you is going to go after the servers and the spool files -- it's easier, more reliable, etc.  The same is true for system administrators.
If, on the other hand, you have a habit of sending quasi-sensitive email over 802.11 nets, over-the-wire eavesdropping is indeed a real threat, though primarily on that one link.
Or perhaps you rely on links run by people you don't fully trust.  At one major U.S. hotel chain, all port 25 traffic from the in-room Ethernet jacks gets diverted to the hotel's SMTP server.  I'm not sure if they're being friendly -- "let's help people whose MUAs are hard-wired
to some firewall-protected corporate mail server" -- or if they're trying to block check-in spammers or what; I do know that I don't want my email sitting on their servers.
I personally deal with the latter two by tunneling my SMTP and POP3 over ssh to a trusted site; for the first, I use PGP for the tiny amount of email I send or receive that requires end-to-end security.
But I've happily sent my credit card number via email at times, because I don't think the threat is that serious; furthermore, given U.S. law, the consequences aren't that serious.
What's your threat model?  When we know that, we can talk about

@_date: 2004-06-03 11:53:15
@_author: Steven M. Bellovin 
@_subject: "The secret code is 00000000"  
Although I'm not a professional in the nuclear weapons field, I have done a fair amount of research on the subject of PALs (Permissive Action Links); you can find a summary of my results at
  I'll be updating the page soon, to add more information I've received via FOIA and from published papers I've seen more recently, but none of the updates will change any of the discussion below.  (The parent directory of my Web page discusses the possible relationship of PALs to the history of public key cryptography.)
The first thing to realize is that Blair's short note, on the 00000000 launch code, confuses PALs with "use control systems".  A PAL is integral to the weapon itself; a use control system regulates the launch vehicle.  This is important because PALs are within the security perimeter -- the tamper-resistant barrier -- of the bomb; if a bomb were detached from a missile, the missile couldn't be launched without bypassing the use control system, but the bomb could be detonated if other safety mechanisms were bypassed.  These safety mechanisms are designed to reflect "human intent" and proper environmental conditions -- a missile-launched bomb, for example, should experience a period of high acceleration, then free fall, then decelaration and heat.  But the inputs from these sources are outside the barrier, and hence could presumably be spoofed.  For various reasons, I do not think these signals are cryptographically protected, though I've seen some indications (not yet on the Web page) that the human intent signal might be.  (I should note that Blair is very well respected in this field; I cite one of his books in my bibliography.  I'm frankly a bit puzzled by his note.)
The second critical point about PALs is that they were *not* intended to guard against what I'll call the "Dr. Strangelove scenario".  While there certainly was tension between parts of the military and the civilian authorities -- Curtis LeMay did his best to provoke World War III, and his successor as the head of the Strategic Air Command, Thomas Power, was described as worrisomely unstable by his own colleagues -- preventing such misbehavior was not the primary goal of PALs.  If nothing else, President Kennedy never could have sold the idea to Congress under those circumstances.  Instead, the problem was to retain U.S. control of nuclear weapons that were physically in the hands of our allies; furthermore, there was a desire to permit forward deployment of tactical nukes in West Germany, in positions that were at high risk of being overrun in the early stages of a Warsaw Pact invasion.  The former was politically vital: not only was Congress concerned about our allies (France was seen as politically unstable; one of their own nominal nuclear tests was, in fact, scuttling a bomb before the rogue generals in the Algerian campaign could get hold of it), but German access to nuclear weapons was *extremely* threatening to the Soviets.  (Think of Tom Lehrer's line in "MLF Lullaby":
and recall that this was less than 20 years after the end of World War II.)
The Pentagon, on the other hand, was attracted by the forward deployment feature.  It was geographically obvious that the West German frontier was indefensible against a massive armored invasion from the east, but it was politically impossible to state that or to act as if the real plan was to fall back to the Fulda Gap.  The only solution seen was tactical nuclear weapons (which gave us such charming things as nuclear artillery shells and backpack-carried nuclear land mines).  But these had to be deployed with the forward units, which might easily be overrun.  Worse yet, a junior officer might use a nuke without authorization, out of desperation.  PALs solved that problem, too -- the devices couldn't be used without the unlock codes, either by our forces or by the Soviets.
To sum up (this note is already far too long; see my web page for details and bibliographic citations), the threat that PALs were intended to deal with was physical capture of the devices; it had nothing to do with our own launch officers.  The Pentagon was very worried about PAL or procedural malfunctions preventing use of nuclear weapons (command and control of the military during a nuclear war --
including ending the war! -- is a subject that has received a great
deal of study; there's a vast literature on it); given that, I'm not particularly surprised by the 00000000 code.  Blair's 1977 article on the physical risk to our missile silos illustrated that there was a capture risk to them, too; official reaction was apparently swift and (at least partially) appropriate.  Blair got it right; the Pentagon had been wrong.

@_date: 2004-06-14 17:10:48
@_author: Steven M. Bellovin 
@_subject: Is finding security holes a good idea?  
Or rather, that the patch process introduces new bugs.  Let me quote from Fred Brooks' "Mythical Man-Month", Chapter 11:
Etc.  In other words, though the original code may not have had an
infinite number of bugs, the code over time will produce an infinite

@_date: 2004-06-28 09:24:46
@_author: Steve Bellovin 
@_subject: Swiss NEMA rotor machine for sale on EBay 
I'm sure we'll see the usual complaints about people being unable to view it...

@_date: 2004-05-11 11:36:35
@_author: Steven M. Bellovin 
@_subject: The future of security  
And rightly so, since most security problems have nothing to do with the absence of crypto.
This ties into the same thing:  spam is *unwanted* email, but it's not *unauthorized*.  Crypto can help with the latter, but only if you can define who is in the authorized set of senders.  That's not feasible for most people.

@_date: 2004-05-25 11:01:23
@_author: Steve Bellovin 
@_subject: CAs for spies? 
Have you ever wondered what CA a spy agency would trust?  In the case of the Mossad, it's Thawte.
Go to and click "Contact Us" or "Application Form".  You'll get an SSL-protected connection, with a 1024-bit RSA key (with MD5) in a certificate issued by Thawte.  The connection itself used 256-bit AES.

@_date: 2004-05-26 11:59:16
@_author: Steven M. Bellovin 
@_subject: The future of security  
The spammers are playing with other people's money, cycles, etc.  They don't care.

@_date: 2004-05-26 17:33:36
@_author: Steven M. Bellovin 
@_subject: The future of security  
We're saying something different.  If I understood your paper correctly, it says, more or less, that setting the cost high enough to reduce spam will make the cost too high for legitimate users.  My point is that even if you do raise the cost high enough, they'll become more aggressive at "0wning" machine so that they can throw more (stolen) cylces or (stolen) zorkmids at the problem.  The economic question, then, is what is the cost of compromising enough new machines.  Given the code base and the user behavior that we see in the field, my answer is "pretty low".  The consequence, in your metric, would be an increase in C, which would further inconvenience legitimate users, thus creating a feedback loop.

@_date: 2004-11-17 17:23:20
@_author: Steve Bellovin 
@_subject: "numbers" stations 
Shortwave radio bands, ignored by commercial broadcasters because of their low fidelity, have long been home to government activity -- whether for national broadcasts such as the BBC World Service, Voice of America and Radio France International, or propaganda broadcasts from the likes of Radio Havana or the U.S.-backed Radio Free Iraq.
Meanwhile, for the last 30 years an altogether more curious kind of international station has been noted on the airwaves. Across the world, high-powered transmitters with global reach are broadcasting seemingly meaningless strings of numbers or letters, along with a lot of buzzing and beeping noises.
Some have speculated that the signals from these "numbers stations" are operated by drug cartels. However, it's more likely they're run by intelligence agencies, as tacitly acknowledged by the British government, and accidentally by the Cubans.

@_date: 2004-11-30 23:36:00
@_author: Steven M. Bellovin 
@_subject: SSL/TLS passive sniffing  
============================== START ==============================
In message <200412010322.iB13MTt1027228 at taverner.CS.Berkeley.EDU>, David Wagner
There are products out there that use their own CA certificate to create new certificates for any end point you try to connect to.  If the user accepts the certificate of an unknown CA -- or, in some cases, if the organization has preconfigured user systems to trust the firewall CA, which I've also seen -- there's a simple MITM attack.

@_date: 2004-10-20 10:54:49
@_author: Steve Bellovin 
@_subject: lack of WW II cryptanalytic co-operation between the US and UK? 
Some recently declassified British documents show that the British
and the Americans did not co-operate as closely on cryptanalytic
matters as is generally thought.  See  for details.
I'd really like to see the full text of Turing's report; does anyone
know if it's online?

@_date: 2004-09-07 23:12:03
@_author: Steve Bellovin 
@_subject: references on traffic analysis? 
What are some of the classic, must-read, references on traffic analysis?
(I'm familiar with the Zendian problem, of course.)

@_date: 2004-09-17 20:41:56
@_author: Steven M. Bellovin 
@_subject: [anonsec] Re: potential new IETF WG on anonymous IPSec (fwd from hal@finney.org) (fwd from touch@ISI.EDU)  
For RFCs, there are two paths.  If the topic is general enough (and, of course, the advice is good enough), Russ Housley or I would consider sponsoring the document as a BCP.  If it's narrow or we're not interested for some reason (other than quality, of course), it could be an individual submission.  I encourage both paths.

@_date: 2004-09-30 12:25:20
@_author: Steven M. Bellovin 
@_subject: IBM's original S-Boxes for DES?  
In message <1096535230.415bccbe98ef6 at webmail1.ec.auckland.ac.nz>, Nicolai Moles
It was only to protect against differential cryptanalysis; they did not know about linear cryptanalysis.  See Don Coppersmith, The Data Encryption
Standard (DES) and its strength against attacks, IBM Journal of Research
and Development, Vol. 38, n. 3, pp. 243-250, May 1994.
