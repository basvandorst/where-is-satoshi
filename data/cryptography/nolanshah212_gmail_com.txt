
@_date: 2017-06-19 12:33:59
@_author: Nolan Shah 
@_subject: [Cryptography] Trustworthiness 
Blockchains can be thought of as a way of building trust in trustless
systems w.r.t. cooperation (in particular, the consensus algorithm). But it
really depends on the situation and whether you consider a consensus to be
That said, I don't consider blockchains practical for a lot of scenarios
(yet). Obviously for e-cash, there is Bitcoin and for e-contracts, there is
Ethereum. But for more concrete and complex use cases (e.g., shared
economy, IoT) it will take some more research/innovation to build good
decentralized systems.
Nolan Shah

@_date: 2019-01-14 15:23:52
@_author: Nolan Shah 
@_subject: [Cryptography] pseudo-homomorphic encryption ?? 
Deep neural network (specifically CNN) classifiers are the go-to ML
technique in the context of image classification. Maybe there is a
less complex algorithm, but it will be at the expense of capability
and elegance. For instance, SVMs do work for image classification when
combined with feature extraction techniques [1]. But how do we extract
topological features from an image in HE? I have no idea. If your
image is small enough, then the pixels could suffice as features, and
*maybe* this would work without much issue.
Ignoring the omnipresent computational difficulties for a moment,
there are lots of questions to be answered at the intersection of HE
(homomorphic encryption) and deep neural networks: How do we perform
functions like softmax, tanh, relu (introduces nonlinearity) over HE?
What is the performance of SGD or other optimization methods? How does
HE introduced variance affect the model in practice? Are the biases
fundamentally different between non-HE and HE models? Could there be
new/special neural structures that work well specifically over HE?
We could perhaps find some features/structure in the encrypted images,
but traditionally the features are very characteristic of qualities
inherent in the image (i.e. early layers would identify low level
features like edges, later layers would identify some kind of abstract
features [2]). Without that in the encrypted space, no model would
perform well, but perhaps the encrypted space has a parallel set of
features that could be learned. I am unsure if homomorphic encryption
could potentially guarantee the preservation of spatial (or temporal
or abstract) patterns even with a restricted set of operations -- I'll
leave this question to the people more knowledgeable than myself.
One thing to note is the potential for information leakage by way of
learned features within the intermediate layers of a ML model if our
dataset is encrypted and our classifications are not. Perhaps there is
some method of interpolation between unencrypted data based models and
encrypted data based models or some form of extrapolation based on
Yosinski2015 [2].
There is a great paper by Microsoft and Princeton from 2016 that is
worth a read. Their model is a really great adaptation of deep neural
network methods into one suitable for homomorphic encryption:
[1] Decent discussion on SVMs for IC:
[2]
