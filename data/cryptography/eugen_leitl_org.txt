
@_date: 2002-08-10 12:15:43
@_author: Eugen Leitl 
@_subject: adding noise blob to data before signing 
1) What's the name of the technique of salting/padding an small integer    I'm signing with random data?
2) If I'm signing above short (~1 kBit) sequences, can I sign them    directly, or am I supposed to hash them first? (i.e. does a presence
   of an essentially fixed field weaken the signature)

@_date: 2002-08-22 20:57:44
@_author: Eugen Leitl 
@_subject: New Palladium FAQ available 
Fat chance. For some strange reason you must have missed that no one
trusts a single sentence coming from Redmond, rightfully suspecting it has
been cleared by if not originated in the local Ministry for Propaganda and
We knew which party line you're relaying, but you shouldn't come on so
heavy. Godwin this, Godwin that, in this particular set of forums you'd
really have a far easier time channelling Dr. Goebbels.

@_date: 2002-12-02 19:19:17
@_author: Eugen Leitl 
@_subject: [mnet-devel] Ditching crypto++ for pycrypto (fwd) 
Reply-To: mnet-devel at lists.sourceforge.net
I have to admit that Crypto++'s build/port problems suck, a lot.  I still have a weird fondness for it (Stockholm Syndrome?).
One feature is that Crypto++ is going to be adopted by the OSAF, which means it will be supported even better than it is now (including new Python wrappers), and might also mean that OSAF would throw money at someone who maintained good Python wrappers for them.
Requirements for backwards compatibility with v0.6:
 * DES-X, CTS mode (Hal Finney has contributed a patch that will implement this    on OpenSSL)
 * RSA, OAEP (we have OAEP, or something much like it, implemented in Python)
 ?
Things I want in the future:
 * Rijndael
 * CBC mode
 * SHA-1 (provided in Python Standard Library, of course, but using the crypto    libraries version might be faster due to closer binding to other crypto    computations)
 * SHA-512
 * Rizzo's forward erasure code (Wei Dai has said he would consider integrating    it with Crypto++ and supporting it, but again it doesn't *need* to be part of    the crypto library)
 * integration with system random pools
This SF.net email is sponsored by: Get the new Palm Tungsten T handheld. Power & Color in a compact size! mnet-devel mailing list
mnet-devel at lists.sourceforge.net

@_date: 2002-12-06 06:21:07
@_author: Eugen Leitl 
@_subject: Help! (fwd) 
I need access to a big fast machine ASAP, to count points on a
humongous elliptic curve.  That requires running a process that takes
about 8 GB of memory (it can be partly swap space - the program is
written to run well in virtual memory).  I have't figured out how to
parallelize the algorithm at all and it needs a few days of CPU on a
fast 64-bit machine.  Best of all is something like a 1 GHz Alpha or
Itanium 2 (preferably with a friendly sysadmin to increase per-process
resource limits :)
If any FoRKer can think of a way of getting access, please make it
happen and spend some karma points if necessary!
Many thanks in advance to those who can be of assistance,
  Rob.
     .-.                                                               .-.
    /   \           .-.                                 .-.           /   \
   /     \         /   \       .-.     _     .-.       /   \         /     \
  /       \       /     \     /   \   / \   /   \     /     \       /       \
 /         \     /       \   /     `-'   `-'     \   /       \     /         \
            \   /         `-'                     `-'         \   /
             `-'                                               `-'

@_date: 2002-12-10 14:48:54
@_author: Eugen Leitl 
@_subject: Research signals safer smart cards 
Research signals safer smart cards
By ComputerWire
Posted: 09/12/2002 at 22:49 GMT
Cryptography Research Inc, the company behind the design of the SSL v3.0 protocol that is used to secure transactions on the world wide web, claims to have discovered a new class of attacks that could be used by hackers to extract secret keys and information from smart cards and secure cryptographic tokens. Known as Differential Power Analysis (DPA), the San Francisco, California-based company says it could be a serious issue affecting smart cards and many other supposedly tamper-resistant hardware devices. DPA is said to exploit characteristic behaviors of transistor logic gates and software running on many of today's smart cards. DPA eavesdrops on the fluctuating electrical power consumption of the microprocessors at the heart of these devices. An attack is performed by monitoring electrical activity and then applying statistical methods to determine secret information, such as secret keys and user PINs that are held on the device. Current generation smart cards are said to be especially vulnerable because of their small size and minimal shielding. Although DPA attacks require a high level of technical skill in several fields to implement, they can be performed using a few thousand dollars of standard equipment. CRI maintains that once perfected, the technique can be used to break a device in a few hours or less. DPA attacks can then be automated. Unsurprisingly, the company claims to be one step ahead with a workstation system that will defend against this new class of attacks by testing power-related security vulnerabilities. Cryptography Research provides a variety of design and research services to Visa International, Mondex, Netscape, Microsoft and Intuit. The market for smart cards surged in the six months ending June 2002, with shipments to the US and Canada exceeding 31 million cards, more than double that for the year-ago period.

@_date: 2002-07-22 17:31:07
@_author: Eugen Leitl 
@_subject: "Freedom Corps" vs. Software Security? 
Wrong question. The right (albeit rhetorical) question: can closed source
software, regardless of its point of origin, be trusted, at least in
The answer for most people should be: no.

@_date: 2002-07-23 08:39:24
@_author: Eugen Leitl 
@_subject: building a true RNG (was: Quantum Computing ...) 
I've got a framegrabber with a 640x480 24 bit/pixel camera. It doesn't compress, is rather noisy, and since self-adjusting I get the maximum entropy at maximum darkness.
Is there any point in compressing the video before running it through a cryptohash? How does e.g. SHA-1 fare with very sparse bitvectors?

@_date: 2002-07-24 19:17:12
@_author: Eugen Leitl 
@_subject: building a true RNG 
I haven't tried this, but assuming I'm digitizing dark video and only get
noise in the lower significant bits I can just mask out the constant
(zero) ones and paste them together to destill the entropy with a very low computational cost before feeding it into a cryptohash.
As an aside to what constitutes physical entropy of a system it is indeed depending on context of the measurement. A good source of information on entropy in all contexts is

@_date: 2002-06-01 12:57:33
@_author: Eugen Leitl 
@_subject: the anvil problem 
Switch to open standars, e.g.  hopefully, way Don't people ever get tired of screening the EULAs for the firstborn
clause, hacking in product keys (which get longer and longer), programs
and operating systems bristling with snoopware, and goverment-mandated

@_date: 2002-05-13 22:32:52
@_author: Eugen Leitl 
@_subject: objectivity and factoring analysis 
Moore's law is about integration density. That has zero to do with
problem-specific system performance. That one is indeed lagging.

@_date: 2003-03-14 06:26:04
@_author: Eugen Leitl 
@_subject: Microsoft: Palladium will not limit what you can run 
Unfortunately no one can accept in good faith a single word coming out of
Redmond. Biddle has been denying Pd can be used for DRM in presentation
(xref Lucky Green subsequent patent claims to call the bluff), however in
recent (of this week) Focus interview Gates explicitly stated it does.  This is merely a most recent lie in a long sequence of it. Operating from
behind an anonymous remailer doesn't quite have the same handicap as
having microsoft.com as part of your email address, but the heavy
spinmeistering does reveal the origin as reliably. You can use your real emal address next time.
Let's see, we have an ubiquitous built-in DRM infrastructure, developed
under great expense and deployed under costs in an industry turning over
every cent twice, and no-one is going to use it ("Palladium will limit
what programs people can run")?
Right. It's all completely voluntary. There will be no attempts whatsoever to lock-in, despite decades of attempts and considerable economic interests involved.

@_date: 2003-03-15 11:12:36
@_author: Eugen Leitl 
@_subject: Microsoft: Palladium will not limit what you can run 
Of course it's useful. Does the usefulness outweigh the support for special interests (DRM, governments, software monopolies)? There is no value for the end user which can't be achieved with smart cards, which have the additional potential of being removable and transportable.
No, I meant it's a nonnegligible incremental cost on the system. It
increases the chipcount and/or the design complexity, and requires strong
encryption on interchip and intercomponent bus traffic. I don't know what
the increased cost on a motherboard is, but it's probably in the dollar
range at least.  Very nonegligible for an industry learned caution by low
profit margins. There's clearly a long-term political motivation present.
I notice that the technology is primarily rolled out in high-margin areas
first like notbooks (and in game consoles where considerable front
investments need to be protected).
This is a gross misrepresentation. Content (whether executable code or
media, it doesn't really matter as the difference is blurring) can be
keyed to individual machines. This kills copying. There's an intense
battle going on between open science proponents and the likes of Elsevier.
Distribution range of documents can be limited. Access to documents can be
limited to specific time window. Secrets inserted at manufacture time ask
for legislation demanding subpoenable records. Hardware can be made which
prefers a specific vendor by selective disclosure of information.
Capability for strong authentication asks for legislation making it
nonfacultative, basically outlawing anonymity. Etc. etc. There are many way by which this envelope of technologies here informally
called Pd will limit dissemination of information and increase control on
side of governments and large companies. Above off-the-cuff list indicates it's a giant, yet untapped can of worms.
Unlike subsidized smartcard readers to initial fax effect the user can
only lose.
This is an intensely political technology, and as such ignoring the political component by just focusing on fair and useful side of it will result in a very skewed estimate of its future impacts. It doesn't pay to be naive.
Under the circumstances, it is much better to just block it.

@_date: 2003-03-16 12:39:03
@_author: Eugen Leitl 
@_subject: Face-Recognition Technology Improves 
I notice the systems mentioned in the study rely on biometrics extracted
from flat images. Recent crop of systems actually scan the face geometry
by using patterned light (apparently, cheaper than using a laser scanner),
resulting in a much richer and standartized (lighting and facial
orientation is irrelevant) biometric fingerprint.
There's a world of difference between a line of people each slowly
stepping through the gate past a sensor in roughly aligned orientation and
a fixed-orientation no-zoom low-resolution camera looking at a group of
freely behaving subjects at varying illumination.
Even with basically single-source nonintegrative biometrics one could do a
lot with hi-res camera with zoom actively tracking a single person at a
time, using a NIR (skin is far more transparent to IR, resulting in a far
richer pigmentation pattern fingerprint to be acquired) for illumination.
Then there's gait, a physical body model, etc. Shortwave SAR (SAR for THz
wavelenths seems to be doable according to recent publications), so
reading body geometry would appear possible.
Volatile MHC fragment chemosensors are being developed, a hi-tech variant of Stasi's approach with odor samples and canines. (Calibrated sensors, no need for sensor to be exponsed to the scent before, bit vectors never grow stale).
By using multichannel, integrative approaches and more sophisticated DSP the error rate can be eventually brought down arbitrarily low, and simultaneously become increasingly hard to falsify.
The costs will come down eventually for such integrative telebiometrics systems realtime connected via wireless to be blanket deployable. Unlike a mobile telephone, you can't switch your body off, or leave it at
It will be interesting to see what will happen politically once the majority of voters will realize they're living in a strictly unilateral version of Brinworld.

@_date: 2003-03-16 20:44:47
@_author: Eugen Leitl 
@_subject: Face-Recognition Technology Improves 
I think the security-crazed data gatherers would just want to scan
biometrics of every single person passing through the metal detector
gates, check them against the list of usual suspects, and insert them in
realtime into a central database. Where they will remain, for indefinite
time, free for any authorized party to do data mining on.
Unless explict laws have been passed preventing this very eventuality, and the systems are actually audited that no data is retained beyond what is necessary for processing.

@_date: 2003-03-22 09:51:22
@_author: Eugen Leitl 
@_subject: Brumley & Boneh timing attack on OpenSSL (fwd) 
Some clarification by Peter Gutmann  on why cryptlib doesn't do timing attack resistance default:
Peter Gutmann :
cryptlib was never intended to be a high-performance SSL server (the docs are
fairly clear on this), and I don't think anyone is using it to replace Apache
or IIS.  OTOH it is used in a number of specialised environments such as closed
environments, embedded systems and mainframes.  For example two real-world uses
of the cryptlib SSL server are in embedded environment A and mainframe
environment B.
  In A, the processing is handled by a low-power embedded processor.  It takes
  10-15s to perform an SSL handshake, and that's after the code has been
  optimised to death to squeeze every possible bit of performance out of it.
  Performing the necessary 1.5M queries at 15s each would take approximately 8
  1/2 months at 100% CPU load (meaning that the device is unable to perform any
  other operations in that entire time).  This is unlikely to go unnoticed,
  given that it's polled from other devices for status updates.
  In B, CPU resources are so scarce that the implementation uses null cipher
  suites because it can't afford the overhead of even RC4 for encryption
  (admittedly this required a custom code hack, cryptlib doesn't normally
  support null encryption suites).  After about 100 or so attempts at a full
  SSL handshake, klaxons would sound and blue-suited troops would deploy onto
  the raised flooring to determine where all the CPU time is going.
In neither of these environments (and various similar ones) would a side-
channel attack requiring 1M or so queries (e.g. this one, or the Bleichenbacher
attack, or the Klima-Pokorny-Rosa attack, which cryptlib shouldn't be
vulnerable to since I'm paranoid about error reporting) be terribly feasible.
OTOH blinding does produce a noticeable slowdown for a process that's already
regarded by its users as unacceptably slow and/or CPU-intensive (I have some
users who've hacked the key-exchange process to use fixed shared keys because
they just can't spare the CPU time to do a real handshake, e.g. by injecting
the shared key into the SSL session cache so you just do a pseudo-resume for
each new connection).  For this reason, cryptlib makes the use of sidechannel-
attack-protection an optional item, which must be selected by the user (via use
of the blinding code, now admittedly I should probably make this a bit easier
to do in future releases than having to hack the source :-).  This is not to
downplay the seriousness of the attack, merely to say that in some cases the
slowdown/CPU consumption vs.attack risk doesn't make it worthwhile to defend

@_date: 2003-03-31 20:16:46
@_author: Eugen Leitl 
@_subject: Russia Intercepts US Military Communications? 
Trivial ones are voice radio. Nontrivially to encrypt (mil people tend to
be conservative), unlike teletype (I've used NEMP-proof perforated tape,
teletypes and electromechanical rotor crypto keyed by a wire plug box in
1988's Bundeswehr).
While there's no doubt comm is being intercepted the  main analyst (forgot his name) is purported to be not very credible.

@_date: 2003-11-14 11:52:52
@_author: Eugen Leitl 
@_subject: XML-proof UIDs 
Does anyone have robust code to generate globally unique IDs which won't break XML parsing,
and work on several platforms?
I was thinking of using an entropy pool to seed a cryptographic PRNG, used to
generate a sequence of SHA-1 hashes, dumped to an XML-armored representation.

@_date: 2004-08-28 08:29:40
@_author: Eugen Leitl 
@_subject: [Muscle] [PATCH] MuscleCard engine for OpenSSL (fwd from mgold@cbnco.com) 
Reply-To: mgold at scs.carleton.ca, MUSCLE I've created a patch to add a MuscleCard engine to OpenSSL 0.9.7d,
allowing it to access smart cards using the MuscleCard API. It is
located at:
    This engine implements RSA encryption (signing) and decryption using a
private key stored on a MuscleCard-compatible smart card. It has been
tested with a Cyberflex e-gate 32K Java Card running MUSCLE's
CardEdgeApplet (using the MCardPlugin service for PCSC Lite).
Usage example
This command will use the MuscleCard engine to create a self-signed
openssl req -new -text -sha1 -x509 \
        -engine musclecard -keyform engine \
        -key "E-Gate 00 00:0:1:1111:/var/ssl/cflex_pub.key" \
        -out cacert.pem
The meaning of the key string is as follows:
  Use PCSC Lite reader "E-Gate 00 00"
  Private key 0
  Authenticate with PIN  value "1111"
  Public key is stored in /var/ssl/cflex_pub.key (to export public
    key 1 using muscleTool: "exportkey 1 /var/ssl/cflex_pub.key")
- Michael
Muscle mailing list
Muscle at lists.musclecard.com

@_date: 2004-07-12 07:14:18
@_author: Eugen Leitl 
@_subject: EZ Pass and the fast lane .... 
While Toll Collect (the german system) isn't yet operational, the license
plate realtime OCR part is. It does read license plates in realtime via video
from overhead bridges, no slowing down necessary.
The police is very interested to keep that part of the infrastructure
operational, for obvious reasons. Currently, all non-truck license plates are
discarded, but it's clear enough theres demand for realtime tracing of select
and movement profiles for the masses, for data mining.

@_date: 2004-06-01 21:30:23
@_author: Eugen Leitl 
@_subject: The future of security 
You got fooled by the present tense. If there was such an architecture, I
wouldn't have written that message. The distributed tamper-proof
cryptographic p2p store should have been a dead giveaway.
No, of course. See above.
The web of trust sure fails, dunno about machine-moderated. There's no such animal yet.
If you don't have their key, you can't pretend to sign the spambots'. If you
sign the spambots', you burn whatever little prestige you have happened to
start out with, and drained the mana of whatever hapless warm body signed
your keys.
Web of trust is useless, if Johnny User is supposed to do the checking.

@_date: 2004-06-03 18:13:04
@_author: Eugen Leitl 
@_subject: Article on passwords in Wired News 
Customers hate PINs/TANs (have to carry then around, PINs typically are not
alphanumeric, and fixed-length, print is low-contrast). Which is why power users have a (Windows-only, for some reason couldn't get GNUcash working, despite right crypto libraries and proper port punched through firewall) HBCI software alternatives. Which are not used widely, alas.
Banks tried to push smart cards, but very half-heartedly (didn't offer free
readers, which could have created critical mass). Now some folks are trying
to use existing smartcard-authenticated mobile phone infrastructure for
online payments, but it has its own problems (Bluetooth/IrDa, security, fax
effect, etc).

@_date: 2004-06-16 14:27:46
@_author: Eugen Leitl 
@_subject: Interview with Glenn Henry, founder of VIA processor subsidiary Centaur (fwd from eugen@leitl.org) 
The third one, is one you haven't asked me about, this is actually my pet
hobby, here -- we've added these fully sophisticated and very powerful
security instructions into the...
Q19: That was my last question!
A19: So the classic question is, hey, you built some hardware, who's going to
use it? Well, the answer is, six months after we first started shipping our
product with encryption in it [story], we have three or four operating
systems, including Linux, OpenBSD, and FreeBSD, directly supporting our
security features in the kernel.
Getting support that quickly can't happen in the Microsoft world. Maybe
they'll support it someday, maybe they won't. Quite honestly, if you want to
build it, and hope that someone will come, you've got to count on something
like the free software world. Free software makes it very easy for people to
add functionality. You've got extremely talented, motivated people in the
free software world who, if they think it's right to do it, will do it. That
was my strategy with security.
We didn't have to justify it, because it's my hobby, so we did it. But, it
would have been hard to justify these new hardware things without a software
plan. My theory was simple: if we do it, and we do it right, it will appeal
to the really knowledgeable security guys, most of whom live in the free
software world. And those guys, if they like it, and see it's right, then
they will support it. And they have the wherewithal to support it, because of
the way open software works.
So those are my three themes, ignoring the fourth one, that's obvious: that
without competition, Windows would cost even more. To summarize, for our
business, [Linux is] important because it allows us to build lower-cost PC
platforms, it allows people to build new, more sophisticated embedded
applications easier, and it allows us, without any software costs, to add new
features that we think are important to the world.
Our next processor -- I haven't ever told anyone, so I won't say what it is

@_date: 2004-05-28 21:07:26
@_author: Eugen Leitl 
@_subject: The future of security 
If I'm a node in a web of trust (FOAF is a human), prestige will percolate through it completely. That way I can color a whole domain with a
nonboolean trust hue, while a domain of fakers will have only very few
connections (through compromises, or human mistakes), which will rapidly sealed,
once actually used to do something to lower their prestige ("I signed the key
of a spammer, please kill me now"). Of course, tracking prestige globally, robustly in a p2p fashion is
difficult, and will require agoric load levelling elements (to prevent bad
nodes from DoSing the global store) which also requires prestige tracking.

@_date: 2004-05-28 21:22:07
@_author: Eugen Leitl 
@_subject: Satellite eavesdropping of 802.11b traffic 
If you want to fly a LEO constellation of them, you need a very sparse structure (or
a huge density of pongsats, which doesn't agree with observations).

@_date: 2004-05-31 09:25:14
@_author: Eugen Leitl 
@_subject: The future of security 
Sending mail originating with a person always requires human action.
If one cannot be bothered to mark friends in his addressbook as humans (in
fact, the very act of adding someone to an addressbook is sufficient, that
information just needs to be processed).
Do spammers have many friends? They certainly network.
The point of an automated web of trust is that the machine is doing the
accounting for you.
Human network connectivity have such properties. The entire graph is
connected, and each person is reachable via a few hops. Given that there are
only a few billion people on this planet, such a database should be quite
easy to store and to query in a P2P fashion. It only becomes nontrivial when
it has to distributed, and immune to content forgery and DoS.
The real issue is whether people can volunteer information stored in their
addressbook. Not everybody is an Orkut/Friendster/FOAF exhibitionist.

@_date: 2004-11-08 15:03:54
@_author: Eugen Leitl 
@_subject: RC4 optimized for AMD64 (+130% speedup) (fwd from bevand_m@epita.fr) 
Reply-To: openssl-dev at openssl.org
I have published a paper about optimizing RC4 for AMD64. A working
implementation, designed to be easily integrated into OpenSSL, is
also provided:
  I would love seeing this integrated into OpenSSL.

@_date: 2004-11-17 10:22:49
@_author: Eugen Leitl 
@_subject: OCF port to linux (fwd from davidm@snapgear.com) 
Hi all,
Just thought I drop a line to see if anyone is interested in a linux
port of the FreeBSD(OpenBSD) Open Cryptographic Framework (OCF) ?
I needed user crypto acceleration under 2.4 in a hurry and Evgeniy
Polyakov hadn't quite posted his work at the time,  so I ported the
full OCF framework.  The userland API is 100% BSD compatible,  thus
reducing the work I needed to do with openssl/ssh.
I have read all the posts to the list on Evgeniy's work and also Michal
Ludvig's /dev/crypto work.   I understand that this probably isn't the
format/license/API that people would like,  but it is working and can
used for comparison if nothing else :-).  If anyone would like to play
with it I can put together a patch for 2.4 or 2.6.  The patch would be
about 70k.
I have a software OCF driver (using the crypto API in the kernel), a
safenet driver and an Xscale CryptACC driver.  I should get time to
port the hifn driver in the next day or so.
Anyway,  everyone wants to see the numbers,  they are included below.
Of course there are still a few bugs to work out :-)  The results do
show the trends in trade offs between user/kernel assisted crypto
though,  the most obvious is that for small packets user crypto is better,
Early OCF test results
Here is the result of some tests run on OCF under linux.  The platform was a
533MHz Intel Xscale IXP425 platform (ARM big endian).  The board has a
safenet 1141 on the PCI bus and also the IXP has a built in crypto engine.
The following tests were done using the following commands.
    openssl speed -evp des -elapsed
    openssl speed -evp des3 -elapsed
"-engine cryptodev" was added to the command when OCF acceleration was desired.
The OCF modules used are:
    none            - completely user mode software crypto
    soft            - using crypto framework with software crypto engine
    safe            - using crypto framework with safenet crypto engine
    ixp             - using crypto framework with IXP crypto engine
I dropped the max packet size down to 2048 bytes,  8192 seems a little
unrealistic.  Needless to say,  the HW crypto is even further ahead with
bigger buffers to work on.
cipher       mod.   16 bytes     64 bytes    256 bytes   1024 bytes   2048 bytes

@_date: 2004-10-23 22:41:55
@_author: Eugen Leitl 
@_subject: Financial identity is *dangerous*? (was re: Fake companies, real money) 
No, that's going to be the mobile phone. These already come with smartcards;
unfortunately their security is really lousy, so a secure pathway into the
secure crypto compartment for PIN entry is required.
In practice, no one is going to give a damn, until PIN-harvesting Bluetooth &
Co worms will result in palpable loss for the institutions.

@_date: 2004-10-24 07:24:12
@_author: Eugen Leitl 
@_subject: VIA PadLock reloaded (fwd from michal@logix.cz) 
Just in case you have already looked there - few minutes ago I have
added a new section with IPsec benchmark. Rough results:
Plaintext throughput: 11.21 MB/s
IPsec (ESP/transport) without HMAC:
- PadLock AES:   11.00 MB/s (keylen independent)
- AES-i586:      8.01 to 9.84 MB/s depending on the keylen
- Generic C AES: 6.37 to 8.24 MB/s
IPsec with HMAC-SHA256:
- PadLock AES:   8.06 MB/s
- Software AES slower by some 45% than without HMAC.
As soon as I get VIA Esther that can do SHA1/SHA256 in hardware I'll
update the padlock driver as well. Than I expect almost no slowdown even
in HMAC mode (which is almost always used in ESP).
Michal Ludvig
Subscription: List archive:

@_date: 2004-10-25 17:01:22
@_author: Eugen Leitl 
@_subject: OpenSSL 0.9.7e released (fwd from mark@openssl.org) 
Reply-To: openssl-dev at openssl.org
  OpenSSL version 0.9.7e released
  ==========================================
  OpenSSL - The Open Source toolkit for SSL/TLS
    The OpenSSL project team is pleased to announce the release of
  version 0.9.7e of our open source toolkit for SSL/TLS.  This new
  OpenSSL version is a bugfix release and incorporates changes and
  bugfixes to the toolkit (for a complete list see    ).
  The most significant changes are:
    o Fix race condition in CRL checking code.
    o Fixes to PKCS (S/MIME) code.
  We consider OpenSSL 0.9.7e to be the best version of OpenSSL available
  and we strongly recommend that users of older versions upgrade as
  soon as possible.  OpenSSL 0.9.7e is available for download via HTTP
  and FTP from the following master locations (you can find the various
  FTP mirrors under     o     o ftp://ftp.openssl.org/source/
  The distribution file name is:
    o openssl-0.9.7e.tar.gz
      MD5 checksum: a8777164bca38d84e5eb2b1535223474
  The checksums were calculated using the following command:
    openssl md5 < openssl-0.9.7e.tar.gz
  Yours,
  The OpenSSL Project Team...      Mark J. Cox             Ben Laurie          Andy Polyakov
    Ralf S. Engelschall     Richard Levitte     Geoff Thorpe
    Dr. Stephen Henson      Bodo M?ller
    Lutz J?nicke            Ulf M?ller
OpenSSL Project                                 Development Mailing List                       openssl-dev at openssl.org
Automated List Manager                           majordomo at openssl.org

@_date: 2004-10-29 08:55:35
@_author: Eugen Leitl 
@_subject: Financial identity is *dangerous*? (was re: Fake companies, real money) 
Er, it has been a while since you bought a new mobile, right?
About all of them have several MBytes memory, and run Java. Some Motorolas
run Linux. The better smart phones are pretty beefy PDAs.
The problem with modern mobiles that their security is of the cargo
cult/snake oil variety. Only a question of time before the first MMS worm
wipes out all Nokias, or something.

@_date: 2004-09-03 10:44:15
@_author: Eugen Leitl 
@_subject: [wearables] CFP: Workshop on Pervasive Computing and Communication Security (fwd from tech-wearables@bobmayo.com) 
Reply-To: tech-wearables at bobmayo.com
                            CALL FOR PAPERS
                              PerSec 2005
     Second IEEE International Workshop on Pervasive Computing and
                         Communication Security
               Held in conjunction with IEEE PerCom 2005
                8 March 2005, Kauai island, Hawaii, USA
                  Research in pervasive computing continues to gain momentum. The importance of
security and privacy in a pervasive computing environment cannot be
underestimated. PerSec 2005 will bring together the world's experts on this
topic and provide an international forum to stimulate and disseminate original
research ideas and results in this field.
Contributions are solicited in all aspects of security and privacy in pervasive
computing, including:
Models for access control, authentication and privacy management.
Incorporation of contextual information into security and privacy models, and
Management of tradeoffs between security, usability, performance, power
consumption and other attributes.
Architectures and engineering approaches to fit security and privacy features
into mobile and wearable devices.
Biometric methods for pervasive computing.
Descriptions of pilot programs, case studies, applications, and experiments
integrating security into pervasive computing.
Auditing and forensic information management in pervasive settings.
Protocols for trust management in networks for pervasive computing.
Incorporation of security into communication protocols, computing architectures
and user interface designs for pervasive computing.
Impact of security and privacy in relation to the social, legal, educational
and economic implications of pervasive computing.
INSTRUCTIONS FOR AUTHORS
Papers must be sent to persec-2005 at cl.cam.ac.uk as file attachments in Adobe
PDF format.
Papers must have authors' affiliation and contact information on the first
Papers must be unpublished and not being considered elsewhere for publication.
In particular, papers submitted to PerSec must not be concurrently submitted to
PerCom in identical or modified form.
Papers must be formatted in strict accordance with the IEEE Computer Society
author guidelines published at
ftp://pubftp.computer.org/Press/Outgoing/proceedings/INSTRUCT.HTM. For your
convenience, templates are available at
ftp://pubftp.computer.org/Press/Outgoing/proceedings/. LaTeX is recommended.
Papers are limited to 5 pages in IEEE 8.5x11 conference
format. Excessively long papers will be returned without review.
Papers selected for presentation will be published in the Workshop Proceedings
of PerCom 2005 by IEEE Press.
IMPORTANT DATES
Paper submission: 13 September 2004
Acceptance Notification: 15 November 2004
Camera-ready manuscripts: 29 November 2004
PerSec Workshop: 8 March 2005 (first day of PerCom, which runs until the PROGRAM CO-CHAIRS
     * Frank Stajano, University of Cambridge, UK
     * Roshan Thomas, McAfee Research, USA
     * Boris Dragovic, University of Cambridge, UK
Contact email (goes to co-chairs and secretary): persec-2005 at STEERING COMMITTEE CHAIR
     * Ravi Sandhu, George Mason University, USA
PROGRAM COMMITTEE
     * Tuomas Aura, Microsoft Research, UK
     * Mark Corner, UMass, USA
     * Srini Devadas, MIT, USA
     * Boris Dragovic, University of Cambridge, UK
     * Naranker Dulay, Imperial College, UK
     * Kris Gaj, George Mason University, USA
     * Robert Grimm, NYU, USA
     * Dieter Hutter, DFKI, Germany
     * Ari Juels, RSA Laboratories, USA
     * Tim Kindberg, HP Labs Bristol, UK
     * Cetin Kaya Koc, Oregon State University, USA
     * Marc Langheinrich, ETH Zurich, Switzerland
     * Mark Lomas, BIICL, UK
     * Robert N. Mayo, HP Labs Palo Alto, USA
     * Refik Molva, Eurecom, France
     * Kai Rannenberg, University of Frankfurt, Germany
     * Stephen Weis, MIT

@_date: 2004-09-10 18:20:28
@_author: Eugen Leitl 
@_subject: [anonsec] Re: potential new IETF WG on anonymous IPSec (fwd from hal@finney.org) (fwd from touch@ISI.EDU) 
Reply-To: "Discussions of anonymous Internet security." Clarifications below...
It does not authenticate the endpoint's identification, other than "same place I had been talking to."
There's no difference between having no "name" and having a name you cannot trust. I.e., I could travel under the name "anonymous" or "", or under the name "A. Smith". If you don't know whether I am actually A. Smith, the latter is identical to the former.
Correction: it is a proposal to extend Internet security - including Ipsec, but also including TCP-MD5 (sometimes called "BGP MD5") and other security mechanisms at various layers. It is not focused only on IPsec.
This is one option, but not the only one.
There are two aspects:
The last one, agreed. But the primary assumption is that we can avoid a lot of infrastructure and impediment to deployment by treating an ongoing conversation as a reason to trust an endpoint, rather than a third-party identification. Although anonymous access is not the primary goal, it is a feature of the solution.
Please review the draft; there are a number of reasons this is being considered, not the least of which is to reduce the cumbersome requirement of key infrastructure as well as to avoid performance penalties.
Please be more specific; how would it be better?
Address != identity. Agreed, if what you want to do is hide traffic, this does not provide traffic confidentiality. But it does not tell you whether the packets come from 128.9.x.x (ISI, e.g.) or from someone spoofing 128.9.x.x; all you know is that whoever is using that address is capable of having an ongoing conversation (TCP connection, e.g.) with I.e., there are two ways to be anonymous, as noted earlier:
Even if you use "real" names in (2), there's no difference with (1), since you don't know whether the real Mickey Mouse is using it.

@_date: 2004-09-14 10:31:11
@_author: Eugen Leitl 
@_subject: pci hardware for secure crypto storage (OpenSSL/OpenBSD) 
I'm looking for (cheap, PCI/USB) hardware to store secrets (private key) and
support crypto primitives (signing, cert generation). It doesn't have to be
fast, but to support loading/copying of secrets in physically secure environments, and
not generate nonextractable secret onboard. Environment is
Any suggestions?

@_date: 2004-09-15 17:56:04
@_author: Eugen Leitl 
@_subject: pci hardware for secure crypto storage (OpenSSL/OpenBSD) 
"If you loose or damage your token: you loose your private key and any data
encrypted to it. Because the key is generated inside the token and cannot
leave it, it is not possible to make a backup of the private key." is a
knockout criterium, though.
Also an interactive PIN entry for each interaction is a no-no, if the machine
is in a rack at the host.
H4x0rs may break in and sign a few stray blobs, but they won't be able to
steal the private key itself.

@_date: 2004-09-17 22:28:51
@_author: Eugen Leitl 
@_subject: public-key: the wrong model for email? 
apt-get install postfix-tls
Allright, this still doesn't generate the certs, nor reference them in the
I would cache the cert fingerprints, and log when those change.
Start/TLS does encrypt my mail far more often the PGP/GPG.
Talk to Exim/Postfix maintainers. They should ship self-signed cert Start/TLS
config out of the box. Even without cert caching, that'd require a MITM.
Not exactly cheap, and prone to detection, if practiced on a nonnegligible
scale (fingerprint checking).

@_date: 2005-04-11 08:57:23
@_author: Eugen Leitl 
@_subject: DTV Content Protection (fwd from cripto@ecn.org) 
DTV Content Protection
Two content protection systems are in use to protect digital television
(DTV) signals on the wires of American home video systems: HDCP and DTCP.
HDCP is used for the most common digital cable connection to HD monitors,
HDMI, which is a variant of DVI.  DTCP is used for digital connections
to video equipment, especially digital VCRs.  It was originally designed
for Firewire (aka iLink, aka IEEE-1394) but has been extended to USB-2
and Bluetooth, with IP in the works.  Apparently monitors with both HDMI
and Firewire connections would have to implement both.
HDCP is described at  and DTCP at
  The full DTCP spec is still secret unless you
are a licensee and the site has only limited information.
The two systems are very different cryptographically.  HDCP uses a
56-bit keyed stream cipher based on LFSRs.  DTCP uses block ciphers,
either a 56-bit key proprietary block cipher from Hitachi called M6,
or AES with 128-bit keys.  M6 is the default that all devices must
implement.  M6 uses an odd chaining mode called "converted CBC" which
seems to chain the ciphertext into the next block's key material rather
than the plaintext, possibly with an abbreviated key schedule.
Here I want to focus on the key agreement protocol.  Both systems use a
similar approach which has never been formally presented or documented.
For convenience I will call it SKDH, for Symmetric Key Diffie Hellman.
SKDH has some properties of Diffie Hellman key exchange, but it uses
simple addition operations rather than public key functions.  It also has
some properties of identity-based encryption, in that there is a master
key center that issues the private keys to each device.  However it
is not secure against collusion by users who know their private keys,
so would not be suitable for a true IBE system.
DTCP has two key agreement protocols. There is a full protocol which is
EC-DH (elliptic curve Diffie Hellman) and is mandatory for "copy never"
content, ie. pay per view content.  It also specifies a restricted
protocol which is acceptable for "copy once" and "copy no more" content,
that uses the SKDH technique described below.  This will be much cheaper
to implement for manufacturers and is probably used by typical recording
DHCP has just one key agreement protocol and it is of this new type
as well.
SKDH key agreement has not been published but it is presumed that it
works as follows.  There is a secret matrix which is known only to
the agency that issues keys.  Let us call this the Master Matrix, MM.
The system is based on matrix algebra as follows:
Pub1 * MM * Pub2 = shared key.
Pub1 and Pub2 are vectors of 1's and 0's which are the "public keys"
of the two devices, called "key selection vectors" or KSVs.  Each device
is issued such a vector, along with its private keys, which are defined
as follows:
Priv1 = Pub1 * MM
Priv2 = MM * Pub2
Priv1 and Priv2 are vectors of numbers whose size depends on the values
in MM.  Details for the two known implementations are described below.
By associativity, we have:
Pub1 * MM * Pub2 = Priv1 * Pub2 = Pub1 * Priv1 = shared key.
The two parties do a key exchange by giving each other their KSVs,
the public Pub1 and Pub2 values.  Each one then multiples the vector
of 1's and 0's they received from the other side times their vector of
Priv values.  This amounts to simply adding the Priv values selected
by the 1's received from the other side.  Because of the relationship
between the public and private values, this insures that both sides
receive the same shared key.
The analogy to Diffie Hellman which motivated the name SKDH should now
be clear.  Each side receives a public value from the other, combines
it with its own private data, and creates a shared secret.
In HDCP, the MM matrix is 40 by 40, and entries are 56 bits long.  In
DTCP, the MM matrix is 12 by 12, and entries are 64 bits long.
The weakness of this system is that if the the private key vectors are
published, they leak information about the MM matrix.  In principle as
few as 40 private/public key pairs could fully reveal MM in the case of
HDCP, and as few as 12 in the case of DTCP.  This makes the cryptographic
scheme unsuitable for any widespread identity based encryption scheme;
it will only work in a closed system like these, where manufacturers
must take great pains to keep their private keys secret.
Attacks on HDCP
Several attacks have been published and unpublished on HDCP.  The most
famous is from Niels Ferguson, who has announced an attack but will not
publish it for the reasons described at
  According to Ferguson:
"HDCP is fatally flawed. My results show that an experienced IT person
can recover the HDCP master key in about 2 weeks using four computers
and 50 HDCP displays. Once you know the master key, you can decrypt any
movie, impersonate any HDCP device, and even create new HDCP devices
that will work with the 'official' ones. This is really, really bad
news for a security system. If this master key is ever published, HDCP
will provide no protection whatsoever. The flaws in HDCP are not hard
to find. As I like to say: 'I was just reading it and it broke.'"
Keith Irwin has published four (actually five) attacks on HDCP at
  His last one
is perhaps along the lines that Ferguson envisioned, and I will say more
about it below.
Similar concepts are presented in
 by
Scott Crosby, Ian Goldberg, Robert Johnson, Dawn Song and David Wagner.
This paper assumes (unlike Irwin) that attackers have access to the
private keys of chosen devices.  This is a questionable assumption as
it will take very expensive laboratory equipment to extract sensitive
key material from today's protected chips.
Irwin's fifth attack is presented in an addendum.  It involves presenting
random KSVs to a display and using a birthday trick to find the "shared
key" values relatively quickly, which could lead to a break in about
a month.  However Irwin is more pessimistic about the number of displays
and assumes that 74 will be needed to have a good chance of spanning the
whole matrix.  If 50 properly chosen displays are enough then Irwin's
attack would be pretty close to Ferguson's two week time frame.
All of these attacks focus on finding the master secret MM value; once
that is found, the security of the system collapses.  Given a KSV it is
immediately possible to deduce the corresponding private key if you know
the MM.  Although both HDCP and DTCP have mechanisms for revocations of
cracked keys, a total break like this cannot be rescued by revocation.
Attacks on DTCP
DTCP seems not have gotten as much attention from cryptographers, in
part because the details are secret.  But its restricted authentication
handshake uses the same SKDH algorithm as HDCP.  DTCP requires the two
sides to have certificates, but it appears that the receiver of the
data does not check them, so Irwin's random-KSV birthday attack should
still work.  It may take a little longer due to the key size being 64
rather than 56 bits, but this will be somewhat compensated by the fact
that the matrix size is 12 rather than 40.
The time will depend crucially on how quickly a handshake can be
completed with a device, and the DTCP spec is somewhat vague about this.
It's possible that the handshake could be much faster, and then the attack
could complete even more quickly than HDCP.  Since DTCP has only a 12 bit
public key there are only 2^12 possibilities, so these keys will not be
distinct between different devices, but rather will be common across a
model or even across a manufacturer.  This could make it harder to find
12-15 devices with different keys that will span the MM matrix.
The M6 cipher used in DTCP is actually a family of ciphers, and some of
them are attacked in  by John
Kelsey, Bruce Schneier and David Wagner.  However that attack depends
crucially on the use of addition in a certain phase of the algorithm, and
M6 is also documented to use XOR there in some variants.  The specific
version of M6 used in DTCP is not known, and even if the attackable
version is used it's not clear if this would weaken the cipher enough
to make it the weakest link in the chain.
Both HDCP and DTCP use cryptographic mechanisms for which published
attacks have existed for several years, yet deployment proceeds unabated.
Almost all new HDTV equipment in the U.S. implements one or both of
these cryptographic protocols.  As discussed above, if enough private
keys leak or are scraped out, or if Irwin's attack works, the security
of these systems will collapse.
DTCP has a fallback in is its certificate protected, EC-DH based
full authentication mode, using AES-128 to avoid any weaknesses in M6.
It would take years though before existing equipment could be obsoleted
by ceasing to support the restricted authentication mode that uses SKDH.
HDCP has no fallback and it would be necessary to redesign the handshake,
again with a several year lag time for deployment of the updated system.
It will be interesting to see whether these theoretical attacks can
be successfully mounted now that HDTV equipment is widely available.
As the cost continues to drop over the next couple of years it should
soon be practical for hobbyists to begin experimenting with Irwin's
attack and start collecting KSV + private key pairs.  DTCP would be an
even more attractive target as it would allow easy computer recording
of protected data via Firewire, USB2, or IP.  However its reliance on
the much-maligned principle of security through obscurity (keeping the
details secret) may in practice give it a greater degree of protection.

@_date: 2005-12-05 08:54:58
@_author: Eugen Leitl 
@_subject: [Clips] Banks Seek Better Online-Security Tools 
I've been using online banking for many years, both US and Germany. The German PIN/TAN system is reasonably secure,
being an effective one-time pad distributed through out of band channel
(mailed dead tree in a tamperproof envelope). It is of course not immune
to phishing (PIN/TAN harvesting), which has become quite rampant recently.
I'm about to setup HBCI with my business account (both GnuCash and
openhbci/aqbanking from the command line), which can in principle cooperate
with a smartcard. It is a major pain to set up, however, especially on an
unsupported platform.
I do have a HBCI smartcard setup with my private account but don't use it
since it's locked in a proprietary software jail.

@_date: 2005-12-15 17:56:09
@_author: Eugen Leitl 
@_subject: automatic toll collection, was Japan Puts Its Money on E-Cash 
The German TollCollect system (used on the national highway system)
reads license plates of every vehicle (currently, only trucks
are charged) by OCR. The police is purportely very interested to obtain
realtime access to the logs. Don't we all feel much safer, already?

@_date: 2005-02-03 09:07:38
@_author: Eugen Leitl 
@_subject: Dell to Add Security Chip to PCs 
Please stop relaying pro-DRM pabulum. The only reason for Nagscab is
restricting the user's rights to his own files.
Of course there are other reasons for having crypto compartments in your
machine, but the reason Dell/IBM is rolling them out is not that.
Really? How interesting. Please tell us more.

@_date: 2005-01-07 19:30:48
@_author: Eugen Leitl 
@_subject: [PadLock] PadLock patches for linux kernel 2.6.10 (fwd from michal@logix.cz) 
Hi all,
Updated VIA PadLock drivers for linux kernel 2.6.10 are available at The recently reported problem with GCC 3.4.3 is addressed there.
Good news - initial PadLock support was accepted into the vanilla kernel in 2.6.10-bk1 (i.e. right after 2.6.10 was released). Official kernel 2.6.11 will have it without patching.
Michal Ludvig

@_date: 2005-01-15 15:02:23
@_author: Eugen Leitl 
@_subject: [PATCH 1/2] CryptoAPI: prepare for processing multiple buffers at a time (fwd from clemens@endorphin.org) 
Fine, I just saw in Evgeniy's reply, that he took your padlock
implementation. I thought both of you have been working on different
implementations. But actually both aim for the same goal. Hardware crypto-offloading.
With padlock the need for a async interface isn't that big, because it's
not "off-loading" as it's done on the same chip and in the same thread. However, developing two different APIs isn't particular efficient. I
know, at the moment there isn't much choice, as J.Morris hasn't commited
to acrypto in anyway. But I think it would be good to replace the
synchronized CryptoAPI implementation altogether, put the missing
internals of CryptoAPI into acrypto, and back the interfaces of
CryptoAPI with small stubs, that do like
somereturnvalue synchronized_interface(..) {
The other way round, a asynchron interface using a synchronized
interface doesn't seem natural to me.
(That doesn't mean I oppose your patches, merely that we should start to
think in different directions)
Err, right. I overlooked that it's cia and not cit. However, I don't
like the idea of extending structs when there is a new cipher mode. I
think the API should not have to be extended for every addition, but
should be designed for such extension right from the start.
What about a "selector" function, which returns the appropriate
encryption function for a mode?
typedef void (procfn_t)(struct crypto_tfm *, u8 *,
                        u8*, cryptfn_t, int enc, void *, int);
put into struct crypto_alg;
then in crypto_init_cipher_ops, instead of
        	ops->cit_encrypt = cfb_encrypt;
we do,
Alternatively, we could also add a lookup table. But I like this better,
since this is much easier to read for people, and tfm's aren't alloced
that often.
Probably, we can add a wrapper for cia_modesel, that when cia_modesel is
NULL, it falls back to the old behaviour. This way, we don't have to
patch all algorithm implementations to include cia_modesel.
How you like that idea?

@_date: 2005-01-18 09:09:26
@_author: Eugen Leitl 
@_subject: [i2p] Tunnel cryptography for I2P 0.5 (corrected typo) (fwd from barnesc@engr.orst.edu) 
Citizens of I2P,
The following is a discussion of tunnel cryptography plans for
I2P 0.5.  There are two options; one will be chosen.
[1] and [2] offer more complete discussion of these plans.  Note that
the cryptographic methods discussed in [2] are incomplete.  They are
complete in this message.
 - Connelly

@_date: 2005-01-29 18:37:17
@_author: Eugen Leitl 
@_subject: Students Find Hole in Car Security Systems 
Students Find Hole in Car Security Systems
By JOHN SCHWARTZ
Published: January 28, 2005
BALTIMORE - Matthew Green starts his 2005 Ford Escape with a duplicate key he
had made at Lowe's. Nothing unusual about that, except that the automobile
industry has spent millions of dollars to keep him from being able to do it.
Mr. Green, a graduate student at Johns Hopkins University, is part of a team
that plans to announce on Jan. 29 that it has cracked the security behind
"immobilizer" systems from Texas Instruments Inc. The systems reduce car
theft, because vehicles will not start unless the system recognizes a tiny
chip in the authorized key. They are used in millions of Fords, Toyotas and
All that would be required to steal a car, the researchers said, is a moment
next to the car owner to extract data from the key, less than an hour of
computing, and a few minutes to break in, feed the key code to the car and
hot-wire it.
An executive with the Texas Instruments division that makes the systems did
not dispute that the Hopkins team had cracked its code, but said there was
much more to stealing a car than that. The devices, said the executive, Tony
Sabetti, "have been fraud-free and are likely to remain fraud-free."
The implications of the Hopkins finding go beyond stealing cars.
Variations on the technology used in the chips, known as RFID for radio
frequency identification, are widely used. Similar systems deduct highway
tolls from drivers' accounts and restrict access to workplaces.
Wal-Mart is using the technology to track inventory, the Food and Drug
Administration is considering it to foil drug counterfeiting, and the medical
school at the University of California, Los Angeles, plans to implant chips
in cadavers to curtail unauthorized sale of body parts.
The Johns Hopkins researchers say that if other radio frequency ID systems
are vulnerable, the new field could offer far less security than its
proponents promise.
The computer scientists are not doing R.&D. for the Mafia. Aviel D. Rubin, a
professor of computer science who led the team, said his three graduate
students did what security experts often do: showed the lack of robust
security in important devices that people use every day.
"What we find time and time again is the security is overlooked and not done
right," said Dr. Rubin, who has exposed flaws in electronic voting systems
and wireless computer networks.
David Wagner, an assistant professor of computer science at the University of
California, Berkeley, who reviewed a draft of a paper by the Hopkins team,
called it "great research," adding, "I see it as an early warning" for all
radio frequency ID systems.
The "immobilizer" technology used in the keys has been an enormous success.
Texas Instruments alone has its chips in an estimated 150 million keys.
Replacing the key on newer cars can cost hundreds of dollars, but the
technology is credited with greatly reducing auto theft. - Early versions of
in-key chips were relatively easy to clone, but the Texas Instruments chips
are considered to be among the best. Still, the amount of computing the chip
can do is restricted by the fact that it has no power of its own; it builds a
slight charge from an electromagnetic field from the car's transmitter.
Cracking the system took the graduate students three months, Dr. Rubin said.
"There was a lot of trial and error work with, every once in a while, a
little 'Aha!' "
The Hopkins researchers got unexpected help from Texas Instruments itself.
They were able to buy a tag reader directly from the company, which sells
kits for $280 on its Web site. They also found a general diagram on the
Internet, from a technical presentation by the company's German division. The
researchers wrote in the paper describing their work that the diagram
provided "a useful foothold" into the system. (The Hopkins paper, which is
online at  does not provide information that might allow
its work to be duplicated.
The researchers discovered a critically important fact: the encryption
algorithm used by the chip to scramble the challenge uses a relatively short
code, known as a key. The longer the code key, which is measured in bits, the
harder it is to crack any encryption system.
"If you were to tell a cryptographer that this system uses 40-bit keys, you'd
immediately conclude that the system is weak and that you'd be able to break
it," said Ari Juels, a scientist with the research arm of RSA Security, which
financed the team and collaborated with it.
The team wrote software that mimics the system, which works through a pattern
of challenge and response. The researchers took each chip they were trying to
clone and fed it challenges, and then tried to duplicate the response by
testing all 1,099,511,627,776 possible encryption keys. Once they had the
right key, they could answer future challenges correctly.
Mr. Sabetti of Texas Instruments argues that grabbing the code from a key
would be very difficult, because the chips have a very short broadcast range.
The greatest distance that his company's engineers have managed in the
laboratory is 12 inches, and then only with large antennas that require a
power source.
Dr. Rubin acknowledged that his team had been able to read the keys just a
few inches from a reader, but said many situations could put an attacker and
a target in close proximity, including crowded elevators.
The researchers used several thousand dollars of off-the-shelf computer
equipment to crack the code, and had to fill a back seat of Mr. Green's
S.U.V. with computers and other equipment to successfully imitate a key. But
the cost of equipment could be brought down to several hundred dollars, Dr.
Rubin said, and Adam Stubblefield, one of the Hopkins graduate students,
said, "We think the entire attack could be done with a device the size of an
The Texas Instruments chips are also used in millions of the Speedpass tags
that drivers use to buy gasoline at ExxonMobil stations without pulling out a
credit card, and the researchers have shown that they can buy gas with a
cracked code. A spokeswoman for ExxonMobil, Prem Nair, said the company used
additional antifraud measures, including restrictions that only allow two gas
purchases per day.
"We strongly believe that the Speedpass devices and the checks that we have
in place are much more secure than those using credit cards with magnetic
stripes," she said.
The team discussed its research with Texas Instruments before making the
paper public. Matthew Buckley, a spokesman for RSA Security, said his
company, which offers security consulting services and is developing radio
frequency ID tags that resist unauthorized eavesdropping, had offered to work
with Texas Instruments free of charge to address the security issues.
Dr. Wagner said that what graduate students could do, organized crime could
also do. "The white hats don't have a monopoly on cryptographic expertise,"
he said.
Dr. Rubin said that if criminals did eventually duplicate his students' work,
people could block eavesdroppers by keeping the key or Speedpass token in a
tinfoil sheath when not in use. But Mr. Sabetti, the Texas Instruments
executive, said such precautions were unnecessary. "It's a solution to a
problem that doesn't exist," he said.
Dan Bedore, a spokesman for Ford, said the company had confidence in the
technology. "No security device is foolproof," he said, but "it's a very,
very effective deterrent" to drive-away theft. "Flatbed trucks are a bigger
threat," he said, "and a lot lower tech."

@_date: 2005-06-09 18:24:18
@_author: Eugen Leitl 
@_subject: "Retailers Experiment With Biometric Payment" article 
The fingerprint hash (fingerprint's fingerprint) has to be resistant to rotation/translation, area size and subpattern presence, and tolerate some skin lesion noise, so it's the very opposite of a cryptographic hash.
Probably quite easy to reverse.

@_date: 2005-03-07 21:23:41
@_author: Eugen Leitl 
@_subject: [0/many] Acrypto - asynchronous crypto layer for linux kernel 2.6 (fwd from johnpol@2ka.mipt.ru) 
Reply-To: Evgeniy Polyakov I'm pleased to announce asynchronous crypto layer for Linux kernel 2.6.
It supports following features:
- multiple asynchronous crypto device queues
- crypto session routing
- crypto session binding
- modular load balancing
- crypto session batching genetically implemented by design
- crypto session priority
- different kinds of crypto operation(RNG, asymmetrical crypto, HMAC and
any other)
Some design notes:
acrypto has one main crypto session queue, into which each
newly allocated session is inserted and this is a place where load
balancing searches it's food. When new session is being prepared for
insertion it calls load balancer's ->find_device() method, which should
return suitable device(current simple_lb load balancer returns device
with the lowest load(device has the least number of session in it's
queue)) if it exists. After crypto_device being returned acrypto creates
new crypto routing entry which points to returned device and adds it to
crypto session routing queue. Crypto session is being inserted into
device's queue according to it's priority and it is crypto device driver
that should process it's session list according to session's priority.
Each crypto load balancer must implement 2 methods: ->rehash() and ->find_device() which may be called from any context and
under spinlock.
->rehash() method should be called to remix crypto sessions in device's
queues, for example if driver decides that it's device is broken it
marks itself as broken and load balancer(or scheduler if you like)
should remove all sessions from this queue to some other devices. If session can not be completed scheduler must mark it as broken and
complete it(by calling first broke_session() and then complete_session()
and stop_process_session()). Consumer must check if operation was
successful(and therefore session is not broken).
->find_device() method should return appropriate crypto device.
Since load balancers may be loaded and unloaded without any restriction,
one may create it's own crypto load balancers, which may use
crpypto session's (crypto_data) private area to select appropriate device,
for example, one may store process' pid in private area and write it's own
crypto load balancer which will select private crypto device for given PID,
and the rest of the cypto system to process other requests.
For crypto session to be successfully allocated crypto consumer must
provide two structures - struct crypto_session_initializer and struct crypto_data.
struct crypto_session_initializer contains data needed to find
appropriate device, like type of operation, mode of operation, some
flags(for example SESSION_BINDED, which means that session must be bound
to specified in bdev field crypto device, it is useful for TCPA/TPM),
session priority and callback which will be called after all routing for
given session are finished.
struct crypto_data contains scatterlists for src, dst, key and iv.
It also has void *priv field and it's size which is allocated and may be
used by any crypto agent(for example VIA PadLock driver uses it to store
aes_ctx field, crypto_session can use this field to store some pointers
needed in ->callback()).
Actually callback will be called from work queue context, but I suppose it is
better to not assume calling context.
->callback() will be called after all crypto routing for given session
are done with the same parameters as were provided in initialisation
time(if session has only one routing callback will be called with
original parameters, but if it has several routes callback will be
called with parameters from the latest processed one). I believe crypto
callback should not know about crypto sessions, routings, device and so
on, proper restriction is always a good idea.
Crypto routing.
This feature allows the same session to be processed by several
devices/algorithms. For example if you need to encrypt data and then
sign it in TPM device you can create one route to encryption device and
then route it to TPM device, or this can be used for tweakable cipher
encryption without 2-atomic-maps restriction.
Crypto device.
It can be either software emulator or hardware accelerator chip(like
HIFN 79*/83* or Via PadLock ACE/RNG, or even TPM device like each IBM
ThinkPad or some HP laptops have.
It can be registered with asynchronous crypto layer and must provide
some data for it:
->data_ready() method - it is called each time new session is added to
device's queue.
Array of struct crypto_capability and it's amount - struct crypto_capability describes each operation given device can
handle, and has a maximum session queue length parameter.
Note: this structure can [be extended to] include "rate" parameter to
show absolute speed of given operation in some units, which therefore
can be used by scheduler(load balancer) for proper device selection.
Actually queue length can somehow reflects device's "speed".
Note2: it can be calculated using ptime parameter of the session initializer - it is time given session was processed in crypto device.
Acrypto has full userspace support through ioctl and direct process' vmas and pages access.
It is done using ioctl() with 2 copyings from+to userspace data.
Session processing contains of 3 major parts:
1. Session creation. CRYPTO_SESSION_ALLOC ioctl.
User must provide special structure which has src, dst, key and iv data sizes and crypto initializer(crypto operation, mode, type and priority).
2. Data filling. User must call several CRYPTO_FILL_DATA ioctls.
Each one requires data size and data type(structure crypto_user_data) and data itself.
3. Finish. User must call CRYPTO_SESSION_ADD ioctl with pointer to the are whre crypting result must be stored.
The latter ioctl will sleep while session is being processed.
Second userspace communication mechanism is based on direct access to the process' vmas and pages from acrypto, pointers are transferred using special kernel connector structure.
Obviously it can not be used with the most hardware, but I like the idea itself.
Currently supported HIFN 7955(small load testing), via padlock driver(not tested), driver for CE-InfoSys FastCrypt PCI card equipped with a SuperCrypt CE99C003B chip(not tested).
Subscription: List archive:

@_date: 2005-03-10 11:34:07
@_author: Eugen Leitl 
@_subject: [0/many] Acrypto - asynchronous crypto layer for linux kernel 2.6 (fwd from johnpol@2ka.mipt.ru) 
Organization: MIPT
Reply-To: johnpol at 2ka.mipt.ru
Patch on the web has quite small interest for the majority of the
but probably it is better than 50+ e-mails...
The latest sources which can be compiled as external module are available at That would be very good.
You can find HIFN, VIA, FCRYPT drivers created for acrypto at
P.S. Above site is currently down, it will be turned on asap.

@_date: 2005-03-15 14:39:20
@_author: Eugen Leitl 
@_subject: ocf-linux-20050315 - Asynchronous Crypto support for linux (fwd from davidm@snapgear.com) 
Hi all,
The latest release of ocf-linux (20050315) is available for download
from the project page:
This release includes the following changes:
OCF-Linux is a Linux port of the OpenBSD/FreeBSD Cryptographic Framework
(OCF). This port aims to bring full asynchronous HW/SW crypto
acceleration to the Linux kernel and applications running under Linux.
Results have shown improvements of up to 7 times that of software crypto
for bulk crypto throughput using OpenSSL.
At this point in time OCF-Linux provides acceleration for OpenSSL,
OpenSSH (scp, ssh, ...) and also supports the BSD crypto testing
applications. It can accelerate DES, 3DES, AES, MD5, SHA, and Public Key
operations with plans to include Random Number generators and more. This
project is being actively developed as a high performance crypto
solution for embedded devices but also applies equally well to any linux
based server or desktop.

@_date: 2005-09-10 22:55:30
@_author: Eugen Leitl 
@_subject: Is there any future for smartcards? 
We also have ubiquitous networking of systems which are vulnerable and frequently compromised. Smartcard + reader is a hardened cryptographic
compartment where you can still trust what you see on the reader display, and that nobody can sniff what is entered on the keypad.
Such a system can be safely connected to an insecure, networked machine.

@_date: 2005-09-11 19:32:45
@_author: Eugen Leitl 
@_subject: Is there any future for smartcards? 
Pat Farrel spoke about the infrastructure required for smartcards to have
at all a point. Inexpensive USB readers with integrated keypad (and LCD display)
exist, and are a basic component of such smartcard infrastructure. Unless it's
pure snakeoil, by design. USB smarcard readers with displays are not expensive, especially
if purchased in quantities. A financial institution would probably
recover the costs quite rapidly, if it gave away smartcards and such readers for free to its customers, given the amount of fraud.
It is symptomatic that this is not happening, and that e.g.
HBCI support hereabouts is very thin. HBCI+smartcard, especially on
a non-Redmond system, is nearly impossible to set up. Zero support.
(Support in fact discourages use of smartcard). Default for
local online banking is PIN/TAN (TANs distributed on dead tree).

@_date: 2005-09-12 13:46:20
@_author: Eugen Leitl 
@_subject: Is there any future for smartcards? 
The smartphones not secure at all, because anything you enter
on the keypad and see on the display can be compromised, so
the tamper-proof cryptographic goodness locked inside the SIM
smartcard will cheerfully approve whatever the code running
on the smartphone will tell it to approve, regardless of
what is being displayed to the user.
Virtually all new phones sold are smartphones, and for every
platform there are documented vulnerabilities, exploits, and
malware already in the wild. Increased use of mobile phones as means of payment are a strong motivation for malware writers. Most of smartphone users are security-naive teenagers.
This indicates that we'll be getting all problems with desktop
machines, and more, shortly. I own a secure home card reader (which happens on run on Windows, Linux
and OS X, with open source drivers -- my model has a keyboard but no display, but other models from the same manufacturer do). Standars are good. I'm all for standars, as long as they describe what eventually will be a real world product. Unless financial
institutions will be required by law to issue secure smartcards
and smartcard readers, or suffer extreme losses through fraud
they won't introduce these secure readers and smartcards.

@_date: 2005-09-13 15:57:16
@_author: Eugen Leitl 
@_subject: Is there any future for smartcards? 
It's just a networked computer that happens to look
like a mobile phone. Not particularly security-oriented.
It also doesn't matter what current malware does on the current
platform. FWIW, it's still in primitive shenanigan stage. It's a question what future malware on future mobile platforms
will do. It's a machine for young social primates. Not suitable
for a payment system, unless equipped with dedicated, hardened
cryptographic compartment with dedicated display and PIN/biometrics. Yesterday we received information on Commwarrior.B sightings on two new countries: Greece and South Africa.
So it seems that the rate in which Commwarrior is spotted is quite a lot faster than with Cabir. But then again, high discovery rate might be result of increased public awareness.
Also as Commwarrior is in the wild here in Finland, we have had an opportunity to follow how the worm spreads and interviewed people who have been infected with it. And it seems that we have found at least partial answer to the question why people install Symbian worms on their phones.
The most common reason why people have installed Commwarrior from MMS message is the trust that they have on the sender. People are wary of messages that they receive from unknown sources, but quite willing to install whatever has been sent from a friends mobile. This is a phenomenon that we have also seen with E-Mail worms, people just are unwilling to mistrust something coming from a friend.
Current count of countries with Commwarrior sightings:
8.South Africa
Are we talking even about the same species? About
the same teenagers which already own malware-infested PCs, and swap whatever ringtones, logos and games en vogue
with their FOAFs?

@_date: 2005-09-17 18:30:13
@_author: Eugen Leitl 
@_subject: European country forbids its citizens from smiling for passport photos 
U.K.? All of them? US and Canadia as well?
We should violet-wand the smartcard pads. Or sever the antenna for the RFID.
Or just use the dead tree one, and not reapply when it expires.
Not ready for 1984? One sure would hope so.

@_date: 2007-04-30 16:38:14
@_author: Eugen Leitl 
@_subject: C7, Jetway, performance 
Anyone here running a recent Jetway or similiar product with a C7?
Care to share your benchmarks, as to IPsec & Co throughput?
I'm thinking about picking up a J7F2WE1G5D, or similiar, and
a triple-GBit Ethernet (Realtek RTL81108, or similiar), and am
interested in how that thing performs at 100..1000 MBit/s
speed, with IPsec or OpenVPN (FreeBSD 6.2 or pfsense data
would be great).

@_date: 2007-06-21 18:19:10
@_author: Eugen Leitl 
@_subject: ad hoc IPsec or similiar 
There's a rather ominous EU legislation to be passed soon,
which requires any party acting as a provider (you run anonymous
proxy, or mix cascade, you are a provider) to log all connection
info (when, who, with whom). What's the status of ad hoc IPsec
or any other TCP/IP-tunneling VPN for random endpoints?

@_date: 2007-06-21 20:33:42
@_author: Eugen Leitl 
@_subject: ad hoc IPsec or similiar 
It is not national law yet. I'm only concerned about when I
have to deal with it personally.
The pending legislation is stated broadly enough to include anyone
with a proxy or a mix cascade, company or private body, for-profit
or non-profit. It threatens up to half a megaeuro penalty and up to two years in jail. Any random endpoints will be passing through the ISP, and hence
subject to retention. An ad hoc IPsec or VPN tunnel setup will
make data analysis more difficult, especially if there's traffic
background (P2P, etc).
So what's the state in ad hoc IPsec/VPN setup for any end points?
I've been told this legislation will be used by several persons
within BKA etc. to harass Tor operators. This is not a guess; I'm
not sure how reliable that source is, however.
The financial burden is completely on the side of the providers.
Unfortunately, I know more about the plans than I ever wished.
It also applies to mobile phone location in the cell.
Apparently, Germany will implement Internet connection retention by
end of the year/beginning of 2008 latest.

@_date: 2008-08-28 10:49:20
@_author: Eugen Leitl 
@_subject: road toll transponder hacked 
is in operation in entire
Germany. It does OCR on all license plates (also used for police
purposes in realtime, despite initial vigorous denial) but currently is only used for truck toll.

@_date: 2008-08-28 18:55:52
@_author: Eugen Leitl 
@_subject: road toll transponder hacked 
They (not Toll Collect, though) do a realtime query against a reasonably long list of license plates in some German states, I recall reading.
Given where things are headed in Germany, I guarantee you Toll Collect
will be required by law to do data retention for at least a year or
two in less than 5 years.

@_date: 2008-12-05 14:16:09
@_author: Eugen Leitl 
@_subject: Quantum direct communication: secrecy without key distribution 
[1]the physics arXiv blog
   [2]Quantum direct communication: secrecy without key distribution
   Posted: 04 Dec 2008 09:13 PM PST
   [3]quantum-direct-communication.jpg    An interesting development in the world of quantum encryption.
   In the last couple of years, we've seen a number of quantum key
   distribution systems being set up that boast close-to-perfect security
   ([4]although they're not as secure as the marketing might imply).
   These systems rely on two-part security. The first is the quantum part
   which reveals whether a message has been intercepted or not. Obviously
   this is no use when it comes to sending secret message because it can
   only uncover eavesdroppers after the fact.
   So Alice sends a one time pad over this quantum channel that she and
   Bob can later use to encrypt and send a message classically. If this
   key is compromised, Alice sends another.
   What guarantees the security is not quantum mechanics but the second
   part of the system: the one time pad.
   Today, Seth Lloyd and colleagues at the Massachusetts Institute of
   Technology in Cambridge, publish a way of guaranteeing security over a
   quantum channel without having to fall back on a one time pad.
   Their idea is to send a message over a standard quantum channel
   without bothering with a one time pad. The security, they say, can be
   monitored by randomly checking the channel to see whether any of the
   qubits are being lost (potentially to Eve).
   The security of the channel then depends on how much loss of
   information Alice and Bob are willing to accept, but can always be
   improved by checking more often for eavesdroppers.
   Quantum direct communication, as the team call it, looks interesting.
   But it will be demanding to implement, not least because any noise in
   the channel will look like an eavesdropper. So it looks as if this
   idea will have to be limited to short range applications where noise
   can be kept to a minimum.
   Nevertheless, a cool idea.
   Ref: [5]arxiv.org/abs/0802.0656: Quantum Direct Communication with
   Continuous Variables
   [6][ISMAP:i]    [7][arXivblog?d=41] [8][arXivblog?d=43] [9][arXivblog?i=FkCcdrzA]
   [10][arXivblog?d=50] [11][arXivblog?i=AA6d3u4X] [12][arXivblog?d=54]
   [13][arXivblog?i=gWxiPcYK] [14][arXivblog?d=52]    You are subscribed to email updates from [15]the physics arXiv blog
   To stop receiving these emails, you may [16]unsubscribe now. Email
   delivery powered by Google
   Inbox too full? [17](feed) [18]Subscribe to the feed version of the
   physics arXiv blog in a feed reader.
   If you prefer to unsubscribe via postal mail, write to: the physics
   arXiv blog, c/o Google, 20 W Kinzie, Chicago IL USA 60610
   1.    2.    3.    4.    5.    6.    7.    8.    9.   10.   11.   12.   13.   14.   15.   16.   17.   18.

@_date: 2008-07-10 18:10:27
@_author: Eugen Leitl 
@_subject: how bad is IPETEE? 
In case somebody missed it, I'm not sure what the status of is, the mailing list traffic dried up a while back.

@_date: 2008-06-21 15:11:26
@_author: Eugen Leitl 
@_subject: [Beowulf] Re:  "hobbyists" 
Organization: Bio-X / Clark Center - Stanford University
I think that's a wise decision. Skype is a giant black box. Fabrice Desclaux published a fair amount of cryptanalysis papers about Skype, each one more frightening than the previous ([1], [2] and [3])
In 2005, an official recommendation has been issued by the French authorities to prohibit usage of Skype in the National Center for Scientific Research (CNRS)'s networks (see [4], and [5] for the machine-translated version)

@_date: 2008-10-24 15:50:10
@_author: Eugen Leitl 
@_subject: 26 historic Enigmas found in Spain 
Spanish discover cache of 26 Enigma machines
Franco's 'secret weapon' tracked to army HQ
By Lester Haines Posted in Science, 24th October 2008 10:03 GMT
Spanish newspaper El Pa?s last week tracked down 26 examples of Franco's
"secret weapon" against Republican forces in the country's civil war - a
cache of perfectly-preserved Enigma machines hidden for years in a "gloomy
office" in the army's main headquarters in Madrid.
Nationalist forces led by Franco acquired their first ten Enigma machines
from Germany in 1936. While Hitler "had already decided to offer Franco his
full support" in the Spanish civil war, this didn't actually extend to the
full-fat military versions of Enigma, and his Iberian ally had to make do
with the "vastly inferior" commercial "D" model.
The German High Command was apparently concerned that careless Spaniards
might let the Republicans get their hands on an Enigma. Indeed, even
Germany's Condor Legion - dispatched to Spain to aid the Nationalist cause -
also reportedly used commercial Enigmas in the field.
Nonetheless, the Republicans were never able to decipher Enigma
communications between Franco and his top brass, and the machines' success
led to further acquisitions. Commander Antonio Sarmiento, charged with
training operators in Franco's Salamanca headquarters, enthusiastically
reported in 1936: ?To give some idea of the level of security these machines
offer, it's suffice to say that the number of possible combinations is an
astounding 1,252,962,387,456.?
The total number of machines eventually bought by Spain is unknown, although
estimates vary from 30 to 50. They were not withdrawn from service until the
early 1950s, which offers the rather agreeable possibility that the British
were able to read the Spanish dictatorship's military communications while
Franco remained blissfully unaware that his Nazi sponsors' device had been
laid bare by Bletchley Park years before. El Reg is, of course, supporting Bletchley Park and the National Museum of
Computing with our splendid Enigma t-shirt. Get it before Cash'n'Carrion's
free shipping offer ends on 31 October.

@_date: 2008-10-29 18:24:13
@_author: Eugen Leitl 
@_subject: the skein hash function 
October 29, 2008
The Skein Hash Function
NIST is holding a competition to replace the SHA family of hash functions,
which have been increasingly under attack. (I wrote about an early NIST hash
workshop here.)
Skein is our submission (myself and seven others: Niels Ferguson, Stefan
Lucks, Doug Whiting, Mihir Bellare, Tadayoshi Kohno, Jon Callas, and Jesse
Walker). Here's the paper:
    Executive Summary
    Skein is a new family of cryptographic hash functions. Its design
combines speed, security, simplicity, and a great deal of flexibility in a
modular package that is easy to analyze.
    Skein is fast. Skein-512 -- our primary proposal -- hashes data at 6.1
clock cycles per byte on a 64-bit CPU. This means that on a 3.1 GHz x64 Core
2 Duo CPU, Skein hashes data at 500 MBytes/second per core -- almost twice as
fast as SHA-512 and three times faster than SHA-256. An optional hash-tree
mode speeds up parallelizable implementations even more. Skein is fast for
short messages, too; Skein-512 hashes short messages in about 1000 clock
    Skein is secure. Its conservative design is based on the Threefish block
cipher. Our current best attack on Threefish-512 is on 25 of 72 rounds, for a
safety factor of 2.9. For comparison, at a similar stage in the
standardization process, the AES encryption algorithm had an attack on 6 of
10 rounds, for a safety factor of only 1.7. Additionally, Skein has a number
of provably secure properties, greatly increasing confidence in the
    Skein is simple. Using only three primitive operations, the Skein
compression function can be easily understood and remembered. The rest of the
algorithm is a straightforward iteration of this function.
    Skein is flexible. Skein is defined for three different internal state
sizes -- 256 bits, 512 bits, and 1024 bits -- and any output size. This
allows Skein to be a drop-in replacement for the entire SHA family of hash
functions. A completely optional and extendable argument system makes Skein
an efficient tool to use for a very large number of functions: a PRNG, a
stream cipher, a key derivation function, authentication without the overhead
of HMAC, and a personalization capability. All these features can be
implemented with very low overhead. Together with the Threefish large-block
cipher at Skein core, this design provides a full set of symmetric
cryptographic primitives suitable for most modern applications.
    Skein is efficient on a variety of platforms, both hardware and software.
Skein-512 can be implemented in about 200 bytes of state. Small devices, such
as 8-bit smart cards, can implement Skein-256 using about 100 bytes of
memory. Larger devices can implement the larger versions of Skein to achieve
faster speeds.
    Skein was designed by a team of highly experienced cryptographic experts
from academia and industry, with expertise in cryptography, security
analysis, software, chip design, and implementation of real-world
cryptographic systems. This breadth of knowledge allowed them to create a
balanced design that works well in all environments.
Here's source code, text vectors, and the like for Skein. Watch the Skein
website for any updates -- new code, new results, new implementations, the
NIST's deadline is Friday. It seems as if everyone -- including many amateurs

@_date: 2009-04-30 13:56:38
@_author: Eugen Leitl 
@_subject: [tahoe-dev] SHA-1 broken! (was: Request for hash-dependency in Tahoe security.) 
Reply-To: tahoe-dev at allmydata.org
Wow!  These slides say that they discovered a way to find collisions  in SHA-1 at a cost of only 2^52 computations.  If this turns out to  be right (and the authors are respected cryptographers -- the kind of  people who really hate to be wrong about something like this) then it  is very exciting!  SHA-1 was already known to be vulnerable to attack  by a moderately well-funded organization such as a national security  agency, national military, corporation, or organized criminal group.   Now it turns out that finding SHA-1 collisions is in the reach of a  dedicated hobbyist or an eccentric genius [1].  Let's put a rough  number on it.  I might be a little bit off, but you can build a  COPACOBANA machine for about $10,000 [2], and it can brute-force a 56- bit DES key in about six and a half days.  2^52 SHA-1 operations  should take roughly the same amount of time and money.  As another  example I guess that distributed computation engines [3] and botnets  [4] might be able to generate a SHA-1 collision in seconds.
Plus of course the amplifying effects of birthday attacks and rainbow  tables and so on mean that the longer you keep your COPACOBANA or  your botnet generating SHA-1 collisions, the more SHA-1 users around  the world become vulnerable to you. So basically, if these slides are  right then relying on SHA-1 collision-resistance has been revealed as  a major vulnerability!
Almost all hash functions in civilian, open use are either MD5 or  SHA-1.  For example, decentralized revision control tools such as  monotone, git, and hg rely on SHA-1.  Interesting times!
As Shawn already correctly pointed out (and as Nathan probably  already knew), Tahoe doesn't use SHA-1, so we're not affected by this  new discovery.  Tahoe-LAFS uses SHA-256 (in the "double-hashing" mode  suggested by Ferguson and Schneier and named "SHA-256d").  We also  add our own tagging and salting prefix to avoid certain problems.  We  aren't currently vulnerable to hash collision attacks, and we plan  never to get into that position (about which more below).
Nonetheless, it would be a very good exercise to spell out what sorts  of problems could result if attackers could violate what sorts of  properties of the hash function(s) used in Tahoe.  The basic uses of  secure hashes in Tahoe are for integrity-checking of immutable files  and for digital signatures on mutable files and directories.
If an attacker could generate two different inputs which yielded the  same hash output (that is, to find a "hash collision"), then they  could give you a single immutable file cap that produced two (or  more) different files when you used it to download the file.  We  believe that nobody is currently able to do that, so currently if  someone gives you an immutable file cap, you can rely on there being  at most one file which can be downloaded using that cap.
For mutable files it is even safer.  If an attacker could find an  input which yielded the same output as someone *else*'s input (that  is, to find a "second pre-image"), then that attacker could write  changes to a mutable file or directory that they were not authorized  to write to.  Finding a second pre-image is probably much harder than  finding a collision -- for example nobody has yet figured out how to  find a second pre-image in SHA-1.  That's why I say it is even  safer.  You already assume that the person who can write to a mutable  file can make it so that two or more different file contents would be  downloaded from using the same mutable-file read cap, but for  immutable files we hold them to a higher standard and prevent even  the original uploader of the immutable file from being able to make  more than one file that matches the immutable-file read cap.
There are a lot more details of how Tahoe uses hash functions that I  would be happy to work out when I have time, but those are the most  important ones, and the immutable file caps are the most likely to  turn out to be vulnerable.  (Although, as I've said, even the  immutable file caps are extremely unlikely to be vulnerable.)
(Hm, this puts an interesting twist on Vincent and Nathan's idea of  layering Mercurial-or-Bazaar on top of Tahoe.  Tahoe uses stronger  cryptography (and also more flexible cryptography, by the way), so if  you have uploaded your Mercurial repository to Tahoe then even when  SHA-1 turns out to be weak (as it has), you can still rely on the  integrity of your repository.)
Sure -- a Merkle Tree has collision-resistance if the underlying hash  has collision-resistance, and a Merkle Tree has second-preimage- resistance if the underlying hash has second-preimage resistance.  So  if the underlying has doesn't have collision-resistance but does have  second-preimage-resistance (as we currently suspect that SHA-1  might), then your Merkle Tree would stil have second-preimage- resistance.  Also a Merkle Tree might be stronger than its underlying  hash function in a few ways, even if the underlying hash is somewhat  It is certainly possible to preserve all the data.
The obvious way is to download your files and re-upload them in the  new format.  I suspect that will probably end up being the best way,  too.  I would like to emphasize that it is extremely unlikely that  anyone will need to do this due to a weakness in the hashing  algorithm in Tahoe in a hurry.  The people who are suffering from the  collisions in MD5 and SHA-1 are suffering, not because MD5 or SHA-1  were suddenly revealed to be insecure, but because they ignored the  warning messages from cryptographers for many years.  (I'm a tad  irritated about this, since "I tried to tell them" [5] and "They  wouldn't listen!" [6].)
By the time that SHA-256 (plus our tagging and salting) is vulnerable  to collisions, which could be anywhere from five years to a hundred  years from now, we will have already upgraded Tahoe to use a stronger  hash function (SHA-3 or a SHA-3 candidate) and gracefully upgraded  pre-existing files.
Now the actual details of securely upgrading extant files to new  integrity check mechanisms could be interesting.  We've thought a bit  about how to facilitate future graceful upgrades and this will no  doubt prompt us to think about it some more.  The stickiest bits are  in the capability itself.  Let's put it this way: suppose you upload  a file to a Tahoe grid today and get an immutable read cap in  return.  Then suppose a few years from now someone does some  unspecified operation which adds stronger hashes to the file as it  exists out there on the servers.  Now, how do you as the holder of  the original immutable read cap know that those new stronger hashes  are correct?  You don't, because your read-cap wasn't generated from  those new stronger hashes.  This isn't a weakness in the Tahoe  capability-oriented design, it's more of a fundamental problem which  is just thrown into sharper light by the cap design.  You can, of  course, choose to delegate your decision about whether or not the  file is correct to someone else (using Tahoe as well as using any  other scheme), but if you want to actually have certainty *yourself*  that the file is correct using the new hashes, then you're going to  have to do some sort of download and computation on the file  yourself, using the new hash algorithm.
[1] [2] [3] [4] [5] [6] tahoe-dev mailing list
tahoe-dev at allmydata.org

@_date: 2009-04-22 11:56:53
@_author: Eugen Leitl 
@_subject: Mission Impossible: The Code Even the CIA Can't Crack 
Mission Impossible: The Code Even the CIA Can't Crack
By Steven Levy Email 04.20.09
The sculpture named Kryptos at CIA headquarters contains a secret message ?
but not even the agency's brightest can crack its code.
Photo: Adrian Gaut
The most celebrated inscription at the Central Intelligence Agency's
headquarters in Langley, Virginia, used to be the biblical phrase chiseled
into marble in the main lobby: "And ye shall know the truth, and the truth
shall make you free." But in recent years, another text has been the subject
of intense scrutiny inside the Company and out: 865 characters of seeming
gibberish, punched out of half-inch-thick copper in a courtyard.
It's part of a sculpture called Kryptos, created by DC artist James Sanborn.
He got the commission in 1988, when the CIA was constructing a new building
behind its original headquarters. The agency wanted an outdoor installation
for the area between the two buildings, so a solicitation went out for a
piece of public art that the general public would never see. Sanborn named
his proposal after the Greek word for hidden. The work is a meditation on the
nature of secrecy and the elusiveness of truth, its message written entirely
in code.
Almost 20 years after its dedication, the text has yet to be fully
deciphered. A bleary-eyed global community of self-styled cryptanalysts?along
with some of the agency's own staffers?has seen three of its four sections
solved, revealing evocative prose that only makes the puzzle more confusing.
Still uncracked are the 97 characters of the fourth part (known as K4 in
Kryptos-speak). And the longer the deadlock continues, the crazier people
Whether or not our top spooks intended it, the persistent opaqueness of
Kryptos subversively embodies the nature of the CIA itself?and serves as a
reminder of why secrecy and subterfuge so fascinate us. "The whole thing is
about the power of secrecy," Sanborn tells me when I visit his studio, a
barnlike structure on Jimmy Island in Chesapeake Bay (population: 2). He is
6'7", bearded, and looks a bit younger than his 63 years. Looming behind him
is his latest work in progress, a 28-foot-high re-creation of the world's
first particle accelerator, surrounded by some of the original hardware from
the Manhattan Project. The atomic gear fits nicely with the thrust of
Sanborn's oeuvre, which centers on what he calls invisible forces.
With Kryptos, Sanborn has made his strongest statement about what we don't
see and can't know. "He designed a piece that would resonate with this
workforce in particular," says Toni Hiley, who curates the employees-only CIA
museum. Sanborn's ambitious work includes the 9-foot 11-inch-high main
sculpture?an S-shaped wave of copper with cut-out letters, anchored by an
11-foot column of petrified wood?and huge pieces of granite abutting a low
fountain. And although most of the installation resides in a space near the
CIA cafeteria, where analysts and spies can enjoy it when they eat outside,
Kryptos extends beyond the courtyard to the other side of the new building.
There, copper plates near the entrance bear snippets of Morse code, and a
naturally magnetized lodestone sits by a compass rose etched in granite.
"People call me an agent of Satan," says artist Sanborn, "because I won't
tell my secret."
Photo: Adrian Gaut
The heart of the piece, though, is the encrypted text, scrambled, Sanborn
says, by "a coding system that would unravel itself slowly over a period of
When he began the work, Sanborn knew very little about cryptography, so he
reluctantly accepted the CIA's offer to work with Ed Scheidt, who had just
retired as head of Langley's Cryptographic Center. Scheidt himself was
serving two masters. "I was reminded of my need to preserve the agency's
secrets," Scheidt says. "You know, don't tell him the current way of doing
business. And don't create something that you cannot break?but at the same
time, make it something that will last a while."
Scheidt schooled Sanborn in cryptographic techniques employed from the late
19th century until World War II, when field agents had to use pencil and
paper to encode and decode their messages. (These days, of course,
cryptography is all about rugged computer algorithms using long mathematical
keys.) After experimenting with a range of techniques, including
poly-alphabetic substitution, shifting matrices, and transposition, the two
arrived at a form of old-school, artisanal cryptography that they felt would
hold off code breakers long enough to generate some suspense. The solutions,
however, were Sanborn's alone, and he did not share them with Scheidt. "I
assumed the first three sections would be deciphered in a matter of weeks,
perhaps months," Sanborn says. Scheidt figured the whole puzzle would be
solved in less than seven years.
During the two years of construction, there were moments of intrigue and
paranoia, in keeping with the subject matter and the client. "We had to play
a little on the clandestine side," says Scheidt, who talks of unnamed
observers outside armed with long-range cameras and high-intensity
microphones. "We had people with ladders climbing up the walls of my studio
trying to photograph inside," Sanborn says. He came to believe that factions
within the CIA wanted to kill the project. There were unexplained obstacles.
For instance, he says, "one day a big truckload of stone for the courtyard
disappeared. Never found. I saw it in the evening, went back in the morning,
and it had vanished. Nobody would tell me what happened to it."
Sanborn finished the sculpture in time for a November 1990 dedication. The
agency released the enciphered text, and a frenzy erupted in the crypto world
as some of the best?and wackiest?cryptanalytic talent set to work. But it
took them more than seven years, not the few months Sanborn had expected, to
crack sections K1, K2, and K3. The first code breaker, a CIA employee named
David Stein, spent 400 hours working by hand on his own time. Stein, who
described the emergence of the first passage as a religious experience,
revealed his partial solution to a packed auditorium at Langley in February
1998. But not a word was leaked to the press. Sixteen months later, Jim
Gillogly, an LA-area cryptanalyst used a Pentium II computer and some custom
software to crack the same three sections. When news of Gillogly's success
broke, the CIA publicized Stein's earlier crack.
James Sanborn buried his sculpture's message so deeply that a CIA staffer
took seven years to solve just the first three sections. Here's what we know.
The first section, K1, uses a modified Vigen?re cipher. It's encrypted
through substitution?each letter corresponds to another?and can be solved
only with the alphabetic rows of letters on the right. The keywords, which
help determine the substitutions, are KRYPTOS and PALIMPSEST. A
misspelling?in this case IQLUSION?may be a clue to cracking K4.
K2, like the first section, was also encrypted using the alphabets on the
right. One new trick Sanborn used, though, was to insert an X between some
sentences, making it harder to crack the code by tabulating letter frequency.
The keywords here are KRYPTOS and ABSCISSA. And there's another intriguing
misspelling: UNDERGRUUND.
A different cryptographic technique was used for K3: transposition. All the
letters are jumbled and can be deciphered only by uncovering the complex
matrices and mathematics that determined their misplacement. Of course, there
is a misspelling (DESPARATLY), and the last sentence (CAN YOU SEE ANYTHING?)
is strangely bracketed by an X and a Q.
Sanborn intentionally made K4 much harder to crack, hinting that the
plaintext itself is not standard English and would require a second level of
cryptanalysis. Misspellings and other anomalies in previous sections may
help. Some suspect that clues are present in other parts of the installation:
the Morse code, the compass rose, or perhaps the adjacent fountain.
But if anyone expected that solving the first three sections would lead to a
quick resolution of the whole puzzle, their hopes were soon dashed. The
partial solutions only deepened the Gillogly turned up that passage, he says,
he had "the same excitement and exultation that Carter described. In a way,
it seems that the plaintext is a metaphor for the work of the code breaker,
or perhaps of the CIA itself."
The 97 characters of K4 remain impenetrable. They have become, as one
would-be cracker calls it, the Everest of codes. Both Scheidt and Sanborn
confirm that they intended the final segment to be the biggest challenge.
There are endless theories about how to solve it. Is access to the sculpture
required? Is the Morse code a clue? Every aspect of the project has come
under electron-microscopic scrutiny, as thousands of people?hardcore
cryptographers and amateur code breakers alike?have taken a whack at it. Some
have gone off the deep end: A Michigan man abandoned his computer-software
business to do construction so he'd have more time to work on it. Thirteen
hundred members of a fanatical Yahoo group try to move the ball forward with
everything from complex math to astrology. One typical Kryptos maniac is
Randy Thompson, a 43-year-old physicist who has devoted three years to the
problem. "I think I'm onto the solution," he says. "It could happen tomorrow,
or it could take the rest of my life." Meanwhile, some of the seekers are
getting tired. "I just want to see it solved," says Elonka Dunin, a
50-year-old St. Louis game developer who runs a clearinghouse site for
Kryptos information and gossip. "I want it off my plate."
Making the effort more complicated is the fact that the puzzle maker is alive
and, in theory at least, a potential resource. For years, there has been a
delicate pas de deux between the artist and the rabid Kryptos community.
Every word Sanborn utters is eagerly examined for hints. But they also have
to wonder whether he's trying to help them or throw them off track. Scheidt
says that this process parallels the work of the CIA: "The intelligence
picture includes mirrors and obfuscation." Photo: Adrian Gaut
"It's not my intent to put out disinformation," Sanborn says. "I'm a
benevolent cryptographer." Some think otherwise, and Sanborn occasionally
receives messages from people enraged that he knows the secret and they
don't. "It's the fact that I have some sort of power," he says. "You get
stalkers. I don't know how they get my cell numbers and everything off the
Internet, but they do. People have called me and said pretty terrible things.
There are some who say I'm an agent of Satan because I have a secret I won't
Though Sanborn's usual practice is to stay in the background, every so often
he feels obliged to comment. In 2005, he refuted author Dan Brown's claim
that the "WW" in the plaintext of K3 could be inverted to "MM," implying Mary
Magdalene. (Brown included pieces of Kryptos on the book jacket of The Da
Vinci Code and has hinted that his next novel will draw on the CIA sculpture,
a prospect that deeply annoys Sanborn.)
Intentional or not, Sanborn's comments (or lack thereof) seem to generate an
added layer of confusion. Even a straightforward question, like who besides
him knows the solution, opens up new wormholes. The official story is that
Sanborn shared the answer with only one person, the CIA director at the time,
William Webster. Indeed, the decoded K3 text reads in part, "Who knowshat it
says." What does the CIA make of all this? "When it comes to the solution,"
says spokesperson Marie Harf, "those who need to know, know."
If anyone manages to solve the last cipher, that won't end the hunt for the
ultimate truth about Kryptos. "There may be more to the puzzle than what you
see," Scheidt says. "Just because you broke it doesn't mean you have the
answer." All of this leads one to ask: Is there a solution? Sanborn insists
there is?but he would be just as happy if no one ever discovered it. "In some
ways, I'd rather die knowing it wasn't cracked," he says. "Once an artwork
loses its mystery, it's lost a lot."
The day I visited Kryptos, a rare snowstorm in Virginia had blanketed the
courtyard in white. I circled the sculpture carefully, marveling at the way
the colors and texture of the surrounding landscape affected the panels, as
some character strings became highlighted in white and other phrases
shimmered, reflecting the dull light bouncing off the windows. I examined all
the pieces, brushing aside the snow to uncover the Morse code and the compass
rose. It was like unearthing hieroglyphs in some ancient ruin. Agents and
bureaucrats shuffled past, deep in thought, clutching cups of coffee from the
onsite Starbucks. In their midst, Jim Sanborn's statement in copper, wood,
and granite remains, proof that even in the house of spies, some truths may
never be found.
Senior writer Steven Levy (steven_levy at wired.com) wrote about the 20th
anniversary of the Mac in issue 17.01.

@_date: 2009-01-15 18:10:47
@_author: Eugen Leitl 
@_subject: [Opensim-dev] Technical assessment of Cable Beach asset server 
Reply-To: opensim-dev at lists.berlios.de
Eugen Leitl kirjoitti:
that has been my understanding as well. basically after worked a bit with the guys who pushed it in the Fenfire project (in 2002).
i've understood that basically by using URIs as references to assets we get that: URLs for current http stuff and location independent URNs with distributed things like p2p networks. seems that Tahoe also uses "short URI-like strings" - dunno why 'URI-like' and not just URIs but anyway :) .. also as SL and OpenSim already uses UUIDs i guess some things are basically kind of ready for this.
 is about the work in that area i was interested back long ago, dunno about the current implementations whether Tapestry, that Tahoe or something I haven't heard of is the thing, but i guess the basic idea is the same. in that Fenfire Storm the idea was to use content based hashes as IDs of files (like images), similar to Freenode -- the goal not being anonymous publishing in a secure p2p net, but instead having a nice storage system for both local own files and publishing them on the net. goals included the secure storage via redundancy, that seems to be emphasized in Tahoe and is indeed a great motivation for these things.
looking forward to learning more, perhaps by testing Tahoe
Opensim-dev mailing list
Opensim-dev at lists.berlios.de

@_date: 2009-06-04 19:00:00
@_author: Eugen Leitl 
@_subject: Tellitec Tellinet Sat Spy manual leaked 
Tellitec Tellinet Sat Spy manual, 6 Mar 2006
May 24, 2009
Tellinet is an accelerator for satellite communications made by Tellitec GmbH of Berlin. It supports encrypted TCP (ETCP), but as this confidential manual shows, it also supports covert remote interception of communications data.
DOWNLOAD/VIEW FULL FILE FROM
    fast site, current site, Sweden, US, Latvia, Slovakia, UK, Finland, Netherlands, Poland, Tonga, Europe, SSL, Tor     Germany Primary language
File size in bytes
File type information
PDF document, version 1.3
Cryptographic identity
SHA256 c1ac645e16624815e9ef75dd3d959b1b681e82b68a5261a4cea3c7a6f251370b

@_date: 2009-06-24 21:26:23
@_author: Eugen Leitl 
@_subject: [btns] IETF75 
I can has contributions, please?
    Eugen> On Wed, Jun 24, 2009 at 03:15:59PM +0200, Julien Laganier
    >> We're currently progressing connexion latching thru IESG.
    >>     >> What remains to be done for the WG is to complete the API work
    >> item.  Since those haven't been discussed much on the mailing
    >> list we felt that a meeting wouldn't be productive.
    Eugen> How far is the proposed standard from being able to hit the
    Eugen> road?  I realize "it's done when it's done" but are we
    Eugen> looking at months, years, half a decade until there's a first
    Eugen> implementation available to beta testers?
  Read the document and comment.
  The API documents are stuck for lack of contributions.

@_date: 2009-10-27 17:19:42
@_author: Eugen Leitl 
@_subject: Old Trick Threatens the Newest Weapons  
Old Trick Threatens the Newest Weapons
By JOHN MARKOFF
Published: October 26, 2009
Despite a six-year effort to build trusted computer chips for military
systems, the Pentagon now manufactures in secure facilities run by American
companies only about 2 percent of the more than $3.5 billion of integrated
circuits bought annually for use in military gear.
That shortfall is viewed with concern by current and former United States
military and intelligence agency executives who argue that the menace of
so-called Trojan horses hidden in equipment circuitry is among the most
severe threats the nation faces in the event of a war in which communications
and weaponry rely on computer technology.
As advanced systems like aircraft, missiles and radars have become dependent
on their computing capabilities, the specter of subversion causing weapons to
fail in times of crisis, or secretly corrupting crucial data, has come to
haunt military planners. The problem has grown more severe as most American
semiconductor manufacturing plants have moved offshore.
Only one-fifth of all computer chips are now made in the United States, and
just one-quarter of the chips based on the most advanced technologies are
built here, I.B.M. executives say. That has led the Pentagon and the National
Security Agency to expand significantly the number of American plants
authorized to manufacture chips for the Pentagon s Trusted Foundry program.
Despite the increases, semiconductor industry executives and Pentagon
officials say, the United States lacks the ability to fulfill the capacity
requirements needed to manufacture computer chips for classified systems.
 The department is aware that there are risks to using commercial technology
in general and that there are greater risks to using globally sourced
technology,  said Robert Lentz, who before his retirement last month was in
charge of the Trusted Foundry program as the deputy assistant defense
secretary for cyber, identity and information assurance.
Counterfeit computer hardware, largely manufactured in Asian factories, is
viewed as a significant problem by private corporations and military
planners. A recent White House review noted that there had been several
 unambiguous, deliberate subversions  of computer hardware.
 These are not hypothetical threats,  the report s author, Melissa Hathaway,
said in an e-mail message.  We have witnessed countless intrusions that have
allowed criminals to steal hundreds of millions of dollars and allowed
nation-states and others to steal intellectual property and sensitive
military information. Ms. Hathaway declined to offer specifics.
Cyberwarfare analysts argue that while most computer security efforts have
until now been focused on software, tampering with hardware circuitry may
ultimately be an equally dangerous threat. That is because modern computer
chips routinely comprise hundreds of millions, or even billions, of
transistors. The increasing complexity means that subtle modifications in
manufacturing or in the design of chips will be virtually impossible to
 Compromised hardware is, almost literally, a time bomb, because the
corruption occurs well before the attack,  Wesley K. Clark, a retired Army
general, wrote in an article in Foreign Affairs magazine that warns of the
risks the nation faces from insecure computer hardware.
 Maliciously tampered integrated circuits cannot be patched,  General Clark
wrote.  They are the ultimate sleeper cell. Indeed, in cyberwarfare, the most ancient strategy is also the most modern.
Internet software programs known as Trojan horses have become a tool of
choice for computer criminals who sneak malicious software into computers by
putting it in seemingly innocuous programs. They then pilfer information and
transform Internet-connected PCs into slave machines. With hardware, the
strategy is an even more subtle form of sabotage, building a chip with a
hidden flaw or a means for adversaries to make it crash when wanted.
Pentagon executives defend the manufacturing strategy, which is largely based
on a 10-year contract with a secure I.B.M. chipmaking plant in Burlington,
Vt., reported to be valued as high as $600 million, and a certification
process that has been extended to 28 American chipmakers and related
technology firms.
 The department has a comprehensive risk-management strategy that addresses a
variety of risks in different ways,  said Mitchell Komaroff, the director of
a Pentagon program intended to develop a strategy to minimize national
security risks in the face of the computer industry s globalization.
Mr. Komaroff pointed to advanced chip technologies that made it possible to
buy standard hardware components that could be securely programmed after they
were acquired.
But as military planners have come to view cyberspace as an impending
battlefield, American intelligence agency experts said, all sides are arming
themselves with the ability to create hardware Trojan horses and to hide them
deep inside the circuitry of computer hardware and electronic devices to
facilitate military attacks.
In the future, and possibly already hidden in existing weapons, clandestine
additions to electronic circuitry could open secret back doors that would let
the makers in when the users were depending on the technology to function.
Hidden kill switches could be included to make it possible to disable
computer-controlled military equipment from a distance. Such switches could
be used by an adversary or as a safeguard if the technology fell into enemy
A Trojan horse kill switch may already have been used. A 2007 Israeli Air
Force attack on a suspected partly constructed Syrian nuclear reactor led to
speculation about why the Syrian air defense system did not respond to the
Israeli aircraft. Accounts of the event initially indicated that
sophisticated jamming technology was used to blind the radars. Last December,
however, a report in an American technical publication, IEEE Spectrum, cited
a European industry source in raising the possibility that the Israelis might
have used a built-in kill switch to shut down the radars.
Separately, an American semiconductor industry executive said in an interview
that he had direct knowledge of the operation and that the technology for
disabling the radars was supplied by Americans to the Israeli electronic
intelligence agency, Unit 8200.
The disabling technology was given informally but with the knowledge of the
American government, said the executive, who spoke on the condition of
anonymity. His claim could not be independently verified, and American
military, intelligence and contractors with classified clearance declined to
discuss the attack.
The United States has used a variety of Trojan horses, according to various
In 2004, Thomas C. Reed, an Air Force secretary in the Reagan administration,
wrote that the United States had successfully inserted a software Trojan
horse into computing equipment that the Soviet Union had bought from Canadian
suppliers. Used to control a Trans-Siberian gas pipeline, the doctored
software failed, leading to a spectacular explosion in 1982.
Crypto AG, a Swiss maker of cryptographic equipment, was the subject of
intense international speculation during the 1980s when, after the Reagan
administration took diplomatic actions in Iran and Libya, it was widely
reported in the European press that the National Security Agency had access
to a hardware back door in the company s encryption machines that made it
possible to read electronic messages transmitted by many governments.
According to a former federal prosecutor, who declined to be identified
because of his involvement in the operation, during the early  80s the
Justice Department, with the assistance of an American intelligence agency,
also modified the hardware of a Digital Equipment Corporation computer to
ensure that the machine   being shipped through Canada to Russia   would work
erratically and could be disabled remotely.
The American government began making a concerted effort to protect against
hardware tampering in 2003, when Deputy Defense Secretary Paul D. Wolfowitz
circulated a memorandum calling on the military to ensure the economic
viability of domestic chipmakers.
In 2005, the Defense Science Advisory Board issued a report warning of the
risks of foreign-made computer chips and calling on the Defense Department to
create a policy intended to stem the erosion of American semiconductor
manufacturing capacity.
Former Pentagon officials said the United States had not yet adequately
addressed the problem.
 The more we looked at this problem the more concerned we were,  said Linton
Wells II, formerly the principal deputy assistant defense secretary for
networks and information integration.  Frankly, we have no systematic process
for addressing these problems.

@_date: 2009-10-29 14:24:54
@_author: Eugen Leitl 
@_subject: AES-CBC + Elephant diffuser 
"We discuss why no existing cipher satisfies the requirements of this
application". Uh-oh.
AES-CBC + Elephant diffuser
Brief Description
A Disk Encryption Algorithm for Windows Vista
The specifications of the AES-CBC + diffuser algorithm used in BitLocker
Drive Encryption
The Bitlocker Drive Encryption feature of Windows Vista poses an interesting
set of security and performance requirements on the encryption algorithm used
for the disk data. We discuss why no existing cipher satisfies the
requirements of this application and document our solution which consists of
using AES in CBC mode with a dedicated diffuser to improve the security
against manipulation attacks.

@_date: 2009-10-29 15:25:40
@_author: Eugen Leitl 
@_subject: AES-CBC + Elephant diffuser 
Ah, should have spent a few seconds looking him up

@_date: 2009-09-10 10:49:01
@_author: Eugen Leitl 
@_subject: Serpent close to AES speed thanks to SSE2 
Wed, 09 Sep 2009
Speeding up Serpent: SIMD Edition
The Serpent block cipher was one of the 5 finalists in the AES competition,
and is widely thought to be the most secure of them due to its conservative
design. It was also considered the slowest candidate, which is one major
reason it did not win the AES contest. However, it turns out that on modern
machines one can use SIMD operations to implement Serpent at speeds quite
close to AES.
Serpent uses an interesting bitsliced design with eight 4 bit sboxes which
are computed in parallel using boolean operations on registers. Rather than
splitting up the 32 bit words into nibbles and passing them through table
lookups, a special instruction sequence is used which performs the same
operation using only instructions like AND, OR, XOR, and NOT. Typically these
are done using 32 bit register operations, but it was recently suggested that
SIMD operations such as those available in SSE2 or AltiVec could be used to
encrypt 4 blocks in parallel.
Most cipher modes, such as CBC and OFB, are iterative; after splitting the
plaintext into blocks, the input to the second block depends on the
previously computed ciphertexts. This data dependency means it is impossible
to use a block-parallel implementation in these modes. However some other
modes, including CTR, EAX, and XTS, do not exhibit this data dependency, and
allow for many blocks to be encrypted in parallel. So being able to compute
many encryptions in parallel is only useful for these modes. Fortunately,
CTR, EAX, and XTS are very useful, unpatented, and (in the case of CTR and
XTS) widely standardized modes.
Recently I implemented Serpent using SSE2 intrinsics in the botan
cryptography library. While not quite as fast as AES, it easily boosts
Serpents performance by a factor of over 2.5 on an Intel Core2 processor.
Up until now, botan has used a rather conventional block cipher interface
where only a single block of data (typically 64 or 128 bits) would be
encrypted at a time; processing multiple blocks required calling the function
multiple times, one for each block. However this completely hides any
parallelism from the block cipher implementation. So in the upcoming
development release (1.9.0), botan offers two new interfaces for block
   void encrypt_n(const byte in[], byte out[], u32bit blocks) const;
   void decrypt_n(const byte in[], byte out[], u32bit blocks) const;
which will process many blocks in a single call. In addition some mode
implementations (at this time, ECB and CTR) will batch their inputs into
larger groups. This will not only allow for parallel encryption using SIMD
techniques, it also improves instruction and data cache utilization for all
ciphers. Right now, the modes will batch 8 blocks of data together; it is
unclear if this is sufficient for the best performance, but in any case is
easy to modify by changing a macro value in build.h.
On a 2.4 GHz Intel Core2 with GNU C++ 4.3.3, I got these results:
Algorithm 	1.8.6 (MiB/s) 	1.9.0 (MiB/s) 	Speedup
Serpent/ECB 	42.1 	113.5 	2.7
Serpent/CTR 	39.7 	100.8 	2.5
AES-128/ECB 	112.7 	134.4 	1.2
AES-128/CTR 	99.1 	114.1 	1.15
The AES speedups nicely demonstrate that even without any explicit SIMD
operations, the improved cache utilization can make a pretty big difference.
I also experimented with performing 8 Serpent block operations in parallel,
by interleaving two 4-wide SIMD encryptions. This reduced the number of key
variable loads, as well as offering the processor much more in the way of
independent computations for hot hot superscalar action. On my Core2, this
pushed Serpent's performance north of 160 MiB/s in CTR mode, which is pretty
impressive considering that is right about the speed of OpenSSL's AES-128
implementation on the same platform. However this variant seems slower on
anything but a Core2; tests on an Opteron showed it to be somewhat slower
than 4-way SIMD, and it is highly likely that it would also be much slower on
32-bit x86 processors due to excessive register pressure.
AltiVec looks to be an even more promising platform for multiblock Serpent
encryption, as it includes native rotation instructions, which in SSE2 must
be emulated using two shifts and an OR. It is very likely the Cell processors
SIMD units could also implement Serpent in a SIMD mode. Considering the Cell
SPE contains 128 SIMD registers, it might even be feasible to implement a
variant suggested by Wei Dai of encrypting 128 blocks in parallel without
suffering an excessive number of register spills.

@_date: 2010-04-22 17:35:22
@_author: Eugen Leitl 
@_subject: Quantum Key Distribution: the bad idea that won't die... 
This is interesting. However, even if you can use LoS up to LEO,
the question is of what the added value of a (supposedly, trend
in QC state cloning attacks is there) tamperproof exchange is over traditional cryptography.
I agree with Perry that it solves a non-problem.

@_date: 2010-08-03 17:49:00
@_author: Eugen Leitl 
@_subject: GSM eavesdropping 
Extreme? I don't see why my ISP should be able to inspect and monetize
my data stream.
Encryption is cheap enough (especially if you cache keys from
previous sessions). Why not encrypt everything?

@_date: 2010-07-02 14:19:14
@_author: Eugen Leitl 
@_subject: Intel to also add RNG 
Tuesday, June 29, 2010
Nanoscale Random Number Circuit to Secure Future Chips
Intel unveils a circuit that can pump out truly random numbers at high speed.
By Tom Simonite
It might sound like the last thing you need in a precise piece of hardware,
but engineers at Intel are pretty pleased to have found a way to build a
circuit capable of random behavior into computer processors.
Generating randomness--an unpredictable stream of numbers--is much harder
than you might think. It's also crucial to creating the secure cryptographic
keys needed to keep data safe. Building a random-number-generating ability
into the Central Processing Unit (CPU) at a computer's heart is ideal, says
Ram Krishnamurthy, an engineer at Intel's Microprocessor Technology Labs, in
Hillsboro, OR. It should speed up any process that requires the generation of
an encrypted key, for example securing sensitive data on a hard drive, and
make it harder for an attacker to compromise that encryption.
Building circuitry capable of producing random numbers into a CPU has proved
difficult. "Today random numbers are either generated in software, or in the
chip set outside the microprocessor," explains Krishnamurthy, one of the
Intel researchers on the project.
Neither solution is ideal. Software produces only pseudo random numbers
(given enough computing power, patterns can be found within that randomness).
"If the random numbers are not truly random, for example, if they are biased
in some way, then an adversary has a better chance of guessing/determining
the value," explains mathematician Elaine Barker, at the National Institute
for Standards and Technology (NIST), in Gaithersburg, MD. "In the case of
cryptographic keys, if the adversary can determine the key without an
excessive amount of computing power, then he can breach the confidentiality
of that data."
Installing a source of random numbers outside of a computer's core
microprocessor provides another avenue of opportunity to attackers, says
Krishnamurthy. "You are vulnerable to side channel attacks," he explains,
"there are many ways by which the key can be directly read off of the bus, or
attacks that look at how the power supply varies and look for signatures that
indicate what the key looks like."
Building the circuit into the main processor shuts off that possibility, says
Krishnamurthy, although the barrier to doing that has been practicality. The
best-established methods of generating random numbers use analog circuits
that rely on thermal noise as a source of randomness, and those circuits are
not easily fabricated with the techniques used to make the digital circuits
of a microprocessor. Nor are they easily scaled down to the size of
components on modern chips.
Intel's new circuit has a fully-digital design, making it possible to
incorporate it into the microprocessor die. At the heart of the new design is
a cross-coupled inverter, a combination of two basic circuit components that
is essentially a memory capable of storing a single 1 or 0. This memory,
though, is designed to be unreliable; it can be tipped between its two
possible outputs by the influence of thermal noise from the surrounding
silicon. Since that thermal noise is random, the circuit's output should be,
In reality, though, the influence of fluctuations in voltage and temperature
normal inside a chip could bias that output to be less-than-random, requiring
Krishnamurthy and colleagues to develop additional measures to counteract
their influence. Benchmarks for "true" randomness maintained by NIST were
used to confirm they had been successful. "We exceeded all of those
thresholds," he says. The speed at which the new circuit cranks out
numbers--2.4 billion a second or 2.4Gbps--is also around 200 times faster
than anything before, Krishnamurthy adds.
Having built the circuit with a smallest feature size of 45 nanometers, he
and colleagues are now working toward proving it can be built using 32 and 22
nanometer manufacturing processes with minimal design tweaks.
Passing existing benchmarks of randomness, though, does not mean the new
circuit is perfect. Current techniques do not make it possible to be certain
that any source of randomness is truly random, says Barker. "We just don't
know enough to design tests that catch all the problems, and tests may not
always catch the point at which a noise source starts to go bad if the change
is subtle." Research by groups like that at NIST will generate smarter tests
that help industry engineers raise the bar further.

@_date: 2010-03-05 13:55:11
@_author: Eugen Leitl 
@_subject: Fault-Based Attack of RSA Authentication 
Reply-To: or-talk at freehaven.net
Hi everyone,
I thought this might be of interest to the list.   Pellegrini, Bertacco
and Austin at U of Michigan have found an interesting way to deduce the
secret key by fluctuating a device's power supply.  Its a minimal threat
against servers, but against hand held devices its more practical.  The
openssl people say there's an easy fix by salting.
Here's some referneces:

@_date: 2010-03-25 13:27:36
@_author: Eugen Leitl 
@_subject: [vserver] Bought an entropykey - very happy 
be actively controlled as each junction is different) is a good source of
randomness (up to megabits / sec / junction), "encrypting" it just means
masking possible low entropy. I'd prefer to see raw conditoned stream than
"encrypted" one (even web content looks high-entropy to Diehard when
i have loved the padlock engines on via cores since they hit the
market in C5XL form with a single hw generator available via XSTORE.
unlike many designs this free wheeling resource can provide a torrent
of entropy sufficient to sate even the most gregarious consumption.
as mentioned above, you need a fast user space entropy daemon sanity
checking the raw, (probably) biased stream coming from hardware but it
is still good practice to digest this entropy to obscure any potential
generator state/bias heading into the host entropy pool.
that is to say, of the two common modes for utilizing hw entropy:
a. conservatively sample from a whitened, string filtered entropy
source for a low rate of high quality output (see xstore config words)
b. ramp un-whitened, un-filtered source(s) to maximum rate and AES/SHA
mix for high throughput, high quality output while irreversibly
masking generator bias/state present in the raw source stream.
the latter is more effective in practice and capable of generation
rates > 20Mbps with full FIPS sanity checks. the former tops out
around 1Mbps or less with more transient latency spikes on read (when
successive attempts to read fail to pass whiten+strfilter). note that
padlock engine supports SHA and AES on die as well making these easy
and fast to apply to generator output.
if you are still concerned a more conservative configuration would
estimate entropy density while feeding from raw input stream and add
encrypted/digested product to the host entropy pool with the specified
entropy density estimate adjusted downward to your requirements. (most
OS'es support this)

@_date: 2010-10-01 13:01:09
@_author: Eugen Leitl 
@_subject: [tt] Random numbers created out of nothing 
That QM RNGs are special in comparison to other RNGs, which have been
shipping in mainstream systems (both chipsets and CPUs) for many years.
How about GBit/s, for free?
The claim that QM RNGs produce qualitatively different
entropy than dozens of existing, deployed hardware RNGs.

@_date: 2010-09-27 13:59:58
@_author: Eugen Leitl 
@_subject: Former Stasi Cryptographers Now Develop Technology for NATO 
09/27/2010 11:23 AM
Recruited by West Germany
Former Stasi Cryptographers Now Develop Technology for NATO
By Marcel Rosenbach and Holger Stark
After the fall of the Berlin Wall, the West Germans were desperate to prevent
the Stasi's top codebreakers from falling into the wrong hands. from falling
into the wrong hands and set up a company to hire the East German
cryptographers. Now the former Stasi scientists develop technology used by
Angela Merkel and NATO.
Every morning, while going to his office in Berlin's Adlershof district,
Ralph W. passes a reminder of his own past, a small museum that occupies a
room on the ground floor of the building. The museum could easily double as a
command center run by the class enemy in an old James Bond film. A display of
coding devices from various decades includes the T-310, a green metal machine
roughly the size of a huge refrigerator, which East German officials used to
encode their telex messages.
The device was the pride of the Stasi, the feared East German secret police,
which was W.'s former employer. Today he works as a cryptologist with Rohde &
Schwarz SIT GmbH (SIT), a subsidiary of Rohde & Schwarz, a Munich-based
company specializing in testing equipment, broadcasting and secure
communications. W. and his colleagues encode sensitive information to ensure
that it can only be read or heard by authorized individuals. Their most
important customers are NATO and the German government.
Rohde & Schwarz is something of an unofficial supplier of choice to the
German government. Among other things, the company develops bugproof mobile
phones for official use. Since 2004, its Berlin-based subsidiary SIT, which
specializes in encryption solutions, has been classified as a "security
partner" to the German Interior Ministry, which recently ordered a few
thousand encoding devices for mobile phones, at about ?1,250 ($1,675) apiece.
Even German Chancellor Angela Merkel has used phones equipped with SIT's
encryption technology. In other words, the Stasi's former cryptographers are
now Merkel's cryptographers.
Secret Operation
The transfer of Ralph W. and other cryptologists from the East German
Ministry for State Security, as the Stasi was officially known, to West
Germany was handled both seamlessly and discreetly. West German officials
were determined to make sure that no one would find out about the integration
of East Germany's top cryptologists into the west. The operation was so
secret, in fact, that it has remained unknown to this day.
Only a handful of officials were involved in the operation, which was planned
at the West German Interior Ministry in Bonn. In January 1991, Rohde &
Schwarz SIT GmbH was founded. The company was established primarily to
provide employment for particularly talented Stasi cryptologists that the
Bonn government wanted to keep in key positions.
Ralph W. is one of those specialists. W., who holds a doctorate in
mathematics, signed a declaration of commitment to the Stasi on Sept. 1,
1982. By the end of his time with the Stasi, he was making 22,550 East German
marks a year -- an excellent salary by East German standards. And when he was
promoted to the rank of captain in June 1987, his superior characterized W.
as one of the "most capable comrades in the collective." While with the
Stasi, W. worked in Department XI, which also boasted the name "Central
Cryptology Agency" (ZCO).
Looking for the Top Performers
The story begins during the heady days of the East German revolution in 1990.
Officially, the East German government, under its last communist premier,
Hans Modrow, had established a government committee to dissolve the Ministry
for State Security which reported to the new East German interior minister,
Peter-Michael Diestel. In reality, the West German government was already
playing a key role in particularly sensitive matters. Then-West German
Interior Minister Wolfgang Sch?uble (who is the current German finance
minister) had instructed two senior Interior Ministry officials, Hans Neusel
and Eckart Werthebach, to take care of the most politically sensitive
remnants of the 40-year intelligence war between the two Germanys.
The government of then-Chancellor Helmut Kohl was interested in more than
just the politically explosive material contained in some of the Stasi's
files. It also had its eye on the top performers in the former East German
spy agency. The cryptologists were of particular interest to the Kohl
government, which recognized that experts capable of developing good codes
would also be adept at breaking them. The Stasi cryptologists were proven
experts in both fields.
Documents from the Stasi records department indicate that the one of the
Stasi cryptologists' achievements was to break Vericrypt and Cryptophon
standards that had been used until the 1980s. This meant that they were
capable of decoding encrypted radio transmissions by the two main West German
intelligence agencies -- the Office for the Protection of the Constitution
and the Federal Intelligence Service (BND) -- and the West German border
police. The East Germans even managed to decode the BND's orders to members
of the clandestine "Gladio" group, which was intended to continue
anti-communist operations in the event of a Warsaw Pact invasion of Western
The West German government was determined to prevent these highly trained
East German experts from entering the free market. The idea that specialists
who had spent decades working with West German encryption methods and had
successfully cracked West German intelligence's codes could defect to Middle
Eastern countries like Syria was a nightmare. Until then, the BND had had no
difficulties listening in on intelligence communications in the Middle East,
an ability the potential defection of Stasi experts would likely have
compromised. Bonn also hoped to use their skills to break into regions where
its own agents were making no headway. All of this meant that the Stasi
experts had to be brought on board in the West -- even if it involved
unconventional methods.
Cherrypicking the Stasi's Top Brains
The government officials in Bonn turned to an expert for advice: Otto
Leiberich, a cryptologist and mathematician who had headed the Central Office
for Cryptology, the equivalent of the Stasi's ZCO at the West German BND,
until the mid-1970s. Leiberich's task, after he was brought in as a member of
the secret operation, was to evaluate the professional abilities of the Stasi
experts.  Leiberich still has vivid memories of his first official trip to
the town of Hoppegarten, next to Berlin. One of the East German cryptologists
at the meeting greeted the members of the West German delegation as
"comrades," Leiberich recalls. He was impressed by the East Germans'
expertise, says Leiberich. "They were excellent mathematicians who were not
personally guilty of any misconduct."
Leiberich says he would have liked to hire them, particularly the Stasi's
then "chief decoder," the ZCO department head, Horst M. A gaunt chain-smoker
who wore horn-rimmed glasses, M. was born in 1937 and had earned a degree in
mathematics at East Berlin's Humboldt University. But the West was also
interested in younger people, in the expectation that they would be of
greater value in the nascent computer age.
A Free-Market Solution
Leiberich could have used the extra manpower, especially after 1990, when the
West German Central Office for Cryptology was spun off from the BND and a law
was enacted to form the new Federal Office for Information Security (BSI).
Leiberich, who was named the BSI's first president, headed a team consisting
mainly of former intelligence colleagues.
But Neusel, the senior official from the West German Interior Ministry,
dismissed the idea as too precarious. Firstly, the government had decided not
to integrate former Stasi officials, because of their past activities, into
the bureaucracy of a unified Germany. Additionally, as one person involved in
the operation recalls, concerns about potential traitors gave rise to a
"sacred principle," namely that "no one from the Stasi was to be transferred
to the West German intelligence agenciewith the Stasi for eight years, also
fitted the desired profile, as did his colleagues Wolfgang K. and Volker S.
In total, about a dozen former Stasi employees, most of them mathematicians,
were given the chance to embark on a second cryptology career in
post-reunification Germany.
The federal government provided whatever assistance it could, but only with
the utmost discretion. SIT was initially headquartered in the town of
Gr?nheide in the eastern state of Brandenburg, in a former Stasi children's
'Cosmic Top Secret'
An episode from the 1990s shows how conspiratorially the operation was
handled, even within the West German intelligence community. When the BND
needed a "D-channel filter" -- a precursor to today's firewalls -- to protect
communications networks, it contacted the Federal Office for Information
Security (BSI). But BND officials pricked up their ears when they discovered
that the work was being done by SIT. A private company protecting the
computers of Germany's foreign intelligence agency? Nevertheless, the BND
officials were told that it was "totally OK," and that the BSI would take
responsibility for SIT.
For the parent company Rohde & Schwarz, the former problem child in
Brandenburg soon became a success story. SIT took over the cryptology
division of German engineering giant Siemens, and the company now employs
about 150 mathematicians, engineers and computer scientists at its three
locations. SIT, which proudly refers to itself as the "preferred supplier of
high-security cryptography" for NATO, even includes in its product line
devices classified as "Cosmic Top Secret," NATO's highest secrecy level.
SIT's Elcrodat solution, standard equipment on NATO submarines, frigates and
military helicopters, has provided the company with orders worth millions for
When approached by SPIEGEL, Rohde & Schwarz declined to comment on this
previously unknown part of its company history.
To show its gratitude for the company's efforts, the federal government did
more than just provide it with lucrative contracts. Eckart Werthebach, the
Interior Ministry official, awarded the former managing director of SIT, a
senior Rohde & Schwarz executive originally from West Germany, the Order of
Merit o at Villa Hammerschmidt in Bonn, the former official residence of the
German president.
Translated from the German by Christopher Sultan

@_date: 2013-08-26 22:00:27
@_author: Eugen Leitl 
@_subject: [Cryptography] Email and IM are ideal candidates for mix 
Recently there's a trend for at least somewhat open hardware (Raspberry Pi, other ARM systems, Parallella Epiphany) some of
which contain enough FPGA real estate (sure, we know there are FPGA backdoors, but) so that you could boot up an open
core soft CPU, and even bootstrap your own toolchain from
In principle an FPGA die is regular, and hence more easily
inspectable, but even SoCs can be sampled by reverse-engineering
them from the metal layers. We need open, fully inspectable systems. If proving code, or
at least, auto-generating code from state machines catches on
in open source the number of exploitable vulnerabilities can
be greatly diminished.

@_date: 2013-08-30 11:00:19
@_author: Eugen Leitl 
@_subject: [Cryptography] Keeping backups (was Re: Separating concerns 
This is precisely the use case for Freedombox running Tahoe LAFS.

@_date: 2013-11-24 13:31:04
@_author: Eugen Leitl 
@_subject: [Cryptography] (no subject) 
No need to invoke grannies, all but two of our developers are a lost case when it comes to crypto. And none of them can write
secure code, despite being Ph.Ds.

@_date: 2013-11-25 12:17:31
@_author: Eugen Leitl 
@_subject: [Cryptography] Lawyer: "Are you familiar with public key 
Newegg trial: Crypto legend takes the stand, goes for knockout patent punch
Taking a bet on Whit Diffie, as the trial against "patent troll" TQP wraps up
by Joe Mullin - Nov 25 2013, 6:58am WEST
Whitfield Diffie and Newegg lawyer Alan Albright, outside the federal
courthouse is Marshall, Texas.
Joe Mullin
Newegg?s chief counsel testifies: 30 infringement claims in last 8 years
Newegg on trial: Mystery company TQP rewrites the history of encryption
Newegg on trial, day one: Picking a patent jury
Newegg hurtles toward Texas showdown with famed ?patent troll?
MARSHALL, TX?Newegg's courtroom face-off with patent-licensing giant TQP
Development is nearing its end. TQP has sued hundreds of companies saying it
has patented the common Web encryption scheme of combining SSL with the RC4
cipher. Almost 140 companies have paid TQP a total of more than $45 million.
But online retailer Newegg, which has sworn not to settle with "patent
trolls" like TQP, took the case to a jury.
On Thursday, Newegg's top lawyer Lee Cheng took the stand. He was followed by
a non-infringement expert and three well-known computer scientists who
emphasized the importance of Newegg's "prior art."
Ron Rivest testified, via videotaped deposition, about how he invented the
RC4 cipher while at RSA Security in 1987, two years before the TQP patent
application was filed. Former Microsoft CTO Ray Ozzie described demonstrating
Lotus Notes to Bill Gates in 1988. Alan Eldridge, who worked on the Notes
product, flew down to Marshall in person to describe how he put RC4 in the
Eldridge wasn't paid, as expert witnesses were?he came down to testify
against the Jones patent out of a feeling of "civic responsibility," he said.
He didn't know who the defendants in this case were until he was told. "I
hadn't even heard of New Age until Saturday," said Eldridge at one point, as
laughs were stifled in the courtroom.
On Friday Newegg's star witness, cryptographer Whitfield Diffie, took the
stand. Diffie's goal is to knock out the Jones patent with "clear and
convincing" evidence (which is the standard for invalidating a patent).
Diffie looked the part of the eccentric genius, resplendent with his long
white hair and beard. He spoke with a booming voice but carefully articulated
manner; he was professorial but not overbearing. He could have been the
amiable professor you wish you'd had in college.
TQP's patent, invented alongside Michael Jones' failed modem business, wasn't
much of an invention at all according to Diffie's telling. It was a
pre-Internet patent, describing an old method of encoding data. Internet
security needed "public key" cryptography.
"We've heard a good bit in this courtroom about public key encryption," said
Albright. "Are you familiar with that?
"Yes, I am," said Diffie, in what surely qualified as the biggest
understatement of the trial.
"And how is it that you're familiar with public key encryption?"
"I invented it."
A brief history of public-key crypto
In 1973, Diffie left his work at Stanford's Artificial Intelligence Lab to
travel the country and learn more about cryptography.
"It was kind of a secret field at the time, and the literature was hard to
find," said Diffie. "I was traveling around academic libraries digging up
whatever I could."
The following year, he returned to Stanford and started his work with a
professor there, Martin Hellman.
"I want you to put it in perspective for the court and for the jury," said
Albright. ""What is the problem that you two gentlemen saw, that you were so
worried about?"
The problem was vast, Diffie explained?nothing less than how to keep things
private in a networked world. He recalled a conversation with his wife in
1973, sitting on a New Jersey park bench. "I told her that we were headed
into a world where people would have important, intimate, long-term
relationships with people they had never met face to face," he said. "I was
worried about privacy in that world, and that's why I was working on
At that time, the only encryption happened within "closed systems." IBM could
encrypt information within its own company's networks, and Texas Instruments
could encrypt on theirs. But some kind of courier would have to carry
encryption "keys" to both companies before they could do so.
That was the "key distribution" problem Diffie strove to solve. "It's
arranging to provide keys to two people who have never met before, who
suddenly find themselves with a need to communicate," he explained. "This is
much the way we visit websites these days."
There was one other big need: proving authenticity.
"The receiver of the document can come into court with the signed document
and prove to a judge that the document is legitimate," he said. "That person
can recognize the signature but could not have created the signature."
In spring of 1975, Diffie was "playing house husband" near Stanford, while
his wife worked in San Francisco for British Petroleum. It was then, spending
his afternoons unbothered working on cryptography, when he hit on a solution
that could solve both the key distribution and authenticity puzzles.
Public-key crypto could kill two birds with one stone.
"What I suddenly understood was that you could break the key into two pieces,
and only one piece would have to be secret," said Diffie, speaking excitedly.
"There would be a secret piece and a public piece."
In 1976, he published "New Directions in Cryptography" with Martin Hellman.
The paper's cover sheet was displayed on the screen in court.
"Is it fair to say that the jury is looking at a little bit of history, in
terms of cryptography?" asked Albright.
"You embarrass me," said Diffie. "But yes, I think it's fair."
The world of cryptography was utterly changed. Whereas there were "not more
than a dozen or two" people working on cryptography outside government, "now
there are thousands," Diffie explained.
Jones and Erich Spangenberg, the patent-licensing kingpin who owns TQP, have
claimed that the Jones patent is fundamental to Internet commerce. They've
sued hundreds of companies for infringing it.
Albright made sure the jury got one point clearly: it was Diffie's invention
that ushered in the world of online commerce. "Would it be fair to say we
wouldn't have Internet commerce without this?" asked Albright.
"I think where there's commerce, it will find a way," said Diffie. "But this
has certainly smoothed that way a good deal."
Prior Art: Some software and a good old-fashioned textbook
After describing his history, it was time to take a shot at Jones' patent.
There were two key pieces of prior art. First up was a 1982 textbook called
Cryptography and Data Security by Dorothy Denning.
Denning Albright showed the jury a diagram of a symmetric, "closed"
cryptographic system from that book. "That diagram represents all
cryptographic practice up to a few years earlier [than 1982]," explained
Diffie. It also describes everything in Jones' patent. The "key generator" in
Denning's book corresponded to the "pseudo-random number generator" talked
about in the Jones patent; and every message block is encrypted and decrypted
in the same manner.  Then he moved to the most-discussed piece of prior art:
RC4, combined with Lotus Notes, an early e-mail and social networking
product. TQP actually admits that the combination of RC4 and Lotus Notes
anticipates its patent, but the organization argues that it was kept as a
trade secret until after the "critical date" of October 6, 1988, one year
before the patent filing.
Diffie ran through the timeline: Rivest invented RC4 in 1987. By January
1988, Lotus had paid for the Notes product, a total of $200,000. In April
1988, Rivest wrote to the National Security Agency asking for an "export
license" for RC4?a step he wouldn't have taken unless the product was ready
to go, said Diffie. That same month, Ray Ozzie showed Notes and RC4 to Bill
Gates. In May of that year, the product was shown at Lotus Week, a huge
computer show.
That meant Lotus Notes had been "offered for sale" even though Lotus Notes
wasn't actually shipped to the public until December 1989. Paying for
something before you get it isn't unusual, he reminded jurors.
"This happens in commerce all the time," he said. "You can go to a car
dealer, and you look around the lot... but you don't like any exact one
that's there. You give the salesman a list of the features you want, and you
pay for the car. They send word off to Detroit, and Dearborn builds it for
you, and a few weeks later, your car shows up, and you drive it away. "
Diffie's testimony went on some time, but he seemed to have the jury in the
palm of his hand. A few jurors laughed at his jokes and smiled, and the more
serious ones were certainly focused on his testimony. After about two hours,
Albright passed the witness.
A stunning attack
One might imagine an opposing attorney would handle a famous witness, who had
just connected with the jury, carefully. TQP lawyer Marc Fenster could have
acknowledged Diffie's accomplishments while arguing that his client?an
admittedly little guy?still should get his rights, his little piece of
"intellectual property."
That's not what Fenster did. He went on the attack.
"You never completed a master's degree, correct?" he asked Diffie.
"That's correct," said Diffie.
"Other than the honorary degree, you don't have an earned doctorate or Ph.D.
"That is correct," said Diffie.
And even though he taught a few courses, "you never had a real professorship,
correct?" asked Fenster.
"I never had a full-time academic job, no."
Fenster noted that while Diffie was testifying in court for the first time,
he had other expert witness work lined up. His rate varies from $500 to $600
per hour, and it's $700 for testifying in court.
"Your agent helps you to get expert witness jobs, is that right?"
"Actually, no," said Diffie. "My agent handles the arrangements with my
clients. All of the jobs have come in directly through me."
Then Fenster mounted an even more surprising strategy: he pursued a line of
questioning suggesting that it was Diffie who was being misleading about his
own invention.
"Dr. Diffie, you agree that you can still be an inventor on a patent even
though others may have invented the same thing earlier but kept their
invention secret, correct?" asked Fenster.
"Under some circumstances, yes," answered Diffie.
"In fact, Dr. Diffie, you have some personal experience with this particular
aspect of the patent law, don't you?"
"You'll have to remind me," answered Diffie.
Then Fenster dropped this bombshell: "Dr. Diffie, you were not the first to
invent public key cryptography, were you?"
"I believe that I may have been," said Diffie, speaking cautiously. "But
perhaps you could be more specific?"
"In fact, a gentleman named James Ellis in England invented it before you,
Diffie sighed. He seemed, suddenly, almost tired. He had heard this one
before. "I spent a lot of time talking to James Ellis, and I can't figure it
out," he said. "James Ellis did very fine work."
Fenster pulled up the history website for the Institute of Electrical and
Electronics Engineers, a page that displayed "milestones" in engineering
dating back to 1800. The page showed James Ellis, not Diffie, as the inventor
of public-key cryptography. Ellis made the breakthrough at the British GCHQ
intelligence agency but kept it secret. With these discoveries, the essential
principles were known but "were kept secret until 1997," stated the IEEE
"It describes this invention as being accomplished by James Ellis in
Britain's government, correct?" asked Fenster
"It does."
"And it does not list you as the inventor or credit you with the invention of
public key cryptography, correct?"
The article described Ellis as inventing public key cryptography in 1969 but
keeping it confidential until 1997.
"Let's read together," said Fenster. Reading the website, he intoned: "All of
the essentials of public key cryptography had been discovered by Ellis and
two others by 1975."
"That's what it says," said Diffie.
"And by that time, the public recognition of the invention of public key
cryptography had been allocated to the researchers at Stanford and
"That's what it says."
"So, in fact, according to the IEEE, someone else invented public key
cryptography before you, correct?"
"I disagree," said Diffie. "Ellis's paper is in no sense enabling. [His
partner] Malcolm Williamson's paper enables Diffie-Hellman, and it was an
internal secret note written two months after I presented that at the largest
computer conference in the world."
Diffie said he sought out those three inventors himself and talked to them
"extensively" about their work. He started those discussions in 1982 and they
continue to the present.
"Dr. Diffie, you were entitled to your patent because the alleged prior
inventor kept it secret, right?"
"The alleged prior inventors not only kept it secret but did very little with
it," said Diffie. "In James Ellis's words to me: 'You did a lot more with it
than we did.'"
If Fenster wanted to talk about other claims to the public-key crypto
breakthrough, Diffie seemed suddenly happy to help him out. He started
bringing out his own examples.
"When the director of NSA spoke to Congress, in about 1977, he rather
perversely made the claim that NSA had invented these things a decade
earlier," said Diffie. "Both the time and the credit seem a little bit off.
But there was a steady sort of attempt to claim credit for this, without
releasing documents, until 1997."
After Fenster finished, Albright went back to the podium and gave Diffie a
chance to regroup and explain. In the US National Inventors' Hall of Fame,
Albright pointed out, it was Diffie who was credited with the invention.
"Would you explain to the jury why it is that you represented to them here in
open court under oath that you were the inventor?"
"I've studied this with some care," said Diffie. He continued:
The short answer would be that James Ellis' work in 1969 and 1970 certainly
does not teach the methods. Personally, I find that paper incomprehensible.
I'm not clear how anybody became convinced of anything from it.
Williamson wrote a paper?and internal, secret paper at GCHQ that is dated the
eighth of August, 1976, or close to that?two months after I presented the
Diffie-Hellman key exchange at the National Computer Conference in New York.
My view is that they did very fine work. I think my conception of public key
was clearer than James Ellis'. But every time we have been given awards on
this, I have cited those people and praised them for the work they did.  By
the time Diffie finished testifying, it was near the end of the day. Then
came another stunner: Newegg rested its case. It did so without putting on
its expert witness to rebut TQP's $5.1 million damage claim?even though
documents in the court docket clearly indicate the company had such a
Defendants put on damage experts as a matter of course in patent cases, so
not doing so here is a huge bet. It suggests Newegg is hoping strongly enough
for a straight win that it believes more focus on damages would be
TQP's final witness, Dr. Tom Rhyne, is an expert to rebut Diffie. His
testimony will continue to Monday, and will be followed by closing arguments.
After that, the fate of Newegg and the Jones patent will be in the hands of
the jury. A verdict could come by Monday evening.

@_date: 2013-10-11 10:45:05
@_author: Eugen Leitl 
@_subject: [Cryptography] prism-proof email in the degenerate case 
This is what Bitmessage attempts to achieve, but it has issues.
Assuming these can be solved (a rather large if), and glue like  is available to be run by end users
it could be quite useful.

@_date: 2013-10-11 13:24:44
@_author: Eugen Leitl 
@_subject: [Cryptography] PGP Key Signing parties 
This obviously ignores the threat model of official fake IDs.
This is not just academic for some users. Plus, if you're e.g. linking up with known friends in RetroShare
(which implements identities via PGP keys, and degrees of
trust (none/marginal/full) by signatures, and allows you to tune your co-operative variables (Anonymous routing/discovery/
forums/channels/use a direct source, if available) depending on the degree of trust.

@_date: 2013-10-14 15:36:14
@_author: Eugen Leitl 
@_subject: [Cryptography] funding Tor development 
Guys, in order to minimize Tor Project's dependance on
federal funding and/or increase what they can do it
would be great to have some additional funding ~10 kUSD/month.
If anyone is aware of anyone who can provide funding at
that level or higher, please contact execdir at torproject.org

@_date: 2013-10-17 10:29:45
@_author: Eugen Leitl 
@_subject: [Cryptography] Cryptographer Adi Shamir Prevented from Attending 
Cryptographer Adi Shamir Prevented from Attending NSA History Conference
Categories: Science, Secrecy
In this email message to colleagues, Israeli cryptographer Adi Shamir
recounts the difficulties he faced in getting a visa to attend the 2013
Cryptologic History Symposium sponsored by the National Security Agency. Adi
Shamir is the ?S? in the RSA public-key algorithm and is ?one of the finest
cryptologists in the world today,? according to historian David Kahn. The NSA
Symposium begins tomorrow. For the reasons described below, Dr. Shamir will
not be there.
The purpose of this email is to explain why I will not be able to attend the
forthcoming meeting of the History of Cryptology conference, even though I
submitted a paper which was formally accepted. As an active participant in
the exciting developments in academic cryptography in the last 35 years, I
thought that it would be a wonderful opportunity to meet all of you, but
unfortunately the US bureaucracy has made this impossible.
The story is too long to describe in detail, so I will only provide its main
highlights here. I planned to visit the US for several months, in order to
attend the Crypto 2013 conference, the History of Cryptology conference, and
to visit several universities and research institutes in between in order to
meet colleagues and give scientific lectures. To do all of these, I needed a
new J1 visa, and I filed the visa application at the beginning of June, two
and a half months before my planned departure to the Crypto conference in mid
August. I applied so early since it was really important for me to attend the
Crypto conference ? I was one of the founders of this flagship annual
academic event (I actually gave the opening talk in the first session of the
first meeting of this conference in 1981) and I did my best to attend all its
meetings in the last 32 years.
To make a long story short, after applying some pressure and pulling a lot of
strings, I finally got the visa stamped in my passport on September 30-th,
exactly four months after filing my application, and way beyond the requested
start date of my visit. I was lucky in some sense, since on the next day the
US government went into shutdown, and I have no idea how this could have
affected my case. Needless to say, the long uncertainty had put all my travel
plans (flights, accomodations, lecture commitments, etc) into total disarray.
It turns out that I am not alone, and many foreign scientists are now facing
the same situation. Here is what the president of the Weizmann Institute of
Science (where I work in Israel) wrote in July 2013 to the US Ambassador in
?I?m allowing myself to write you again, on the same topic, and related to
the major difficulties the scientists of the Weizmann Institute of Science
are experiencing in order to get Visa to the US. In my humble opinion, we are
heading toward a disaster, and I have heard many people, among them our top
scientists, saying that they are not willing anymore to visit the US, and
collaborate with American scientists, because of the difficulties. It is
clear that scientists have been singled out, since I hear that other ?simple
citizen?, do get their visa in a short time.?
Even the president of the US National Academy of Science (of which I am a
member) tried to intervene, without results. He was very sympathetic, writing
to me at some stage:
?Dear Professor Shamir
I have been hoping, day by day, that your visa had come through. It is very
disappointing to receive your latest report. We continue to try by seeking
extra attention from the U. S. Department of State, which has the sole
authority in these matters. As you know, the officers of the Department of
State in embassies around the world also have much authority. I am personally
very sympathetic and hopeful that your efforts and patience will still yield
results but also realize that this episode has been very trying. We hope to
hear of a last-minute success.
Yours sincerely, Ralph J. Cicerone?
What does all of this have to do with the History of Cryptology conference?
In January 2013 I submitted a paper titled ?The Cryptology of John Nash From
a Modern Perspective? to the conference, and a short time afterwards I was
told by the organizers that it was accepted. In July 2013 I told the
NSA-affiliated conference organizers that I was having some problems in
getting my visa, and gently asked whether they could do something about it.
Always eager to help, the NSA people leaped into action, and immediately sent
me a short email written with a lot of tact:
?The trouble you are having is regrettable?Sorry you won?t be able to come to
our conference. We have submitted our program and did not include you on it.?
I must admit that in my 35 years of attending many conferences, it had never
happened to me that an accepted paper of mine was yanked out from the
official program in such a unilateral way. However, since I never try to go
to places where I do not feel wanted, I decided to inform MIT that a window
had become available in my busy schedule. They immediately invited me to
visit them on October 17 and 18, and to give a major lecture during my visit.
Naturally, I accepted their gracious invitation.
The final twist in this saga happened a few days ago, when out of the blue I
was suddenly reinvited by the conference organizers to attend the event and
to present my paper. However, this is too late now, since I am already fully
committed to my visit to MIT.
So what is the bottom line of this whole unhappy episode? Clearly, no one in
the US is trying to see the big picture, and the heavy handed visa
bureaucracy you have created seems to be collapsing under its own weight.
This is not a security issue ? I have been to the US close to a hundred times
so far (including some multi-year visits), and had never overstayed my visas.
In addition, the number of terrorists among the members of the US National
Academy of Science is rather small. As a friend of the US I am deeply worried
that if you continue to delay visas in such a way, the only thing you will
achieve is to alienate many world-famous foreign scientists, forcing them to
increase their cooperation with European or Chinese scientists whose
countries roll the red carpet for such visits. Is this really in the US best
Best personal wishes, and apologies for not being able to meet you in person,
Adi Shamir

@_date: 2013-10-17 22:32:11
@_author: Eugen Leitl 
@_subject: [Cryptography] funding Tor development 
They do that already, actually. Goes up to some 75 kUSD
Source: They don't take BTC, but some other Tor projects do.

@_date: 2013-10-17 22:51:24
@_author: Eugen Leitl 
@_subject: [Cryptography] funding Tor development 
Their lawyears advised them not to. Some other projects
do:

@_date: 2013-10-25 12:09:06
@_author: Eugen Leitl 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
That's an interesting idea. Can you provide a cicuit and a parts
list for that? That could be a worthwhile kit bundle, especially if
you could order it via a single click.

@_date: 2013-09-06 13:47:10
@_author: Eugen Leitl 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Snowden didn't have clearance for that information. He's being described as 'brilliant' and purportedly was able to access documents far beyond his level by impersonating (using stolen/falsified secrets) higher level officials.
Culling admins and adding the two-eyes rule will cripple the TLAs more than it will accomplish anything. We're still missing the information which cyphers are now legacy, and
which are still considered useful. I keep seeing PFS being touted,
but there is no evidence yet we can trust PFS to be yet unbroken
though it appears plausible.  Others are suggesting that public key encryption methods are suspect,
while symmetric encryption has a better story. I'm personally becoming
quite interested in a reliable way to produce secure one-time pads,
using physical entropy sources which have been validated. It would
be interesting to physically/securely exchanging large one-time
pads in one's social network, and reaching farther recipients in
a Retroshare-like (turtle router) model.
It might be useful to combine one-time pads with symmetric encryption,
automatically rekeying every large block of data for high-volume
transfers (e.g. mesh routers) to stretch a one-time pad without
completely losing its properties. The question is how large a block
can be before it leaks enough information about the key.

@_date: 2013-09-06 23:00:20
@_author: Eugen Leitl 
@_subject: [Cryptography] Bruce Schneier has gotten seriously spooked 
This is why I've been verifying Tor downloads using
out of band fingerprints of signing key.
Just because active attacks are more expensive than passive attacks
and are fundamentally detectable, don't assume they're not being
used in highly targeted cases.
If you have ever been under telco surveillance, that's enough
effort already spent to warrant slipping you some custom malware with
no added bill of materials.

@_date: 2013-09-07 10:50:25
@_author: Eugen Leitl 
@_subject: [Cryptography] Opening Discussion: Speculation on "BULLRUN" 
Apropos IPsec, I've tried searching for any BTNS (opportunistic encryption mode for
IPsec) implementations, and even the authors of the RFC are not aware of any.
Obviously, having a working OE BTNS implementation in Linux/*BSD would be a very
valuable thing, as an added, transparent protection layer against passive attacks.
There are many IPsec old hands here, it is probably just a few man-days worth
of work. It should be even possible to raise some funding for such a project.
Any takers?

@_date: 2013-09-07 23:07:38
@_author: Eugen Leitl 
@_subject: [Cryptography] Washington Post: Google racing to encrypt links 
Nanog and denog had a discussion about this, and in general nobody
believes the products you can buy, especially the export version, have no backdoor.
Doing it in software is only feasible at network edge, not core.

@_date: 2013-09-08 13:47:37
@_author: Eugen Leitl 
@_subject: [Cryptography] MITM source patching [was Schneier got spooked] 
There is a specific unit within NSA that attempts to obtain keys not in
the key cache. Obviously, package-signing secrets are extremely valuable,
since they're likely to work for hardened (or so they think) targets.
For convenience reasons the signing secrets are typically not secured.
If something is online you don't even need physical access to obtain it.
The workaround for this is to build packages from source, especially
if there's deterministic build available so that you can check whether
the published binary for public consumption is kosher, and verify
signatures with information obtained out of band. Checking key fingeprints on dead tree given in person is inconvenient, and does not give you complete trust, but it is much better than just blindly install something from online depositories.

@_date: 2013-09-08 22:36:15
@_author: Eugen Leitl 
@_subject: [Cryptography]  Opening Discussion: Speculation on "BULLRUN" 
Forwarded with permission.
So there *is* a BTNS implementation, after all. Albeit
only for OpenBSD -- but this means FreeBSD is next, and
Linux to follow.

@_date: 2013-09-09 10:25:03
@_author: Eugen Leitl 
@_subject: [Cryptography] very little is missing for working BTNS in Openswan 
Just got word from an Openswan developer:
To my knowledge, we never finished implementing the BTNS mode.
It wouldn't be hard to do --- it's mostly just conditionally commenting out
There's obviously a large potential deployment base for
BTNS for home users, just think of Openswan/OpenWRT.

@_date: 2013-09-09 10:45:02
@_author: Eugen Leitl 
@_subject: [Cryptography] SSH uses secp256/384r1 which has the same parameters 
SP800-90 for Dual EC DRBG!
Forwarded without permission, hence anonymized:
Hey, I had a look at SEC2 and the TLS/SSH RFCs. SSH uses secp256/384r1
which has the same parameters as what's in SEC2 which are the same the
parameters as specified in SP800-90 for Dual EC DRBG!
TLS specifies you can use those two curves as well...
 Surely that's not coincidence..

@_date: 2013-09-09 11:23:29
@_author: Eugen Leitl 
@_subject: [Cryptography] IETF: Security and Pervasive Monitoring 
Security and Pervasive Monitoring
The Internet community and the IETF care deeply about how much we can trust
commonly used Internet services and the protocols that these services use.
So the reports about large-scale monitoring of Internet traffic and users
disturbs us greatly.  We knew of interception of targeted individuals and
other monitoring activities, but the scale of recently reported monitoring is
surprising. Such scale was not envisaged during the design of many Internet
protocols, but we are considering the consequence of these kinds of attacks.
Of course, it is hard to know for sure from current reports what attack
techniques may be in use.  As such, it is not so easy to comment on the
specifics from an IETF perspective.  Still, the IETF has some long standing
general principles that we can talk about, and we can also talk about some of
the actions we are taking.
In 1996, RFC 1984 articulated the view that encryption is an important tool
to protect privacy of communications, and that as such it should be
encouraged and available to all.  In 2002, we decided that IETF standard
protocols must include appropriate strong security mechanisms, and
established this doctrine as a best current practice, documented in RFC 3365.
Earlier, in 2000 the IETF decided not to consider requirements for
wiretapping when creating and maintaining IETF standards, for reasons stated
in RFC 2804. Note that IETF participants exist with positions at all points
of the privacy/surveillance continuum, as seen in the discussions that lead
to RFC 2804.
As privacy has become increasingly important, the Internet Architecture Board
(IAB) developed guidance for handling privacy considerations in protocol
specifications, and documented that in RFC 6973. And there are ongoing
developments in security and privacy happening within the IETF all the time,
for example work has just started on version 1.3 of the Transport Layer
Security (TLS, RFC 5246) protocol which aims to provide better
confidentiality during the early phases of the cryptographic handshake that
underlies much secure Internet traffic.
Recent days have also seen an extended and welcome discussion triggered by
calls for the IETF to build better protections against wide-spread
As that discussion makes clear, IETF participants want to build secure and
deployable systems for all Internet users.  Indeed, addressing security and
new vulnerabilities has been a topic in the IETF for as long as the
organisation has existed.  Technology alone is, however, not the only factor.
Operational practices, laws, and other similar factors also matter. First of
all, existing IETF security technologies, if used more widely, can definitely
help.  But technical issues outside the IETF?s control, for example endpoint
security, or the properties of specific products or implementations also
affect the end result in major ways. So at the end of the day, no amount of
communication security helps you if you do not trust the party you are
communicating with or the devices you are using. Nonetheless, we?re confident
the IETF can and will do more to make our protocols work more securely and
offer better privacy features that can be used by implementations of all
So with the understanding of limitations of technology-only solutions, the
IETF is continuing its mission to improve security in the Internet.  The
recent revelations provide additional motivation for doing this, as well as
highlighting the need to consider new threat models.
We should seize this opportunity to take a hard look at what we can do
better.  Again, it is important to understand the limitations of technology
alone. But here are some examples of things that are already ongoing:
We?re having a discussion as part of the development of HTTP/2.0 as to how to
make more and better use of TLS, for example to perhaps enable clients to
require the use of security and not just have to react to the HTTP or HTTPS
URLs chosen by servers.
We?re having discussions as to how to handle the potentially new threat model
demonstrated by the recent revelations so that future protocol designs can
take into account potential pervasive monitoring as a known threat model.
We?re considering ways in which better use can be made of existing protocol
features, for example, better guidance as to how to deploy TLS with Perfect
Forward Secrecy, which makes applications running over TLS more robust if
server private keys later leak out.
We?re constantly updating specifications to deprecate older, weaker
cryptographic algorithms and allocate code points for currently strong
algorithm choices so those can be used with Internet protocols.
And we are confident that discussions on this topic will motivate IETF
participants to do more work on these and further related topics.
But don?t think about all this just in terms of the recent revelations.  The
security and privacy of the Internet in general is still a challenge even
ignoring pervasive monitoring, and if there are improvements from the above,
those will be generally useful for many reasons and for many years to come.
Perhaps this year?s discussions is a way to motivate the world to move from
?by default insecure? communications to ?by default secure?.  Publicity and
motivation are important, too. There is plenty to do for all of us, from
users enabling additional security tools to implementors ensuring that their
products are secure.
In the Vancouver IETF meeting, there will be time dedicated to discuss this,
and we ask that those interested in working on this topic contribute to the
analysis and develop proposals in this area.  Those contributions are very
welcome and can start now and continue in Vancouver and beyond.
Relevant mailing lists (from most specific to most general) include:
The perpass mailing list (perpass at ietf.org), recently set up to consider how
the IETF ought react to pervasive monitoring
The ietf security area mailing list (saag at ietf.org), for general security
The ietf main mailing list (ietf at ietf.org), for general discussion
Jari Arkko, Chair of the IETF and Stephen Farrell, IETF Security Area
This entry was posted in IETF on 2013/09/07.

@_date: 2013-09-09 14:40:10
@_author: Eugen Leitl 
@_subject: [Cryptography] Scott Aaaronson: NSA: Possibly breaking US laws, 
NSA: Possibly breaking US laws, but still bound by laws of computational
Last week, I got an email from a journalist with the following inquiry.  The
recent Snowden revelations, which made public for the first time the US
government?s ?black budget,? contained the following enigmatic line from the
Director of National Intelligence: ?We are investing in groundbreaking
cryptanalytic capabilities to defeat adversarial cryptography and exploit
internet traffic.?  So, the journalist wanted to know, what could these
?groundbreaking? capabilities be?  And in particular, was it possible that
the NSA was buying quantum computers from D-Wave, and using them to run
Shor?s algorithm to break the RSA cryptosystem?
I replied that, yes, that?s ?possible,? but only in the same sense that it?s
?possible? that the NSA is using the Easter Bunny for the same purpose.  (For
one thing, D-Wave themselves have said repeatedly that they have no interest
in Shor?s algorithm or factoring.  Admittedly, I guess that?s what D-Wave
would say, were they making deals with NSA on the sly!  But it?s also what
the Easter Bunny would say.)  More generally, I said that if the open
scientific world?s understanding is anywhere close to correct, then quantum
computing might someday become a practical threat to cryptographic security,
but it isn?t one yet.
That, of course, raised the extremely interesting question of what
?groundbreaking capabilities? the Director of National Intelligence was
referring to.  I said my personal guess was that, with ~99% probability, he
meant various implementation vulnerabilities and side-channel attacks?the
sort of thing that we know has compromised deployed cryptosystems many times
in the past, but where it?s very easy to believe that the NSA is ahead of the
open world.  With ~1% probability, I guessed, the NSA made some sort of big
improvement in classical algorithms for factoring, discrete log, or other
number-theoretic problems.  (I would?ve guessed even less than 1% probability
for the latter, before the recent breakthrough by Joux solving discrete log
in fields of small characteristic in quasipolynomial time.)
Then, on Thursday, a big New York Times article appeared, based on 50,000 or
so documents that Snowden leaked to the Guardian and that still aren?t
public.  (See also an important Guardian piece by security expert Bruce
Schneier, and accompanying Q&A.)  While a lot remains vague, there might be
more public information right now about current NSA cryptanalytic
capabilities than there?s ever been.
So, how did my uninformed, armchair guesses fare?  It?s only halfway into the
NYT article that we start getting some hints:
The files show that the agency is still stymied by some encryption, as Mr.
Snowden suggested in a question-and-answer session on The Guardian?s Web site
in June.
?Properly implemented strong crypto systems are one of the few things that
you can rely on,? he said, though cautioning that the N.S.A. often bypasses
the encryption altogether by targeting the computers at one end or the other
and grabbing text before it is encrypted or after it is decrypted?
Because strong encryption can be so effective, classified N.S.A. documents
make clear, the agency?s success depends on working with Internet companies ?
by getting their voluntary collaboration, forcing their cooperation with
court orders or surreptitiously stealing their encryption keys or altering
their software or hardware?
Simultaneously, the N.S.A. has been deliberately weakening the international
encryption standards adopted by developers. One goal in the agency?s 2013
budget request was to ?influence policies, standards and specifications for
commercial public key technologies,? the most common encryption method.
Cryptographers have long suspected that the agency planted vulnerabilities in
a standard adopted in 2006 by the National Institute of Standards and
Technology and later by the International Organization for Standardization,
which has 163 countries as members.
Classified N.S.A. memos appear to confirm that the fatal weakness, discovered
by two Microsoft cryptographers in 2007, was engineered by the agency. The
N.S.A. wrote the standard and aggressively pushed it on the international
group, privately calling the effort ?a challenge in finesse.?
So, in pointing to implementation vulnerabilities as the most likely
possibility for an NSA ?breakthrough,? I might have actually erred a bit too
far on the side of technological interestingness.  It seems that a large part
of what the NSA has been doing has simply been strong-arming Internet
companies and standards bodies into giving it backdoors.  To put it bluntly:
sure, if it wants to, the NSA can probably read your email.  But that isn?t
mathematical cryptography?s fault?any more than it would be mathematical
crypto?s fault if goons broke into your house and carted away your laptop.
On the contrary, properly-implemented, backdoor-less strong crypto is
something that apparently scares the NSA enough that they go to some lengths
to keep it from being widely used.
I should add that, regardless of how NSA collects all the private information
it does?by ?beating crypto in a fair fight? (!) or, more likely, by
exploiting backdoors that it itself installed?the mere fact that it collects
so much is of course unsettling enough from a civil-liberties perspective.
So I?m glad that the Snowden revelations have sparked a public debate in the
US about how much surveillance we as a society want (i.e., ?the balance
between preventing 9/11 and preventing Orwell?), what safeguards are in place
to prevent abuses, and whether those safeguards actually work.  Such a public
debate is essential if we?re serious about calling ourselves a democracy.
At the same time, to me, perhaps the most shocking feature of the Snowden
revelations is just how unshocking they?ve been.  So far, I haven?t seen
anything that shows the extent of NSA?s surveillance to be greater than what
I would?ve considered plausible a priori.  Indeed, the following could serve
as a one-sentence summary of what we?ve learned from Snowden:
Yes, the NSA is, in fact, doing the questionable things that anyone not
living in a cave had long assumed they were doing?that assumption being so
ingrained in nerd culture that countless jokes are based around it.
(Come to think of it, people living in caves might have been even more
certain that the NSA was doing those things.  Maybe that?s why they moved to
So, rather than dwelling on civil liberties, national security, yadda yadda
yadda, let me move on to discuss the implications of the Snowden revelations
for something that really matters: a 6-year-old storm in theoretical computer
science?s academic teacup.  As many readers of this blog might know, Neal
Koblitz?a respected mathematician and pioneer of elliptic curve cryptography,
who (from numerous allusions in his writings) appears to have some
connections at the NSA?published a series of scathing articles, in the
Notices of the American Mathematical Society and elsewhere, attacking the
theoretical computer science approach to cryptography.  Koblitz?s criticisms
were varied and entertainingly-expressed: the computer scientists are too
sloppy, deadline-driven, self-promoting, and corporate-influenced; overly
trusting of so-called ?security proofs? (a term they shouldn?t even use,
given how many errors and exaggerated claims they make); absurdly overreliant
on asymptotic analysis; ?bodacious? in introducing dubious new hardness
assumptions that they then declare to be ?standard?; and woefully out of
touch with cryptographic realities.  Koblitz seemed to suggest that, rather
than demanding the security reductions so beloved by theoretical computer
scientists, people would do better to rest the security of their
cryptosystems on two alternative pillars: first, standards set by
organizations like the NSA with actual real-world experience; and second, the
judgments of mathematicians with ? taste and experience, who can just see
what?s likely to be vulnerable and what isn?t.
Back in 2007, my mathematician friend Greg Kuperberg pointed out the irony to
me: here we had a mathematician, lambasting computer scientists for trying to
do for cryptography what mathematics itself has sought to do for everything
since Euclid!  That is, when you see an unruly mess of insights, related to
each other in some tangled way, systematize and organize it.  Turn the tangle
into a hierarchical tree (or dag).  Isolate the minimal assumptions (one-way
functions?  decisional Diffie-Hellman?) on which each conclusion can be
based, and spell out all the logical steps needed to get from here to
there?even if the steps seem obvious or boring.  Any time anyone has tried to
do that, it?s been easy for the natives of the unruly wilderness to laugh at
the systematizing newcomers: the latter often know the terrain less well, and
take ten times as long to reach conclusions that are ten times less
interesting.  And yet, in case after case, the clarity and rigor of the
systematizing approach has eventually won out.  So it seems weird for a
mathematician, of all people, to bet against the systematizing approach when
applied to cryptography.
The reason I?m dredging up this old dispute now, is that I think the recent
NSA revelations might put it in a slightly new light.  In his article?whose
main purpose is to offer practical advice on how to safeguard one?s
communications against eavesdropping by NSA or others?Bruce Schneier offers
the following tip:
Prefer conventional discrete-log-based systems over elliptic-curve systems;
the latter have constants that the NSA influences when they can.
Here Schneier is pointing out a specific issue with ECC, which would be
solved if we could ?merely? ensure that NSA or other interested parties
weren?t providing input into which elliptic curves to use.  But I think
there?s also a broader issue: that, in cryptography, it?s unwise to trust any
standard because of the prestige, real-world experience, mathematical good
taste, or whatever else of the people or organizations proposing it.  What
was long a plausible conjecture?that the NSA covertly influences
cryptographic standards to give itself backdoors, and that
otherwise-inexplicable vulnerabilities in deployed cryptosystems are
sometimes there because the NSA wanted them there?now looks close to an
established fact.  In cryptography, then, it?s not just for idle academic
reasons that you?d like a publicly-available trail of research papers and
source code, open to criticism and improvement by anyone, that takes you all
the way from the presumed hardness of an underlying mathematical problem to
the security of your system under whichever class of attacks is relevant to
Schneier?s final piece of advice is this: ?Trust the math.  Encryption is
your friend.?
?Trust the math.?  On that note, here?s a slightly-embarrassing confession.
When I?m watching a suspense movie (or a TV show like Homeland), and I reach
one of those nail-biting scenes where the protagonist discovers that
everything she ever believed is a lie, I sometimes mentally recite the proof
of the Karp-Lipton Theorem.  It always calms me down.  Even if the entire
universe turned out to be a cruel illusion, it would still be the case that
NP ? P/poly would collapse the polynomial hierarchy, and I can tell you
exactly why.  It would likewise be the case that you couldn?t break the GGM
pseudorandom function without also breaking the underlying pseudorandom
generator on which it?s based.  Math could be defined as that which can still
be trusted, even when you can?t trust anything else.
This entry was posted on Sunday, September 8th, 2013 at 11:31 am	 and
is filed under Complexity, Nerd Interest. You can follow any responses to
this entry through the RSS 2.0 feed. You can leave a response, or trackback
from your own site.
24 Responses to ?NSA: Possibly breaking US laws, but still bound by laws of
computational complexity? Aaronson on crypto. Schneier ?elliptic-curve
systems; the latter have constants that the NSA influences when they can.? |
Gordon's shares Says: Comment  September 8th, 2013 at 1:22 pm [?] Link.
Trust math, but not NSA mathematicians. [?]
Douglas Knight Says: Comment  September 8th, 2013 at 1:35 pm Could you be
more specific about what you mean by the hypothetical ?big improvement? on
number theory algorithms that is covered by your 1%?
Do elliptic curve algorithms count? Does an L(1/4) algorithm count, or only
quasi-polynomial? What if they can?t break all instances, but, as has
repeatedly happened, they discovered bad primes or bad exponents that make
particular keys weak? Breaking a random half of all keys is almost as good as
breaking all of them. Schneier?s condemnation of ECC seems to require more
than 1% chance NSA knows something special about ECC.
PS ? David Jao, commenting on Schneier?s blog says that we can and do use
cryptography to prevent NSA from meddling with mystery constants. He says
that the ECC standard curves are generated by SHA-1, so to meddle, NSA would
have to break the has function. (But if half of curves are bad, that?s easy.)
Anonymous Says: Comment  September 8th, 2013 at 1:45 pm
You are making good and interesting points. However, Koblitz also has some
valid criticisms of TCS even if his conclusions are not valid. The
mathematical models we built in TCS are useless if they don?t relate to the
practice and we know many of our standard models are not good enough
approximation of the reality and arguably there isn?t enough effort to deal
with these issues. Technical heavy weight lifting is used as the ultimate
criteria for judging the value of research projects inside the community.
Also I think you are exaggerating what most cryptographers expected that NSA
was doing. I have heard several famous crypto experts quite surprised by
these revelations and it has shaken their trust in the government
institutions. I never understood why some people presume that government is a
benevolent entity, such beliefs in government institutions seems like
ideology to me.
Daniel Armak Says: Comment  September 8th, 2013 at 2:06 pm
You can trust the math itself, and so can Bruce Schneier and a few tens of
thousands of other people. But everyone else who can?t grok the entire
mathematical arguments for each cryptographical system, or doesn?t want to
spend a long time studying it, must trust the word of people like you. And
since the NSA can and does subvert people like you, who do original work and
analyze others? work and sit on standards committees, not to mention the
programmers who implement it in code, what are we to do?
Daniel W. Says: Comment  September 8th, 2013 at 2:33 pm
In my mind, the best circumstantial evidence that the NSA has not practically
broken any of the major cryptosystems is the following:, if they had, they
would most likely keep this as a highly guarded secret to be used only
against high value targets rather than as a means of monitoring potential
terrorists. It would most likely be contained within a small circle and not
mentioned in power-point presentations to low-level analysts.
Of course, the above argument may be flawed by assuming the NSA has too high
of a level of competence.
T H Ray Says: Comment  September 8th, 2013 at 2:43 pm
? ? the clarity and rigor of the systematizing approach has eventually won
No doubt. In Euclid?s time as well as the present, though, it is helpful to
have something to systematize. Making that assumption available and
convenient is what mathematicians do.
Scott Says: Comment  September 8th, 2013 at 3:02 pm
Daniel Armak You can trust the math itself, and so can Bruce Schneier and a few tens of
thousands of other people. But everyone else ? must trust the word of people
like you.  You raise an excellent point, which I think applies even more
broadly than you say. For one thing, I merely understand some of the general
ideas: I haven?t gone through every detail of the math used by the crypto in
my web browser, and I dare say that most professional cryptographers haven?t
For another, the point is much broader than cryptography: how can you trust
quantum mechanics, if you haven?t done the requisite experiments yourself?
The physicists could?ve all been bought off by some anti-realist cabal. :-)
Or how can you trust that the government isn?t putting mind-control drugs
into the fruit you buy in the supermarket, etc. etc.
So we?re extremely lucky that science hit on a solution to these problems?the
only workable solution, really?back in the 17th century. The solution is to
open up every question to scrutiny, discussion, and challenge by any
interested person. Assertions gain credibility by surviving public
criticism?and that?s just as true in math as it is in experimental sciences.
I believe many theorems even though I haven?t checked the proofs myself,
because I know that if there were an error, then someone else could?ve made a
name for themselves by finding it.
Now, for this Popperian dynamic to work, the whole process has to be carried
out in the open: if I thought someone who found a fatal flaw in a proof would
only tell their friends, then that doesn?t do me any good. That?s why the
dividing line between ?crypto as black art? and ?modern crypto? happened
precisely when new discoveries started being published in the open
literature, rather than being filed in a drawer at NSA or GCHQ.
wolfgang Says: Comment  September 8th, 2013 at 3:20 pm
Unfortunately, this xkcd.com/538/ had it right imho.
Scott Says: Comment  September 8th, 2013 at 3:20 pm
Daniel W.  If the NSA had really broken strong cryptosystems, then why
would they have resorted to so many covert tactics (or, in the case of the
Clipper Chip, overt attempts) to prevent people from using strong crypto,
unless NSA has a backdoor? I suppose it?s all elaborate psychological
warfare, to prevent us from discovering the fact that these cryptosystems
were broken? And that even Snowden himself is part of the NSA?s master plan?
At least in my book, every time you claim that what looks on its face like
evidence for X, is really evidence for a powerful cabal trying to prevent
everyone from discovering not(X), the plausibility of your theory gets cut by
a factor of maybe 50,000. This is directly related to the fact that I don?t
believe any conspiracy theories?as in zero, not one.
Scott Says: Comment  September 8th, 2013 at 3:32 pm
Douglas Knight  Sure, dramatic improvements in elliptic-curve algorithms
would certainly count?as would ?merely? subexponential algorithms, were the
improvements large enough to threaten key sizes that the academic
cryptographers considered safe.
More broadly, though, you?re entirely right that there?s not a sharp line
between ?improved number-theory algorithms? and ?implementation
vulnerabilities.? Often, what?s happened in practice is that an
implementation vulnerability has opened the way for an attack that still
requires interesting and nontrivial number theory. But I suppose that sort of
thing would still belong to the ?99%? part of my probability estimate. In the
?1%? part, I really had in mind ?something that would give theoretical
cryptographers a heart attack? (like, I dunno, factoring in L(1/10), or
elliptic curve discrete log in quasipolynomial time).
Scott Says: Comment  September 8th, 2013 at 5:03 pm
Anonymous You are making good and interesting points. However, Koblitz also has some
valid criticisms of TCS even if his conclusions are not valid.  I completely
agree that Koblitz has some valid criticisms.
However, I?ve read pretty much all of his and Menezes?s anti-TCS screeds, and
to me what he?s doing seems, if you like, too easy to be helpful. Koblitz?s
favorite M.O. is to recount various slip-ups by people in the ?Goldreich
school of crypto? and laugh at them: ?haha, they talk about ?provable
security,? but there was a bug in their proof! or their security definition
left out an important class of side-channel attacks!? Then, with even more
glee, Koblitz relates how the hapless computer scientists put out a new paper
supposedly fixing the problem, but that paper had its own problems, and so
The trouble is, that is indeed what a bunch of incompetent buffoons would
look like, but it?s also what science looks like! :-) Koblitz never seems to
want to acknowledge that the end result of the process is better scientific
understanding and more secure cryptosystems than before (even if still not
Also, of course, Koblitz almost defiantly refuses to suggest any better
mathematical foundations for cryptography, besides the reduction-based
foundations that were built up over the last 30 years. I.e., it?s not that
instead of adaptive chosen ciphertext attack, he has a better definition to
propose, or that instead of ?bodacious? new hardness assumptions, he can give
a single assumption that suffices for everything. Instead, what he appears to
want is simply a return to the ?black art? era of cryptography, when security
arguments boiled down to ?we tried to break it and failed? or ?trust us, we
have better mathematical taste than you.?
The trouble is, I can?t think of a single case in the history of science when
mathematical foundations as well-developed as cryptography?s now are, were
simply abandoned wholesale without better mathematical foundations to replace
them. So intellectually, Koblitz strikes me as someone who?s throwing spears
at battle-tanks. Being the excellent marksman that he is, he actually scores
some hits?but the reduction-encrusted battle-tanks are still going to win in
the end.
The mathematical models we built in TCS are useless if they don?t relate to
the practice and we know many of our standard models are not good enough
approximation of the reality and arguably there isn?t enough effort to deal
with these issues.  Would one also say that the mathematical foundations of
topology?open sets, Urysohn?s Lemma, etc.?are useless if they don?t relate to
the practice of tying and untying knots? I think that?s a pretty close
analogy for the relationship between what, say, Goldreich or Goldwasser or
Micali do, and the actual practice of cryptography. In both cases, yes,
there?s some relation between the intellectual foundations on the bottom and
the beautiful ornaments on top, but not surprisingly there are many floors in
between. Starting from a one-way function, for example, you first have to
construct a quasi-regular one-way function, then a pseudoentropy generator,
then a pseudorandom generator, then a pseudorandom function, and then maybe
you can start to think about building (say) a rudimentary private-key
cryptosystem or signature scheme.
Also I think you are exaggerating what most cryptographers expected that NSA
was doing. I have heard several famous crypto experts quite surprised by
these revelations and it has shaken their trust in the government
institutions. I never understood why some people presume that government is a
benevolent entity, such beliefs in government institutions seems like
ideology to me.  My situation is different: I never had any real doubt that
NSA was doing such things; the thing I genuinely don?t know is whether they
have good reasons to be doing them. I consider it conceivable that the NSA
has indeed stopped many terrorist attacks or other international disasters
that we never hear about?in which case, the strongest case in their favor
might be stronger than the strongest case that can ever be made publicly. The
fact that President Obama, who?s so reasonable on so many issues, has implied
as much is evidence for that view from my perspective. On the other hand, I
also consider it conceivable that the current eavesdropping regime is purely
a result of the universal tendency of bureaucracies to expand, justify
themselves, and zealously guard their power and privileges. Or it could be
some combination of the two.
For me, though, the deciding consideration is that, even in a fantasy world
where the NSA?s actions had always been 100% justified, I?d still want them
to be more accountable to the public than they are now. ?Trust that we have
our reasons, even though we can?t tell you what they are? simply doesn?t work
over the long term in a democracy, even if the trust is justified at any
particular time or in any particular case (and of course, often it hasn?t
Anonymous Says: Comment  September 8th, 2013 at 8:05 pm
I agree with you that his attitude is not constructive criticism. I would
even go further than you and say it is stupid to forget the science of crypto
and go back to purely engineering art treatment.
Regarding reasonability of what NSA does, NSA and its backers would of course
claim these tools are useful. To be honest, security was a weak point of
Obama?s campaign, he is not really knowledgeable in these issues and he has
not gone and will not go against his advisers if they tell him these tools
are necessary to fight terrorism. However, as far as I have heard, they have
hard time convincing anyone outside executive branch that these tools have
been as useful as they are claiming. How many major terrorist plots they have
been uncovered and prevented using these tools? It seems that they are using
these tools for a very wide range of activities including industrial and
political espionage on foreign governments and companies and gain political
and commercial advantage (what they call US national interests, not just
securing Americans against terrorists). Does anyone really believe that EU or
Brazil or liberal NGOs will launch a terrorist attack on US? FBI?s actions
against Dr. King is telling how far they would go. They use the fear factor
of a possible terrorist attacks to justify these actions to the public,
however the laws allow them to do whatever they want to and when there are
restrictions (like the fourth amendments) they find ways to circumvents them
(e.g. by colliding with foreign intelligence services like GCHQ to spy on
American citizens) or change the interpretations of those laws. We are very
lucky that many influential Americans in the previous generations had a
negative view of the federal government and wanted to restrict its powers as
much as possible, restrictions which are being removed in practice (partly
because some people want to settle sociopolitical disputes present in the
country using the government?s power). I don?t see why so much power should
be invested in a single authority with almost no real public supervision and
scrutiny (a role that media was playing to some extent in previous decades
but is coming under heavy pressure from government as Manning, Swartz,
Snowden, ? cases demonstrate). And even when courts find that someone in the
government has seriously violated the laws the president forgives them and
they avoid real punishment (as Scoot Libby case demonstrates).
It is not just US government, there is a trend in western liberal
democracies. It is simply unbelievable that the UK security forces used a law
passed to fight terrorism to hold the partner of a Guardian journalist for 9
hours without a lawyer and without the protection of Miranda rights against
self-incrimination. Anyone who thinks that security forces will only use the
authority and tools they obtain to the limited extent of the original goal
suffers from extreme nativity. They will use any tools in their disposal to
the fullest extent they can to achieve what they perceive to be the goals of
their institution. When they perceive journalists like Greenwald as a threat
to the national interests they use these tools to fight them which includes
intimidating the partner of a journalist using terrorism fighting powers. I
still fund it really hard to believe that we have gone so far in the
direction of an Orwellian society.
What can theoretical computer science offer biology? | Theory, Evolution, and
Games Group Says: Comment  September 9th, 2013 at 2:16 am
[?] the aid that cstheory can offer to biological understanding. In
yesterday?s post on the NSA and computational complexity, Aaronson ? with
attribution to mathematician Greg Kuperberg ? provided the following [?]
Paul Beame Says: Comment  September 9th, 2013 at 2:45 am
Some of the NSA revelations have been no surprise at all. It was well known
in the 1980?s, particularly after the publication of The Puzzle Palace, that
the NSA was tapping all the trans-Atlantic telephone cables; gathering up of
all e-mail to foreign addresses seems like more of the same.
The relationship of the NSA with TCS cryptographers has been pretty shaky. I
recall attending a theory of cryptography workshop at MIT?s Endicott House in
June 1985 with one or two official NSA attendees. At the time, there were one
or two TCS attendees known to have NSA funding and the NSA people wanted to
recruit more. In announcing their desire to sponsor more TCS cryptographers,
one of the NSA people cast a pall over the meeting by saying: ?If you are
interested, just mention it in a phone conversation with one of your friends
and we?ll get back to you.? This didn?t exactly endear them to anyone.
J Says: Comment  September 9th, 2013 at 2:51 am
?Math could be defined as that which can still be trusted, even when you
can?t trust anything else?
Wait till someone shows multiplication and addition have same complexity or
possible Voevodsky?s/Nelson?s worst nightmare comes true
Scott Says: Comment  September 9th, 2013 at 4:20 am
J  Multiplication and addition having the same complexity (and yes, it?s
conceivable that there?s a linear-time multiplication algorithm) wouldn?t do
anything whatsoever to undermine my trust in math?why would it?
Also, even if ZF set theory were shown to be inconsistent (and it won?t be
:-) ), that wouldn?t do anything whatsoever to undermine my trust in theorems
about (say) finite groups, or low-dimensional topology, or theoretical
computer science?in fact, about anything that doesn?t involve transfinite
sets. It would ?merely? tell me that there was a need (and, of course, an
exciting opportunity) to rethink the foundations. That?s something that
already happened 100+ years ago (the renovations causing virtually no damage
to the higher floors), and that could conceivably happen again.
Vitruvius Says: Comment  September 9th, 2013 at 4:58 am
I agree, Scott, with your general position that any time one claims that
?evidence for x is really evidence for a powerful cabal trying to prevent
everyone from discovering not(x)? one?s credibility drops by an irrecoverably
large factor, and I agree with you that ?math can be defined as that which
can still be trusted, even when you can?t trust anything else? (as you put
it), yet that still begs the question of how we the people decide what to
trust to be valid math.
Similarly, while your suggestion to ?open up every question to scrutiny,
discussion, and challenge by any interested person? may be necessary in order
to establish public trust, it isn?t sufficient because we still have the
problem of deciding which such interested persons to trust, and which to
write off as conspiracy theorists in their own right. How do we feasibly
decide, in effect, whether Ehrenhaft is a crackpot (as it were), and whether
?Snowden himself is part of the NSA?s master plan? (as you playfully alluded
To that end you may be interested in Why Doesn?t the Public Trust
Scientists?, a lecture by The Right Honourable Professor The Baroness O?Neill
of Bengarve, Emeritus Professor of Philosophy at the University of Cambridge
and past Principal of Newnham College, Cambridge, which she presented in 2005
as part of the Science Futures series by the San Diego Science and Technology
Council?s Center for Ethics in Science and Technology.
Note that while ?scientists? are the titular and exemplary referent matter in
that lecture, Baroness O?Neill?s talk actually considers a range of questions
in regard of public trust, including the roles of professional organizations,
trustworthiness (which can?t replace trust because of the quis custodiet
ipsos custodes problem), statutory regulation, post hoc accountability, &c,
which apply more broadly to the matters of public trust in any and every
profession and institution, including politics and the law.
O?Neill argues, if I may be so bold as to suggest a pr?cis, that going back
through the 17th century (as you noted) western liberal democracies have
indeed evolved a multipartite methodology that does tend work in practice and
that may well be the best we can get in principal, though it remains unclear
to me how well we are applying those techniques to matters of state security
in general, and how effectively you folks in the United States of America are
applying those techniques to your vaunted Agency in particular.
Scott Says: Comment  September 9th, 2013 at 5:01 am
Paul Beame  I?ve actually heard that joke many times, in other variants.
(?Interested in career opportunities at the NSA? Call your mom and let her
know!?) I didn?t know that NSA people themselves used the joke at
conferences, but it doesn?t surprise me at all.
J Says: Comment  September 9th, 2013 at 6:39 am ?Multiplication and
addition having the same complexity (and yes, it?s conceivable that there?s a
linear-time multiplication algorithm) wouldn?t do anything whatsoever to
undermine my trust in math?why would it??
I thought I read somewhere that if addition and multiplication turn out to be
similar in complexity, then it would imply something is wrong with
On the same vein think of the generalization of scheme theory that Mochizuki
claims to have undertaken to take apart + and x in ring structure.
I would think something fundamentally would have changed in our picture if
they turn to be similar in complexity.
J Says: Comment  September 9th, 2013 at 6:47 am
Atleast for computational purposes, the multiplicative group structure and
additive group structure of $\Bbb Z$ seem to be coinciding. This seems wrong.
I cannot directly relate to $Z \bmod p$ but this seems to have implication to
Discrete Log. An implication for this may not be beyond reach for atleast a
few other rings as well.
Scott Says: Comment  September 9th, 2013 at 7:02 am
J  Well, we already have a remarkable O(n logn loglogn) multiplication
algorithm (due to F?rer, and building on many previous works), and it hasn?t
created any problem for the foundations of mathematics that I know about.
Meanwhile, just like for most problems, we currently have no lower bound for
multiplication better than the trivial ?(n). I suppose I?d guess that ?(n
logn) is some sort of barrier, but not with any strength of conviction: if a
linear-time algorithm were discovered, it certainly wouldn?t cause me to
doubt the consistency of ZF set theory. :-)
Scott Says: Comment  September 9th, 2013 at 7:16 am
Vitruvius it remains unclear to me ? how effectively you folks in the United States of
America are applying those techniques to your vaunted Agency in particular.
As long as we?re trading mild national barbs, you?re Canadian? You guys do
have the Communications Security Establishment, which according to the NYT
article is one of only four foreign agencies (along with Britain?s,
Australia?s, and New Zealand?s) that ?knows the full extent? of the NSA?s
decoding capabilities and is cleared for its ?Bullrun? program. Though I
confess that, when I try to imagine Canada?s CSE, I come up with something
like the following:
Read this gentleman?s private email? Ooo, nooo, that doesn?t sound terribly
polite, eh?
J Says: Comment  September 9th, 2013 at 7:21 am
Professor I am well aware of all $n^{1+\epsilon}$ algorithms and Schonage?s
$O(n)$ algorithm on multitape machines. I cannot find the reference I am
thinking. It was written by a TCS theorist. I would seriously think that the
standard ring structure in $\Bbb Z$ could be modeled differently. I do not
know if ZF would be affected. However the question of treating x and +
differently for computation purposes compare to mathematical purposes arises
making things murky.
I am not implicating ZF with $O(n)$ algorithms for standard x operations on
the standard structure of $\Bbb Z$. The ZFC comment was a second piece of
mathematical conundrum some reputed folks have raised awareness about for a
need to be more well-grounded and it rang well with your statement on truth
in math as we know it. (Unrelated but bringing in ? $Z$ has been a puzzle
before as well ? it is the simplest ring with a spectrum of prime ideals
whose dimension is unclear to be interpreted in a standard way)
Scott Says: Comment  September 9th, 2013 at 7:23 am
Wolfgang Unfortunately, this xkcd.com/538/ had it right imho.
YES! I especially liked the mouseover text (?Actual actual reality: nobody
cares about his secrets?).

@_date: 2013-09-11 10:43:54
@_author: Eugen Leitl 
@_subject: [Cryptography] Thoughts about keys 
With a FOAF routing scheme with just 3 degrees of separation
there are not that many strangers left.
If you add opportunistic encryption at a low transport
layer, plus additional layers on top of you've protected
the bulk of traffic.

@_date: 2013-09-11 13:21:29
@_author: Eugen Leitl 
@_subject: [Cryptography] SPDZ, 
Breakthrough in cryptography could result in more secure computing
Tags: computer science, research, security, cryptography
Nigel Smart, Professor of Cryptology New research to be presented at the 18th European Symposium on Research in
Computer Security (ESORICS 2013) this week could result in a sea change in
how to secure computations.
The collaborative work between the University of Bristol and Aarhus
University (Denmark) will be presented by Bristol PhD student Peter Scholl
from the Department of Computer Science.
The paper, entitled 'Practical covertly secure MPC for dishonest majority -
or: Breaking the SPDZ limits', builds upon earlier joint work between Bristol
and Aarhus and fills in the missing pieces of the jigsaw from the groups
prior work that was presented at the CRYPTO conference in Santa Barbara last
The SPDZ protocol (pronounced "Speedz") is a co-development between Bristol
and Aarhus and provides the fastest protocol known to implement a theoretical
idea called "Multi-Party Computation".
The idea behind Multi-Party Computation is that it should enable two or more
people to compute any function of their choosing on their secret inputs,
without revealing their inputs to either party. One example is an election,
voters want their vote to be counted but they do not want their vote made
The protocol developed by the universities turns Multi-Party Computation from
a theoretical tool into a practical reality. Using the SPDZ protocol the team
can now compute complex functions in a secure manner, enabling possible
applications in the finance, drugs and chemical industries where computation
often needs to be performed on secret data.
Nigel Smart, Professor of Cryptology in the University of Bristol's
Department of Computer Science and leader on the project, said: "We have
demonstrated our protocol to various groups and organisations across the
world, and everyone is impressed by how fast we can actually perform secure
"Only a few years ago such a theoretical idea becoming reality was considered
Alice in Wonderland style over ambitious hope. However, we in Bristol
realised around five years ago that a number of advances in different areas
would enable the pipe dream to be achieved. It is great that we have been
able to demonstrate our foresight was correct."
The University of Bristol is now starting to consider commercialising the
protocol via a company Dyadic Security Limited, co-founded by Professor Smart
and Professor Yehuda Lindell from Bar-Ilan University in Israel.
Note: This story has been adapted from a news release issued by the
University of Bristol

@_date: 2013-09-11 15:49:33
@_author: Eugen Leitl 
@_subject: [Cryptography] NIST reopens RNG public comment period 
Sep. 9, 2013
SP 800-90 A Rev 1 B and C
DRAFT Draft SP 800-90 Series: Random Bit Generators 800-90 A Rev. 1: Recommendation for Random Number Generation Using Deterministic Random Bit Generators 800-90 B: Recommendation for the Entropy Sources Used for Random Bit Generation 800-90 C: Recommendation for Random Bit Generator (RBG) Constructions
In light of recent reports, NIST is reopening the public comment period for Special Publication 800-90A and draft Special Publications 800-90B and 800-90C.
NIST is interested in public review and comment to ensure that the recommendations are accurate and provide the strongest cryptographic recommendations possible.
The public comments will close on November 6, 2013. Comments should be sent to RBG_Comments at nist.gov. In addition, the Computer Security Division has released a supplemental ITL Security Bulletin titled "NIST Opens Draft Special Publication 800-90A, Recommendation for Random Number Generation Using Deterministic Random Bit Generators, For Review and Comment (Supplemental ITL Bulletin for September 2013)" to support the draft revision effort.
Draft SP 800-90 A Rev. 1 (721 KB) Draft SP 800-90 B (800 KB) Draft SP 800-90 C (1.1 MB)

@_date: 2013-09-13 11:49:24
@_author: Eugen Leitl 
@_subject: [Cryptography] Stealthy Dopant-Level Hardware Trojans 
Stealthy Dopant-Level Hardware Trojans ?
Georg T. Becker1
, Francesco Regazzoni2
, Christof Paar1,3 , and Wayne P. Burleson1
1University of Massachusetts Amherst, USA
2TU Delft, The Netherlands and ALaRI - University of Lugano, Switzerland
3Horst ortz Institut for IT-Security, Ruhr-Universiat Bochum, Germany
Abstract. In recent years, hardware Trojans have drawn the attention of governments and
industry as well as the scientific community. One of the main concerns is
that integrated circuits, e.g., for military or critical infrastructure
applications, could be maliciously manipulated during the manufacturing
process, which often takes place abroad. However, since there have been no
reported hardware Trojans in practice yet, little is known about how such a
Trojan would look like, and how dicult it would be in practice to implement
In this paper we propose an extremely stealthy approach for implementing
hardware Trojans below the gate level, and we evaluate their impact on the
security of the target device. Instead of adding additional circuitry to the
target design, we insert our hardware Trojans by changing the dopant polarity
of existing transistors. Since the modified circuit appears legitimate on all
wiring layers (including all metal and polysilicon), our family of Trojans is
resistant to most detection techniques, including fine-grain optical
inspection and checking against "golden chips".  We demonstrate the
ectiveness of our approach by inserting Trojans into two designs | a digital
post-processing derived from Intel's cryptographically secure RNG design used
in the Ivy Bridge processors and a side-channel resistant SBox implementation
and by exploring their detectability and their ects on security.
Keywords: Hardware Trojans, malicious hardware, layout modifications, Trojan

@_date: 2013-09-13 10:13:49
@_author: Eugen Leitl 
@_subject: [Cryptography] Radioactive random numbers 
What makes you think that e.g. breakdown oin a reverse biased
Zener diode is any less "true" random? Or thermal noise in a
crappy CMOS circuit?
In fact, listens a lot of potential sources, some with a higher
rate and more private than others.

@_date: 2013-09-13 08:08:38
@_author: Eugen Leitl 
@_subject: [Cryptography] Perfection versus Forward Secrecy 
I do not think that the spooks are too far away from open research in
QC hardware. It does not seem likely that we'll be getting real QC
any time soon, if ever.
The paranoid nuclear option remains: one time pads. There is obviously
a continuum for XORing with output very large state PRNGs and
XORing with one time pads. It should be possible to build families
of such which resist reverse-engineering the state. While
juggling around several MByte or GByte "keys" is inconvenient, some
applications are well worth it.
Why e.g. SWIFT is not running on one time pads is beyond me.

@_date: 2013-09-13 08:24:14
@_author: Eugen Leitl 
@_subject: [Cryptography] Introducing strangers. Was: Thoughts about keys 
You don't. The message is routed through the social network, until
it reaches your destination.
By running onion routers like Tor on top of that routed network.
With FOAF I don't mean a specific system, but a generic small-world
social network, where each member is reachable in a small number
of hops.
With multilayer transport protection, you'll get multiple layers
of encryption for your typical connection.

@_date: 2013-09-25 14:16:21
@_author: Eugen Leitl 
@_subject: [Cryptography] Gilmore response to NSA mathematician's "make 
That would completely undermine their "free" (selling their customers
as a service) model. For privacy-minded, the centralist cloud model seems to be irreversibly dead. P2P clouds are currently too unreliable
unfortunately. What we need is end to end reachability (IPv6) and
sufficient upstream for residential connections, all running on low-power
no-movable-part systems (embedded/SoCs). Most of that is still in
our future.

@_date: 2014-08-29 10:26:53
@_author: Eugen Leitl 
@_subject: [Cryptography] Hal Finney cryopreserved 
Max More max at maxmore.com Thu Aug 28 18:41:54 UTC 2014
Previous message: [ExI] It's alive?
Next message: [ExI] Hal Finney being cryopreserved now
Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]
I am both sad and happy to tell you that long-time Extropy
Institute/Extropy magazine/Extropy chat list member -- and honored
cypherpunk and Bitcoin pioneer ? was declared clinically dead this morning
and is now being cryopreserved.
Hal was diagnosed with ALS five years ago. He made it clear that once he
lost the ability to communicate, he did not want his vital functions
supported any further but should be allowed to cease functioning and
promptly be cryopreserved. Hal and Fran Finney arrived in Scottsdale,
Arizona on Tuesday where he was checked into ICU of a hospital near Alcor.
After administration of drugs to ensure no consciousness, his ventilator
was removed. Although the doctors expected all breathing to cease within an
hour, Hal?s body kept going until shortly before 9:00 am this morning,
August 28, 2014.
Immediately after pronouncement of legal death, Alcor?s standby team went
into action, restoring circulation, ventilation, administering an array of
medications, and initiating external cooling. Surgery is currently underway
to enable us to replace Hal?s blood and interstitial fluids with
cryoprotectant. Once perfusion is finished we will be able to plunge Hal?s
temperature down past the freezing point without any significant ice
formation. Once he is down to around -110 degC we will slow cooling and
take a couple more days to reach the final storage temperature of -196
degC. After that, Hal will be placed in long-term storage and cared for
until the day when repair and revival may be possible.
Hal?s wife, Fran (also an Alcor member) has stayed by Hal?s side throughout
and is observing our procedures firsthand.
Since Hal is open about his Alcor membership and said that he would be
happy for us to tell people about his choice if it might be good for
cryonics, we will be issuing a press release, as well as writing something
more extensive for *Cryonics* magazine and elsewhere. If you have thoughts
on Hal and his life and work, please send them to me.
Hal, I know I speak for many when I say that I look forward to speaking to
you again sometime in the future and to throwing a party in honor of your

@_date: 2014-07-11 13:51:02
@_author: Eugen Leitl 
@_subject: [Cryptography] hashes based on lots of concatenated LUT lookups 
It's hard to make a cryptocurrency hash that's ASICproof.
Cheap/multisource serve/PC COTS hardware has large memory size, and intrinsic random access latencies that can't be much improved upon for physical reasons (embedded memory
is limited in size due to die yield reasons, so large
LUTs are always much slower than embedded memory).
As such any hash that needs lots of serial/concatenated lookups on large (several GByte), random (same preparation as one-time
pads) memory-locked LUTs to compute is ASIC/FPGA/GPU-proof
since it can't be parallized without replicating the expensive
LUT. Dedicated hardware LUT doesn't have price advantages
over COTS-based LUT, though at very large scales LUTs requiring no
refresh are more energy-efficient.
LUT size can be variable to track technology improvements.
Distribution of several GByte LUT across participating nodes
is not too difficult with P2P protocols (Bittorrent & Co)
as it only happens once on bootstrap.
Memory-bound code, especially if run at low priority does
not make end user all-purpose (ASIC is intrinsically special-purpose) hardware unusable for other tasks the way GPU mining is.
How would you construct such a hash?

@_date: 2014-03-13 12:07:43
@_author: Eugen Leitl 
@_subject: [Cryptography] recommending ChaCha20 instead of RC4 (RC4 again) 
Moore's law is over (no more linear semilog plots), and
performance increase has never followed Moore anyway.
A lot of software developers haven't yet realized that
multi-threading scaling is doomed, too.

@_date: 2015-03-02 18:02:57
@_author: Eugen Leitl 
@_subject: [Cryptography] [Bitcoin-development] New paper: Research 
We (Joseph Bonneau, myself Arvind Narayanan, Jeremy Clark, Ed Felten,
Josh Kroll -- from Stanford, Maryland, Concordia, Princeton) have
written a ?systemization? paper about Bitcoin-related research. It?s
going to appear in the Oakland security conference later this year
(IEEE Security and Privacy) but we wanted to announce a draft to this
community ahead of time.
One of the main goals of our work is to build a bridge between the
computer science research community and the cryptocurrency community.
Many of the most interesting ideas and proposals for Bitcoin come from
this mailing list and forums/wikis/irc channels, where many academic
researchers simply don?t know to look! In fact, we started out by
scraping all the interesting posts/articles we could find and trying
to figure out how we could organize them. We hope our paper helps some
of the best ideas and research questions from the Bitcoin community
bubble up and inspires researchers to build on them.
We didn?t limit our scope to Bitcoin, but we also decided not to
provide a complete survey of altcoins and other next-generation
cryptocurrency designs. Instead, we tried to explain all the
dimensions along which these designs differ from Bitcoin.
This effort has roughly been in progress over two years, though it
stopped and restarted several times along the way.
If anyone has comments or suggestions, we still have a week before the
final version is due, and regardless we plan to continue updating our
online version for the forseeable future.

@_date: 2019-07-02 13:10:37
@_author: Eugen Leitl 
@_subject: [Cryptography] PacketCrypt: Bandwidth-hard proof of work 
This is best seen in context of community wireless mesh networks.
Bandwidth-hard proof of work. Build Status
Since the invention of blockchains, there has been research into how to make
the proof of work do something useful. Unfortunately, it has been remarkably
difficult to make the work useful without allowing miners to influence the
nature of the work problem to their own advantage, destroying the fairness of
the algorithm.
PacketCrypt takes a different approach, while the work done in PacketCrypt is
itself useless, PacketCrypt is designed to encourage investment into the
design and deployment of hardware which is useful for other purposes.
PacketCrypt encourages development of hardware solutions for high speed
encryption and decryption of messages about the size of an internet packet.
It also uses randomized code in order to encourage CPU mining as well as next
generation CPU design research. Perhaps most significantly, PacketCrypt
encourages cooperation between many mining devices, allowing bandwidth to be
expended in lieu of processor effort.

@_date: 2019-11-05 12:47:26
@_author: Eugen Leitl 
@_subject: [Cryptography] [paper] Breaking and (Partially) Fixing Provably 
Breaking and (Partially) Fixing Provably Secure Onion Routing
Christiane Kuhn, Martin Beck, Thorsten Strufe
(Submitted on 30 Oct 2019)
After several years of research on onion routing, Camenisch and Lysyanskaya,
in an attempt at rigorous analysis, defined an ideal functionality in the
universal composability model, together with properties that protocols have
to meet to achieve provable security. A whole family of systems based their
security proofs on this work. However, analyzing HORNET and Sphinx, two
instances from this family, we show that this proof strategy is broken. We
discover a previously unknown vulnerability that breaks anonymity completely,
and explain a known one. Both should not exist if privacy is proven
correctly. In this work, we analyze and fix the proof strategy used for this
family of systems. After proving the efficacy of the ideal functionality, we
show how the original properties are flawed and suggest improved, effective
properties in their place. Finally, we discover another common mistake in the
proofs. We demonstrate how to avoid it by showing our improved properties for
one protocol, thus partially fixing the family of provably secure onion
routing protocols. Subjects: 	Cryptography and Security (cs.CR)
Cite as: 	arXiv:1910.13772 [cs.CR] (or arXiv:1910.13772v1 [cs.CR] for
this version)
