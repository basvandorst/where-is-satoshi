
@_date: 2009-08-25 11:32:39
@_author: Jonathan Thornburg 
@_subject: SHA-1 and Git (was Re: [tahoe-dev] Tahoe-LAFS key management, 
If active attackers are part of the threat model, then you need to
worry about version-rollback attacks for as long as in-the-field software
still groks the old (now-insecure) versions, so "versioning" is actually
more like "Byzantine versioning".

@_date: 2009-02-01 22:53:38
@_author: Jonathan Thornburg 
@_subject: full-disk subversion standards released 
On Fri, 30 Jan 2009, Brian Gladman asked:
It's instructive to the distinction between "data in motion" encryption
(for example, a network-encryption-box (NEB) and "data at rest" encryption
(for example, a cryptographic filesystem):
A network-encryption box:
computer <----> NEB <----> ((network)) <----> NEB <----> computer
          plaintext    ciphertext         ciphertext   plaintext
As described by Henry Spencer in
  it's perfectly practical for (say) the NSA to arrange for a backdoor
in each NEB which occasionally leaks the keystream into the network,
in a way that's very unlikely to be caught in testing, but would make
it easy for an eavesdropper on the network to recover the plaintext.
A cryptographic filesystem:
I could imagine the NSA having arranged to plant some sort of microcode
backdoor in the Pentium III processor in my laptop.  (The hardest part
would probably be persuading all the Intel employees involved that it
wouldn't be a PR disaster for Intel if the news leaked out.)  In the
context of my original message, the backdoor would have to recognize
the binary code sequence of the OpenBSD AES routines when invoked by
the encrypting-filesystem vnode layer, and somehow compromise the
security (maybe arrange to leak keystream bits into free disk sectors??).
That's a tricky technical job, but I could imagine it being done, and
if it's all in processor microcode, I could even imagine it having
stayed a secret.
But that's not good enough:  What about Matt Blaze's Cryptographic File
System?  What about all the people using the various Linux encrypting
file systems?  The backdoor(s) need to cover them, too.  And the MacOS
ones (if there's not a software backdoor there).  And all the other
open-source-crypto systems.  And the backdoors have to do this without
compromising interoperability -- I have CFS directory trees which I
created on an old Sparc that I now use on my laptop.
But I think the hardest part of all is that the backdoor has to still
still recognize the various crypto binary-code-sequences even when the
relevant software is recompiled with a newer compiler using a different
global optimizer, even though that newer compiler might not even have
existed when the backdoor was inserted.
It's this variety of different software encryption schemes -- and
compilers to turn them into binary code (which is what the NSA/Intel
backdoor ultimately has to key on) that, I think, makes it so much
harder for a hardware backdoor to work (i.e. to subvert software
encryption) in this context.

@_date: 2009-01-17 11:49:45
@_author: Jonathan Thornburg 
@_subject: Bitcoin v0.1 released 
[[various possible uses of Bitcoin et al]]
In the modern world, no major government wants to allow untracable
international financial transactions above some fairly modest size
thresholds.  (The usual catch-phrases are things like "laundering
drug money", "tax evasion", and/or "financing terrorist groups".)
To this end, electronic financial transactions are currently monitored
by various governments & their agencies, and any but the smallest of
transactions now come with various ID requirements for the humans
on each end.
But if each machine in a million-node botnet sends 10 cents to a
randomly chosen machine in another botnet on the other side of the
world, you've just moved $100K, in a way that seems very hard to
trace.  To me, this means that no major government is likely to allow
Bitcoin in its present form to operate on a large scale.
I also worry about other "domestic" ways nasty people could exploit
a widespread Bitcoin deployment:
* Spammer botnets could burn through pay-per-send email filters
  trivially (as usual, the costs would fall on people other than the
  botnet herders & spammers).
* If each machine in a botnet sends 1 cent to a herder, that can add
  up to a significant amount of money.  In other words, Bitcoin would
  make botnet herding and the assorted malware industry even more
  profitable than it already is.
Is there something obvious I've missed?  Is there a clever aspect of
the design which prevents botnets from exploiting the system?  Is there
a way for every major government to monitor all Bitcoin transactions
to watch for botnet-to-botnet sending?

@_date: 2009-01-30 16:41:56
@_author: Jonathan Thornburg 
@_subject: full-disk subversion standards released  
Indeed, the classic question is "I've just bought this new computer
which claims to have full-disk encryption.  Is there any practical
way I can assure myself that there are (likely) no backdoors in/around
the encryption?"
For open-source software encryption (be it swap-space, file-system,
and/or full-disk), the answer is "yes":  I can assess the developers'
reputations, I can read the source code, and/or I can take note of
what other people say who've read the source code.
Alas, I can think of no practical way to get a "yes" answer to my
question if the encryption is done in hardware, disk-drive firmware,
or indeed anywhere except "software that I fully control".

@_date: 2009-05-01 10:49:53
@_author: Jonathan Thornburg 
@_subject: CSPRNG algorithms 
There's a nice survey, with some advice on how to construct a "good"
PRNG, at
  J. Kelsey, B. Schneier, D. Wagner, and C. Hall
  "Cryptanalytic Attacks on Pseudorandom Number Generators"
  Fast Software Encryption, Fifth International Workshop Proceedings
    (March 1998), Springer-Verlag, 1998, pp. 168-188.
    ABSTRACT: In this paper we discuss PRNGs: the mechanisms used by
  real-world secure systems to generate cryptographic keys,
  initialization vectors, "random" nonces, and other values assumed
  to be random. We argue that PRNGs are their own unique type of
  cryptographic primitive, and should be analyzed as such. We propose
  a model for PRNGs, discuss possible attacks against this model,
  and demonstrate the applicability of this model (and our attacks)
  to four real-world PRNGs. We close with a discussion of lessons
  learned about PRNG design and use, and a few open questions.
The authors' reputations suggest their advice is probably excellent...

@_date: 2010-08-01 13:57:59
@_author: Jonathan Thornburg 
@_subject: Is this the first ever practically-deployed use of a threshold 
A minor nit... his name was "Lagrange" (one word), not "La Grange"
(2 words).  See  for further details.
Lagrange interpolating polynomials are widely used in non-crypto numerical
computations (solving differential equations and suchlike).

@_date: 2010-07-09 21:16:30
@_author: Jonathan Thornburg 
@_subject: [TIME_WARP] 1280-Bit RSA 
The following usenet posting from 1993 provides an interesting bit
(no pun itended) of history on RSA key sizes.  The key passage is the
last paragraph, asserting that 1024-bit keys should be ok (safe from
key-factoring attacks) for "a few decades".  We're currently just
under 1.75 decades on from that message.  I think the take-home lesson
is that forecasting progress in factoring is hard, so it's useful to
add a safety margin...
   From: pcl at ox.ac.uk (Paul C Leyland)
   Newsgroups: sci.crypt
   Subject: Re: Questions about RSA.
   Message-ID:    Date: 16 Feb 93 10:26:11 GMT
   References: <1993Feb10.183246.29386 at ee.ubc.ca>
   Distribution: sci.crypt, alt.security
   Organization: Oxford University Computing Services, 13 Banbury Rd Oxford OX2 6NN
   Lines: 59
   In-reply-to: jrusmise at ee.ubc.ca's message of 10 Feb 93 18:32:46 GMT
   ...
      1) The article suggests that the length of 'n', (where n is the product
      of two large primes p and q, and n is the modulus used with the
      encryption and decrytion keys to decode and encode) be 200 digits. [page
      125, top right]  200 digits base 10 is about 664 binary digits.  Now, to
      the question.  The program PGP provides various levels of key length,
      384 bits, 512 bits and 1024 bits.   How were these numbers decided on? I
   The PGP values are round numbers (3/8, 1/2 and 1) in kilobits.
   They are (handwaving furiously here) "about the right size" for
   testing, routine use and archival security.  The RSA values are
   about the right size for routine use.
      realize that the state of computer technology at the time the RSA
      article was written was very different than it is now, but have there
      been significant advances in crypto breaking since 1978 that would
      make factoring such large numbers much easier? (Perhaps the Connection
      Machine.....)  Really I'm interested in a discussion of the design
      decisions/tradeoffs here.
   Let me try to justify the armwaving a little.  First, we must
   realise that the larger the keys, the greater the run-time of the
   encryption and decryption process.  Purists may nit pick, but
   roughly speaking doubling the number of digits in the key
   increases the run time eightfold.  [Purists: I'm assuming a
   n-squared multiplication routine and the simple binary method of
   exponentiation].  So small moduli are good.
   So far as is known, the only way to find the RSA secret key
   (other than espionage, bribery, extortion, etc) is to factorize
   the modulus.  Here large moduli are good.  Roughly speaking
   *adding* a few bits to the length of the modulus raises the
   factorizing cost eightfold.  Compare this to the encryption,
   where *doubling* costs us that much.  The meaning of "a few bits"
   can also be argued over, but it is around 20 bits, depending on
   methods and the size of the number.
   Current state of the art described in the open literature
   factorizes 120-digit numbers in a time of order one year, using
   machines of order 1000mips performance.  Again, purists can post
   better numbers if they wish.  384 bits is 116 digits so the PGP
   test keys can, with sufficient effort, be cracked with today's
   technology.  512 bits is well beyond current technology (155
   digits) but *might* be accessible in a few years with better
   algorithms and faster machines and more of them working in
   parallel and ... (I'm handwaving again).  1024-bits, so far as is
   known should be ok for a few decades.  I'd be happy to be proved
   wrong, as there's lots of other numbers I'd like to be able to
   factorize.
   Paul
   --
   Paul Leyland           | Hanging on in quiet desperation is
   Oxford University Computing Service      |     the English way.
   13 Banbury Road, Oxford, OX2 6NN, UK     | The time is come, the song is over.
   Tel: +44-865-273200  Fax: +44-865-273275 | Thought I'd something more to say.
   Finger pcl at black.ox.ac.uk for PGP key    |

@_date: 2010-07-28 11:04:30
@_author: Jonathan Thornburg 
@_subject: deliberately crashing ancient computers (was: Re: A mighty fortress 
Please stop and think about the consequences before using something
like this!  People who are still using IE6, Windows 95, etc, are
usually doing so for reasons which make sense in their lives, things
(a) very low computer literacy
(b) slow/unreliable internet connections (dialup?)
(c) old/small/slow computer (& lack of money to buy a better one)
(d) English not her/his native language (to read your how-to-upgrade msg)
(e) that's what all their friends & professional colleagues use
These people are unlikely to change just because your site makes
their computer crash.  (They're also unlikely to distinguish between
"IE6 crashed" and "the computer crashed", and yes, they're likely to
blame your website for the problem.)
I too would love to see IE6 die.  Ditto Windows 95.  But I don't think
actively trying to crash my colleague Professor X's computer is either
ethical or an appropriate solution to her ancient computer environment.
(She is elderly, retired, lives in a very poor country in South America,
and has only dialup internet.  The local computer shops/geeks where she
lives usually recommend Windows 95 for upgrades/reinstalls.  I don't
know what web browser they pitch...)

@_date: 2010-10-06 16:05:42
@_author: Jonathan Thornburg 
@_subject: Formal notice given of rearrangement of deck chairs on RMS 
I found it amusing that this message was accompanied by an S/MIME
certificate which my mail client (alpine) was unable to verify, resulting
in the error messages
          [Couldn't verify S/MIME signature: certificate verify error]
    [ This message was cryptographically signed but the signature ]
    [ could not be verified. ]

@_date: 2013-08-27 21:47:04
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Implementations, attacks on DHTs, Mix Nets? 
This sounds remarkably like a description of DNSSEC.
Assuming it were widely deployed, would DNSSEC-for-key-distribution
be a reasonable way to store
  email_address --> public_key

@_date: 2013-08-28 11:03:55
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Email and IM are ideal candidates for mix 
<521CE337.6030706
Maybe it's because you've forgotten the passphrase guarding the
corresponding private key?
Or because you'd like to do the electronic equivalent of "change my name,
start [this facet of] my electronic life over"?

@_date: 2013-08-30 16:52:27
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Functional specification for email client? 
This probably needs amending to deal with messages addressed to multiple
recipients (either cc:, bcc:, or simply multiple to: addresses).

@_date: 2013-12-07 16:33:59
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Fun with hardware RNGS: the Infinite Noise 
I have several (somewhat related) devil's-advocate comments:
[These actually apply to just about any hardware RNG]
[I should emphasize that I'm *not* trying to be irritating here, i.e.,
these are meant as *constructive* comments and implicit suggestions for
how the design might be made more robust.]
It's really good that you checked that coupling in a 1 MHz sine wave
doesn't ruin the randomness.  But what about other nonrandom signals
coupled in from the environment?  Most real-world environments have a
lot of RF floating around (not to mention 50/60Hz hum), and it would
be nice to check a wide range of possible signals and
Checking for couplings with a spice model is good... but can we be sure
that the behavior of the actual physical circuit matches that of the
spice model in this regard?  E.g., does the spice model accurately model
all the parasitic capacitances between different circuit elements?  If
not, is there some argument that it's ok to neglect these?
If you have multiple copies of the circuit in close proximity, (how)
do they perturb each other's operation?  Particularly given that they
probably all share a common clock to avoid Buridan's paradox.  Maybe
we need some shielding around each circuit?  Or at least some buffer
amps in the clock tree?
Instead of xoring 80 mildly-random bits, why not output them all and
let software [test them and then] run them through your favorite
cryptographic hash fn?
The underlying problem in (1), (2), and (3) is that this circuit is --
by design -- very sensitive to tiny amounts of noise... so we have be
very paranoid that that "noise" isn't a nonrandom parasitic coupling
from somewhere else.

@_date: 2013-12-17 10:23:09
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Fwd: [IP] 'We cannot trust' Intel and Via's 
This (and everything else ianG wrote EXCEPT for the sentence I'm about
to quote) is [IMHO] certainly true.
IanG went on to write
I don't think that fact argues anything one way or the other on the
trustworthyness of Intel CPUs.  I think straightforward above-board
marketing logic can equally well explain popcount:
Suppose you're an Intel manager.
A customer (who has bought lots of Intel chips in the past
            and who we know has a huge budget and plans to buy
            either Intel chips stuff or someone else's in the future)
comes to Intel and says
  "if you add popcount, we will be more likely to buy Intel chips".
Or even
  Intel manager knows that the NSA loves popcount instructions.
  (E.g., s/he knows about history of CDC Cyber Series & Cray back
  in the 1960s/70s/80s.)  S/he puts 2 and 2 together and decides
  to have a chat with Intel's government-sales people to see if
  popcount might boost sales.  They say "oh yea, the NSA people are
  always going on about how great popcount is".  Manager  asks
  architecture manager how much it would cost to implement popcount.
  Architecture manager checks with the tech folks and replies "it
  would be pretty cheap".  Information percolates back up the
  corporate food chain until somebody says "Make it so".
It's perhaps also pointing out that some of Intel's competitors also
have popcount instructions, e.g. Sparc v9 and Alpha (r.i.p.).

@_date: 2013-12-22 16:51:44
@_author: Jonathan Thornburg 
@_subject: [Cryptography] how reliably do audits spot backdoors? (was: Re: RSA 
[[re Peter Gutmann's claim that backdoors in source-code
may escape discovery in audits]]
Looking at the winners in the Underhanded C Contest
  strongly suggests that Peter is right.  And these are backdoors hidden
in on-the-order-of-100 lines of code, which is a lot smaller (and thus
harder-to-hide-a-backdoor-in) than most real crypto code.
For that matter... OpenBSD did full code audits many years ago... yet
nontrivial bugs (accidental, not maliciously-planted) are still being
found in the codebase.
Auditing code is *hard*.  We should no more expect auditors to be 100%
perfect at finding backdoors than we should expect well-meaning programmers
to be 100% perfect at (say) correctly using strncpy().

@_date: 2013-12-24 16:24:28
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Passwords are dying - get over it 
What are the advantages & disadvantages of this (diceware) vs the old
"think of a long sentence or phrase, and take the 1st letter of each word"
scheme.  E.g. "FDR was elected to 3 full terms as US president & also
served part of a 4th term, but he was never vice-president" gives
  Fwet3ftaUp&aspoa4t,bhwnv-p
That's 26 characters, with surely at least 4 bits of entropy/character,
so we're comfortably over 100 bits of entropy.

@_date: 2013-12-25 11:05:40
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Passwords are dying - get over it 
On Wed, 25 Dec 2013, Kent Borg replied:
You're right.  I should have written "a long sentence or phrase
which is *unique*, i.e., something that noone has ever written before"
Anything that's part of some larger body of text (whether dead-trees
or online) is verboten.
It seems to me to be a modest improvement on the "sequence of
semantically-unrelated-words" scheme.
My (geek) experience is that for passwords which are used *often*
(say multiple times per day) memorization happens automagically.
So... such a scheme can be used for the (strong) master password which
unlocks a password manager; the latter can be used to hold all the other
passwords with which one is plagued.
Of course, this requires a strong password manager, a robust (encrypted)
backup scheme for the password-manager database, and probably various
other fundamentally-doable-but-all-tricky-for-non-geeks tasks which
have slipped my mind right at the moment.
I don't know how well or poorly this will work for non-geeks.
On the optimistic side: even  probably knows a great many details about *something*
(maybe the history of the 1953 playoffs in , maybe 8 generations
of family geneology, maybe the social life of every TV starlet of
the past decade, but most humans have passionate interests in
*something*).  Using the 1st-letter-of-each-word scheme, that
"something" could be the topic underlying a fairly-memorable strong
On the pessimistic side: I fear that this (together with the use of a
good password manager and robust encrypted backups for same) is asking
for more mental effort than [the quite small amount] the median computer
user is willing to exert.
Along these lines, the classic
  Whitten & Tygar
  "Why Johnny can't Encrypt: A Usability Evaluation of PGP 5.0"
  8th Usenix Security Symposium, 1999
  is very salutory, and well worth rereading every so often.

@_date: 2013-12-26 11:13:54
@_author: Jonathan Thornburg 
@_subject: [Cryptography] On Security Architecture, The Panopticon, 
[[a hardware AES accelerator can't be backdoored because it's deterministic]]
Henry Spencer posted the classic key-leaking attack against a hardware
encryptor way back in 1999.  If our Esteemed Moderator will permit it,
I'd like to repost Henry's message here.  Alas the original list-archive
url is now dead.
--- begin Henry Spencer repost ---
      _________________________________________________________________
   [Date Prev][Date Next][Thread Prev][Thread Next][Date Index][Thread
   Index]
Re: linux-ipsec: Intel IPSEC accelerator gives 3DES protected 100Mbit Ethernet
     _________________________________________________________________
     * To: Linux IPsec      * Subject: Re: linux-ipsec: Intel IPSEC accelerator gives 3DES
       protected 100Mbit Ethernet
     * From: henry at spsystems.net (Henry Spencer)
     * From: linux-ipsec at clinet.fi
     * Date: Thu, 16 Sep 1999 10:48:52 -0400 (EDT)
     * In-Reply-To: <199909161411.KAA02388 at tonga.xedia.com>
     * Reply-To: linux-ipsec at clinet.fi
     * Sender: owner-linux-ipsec-local at sandelman.ottawa.on.ca
     _________________________________________________________________
At first I thought this was pretty much a non-issue here.  The problem
with the RNG is that it's so hard to decide whether its output is "really"
random.  But 3DES is a deterministic transform which can be tested against
other implementations, so you can easily establish whether the chip is
really doing 3DES or not.
Alas, then I got to thinking.  Suppose one built a 3DES accelerator chip
so that, if and only if:
(a) the chip is doing near-continuous encryptions at high speed, and
(b) the keys are changing every packet or two, and
(c) the chip detects -- via a simple mechanism like a little hash table --
        a key which has appeared before, recently, and
(d) this key has not been marked "compromised" in the hash table, and
(e) an internal 16-bit packet counter is all-1s,
(!) mark the key compromised in the hash table, XOR the key with the
string "GOTCHA, YOU OPEN-SOURCE WEENIES -- NSA RULES!", prefix it with a
random-looking constant bit pattern, and sprinkle the resulting bits into
the encrypted data, in a haphazard but deterministic pattern.
This is, of course, an encryption error.  But rules (a)-(e) make it
essentially irreproducible, so it won't happen a second time (and will be
quite difficult to reproduce even in a test setup).  Almost certainly it
will get written off as a random error, and the affected packet will be
re-processed correctly and re-sent, and all will be well.
Except that an eavesdropper on the high-speed wire just looks for the
constant bit pattern in the right places in a packet, and (almost) every
time he sees it, he's nabbed an encryption key.
There's no limit to the complexity that can be added -- especially if
you're willing to consider active wiretapping, with the chip going into
this mode only if it sees (say) an ICMP ping with the right data in it --
to defeat attempts to find this sort of thing on the test bench.
I fear I agree with William; nothing short of peer review of the hardware
design makes such a device trustworthy.
                                                          Henry Spencer
                                                       henry at spsystems.net
                                                     (henry at zoo.toronto.edu)
This is the linux-ipsec-local at sandelman.ottawa.on.ca mailing list. It is a
restrict-Post filtered version of linux-ipsec at clinet.fi.
     _________________________________________________________________
   Follow-Ups:
     * Re: linux-ipsec: Intel IPSEC accelerator gives 3DES protected
       100Mbit Ethernet
     * From: Richard Guy Briggs
       linux-ipsec at clinet.fi
   References:
     * Re: linux-ipsec: Intel IPSEC accelerator gives 3DES protected
       100Mbit Ethernet
     * From: pkoning at xedia.com (Paul Koning)linux-ipsec at clinet.fi
     _________________________________________________________________
     * Prev by Date: Re: linux-ipsec: Intel IPSEC accelerator gives 3DES
       protected 100Mbit Ethernet
     * Next by Date: linux-ipsec: IP Sec w/ dynamic IP addresses ?
     * Prev by thread: Re: linux-ipsec: Intel IPSEC accelerator gives
       3DES protected 100Mbit Ethernet
     * Next by thread: Re: linux-ipsec: Intel IPSEC accelerator gives
       3DES protected 100Mbit Ethernet
     * Index(es):
          + Main
          + Thread
--- end Henry Spencer repost ---

@_date: 2013-12-28 15:16:30
@_author: Jonathan Thornburg 
@_subject: [Cryptography] how reliably do audits spot backdoors? 
A related point, which seems relevant in view of the recent thread on
whether all-integer-arithmetic-modulo-2^N is (paraphrasing) "logical"
or "evil":
In C, signed-integer size and overflow semantics are a "quality of
implementation" issue, i.e., a C compiler is allowed-but-not-required
to trap signed integer overflow.  E.g., gcc supports the '-ftrapv'
option which generates traps for signed overflow on addition, subtraction,
and multiplication operations.  C unsigned integers have (guaranteed)
modulo-2^N arithmetic semantics.
In Java, ONLY 32-bit signed integers are available; there are NO unsigned
integers and no 64-bit (or other-length) integers available.  Moreover,
integer overflow checking is forbidden, i.e., if you take i = 2147483647
and add one to it, the result is REQUIRED to be -2147483648.
In C++, native integers are the same as C, but the language permits one
to define (say) an integer-with-guaranteed-overflow-checking class; other
code can then rely on overflows being caught.

@_date: 2013-12-31 00:05:40
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Whether Henry Spencer's key-leak would be 
John Gilmore replied:
I suspect things are much *worse* for long-haul networks, and even
worse for VPNs routed over the public internet.  If (say) 'ping' sees
1% of packets lost between Tokyo and Tehran, there are a lot of hops
involved, and a lot of different players who would need to be contacted
to pin down where the packets are being 'lost'.

@_date: 2013-10-02 10:25:19
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
On Tue, 1 Oct 2013, someone who (if I've unwrapped the nested quoting
Standard construction in US & Canada uses 2/4's on 16" (repeat: 16")
centers.  Perhaps there's a lesson here:  leave carpentry to people
who are experts at carpentry.
And leave crypto to people who are experts at crypto.

@_date: 2013-09-14 11:39:57
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Credit for Trusting Trust 
[[about Paul Karger's countermeasure to the "Ken Thompson" trojan-compiler
It's important to realise that Wheeler's "diverse double-compiling"
(DCC) countermeasure does NOT require hand examination of compiler
output -- the tests are (or can be) fully automated even for realistic
industrial-strength compilers like GCC (on which Wheeler demonstrated
DCC in his thesis).
And a tiny historical nit: Wheeler's dissertation was in 2009, not 2005.

@_date: 2014-04-03 14:07:09
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Clever physical 2nd-factor authentication 
This seems like a variant on the Cardano grille
  It also resembles a generalization of a scheme I've seen used by some
UK banks: the customer has an N-digit PIN, and on any given transaction
she is asked for some proper subset of those digits.
In each case, replaying a single captured transaction should fail, but
an attacker who can observe or actively-attack multiple transactions
can easily break the system.

@_date: 2014-04-08 13:12:25
@_author: Jonathan Thornburg 
@_subject: [Cryptography] The Heartbleed Bug is a serious vulnerability in 
This analysis appears to say that it's not worth spending money to
fix a hole (bug) unless either money has already been spent or damages
have *already* occured.  This ignores possible or probable (or even
certain!) *future* damages if no rework has yet happened.
This seems like a flawed risk analysis to me.
In particular, this analysis could be used to argue against spending any
money trying to reduce risk or damages from rare events which haven't
happened yet.  For example, as of January 1, 2011 (= 69 days before the
Fukushima Daiichi disaster), this analysis would have said that since no
nuclear reactor in the world has ever been damaged by a tsunami (a true
statement on that date), it isn't worth spending any money trying to
secure nuclear reactors against tsunami damage.

@_date: 2014-04-18 13:39:43
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Simpler programs? 
Licensing is important.  IBM's lawyers put some dubious clauses in
Postfix's license (see, e.g.,
  for a synopsis), so OpenBSD considers it inappropriate for their base
install.  OpenBSD is in the process of moving from Sendmail to their
own new MTA "OpenSMTPD" (BSD-licensed, includes privilege-separation).

@_date: 2014-04-21 12:52:25
@_author: Jonathan Thornburg 
@_subject: [Cryptography] It's all K&R's fault 
For anyone who hasn't read them, the paper/slides describing OpenBSD's
swap encryption (which has been turned *on* in the default install
since ~2000) make interesting reading:

@_date: 2014-04-22 16:10:05
@_author: Jonathan Thornburg 
@_subject: [Cryptography] encrypted swap (was: It's all K&R's fault) 
On Mon, Apr 21, 2014 at 05:57:23PM -0400, Sandy Harris asked:
Now that RAM is relatively cheap swap isn't needed anywhere near as
often as it was 10 or 20 or 30 years ago.  But some computer users
still find it useful to occasionally run workloads which swap, without
needing to provision correspondingly large physical memory (which would
go unused much of the time).
For example, the laptop on which I'm typing this message has 3GB of
physical memory, and most of the time I use considerably less than
that.  But every few months I need to (re)compile the latest revision
of some machine-generated C code for which the compiler needs 4-6 GB
of memory (that's *without* optimization).  Given some swap space,
this compile is as simple as typing 'gmake' and going to bed.  Without
swap, I'd probably need to get a new laptop, or I'd need to arrange an
account on a large-memory machine somewhere else (running the identical
OpenBSD version) and copy the code and .o files back and forth as
necessary.  So swap looks pretty attractive...

@_date: 2014-04-25 13:21:34
@_author: Jonathan Thornburg 
@_subject: [Cryptography] GCC bug 30475 (was Re:  bounded pointers  in C) 
The preprocessor doesn't grok  sizeof() , so this won't do what you want.
(One way to see the problem is you're writing  sizeof(type)  and C types
live within {}-scopes... but the preprocessor groks neither types nor

@_date: 2014-01-02 11:44:48
@_author: Jonathan Thornburg 
@_subject: [Cryptography] What is a secure conversation? (Was: online 
The most detailed and authoritative (public) version is probably

@_date: 2014-01-04 18:23:32
@_author: Jonathan Thornburg 
@_subject: [Cryptography] defaults, black boxes, APIs, 
I'm not sure if that's true.  What I see is low-security consumer
systems (e.g., the usual stuff from Microsoft, Adobe, etc) doing
dynamic updates every month or even every week.  But OSs which make
security a very high priority, like (say) OpenBSD, aren't moving that
way at all -- they're staying with the old "updates are manually
applied by a (human) system administrator" model.
The OpenBSD website points out that they've only had two remote holes
in the default install in "a heck of a long time" (I think more than a
decade).  So perhaps the manual-updates security model remains viable....

@_date: 2014-01-05 12:25:34
@_author: Jonathan Thornburg 
@_subject: [Cryptography] defaults, black boxes, APIs, 
I wrote
On Sun, 5 Jan 2014, Phillip Hallam-Baker replied:
That's certainly part of it:
from # To ensure that novice users of OpenBSD do not need to become
# security experts overnight (a viewpoint which other vendors seem
# to have), we ship the operating system in a Secure by Default mode.
# All non-essential services are disabled. As the user/administrator
# becomes more familiar with the system, he will discover that he
# has to enable daemons and other parts of the system. During the
# process of learning how to enable a new service, the novice is
# more likely to learn of security considerations.
# This is in stark contrast to the increasing number of systems that
# ship with NFS, mountd, web servers, and various other services
# enabled by default, creating instantaneous security problems for
# their users within minutes after their first install.
Actually, sendmail is (still) part of the current OpenBSD, and runs in
the default install.  I don't know if that sendmail is vanilla ISC or
if OpenBSD has local patches to it.
The OpenBSD project is working on a replacement MTA (smtpd), but this
isn't quite ready for full-time production use yet.
I agree, userland causes a lot more problems than kernels.  Fortunately,
there are things a kernel and a libc can do that help, by reducing the
incidence of bugs in userland code
  and/or by blocking some bugs from being exploitable
  Only 30? :)
But this raises some genuine questions:
* Is there a secure web browser?  My trust level in any of the biggies
  (Microsoft, Apple, Google, Mozilla) is low...
* I've just booked a hotel room in ; the hotel sent me a
  .docx file which claims to be a confirmation.  Is there an "office suite"
  in which it's safe for me to look at that .docx file?
* Same question, but for pdf files?
* For bonus points, can that pdf-viewer edit fillable pdf forms?  I have
  seen claims that evince or mupdf can do this... but neither seems to
  handle either US or Canadian tax forms. :(

@_date: 2014-01-05 22:18:30
@_author: Jonathan Thornburg 
@_subject: [Cryptography] defaults, black boxes, APIs, 
I emaphatically agree.  NoScript offers a lot of protection, but its
cost in usability is pretty high.  Many websites work fine without
javascript, but alas a fair number of (badly designed) websites fail,
often in unobvious ways.
When the failure mode is "I can't login" that's at least a
fail-safe system.  But when the failure mode is "I'm trying to do
$very_important_transaction and have entered all my credit-card and
other information and clicked the "make it so" button, then the
website hangs (endlessly showing a spinner animated-gif) with no
indication of whether or not my transaction went through", well,
that's a more serious problem.  Alas, it's one that occurs fairly
often with NoScript, so much so that I tend to disable NoScript
before doing $very_important_transaction on any website where I
haven't successfully used NoScript before.
I think the root of the problem is that many websites use 3rd-party
processors for some functionality, and the 3rd-party website must
be whitelisted (to allow its javascript to run) BEFORE the transaction
starts in order for things to function properly.  Alas, there's often
no way to find out just which 3rd-parties need to be whitelisted
(leaving aside the issue of whether or not they're trustworthy)
ahead of time. :(
It would be nice if NoScript had a "temporary disable" feature,
i.e., a "allow scripts globally, but only for {the next 10 minutes,
the lifetime of this browser tab, or some other short time}.
But so far as I can tell, this feature doesn't exist.

@_date: 2014-01-06 13:01:47
@_author: Jonathan Thornburg 
@_subject: [Cryptography] defaults, black boxes, APIs, 
Widespread use of EXISTING compiler options which catch almost all
buffer overruns in C code would be a good starting point.  For example:
* AddressSanitizer does compiler instrumentation of memory accesses
  to catch almost all buffer overruns in C code at a cost of around
  a factor of 2 in CPU and < 12.5% in memory use, see
      for details
* bounded pointers (compiler represents all pointers "fat", i.e.,
  augmented with explicit lower/upper bounds maintained and checked
  at runtime) ==> also catches almost all buffer overruns, again at
  a factor-of-a-few cost in CPU + modest memory overheads
Right now some compilers have skeleton support for these:
* llvm and gcc implement AddressSanitizer for {x86,x86-64}, but is this
  production-ready?
* what about other platforms?
* gcc has had multiple bounded-pointers projects over the years, most
  recently "mudflap", but it's not even clear if this works reliably
* do debuggers grok this?
Once compiler support is solid, then a lot more grunt work (libraries,
debuggers, and all the other pieces of the software-development toolchain)
will still be needed before this can be used routinely by developers.
But ultimately, if security-critical OSs and applications routinely used
this sort of run-time protection, they'd be secure against a large class
of buffer overruns.  We have enough CPU and memory available today that
"wasting" a factor of 2 or 3 or even 10 on this might well be a good
On the other hand... returning from security-geek-fantasy-land to the
real world...  right now there are still a lot of production OSs, even
ones that call themself "server OSs" (FreeBSD 10, here's looking at you!),
that don't even have ASLR (address-space layout randomization) turned on
by default.  This has a performance cost of only 1 to 3 percent!  Sigh.....
Indeed, how many binaries on *your* laptop still use gets() and sprintf()?

@_date: 2014-01-21 08:13:16
@_author: Jonathan Thornburg 
@_subject: [Cryptography] cheap sources of entropy 
However -- and very much *unlike* electronic voting systems -- given
opposition-party scruitineers watching the counting process (and by
"watching" I mean literally looking over the shoulders of the ballot
counters), it's very hard to do such an attack on a *large scale* in

@_date: 2014-07-18 14:03:24
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Steganography and bringing encryption to a piece 
Alternatively, as impenetrable as
  130 13042 13401 8501 115 3528 416 17214 6491 11310
  18147 18222 21560 10247 11518 23677 13805 3494 14936
  ...
(the first two lines of the Zimmermann Telegram,
The Zimmerman-telgram code had a many-to-one mapping from German words
to codewords, large numbers of nulls, and various other measures to
confuse any attempted decryption.  But Room 40 still broke it.
A rereading of Kahn "The Codebreakers" on the era of Nomenclatures and
beyond does not offer high hopes of this diary-code staying unbroken if
the NSA decides it's worth a few analyst-months and GPU-centuries...

@_date: 2014-07-21 09:15:44
@_author: Jonathan Thornburg 
@_subject: [Cryptography] miniLock seems pretty interesting 
Page 8 of the slides pdf is a description of cryptocat with no mention
of it's gaping holes.  This does not inspire warm&fuzzy feelings about
top-notch crypto programmers:

@_date: 2014-06-25 12:32:44
@_author: Jonathan Thornburg 
@_subject: [Cryptography] What has Bitcoin achieved? 
Two other contemporary-use-of-cheques notes:
* BC Hydro, the main electricity utility in the province of
  British Columbia, Canada, does not currently offer online payments.
  (I think they'll allow you to use a 3rd-party online payment system,
  who of course charges a fee for that "privilege", quite apart from
  any security issues.)  So, I mail a paper cheque to BC Hydro every
  2 months to pay my electricity bill.
* Typical international wire-transfer fees between (say) the USA and
  Canada are around $50-$75 per transfer.  Depending on your financial
  institution's fee schedule and exchange-rate policies, mailing a paper
  cheque can be significantly cheaper than an international wire transfer.

@_date: 2014-05-01 14:36:56
@_author: Jonathan Thornburg 
@_subject: [Cryptography] GCC bug 30475 (was Re: bounded pointers in 	C) 
Moreover, the Java Language Spec states, ("Java SE 8 Edition", page 44
of the pdf)
# The integer operators do not indicate overflow or underflow in any way.
In other words, in Java 2's-complement wraparound is *mandatory*.  Among
other things this means that a Java implementation is *forbidden* from
throwing an exception on integer overflow.

@_date: 2014-05-08 10:19:33
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Cryptography topic for Research Paper 
As others have noted, there's a *lot* of hype surrounding quantum
computing.  Scott Aaronson's blog is a useful counterweight, e.g.,
        The last of these is an excellent discussion (refutation!) of D-Wave's
claims that their quantum computer can already solve certain problems
faster than any classical computer.

@_date: 2014-11-19 16:13:37
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Where should I start with cryptography? 
As well as the crypto (which various other people have covered),
it's also very important to know some of the "big picture" issues
which surround the crypto.  I highly recommend Schneier's blog
( and the following two books:
Peter Gutmann
"Engineering Security"
drafts available free online at
Ross Anderson
"Security Engineering", 2nd Edition
Wiley, 2008, ISBN 978-0-470-06852-6

@_date: 2014-10-21 17:48:26
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Best internet crypto clock 
[[...]]  While describes the technique, and says that the UK police have recorded
this since 2005.

@_date: 2014-09-13 11:59:11
@_author: Jonathan Thornburg 
@_subject: [Cryptography] RFC possible changes for Linux random device 
Without knowing the full set of design goals and the threat model,
it's very difficult to evaluate the code.  That is, we don't know what
you're trying to accomplish -- is your new code supposed to
* be faster?
* to be stronger against cryptographic analysis of its output?
* provide high-quality randomness earlier in the boot sequence?
* use less kernel memory?
* be more resistant to cache or timing attacks by malicious user code
  running the local processor?
* more resistant to cache or power-consumption side-channel attacks
  mounted by an attacker with physical (but not software) access to
  the local processor & memory?
* be more resistant to timing attacks by attackers on the local network?

@_date: 2014-09-18 10:16:33
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Email encryption for the wider public 
This breaks an E-mail use case that I often use fairly frequently:
I need to read someone my E-mail address over the phone.  (For example,
I've just completed some transaction by telephone, and I'd like the
business to E-mail me a receipt/confirmation/whatever.)  Getting the
spelling of $spouse's (8-letter, but "odd" to many people) E-mail correct
over a poor-quality phone connection is hard enough already!

@_date: 2014-09-18 10:27:16
@_author: Jonathan Thornburg 
@_subject: [Cryptography] RFC possible changes for Linux random device 
It's perhaps worth noting that OpenBSD has had this (and turned it on
by default) since around 2000.  In fact, the OpenBSD implementation uses
per-page encryption keys.  See
    for the paper & slides presented at Usenix Security 2000.
I don't think OpenBSD has this. :(

@_date: 2014-09-19 13:31:34
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Email encryption for the wider public 
I replied:
Alas, my experience has not been so good:
* If I just say "Hotel Oscar Romeo Sierra Foxtrot ..." a significant
  fraction of listeners have no idea of what I'm talking about.
* Even I say "H as in Hotel, O as in Oscar, R as in Romeo, ...", the
  error rate is still substantial, particularly if the E-mail address
  I'm trying to spell out has repeated letters.

@_date: 2014-09-21 21:54:40
@_author: Jonathan Thornburg 
@_subject: [Cryptography] new wiretap resistance in iOS 8? 
[[about DES]]
Actually, Diffie and Hellman published their design for a
custom-hardware DES-cracker in 1977:
  Whitfield Diffie and Martin E. Hellman
  "Exhaustive Cryptanalysis of The NBS Data Encryption Standard"
  IEEE Computer, June 1977, pages 74-84,
  Their paper makes fascinating reading even today.
Their design could search the entire 2^56 DES keyspace in about a
day (mean time to solution about 12 hours), at a capital cost which
they estimated at about $20 Million (using 1976 hardware technology).

@_date: 2015-12-04 12:32:21
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Anyone else seen some odd shipping delays? 
A slightly more accurate statement might be that China has good reason
to fear cyber attack from the US, Russia, and other countries.  But it
seems to me that the US is China's  attack threat.  (Consider the classic
trilogy -- Means: Stuxnet et al; Motive: geopolitics; Opportunity: lots
of IP connectivity, lots of business travelers to provide cover, lots of
submarine cables to tap, etc.)

@_date: 2015-12-07 21:59:33
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Anyone else seen some odd shipping delays? 
So... how does one go about buying something that local retailers
don't carry?  Almost any online purchase wants a credit card
(= tied to your identity) and a shipping address (ditto).
The alternatives which occur to me are
* travel to $big_city and visit a well-stocked retailer
  (still falls down for unusual stuff)
* ask a friend to place the order for you
* ask a local store to special-order for you
Are there better alternatives?

@_date: 2015-12-24 14:13:42
@_author: Jonathan Thornburg 
@_subject: [Cryptography] are flipped coins unbiased? (was: Re: Photon beam 
For a detailed analysis of coin tossing, see
   Persi Diaconis, Susan Holmes, and Richard Montgomery
   "Dynamical Bias in the Coin Toss"
   SIAM Review, 49(2):211-235 (2007)
      Abstract:
      We analyze the natural process of flipping a coin which is caught
      in the hand. We show that vigorously flipped coins tend to come
      up the same way they started. The limiting chance of coming up
      this way depends on a single parameter, the angle between the
      normal to the coin and the angular momentum vector. Measurements
      of this parameter based on high-speed photography are reported.
      For natural flips, the chance of coming up as started is about .51.
(For those who may not know of him, Persi Diaconis is a very well-regarded
professional mathematician, former professional magician, and expert card

@_date: 2015-02-10 15:39:19
@_author: Jonathan Thornburg 
@_subject: [Cryptography] What do we mean by Secure? 
That not true either.
For example, by looking around the (farily small) room in which I'm
sitting right now, I can prove the absence of adult elephants in this
If you want a purely computer-based example, if (on a Unix system) I
execute 'cat /etc/motd' and the output is unexceptional, that proves
the absence of any multi-megabyte-long Secret Plan for World Domination
stored in that file.
This latter example also demonstrates that proofs generally (maybe
always?) assume certain axioms.  In this case, these include that my
shell is finding and executing the right 'cat' program, that 'cat' is
telling the truth about the file contents, and that xterm and the X
server are faithfully rendering those contents into pixels-on-the-screen.
In the face of a sufficiently clever rootkit any/all of these assumptions
might fail.

@_date: 2015-02-20 14:45:18
@_author: Jonathan Thornburg 
@_subject: [Cryptography] [cryptography] Equation Group Multiple Malware 
+1 on the above.
However, note that postal-mail *metadata* (i.e., everything on the
outside of the envelope, including specifically the to/from address,
date, and point of entry into the postal system), are defintely
recorded/logged/archived in at the USA (and probably many other
countries as well).  See, e.g.,
  with the "money quote" buried in the 5th paragraph:
# a vastly more expansive effort,
# the Mail Isolation Control and Tracking program, in which Postal Service
# computers photograph the exterior of every piece of paper mail that is
# processed in the United States -- about 160 billion pieces last year. It
# is not known how long the government saves the images
is also informative:
# The Postal Service also uses a program called Mail Imaging, in which its
# computers photograph the exterior of every piece of paper mail sent in
# the United States. The program's primary purpose is to process the mail,
# but in some cases it is also used as a surveillance system that allows
# law enforcement agencies to request stored images of mail sent to and
# received by people they are investigating.

@_date: 2015-01-02 19:42:49
@_author: Jonathan Thornburg 
@_subject: [Cryptography] The Crypto Pi 
What about the PC Engines Alix (AMD Geode LX800 CPU @ 500 MHz, 256MB RAM)
or APU (AMD T40E dual-core CPU @ 1GHz, 2GB or 4GB RAM) boards,
  They have the full circuit schematics on their website, plus GPL-ed BIOS
source/binary code available, and they don't require any "binary-blob"
They have excellent free-software support, including OpenBSD, FreeBSD,
many different Linux distributions, and assorted "internet appliance"
hardware/software setups.

@_date: 2015-06-13 15:02:06
@_author: Jonathan Thornburg 
@_subject: [Cryptography] let's do something intelligent about md5sum! 
Given the existing confusion with multiple incompatible 'sum' and
'echo' commands (e.g., SysV vs BSD), perhaps it would be wise to choose
a name that isn't quite so easily confused with the POSIX.1 'cksum'
  (which computes a CRC-32)?

@_date: 2015-03-03 16:14:19
@_author: Jonathan Thornburg 
@_subject: [Cryptography] practical verifiable systems -- forensic and 
It seems to me that any system involving a scanner and software is
much *less* secure than an all-paper scheme (with humans counting the
ballots at the polling site after polling closes, watched by multiple
other humans from different parties) (multiple other humans have of
course also checked that the ballot boxes were empty at the start of
polling, and have watched the ballot boxes all day):
* scanner+software --> vulnerable to a variety of software attacks
                   --> a single software attack can potentially
                       compromise the count at every polling place
                       across the country
* all-paper + human watchers/counters
                   --> vulnerable to "up-the-sleeve" and other
                       "stage-magician" tricks
                   --> those attacks require a trained/skilled attacker
                       at the (each) polling place, and hence are very
                       hard to run -- and keep secret -- at a big enough
                       scale to affect national results

@_date: 2015-03-03 21:59:10
@_author: Jonathan Thornburg 
@_subject: [Cryptography] practical verifiable systems -- forensic and 
Assuming that none of the scrutineers (who are probably standing behind
the vote counter looking over her/his shoulder) notice, that strategy
can successfully attack the count at *one* polling place.  Unless there's
a *very* close race, this probably won't change the outcome.
Doing this in N polling places requires N crooked vote counters, so it's
hard to scale this up enough to change a substantial percentage of the
votes cast in a large-scale race.  And if this is done on a large scale,
it's even harder to keep it secret.
In contrast, hacking an electronic system can attack the count across the
entire election.

@_date: 2015-03-24 13:04:47
@_author: Jonathan Thornburg 
@_subject: [Cryptography] "Most Americans Don't Mind Being on Candid 
Dave Eggers' novel "The Circle" (hardcover: McSweeney's and Knopf,
2013; paperback: Vintage, 2014) is a brilliant exploration of how
such a surveillance society could be created -- with superficially
benign intent -- by social networking run amok.  I highly recommend
the novel.

@_date: 2015-03-26 13:36:57
@_author: Jonathan Thornburg 
@_subject: [Cryptography] How to crypto secure speed limit signs 
[[what to do with existing "low-tech" signs]]
Beware the closed-world fallacy:  There are a lot of existing cars
which don't/won't grok the new high-tech signs, so we need to keep
all the old Mk-1-eyeball signs (and keep them up-to-date, and keep
them legally binding) for plural decades until all the existing stock
of cars age out of the fleet.
And most jurisdictions like to encourage tourism, including tourists
driving in from other countries in their own cars, so we actually need
to keep all the old Mk-1-eyeball signs (and keep them up-to-date and
keep them legally binding) until all nearby countries' old cars age out
of their fleets, too.
[A distinct point... how do we power these high-tech signs?  There
are lots of roads in rural reas with no nearby power lines.  Ok, solar
cells..... until they're covered by a heavy snowfall.  Or until we
have to deal with roads in the arctic where there can be months without
sunlight.  It's probably easier to just keep the old Mk-1-eyeball signs
forever in such areas.  Which means that even new cars/laws have to be
able to deal with this "forever" in fallback mode.]

@_date: 2015-05-27 22:41:21
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Guaranteeing that no distinct keys produce 
There is good evidence that DES is *not* a group (references below).
This means that composing multiple DES encryptions yields an operation
which is distinct from any single-DES.
The reason to use EDE rather than EEE when doing 3DES is to allow
backward-compatability with single-DES when all three keys are the same.
* Kaliski, Burton S. Jr.; Ronald L. Rivest; and Alan T. Sherman,
  "Is the Data Encryption Standard a Group?"
  Eurocrypt 85 (Springer LNCS 219) pp 81 - 95
* Kaliski, Burton S. Jr.; Ronald L. Rivest; and Alan T. Sherman,
  "Is the Data Encryption Standard a group?"
  Journal of Cryptology, 1:1 (1988), 3--36.

@_date: 2015-11-01 11:58:31
@_author: Jonathan Thornburg 
@_subject: [Cryptography] How programming language design can help us 
Peter later quoted the documentation in question:
Ok, I'll bite.  The first thing I think gcc (or any other C compiler)
will do with the code in question is complain that trying to declare/define
a function named 'double' isn't allowed, because 'double' is a reserved
Once we rename the function, then based (solely) on the documentation Peter
quoted, I expect the semantics of the function to be
* If passed a non-NULL pointer p, return 2 * (*p)
* If passed a NULL pointer, then undefined behavior occurs: I have
  promised the compiler that this pointer will *always* be non-NULL,
  and explicitly given the compiler license to optimize based on this
  assumption.  I've then then broken my promise, so all bets are off.
  This is the key thing: I've lied to the compiler, so I should expect
  lots of trouble.  In particular, I do NOT expect that the code is
  made "safe" by the attempted guard code
  since I've explicitly promised to the compiler that this guard
  can *never* be satisfied, and I've given the compiler explicit
  license to optimize (e.g. dead-code-removal) based on that promise.
  If the code containing the NULL-pointer call includes a /dev/nasal-demon
  driver, then I expect that nasal demons may appear.

@_date: 2015-11-01 19:22:21
@_author: Jonathan Thornburg 
@_subject: [Cryptography] [FORGED] Re: How programming language design can 
Note that 'gcc -fwrapv' is such a compiler.  gcc introduced this option
in 2003 for gcc 3.3.  (gcc also provides two similar-but-not-quite-the-same
options, -fno-strict-overflow and -Wstrict-overflow.  See
  for a nice discussion of the difference between these; the author is the
gcc developer who implemented these options.)

@_date: 2015-11-16 22:19:01
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Post Quantum Crypto 
Indeed, fusion power was first experimentally demonstrated in 1952
(the first hydrogen bomb was tested on 1952-10-31).  And it had (very)
positive energy gain, too!
Oh, you wanted the apparatus to be last longer than a few nanoseconds,
and to be at least vaguely "safe" for nearby humans?  More engineering
details..... ;)

@_date: 2015-11-25 20:27:05
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Security of a permute-only system? 
Wouldn't this be vulnerable to multiple-anagraming attacks whenever we
have known (or even just recognizable) plaintext spanning multiple blocks?

@_date: 2015-09-23 16:36:13
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Follow up on my password replacement idea 
Doesn't rejecting 3rd-party cookies (or more accurately, not sending
them back to anyone) solve that problem?  I had always thought that any
system or configuration with "privacy > 0" in the list-of-design-goals
would do that.  It seems more effective than the do-not-track header
(that I gather is widely ignored by people in the tracking (ad) business).

@_date: 2016-12-28 12:40:16
@_author: Jonathan Thornburg 
@_subject: [Cryptography] where shall we put the random-seed? 
OpenBSD puts it in /etc/random.seed (owned by root, mode 600, i.e.,
read/write for root, no access for non-root).

@_date: 2016-01-01 10:58:02
@_author: Jonathan Thornburg 
@_subject: [Cryptography] CCC: DJB on Post Quantum Crypto 
That url doesn't work (403 error); an alternate is

@_date: 2016-01-13 20:08:32
@_author: Jonathan Thornburg 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
How do we know that this value *randomly* flips, as opposed to (say)
flipping in phase with residual 50/60Hz noise from the power supply?
Or in phase with the temperature of that capacitor?  Or in phase with
the temperature *difference* of those two resistors?  Or the temperature
*difference* of two "balanced" components inside the ADC, which in turn
correlates with the overall idle-time fraction (& hence CPU power dissipation)
of the system?  Or the noise from switching some address-bus circuit-board
trace which turns out to be periodic with the OS software-clock-interrupt
frequency?  Any of these *might* be random-to-an-attacker... or they might
More generally, the problem with amplifying environmental noise is that
the circuit is now exquisitely sensitive to other noise sources as well.
I think you need some pretty serious power-supply regulation, RF filtering,
and thermal control, not to mention excellent analog-electrical-engineering
(e.g., the same sort of red/black signal separation used in TEMPEST hardware)
if you want to have *confidence* that this is a true source of randomness.
And (alas) I don't think that level of design & construction quality is
going to be cheap.

@_date: 2016-01-23 21:07:05
@_author: Jonathan Thornburg 
@_subject: [Cryptography] USS Pueblo and crypto 
Laura Heath's thesis on John A Walker's spying (for the USSR),
  says there's some evidence (of course, not conclusive) that the Pueblo
seisure was orchestrated by the USSR, and that 792 pounds of equipment
and documents captured from the Pueblo were shipped to the USSR shortly
after the capture.
["792 pounds" strikes me as an odd value, since a USSR source would
probably quote a round number in kilograms, but 360kg = 793.4lbs.]
David Kahn's "The Codebreakers" says there were a fair number of warning
signs which the NSA missed/overlooked/ignored that the Pueblo's mission
might provoke a serious North-Korean response.  After the Pueblo's capture,
the NSA quietly ended the AGER spy-ship program (of which the Pueblo was
a member).

@_date: 2016-03-09 17:30:58
@_author: Jonathan Thornburg 
@_subject: [Cryptography] All applications need top security (was Re: 
An additional argument in the same direction is that by having the
cat-food-and-baby-pictures traffic protected by the same (strong)
crypto as My Secret Plan for World Domination, the latter no longer
stands out as obviously different from the large mass of
cat-food-and-baby-pictures traffic.
This in turn means that "sending encrypted traffic" or "using good
crypto" no longer marks one as suspicious.

@_date: 2016-03-17 17:18:20
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Formal Verification 
Is there a published paper describing this work?
I wonder why none of the big secure-mailer projects (e.g. postfix, qmail,
opensmtp, etc) are using this type of technique?
Indeed, it would seem to provide an interesting vehicle for producing
a formally-verified TCP/IP stack.  Has anyone tried this?

@_date: 2016-05-27 22:21:17
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Entropy Needed for SSH Keys? 
It's actually 29.98cm = 11.80 inches (in round numbers, 1 foot).

@_date: 2016-11-12 18:10:14
@_author: Jonathan Thornburg 
@_subject: [Cryptography] would email encryption have saved Hillary Clinton's 
Someone whose message I mistakenly deleted :( wrote (paraphrased) that
if Hillary Clinton's had been encrypted, she would have won the election.
Hmm.  The emails were stolen by using spear-phishing to steal the
credentials (passwords) of legitimate users.  I see no way in which
email encryption would have been even a speed-bump.
2FA as it's usually done (via an SMS to the user's cellphone) would have
helped a bit...  until the KGB (or whoever else) deployed an iOS/Android
0day or spear-phish to intercept the SMS.  2FA via a secure token would
have helped a lot... although with the endpoint pc pwned there are still
straightforward ways around this (see attacks on 2FA online banking).
Basically, good security with pwned endpoints is just about impossible. :(
There are no silver bullets.  And we've always been at war with Eastasia.

@_date: 2016-11-15 22:07:02
@_author: Jonathan Thornburg 
@_subject: [Cryptography] On the deployment of client-side certs 
What happens when the user's smartphone is pwned by a carelessly-coded
or malicious app, exploiting yet another android/ios 0day?  At that point
I don't see how the "security token" gives any security improvement
over the bare (also pwned) client pc/mac.
The only way I can see to keep the security token secure is for it to
be a special-purpose device that doesn't support user-loaded software.

@_date: 2016-10-29 22:14:59
@_author: Jonathan Thornburg 
@_subject: [Cryptography] How to prove Wikileaks' emails aren't altered 
See also
WASHINGTON -- In a rare public accounting of its mass surveillance
program, the United States Postal Service
reported that it approved nearly 50,000 requests last year from law
enforcement agencies and its own internal inspection unit to secretly
monitor the mail of Americans for use in criminal and national security
The number of requests, contained in a little-noticed 2014 audit
of the surveillance program by the Postal Service's inspector general,
shows that the surveillance program is more extensive than previously
disclosed and that oversight protecting Americans from potential abuses
is lax.
The audit, along with interviews and documents obtained by The New York
Times under the Freedom of Information Act, offers one of the first
detailed looks at the scope of the program, which has played an
important role in the nation's vast surveillance effort since the
terrorist attacks of Sept. 11, 2001.
The audit found that in many cases the Postal Service approved requests
to monitor an individual's mail without adequately describing the reason
or having proper written authorization.

@_date: 2017-02-20 21:41:44
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Security proofs prove non-failproof 
[[about when formal methods will be more widely used]]
I think we're already there: Airbus uses formal methods to verify
parts of the fly-by-wire flight-control software for its airliners:
"Formal Verification of Avionics Software Products"
Jean Souyris, Virginie Wiels, David Delmas, and Herve Delseny
  This paper relates an industrial experience in the field of formal
  verification of avionics software products. Ten years ago we
  presented our very first technological research results in [18].
  What was just an idea plus some experimental results at that time
  is now an industrial reality. Indeed, since 2001, Airbus has been
  integrating several tool supported formal verification techniques
  into the development process of avionics software products. Just
  like all aspects of such processes, the use of formal verification
  techniques must comply with DO-178B [9] objectives and Airbus has
  been a pioneer in this domain.
  avionics software, safety, development process, verification,
  formal verification, Abstract Interpretation, static analysis
published in
  A. Cavalcanti and D. Dams (Eds.): FM 2009, Springer Lecture Notes
  in Computer Science volume 5850, pp. 532--546 (2009)
  Another interesting paper from Airbus is:
"Towards Formally Verified Optimizing Compilation in Flight Control Software"
Ricardo Bedin Franca, Denis Favre-Felix, Xavier Leroy, Marc Pantel,
and Jean Souyris
  This work presents a preliminary evaluation of the use of the
  CompCert formally specified and verified optimizing compiler for
  the development of level A critical flight control software. First,
  the motivation for choosing CompCert is presented, as well as the
  requirements and constraints for safety-critical avionics software.
  The main point is to allow optimized code generation by relying on
  the formal proof of correctness instead of the current un-optimized
  generation required to produce assembly code structurally similar
  to the algorithmic language (and even the initial models) source
  code. The evaluation of its performance (measured using WCET) is
  presented and the results are compared to those obtained with the
  currently used compiler. Finally, the paper discusses verification
  and certification issues that are raised when one seeks to use
  CompCert for the development of such critical software.
published in
  "Predictability and Performance in Embedded Systems : PPES 2011"
  volume 18 (2011) 59--68

@_date: 2017-01-01 18:08:05
@_author: Jonathan Thornburg 
@_subject: [Cryptography] Smart electricity meters can be dangerously 
It's usually a lot more than "several tens of amps".  A single circuit
is typically 15 amps in Canada/USA, and a house may have 10 to 20 of these.
My home in Canada (built/wired in the 1980s) has a 200-amp service entrance.
Power-switching for that would require some hefty hardware.
