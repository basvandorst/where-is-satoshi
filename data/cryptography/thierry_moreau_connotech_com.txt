
@_date: 2003-12-08 17:40:16
@_author: Thierry Moreau 
@_subject: Inescapable public key property of secret key transport? 
In the massive effort to secure the open networks, personal
computers and software trustworthiness, I wonder how the
following two security properties for a secret key transport
scheme has been addressed.
For the purpose of this post, a secret key transport scheme is
defined as the server processing of a key establishment packet
(cryptogram) that brings to the *server* the knowledge of a
secret key value that is assumed to be shared with a legitimate
*entity* (that is, we focus on the server perspective).
The two security properties are
(1) Inescapable public key property
     An outcome of the secret key transport is the assurance
     gained by the server that the secret key can only be
     (initially) shared with an entity that used a given public
     key (the server public key) when applying the exact public
     key primitive in the secret key transport specification.
     Otherwise, the secret key can only be (initially) shared
     with an entity that knows the server private key.
(2) Inescapable secret key processing rules
     An outcome of the secret key transport is the assurance
     gained by the server that the secret key can only be
     (initially) shared with an entity that followed the secret
     key preprocessing rules in the secret key transport
     specification.
     Note:     The qualification (initially) refers to the fact
               that the server can't assume that the remote
               entity will indeed preserve the secret key
               confidentiality over time.
Note that the naive assumption that the remote entity uses a
"trusted software" is a convenient way to circumvent the security
These two properties are present in the PEKE cryptosystem
(Probabilistic Encryption Key Exchange). The references are
     Moreau, Thierry, Probabilistic Encryption Key Exchange,
     Electronics Letters, Vol. 31, number 25, 7th December 1995,
     pp 2166-2168.,or
     In order to spare the reader the learning time associated with
the PEKE cryptosystem, here is a possible equivalent
implementation with the RSA primitive (caveat: this scheme is a
draft, I whish to learn if and how equivalent precautions are
done by fielded secret key transport implementations):
(A)  a legitimate entity selects a random secret S;
(B)  it sends the key establishment packet (cryptogram)
     C=Encr(S||Hash(S||PubK)) where
          Encr is the RSA encryption function with the public key
          PubK, and
          Hash is a secure hash function;
(C)  the key transported is K=Hash(S||PubK).
Accordingly, the server performs the following operations upon
receiving some C from an unknown entity:
     D=Decr(C);
     if D does not look like S'||Hash(S'||PubK), reject the key
     transport operation;
     else use K'=Hash(S'||PubK) as the transported key.
Note:     This prevents the following attack where the key
          transport is simply based on Encr(K):
     The hacker modifies the legitimate entity's Pubk to his own,
     PubK" (with encryption function Encr" and decryption
     function Decr").
     The legitimate entity inadvertently sends Encr"(K) instead
     of Encr(K). The hacker intercepts Encr"(K), recovers
     K=Decr"(Encr"(K)), and sends Encr(K) to the server on behalf
     of the legitimate entity.
The "inescapable secret key processing rules" security property
intuitively refers to the fact that the step K=Hash(S||PubK)
prevents the remote entity from selecting an hidden pattern or
property in the transported key.
So, the questions is how are the two properties ("inescapable
public key property" and "inescapable secret key processing
rules") addressed in the existing key establishment protocols?
Thanks in advance!
- Thierry Moreau
CONNOTECH Experts-conseils inc.
9130 Place de Montgolfier
Montreal, Qc
H2M 2A1
Tel.: (514)385-5691
Fax:  (514)385-5900
e-mail: thierry.moreau at connotech.com

@_date: 2003-11-26 17:50:40
@_author: Thierry Moreau 
@_subject: Reference for Sealed Storage component of Trusted Computing? 
Would anybody have a specific patent or patent application reference for
the Sealed Storage component of the "Trusted Computing" initiatives (see
Seth Schoen, Trusted Computing: Promise and Risk, at
The description of this scheme reminds me the all-or-nothing discussions
that occurred in the sci.crypt newsgroup a few years ago.
Thanks in advance.
- Thierry Moreau
CONNOTECH Experts-conseils inc.
9130 Place de Montgolfier
Montreal, Qc
H2M 2A1
Tel.: (514)385-5691
Fax:  (514)385-5900
e-mail: thierry.moreau at connotech.com

@_date: 2004-04-14 11:17:37
@_author: Thierry Moreau 
@_subject: Definitions of "Security"? 
"a well-informed sense of assurance that information risks and controls are in balance"
James M. Anderson, Why We Need a New Definition of Information Security, Computers & Security, vol 22, no. 4, May 2003, 2003, pages 308-313.

@_date: 2004-08-25 15:40:58
@_author: Thierry Moreau 
@_subject: New directions for hash function designs (was: More problems 
Just for the record, the Frogbit algorithm is a compression function with a 1-bit block size and a variable size state information.
The Helix cipher shares with the Frogbit algorithm the use of dual key stream usages between which the plaintext stream is inserted in the computations. However, the Helix authors do not recommend their construct for a hash function.
Perhaps ideas combined from these two approaches can help define other constructs for hash functions. Obviously, if the sate information is to end up in a standard size at the end of the plaintext processing, the additional state information has to be "folded", which means additional processing costs, of discarded.

@_date: 2004-09-15 15:49:12
@_author: Thierry Moreau 
@_subject: pci hardware for secure crypto storage (OpenSSL/OpenBSD) 
If I may put words in your mouth, you would require a server-side public key cryptography apparatus where the long-term private key value would be subject to utmost protection available, and the signature capability is nonetheless available to some "functional area" software on an general-purpose processor with less stringen protections. Hint: the software application where a security certificate is authorized is the ?functional area? software. Presumably, some key management scheme must be provided so that once a "functional area" becomes suspicious, its usage of the private key can be rovoked through a key renewal, and the private key is not at stake.
The disclosure of such system is at  Be reassured that this was a preventive publication, so this design is in the public domain (and is, or should have been, prior art to US patent 6,671,804).
Such server-side cryptographic hardware is currently under development. It should take the form of a 1U operational secure device and a separate key management console, the latter ensuring that no significant secret is ever stored on a personal computer. The application is not, however, certificate signing, as your post implies. I doubt that you will find products that fits your need as I expressed them. Perhaps with lower security, notably requiring that you trust the API design and implementation between the cryptographic hardware and the functional area.

@_date: 2005-08-04 10:43:38
@_author: Thierry Moreau 
@_subject: Standardization and renewability 
It allows to distribute public keys to be used, if need be, at a later time in a different context.

@_date: 2005-07-06 11:00:34
@_author: Thierry Moreau 
@_subject: A Note About Trust Anchor Key Distribution 
To all:
Here is a scheme for a central organization
distributing a trust anchor public key with rollover
requirement. The suggested acronym for this scheme is
TAKREM for Trust Anchor Key REnewal Method.
We use the notation  for the public "root" public
key  with the private key counterpart The central organization establishes key pairs
   ...,
 allocating the pair  as the
initial private/public trusted key pair, and reserving
each key pairs  for the cryptoperiod
starting with the  root key renewal, for
A separate MASH (Modular Arithmetic Secure Hash)
instance  is created for each  MASH is
defined in International standard document ISO/IEC
10118-4:1998, "Information technology - Security
techniques - Hash-functions - Part 4: Hash-functions
using modular arithmetic."
That is, the central organization selects a large
composite modulus number  used in the MASH round
function and a prime number  used in the MASH
final reduction function.
Then, the central organization selects a random salt
field A hash computation gives a root key digest  :
            .
The digest  is like an advanced notice of future
trust anchor key The data tuple  is set
aside in dead storage.
The trust anchor key initial distribution is
            D[1], D[2], ..., D[n]# .
Security rationale: with data tuple
 totally concealed until
the usage period for key pair  an
adversary is left with the digest  from which it
is deemed impossible to mount a brute force attack.
A root key rollover is triggered by the following
            .
Upon receipt of this messsage, the end-user system
becomes in a position to validate the root key digest
More details are provided in

@_date: 2005-06-03 00:12:31
@_author: Thierry Moreau 
@_subject: [Clips] Storm Brews Over Encryption 'Safe Harbor' in Data Breach 
Posted on cryptography at metzdowd.com:
Here is a suggestion for an encrypted data exception based on reasonable key management principles:
Is that actually a reasonable key management principle?
Is it possible the the US law-makers adopt such sensible approaches?

@_date: 2005-06-03 09:21:44
@_author: Thierry Moreau 
@_subject: [Clips] Storm Brews Over Encryption 'Safe Harbor' in Data Breach 
I'm not familiar with SQL injection vulnerabilities. Perhaps the issue is misrepresentation by the SQL provider that the database is encrypted using proper algorithms and key management. I guess that if a database access application using SQL injections has cleartext access to the data, this data is either not appropriately encrypted or the control of the encryption key escaped the legitimate user when the SQL injections were leaked to the adversary.
One issue with rulemaking/lawmaking is that consequences of a rule are sometimes unexpected because words (e.g. "properly encrypted") are smetimes corrupted by diverted usage e.g. public relations aspects of e-commerce security. So, even if your statement was technically wrong, if *you* are convinced that a database vulnerable to SQL injection tampering threat is nonetheless "encrypted", then a judge might be so convinced. Consequently, the lawmaking exercise must be more specific than above, e.g. using reference to by-laws which define acceptable encryption technology and key management techniques ... which is no longer a simple solution.
Thanks for highlighting the limits of the original post, either on a technical basis or on issues of lawmaking strategy.

@_date: 2005-03-07 12:59:17
@_author: Thierry Moreau 
@_subject: No Encryption for E-Passports 
See the following comments submitted to the Department of State
- Thierry Moreau
CONNOTECH Experts-conseils inc.
9130 Place de Montgolfier
Montreal, Qc
Canada   H2M 2A1
Tel.: (514)385-5691
Fax:  (514)385-5900
web site: e-mail: thierry.moreau at connotech.com
                       Comments on the
   Department of State Public Notice 4993 (RIN 1400 AB93)
                            about
                     Electronic Passport
                        March 7, 2005
                      by Thierry Moreau
               CONNOTECH Experts-conseil inc.
                  9130 Place de Montgolfier
                Montr?al, Qc, Canada H2M 2A1
                    Tel.: +1-514-385-5691
                    Fax: +1-514-385-5900
                 E-mail: info at connotech.com
             Internet:      We appreciate the opportunity to submit comments on the
electronic passport (e-passport) global project and proposed
regulation changes ([1]). Some of these comments have a
broader scope than the regulation change (this seems to be
invited by the Department of State by the public notice
discussion of e-passport encryption debate, i.e. [1] page
8306, center column, 2nd to 4th paragraphs). Our comments are
centered on the information security aspects of the e-
passport global project, notably the ICAO Public Key
Infrastructure (PKI) framework, i.e. [2].
     The uniqueness of security requirements for the global
interoperability of e-passports has been recognized early in
the ICAO development process that brought the document [2] to
its current version. As a result, most of the traditional PKI
concepts has been omitted or simplified. We believe there are
merits in the scheme found in the document [2] for the e-
passport security, including the selection of un-encrypted e-
passport electronic chip data. The driving design criteria
has been operational hindsight rather than conservatism. We
are concerned that this hindsight is not always reflected in
the [1] public notice.
     Our comments below are itemized, and they do not have
equal importance, significance, or relevance to the specific
regulatory change.
Unencrypted e-passports is a valid direction
     We generally concur with the ICAO selection of
unencrypted e-passports. Encryption would mean a global key
management scheme to determine the circumstances in which an
e-passport would be unlocked by a reader. Such a key
management scheme would imply granting reading rights to some
organizations and denying such rights to others. Those
opposing the unencrypted e-passports would certainly be even
more suspicious of any workable key management scheme for
encrypted e-passports. We have yet to see any suggestion as a
key management scheme that might appear acceptable to a
security expert who claimed that unencrypted e-passport are
putting US citizens at risk. This explanation seems reflected
in the Department of State statement that "in order to be
globally interoperable, encryption would require a higher
level of technology and more complicated technical
coordination with other nations." ([1] page 8306, center
column, 2nd paragraph) although we would have liked the
Department of State to speak for itself (e.g. "Such technical
coordination includes notably the cryptographic key
management for electronic chip decryption keys.").
Doubtful representation of e-passport technology,
reader requirements and skimming threat
     According to the document [2], "Everyone who has the
appropriate equipment is able to read the chip contents of
the MRTD, but only the parties that are provided with the
appropriate public key certificates and certificate
revocation lists will be able to verify the authenticity and
integrity of the chip contents." (Document section 2.4.4) So
we find misleading the [1] public notice that eavesdropping
requires a reader "furnished with the proper public key" ([1]
page 8306, center column, 4th paragraph). In fact, reading of
electronic chips by international transportation operators
(e.g. airlines) is encouraged by the ICAO.
     The e-passport proponents should not minimize the
significance of unauthorized e-passport reading threats.
Anti-skimming features are important to US travelers wishing
to protect their anonymity and privacy. The Department of
State should provide reliable information about their
effectiveness and their prudent use, since the momentary
disabling of anti-skimming mechanisms (e.g. the removal of a
metallic shield surrounding the electronic chip antenna)
materializes the e-passport bearer authorization to read the
Doubtful representation of e-passport technology,
global skimming countermeasures
     We are puzzled by the Department of State statement that
it will "will work vigorously with other governments to
encourage them to eliminate the threat of eavesdropping by
requiring all chip readers to be electronically shielded to
prevent signals from being transmitted beyond the reader."
([1] page 8306, center column, 4th paragraph) The definition
of "signal" and "electronically shielded" should be more
precise. If this means that no signal whatsoever (except the
displayed data, as the context implies) will be emitted by
the reader, then
 a)  the e-passport reader equipment will not provide
     traveler identification data to other system components,
     e.g. an airline passenger list system, and
 b)  every readers at ports of entry will need to receive the
     complete list of invalidated passports.
The item a) above defeats the purpose of biometric
identification information (i.e. matching the traveler
digital facial image with a database of unwanted individuals
on a port of entry). This is certainly not the intent, and
will hardly be agreed by other governments.
     Due to  the well-known eavesdropping vulnerabilities of
computer networks, signals from an e-passport reader, e.g.
data transmission to government or airline computer systems,
should be encrypted to prevent disclosure of traveler
information to unauthorized parties. Paradoxically, the
computer network encryption technology is subject to export
control restrictions advocated by the US government as a
participant in the Wassenaar agreement. The Department of
State should disclose a clear position on the privacy
protection mechanisms that it finds suitable to e-passport
reader data transmission.
A missing provision in the proposed regulation
     The document [2] explains a potential source of
electronic chip failure for which the FR public notice is
silent. Specifically, we are referring to the compromise of a
document signer private key (the same applies to the
compromise of a country signing CA private key).
     As a consequence of a document signer key compromise, a
large group of e-passports would suddenly have "otherwise
nonfunctioning electronic chip" (proposed 22 CFR Part 51, 
51.6). This would be a difficult operational situation,
especially if any noticeable number of counterfeit e-
passports are created by illicit use of the document signer
private key. The document [2] this situation does not
invalidate e-passports: "In the event that the data from the
chip cannot be used, for instance as a result of a [reported
document signer private key compromise] or [...], it does not
necessarily invalidate the MRTD. In that case a receiving
State MAY rely on other document security features for
validation purposes."
     For this security breach to be prevented, an appropriate
combination of technological means and internal controls
needs to be deployed in national e-passport issuance systems
and processes. European quality standard documents ([3], [4])
exist for the required secure systems (there seems to be no
US equivalent of these standard documents).
     However small the perceived likelihood of such a
security breach, the consequence of its occurrence should be
addressed by an elaborate national regulatory system like the
US one. If properly addressed by the regulation, the
operational costs and burden of preventing such security
breach are deemed to be easier to secure in the government
budget, and the recovery processes are deemed to be better
planned. In practice, this might be a no cost replacement of
e-passports since the good faith document bearer are in no
way involved in the security incident.
     We attempted to promote a better understanding of the
information security technology behind the global e-passport
deployment initiative. Unless someone is against travel
document automation as a whole, the ICAO security scheme
should be acceptable.
     Our main concern lies with the security of a globally
deployed e-passport infrastructure, of which the computer
network security is an integral part. The level of security
deserved is analogous to a retail on-line payment network,
except that the threat model is physical security of
travelers safeguarded by privacy and anonymity protection.
Also, data encryption is needed where transaction
authentication is needed for a retail payment network.
     The public confidence in the e-passport technology rests
with a global compliance to adequate security standards. In
economic terms, this is a situation where the IT security
benefits accrue to a large participant community, while the
costs incurred by individual participants are remotely
connected to the benefits. In such cases, an overseeing
compliance enforcement authority seems appropriate (e.g. the
rules applicable to financial institutions participating in
an electronic payment scheme). Perhaps an international
security certification program would be needed with a
(legally protected) visual mark indicating a compliant e-
passport reader, data networks and computer applications. The
Department of State should not claim that it can force every
e-passport readers to comply with the required level of
privacy protection.
[1]  US Department of State, Electronic Passport, Federal
     Register, Vol. 70, No. 33, February 18, 2005, pp
     8305-8309 (Public Notice 4993, RIN 1400 AB93)
[2]  International Civil Aviation Organization, Tom A.F.
     Kinneging for ICAO-NTWG, PKI Task Force, PKI for Machine
     Readable Travel Documents offering ICC Read-Only Access,
     Version - 1.1, October 1, 2004
[3]  European Committee for Standardization (CEN),
     Cryptographic module for CSP signing operations with
     backup - Protection profile - CMCSOB PP, CWA
     14167-2:2004, May 2004
[4]  European Committee for Standardization (CEN),
     Cryptographic module for CSP signing operations -
     Protection profile - CMCSO PP, CWA 14167-4:2004, May
     2004

@_date: 2005-09-08 10:46:28
@_author: Thierry Moreau 
@_subject: Another entry in the internet security hall of shame.... 
See Incidentally, TLS-PSK protocol standardization proposals has been around in the IETF for some time, and it is the mobile telephony development momentum made it pass the standardization process (e.g. drafts by Nokia). In the mobile telephony world, the physical distribution of "subscriber identity mudules" (i.e. integrated circuits with secret/private keying material) is physically distributed to subscribers.
The incremental operating cost can be resaonable only for organizations that already incur the *authorization* management overhead.

@_date: 2006-01-26 14:28:44
@_author: Thierry Moreau 
@_subject: thoughts on one time pads 
You shift to the problem of filling CDs with pure random data. Which physical property do you want to sample and with which type of hardware do you expect to sample it and at which rate, and with which protection against eavesdroping during the sampling? At what cost? With what kind of design assurance that the pure random data is indeed pure and random?
Have fun.

@_date: 2006-06-04 20:23:07
@_author: Thierry Moreau 
@_subject: Status of opportunistic encryption 
Thomas Harold wrote, in part:
E.g. RFC4033, RFC4034, RFC4035.
- Thierry

@_date: 2006-06-15 14:52:40
@_author: Thierry Moreau 
@_subject: free e-voting software available?! 
Query your search engine for Punchscan, a design led by the distinguished cryptographer David Chaum, e.g. Apparently, their development project is aimed at educational votations as an operational proof-of-concept.
Interesting project, cryptography application to voting system without number theory or secret key cipher design.
Have fun.

@_date: 2006-03-22 07:28:38
@_author: Thierry Moreau 
@_subject: passphrases with more than 160 bits of entropy 
More than 160 bits is a wide-ranging requirement.
Entropy is a highly discussed unit of measure.
Anyway, keep it simple, use a larger hash: SHA-256, SHA-512, or for hash with user-selectable size, MASH:
International standard document ISO/IEC 10118-4:1998, Information technology - Security techniques - Hash-functions - Part 4: Hash-functions using modular arithmetic

@_date: 2006-05-01 22:12:24
@_author: Thierry Moreau 
@_subject: what's wrong with HMAC? 
I suggest that you read the theory, make your own mind, and share your opinion with us.
Perhaps Mr. Anderson read the theory, made his own mind, and shared his opinion with whoever was listening or reading the above citation.
I recall having read some theory, made my own mind, and Mr. Anderson's citation above wouldn't be too far from my opinion at that time.
All theories are equal, but some theories are more equal than others ...
Have fun!

@_date: 2006-09-07 10:57:07
@_author: Thierry Moreau 
@_subject: DNS/DNSSEC as an inbound mail signature public key distribution 
"the signing key is in the network" --> Indeed. The public signature key is stored in the DNS.
DKIM might be the first widely deployed application to use the DNS as the preferred means of distributing public keys.
*Authenticated* public key distribution would need an upgrade of the DNS with DNSSEC deployment.
Perhaps it is time for discussion groups like this one to take a look at DNSSEC (RFC4033 / RFC4034 / RFC4035) and review its security principles, trust model, deployment challenges, HMI (Human Machine Interaction) aspects, etc.
Look at  or query your favorite web search engine with "DNSSEC".
Good reading.

@_date: 2006-09-11 10:09:19
@_author: Thierry Moreau 
@_subject: Exponent 3 damage spreads... 
If I understand the attack mathematics correctly, the following algorithm should give you an alleged signature value that would be mistakenly accepted by a flawed RSA implementation. I didn't implement the algorithm, and I will not make suggestions as a convenient big number arithmetic tool to implement it.
Note: The algorithm output value is NOT A FORGED SIGNATURE, since a non-flawed RSA signature verification implementation will correctly reject it. Nonetheless, using public exponent 3 with any use of RSA should be deprecated.
For the record, I am referring to
Hal Finney, "Bleichenbacher's RSA signature forgery based on implementation error" Wed, 30 Aug 2006
 at metzdowd.com/msg06537.html
N, large public modulus (of unknown factorization)
h, hash value
p: hex 01 FF 00 30 21 30 09 06 05 2B 0E 03 02 1A 05 00 04 14
A random binary source (e.g. large enough PRNG output)
(A) find the largest value of r such that b=(p*2^20+h)*2^(8r) such that (B) select random a, 0<a<N^2, then set c=a*N^2+b+2^(8r)-1
(C) using a simple binary search, find the d = integer cubic root of c
(D) if d^3<a*N^2+b, go back to step (B) -- if it occurs with a high probability, that's a failure of the approach proposed here, intuition suggests that the probability is either very close to zero, or very close to one
(E) set alleged signature s=d mod N (indeed, d<N, so s=d) and validate (merely as a software self-check) that (s^3 mod N) div 2^(8r) equals (F) output alleged signature s

@_date: 2006-09-14 11:47:44
@_author: Thierry Moreau 
@_subject: Rabin-Williams exponent 2 is not at stake, never been (WAS: Exponent 
OK, we've got into trouble with the exponent 3 because the RSA technique has been applied with varying degrees of care (both specifications drafting and implementation phase), and the number-theoretic properties of low-exponent RSA are now hitting us, as the theory predicted.
But please, don't put the Rabin-Williams exponent 2 into the picture at the same level of low-exponent RSA. The two are close numerically, but very far apart historically, number-theoretically (wrt computational complexity proofs), and implementation-wise. First, the exponent 2 has a built-in 4-to-1 ambiguity in the private key computation, which has been addressed in many different ways in cryptosystems based on the "x^2 mod N" primitive. Second, the number-theoretic proofs were always more advanced with exponent 2 than low exponent RSA, so that specifications drafters were well informed of the implementation pitfalls.
Peter, if you know a standard that uses public exponent 2 *and* either handles the 4-to-1 ambiguity in the private key computation in a way that appears inadequate, or allows arbitrary selection of (portions of) the public key operation input value, tell us. It would be specifications drafted without consideration of the most elementary advice from the number-theoreticians. The equivalent advice was usually lacking in the case of low-exponent RSA.
This being said, I don't want to participate in a further debate Rabin-Williams vs low exponent RSA. I just whish to limit the misrepresentations about the Rabin-Williams family of cryptosystems.

@_date: 2007-12-10 02:47:41
@_author: Thierry Moreau 
@_subject: More on in-memory zeroisation 
Then, s/memset(?,0,?)/(memset)(?,0,?)/ to get rid of compiler in-lining.
Ref: ANSI X3.159-1989, section 4.1.6 (Use of C standard library functions)

@_date: 2007-12-11 15:56:20
@_author: Thierry Moreau 
@_subject: More on in-memory zeroisation 
Indeed, the actual function, memcpy in the present instance.
memcpy, the actual function, is aware of the execution environment, because it is part of the run-time library. The compiler is not as deeply aware of the execution environment.
The source code construct (f)(args) is provided by the standard to allow the program to explicitly rely on the actual library function.
At least this is my understanding of compiler optimization techniques as subordinate to standard definition of the C language. I too often turned off optimization due to (suspected) optimized-in crash, I would like to rely on the (f)(args) to locally turn off optimization.
The standard actually says "... it is permitted to take the address of a library function even if it is defined as a macro ...". The standard works for me as a source code author who needs an execution-aware memcpy function from time to time. Overworked GCC contributors should work to comply to the standard, not to address Peter, Thierry, and whoever's wildests dreams.
It can't prove much in the case of (memset)()

@_date: 2007-12-11 20:53:06
@_author: Thierry Moreau 
@_subject: More on in-memory zeroisation 
Case of static function definition: the standard says that standard library headers *declare* functions, not *define* them.
Case of inline: I don't know if inline definition falls in the standard definition of declaration.
Also, the standard refers to these identifiers as external linkage. This language *might* not creare a mandatory provision if there was a compelling reason to have static or inline implementation, but I doubt the very infrequent use of (memset)(?,0,?) instead of memset(?,0,?) is a significant optimization opportunity. The compiler writer risks a non-compliance assessment in making such strectched reading of the standard in the present instance, for no gain in any benchmark or production software speed measurement.
Obviously, a pointer to an external linkage scope function must adhere to the definition of pointer equality (==) operator.
Maybe a purposedly stretched reading of the standard might let you make your point. I don't want to argue too theoretically. Peter and I just want to clear memory!
Kind regards,

@_date: 2007-12-12 16:24:43
@_author: Thierry Moreau 
@_subject: More on in-memory zeroisation 
typedef void *(*fpt_t)(void *, int, size_t);
void f(fpt_t arg)
  typedef void *(*fpt_t)(void *, int, size_t);
extern void f(fpt_t arg);
int main(int argc, char *argv[])
             - Thierry Moreau */

@_date: 2007-12-12 17:27:38
@_author: Thierry Moreau 
@_subject: More on in-memory zeroisation 
If there is a consensus among comforming implementation developers that the above program is comforming, that's a good enough "proof" for me.
As a consequence of alleged consensus above, my understanding of the C standard would prevail and (memset)(?,0,?) would refer to an external linkage function, which would guarantee (to the sterngth of the above consensus) resetting an arbitrary memory area for secret intermediate result protection.
Reading ANSI X3.159-1989, I believe there would be such a consensus, and I find it quite obvious. You may disagree, and I will no further argument.

@_date: 2007-12-14 12:42:19
@_author: Thierry Moreau 
@_subject: More on in-memory zeroisation 
Thank you for pointing this. I must admit you point to an inescapable counter-example for my analysis.
Maybe global optimization was not a significant factor in the 1980's when the C standard language was established -- it does refer to external linkage and "genuine function".
In the case of volatile declaration, the GCC 4.2.2 compiler gave me a warning that the volatile qualifier was ignored because the memset formal parameter declaration does not match. At least, as a compiler user I get a proper warning message.
  - Thierry Moreau
Original message:

@_date: 2007-06-22 13:23:13
@_author: Thierry Moreau 
@_subject: question re practical use of secret sharing 
Very interesting discussion.
I bring a different angle to the very topic of discussion ("practical use"). See below, after the quotes which I fully agree.
Here is a different perspective.
Forget about mathematics (who wants to go farther than 2 out of 3, 3 out of 4, and 2 out of 4).
Forget about an API: think first of a potential application area.
Forget about HCI (Human Computer Interface): focus on the control/liability allowed/implied by a key share and the administrative Forget about processors and computers altogether!
If I didn't lose you yet, think of secret sharing for the *long-term cryptographic key material* for DNSSEC support at the root.
I.e. share the control over delegation of DNSSEC *routine* signature operations (to IANA staff in the foreseeable future) among secret sharing entities, say USG NTIA, an European entity, and a third one Store the key shares on paper sheets of bar codes - the user interface is a safe box for the secure hardware, and a diplomatic briefcase for transport layer.
Actually, secret sharing implies significant procedural overhead for key management, and hence may find applications only in "master keys" of some orgnizations.
I did propose a scheme where the above principles are implicitly put forward, i.e. TAKREM for DNSSEC (root) trust anchor key rollover. The above "long-term cryptographic key material" is specified in the TAKREM documentation (perhaps other "routine" public key cryptoperiod management schemes might use the same principles for secret sharing).
 From some of those who develop interoperability specifications (i.e. IETF participants) I was called a "patent troll". From those organizations who control the Internet, i.e. USG NTIA, Verisign, and ICANN, I seem to be nobody. Hence the proposal made little progress.
In summary, to answer the question "practical use of secret sharing", I don't see it in my crystal ball. Nonetheless, control of DNSSEC root signature key would be a good candidate application area for secret sharing.
Admittedly, the above change in perspective does not solve "the difficulty people have in managing keys in general" -- it merely shifts it from trusted system administrators to diplomats and like individuals. (A DHS sponsored study even ignored or downplayed mere split key storage for protecting the DNSSEC root private key.)

@_date: 2008-04-23 11:35:08
@_author: Thierry Moreau 
@_subject: [Fwd: Secure Server e-Cert & Developer e-Cert. Comerica TM Connect 
I did notice this reference to certificates in the phishing blabla message.
I checked very quickly at comerica.com, they don't seem to use client PK pairs (nor certificates), merely the usual name/password authentication.
If the target financial institution was using client authentication, it would be interesting to see phishing scenario details, but that's not the case until shown otherwise.
I'm not impressed by the phisher blabla message.

@_date: 2008-08-27 10:42:02
@_author: Thierry Moreau 
@_subject: Decimal encryption 
The short answer is no, nobody knows a secure algorithm that would "work" as a decimal stream cipher AND would not extend the message size for some form of key material reference data (or salt or IV ...).
If you have room for such message-specific reference data, it should be easy to design a decimal stream cipher for short messages.

@_date: 2008-02-18 14:05:15
@_author: Thierry Moreau 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
Some feedback on the above security certificate issuance process.
At first, it seems neat. But then, looking at how it works in practice:
the client receives an e-mail notification soliciting him to click on a
HTML link and then enroll for a security certificate,
the client is solicited exactly like a phishing criminal would do, and
a java software utility downloaded from the web should not be allowed to
modify security-critical parameters on the local machine.
According to my records, this issuance process is nonetheless
representative of research directions for user enrollment, i.e. there
aren't too many other documented processes in this area.

@_date: 2008-01-07 09:29:27
@_author: Thierry Moreau 
@_subject: Question on export issues 
Thanks for this long and thoughtful reply. Some feedback below
Indeed, there is no doubt that good algorithms and good protocols are implemented in exportable implementations.
I was referring mainly to key management and implementation correctness for "hard things" in applied cryptography, e.g.
brwosers and OSs allow easy tampering with the list of "trusted" CAs,
"ennemy" software on the local system
crypto-services layer
crypto-application installation time
Agreed, if you are satisfied with the current state of development for IT security with respect to issues such as the above ones, and if the extent of customization does not include innovations in these issues.
Otherwise, the export control regime is still a nuisance.
By itsef, that's alggorithm tweaking. Remote from key management and implementation pitfall avoidance.
- Thierry Moreau

@_date: 2008-01-31 10:08:55
@_author: Thierry Moreau 
@_subject: Fixing SSL (was Re: Dutch Transport Card Broken) 
If I recall correctly, SSL was designed chronologically after ISO OSI Network-Layer Security Protocol (yes, the official WAN was actually X.25 at one point) or Transport Layer Security Protocol, both in their connection-oriented flavor, which used ideas originating from DecNET designs (researcher names Tardo, Alagappan; I once had a patent number in this thread of protocol engineering, but I lost it). Anyway, the key point in these visionary ideas is that the D-H exchange occurs *before* the exchange of security certificates. This provided the traffic-flow confidentiality that becomes desirable to protect privacy these days.
So, you got your fix with OSI NLSP or TLSP, you just have to overcome the *power of the installed base*!

@_date: 2008-07-23 15:07:56
@_author: Thierry Moreau 
@_subject: The PKC-only application security model ... 
Dear all:
This is a two-fold announcement, big picture and specific document announcement. The whole thing is "for your information" as security experts.
A)	The big picture refers to the "PKC-only application security scheme", in which client-server applications may be secured with client-side public key pairs, but *no trusted certification authority* is involved (server operators are expected to maintain a trusted database of their clients' public keys).
B)	The specific document announcement refers to what is required to field the PKC-only application security scheme: explicit meaningless security certificates. The reference is "Explicit Meaningless X.509 Security Certificates as a Specifications-Based Interoperability Mechanism", This post leaves it to your imagination and creativity about how a PKC-only security scheme may work in practical details, i.e. how the third party trust management may be replaced by first party trust management (first party = server operator as the relying party for client public keys). I have been doing some work in this area, but I have no results to report in a properly written document. Anyway, the PKC-only security scheme does not imply significant standardization for interoperability among independent service operators.
The document is open for discussion. It covers the minimal provisions for PKC-only deployment in the installed base of browsers supporting the TLS protocol.
Sometimes in the future, a very reduced version might be prepared as an Internet draft intended to the RFC editor publication route (RFC3932) with the experimental status (this is different from the individual RFC submission route in which the IESG is involved in the document publication process but no IETF working group is assigned an editorial Good reading.

@_date: 2008-07-23 17:32:02
@_author: Thierry Moreau 
@_subject: The PKC-only application security model ... 
Anne & Lynn Wheeler wrote about various flavors of certificateless public key operation in various standards, notably in the financial Thanks for reporting those.
No doubt that certificateless public key operation is neither new nor absence from today's scene.
The document I published on my web site today is focused on fielding certificateless public operations with the TLS protocol which does not support client public keys without certificates - hence the meaningless security certificate. Nothing fancy in this technique, just a small contribution with the hope to facilitate the use of client-side PKC.
- Thierry Moreau

@_date: 2008-07-24 06:42:57
@_author: Thierry Moreau 
@_subject: The PKC-only application security model ... 
In draft-ietf-sip-dtls-srtp-framework, the detailed scheme uses self-signed certificates created by client end-entities themselves. The basic idea is identical. At the detailed level in my document, the client end-entity "auto-issues" a security certificate with a "breached" CA private key.
In the TLS Certificate request message, a list of CA distinguished names is provided to the end entity. Referring to a "breached" CA public key is an invitation to submit a meaningless end-entity certificate, making the detailed scheme "more plain" with respect to TLS options (i.e. an empty list in a certificate request message could be a not so well supported mode in TLS software implementations).
So, maybe the reference to the notion of self-signed EE certificates in draft-ietf-sip-dtls-srtp-framework could be replaced by "meaningless EE certificates" (or something else), which would include both self-signed or auto-issued. In such a case, the RFC publication for my document would become more pressing.
A related discussion occurred on the IETK PKIX mailing list in June 2008 under the subject "RFC 5280 Question".

@_date: 2008-07-24 07:21:20
@_author: Thierry Moreau 
@_subject: The PKC-only application security model ... 
Thanks, I will look into this.
Neither patent nor patent application for the matter contained in the referenced document.

@_date: 2008-06-12 15:36:24
@_author: Thierry Moreau 
@_subject: Why doesn't Sun release the crypto module of the OpenSPARC?  
That's an interesting observation, raising the issue of what is "speech"   vs hardware.
When I looked into this issue, I found the "Common Criteria" certification methodology as evidence that "speech" covers everything from the most high level abstract design description to the most concrete representation of the hardware that you would look at, e.g. for security certification assurance that electronic gates are properly positioned by the Computer-Aided-Design tools. Hence, any information is "speech", and if it's in the public domain, I would expect an export control exception would apply. Only the actual silicon, and non human-readable dies for the silicon, would be hardware.
Otherwise, I see no legal base to locate a cut-off point between "speech" and hardware in the process of design refinements leading to the actual processor.

@_date: 2008-10-24 10:23:07
@_author: Thierry Moreau 
@_subject: combining entropy 
Do you really trust that no single source of entropy can have knowledge of the other source's output, so it can surreptitiously correlate its own?
I.e, you are are also assuming that these sources are *independent*.

@_date: 2008-10-29 23:41:40
@_author: Thierry Moreau 
@_subject: Who cares about side-channel attacks? 
Now you seem to answer the question yourself: SCA protections apply to a single class of attacks, while there are many.
Going back to "who cares", having done certification consulting assignments for some devices with crypto, when there was no checklist-based standard to apply, "good practice" security criteria (to be briefly documented in the report) would include the following questions:
(A) Is the secret key inside a device unit applicable to this single unit, or is it a system-wide, or domain-wide key?
That's a key management scheme question.
(B) Is the attack destructive? Which device unit features (especially "be in working order", but also "be absent of actual tampering evidence" or even "remain under the control of the legitimate user without interruptions longer than X" ) need to be impaired for a given class of attack to succeed? This question pertains to the secret key as in (A) and also to any public-key-to-be-integrity-protected which would prevent malicious code download.
That's a product design question.
(C) What are the incentives, if any, for the legitimate user to remain well-behaved in the human aspects of device protection? (E.g. a merchant has some incentive to maintain a payment authorization device in good working order.) This leads to the question of insider threats, so satisfactory answers in this area are seldom present.
This is an application design question.
This gives an idea of analyses that drives security-related spendings (in my limited experience). Clients (intend to) pay for protections that will prevent financial losses and major public relations impacts (and then cut operating budgets soon after the project gets its authorization!). The consultant study must clearly link attackers' motivations to impacts and to countermeasures.
Refinements to the above analysis methodology call for the same creative mind that you assume from the part of the attackers. E.g. the usefulness of a device unit clone for the attacker should be considered for questions (B) and (C).
Does SCA protection enter the picture? Marginally at best.

@_date: 2008-09-09 13:52:30
@_author: Thierry Moreau 
@_subject: Let's be paranoid about CSS (cascaded style sheet) as an application 
Dear security experts:
Suppose I want to use the HTML syntax and a plain web browser as a user interface for a secure application. By "secure", I mean, among other things, that the application service provider is confident that the user sees the HTML contents without integrity vulnerabilities. Of course, https is the only allowed protocol for reaching this web page, and the only protocol present in any link from this page to a next one.
I am now concerned about the default and implicit style sheets that the web browser uses for HTML content rendering.
Here is a simple exploit which alters the ietf.org main page. Insert the following four lines
a[title="IETF Secretariat"]:before
{content: "Don't trust the "}
a[title="IETF Secretariat"]:after
{content: " for anything security-critical."}
to the file /usr/lib/firefox/res/html.css
then restart the Mozilla Firefox and bingo, the itef.org main page is subrepticiously changed. I.e. the link to "IETF Secretariat" is canged to "Don't trust the IETF Secretariat for anything security-critical."
OK, this requires root access because the Linux community is generally security-conscious. But you should see the general idea: paranoia leads me to think of an adversary who would threatens application integrity (such as the above) without leaving much trace of computer system This attack vector is trivial based on the HTML markup language philosophy - the above "exploit" merely alters default settings in a parameter specifications language (css) having a fine grained expressivity potential. CSS is about what the user sees when HTML contents is displayed on a media (typically a web browser.
Does anybody have any tip about how to mitigate this vulnerability, with minimal assumptions about the client web browser?
The basic idea would be to "patch" any default setting (that could alter the user display ...) in the CSS specifications with explicit parameter setting associated with the HTML contents. In the above case, the IETF can protect itself with the following HTML markup text near the beginning of the file:
The habit of storing css style information in various style sheets files separate from the HTML contents is worrysome as each stylesheet retrieval operation is a potential attack vector.
Thanks in advance. More specifically, with the hope that paranoia can sometimes be a productive state of mind, I remain paranoid-ly grateful for your answers.

@_date: 2008-09-17 07:16:21
@_author: Thierry Moreau 
@_subject: RSA modulus record 
But it is trivially factored as (2^43112609-1) * (2^37156667-1)
Factorization based modulus need to be drawn from a pool of numbers "without special properties", so that their factorization is not facilitated by special-purpose algorithms. There is ample academic work aiming to refine "without special properties", and there is also ample (debated) academic work which assumes that "without special property" is a reasonable assumption in practice.
The fun part is to reconcile theory and practice, e.g. a decade of RSA industrial application before retrofitting the probabilistic property in RSA, while probabilistic cryptosystems has been around in academic work amost since the early days of published work on PK crypto.
- Thierry Moreau
CONNOTECH Experts-conseils inc.
9130 Place de Montgolfier
Montreal, Qc
Canada   H2M 2A1
Tel.: (514)385-5691
Fax:  (514)385-5900
web site: e-mail: thierry.moreau at connotech.com

@_date: 2009-08-19 13:56:37
@_author: Thierry Moreau 
@_subject: Re (security fix): A Basic Rabin-Williams Digital Signature Specification 
Dear all:
A revised document has been posted at  including a fix for an elementary security issue (and two other items, see document revision I received some, but not much, feedback (positive) on the first version.
- Thierry

@_date: 2009-07-27 10:35:21
@_author: Thierry Moreau 
@_subject: A Basic Rabin-Williams Digital Signature Specification 
Dear all:
As you know well, there is nothing quite new with the Rabin-Williams digital signature scheme.
I just formulated a basic specification of it, leaving aside to the greatest extent anything that would not be rooted in some theoretical The result is at Title and abstract:
Scirpo, a Basic Rabin-Williams Digital Signature Specification
The public key cryptography digital signatures are well studied since the early publications by academics three decades ago. On the deployment front, many standardization efforts brought the digital signature techniques at the core of current computer networks. This document almost completely ignores such standards, and focuses on the theoretical foundations of the Rabin-Williams digital signature scheme; it merely describes a simple digital signature scheme including minimal interoperability provisions. While devoid of any advance to the art or science of applied cryptography, this document appears original in its formalization of a signature scheme details with this minimalistic approach centered on theoretical foundations.
I already suspect that the usefulness of this document is limited, so if you do find some value in it, please let me know how the document can be improved for your purpose.
If anyone has other comments, I would like to read them.
- Thierry Moreau

@_date: 2009-05-04 22:29:33
@_author: Thierry Moreau 
@_subject: Has any public CA ever had their certificate revoked? 
Now that the main question is answered, there are sub-questions to be asked:
1. Has any public CA ever encountered a situation where a revocation would have been necessary?
1.1 Has any public CA ever had a disgrunted employee with too many privileges not revoked on a timely manner?
1.2 Has any public CA ever experienced a corporate reorganization where a backup HSM has been lost?
1.3 ...
2. Has any public CA ever suspected a situation where a revocation would have been necessary?
2.1 Has any public CA ever had an audit that identified mismanagement of signature private key over some extended period of time?
2.2 ...

@_date: 2009-05-05 13:01:00
@_author: Thierry Moreau 
@_subject: Has any public CA ever had their certificate revoked? 
Before the collapse of the .com market in year 2000, there were grandiose views of "global PKIs," even with support by digital signature Actually, it turned out that CA liability avoidance was the golden rule at the law and business model abstraction level. Bradford Biddle published a couple of articles on this topic, e.g. in the San Diego Law Review, Vol 34, No 3.
The main lesson (validated after the PKI re-birth post-2002) is that no entity will ever position itself as a commercially viable global CA unless totally devoid of liability towards relying parties.
Thus no punishment is conceivable beyond the Peter's opinions (they are protected by Freedom of speech at least). That was predicted by the Brad Biddle analysis 12 years ago.

@_date: 2009-10-05 12:52:09
@_author: Thierry Moreau 
@_subject: Trusted timestamping 
I answer your question by two questions:
Trusted timestamping service is like a specialized form of non-repudiation service. You may wonder if there is any fielded usage of genuine non-repudiation service, i.e. extending to an arbitration function that would support evidence management in some litigation forum. Fraud prevention in payment systems is not based on a genuine non-repudiation scheme. Are you aware of the current state of genuine non-repudiation service?
Another approach to your question is that timestamping service has to be sold before being fielded and used. Who is(are) the real beneficiary(ies) in a trusted timestamping service, and how do you sell the service to them so that it makes economic sense?
- Thierry Moreau

@_date: 2010-04-09 16:16:57
@_author: Thierry Moreau 
@_subject: Wikileaks video "crypto". 
As the adage goes, "Those who know don't speak. Those who speak don't know." I am in the latter category.
I guess we can use the simplest explanation from the available clues.
(A) The video file was encrypted when it circulated within the "victim" organization (e.g. encrypted .zip file attached to an e-mail). (Granted "victim" of the breach is an euphemism when consideration is given to civilian deaths.)
(B.1) Someone not having the decryption key had a personal motivation for the leak.
(B.2) Or someone having the decryption key feared that release in decrypted form would allow to trace the source of the leak. Don't forget that many more people would have legitimate access to the ciphertext.
(C) Wikileaks analysts understood the brute force key cracking (and/or dictionary attack for a password-derived encryption key) and deemed it was useful in this case due to the significance of the video.
 From these simple explanations, the lesson would be the irony of the situation where brute force attack success (respectively dictionary attack success) can be attributed to the restrictions in cipher strength (respectively impediments to sensible key management schemes) that the government officials promoted for civilian use crypto.
My 0.00002 worth of wisdom (Friday afternoon special promotion!).
- Thierry Moreau

@_date: 2010-04-20 20:58:25
@_author: Thierry Moreau 
@_subject: What's the state of the art in factorization? 
I had the opportunity to listen to Prof. Dan Bernstein talk last Friday morning. I was very glad to see him as I respect his dedication to crypto maths, algorithm implementation, and very applied studies of computation complexity.
The slides are pretty much representative of his talk. New material starts on slide 17. If you are familiar with the contents of slides 1-16 and elliptic curve methods (I am not), then you should appreciate the contents of slides 17 up to 45.
Slides 46 to 47 deal with the computation speedups available with graphics processors.
In the audience, there seemed to be some who followed the presentation more than I did but Dan made a great talk even for people like me.
According to my records, the state-of-the-art is reference
Joppe W. Bos, Marcelo E. Kaihara, Thorsten Kleinjung, Arjen K. Lenstra, and Peter L. Montgomery, "On the Security of 1024-bit RSA and 160-bit Elliptic Curve Cryptography", version 2, August 7, 2009, 18 pages (published on pages 43-60 in "Comments on the Transition Paper" available at  which was listed at plus this talk last Friday (and references). From these, you have to do your homework in guesswork about your actual enemy's power.
In the Intaglio NIC project white paper I contributed towards the deployment of an alternate source for signed official DNS root data, I had to refer to the state-of-the-art. See  (document section 3.6 Early Project Decisions about Protection Level).
The DNS root may be qualified as a "high valued" zone, but I made the effort to put in writing some elements of a "risk analysis" (I have an aversion for this notion as I build *IT*controls* and the consultants are hired to cost-justify avoiding their deployments, basically -- but I needed a risk analysis as much as a chief financial officer needs an economic forecast in which he has no faith.) The overall conclusion is that the DNS root need not be signed with key sizes that would resist serious brute force attacks.
See  (document annex C. Risk Analysis Elements for DNSSEC Support at the Root).
By the way, state-of-the-art in factorization is just a portion of the story. What about formal proofs of equivalence between a public key primitive and the underlying hard problem. Don't forget that the USG had to swallow RSA (only because otherwise its very *definition* of public key cryptography would have remained out-of-sync with the rest) and is still interested in having us adopt ECDSA.
So, yes, it's always good to ask questions. I usually complain that one seldom gets a simple answer for a simple question addressed to a specialist. I don't feel I provided a simple answer, but I don't claim to be a specialist.
- Thierry Moreau

@_date: 2010-04-21 23:19:48
@_author: Thierry Moreau 
@_subject: What's the state of the art in factorization? 
Do you have a suggestion for a less ad-hoc fashion?
For which purpose(s) is the DNS root signature key an attractive target? Given these purposes, who are the potential adversaries (Dan Bernstein claims that they don't need to be well funded)? I am not really seeking an answer, but these question are investigated (indeed in a rather ad-hoc fashion) in the above referenced annex.
Indeed. And maybe social-engineering the zone signature function comes in this category.
You may observe that the DNS root zone signature function is also subject to social-engineering attack. This should be a basic concern for the DNS root key management procedures, independently for both the official DNS root signature and the Intaglio NIC alternative source.
Correct. In this perspective, the Rabin-Williams cryptosystem is superior. But nowadays nobody seeks to make this advantage available in standardized protocols. This is a fascinating area, ...

@_date: 2010-04-22 11:55:02
@_author: Thierry Moreau 
@_subject: What's the state of the art in factorization? 
E.g. Koblitz, Neal; Menezes, Alfred, "Another Look at ``Provable Security''", Cryptology ePrint Archive: Report 2004/152, available at - Thierry Moreau

@_date: 2010-04-22 13:12:01
@_author: Thierry Moreau 
@_subject: What's the state of the art in factorization? 
Thanks for this feedback.
No, no, and no.
No, because I asked the question as a matter of security analysis methodology. My conclusion is that no purpose justifying an attack on the overall DNSSEC scheme particularly threatens the DNS root.
No, because while someone else's answer might be formulated based on non-rationale anti-USG paranoia (leading to a nice media story), the pervasive USG influence in the DNSSEC key management has very different impacts, the foremost one being that the DNS root may actually be signed soon (hey, great!).
No, because I don't want to handle the trouble of high visibility in a field where the public relations are already mixing up things (e.g. .org is signed but a registrant can't have a secure delegation for a .org domain as of today).
Caveat: I stopped volunteering information about specific elements of official DNSSEC root key management which might be criticized. It is time for the DNS root signature project to move forward. Also, the Intaglio NIC project has no value unless the official DNS root holds secure delegations.
But even without this self-restraint, there would be no spin for a CNN story. Dedication to good cryptographic key management is squarely dull and boring for a typical person.

@_date: 2010-08-01 10:43:23
@_author: Thierry Moreau 
@_subject: Is this the first ever practically-deployed use of a threshold 
Dear Peter,
It's about time the PKI experts have a look at DNSSEC ...
Let me try to convey my understanding to you, but please forgive the condensed language (I don't have time to make it self-explanatory).
Yes, the DNSSEC root KSK private signature key is protected with such a Technically, the USG requested FIPS-140-2 level 4 HSM technology for the DNS root signing gear. This implies a single source, with a very inflexible user interface (no special personalization of the HSM for the DNSSEC project). The threshold scheme was present in the vendor offering but there was no documented use of it (it may have been used internally by some organizations that would have taken seriously the dual control principle but who knows).
I don't know whether a number-theoretic foundation lies behind the threshold scheme. In any event, the crypto value protected by the scheme is the long term (intergity-)encryption key for the HSM configuration file, which includes the DNSSEC KSK private key.
The request by the USG is documented among other root signing requirements.
The detailed usage (the HSM is FIPS-approved, the usage is outside of compliance scope) is also documented (as usual you have to infer the operating principles from a plethora of minute details and meaningless acronyms). I made a critique of it on this list recently. Outside of this critique is the (inconsequential) fact that they seem to use "1234" as the PIN for the smart cards (I got this fact from a glimpse at the real-time video of the key ceremony).
They used the threshold scheme for two purposes.
One is the backup for long-term recovery capability. They rely on 5-of-7 custodians spread across a few continents (ICANN needs to look like an international organization).
The other purpose was transient, for the duplication of signature capability from the "East coast facility" to the "West coast facility". In that case, they use something like 2-of-3 (or 2-of-4) but they shipped the key share media (smart cards) and the HSM configuration file (yes, it *WAS* encrypted!! ) by means not subject to the same control/audit scrutiny as the rest of the procedure.
My critique is this lack of control/audit scrutiny for one-time shipment of crypto configuration material. Had ICANN published the *detailed* procedure in draft form, I would have pointed out this to them in a timely manner. In retrospect, their draft procedure document (which was a summary) hinted to this critique, but formulating it at that point was not on my plate: the Intaglio NIC key management organization does not need this second purpose (it applies its solution equally to the first purpose to the second purpose if it arises -- I presumed ICANN would come up with the same idea in their detailed procedure).
With the next key generation for DNS root KSK signature key, ICANN may have an opportunity to improve their procedure. However, at this point the project will be the focus of less attention, and the institutional commitment may not be as strong as it was for the first key generation.
Hope it helps ...

@_date: 2010-08-01 16:24:24
@_author: Thierry Moreau 
@_subject: Is this the first ever practically-deployed use of a threshold 
I was referring to "documented use of it" *before* the ICANN work on DNS root signature. I am sorry if you understood differently.
I am quite sure the activation keys are outside the scope of attention by Peter. Activation keys relate to a very different set of threats and Thanks for the clarification. Indeed, the choice not to use it (and not to apply PIN protection to the SMK shares by design) follows a logical set of usage assumptions.
If it leaked in transit, the destruction (electronic erasure followed by actual shredding of smart cards) is pointless. Otherwise, we seem to agree on the basic facts.
The very "couriered key material" was indeed created and used under these controls. My attention is focused on the courier *OPERATION* itself.
The offer to answer questions triggered a private e-mail to Jakob (but no genuine question). If anything new comes from this exchange, I will try to report to this same mailing list.

@_date: 2010-08-01 16:52:25
@_author: Thierry Moreau 
@_subject: Is this the first ever practically-deployed use of a threshold 
I fully agree with the general ideas above with one very tiny exception explained in the next paragraph. The DNSSEC root key ceremonies remains nonetheless an opportunity to review the practical implementation details.
The exception lies in a section of a paranoia scale where few organizations would position themselves. So let me explain it with an enemy of the USG, e.g. the DNS resolver support unit in a *.mil.cc organization. Once their user base rely on DNSSEC for traffic encryption keys, they become vulnerable to spoofed DNS data responses. I leave it as an exercise to write the protocol details of an hypothetical attack given that Captain Pueblo in unito-223.naval.mil.cc routinely relies on a web site secured by DNSSEC to get instructions about where to sail his war ship on June 23, 2035 (using the unrealistic assumption that Pueblo's validating resolver uses only the official DNS root trust anchor).

@_date: 2010-08-03 11:45:16
@_author: Thierry Moreau 
@_subject: Is this the first ever practically-deployed use of a threshold 
There is more than the UI at stake here, i.e. the basic functionality of the scheme. Say you distribute shares in a 4 out of 7 scheme (ABCDEF) and share A is published on the web. How do you recover from the remaining 3 out of 6 scheme into a 4 out of 6 scheme without having a key ceremony? In an ad-hoc multi-party scheme, you request 4 of the remaining compliant parties to destroy key material allowing them to participate in a group with the traitor A, but no other key material. No system UI, but admittedly a coordination nightmare!

@_date: 2010-08-04 11:23:06
@_author: Thierry Moreau 
@_subject: Is this the first ever practically-deployed use of a threshold 
Yes, or at least it gives a good sense that these issues has been dealt with in the cryptographic literature. It seems to fulfill the operational requirements (obviously when a good faith participant receives new shares from a remote party, a trust relationship is needed, but that is a given irrespective of the underlying crypto).
Thanks a lot for your answer!

@_date: 2010-08-23 17:17:56
@_author: Thierry Moreau 
@_subject: Fw: [IP] Malware kills 154 
FYI, avionics firmware/software is subject to RTCA DO-178b certification and fly-by-wire will inevitably require a "level A" certification which is quite demanding (i mean *QUITE*DEMANDING*) for software development process certification. There is no chance that an XP-based application/system would ever meet even the lower certification levels (but for the lowest one which corresponds to passenger entertainment Commercial avionics certification looks like the most demanding among industrial sectors requiring software certification (public transportation, high energy incl. nuclear, medical devices, government IT security in some countries, electronic payments, lottery and casino

@_date: 2010-08-26 11:05:03
@_author: Thierry Moreau 
@_subject: Is determinism a good idea? WAS: questions about RNGs and FIPS 
I guess the more productive question is "Since determinism requires a PRNG algorithm of some sort, which PRNG properties are needed in a given usage context?"
In all cases, the PRNG relies on a "true" random source for seeding.
You refer to IT security clients (SSL fiasco), IT security servers (virtualization), and lottery/gaming systems. In IT security nowadays large PRNG periods and crypto-strength PRNG algorithm are the norm. As I understand the state of the art in lottery/gaming industry (incl. standards), it is an accepted practice to use "short" period (by IT security standards) PRNG combined with a form of continuous entropy collection: background exercise of the PRNG.
I think the SSL fiasco "root cause analysis" would remind us of criteria that are nowadays well addressed in the IT security sector (assuming minimal peer review of the design and implementation).
In a security analysis, you watch for data leaks, either in the source of truly unpredictable events, or the present/past PRNG state for the deterministic components of your design. If you already need data leak protection for private or secret keys, your system design may already have the required protections for the PRNG state (except that the PRNG state is both long-term -- as a long-term private key or long-term symmetric authentication key -- and updated in the normal system operations -- as session keys).
So, there is no simple answer. I guess every designs facing actual operational demands rely on some determinism because a sudden surge in secret random data usage is hard to fulfill otherwise.
Forgive me to remind the PUDEC (Practical Use of Dice for Entropy Collection) which mates well with a server system design using PRNG determinism after installation (or periodic operator-assisted maintenance). This project is still active. See  . You may see this as a bias in my opinions, but I don't see any benefits in misrepresenting relevant facts and analyzes.

@_date: 2010-08-26 13:43:31
@_author: Thierry Moreau 
@_subject: questions about RNGs and FIPS 140 
Such implementations may be *certified* but this mode of CSPRNG seeding is unlikely to get *NIST*approved*. Cryptographic systems are *certified* with by-the-seat-of-the-pant CSPRNG seeding strategies (I guess) since crypto systems *are* being certified.
The tough part is to describe something with some hope of acquiring the *NIST*approved* status at some point. The above proposal merely shifts the difficulty to the TRNG. Practical Use of Dice for Entropy Collection is unique because the unpredictable process (shuffling dice) has clear and convincing statistical properties.
- Thierry Moreau

@_date: 2010-07-16 13:59:41
@_author: Thierry Moreau 
@_subject: Fw: Root Zone DNSSEC Deployment Technical Status Update 
That's a great achievement for the parties involved. It is also a significant step towards more trustworthy DNS data.
I have been following this with attention from the perspective of "system-wide master key", i.e. a slightly different perspective than "trust anchor". The trust anchor may indeed be trusted by anyone. The "system-wide master key" is intended to be trustworthy to some "broadest extent" according to some (tacit) assessment.
Three outstanding issues on my plate:
A social engineering incident?
With what was called DURZ (Deliberately Unvalidatable Root Zone), you, security experts, has been trained to accept signature validation failures as false alarms by experts from reputable institutions. I spare you the details, since DURZ is now over (it may have spread to TLD managers though), but the formal protocol specification allows a compliant validator implementation to declare a signature failure with the DURZ as it was deployed. No specific rationale was given to me for the non-use of unknown/proprietary/foreign signature algorithm code(s) as a better interim deployment strategy.
Auditing details are not yet public.
I am wondering specifically about the protections of the private key material between the first "key ceremony" and the second one. I didn't investigate these details since ICANN was in charge and promised full transparency. Moreover, my critiques were kind of counterproductive in face of the seemingly overwhelming confidence in advice from the Verisign experts. In the worse scenario, we would already have a KSK signature key on which a "suspected breach" qualification would be attached.
Is there an emergency KSK rollover strategy?
Again, I spare you the details, but the way the RFC5011 is implemented, there is no automated KSK rollover strategy (this would require a larger set of keys at the root because a standby KSK would be needed).
Nothing above threatens the relevance, effectiveness, and benefits of the current deployment, unless you have a rationale risk analysis that convinces you that "national security" grade key management is a necessity. My DNSSEC root signature key risk analysis does not conclude that "national security" grade key management is needed for the official DNS root zone.
But lessons may be learned with the perspective of a rigorous security analysis (if we had to do some system-wide key deployment with impacts similar to the global DNS integrity ...). The DNSSEC protocol definition and root deployment project has many facets in which it was venturing into virgin ground (e.g. the claimed transparency for the KSK management procedures by ICANN).
Nobody ever done such a thing before, even less so in a production system with global impacts, so I give them a provisional A grade (not an A+) until the full auditing details are provided. But that's only me!

@_date: 2010-07-17 09:52:04
@_author: Thierry Moreau 
@_subject: Root Zone DNSSEC Deployment Technical Status Update 
Dear Jakob:
Trying to reply specifically. The bigger picture would require extensive background explanations.
This is not the way I approach the DURZ strategy as implemented by the deployment team.
I am referring to a specific DNSSEC protocol provision, but I will first make an analogy.
You install a fire alarm system in your house (DNSSEC is an alarm system for bogus DNS data) but the UL certification officer didn't come yet to make the official approval (no trust anchor for a zone on which your e-banking relies). Then an alarm triggers in the night (the mob behind the e-banking phishers got the RRSIG wrong -- they have a learning curve too). You tell your relatives to stay in the house because the alarm system is not reliable. Oh no, you would rather play it safe! (but is that what your DNSSEC-aware banking application would do: avoid a service call to the e-banking center because you don't have a configured trust anchor?).
Here is the protocol provision: RFC4035 5.1 allows validators to report bogus (alarm signal) when encountering an unvalidatable RRsig for a zone without a local basis for trust anchor.
Incidentally, you say you [the design team] had good *documented* reasons for implementing DURZ *as*you*did*. Did you document why any of unknown/proprietary/foreign signature algorithm code(s) were not possible (this was an alternative)? This was my outstanding question.
Thanks, great. The two key ceremony scripts are what I wanted to look at.
OK. You seem to refer to courier service between East Cost Facility (ECF) safe  (closed at ceremony 1 steps 199-202 and presumably opened for the courier service later on), carrying Tamper Evident Bags (TEB) sealed at steps 194-197 (see also 80-84), and deposited in West Coast Facility (WCF) safe  in advance of ceremony 2. At the WCF ceremony 2, the TEB were retrieved from the safe at steps 35-38, and the TEB tamper clues were verified at steps 73-76.
For the record, this key material exited the WCF HSM technology-intensive world at ceremony 1 step 60 and re-entered the ECF HSM  at ceremony 2 step 77-78. (The key material also entered WCF HSM  and ECF HSM I don't have a question. I will trust the DNSSEC root signatures. However, it seems obvious that formal dual-control rules should have been designed, e.g. a "Trusted Courier Officer" role with a 3 out of 4 (or 5) separation of duty. Without this, the key material has been protected only by the tamper-evident protection in transit from the ECF to the WCF. This role would have been limited in time.
I don't want to discuss the effectiveness of tamper-evident envelopes, or the additional controls built around the core key material in the HSM technology. These are mainly obfuscating the core principles.

@_date: 2010-07-17 14:23:41
@_author: Thierry Moreau 
@_subject: Root Zone DNSSEC Deployment Technical Status Update 
Yes. E.g. if a zone is signed only by algorithm GOOSE_128, and your validating resolver does not know this algorithm, the DNS zone data remains "insecure" (this is what you mean by "unverified" I guess). That's in the DNSSEC protocol.

@_date: 2010-07-22 15:44:59
@_author: Thierry Moreau 
@_subject: What if you had a very good entropy source, but only practical at 
See  .
(OK, it's also practical whenever the server needs servicing by trusted Then, you care about the deterministic PRNG properties, the secrecy of its current state, and the prevention of PRNG output replays from an out-of-date saved state.
And bingo, you solved the random secret generation issue satisfactorily!

@_date: 2010-07-29 16:51:50
@_author: Thierry Moreau 
@_subject: Persisting /dev/random state across reboots 
First look at There is a tremendous value in the Linux kernel technology, including extensive peer review from an IT security perspective.
If you think there are security requirements not met (e.g. assurance of entropy characteristics, assurance of implementation configuration sanity), then you should state your design goals. Only thereafter we get an understanding of good, bad, or more relevant: improved.

@_date: 2010-10-06 12:48:25
@_author: Thierry Moreau 
@_subject: What if you had a very good entropy source, but only practical 
Dear all:
The PUDEC (Practical Use of Dice for Entropy Collection) scheme has been advanced. The new web page is at The main technical advance in this release is the documentation of (deterministic) algorithmic support (  ). This development effort uses a structured process as if it targeted FIPS140-2 level 4 certification, hence the release of documentation before reference source code.
Plus the PUDEC dice sets are now offered for sale.
If you are part of an open source project (GPL) for a cryptographic key management server or an "open source HSM" and you see a useful feature in self-evident entropy source, don't hesitate to contact me (I would consider an open source contribution if such projects have a reasonable chance of critical mass adoption).

@_date: 2010-09-07 10:12:59
@_author: Thierry Moreau 
@_subject: questions about RNGs and FIPS 140 
Well, I find SP800-90 Annex C (Entropy and Entropy Sources) quite clear about the requirements. If nothing is approved, we may guess it's because no unpredictable phenomenon has been shown (convincingly) to be In terms of solution documentation requirements, I see four stages:
1) unpredictable phenomenon,
2) sensor technology,
3) digitalization,
4) conditioning.
I separate 2 and 3 while NIST seems to merge them. I see them separate since the sensor technology is seldom developed with the entropy collection application in mind (the unpredictable phenomenon is not engineered: it just exists). The digitalization refers to the algorithmic processing taking raw A-to-D (analog to digital) data and giving some discrete measurement of the unpredictable phenomenon. This measurement is basically a convenient intermediate representation using a physical characteristic that is better understood, for analysis purposes, than the raw A-to-D data.
The digitalization algorithm may be the same as for pre-existing uses of the sensor technology, in which case an after-the-fact certification is NIST seems to favor very well defined algorithms for affixing the NIST approved mark. The, the digitalization algorithm for a given pair  may be challenging.
I released (a few days ago) a specification document for digitalization and conditioning algorithms for PUDEC, Practical Use of Dice for Entropy Collection, see Incidentally, another difficulty is that confidence in the entropy collection function is difficult to support with boot time / run time testing. IIRC, the statistical testing at boot time had to be dropped from the FIPS140 requirements because false failures (intrinsic to statistical testing) were not manageable in an operational context.
Obviously, there are other considerations to NIST approval because it would become a procurement specification for the US Federal government.

@_date: 2010-09-28 10:18:52
@_author: Thierry Moreau 
@_subject: Certificate-stealing Trojan 
Don't forget that the described trojan looks for an actual *client* private key and certificates. This puts Malory in a position to impersonate the victim comprehensively including non-crypto validity checks (e.g. confidence gained from log of recent activity using this Then the question is which PKIs actually deploy client certificates.

@_date: 2013-12-28 12:42:32
@_author: Thierry Moreau 
@_subject: [Cryptography] Fwd: [IP] RSA Response to Media Claims Regarding 
I am of the opinion that this is precisely the greatest victory of ITAR regimes (i.e. COCOM then Wassenaar): to shrink the market for sound IT security solutions using cryptographic techniques to a point where this industry segment would be essentially ineffective.
But due to "the power of the installed base," the above-mentioned victory is still highly influential.

@_date: 2013-11-07 09:54:26
@_author: Thierry Moreau 
@_subject: [Cryptography] CD bootable Linux (was randomness +- entropy) 
There is this US military sector initiative "Lightweight Portable Security" with precisely this mandate.
I looked at it (version 1.2.0), initially to get the tools to re-create my own (say I don't like their list of trusted root CA ...) and expected to get some contact point where I could get the source ... I didn't finish this chase, but in looking for GPL'ed software components I came across their selected solution for a true RNG source (it's a security-centric raison d'?tre, so there must be some thought in this aspect of *system* design).
The finding was plainly uninteresting: some cpu instruction timing jitter measurements developed by someone who lost interest after having released his code under the GPL.
I would definitely like to see some distribution of required tools and scripts for creating a CD bootable Linux with an emphasis on security considerations. Obviously, e.g. from this long discussion, the true RNG source would remain an "area for further study."

@_date: 2014-04-10 07:51:15
@_author: Thierry Moreau 
@_subject: [Cryptography] E-government service outage from HeartBleed 
Quote from the home page of Canadian tax authority
=== beginning of quote ===
CRA update regarding the Heartbleed Bug - Wednesday, April 9, 3pm
The Canada Revenue Agency (CRA) places first priority on ensuring the confidentiality of taxpayer information.
After learning late yesterday afternoon about the Internet security vulnerability named the Heartbleed Bug that is affecting systems around the world, the CRA acted quickly, as a preventative measure, to temporarily shut down public access to our online services to safeguard the integrity of the information we hold. Applications affected include online services like EFILE, NETFILE, My Account, My Business Account and Represent a Client.
We are currently working on a remedy for restoring online services and, at this time, anticipate that services will resume over the weekend.
The CRA recognizes that this problem may represent a significant inconvenience for individual Canadians who count on the CRA for online information and services.
Recognizing this, the Minister of National Revenue has confirmed that individual taxpayers will not be penalized for this service interruption.
We continue to investigate any potential impacts to taxpayer information, and to be fully engaged in resolving this matter and restoring online services as soon as possible in a manner that ensures the private information of Canadians remains safe and secure.
We will provide further information and daily updates at 3PM EDT on our home page.
=== end of quote ===

@_date: 2014-01-02 22:16:25
@_author: Thierry Moreau 
@_subject: [Cryptography] Dual_EC_DRBG backdoor: a proof of concept 
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
This is the only thing that the alluded BBS "backdoor" allows. In other words, the backdoor allows one to write a custom-made statistical test that the generator will fail. The backdoor does not allow the recovery of the PRNG state from a fraction of the output sequence -- or at least I never saw the slightest hint, speculation, or academic author conjecture that this would be possible for any fraction less than 1.
Out of memory, the engineering issue is solved as follows:
(A) Generate a first BBS modulus and discard the prime factors P and Q.
(B) When provisioning a secure device, seed the first BBS with true entropy, then generate a device-specific BBS modulus and discard prime factors P' and Q'. Don't use the first BBS for any other purpose starting with the same seed.
(C) In operations, occasionally re-seed the device-specific BBS as you would do with any deterministic PRNG.
If you don't trust the software for the discard operation in (A) and (B), then you shouldn't trust the software for any other crypto algorithm.
For bootstrap your confidence, you recursively perform (A)-(B)-(C) with   (C) being used for the next (A) in the recursion, until the "security by management exhaustion" paradigm applies.
Have fun with crypto-grade PRNG selection and implementation design!

@_date: 2014-01-03 14:39:30
@_author: Thierry Moreau 
@_subject: [Cryptography] Dual_EC_DRBG backdoor: a proof of concept 
It's interesting that you ask this question in the specific context of device provisioning. Maybe it's not intentional, but I intend to answer the question in this specific context.
If you provision a secure device for a usage that deserves strong protection, you may temporarily attach a trusted secret random data source for the provisioning operation.
Obviously, entropy source assurance is a system-level assurance challenge. If you procure turnkey systems from a given vendor, you either trust the vendor, or add an entropy source solution as an accessory. This is independent of a PRNG algorithm selection.
   If you are
But Linux itself is not a system-level solution. Even a Linux distribution is not a system-level solution. It is when installed on a given hardware that we get a system-level solution and we may make a final assurance assessment.
   How do you peer review whether or not Apple (or more
You define the problem as an impossible one. It's impossible for you and I to ensure John Doe can trust a manufacturing process.
Maybe we can first address the needs in usage contexts where security impediments are offset by the value of additional protections. At least this is how I see my mission (in which the BBS algorithm has its merits).

@_date: 2014-01-19 14:49:36
@_author: Thierry Moreau 
@_subject: [Cryptography] HSM's 
That's nice to dream of a "Multi-Party Computing HSM" (such concepts might already exist in the academic literature). But at the end of the journey, one party will be faced with the same initial dilemma: trust some vendor or build your own (OK each party *independently* faces the I once thought that there was substance in an HSM (assuming the HSM API could be made "secure" ...).
The more I think about it, the more I see the whole concept a mere social issue: irrespective of the technology, you end up trusting a -- socially acceptable -- organization operating the HSM.
For an off-line HSM (one used in occasional "key ceremonies") the practical solution looks like a controlled Linux kernel plus minimal crypto utilities with multi-party key injection and secure destruction respectively opening and closing the key ceremony. Pick up the oldest hardware that supports your software. Side channel vulnerabilities handled by selecting the facilities where the ceremony occurs (more or less inhibiting paranoia operating here). The HSM concept turns into an organizational trust issue because the parties doing the key injections are now a critical point.
For an on-line HSM, you end up trusting the host applications making use of the HSM services, again a dependency on the operating organization.
A final note: Anyone aware of an HSM vendor that did not follow NIST advice in their engineering? Maybe the HSM concept is just dead after the Snowden revelations.

@_date: 2014-01-20 13:42:54
@_author: Thierry Moreau 
@_subject: [Cryptography] HSM's 
Good joke!
"Industry best practice" suffices for avoiding known weak algorithms and crypto parameter sizes, given a knowledgeable customer organization.
Also thanks for pointing to the vagueness of my previous post. Let me attempt to clarify.
NIST-independent HSMs could aim at certification per
CEN WORKSHOP AGREEMENT, "Security Requirements for Trustworthy Systems Managing Certificates for Electronic Signatures - Part 1: System Security Requirements" CWA 14167-1, June 2003 (and other parts and related documents).
My original question hinted at a very very small market for this idea of a NIST-independent HSM.
NIST-independent HSM designed and build at arms' length with the US jurisdiction might be less subject to NSA backdoors. Obviously I'm just speculating with these words but you might see my point.
- Thierry Moreau

@_date: 2014-01-21 06:46:58
@_author: Thierry Moreau 
@_subject: [Cryptography] HSM's 
On the other hand, each relying party has to reassemble a public key set with each elementary public key subject to revocation, rollover, and the like. Not a trivial task for a large population of relying parties.

@_date: 2014-01-21 16:18:58
@_author: Thierry Moreau 
@_subject: [Cryptography] Auditing rngs 
You did not prove anything about the 512 bits entropy estimate. You merely postulated it. The deterministic process from (Ex,Ax) to keypairx may be audited like any other software logic implementation.

@_date: 2014-01-29 05:03:37
@_author: Thierry Moreau 
@_subject: [Cryptography] cheap sources of entropy 
Indeed there are no low entropy environments. However, the very mission of a digital system is to methodically provide tidiness out of a mostly chaotic environment.
The problem with these precise measurements (low bits of precise event timing or physical phenomenon measurements) is that there is no known usage except as a source of entropy. Then a reasonable system design might find no justification for preserving these "useless bits" and drop them early in the acquisition chain (truncation, filtering, hysteresis algorithm). Such design approach would be even preferable for processing determinism, memory efficiency, easier system validation (less "useless bits"-dependent bugs).
Plus obviously that these precise measurements are system specific and not part of a vendor commitment with respect to minimal specifications (e.g. an ambient temperature measurement needs no greater precision than one degree, so the 0.01 fractional degree happens to exhibit jitter in one system production batch and turns constant in the next one).
There are no economic incentives for a low-cost manufacturer to commit to provide a "trusted" source of entropy. Intel did something and now their design is suspected of back-door by (a portion of) the very community that requested something to be done.
Somehow this discussion tends to run into circles.

@_date: 2014-06-16 03:27:06
@_author: Thierry Moreau 
@_subject: [Cryptography] [cryptography] Dual EC backdoor was patented by 
I looked at the primary documents in the USPTO databases. The part that is missing from the US patent 8,369,213 (i.e. missing from the original filing and the European patent I suppose) is now in the pending patent application US-2013-0170642-a1.
Are these inventors claiming to have *invented* the backdoor in this PRNG method? At least an USPTO examiner hints at this: "[claims now in US-2013-0170642-A1] are drawn to establish escrow key with elliptical curve random number generator." The inventors *describe* the escrow technique but need not *claim* it.
Note also that the earliest (USA) filing date is 2005/01/21 as a provisional US patent application number 60/644982.
Technically, this is not a submarine patent. The publication date is 2007/08/16 (soon after the international-treaty-based 18 months delay after the filing date applicable to the non-USA patent jurisdictions) and anyone could have access to this information by then.
Sometimes I think a little more patent literacy might help. E.g. a self-defense behavior for some system designer relying on the ECC techniques would include a periodic look at patent applications freshly published in this area and/or by the known players.
Fascinating case study anyway!
- Thierry Moreau

@_date: 2014-06-19 03:57:59
@_author: Thierry Moreau 
@_subject: [Cryptography] Shredding a file on a flash-based file system? 
A question in the recurring issue of hiding a secret in a computing device.
Suppose you have a small computing device to do some crypto with only a flash-based file system (no swap area, and you can afford a destructive RAM test upon shutdown, so RAM reminiscence is a lesser issue). You store lasting secret data in a file.
When you want to zeroize the critical file, you can not rely on the shred utility (or do you?) due to the core flash technology (turning a bit from "1" to "0" is a simple write, the reverse commands a full block erasure for some flash-integrated-circuit-fixed block size).
We are dealing only with non-journalizing file systems. Also, one should check that the file system does not keep track of access times (and modification times) for the file since these reveals some information to an adversary.
Here is my current concern: if one assumes that a flash file system will optimize write operations such that turning every bits to zero will *not* trigger allocation of new file space on disk.
Does anyone know if this assumption is reasonable?
I understand that solid state drives come with various implementations of a low level space management system logic, over which a partitioning logic applies before a file system (in the traditional O/S sense) is hosted in a (more or less?) device-independent way. I would suspect that the most fundamental optimization (not allocating new space when a write request only turns "1" bits to "0") is applied effectively despite this involved logic arrangement.
Generally, I don't like flash-based mass storage, but they are cost-effective nowadays.
Maybe the best answer requires experimentation with a specific combination of solid state drive, controller, driver, and file system (ext2 most likely). That is, behave like an enemy (law enforcement friend) chasing the secret data after the zeroization attempt, except that I known the exact data values to look for. A low-level read-only access to the block device is the basic facility for this unsophisticated experiment. Anybody attempted this?
Let's advance the field! Thank in advance.
- Thierry Moreau

@_date: 2014-06-19 14:15:25
@_author: Thierry Moreau 
@_subject: [Cryptography] [cryptography] Dual EC backdoor was patented by 
I thought the spec from NIST included curve and point parameters that can be "freely used." I assumed this as a repetition of the Suite B case where a license granted by the patentee to the US government had a similar effect. The problem being that "best industry practice" turned out as a recommendation to use other parameters.
But please don't take my words as authoritative: I did not check the relevant details.
- Thierry Moreau

@_date: 2014-06-20 14:27:58
@_author: Thierry Moreau 
@_subject: [Cryptography] Shredding a file on a flash-based file system? 
Dear John:
Thanks for your extensive and most interesting answer. See below for a specific acknowledgment.
Thanks for the bad news. This paragraph puts the last nail in the coffin, with convincing evidence (i.e. more than a mere "I would never trust vendors").
- Thierry

@_date: 2014-03-17 12:43:59
@_author: Thierry Moreau 
@_subject: [Cryptography] Client certificates as a defense against MITM 
Maybe you merely (re-)invented the HTML cookie holding the client private key.
More or less explicitly, the "first party certification paradigm" seems attractive to you: no CA-in-the-loop for server trust in client public keys.
- Thierry Moreau

@_date: 2014-03-17 12:50:33
@_author: Thierry Moreau 
@_subject: [Cryptography] Client certificates as a defense against MITM 
Indeed it is not trivial. In a self-defense perspective where the client knows what its private key computations are doing, the above protection against MITM is focused on the "don't speak to strangers" motto. I.e. as you indicated, don't provide any sensitive information from any site before it displays prior personal data in the HTTPS session authenticated with your private key.
The main challenge is to eradicate the client *certificate* from user (and security expert as well) mental model and bring the core notion of client PPKP (Public-Private Kery Pair), while the browser only takes PKCS12 format.
The IT security community did not need an NSA for this self-inflicted harm.
- Thierry Moreau

@_date: 2014-05-20 18:19:50
@_author: Thierry Moreau 
@_subject: [Cryptography] The Trust Problem 
Please demand nothing from this vendor.
Simply ask yourself how you can share encrypted data "with the people you trust." If this undertaking made a breakthrough in this area, help us learn about their scientific publication explaining it (that would disclose a novel encryption key management scheme).
Nice mobile app packaging is evidence of nothing.
Your decision should have been made long ago. It's about symmetric encryption key management, public key cryptography assisted or not, and remote party authentication, the way you like it.
- Thierry Moreau

@_date: 2015-04-01 15:37:43
@_author: Thierry Moreau 
@_subject: [Cryptography] The "Evanescent Security Module", 
here is this new document:
"The Evanescent Security Module, Concepts and Linux Usage Strategies"
(Not an April fool announcement despite the funny name for an HSM!)
- Thierry Moreau

@_date: 2015-04-01 17:46:48
@_author: Thierry Moreau 
@_subject: [Cryptography] The "Evanescent Security Module", 
here is this new document:
"The Evanescent Security Module, Concepts and Linux Usage Strategies"
 (corrected URL)
(Not an April fool announcement despite the funny name for an HSM!)
- Thierry Moreau

@_date: 2015-04-17 17:26:11
@_author: Thierry Moreau 
@_subject: [Cryptography] Entropy is forever ... 
Dear all:
Quoting the basic definition of entropy from Wikipedia, "In information theory, entropy is the average amount of information contained in each message received. Here, message stands for an event, sample or character drawn from a distribution or data stream." In applied cryptography, the entropy of a truly random source of "messages" is an important characteristic to ascertain. There are significant challenges when applying the information theory, probability, and statistics concepts to applied cryptography. The truly random source (and computations using random message data) must be kept secret. Also the following dilemma should be noted: the truly random source is needed in a digital processor system typically engineered with determinism as a design goal derived from the basic reliability requirement. Quantitatively, the entropy measure for applied cryptography, in the order of hundreds of bits, is way beyond any workable statistical analysis processes. In practice, a truly random source usable for applied cryptography is a system procurement issue that can seldom be blindly delegated as an ordinary operating system service. Thus, one wants a reliable source of uncertainty, a trustworthy one than can barely be tested, as a universal operating system service totally dependent on hardware configuration.
Applying the information theory to actual situations is error-prone. Is there a lower entropy in "Smith-725" than in "gg1jXWXh" as a password string? This question makes no sense as the entropy assessment applies to the message source. A password management policy that rejects "Smith-725" as a message originating from the end-user population actually constraints this message source with the hope of a higher average amount of information in user-selected passwords. From a single end-user perspective having to deal with an ever growing number of passwords, the entropy concept appears as a formalization of the impossible task he/she faces.
Significant conceptual deviation may occur from the common (and correct) system arrangement where a software-based pseudo-random number generator (PRNG) of a suitable type for cryptography is initially seeded from a secret true random source and then used for drawing secret random numbers. It is often inconvenient for statistical testing to apply directly to the true random source messages, but statistical testing of the PRNG output gives no clue about the true random source. The design of PRNG seeding logic is an involved task dependent on the true random source which may be hard to modelize in the first place. In actual system operations, the inadequate seeding may have catastrophic indirect consequences but it may be difficult to detect, and it is certainly a challenging error condition for service continuity (programmers may be inclined to revert to insecure PRNG seeding when the proper true random source breaks down).
Despite these pitfalls, I assume my reader to share my endorsement of the true random seeding of a cryptographic PRNG as the main source of random secrets for a digital processor system dedicated to cryptographic processing. As this PRNG output is being used in various ways, chunks of the output sequence may be disclosed to remote parties. It is an essential requirement for a cryptographic PRNG that no output chunk may allow the recovery of its internal state (i.e. some data equivalent to PRNG seed data leading to the same PRNG output sequence as the secret PRNG).
In this note, I challenge the view that an entropy pool maintained by an operating system ought to be depleted as it is used. I am referring here to the Linux "entropy pool." My challenge does not come through a review of the theory applied to the implementation. Instead, I propose a counter-example in the form of the above arrangement and a very specific example of its use.
The central question is this problem. A system is booted and receives 2000 bits of true randomness (i.e. a 2000 bits message from a source with 2000 bits of entropy) that are used to seed a cryptographic PRNG having an internal state of 2000 bits. This PRNG is used to generate 4 RSA key pairs with moduli sizes of 2400 bits. The private keys are kept secret until their use in their respective usage contexts. No data leak occurred during the system operation. After the key generation, the system memory is erased. What is the proper entropy assessment for each of the RSA key pairs (assume there are 2^2000 valid RSA moduli for a moduli size of 2400 bits, a number-theoretic assumption orthogonal to the entropy question)?
My answer is that each of the 4 RSA key pairs are independently backed by 2000 bits of entropy assurance. The entropy characterization (assessment) of a data element is a meta-data element indicating the entropy of a data source at the origin of the data, plus the implicit statement that no information loss occurred in the transformation of the original message into the assessed data element. Accordingly, my answer should be made more precise by referring to an unbiased RSA key generation process (which should not be considered a reasonable assumption for the endorsement of lower ranges of entropy assessments).
To summarize, the entropy assessment is a characterization of a the data source being used as a secret true random source. It also refers to the probability distribution of messages from the data source and the quantitative measure of information contents derived from the probability distribution according to the information theory. This mathematical formalism is difficult to apply to actual arrangements useful for cryptography, notably because the probability distribution is not reflected in any message. The information theory is silent about the secrecy requirement essential for cryptographic applications. Maybe there is confusion by assuming that entropy is lost when part of the random message is disclosed, while only (!) data suitability for cryptographic usage is being lost. In applying the information theory to the solution of actual difficulties in applied cryptography, we should address secrecy requirements independently. The probability distribution preservation through random message transformations is an important lesson from the theory that might have been overlooked (at least as an explicit requirement).
A note about the genesis of the ideas put forward. In my efforts to design applied cryptography key management schemes without taking anything for granted and paying attention to the lessons from the academia and their theories, I came with a situation very similar to the above problem statement. The 2000 bit random message from a 2000 bits entropy truly random source is a simplification to the actual situation in which a first message transformation preserves the probability distribution of random dice shuffling. In the above problem statement, the PRNG seeding is another distribution preserving transformation. The actual PRNG is based on the Blum-Blum-Shub x^2 mod N generator, which comes with two bits of entropy loss upon seeding. The above problem statement is thus concrete.
Maybe the term entropy is used, more or less by consensus, with a definition departing from the information theory. Indeed, NIST documents covering the topic of secret random numbers for cryptography use conflicting definitions surrounding the notion of entropy.
Although my own answer to the stated problem puts into question the Linux "entropy pool" depletion on usage, I do not feel competent to make suggestions. For instance, my note hints that a PRNG algorithm selection should be part of the operating system service definition for idea of whether and how the open source community might move in this Entropy is forever ... until a data leak occurs.
A diamond is forever ... until burglars break in.
- Thierry Moreau

@_date: 2015-04-19 13:23:52
@_author: Thierry Moreau 
@_subject: [Cryptography] Entropy is forever ... 
In the question I asked, the computational independence is
In the question I asked, the two disclosures are distinct
one-way transformations of the common 2000 bit sample.
You may even explicitly consider the case where the
two disclosures are to distinct parties (the RSA key pairs
"usage context" was unspecified).
Thermodynamics ...
Well, you may blame my incompetence for my unwillingness
to follow this route.

@_date: 2015-04-21 14:10:55
@_author: Thierry Moreau 
@_subject: [Cryptography] Entropy is forever ... 
Thanks for this feedback from the practitioner perspective.
See below for a comment.
My suspicion (in trying to adapt the theoretical work to trustworthy implementations) is that no heuristic can do this entropy extraction with 100% efficiency. Here is an ideal extractor algorithm and an artificial distribution that (I guess) shows what I mean. Take a 256 bits PRNG seed and a 256+8=264 bits random message source with with a uniform distribution for the 2^264 messages except that a specific message occurs 16 times more often. The minimum entropy measure would thus be 260 (based on the message sample with the highest probability).
The entropy extractor designer does not know for sure the 2^264 bit message distribution.
The ideal extractor is a fixed pseudo-random mapping from 264 bit strings to 256 bits ready to seed the PRNG (it is "pseudorandom" in order to wipe out statistical defects not considered in the artificial distribution). The mapping of the singular message creates a statistical defect in the seeding operation.
So, even if the minimum entropy is larger than the PRNG seed size, it seems impossible to design an extractor that can reach full entropy for the PRNG seed.
 From the practitioner perspective, the artificial distribution is a secondary consideration but the conclusion inferred from it may be relevant. This is why I prefer a larger PRNG seed (and internal state) larger than the key space sizes for the cryptography downstream in the random data processing flow.
Before the Edward Snowden wake-up signal, it would have been silly to publicly suspect NIST to be influenced by the NSA for PRNG seed sizes exactly fit to the cryptographic processing downstream. Understandably, the role of the NSA is to preserve its future ability to "break some of the codes some of the times" and a few bits of entropy surreptitiously chopped off from the key space is a small gain for them.
Yes, "it's not necessarily the best way" because there seems to be no best way.
Again, thanks for the feedback.

@_date: 2015-04-21 23:22:55
@_author: Thierry Moreau 
@_subject: [Cryptography] Entropy is forever ... 
This concept is used in NIST documents for a conservative estimate of randomness from a hardware random source.
- Thierry

@_date: 2015-04-23 11:38:14
@_author: Thierry Moreau 
@_subject: [Cryptography] Entropy is forever ... 
Another perspective perspective is to break down the analysis in two steps:
1) You need the lessons from physicists before the digitizing sensor for the real world random process on which the hardware RNG relies.
2) After the digital samples (numeric values) are taken, the system analysis turns to the Shanon information theory (and refinements like the R?nyi entropy) with its limited definition of entropy.
In the second step, the (information theory) entropy assessment of a PRNG seed is derived from the analysis in the first step (a characterization of the random data source). This analysis is (typically, necessarily?) out-of-band of the data flow.
Despite the inter-relationships between the two steps, breaking down the analysis in two steps helps simple minded persons like me.
- Thierry

@_date: 2015-08-12 14:25:31
@_author: Thierry Moreau 
@_subject: [Cryptography] SRP for mutual authentication - as an 
On the relevance of the fidoalliance.org initiative,
My two points: 1) general feedback of UAF / U2F
2) specific comment on Ben objections
1) general feedback
 From a very superficial look at the technology, the UAF / U2F approach has some good points:
- by relying on a public key digital signature for routine authentication (login), it rests on a very effective password phishing countermeasure (maybe the only effective countermeasure),
- it uses client private signature keys without the concept of client security certificate, something I refer to as the "first party certification" paradigm,
- it managed to get some momentum as an industry alliance.
It may also have limitations:
- the proof of possession at the registration phase provides no protection against impersonation attack at this phase,
- while the client side device (could be a software emulation) is touted as requiring a form of biometric or PIN enablement, this requirement is hardly enforceable by the protocol.
Both of these limitations appear minor if we envision the technology as a replacement for password-only authentication for minimal security applications, but may become more serious when the added security attracts higher valued services and/or when the added perceived security induces a relaxation of vigilance for the limitations.
2) Specific comment on recovery of lost authenticator
The client-side implementation may include private signature key backup facilities. Obviously, there is an implicit vulnerability with this avenue, but nonetheless that's an ever-present mitigation strategy for the ever present operational threat of a private key loss incident.
Maybe Ben should have figured it by himself; likely he did but was arguing from an ordinary user perspective.
The UAF / U2F approach seems to defer the difficult user interface for managing a private signature key to the implementation at the client side. Do we have some anecdotal experience in user interface for managing bare private keys (not linked to a security certificate, and without cryptoperiod expiration requirements)?
- Thierry Moreau

@_date: 2015-12-04 17:31:58
@_author: Thierry Moreau 
@_subject: [Cryptography] Anyone else seen some odd shipping delays? 
Is paranoia a productive feeling? See below for details.
Two propositions:
a) you missed a simple explanation for delays and apparent non-sense,
b) irrespective of your findings, you will remain suspicious of what's inside these boxes full of firmware with peripheral access to potential subliminal channels.
Is your day job about designing crypto key management schemes where the most critical operations are performed in computing environments (e.g. an "open source HSM") where critical secret leakage risk is manageable?
(At least I think the last paragraph is a more productive use of my time.)
For minimally related feedback, a shipment for a box equipped with wired and wireless interfaces had neat bar code labels on the outside of the box for the MAC addresses of both interfaces. I guess this is useful for feeding a database of [MAC address to customer shipment details] for mass surveillance support.
I guess the last trusted box I procured was a 80486-based desktop with a 40GB hard disk found in the garbage in a city sector remote from where I live. Nonetheless, I do not plan future procurements with this strategy.
- Thierry

@_date: 2015-06-17 13:32:22
@_author: Thierry Moreau 
@_subject: [Cryptography] password fatigue;  was: Lastpass 
Thanks for this well-written review of a central issue.
I must admit I never studied the SRP protocol details. I looked at it from time to time, however.
However, it may be significant that I never learned any *enrollment* protocol companion for SRP. Let me ask the question in the perspective of the present claim that larger SRP deployment is a good strategy for using a single password for multiple sites.
Say Alice enrolled a dozen sites with a single password using SRP for routine authentication. When enrolling with a next site, she worries:
a) is the local implementation supporting the enrollment procedure trustworthy with respect to not disclosing my password to the next site?
b) if I'm unsure about question a), I will have to revoke my enrollments with the already enrolled 12 sites ... hum ... the SRP designers must have foreseen this, don't they?
c) why nobody taught me something about SRP enrollment security?
(Obviously an enrollment protocol that discloses the password to the site with the assumption that the site will delete it at the end of the protocol is not an acceptable solution.)
I see only one direction, which is actually not present in the marketplace. You need a separate system with limited functionality, features-lean instead of features-rich, on which the end-user performs the security-critical applications.
- Thierry Moreau

@_date: 2015-05-11 16:56:51
@_author: Thierry Moreau 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
I doubt the foremost questions will be addressed:
To which extent NSA influence motivates NIST in advancing the ECC standards?
Can independent academia members present hypothetical mathematical advances (even breakthroughs) that NSA could have made, or could speculatively expect to make, in order for the NSA to provide the US a cryptanalysis advance over the rest of the world (central to NSA mission).
To which extent the table of key size equivalences (between factoring-based cryptosystems and ECC schemes) is biased for a faster adoption of ECC (e.g. it makes sense to move to ECC because the "equivalent" RSA key sizes are inconvenient)?
NIST has been unquestionably useful for the cryptographic community with the AES and ASHA competitions. The outcome of the former is a widely deployed improvement over prior symmetric encryption algorithms. The outcome of the latter appears less attractive for adoption decisions, but the very challenges of an efficient secure hash algorithm seems to be the root cause, and not the NIST competition process.
With ECC, I have less confidence in NIST ability to leverage the cryptographic community contributions.
- Thierry Moreau

@_date: 2015-05-12 02:14:46
@_author: Thierry Moreau 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
Thanks for the reminder. I did read one report by NIST on this subject and it was already surprising how self-critical NIST was. The above talk goes in the same encouraging direction.
Let me try to re-phrase what I meant.
I do not want to push any plot theory without a deep understanding of the ECC fundamentals. But recalling that NSA had prior knowledge of differential cryptanalysis (versus academia) and prior knowledge of RSA and D-H, is there any specific research directions in the ECC field in which the NSA could have advance knowledge that would induce them to push ECC deployment over factoring-based RSA?
- Thierry

@_date: 2015-11-02 18:50:00
@_author: Thierry Moreau 
@_subject: [Cryptography] Curious about FIDO Alliance authentication scheme 
I previously asked the same question as Henry Baker in another thread (YubiKeys / FIDO / U2F ??), but I did some primary source material analysis which I shared.
Here is a reminder:

@_date: 2015-11-18 13:21:15
@_author: Thierry Moreau 
@_subject: [Cryptography] Diffie-Hellman after the Logjam paper versus IETF 
The Logjam paper ( makes three recommendations for Diffie-Hellman parameters: transition to ECC-DH, use larger (>=2048 bits) DH primes, and avoid fixed 1024-bits DH primes.
In reviewing the current standardized DH parameters, I came across two First some references with an historical perspective.
Oakley primes were introduced in RFC2409 section 6 (768 and 1024 bits). Larger primes were standardized in RFC3526 (confirmed widely used 1536 bits plus 2048, 3072, 4096, 6144, and 8192 bits). The DH generator is 2.
Very recently (
 appendix A) the Oakley prime number generation strategy is replayed, substituting the Euler constant binary extension for the pi binary extension as an unbiased trusted pseudo-random sequence. Note that the DH generator remains at 2 in this new document.
In the meantime, two standardization actions took place.
The authors of an EAP variant RFC6124 (section 7.1) found useful to modify the Oakley standard parameters by changing the DH generator value from 2 to a small prime number specific to each DH prime number (respectively 5, 31, 11, 5, and 5 for Oakley primes of 1024, 1536, 2048, 3072, and 4096).
Finally, RFC5114 seems to scoop NIST on its own ground, introducing DH parameter sets with a defined and reduced size "prime order subgroup" with a generator value as large as the DH prime. I wonder if this standardization action actually turned a test vector example (originally intended as an example of a random parameter generation) into a fixed DH parameter set of the type found problematic in the Logjam paper. Indeed, the RFC5114 text refers to the NIST CSRC page  from which one may come to the document
 which is over 100 pages of test data without textual explanations or author attribution.
Then the two questions:
Q.1 Is the generator value selection per RFC6124 a better alternative than the fixed generator value 2?
Q.2 Is there any benefit in the size reduction for the prime order subgroup standardized by RFC5114 (beyond complying to the NIST addiction to cryptographic parameters exactly fit to a given security parameter)?
The default answers are yes to Q.1 and no to Q.2. Therefore, ongoing standardization work is a dubious place for basic wisdom on using a cryptographic primitive. RFC6124 has it almost right (it should have omitted the 1024 prime size) but seems outside of mainstream IETF work.
Apologies to IETF'ers for not making a contribution out of my opinion (you may use this message as you see fit).
Thanks in advance for comments!
- Thierry Moreau

@_date: 2015-10-02 20:46:20
@_author: Thierry Moreau 
@_subject: [Cryptography] Paper check security 
So you suggest a PKI. I.e. as a check / digital signatory, I expect every candidate depository financial institution to act as a relying party for my digital signature. Maybe a certification authority in between?
- Thierry Moreau

@_date: 2015-10-19 13:10:30
@_author: Thierry Moreau 
@_subject: [Cryptography] Other obvious issues being ignored? 
The recent realization that public key cryptosystems having common parameters (DH) may be vulnerable from the very fact that they rely on common parameters is puzzling to me.
In hindsight, the question would have been (highly) relevant ever since the practitioner had a choice between such cryptosystems and cryptosystems having entity-specific parameters (RSA, Rabin-Williams), the latter being vulnerable to flaws or trapdoors in the parameter generation implementation for each entity.
Moreover, the basic finding in the "Imperfect forward secrecy" publication ( was within the reach of skilled mathematicians ever since the number field sieve algorithm could be explained in a university classroom.
It's a shame that this old issue has been ignored until now!
What other "obvious" questions are we ignoring?
- Thierry Moreau

@_date: 2015-10-25 14:39:07
@_author: Thierry Moreau 
@_subject: [Cryptography] Known Hardware (was Other obvious issues being 
I tried to be in a position to know for the "Open source HSM" concept turned into the "evanescent security module" concept:
I bought a booksize X86 box: No hard disk, no internal flash disk.
I should have removed the wi-fi daughterboard.
I installed my own "Linux from scratch" with as little outside world driver support as possible on either USB flash disk or MicroSDHC bootable media.
I used the (recently introduced) Linux overlay file system such that the boot media is root file system but remains read-only (i.e. unavoidably writable directories such as /var/run are "overlay-ed" by RAM file system directories).
The boot process starts an HTTP server with a single dedicated application -- application-specific session with cookie-like session management limited to a single instance.
There are two flavors of applications: (equivalent to) create root CA private key pair and sign security certificates by root CA.
The application console is any browser connected to the RJ45 port on the Critical inputs are through a cheap bar code reader. Critical outputs are through a plain laser printer.
I would have preferred input and output with paper punch ribbon media but the local computer dealer did not carry those items when I started the project.
(Basically, the critical data is the root CA private key.)
What remains problematic:
Side channel attacks: I plan to do the work sessions in a remote fishing cabin in the northern forests, out of battery power. Air gap of a few kilometers from the nearest motor vehicle as we are completing the journey by row boat. Please leave your cell phones at home.
Leftover buffer data in the printer: purchase the printer unit with as little RAM memory as possible and have these RAM buffers stuffed with random page data after the work session.
How do I convince you that this fingernail size flash memory IC has the software which you had a chance to review before the work session (you obviously were given a copy of all relevant source code and build scripts plus a chance to procure a development box within a reasonable budget)? ... see below ...
Two Main lesson:
(A) Having a computer do a critical computation under strictly controlled conditions is possible these days with the scope of control being a complete application in the occasional key management work session context ...
... but ...
... as any IT controls, the scheme only shifts control from a comprehensive system (or set of data) towards a smaller component: a flash memory IC in demand of data integrity protection (or a master cryptographic key in demand of secrecy protection).
I vaguely envision that a workable solution would rest on multiple flash memory ICs compiled by different parties, ...
(B) The fun thing is that you don't need throughout software quality control. The critical computation is the only useful work done by the whole computer system. Hence if it works in the laboratory for some data set and the only software along the critical path of the critical computation is reviewed, you should get a proper assurance level.
- Thierry Moreau

@_date: 2015-10-25 15:01:59
@_author: Thierry Moreau 
@_subject: [Cryptography] Other obvious issues being ignored? 
May I suggest that this language is not ideal for having a feature request being handled with the best hope of client satisfaction.
As I understand it, a gcc release formally introduced an indefinite precision arithmetic library for the compile-time arithmetic computations. (Maybe a benefit is that CPU-architecture-independent optimizations would be easier to implement/validate/debug with this perfect integer arithmetic abstraction).
Your feature request would be compiler switches for compile-time integer arithmetic aligned with the target CPU under a few defined contexts (to be discussed between *polite* feature requestors and compiler writers).
Incidentally I have huge respect for the gcc developers as the most significant piece of software for the whole information society.
- Thierry

@_date: 2015-10-31 21:39:57
@_author: Thierry Moreau 
@_subject: [Cryptography] [FORGED] Re: How programming language design can 
Now I am teaching programming subtleties to Peter ...
This is a compile-time verification, a compile-time warning. It is obviously the case that compile-time "determinations" are limited, and a reasonable programmer would not expect a compile-time warning for a null pointer that can be "determined" only at run-time.
These potential optimizations would typically be *within* the function The avoided warning would be that the removed checks were optimized-away.
- Thierry

@_date: 2015-11-01 02:35:30
@_author: Thierry Moreau 
@_subject: [Cryptography] [FORGED] Re: How programming language design can 
I doubt the gcc data flow analysis phase is devoid of a warning issuance facility. But I expect the data flow analysis to be less than perfect in identifying conditions that would bring a NULL pointer to the function call.
Well, if you depend on a compiler for the potentially dramatic consequences of "inadvertently missed NULL pointers" (I assume it is the programmer who missed a NULL pointer condition in the software logic but you depend on the compiler to catch it), your development process might be questioned.
Ah! Indeed a mission-critical piece of software logic would hardly use a compiler switch that allows an explicit preventive programming provision to be optimized away without a trustworthy data flow analysis. Isn't this a basic precaution from the compiler *user*?
These words are yours. I find them counterproductive.
- Thierry

@_date: 2015-09-23 13:33:08
@_author: Thierry Moreau 
@_subject: [Cryptography] Curious about FIDO Alliance authentication scheme 
Here is a quick review of the FIDO alliance authentication proposal [1]. After looking superficially at the specifications documentation [2], I came to the tentative summary below. I did not feel a need to delve into the companion documentation set [3].
Core cryptographic principles:
(A) The scheme uses public key crypto signatures (PK signatures) without security certificates, for client authentication, in client-server (B) Each server entity (relying party) maintains its own database of public keys to account identity relationships.
(C) The scheme documentation suggests a unique PK signature key pair for each triplet .
(D) Account registration is devoid of special provisions for client identity verification: client device selects a PK signature key pair, signs a protocol-negotiation-derived context-dependent data stream and that's it.
Best practice security principles:
(E) The scheme documentation includes a taxonomy of mechanisms with which the client device may protect the activation of the device PK digital signature capability.
(F) In the account registration protocol exchanges, such client local mechanisms are negotiated.
(G) This arrangement is herein qualified as "best practice" because the server has no cryptographic integrity protection for client assertions in this account registration protocol exchange.
Scheme adoption strategy:
(H) The initial teaser is the appeal of an anti-phishing solution (alternative to password authentication).
(I) Levels the playing field for biometric/two-factor/tamper-processor authentication vendors.
(J) Not sure about browser support barrier to entry strategy.
Please use this summary with caution since it is very much of a guesstimate.
Two questions:
1) any comment about the above summary ...
2) assuming the authentication scheme turns widely deployed, what are the opportunities for the bad guys (those being creative, patient, and resourceful at attacking IT security schemes)? (Vulnerabilities in the client device are countless, dependent on local arrangements, and mostly well understood; it's the protocol vulnerabilities that would be relevant in view of the scheme novelty.)
Thanks in advance for feedback.
- Thierry
[1] [2]

@_date: 2016-04-06 12:05:41
@_author: Thierry Moreau 
@_subject: [Cryptography] At what point should people not use TLS? 
Those who study TLS when they are envisionning a new secure protocol based on public key cryptography, IMHO, completely miss the important lessons from the crypto science.
Below is an overview summary, excerpt from a draft document in preparation. Comments welcome.
- Thierry Moreau
Classical Authenticated Diffie-Hellman (D-H) Exchange
The original D-H cryptosystem publication [...] has been followed by the development of workable public key digital signatures and the concept of security certificates for automated trust decisions for a remote party public signature key. The authenticated D-H exchange combines these developments for the establishment of an authenticated shared session key between a local and remote party, with the authentication based solely on a trusted certification authority (CA) public key.
Here is the historic perspective. The industrial application of public key cryptography concepts for telecommunications were first envisioned for secure telephony, both as a US government controlled technology with the STU-III model ([1]) and as the then emerging ISDN technology (e.g. references 41 and 81 in [1]). Indeed, two detailed disclosures of the basic authenticated D-H exchange were made by researchers at two telephone equipment manufacturer research organisations, namely Bell Northern Research ([2]) and AT&T ([3]). The Bell Northern publication is known as the Station-to-Station (STS) protocol and is acknowledged as a source of inspiration for the later developments. Notably, this basic scheme was first standardized in the OSI network layer security protocol (NLSP, [4]) and transport layer security protocol (TLSP, [5]). These references are not to be confused with the reference [6] which is sometimes cited as an STS variant while actually making no use of the Diffie-Hellman cryptosystem. With the domination of Internet protocols over ISDN and OSI came the adoption of the SSL protocol that got IETF endorsement as the TLS protocol, without a connection to STS. The latter made a comeback in the IPSEC protocol suite as IKE and then IKE version 2 ([7]). It is in this form that the authenticated D-H exchange is present in modern networks, with security critical improvements explained in an essential article by Hugo Krawczyk ([8]). This state of the art gets a further endorsement in the Host Identity Protocol (HIP, [9]), a leading edge research proposal for secure Internet protocol.
However the seemingly endless IPSEC protocol standardization details obscure the essential characteristics of the authenticated D-H exchange, notably due to a dedication to interoperability in presence of many implementation options. A trend in the IPSEC options expansion is the adoption of optional authentication schemes other than public key cryptography digital signatures, e.g. Extensible Authentication Protocol (EAP). Also, the IKE protocol has provisions for cryptographic key management beyond the initial authenticated D-H exchange, notably for rekeying and establishment of parallel logical secure channels.
The relatively small usage of the genuine authenticated D-H exchange might be explained by the practical deployment challenge of digital signature key pairs for every communicating entities (client security certificates in the TLS jargon which puts the user mental model remote from the inner working of digital signatures). In this historical perspective, the authenticated D-H exchange would be the core of the lost art of classical public key cryptography. Indeed, one may notice the prudent recommendation in section 5.2 of the original STS publication ([2]) that anticipated to the very root cause of the Logjam major vulnerability in Internet security protocols uncovered in 2015 ([10]).
Another approach to justify the relevance of the authenticated D-H exchange is bottom up, starting from a naive desire to establish a scrambled communication channel between two parties on the Internet. By some iterative learning and creativity process, the pitfalls of an home brewed encryption scheme might be understood and fixed. That would start with a conventional symmetric cipher, then the addition of symmetric integrity protection and the naked Diffie-Hellman exchange for setting up a shared key (a rudimentary hybrid cryptosystem). The MITM vulnerability would come next, and so on until the full authenticated D-H exchange is considered an essential requirement for key establishment. In this process, the benefits of forward secrecy and desirability of traffic flow confidentiality would further disqualify alternative solutions. At the end would remain the authenticated D-H exchange for key establishment and a bulk secure communication scheme for the actual data transmission (any rekeying requirement is explicitly omitted and may be the subject of further study). In the IPSEC world, the latter is the Encapsulating Security Payload (ESP) protocol [11].
While standardization bodies adopted the reference [8] as a yardstick for authenticated and key agreement using public key cryptography, a little noticed alternate academic contribution attracted less attention: under the leadership of professor Lein Harn, the mutual authentication of a Diffie-Hellman shared secret is wholly achieved with discrete logarithm based cryptography, i.e. neither hash functions nor factoring based cryptography are needed. The seminal idea of a digital signature scheme specialized for Diffie-Hellman shared secrets is in the reference [12]. However, when applied to mutual authentication in a Diffie-Hellman exchange, an attack ruins the forward secrecy property. This was fixed in reference [13], and a more elaborate proposal came in reference [14]. This alternate research direction hints that the standardization solution may not be the last word in every aspects. It may also help the structured study of the diversified set of discrete log cryptosystems.
[1] Whitfield Diffie, "The First Ten Years of Public-Key Cryptography", invited paper, Proceedings of the IEEE, Vol. 76, No. 5, MAY 1988.
[2] Whitfield Diffie, Paul C. Van Oorschot, and Michael J. Wiener "Authentication and Authenticated Key Exchanges", in Designs, Codes and Cryptography, 2, 107-125 (1992) (received by editor Nov. 22, 1991 and revised Mar. 6, 1992).
[3] Steven M. Bellovin and Michael Merritt, "Cryptographic protocol for secure communications", United States Patent number 5,241,599, August 31, 1993, filed October 2, 1991.
[4] ITU-T Recommendation X.273 (1994) | ISO/IEC 11577:1995, "Information technology - Open Systems Interconnection - Network layer security protocol", available at [5] ITU-T Recommendation X.274 (1994) | ISO/IEC 10736:1995, "Information technology - Telecommunications and information exchange between systems - Transport layer security protocol", available at [6] ISO/IEC 9798-3:1993, "Entity authentication mechanisms -- Part 3: Entity authentication using asymmetric techniques".
[7] C. Kaufman, P. Hoffman, Y. Nir, P. Eronen, and T. Kivinen, "Internet Key Exchange Protocol Version 2 (IKEv2)", IETF RFC 7296, Internet Engineering Task Force (IETF), October 2014, available at [8] Hugo Krawczyk, "SIGMA: the 'SIGn-and-MAc' Approach to Authenticated Diffie-Hellman and its Use in the IKE Protocols", 2003, proceedings of Crypto'03 (LNCS Series, Vol. 2729), extended version available at [9] R. Moskowitz (editor), T. Heer, P. Jokela, and T. Henderson, "Host Identity Protocol Version 2 (HIPv2)", IETF RFC 7401, Internet Engineering Task Force (IETF), April 2015, available at [10] David Adrian, Karthikeyan Bhargavan, Zakir Durumeric, Pierrick Gaudry, Matthew Green, J. Alex Halderman, Nadia Heninger, Drew Springall, Emmanuel Thom'e, Luke Valenta, Benjamin VanderSloot, Eric Wustrow, Santiago Zanella-B'eguelin, and Paul Zimmermann, "Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice" in proceedings of 22nd ACM Conference on Computer and Communications Security, October, 2015, DOI:  also visit [11] S. Kent, "IP Encapsulating Security Payload (ESP)", IETF RFC 4303, Network Working Group, December 2005, available at [12] L. Harn, "Digital signature for Diffie-Hellman public keys without using a one-way function", Electron. Lett., vol. 33 (1997), no 2, pp [13] L. Harn and H.-Y. Lin, "Authenticated key agreement without using one-way hash functions", Electron. Lett., vol. 37 (2001), no. 10, pp [14] L. Harn, W.-J. Hsin, and M. Manish, "Authenticated Diffie-Hellman key agreement protocol using single cryptographic assumption", IEE Proceedings Communications, Vol. 152, No. 4, pp. 404-410, Aug 2005.
References 1, 2, 11, 12, 13, and 14 may be available in digital format through one's preferred search engine.
=== The End ===

@_date: 2016-04-13 09:06:28
@_author: Thierry Moreau 
@_subject: [Cryptography] [cryptography]  Show Crypto: prototype USB HSM 
=========================
Who wants to be optimistic with respect to threat models in the current IT landscape?
Do you?
(I much liked what I glimpsed from the original post.)
- Thierry Moreau

@_date: 2016-04-16 22:17:02
@_author: Thierry Moreau 
@_subject: [Cryptography] RCMP Had BlackBerry's Global Decryption Key 
In the years Reseach In Motion (RIM) marketed globally the Blackberry with end-to-end encryption with what looked like a sensible key management scheme, an export license would not (educated guess) be possible unless a back door is offered to "friends".
Thus, the exclusive is not so new (wholly to be expected).
In the same spirit, US gov executive has some RCMP friends.
Who can trust IT vendors?
There would be a KDC (key distribution center) public-private key pair, so the search would boil down to a factoring or discrete log challenge.

@_date: 2016-08-23 15:24:34
@_author: Thierry Moreau 
@_subject: [Cryptography] Real-world crypto/PRNG problem:  Bridge 
One random hand is a selection among 52! which is about 225 bits of entropy.
Repeat this 76,000 times and you get roughly 17 million bits.
Any single PRNG instance solution is going to trigger endless discussions among experts. The client organization/community (presumably) has little ability to select a good expert.
Thus, this would be a good sell for the so-called "quantum" random number generators (actually based on an arrangement of single photon I.e. without millions of truly random bits, a typical client community participant would have hard time to acknowledge that while e.g. 75,995 hands are deterministically dependent on the first 5, it does not matter. Computational independence is appealing to a significant portion of exerts, but not necessarily to a player/gamer.
- Thierry Moreau

@_date: 2016-08-23 20:51:44
@_author: Thierry Moreau 
@_subject: [Cryptography] Real-world crypto/PRNG problem:  Bridge 
(same post, revised numbers due to a combinatorial counting error)
Read a selection among 52!/(4*13!) and 95 bits bits of entropy.
Read 7 million bits.
Read 75,990 hands deterministically dependent on the first 10.

@_date: 2016-02-17 14:59:41
@_author: Thierry Moreau 
@_subject: [Cryptography] Hope Apple Fights This! 
Reading the Court order (posted on another thread) paragraph 2, the software functions (erase of user data upon password entry failures, time throttling of password entry attempts) that need to be customized for the forensic facilities are typically *not* implemented in a secure co-processor (or at least not implemented in a secure co-processor devoid of a flash re-programming capability).
Not that such an architecture is impossible: it is simply too antagonistic to product development culture to come up with a product where encrypted user data is irrevocably lost when an encryption key is - Thierry

@_date: 2016-02-19 02:55:34
@_author: Thierry Moreau 
@_subject: [Cryptography] [FORGED] Re:  Hope Apple Fights This! 
These types of attack are not preserving the smart card in its full integrity (destructive attacks). Forensic investigation has (at least in theory) to preserve the investigated system, such that investigators keep the initial evidence intact for further investigation and do not grant themselves any opportunity to plant a piece of evidence.
This raises an interesting question.
The Court order is written for a high quality forensic investigation tool. The evidence extracted from the device would be fully admissible in a trial with a competent defense lawyer.
"[the backdoor software] will not modify the iOS on the actual phone, the user data partition or system partition on the device's flash memory."
"evidence preservation shall remain the responsibility of law enforcement agents."
Do they (the FBI) actually need this for this particular phone?
Alternatively, they could be looking for missing clues in the investigation (possibly without a guarantee of admissibility in the trial) from which new investigation paths might be followed and/or additional evidence might be sought from other sources. In this case, they might be willing to rely on destructive attacks.
According to the Court order, they look for a high quality forensic tool. Period.
There are no Judge reasons why a destructive attack is not among the possibilities for a productive investigation. The reasons are limited to "For good cause shown."
- Thierry

@_date: 2016-02-28 02:57:39
@_author: Thierry Moreau 
@_subject: [Cryptography] From Nicaragua to Snowden - why no national 
The algorithms developed by academic contributions, often improved by academic contributions unrelated to the original work.
A good portion of public key cryptography algorithms would fall into this category (DSA / ECDSA being the most obvious counterexample).
For hash functions and symmetric encryption "Your mileage may vary" e.g. the set of ASHA and AES competitors may include algorithms sufficiently peer-reviewed with some independence from the right nation (who managed the competitions).
- Thierry

@_date: 2016-01-08 18:49:22
@_author: Thierry Moreau 
@_subject: [Cryptography] FTC sues for crappy crypto 
From the original post:
"security protections in compliance with HIPAA rules"
which would (indirectly?) mandate effective data protection (... whether this extends to proper key management procedures is another story ...).
The US health sector is governed by HIPAA for privacy of medical records. With the battle between lawyers and insurance companies (for clinicians error liability coverage) in the private-organization-centric US health care system, I would suspect the HIPAA rules are implemented with some dedication.
Again, HIPAA.
- Thierry

@_date: 2016-01-14 14:11:31
@_author: Thierry Moreau 
@_subject: [Cryptography] TRNG review: Arduino based TRNGs 
Once I had access to a silicon part claiming "random" when a wrong password was entered (I-Button secure memory). I ran the Berlekamp-Massey algorithm on it and I was half-surprised: one of two Berlekamp-Massey "signatures" would be detected by this method when the wrong password was entered. I did not consider this an "exploit" (please train yourself on fundamentals, not on anecdotal consequences).
The reference [5] section 3.2 hints at similar property from the fact that 32 bytes are output as a "combination" of two registers (boot-or-awakening nonce register plus "random" register) which are typically no larger than 8 bytes.
With a closer analysis, the datasheet claims 32 bytes random output, with no entropy estimate, but with a two-stage process: HW random number generation followed by "a combination" of HW random number plus "seed" (a nonce updated whenever the device internal RAM is reset, omitting the mode where the EEPROM lifetime preservation is preferred over the security level). The timing of commands to the silicon part hints that a random number draw (the two stages) takes about the same time as an SHA256 computation.
If the "a combination" is based on SHA rounds, then the discovery of statistical structure in the 32 bytes "random" output is unlikely. But the time budget for the HW random number generation would be very small for a reliable HW random circuit.
Furthermore, even with a perfect implementation of the "random" register, the reliable entropy is no larger than the size of the "random" register (and not specified in the datasheet).
It seems that the threat model for this silicon part is DRM / "Trusted computing" where a global (e.g. at the granularity of a consumer electronics model) secret is controlled by a digital product vendor.
The use of this part for defending the individual user against Trojan Horse threats in a personal device appears more problematic (password entry still done through the attacked system keyboard).
Overall, this datasheet is yet another instance where security support silicon offering appears unsatisfactory. Given that the HW random number generation principles are unspecified and no entropy estimate given, it might be unsatisfactory even for the presumed threat model.
- Thierry

@_date: 2016-01-20 16:30:32
@_author: Thierry Moreau 
@_subject: [Cryptography] TRNG related review: rngd and /dev/random 
Those who maintain the Linux kernel are not in a position to *require* either health monitors or good entropy estimators. The inclusion of an entropy source in a system is a decision that may be made even after the Linux distribution packaging.
Maybe you failed to fulfill the Linux distribution requirement for both health monitor and entropy estimator (pun intended). You may be confident in the OneRNG but how the Linux distribution specialists might be convinced?
I guess the process of trusted secret random source provisioning may not be delegated to O/S team.
- Thierry

@_date: 2016-01-27 02:23:19
@_author: Thierry Moreau 
@_subject: [Cryptography] Anyone have information on Export 1024 RSA? 
Ray Dillinger replied with relevant considerations.
There is a lot of speculation needed in this subject area.
When I search for academic publications on the RSA modulus size recommendations, I prefer to rely first on the authors who consider only published factorization efforts and results. Speculation comes after.
There was a talk by Dan Bernstein a few years ago title something like "RSA modulus factorization beyond 1024 bits." He started with the statement "anybody can do 1024 bits modulus as of now" (the audience was not educated enough for a challenge to this, I guess; I was shy to ask background info because I was admitted un-officially). Then he explained the factorization method and explained that full exploitation of the GPU architecture was the next step. I don't know if Dan Bernstein qualify as an "author who consider only published factorization efforts and results."
In the related subject of ECC curve size, the academic publication introducing curve448 ("Ed448-Goldilocks, a new elliptic curve" by Mike Hamburg,  ) has a neat explanation about "overkill" security parameters for asymmetric crypto (where non-overkill is 128 bits symmetric key security equivalency).
So, I guess another way to ask the question is:
"What RSA modulus size is equivalent to 128 bits security?"
Now, I take the liberty to speculate:
The RSA modulus size equivalent to 128 bits symmetric key security is in the range 1280 to 1536 bits.
The NSA would like the switch from RSA to ECC to occur sooner than later.
In (having NIST) advocating RSA 2048 bits modulus, the NSA gains: the performance advantage in favor of ECC is increased, and the switch away from RSA comes earlier.
(as I write this, I realize that I do not even convince myself)
Also, the NSA wishes the crypto community to waste brain resource on post-quantum crypto instead of fixing more mundane weaknesses in deployed algorithms.
Enough speculation ... bye!
- Thierry

@_date: 2016-07-07 14:09:29
@_author: Thierry Moreau 
@_subject: [Cryptography] What to put in a new cryptography course 
To some extent, you just provided a bit of evidence:
If the ECC complexity may hardly be understood by ordinary computer security specialists, then its security rests mainly in the reputation of more expert minds. Security by reliance on someone else expertise ... the danger is when such reliance is recursive to a more or less well identified small group of experts.
More worrisome for the original post question, if/when you teach that ECC is a trend to follow, you might imprint this behavior of reliance on someone more expert for the security system principles.
- Thierry

@_date: 2016-07-11 22:38:44
@_author: Thierry Moreau 
@_subject: [Cryptography] State of sin (was Re: What to put in a new 
Ah ah! You might need a different example, or a different explanation:
A prudent recommendation in section 5.2 of the original Station-To-Station Protocol publication ([1]) anticipated to the very root cause of the Logjam major vulnerability.
[1] Whitfield Diffie, Paul C. Van Oorschot, and Michael J. Wiener "Authentication and Authenticated Key Exchanges", in Designs, Codes and Cryptography, 2, 107-125 (1992) (received by editor Nov. 22, 1991 and revised Mar. 6, 1992), available as Appendix B to US patent 5,724,425.
Hence the "realization" was not new.
Maybe the cryptographic community has to listen more carefully to these theoretical contributions that are being relied upon in deployed crypto - Thierry

@_date: 2016-06-28 21:25:21
@_author: Thierry Moreau 
@_subject: [Cryptography] Phishing Attacks - Alice, HAL and Bob 
Do I need to apologize for being a little bit rude? After all, you seem to insist.
Unrealistic assumptions about elements on which a practical solution may be based:
"The final solution proposed is a mixed strategy of
(1) a user-browser shared secret to facilitate extending TLS, for Alice to authenticate Bob,
(2) standardisation of the login process via a browser created login window,
(3) using central banks as Trent for financial institutions and
(4) utilisation of common knowledge and education to guide Alice through the process i.e. to prevent phishing attacks Alice must fulfil her role and authenticate Bob."
No need to read any further for me.
- Thierry

@_date: 2016-03-03 03:37:05
@_author: Thierry Moreau 
@_subject: [Cryptography] A question on Shannon's entropy 
Wrong application of Shannon lessons.
An entropy measure is tied to a data source that can emit codes without a size limit for the output.
In your question A and B are not data sources. If they were to be equated to a data source, the respective codes would have to be defined, e.g. as "alphabetic sequences of length-of-A" for A, and then sorting a sample from A creates a very different data source.
Said otherwise, the Shanon entropy of a sequence makes no sense. You must make assumptions of the data source behind the sequence and analyze the data source itself with the Shanon lessons.
- Thierry
  One could eventually employ pairs

@_date: 2016-03-10 14:06:28
@_author: Thierry Moreau 
@_subject: [Cryptography] Help with Raspberry Pi IoT initialization... 
If you take the personal SD boot card from a personal drawer, why do you want a signature verification in the first place?

@_date: 2016-03-19 18:23:32
@_author: Thierry Moreau 
@_subject: [Cryptography] Christophe Petit on ECDLP future advances 
For those having both the mathematical skills and a chance to be in Paris on March 30, here is an opportunity for learning some recent trends in ECDLP (elliptic curve discrete logarithm problem).
See also Professor Petit academic web page:
- Thierry Moreau
(message forwarded from another list)
Bonjour  tous,
J'ai le plaisir de vous annoncer que l'quipe Almasty (ALgorithms, MAths and SecuriTY) du LIP6 accueillera :
           Christophe PETIT (University of Oxford)
               le mercredi 30 mars  17 heures
    en salle 24-25-405, UPMC, 4 place Jussieu, 75005 PARIS
        (montez par la tour 24 jusqu'au 4me tage et
         prenez le couloir qui mne  la rotonde 25)
                         TITRE :
Recent advances in Elliptic Curve Discrete Logarithm algorithms
RESUME : The elliptic curve discrete logarithm problem (ECDLP) is one of the core number theory problems used in cryptography today, for example in TLS protocol. The elliptic curve discrete logarithm problem is believed to be much harder than the discrete logarithm problem over finite fields and the factorization problem, as the best attacks for commonly used parameters are still generic DLP algorithms. As key sizes in applications are chosen accordingly, it is important to understand the exact hardness of ECDLP.
In this talk, I will review recent advances in solving this problem using index calculus algorithms, starting from the work of Semaev in 2004. As it happens, we now have subexponential (in L(2/3) time) algorithms for special families of parameters, but these parameters are however not really used in practice. I will then show how these algorithms can potentially be adapted to elliptic curves defined over binary fields of prime degree extensions and to elliptic curve defined over prime fields (the two families that appear in standards and applications), and I will describe remaining challenges in improving both their complexity and their analysis.

@_date: 2016-03-21 23:47:11
@_author: Thierry Moreau 
@_subject: [Cryptography] [cryptography] USG moves to vacate hearing 
If the USG preferred no ruling on the arguments presented, they would not behave differently.
If the FBI needed a good forensic tool created for them more than they need the data on this specific iPhone (as I initially guessed), the risk of a bad ruling for them would be a major step back in their creative procurement of forensic tools. Hence the USG would prefer no ruling.
- Thierry Moreau

@_date: 2016-03-25 15:48:43
@_author: Thierry Moreau 
@_subject: [Cryptography] On the Impending Crypto Monoculture 
Nice essay.
One general comment and a few specific observations.
Once upon a time, IPv4 needed an upgrade (address space limitation made it brittle) and 128 bit addresses were seen as a silver bullet ...
As one commentator hinted, replacing the low-level primitives does not achieve a great deal towards failure-resilient mechanisms and failure-resilient implementations.
With regards to mechanisms, I long wondered why the classical authenticated D-H exchange has been ignored in the TLS design (I still wonder somehow after I reviewed the question recently). IPSEC and Host Identity Protocol (HIP) have it (buried in a pile of standardization details). The core lessons are here:
Hugo Krawczyk, "SIGMA: the 'SIGn-and-MAc' Approach to Authenticated Diffie-Hellman and its Use in the IKE Protocols", 2003, proceedings of Crypto'03 (LNCS Series, Vol. 2729), extended version available at What is the basic scheme envisioned for authenticated key establishment in the new crypto monoculture?
Implementations are a few machine instructions away from a catastrophic failure in many ways, in any scheme. Implementers must be ready. Is the counter mode pitfall really special in this respect?
Plus any data integrity (including authentication) protection is one machine instruction away from ignoring a negative validation result.
I guess every theoretical weakness has seen actual security incidents in which it was a root cause.
- Thierry

@_date: 2016-05-28 19:26:00
@_author: Thierry Moreau 
@_subject: [Cryptography] Anybody sorted out the MQV patent claims? 
While looking at discrete logarithm signatures in relation with Diffie-Hellman key establishment, I (re-)discovered a whole facet of public key cryptography.
Certicom is aggressive in asserting intellectual property rights in this In a 2005 letter to a standardization body, Certicom indicated four US patents as pertaining to the MQV protocol (two "continuation in part") and one european patent.
US 5,896,455 --> US 5,761,305
US 6,785,813 --> US 6,122,736 (EP 0 739 105)
In all of these, the independent claims include the limitation that each party computes a digital signature value separate from the ephemeral D-H shared secret.
However, the MTI (ref [47] in [0]) protocol (the seminal idea for MQV, HMQV, and OAKE [0] as well) precisely *avoids* such a signature value (and thus avoids the DSA-type vulnerability to ephemeral private random number leakage -- neat achievement).
Thus, I see the above four patents as claiming something other than MQV. Anybody ever sorted this out?
The question pertains to patents that appears either expired (in first-to-file jurisdictions) or about to expire (in first-to-invent jurisdiction). I ask because the technical issues at stake appear relatively simple: compare figure 2 in US 6,122,736 and/or claim 1 in EP 0 739 105 with the basic MQV operating principle.
- Thierry Moreau
[0] Andrew C. Yao and Yunlei Zhao, "A New Family of Implicitly Authenticated Diffie-Hellman Protocols", Cryptology ePrint Archive: Report 2011/035,

@_date: 2016-11-15 02:26:52
@_author: Thierry Moreau 
@_subject: [Cryptography] On the deployment of client-side certs 
This is a multi-million dollar question: a workable answer might signal a serious alternative to password-based authentication.
Some historic perspective.
The privacy question was raised early: the client certificate was to hold the user identity and sent in the clear with SSL.
Client certificate costs were intended to fund certification authorities, i.e. entities collecting feed and avoiding liability by all means. No financial institution would trust such a third party.
Also, in these days where suspicion about state surveillance agenda is fashionable, I might argue that SSL lack of privacy was a bargain considering that OSI Network Layer Security Protocol had built-in certificate encryption (for the technical side of this -- pointless -- arguing, see  ).
The user mental model (even before the user interface issue is addressed) is very difficult. The authentication capability lies in the PRIVATE COUNTERPART of the public key found in the certificate, and the certificate itself is at once public and privacy-threatening. I note that your post makes no reference to the very security basis (again the PRIVATE key). Try to explain that you might get certified for a PRIVATE key that your device generated, or be provided a PRIVATE key along with a certificate, or renew a certificate with either the same or a fresh PRIVATE key, or ...
Instead of self-signed, I prefer auto-issued (see  ) because it facilitates the server side configuration.
Make certificates totally meaningless except as a carrier format (SSL compliance concern, period) for the public key matching the PRIVATE key.
I am not too familiar with pinning concept (does it apply at all to the client side?). I prefer first party certification where any service provider maintains its own database of trusted public keys (along with the bank account number, hospital patient file index, or whatever socio-legal convention for entity name applies).
I have a scheme for user enrollment with this first party certification concept, but that's may not be applicable as a mass market solution since the other aspects are unresolved.
Anyway in this view the user cares about the PRIVATE key, finds ways to carry it between devices (admittedly easier said than done), and self-issues certificates at will.
The educational challenge is enormous since almost every security expert has been trained (more or less implicitly) to relegate the PRIVATE key protection issue as a minor system configuration management duty (to be isolated from the user mental model). How many security experts ever tried to explain (e.g. to a computer-literate user audience) the very foundational principle of public key digital signatures?
-Thierry Moreau

@_date: 2016-11-15 14:46:07
@_author: Thierry Moreau 
@_subject: [Cryptography] On the deployment of client-side certs 
Hardware tokens are indeed an important aspect in the longer explanation.
Historically, two-factor authentication solutions has been presented as universal in theory, but marketed as a highly branded solution. The corporate treasury management services of each bank would have its own flavor of essentially the same concept. Switching to mass market, the desirable unifying operator (now Google by default?) is yet to emerge.
- Thierry Moreau

@_date: 2016-11-15 19:25:32
@_author: Thierry Moreau 
@_subject: [Cryptography] On the deployment of client-side certs 
About identity information leakage, the first SRP message sent from the client to the server includes plaintext identity, isn't it?
About password being stored on an hardware token, then the SRP password secret turns into a long term discrete logarithm private authentication key. With this understanding, SRP enrollment with a server becomes equivalent to registering a unique public key for each server.
I do not know which exact scheme is easier and more efficient. Nonetheless, SRP with user-remembered password spares "secure mechanism to hold a private key" but requires a "secure mechanism to apply a private key." If you afford a secure hardware token, the SRP main benefit appears less relevant.
- Thierry Moreau

@_date: 2016-11-15 23:15:21
@_author: Thierry Moreau 
@_subject: [Cryptography] On the deployment of client-side certs 
As an aside piece of information on the adoption of two-factor authentication, the US federal government has been the largest client organization with the NIST PIV program and recently had to revert to client device software-based solution for private key management. The rationale is to remain compatible with the newer mobile devices.
See NIST Special Publication 800-157, "Guidelines for Derived Personal Identity Verification (PIV) Credentials"
- Thierry Moreau

@_date: 2016-11-17 21:11:07
@_author: Thierry Moreau 
@_subject: [Cryptography] On the deployment of client-side certs 
OK, this is a reasonable problem statement. However ...
My bet is that is is impossible to come up with a sound API design (between the secure chip and the hostile general-purpose digital computing environment). Basically, if the secure chip provides a service to a legitimate application and refrain from doing so for something else, the secure chip needs another secure scheme for deciding which application is legitimate.
- Thierry Moreau

@_date: 2016-10-01 20:04:30
@_author: Thierry Moreau 
@_subject: [Cryptography] Use Linux for its security 
Indeed, for any seriously security-minded web-enabled application.
Client-side logic is incompatible with a self-defense strategy for an http server application.
Even en HTML 4.1 "disabled" user interface element must not be trusted as preventing the disabled user action from occurring.
Even then, the user might be mislead by the display logic being intrinsically client-side dependent.
A secure system equates with a features-lean one. Period.
The Linux kernel may be configured with only the required device drivers and file system support (e.g. no NTFS support for USB flash devices).
- Thierry Moreau

@_date: 2016-09-06 15:43:06
@_author: Thierry Moreau 
@_subject: [Cryptography] Why TLS? Why not modern authenticated D-H exchange? 
Dear applied cryptographers ...
The STS protocol (Station-To-Station) evolved into Hugo Krawczyk SIGMA (Sign-and-MAC) variant which is now found in IPSEC IKE and HIP (Host Identity Protocol, IETF RFC7401).
However, if one wants to consider this as an alternative to TLS, documentation sources are few and either too academic or too overloaded with protocol details detracting from the security properties.
I did face this situation while looking for a basic authenticated key establishment protocol. STS has been the very first secure protocol to which I was exposed decades ago, but recently I could not recognize its features/properties in any TLS deployment profile. So I researched the STS impact on modern protocols and I recorded my findings in this document:
"The Classical Authenticated Diffie-Hellman Exchange Revisited (with the Bladderwort Protocol Feature Addition)"
When a secure data communications channel between two distant server systems must be established, the TLS (Transport Layer Security) is the solution that comes first to the mind of IT security experts. Departing from this default common wisdom, we revisit the authenticated Diffie-Hellman exchange as a solution well rooted in the early ideas in the field of public key cryptography, refined by the dedication of theoreticians, and entrenched in a few (less conspicuous) Internet secure protocol standards, namely IPSEC IKE and HIP. Under the name Bladdarwort, we also propose a minor protocol addition for streamlined server operations where a long-term private signature key is better kept off-line during the operational phase of the secure communications channel.
I guess the end result holds important lessons, as a straightforward solution path for a basic and recurring issue in IT security. Yet, the difficult aspects of applied cryptography remain difficult, the document being explicit about them.
Thus, why TLS?
- Thierry Moreau

@_date: 2016-09-15 19:34:29
@_author: Thierry Moreau 
@_subject: [Cryptography] True RNG: elementary particle noise sensed with 
A true random number generation strategy is no better than its trustworthiness. Here is a suggestion for a simple scheme which rests on a common digital electronic design.
While helping an undergrad student in a weight scale project, I encountered an A-to-D conversion circuit datasheet where some fundamental noise was explicitly quantified.
After a little research, I learned that a foremost unavoidable noise source is resistor "current noise" (i.e. occurring due to an elementary physics phenomenon):
Thick-film resistors are made of a mixture of conductive particles (metallic grains) with a glassy binder and an organic fluid. This ink is printed on a ceramic substrate and heated in an oven. During this firing process the conductive particles within the glassy matrix are fused to the substrate and form the resistor.
[All types of resistors] have in common that the total noise can be divided into thermal noise and excess noise. Excess current noise is the bunching and releasing of electrons associated with current flow, e.g. due to fluctuating conductivity based on imperfect contacts within the resistive material. The amount of current-noise depends largely on the resistor technology employed.
[T]hick film resistors show large excess noise.
Source: Frank Seifert, "Resistor Current Noise Measurements," April 14, 2009
The classical weight scale design is based on an 24 bits A-to-D (analog to digital) conversion with the sensing circuit made of a wheatstone bridge (a simple resistor network arrangement) that amplifies minute variations in individual resistor voltage caused by strain gauge deformation (a small directional stress on a strain gauge induce a change in resistor value). The basic idea of turning this classical design into a true noise sensing application is this one: replace the (minutely) variable resistor by a fixed resistor with a high noise level.
The surprisingly simple electronics is illustrated by two A-to-D integrated circuits (Avia Semiconductor HX711 and Texas Instrument ADS1232) and the open hardware design for a weight scale microprocessor board (SparkFun OpenScale).
Obviously the evil is in the details, and some refinements are desirable since a) the noise sensing application is better served with a larger signal amplification, and b) the confidence in the noise sampling approach is (presumably) raised if noise sources other than current noise are reduced with appropriate circuit design techniques. But none of this is rocket science (e.g. compared with other elementary physics noise sampling such as so-called quantum noise generators).
Unavoidable current noise source:
  - thermal noise
  - excess current noise caused by the above resistor material construction
Noise sources to be reduced (as a matter of sampling approach coherency)
  - electrostatic ...
  - electromagnetic ...
Any thoughts?
- Thierry Moreau

@_date: 2016-09-16 13:55:04
@_author: Thierry Moreau 
@_subject: [Cryptography] True RNG: elementary particle noise sensed with 
I don't understand this last sentence. Valuable to who?
A device that start very simple (e.g. resistor current noise) turns not so simple when design details are turned into attack vectors in the discussion. In practice, which type of device is promising in the above Easier said than done. Such a specification document would need a definition of "random" ...
That *is* the strategy in my original post. In here, "random" means the 24 bits samples extracted from the analog-to-digital conversion circuit with whatever randomness is present. The wire-level protocol is a USB serial port emulation from which the host simply reads data. Alternately, the digital I/O pins could be directly connected to the PC parallel port, but that is not fashionable these days (hence not "running any code" is not achievable in practice).
A problem I found when attempting to reduce the system integrity (visual or whatever) inspection property is the following one: once the system integrity finally rests on a very simple and small system component (e.g. the device you suggest), the inspection either turns into an act of faith, or requires sophisticated tools (not very practical). Indeed someone pointed at the attack vector of a high quality noise-free resistor hidden in the package of a cheap noisy resistor.
Here you are asking for interoperability between HW and SW based on a specification. The definition of "random" (now "unpredictable bits") is challenging: beyond the O/S device driver, there is a randomness extractor software component that depends on statistical distribution hypotheses that the "simple device" would need to match.
Again, the HW / SW interoperability dream.
May I stress the main point in my original post: the resistor "current noise" would be a good source of true randomness when sampled by the same electronics as in a digital weight scale. Details can be worked out given that a 24 bits analog to digital conversion appears as the typical essential component.
   - Thierry Moreau

@_date: 2016-09-17 17:02:47
@_author: Thierry Moreau 
@_subject: [Cryptography] True RNG: elementary particle noise sensed with 
Yes, indeed for the unpredictability property. But forward secrecy is enhanced by periodic or occasional re-seeding. Otherwise, the seed or the current CPRNG state turns into a long-term secret. Looking at the overall system security, one must assume that some other long-term secrets will be present, especially for authentication purposes.
So, periodic or occasional reseeding is a desirable feature, but not a   - Thierry Moreau

@_date: 2016-09-17 17:03:18
@_author: Thierry Moreau 
@_subject: [Cryptography] True RNG: elementary particle noise sensed with 
A definition of randomness is needed in the discipline of mathematics if some theoretical arguments about randomness extractors is part of the justification for trust in the whole scheme.
As hinted below, you seem satisfied with the /dev/random implemetation (or its equivalent in other O/S'es). Then I appreciate that you are not in demand of such theoretical support. Other critics-would-be-adopters may have a different attitude.
The more demanding expectations may not be fulfilled by hardware alone.
Point well taken. However, I found that USB is ever becoming harder to avoid: BIOS boot from USB media, USB mouse and keyboards, ... As a self-defense strategy, I do compile the Linux kernel with selected USB device support.
There are three sections in this schematics:
- The wheatstone bridge (a resistor network with a regulated DC source)
- The analog-to-digital conversion step (with an operational amplifier stage before the actual digitization)
- The very simple logic for interfacing to the host, supporting the protocol (actually RS232 serial transmit only, or a functional equivalent).
The first part I should release soon, as a simple service to the crypto The second part is the Texas Instrument ADS1232 integrated circuit, or The last point does require some logic which can hardly be implemented by discrete TTL gates these days (did you ear that CMOS has been invented not too long ago?). The hardware designer would go for a CPLD implementation and the software actor would go for an 8-bit My I introduce you to Sebastian, who somehow cares about philosopher (mathematics has been a branch of philosophy) ...
I offered Sebastian a self-contained digital device with a simple serial port outputting unpredictable bits, totally incompressible. The device implements a CPRNG with a fixed seed, stored in EEPROM memory when the device is manufactured (the vendor would not reveal the seal except as ordered by a legal subpoena). When Sebastian listened to my explanation, he started to worry about a definition of randomness.
I would add that once the wheatstone resistor bridge schematic is accepted as a reliable way to sense resistor current noise as a controlled "physics experiment," it should be reasonable to assess some entropy quantification which might then allow a link to entropy extractor theoretical work.
- Thierry Moreau

@_date: 2017-04-12 12:04:31
@_author: Thierry Moreau 
@_subject: [Cryptography] Key escrow scheme 
This looks like an "N out of M plus one" (more or less) instead of the nominal "N out of M". We have (as relying parties) such a little-touted "plus one" with the DNSSEC root KSK recovery scheme (the "plus one" agent being IANA holding an HSM encrypted configuration blob as part of their regular operational backups).
About this last sentence: I think the most obvious N out of M scheme deployment is the RSA private key encrypted in AES 256 with the resulting ciphertext given to each of the M key recovery agents (along with their respective secret sharing share).
One important reminder about secret sharing: nice concept in theory, which totally breaks if an individual recovery agent understands its role in isolation: the key share is believed to deserve no out-of-routine confidentiality protection since it is analogue to a key management ciphertext. (In FIPS 140-2, an encrypted secret present in a key management scheme falls out of certification scope.) The role in isolation merely suggests to report a "failure" in case of key share loss (while a suspected key share breach may result in the overall scheme failure).
In other words, if I was the enemy of a deployed scheme, I would -- assisted by social engineering -- provide backup services to recovery agents (please avoid a key share loss by all means) ...
(I was actually served an argument based on the individual agent role perspective while criticizing some aspect of the DNSSEC root KSK recovery scheme -- then I just gave up any educational attempt in these matters, I was not the "expert" telling what the audience wanted to listen.)
Have fun!
- Thierry

@_date: 2017-08-07 18:39:03
@_author: Thierry Moreau 
@_subject: [Cryptography] Finding undocumented opcodes 
This is a speedup instruction for the Berlekamp-Massey algorithm that recovers the parameters and state of LFSR-based ciphers, which were present in the military crypto "culture" (hearsay). This instruction is present in a high end DSP architecture that I reviewed for RSA acceleration suitability.
- Thierry

@_date: 2017-12-13 20:19:17
@_author: Thierry Moreau 
@_subject: [Cryptography] Bitcoin theft and the future of cryptocurrencies 
FYI, Canada LVTS (Large Value Transfer System) is a system where payments are "immediately final and irrevocable."
A procedural protection is to precede a large payment with one of say 14.87 $ to the intended recipient (with an off-line confirmation) before the large payment is made. Sophisticated cryptography is not always needed.
Bitcoin does not qualify as a currency, its volatility disqualifies it (if nothing else, e.g. scalability).
- Thierry

@_date: 2017-02-16 14:52:59
@_author: Thierry Moreau 
@_subject: [Cryptography] So please tell me. Why is my solution wrong? 
I wonder to which extent the "open" qualification actually applies (IPR encumbrance, completeness of the specification, mandatory consortium membership fees, ...).
Is "open spec" meaning no-fee download from Google-controlled appstore? (I am not knowledgeable of mobile app development environment, but the last time I checked, the basic required hardware was hard to procure without developer licenses with too much -- seemingly -- innocuous All these services are controlled by remote entities. To some readers of this list, those remain difficult to trust, and perhaps plainly obscure.
Maybe it's available with some leap of faith in security techniques implemented by those remote entities. However, trust backed by a reasonable security review appears totally out of reach.
- Thierry

@_date: 2017-01-06 16:09:43
@_author: Thierry Moreau 
@_subject: [Cryptography] Internet of things - can we secure it by going 
see below
Actually, the embedded web server does not *parse* HTML, except for HTML 4.1 forms. HTML *generation* is much more simple.
This is what I aimed at when I tailored a Linux distribution using a diskless booksize PC as an "open source HSM"
- booting directly into a single embedded web server application with an application-specific "script", and a single HTTP/HTML session capability.
- the "console" is then any HTTP client that happened to grab the single session at boot time -- no need for HTTPS
- (since it is an HSM application) any critical input comes from a bar code reader, and this includes the SHA-256 fingerprint for the script variant to be run, it also includes a decryption key for file upload when confidentiality is at stake (e.g. in a closed auction decision machine) or the SHA-256 fingerprint (e.g. if the HSM signs certificates for a central certification authority)
- conversely, any critical output is assisted with a printer for bar code pages (the HSM is evanescent) (e.g. a certificate signed in advance of its validity period is encrypted before being downloaded from the embedded server and the encryption key is printed as a bar code to be distributed to whoever controls the certificate release -- used in my designs as an obituary/revocation certificate that may be released even if the certification authority private key is lost)
Basically, what has to be audited is critical input and output channels There are remaining challenges, some mainly requesting time/effort.
The more significant remaining challenge is that the whole application logic now lies on a tiny memory device (read-only boot media); thus how do you and I agree about the software integrity.
That's for an HSM. A simpler IoT application might have some characteristics, but not all of them.
For performance warranty, the remote firmware upgrade is almost unavoidable. The problem is the recurring operational mishaps (or engineering flaws) with firmware integrity protection. Getting our customers to improve their internal processes is seldom possible.
- Thierry Moreau

@_date: 2017-01-29 16:02:38
@_author: Thierry Moreau 
@_subject: [Cryptography] HSM's to be required for Code Signing 
This (or the mere count of digital signature operations performed during an HSM session, reported in a trustworthy way) is actually missing from the most readily documented HSM deployment project, the DNSSEC root KSK signature ceremonies held by IANA on a regular basis.
The evil is in the details! Believe me, or look at
- Thierry

@_date: 2017-01-30 15:17:02
@_author: Thierry Moreau 
@_subject: [Cryptography] HSM's to be required for Code 
The threat model is good question, and I have no answer to share.
I used the ICANN/Verisign/NIST determination to make a globally trusted HSM deployment as a study case for cryptographic controls implemented transparently and "to the highest standards."
(The transparency aspect is more readily present if one refers to the process design documents pre-dating the first ceremony.)
The defense potential is as follows. The KSK signing ceremony outputs a known number of ZSK-certification digital signatures. If the bad guys are controlling the laptop during a legitimate ceremony, they might harvest a few extra signatures from the HSM (i.e. certifying their own ZSK public key for which they control the private counterpart). If the HSM reported the number of signatures actually performed on its own display, it would allow a ceremony witness to confirm that the HSM did not do this service to the bad guys.
As a matter of fact, no.

@_date: 2017-07-13 11:10:55
@_author: Thierry Moreau 
@_subject: [Cryptography] [FORGED] Attackers will always win, 
Ah! A constructive post from and by Peter. The problem with this model is that the integrity of the loaded algorithm implementation (and the loading media) is very hard to support by sufficient evidence.
You then need a trusted compiler engine to create the loading media. And you start all over again. Crypto only shifts controls ...
- Thierry

@_date: 2017-07-27 14:52:08
@_author: Thierry Moreau 
@_subject: [Cryptography] Anyone interested in a cheap security module for 
This looks like a centrally controlled set of digital devices. Reminds me of "trusted computing". The proposed variant is that an external HSM does what the TPM (trusted platform module) is expected to do inside the The API between hosts and either TPM or your intended HSM is deemed to be quite challenging.
Sorry, I doubt this threat model is going to attract much interest from the crypto community.
In any event, the use of highly integrated microprocessor systems for security opens new opportunities and the SC4-HSM is a foremost example.
- Thierry

@_date: 2017-06-05 15:11:05
@_author: Thierry Moreau 
@_subject: [Cryptography] Distributed Ledger Technology gets a high level 
Fascinating read this morning:
This reports the findings of a DLT trial for the financial sector. Definitely geared towards wholesale payment systems (a world with its own culture), it nonetheless presents a well-informed assessment of DLT deployment challenges.
In my opinion, the main conclusion (DLT may not replace centralized wholesale payment operators) was to be expected since the reference used for comparison (i.e. Canada LVTS) is among the most advanced system.
Secondary conclusions are less damaging to the Distributed Ledger Technology deployment potential.
- Thierry Moreau

@_date: 2017-06-20 03:24:23
@_author: Thierry Moreau 
@_subject: [Cryptography] Brainstorming for encrypted text messaging 
I actually created a set of six cubic dice for random password generation (an alphabet of 72 characters) plus a one-time pad, with instructions and work sheets for modulo 72 arithmetic.
It can be used for password generation and storage as dual components.
Dual component storage should use money bags (a currency handling accessory) sealed with seal serial number control for data integrity. (Tamper evident bags may do the job as well, but an NSA employee patent application explains that cryognenic techniques are effective to surreptitiously defeat the tamper-evident glue on most envelope models.)
The password dice set works but it is very cumbersome. It effectively shows how unrealistic it is to expect users to manage passwords securely when a different password is recommended for each application or service. (It also shows the one-time pad.)
So, my recommendation is to implement client-side private signature keys and have fewer passwords to back up.
- Thierry

@_date: 2017-03-10 21:44:39
@_author: Thierry Moreau 
@_subject: [Cryptography] Crypto best practices 
No insight from my part, just a guess.
NSA has to maintain some advance in protocol vulnerability exploits (over academia) and the protocol negotiation downgrade in active (MITM) attacks is certainly among their main sources of inspiration.
(NSA role is to prepare for the crypto warfare in WWIII ...)
What the above CIA document says is that NSA would indeed have had some advance over academia when the document was prepared, in at least one standardized connection re-keying sub-protocol.
However, the wording does not apply to Diffie-Hellman as such (basically *the* mechanism that supports forward secrecy) since D-H is used in the initial key exchange (that NSA knows discrete log algorithms in advance of academia is a separate question).
- Thierry

@_date: 2017-03-13 18:49:31
@_author: Thierry Moreau 
@_subject: [Cryptography] USB firewall/condom HW/SW 
This paper dates 1984 ...
Well, one might read it the reverse in these days where programmable bugs are present everywhere (e.g. try to buy a system board without a microphone and network interface microcontroller off-loading the CPU).
So, devices reduced to a single microprocessor implementing an elementary security function has a greater potential to be trusted merely because it has been programmed by fewer developers.
I did not look at the specifics here. However from the stated mandate, it seems to fall in the category I just described.
- Thierry Moreau

@_date: 2017-03-25 13:48:37
@_author: Thierry Moreau 
@_subject: [Cryptography] Google distrusts Symantec for mis-issuing  30, 
The PKC (public key crypto) security certificate technology was never taught with any sensible user mental model.
If it had been, there would be a trust anchor editor in our systems and you and I, even only as expert users, would be inclined to add and remove entries. Furthermore, the edited trust anchor set would be applied to new browser installations (as a typical recommended installation step), and carried to a new laptop, just like our contact list.
Delegation of trust anchor set management to some user-selected entity would likely be prevalent (e.g. employer organization, ISP, ...) but the trust anchor editor tools used by the management entity would remain available if the user revokes the delegation.
In the times when this should have been put in place, the fashionable issues (e.g. key size recommendations, RSA vs ECC) were obfuscating the core technology ingredients.
- Thierry Moreau

@_date: 2017-11-27 12:33:12
@_author: Thierry Moreau 
@_subject: [Cryptography] Is ASN.1 still the thing? 
This is an incomplete picture.
A digital signature needs serialization. The relying parties do not negotiate with the signatory prior to the signing operation when the signature is for a more-than-transient data life span. E.g. a certificate.
- Thierry

@_date: 2017-10-25 22:18:55
@_author: Thierry Moreau 
@_subject: [Cryptography] Any serious study about Open source effectiveness in 
Quick question in the subject line.
Anything beyond anecdotal accounts?
Thanks in advance and best regards
- Thierry Moreau

@_date: 2017-10-31 15:58:49
@_author: Thierry Moreau 
@_subject: [Cryptography] Response to weak RNGs in Taiwanese and Estonian 
Ah! Quite instructive!
Some wise guys found an optimization for RSA prime generation in smart cards. The remaining entropy was somewhat marginal, but still acceptable. The resulting RSA modulus had a hidden structure, but it would be impossible that anybody would notice, and then who would be qualified enough, motivated enough, patient enough, and rich enough to find and exploit a specialized factorization algorithm matching the RSA modulus structure.
The hidden structure was identified earlier by the same group, see reference [78] in the above article.
In hindsight, the hidden structure was not a good decision:
- security by obfuscation,
- residual entropy could be too small, and
- a specialized factorization algorithm *might* be found.
Basic lesson: be cautious about tricks in applied public key crypto.
Outstanding question: does ECC (or any portion thereof) qualifies as a - Thierry Moreau

@_date: 2018-03-28 14:44:15
@_author: Thierry Moreau 
@_subject: [Cryptography] Specialized crypto processor architectures ? 
Is this post about instruction set architecture for some algorithm or about isolation of "secure" computations in a modern processor implementation? See more comments in-line.
I guess that those vulnerabilities are intrinsic to two broad classes of challenges: an API for a crypto module, and side channel leakage.
Then what? The economics of fielding a new processor architecture makes this attempt at reducing side channel vulnerabilities not feasible.
I see the "open source HSM" model with application agility as a more promising research avenue (put both the critical crypto and application logic in a device on which the end-user has more control than with features-rich computing devices).
- Thierry

@_date: 2018-10-06 18:45:46
@_author: Thierry Moreau 
@_subject: [Cryptography] China Spies In SuperMicro Mobos - Exemplar 
However, I do not see any ISA (instruction set architecture) for which the proprietary sub-components are absent or minimized. The matter becomes worse as the level of system integration increases.
Cost-effectiveness in the short term, and long term procurement reliability are serious issues.
My best attempt so far is ARM-based, in a SOC configuration targeted at TV set boxes, for which hobbyist boards are almost cheap, and long-term support should remain as the consumer market segment is stable. U-boot and Linux kernel support by the community is good. The vendor claim for open hardware is an overstatement.
The tradeoff is remaining proprietary aspects, including boot details, GPU (which I don't use), and crypto accelerator (which I don't need given the main CPU power).
- Thierry

@_date: 2018-10-15 18:52:08
@_author: Thierry Moreau 
@_subject: [Cryptography] Random permutation model for encryption as a 
This is exactly the problem statement for a "good" block cipher: find an heuristic for the selection of 2^n permutations "good for block ciphers," out of the (2^b)! possibilities, with some efficient formulation for implementation (key schedule, encrypt, decrypt).
- Thierry

@_date: 2018-09-04 15:31:25
@_author: Thierry Moreau 
@_subject: [Cryptography] WireGuard 
Here is the result of looking into this very significant contribution.
Looking at the fundamental public key crypto arrangement, Wireguard is an application of DH-based schemes combining long term (authenticating) and ephemeral key pairs in an authenticated key agreement protocol.
Lein Harn et al. pioneered this approach (e.g. [1]). The MQV and HMQV schemes also fall into this category. In contrast to these, the Wireguard proposal (in its adaptation of the Noise protocol) heavily relies on symmetric integrity algorithms for binding together the authenticating and ephemeral DH primitives.
The other fundamental public key crypto arrangement for the same protocol services (authenticated key agreement) is work derived from station-to-station and SIGMA schemes ([2]) and includes IKEv2 and HIPSEC.
I never figured out an equivalent public key foundation summary for either TLS or SSH.
Clearly Wireguard has a much wider relevance than this fundamental public key scheme analysis (Wireguarg is encompassing an impressive lot of implementation aspects).
- Thierry Moreau
[1] L. Harn, W.-J. Hsin, and M. Manish, "Authenticated Diffie-Hellman key agreement protocol using single cryptographic assumption", IEE Proceedings Communications, Vol. 152, No. 4, pp. 404-410, Aug 2005, available at [2] Hugo Krawczyk, "SIGMA: the 'SIGn-and-MAc' Approach to Authenticated Diffie-Hellman and its Use in the IKE Protocols", 2003, proceedings of Crypto'03 (LNCS Series, Vol. 2729), extended version available at

@_date: 2019-04-07 19:31:23
@_author: Thierry Moreau 
@_subject: [Cryptography] Name for three key ECDH 
Hugo Krawczyk SIGMA ...
She may send an ephemeral D-H public value and a request for same and some authentication from the server, thus hiding her identity. See SIGMA and e.g. HIP implementation (IETF Host Identity Protocol).
- Thierry

@_date: 2019-08-16 21:46:36
@_author: Thierry Moreau 
@_subject: [Cryptography] generated passphrases 
FIPS 181
Automated Password Generator (APG)
  "odnipnabiddiakodregcovji" ("od-nip-nab-idd-iak-o-dreg-cov-ji")
  "tadfahequemvuitexnobricophgov"   "obgeghagveotubjerasgiubeapo" ("ob-ge-ghag-ve-ot-ub-jer-as-gi-ub-eap-o")
  "cajbacipocerdekorevdykteav" ("caj-bac-ip-oc-erd-ek-or-ev-dyk-teav")
  "fonpyffonwugonboasyirtoitgek" ("fon-pyff-on-wu-gon-boas-yirt-oit-gek")
  "croycsadguphoodquoithsou" ("croycs-ad-guph-ood-quoiths-ou")
  "deahattyitosterhacwyftad" ("dea-hatt-yit-ost-er-hac-wyft-ad")
  "aktoasyuabnuorsherejvoariosa" ("ak-toas-yu-ab-nu-orsh-er-ej-voar-i-os-a")
  "penroobetawwyotyelsooght" ("pen-roob-et-aw-wyot-yels-ooght")
  "duhygyilthyalolaivequefcoybhu" ("du-hyg-yilth-yal-ol-aiv-e-quef-coyb-hu")
  "jehitsobofsacemhykussacdiflo" ("je-hits-ob-ofs-ac-em-hyk-uss-ac-dif-lo")
  "jodtuheivjeoneothywaddeumoid" ("jod-tu-heiv-je-on-e-ot-hy-wadd-eum-oid")
  "kryctioswysanyeicnanathufji" ("kryct-i-o-swys-an-yeic-nan-at-huf-ji")
  "nocvevweosyugnisadsyenobsi" ("noc-vev-we-os-yug-nis-ads-yen-obs-i")
  "yavvejnocafhedlikmidunis" ("yav-vej-noc-af-hed-lik-mid-un-is")
  "nihithikmuverajkidjunuckni" ("ni-hith-ik-muv-er-aj-kid-jun-uck-ni")
  "meramhokictyaudcarshyunsaitwek"   "liricustijwawowtyedezjeslinoc"   "bucnogdewtyaidsyutbimoad" ("buc-nog-dewt-yaids-yut-bim-oad")
  "reardeperpivvikcahaifcani" ("reard-ep-erp-iv-vik-ca-haif-can-i")
- Thierry

@_date: 2019-02-20 14:55:05
@_author: Thierry Moreau 
@_subject: [Cryptography] A seemingly simple question ... 
I used to think that a simple question to experts triggers a lengthy and complex answer.
Now I have a simple question in a field where I might be an expert (we are always on a learning curve).
An application requires data exchange between two distant server systems operated by "responsible organizations" according to a lasting agreement.
A secure channel is thus required between these two server applications. Confidentiality, data integrity, remote party authentication, and replay attack prevention would be needed. Non-repudiation is a non-goal (since no legal precedent ever hinted that public key crypto digital signatures would be a legal standard of courtroom evidence).
Supposedly, the initial cryptographic key material setup need not be What is the typical secure protocol deployed in this context? Obviously, "TLS" or "IPsec" is a partial answer due to the many protocol versions, options, configurations, ...
Also, if the answer is a transport layer protocol (e.g. TLS in a given profile) or a network layer protocol (e.g. IPsec in a given profile), is there any notable vulnerability originating from the fact that the security requirement is at the application layer? If so, what are the Hope this question is of interest to some of you!
- Thierry Moreau

@_date: 2019-02-27 15:32:29
@_author: Thierry Moreau 
@_subject: [Cryptography] A seemingly simple question ... 
Thank you for this reminder. I found it difficult to get the core lesson from the Noise protocol framework document.
Here is my summary: despite giving credit to SIGMA (an important source of inspiration for IpSEC IKEv2) and H*MQV, the noise protocol usage of public key crypto is basically a (flexible) combination of ephemeral Diffie-Hellman and static (i.e. authenticating) Diffie-Hellman.
There are many other aspects ... The above is just the core arrangement for a secure key exchange handshake. Is it good or bad? No opinion from my part except that this arrangement has been (implicitly) in the literature for a long time (too simple to attract attention of - Thierry

@_date: 2019-03-22 13:42:28
@_author: Thierry Moreau 
@_subject: [Cryptography] Best/simplest document encryption 
You start with a basic question, and then you add a plethora of additional requirements.
That's the basic question.
Basic answer: good local random source, Diffie-hellman exchange with out-of-band public key integrity check, conventional AES encryption with AEAD scheme. This is the implementation I came with when I felt the need to do the exercise of addressing the basic question as simply as possible.
Otherwise, train users with GPG (untrained users will be exposed to data leaks in any scheme).
- Thierry

@_date: 2019-05-17 16:40:12
@_author: Thierry Moreau 
@_subject: [Cryptography] A two key file/program 
If it is really only two keys that is required, the Shamir scheme is an The hidden details in the requirements include backup (for service continuity assurance), preventing the decrypted contents from being present on the Windows past their legitimate usage period, physical secrecy protection for each of the two keys at rest on a 7/24 basis (a storage format that prevents surreptitious duplication ...). Little of this is addressed by crypto-academic proposals.
My feeling is that the financial institution regulations are crafted for larger organizations able to show a larger staff and system budget which mystifies the auditors (market entry barriers). NIST CSRC is in this type of business for the US government (...). A FIPS 140 certified HSM buys a good autonomy in this perspective.
In derision of the user burden with password management, I crafted a totally manual scheme including one-time-pad encryption and sealed money bags. This is effective in every aspects of password handling prescriptions, without being really error-prone. But the workload is large and the user training would be challenging.
A FIPS 140 certified HSM may keep the auditor at bay, ...
- Thierry

@_date: 2019-11-11 20:02:10
@_author: Thierry Moreau 
@_subject: [Cryptography] Why RSA-PSS is much less secure than PKCS #1 v1.5 
Executive summary: crypto coding is hard, watch out for algorithm agility.
(I did not review this aspect) This seems a very big newbie design error, hence ??!
What is the relevance of a side-channel vulnerability for signature *validation* which handles only public data?
That's it: implement any algorithm agility "feature" with a self-defense strategy -- always.
Relevant history: an RSA exponent 3 signature validation implementation flaw was wrongly described as "allowing the attacker to create valid signatures without the the private signature key" (or so) while it is the flawed validation that issued a false positive outcome.
- Thierry
P.S. Do we have an ASN.1 Org Id for CRC-256 hash algorithm?

@_date: 2019-10-05 15:10:14
@_author: Thierry Moreau 
@_subject: [Cryptography] NSA FOIA: Fifty Years of Mathematical 
Thanks for this pointer.
The document reminds us about NSA mission and internal culture.
"[...] academic mathematicians slowly but surely discovering our secrets and publishing them openly. [...] Our lead is bound to diminish."
"[...] software cryptography can be replaced overnight which means that attacks must be developed under time and pressure, if at all; it may not even be cost effective to attack usages of software cryptography that change too frequently. On the other hand, it is more difficult than most people realize to devise secure cryptography and therefore we may expect frequent software changes at least occasionally to produce highly exploitable systems."
- T.

@_date: 2020-08-29 21:16:10
@_author: Thierry Moreau 
@_subject: [Cryptography] =?utf-8?q?TLS_1=2E0=2C_Diffie-Hellman=2C_RSA=2C_A?= 
A weird observation from my experimentation with open source security
I installed an Apache server with a single TLS profile which I believed robust in spite of being a bit outdated. I prioritized Diffie-Hellman for ?forward secrecy?, considered RSA, AES128 CBC, and SHA valid choices despite a bulk encryption key size in the low range. I assumed that a recent openssl library would implement the most needed countermeasures for known veakenesses in TLS 1.0.
I configured the thing HTTPS-only and requiring client certificate in all cases. Indeed I recorded that a friendly certificate ?subject public key? was used in the connection (through apache SSL environment variables ...).
In essence, it appears to work as intended.
The Firefox version 76.0.1 reported ?TLS_DHE_RSA_WITH_AES_128_CBC_SHA, 128 bit keys, TLS 1.0? as the technical details for the security of the web page.
In essence, it appears to work as intended ... but
The firefox browser qualifies this as ?broken encryption?. ?Your connection to this website uses weak encryption and is not private. Other people can view your information or modify the website's behavior. Information sent over the Internet without encryption can be seen by other people while it is in transit.?
And the security icon on the left of the URL entry field is yellow.
Then what?
Am I too old to craft an apache/openssl secure configuration? Indeed I am reluctant to chase a configuration including Diffie-Hellman forward secrecy that would fate better in the Firefox security assessment.
How can I claim that this is secure to third parties?
- Thierry Moreau
(In case you want to try with a different client browser, this listens on the public Internet but requires a client certificate. Since I trust only individually selected end-entity certificates as roots of trust, you need to send me your application ?out-of-band? with a motivation letter ... OK, off-list e-mail might allow you a short cryptoperiod of trust -- I reserve the right to limit the not-after field in the certificate. Public key algorithms other than RSA or with short modulus will be rejected without contacting the applicant!)

@_date: 2020-02-12 15:53:51
@_author: Thierry Moreau 
@_subject: [Cryptography]  
=?windows-1252?q?he_century=92=22?=
A purpose of one aspect of my life has been to build crypto-based protections, and I have been through these years when single DES was strong encryption subject to export controls.
With regards to data communications encryptors sold by Switzerland-based suppliers, I recall that after the Falklands war, the interception of messages by the UK has been traced to some events like the Crypto AG deception reported in the above 2015 BBC inquiry into de-classified NSA However, I am not sure if another Switzerland-based supplier (?? by the name of Cryptech ??) was involved or it was Crypto AG. It *might* be that this other supplier went out of business and Crypto AG reputation remained intact.
I recall a journalist interview with a former software specialist of the defaulted supplier reporting having someone coming from nowhere and introduced by the company management and dictating the encryption algorithms to use, while the young software specialist has prior education about cryptography (he was competent to see what was going on).
Basically, I was bored when I read a John le Carr? novel -- real events are more interesting!
- Thierry Moreau

@_date: 2020-01-30 21:41:21
@_author: Thierry Moreau 
@_subject: [Cryptography] Proper Entropy Source 
Be aware of audio compression. Lossy audio compression suppresses noise in the raw audio level samples. Lossless audio compression has limited uses in practice.
- Thierry

@_date: 2020-07-03 14:41:06
@_author: Thierry Moreau 
@_subject: [Cryptography] IPsec DH parameters, other flaws 
Thanks for this interecting historical perspective.
See below for a few comments.
To me as an applied cryptography practitioner, the documentation of the NULL encryption option was a convenient (i.e. readily identified upon a first look at the document) that the whole thing was not aimed at end-to-end security for the benefit of users.
At layer 9, IPsec was envisioned as a mandatory requirement for IPng (to become IPv6) which would not fit the US (and allies) dedication to preserve "national security" network traffic interception capability. Thus a flawless IPsec was institutionally/constitutionally impossible.
Your "almost all" qualification turns down my interest in the detailed TLS 1.3 design study. I do not see a rationale for giving up *any* of the security features present in the basic cryptographic protocol science available in the 1995-2005 period.
More specifically: Only from the current challenges of Internet presence for large organizations, I presume the TLS 1.3 design addresses the requirements for heavy server side loads (connection setups and overall encrypted data throughput), the ultimate end-to-end security being subordinated to server side efficiency.
Still without any definite rationale, I expect that some of the TLS 1.3 options would meet the ultimate end-to-end security criteria, but the corresponding profiles would not be readily deployed by servers and thus perhaps not well supported by browsers. Am I right with this expectation?
- Thierry

@_date: 2020-03-06 13:21:09
@_author: Thierry Moreau 
@_subject: [Cryptography] Possible reason why password usage rules are 
This illustrates how the public key cryptography is not too well mastered by the "experts." A certificate renewal would make sense for the same "subject" public key as the expired certificate. Then, the malevolent random third party would not be able to use the certificate.
- Thierry

@_date: 2020-11-16 13:19:20
@_author: Thierry Moreau 
@_subject: [Cryptography] Swiss helped with CIA spying 
In my recollection, this crypto gear was used during the Falklands/Malvinas war between UK and Argentina, giving intelligence advantage to the brits. More or less, the technology was proprietary symmetric key cipher packaged in an encryption modem.
More relevant to the topic of this group was this interview with an algorithm/software designer (after Crypto AG closure) explaining that a manager came in to stop his design work and ordered to implement exactly what an external "consultant" specified.
Actually eared during this era: "We will provide you the S-boxes." and (tacitly) replied "Don't call us, we'll call you."
Other times, other challenges, despite commonality of core principles.
- Thierry
