
@_date: 2010-08-06 20:38:54
@_author: Tom Ritter 
@_subject: A mighty fortress is our PKI, Part II 
Absolutely, on initial install there's no way to know it was originally
signed (if you're smart about it).  But in another architecture
Microsoft makes available (ClickOnce) software _upgrades_ that _were_
initially signed - but now are not - do not give indication that
something fishy is going on.

@_date: 2010-09-14 11:16:01
@_author: Tom Ritter 
@_subject: 'Padding Oracle' Crypto Attack Affects Millions of ASP.NET Apps 
When their talk first started getting hyped on twitter last Thursday,
the focus was on ASP.Net's viewstate [1,2] rather than the cookie
aspect. (Viewstate is a base64 blob of data in a hidden form field
about the current state of controls on the page.) I wonder if
threatpost focused on cookies because it's more accessible to
non-webforms programmers.  On Friday, a tweet mentioning using HMAC on
the viewstate was a valid mitigation [3].  This made sense to me
If Viewstates are protected with a simple hash by default, you could
append data and still generate a valid hash (because of many hash
functions' design flaw that created the need for HMAC itself [4]).
So you run the padding oracle attack described (which I won't explain
for fear of explaining it wrong) but you can append encrypted blocks
and generate valid hashes of your appended data.
Using HMAC on the viewstate instead of a vanilla hash function
prevents targeting the viewstate because you can no longer append
blocks and generate new hash.
What's weird is I find confusing literature about what *is* the
default for protecting the viewstate.  In this article[5] it says that
in .Net 1.1 viewstates are HMAC-ed to prevent tampering...
to make ViewState tamper proof.
But this article [6] implies only SHA1 uses an HMAC and MD5 does not,
in .Net 2.0.  (.Net 2 also added encrypted viewstate which is another
forms authentication ticket. When SHA1 is selected for the validation
attribute, the algorithm used is HMACSHA1.
forms authentication ticket.
And in this article[7], maybe the most recent, which talks about .Net
4.0 it gets even more confusing, adding specific HMAC options:
you can choose SHA1 (the default value), AES, MD5 or 3DES as the MAC
algorithm. If you're running .NET Framework 4, you can also choose
MACs from the SHA-2 family: HMACSHA256, HMACSHA384 or HMACSHA512.
specify the validation key. Remember to use cryptographically strong
random numbers: if necessary, you can refer to the key generation code
specified earlier. You should use at least 128-byte validation keys
for either HMACSHA384 or HMACSHA512, and at least 64-byte keys for any
other algorithm.
I'm thoroughly confused about what the default is in each version, and
how each option actually behaves.  Based on some of the documentation
and how I understand POET (their tool for the padding oracle attack)
working, I think there may be a disconnect between the writers, and
the security team.  I tried hard to get my company to send one of our
(non-security) Argentinean devs I'm friends with to ekoparty to take
notes and fill me in, but to no avail.  I hope after the presentation
blogs and this list fill with details about it.
Unrelated, at one point a phrase was written and echoed precipitously:
SHA1 is preferable because it produces a larger hash
Anyway, Colin Percival and Thomas Ptacek got in a discussion[x] about
Encrypt-then-MAC, reproduced here because following twitter
discussions is a pain:
  Ptacek: CBC + HMAC decrypt+validate is an infamously tricky piece of
code to get right. I've never seen a generalist's implementation that
  Percival: This is why (a) you should encrypt-then-MAC, not vice
versa, and (b) not use CBC mode.
  Ptacek: What does encrypt-then-MAC have to do with it? That's the
pattern that creates the timing variant of the attack.
  Percival: With encrypt-then-MAC, fake messages are discarded without
having their CBC padding inspected.
  Ptacek: Sorry, I misread. But then: you trust SHA256 as a first-line
defense more than AES?
  Percival: Do I trust HMAC-SHA256 more than AES? Hell yes.
Colin's right of course, if the HMAC option is used, then it should
throw out the attempts POET makes without indicating the padding is
good or bad... It's just that darned documentation that's confusing
[1] [2] [3] [4] [5] [6] [7] [x]

@_date: 2013-12-04 08:56:29
@_author: Tom Ritter 
@_subject: [Cryptography] Kindle as crypto hardware 
Yes, I would add Tamper Evident.  I don't want to carry a key management
device everywhere.  It _might_ be feasible if it was one of those stub usbs
that are as small as the plug itself... but there goes the display.
The question is, can tamper evident be grafted _onto_ a kindle easily and
reliably?  Nearly all forms of tamper evidence have fallen to Defcon's
Tamper Evident contest.  That doesn't mean they're worthless, because they
increase attacker cost, but they can't be relied on fully.

@_date: 2013-11-04 07:36:50
@_author: Tom Ritter 
@_subject: [Cryptography] DNSSEC = completely unnecessary? 
DNS does not provide authenticity, DNSSEC does.  Not everything we do
online uses SSL, so while many protocols have some amount of
authenticity built in to them (each flawed in their own way, as
Zooko's Triangle dictates some practical limits) - DNSSEC lets us
bootstrap authenticity for any protocol.  "The person you want to talk
to is [here] and he will use [this key fingerprint]."
DNSSEC prevents cache poisoning, when used correctly. And SSL/TLS does
not protect HTTP, which I would venture is a laaaaarge percentage of
web traffic, even when SSL is available.
And if you argue "Well, the HTTP problem can be solved by HSTS" I will
say "Okay, how do you securely communicate HSTS to a host to which the
answers are: 'Hope the user isn't owned the first time', 'Bake
preloaded HSTS into every browser', or 'Securely transmit HSTS
information using some other protocol like DNS."
It's true as we bolt more and more stuff into HTTP Headers (HSTS,
Public Key Pinning, etc) the value of DNSSEC _for HTTPS_ goes down.
But there is still value there to be gained for other protocols,
nearly all of which bootstrap off DNS.  The other big win for HTTP
we'll see is the ability to use self-signed certificates via DANE,
which relies on DNSSEC.

@_date: 2013-11-15 11:02:21
@_author: Tom Ritter 
@_subject: [Cryptography] programable computers inside our computers (was: 
Reviving an old thread because I particularly like this statement and
agree with it at the moment.
Also, I believe TPM 2.0 includes remote attestation. Clearly this
could be abused, and probably will be, but I'm also interested in
applicability in scenarios where the queryier and attestor are in
cooperation. I'd love to query cryptocat's servers and verify they are
running a particular system build without modification. This might
even be able to provide more improved warrant canary type approaches.
Similarly, in the corporate sector (which includes field agent
activists) verifying that a user's laptop is running the bios and
kernel you expect. This can all raise the bar for attackers.

@_date: 2013-10-22 12:29:33
@_author: Tom Ritter 
@_subject: [Cryptography] programable computers inside our computers (was: 
And to add another, there was a presentation on ARM TrustZone, the OS
inside your CPU, that's seems so designed for backdoors that ARM
actually gives tips for running TrustZone invisible to the normal OS.
These are increasingly worrying me as well.  The Secure Element on
Android can at least (if you root and edit the .xml file) be queried
to learn identifiers of what is installed there, if not directly
interact with them.

@_date: 2013-10-22 21:20:18
@_author: Tom Ritter 
@_subject: [Cryptography] prism-proof email in the degenerate case 
It'd be a step forward, for sure.  The fact that it's on Github may
imply it's a finished project, but it is actually more like 10-20%
Pynchon Gate (
is, if I butcher it a little summing it into a single sentence, a
pseudonym server that aims to allow you to receive messages without
letting your pseudonym be linked to you.  It's like Tor for email -
doesn't disguise the fact that you're using it, but aims to disguise
what you're doing with it. Or, another way, it's the second generation
of nym servers.
As part of it's operation it requires a remailer network (which we
don't really have in a robust fashion these days), although in a pinch
you could use Tor instead.

@_date: 2014-08-15 11:05:47
@_author: Tom Ritter 
@_subject: [Cryptography] Open Source Sandboxes to Enforce Security on 
AppArmor, SELinux.
The Chromium sandbox is open source, pretty sure NaCL is as well.
Mozilla is sandboxing the proprietary DRM blob inside Firefox, I
assume the sandboxing mechanisms are open source.
Building an open source app like Sandboxie using the Chromium sandbox
would be awesome.

@_date: 2014-08-18 16:46:03
@_author: Tom Ritter 
@_subject: [Cryptography] Encryption opinion 
I don't believe you. You're a wonderful guy with fantastic choice in
restaurants, but I'm going to need to check this myself. ;)
This is not particularly easy to verify, but I downloaded Firefox ESR
17 (which still has the old ciphers), and flipped them all. RC4/56,
Single DES, RC4/40, NULL, I've got all the bad ones and none of the
good ones.  Then I went to as many sites as I could think of:
Ebay - Nope
Westpac.com.au - nope
Wells Fargo - nope
Bank of America - nope
Google Search - nope (made this tricky, had to use bing)
HSBC US, UK, and HK - nope
BoA - nope
Barclays UK - nope
Chase - no
Citi - nope
Vanguard - nope
None of those sites accepted the SSL handshake.  I'm certain that
there are still some banks out there that allow weak ciphers, but
saying it's the norm does not seem to be correct from my testing.
Moving back to speaking generally:
Also, FWIW, I was doing 30-hour RSA-512 factorings in 2011.  Haven't
tried on new hardware, probably down to a day now, maybe faster.  The
square root is not nicely parallelized.
Factoring RSA-1024 is definitely a feat of accomplishment, and you're
right, if I was going to go after 1024 bit, I'd go factor one the
1024-bit CA roots Mozilla is still shipping, not Jorge's app.  But I
would be genuinely surprised and disappointed if there wasn't an
academic project sieving for RSA-1024 right now.  With the right team
of grad students and access to a good cluster, I would expect it to
take 2-3 years calendar time and $1m (plus some free sieving time) to
fall.  And when that happens, even more than today, using RSA-1024 is
a marketing disaster.
But choosing such weak cryptography, when stronger, faster, smaller
options exist seems foolish.  If you can integrate one of djb's
libraries for curve-25519 into your code, and you're reasonably
careful, ECC's 'brittleness' won't be any more brittle than RSA.
_Especially_ when you factor in Steve's observations about unpadded
Also, Jorge, you should reach out to Sandy at
and visit them. There are a lot of technologists and crypto
enthusiasts in NYC; I can introduce you to some directly as well.

@_date: 2014-08-19 08:59:00
@_author: Tom Ritter 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
What's the point?  Anything that speaks HTTP also speaks HTTPS, so
there's no need for the "If you support it, I have TLS available."
Just use any of multitude of redirect mechanisms for your webserver to
kick people onto HTTPS.
I didn't read the draft word for word, but I don't see anything in it
that indicates the client MUST NOT validate the server certificate or
MUST use anonymous ciphersuites.  Indeed it seems to say the opposite.

@_date: 2014-08-21 10:40:33
@_author: Tom Ritter 
@_subject: [Cryptography] GPU farm ideas: Break SHA-1? 
There was a SHA-1 Collision Search on BOINC (which is a fantastic
platform for this sort of thing) back in 2007... I thought they met
the computation necessary, but it failed for some reason... does
anyone here know more about that effort?

@_date: 2014-02-13 18:24:14
@_author: Tom Ritter 
@_subject: [Cryptography] Are Tor hidden services really hidden? 
Hiding a server is of course much harder than hiding a client.  But
clients can also be servers - Facebook chat, for example, turns anyone
into a server that can be contact with variable length messages at the
attacker's leisure.
Lots of people assume this, but it doesn't seem to bear out well.
Besides the NSA docs that expose their lack of interest in doing so,
visit here:  While there's a large 'unknown' percentage - most of these large
bubbles are people that the Tor Project is in close contact with and
the community knows personally.
An entry node knows who is talking, but not to whom. A middle node
knows no IP addresses. An exit node knows the recipient IP but not the
origin.  So I'm not sure what you mean by seeing IPs, but they are
unable to see sender and receiver IPs unless they operate both the
start and end node. This is a tagging attack (active) or a traffic
confirmation attack (passive).  It's difficult to achieve, as Tor uses
entry guards to lower the probability of achieving the entry node.
It depends on your model. If you're saying a Globally Passive
Adversary can de-anonymize low latency connections - and thus the dark
net can't exist: I would agree with you.  If you're saying "Tor Hidden
Services can never provide a level of protection against automatic
wide-scale de-anonymization attacks by a government TLA" - I'll
disagree and start diving into specifics with you.

@_date: 2014-02-14 10:50:42
@_author: Tom Ritter 
@_subject: [Cryptography] Are Tor hidden services really hidden? 
The RP is chosen by the client, so the attacker doesn't need to
control those. When the HS contacts the RP, it's via a Tor circuit, so
the RP doesn't learn the HS's actual IP, only the exit IP.  This
doesn't get you any closer to finding it though.
The attacker needs to be come the entry point for a HS to perform a
traffic confirmation attack. By sending lots of data to the HS from a
client, the entry point can correlate that traffic being delivered to
the connection, even if it can't read it.
To protect against this attack, Tor uses Entry Guards:
 These aim to 'stick' a
client (or HS) to a set of entry nodes.  If you, the attacker is in
that set - you're good to go. But if you're not, it's much more
difficult for you to get _into_ that set.

@_date: 2014-02-14 11:50:01
@_author: Tom Ritter 
@_subject: [Cryptography] Are Tor hidden services really hidden? 
Agreed, wholly.
I'll nit and say we only have 5K nodes, including 1K exits and 2K
guards but it's possible.  I proposed (and intended to do before I got
sidetracked) that we just go through the exit probability percents and
tick off which nodes we believe are run by trustworthy people, and
just see what percentage we get to.  I think it will be less than 50%,
but greater than 25%.

@_date: 2014-05-02 16:56:42
@_author: Tom Ritter 
@_subject: [Cryptography] Need Debunking help 
Never heard of it.  What the heck is it supposed to do?  They post the
APK, which is polite of them.  Yanking the source code out of it
yields the following:
Tiny Manifest File. [0]  Low permisisons, which is good, but only one
activity.  App doesn't seem very large...
Working on SDCard, which is a no-no
        fileoutputstream = new FileOutputStream((new
They embed a webview, which has some dangerous options, but I didn't
see any of the scary addJavascriptInterface calls.  Although there is
        public void onReceivedSslError(WebView webview,
SslErrorHandler sslerrorhandler, SslError sslerror)
        {
            sslerrorhandler.proceed();
        }
Looking like they're overriding certificate validation. Yay. ;)
Posting username and password over HTTP in the URL?
                String s1 = (new
EncodingUtils.getBytes(s1, "base64"));
Oh come on.  At this point, I stopped looking.  I still have no idea
what this app _does_ and if any of these are legitimate bugs.  Maybe
'username' and 'password' in this context are completely harmless?
Doubt it though....
Anyway, I just wanted to remind folks that 'closed source'
applications, especially on Android, are often easily picked apart and
analyzed.  You don't always have to speculate about how something
works, you can go dig in.[1]
[0]    [1] Or hire a security firm to review a piece of software you are
considering purchasing. ;)

@_date: 2014-05-17 12:16:59
@_author: Tom Ritter 
@_subject: [Cryptography] Are there other anonymous key exchange 
Is this not the same paper as  ,
which we talked about in the Cryptopocalypse media frenzy of last

@_date: 2014-05-20 13:59:21
@_author: Tom Ritter 
@_subject: [Cryptography] The Trust Problem 
We've reached the point where most people are trying to build apps
that directly tackle a 'hard problem'.  Hard problem is subjective of
course, but we can probably roughly agree on them.
Mustbin syncs data between devices - the 'hard problem' there is how
do you get a key on device 1 & 2 without giving it to Mustbin.  Based
on their blog post, they would have to encrypt a key using your
password and using your answers to security questions, and on device
two you login and can decrypt that key.  That solves the 'hard
problem' of sharing keys and moves the onus on the user to have a
secure password and answers to secret questions.
But they _also_ say that you can share photos with other people.  Now
we have another hard problem! Assuming the photo is even encrypted,
how do I get the key for the other person, and how do I know that key
is really their key and it's not the central service impersonating
them? This is the same problem iMessage, Silent Circle, Wickr, and a
host of others have.   And although I've never used the latter two - I
bet none of them attempt to address or solve it.
So to answer the question - I determine, in a large part, whether or
not to trust someone by identifying the 'hard problem' they're working
against, and if they address is plainly and simply, explaining how
they traded against usability and simplicity and security.  Mustbin
does not seem to meet these criteria.

@_date: 2014-05-20 14:06:54
@_author: Tom Ritter 
@_subject: [Cryptography] Facebook on the state of STARTTLS 
Short: MX records (without DNSSEC) are unauthenticated and can point
to a domain the attacker can legitimately get a certificate for.
If I do an MX lookup on konklone.com, I get the following:
;; ANSWER SECTION:
konklone.com. 3599 IN MX 10 mx-3.rightbox.com.
konklone.com. 3599 IN MX 10 mx-2.rightbox.com.
konklone.com. 3599 IN MX 10 mx-1.rightbox.com.
If I use  to check if I can send you email
securely, I see that I get a certificate with the commonName of
*.pobox.com.  So the cert doesn't match rightbox.com - and if I were
doing strict name checking, I would reject it.  But let's pretend we
do replace the cert, or stick in a SAN for *.rightbox.com, so now it
Well, we're assuming an attacker who can modify traffic on the wire,
otherwise you don't even need a CA cert, a self-signed opportunistic
encrypted channel is sufficient to protect it against a passive
So this attacker doesn't present a false certificate, because you're
doing strict name checking and requiring a valid CA-signed cert.
Instead they just return a MX record to ritter.vg.  I own ritter.vg
and thus can get a valid CA-signed certificate for it.  So now when
you want to email someone, you do an MX lookup, get directed to
ritter.vg, check that the certificate matches and is CA-signed, and
you deliver the mail.

@_date: 2014-11-01 20:23:58
@_author: Tom Ritter 
@_subject: [Cryptography] Vulnerability of RSA vs. DLP to single-bit faults 
You can say that, but I think it'd be wrong to dismiss it entirely,
considering the success that Bitsquatting had:
I don't have any pointers, Peter, but I'm definitely curious to see
what you come up with.

@_date: 2014-11-07 11:19:47
@_author: Tom Ritter 
@_subject: [Cryptography] Who's solving difficult security problems 
Don't get me wrong, Google deserves a lot of credit for a) deploying
it first and b) being a major author behind the specs - but that's
actually the FIDO Alliance:

@_date: 2014-11-19 08:59:44
@_author: Tom Ritter 
@_subject: [Cryptography] STARTTLS, 
Or we tend to skip over threads with a low fact:opinion ratio ;)
But then why didn't Cricket do what Comcast does, and just block it,
instead of doing this super-sketchy 'Let's just remove the crypto and
inspect the user's data' approach?  Or, what I think is a fairly
reasonable tactic that some ISPs do on consumer home ISPs, and block
ports but let you opt-out in your user account.  (I had an ISP that
blocked 80 and 25, and two checkboxes to immediately undo it.)

@_date: 2014-10-13 21:21:20
@_author: Tom Ritter 
@_subject: [Cryptography] factoring small(ish) numbers 
512-bit numbers are just on the cusp of 'doable in a month' depending
on how 'standard' your 'standard' PC is.  (3) is satisfied.

@_date: 2014-09-04 18:19:58
@_author: Tom Ritter 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
I took it to mean something different, literally to mean "Start
talking [full] TLS to me."  Which is what the draft in your initial
email seems to indicate, as it seems to require cert validation.
That's why I countered with 'What's the point of this draft? Just send
a redirect.'
Opportunistic encryption for HTTP is good, and I support it.  It's
being worked on in the IETF, too, so it seems like it will at least be
standardized.  Just not under the moniker 'STARTTLS for HTTP'.  :)

@_date: 2014-09-04 20:51:16
@_author: Tom Ritter 
@_subject: [Cryptography] Are there Key Server for non-PGP systems? 
That's a pretty good question.  I'm not aware of any HKP
implementations.  But broadening it, I'm not even sure if there are
many key servers for stuff _in general_?
I know about the DLV for DNSSEC:
And I know if you use LDAP or Active Directory, it's common to put
people's certificates in there - but those are usually internal-only.

@_date: 2015-08-02 08:20:26
@_author: Tom Ritter 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
My opinion is that the rough consensus can be counter-balanced by
"running code".  If the original group moves forward, deploys, gets
early adopters, shows it's working, and perhaps wonder-of-wonders gets
it picked up by one of the big behemoths that could jump-start
deployment (maybe Google, or Akamai, or CloudFlare) - well they can
document as an informational document at least.  And you can
interoperate with the folks who have deployed.

@_date: 2015-01-28 18:34:02
@_author: Tom Ritter 
@_subject: [Cryptography] [cryptography] Underhanded Crypto 
I don't think so, if it has I owe someone a prize. I think they extended
the judging timeframe to end of January.

@_date: 2015-07-16 07:09:51
@_author: Tom Ritter 
@_subject: [Cryptography] Super-computer project wanted 
Not the whole thing, but there's been work on the components of the
GNFS, and test-runs to see if those changes are worthwhile when
applied to the polynomial selection or sieving could be helpful.  See
for examples; and I believe Paul Zimmermann would be to the person to
ask if he has any ideas in the works that could use the flops.

@_date: 2015-06-17 12:53:00
@_author: Tom Ritter 
@_subject: [Cryptography] Anyone know of crypto hooks in webmail systems? 
No, nothing standardized or even formally committed to, that I'm aware of.
I would look at how Google's and Yahoo's plugins do it.  I have to
assume they're doing the same thing everyone's done for years: grab
the div id's out of the source code, and hardcode them.  *But* since
Google and Yahoo are doing this internally themselves, there's less of
a chance that the ids will change out from underneath you in a way
that invalidates your technique.  (Which was always the problem
before.)  You can also look at how Mailvelope does it.

@_date: 2015-03-11 20:51:58
@_author: Tom Ritter 
@_subject: [Cryptography] Digital Certificate Forensics: Clinton Email 
If you're curious about the certs, they're probably here:
  (Obviously this
doesn't tell you deployment dates)
ctwatch is a Monitor front-end to Cert Transparency.  Google seems to
have dumped all the certs they've seen on the internet into their log
servers, and you can view them using ctwatch or your own command-line

@_date: 2015-03-26 20:18:02
@_author: Tom Ritter 
@_subject: [Cryptography] Certificate transparency on blockchains 
It would be better to voice them on trans, which I am copying.  I
suggest we move it there for follow-ups.
It checks if the signature over the data is valid.
Keeping data for an invalid signature (or a signature for a log which
I do not recognize and thus don't have the public key) would allow
clients to store arbitrary data on your server. Complex rate-limiting
and DoS concerns now apply.
Yup. We can't force anyone to participate unfortunately.  A client
_can_ opt-in to using a trusted auditor and send SCTs to them, which
then mitigates the concerns over a server not participating.  But I
will note that if a server does not participate they are essentially
opening themselves to attacks by logs. So they have an incentive to
There is nothing stopping a server from being an auditor and detecting
log misbehavior.  I suppose we could add a note in the draft to that
effect, but it's a pretty weighty option I imagine most people will
not pursue.
(nit: Server can instead just make the SCTs available for auditors to
query and retrieve from them. Server doesn't have to initiate outbound
Yes, an attacker who can persistently isolate a client or server from
the rest of the internet is powerful, and is difficult to defeat. We
do not defend against such an attacker. I'm open to suggestions here,
but none really came to me.
That's fair.  There are limitations to the draft, to be sure - but
balancing the very difficult privacy concerns of literally
broadcasting the websites you've visited is also important.

@_date: 2015-05-05 01:17:55
@_author: Tom Ritter 
@_subject: [Cryptography] replacing the whole sodding lot 
You can like QUIC as a TLS-replacement... but it doesn't change PKI.
It's still rooted in CAs (modulo certificate pinning.)

@_date: 2015-05-11 21:44:52
@_author: Tom Ritter 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
On the lightweight side, I get the impression that block ciphers are
also a big topic, but that there isn't a ton of work being done
there... besides the NSA ciphers, SIMON and SPECK. John Kelsey
mentioned these at RWC. The NSA came to NIST and said "Check out these
ciphers!" and NIST said "Those look cool, but please publish them for
academic review so we're not favoring you in any way."  So they did.
But now the onus is on the community to analyze them and either poke
holes in them or present something better.

@_date: 2015-05-25 19:56:54
@_author: Tom Ritter 
@_subject: [Cryptography] open questions in secure protocol design? 
10. Which Anti-Replay Mechanism?
11. Clocks or no?
12. Authentication Model (CAs? Namecoin? Perspective? WoT? Pre-Shared Keys?)
13. State vs Statelessness
And if you want to get fancy, things like authenticated downtime.
In particular, the ones I see the most teeth-gnashing with is figuring
out anti-replay and state (especially on those damned IoT things).
