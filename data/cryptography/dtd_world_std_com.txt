
@_date: 2001-04-17 22:33:40
@_author: Don Davis 
@_subject: Alcatel ADSL Modem vulnerabilities 
Researchers associated with the San Diego Supercomputer
Center at the University of California, San Diego have
identified multiple implementation flaws in the Alcatel
Speed Touch ADSL "modem" (actually an ADSL-Ethernet
router/bridge). These flaws can allow an intruder to
take complete control of the device, including changing
its configuration, uploading new firmware, and disrupting
the communications between the telephone central office
providing ADSL service and the device.
These flaws allow the following malicious actions:
  * changing the device's configuration such that the
    device can no longer be accessed;
  * disabling the device, either temporarily or
    permanently (requiring return of the device to
    the manufacturer); and
  * installation of malicious code, such as a network
    sniffer to gather local LAN traffic (that is not
    being bridged) and making the box more easily/covertly
    remotely accessible.
One of the more interesting discoveries was a cryptographic
challenge-response back door that completely bypasses any
password that a user may have set on the device.
All testing to date has been done in LLC/SNAP bridge mode.
Routing mode was not tested. There may be other flaws that
are easier to exploit in that mode.
(Speed Touch is a trademark of Alcatel.)

@_date: 2001-07-02 22:06:23
@_author: Don Davis 
@_subject: Crypographically Strong Software Distribution HOWTO 
this is because dobbertin's attack works only
against message-digest applications of md5;
his attack doesn't work against md5 MACs, ie,
when md5 is used to hash a symmetric key with
the plaintext.
but, i generally tell clients to use sha-1 even
for MACs, just to avoid confusing their customers.

@_date: 2001-06-02 21:11:46
@_author: Don Davis 
@_subject: article: german secure phone 
Portable privacy
A mobile phone that protects transmissions from
sophisticated eavesdropping is launched in Germany
A mobile phone that protects transmissions from
sophisticated eavesdropping has been launched in
Communications company Rohde Schwarz created the TopSec
GSM phone by fitting military grade encryption hardware
into an ordinary S35i Siemens mobile phone.
The company expects the device to appeal to businessmen
who want to protect themselves against industrial
espionage and government representatives concerned
about spying. "In both cases communications have to be
secure," says a company representative.
Ex-Nato technical expert Brian Gladman told New
Scientist: "If done correctly, the encryption would be
effectively attack-proof."
Although the GSM standard does protect transmissions by
encoding them, a number of weaknesses have been
discovered with the system. These could allow
sophisticated eavesdroppers to listen in. The TopSec
GSM phone is designed to provide an extra, robust layer
of security.
The phone may not be for everyone, however. Each device
costs ?1800 and so far only 500 handsets have been
created. These must also be bought directly from Rohde
Private keys
The handset works like any normal GSM mobile phone. But
users can establish a secure communications channel
when "Crypto" is selected from the customised display
menu. When a number is dialled and the Crypto function
selected, the phone checks to see if the device at the
other end is compatible. Currently, the phone works
only with other TopSec mobile phones and ISDN phones
produced by Rohde Schwarz.
If the device at the other end is compatible, each
phone opens a data channel and exchanges its public
encryption key. Using mathematically-linked private
keys, the phones then establish a shared code for
securing voice communications at speed.
It is theoretically possible to decipher messages
encrypted in this way by trying all possible keys in
succession. But in practice this would require a
formidable amount of computational power. Rohde Schwarz
estimates that it would take 100 average desktop
computers 10 years to decrypt a 10-minute phone call.
Although the encryption itself may be secure, Gladman
says it might be possible to trick the phones into
giving up their secrets using a "man in the middle"
attack. This would involve carrying out a dummy key
exchange with both parties and creating two secure
channels. Each party would be communicating securely,
but only through a third eavesdropper.
This technique would be beyond most industrial spies.
Gladman says it might be within the capabilities of
some government intelligence agencies, however.
Devices that work along similar lines are already used
by the US military. And this is not the first attempt
to make a commercial encryption phone. US company
Starium has created a device that can be attached to
standard phone lines in order to secure voice
communications with encryption.
Web link:
Rohde Schwarz  1630 GMT, 31 May 2001

@_date: 2001-06-22 10:15:57
@_author: Don Davis 
@_subject: crypto flaw in secure mail standards 
All current secure-mail standards specify, as their "high-
security" option, a weak use of the public-key sign and encrypt
operations.  On Thursday the 28th of this month, I'll present
my findings and my proposed repairs of the protocols, at the
Usenix Technical Conference here in Boston:
  Don Davis, "Defective Sign & Encrypt in S/MIME, PKCS MOSS,
PEM, PGP, and XML."  To appear in Proc. Usenix Tech. Conf. 2001,
Boston.  June 25-30, 2001.
A short summary:  All current secure-mail standards have a
significant cryptographic flaw.  There are several standard
ways to send and read secure e-mail.  The most well-known
secure mail systems are PGP and S/MIME.  All current public-
key-based secure-mail standards have this flaw.  Here are some
examples of the flaw in action:
Suppose Alice and Bob are business partners, and are setting
up a deal together.  Suppose Alice decides to call off the
deal, so she sends Bob a secure-mail message: "The deal is off."
Then Bob can get even with Alice:
  * Bob waits until Alice has a new deal in the works
    with Charlle;
  * Bob can abuse the secure e-mail protocol to re-encrypt
    and resend Alice's message to Charlie;
  * When Charlie receives Alice's message, he'll believe
    that the mail-security features guarantee that Alice
    sent the message to Charlie.
  * Charlie abandons his deal with Alice.
Suppose instead that Alice & Bob are coworkers.  Alice uses
secure e-mail to send Bob her sensitive company-internal
sales plan.  Bob decides to get his rival Alice fired:
  * Bob abuses the secure e-mail protocol to re-encrypt and
    resend Alice's sales-plan, with her digital signature,
    to a rival company's salesman Charlie.
  * Charlie brags openly about getting the sales plan from
    Alice.  When he's accused in court of stealing the plan,
    Charlie presents Alice's secure e-mail as evidence of
    his innocence.
Surprisingly, standards-compliant secure-mail clients will
not detect these attacks.
Once I've presented the paper, I'll make this link live:

@_date: 2001-06-23 00:48:57
@_author: Don Davis 
@_subject: crypto flaw in secure mail standards 
i've received permission from usenix to release the
paper on saturday (6/23):

@_date: 2001-06-23 19:59:23
@_author: Don Davis 
@_subject: crypto flaw in secure mail standards 
please forgive my failure to reply to the list
members' comments individually, but my paper has
attracted so much mail, that i can't fulfill my
obligation to answer each of you courteously.
your critiques fall into a few categories:
   * old news; there's no new crypto problem here;
   * not a crypto problem, but a foolish-user problem;
   * not a crypto problem; the attacks work even
     without encryption, and even with surface mail;
   * not a crypto problem, because the problem is
     easily fixed with signed header-info, or with
     signed salutations.
   * this problem is one of a large class that's
     too hard to fix in full generality.
my paper raises almost all of these points, and i
agree with all of them, except with their common
theme: "it's not really a crypto problem."  in my
paper, i argue that there _is_ a clear-cut lapse of
good crypto-protocol design here.  the most basic
difference between my claim and the critiques, is
about usability.  i believe today's secure-mail
protocols should fulfill today's users' rather
na?ve and inarticulate expectations about security
and ease-of-use.  unfortunately, today's secure-mail
protocols were designed before these na?ve newbie
users flooded into the net.  this isn't the fault
of the diligent and brilliant engineers who contri-
buted to the various secure-mail standards.  but,
i suggest that it's more realistic to revisit their
work, and to change the secure-mail protocols and
products, than it is to try to change all of the
net's na?ve users into crypto-aware users who can
wield the current secure-mail products effectively.

@_date: 2001-06-28 21:21:08
@_author: Don Davis 
@_subject: blocking chinese domains? 
does anyone know whether china has recently shut
down its citizens' outgoing network access?
in looking over the hits on my web-page recently,
i noticed a bizarre factoid:  of 7000 hits, none
came from the .cn domain;  there were hits from
armenia, fiji, niue, korea, and other equally-
small venues, but none at all from the PRC.  is
there any known reason for this consistent disparity?

@_date: 2001-05-31 22:07:14
@_author: Don Davis 
@_subject: use of digital signatures and PKI 
============================== START ==============================
i have one potent, anecdotal data point:  a friend of
mine is a 3-letter executive at one of the older/bigger
PKI vendors.  he surprised me in a recent conversation,
by mentioning that essentially none of his company's
customers are using PKI for signatures.  actually, he
may have said, "_no-one_ is using PKI for signatures."
he says that practically all of the certs are being
used for negotiating symmetric session-keys.

@_date: 2001-11-01 13:57:06
@_author: Don Davis 
@_subject: Proving security protocols 
5 years ago, i saw meadows give an interesting talk,
comparing the various state-of-the-art verification
tools, with caveats about each one's blind spots, and
with some attention to how easy/hard it is to make
mistakes while using such tools.  i suspect that the
talk i saw was from this paper:
Catherine Meadows, "Formal Verification of Cryptographic
Protocols: A Survey," Advances in Cryptology - Asiacrypt
'94, LNSC 917, Springer-Verlag, 1995, pp. 133-150.
       In this paper we give a survey of the state of the
       art in the application of formal methods to the
       analysis of cryptographic protocols. We attempt to
       outline some of the major threads of research in
       this area, and also to document some emerging trends.
a more recent meadows paper surveys open problems in
the field:
Meadows, Catherine, "Open Issues in Formal Methods for
Cryptographic Protocol Analysis,"  Proc DISCEX 2000,
IEEE Computer Society Press, pp. 237-250, January, 2000.
       The history of the application of formal methods
       to cryptographic protocol analysis spans nearly
       twenty years, and recently has been showing signs
       of new maturity and consolidation. A number of
       specialized tools have been developed, and others
       have effectively demonstrated that existing general-
       purpose tools can also be applied to these problems
       with good results.  However, with this better
       understanding of the field comes new problems that
       strain against the limits of the existing tools.
       In this paper we will outline some of these new
       problem areas, and describe what new research needs
       to be done to to meet the challenges posed.
i found these papers on her group's publications page:

@_date: 2002-08-07 08:54:02
@_author: Don Davis 
@_subject: deterministic primality test 
from slashdot:
                 PRIMES in P
       M. Agrawal, N. Kayal, N. Saxena
            Dept. of C.S. & Eng,
        Indian Inst. of Tech. Kanpur
                 Aug 6, 2002
Abstract:  We present a deterministic polynomial time
algorithm that determines whether an input number is
prime or composite.
Summary:  time complexity is O((log n)^12), but the
exponent can be reduced to 6, assuming the truth of
the hardy-littlewood conjecture about the distribution
of sophie germain primes.  the exponent might be
reducible to 3, if another, less-famous conjecture
is true.
bona fides:  FWIW, the authors acknowledge some well-
known workers.

@_date: 2002-07-02 13:47:08
@_author: Don Davis 
@_subject: Montgomery Multiplication 
here's an explanation i wrote a couple of years ago:
what's going on with montgomery reduction:
do you remember in your first digital-hardware class, how they taught
you that you don't need AND, OR, and NOT gates, to build full-function
logic circuits, because you can do everything with just NAND gates?
montgomery's algorithm is kind of like that; it shows that you don't
need the multiply, divide, and remainder operations to do bignum modular
exponentiations, because you can use this montgomery-multiplication
operation over-and-over, instead.  the advantage of montgomery-mult'n
is that it avoids the remaindering operation, and so avoids expensive
divisions, but nevertheless manages to keep an exponentiation's
intermediate products small, in a very cheap & easy way.
it works rather like logarithms, and the performance trade-offs are
similar:  to multiply two numbers, you have to transform them to the
montgomery representation, montgomery-multiply the transformed numbers,
then transform the product's montgomery-representation back to the
normal representation.  for two factors, this takes longer than a
normal multiply-and-take-remainder step would, even though montgomery-
multiplication is just as cheap as normal multiplication, because the
final transformation takes longer than doing a remainder in the usual
way. but, for exponentiation, where we would montgomery-multiply many
times, we only have to do the representation-change twice, at the
beginning and end.  to do a modular exponentiation in the normal way,
we'd have to take the remainder after every multiplication.  so, that's
how montgomery saves time: convert the operand to a representation in
which the remaindering operation disappears, multiply that representation
by itself as much as the exponent indicates, then change the repre-
sentation back.  this is like the advantage of logarithms: if you're
multiplying many numbers together, then you convert all the operands
once to their logs, and you convert the final result back, but you
don't have to convert any of the intermediate results, so the cost
of converting to & from logarithm format is more than offset by
the cheapness of adding instead of multiplying.
now, how does montgomery representation make remaindering go away?
the basic idea is that when we're doing a long chain of modular
multiplications, we need to keep the intermediate products from
getting too big, but taking their remainders mod N isn't the only
way to keep them small.  montgomery's conversion just multiplies
each operand by the maximum operand-size, say 2^1024, modulo the
crypto-system's modulus N.  now, when we multiply two such trans-
formed operands, the product gets bigger than we want to keep around,
just as in normal modular arithmetic, but it's much easier to make
the montgomery representation's excess go away at each step.  the
heart of montgomery's theorem is the trick of adding a certain
simple multiple of the modulus N to this intermediate product,
making a modulus-N equivalent that happens to be a multiple of
2^1024 .  now, recall that this intermediate product is not a good
montgomery representation; it's too big by just this factor of 2^1024.
so, by throwing away the least-significant 1024 bits, we kill two birds
with one stone: we keep the intermediate product's size manageable,
and we keep the intermediate product in montgomery representation,
so it's ready for another round of montgomery-multiplication.  it's
very slick, but none of the explanations i've read, treat this
intermediate-size issue at all.

@_date: 2002-11-07 23:41:34
@_author: Don Davis 
@_subject: Did you *really* zeroize that key? 
i include below two parts:  a summary of the vuln-dev
thread, and a compiler jock's explanation of why peter's
 is the _only_ solution that reliably will work.
vuln-dev thread:
      (thanks to tim fredenburg sending this URL to me.)
summary:  programmers can obstruct dead-code elimination
in various ways:
   - use the volatile attribute (but correctly);
   o introduce dynamic dependency;
   + do the memset with an external call.
punchline:  the subtler or newer the obstruction,
the less likely we are to see that _all_ compilers
treat the obstruction correctly.  the safest route
is to code with obstructions that have long been
known to obstruct dead-code elimination.  hence,
wrapping memset() in an external routine is most
likely to work with various buggy compilers.
synopsis:  * peter posted the same message as he posted to
   the cryptography list, appealing for new support
   from the compilers;
   * syzop said, "didn't happen w/ gcc 2.95.4";
   * michael wojcik suggested:
     define an external call that does memset's job,
     so as to defeat dead-code elimination    * dan kaminsky suggested: introduce dynamic [runtime]
     dependencies;
   * dom de vitto said, "use the volatile attribute";
     * kaminsky replied:  compilers are more likely
       to reliably respect dynamic dependency, than
       to correctly support the volatile attribute;
     * pavel kankovsky replied, "volatile" is mandatory
       in the standard, so it's ok to trust it;
     * peter also replied to kaminsky:  the dead-code
       elimination problem seems specific to gcc 3.x .
       the underlying problem is unreliable support for
       standard features and for standards compliance.       * michael wojcik explains (to peter, pavel, and
       kaminsky) why "volatile" isn't as good as his
       external call:
         - "passing a volatile object to memset
            invokes undefined behavior"
         - "access to volatile objects may be
            significantly slowed"          - "volatile seems like the sort of thing
            broken implementations may get wrong"
       michael also argues that more compiler support
       isn't necessary, since the standard provides
       effective features.
since i used to build compilers long ago, before i got
into security work, i asked an expert friend (32 yrs of
compiler development) about what he thought of this
problem, and of the proposed solutions.  this guy, btw,
was the lead engineer for digital/compaq's fx32! runtime
binary translator for the alpha workstations, & he knows
a lot about optimizers.  he says that of the four
proposed solutions -
   *  dont_remove_this_code_you_bastard;
   * use the volatile attribute (but correctly);
   * introduce dynamic dependency;
   * do the memset with an external call;
- only peter's pragma can be expected to work reliably:
   * the c99 standard and its predecessors don't
     at all intend "volatile" to mean what we naively
     think it means.  specifically, in the hands of a
     high-end compiler developer, the spec's statement:
        "any expression referring to [a volatile]
         object shall be evaluated strictly according
         to the rules of the abstract machine"
     is really talking about what the compiler can
     infer about the program's intended semantics.
     a c99-compliant compiler _can_ legitimately
     remove a volatile access, as long as the compiler
     can deduce that the removal won't affect the
     "program's result."  here, "the program's result"
     is defined by the compiler's sense of what the
     "abstract machine" is:  the abstract machine
     is mostly defined by the language features, but
     can also take into account whether a debugger
     or specialized hardware are running during
     compilation & or runtime execution.
     for example, such a savvy compiler might leave
     our volatile-memory memset() call in place when
     the debugger is running (knowing that the debug-
     ger might want to view the zeroed key). but then,
     when the debugger is turned off, the same compiler
     could decide to remove the "dead" memset() call,
     because this won't affect the program's results.
   * standards-compliant compilers normally distinguish
     between "conformant" source programs and "noncon-
     formant" source programs.  for example, a noncon-
     formant program might be one that uses a deprecated
     feature.  with nonconformant source programs, the
     compiler can perfectly legitimately bend various
     compilation rules, especially so as to get better
     optimization results.   the idea is that the spec's
     strict rules and semantics only make sense for
     conformant programs.  so, in the case of "volatile,"
     a compiler won't necessarily be bound by the "rules
     of the abstract machine," unless the source program
     strictly conforms to the language spec's "best
     practice" definition of how a C/C++ program ought
     to look.    * with the most modern dynamic compilation techniques
     (my friend's specialty), the compiler re-examines
     & re-optimizes the executable program _at_runtime_ ,
     so external references and dynamic dependencies
     aren't intrinsic obstacles to code-motion during
     optimization, anymore.
   * finally, my friend gives the example of a compiler
     that might decide to make a copy of our key buffer
     at runtime, in pursuit of some optimization.  the
     compiler might have the program zeroize one copy of
     the key, but not the other copy.  as long as the
     program's end result turns out to be "correct,"
     such a bizarre trick can still fulfill the language
     spec.

@_date: 2002-09-04 18:45:46
@_author: Don Davis 
@_subject: Constructing "capability" URLs 
...
 ...
use /dev/urandom (the psudorandomly-amplified version
of /dev/random), and you can change the key more
frequently, without emptying /dev/random's entropy
buffer.  unless i'm missing something, /dev/urandom
is secure enough for your application.

@_date: 2002-09-04 23:03:02
@_author: Don Davis 
@_subject: new attack on des 
does anyone know of an on-line copy of this paper?
 A New Class of Side-Channel Attacks on DES,
Prof. Christof Paar, Chair for Communication Security,
Ruhr-University Bochum, Germany
Thursday, August 8, 2002, 1:30 PM, Atwater Kent, WPI, Room 218
[Joint work with Jan Pelzl, Thomas Wollinger and Hans Dobbertin]
About 5 years ago, a new approach for attacking cryptographic hardware was proposed. This approach is referred to as side-channel attack. It exploits information such as power consumption, timing behavior, or electro magnetic radiation to extract a secret key from a piece of cryptographic hardware. These attacks have been proved to be especially powerfull for reading "hidden" keys from smart cards.
This presentation introduces a new class of side-channel attacks against the popular block cipher DES. Power analysis is used to detect collisions within the DES algorithm thus combining a cryptanalytic approach with side channel evaluation. A step-by-step optimization of the attack is presented in order to increase the probability of a collision. It is shown that a collision within three adjacent S-boxes of DES can be found with as few as 135 encryptions (averaged over 10,000 simulated attacks with random keys) exposing detailed information about 18 key bits.

@_date: 2004-04-04 17:56:51
@_author: Don Davis 
@_subject: [Mac_crypto] Apple should use SHA! (or stronger) to 
hi, mr. reinhold --
there's stronger reason than the ones you cite,
to distrust md5 as a message-digest.  see these
old sci.crypt threads, and the google-search below,
for discussions of hans dobbertin's 1996 crack
of md5:
btw, in a phone conversation, dobbertin emphasized
to me that his attack only works when md5 is used
as a message-digest; it doesn't work when md5 is
used with a key to prepare a MAC.  he also mentioned
that while sha-1 may be vulnerable to an attack of
a similar style (because sha-1 is similar in struc-
ture to md5), he himself was forbiddden by german
law to work to cryptanalyze sha-1, because he worked
at that time for the german federal security service,
and so wasn't allowed to attack the USG's standard
ciphers.  now he's at ruhr university (in bochum),
but i don't know whether he's more of a free agent.

@_date: 2004-06-23 18:33:33
@_author: Don Davis 
@_subject: cryptograph(y|er) jokes? 
Q: How is a key-pair like a hand grenade?
A: You get two parts, there's no aiming,
   & it's hard to use safely.
Q: How are they different?
A: With a grenade, you throw the dangerous
   part away...
for a pictorial version, see the attachment.

@_date: 2004-03-25 21:40:32
@_author: Don Davis 
@_subject: Israeli coders, Arab testers 
from "the volokh conspiracy" weblog, a law professors' blog:
Eugene Volokh, 3/25/2004 04:02:38 PM Israeli coders, Arab testers: A reader writes, apropos
checking sensitive source code for sabotage:  I spoke to
[someone] from the NSA, about this subject a couple of
years back. As you probably know, although the NSA has
teams of cryptographers at its disposal, a large amount
of the successful interception it carries out is simply
due to exploiting software faults in communications soft-
ware. Consequently, in their other role, as advisor to
the DoD about communications security issues, they focus
on software assurance to an extent that often takes new-
comers by surprise.
The NSA used to have a requirement that only American
citizens should be allowed to work on sensitive source
code, because they considered there to be too great a
risk of backdoors being placed in the code by foreign
nationals . . . . More recently, because of the number
of H1(B)s and green cards in the computer industry, it's
been impractical for the NSA to insist on that. Instead,
what they've encouraged -- and this is the interesting
and quite clever part -- is that programmers and testers
should be of different nationalities. If you have Israeli
coders, get Arabic testers. If you have British coders,
get French testers. And so on.
A cute solution to the problem. But I don't know if it
ever worked. I suspect the NSA still insists, though,
that source code for sensitive systems be written by
American companies on American soil, even if it isn't
written by American fingers.Of course, even if the NSA's
program worked for the NSA, it would be pretty expensive
to adopt for the important source code and off-the-shelf
object code used by lots of other organizations -- many
of which are private companies -- that manage critical
American infrastructure. Nor am I sure that it would work
that well even if it were adopted. Still, it struck me as
interesting enough to be worth mentioning.

@_date: 2004-05-08 21:24:49
@_author: Don Davis 
@_subject: Security Architect Position at National Archives 
i talked to them.  the downside is that they want this
security architect to be the security administrator,
once the system is built...
