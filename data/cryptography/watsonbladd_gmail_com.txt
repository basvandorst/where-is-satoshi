
@_date: 2013-11-01 22:22:17
@_author: Watson Ladd 
@_subject: [Cryptography] What's a Plausible Attack On Random Number 
I'ld like to note that Ivy Bridge includes an on-chip random number
generator, VIA has made chips with that support before,
and various embedded devices have also had random number generators.
What's wrong with just using them?
This whole conversation is as pointless as discussing the best way to
use a crowbar to open a can when a can opener is
sitting right next to the crowbar.

@_date: 2013-11-04 20:46:05
@_author: Watson Ladd 
@_subject: [Cryptography] randomness +- entropy 
Where do seeds come from?
I'm sorry: Did the Mind your P's and Q's paper escape everyone on this list?
There are thousands of devices out there generating keys on first-power on
with insufficient entropy, with observable deleterious effects.
This problem needs to be solved, and the only way to do it is to find
or add sources of randomness to the hardware and have the kernel
use them, as well as a critical failure if they do not exist/are not sufficient.

@_date: 2013-11-05 19:04:27
@_author: Watson Ladd 
@_subject: [Cryptography] randomness +- entropy 
Nothing outside the kernel can determine if entropy has been added to
the kernel pool.
Furthermore, plenty of programs like gpg and openSSH would use it, and those
are the important ones where lack of randomness can hurt very badly.
And in the current situation the engineers and product managers have
no idea if the kernel
is collecting enough entropy.
Furthermore, the cost of adding a cycle counter on chip is much less
than of things that are selling points: built-in crypto
acceleration, etc.

@_date: 2013-11-10 12:09:56
@_author: Watson Ladd 
@_subject: [Cryptography] SP800-90A B & C 
I disagree with some of these comments, and agree with others, but I
think it would be productive to have a broader discussion of the
issues you raise (modulo
editorial foibles)
There are (broadly speaking) two different designs for random number
generators. NIST is using the physics+stretch approach: A low
bandwidth source of random bits, defined in 90B, periodically reseeds
a pseudorandom generator as in 90A.
The other design, exemplified by Yarrow, Fortuna, the Linux kernel
randomness subsystem, and others, uses large numbers of inputs of
unknown entropy, and attempts to distill a few bits of known entropy.
I believe that we have a much better handle on the first class of
designs from a cryptanalytic perspective then the second. In
particular the pooling design can fail in very subtle ways if it has
too few sources. By contrast the first approach is guaranteed by
design to have a seed from a random process if it works.

@_date: 2013-11-11 19:38:28
@_author: Watson Ladd 
@_subject: [Cryptography] SP800-90A B & C 
Such as the clock skew between the CPU and wall power, or sampling the
Johnson noise in a resistor, or
lots of other physical effects. If you don't trust your CPU designer
to add in a ring oscillator, add an external one and use
it. But why shouldn't the spec ask you to explain why what you are
doing is likely to get entropy into the system?
And if you don't like the spec, don't use it.

@_date: 2013-11-29 20:31:17
@_author: Watson Ladd 
@_subject: [Cryptography] Something weird about FIPS 140-2 
It being the day after Thanksgiving I decided to read crypto
standards. And in the process of reading FIPS 140-2 I came across
section 4.6.1, mandating a single operator and no preemption of
processes doing cryptography. How exactly could OpenSSL on a COTS
operating system ever meet the requirements of FIPS 140-2 given that
Could someone deign to explain to me what exactly FIPS validation
means for software?
It appears that is nothing beyond an excuse to implement DUAL_EC_DRBG.

@_date: 2013-10-03 18:59:20
@_author: Watson Ladd 
@_subject: [Cryptography] AES-256- More NIST-y? paranoia 
This is complete and utter bullshit if you can count, or make big enough
random numbers if you cannot. Read "Cryptography in NaCl" or
Rogaway's analysis of authenticated encryption modes in standards if you
don't believe this is a solved problem in theory, or heck, even the GCM or
CCM standards. Or Rogaways OCB paper.
PRP security does not imply security in the related-key model. It also
doesn't imply sPRP security. But you don't need it.
Now, if you are making a claim about block cipher constructions, go show me
why this matters by publishing an attack or some theoretical analysis about
related keys leading to good attacks in a stronger setting.
Watson Ladd

@_date: 2013-10-03 19:00:37
@_author: Watson Ladd 
@_subject: [Cryptography] encoding formats should not be committee'ized 
What part of the Chomsky hierarchy do you not understand?
What part of running computations on untrusted data which amount to Turing
machines sounds like a good idea? The trivial DDOS, or the oh-so-amusing
use as part of a distributed computing service?
What dangers of multipass computation on potentially ambiguous data do you
think are worth the extra connivence?
And let's not forget the bugs that context-sensitive grammars invite.

@_date: 2013-10-08 09:13:20
@_author: Watson Ladd 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
we are dealing with today were known at the time the standard was being
developed. RFID usually isn't that security critical: if a shirt insists
its an ice cream, a human will usually be around to see that it is a shirt.
AES will last forever, unless cryptoanalytic advances develop. Quantum
computers will doom ECC, but in the meantime we are good.
Cryptography in the two parties authenticating and communicating is a
solved problem. What isn't solved, and behind many of these issues is 1)
getting the standard committees up to speed and 2) deployment/PKI issues.
Great big warning lights saying "Insecure device! Do not trust!". If Wells
Fargo customers got a "Warning: This site is using outdated security" when
visiting it on all browsers, they would fix that F5 terminator currently
stopping the rest of us from deploying various TLS extensions.

@_date: 2013-10-09 19:12:37
@_author: Watson Ladd 
@_subject: [Cryptography] Crypto Standards v.s. Engineering habits - Was: 
15 years ago is 1997. Diffie-Hellman is much, much older and still
works. Kerberos is of similar vintage. Feige-Fiat-Shamir is from 1988,
Schnorr signature 1989.
As one of the "Do it right the first time" people I'm going to argue
that the experience with TLS shows that extensibility doesn't work.
TLS was designed to support multiple ciphersuites. Unfortunately this
opened the door to downgrade attacks, and transitioning to protocol
versions that wouldn't do this was nontrivial. The ciphersuites
included all shared certain misfeatures, leading to the current
TLS is difficult to model: the use of key confirmation makes standard
security notions not applicable. The fact that every cipher suite is
indicated separately, rather than using generic composition makes
configuration painful.
In addition bugs in widely deployed TLS accelerators mean that the
claimed upgradability doesn't actually exist. Implementations can work
without supporting very necessary features. Had the designers of TLS
used a three-pass Diffie-Hellman protocol with encrypt-then-mac,
rather than the morass they came up with, we wouldn't be in this
situation today. TLS was not exploring new ground: it was well hoed
turf intellectually, and they still screwed it up.
Any standard is only an approximation to what is actually implemented.
Features that aren't used are likely to be skipped or implemented
Protocols involving crypto need to be so damn simple that if it
connects correctly, the chance of a bug is vanishingly small. If we
make a simple protocol, with automated analysis of its security, the
only danger is a primitive failing, in which case we are in trouble

@_date: 2013-10-21 21:17:00
@_author: Watson Ladd 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
And with a wire that costs 25 cents connecting the wallwart to the
interrupt pin we've got 60 Hz (50 in Europe) uncorrelated to our local
clock. Measure the drift, and in 5 seconds we are done collecting 250
bits of entropy (one bit per interrupt).
2^40 is not a lot for your colleges in Fort Mead. Imagine this is host
key generation on hosts on large, important, networks. Piddling with
the MAC key won't keep out anyone who seriously wants to get in.

@_date: 2013-10-24 13:06:35
@_author: Watson Ladd 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
I'm actually horribly underestimating it, if you understand what the
source actually is.
It's not the frequency variations of the mains, but the phase
variation of our local clock.
That's not where the randomness is coming from. Let's assume that the
mains frequency is a precisely divided
down to 60 Hz, according to an atomic clock/optical clock, and let's
assume our clock is 60 MHz, not in a PLL with
the mains. Then each time we have an interrupt from the mains we
should have seen one million ticks of our local clock.
But thanks to the noise in our local oscillator, we won't always see
exactly one million. It's a selling point if the jitter is less
then one picosecond, which is one millionth of our frequency. Mirable
dictu, this is the last bit of the tick count.
Watson Ladd

@_date: 2013-09-15 07:48:13
@_author: Watson Ladd 
@_subject: [Cryptography] real random numbers 
Clock skew is very well understood. In particular, I've thought about
using the DC-to-DC converter's oscillator in the power supply to
trigger interrupts, and use the usual timing based thing. The timing
is influenced by the amount of voltage that is on the
grid at a particular time, component variations, and thermal noise.
Phase noise is real!
More importantly, this provides a continuous stream of about 300k
deskewed random bits per second,
available as long as power is around.
Watson Ladd

@_date: 2013-09-16 16:52:04
@_author: Watson Ladd 
@_subject: [Cryptography] The paranoid approach to crypto-plumbing 
value is not much harder than finding ... pairs of messages".  This has
some surprising implications.  In particular, Joux uses it to show that, if
F(X) and G(X) are cryptographic hash functions, then H(X) = F(X) || G(X)
(|| is concatenation) is about as hard as the harder of F and G - but no
cryptographers. :-)
going to use a specialized combined encryption and authentication mode, you
might as well use counter mode (with, of course, required authentication).
 For the encryption part, counter mode with multiple ciphers and
independent keys has the nice property that it's trivially as strong as the
strongest of the constituents.  (Proof:  If all the ciphers except one are
cracked, the attacker is left with a known-plaintext attack against the
remaining one.  The need for independent keys is clear since if I use two
copies of the same cipher with the same key, I end up sending plaintext!
 You'd need some strong independence statements about the ciphers in the
set if you want to reuse keys.  Deriving them from a common key with a
one-way hash function is probably safe in practice, though you'd now need
some strong statements about the hash function to get any theoretical
result.  Why rely on such things when you
authentication is.
The right procedure would be to use a universal hash function together with
counter mode encryption. This has provable security relatable to the
difficulty of finding linear approximations to the encryption function.
But I personally don't think this is much use. We have ciphers that have
stood up to lots of analysis. The real problems have been in modes of
operation, key negotiation, and deployment.
Watson Ladd

@_date: 2013-09-30 15:51:13
@_author: Watson Ladd 
@_subject: [Cryptography] NIST about to weaken SHA3? 
This isn't true: Keccak's designers proposed a wide range of capacity
parameters for different environments.
No, it is the Keccak construction with a different rate and capacity.
I'm sorry, but the tradeoffs in capacity and their implications were part
of the Keccak submission from the beginning. During the entire process
commentators were questioning the difference between collision security and
preimage security, as it was clear that collisions kill a hash as dead as
preimages. This was a topic of debate on the SHA-3 list between DJB and
others, because DJB designed Cubehash to have the same tradeoff as the
design NIST is proposing to standardize.

@_date: 2014-04-20 18:37:58
@_author: Watson Ladd 
@_subject: [Cryptography] It's all K&R's fault 
Why does it matter if we make copies in memory if they do not go to
unencrypted disk or can be seen by any other application, or leaked by
our application? Wiping memory and pinning to avoid swap assume that
1) the OS won't wipe memory between processes and 2) swap is
In particular, even if I don't save keys to disk because I've pinned
them, I save confidential documents to swap because my editor doesn't
know how to deal with them. And if I encrypt swap, there isn't any
reason that keys landing there is a bad thing.
Watson Ladd

@_date: 2014-04-27 17:24:59
@_author: Watson Ladd 
@_subject: [Cryptography] Because one TLS bug per month is just not enough 
Nope: this affects all implementations. It's an issue in the protocol.
Furthermore, it's the kind of issue that tools like Proverif can
detect, automating the sort of analysis that BAN logic or Yao-Dolev
asks you to do by hand.
The miTLS team discovered it while attempting to show that TLS was
secure. Previously Kerberos v4 had to get bumped to v5 because a
similar analysis found a similar issue.
Watson Ladd

@_date: 2014-08-10 10:55:45
@_author: Watson Ladd 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
Actually, letting in RC4 after it was cryptanalyzed was a mistake. How
did this happen? Stupidity: no one took the time to reevaluate the
ciphers in TLS 1.0 when moving to TLS 1.1. How did Triple Handshake
and the Renegotiation Bug happen? Extra complexity, and some
misfeatures, that made academic analysis far harder than it needed to
By contrast IKE2 was designed by Hugo Krawczyk, and adopted wholesale.
The result is far better (the rest of IPsec is still pretty bad: lots
of red buttons waiting to be pressed).
Have you ever sat down, examined the output of WGs, and tried to go
back from that to the process that produced them? It's pretty clear
that IETF WGs lead in a lot of cases to very poor designs, for a
number of sociological reasons similar to those inherent in design by
committee. The joke about compilers having n-1 passes, where n is the
number of people working on them, is pretty spot on. Now apply it to a
process with no structure.
(That (some) IETF standards are bad is not up for debate: DNSSEC, TLS,
probably dozens that haven't attracted attention).
There are a number of reasons I see for this: the first is that the
sort of expertise that makes Rogaway believeable and Joe Someone else
not is really hard to evaluate. This especially true when the argument
for the correct position is "Consider a multitape Turing machine A
limited to n oracle queries with advantage \epsilon in game
\mathcal{G}..." and the argument for the wrong position is "the MAC
might leak information", or there are subtle issues with arguments for
the wrong position.
The second is that it's very easy to think that your particular
feature or desire won't massively increase complexity. But if everyone
thinks this way bad things happen. At least in aerospace the thing
needs to fly with all the features, limiting the impact. But see the
F-35 Lightning II.
The third is it's very hard to make a complaint that "I don't have
confidence in this design" seem meaningful to people who don't
understand cryptography and the ease with which good seeming designs
can fail. People also become invested in the outcome of the product
far too much: there was an eight page report, not made public sadly,
about why TLS 1.0 should be sent back to the WG. But it was decided
that this wouldn't work, so it was better to push what we had.
Sentences like "not believed to be exploitable" should be red flags:
all too often they aren't.
Implementor feedback is often completely ignored. How someone thinks
dynamically validating that a prime is safe enough for Diffie-Hellman
is possible is beyond me: only if they hadn't implemented it, or seen
how long it takes, would the believe this to be possible.
It's to the point we have people openly speculating that some primes
are more "proven" than others in Diffie-Hellman. Newsflash: that's not
what cryptanalysts do all day. Network engineers should leave crypto
to the cryptographer, singular, who designs a solution to the problem.
Watson Ladd

@_date: 2014-08-19 06:38:44
@_author: Watson Ladd 
@_subject: [Cryptography] Encryption opinion 
cipher in
Did you miss BEAST? On a browser without 1/n-1 record splitting, with
certain extensions, we can steal cookies. The reason this isn't exploited
is everyone patched it.
MD5 collisions lead to a forged CA and Flame. Cryptanalysis of RC4 broke
WEP, and lead to the TJ Maxx breach. Bitcoin brain wallets are snarfed up
by bots watching for keys derived from common passwords. Keyloq got busted
wide open.
Some of us, including myself, work for organizations which have nasty,
nasty enemies. To the extent that we have "good enough' security on the
Internet, our ability to be secure becomes limited because we can't use
technology everyone is assumed to have. Single DES cryptanalysis is cheap:
if enough people could get in trouble if you had it, it would get done.
As for the original poster, I have found issues in many crypto libraries
that lead to all sorts of badness. It might look like it works, but ends up
dumping secrets all over the place.
Your average script kiddie isn't going to advance RC4 cryptanalysis when
they can use default passwords and the promise of dirty pictures to get
credit cards. The same applies to developing exploits. Would you say buffer
overruns aren't a problem because they are hard to exploit and so script
kiddies don't?

@_date: 2014-08-26 20:06:16
@_author: Watson Ladd 
@_subject: [Cryptography] Encryption opinion 
And what exactly can the IETF do about it? Mandate that people not use
C unless absolutely necessary for system utilities?  Force people to
use capabilities so downloading a screensaver of dancing ponies
doesn't automatically mean handing over everything you do to an
attacker? Implement echo servers correctly?
The solutions to these problems emerged in the 1950-1960's, and as
late as the 1980's the Orange Book made the sort of system that CapOS,
Coyote, and Ethos attempted to make the gold standard. No one did it
for a variety of reasons, but you certainly could with enough work,
make a single-user system with the property that all access to
documents is authorized by a UI action, or use Keychain/factotum style
auth for all SSH private keys.
The reasons for non-adoption of these solutions are complex, and the
IETF deserves a lot of blame for failing to understand the Chomsky
Hierarchy and the consequences for validation, particularly when
different implementations need to produce the same results on all
inputs for security.
Security is a subset of correctness: I don't care that viewing a cat
picture can cause grey and multicolored splotches on my screen within
the area the picture says it occupies, but I do care that it can lead
to my tax returns being exfiltrated to Somalia, or all my contacts
being rounded up by the Secret Police. Somehow, in 60 years of
software engineering practice, we have not yet learned the nature of
the problem: ensuring a system of rules has a property.
Watson Ladd

@_date: 2014-02-03 21:12:55
@_author: Watson Ladd 
@_subject: [Cryptography] Random numbers only once 
As DJB pointed out on another listhost, one only needs 256 random bits
once, and can then use a PRF to generate an indefinite number forever.
Why does /dev/random not do this and so avoid blocking after startup?
It wouldn't be that hard to write to a defined block of a disk image
these 32 random bytes.
Watson Ladd

@_date: 2014-02-04 16:59:37
@_author: Watson Ladd 
@_subject: [Cryptography] Random numbers only once 
But that only justifies blocking exactly once after boot.

@_date: 2014-02-04 19:09:58
@_author: Watson Ladd 
@_subject: [Cryptography] Random numbers only once 
Why not provision the fresh install with entropy on the machine
flashing the image?
There weren't two different oscillators? No radio which could tune to
an empty band?
No DRAM amplifiers which could be fooled into reading a high entropy state?
Wait, why does DNSSEC validation require entropy?
I'm still not sure how running with low entropy fixes this, except
for a funny definition of fixed.
DNSSEC for pool.ntp.org?
Do we need to make an authenticated NTP, or would a signed clock
protocol work fine for this?
I've thought on and off about this problem, but it is tough given the
latency requirements for NTP,
and the fact that server state in a UDP protocol can have interesting effects.

@_date: 2014-01-03 11:57:14
@_author: Watson Ladd 
@_subject: [Cryptography] nuclear arming codes 
The test ban treaty doesn't use verification with covert channels an
issue. Instead they drop seismographs into wells, then cap the well
with concrete. The seismograph can send back whatever info it likes:
it's in a block of concrete. Tampering is prevented because the
seismograph will detect any drilling, and the blast of a nuclear bomb
within a very large radius.
For the arms control treaties they use statistical methods AFAIK.

@_date: 2014-01-15 21:07:06
@_author: Watson Ladd 
@_subject: [Cryptography] Boing Boing pushing an RSA Conference boycott 
Because your job as a cryptography company is not to be tricked, and
to exercise the judgement your client is hiring you to exercise in
their interests. If you can't or won't do it, you shouldn't take the
money of your customer. 2007 should have seen an immediate rush to fix
the problem. But instead they left their clients vulnerable to a known
weakness for 6 years, in exchange for millions of dollars. If they
were accountants or lawyers, they would be in jail for something

@_date: 2014-07-22 18:47:13
@_author: Watson Ladd 
@_subject: [Cryptography] The role of the IETF in security of the 
the net?
On Tue, Jul 22, 2014 at 12:46 PM, Stephen Farrell
It really isn't: trying to add curve25519 to TLS has turned into a process with
no end in sight, because Microsoft has provided an alternative to
twisted Edwards curves of slightly different
twisted Edwards curves. For all the talk of "rough consensus and
running code" TLS 1.3 has been very controversial,
and with very little running code.
The agility in TLS was useless: both options were fatally flawed, and
this was documented in the RFC.
Similar flaws were documented in early IPsec versions earlier that
year. It took 14 years to fix this bug.
The downgrade to SSLv3 was known from the start, and wasn't fixed until now.
Tcp encryption was demonstrated: it shouldn't be that hard to start
with what was implemented and demonstrated.
Yet the WG can't get its charter together, and I have no idea what
that conversation is about. How many of the people
on that list write TCP stacks?
ECC for PGP is still not implemented by anyone other than a recent
in-browser(!) javascript implementation.
OpenPGP is unanalyzable, and PKIX is PKIX.  The complexity of PKIX is
particularly painful as it puts a lot of nasty
(usually C) parsing code into the TCB.
DNSSEC has been in the works for longer than I have been alive. It
still isn't deployed. Despite two email encryption standards,
S/MIME and PGP, most email is unencrypted. Even using the mail
provider as a PKI, or having a file of email public key pairs
would solve this problem. The file wouldn't even be that big compared
to the English Wikipedia.
Of the three IETF protocols I've found for establishing connections
between two parties authenticated with public keys, the only
one that is correct is the one no one uses, and the most important one
is the worst one. The IETF has never taken cryptography
seriously: the channel binding drafts are based on a misunderstanding
of what key protocols can promise, and in fact require
an impossible protocol (two-party fair coinflip) to be completely secure.
I've found major errata in RFCs documenting algorithms. Guidance on
implementations is nowhere to be found. It takes work to
do this badly.
This is not confined to the security area: NFS vs. 9p is instructive.
Most of the innovation in security tools is happening outside of the
IETF, even when it could benefit from standardization as a means
to ensure multiple implementations and to drive more adoption.
Watson Ladd

@_date: 2014-07-27 10:57:41
@_author: Watson Ladd 
@_subject: [Cryptography] IETF discussion on new ECC curves. 
Picking from 6 curves means that 1/6 curves has to be weak to force the choice.
Picking a BADA55 curve means 1/2^32 curves has to be weak. The rigidity issue
is much less bad than you make it out to be.
By contrast, rigidly picking curves ignoring performance means that
people will use
the small curve instead of the big curve, when they would prefer the
medium curve.
These curves are all about speed.
There is: performance. People do not enable DHE suites in TLS because
of performance concerns.
Curve25519 was put forwards for TLS because of performance. I don't
see why 2^512-x would be
picked: E-521 is stronger and faster, and we've got some very nice alternatives.
Watson Ladd

@_date: 2014-03-06 17:21:14
@_author: Watson Ladd 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
And if you want to get it right, why use C? A bug in your C code could
look at places it shouldn't, and thus break the whole thing apart.
There is no reason today to not use memory-safe languages or isolate
crypto code from code that can break its security.

@_date: 2014-03-06 22:55:19
@_author: Watson Ladd 
@_subject: [Cryptography] GnuTLS -- time to look at the diff. 
There is no reason why either function needed manual resource control.
The absence of memory safety and nonexistence of a genuine bool type
made both functions impossible to understand. Staying in C, applying
the Power of Ten would have worked fine. But because C forces manual
memory management cleanup gotos have become accepted style.
Correctness simply wasn't a priority.
Watson Ladd

@_date: 2014-03-08 16:39:20
@_author: Watson Ladd 
@_subject: [Cryptography] RC4 again (actual security, 
Sorry, the bytes out of RC4 are not IID. This means an RC4 encrypted
plaintext reveals information to an attacker. This has been known
since 2000 when Fluhrer and McGrew published on this subject.
Watson Ladd

@_date: 2014-03-08 21:40:54
@_author: Watson Ladd 
@_subject: [Cryptography] Fwd:  GnuTLS -- time to look at the diff. 
The JPL coding style is a more expanded view. In particular, hashing
should never fail: it's computing a function, therefore doesn't need
to allocate any resources. Letting it return failure breaks several
rules in the JPL coding style, in particular the preference for total
functions. The apple bug resulted from handling errors that should never happen.
The gnu TLS verify.c code uses nonstandard control flow. Had the goto
cleanup been written as cleanup, followed by return, it would be clear
that the wrong value was being returned. Several times a comment is
made that a function returns only 0 or 1. If that's the case, write
the function to return only 0 or 1 or make assertions to force that. A
single assertion before return ensuring the returned value was in
scope would have turned this into a bug, instead of an exploitable
So applying a "set of best practices" clearly didn't work, while
turning comments into assertions where possible, using simple flow
control, and validating inputs and outputs of functions would have
prevented both of these issues.
Watson Ladd

@_date: 2014-03-09 15:26:59
@_author: Watson Ladd 
@_subject: [Cryptography] RC4 again (actual security, 
Well, here is the paper about RC4:
 It turns out that for
plaintext which is highly compressible, using a Verbiti-style decoding
algorithm recovers quite a bit given a small number (2^20) of
identical ciphertexts. Add in the use of Javascript to make requests
automatically, and you can decrypt responses that should be
RC4 is broken in TLS. The attack looks like BEAST or Lucky13, and is
intermediate in complexity in terms of number of connections gathered.
In any setting you learn a lot about the plaintext sent. Turning it
into a "real break" is not surprising. Why take the risk?
AES-GCM is tough to do in software on things like mobile phones or
embedded devices. I can run Chacha20 in constant time efficiently on a
$1 8 pin DIP ARM-M0. AES-GCM is a bit tricky there.
Furthermore, I read AGLs blog post and never saw him describe ChaCha20
as a fallback for cryptographic reasons. He indicated that it was a
matter of performance and hardware support between AES-GCM and
Chacha20-Poly1305, and I think most cryptographers would agree with
Watson Ladd

@_date: 2014-03-29 19:22:54
@_author: Watson Ladd 
@_subject: [Cryptography] OpenPGP and trust 
Aren't MACs okay? I believe the 2003 ARRL handbook explains that each
command to an OSCAR is suffixed with an authentication code to prevent
Watson Ladd

@_date: 2014-11-14 14:26:01
@_author: Watson Ladd 
@_subject: [Cryptography] ISPs caught in STARTTLS downgrade attacks 
Most people don't run their own mail servers, and there isn't a per user
key discovery mechanism yet. One can easily be designed: it just hasn't
Most PGP users don't use 1024 bit RSA. Interesting how DNSSEC proponents
never mention that this is what they want to use.
Watson Ladd

@_date: 2014-11-16 09:58:55
@_author: Watson Ladd 
@_subject: [Cryptography] ISPs caught in STARTTLS downgrade attacks 
I think you seriously underestimate the value of specialization, and
the degree to which this specialization exists in cryptography. There
is no reason the cryptocat author couldn't have sat down with someone
who knows cryptography at the start, and avoided massive bugs. I'm not
a usability expert, I'm merely okay at programming, and I have no idea
about the pathologies of massive operations. Even in cryptography, I'm
not an expert on cryptographic protocols: I can read much of the
research, and can design protocols accordingly, but nothing
groundbreaking. I'm entirely ignorant of cryptanalysis: I know what's
out there and that's it.
DJB is the rare exception: an expert in secure C coding (don't code in
C: it's not worth it) and in high-performance cryptography. But if you
look at his research you will see that cryptographic protocols are not
his forte: he's not the person you should ask about replacing TLS.
Hugo Krawczyk has a number of publications in the world of protocol
design, but few in implementations. Neither of them is Lars Knudsen,
who did a lot of cryptanalysis research, but very little in either
implementation or protocol design.
I haven't even touched usability, the 800-pound elephant in the room
and the reason why Johnny Can't Encrypt. The set of people who are
good enough at cryptography, secure coding, and usability to do
interesting things is small, possibly empty. That's what collaboration
is for. But the first part is telling people "no, you don't know
everything: have me handle the part I'm good at and you the part
you're good at".
DANE here might not be so bad: the alternative is no authentication
whatsoever. But some of the other suggested uses actually are steps
backwards, like proposed uses in TLS 1.3 Paul Wouters hasn't seriously
analyzed the runtime of batch NFS as far as I can tell: this 30 day
rotation is based on an analysis ignoring standard speedups.
The result of "cypherpunks write code" is similar to the "real men
drill holes" philosophy. It doesn't matter how much code you write, or
how many holes you drill if it doesn't solve the problem. It just gets
in the way. If people can't use PGP, it doesn't matter how good the
design is: it doesn't work. If RSA-1024 can be broken by custom
hardware, it doesn't matter how unusable DNSSEC is: the whole thing is
Watson Ladd

@_date: 2014-09-26 20:29:20
@_author: Watson Ladd 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
That's actually a feature, not a bug. We want to be able to steal
wallmart.com or goldmansachs.com from a domain squatter and transfer
It also solves lost names: if someone loses the keys for xkcd.com,
fpqc.com is not as valuable as a replacement. This is not the case for
If blockchains kept the list of valid SSL certs for domains, a list
anyone could add to, they would be a stronger mechanism for achieving
The current CT mechanism uses a different mechanism to achieve public
consensus on which certificates are out there, which as you not is not
as strong.
The "right approach" is to use a blockchain to monitor what certs are out there.

@_date: 2014-09-26 20:34:15
@_author: Watson Ladd 
@_subject: [Cryptography] The Trouble with Certificate Transparency 
Funny, I didn't realize that Israeli intelligence was involved in
Diginotar or Turktrust. And if the CAs run the logs, we can expect
that they will be vulnerable to the same bugs as the CA, as people
will use the same sort of systems. It's not an unreasonable question
to ask: what if both trusted people are the same?

@_date: 2015-08-02 12:55:36
@_author: Watson Ladd 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
On Sun, Aug 2, 2015 at 4:33 AM, Stephen Farrell
That way, no one can actually argue about what's going on, as they
have no idea what sources you are examining and how you are drawing
the conclusions you are drawing. Unless we talk about specifics, we
can't actually come to grips with what is, as opposed to what we think
Yes, it's true that some people will not consider the costs of any
change to deploy. But that's not the situation we're talking about.
Rather its when you have 2 proposals, one with running code, and
another with no running code, both very similar properties, and yet we
can't pick the one that works. Not reacting to known defects until it
is too late is a distinct failure mode.
We know that the NSA spent millions of dollars on influencing
standards. We know some of these activities involved NIST and ISO. Why
wouldn't they also target IETF? We also know that the TLS WG
repeatedly ignored email messages concerning holes TLS that were later
exploited, as well as papers and documents outlining these problems
for years. The process needs to stand up to subversion.
Are you capable of determining backdoors in protocols yourself? No.
Does the IETF process catch crypto vulnerabilities in protocols? No.
So why are you confident that you can find disruption of the process
by intelligence agencies? I agree it might seem more visible, but
consider that the complexity of X509 lead to holes, and X509 was
pushed by governments heavily over simpler options. Was this part of
the thinking? (The NSA also shapes how grants are paid out in the US
to discourage some kinds of research: this is openly discussed on
their website)
John Kelsey had no reason to believe the NSA was pulling anything over
on him. But ultimately he ended up defending the inclusion of
Dual_EC_DRBG, despite having questioned it internally. Consider that
as the prototypical example of an attack.
But we know that some IETF protocols have had better track records on
security than others, and that many changes
Can you point to a correctly designed protocol done by rough
consensus? It's clear most successful protocols have actually been
designed by small teams, and adopted through consensus. Asking a
committee to design something is a proverbially bad idea.

@_date: 2015-08-06 09:05:10
@_author: Watson Ladd 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
nearly all the time.  The other just barely works in the best of times and
often breaks down under its own weight.  It's pretty easy to tell when the
first system has been sabotaged, but really hard to tell when the second
one has been sabotaged.
second system than the first.
Notice how IEEE 743 and RnRS don't have these problems. Then look at the
authors and compare what they know to what the people making crypto
standards know, and you'll have the explanation.
I'd never design controls without knowing the theory or a house without
sesmic engineering. Somehow we've accepted this in crypto standards.
them because it's a general issue, but we're talking about one of those
"rough consensus and working code" rooms where dedicated engineers do what
they most want to do - create new Internet systems.
trove of data and hide it.  Not particularly well but well enough to make
the attacker work at it.  The attacker will have to actually do something,
instead of just hoovering.
spotted - so it will be reserved for those moments and targets where it's
worthwhile.  It's not as if the attacker cares that much about being
spotted, but embarrassment is best avoided.
data set, down to 99% closed, over some time and some deployment curve.
attitudinal inspiration from Hollywood, or other enlightened sources like
NYT on how to retaliate in cyberwar (OPM, anyone?) [0].  Which is to say,
it decides to fight back.  Game on.
protocol.  How?
protocol in mind, then all the attacker has to do is:
balanced between the original and the challenger.
prototypes out there, just gotta pick one that's sufficiently different.
In this case I can think of 3 others without trying, and 6 people on this
group could design 1 in a month.
Call in favours.  So many people out there who would love to pop in and
utter an opinion.  So many friends of friends, willing to strut their stuff.
preserved, then it stops all forward movement.  This is a beautiful
attack.  If the original side gets disgusted and walks, the attacker can
simply come up with a new challenger.  If the original team quietens down,
the challenger can quieten down too - it doesn't want to win, it wants to
preserve the conflict.
uttering an opinion as they would if asked.  The attack simply uses the
time-tested rules which the project is convinced are the only way to do
these things.
rough consensus, it's almost a gilt-edged invitation to the attacker. The
attacker isn't so stupid as to not use it.
a marker on the map - you simply can't do a security/crypto protocol under
rough consensus in open committee, when there is an attacker out there
willing to put in the resources to stop it.

@_date: 2015-08-08 15:18:38
@_author: Watson Ladd 
@_subject: [Cryptography] SHA-3 FIPS-202: no SHAKE512 but SHAKE128; 
That's missing part of the story. NIST had eliminated CubeHash on the
basis that its preimage resistance was insufficient, in favor of
Keccak parameters which had been designed for their ridiculous
requirements. This elimination happened going into the final round.
Once that requirement was dropped, they would have had to redo a bunch
of things to be fair to everyone.

@_date: 2015-08-14 07:07:18
@_author: Watson Ladd 
@_subject: [Cryptography] Why is ECC secure? 
It's true that given phi I can factor the modulus. But it's not known
that being able to decrypt an RSA ciphertext that I can factor the
modulus. Some schemes like Rabin-Williams are provably equivalent to
factoring, but as far as I know a similar result hasn't been shown:
the best results in this direction involve unrealistic models of
algorithms, and there are proofs that certain classes of reduction
would make factoring easy.

@_date: 2015-12-01 06:27:30
@_author: Watson Ladd 
@_subject: [Cryptography] where is the weakness? related-key, 
This is not quite right. It was always obvious (to the right people,
for definitions of obvious) that EtA is always good, as Rogaway's
comments on IPsec show. The failure to understand this was one of
people not taking seriously or even knowing the mathematics involved.

@_date: 2015-12-07 17:54:38
@_author: Watson Ladd 
@_subject: [Cryptography] Long-term security (was Re: ratcheting DH 
You assume that packets take an easily predictable path across the
entire Internet that isn't modifiable by attackers. This is just
wrong: BGP does weird stuff every day because of accidents.
Or you could write code that doesn't turn any bug into remote code
execution, so we've solved all of those problems. Then you have to
worry about protecting authorization keys.
Let's stop pretending these problems aren't solvable. They are.

@_date: 2015-12-23 17:02:07
@_author: Watson Ladd 
@_subject: [Cryptography] Post your IKEv1 and IKEv2 packet captures from 
Dear all,
We've learnt a lot about the way the backdoor seems to work, but still
are missing some basic details. To help solve this mystery, I need
packet captures from vulnerable and non-vulnerable devices doing IKE,
along with information about the version and configuration.
Any little bit helps. Let me know off the list if you have them, and
please try to make some. Omitting IP addresses is fine, and probably a
good idea unless you upgrade anyway.
Watson Ladd

@_date: 2015-12-25 07:14:05
@_author: Watson Ladd 
@_subject: [Cryptography] Juniper & Dual_EC_DRBG 
Breaking an accelerator chip (still unnamed: would be great to know
what we had to reverse) gives you access to all products using that
chip. Break an OS gives you everything running that OS, including
pure-software lower end entries, and devices that change vendor.
There's plenty of reason to do both.
I'm working on this, but the IKE negotiations and packet forming are
not done by the accelerator but the CPU. That's enough to recover the
keys. Furthermore, there are many systems involved, some very low end.

@_date: 2015-02-01 13:34:24
@_author: Watson Ladd 
@_subject: [Cryptography] best practices considered bad term 
Huh? We know quite a bit about cryptography from actual
cryptographers, which ignoring lead to exploitable holes. In
-Statistical problems in RC4 output resulted in stealing cookies.
-The need for randomization of CBC inputs->BEAST
-The need for formal models of key negotiation->Triple Handshake, the
renegotiation vulnerability,
-The failure of generic security for MtE->Lucky13, POODLE, the SSH
equivalents, XML encryption vuln
-PKCS 1.5 encryption->periodic bugs in TLS implementations
-SPA and DPA/timing attacks
-Failure to validate input points -> problems all over the place
We also know that RSA is significantly slower at reasonable security
levels then ECC, and that AES-GCM outperforms hash-based constructions
in hardware and now in software on recent Intel processors, while
Poly1305 does so across a wider range of machines. Of course, this is
all covered with a level of BS from people who aren't cryptographers.
Explain why Flame needed to use an MD5 collision then. Or how about
"pass-the-hash"? What about the poor random number generation in
Android leading to bitcoin thefts through Bleichenbacher attack? Or
all the attacks on OpenSSL in shared hosting environments (think AWS)
with key recovery as the bottom line?
The NSA is exploiting IKE v1 Aggressive mode with PSK.
Has any software bug ever resulted in liability for the vendor? I
don't see companies rushing out to stop writing network servers in C,
even though we all know that writing them in Java, Go, or Ada would
make buffer overflows unexploitable.
Watson Ladd

@_date: 2015-02-17 08:42:21
@_author: Watson Ladd 
@_subject: [Cryptography] Equation Group Multiple Malware Program, 
Consider the difference in motivation between the NSA and your usual
bunch of malcontents from Elbonia. The Elbonians don't have a target
list: anything that gives them credit card numbers is good. The NSA
has a target list: they need the crush depth of the Russian's latest
submarine, they can't hand over Putin's dry cleaning bill and get
credit. As a result, the NSA is going to invest more in not being
detected, and in keeping their presence beyond a few months.
However, academic cryptographers and the NSA had an interest in very
similar problems. When we see things like the MD5 collision in Flame,
they look very much like the attacks that were academically known, but
a bit different. When we see Skipjack or the DES S-box changes, it
makes a lot of sense. What is true is a lot of the more theoretical
work (Brent Water's stuff, verifiable computing) isn't relevant to the
NSA or GCHQ, as we know from declassified reports from CRYPTO. At the
same time, we don't spend years trying to crack North Vietnamese rotor
machines to figure out exactly what they were doing during the Tet
Offensive, for example.

@_date: 2015-02-24 10:26:44
@_author: Watson Ladd 
@_subject: [Cryptography] information, Shannon, and quantum mechanics 
No, Denker is right. You can perform a reversible computation with
zero entropy gain. Even if you erase a bit, that might not cost
energy, but can cost entropy. See for example
Watson Ladd

@_date: 2015-01-28 10:43:40
@_author: Watson Ladd 
@_subject: [Cryptography] Introduction to EC that is actually an 
On Jan 28, 2015 10:08 AM, "Phillip Hallam-Baker" to a rather deeper degree than hitherto. Or rather, at a lower level.
Certicom one and don't actually explain a damn thing. They just draw a
couple of squiggles and put a line through them.
Read Silverman and HEHCC.

@_date: 2015-03-05 10:18:15
@_author: Watson Ladd 
@_subject: [Cryptography] FREAK attack 
SSL/TLS have used?
protocol changes needed to deploy.  But more importantly, if "pick a
cipher" isn't part of the initial connection, does it become "pick a
version"?  Or does the client connect 'n' times, with the associated TCP
The myth is that cryptographers in 1995 did not understand the proper order
of encryption and MACing. The reality is they did. Furthermore,  the RC4
results date back to 1995 as well.
Cryptanalysis has had far less of an impact then imagining that protocol
design isn't cryptography.

@_date: 2015-03-05 19:28:30
@_author: Watson Ladd 
@_subject: [Cryptography] FREAK attack 
Bellare-Nampare and the Vaudenay padding oracle attack were both known
in 2001. Both were major events at CRYPTO and both refer to the
encrypt then MAC result as folklore. It's also an easy exercise if you
know the definitions, hence why it was never published separately.
The proceedings of the biggest conference in cryptography is hardly an
obscure place to look when writing a comprehensive book on
cryptography. I think the absence of this subject says more about the
books than the obscurity of the subject.
Watson Ladd

@_date: 2015-05-11 20:14:40
@_author: Watson Ladd 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
PRESENT, LED, and a few other proposals have been made in this area.

@_date: 2015-11-01 06:49:26
@_author: Watson Ladd 
@_subject: [Cryptography] [FORGED] Re: How programming language design can 
Have you ever read Appel's compiler book? The myth of
"machine-independent assembler" ignores even the most basic of tricks
like register allocation.  For instance every assembler coder will
omit redundant loads and stores, and so will a compiler. But this
breaks the relation between stack locations and variables, in some
cases quite badly. There are lots of other examples, like instruction
scheduling, strength reduction, etc. A lot of the "machine independent
compiler myth" stems from the poor quality of C compilers.  Why do you
care what the assembly looks like, instead of what it does?
(And yes, this pass removes code. Assignments are completely
obliterated in an SSA transformation, and further munged by graph
What you should do is think about the semantics of the programming
language, and realize compilers preserve those semantics. So what's
being called for is an introduction of 2's complement semantics for
signed integer overflow into C. Alternatively you could pick a
language that provides those semantics, or write a C compiler that
provides these semantics. But this whole complaint that "the compiler
doesn't do what I think it should" completely ignores what compilers
for some languages have *always* done.

@_date: 2015-11-15 07:19:28
@_author: Watson Ladd 
@_subject: [Cryptography] Nvidia- one Tflop could change the rules quicker 
Let's consider the amount of work required to compute a discrete log
in a group of size 2^256 with only the inversion automorphism
efficiently computable.  It's 2^128 bit operations. We'll assume each
bit operation costs the same as a floating point operation: of course
serious attackers design hardware. Then 1 teraflops is 2^40 of these
operations per second, leaving 2^88 device-seconds. This sounds
scarily small, so let's have another 2^40 of these machines. They
would have to compute for over 34 millennia to solve a discrete
It's amazing what basic arithmetic can do.

@_date: 2015-11-21 19:53:13
@_author: Watson Ladd 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on key 
To compare two lists with 2^64 elements requires only 2^64 operations,
not 2^128. Furthermore, using distinguished point methods there are
further savings. What DJB points out is that standard methods for
reversing some values of a one-way function
can be applied to AES(K, 0).

@_date: 2015-11-22 21:42:46
@_author: Watson Ladd 
@_subject: [Cryptography] Bin Laden satphones 
The information Bush claimed was classified and leaked was not that
bin Laden used Iridium, but that the US could track him with it. This
fact doesn't appear in the second link in your email. Obviously bin
Laden knew what kind of phone he used! I haven't dug up the Washington
Post article the 9/11 commission cited as containing this detail to
check whether or not the fact appears, but it doesn't appear in the
Time article.
This article also misses the first phrase in Bush's sentence,
discussing the phone and not the capability.

@_date: 2015-10-08 12:23:52
@_author: Watson Ladd 
@_subject: [Cryptography] [openpgp] OpenPGP SEIP downgrade attack 
with PGP
Does this provide the right agreement semantics for both sender and
recipient? It certainly doesn't solve the security issues with CFB mode.

@_date: 2015-10-16 17:33:05
@_author: Watson Ladd 
@_subject: [Cryptography] Fwd: freedom-to-tinker.com: How is NSA breaking 
The difference between "completely implausible calculation of size
2^120" and "somewhat plausible 2^80" matters far more than the slight
gains from being able to reuse work across targets. That's not always
true: brute force of symmetric keys does gain somewhat.

@_date: 2015-10-17 06:59:28
@_author: Watson Ladd 
@_subject: [Cryptography] Fwd: freedom-to-tinker.com: How is NSA breaking 
back to
Snowden did not have access to BULLRUN, which protects fact of
cryptanalysis against a protocol.
Scope doesn't fit: most PRNGS reduce to AES, or were never used.
off, I'd
Wrong timeframe. NSA curves was in 1993.
The NSA is very interested in communications carried over large VPN
installations like diplomatic communications. That might be enough to
justify it. Also the computer doesn't go away afterwards: can still do
other things with it.

@_date: 2015-10-19 19:47:14
@_author: Watson Ladd 
@_subject: [Cryptography] Other obvious issues being ignored? 
There were plenty of guidelines from NIST and others that said that
1024 bit DH should not be expected to provide any security after 2014.
One example is from 2007. You even had Suite B guidelines pointing out
ECC was much more efficient with higher security.
(one example: This is not true. The size of the numbers that need to be smooth
depends on the modulus, which Pohlig-Hellman doesn't reduce.

@_date: 2015-10-20 07:41:27
@_author: Watson Ladd 
@_subject: [Cryptography] Other obvious issues being ignored? 
Let's remember that the RSA keys are generated by another party. The
protocol can't protect against stupidity of another party, but should
ensure that it isn't possible to affect the security of connections
with other honest parties. That was the real problem with TLS here.
Likewise, checking DH parameters for validity has obvious problems: it
doesn't actually prevent small subgroup confinement unless you ban DSA
style primes. The right solution is to design the protocol so that
isn't required. Protocols can and should reduce the amount of work
necessary to be sure implementations are safe.

@_date: 2015-10-23 15:14:39
@_author: Watson Ladd 
@_subject: [Cryptography] Other obvious issues being ignored? 
STACK UB
Are you claiming that one cannot write a pointer overflow check in portable
C, or the checks people do write are broken?
This paragraph is just wrong. In executions where overflow does not happen,
the gcc produced binary will match the behavior of the abstract machine in
the C spec. What the compiler is warning about is optimizations only safe
if overflow doesn't happen which it cannot determine doesn't ever happen.
the 64-
No, you just refuse to accept the burden of writing C. C programs avoid
enumerated bad behavior. Go make a compiler for a safer C instead if you
cannot write C correctly.

@_date: 2015-10-24 16:44:25
@_author: Watson Ladd 
@_subject: [Cryptography] [FORGED] Re: How programming language design can 
Does anyone have a minimal example on this list, and can point to the
formal semantics and the standard with enough detail to demonstrate
the existence of a gcc bug here?

@_date: 2015-10-26 13:18:19
@_author: Watson Ladd 
@_subject: [Cryptography] composing EC & RSA encryption? 
NTRU has been around since the early 90's, has small key sizes, and
reasonable performance. There has been some doubt about the hardness
of some ring based lattice problems due to the fields that are used,
but slight variations on NTRU solve these problems, while, as far as
we know, not introducing new ones.
We don't need postquantum signatures until quantum computers exist.
But data you generate and want to secure now until even after quantum
computing requires postquantum encryption.

@_date: 2015-10-27 06:36:57
@_author: Watson Ladd 
@_subject: [Cryptography] Other obvious issues being ignored? 
So go use Java, which defines 2's complement semantics for integer
overflow. Or Go, or Modula-2, or Ada, or half a dozen languages without C's
issues here, and that can fix lots of other issues (bound checks, etc).
There's no reason to write emails complaining about this when you can fix
the problem instantly.
Or you could learn how to write overflow checks correctly. We don't
complain about null pointer dereference being a bad idea or manual memory
nanagement, we change languages instead. Use tools which ensure UB won't
happen like FRAMA.
Also there is no such thing as a compiler that doesn't optimize. Toy
compilers might not do sophisticated dataflow analysis, but they certainly
will do graph coloring and omit redundant stores and loads.
TL;DR use Ada.

@_date: 2015-09-03 19:31:25
@_author: Watson Ladd 
@_subject: [Cryptography] Introducing the phone-directory certificate 
What exactly is a X509 certificate, that enables it to "vouch", and
what does it actually mean? The answer of course is that whatever
entity appears in the certificate desires that this server be
recognized as controlled by it. A great deal of complexity in X509
like policy mapping was meant to support something more, with no
understanding of how useless it would be.

@_date: 2015-09-30 18:20:47
@_author: Watson Ladd 
@_subject: [Cryptography] Insecure Chip 'n' PIN starts tomorrow 
about shifting liability away from the banks.
Is the relevant payment regulation shielding consumers being changed? No.
fraud so long as I don't have to pay. That's what went wrong in the UK
Dodge, executive vice president of the Retail Industry Leaders
Association.  But thats not what American consumers are getting, and thus
far banks have gone to great lengths to blur the lines between the two
distinctly different transactions.
they are in helping the retailers out.
issuers to use chip n PIN only; but they never did.'

@_date: 2016-04-30 15:57:57
@_author: Watson Ladd 
@_subject: [Cryptography] Mathematics of variable substitutions? 
See any book on algebraic geometry which proves the genus is a
birational invariant.

@_date: 2016-08-06 14:43:35
@_author: Watson Ladd 
@_subject: [Cryptography] Generating random values in a particular range 
That second method is known as rejection sampling and was invented by
John von Neumann.

@_date: 2016-08-24 13:05:50
@_author: Watson Ladd 
@_subject: [Cryptography] "NSA-linked Cisco exploit poses bigger threat 
kind of
language".  You
everywhere, and
got to
issues at all.
Consequence of short buffer in java: a crash. In C: epic pwnage. All the
other bugs still exist in C programs. Java just closes a huge swath.
will come around.

@_date: 2016-02-07 11:49:42
@_author: Watson Ladd 
@_subject: [Cryptography] Basic auth a bit too basic 
Logging out doesn't really help. Let's consider this hypo.
I find that corporation A is using an insecure product B where a CSRF
or XSS attack will lead to me getting credentials I want. Problem:
people rarely log into product B, as its some sort of payroll/tax
system that gets checked maybe once a year by most employees.
Solution: phish. Send an email asking them to click on a link to check
their direct deposit information. The link redirects their browser to
correct website, so it looks exactly right. I have however thrown up a
popunder that will start mounting the CSRF attack. Eventually the
victim does log in.
Importantly I have to solve this problem regardless of whether
sessions are expiring, or people aren't logging in often.
For XSS if the XSS is reflected users will be prompted to log in.
Typically this will result in a redirect to the original URL, causing
things to work again. It's not 100% guaranteed that you can evade
this, but roadbump not locked door.

@_date: 2016-02-19 20:27:59
@_author: Watson Ladd 
@_subject: [Cryptography] Apple 3rd Party dilemma 
customer's phone.
customer's explicit consent, then they'd be out of this mess.
Not really: the owner of the phone has agreed to the search, and the FBI
wants to use physical access for a firmware reset.
provides the govt "most favored nation status": if you as a customer
provide your data to *any* third party, then the govt will claim access, as
well.  (I believe that this is the modern version of the old "Lord of the
Manor" privilege, which allowed the Lord of the Manor access to any maid in
his territory who wishes to marry; for this reason, I suggest that the 3rd
Party Doctrine be renamed the "Government Rape Doctrine", which might help
to speed its demise.)
That's not true either. All the 3rd party doctrine holds is that you do not
have a 4th amendment interest in the possessions of another, including
information you gave to them. They can still contest any searches, and the
warrant requirement doesn't go away.  The third party doctrine simply says
that if you give me evidence of a crime, I can hand it over to the
government and you can't stop me.
Comparisons to rape are simply ridiculous.
to remain strongly encrypted in such a way that no 3rd party can gain
access.  (Homomorphic encryption, anyone?)
completely insane, since it doesn't trust the computer's own owner?
order to protect the user's information, then so be it.  The good news is
that IoT chips are getting really cheap.

@_date: 2016-02-23 08:43:36
@_author: Watson Ladd 
@_subject: [Cryptography] eliminating manufacturer's ability to backdoor 
RTFA, in particular note 2 on cryptography.  You can bring your phone
with you and use it and not be an arms smuggler. Furthermore, the
question is about what the national legislation says: Wassenaar is not
Does anyone actually know of a case where BIS denied a license since
2001 or so to cryptography exports without changes?

@_date: 2016-02-27 15:31:07
@_author: Watson Ladd 
@_subject: [Cryptography] From Nicaragua to Snowden - why no national 
keen on other nations mandating their crypto.
Because Rijndael is such an American name. The AES was the result of an
open international competition.
Other contests like Nessie have not produced standards that people want.
What's the advantage of national ciphers over AES? Just being different?
US, with grudging support of their close allies.

@_date: 2016-02-27 21:30:54
@_author: Watson Ladd 
@_subject: [Cryptography] From Nicaragua to Snowden - why no national 
If companies actually want to deploy them because they have savings in
speed and power or security gains they will. That's the story of ChaCha20
and Curve25519. That this hasn't really happened with national ciphers
shows the complete absence of a need for them.
What changed about the AES when the US standardized it that makes other
countries not want to use it?

@_date: 2016-03-25 11:42:45
@_author: Watson Ladd 
@_subject: [Cryptography] On the Impending Crypto Monoculture 
It was actually considered. The problem is that many sites would have
problems getting new certificates, so we had to make sure signature
based auth would work.

@_date: 2016-11-26 07:06:43
@_author: Watson Ladd 
@_subject: [Cryptography] Use of RDRAND in Haskell's TLS RNG? 
Have you looked at the RDRAND circuit and the on-chip power
distribution network? Your claimed "simple power droop attack" depends
on the output impedance of the power supply and the variance in the
current consumption caused by your instructions. Both are potentially
knowable: did you do the work to know them? Then you have to explain
how your "simple" attack avoids the on chip health checks.
Does /dev/random actually mix the entropy correctly? Does /deve/random
protect against malicious sources? Actual history indicates neither of
these assumptions are true.

@_date: 2016-11-29 11:08:21
@_author: Watson Ladd 
@_subject: [Cryptography] [FORGED] Re: OpenSSL and random 
built, and installed OpenSSL.  A handful of distributions also do that, and
bundle it with their release. For a variety of understandable reasons, said
distro's are always out of date.
bell like this to go off to let them know when something is wrong.
or swamp us with email or perhaps fall back to plaintext.
of entropy.
They have RDRAND. Silent failure is not a good idea. Can any user of
OpenSSL be sure the random number generator is properly set up?

@_date: 2016-10-03 16:36:11
@_author: Watson Ladd 
@_subject: [Cryptography] French credit card has time-varying PIN 
three years.
worthless, and that's a huge blow for criminals.
generates unique values for less than forty-two days, not three years.
thirty-five times.  Nonetheless, it's a step in the right direction.
I have a list of all the PINs everyone is using. Good thing you only have a
limited number of tries before getting locked out.

@_date: 2016-09-12 15:48:31
@_author: Watson Ladd 
@_subject: [Cryptography] Secure erasure 
If only there was a widely used embedded language designed by the DoD with
built-in bounds checks, widespread compiler support on different
architectures, and in GCC.
Maybe it's even named after a woman.

@_date: 2016-09-16 16:01:58
@_author: Watson Ladd 
@_subject: [Cryptography] Ada vs Rust vs safer C 
languages including Ada and Rust. But there is a vast mount of code already
written in C. Converting all of it or even a large fraction seems hopeless.
For comparison what would it take to make a safer C?
do with the large number of undefined behaviors in C. Since the dogma is
that undefined means the compiler can do anything its developers want, what
would it take to develop a supplemental specification that defines the most
concerning undefined behaviors? What would it then take to develop compiler
that meets those specifications? If the Free Software Foundation might be
convinced to help. If not, GCC, or parts of it, could be forked. There must
be some programmers out there with compiler chops that would find this kind
of project interesting. Perhaps a Kickstarter campaign might be helpful.
Defining undefined behavior shouldnt affect most existing programs.
Compilers can't introduce bounds checks without changing pointer
representations. That will break calling conventions and hardware. You
could get around this, but it would be painful, particularly when functions
want to change the endpoints of pointers (like allocators).
code, and programers, to new languages.

@_date: 2016-09-17 10:41:07
@_author: Watson Ladd 
@_subject: [Cryptography] Ada vs Rust vs safer C 
languages including Ada and Rust. But there is a vast mount of code already
written in C. Converting all of it or even a large fraction seems hopeless.
For comparison what would it take to make a safer C?
make a faster C.
do with the large number of undefined behaviors in C.  Since the dogma is
that undefined means the compiler can do anything its developers want, what
would it take to develop a supplemental specification that defines the most
concerning undefined behaviors? What would it then take to develop
compiler that meets those specifications? If the Free Software Foundation
might be convinced to help. If not, GCC, or parts of it, could be forked.
There must be some programmers out there with compiler chops that would
find this kind of project interesting. Perhaps a Kickstarter campaign might
be helpful. Defining undefined behavior shouldnt affect most existing
using tcc instead of gcc is probably already a huge win.
C code, and programers, to new languages.
silently emitting stupid code) would be huge win.
That's not what compilers are doing. They carry out transformations valid
in the absence of undefined behavior. Really the only big one here is
signed overflow, for which there already is a gcc flag to wrap and some
compilers will trap.
to optimize anything, just a completely straightforward translation of C
into assembly) would likewise be a huge win.
Has this lead to security bugs? No. Forget the nonsense of secure erasure
and realize operating systems clear memory between users and programs.
internally between T* v and T v[c], and likewise distinguish between
*(v+offset) and v[offset], and add bounds checking in the latter case.
Yes, this violates the C standard, but so what?  The C standard is stupid.
Please cite chapter and verse. Bounds checking is legal as the C memory
model is not a flat address space. The keyword is derived pointer: you can
only legitimately access a memory region through pointers created certain
just like C but where v[offset] and *(v+offset) are NOT equivalent
operations, and deprecate the latter.
What semantics do you want here?

@_date: 2016-09-24 15:49:59
@_author: Watson Ladd 
@_subject: [Cryptography] Spooky quantum radar at a distance 
Picked up is one thing. Shoot down? If you don't have any
interceptors, you will be relying on SAM missiles. Vietnam-era designs
like the S-75 use shorter frequencies for technical reasons I don't
recall, and so will not be effective against stealth planes. Bistatic
installations cannot be easily mobile, which is where cruise missiles
come in.
Stealth is not about perfect undetectability, but about reducing the
effectiveness of long-range radar based weapons, which for physics
reasons have to use high frequencies. The engagement range of a
stealth aircraft is longer than that of its opponent, providing ample
opportunities to destroy the opponent first. You cannot fit an L band
antenna onto a SAM missile without serious size problems.
Watson Ladd

@_date: 2017-04-06 11:16:03
@_author: Watson Ladd 
@_subject: [Cryptography] Regulations of Tempest protections of buildings 
Your own damn fault. There is no requirement to own a radio capable of
receiving these transmissions.

@_date: 2017-07-02 13:43:59
@_author: Watson Ladd 
@_subject: [Cryptography] OpenSSL CSPRNG work 
Arc4random should not be mistaken for a CSPRNG.  It's a good PRNG, but
at this point there are enough attacks on it that it's not really good
enough for cryptography anymore.  So it should not be certified as
cryptographically secure - there is no "pretending" about it, and it is
not "gaming" the auditing process.
On the other hand, given some particular permutation of 256 elements,
its stream of output is entirely repeatable.  So it's fine as a PRNG for
repeatable sequences.
Backwards compatibility: it is really ChaCha.
                                Bear
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2017-07-07 07:46:46
@_author: Watson Ladd 
@_subject: [Cryptography] OpenSSL CSPRNG work 
This is not a problem on recent x86: just use RDRAND. We need more CPU
makers to do the same, and more efficient designs for doing it.

@_date: 2017-06-28 22:39:15
@_author: Watson Ladd 
@_subject: [Cryptography] OpenSSL CSPRNG work 
I would strongly suggest only using /dev/random or /dev/urandom to
seed the top level generator. On Windows there is a separate API for
the same thing. Other sources are not guaranteed to be random, and
ultimately the OS knows far more than you do.

@_date: 2017-03-19 12:25:29
@_author: Watson Ladd 
@_subject: [Cryptography] Crypto best practices 
It makes two passess to be nonce-misuse resistant. I don't understand
what "brittleness" you complain about: it doesn't fail
on nonce reuse the same way CTR mode does. The reason why people pick
CTR is parallelizability, not mathematical elegance.
Streaming is inherently dangerous as the application can use data
which has not been authenticated yet. Packetizing into small
authenticated packets is the way to go here.

@_date: 2017-11-17 11:07:10
@_author: Watson Ladd 
@_subject: [Cryptography] Is ASN.1 still the thing? 
IEEE754 issues are encoding-agnostic.  This kind of thing comes up all
the time in JSON tooling, in ECMAScript, in RDBMSes, and many other
things besides.  S-expressions wouldn't be immune.  If you want floating
point numbers to interop and round-trip then all implementations must
use arbitrary precision floating point software implementations.
This is not exactly  true. IEEE floats don't come with a wire format but
you can serialize and deserialize the fields in the float and that is
specified to work. Formats using other bases can work with the right high
precision print routine.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2017-11-17 12:36:09
@_author: Watson Ladd 
@_subject: [Cryptography] Is ASN.1 still the thing? 
That's not the problem. The problem is representing IEEE745 floats and
serializing and deserializing That IEEE745 floats might not represent
every number you want i
If your serialization doesn't know about floats, it won't work with
floats. If your source and destination are using different
representations why on earth would you expect that to work?
What should be the case, is that your destination gets the closest
representable approximation to what your source wrote. But that won't
round trip: how could it?

@_date: 2017-09-12 17:33:57
@_author: Watson Ladd 
@_subject: [Cryptography] Chrome & Firefox protecting users against 
Doesn't cleaning it up and mothballing some CAs reduce the scope of
audits? If Symantec had issued new browser certs only from on CA, and
put all the others outside the scope of the BRs by mothballing them,
they wouldn't have nearly as many problems as they do now.

@_date: 2018-03-24 21:44:13
@_author: Watson Ladd 
@_subject: [Cryptography] Does RISC V solve Spectre ? 
Doing this bakes in details of what execution units are available and their
latencies into the generated machine code. This is acceptable for
specialized DSP designs, but not acceptable for CPUs where a wide range of
CPUs should all get good performance on a wide amount of precompiled
software. Most software has a small number of live variables in each basic
block and unpredictable branching: speculative execution is necessary to
access parallelism.
"Man is born free, but everywhere he is in chains".
