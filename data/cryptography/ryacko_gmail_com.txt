
@_date: 2014-08-13 16:07:18
@_author: Ryan Carboni 
@_subject: [Cryptography] cryptography Digest, Vol 16, Issue 11 
As long as data isn't being manipulated, it is safe and secure. Problem is
that we aggregate files onto one drive, use a relatively low entropy
password to generate a key, and we have no idea if our hardware is secure,
or if the file encryption system is properly implemented.
Veracrypt is based on Truecrypt, but there's no backwards compatibility.
This lack of cross-compatibility forces you to trust a team of programmers,
no way to cross-check.
Novel forms of cryptography will be used to create new algorithms safe from
new methods of crypt-analysis. It's a guessing race, and partly why
Skipjack was found to be so vulnerable, a new form of cryptanalysis was
discovered. AES-2 is more likely to appear than triple AES, unless security
margins drop to 2^80 or something dangerous. Skein is a good example of the
new methods that are coming up, no S-boxes, simple implementation. To quote
Bruce Schneier: ``I have never been a TEA fan, although 64 rounds can cure
a lot of sins.''
Skein has 72 rounds, although most of the them are broken.
AES has an attack against it faster than brute force. There will be
improvements, there always will.

@_date: 2014-08-14 10:51:47
@_author: Ryan Carboni 
@_subject: [Cryptography] cryptography Digest, Vol 16, Issue 11 
What kind of argument is this?
"Cryptography is all about safety margins. If you can break n round of a
cipher, you design it with 2n or 3nrounds." - Schneier
On this basis, Threefish/Skein is worthless. So is Skipjack.

@_date: 2014-08-18 23:09:41
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] STARTTLS for HTTP 
It would be secure against wifi eavesdropping. But worse it might instill a
false sense of security.

@_date: 2014-08-22 17:18:30
@_author: Ryan Carboni 
@_subject: [Cryptography] GPU farm ideas: Break SHA-1? 
It's all probabilistic anyway.  I'd wait after a new attack on SHA-1 that
reduces it to 2^52 first.

@_date: 2014-08-23 10:33:29
@_author: Ryan Carboni 
@_subject: [Cryptography] cryptography Digest, Vol 16, Issue 22 
Message: 10
"Nothing impressed me very much and all I discovered was that cryptology
The FBI cannot crack some pen-and-paper codes.
For short messages, it's probably not that difficult to use a
substitution-permutation network of only two rounds.  And use shorthand as
the alphabetic system. Would definitely reduce entropy.
And use John Young's system of grammar.

@_date: 2014-08-23 10:32:42
@_author: Ryan Carboni 
@_subject: [Cryptography] "Re:  [cryptography] STARTTLS for HTTP" 
that you don't treat HTTP over TLS as if it > were HTTPS.  It's
unauthenticated. And the end-user isn't really supposed > to be led
into thinking that the user-agent is making things secure.  The >
rules for handling cookies, for example, don't let them become "secure
It's a hard concept to wrap your head around unless you're a hardcore
HTTP > geek.  You have to think about what the HTTP/2 spec says,
carefully. It's > an implementor's document, not an end-user document.
to use > HTTP over TLS because they want as much encryption as
possible. Chrome has > said they will not do it because they want as
much authenticated encryption > as possible. IE has said no, but seems
to be thinking about yes. I haven't > heard what Opera's said, if
anything. And Safari is, as usual for Apple, > keeping things to
themselves. > > It's definitely in a state of flux. And trying to
guess what the browsers > will do is very much the n-body problem,
because they all affect each other > as they call compete for market
share. > >         /r$ > > -- > Principal Security Engineer > Akamai
Technologies, Cambridge MA > IM: rsalz at jabber.me Twitter: RichSalz > >
Firefox users are probably going to keep
using Firefox.Chrome users are probably going to keep using
Chrome.Opera users use Opera because of it's nice
little features.
Firefox users are probably going to keep using Firefox. Chrome users
are probably going to keep using Chrome. Opera users use Opera because
of it's nice little features. IE users are likely using a pirated
version of Windows and live in China.
 The marginal difference
between Firefox and Chrome, beyond Chrome's sandbox, isn't
particularly great.

@_date: 2014-08-23 21:03:04
@_author: Ryan Carboni 
@_subject: [Cryptography] CSPRNG for password salt 
There is one counter program that never has collisions: Block ciphers in
CTR mode.
It is for this reason that I am disappointed that NIST didn't specify
non-cryptographic and cryptographic modes of operation for Rijndael. It'd
be superior to CRC32 in hardware.

@_date: 2014-08-24 11:05:02
@_author: Ryan Carboni 
@_subject: [Cryptography] "Re: [cryptography] STARTTLS for HTTP" 
Given the lack of any public study as to the psychology behind browser
choice, I suspect there's a core of followers that sticks to each browser.
In my opinion, Chrome is best for security (but it gets memory heavy if you
don't close enough tabs). Opera is best for baked in features. Firefox is
best it's add-on community (they fixed the memory leaks, but they keep
superficially increasing the version number). The only changes occur when
people change their own preferences. Not as a result of Browser features.
[obligatory crypto comment] Chrome has ChaCha20 for google websites,
reducing processer cycles spent on crypto. The great question of the day is
do people actually understand the relationship between cryptography and
battery life? It won't change speed of page load, unless the person is
using gigabit internet and uses triple-DES crypto.
Besides, the browser competition ended when IE added tabs. Tabs were a true

@_date: 2014-08-26 11:15:35
@_author: Ryan Carboni 
@_subject: [Cryptography] Which big-name ciphers have been broken in 
Is there any evidence that CAST5 is in any way inadequate?
People are upset with use of an "Antique" algorithm?  Why?
I would be upset with the use of an "Insecure" algorithm or
an "Untested" algorithm.  Into neither of which classes
CAST5 falls.
So, I say the burden of evidence falls on those requesting a
change here.  What is wrong with CAST5 that people want to get
rid of it?
64-bit blocks. CAST5 is only suitable for files no greater than 4 GB.
Although I haven't seen much cryptanalysis on an electronic codebook attack.

@_date: 2014-08-30 01:17:05
@_author: Ryan Carboni 
@_subject: [Cryptography] Made a modification to RC4 
Feed RC4 through a transposition cipher... essentially a single round
2048-bit block cipher.
S1: 256 permuted bytes, serves as the PRGA
S2: 256 permuted bytes, serves as the transposition cipher
S3: 256 empty values, serves as the output array
S4: 256 empty values, serves as the output array to rescramble the
transposition cipher
i := 0 (S1)
j := 0 (S1)
while GeneratingOutput:
    i := i + 1
    j := (j + S1[i]) mod 256
    swap values of S1[i] and S1[j]
    K := S1[(S1[i] + S1[j]) mod 256]
    output K to position S2[i] in S3
    XOR K and S4[i]
    if i = 255
        output S3
        while i > 0
            swap values of S2[i] and S2[S4[i]]
            i := i - 1
This should flatten the biases in the first 256 bytes of RC4. It should
also reduce the relationship between byte values and the internal state.
I call this XARC4.

@_date: 2014-12-09 09:08:45
@_author: Ryan Carboni 
@_subject: [Cryptography] Bitcoin networks surpasses 2^80 hashes per week 
Erm. How? To my knowledge you can't predetermine if a hash could
potentially collide.

@_date: 2014-12-15 14:33:49
@_author: Ryan Carboni 
@_subject: [Cryptography] Sony finding SHA1 collisions? 
Looks like you made an error in your script. I could create a SHA-1
collision easy:
H[1]: Message
H[2]: Message + padding

@_date: 2014-12-18 14:22:21
@_author: Ryan Carboni 
@_subject: [Cryptography] Fwd: 78716A 
Common Americans are no longer considered worth protecting as part of
national security.
 Mr. Carboni,
Thank you for providing the information below.  We have conducted an
initial search within the organization that is most likely to hold records.
That organization advised that the request, as worded, is overly broad.
Querying any of our organizations would likely result in the same
response.  The phrase ?malware transmitted through USB firmware? is overly
broad, such that any of our internal organizations would not be able to
determine which files to search or be able to conduct a search with a
reasonable amount of effort. Terms such as ?malware? or ?firmware? may turn
up in any number of NSA records and most likely would not be related to
securing home networks. Furthermore, added search without a clarification
of context and specific records sought, would incur significant fees which
would be passed on to you as an ?all other? requester.
  A large facet of the NSA/CSS mission is to protect National Security
(i.e. government, DoD, Industry partners) information systems.  In doing
so, this Agency provides guidance on Information Assurance security
solutions to our Industry and Government customers regarding risk,
vulnerabilities, mitigations, and threats.  While it is not part of our
mission to provide guidance on securing home networks, we may occasionally
post information on our website as you may recall from our letter. Our
Information Assurance Directorate (IAD) has provided some information to
the public that may be of interest to you.  Here are some additional links
that you may peruse:
(this is a recent article the does provides a link regarding malware)
  The last paragraph provides a video
link under ?IAD's Latest Security Guide Helps Customers Protect Home
Networks,? and there is also a fact sheet titled ?Best Practices for
Keeping Your Home Network Secure.? Since the information you appear to be
requesting (protecting home networks) does not fall under the purview of
NSA/CSS missions, continued search of our files would not be productive.
Your request will be administratively closed as an improper FOIA.  If,
after reviewing the information on our website, you wish to submit a FOIA
request on similar topic(s), please provide enough detail to allow for an
accurate and focused search.
Cindy B
NSA/CSS FOIA Requester Service Center

@_date: 2014-12-18 14:28:02
@_author: Ryan Carboni 
@_subject: [Cryptography] Sony "root" certificates exposed 
Ars most recently promoted a comment saying that salting reduces the speed
of a brute force password search by 1000x in an attempt to argue that the
recent hacking against Ars won't crack many passwords, using their KDF of
md5 several thousand times.
Naturally my password for Ars is at least 56 bits secure, so I don't think
a hacker is going to spend several thousand dollars just to crack a
password I use no where else.

@_date: 2014-12-22 18:47:54
@_author: Ryan Carboni 
@_subject: [Cryptography] Fwd: 78716A 
That's true. But they do in fact do research into malware, and it is
infact my right to request information for "personal noncommercial
use" which includes attempting to secure my computer.
If the government produced records on how to best design a tree house,
I am still allowed to request records on how to build a tree house. I
cannot force them to create new records, but for records they have
already produced, they have the duty and obligation to make a
reasonable search.

@_date: 2014-12-24 11:46:33
@_author: Ryan Carboni 
@_subject: [Cryptography] GHCQ Penetration of Belgacom 
3,000 gates might be too high, infact, given the recent BadBIOS malware,
it's entirely possible to alter a CPU's microcode. so 0 gates is possible,
hell, OS-level root kits are also possible
 you never know

@_date: 2014-12-24 13:33:44
@_author: Ryan Carboni 
@_subject: [Cryptography]  Certificates and PKI 
Given the ballooning of disk space, it would be trivial to store the
certificates of all the websites in my browser history. A certificate is
only what, 10 kb?  Say I visit, 1024 websites, that's only 10 MB of
certificates. This way software only have to check if a certificate is
revoked. And revocations could easily be distributed via a p2p network.
So, IMO, the best certificate system would be:
self-signed certificates, whose authenticity is confirmed by a network of
notaries a la perspectives.
revocations distributed by the original server and a p2p network.

@_date: 2014-12-24 14:22:44
@_author: Ryan Carboni 
@_subject: [Cryptography] Tribler also means you're an exit node? 
Tribler also means you're an exit node?
To quote:
I received two copyright notices from Comcast while letting Tribler idle.

@_date: 2014-12-28 15:24:56
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] NSA Attacks on VPN, SSL, TLS, SSH, 
my browser says it's 188 MB... am I being man in the middled?
-Ryan C.

@_date: 2014-12-29 22:48:19
@_author: Ryan Carboni 
@_subject: [Cryptography] Fwd: 78716A 
Records Requested: I request any information the NSA has on malware
transmitted through USB firmware.
I request this for personal, noncommercial purposes, particularly for
securing my own personal computer.
I authorize fees up to $20.

@_date: 2014-12-31 13:39:34
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] Snowden docs show none are 
============================== START ==============================
Makes it easier to launder documents stolen by other spies and given to

@_date: 2014-07-13 10:00:37
@_author: Ryan Carboni 
@_subject: [Cryptography]  hashes based on lots of concatenated LUT lookups 
A cryptocurrency that is resistant to centralization, botnets, and ASICs
(which is perhaps a form of centralization, but by a third-party).
The impossible trinity in economics is a fixed exchange rate, free capital
movement, and an independent monetary policy. I guess I just discovered the
impossible trinity of cryptonomics.
Personally, I theorize that half of the mining in Bitcoin is probably done
by SIGINT agencies. Bitcoin is far better for funding foreign freedom
fighters than suitcases full of hundreds.

@_date: 2014-11-06 16:02:17
@_author: Ryan Carboni 
@_subject: [Cryptography] Extending Hash length using hash tree 
Extending Hash length using hash tree
If I just rotated each node by one and rehashed the tree, could I achieve
the same cryptographic security while extending the size of the hash output?

@_date: 2014-11-29 01:51:25
@_author: Ryan Carboni 
@_subject: [Cryptography] XXTEA's mode of operation 
anyone know why XXTEA's mode of operation isn't more widely used?

@_date: 2014-11-30 00:55:12
@_author: Ryan Carboni 
@_subject: [Cryptography] [tor-talk]  Blogpost: CITAS, 
While my analogy and definition of security may not have been best
suited, nor is this reply, the point remains that there is nothing
special here for you as a corp. Anything you say that LE can provide
for *you* with honeypots can also be sourced internally or from the
open market and your subsequent call to LE to mop up upon discovery
of badness therein.
Revolutionary concept... but businesses could work together on their own
initiative. It's how inter-bank checking began.

@_date: 2014-10-02 18:08:00
@_author: Ryan Carboni 
@_subject: [Cryptography] Best Internet crypto clock ? 
Link to one of the following:
Or use Bitcoin block

@_date: 2014-10-02 23:29:48
@_author: Ryan Carboni 
@_subject: [Cryptography] Best Internet crypto clock ? 
"Each such value is sequence-numbered, time-stamped and signed, and
includes the hash of the previous value to chain the sequence of values
together and prevent even the source to retroactively change an output
package without being detected."
They are both block chains.
And they both include the time.

@_date: 2014-10-07 17:17:11
@_author: Ryan Carboni 
@_subject: [Cryptography] Creating a Parallelizeable Cryptographic Hash 
Hash trees are provably secure, and fastest on typical processors when

@_date: 2014-10-07 17:30:24
@_author: Ryan Carboni 
@_subject: [Cryptography] Do you think RC4 will become insecure for 2^16 
Do you think RC4 will become insecure for 2^16 encryptions of the same
plaintext or less? Such a weakness would be crackable. It could probably be
achieved if weak states were discovered. But I don't think it would be a
result of the current attack discovered in 2013 by Bernstein and Co.

@_date: 2014-10-08 00:15:08
@_author: Ryan Carboni 
@_subject: [Cryptography] Do you think RC4 will become insecure for 2^16 
I doubt it will ever be broken though. Attacks don't improve linearly, they
improve logarithmically as knowledge reaches the maximum attainable.

@_date: 2014-10-09 09:04:11
@_author: Ryan Carboni 
@_subject: [Cryptography] Best Internet crypto clock ? 
I think it is ludicrous to demand time be more precise then ten minutes, I
mean, if you're committing a crime and you're demanding bitcoins for
payment, I think it a printed out screenshot of the current block held up
in a photo would be the most reasonable.
A cryptoclock would be more precise than a newspaper in any case, which has
a granularity of one day.

@_date: 2014-10-20 17:35:49
@_author: Ryan Carboni 
@_subject: [Cryptography] Better Version of Triple-DES 
Might be wrong, but I think this would be a better version of TripleDES,
Have the first encryption be DES in CTR mode, the second encryption being
the data, and the third encryption being CTR mode again. Since CTR mode is
a stream cipher, it would be DES-X style key-whitening, except the full
168-bit key would be usable.

@_date: 2014-09-07 12:22:00
@_author: Ryan Carboni 
@_subject: [Cryptography] sunsetting SHA-1 in Chrome 
SHA-2 has a better security margin than SHA-1.
To protect against a collision attack which allows someone to pose as an
intermediate authority.
That reminds me, I gave a public comment to NIST, telling them that
SHA-3-224 is useless as everyone should phase away from 112-bit security,
and that there should be a SHA-3-160, since for most uses 80-bit security
is sufficient and is superior for terseness. They didn't listen, crudgy

@_date: 2014-09-16 10:45:20
@_author: Ryan Carboni 
@_subject: [Cryptography] List of Proven Secure Ciphers / Hashes 
Excessively secure and I suggest reversing the operations. Use single round
AES to encrypt the 3 nonce words and the single counter word. That reduces
the predictability of the inputs for ChaCha, increasing it's security equal
to that of CryptMT. And then hash the variables using ChaCha8.

@_date: 2014-09-17 08:05:13
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] Email encryption for the wider 
The majority of people are no more capable of GnuPG than understanding why
RAM can't be solely used on a computer.
GnuPG has some weird defaults that are difficult to change as well without
some command line commands.
Ultimately your system will have a major flaw: passwords are typically have
low entropy, and anyone with the same password will read the same mail
unless you concatenate a salt the user has to remember.
The ideal system would be to use Tor in conjunction with guerrillamail. Or
to use a preshared key with a block cipher, and hide the encryption (since
evidently you want to avert the attention of the NSA to be encrypting in
the first place) using steganography.

@_date: 2014-09-22 23:47:50
@_author: Ryan Carboni 
@_subject: [Cryptography] Just found about Even-Mansour 
Just found about Even-Mansour scheme. Simplest possible cryptosystem,
xor-permute-xor, and for a single round it is roughly as secure as half the
block size, while two rounds have brute force security. If one only desires
confidentiality against attacks faster then brute force, can't one generate
subkeys using RC4, and use a two round substitution-permutation block
cipher with key-dependent permutations and substitutions? Would only be
useful for communication or storage, not hashing.
Would be faster than AES, but AES needs to be secure against even
distinguishing attacks while consumer crypto doesn't need as much security.

@_date: 2014-09-25 18:09:26
@_author: Ryan Carboni 
@_subject: [Cryptography] Based on Even Mansour 
Based on Even Mansour, wouldn't even the most basic block ciphers be secure
as long as the key size was half of the block size?

@_date: 2014-09-27 17:37:17
@_author: Ryan Carboni 
@_subject: [Cryptography] Based on Even Mansour 
Even Mansour is secure against 2^(n/2) chosen plaintexts.

@_date: 2014-09-30 19:50:10
@_author: Ryan Carboni 
@_subject: [Cryptography]  new wiretap resistance in iOS 8? 
You know the funny thing is, we'd still be using DES today if they used a
64-bit key. By '84 they'd be able to start bruteforcing it, and in
mid-2005, there'd be an AES competition. But there'd be a large probability
that everyone would be using 64-bit keys as a result of obsolete browser
 Instead everyone is increasingly using large-key crypto that the NSA
cannot break. But the NSA still finds other ways. Stuxtnet was one way. I
guess we shouldn't use USB anymore.
I wonder if the government ever looks to the future. They're supposed to,
roads don't yield dividends immediately, and neither does bonds.

@_date: 2014-09-30 19:52:49
@_author: Ryan Carboni 
@_subject: [Cryptography]  Just found about Even-Mansour 
============================== START ==============================
 I'm just saying, the bare minimum of security a block cipher is capable of
is half of it's block size. Thus if one uses a 256-bit block cipher with a
128-bit key, it would never be "theoretically" broken.

@_date: 2015-04-04 01:27:33
@_author: Ryan Carboni 
@_subject: [Cryptography] OPENSSL FREAK 
surely 90% of the labor cost is assuring cross-platform compatibility?

@_date: 2015-04-06 09:11:58
@_author: Ryan Carboni 
@_subject: [Cryptography] Fwd: OPENSSL FREAK 
What do you want, he's part of the IETF TLS faction that thinks RC4 is
insecure, because one guy is selectively using math to attack RC4 in a
fashion no one would ever actually attempt.
I'll just reiterate what I previously posted to this mailing list:
But whatever.

@_date: 2015-04-13 11:47:58
@_author: Ryan Carboni 
@_subject: [Cryptography] upgrade mechanisms and policies 
Don't be silly, many servers don't allow more than five algorithms in SSL
A better version of TLS wouldn't be one that has less algorithms, but one
that negotiates better, and one that cannot be easily attacked when
negotiating an algorithm.
Also, I believe RC4 is a perfectly adequate method of encryption of media

@_date: 2015-04-15 14:12:26
@_author: Ryan Carboni 
@_subject: [Cryptography] Fun and games with international transaction 
currencies)
2 things: How will the NSA be able to acquire bitcoins using it's massive
ASIC black budget?
2. Also, how will people be able to acquire bitcoins in the first place?
Proof of stake is a great idea, problem is, how do you distribute it?
Initially it's not going to be worth anything, and hoarders will
destabilize the currency.
Economics is more important than cryptography in designing a currency,
although both are required for viability.

@_date: 2015-04-15 21:37:17
@_author: Ryan Carboni 
@_subject: [Cryptography]  upgrade mechanisms and policies 
Cryptography is a mature science. Cipher algorithms degrade far more
gracefully than you think.  Linear and differential cryptanalysis are much
more difficult using modes other than ECB or CTR. And even if there is a
full round break, brute force is usually faster and easier, as is currently
the case for DES and AES. (anyone have any idea how much a differential
attack against single-key DES would cost in monetary terms?)
Hash algorithms have also improved to the point that I do not think there
ever will be a malicious collision with SHA-256 (although I'm sure in
twenty years there'd be some form of full round break).
My approach is this: media files are large in volume and much of their
computation overhead is from encryption, when encrypted. In some cases,
there is overhead from compression, but if you're running your own
optimized servers, you're probably disabling compression served from files
from servers that work under a certain subdomain.
I believe there should be a flag called importance. If it is or isn't
important, that should be set on the server end. If the flag is set,
browsers should be fine in accepting low-secure ciphers... including NULL
encryption and RC4.
Because for most files exchanged over the internet, authentication is more
I mean, for instance. Do you think this email should be encrypted, or
simply authentificated?

@_date: 2015-04-15 21:54:33
@_author: Ryan Carboni 
@_subject: [Cryptography] Fun and games with international transaction 
currencies)
The two things are intrinsically tied to each other.
Personally, I'd rather spend 10% of GDP on ASICs as opposed to 10% of GDP
on the financial sector, but that's just me.

@_date: 2015-04-16 12:16:55
@_author: Ryan Carboni 
@_subject: [Cryptography]  upgrade mechanisms and policies 
OH NO, I MUST GET THE LIST MODERATOR TO PUT UP A ROBOTS.TXT FILE IN CASE
THAT HAPPENS
When 99% of the data you receive is a known plaintext, you are going to
have to deal with several trade-offs.

@_date: 2015-04-16 22:41:14
@_author: Ryan Carboni 
@_subject: [Cryptography] upgrade mechanisms and policies 
OTR is authed.
In any case, secrecy + integrity = confidentiality
Some concerns about man in the middle attacks involve manipulation of files
or injection. But much data shared does not need to be secret. So integrity
is only needed.
In anycase, my point was inspired by the recent Netflix announcement of
encryption. For end users on a desktop, there is so much surplus processing
capacity that cryptography is no longer an issue. Different story for
mobile (batteries), and rapidly expanding companies (razor thin profits).
I don't have much knowledge about costs of purchasing hardware accelerators
or how much throughput they have.
For personal reasons, I hope one day there will be a generation of IRC
using public key cryptography. Not SSL. User authentication integrated with
the login mechanism.
Afterall, on the internet, no one knows if you're a dog.

@_date: 2015-04-17 11:50:26
@_author: Ryan Carboni 
@_subject: [Cryptography] upgrade mechanisms and policies 
2011: Full biclique attack on AES.
AES likely has a security level equal to that of Skipjack, but I feel a
little itchy when AES and SHA-3 share some designers, and as attacks
against AES improve, inertia to keep AES increases.
I really want a cryptographic FPGA coprocessor for multicore CPUs. Many
processors already have integrated graphics.

@_date: 2015-04-22 23:56:56
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] Shamir Reveals Sisyphus Algorithm 
not a totally unreasonable amount of money...
just the size of the entire US IT budget.

@_date: 2015-04-28 19:25:43
@_author: Ryan Carboni 
@_subject: [Cryptography] upgrade mechanisms and policies 
Indeed.  But take the well-known case of SSL.  The industry bends over
Yeah, it would be nice if affidavits and background checks were used to
authenticate people applying for certificates.
If you want security solutions to be widely deployed, nothing
 If a standard is terrible, there can be three reasons:
1. Stupidity
2. Corruption
3. Greed
TLS with CAs could very well be any or all three. SSL did not standardize
padding. Corruption to allow state actors to violate trust (our CA was
accidentally hacked). You explained how greed could be a motive.

@_date: 2015-08-02 21:57:49
@_author: Ryan Carboni 
@_subject: [Cryptography] 420,000 devices connected to internet hacked 
Well, it's an old article, but as things move on, it seems like people are
seriously planning on creating an internet of things.
A billion new devices are connected to the internet each year.
On the plus side, the next internet census can be conducted much faster now
that we have so much more vulnerable devices.

@_date: 2015-08-12 23:34:45
@_author: Ryan Carboni 
@_subject: [Cryptography] Why is ECC secure? 
Quite bluntly, millennia have been spent towards prime numbers.
The history of ECC is quite short. The history of post-quantum prime
is even shorter.
Prime numbers came before modern machine-assisted cryptanalysis.
The thing that really makes me nervous is AES. The biclique attack
shows that attacks can be combined. The mix columns only provide
diffusion if each byte is not equal, as a result, the weak key
schedule prevent inter-round symmetry. AES seems to have too many weak
components. And comments in the Rijndael specification that "The
cipher is fully 'self-supporting'. It does not make use of another
cryptographic component, S-boxes 'lent' from well-reputed ciphers,
bits obtained from Rand tables, digits of  π or any other such jokes."
Or that "The polynomial  m ( x  ) (‘11B’) for the multiplication in
GF(2 8 ) is the first one of the list of irreducible polynomials of
degree 8, given in [LiNi86, p. 378]."
I even find Speck to be suspicious. Even SHA-1 is a block cipher, and
it is ARX. But the NSA says that without Threefish's design of several
sequential operations, they wouldn't have developed Speck. They
certainly have the resources to bruteforce every possible ARX function
to see if it meets any tests they themselves developed. There also
seems to be a persistent insistence on having as a maximum, 128-bit
block widths.
When there is a logical contradiction, suspicions must be raised and
items looked into. Math teaches reasoning, yes?
But for Dual EC, I think it is best to use Blum Blum Shub instead.

@_date: 2015-08-12 23:37:30
@_author: Ryan Carboni 
@_subject: [Cryptography] Speculation about Baton Block Cipher 
I think in modern terms, according to the above wikipedia page:
BATON is a family of authenticated encryption ciphers, with a variable
block width, and accepts a tweak as an input?
To think that since 1995 the NSA has a cipher that the civilian
cryptographic community is on the verge of accepting!
And this is before the AES competition as well!
It's only been 20 years anyway.

@_date: 2015-08-16 18:12:30
@_author: Ryan Carboni 
@_subject: [Cryptography] SHA-3 FIPS-202: no SHAKE512 but SHAKE128; 
A Rasperry Pi 2 can encrypt a million AES blocks per second using a single
thread. Can saturate the 100 megabit ethernet port on the chip (if one
includes packet overhead).
The Raspberry Pi 2 has reasonable and satisfactory performance.

@_date: 2015-08-16 22:35:33
@_author: Ryan Carboni 
@_subject: [Cryptography] Why is ECC secure? 
Why do you need public key cryptography for token binding? Does it provide
protection from passive eavesdropping? If so, why not use HMAC? Maybe I
would understand why public keys would be used if client certificates were
also signed, but otherwise I do not see Why is token binding secure?

@_date: 2015-08-18 10:18:30
@_author: Ryan Carboni 
@_subject: [Cryptography] Speculation about Baton Block Cipher 
Baton has:
12 byte block size
16 byte block size
24 byte initialization vector
20 byte key
20 byte checksum
Let's play a what does not belong game.
Which number does not belong?

@_date: 2015-08-27 12:04:40
@_author: Ryan Carboni 
@_subject: [Cryptography] Is MD4 as secure as Poly1305 in an AEAD scheme? 
Is MD4 as secure as Poly1305 in an AEAD scheme?
I notice it consumes roughly the same amount of cycles, and any
forgery attempts would be nearly as difficult without knowledge of the
state of the MAC. Afterall, most AEAD schemes also encrypt the MAC
which essentially negate many attacks. I can't help but feel that MD4
is set to unfair standards while everything else is set to more
logical standards.

@_date: 2015-08-30 01:36:14
@_author: Ryan Carboni 
@_subject: [Cryptography] Does Simon effectively use the Toffoli Gate as it's 
Does Simon effectively use the Toffoli Gate as it's Feistel function?

@_date: 2015-08-31 14:03:39
@_author: Ryan Carboni 
@_subject: [Cryptography] Does Simon effectively use the Toffoli Gate as 
Good. It would be terrible if Simon had the same security level as a
series of rotations and xors alone.

@_date: 2015-12-05 15:13:21
@_author: Ryan Carboni 
@_subject: [Cryptography] Cryptography is not a science currently 
Recently The Moral Character of Cryptographic Work was published online by
Philip Rogaway.
I am going to explain that the disciplinary culture of cryptography is not
a scientific discipline. Cryptography itself is a science. Cryptography in
many respects is the inverse of forensic science, while forensics follow a
protocol, their results are no better than guessing. While cryptography's
results are concrete, the culture is a serious failure.
Cryptographers are well aware of the moral implications of their work...
since Diffie and Hellman condemned DES's short key length (
 ). If according to Rogaway,
"Most academic cryptographers seem to think that our field is a fun, deep,
and politically neutral game—a set of puzzles involving communicating
parties and notional adversaries", the fault is not with most
cryptographers, but with all cryptographers.
Paranoid fear surrounded the AES competition, that a cipher might have a
backdoor (it turns out backdooring ciphers are more difficult than
expected). Yet after the AES report turns out the full of lies (
 ), that additions are
more vulnerable to timing attacks then... table lookups, one should do some
critical self analysis.
That a cryptographer calls for some sort of self-analysis long after the
AES competition, the SHA-3 competition, basically after all the currently
accepted ciphers have become entrenched is alarming.
Each and every cryptographer seems to fail to understand what the US
intelligence community actually does. They truly do, they do not seem to
understand that for anyone of import, they'd develop biographies on people,
if one is important enough, they might create a psychological profile.
Maybe this sounds paranoid. But given that the greatest intelligence
scandals involve what is believed to be true to be absolutely false and
what is believed to be false to be absolutely true, paranoia is to be
expected if the state takes an interest in your profession.
And all cryptographers know that the state is interested in cryptography.
What about the constant struggles of cryptographers getting their papers
published in the seventies and eighties? Maybe only Dan Bernstein remembers
that he went to court just to publish his own cipher.
Naturally for Philip Rogaway, these issues came to a head after the Snowden
disclosures (I'm still waiting for the next drip). For anyone to discredit
themselves in the first paragraph of a forty-six page PDF is amazing.
Potentially if all cryptographers somehow manage to ignore this immense
logical failing is an indictment against the entire cryptographic
profession. Especially given that it is commonly accepted that mathematics
requires logic.
Truly Rogaway is the Chomsky of Cryptography. Chomsky will deny the
Cambodian holocaust and claim that oppression in the US "isn't that bad".
For anyone to run out and say they are taking on the elite without knowing
a damn thing about anything, I wish them a lot of luck.
I might as well post a modest suggestion: cryptographers should support an
FPGA integrated into the CPU or the ability to use integrated graphics for
cryptography. This would remove entrenchment of standards, and allow people
to pick their own ciphers. It's possible the AES-NI instructions were
developed after the NSA panicked at seeing AES usage in TLS drop rapidly
after the timing attacks were revealed. The AES-NI instructions are
overkill, and seem to take CISC too literally. One only needs,
mixcolumn+subbytes, subbyte, reverse+mixcolumn+subbytes, AESIMC and
subbytes instructions of 32-bit sizes each (no need for AESENC, AESENCLAST,
AESKEYGENASSIST, AESDECLAST, AESDEC, AESIMC), it would save one
instruction, and the instruction will use only one operand. The way the
AES-NI instructions are designed precludes usage for Rijndael with 256 bit
blocks, and it seems odd that the AES-NI instructions only accept data from
the XMM registers.
Rigidity should be viewed with suspicion.
"Therefore the clever combatant imposes his will on the enemy, but does not
allow the enemy's will to be imposed on him." -Sun Tzu

@_date: 2015-12-06 07:46:41
@_author: Ryan Carboni 
@_subject: [Cryptography] Cryptography is not a science currently 
People talk badly about Hoover, but never about the CIA? Given the powers
of the FBI, Hoover was nothing like L. Ron Hubbard, Nixon, or Beria. The
CIA on the other hand.... stole a hard drive.
This year. Hoover's FBI constantly talked about discretion, and people even
wrote to Hoover! Some villain he is. He even blackmailed the elites, which
is pretty terrible. Strange that a senile war criminal like Ronald Reagan
is more admired than J. Edgar Hoover, true American hero.
 I assume Google now encrypts everything everywhere inside the corporation.
Excellent, except why didn't all the targets in Prism join all at the same
time?  I guess each corporation's plaintext are just that hard to crack,
they had to work a year per company to break their plaintext. Maybe instead
of encryption they should change their plaintext encoding? Maybe for
additional security everyone should proprietary plaintext?
So when the Snowden papers came out 20 years later they suddenly realized
Snowden isn't such a big deal.
Maybe no one cares about Nicholas Merril and his fight against a national
security letter.
Maybe no one cares about Mark Klein, or that Congress gave retroactive
immunity to telecommunications providers in cooperating with the government.
Maybe no one cares that Theo de Raadt lost a DARPA grant for criticizing
the Iraq war.
Maybe no one cares...
Why am I wasting my time? There are thousands of events that transpired
before Snowden, and Snowden is a big deal? How is he a big deal? If you
didn't know the NSA was spying on everyone before Snowden, you're a moron
or a shill. There's no respectful way to get this point across, it's
abundantly clear to anyone with half a brain and pays attention to anything
that this is all public knowledge. To pretend that there was some big
secret before Snowden is ridiculous. The only interesting new bit of
knowledge in 2013 was parallel construction. I had no idea that the federal
government was */that/* crooked.

@_date: 2015-12-06 09:16:46
@_author: Ryan Carboni 
@_subject: [Cryptography] Non-DoD crypto funding? A contradiction in terms? 
And yet he expressed fear that an errant remark on a phone call would lead
to his assassination? I will trust him if he has a suspicious suicide,
otherwise the hyperbole is more cause for suspicion.

@_date: 2015-12-06 17:30:38
@_author: Ryan Carboni 
@_subject: [Cryptography] Cryptography is not a science currently 
I saw it. But whenever someone mentions Snowden, all previous knowledge
seemingly leaves the head.
Congress will... grant retroactive immunity if the need arises. The
Benghazi, SSCI, etc, are all a giant farce.
 Chomsky says that control is achieved through manipulating attitudes and
We live in a democracy afterall.
Erm... it's possible to learn by watching enough CCC videos of
presentations to know all about the NSA and other five eyes intelligence.
The logistics of it is impossible to hide. They have satellites next to
satellites to intercept data. The FBI has thirty thousand employees (and
operates DITU). The NSA has five times the budget and same number of
employees. The CIA has seven times the budget and twenty thousand
employees. This is just the US, the rest of Five Eyes puts in their fair
share as well.
To ensure staying on the topic of cryptography, how many cryptographers do
you think there are? Given the discovery of high level spies within
intelligence agencies (Redl, Ames, Hanssen), how could cryptographers hope
to assure security if the top spies can't? It has been alleged that
activist groups had been penetrated and the course of discussion
manipulated. If one million dollars per year is spent towards manipulating
cryptography, how would you think it would be used?
The only secure place is your brain. If you can think for yourself, then
you know your own thoughts are secure. Groupthink is the original cloud
Naturally, Rogaway doesn't mention any of this. He makes no frank
assessment of risks and possibilities. And I am the only person to engage
in a line by line examination his treatise? It is erroneous in numerous
sections. Contains a lot of obscure historical details, but seemingly
ignores the important ones? What is the impact upon you from reading the
document? What do you feel? What possible alternative motivations by the
author are there?

@_date: 2015-02-03 09:17:17
@_author: Ryan Carboni 
@_subject: [Cryptography] Wrong uses of filesystem encryption 
Which is why you store keys in hardware, not in hardware.

@_date: 2015-02-04 14:51:00
@_author: Ryan Carboni 
@_subject: [Cryptography] best practices considered bad term 
Pfft. I made a few submissions to the TLS mailing list.
RC4 apparently is too weak, and they think somehow the NSA might improve on
a statistical attack? Their logic is as nonsensical as attributing godlike
powers to the NSA and thinking the NSA has improved upon adding two num
I don't even know how packets are arranged when web pages are sent., I do
know it comes as multiple packets, but it is possible to distinguish
between which packet contains the cookie and which packet does not?

@_date: 2015-02-05 12:00:12
@_author: Ryan Carboni 
@_subject: [Cryptography] best practices considered bad term 
That's even less feasible. Most computers have at best, one megabit upload.
Which is further reduced by 5x assuming 2% dropped packets.
Besides, RC4 is less secure than desirable. There is no practical break.
This math obsession is probably what led the NSA to issue SHA-384 and
SHA-224 as standards... to provide mathematically comparable security, as
opposed to practical security.

@_date: 2015-02-09 14:57:40
@_author: Ryan Carboni 
@_subject: [Cryptography] Security vulnerabilities in BMW's ConnectedDrive 
Honestly, I prefer to use airplane mode rather than turn off my phone,
since even in a worst case scenario, no one wants their spyware to bring
down a plane. Wars get fought over such mistakes.

@_date: 2015-02-18 02:32:23
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] Equation Group Multiple Malware 
Can't trust anything, except the mail.
Only solution: personally encrypt messages by hand, using computers and GPG
only for transmitting master keys if the keys cannot be delivered in person.
Oddly there isn't as much outcry over this as compared to FBI black bag
jobs, even though this is literally the same.

@_date: 2015-02-23 23:24:15
@_author: Ryan Carboni 
@_subject: [Cryptography] trojans in the firmware 
Fighting against a nation state using equipment you cannot design yourself
or anyone you know could design... don't.
All computer components are designed by multiple committees, some of them
for standardization.
Physical security is the only way to succeed.

@_date: 2015-01-02 23:12:00
@_author: Ryan Carboni 
@_subject: [Cryptography] New Encryption Standard of the Russian Federation 
So they're finally fixing GOST after an embarrassing weakness was found?

@_date: 2015-01-08 13:35:35
@_author: Ryan Carboni 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
If we're doing alternate history and second guessing the decisions of the
Germans while they had limited resources.... why not use a Feistel cipher
with six letter blocks in ECB mode? Such a machine would only weigh 50
kg... not a major problem?

@_date: 2015-01-08 15:48:59
@_author: Ryan Carboni 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
the lightest Enigma was 12 kg.... the heaviest Enigma was 50 kg
it's telling when the only unbreakable cipher machine during the second
world war weighed fifty tons.

@_date: 2015-01-08 18:08:51
@_author: Ryan Carboni 
@_subject: [Cryptography] Imitation Game: Can Enigma/Tunney be Fixed? 
better stuff. I'm one of the co-authors of Threefish, and let's look at
that for a moment. It has a large block size -- 512 or 1024 bits (I'm
ignoring the 256 bit one) -- and runs at twice the speed of AES *because*
it has a larger block size. In fact, the 1024 bit variant runs slower on an
Intel processor than 512 only because the processor doesn't have enough
registers to hold the state -- and even then, it's only like 10% slower.
XXTEA is the fastest of all (and to my knowledge, differential
cryptanalysis has yet to be applied to partial blocks, thus it would be
secure in a non-naive implementation (it is still secure for many other
uses as well) ). But it was designed during an era when cryptography was
immature and many did not like block ciphers that were overly simple, such
a stigma continued to this day sadly.
"I have never been a TEA fan, although 64 rounds can cure a lot of sins.''
- Bruce Schneier
Naturally Threefish uses more rounds.
It would be trivial to manufacture an authenticated encryption construct
out of XXTEA, just reserve the first four 32-bit words as the
authentication key (same amount of data as HMAC-MD5, without the
computational overhead), if the first four words don't match, the message
would be rejected. Including a nonce would secure it for a larger number of

@_date: 2015-01-25 21:25:23
@_author: Ryan Carboni 
@_subject: [Cryptography] actual NSA protocol docs to mine... 
oddly enough, Appelbaum is right in his baseless accusations

@_date: 2015-01-26 11:46:59
@_author: Ryan Carboni 
@_subject: [Cryptography] actual NSA protocol docs to mine... 
Apologies, the wikipedia article implied that you or someone else somehow
achieved a distinguishing attack. Naturally I read the single sentence of
the wikipedia article as opposed to watching the hour long video it

@_date: 2015-07-02 13:35:37
@_author: Ryan Carboni 
@_subject: [Cryptography] Amazon releases open source cryptographic module 
s2n versus LibreSSL?
I lean toward the folks that aren't hired by the US government to do cloud
Cloud computing specifically for the US government.

@_date: 2015-07-02 23:47:29
@_author: Ryan Carboni 
@_subject: [Cryptography] Amazon releases open source cryptographic module 
The code wasn't so easy to read to prevent Heartbleed, now was it? Some of
the most catastrophic bugs in C seemingly involve a few lines of code
needing to be fixed.
To quote: s2n is written in C99, a language which lacks a "standard"
testing framework. Although there are some more well used C++ testing
frameworks, s2n also targets some embedded platforms on which a C++
compiler is unavailable.

@_date: 2015-07-04 13:23:54
@_author: Ryan Carboni 
@_subject: [Cryptography] Best AES candidate broken 
The best AES candidate, fastest on software, and faster than Rijndael on
hardware, has finally been broken!

@_date: 2015-07-04 22:34:15
@_author: Ryan Carboni 
@_subject: [Cryptography] Best AES candidate broken 
Except there's one problem with that assertion... Rijndael is easily broken
by.... cache timing, differential power, and many other attacks. The
knowledge that those attacks could be used certainly was known during the
AES competition. [relevant page from Serpent submission attached, will show
up in the Metzdowd archives]
Serpent was designed to be fast in hardware implementations... according to
the NSA's estimates for the NIST competition, 60% faster than Rijndael,
with a latency only twice as much.
But Serpent was not chosen. Serpent's designers did have slides during an
AES conference showing that standards are often used for decades... even a
century. [can't recall where those slides are]
I do not know what historians will think about modern cryptography, but I'm
guessing you could figure out what I think.
While Serpent was slower than Rijndael, there apparently were discussions
during the AES competition about requesting clarification as to the
security/performance tradeoffs for something more concrete than "more
secure and faster than TripleDES". [cannot remember where those documents
were] It's possible that the questions used for polling for the best cipher
for AES were loaded questions. The simplest modification to the ciphers
would be to ask the designers to increase or decrease the number of rounds.

@_date: 2015-07-05 12:59:10
@_author: Ryan Carboni 
@_subject: [Cryptography] Best AES candidate brokenby the way that 
That is correct. This is why the NSA implements their cryptographic
algorithms on secure computer system on a wide area network separate from
the internet.

@_date: 2015-07-05 12:55:44
@_author: Ryan Carboni 
@_subject: [Cryptography] Best AES candidate broken 
Yes, things have moved on since.... what was the release date of IDEA?
1991? Yes, things have moved on since 1991, ciphers have gotten more
advanced with the addition of S-boxes.  No wait, S-boxes in electronic
ciphers were first pioneered in 1977 with DES. But then most of the ciphers
in the AES competition used s-boxes. I don't know if we are moving forwards
or backwards anymore!
Actually the AES S-boxes are secure. As long you don't combine the steps to
create a 256*32 S-box. Modular addition has an issue though, high latency
given that it is a serialized operation. S-boxes are more easily
But I'm just repeating things I've read. What are PhDs supposed to be
anyway, contributors to their field of study?

@_date: 2015-07-05 22:13:34
@_author: Ryan Carboni 
@_subject: [Cryptography] Best AES candidate broken 
Interesting. I'd make a Freedom of Information Act request, but the backlog
is reaching such a point that they won't get to it within the next three

@_date: 2015-07-06 11:20:04
@_author: Ryan Carboni 
@_subject: [Cryptography] Amazon releases open source cryptographic module 
Two lines in Debian removed. Reduced cryptographic security by 99.99%.
the addition of one line to fix a bug
addition of two lines to linux source code by unknown hackers. The addition
of one character would mean the code would not provide root access.
I understand that cryptography is extremely subtle. Actually most
programming is pretty subtle.
This is why I'm saying that the length of the code or it's readability is
not a factor.
I'm saying that it's possible for ten lines of code to be backdoored.

@_date: 2015-07-07 13:12:26
@_author: Ryan Carboni 
@_subject: [Cryptography] Anti-clipper team re-assembles 
This is all a smokescreen. Passwords of insufficient entropy should be a
larger concern.
The FBI has a distributed computing project called Gridnet, for
workstations left on over night. Now, what sort of tasks would the FBI
require a massively parallelized effort to search towards?
I mean, the simplest backdoor would be to require free services to use a
secret salt and a 72-bit user provided secret.
(obviously if you're using a free service, you don't expect much privacy to
begin with, just look at the ads)

@_date: 2015-07-08 00:20:15
@_author: Ryan Carboni 
@_subject: [Cryptography] Anti-clipper team re-assembles 
Well, as long as they waste your time in explaining to everyone that
government should get out of encryption, instead of you patching problems,
I think it will make them happy.

@_date: 2015-07-16 15:39:30
@_author: Ryan Carboni 
@_subject: [Cryptography] Super-computer project wanted 
I thought the limiting factor was storage. If $10,000 of FPGAs can
bruteforce DES in a day, then a collision search could be achieved with
more modern FPGAs within a few months. 0.032 [price per GB] * (2^60
[operations] * 2^7 [size of SHA-1 block size] / 2^30 [size of a gigabyte])
= $4,398,046,511.104 in hard drives.
I think the issue in this case is not computations but storage capacity.

@_date: 2015-07-17 15:35:05
@_author: Ryan Carboni 
@_subject: [Cryptography] Nasruddin Cryptographic Function (99% finalized) 
This should be better than Rijndael, and takes advantage of 256-bit SIMD.

@_date: 2015-07-18 00:57:50
@_author: Ryan Carboni 
@_subject: [Cryptography] Nasruddin Cryptographic Function (99% finalized) 
To Ray:
This uses the same S-box. Thus the security proof has been forked. This
essentially replaces the mix columns with a better mixing function, as the
AES mix columns appears to have anti-cryptographic properties. Although
Rijndael seems vulnerable to Bicliques.
One thing that SIMD ciphers are particularly prone to is
Except that each input is different? It is an interesting challenge to
distinctly figure out the internal state of each ALU unit based on
emissions, although when many ALU units are simultaneously active, that may
make things difficult.
I'm not capable of addressing your other points.
To *Alexandre:*
This is both heavier and slower than regular AES
TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 costs at least one hundred
thousand cycles for the key schedule. The key schedule for ciphers in
Veracrypt requires around 10,000,000 cycles?
That's the thing, for big computers, key set-up time is insignificant
compared to asymmetric cryptography, or for key stretching.
For long messages, Nasruddin aims to be fast using modern instruction sets.
AESENCLAST has a latency of 6 cycles, but a throughput of 2 cycles. Thus
the subbytes step will cost (although the requirement of having a few
registers dedicated to a key of zero could cause a cache miss) eight cycles
per round.
Packed addition may take a few cycles per round.
This might be... two or three cycles per byte?
In any case, if computers gain a Speck New Instructions set, and if it
includes the ability to pipeline multiple Speck encryptions per cycle, than
this will be less than a cycle per byte. But such a thing is purely
hypothetical. But it seems likely that Speck would be standardized over
Simon, considering that Simon is nearly broken and it hasn't even been
adopted! It's simple key schedule certainly reduces it's security margin.

@_date: 2015-07-18 23:15:07
@_author: Ryan Carboni 
@_subject: [Cryptography] Hypothetical WWII cipher machine. 
A simple improvement upon Enigma: use different sets of rotors for each
service, that way, in the event of a compromise, you still have security by
obscurity. Rear area communications shouldn't be compromised by a division
being overrun. A side benefit is that brute force attacks require several
times as much work.
For low volume and/or high security messages, use a transposition cipher.
The VIC cipher's diffusion properties provided all of it's security, it's
confusion properties were nearly non-existent, depending on linear shift
register for substitution.
Afterall, a transposition cipher is difficult to achieve mechanically, but
can easily be done by hand. Triple substitution is difficult to achieve by
hand, but easy to do mechanically.

@_date: 2015-07-26 06:31:55
@_author: Ryan Carboni 
@_subject: [Cryptography] Whitening Algorithm 
Best attack: ISAAC 's security is greater than the permutation length of RC4-8

@_date: 2015-06-06 15:58:11
@_author: Ryan Carboni 
@_subject: [Cryptography] let's kill md5sum! 
My personal preference is the Tiger hash.
It's the only long-lived hash function that hasn't been broken, and it is
fast in software and slow in hardware, which is a plus for typical usages.

@_date: 2015-06-07 19:57:45
@_author: Ryan Carboni 
@_subject: [Cryptography] RC4 thought experiment 
This is purely a thought experiment, but the only secure communications
method is probably RTTY over phone lines, with encryption. 7-bit ASCII. And
each RC4 keystream byte is truncated to 7-bits. How would this influence
the biases?

@_date: 2015-06-07 22:45:58
@_author: Ryan Carboni 
@_subject: [Cryptography] let's kill md5sum! 
The attack is from 2007. The year is 2015. As time goes on, new attacks are
less likely to be developed, not more. I'm still waiting for DES to be
broken to 2^34 chosen or known plaintexts. That would mean a practical
break of TripleDES. Actually, DES is still widely used and a new break
would be pretty reknown, so there's no reason for any cryptographer to fail
to improve upon attacks on DES.
Furthermore... compared to SHA-1, RIPEMD, and MD5, Tiger is secure.

@_date: 2015-06-08 09:55:41
@_author: Ryan Carboni 
@_subject: [Cryptography] let's kill md5sum! 
"substantially faster"
BLAKE2 has been optimized for modern architectures. Has Tiger? And how much
is substantial?
And collision attacks are more important than preimage attacks anyway.
And when the security margin has been exhausted after two decades of
Are you going to say DES is insecure now too?
There's a certain ludicrousness to evaluating each cipher as if they came
out only a year ago.

@_date: 2015-06-08 16:44:46
@_author: Ryan Carboni 
@_subject: [Cryptography] let's kill md5sum! 
64-bit multiplication with 32-bit integers requires about four
instructions... I think?
That has been reduced to one instruction in modern architectures, a savings
of about three instructions per round, 24 rounds, so 72 instructions? There
is one multiplication each round in Tiger, I think.
BLAKE (the immediate ancestor of BLAKE2) came out in 2008, and during
You may not be aware of this in economics, but there's a loss in efficiency
when you increase inputs per unit of time.

@_date: 2015-06-09 00:24:48
@_author: Ryan Carboni 
@_subject: [Cryptography] Please "ERDJ" Congress to keep the FBI from 
Pi is in fact, 3.2.
Please read up on laws before passing new ones.

@_date: 2015-06-21 12:40:09
@_author: Ryan Carboni 
@_subject: [Cryptography] Nasruddin cryptographic function 
A rough draft of a 512-bit cryptographic function based upon Rijndael,
except the Mix Columns is replaced with Speck.
I call it the Nasruddin cryptographic function.
The Subbytes step could be sped up on computers with AES-NI by using the
AES encrypt last round instruction with a subkey of zero and reshuffling
the bytes.
The Shift Rows shifts each 64-bit row by n bytes, depending on the position
of the row.
The Mix Columns simply operates on each column using the 64-bit Speck round
function (word size 32-bits).
The AddRoundKey simply xors the state with a 512-bit subkey.
In stream cipher mode of operation, it functions much like ChaCha. 192-bits
of key, followed by 128-bits of nonce, followed by 64-bits of counter, and
a 128-bit constant (first 128-bits of pi, according to this web page:
 ). It uses no key schedule, and
xors the original state into the current state after each round iteration.
While like ChaCha it is vulnerable to slide attacks, the limit to the
number of outputs is far below the birthday bound, thus making it an
unlikely possibility to find a slide pair.
In block cipher modes of operation, the subkeys are generated through a
similar mode as the stream cipher mode of operation.
The first 48 bytes of state uses the key (of whatever length), with zero
bytes for padding. The last 128-bits is the aforementioned constant.
Then each key byte is xored with a byte integer of the round number (with
the padding and constant untouched). (making each key length independent
from each other)
Then the round function is applied three times, with the original state
used for AddRoundKey.
The final state is the subkey for the block cipher round.
The pre-whitening and post-whitening keys is generated by encrypting the
integers 0b0, and 0b1, respectively, using the block cipher in ECB mode
without whitening. The post-whitening key is added modulo 2^64. The author
believes that even with independent subkeys, this method of generating
whitening keys would make related key attacks vastly more difficult.
It is suggested that 16 rounds be used, except for keys of 192-bits or
less, for which 12 rounds are suggested. Obviously no more than 256 rounds
could be used.
XXTEA-style mode of operation which expands the block is favored by the
author, but to avoid implementation errors, it is suggested that one limits
the number of possible block sizes and thoroughly test each one.
In a hash mode of operation, it uses a variant of Davies-Meyer fast wide
pipe construction, except it mixes the entire state more thoroughly.
The cryptographic function is used in a 1024-bit feistel network. The
message is prepended with a byte integer of the number of bytes of the hash
to be outputted (limited to 64 bytes, in essence the cipher is truncated by
at least half). The cipher is designed to be nothing more than 256-bit
secure from collisions and preimage.
It uses an initialization vector of zero, the internal state is xored with
a 1024-bit integer / counter of the number of blocks hashed after each
It takes 1536-bits of message. Each 512-bit block is used as a subkey for
each of the first three rounds.
The remaining four rounds uses 384-bits from the message and expands it to
a 512-bit subkey using the stream cipher mode of operation with five rounds.
I hope this is more secure than many other ciphers from Buffer over-read,
Cache timing (at least it doesn't use an excess of matrix multiplication),
Differential Power, and other attacks.
A hardware unlimited implementation I believe should not be slower than
64-bit Speck in hardware (the S-box should accelerate diffusion). I
speculate that this would improve interoperability between smart cards, and
non-portable devices, so that support for Speck wouldn't cripple the
cryptographic capabilities of IBM-compatible PCs. It is likely for the
indefinite future that hundred dollar CPUs will carry AES-NI support (the
US government certainly still uses TripleDES).
Simple instruction set improvements for the function include an accessable
zero register (already available on many RISC processors), and a solo
instruction for AES subbytes (which would speed up Whirlpool and
Rijndael-256 (most commonly used for Freenet) as well).
I leave you with a Nasruddin joke.
The times were uncertain, and the King's spies read the mail.
Nasruddin did not like that and invented his own language to use with a
An officer of the king knocked on his door the day after he mailed a letter.
"Nasruddin, what is this?" holding up the letter.
"It is in a different language."
"Yes, but which one?"
"I invented it with a friend."
"...what does it say?"
"We disagree on some of the meanings of those words."
"...what about the other words?"
"I forget some of those words. I didn't have much time to learn the
"...in the future, I will tear up letters like this."
And another joke:
Why is the cipher named AES?
Because no one can pronounce the original name.

@_date: 2015-06-24 10:04:05
@_author: Ryan Carboni 
@_subject: [Cryptography] Nasruddin cryptographic function 
Given that there's no comments on what I proposed, I only have the
following questions:
1. Is it possible to develop an algebraic equation expressing an ARX
2. Is it possible to express an algebraic equation as an ARX function?
implemented with ARX operations and constants." - Rotational Cryptanalysis
of ARX

@_date: 2015-06-29 17:46:44
@_author: Ryan Carboni 
@_subject: [Cryptography] Dilbert on WiFi password security 
Well, I'll get to find out whether the Metzdowd archives can save picture
I find it odd that Ethernet and Wifi are both designed to be used in a 100%
trusted environment. The use of DH-1024 (with random primes) and DES-X
(wifi and ethernet both require substantial hardware circuits anyway) would
be sufficient to deter most malicious actors.
I mean, all I need to do to eavesdrop on either one is to simply... connect.
I don't know what international standards committees are doing, but the
fact that USB condoms are a thing should be some sort of indicator? Maybe?

@_date: 2015-02-28 22:11:37
@_author: Ryan Carboni 
@_subject: [Cryptography] information, Shannon, and quantum mechanics 
128-bit keys are secure from quantum computers, given that agencies could
potentially bruteforce 80-bit keys, and grover's alg reduces 128-bit
security to 64-bit, the cost of a single quantum evaluation of AES must be
equal to or less than 2^16 the cost of a classical computation of AES.
No worries there! Apparently buying a quantum computer with hundreds or
thousands of gates (no recent news articles about the current state of the
art), costs millions.
So we're quite safe.

@_date: 2015-03-06 15:44:30
@_author: Ryan Carboni 
@_subject: [Cryptography] FREAK attack 
Very simple.
DHE-RSA-1024, RC4-128. I would double RC4's key scheduling rounds though.
Double-DES would also work, a man-in-the-middle attack isn't feasible in
any sense.
 128-bit ciphers are secure against quantum cryptography, as long as a
single quantum evaluation is equal or greater than 2^16 classical
evaluations. That would make the cost of a quantum attack equal to a 2^80
attack, which is pretty cost prohibitive.

@_date: 2015-03-10 18:31:19
@_author: Ryan Carboni 
@_subject: [Cryptography] Is there a point to key schedules? 
Is there a point to key schedules? Let's look at the origin of entropy for
an HTTPS session. First hardware entropy is collected. It is usually then
hashed. That is then used to seed a PRNG, often a block cipher, sometimes
RC4 (although ChaCha is being adopted). Due to biases in RC4 and other
biases in all block ciphers, if a 256-bit key is generated, it is at best
255.999... bits secure.
That key is then used for a block cipher....
Now lets go see how many bits a 128-bit block cipher takes... say a
hypothetical one with thirty-two rounds.
 32*128= 4096 bits. 4096 bit asymmetric ciphers have 128-bit security and
could transmit 4096 bits. so everything is mathematically comparable.

@_date: 2015-03-11 14:40:34
@_author: Ryan Carboni 
@_subject: [Cryptography] Securing cryptocurrencies 
I'm not in a position to bet currently, and it's a bet best done through
the Long Bets foundation, but I believe SHA256 will not have a malicious
collision in the next hundred years.
It's a modern hash function designed when hash function design finally

@_date: 2015-03-16 09:49:50
@_author: Ryan Carboni 
@_subject: [Cryptography] Excessive Math? 
A 2^24 attack is impressive.
Now... let's see... going through a list of 70,000,000 passwords
 log(70,000,000)/log(2)=26 bits.
but many passwords aren't unique, and many are more common than others
and could be cross referenced with other databases of usernames and
passwords, as well as maybe an automated search of a user's social media
preference to determine their pets and interests....
I think cryptography is suffering from an excessive focus on math.

@_date: 2015-03-20 09:02:36
@_author: Ryan Carboni 
@_subject: [Cryptography] (no subject) 
Curious, how does anyone truly know how many certificates are signed by any
authority... beyond their word?

@_date: 2015-03-22 22:27:19
@_author: Ryan Carboni 
@_subject: [Cryptography] Kali Linux security is a joke! 
For software fingerprints, fuzzy hashes are better.
And it depends on whether you're using a whitelist or a blacklist or both.
Antiviruses, the automatic scanners that gmail and other providers use, all
blacklists. A typical hash is bad, change a few bits, and you'll be clear.
For a white list, collisions are worse as you can trick an authority into
approving it.

@_date: 2015-03-24 02:20:51
@_author: Ryan Carboni 
@_subject: [Cryptography]  TB2F CAs as (un)official browser policy 
I've said it before, but I think a series of network notaries like
Perspectives should be used to make sure everyone is receiving the same
public key for a website.
Pretty much the only way.

@_date: 2015-05-12 14:24:32
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
Don't be ridiculous, NIST providing standards that people care to

@_date: 2015-05-12 16:41:28
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
There is a very simple way around this. Block XXTEA introduced a new method
of operation, since folks seem to be renaming primitives (someone decided
to call Block Cipher Spices "Tweaks") so let's call it Cipher Round
Chaining. Basically a simple cryptographic function is turned into a
circular feistel array. In the event that people complain this breaks
hardware, I just want to remind everyone that much cryptography is done
through instruction sets, and making a single call for a round function.
It's quite possible that one could achieve the same security of AES CBC in
less rounds using Block XXTEA chaining, without the probabilistic risk of
plaintext leakage. Block XXTEA also has some nice data integrity
properties, so if the first few words were a shared authentification
secret, it could be easy to reject encryptions that don't match the secret.
Although for the internet and smart cards, data packets are small enough
for 64 bit blocks not to matter as long as you rekey between packets.

@_date: 2015-05-12 23:34:58
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
Did you some how miss the suggestion to convert AES to the same method by
using XORs?

@_date: 2015-05-13 15:30:47
@_author: Ryan Carboni 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
I'm confused by the current discussion. It seems predicated on the
assumption that standards and implementations are equal to each other. Most
implementations are standards cobbled together, and I wish most
implementations were cross compatible (the best form of auditing is to have
two independent attempts), but they aren't. And smart cards don't usually
communicate using the internet, so they'd use a different protocol and
implementation than a desktop.
In any case, XXTEA reduces from 32 rounds to 6 rounds for large blocks, and
it's round function is pretty weak, so the method seems to strengthen small
ciphers applied to large blocks.
In odd news, the US government has to pay private companies for
certificates. You'd think they'd be able to get browser makers to allow a
root certificate that can only verify ".gov" addresses and do some
certificate pinning.

@_date: 2015-05-14 00:28:12
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
In order for there to be some kind of preimage attack using the constants,
which were generated using SHA-1, then there has to be some sort of
preimage attack on SHA-1.
Now assuming the $50 million 1982 DES bruteforce attack was possible, and
factoring in that the value of breaking all the cryptography is more than
just one key, assuming that it would be worth two months of computation
(thus reducing the cost of the attack by 30), and assuming that budgets
increase 10% year after year...
There must approximately be a 72-bit preimage attack on SHA-1.
That no one has discovered.
So there's two possibilities...
1. all the cryptography is trivially broken
2. NIST is incompetent

@_date: 2015-05-14 11:27:34
@_author: Ryan Carboni 
@_subject: [Cryptography] [cryptography] NIST Workshop on Elliptic Curve 
1. They already own their own servers in many cases.
2. The whole point of certificates is to prevent a man-in-the-middle attack.
3. Certificate authorities have proven to be vulnerable to hacking. See
4. A certificate costs at least several hundred dollars. Multiply that
against a hundred .gov websites that use certificates.
5. The US government pays hundreds of millions of dollars per year for it's
own cybersecurity.
6. The US government usually operates those airplanes.
Or the NIST curves are not secure, nor is SHA-1, and if SHA-1 isn't secure
five years from it's release from the NSA, why would SHA-256 be secure
fifteen years after it's release from the NSA, and why would the NSA stop
at just SHA 1 and 2, why not AES and SHA-3?
So the question of whether the NIST curves are backdoored becomes a
question of... is the entire internet backdoored?
It's possible that the SHA-1 outputs weren't generated using a differential
attack but using random numbers, but wouldn't timestamps to nanosecond
precision equally work as well? And it's a lot more difficult to check if
some constants have backdoored properties that no one else would discover
than to find your own constant with unique properties, and attempt to
preimage that
But what do I know? Cryptographers don't trust the NIST curves, but they
trust SHA-1 for everything outside of collision resistance, I mean... it's
not like there's logic involved in decision making.

@_date: 2015-05-14 15:43:44
@_author: Ryan Carboni 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
Well, if you're making that argument, that it simply is difficult to
implement, I just would like to point out the Bad Crypto winner:
Otherwise I have nothing more to add.
But my awareness of ECC issues is that the constants are suspicious
according to this web page: But I'm not aware of everything and I welcome being corrected.

@_date: 2015-05-15 15:52:36
@_author: Ryan Carboni 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
Look now I'm really confused. Before differential cryptanalysis, DES
s-boxes were viewed with suspicion.
But now people are saying, "we don't completely understand ECC, but we have
devised means of creating EC and hope we get lucky and it ends up secure
twenty years down the road."
Naturally RC4 as a cipher was created by accident. (and so was Penicillin
as a drug)
But no one wants accidents in cryptography.
And I don't really trust any process that no one understands to protect
anything important.
I suppose the most important takeaway I'm getting is that ECC is secure
enough for obfuscation-grade cryptography.
Otherwise one should should stick with 2048-bit RSA?
But what would I know?

@_date: 2015-05-15 16:34:12
@_author: Ryan Carboni 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
"indicates a name space within which all subject names in  subsequent
certificates in a certification path MUST be located."
I don't really have much more to say.

@_date: 2015-05-15 18:08:09
@_author: Ryan Carboni 
@_subject: [Cryptography] Is there a good algorithm providing both 
A 32768-bit block cipher would make what you are saying true (and would
also be good for hard disk encryption).
But one can determine things with 16-byte precision with modern ciphers.
And one does not usually look at one wikipedia page.
And one does not look for people on a case by case basis.
One looks for patterns. The fact that your name has appeared on this list
may or may not merit the expenditure of an additional hundred thousand CPU
cycles. And there are other things, one does not need to know what web
pages you look at, simply what websites you look at. All resources are
finite. So it all amounts to prioritization.

@_date: 2015-05-15 19:09:09
@_author: Ryan Carboni 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
No. I think you're arguing that it's possible to secretly create a curve
vulnerable to attack, so it's better to make our own curve based on what we
think is secure, even though it's not easy to discover how a curve was
backdoored after a decade even when you have all the math right in front of
And AFAIK, the NSA curves (besides Dual_EC_DRBG) have not been proven to be
backdoored, they've only been proven to be suspicious. How would you know
that the NSA didn't choose the constants for additional security, like the
DES s-boxes?
I don't know. How many key bytes are leaked using RSA? How many key bytes
could be leaked using ECC? Although it is clear that AES leaks key bytes
according to a paper entitled "Transposition of AES Key Schedule," but I'm
fuzzy on the math involved.
The performance difference between RSA and ECC is about 20x. So it
ultimately depends on how much you're willing to pay for additional
TBF, the Rabin cryptosystem is more secure than RSA, as the RSA problem is
unique to RSA.
I suppose this all ultimately depends on your threat model. If your threat
model requires protection against agencies capable of manipulating devices
in transit, global passive surveillance, backdooring firmware, hacking
servers that contain crypto keys, a war chest of dozens of zero days, and a
general need for security theater, then perhaps one should not use a NSA
ECC. Afterall. At least your key exchange algorithm /might/ be more than
the NSA's versus the NSA.

@_date: 2015-05-17 18:37:30
@_author: Ryan Carboni 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
Well, I see three worlds. I see the microcontroller software world (it
seems unavoidable that people are going to be wearing $10 CPUs with the
computational capacity of an eleven year old desktop and the security of
Windows XP), the microcontroller hardware world, and the multi-hundred
dollar CPU world.
Ultimately, Speck, Threefish, or ChaCha, fufills the needs of all three
But there's a problem with the multi-hundred buck CPU world, fancy
cryptographic instruction sets are most efficient when combined with
complex branch prediction and parallelizable modes of operation, and it
creates a certain degree of inertia. There is a middle ground. One could
replace a core with an FPGA cryptographic coprocessor. Cryptography, unlike
most CPU instructions, doesn't need to calculate an operation within one
microsecond. A millisecond, like the GPU, is fast enough (and is smaller
than network jitter). Want RC4? You can have it at x gigabits per second.
Want rijndael? You can have it at x gigabits per second. Want serpent? Also
available at a gigabit per second rate. Etc, etc. Afterall, modern CPUs
have more transistors than the GTX 260.
And there are other non-cryptographic applications that require fast
compact ciphers. Many GPUs uses a hardware LCG for random numbers, which
are biased and inefficient. Fast non-cryptographic random number generation
is a concern, for simulation, and gaming. Ciphers shouldn't be totally
standardized, there ought to be optional variants of operation for lesser
threat models. One only needs 2^64 security against linear cryptanalysis to
protect against script kiddies if one is programming a game. To prevent a
collision of seeds, one should also have a seed state of at least 2^80, if
one is using randomly generated seeds.
Also. There was a mention of cipher keying for different round versions by
some person.
Doesn't Simon and Speck differentiate in it's family of ciphers using word
size and round constants?

@_date: 2015-05-18 06:11:33
@_author: Ryan Carboni 
@_subject: [Cryptography]  Intel SGX: Augean stables piled higher & deeper? 
There actually is a very simple solution to that.
Insist on WSIWYG.
It shouldn't be so trivial to inject malware into winlogin or create root
Actually I don't even understand rootkits, file systems shouldn't be able
to reference sectors that it doesn't make the user aware of.

@_date: 2015-05-19 17:56:52
@_author: Ryan Carboni 
@_subject: [Cryptography] NIST Workshop on Elliptic Curve Cryptography 
Windows XP was last sold on 2008.
SHA-1 will be deprecated on 2017 (or around then).
For most computers that weren't pirated, I'll be surprised that not a
single component fails first. I remember when the GPU on my old laptop
failed during a hot summer, (interestingly, the command line was even
corrupted) the laptop was about nine years old and ran Windows XP.
Although SHA-1 deprecation wouldn't really matter. The major browsers will
stop supporting XP around next year, so it's ultimately up to the servers
to stop supporting SHA-1.
Hey, is there a census of SSL cipher support and usage?

@_date: 2015-05-20 23:24:41
@_author: Ryan Carboni 
@_subject: [Cryptography] Intel SGX: Augean stables piled higher & deeper? 
Still does not improve security against the NSA.
Question: is there a debugging instruction that allows a memory dump of
branch predictions of the most common instructions used?
Like subkeys?

@_date: 2015-05-27 15:46:51
@_author: Ryan Carboni 
@_subject: [Cryptography] Is this a "relevant" attack against HMAC-MD5? 
That 2^72 attack against MAC MD5 is an online attack.
It is only in the reach of the NSA if it's a server capable of handling
2^72 queries per year.
Keep in mind if each query was one byte, that would be several zettabytes
of data.
The internet isn't even that big.

@_date: 2015-05-27 16:09:12
@_author: Ryan Carboni 
@_subject: [Cryptography] open questions in secure protocol design? 
it was a system that didn't even involve a key exchange protocol!
too bad security by obscurity does not work

@_date: 2015-05-29 12:31:44
@_author: Ryan Carboni 
@_subject: [Cryptography] [tor-talk] Dark Web should really be called the 
To my knowledge, traffic is randomly assigned by clients based on consensus
In order to have a proper padding system, a lot more information needs to
be leaked about current bandwidth demand.

@_date: 2015-05-30 12:04:08
@_author: Ryan Carboni 
@_subject: [Cryptography] open questions in secure protocol design? 
*Tony Arcieri *
*Fri May 29 21:49:53 EDT 2015*
Uh. There's a number in the front of the Bitcoin key. Either 1 or 3 to
signal the signature and protocol.
On another note, I do believe Bitcoin will die, only because it's economics
model is invented by people who believe in the opposite of Keynesians...
that hyperdeflation is good.

@_date: 2015-05-30 11:08:36
@_author: Ryan Carboni 
@_subject: [Cryptography] Why is ECC secure? 
There have been attacks as a result of nonce reuse and poorly generated
nonces for ECC. There may be as of yet unknown attacks against ECC private
keys that are heavily used but with random nonces.
No such attacks for public key cryptosystems using prime factorization.

@_date: 2015-05-31 01:43:17
@_author: Ryan Carboni 
@_subject: [Cryptography] Why is ECC secure? 
Okay, the difference between ECC and RSA is that RSA is so simple that it
can be incompetently implemented, and ECC is so complex that it can be
incompetently implemented.
True, if you're talking about ECDSA, but ECDSA sucks. Use EdDSA and this
Nonce reuse is still a problem.
tl;dr: RSA sucks. Stop using it.
There is such as thing as SSL accelerators. ASICs aren't just for the NSA
and the EFF.
And it's the cost of security. If your threat model requires security
against agencies, ECC isn't sufficiently proven. No one has shown how the
NIST curves leak. Not even a weak attack.
2048-bit RSA will provide security for the indefinite future, even versus
Considering that Gost was designed in the 80s, and the Slide Attack was
discovered a decade later, and DES was designed in the seventies and the
Differential Attack was discovered a decade and a half later, I won't be
confident in non-NSA designed ECC against cryptanalytic attack until 2020.
That and, how do you protect against attacks you don't understand? It is
quite an accomplishment for a blind man to become a fencing champion.

@_date: 2015-11-11 19:59:06
@_author: Ryan Carboni 
@_subject: [Cryptography] Bitcoin blocksize limit can be removed 
I already suggested an improvement, to avoid a tragedy of the commons, you
need the block size itself to cost the miner bitcoins, and for the mining
rate to be variable based on total hashing power. This way a true market
equilibrium would be achieved based on supply and demand.
This is what happens when cryptographers dabble in economics, not even
economists are able to do economics all that well.

@_date: 2015-11-12 11:34:05
@_author: Ryan Carboni 
@_subject: [Cryptography] Bitcoin blocksize limit can be removed 
Longer transmission time. I can argue you are arguing in bad faith as well.
You seem to totally ignore that mining is done by pools, and that the
"larger chance another block will beat yours" doesn't matter when the the
mining pool servers are in datacenters with ten gigabit connections. Most
arguments in defense in the current system mask the true intent, in that
they bought Bitcoins when they were "cheap" and want to artificially
constrain the creation of currency. This is literally the worst central
banking scheme I've ever seen. Worse than Gorbachev's Uskoreniye, which
mostly was the central bank lending money to the government, while
maintaining price controls, accelerating shortages. Bitcoin can't hope to
reach a reasonable amount of adoption without some sort of automated
central banking policy, to discourage speculation and encourage liquidity.
P.S. I hope discussion of Bitcoin is unlimited, it was posted here afterall.

@_date: 2015-11-12 17:56:30
@_author: Ryan Carboni 
@_subject: [Cryptography] Bitcoin blocksize limit can be removed 
Gold production is based upon price signals for gold, which is why it has
increased, and continues to increase. The gold standard is not a relevant
example, because at no point was the gold standard capped at 21 million
units. The best price signal for bitcoin is hashing rate, and it should be
the hashing rate that decides the amount of Bitcoins produced, and the
block size should be decided by the free market, not by the Bitcoin
foundation. You ignore a ridiculous number of variables, making me think
you are a Keynesian.

@_date: 2015-11-16 14:02:44
@_author: Ryan Carboni 
@_subject: [Cryptography] ratcheting DH strengths over time 
Please be more specific. Outside of birthday attacks, what problems does
CBC have?

@_date: 2015-11-21 13:56:24
@_author: Ryan Carboni 
@_subject: [Cryptography] Dan Bernstein has a new blog entry on key 
It's not a very valid argument, whenever someone contradicts themself, I
take them less seriously. He ignores that each evaluation of an AES
plaintext-ciphertext pair to confirm usage under a key is roughly linear
increasing cost (particularly since key generation per round is technically
simpler than a single round encryption). Thus bruteforcing multiple secret
keys is not equal to bruteforcing a single secret key no matter what he
There are limited instances in which his argument is valid though... if
you're not using an initialization vector.
He then goes on to talk about computational costs of arithmetic versus
memory operations.

@_date: 2015-10-02 14:36:22
@_author: Ryan Carboni 
@_subject: [Cryptography] RFID Protocols 
A google search yields nothing for RFID protocols. So I'm going here to ask
the following questions:
Can an RFID chip contain a store of entropy (meaning must a lightweight
cipher be secure against known and chosen key attacks)?
How does an RFID protocol prevent replay attacks?

@_date: 2015-10-10 20:41:34
@_author: Ryan Carboni 
@_subject: [Cryptography] Collisions w/SHA-1 ~$100,000 TODAY 
What is the memory complexity of this recent attack?
Regardless, the md5 certificate collision attack was only possible by
predicting serial numbers generated by the certificate authority, and it
took multiple weekends to succeed. By that metric, if it costs a single
hundred thousand dollars to generate a collision, it'll take multiple
hundreds of thousands of dollars to succeed. There was also other
difficulties, such as selecting a modulus that would enable such an attack.
It's probably more urgent to add post-quantum root certificates to each
browser than to discontinue SHA-1.

@_date: 2015-10-13 14:52:11
@_author: Ryan Carboni 
@_subject: [Cryptography] (fwd) a tale of software maintenance: OpenSSL 
I have trouble figuring something out with TLS and this reminded me. I know
the cryptoperiod of the shared secret is however long both parties care to
store it, but what is the cryptoperiod of the secret key for the symmetric
cryptography? Each packet (certainly so for RC4, but what about the other

@_date: 2015-10-15 17:04:36
@_author: Ryan Carboni 
@_subject: [Cryptography] How does the size of a set of target results 
Aren't collisions checked manually to ensure that they actually are the
same file? I don't really understand the intent of the question.

@_date: 2015-10-17 21:05:21
@_author: Ryan Carboni 
@_subject: [Cryptography] Fwd: freedom-to-tinker.com: How is NSA breaking 
To arguments about the long generation time of DH keys: you don't need a
cryptoperiod of one use, just have a cryptoperiod of one thousand SSL
connections. It increases the value of each key by one hundred times.
According to "Imperfect Forward Secrecy", it requires 30 core days for the
descent part of factoring, so there could be some variability in the
cryptoperiod length for each component of DH generation. Cryptoperiods are
a thing for a reason, because the government has recognized how difficult
it is to generate and distribute high entropy keys (at best typical crypto
on the internet has 0.9 bits per bit).

@_date: 2015-10-26 16:15:16
@_author: Ryan Carboni 
@_subject: [Cryptography] composing EC & RSA encryption? 
Personally I interpret the news is that they have discovered a generic
precomputation attack against all ciphers. It seems odd that Secret and
Unclassified should now be encrypted at 256-bit.
Or, do we copy the triple DES construction and do EC-RSA-EC?  Chosen
Not really faster. To encrypt the RSA key, you'll have to do about 6 ECC
encryptions in parallel. So it'd become as slow as RSA.

@_date: 2015-10-27 02:03:17
@_author: Ryan Carboni 
@_subject: [Cryptography] The Energy Budget for Wireless Security shows 
Communication costs 99% of energy costs, thus decisions to use Speck is
wholly pointless. One could use the original 256-bit Threefish. One could
use Threefish with triple the number of rounds.
This is a recurrent problem. Focusing on individual cipher costs while
ignoring protocol costs wastes time towards pointless optimizations which
could prove insecure and vulnerable (needless reductions in security
margins). ChaCha's speed likely does not add any true benefit when
asymmetric cryptography is factored in.

@_date: 2015-09-01 00:42:55
@_author: Ryan Carboni 
@_subject: [Cryptography] NSA looking for quantum-computing resistant 
NSA is tasked with keeping information secure for at least 25 years,
all the recent warning means is they think it is likely that a
feasible quantum attack can be achieved within thirty or forty years.
One can speculate what prompted the warning.
Ironic since they've been making it difficult to make things secure by
default. Wonder if OPM used COTS equipment.

@_date: 2015-09-03 15:41:31
@_author: Ryan Carboni 
@_subject: [Cryptography] Introducing the phone-directory certificate 
The NSA is subsidizing the entire backbone in exchange for full take,
nevermind that this is a violation of international law (World Trade
Organization complaints ought to be filed), but it could branch out to
other services that could operate as a "man in the middle."

@_date: 2015-09-06 15:32:54
@_author: Ryan Carboni 
@_subject: [Cryptography] NSA looking for quantum-computing resistant 
...or it could all be a smokescreen to avoid revealing that Snowden
stole the master ECC key.

@_date: 2015-09-09 23:48:51
@_author: Ryan Carboni 
@_subject: [Cryptography] 
For example, pursuant to these sections Apple makes available the following:
{Apple legal source}
Device Registration (name, address, email address, telephone number, iCloud
Apple ID)
Customer Service Records
iTunes (name, physical address, email address, and telephone number,
purchase/download transactions and connections, update/re-download
connections, and iTunes Match connections, iTunes subscriber information
and connection logs with IP addresses, specific content purchased or
Apple Retail Store Transactions (cash, credit/debit card, or gift card
transactions, type of card, name of the purchaser, email address, date/time
of the transaction, amount of the transaction, and store location, receipt
Apple Online Store Purchases (name, shipping address, telephone number,
email address, product purchased, purchase amount)
iTunes Gift Cards (sixteen-digit alphanumeric code, nineteen-digit code,
any purchases, name of the store, location, date, and time, user account
iCloud (music, photos, documents, iCloud email, encryption keys, Subscriber
Information, iCloud feature connections, connection logs with IP addresses,
Mail Logs, records of incoming and outgoing communications such as time,
date, sender email addresses, and recipient email addresses, Email Content,
Other iCloud Content, Photo Stream, Docs, Contacts, Calendars, Bookmarks,
iOS Device Backups, stored photos, documents, contacts, calendars,
bookmarks and iOS device backups, photos and videos in the usersâ camera
roll, device settings, app data, iMessage, SMS, and MMS messages and
Find My iPhone (including connection logs)
Other Available Device Information (MAC Address for Bluetooth, Ethernet,
WiFi, or FireWire)
Requests for Apple Retail Store Surveillance Videos
Game Center (Connection logs with IP addresses, specific game(s) played)
iOS Device Activation (including upgrades the software, IP addresses, ICCID
numbers, and other device identifiers)
Sign-on Logs (iTunes, iCloud, My Apple ID, and Apple Discussions,
Connection logs with IP addresses, Sign-on transactional records)
My Apple ID and iForgot Logs (password reset actions, Connection logs with
IP addresses)
FaceTime (logs when a FaceTime call invitation is initiated, content
protected by 15 bits of entropy if secure enclave baked key is obtained
from manufacturer)
iOS 7 and below the passcodes and full access can be immediately granted.
Encrypted device backups are available for all versions 8 and beyond -
these are protected by just ~15 bits of entropy by default passcode with
access to the secure enclave keying material which is also subject to legal
compulsion and reasonably we can expect the intelligence community to have
access to them.
Their warranty canary was removed, their system (despite claims) is easy to
subvert, there was no big legal case (just a show), they were an early
adopter to upstream programs such as PRISM, they would be breaking the law
if they truly (in praxis) were they preventing access, and yeah... they can
claim they don't give access if they outsource their backdoor to a separate
manufacturer (Apple's entire strategy is to own the entire manufacturing
pipeline - so what's with the outsourcing anyway).
Even if you fool yourself into thinking the touted "Secure Enclave" is
secure for your particular threat model - just pretend that - look over the
list above again.
Yes a thousand times.

@_date: 2015-09-13 23:40:44
@_author: Ryan Carboni 
@_subject: [Cryptography] millions of Ashley Madison bcrypt hashes cracked 
A victim should get a new SSN? I imagine all of us, on this mailing list,
have settled on one primary email address. Access to that email account is
probably more significant than your SSN.

@_date: 2015-09-16 14:27:14
@_author: Ryan Carboni 
@_subject: [Cryptography] An Open Source Analysis of NSA Cryptologic 
Timeline of Events of Note
1992 - DES is broken cryptanalytically, although with an attack greater
than the birthday bound
1993 - SHA released, based on MD4/MD5
1995 - SHA-1 revised, original SHA now called SHA-0
1998 - Skipjack Released
1999 - Impossible Differential Analysis breaks 31 of 32 rounds
2001 - SHA-2 released, by Threefish's standards, a 256-round hash function
2005 - SHA-1 is broken by a non-practical attack, spurs SHA-3 competition
2010 - Xie and Feng announce a one block collision on MD5, which they
cannot release for _security reasons._
The occasional cryptanalytic success implies that the NSA is generally more
advanced, but not always. Cryptanalytic success seems to be a random
process, but it requires previous successes to exist. The NSA seems to be
more advanced than the Chinese, and the Chinese vaguely more advanced than
the remaining cryptographic community. This can probably be attributed to
the fact that the NSA has more money, has the support of other SIGINT
agencies in cryptanalysis, and thus probably have half the world's
mathematicians. Thus perhaps the NSA has a 42% chance of getting a
genuinely new cryptanalytic success, the Chinese a 33%, and the rest of the
world a 25% chance.
The evidence to support such a claim is that impossible differential
analysis nearly broke Skipjack, although maybe the NSA was aware of it and
had less concerns about security margins than we think. Further attacks on
SHA-1 and SHA-2 spurred the SHA-3 competition. While it was reasonable for
the civilian cryptographic community to be concerned, the fact that the NSA
was concerned is telling. It was a result they did not predict, and they
possibly thought further cryptanalysis could break those two hash functions.
Fortunately there is a large body of research on the cost efficiency of
research programs. While one may conclude that the NSA must perpetually be
making leaps and bounds ahead of everyone through the virtues of compound
interest, the answer is pleasanter. There is a diseconomy of scale when it
comes to research. For instance, the Moon program or the Manhattan project
could have been cheaper if more time was allotted for its completion.
Given that the nature of research changes over time as the easiest results
are exhausted, and that large organizations do have waste, it is safe to
say that any gap between NSA and civilian cryptography will shrink by a
small extent, year over year.

@_date: 2015-09-17 15:18:15
@_author: Ryan Carboni 
@_subject: [Cryptography] WashPo: Leaked NSC Memo on Encryption 
Could also be a word doc using Courier New. Bullet points on typewriters
are usually dashes not dots, to save circumference area for the daisywheel.

@_date: 2015-09-20 21:28:49
@_author: Ryan Carboni 
@_subject: [Cryptography] An observation on a Skipjack-style Feistel network 
An observation on a Skipjack-style Feistel network: Assuming the round
function is a pseudo-random permutation, it would achieve security a single
round faster than a feistel network.
Balanced Feistel network of AES round function: 4 rounds for full diffusion.
Skipjack-style Feistel network of AES round function: 3 rounds for full
128-bit Rijndael: 2 rounds for full diffusion.

@_date: 2015-09-23 14:59:10
@_author: Ryan Carboni 
@_subject: [Cryptography] Cycles overhead for TLS 
I'm not sure so these are rough guesses, but:
5 cycles per byte for TCP overhead.
100,000 cycles for ECC key exchange.
Several thousand cycles for PRF key generation.
10 to 1 cycles per byte for symmetric crypto
Average webpage size is 1 megabyte, so maybe average TLS connection
eventually transfers 15 megabytes.
I think any performance improvements in asymmetric and symmetric
cryptography would be minor compared to TCP overhead.

@_date: 2015-09-24 18:16:38
@_author: Ryan Carboni 
@_subject: [Cryptography] Cycles overhead for TLS 
Average webpage 2 MB. Average US internet speed is ~12 Mbps.
Time to download the webpage: 1.3 seconds if you're sitting on top of the
"1.0 second is about the limit for the user's flow of thought to stay
uninterrupted, even though the user will notice the delay. Normally, no
special feedback is necessary during delays of more than 0.1 but less than
1.0 second, but the user does lose the feeling of operating directly on the

@_date: 2015-09-25 00:10:44
@_author: Ryan Carboni 
@_subject: [Cryptography] Cycles overhead for TLS 
Minimum latency is 1.3 seconds, which is a noticeable amount of time? Once
the amount of time it takes to load something is noticeable, it's a
problem. I'm only talking about cost-benefits anyway, and there's a fixed
Typical home wired network? Surely you mean typical wireless home network?
5-10 milliseconds isn't the noticeable component of a problem. Not every
website is run by Google, who relentlessly optimize everything.
While downgrade attacks may be a problem (which is solved in TLS 1.3,
right?), authentication-only cipher suites being enabled on the client-end
would prevent man-in-the-middle attacks and allow for cache engines to work.
On another note, given the long lead times in deploying a new cryptographic
protocol, it might be best to include a post-quantum cipher in TLS 1.3.

@_date: 2015-09-27 14:17:41
@_author: Ryan Carboni 
@_subject: [Cryptography] Brainpool Curves Found to Be Suspicious 
I have nothing to add except a quotation from the above hypertext document.
I am not certain what it proves, but suspicious crypto should be avoided.
The Brainpool standard says that it provides "verifiably pseudo-random"

@_date: 2016-04-08 19:20:48
@_author: Ryan Carboni 
@_subject: [Cryptography] Hillery's Email 
There are far more corners if you include BGP (maybe that's why all the
internet traffic was router to China for a few minutes?), DNS, and anything
I may have forgotten.

@_date: 2016-04-08 19:23:16
@_author: Ryan Carboni 
@_subject: [Cryptography] At what point should people not use TLS? 
Google is already moving away from TLS.
TLS is (more or less) restricted to the PKI ecosystem. TLS is poor for
decentralized or federated applications.

@_date: 2016-04-09 12:13:43
@_author: Ryan Carboni 
@_subject: [Cryptography] What standards are there for post-quantum 
What standards are there for post-quantum certificates? Can't find any.

@_date: 2016-04-09 21:45:57
@_author: Ryan Carboni 
@_subject: [Cryptography] At what point should people not use TLS? 
Okay, it's nearly been a decade.
It takes one year for a draft to start showing signs of finalization.
When will TLS 1.3 be final?

@_date: 2016-04-09 21:50:57
@_author: Ryan Carboni 
@_subject: [Cryptography] At what point should people not use TLS? 
On the topic of using protocols other than TLS, there has been a great deal
of research on the matter of protocols done after many protocols were
I'm not seeing a crypto-protocol falling every year.
In fact many P2P protocols have their own encryption, without the input of

@_date: 2016-04-12 02:22:27
@_author: Ryan Carboni 
@_subject: [Cryptography] At what point should people not use TLS? 
The question ultimately becomes, Rich, that what is easier to
cryptanalyze, a hash function, or a protocol? Furthermore, attacks on
one protocol shouldn't be difficult to apply to other protocols with
similar problems, while applying cryptanalysis is more difficult.

@_date: 2016-02-03 07:50:56
@_author: Ryan Carboni 
@_subject: [Cryptography] Anti-clipper team re-assembles 
I suppose it is alright for there to be disagreements over direction.

@_date: 2016-02-11 11:52:34
@_author: Ryan Carboni 
@_subject: [Cryptography] Cryptographic Regulations by the Department of 
There seems to be more exceptions now, but I haven't heard anything about
enforcement of this, nor do I remotely understand the regulations

@_date: 2016-02-15 19:21:39
@_author: Ryan Carboni 
@_subject: [Cryptography] Cryptographic Regulations by the Department of 
Use the wayback machine from the internet archive.

@_date: 2016-02-16 09:50:36
@_author: Ryan Carboni 
@_subject: [Cryptography] Cryptographic Regulations by the Department of 
Too much to ask for someone who's doing this for free, comrade.
In any case,
   - Commodities and software for quantum cryptography.
That's now an item. Wasn't there before. Not sure how the whole thing
applies, if at all.

@_date: 2016-02-16 10:48:28
@_author: Ryan Carboni 
@_subject: [Cryptography] Proof that the NSA does not have a 
Yet you are ignoring that the federal reserve can print money at will.
The current intelligence budget is around eighty billion dollars.
Medicare fraud is around fifty billion (10% of the total budget), the
Federal Reserve's balance sheet is secret (for some reason Congress has
forgotten that the Federal Reserve is charted by Congress and so Congress
can subpoena whatever it wants), etc.
This is how accounting works. Whatever happens to Occam's conspiracy? The
smallest group at the lowest level of autonomy is sometimes more probable,
ten accountants are more likely then a thousand analysts earmarking
intelligence as "relevant to future stock prices" overseen by a hundred
managers and hoping they won't whistle-blow like Binney.

@_date: 2016-02-16 11:03:59
@_author: Ryan Carboni 
@_subject: [Cryptography] [Crypto-practicum] Justify the sequence of 
Why not use single-key Even-Mansour-like construction?
Ciphertext = E( E(CTR) XOR plaintext)) XOR E(CTR)
Costs only two encryptions, both parallelizable, and has the security of at
least Even-Mansour with a single key, single plaintext-ciphertext pair. At
which point the easiest route is to attack the kernel, not an oracle attack.

@_date: 2016-02-19 17:35:48
@_author: Ryan Carboni 
@_subject: [Cryptography] FBI may have royally screwed up chain of custody 
So in the first 72 hours, the following happened:
-The password to the iPhone is changed, but no one has the new password.
-The news media storm the shooter's home and contaminate the entire crime scene.
-Who knows what else?
And the lesson learned is that law enforcement should be given
absolute authority?

@_date: 2016-01-02 12:49:18
@_author: Ryan Carboni 
@_subject: [Cryptography] List of 64 open spec Single Board Computers 
Few are barely compatible with tails. To be fair, a used laptop completely
reformatted is a bit cheaper (and when bought from a random shop more
trustworthy), but part standardization is important when conducting
revolutions to scale.

@_date: 2016-01-26 12:19:09
@_author: Ryan Carboni 
@_subject: [Cryptography] Anyone have information on Export 1024 RSA? 
It seems like the NSA would have been able to crack 1024 RSA up to ten
years ago if true.

@_date: 2016-03-27 00:31:13
@_author: Ryan Carboni 
@_subject: [Cryptography] Smallest 4-bit S-box? 
4-bit s-box [4, 8, 14, 2, 1, 13, 7, 15, 10, 12, 0, 9, 6, 3, 5, 11]
The method in generating the S-box is encrypting the four bits through
the following function 7 times:
Bit1 = ~((Bit2 & Bit3) | Bit1) ^ Bit4
Bit2 = Bit1 ^ Bit3
Bit3 = Bit2
Bit4 = Bit3
Essentially it's a Feistel network using an AND-OR-INVERT gate to
achieve nonlinearity, and uses a single xor to prevent it from being a
permutation of the input when at least three plaintext bits are one.
The S-box as is would use a minimal number of transistors.
If used in a cipher, it would ideally be used in a Type 1 Feistel
network similar to XXTEA.

@_date: 2016-05-26 12:29:25
@_author: Ryan Carboni 
@_subject: [Cryptography] A promising method to thwart global surveillence 
The Russian Illegals spy ring in New York used steganography.
The Caliphate cell in Brussels used truecrypt files uploaded to
cyberlockers in Turkey. But the grugq notes that truecrypt files would
probably have a fixed size (and even with a random length, it would
still round to kilobyte sizes), so it wouldn't be so simple.
Obviously if state-level actors use these methods against the NSA,
steganography does have a good role to play. Problem is that machine
learning has advanced substantially. In a worst case scenario, it will
be obvious that you have steganographic files, that is if photodna
hashes are similar for many files, but fuzzy hashes aren't as similar.
The best that could be done would be to make automated scans more
probabilistic and less reliable (I have tens of thousands of files on
my computer), by embedding encrypted data steganographically in images
in the PDF file. The text and images of the PDF file could be
procedurally generated.
But I'm not an expert. I'm just pointing out what makes sense to me.

@_date: 2016-11-28 13:02:19
@_author: Ryan Carboni 
@_subject: [Cryptography] What's the point of low-latency cryptography? 
What is the actual latency that would cause pipeline stalls? I would think
that most computations on a computer require at least a hundred cycles
before the result is presented to the user. RAM to begin with requires ten
nanoseconds to retrieve data. Nearly all single-cycle implementations are
probably smaller than the gate area required for a DDR4 Bus.
Although a more holistic approach would use a seekable stream cipher to
generate independent subkeys for a block cipher the size of each
addressable word (which appears to be the byte). This would be vulnerable
to codebook attacks if one can somehow read the encrypted output and submit
256 plaintexts if one knows the address of the data one wishes to
Given that Chrome isn't totally sandboxed, secure enclaves certainly won't
protect against all attacks.
Ideally an operating system would have the security features of OpenBSD,
grsec, and the architecture would aid in securing it.

@_date: 2017-04-10 15:53:43
@_author: Ryan Carboni 
@_subject: [Cryptography] Are current predominant cryptographic functions the 
The AES round function for instance is not the most optimal, just altering
add round key (Transposition of AES Key Schedule) can significantly improve
security. While cryptanalyzing one cipher is hard enough, cryptoanalyzing
any minor change in construction would be very difficult. Times have
changed since the only good cipher was DES, and cryptographers were
examining alternative DES constructions such as Ladder-DES proposed on
sci.crypt. It was a good thing that the Threefish team had to justify their
design decisions since it was very hard to prove security for an ARX cipher.
It still becomes an open question as to whether current knowledge is being
applied most optimally.
Just how much additional security does a tweakable block cipher provide?
Would Madryga even be secure under a tweak construction?
Would a CBC-MAC be immune to Simon’s algorithm if it was truncated?
Wouldn't for wide block encryption, instead of Bear and Lion, be better to
just use an envelope MAC over the plaintext and use half of the MAC output
as the encryption key and the other half as the MAC? Actually ZFS does
something similar.... A search for "zfs" on iacr doesn't reveal anything.
Could the Simon cipher use a stronger 3 to 1 function? Reuse the same
function for the key schedule?
Just how many NSA key schedules did Bruce Schneier see? Should be about
four. He's impressed with all four of them. Impressive.

@_date: 2017-08-12 19:39:03
@_author: Ryan Carboni 
@_subject: [Cryptography] What if 
What if there was a way for a quantum computer to search a mathematical
What if that was the true reason that SHA-3 required 512-bit security? (it
is for lack of imagination that people look at strange things and say, that
is normal)
It gets baffling. But the DES competition asked for ciphers immune to
differential cryptanalysis without saying so, which was the most
significant thing about the DES competition.
Afterall, 1600-bit state is a bit... large. But given that the group size
for DES is somewhere in the hundreds or thousands, Keccak would have a
group size in the millions, certainly.  (not that there weren't other SHA-3
finalists with large internal states)

@_date: 2017-08-15 20:15:26
@_author: Ryan Carboni 
@_subject: [Cryptography] Would haveged ever be cryptanalyzed? 
What is the nature of entropy from interrupts? Based on the cryptanalysis
of AES, it is very low. Superscalar processors doing memory manipulations
aren't very unpredictable. Why is that? Computers are deterministic, even
variable delays can be predicted.
This is well known. Why would there be entropy from network or disk
interrupts then? Packet loss and packet reordering, which is caused by
signal interference. Hard drives have even more interference as they may
fail to write or read a block properly the first time.
These aren't hitherto unknown concepts.
If only instead of examining the state transitions of RC4, people would
examine haveged. I personally can't program so whatever.

@_date: 2017-12-05 10:49:17
@_author: Ryan Carboni 
@_subject: [Cryptography] A dual-use hrng suggestion 
10.1109/DATE.2011.5763260 : Integrated circuits (ICs) are becoming
increasingly vulnerable to malicious alterations, referred to as hardware
Trojans. Detection of these inclusions is of utmost importance, as they may
potentially be inserted into ICs bound for military, financial, or other
critical applications. A novel on-chip structure including a ring
oscillator network (RON), distributed across the entire chip, is proposed
to verify whether the chip is Trojan-free. This structure effectively
eliminates the issue of measurement noise, localizes the measurement of
dynamic power, and additionally compensates for the impact of process
variations. Combined with statistical data analysis, the separation of
process variations from the Trojan contribution to the circuit's transient
power is made possible. Simulation results featuring Trojans inserted into
a benchmark circuit using 90nm technology and experimental results on
Xilinx Spartan-3E FPGA demonstrate the efficiency and scalability of the
RON architecture for Trojan detection.
10.1109/ISCAS.2013.6572251 : Security of implementation of ciphers in
hardware has already been well studied, nevertheless ciphers are not the
only hardware block used for cryptography. True random number generators
(TRNGs) are also significant cryptography blocks since they are used to
provide secret keys, random protection masks, initial values to other
security blocks such as ciphers. The security of TRNG implementations is
thus of paramount importance. Recently, electromagnetic channel has been
used to efficiently attack ring oscillator based TRNG by fault injection.
The work presented in this paper shows that by analyzing electromagnetic
emanation of the TRNG under attack in varying conditions, it is possible to
obtain significant information on the TRNG such as its position and
oscillator frequency, in order to improve the previously published
electromagnetic attack.
A ring oscillator is useful as a random number generator (although with
it's own biases), and could apparently be used as a physical unclonable
function, this would make open source hardware more easily proven to be
secure. Obviously to avoid device fingerprinting and side channel issues,
unprivileged processes shouldn't be allowed to have direct access. Although
device fingerprinting is trivial unless you prevent access to any input
device. Even the user can be fingerprinted across devices through some
It is probably impossible to generate biased random numbers faster or
easier than the source (curious if there is a way to generate numbers
biased like RC4 but faster).
Given that virtually everything so easily analysed by side channel
(although the sheer number of multiplexers and buffer gates cause noise),
even low entropy hardware masking is probably required for some operations,
even at the cost of greater latency. Or metal shielding around the chip,
either grounded or connected to a resistor. There was some research into
using capacitors to limit power analysis success.
Ideally some of the purchase price would go into a trust for legal issues
or to support the design (as opposed to a hard EOL). (there is also the
advantage that if the trust suddenly disappears you can sue for fraud to
figure out wtf is going on, as opposed to hoping Paul Revere won't be
compelled to put up only one lantern)
Ideally jumping into the middle of an instruction should be improbable to

@_date: 2017-12-19 15:35:21
@_author: Ryan Carboni 
@_subject: [Cryptography] World Peace isn't insurmountable 
What if the world isn't dysfunctional? What if it is so by design? What if
all nonfeasance and misfeasance is really malfeasance? Isn't the difference
between a democracy and a dictatorship a matter of active consent vs
passive consent? If five hundred random people were stuffed into Congress
and made the laws, would they run the country in the same way? Well, I
suppose there are true heroes, like Litt who said that DES couldn't be
cracked, and Clapper, who said a "truth" to Wyden who really should have
known better.
Anything exceptional that I pointed out is a product of pure deduction, a
quality few possess, that the school systems intentionally attempt to
deprive their students of.
To perhaps parody Cloudflare's complaint about ARX-512 making ChaCha20
nearly as fast as AES-NI, clearly Linux's /dev/random/ is not fully
understood and should be avoided. For the entropy estimate only counts the
entropy of individual events, but not the total combinatorial complexity.
Since operating systems have no real time guarantee, and all entropy is a
product of unobserved events, the order in which events occur certainly
adds entropy. Given that combinatorial complexity is not factored in
entropy estimates, the entropy estimate should be considered flawed.
In fact, this combinatorial complexity significantly impacts one's ability
to manipulate the output of the generator without knowing the full state,
and it might be dangerous for /dev/random/ to treat any source of entropy
as 8 bits per byte.
Perhaps only those capable of communicating in pure deduction can only be
trusted by others capable of communicating in the same fashion.
Of course the ability to deduce has long been regarded as the prerequisite
to investigate or understand anything, and is the foundation of all logic
and reason.
In the end though, I must repeat someone else's observation, that Google
could flip a switch, and 7% of all internet traffic will use a new protocol
they devised. I would prefer, in the following order, MitM-vulnerable
cryptography, backdoored forward secret ciphers, and then key length
restrictions. Not... an impossible to design product, with the source code
given to any government (Kaspersky gives their code to the US, IBM gives
their source code to Russia)...
You can make any software licensed under the GPL if you demand it I suppose
(yet it doesn't stop bundling anything with proprietary code). So much
happening right in front of your eyes, I doubt if you object to any of it,
you can possibly stop it.
P.S. To expound upon my previous statement that what one says only has to
be facially true, the argument barely has to justify itself, even using
weak evidence the audience may very well accept what you say as truth. This
makes anything you learn about debating to be a cruel waste of time.

@_date: 2017-07-07 13:17:55
@_author: Ryan Carboni 
@_subject: [Cryptography] NSA provides list of patents it's willing to share 
Nevermind that the NSA currently is paying telecommunication companies to
store our metadata (thanks Snowden!) or that the NSA is subsidizing
transoceanic cables (non sarcastic thanks Snowden)
Patent 8,363,825, from 2009, looks at lot like some kind of CRC fuzzy
Patent  9,525,866, from 2016, is anti-camera forensics. Time to go back to
film! (or maybe just resize it to 50% and save it as a rather lossy JPEG)
Patent 7,406,595, from 2004, shows how the NSA encrypts communications.
Sounds more efficient than Enchilada, as submitted to CAESAR.
Patent  6,922,774, from 2001, shows what the NSA does with virtual machines.
Patent 6,724,893, from 1996, is about key escrow. If one uses TENS, a
version of linux from the US government, one notices that the help manual
for the encryption wizard talks about key escow. But all our keys is
escrowed since the NSA stole SIM card keys from foreign manufacturers of
our devices?
Patent 6,912,284, from 1983 and the longest expiration date, is about some
kind of LFSR AEAD cipher. What? They discovered this in 1983 and we're
still working on AEAD ciphers?
Patent 6,820,830 appears to be just placing slants under a paper shredder
to direct output into multiple rubbish bins.
Like people. You can just go to the NSA's website. This is two clicks away
from the front page. What are you people doing? If you're going to be lazy.

@_date: 2017-07-26 21:04:03
@_author: Ryan Carboni 
@_subject: [Cryptography] A 1986 interview of Miles Copeland explains why 
Okay, I'll give you an answer: The CIA is set up so that it's impossible
for a person as an individual to arrogate to himself the right to lie to a
congressional committee or to anyone else. But what he can or cannot say is
clearly specified from the day he is sworn in. He can lie to people who are
not his bosses, who do not have security clearances. Most congressmen do
not have security clearances. When Senator Frank Church asked me something,
and he said, "Will you take an oath," I said, "Senator, I'll take the oath,
and I wouldn't think of telling you the truth." Personally, I like Colby
very much. He's a very fine man, but he's just the wrong kind of guy to be
head of the CIA. He's a good guy.
For unknown reasons, this has been totally forgotten. Fortunately we rely
on Snowden to remember for us, and he says he revealed the truth for the
first time ever. The news media backs him up on this. And Applebaum kept
his high salary mainly because he was good with the media (or the media was
good with him?). But hey, I wrote something about the Pike Committee
vacuuming up information.
Waiting for Best to come out with some bland matter of fact article about
historical government lies to the public, that'd make your brain lame.
The interesting thing about Miles Copeland is that he does provide the
unvarnished horrible truth of how some things work, as far as I can tell
based on what little information is publicly available.
If you read Miles Copeland's interview, you can understand how Snowden the
movie can be a recruitment video for some, and a video to accept the
current regime for most. (oddly Oliver Stone's trilogy on Presidents were good and honest)
There is no good answers to anything, it's all horrible, no one is doing
anything. I point things out, nothing is really done, I point things out in
greater specificity months later, some indications of something being done
begins to be shown....
It's not an OODA loop if your brain is off. It's just A.
Maybe no one asks me anything because they are afraid of the answers, not
from what influence I would have (which is a non-problem since we got here
by consensus, what could one person even do with diffuse authority?).
Unless there is a critical point of information by which I could begin
pointing out what is going on?

@_date: 2017-06-19 10:49:26
@_author: Ryan Carboni 
@_subject: [Cryptography] Predictions regarding Simon and Speck for 2019 
It has recently come to my attention that "Notes on the design and analysis
of Simon and Speck" (  ) was published.
Thus I have decided to encrypt a message using this page (
) with a key generated by keypass pattern "H(15)" (15 lowercase
hexadecimal). I plan on releasing the key in the early part of 2019
Block XXTEA is not trivially bruteforced with no "cribs" so here's my
predictions for 2019:

@_date: 2017-03-08 01:33:58
@_author: Ryan Carboni 
@_subject: [Cryptography] Crypto best practices 
Wait, AES with a minimum of 256 bits? Might be a typo, but there's only one
AEAD AES with no more than 256-bits right?
Is there key whitening? (I find it odd that few algorithms have strong or
independently generated whitening keys, particularly given that one of the
arguments for 128-bit DES is that it would only have 20% more gates)

@_date: 2017-03-09 14:18:43
@_author: Ryan Carboni 
@_subject: [Cryptography] jammers, nor not 
A secure computer is essentially in a faraday box, and to deal with
cooling, would be full of mineral oil.
I have read about Van Eck phreaking lately, and I don't think I see much in
academia about it. Sure, there's some successful attempts to derive RSA
keys from laptops, but apparently keyboards are vulnerable (
 )? LCD monitors leak their contents(not a
big deal just shelve this away and forget about it)? The Inslaw Affair
involved a backdoor in Promis using side channel emissions?
Has anyone attempted to see how much signal leaks from telephone lines? Or
from ethernet cables? Would an algebraic relationship between ciphertext
bits make it easier for discover the key? Is an MDS matrix necessary for
linear diffusion?
Everything is so cheap nowadays, a software defined radio can be had for
$20.  More impressive than a cryptographic attack against key fobs would be a way
to eavesdrop on all the communications on a telephone line. That'd cause
the immediate adoption of the Clipper Chip!
The academic community for cryptography is strange, no null results are
published anywhere. It'd be useful to have a casual wiki for those. Even if
a novel cryptographic technique that requires more plaintext than
bruteforce for ChaCha is discovered, it would have the potential to be
improved upon.

@_date: 2017-05-06 20:05:19
@_author: Ryan Carboni 
@_subject: [Cryptography] Fixed-state ciphers vulnerable to side channel 
The simplest error correction code is a repetition code. This has escaped
many peoples attention.
" The frequency at which a key should be changed in order to maintain an
minimum level of protection depending on the number of unrolled rounds
computed per cycle is explored."
Here some attacks were made against Simon and Speck.
In my lay opinion, RC4 is more secure for the internet of things. The
greatest vulnerability for computers is memory bound errors, not... uh.
Malicious javascript sending a DDOS on an 100 megabit uplink to a server so
a passive adversary can collect ciphertexts and do statistical analysis.
Naturally everyone says that no one was fired for using AES, but who was
fired for not putting a password on a database?
I think if the RC4 round function was applied key length bytes more times
(128-bit key, 16 more key schedule rounds), the first few bytes will have
less bias, and the only related key recovery attacks apply to the first few
An additional xor to mask the output or input of a byte lookup may improve
Or use an ARX cipher as a NLFSR, like the Lex cipher.
In any case, don't use error correction codes in cryptography.
This is some kinda multidimensional chess.

@_date: 2017-11-22 13:31:37
@_author: Ryan Carboni 
@_subject: [Cryptography] Intel Management Engine pwnd (was: How to find 
There is no logical reason why most of the Intel management engine is
implemented in software.
It should be a coprocessor with most components implemented in hardware.
Too bad we don't have the Clipper chip in our CPUs though. Then we'd be
using TLS Fortezza. No chance of heartbleed or side channels, but we no
doubt will have other issues.

@_date: 2017-11-22 18:33:13
@_author: Ryan Carboni 
@_subject: [Cryptography] Intel Management Engine pwnd (was: How to find 
That is correct.
There are people like Robert Graham who say that American tax money, when
used to purchase munitions in the nation interest, should not be used to
protect Americans, but to attack enemies of the state. I think this is
Well, I digress. Anyway, Facebook's run fast and break things wouldn't have
worked for NASA whose coding practices are very slow.
But I doubt even 10% of a modern CPU's cost is in R&D or at least design
for the wiring. Multi-billion dollar chip fabs. Rare elements. High quality
control standards.
To sufficient amortize the cost of a modern chip fab, it must require
selling hundreds of millions of chips.

@_date: 2017-11-22 18:45:24
@_author: Ryan Carboni 
@_subject: [Cryptography] Intel Management Engine pwnd (was: How to find 
You are right, and Joanna Rutkowska is wrong. I guess stateless isn't what
it is cracked up to be.

@_date: 2017-11-25 15:44:25
@_author: Ryan Carboni 
@_subject: [Cryptography] Intel Management Engine pwnd 
I wish you didn't suddenly fall silent about your suspicions about IPSEC.
You may have been on to something.
Regardless, clearly the mechanism is:
1. Make standards more complex.
2. Hire employees of private companies to commit fraud and theft against
their employer (usually through an allied Five Eyes to get around domestic
restrictions), the complex standard makes it easy to subvert.
3. Options are endless, Socat backdoor is one example.
There is an odd pattern of standards with non-standardized features.
Regardless, FIPS certification requires submitting the design to NIST? Are
you alleging that Intel isn't making their errata fully known?
Your attitude seems to be:
1. Be outraged.
2. Sit.
3. Accomplish nothing.
I'm not entirely sure the point of the open letter to Congress (
 ) I mean, are you saying the government is
lawless and we aren't in a democracy, or the government is lawful and we
are in a democracy? If it's lawless, then why would they listen? If it is
lawful, then wouldn't the mass surveillance be lawful?
But I don't have a PhD so...

@_date: 2017-11-29 15:38:55
@_author: Ryan Carboni 
@_subject: [Cryptography] Intel Management Engine pwnd 
So you're saying this violates the end-to-end principle?
It should be requesting it's own IP address and possess it's own MAC, if
Seems like someone dropped the ball in the Trust Computing Group.

@_date: 2017-11-29 17:39:02
@_author: Ryan Carboni 
@_subject: [Cryptography] Intel Management Engine pwnd 
Don't ludicrous, the US government funds orbital satellites with atomic
clocks on them. (bafflingly, the iphone compass app requires a barometer to
determine altitude when GPS is three-dimensional)
Probably better off with the clock being reset when unplugged, it has
horrible accuracy anyway, worse than quartz wristwatches.
If one is worried about spoofed ntp packets after the time is reset, to
allow revoked certificates being used, then one is facing a far more
elaborate attack then typically practiced.

@_date: 2017-11-30 13:40:57
@_author: Ryan Carboni 
@_subject: [Cryptography] Rubber-hose resistance? 
The freemasons have kept their secrets for longer than the US government.
Perhaps one should learn from them.
But it is a secret.
So who knows?

@_date: 2017-10-19 00:16:40
@_author: Ryan Carboni 
@_subject: [Cryptography] Decoding Simon and Speck: Block Ciphers for the 
I have previously told the Tor developers that they should work in PR, now
I believe that the NSA is also very good at PR. I shall decode Simon and
Speck: Block Ciphers for the Internet of Things for you.
" In a stable world, it’s a good strategy to specialize, but when
conditions change rapidly, specialists don’t always fare so well"
everyone uses AES. Or Keeloq. Or RC4. People select the protocol for the
application they will use, hence why the IoT won't use WPA2. Of course
digital signal processing requires many many gates so...
"For example, the consensus has long been that a budget of 2000 GE is all
the chip area that might reasonably be allocated for security on the most
constrained RFID tags"
Who sets the consensus? I believe Snowden and John Gilmore had something to
say about IPsec consensus?
Regardless, nearly 40% of the registers for 256-bit secure Simon is for the
temporary key. It isn't hard to beat Simon's security for better RFID
performance, but that would hurt it's performance on other applications.
Every cryptographer, particularly the ones who work on examining Keeloq
have totally failed to notice this.
"One further point about AES: not every application requires the same high
level of security that AES is designed to provide."
AES is the worst cipher to be adopted by American industry since DES.
Should've gone with Skipjack.
"that almost exactly matches PRINCE’s latency and area; it implements the
combinational logic for 5 rounds, and encrypts in b 44 / 5 c 9 cycles."
Yes, designing a hardware implementation with reasonable parameters will
reduce latency and area. Would you be surprised if Prince would be better
as a 2 cycle implementation?
"This is excellent performance relative to other block ciphers; indeed
CLEFIA realizes the 'world’s highest hardware gate e ciency'"
Other block ciphers may have been incompetently designed.
"The C implementations of Speck 128/256 have better overall performance
than the best C implementations of ChaCha20, a stream cipher especially
noted for its speed."
ChaCha is a 512-bit poorly keyed block cipher. To achieve diffusion over
such a large block size, more rounds and instructions are needed. To
achieve non-linear dependency on each key bit, more rounds are needed.
Naturally they said in a previous paper that ChaCha doesn't compare to
Speck because it is a stream cipher (weird meme). It is a sad comedy when a
protocol uses SHA-2-512 and truncates it to 256-bits to key a cipher when
to avoid slide and Meet in the Middle attacks one needs at least twice the
round keys.
Anyway, embedded micro controllers for storage devices are 100 MHz ARM CPUs
that cost half a cent each. There exists cheap FPGAs with a thousand slices.
"AES, on processors with cache memory can be particularly vulnerable to
these cache-timing attacks"
they just trolling you now and you don't see it
"Because of their simplicity (and perhaps because of their source!)"
The NSA is very sexy. Join us.
"Simon and Speck have been quite thoroughly vetted by the cryptographic
community in the two years since their publication."
Simon and Speck are very secure because numerous papers have incrementally
improved upon each other, fortunately there wasn't a major breakthrough
because that might halve the number of papers released. (oddly enough many
of the papers were from Chinese researchers)
The NSA manipulates you to your face, and you have failed. Each and every
one of you.
P.S. The phone system was a trade secret, but now WPA2 specification is a
paywall. All these bought off cryptographers are in a cover their ass
operation. They know they overlooked it, they have to explain to you why
they overlooked it so they can still appear valuable to you. We could've
had the Clipper chip, but now we may as well be using Tribler's OFB with
same IV (nothing to see here).
Anyway, WPA3 is needed for post-quantum eventually. Everything should head
towards some sort of post-quantum algorithm, now that NTRU's patent
expired. There is no reason why NTRU is not used, and I'd suggest
conservative parameters for a given amount of input entropy.
Smart cards and post-quantum for everything.
P.P.S. Binney is a pathological liar. Just watch A Good American on
Netflix. It is no wonder that the EFF is currently ineffectually
complaining about unconstitutional laws. John Schindler is right, he
doesn't express himself well, but I'm pretty sure he represents the
opinions of the intelligence community in that many of you are blind and
incompetent. (naturally the same could go for the intelligence community...)
Bonus round because a helicopter flew over my house:
Schneier said: "There is too much mistrust in the air. NIST risks
publishing an algorithm that no one will trust and no one (except those
forced) will use."
That means trust me, I am opposed to what is happening and I am an expert.
Schneier then said: I misspoke when I wrote that NIST made "internal
changes" to the algorithm. That was sloppy of me. The Keccak permutation
remains unchanged. What NIST proposed was reducing the hash function's
capacity in the name of performance. One of Keccak's nice features is that
it's highly tunable.
Oh, I was just exaggerating, trust me, I have gone over to the other's side.
When a familiar face changes their mind, will you go along with them if you
were wavering to begin with?

@_date: 2017-09-11 07:39:49
@_author: Ryan Carboni 
@_subject: [Cryptography] What is the impact of the Quantum Fourier transform 
What is the impact of the Quantum Fourier transform on signal processing?

@_date: 2017-09-17 19:27:39
@_author: Ryan Carboni 
@_subject: [Cryptography] Cold Boot Attack Prevention 
The application of old ideas to old problems, may solve current
problems, which are really old problems.
Possibly the cheapest secure cryptographic device is an arduino with a
screen and keypad inside a faraday bag, operated in an underground
parking garage.

@_date: 2018-04-09 12:09:59
@_author: Ryan Carboni 
@_subject: [Cryptography] The surest way to prevent WPA3 
The surest way to prevent WPA3 is to demand 256-bit encryption instead of

@_date: 2018-04-13 18:01:07
@_author: Ryan Carboni 
@_subject: [Cryptography] Will We Ever Learn? 
The Morris worm was in 1988. That's all you need to know about what is
really going on with internet security.
 A worm crashed the internet, and everyone's response is to do nothing.
That wasn't 2017, that was 1988.
Actually the response may have been spy on all the communications to
discover the perpetrator.

@_date: 2018-04-13 18:03:38
@_author: Ryan Carboni 
@_subject: [Cryptography] The surest way to prevent WPA3 
You're right, it is important to accept government standards for
convenience and expediency. They are comprised of trustworthy individuals,
which is why we should grant the government expansive power to exercise in

@_date: 2018-04-19 17:10:16
@_author: Ryan Carboni 
@_subject: [Cryptography] Will We Ever Learn? 
Now you proved we learn some lessons, but not all lessons, and that the
majority of the population is used to finite state machines, not turing
Maybe if we learned all lessons these things won't happen again.
Said in only 44 words.

@_date: 2018-08-09 13:23:28
@_author: Ryan Carboni 
@_subject: [Cryptography] Project Zero has greatly improved 
Project Zero has greatly improved, it shows an activist element now, there
is no point to end to end encryption if the end is being eavesdropped. But
there is one improvement... instead of donating bug bounties to Amnesty
International, it could just go to Google.org to hire more security
researchers. I doubt a complaint could be made that there is too many code

@_date: 2018-02-12 11:22:04
@_author: Ryan Carboni 
@_subject: [Cryptography] Insufficient MAC randomization 
MAC randomization for only probe requests in insufficient. MAC addresses
used for wireless communication should be the product of a hash of the SSID
and some secret value.
There is the risk that there is a collision of MAC addresses, but most
networks don't handle that many devices, and wifi MAC addresses in use
could be detected.
Although I wonder if that even matters.
Ideally ethernet switches are abolished, and replaced with simple routers
that can assign up to 256 IP addresses, taken from a central DHCP server.
10.0.0.0/8 is enough for any network using NAT.
Makes VLANs easier to secure.

@_date: 2018-02-12 12:31:30
@_author: Ryan Carboni 
@_subject: [Cryptography] Useless side channels 
I'm pretty sure it is illegal for airplane mode not to halt all
Of course this won't matter.
I looked into my BIOS settings and apparently there is spread-spectrum
modulation to reduce EMI? No idea if it reduces or masks side channel
emissions. MAYBE THIS REQUIRES RESEARCH.
There are serious vulnerabilities, and everyone looks the other way. It is
a great mystery.
Somehow there is demand for hardware random number generators when you
could fit an antenna to the microphone jack and pick up low frequency
cosmic background radiation. Or even higher frequencies, wifi requires
error correction because of imperfections within the circuitry and echoes
from walls requiring full knowledge of the device's placement and design.
In the end, the most amazing thing is that every purported benefit is
really a hindrance, and real beneficial things without secret problems are
No really, look for every touted benefit that seems to provide marginal
benefit over a simpler solution, and it is really an elaborate backdoor.
x86 is designed for the unlikely scenario that a computer only needs a few
dozen threads.
P.S. Buy iPhones, not Android, because the Apple tax is really the price
for cybersecurity. In some mystery, carrier-specific forks of Android
should really use a subset of apps, unique sprites, and unique bootloader
screens. If Google cared about cybersecurity, they would bar outdated
phones from being sold that can access Google Play. Android 4.4 devices are
STILL BEING SOLD.
Ideally when people buy products, money goes towards a trust for long term
maintenance of them. Like cemeteries. A properly designed product would be
supported for a long time.
Purism's products seem to be from an irrational design basis that the GPL
will cure everything.

@_date: 2018-02-20 21:25:02
@_author: Ryan Carboni 
@_subject: [Cryptography] Conjecture on mathematically evaluating the ideal 
It is unknown how far the distance is between full avalanche and an ideal
cipher is. I do not believe this has been publicly noted, but every cipher
round generates a polynomial. In the most simple case:
(a + 1)(b + 1) vs. (a + 1)(b)
ab + a + b + 1 vs. ab + b
Normal ciphers are algebraically more complex, but the above example shows
a 2-bit cipher with a 1-bit key, as a xor is simply bitwise addition. A
cipher that is secure has enough rounds for algebraic terms to cancel out,
dependent on the key.
It is likely that ciphers do not become secure until they have enough
rounds for the generated polynomial to become a randomly selected
polynomial from all possible polynomials that generate secure permutations
for the given width, or indistinguishability. This may be why some ciphers
are vulnerable to slide attacks, or rotational cryptanalysis, as many
output bits are similar terms at the point of full avalanche.

@_date: 2018-01-22 08:35:43
@_author: Ryan Carboni 
@_subject: [Cryptography] The most effective argument never used during the 
How much should it cost to hack a $100 computer?
No really, poll it. Make opinion polls, get people to print them out and
mail their congressmen. Have the statistical distribution per decile listed.
Fortunately, we had the NSA make the hard decision on how secure computers
should be. The average person is not capable of making a tradeoff between
freedom and security. This is an unfortunate limit to democracy, people
will only demand what is in their own interests, not preventing the
creation of victims.
Perhaps terrorism could be limited in impact by limiting coverage of it
altogether, but journalists can't help themselves or listen to anyone. If
there was proof otherwise, it'd make people question everything.
The cost of securing a computer is only available to the biggest companies
with economies of scale, small businesses are out of luck. An estimate of
losses to economic espionage is $100 billion a year. Thus the value of
American economic insecurity must be greater than that of secure computing
for everyone.

@_date: 2018-01-22 09:27:00
@_author: Ryan Carboni 
@_subject: [Cryptography] Speculation considered harmful? 
I don't know how there is still enough demand to continue development on
Itanium, which ought to be the real question.
The obvious answer to me is (optional) x86 hardware emulation, and stricter
virtualization, with eDRAM buffers and barrel multiprocessing. Technically
MS-DOS is a virtual machine in the same sense that a burrito is a sandwich.
The difference between a proper software and hardware implementation is
only parsing speed.
Arguably the only part of a CPU that needs to be implemented in silicon is
the ALU, everything else can be implemented in a FPGA. Allows for even more
product binning ( a bit further than agner's idea
 ). This is amazing:
 . 2000 slices for something as
fast as a Pentium III or IV.
Regardless, synthetic benchmarks are pointless if no one focuses on the
amount of cycles spent waiting for data.
Forty million cycles to read from disk.
I have no idea how many branches are computed typically, but apparently it
is around a dozen? Seems like a waste in power, to get around the endless spurts and stops.
Ideally Google or Amazon would appoint Agner Fog as CPU Czar. They both
have the spare cash to actually build an entire chip fab.

@_date: 2018-01-26 05:40:50
@_author: Ryan Carboni 
@_subject: [Cryptography] I'll give the right answers to the right questions 
I just skimmed through Computer Organization and Design RISC-V Edition: The
Hardware Software Interface, so I'll just give you some stream of
consciousness notes on a good CPU
Time Stamp Counter should be virtualized. The white hat counterpart to
Rutkowski's blue pill
no out of order execution, or any other just in time compilation
no speculative execution
implicit parallelization
implement major components of the operating system in hardware, Xen is only
twenty megabytes which is comparable to maximum bitstream size for some FPGA
arguably the only thing that needs to be implemented in silicon is the ALU,
and the bus
each core has multiple threads, even shadow threads invisible to root meant
to handle interupts
to deal with context switch delays, pipeline threads, this may be called a
ready queue?
if a processor can rename registers on the fly, it should be able to load
processes quickly
in fact this may be to some degree done with hyper threading, although
unsure why it is apparently limited to two threads per CPU, although it may
require multiple instruction decoding
buffers, " It seems like the P4 flushes its micro-op cache as part of
handling an interrupt" although this still wouldn't prevent having two threads per CPU, and at
least one standby thread, particularly if a branch prediction buffer is
eDRAM cache buffer scheduled threads, and to partially virtualize L1 caches
for them. maybe no shared caches, everything must be copied into L1 first.
the best possible compromise for single thread performance is to allow the
OS to flag a thread with a high priority, two threads with unequal priority
on a core will mean the higher priority thread will run until its allotted
cycles run out or there is a stall, creating de facto coarse
multithreading, although this seems unlikely to be needed
apparently dynamic power use has been reducing, so speculative execution is
not as big of a power hog as increasing clock speed
copy on write should be done in a way to avoid any possible race condition,
if multiple processes are aware of data before it is marked copy on write,
it is being done wrong
incoherent data should be avoided
anything in complexity that exceeds the short term memory of the smartest
programmers should be avoided
branch prediction apparently involves flushing instructions halfway
ideally flushing is constant time to avoid side channels, which would make
it easier as well, although more hardware intensive
overall illogical and detrimentral design decisions have led to the erosion
of computer security.
emphasis on single thread performance neglects modern computing design
obviously branch prediction or any other optimization should be toggled for
There are many ways of performing a context switch. The x86 CPU provides a
way of doing it completely in hardware, but for performance and portability
reasons most modern OS's do
context switches in software.
The upshot is this: Intel's x86 is a high-level language. Coding everything
up according to Agner Fog's instruction timings still won't produce the
predictable, constant-time code you are looking for. There may be some
solutions, like using CMOV, but it will take research.
research... hmmm... execute and then check or check then execute?
an interesting meme, research, research, research
research and then implement an idea or implement an idea and then research

@_date: 2018-07-11 17:57:52
@_author: Ryan Carboni 
@_subject: [Cryptography] "Public Accountability vs. Secret Laws: Can They 
Someone proposed a blockchain for secret government decisions.
The idea that you have to pay people to store encrypted secret information
is silly. Forty people are storing WikiLeak's secrets for free (
41b179c71088ff5032ad8517c9ff5a3f40c7490f ).
It is disappointing that papers exist where the authors lack common sense,
the quote of Kafka at the beginning is nice but it doesn't seem to account
for how reality works. Released decisions which are enforced against every
major corporation have the name of the corporation redacted (hmm, is this
Verizon? Comcast? is there an option for all of the above?). Redacting a
document is changing it, and would have a different hash regardless.
Furthermore, these are documents that in order for the government to
operate, must be seen by a large number of people, who if they are
betraying the public trust, would be fired.
It's almost as if civil liberty activists don't really take their jobs
seriously. Who on Earth advocates for civil liberty and doesn't understand
one iota of political science?

@_date: 2018-06-13 19:20:24
@_author: Ryan Carboni 
@_subject: [Cryptography] How to make rowhammer less likely 
AES CTR is used for encryption. Now, 8-bit bytes are used so that does
limit what one can do, but if in addition a unique 8-bit involution was
used to encrypt the data in each memory page, in order to successfully
rowhammer bits, it would require obtaining the full codebook for the target
I realize this solution is so simple it may have simply not occurred to
anyone of you. But now I've proposed it, so maybe the cybersecurity
everyone needs gets closer to being realized.

@_date: 2018-03-13 08:43:14
@_author: Ryan Carboni 
@_subject: [Cryptography]  On those spoofed domain names... 
Ah yes, the dilemma between whitelisting and blacklisting.
Between strict parsing and whatever javascript is.
Between promiscuous devices, and uh...
Uh, you do realize that US spy satellites probably record all Wi-Fi beacon
frame responses right?

@_date: 2018-03-13 09:09:31
@_author: Ryan Carboni 
@_subject: [Cryptography] You guys do realize the first crypto war was lost, 
There is evidence that since 1997, we have been buying chips with secret
features that would make our computers more secure, but have been denied to
us as a de facto backdoor right?
There is the reverse of the clipper chip. Except the silicon and the API to
access it is secret, as opposed to only the API.
It is hard to come to any other conclusion that pro-cryptography civil
libertarians are anything other than clowns when Zerodium pays up to
$10,000 for router exploits. You know. Routers, the ones with 128-bit WPA
encryption with shared secrets for multiple devices? I suppose people won't
"wittingly" buy backdoored products.
The good news is that bruteforcing 128-bit encryption with a classical
computer is that it would cost 2^56 times as much as gross bitcoin mining
expenditures. Somehow estimated bitcoin mining expenditures don't seem to
add up though, shouldn't intelligence agencies be able to crack 2^80
encryption with ASICs? Currently costs several billion to preimage at 2^73

@_date: 2018-03-17 21:04:13
@_author: Ryan Carboni 
@_subject: [Cryptography] What everyone is saying about mobile OS security is 
Google Play has given Google more control over security. Like Apple's App
Store, one central app distribution point gives Google more security
control. Google noted that Android devices that only download apps from
Google Play are nine times less likely to get a PHA than devices from other
sources. Google Play Protect protects almost two billion devices.
But is the above precisely correct?
While all Android devices benefit from protections built into the platform,
Android devices with Google Play services have an additional layer of
defense to keep them safe. Google protects these devices right out of the
box with Google Play Protect, our built-in device, data, and apps security
scanning technology.
No it is not, Google Play apps are scanned using a cloud anti-virus program.
What else is special about Google Play?
Manufacturers can be refused a licence if they do not meet Google's
requirements. Google does not charge for a GMS licence, but any company
producing an Android device will need a certificate from an authorised
testing facility in order to apply for the licence. That often incurs fees.
One source told the Guardian that the fee varies and is negotiated on a
case-by-case basis, with one example costing $40,000 for a batch of at
least 30,000 devices. A separate source said that in another deal, a
testing facility quoted $75,000 to test 100,000 devices.
And rather recently, Joseph Cox said in tweets within hours of each other
that the US government shutdown a phone maker that could only sell secure
Blackberries to drug dealers and that a judge signed a warrant for any
Google location enabled apps. For some reason, the Tor Project recieves
more free PR than any business providing a phone remotely resembling
anything that is desired by civil libertarians.
You people don't notice anything. At all. You people never accomplish
anything useful you want, ever.
It is extremely trivial for Google to make Android more secure, create an
app anti-virus API, require security updates within one month of the issue
being discovered for Google Play access, etc.
And the question about whether devices should be rooted or not by the user
is pretty simple. An unrooted device is a production environment designed
to be secure by hundreds of people, and the occasional bug bounty. A rooted
device is a development environment whose security is owed to anyone with
physical access to it.

@_date: 2018-10-29 23:04:06
@_author: Ryan Carboni 
@_subject: [Cryptography] Observation on Simon and Speck 
Simon has 72 rounds, minus 11 rounds for diffusion. Each round uses a
single AND gate per bit, so 61 AND gates are used per bit for the internal
Speck has 32 rounds, minus 8 rounds for diffusion. Each nonlinear function
could be evaluated as either two AND gates or maybe one and a half AND
gates, which isn’t strictly accurate. For the internal function, either 72
AND gates could be said to be used or 60 AND gates.
It appears to achieve 256-bits of security, one only needs about 60 AND

@_date: 2018-09-03 13:49:34
@_author: Ryan Carboni 
@_subject: [Cryptography] WireGuard 
I said this once before and I'll say it again, you people don't notice
anything. I have pointed out that the total cost for mining Bitcoin at
current difficulty proves that 80-bit security is still sufficient, which
is puzzling to some degree or another. Right now ~72-bit difficulty costs
less than a billion dollars to mine. (although it could be that all Bitcoin
miners aren't designed efficiently!)
Everyone here should know that the biggest issue everyone realized after
the Snowden revelations was metadata. People are still talking about
directly attacking crypto.
The direct cost of attacking DES is less than a majority of computer
vulnerabilities that the US government pays for. The Crypto War was
It's probably useful to note that sponge constructions are just wide block
CFB with hidden state. It could be explored how to create other
constructions from block cipher modes of operation.
What good is end to end encryption if the end isn't secure? Double
transposition is potentially post-quantum secure.

@_date: 2019-10-19 22:29:14
@_author: Ryan Carboni 
@_subject: [Cryptography] Current state of tools for making parallelized 
Since 2012 it has been possible to brute force the entire DES keyspace
with GPUs in under a day without needing to hire an electrician.

@_date: 2019-09-24 18:33:46
@_author: Ryan Carboni 
@_subject: [Cryptography] "Exclusive: Russia carried out a 'stunning' 
Well. The US government deprecated 80-bit ciphers a while back.
What makes anyone believe anything about people they never met???

@_date: 2020-02-04 18:57:25
@_author: Ryan Carboni 
@_subject: [Cryptography] SSL Certificates are expiring... 
To repeat a previous email sent to this mailing list (the responses
were along the lines that everything will be quickly updated):
Shouldn?t root certificates switch to McEliece?
Certificates are used for decades, and thus is the only public key
cryptography that need to be protected with the same schedule that the
NSA has.
Let?s Encrypt?s roadmap for upcoming features has ?Support for signing
ECDSA keys with a full ECDSA cert chain will be added later.?
Perhaps it has stalled, but it seems like people are heading into a
direction where cryptography is weaker in the long term?
Maybe the transition will begin at the last minute when academics
finally factor a 128-bit semiprime with a quantum computer

@_date: 2020-02-13 01:09:50
@_author: Ryan Carboni 
@_subject: [Cryptography]  
The Rabin cryptosystem is listed on wikipedia. I don't understand the
math behind it particularly well, but "the Rabin cryptosystem has the
advantage that it has been mathematically proven to be computationally
secure against a chosen-plaintext attack as long as the attacker
cannot efficiently factor integers, while there is no such proof known
for RSA."

@_date: 2020-02-15 06:43:48
@_author: Ryan Carboni 
@_subject: [Cryptography] 'The intelligence coup of the century' 
It is amazing how fast people will change their tune from "that damn
darn NSA is in all our things" to "yeah, it cool, it is just how it
is" based on the right signals.

@_date: 2020-02-16 04:54:37
@_author: Ryan Carboni 
@_subject: [Cryptography] 'The intelligence coup of the century' 
I recommend reading the below Wikipedia article and then reconsider
your choice of profession.

@_date: 2020-02-16 22:59:37
@_author: Ryan Carboni 
@_subject: [Cryptography] SSL Certificates are expiring... 
What you're saying is irrelevant without standards that aim for secure
authentication (which no western country has ever directly
prohibited). Given that everyone complains about forgeries and deep
fakes, but no one is reacting to the inherent democratization of the
technology behind it, stronger standards for authentication within
consumer products are necessary. Cameras with post-quantum signatures
of keyframes, smart cards immune to fault injection, etc.
I find it strange how the least controversial issues become so
incredibly controversial sometimes.

@_date: 2020-02-17 04:51:05
@_author: Ryan Carboni 
@_subject: [Cryptography] SSL Certificates are expiring... 
Given how hard MSNBC has to remind people of recent news, I wonder how
long-term people's memories are. There was a rather big scandal some
time ago...
Every once in a while, someone not an NSA employee, but who had
longstanding ties to NSA, would make a suggestion that reduced privacy
or security, but which seemed to make sense when viewed by people who
didn't know much about crypto.

@_date: 2020-02-19 02:23:30
@_author: Ryan Carboni 
@_subject: [Cryptography] With an e2e network, 
The Chinese have only shown an aptitude at counterfeiting American
ingenuity, I think it would be simpler to cut the middle man and trust
Americans to protect Americans?
This kill people on metadata argument sounds awfully similar to
Snowden's belayed accusation that people at the NSA voyeuristically
share intercepted porn.

@_date: 2020-02-19 20:42:40
@_author: Ryan Carboni 
@_subject: [Cryptography] With an e2e network, 
Don't some companies design their own routers?
No idea what I'm talking about, but a slap-dash solution could be
achieved at the expense of 50% more power consumption and/or 50% more
Watching a robber steal your stuff while staring at them saying, "Yes,
I know what is really going on here." is unusual...
Amazon Web Services is developing customer semiconductors to
accelerate its cloud computing network, expanding its push into custom
hardware, the company said Tuesday. AWS says its new Annapurna ASIC
will enable it move data faster across its huge data center network.

@_date: 2020-01-20 23:04:59
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
I think relying on a combination of futex and ram latency benchmarks
would be enough to provide a reliable source of entropy.
At least a reliable source of entropy of at least 64-bits, of which
there are cheaper ways to break ciphers than through brute force.
Unfortunately, the data turns out to be very noisy. It's very hard to
see if there is a noticeable delay related to the refresh cycles.

@_date: 2020-01-21 00:42:43
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
The Dykstra problem or the McNamara problem?
"named for Robert McNamara, the US secretary of defense from 1961 to
1968, involves making a decision based solely on quantitative
observations (or metrics) and ignoring all others. The reason given is
often that these other observations cannot be proven. "
Smarter decisions are possible if not bound by nomograms or numerical estimates?

@_date: 2020-01-22 07:09:26
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
No, the McNamara fallacy is a valid point. Reality is not merely a
series of numbers to be inventoried by other people or machines,
reality is far more complex and overlooking the complexity will
directly result in failure. The scrypt paper estimates the value of 64
bits of security to be in the millions for password derivation
functions, Schneier's paper on Minimal Key Lengths estimates the value
of 60 bits of security to be $300k in FPGA, COPACOBANA costs
Factually at $1 million, there are more efficient ways to do things. (
 )
Regardless, if you have an adversary capable of benchmarking
production lots of processors for intrinsic properties, be glad that
they are breaking the RNG that way as opposed to other ways...

@_date: 2020-01-22 20:00:00
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
Uh, yes. Unknown information about the start of a program is somewhere
between 17 bits to 32 bits of entropy.  The entropy collected for
modern cryptography is only from the asynchronous operation of
multiple circuits.
Etc, etc.... This is basic computer science.
The system clock seed gave us an idea that reduced the number of
possible shuffles even further. By synchronizing our program with the
system clock on the server generating the pseudo-random number, we are
able to reduce the number of possible combinations down to a number on
the order of 200,000 possibilities. After that move, the system is
ours, since searching through this tiny set of shuffles is trivial and
can be done on a PC in real time.

@_date: 2020-01-22 21:52:59
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
I wonder if I am living in a bizarre comedy, and then I receive
through the electric post a communique about how knowledge has gone
I think if an effort was made to rediscover it, the same conclusions
would be made, and so the knowledge is still valid...

@_date: 2020-01-22 22:32:42
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
To circle back to my original post, the FFT was used to detect
patterns by a Cloudflare employee in RAM refresh.
If there are cyclical patterns, a FFT would detect some of them.
A RNG that fails a statistical test may not be broken if the problem
can be worked around. Otherwise you're all stupid and I should stop
using Linux, and maybe go back to using rock and sticks.

@_date: 2020-01-23 00:25:01
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
What. You mean like very smooth hash, a provably secure hash function?

@_date: 2020-01-24 01:26:43
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
each outlet in your house has a different voltage
a presumption based on the house I live in
regardless, unless it is network boot, a fallback can be reading from
the boot sector and using latency from it

@_date: 2020-03-06 21:59:59
@_author: Ryan Carboni 
@_subject: [Cryptography] Proper Entropy Source 
well, since I'm sure everyone here has read into RDRAND because that
was a hot topic a while back...
"If you put two 64-bit values with additive prediction resistance
togehter [sic], the prediction resistance of the resulting value is
only 65 bits"
now, if you can observe when multiple events occur, each event
providing 10 bits of entropy (I think entropy estimates are
conservative for different reasons), you can engage in something
similar to a meet-in-the-middle attack. This isn't advanced math, I
never passed community college calculus.
There is some boot entropy in reading RAM, reading (at most) a few
random gigabytes of physical RAM might provide a few bits with minimal
additional boot latency, there is some clock drift in CPUs, so there
might be twenty bits of entropy there, CPUs are fairly asynchronous
internally, and RAM operates on their own clock so there is some
entropy in using interactions between the processor and RAM. This
isn't complex stuff.
I wonder why no one speaks much about it.
Anyway, it is unlikely the minimum amount of security practically
obtainable will be much more than the cost of bruteforcing a 72-bit
