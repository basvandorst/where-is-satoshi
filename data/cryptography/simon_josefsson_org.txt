
@_date: 2007-04-05 22:47:30
@_author: Simon Josefsson 
@_subject: DNSSEC to be strangled at birth. 
If you control the root signing key, you can sign a new zone key for,
e.g., '.com' and then create whatever content you want, e.g.,
'example.com' and sign it with your newly created '.com' zone key.
The signatures would chain back and verify to the root key.
However, in practice I don't believe many will trust the root key
alone -- for example, I believe most if not all Swedish ISPs would
configure in trust of the .se key as well.  One can imagine a
web-of-trust based key-update mechanism that avoids the need to trust
a single root key.

@_date: 2007-04-26 15:37:23
@_author: Simon Josefsson 
@_subject: open source disk crypto update 
I believe this is a not completely unreasonable threat.  Modifying files
on the /boot partition to install a keylogger is not rocket science, and
(more importantly) can be done remotely, if you gain unauthorized access
to the machine.
If you boot from a trusted USB stick instead, and check the integrity of
the hard disk, the attacker needs to modify BIOS in order to install the
keylogger.  This may be sufficient difficult to do on a large scale
(there are many different ways to update BIOS software), so that the
attacker goes away to try some other weakness instead.
There is one aspect that I don't recall seeing in this thread: if you
use a laptop, and suspend it to disk, there is no encryption or
authentication of the data as far as I know.  (I believe swsusp
optionally can use SHA-1 or MD5 to verify integrity, but the hash is not
keyed.)  For example, your SSH or PGP RSA key may be copied to disk
without warning.  In addition, someone could modify the on-disk RAM
image to add a new root process when you restart the machine.
Installing or enabling such features remotely is difficult, and
(importantly) cannot be done in the same way for all hardware.

@_date: 2007-10-02 15:50:27
@_author: Simon Josefsson 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
Following up on an old thread with some new information:
Interestingly, Hitachi has updated that paragraph in the paper (re-using
the same URL), and now it reads:
  Hitachi will be offering the Bulk Data Encryption option on specific
  part numbers of all new 2.5-inch hard disk drive products launched in
  2007, including both the 7200 RPM and 5400 RPM product lines. For a
  list of specific part numbers that include the Bulk Disk Encryption
  feature or for more information on how to use the encryption feature,
  see the ?How To Guide? for Bulk Data Encryption Technology available
  on our website.
The How To Guide includes screen shots from BIOS configuration.  The
disk appear to be using the standard ATA BIOS password lock mechanism.
The guide is available from:
Without access to the device (I've contacted Hitachi EMEA to find out if
it is possible to purchase the special disks) it is difficult to infer
how it works, but the final page of the howto seems strange:
   Disable security
   ----------------
   For an end user to disable security (i.e., turn off the password
   access control):
     1. Enter the BIOS and unlock the drive (when required, BIOS
     dependent).
     2. Find the security portion of your BIOS and disable the HDD user
     password, NOT the BIOS password. The master password is still set.
   NOTE: All data on the hard drive will be accessible. A secure erase
   should be performed before disposing or redeploying the drive to
   avoid inadvertent disclosure of data.
One would assume that if you disable the password, the data would NOT be
accessible.  Making it accessible should require a read+decrypt+write of
the entire disk, which would be quite time consuming.  It may be that
this is happening in the background, although it isn't clear.
Another interesting remark is:
  Note that the access method to the drive is stored in an encrypted
  form in redundant locations on the drive.
It sounds to me as if they are storing the AES key used for bulk
encryption somewhere on the disk, and that it can be unlocked via the
password.  So it may be that the bulk data encryption AES key is
randomized by the device (using what entropy?) or possibly generated in
the factory, rather than derived from the password.

@_date: 2007-09-07 11:46:22
@_author: Simon Josefsson 
@_subject: Seagate announces hardware FDE for laptop and desktop machines 
Hitachi's white paper is available From-Mail: From-Name: Btw, it contains something as rare as a reasonable threat analysis!  At
least compared to other advertising materials...
After having acquired the 1TB device, and didn't find any support for
this feature, I re-read some information: The interesting part is the
final sentence of the white paper:
   Hitachi will be offering the Bulk Data Encryption option on all new
   2.5-inch hard disk drive models launched in 2007, including both the
   7200 RPM and 5400 RPM product lines. At the request of the customer,
                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   this option can be enabled or not, at the factory, without any impact
   on the drive?s storage capacity, features or performance.
I wonder how easily it would be to request this for a normal customer.
I gave up when my supplier said they didn't offer this configuration.
I would be interested to know which key-derivation function they are
using, I'm assuming the key is derived from a password, and which AES
mode and IV etc.  Knowing that may enable you to verify that data is
really stored encrypted: buy two devices, set up one to use disk
encryption, and swap the logic boards and then read data from the
supposedly encrypted disk.  As for finding out if they accidentally also
write down the AES key on some hidden part of the disk, that may be more

@_date: 2008-12-16 18:10:03
@_author: Simon Josefsson 
@_subject: CPRNGs are still an issue. 
Not quite, you can optimize that.  Some software (e.g., OpenWRT) forces
users to access the device via (local) ethernet before wireless is
enabled.  This enables security aware people to configure wireless
security, and avoid a period of insecure wireless network.
Incidentally, this approach also enables devices to collect entropy from
the user session.  That could be useful when generating SSH private
keys.  (Although I believe, unfortunately, OpenWRT generates the SSH key
directly after the first boot.  It seems unclear what kind of entropy it
can hope to have at that point?)
I agree with your recommendation to write an AES key to devices at
manufacturing time.  However it always comes with costs, including:
1) The cost of improving the manufacture process sufficiently well to
make it unlikely that compromised AES keys are set in the factory.
2) The cost of individualizing each device.
Each of these costs can be high enough that alternative approaches can
be cost-effective. (*) My impression is that the cost and risks in 1)
are often under-estimated, to the point where they can become a
relatively cheap attack vector.
(*) In case anyone doubts how the YubiKey works, which I'm affiliated
with, we took the costs in 1) and 2).  But they are large costs.  We
considered to require users to go through an initial configuration step
to set the AES key themselves.  However, the usability cost in that is
probably higher than 1) and 2).

@_date: 2008-02-18 12:05:49
@_author: Simon Josefsson 
@_subject: Toshiba shows 2Mbps hardware RNG 
Alas, reading from /dev/urandom depletes the entropy pool much like
reading from /dev/random does.  So if you read a lot of data from
has hit libgcrypt/gnutls via the MTA Exim on a lot of Debian systems.  I
would argue that the linux kernel /dev/*random system is sub-optimally
designed, reading a lot of data from /dev/urandom should not cause the
system's /dev/random to be unusable.
(Admittedly, there were other design flaws in how exim used gnutls, such
as re-generating the DH parameters every X hour, and doing that
synchronously in the SMTP process, causing them all to stall waiting for
entropy, but that has been fixed.)

@_date: 2008-06-04 16:24:15
@_author: Simon Josefsson 
@_subject: Protection mail at rest 
Actually, PGP/MIME uses the same high-level mechanism to wrap MIME
objects as S/MIME does: The PGP/MIME description is in: Specification wise both should work equally well, but implementation
quality may differ.
What is often overlooked is that the e-mail envelope (including the
within the PGP/MIME (or S/MIME) message.  Interoperability of that has
historically been poor, but the more modern MUAs should handle it today.
Writing a .forward proxy that wraps incoming e-mails into PGP/MIME
encrypted message/rfc822 attachments should be simple, probably simpler
than PGP/MIME wrapping all the individual MIME parts in the incoming

@_date: 2008-05-26 11:22:18
@_author: Simon Josefsson 
@_subject: The perils of security tools 
For the linux kernel, there is a paper:
Another important aspect is the semantics of the devices: None of the
There semantics can and do differ.  This is a larger practical problem.
For example, reading a lot of data from linux's /dev/urandom will
deplete the entropy pool in the kernel, which effectively makes reads
from /dev/random stall.  The two devices uses the same entropy pool.
I believe a much better approach would be if /dev/urandom was a fast and
secure PRNG, with perfect-forward-secrecy properties, and /dev/random
was a slow device with "real" entropy (whatever that means..) gathered
from the hardware.  The two devices would share little or no code.  The
time, or from other sources (like kernel task switching timings).  I
believe designs like this have been proposed from time to time, but
there hasn't been any uptake.

@_date: 2008-05-27 11:38:43
@_author: Simon Josefsson 
@_subject: The perils of security tools 
Do you have any references?  Several people have brought this up before
and have been told that the design with depleting the entropy pool is
Still, the semantics of /dev/*random is not standardized anywhere, and
the current implementation is sub-optimal from a practical point of
view, so I think we are far away from an even OK situation.

@_date: 2010-08-17 22:32:52
@_author: Simon Josefsson 
@_subject: 2048-bit RSA keys 
Another breakthrough in integer factoring could be sufficient for an
attack on RSA-2048.  Given the number of increasingly efficient integer
factorization algorithms that have been discovered throughout history,
another breakthrough here seems more natural than unlikely to me.

@_date: 2010-03-24 09:28:08
@_author: Simon Josefsson 
@_subject: "Against Rekeying" 
One situation where rekeying appears to me not only useful but actually
essential is when you re-authenticate in the secure channel.
TLS renegotiation is used for re-authentication, for example, when you
go from no user authentication to user authenticated, or go from user X
authenticated to user Y authenticated.  This is easy to do with TLS
renegotiation: just renegotiate with a different client certificate.
I would feel uncomfortable using the same encryption keys that were
negotiated by an anonymous user (or another user X) before me when I'm
authentication as user Y, and user Y is planning to send a considerably
amount of traffic that user Y wants to be protected.  Trusting the
encryption keys negotiated by user X doesn't seem prudent to me.
Essentially, I want encryption keys to always be bound to
Yes, the re-authentication use-case could be implemented by tearing down
the secure channel and opening a new one, and that may be overall
simpler to implement and support.
However, IF we want to provide a secure channel for application
protocols that re-authenticate, I have a feeling that the secure channel
must support re-keying to yield good security properties.

@_date: 2010-10-06 21:43:04
@_author: Simon Josefsson 
@_subject: Formal notice given of rearrangement of deck chairs on RMS PKItanic 
Another consequence is that people will explore moving to ECC, which is
less studied than RSA and appears to be a patent mine-field.  As much as
I'd like to get rid of old hard coded CAs in commonly used software, I
feel there are better ways to achieve that than a policy like this.

@_date: 2015-08-03 22:34:17
@_author: Simon Josefsson 
@_subject: [Cryptography] asymmetric attacks on crypto-protocols - the 
(Tom Ritter's message of "Sun, 2 Aug 2015 08:20:26 -0700")
The "running code" approch could lead the attacker to change its modus
operandi to 1) attempt to get implementers/deployers out of the decision
making process, or at least sufficiently balanced with people who never
writes code or deploy code, combined with 2) attempts to stall
publication of implemented protocols.  Both are relatively cheap to
achieve in a good-faith organization by a bad-faith participant, and is
possible to do indirectly without being identified.  In the end you get
"rough consensus" decision-making, with the problems discussed here,
without the "running code" mitigator.  Success for the attacker.
The IETF is, I would argue, extremely good at refining/documenting
deployed protocols and resolving identified problems with them.  It has
never (or at least not as long as far as I've been around) been good at
designing things from scratch when the use-case is not clearly expressed
and agreed on.  Sadly it has not been good at learning from this history
